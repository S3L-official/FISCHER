; ModuleID = '../examples/rivain-ches2010-mult.inline-40.ll'
source_filename = "../examples/rivain-ches2010-mult.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@d = dso_local constant i32 40, align 4
@.str = private unnamed_addr constant [7 x i8] c"verify\00", section "llvm.metadata"
@.str.1 = private unnamed_addr constant [35 x i8] c"../examples/rivain-ches2010-mult.c\00", section "llvm.metadata"
@llvm.global.annotations = appending global [2 x { i8*, i8*, i8*, i32 }] [{ i8*, i8*, i8*, i32 } { i8* bitcast (void (i8*, i8*, i8*)* @sec_mult to i8*), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i32 0, i32 0), i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.1, i32 0, i32 0), i32 3 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (i8*)* @refresh_masks to i8*), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i32 0, i32 0), i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.1, i32 0, i32 0), i32 29 }], section "llvm.metadata"

; Function Attrs: alwaysinline nounwind uwtable
define dso_local void @transform(i8* %from, i8* %to, i8 (i8)* %f) #0 {
entry:
  %0 = load i8, i8* %from, align 1
  %call = call zeroext i8 %f(i8 zeroext %0)
  store i8 %call, i8* %to, align 1
  %scevgep.1 = getelementptr i8, i8* %from, i64 1
  %1 = load i8, i8* %scevgep.1, align 1
  %call.1 = call zeroext i8 %f(i8 zeroext %1)
  %scevgep2.1 = getelementptr i8, i8* %to, i64 1
  store i8 %call.1, i8* %scevgep2.1, align 1
  %scevgep.2 = getelementptr i8, i8* %from, i64 2
  %2 = load i8, i8* %scevgep.2, align 1
  %call.2 = call zeroext i8 %f(i8 zeroext %2)
  %scevgep2.2 = getelementptr i8, i8* %to, i64 2
  store i8 %call.2, i8* %scevgep2.2, align 1
  %scevgep.3 = getelementptr i8, i8* %from, i64 3
  %3 = load i8, i8* %scevgep.3, align 1
  %call.3 = call zeroext i8 %f(i8 zeroext %3)
  %scevgep2.3 = getelementptr i8, i8* %to, i64 3
  store i8 %call.3, i8* %scevgep2.3, align 1
  %scevgep.4 = getelementptr i8, i8* %from, i64 4
  %4 = load i8, i8* %scevgep.4, align 1
  %call.4 = call zeroext i8 %f(i8 zeroext %4)
  %scevgep2.4 = getelementptr i8, i8* %to, i64 4
  store i8 %call.4, i8* %scevgep2.4, align 1
  %scevgep.5 = getelementptr i8, i8* %from, i64 5
  %5 = load i8, i8* %scevgep.5, align 1
  %call.5 = call zeroext i8 %f(i8 zeroext %5)
  %scevgep2.5 = getelementptr i8, i8* %to, i64 5
  store i8 %call.5, i8* %scevgep2.5, align 1
  %scevgep.6 = getelementptr i8, i8* %from, i64 6
  %6 = load i8, i8* %scevgep.6, align 1
  %call.6 = call zeroext i8 %f(i8 zeroext %6)
  %scevgep2.6 = getelementptr i8, i8* %to, i64 6
  store i8 %call.6, i8* %scevgep2.6, align 1
  %scevgep.7 = getelementptr i8, i8* %from, i64 7
  %7 = load i8, i8* %scevgep.7, align 1
  %call.7 = call zeroext i8 %f(i8 zeroext %7)
  %scevgep2.7 = getelementptr i8, i8* %to, i64 7
  store i8 %call.7, i8* %scevgep2.7, align 1
  %scevgep.8 = getelementptr i8, i8* %from, i64 8
  %8 = load i8, i8* %scevgep.8, align 1
  %call.8 = call zeroext i8 %f(i8 zeroext %8)
  %scevgep2.8 = getelementptr i8, i8* %to, i64 8
  store i8 %call.8, i8* %scevgep2.8, align 1
  %scevgep.9 = getelementptr i8, i8* %from, i64 9
  %9 = load i8, i8* %scevgep.9, align 1
  %call.9 = call zeroext i8 %f(i8 zeroext %9)
  %scevgep2.9 = getelementptr i8, i8* %to, i64 9
  store i8 %call.9, i8* %scevgep2.9, align 1
  %scevgep.10 = getelementptr i8, i8* %from, i64 10
  %10 = load i8, i8* %scevgep.10, align 1
  %call.10 = call zeroext i8 %f(i8 zeroext %10)
  %scevgep2.10 = getelementptr i8, i8* %to, i64 10
  store i8 %call.10, i8* %scevgep2.10, align 1
  %scevgep.11 = getelementptr i8, i8* %from, i64 11
  %11 = load i8, i8* %scevgep.11, align 1
  %call.11 = call zeroext i8 %f(i8 zeroext %11)
  %scevgep2.11 = getelementptr i8, i8* %to, i64 11
  store i8 %call.11, i8* %scevgep2.11, align 1
  %scevgep.12 = getelementptr i8, i8* %from, i64 12
  %12 = load i8, i8* %scevgep.12, align 1
  %call.12 = call zeroext i8 %f(i8 zeroext %12)
  %scevgep2.12 = getelementptr i8, i8* %to, i64 12
  store i8 %call.12, i8* %scevgep2.12, align 1
  %scevgep.13 = getelementptr i8, i8* %from, i64 13
  %13 = load i8, i8* %scevgep.13, align 1
  %call.13 = call zeroext i8 %f(i8 zeroext %13)
  %scevgep2.13 = getelementptr i8, i8* %to, i64 13
  store i8 %call.13, i8* %scevgep2.13, align 1
  %scevgep.14 = getelementptr i8, i8* %from, i64 14
  %14 = load i8, i8* %scevgep.14, align 1
  %call.14 = call zeroext i8 %f(i8 zeroext %14)
  %scevgep2.14 = getelementptr i8, i8* %to, i64 14
  store i8 %call.14, i8* %scevgep2.14, align 1
  %scevgep.15 = getelementptr i8, i8* %from, i64 15
  %15 = load i8, i8* %scevgep.15, align 1
  %call.15 = call zeroext i8 %f(i8 zeroext %15)
  %scevgep2.15 = getelementptr i8, i8* %to, i64 15
  store i8 %call.15, i8* %scevgep2.15, align 1
  %scevgep.16 = getelementptr i8, i8* %from, i64 16
  %16 = load i8, i8* %scevgep.16, align 1
  %call.16 = call zeroext i8 %f(i8 zeroext %16)
  %scevgep2.16 = getelementptr i8, i8* %to, i64 16
  store i8 %call.16, i8* %scevgep2.16, align 1
  %scevgep.17 = getelementptr i8, i8* %from, i64 17
  %17 = load i8, i8* %scevgep.17, align 1
  %call.17 = call zeroext i8 %f(i8 zeroext %17)
  %scevgep2.17 = getelementptr i8, i8* %to, i64 17
  store i8 %call.17, i8* %scevgep2.17, align 1
  %scevgep.18 = getelementptr i8, i8* %from, i64 18
  %18 = load i8, i8* %scevgep.18, align 1
  %call.18 = call zeroext i8 %f(i8 zeroext %18)
  %scevgep2.18 = getelementptr i8, i8* %to, i64 18
  store i8 %call.18, i8* %scevgep2.18, align 1
  %scevgep.19 = getelementptr i8, i8* %from, i64 19
  %19 = load i8, i8* %scevgep.19, align 1
  %call.19 = call zeroext i8 %f(i8 zeroext %19)
  %scevgep2.19 = getelementptr i8, i8* %to, i64 19
  store i8 %call.19, i8* %scevgep2.19, align 1
  %scevgep.20 = getelementptr i8, i8* %from, i64 20
  %20 = load i8, i8* %scevgep.20, align 1
  %call.20 = call zeroext i8 %f(i8 zeroext %20)
  %scevgep2.20 = getelementptr i8, i8* %to, i64 20
  store i8 %call.20, i8* %scevgep2.20, align 1
  %scevgep.21 = getelementptr i8, i8* %from, i64 21
  %21 = load i8, i8* %scevgep.21, align 1
  %call.21 = call zeroext i8 %f(i8 zeroext %21)
  %scevgep2.21 = getelementptr i8, i8* %to, i64 21
  store i8 %call.21, i8* %scevgep2.21, align 1
  %scevgep.22 = getelementptr i8, i8* %from, i64 22
  %22 = load i8, i8* %scevgep.22, align 1
  %call.22 = call zeroext i8 %f(i8 zeroext %22)
  %scevgep2.22 = getelementptr i8, i8* %to, i64 22
  store i8 %call.22, i8* %scevgep2.22, align 1
  %scevgep.23 = getelementptr i8, i8* %from, i64 23
  %23 = load i8, i8* %scevgep.23, align 1
  %call.23 = call zeroext i8 %f(i8 zeroext %23)
  %scevgep2.23 = getelementptr i8, i8* %to, i64 23
  store i8 %call.23, i8* %scevgep2.23, align 1
  %scevgep.24 = getelementptr i8, i8* %from, i64 24
  %24 = load i8, i8* %scevgep.24, align 1
  %call.24 = call zeroext i8 %f(i8 zeroext %24)
  %scevgep2.24 = getelementptr i8, i8* %to, i64 24
  store i8 %call.24, i8* %scevgep2.24, align 1
  %scevgep.25 = getelementptr i8, i8* %from, i64 25
  %25 = load i8, i8* %scevgep.25, align 1
  %call.25 = call zeroext i8 %f(i8 zeroext %25)
  %scevgep2.25 = getelementptr i8, i8* %to, i64 25
  store i8 %call.25, i8* %scevgep2.25, align 1
  %scevgep.26 = getelementptr i8, i8* %from, i64 26
  %26 = load i8, i8* %scevgep.26, align 1
  %call.26 = call zeroext i8 %f(i8 zeroext %26)
  %scevgep2.26 = getelementptr i8, i8* %to, i64 26
  store i8 %call.26, i8* %scevgep2.26, align 1
  %scevgep.27 = getelementptr i8, i8* %from, i64 27
  %27 = load i8, i8* %scevgep.27, align 1
  %call.27 = call zeroext i8 %f(i8 zeroext %27)
  %scevgep2.27 = getelementptr i8, i8* %to, i64 27
  store i8 %call.27, i8* %scevgep2.27, align 1
  %scevgep.28 = getelementptr i8, i8* %from, i64 28
  %28 = load i8, i8* %scevgep.28, align 1
  %call.28 = call zeroext i8 %f(i8 zeroext %28)
  %scevgep2.28 = getelementptr i8, i8* %to, i64 28
  store i8 %call.28, i8* %scevgep2.28, align 1
  %scevgep.29 = getelementptr i8, i8* %from, i64 29
  %29 = load i8, i8* %scevgep.29, align 1
  %call.29 = call zeroext i8 %f(i8 zeroext %29)
  %scevgep2.29 = getelementptr i8, i8* %to, i64 29
  store i8 %call.29, i8* %scevgep2.29, align 1
  %scevgep.30 = getelementptr i8, i8* %from, i64 30
  %30 = load i8, i8* %scevgep.30, align 1
  %call.30 = call zeroext i8 %f(i8 zeroext %30)
  %scevgep2.30 = getelementptr i8, i8* %to, i64 30
  store i8 %call.30, i8* %scevgep2.30, align 1
  %scevgep.31 = getelementptr i8, i8* %from, i64 31
  %31 = load i8, i8* %scevgep.31, align 1
  %call.31 = call zeroext i8 %f(i8 zeroext %31)
  %scevgep2.31 = getelementptr i8, i8* %to, i64 31
  store i8 %call.31, i8* %scevgep2.31, align 1
  %scevgep.32 = getelementptr i8, i8* %from, i64 32
  %32 = load i8, i8* %scevgep.32, align 1
  %call.32 = call zeroext i8 %f(i8 zeroext %32)
  %scevgep2.32 = getelementptr i8, i8* %to, i64 32
  store i8 %call.32, i8* %scevgep2.32, align 1
  %scevgep.33 = getelementptr i8, i8* %from, i64 33
  %33 = load i8, i8* %scevgep.33, align 1
  %call.33 = call zeroext i8 %f(i8 zeroext %33)
  %scevgep2.33 = getelementptr i8, i8* %to, i64 33
  store i8 %call.33, i8* %scevgep2.33, align 1
  %scevgep.34 = getelementptr i8, i8* %from, i64 34
  %34 = load i8, i8* %scevgep.34, align 1
  %call.34 = call zeroext i8 %f(i8 zeroext %34)
  %scevgep2.34 = getelementptr i8, i8* %to, i64 34
  store i8 %call.34, i8* %scevgep2.34, align 1
  %scevgep.35 = getelementptr i8, i8* %from, i64 35
  %35 = load i8, i8* %scevgep.35, align 1
  %call.35 = call zeroext i8 %f(i8 zeroext %35)
  %scevgep2.35 = getelementptr i8, i8* %to, i64 35
  store i8 %call.35, i8* %scevgep2.35, align 1
  %scevgep.36 = getelementptr i8, i8* %from, i64 36
  %36 = load i8, i8* %scevgep.36, align 1
  %call.36 = call zeroext i8 %f(i8 zeroext %36)
  %scevgep2.36 = getelementptr i8, i8* %to, i64 36
  store i8 %call.36, i8* %scevgep2.36, align 1
  %scevgep.37 = getelementptr i8, i8* %from, i64 37
  %37 = load i8, i8* %scevgep.37, align 1
  %call.37 = call zeroext i8 %f(i8 zeroext %37)
  %scevgep2.37 = getelementptr i8, i8* %to, i64 37
  store i8 %call.37, i8* %scevgep2.37, align 1
  %scevgep.38 = getelementptr i8, i8* %from, i64 38
  %38 = load i8, i8* %scevgep.38, align 1
  %call.38 = call zeroext i8 %f(i8 zeroext %38)
  %scevgep2.38 = getelementptr i8, i8* %to, i64 38
  store i8 %call.38, i8* %scevgep2.38, align 1
  %scevgep.39 = getelementptr i8, i8* %from, i64 39
  %39 = load i8, i8* %scevgep.39, align 1
  %call.39 = call zeroext i8 %f(i8 zeroext %39)
  %scevgep2.39 = getelementptr i8, i8* %to, i64 39
  store i8 %call.39, i8* %scevgep2.39, align 1
  %scevgep.40 = getelementptr i8, i8* %from, i64 40
  %40 = load i8, i8* %scevgep.40, align 1
  %call.40 = call zeroext i8 %f(i8 zeroext %40)
  %scevgep2.40 = getelementptr i8, i8* %to, i64 40
  store i8 %call.40, i8* %scevgep2.40, align 1
  ret void
}

; Function Attrs: alwaysinline nounwind uwtable
define dso_local zeroext i8 @sigma(i8* %a, i8 (i8)* %f) #0 {
entry:
  %0 = load i8, i8* %a, align 1
  %call = call zeroext i8 %f(i8 zeroext %0)
  %scevgep.1 = getelementptr i8, i8* %a, i64 1
  %1 = load i8, i8* %scevgep.1, align 1
  %call.1 = call zeroext i8 %f(i8 zeroext %1)
  %conv.1 = zext i8 %call.1 to i32
  %conv1.1 = zext i8 %call to i32
  %xor.1 = xor i32 %conv1.1, %conv.1
  %conv2.1 = trunc i32 %xor.1 to i8
  %scevgep.2 = getelementptr i8, i8* %a, i64 2
  %2 = load i8, i8* %scevgep.2, align 1
  %call.2 = call zeroext i8 %f(i8 zeroext %2)
  %conv.2 = zext i8 %call.2 to i32
  %conv1.2 = zext i8 %conv2.1 to i32
  %xor.2 = xor i32 %conv1.2, %conv.2
  %conv2.2 = trunc i32 %xor.2 to i8
  %scevgep.3 = getelementptr i8, i8* %a, i64 3
  %3 = load i8, i8* %scevgep.3, align 1
  %call.3 = call zeroext i8 %f(i8 zeroext %3)
  %conv.3 = zext i8 %call.3 to i32
  %conv1.3 = zext i8 %conv2.2 to i32
  %xor.3 = xor i32 %conv1.3, %conv.3
  %conv2.3 = trunc i32 %xor.3 to i8
  %scevgep.4 = getelementptr i8, i8* %a, i64 4
  %4 = load i8, i8* %scevgep.4, align 1
  %call.4 = call zeroext i8 %f(i8 zeroext %4)
  %conv.4 = zext i8 %call.4 to i32
  %conv1.4 = zext i8 %conv2.3 to i32
  %xor.4 = xor i32 %conv1.4, %conv.4
  %conv2.4 = trunc i32 %xor.4 to i8
  %scevgep.5 = getelementptr i8, i8* %a, i64 5
  %5 = load i8, i8* %scevgep.5, align 1
  %call.5 = call zeroext i8 %f(i8 zeroext %5)
  %conv.5 = zext i8 %call.5 to i32
  %conv1.5 = zext i8 %conv2.4 to i32
  %xor.5 = xor i32 %conv1.5, %conv.5
  %conv2.5 = trunc i32 %xor.5 to i8
  %scevgep.6 = getelementptr i8, i8* %a, i64 6
  %6 = load i8, i8* %scevgep.6, align 1
  %call.6 = call zeroext i8 %f(i8 zeroext %6)
  %conv.6 = zext i8 %call.6 to i32
  %conv1.6 = zext i8 %conv2.5 to i32
  %xor.6 = xor i32 %conv1.6, %conv.6
  %conv2.6 = trunc i32 %xor.6 to i8
  %scevgep.7 = getelementptr i8, i8* %a, i64 7
  %7 = load i8, i8* %scevgep.7, align 1
  %call.7 = call zeroext i8 %f(i8 zeroext %7)
  %conv.7 = zext i8 %call.7 to i32
  %conv1.7 = zext i8 %conv2.6 to i32
  %xor.7 = xor i32 %conv1.7, %conv.7
  %conv2.7 = trunc i32 %xor.7 to i8
  %scevgep.8 = getelementptr i8, i8* %a, i64 8
  %8 = load i8, i8* %scevgep.8, align 1
  %call.8 = call zeroext i8 %f(i8 zeroext %8)
  %conv.8 = zext i8 %call.8 to i32
  %conv1.8 = zext i8 %conv2.7 to i32
  %xor.8 = xor i32 %conv1.8, %conv.8
  %conv2.8 = trunc i32 %xor.8 to i8
  %scevgep.9 = getelementptr i8, i8* %a, i64 9
  %9 = load i8, i8* %scevgep.9, align 1
  %call.9 = call zeroext i8 %f(i8 zeroext %9)
  %conv.9 = zext i8 %call.9 to i32
  %conv1.9 = zext i8 %conv2.8 to i32
  %xor.9 = xor i32 %conv1.9, %conv.9
  %conv2.9 = trunc i32 %xor.9 to i8
  %scevgep.10 = getelementptr i8, i8* %a, i64 10
  %10 = load i8, i8* %scevgep.10, align 1
  %call.10 = call zeroext i8 %f(i8 zeroext %10)
  %conv.10 = zext i8 %call.10 to i32
  %conv1.10 = zext i8 %conv2.9 to i32
  %xor.10 = xor i32 %conv1.10, %conv.10
  %conv2.10 = trunc i32 %xor.10 to i8
  %scevgep.11 = getelementptr i8, i8* %a, i64 11
  %11 = load i8, i8* %scevgep.11, align 1
  %call.11 = call zeroext i8 %f(i8 zeroext %11)
  %conv.11 = zext i8 %call.11 to i32
  %conv1.11 = zext i8 %conv2.10 to i32
  %xor.11 = xor i32 %conv1.11, %conv.11
  %conv2.11 = trunc i32 %xor.11 to i8
  %scevgep.12 = getelementptr i8, i8* %a, i64 12
  %12 = load i8, i8* %scevgep.12, align 1
  %call.12 = call zeroext i8 %f(i8 zeroext %12)
  %conv.12 = zext i8 %call.12 to i32
  %conv1.12 = zext i8 %conv2.11 to i32
  %xor.12 = xor i32 %conv1.12, %conv.12
  %conv2.12 = trunc i32 %xor.12 to i8
  %scevgep.13 = getelementptr i8, i8* %a, i64 13
  %13 = load i8, i8* %scevgep.13, align 1
  %call.13 = call zeroext i8 %f(i8 zeroext %13)
  %conv.13 = zext i8 %call.13 to i32
  %conv1.13 = zext i8 %conv2.12 to i32
  %xor.13 = xor i32 %conv1.13, %conv.13
  %conv2.13 = trunc i32 %xor.13 to i8
  %scevgep.14 = getelementptr i8, i8* %a, i64 14
  %14 = load i8, i8* %scevgep.14, align 1
  %call.14 = call zeroext i8 %f(i8 zeroext %14)
  %conv.14 = zext i8 %call.14 to i32
  %conv1.14 = zext i8 %conv2.13 to i32
  %xor.14 = xor i32 %conv1.14, %conv.14
  %conv2.14 = trunc i32 %xor.14 to i8
  %scevgep.15 = getelementptr i8, i8* %a, i64 15
  %15 = load i8, i8* %scevgep.15, align 1
  %call.15 = call zeroext i8 %f(i8 zeroext %15)
  %conv.15 = zext i8 %call.15 to i32
  %conv1.15 = zext i8 %conv2.14 to i32
  %xor.15 = xor i32 %conv1.15, %conv.15
  %conv2.15 = trunc i32 %xor.15 to i8
  %scevgep.16 = getelementptr i8, i8* %a, i64 16
  %16 = load i8, i8* %scevgep.16, align 1
  %call.16 = call zeroext i8 %f(i8 zeroext %16)
  %conv.16 = zext i8 %call.16 to i32
  %conv1.16 = zext i8 %conv2.15 to i32
  %xor.16 = xor i32 %conv1.16, %conv.16
  %conv2.16 = trunc i32 %xor.16 to i8
  %scevgep.17 = getelementptr i8, i8* %a, i64 17
  %17 = load i8, i8* %scevgep.17, align 1
  %call.17 = call zeroext i8 %f(i8 zeroext %17)
  %conv.17 = zext i8 %call.17 to i32
  %conv1.17 = zext i8 %conv2.16 to i32
  %xor.17 = xor i32 %conv1.17, %conv.17
  %conv2.17 = trunc i32 %xor.17 to i8
  %scevgep.18 = getelementptr i8, i8* %a, i64 18
  %18 = load i8, i8* %scevgep.18, align 1
  %call.18 = call zeroext i8 %f(i8 zeroext %18)
  %conv.18 = zext i8 %call.18 to i32
  %conv1.18 = zext i8 %conv2.17 to i32
  %xor.18 = xor i32 %conv1.18, %conv.18
  %conv2.18 = trunc i32 %xor.18 to i8
  %scevgep.19 = getelementptr i8, i8* %a, i64 19
  %19 = load i8, i8* %scevgep.19, align 1
  %call.19 = call zeroext i8 %f(i8 zeroext %19)
  %conv.19 = zext i8 %call.19 to i32
  %conv1.19 = zext i8 %conv2.18 to i32
  %xor.19 = xor i32 %conv1.19, %conv.19
  %conv2.19 = trunc i32 %xor.19 to i8
  %scevgep.20 = getelementptr i8, i8* %a, i64 20
  %20 = load i8, i8* %scevgep.20, align 1
  %call.20 = call zeroext i8 %f(i8 zeroext %20)
  %conv.20 = zext i8 %call.20 to i32
  %conv1.20 = zext i8 %conv2.19 to i32
  %xor.20 = xor i32 %conv1.20, %conv.20
  %conv2.20 = trunc i32 %xor.20 to i8
  %scevgep.21 = getelementptr i8, i8* %a, i64 21
  %21 = load i8, i8* %scevgep.21, align 1
  %call.21 = call zeroext i8 %f(i8 zeroext %21)
  %conv.21 = zext i8 %call.21 to i32
  %conv1.21 = zext i8 %conv2.20 to i32
  %xor.21 = xor i32 %conv1.21, %conv.21
  %conv2.21 = trunc i32 %xor.21 to i8
  %scevgep.22 = getelementptr i8, i8* %a, i64 22
  %22 = load i8, i8* %scevgep.22, align 1
  %call.22 = call zeroext i8 %f(i8 zeroext %22)
  %conv.22 = zext i8 %call.22 to i32
  %conv1.22 = zext i8 %conv2.21 to i32
  %xor.22 = xor i32 %conv1.22, %conv.22
  %conv2.22 = trunc i32 %xor.22 to i8
  %scevgep.23 = getelementptr i8, i8* %a, i64 23
  %23 = load i8, i8* %scevgep.23, align 1
  %call.23 = call zeroext i8 %f(i8 zeroext %23)
  %conv.23 = zext i8 %call.23 to i32
  %conv1.23 = zext i8 %conv2.22 to i32
  %xor.23 = xor i32 %conv1.23, %conv.23
  %conv2.23 = trunc i32 %xor.23 to i8
  %scevgep.24 = getelementptr i8, i8* %a, i64 24
  %24 = load i8, i8* %scevgep.24, align 1
  %call.24 = call zeroext i8 %f(i8 zeroext %24)
  %conv.24 = zext i8 %call.24 to i32
  %conv1.24 = zext i8 %conv2.23 to i32
  %xor.24 = xor i32 %conv1.24, %conv.24
  %conv2.24 = trunc i32 %xor.24 to i8
  %scevgep.25 = getelementptr i8, i8* %a, i64 25
  %25 = load i8, i8* %scevgep.25, align 1
  %call.25 = call zeroext i8 %f(i8 zeroext %25)
  %conv.25 = zext i8 %call.25 to i32
  %conv1.25 = zext i8 %conv2.24 to i32
  %xor.25 = xor i32 %conv1.25, %conv.25
  %conv2.25 = trunc i32 %xor.25 to i8
  %scevgep.26 = getelementptr i8, i8* %a, i64 26
  %26 = load i8, i8* %scevgep.26, align 1
  %call.26 = call zeroext i8 %f(i8 zeroext %26)
  %conv.26 = zext i8 %call.26 to i32
  %conv1.26 = zext i8 %conv2.25 to i32
  %xor.26 = xor i32 %conv1.26, %conv.26
  %conv2.26 = trunc i32 %xor.26 to i8
  %scevgep.27 = getelementptr i8, i8* %a, i64 27
  %27 = load i8, i8* %scevgep.27, align 1
  %call.27 = call zeroext i8 %f(i8 zeroext %27)
  %conv.27 = zext i8 %call.27 to i32
  %conv1.27 = zext i8 %conv2.26 to i32
  %xor.27 = xor i32 %conv1.27, %conv.27
  %conv2.27 = trunc i32 %xor.27 to i8
  %scevgep.28 = getelementptr i8, i8* %a, i64 28
  %28 = load i8, i8* %scevgep.28, align 1
  %call.28 = call zeroext i8 %f(i8 zeroext %28)
  %conv.28 = zext i8 %call.28 to i32
  %conv1.28 = zext i8 %conv2.27 to i32
  %xor.28 = xor i32 %conv1.28, %conv.28
  %conv2.28 = trunc i32 %xor.28 to i8
  %scevgep.29 = getelementptr i8, i8* %a, i64 29
  %29 = load i8, i8* %scevgep.29, align 1
  %call.29 = call zeroext i8 %f(i8 zeroext %29)
  %conv.29 = zext i8 %call.29 to i32
  %conv1.29 = zext i8 %conv2.28 to i32
  %xor.29 = xor i32 %conv1.29, %conv.29
  %conv2.29 = trunc i32 %xor.29 to i8
  %scevgep.30 = getelementptr i8, i8* %a, i64 30
  %30 = load i8, i8* %scevgep.30, align 1
  %call.30 = call zeroext i8 %f(i8 zeroext %30)
  %conv.30 = zext i8 %call.30 to i32
  %conv1.30 = zext i8 %conv2.29 to i32
  %xor.30 = xor i32 %conv1.30, %conv.30
  %conv2.30 = trunc i32 %xor.30 to i8
  %scevgep.31 = getelementptr i8, i8* %a, i64 31
  %31 = load i8, i8* %scevgep.31, align 1
  %call.31 = call zeroext i8 %f(i8 zeroext %31)
  %conv.31 = zext i8 %call.31 to i32
  %conv1.31 = zext i8 %conv2.30 to i32
  %xor.31 = xor i32 %conv1.31, %conv.31
  %conv2.31 = trunc i32 %xor.31 to i8
  %scevgep.32 = getelementptr i8, i8* %a, i64 32
  %32 = load i8, i8* %scevgep.32, align 1
  %call.32 = call zeroext i8 %f(i8 zeroext %32)
  %conv.32 = zext i8 %call.32 to i32
  %conv1.32 = zext i8 %conv2.31 to i32
  %xor.32 = xor i32 %conv1.32, %conv.32
  %conv2.32 = trunc i32 %xor.32 to i8
  %scevgep.33 = getelementptr i8, i8* %a, i64 33
  %33 = load i8, i8* %scevgep.33, align 1
  %call.33 = call zeroext i8 %f(i8 zeroext %33)
  %conv.33 = zext i8 %call.33 to i32
  %conv1.33 = zext i8 %conv2.32 to i32
  %xor.33 = xor i32 %conv1.33, %conv.33
  %conv2.33 = trunc i32 %xor.33 to i8
  %scevgep.34 = getelementptr i8, i8* %a, i64 34
  %34 = load i8, i8* %scevgep.34, align 1
  %call.34 = call zeroext i8 %f(i8 zeroext %34)
  %conv.34 = zext i8 %call.34 to i32
  %conv1.34 = zext i8 %conv2.33 to i32
  %xor.34 = xor i32 %conv1.34, %conv.34
  %conv2.34 = trunc i32 %xor.34 to i8
  %scevgep.35 = getelementptr i8, i8* %a, i64 35
  %35 = load i8, i8* %scevgep.35, align 1
  %call.35 = call zeroext i8 %f(i8 zeroext %35)
  %conv.35 = zext i8 %call.35 to i32
  %conv1.35 = zext i8 %conv2.34 to i32
  %xor.35 = xor i32 %conv1.35, %conv.35
  %conv2.35 = trunc i32 %xor.35 to i8
  %scevgep.36 = getelementptr i8, i8* %a, i64 36
  %36 = load i8, i8* %scevgep.36, align 1
  %call.36 = call zeroext i8 %f(i8 zeroext %36)
  %conv.36 = zext i8 %call.36 to i32
  %conv1.36 = zext i8 %conv2.35 to i32
  %xor.36 = xor i32 %conv1.36, %conv.36
  %conv2.36 = trunc i32 %xor.36 to i8
  %scevgep.37 = getelementptr i8, i8* %a, i64 37
  %37 = load i8, i8* %scevgep.37, align 1
  %call.37 = call zeroext i8 %f(i8 zeroext %37)
  %conv.37 = zext i8 %call.37 to i32
  %conv1.37 = zext i8 %conv2.36 to i32
  %xor.37 = xor i32 %conv1.37, %conv.37
  %conv2.37 = trunc i32 %xor.37 to i8
  %scevgep.38 = getelementptr i8, i8* %a, i64 38
  %38 = load i8, i8* %scevgep.38, align 1
  %call.38 = call zeroext i8 %f(i8 zeroext %38)
  %conv.38 = zext i8 %call.38 to i32
  %conv1.38 = zext i8 %conv2.37 to i32
  %xor.38 = xor i32 %conv1.38, %conv.38
  %conv2.38 = trunc i32 %xor.38 to i8
  %scevgep.39 = getelementptr i8, i8* %a, i64 39
  %39 = load i8, i8* %scevgep.39, align 1
  %call.39 = call zeroext i8 %f(i8 zeroext %39)
  %conv.39 = zext i8 %call.39 to i32
  %conv1.39 = zext i8 %conv2.38 to i32
  %xor.39 = xor i32 %conv1.39, %conv.39
  %conv2.39 = trunc i32 %xor.39 to i8
  %scevgep.40 = getelementptr i8, i8* %a, i64 40
  %40 = load i8, i8* %scevgep.40, align 1
  %call.40 = call zeroext i8 %f(i8 zeroext %40)
  %conv.40 = zext i8 %call.40 to i32
  %conv1.40 = zext i8 %conv2.39 to i32
  %xor.40 = xor i32 %conv1.40, %conv.40
  %conv2.40 = trunc i32 %xor.40 to i8
  ret i8 %conv2.40
}

; Function Attrs: alwaysinline nounwind uwtable
define dso_local zeroext i8 @id(i8 zeroext %x) #0 {
entry:
  ret i8 %x
}

; Function Attrs: alwaysinline nounwind uwtable
define dso_local zeroext i8 @xors(i8* %a) #0 {
entry:
  %0 = load i8, i8* %a, align 1
  %scevgep.1 = getelementptr i8, i8* %a, i64 1
  %1 = load i8, i8* %scevgep.1, align 1
  %conv.i.1 = zext i8 %1 to i32
  %conv1.i.1 = zext i8 %0 to i32
  %xor.i.1 = xor i32 %conv1.i.1, %conv.i.1
  %conv2.i.1 = trunc i32 %xor.i.1 to i8
  %scevgep.2 = getelementptr i8, i8* %a, i64 2
  %2 = load i8, i8* %scevgep.2, align 1
  %conv.i.2 = zext i8 %2 to i32
  %conv1.i.2 = zext i8 %conv2.i.1 to i32
  %xor.i.2 = xor i32 %conv1.i.2, %conv.i.2
  %conv2.i.2 = trunc i32 %xor.i.2 to i8
  %scevgep.3 = getelementptr i8, i8* %a, i64 3
  %3 = load i8, i8* %scevgep.3, align 1
  %conv.i.3 = zext i8 %3 to i32
  %conv1.i.3 = zext i8 %conv2.i.2 to i32
  %xor.i.3 = xor i32 %conv1.i.3, %conv.i.3
  %conv2.i.3 = trunc i32 %xor.i.3 to i8
  %scevgep.4 = getelementptr i8, i8* %a, i64 4
  %4 = load i8, i8* %scevgep.4, align 1
  %conv.i.4 = zext i8 %4 to i32
  %conv1.i.4 = zext i8 %conv2.i.3 to i32
  %xor.i.4 = xor i32 %conv1.i.4, %conv.i.4
  %conv2.i.4 = trunc i32 %xor.i.4 to i8
  %scevgep.5 = getelementptr i8, i8* %a, i64 5
  %5 = load i8, i8* %scevgep.5, align 1
  %conv.i.5 = zext i8 %5 to i32
  %conv1.i.5 = zext i8 %conv2.i.4 to i32
  %xor.i.5 = xor i32 %conv1.i.5, %conv.i.5
  %conv2.i.5 = trunc i32 %xor.i.5 to i8
  %scevgep.6 = getelementptr i8, i8* %a, i64 6
  %6 = load i8, i8* %scevgep.6, align 1
  %conv.i.6 = zext i8 %6 to i32
  %conv1.i.6 = zext i8 %conv2.i.5 to i32
  %xor.i.6 = xor i32 %conv1.i.6, %conv.i.6
  %conv2.i.6 = trunc i32 %xor.i.6 to i8
  %scevgep.7 = getelementptr i8, i8* %a, i64 7
  %7 = load i8, i8* %scevgep.7, align 1
  %conv.i.7 = zext i8 %7 to i32
  %conv1.i.7 = zext i8 %conv2.i.6 to i32
  %xor.i.7 = xor i32 %conv1.i.7, %conv.i.7
  %conv2.i.7 = trunc i32 %xor.i.7 to i8
  %scevgep.8 = getelementptr i8, i8* %a, i64 8
  %8 = load i8, i8* %scevgep.8, align 1
  %conv.i.8 = zext i8 %8 to i32
  %conv1.i.8 = zext i8 %conv2.i.7 to i32
  %xor.i.8 = xor i32 %conv1.i.8, %conv.i.8
  %conv2.i.8 = trunc i32 %xor.i.8 to i8
  %scevgep.9 = getelementptr i8, i8* %a, i64 9
  %9 = load i8, i8* %scevgep.9, align 1
  %conv.i.9 = zext i8 %9 to i32
  %conv1.i.9 = zext i8 %conv2.i.8 to i32
  %xor.i.9 = xor i32 %conv1.i.9, %conv.i.9
  %conv2.i.9 = trunc i32 %xor.i.9 to i8
  %scevgep.10 = getelementptr i8, i8* %a, i64 10
  %10 = load i8, i8* %scevgep.10, align 1
  %conv.i.10 = zext i8 %10 to i32
  %conv1.i.10 = zext i8 %conv2.i.9 to i32
  %xor.i.10 = xor i32 %conv1.i.10, %conv.i.10
  %conv2.i.10 = trunc i32 %xor.i.10 to i8
  %scevgep.11 = getelementptr i8, i8* %a, i64 11
  %11 = load i8, i8* %scevgep.11, align 1
  %conv.i.11 = zext i8 %11 to i32
  %conv1.i.11 = zext i8 %conv2.i.10 to i32
  %xor.i.11 = xor i32 %conv1.i.11, %conv.i.11
  %conv2.i.11 = trunc i32 %xor.i.11 to i8
  %scevgep.12 = getelementptr i8, i8* %a, i64 12
  %12 = load i8, i8* %scevgep.12, align 1
  %conv.i.12 = zext i8 %12 to i32
  %conv1.i.12 = zext i8 %conv2.i.11 to i32
  %xor.i.12 = xor i32 %conv1.i.12, %conv.i.12
  %conv2.i.12 = trunc i32 %xor.i.12 to i8
  %scevgep.13 = getelementptr i8, i8* %a, i64 13
  %13 = load i8, i8* %scevgep.13, align 1
  %conv.i.13 = zext i8 %13 to i32
  %conv1.i.13 = zext i8 %conv2.i.12 to i32
  %xor.i.13 = xor i32 %conv1.i.13, %conv.i.13
  %conv2.i.13 = trunc i32 %xor.i.13 to i8
  %scevgep.14 = getelementptr i8, i8* %a, i64 14
  %14 = load i8, i8* %scevgep.14, align 1
  %conv.i.14 = zext i8 %14 to i32
  %conv1.i.14 = zext i8 %conv2.i.13 to i32
  %xor.i.14 = xor i32 %conv1.i.14, %conv.i.14
  %conv2.i.14 = trunc i32 %xor.i.14 to i8
  %scevgep.15 = getelementptr i8, i8* %a, i64 15
  %15 = load i8, i8* %scevgep.15, align 1
  %conv.i.15 = zext i8 %15 to i32
  %conv1.i.15 = zext i8 %conv2.i.14 to i32
  %xor.i.15 = xor i32 %conv1.i.15, %conv.i.15
  %conv2.i.15 = trunc i32 %xor.i.15 to i8
  %scevgep.16 = getelementptr i8, i8* %a, i64 16
  %16 = load i8, i8* %scevgep.16, align 1
  %conv.i.16 = zext i8 %16 to i32
  %conv1.i.16 = zext i8 %conv2.i.15 to i32
  %xor.i.16 = xor i32 %conv1.i.16, %conv.i.16
  %conv2.i.16 = trunc i32 %xor.i.16 to i8
  %scevgep.17 = getelementptr i8, i8* %a, i64 17
  %17 = load i8, i8* %scevgep.17, align 1
  %conv.i.17 = zext i8 %17 to i32
  %conv1.i.17 = zext i8 %conv2.i.16 to i32
  %xor.i.17 = xor i32 %conv1.i.17, %conv.i.17
  %conv2.i.17 = trunc i32 %xor.i.17 to i8
  %scevgep.18 = getelementptr i8, i8* %a, i64 18
  %18 = load i8, i8* %scevgep.18, align 1
  %conv.i.18 = zext i8 %18 to i32
  %conv1.i.18 = zext i8 %conv2.i.17 to i32
  %xor.i.18 = xor i32 %conv1.i.18, %conv.i.18
  %conv2.i.18 = trunc i32 %xor.i.18 to i8
  %scevgep.19 = getelementptr i8, i8* %a, i64 19
  %19 = load i8, i8* %scevgep.19, align 1
  %conv.i.19 = zext i8 %19 to i32
  %conv1.i.19 = zext i8 %conv2.i.18 to i32
  %xor.i.19 = xor i32 %conv1.i.19, %conv.i.19
  %conv2.i.19 = trunc i32 %xor.i.19 to i8
  %scevgep.20 = getelementptr i8, i8* %a, i64 20
  %20 = load i8, i8* %scevgep.20, align 1
  %conv.i.20 = zext i8 %20 to i32
  %conv1.i.20 = zext i8 %conv2.i.19 to i32
  %xor.i.20 = xor i32 %conv1.i.20, %conv.i.20
  %conv2.i.20 = trunc i32 %xor.i.20 to i8
  %scevgep.21 = getelementptr i8, i8* %a, i64 21
  %21 = load i8, i8* %scevgep.21, align 1
  %conv.i.21 = zext i8 %21 to i32
  %conv1.i.21 = zext i8 %conv2.i.20 to i32
  %xor.i.21 = xor i32 %conv1.i.21, %conv.i.21
  %conv2.i.21 = trunc i32 %xor.i.21 to i8
  %scevgep.22 = getelementptr i8, i8* %a, i64 22
  %22 = load i8, i8* %scevgep.22, align 1
  %conv.i.22 = zext i8 %22 to i32
  %conv1.i.22 = zext i8 %conv2.i.21 to i32
  %xor.i.22 = xor i32 %conv1.i.22, %conv.i.22
  %conv2.i.22 = trunc i32 %xor.i.22 to i8
  %scevgep.23 = getelementptr i8, i8* %a, i64 23
  %23 = load i8, i8* %scevgep.23, align 1
  %conv.i.23 = zext i8 %23 to i32
  %conv1.i.23 = zext i8 %conv2.i.22 to i32
  %xor.i.23 = xor i32 %conv1.i.23, %conv.i.23
  %conv2.i.23 = trunc i32 %xor.i.23 to i8
  %scevgep.24 = getelementptr i8, i8* %a, i64 24
  %24 = load i8, i8* %scevgep.24, align 1
  %conv.i.24 = zext i8 %24 to i32
  %conv1.i.24 = zext i8 %conv2.i.23 to i32
  %xor.i.24 = xor i32 %conv1.i.24, %conv.i.24
  %conv2.i.24 = trunc i32 %xor.i.24 to i8
  %scevgep.25 = getelementptr i8, i8* %a, i64 25
  %25 = load i8, i8* %scevgep.25, align 1
  %conv.i.25 = zext i8 %25 to i32
  %conv1.i.25 = zext i8 %conv2.i.24 to i32
  %xor.i.25 = xor i32 %conv1.i.25, %conv.i.25
  %conv2.i.25 = trunc i32 %xor.i.25 to i8
  %scevgep.26 = getelementptr i8, i8* %a, i64 26
  %26 = load i8, i8* %scevgep.26, align 1
  %conv.i.26 = zext i8 %26 to i32
  %conv1.i.26 = zext i8 %conv2.i.25 to i32
  %xor.i.26 = xor i32 %conv1.i.26, %conv.i.26
  %conv2.i.26 = trunc i32 %xor.i.26 to i8
  %scevgep.27 = getelementptr i8, i8* %a, i64 27
  %27 = load i8, i8* %scevgep.27, align 1
  %conv.i.27 = zext i8 %27 to i32
  %conv1.i.27 = zext i8 %conv2.i.26 to i32
  %xor.i.27 = xor i32 %conv1.i.27, %conv.i.27
  %conv2.i.27 = trunc i32 %xor.i.27 to i8
  %scevgep.28 = getelementptr i8, i8* %a, i64 28
  %28 = load i8, i8* %scevgep.28, align 1
  %conv.i.28 = zext i8 %28 to i32
  %conv1.i.28 = zext i8 %conv2.i.27 to i32
  %xor.i.28 = xor i32 %conv1.i.28, %conv.i.28
  %conv2.i.28 = trunc i32 %xor.i.28 to i8
  %scevgep.29 = getelementptr i8, i8* %a, i64 29
  %29 = load i8, i8* %scevgep.29, align 1
  %conv.i.29 = zext i8 %29 to i32
  %conv1.i.29 = zext i8 %conv2.i.28 to i32
  %xor.i.29 = xor i32 %conv1.i.29, %conv.i.29
  %conv2.i.29 = trunc i32 %xor.i.29 to i8
  %scevgep.30 = getelementptr i8, i8* %a, i64 30
  %30 = load i8, i8* %scevgep.30, align 1
  %conv.i.30 = zext i8 %30 to i32
  %conv1.i.30 = zext i8 %conv2.i.29 to i32
  %xor.i.30 = xor i32 %conv1.i.30, %conv.i.30
  %conv2.i.30 = trunc i32 %xor.i.30 to i8
  %scevgep.31 = getelementptr i8, i8* %a, i64 31
  %31 = load i8, i8* %scevgep.31, align 1
  %conv.i.31 = zext i8 %31 to i32
  %conv1.i.31 = zext i8 %conv2.i.30 to i32
  %xor.i.31 = xor i32 %conv1.i.31, %conv.i.31
  %conv2.i.31 = trunc i32 %xor.i.31 to i8
  %scevgep.32 = getelementptr i8, i8* %a, i64 32
  %32 = load i8, i8* %scevgep.32, align 1
  %conv.i.32 = zext i8 %32 to i32
  %conv1.i.32 = zext i8 %conv2.i.31 to i32
  %xor.i.32 = xor i32 %conv1.i.32, %conv.i.32
  %conv2.i.32 = trunc i32 %xor.i.32 to i8
  %scevgep.33 = getelementptr i8, i8* %a, i64 33
  %33 = load i8, i8* %scevgep.33, align 1
  %conv.i.33 = zext i8 %33 to i32
  %conv1.i.33 = zext i8 %conv2.i.32 to i32
  %xor.i.33 = xor i32 %conv1.i.33, %conv.i.33
  %conv2.i.33 = trunc i32 %xor.i.33 to i8
  %scevgep.34 = getelementptr i8, i8* %a, i64 34
  %34 = load i8, i8* %scevgep.34, align 1
  %conv.i.34 = zext i8 %34 to i32
  %conv1.i.34 = zext i8 %conv2.i.33 to i32
  %xor.i.34 = xor i32 %conv1.i.34, %conv.i.34
  %conv2.i.34 = trunc i32 %xor.i.34 to i8
  %scevgep.35 = getelementptr i8, i8* %a, i64 35
  %35 = load i8, i8* %scevgep.35, align 1
  %conv.i.35 = zext i8 %35 to i32
  %conv1.i.35 = zext i8 %conv2.i.34 to i32
  %xor.i.35 = xor i32 %conv1.i.35, %conv.i.35
  %conv2.i.35 = trunc i32 %xor.i.35 to i8
  %scevgep.36 = getelementptr i8, i8* %a, i64 36
  %36 = load i8, i8* %scevgep.36, align 1
  %conv.i.36 = zext i8 %36 to i32
  %conv1.i.36 = zext i8 %conv2.i.35 to i32
  %xor.i.36 = xor i32 %conv1.i.36, %conv.i.36
  %conv2.i.36 = trunc i32 %xor.i.36 to i8
  %scevgep.37 = getelementptr i8, i8* %a, i64 37
  %37 = load i8, i8* %scevgep.37, align 1
  %conv.i.37 = zext i8 %37 to i32
  %conv1.i.37 = zext i8 %conv2.i.36 to i32
  %xor.i.37 = xor i32 %conv1.i.37, %conv.i.37
  %conv2.i.37 = trunc i32 %xor.i.37 to i8
  %scevgep.38 = getelementptr i8, i8* %a, i64 38
  %38 = load i8, i8* %scevgep.38, align 1
  %conv.i.38 = zext i8 %38 to i32
  %conv1.i.38 = zext i8 %conv2.i.37 to i32
  %xor.i.38 = xor i32 %conv1.i.38, %conv.i.38
  %conv2.i.38 = trunc i32 %xor.i.38 to i8
  %scevgep.39 = getelementptr i8, i8* %a, i64 39
  %39 = load i8, i8* %scevgep.39, align 1
  %conv.i.39 = zext i8 %39 to i32
  %conv1.i.39 = zext i8 %conv2.i.38 to i32
  %xor.i.39 = xor i32 %conv1.i.39, %conv.i.39
  %conv2.i.39 = trunc i32 %xor.i.39 to i8
  %scevgep.40 = getelementptr i8, i8* %a, i64 40
  %40 = load i8, i8* %scevgep.40, align 1
  %conv.i.40 = zext i8 %40 to i32
  %conv1.i.40 = zext i8 %conv2.i.39 to i32
  %xor.i.40 = xor i32 %conv1.i.40, %conv.i.40
  %conv2.i.40 = trunc i32 %xor.i.40 to i8
  ret i8 %conv2.i.40
}

; Function Attrs: alwaysinline nounwind uwtable
define dso_local void @sec_mult(i8* %a, i8* %b, i8* %c) #0 {
entry:
  %r = alloca [41 x [41 x i8]], align 16
  %call = call zeroext i8 (...) @rand()
  %call1 = call zeroext i8 (...) @rand()
  %conv = zext i8 %call to i32
  %0 = load i8, i8* %a, align 1
  %scevgep50.1 = getelementptr i8, i8* %a, i64 1
  %1 = load i8, i8* %scevgep50.1, align 1
  %conv.i.i.1 = zext i8 %1 to i32
  %conv1.i.i.1 = zext i8 %0 to i32
  %xor.i.i.1 = xor i32 %conv1.i.i.1, %conv.i.i.1
  %conv2.i.i.1 = trunc i32 %xor.i.i.1 to i8
  %scevgep50.2 = getelementptr i8, i8* %a, i64 2
  %2 = load i8, i8* %scevgep50.2, align 1
  %conv.i.i.2 = zext i8 %2 to i32
  %conv1.i.i.2 = zext i8 %conv2.i.i.1 to i32
  %xor.i.i.2 = xor i32 %conv1.i.i.2, %conv.i.i.2
  %conv2.i.i.2 = trunc i32 %xor.i.i.2 to i8
  %scevgep50.3 = getelementptr i8, i8* %a, i64 3
  %3 = load i8, i8* %scevgep50.3, align 1
  %conv.i.i.3 = zext i8 %3 to i32
  %conv1.i.i.3 = zext i8 %conv2.i.i.2 to i32
  %xor.i.i.3 = xor i32 %conv1.i.i.3, %conv.i.i.3
  %conv2.i.i.3 = trunc i32 %xor.i.i.3 to i8
  %scevgep50.4 = getelementptr i8, i8* %a, i64 4
  %4 = load i8, i8* %scevgep50.4, align 1
  %conv.i.i.4 = zext i8 %4 to i32
  %conv1.i.i.4 = zext i8 %conv2.i.i.3 to i32
  %xor.i.i.4 = xor i32 %conv1.i.i.4, %conv.i.i.4
  %conv2.i.i.4 = trunc i32 %xor.i.i.4 to i8
  %scevgep50.5 = getelementptr i8, i8* %a, i64 5
  %5 = load i8, i8* %scevgep50.5, align 1
  %conv.i.i.5 = zext i8 %5 to i32
  %conv1.i.i.5 = zext i8 %conv2.i.i.4 to i32
  %xor.i.i.5 = xor i32 %conv1.i.i.5, %conv.i.i.5
  %conv2.i.i.5 = trunc i32 %xor.i.i.5 to i8
  %scevgep50.6 = getelementptr i8, i8* %a, i64 6
  %6 = load i8, i8* %scevgep50.6, align 1
  %conv.i.i.6 = zext i8 %6 to i32
  %conv1.i.i.6 = zext i8 %conv2.i.i.5 to i32
  %xor.i.i.6 = xor i32 %conv1.i.i.6, %conv.i.i.6
  %conv2.i.i.6 = trunc i32 %xor.i.i.6 to i8
  %scevgep50.7 = getelementptr i8, i8* %a, i64 7
  %7 = load i8, i8* %scevgep50.7, align 1
  %conv.i.i.7 = zext i8 %7 to i32
  %conv1.i.i.7 = zext i8 %conv2.i.i.6 to i32
  %xor.i.i.7 = xor i32 %conv1.i.i.7, %conv.i.i.7
  %conv2.i.i.7 = trunc i32 %xor.i.i.7 to i8
  %scevgep50.8 = getelementptr i8, i8* %a, i64 8
  %8 = load i8, i8* %scevgep50.8, align 1
  %conv.i.i.8 = zext i8 %8 to i32
  %conv1.i.i.8 = zext i8 %conv2.i.i.7 to i32
  %xor.i.i.8 = xor i32 %conv1.i.i.8, %conv.i.i.8
  %conv2.i.i.8 = trunc i32 %xor.i.i.8 to i8
  %scevgep50.9 = getelementptr i8, i8* %a, i64 9
  %9 = load i8, i8* %scevgep50.9, align 1
  %conv.i.i.9 = zext i8 %9 to i32
  %conv1.i.i.9 = zext i8 %conv2.i.i.8 to i32
  %xor.i.i.9 = xor i32 %conv1.i.i.9, %conv.i.i.9
  %conv2.i.i.9 = trunc i32 %xor.i.i.9 to i8
  %scevgep50.10 = getelementptr i8, i8* %a, i64 10
  %10 = load i8, i8* %scevgep50.10, align 1
  %conv.i.i.10 = zext i8 %10 to i32
  %conv1.i.i.10 = zext i8 %conv2.i.i.9 to i32
  %xor.i.i.10 = xor i32 %conv1.i.i.10, %conv.i.i.10
  %conv2.i.i.10 = trunc i32 %xor.i.i.10 to i8
  %scevgep50.11 = getelementptr i8, i8* %a, i64 11
  %11 = load i8, i8* %scevgep50.11, align 1
  %conv.i.i.11 = zext i8 %11 to i32
  %conv1.i.i.11 = zext i8 %conv2.i.i.10 to i32
  %xor.i.i.11 = xor i32 %conv1.i.i.11, %conv.i.i.11
  %conv2.i.i.11 = trunc i32 %xor.i.i.11 to i8
  %scevgep50.12 = getelementptr i8, i8* %a, i64 12
  %12 = load i8, i8* %scevgep50.12, align 1
  %conv.i.i.12 = zext i8 %12 to i32
  %conv1.i.i.12 = zext i8 %conv2.i.i.11 to i32
  %xor.i.i.12 = xor i32 %conv1.i.i.12, %conv.i.i.12
  %conv2.i.i.12 = trunc i32 %xor.i.i.12 to i8
  %scevgep50.13 = getelementptr i8, i8* %a, i64 13
  %13 = load i8, i8* %scevgep50.13, align 1
  %conv.i.i.13 = zext i8 %13 to i32
  %conv1.i.i.13 = zext i8 %conv2.i.i.12 to i32
  %xor.i.i.13 = xor i32 %conv1.i.i.13, %conv.i.i.13
  %conv2.i.i.13 = trunc i32 %xor.i.i.13 to i8
  %scevgep50.14 = getelementptr i8, i8* %a, i64 14
  %14 = load i8, i8* %scevgep50.14, align 1
  %conv.i.i.14 = zext i8 %14 to i32
  %conv1.i.i.14 = zext i8 %conv2.i.i.13 to i32
  %xor.i.i.14 = xor i32 %conv1.i.i.14, %conv.i.i.14
  %conv2.i.i.14 = trunc i32 %xor.i.i.14 to i8
  %scevgep50.15 = getelementptr i8, i8* %a, i64 15
  %15 = load i8, i8* %scevgep50.15, align 1
  %conv.i.i.15 = zext i8 %15 to i32
  %conv1.i.i.15 = zext i8 %conv2.i.i.14 to i32
  %xor.i.i.15 = xor i32 %conv1.i.i.15, %conv.i.i.15
  %conv2.i.i.15 = trunc i32 %xor.i.i.15 to i8
  %scevgep50.16 = getelementptr i8, i8* %a, i64 16
  %16 = load i8, i8* %scevgep50.16, align 1
  %conv.i.i.16 = zext i8 %16 to i32
  %conv1.i.i.16 = zext i8 %conv2.i.i.15 to i32
  %xor.i.i.16 = xor i32 %conv1.i.i.16, %conv.i.i.16
  %conv2.i.i.16 = trunc i32 %xor.i.i.16 to i8
  %scevgep50.17 = getelementptr i8, i8* %a, i64 17
  %17 = load i8, i8* %scevgep50.17, align 1
  %conv.i.i.17 = zext i8 %17 to i32
  %conv1.i.i.17 = zext i8 %conv2.i.i.16 to i32
  %xor.i.i.17 = xor i32 %conv1.i.i.17, %conv.i.i.17
  %conv2.i.i.17 = trunc i32 %xor.i.i.17 to i8
  %scevgep50.18 = getelementptr i8, i8* %a, i64 18
  %18 = load i8, i8* %scevgep50.18, align 1
  %conv.i.i.18 = zext i8 %18 to i32
  %conv1.i.i.18 = zext i8 %conv2.i.i.17 to i32
  %xor.i.i.18 = xor i32 %conv1.i.i.18, %conv.i.i.18
  %conv2.i.i.18 = trunc i32 %xor.i.i.18 to i8
  %scevgep50.19 = getelementptr i8, i8* %a, i64 19
  %19 = load i8, i8* %scevgep50.19, align 1
  %conv.i.i.19 = zext i8 %19 to i32
  %conv1.i.i.19 = zext i8 %conv2.i.i.18 to i32
  %xor.i.i.19 = xor i32 %conv1.i.i.19, %conv.i.i.19
  %conv2.i.i.19 = trunc i32 %xor.i.i.19 to i8
  %scevgep50.20 = getelementptr i8, i8* %a, i64 20
  %20 = load i8, i8* %scevgep50.20, align 1
  %conv.i.i.20 = zext i8 %20 to i32
  %conv1.i.i.20 = zext i8 %conv2.i.i.19 to i32
  %xor.i.i.20 = xor i32 %conv1.i.i.20, %conv.i.i.20
  %conv2.i.i.20 = trunc i32 %xor.i.i.20 to i8
  %scevgep50.21 = getelementptr i8, i8* %a, i64 21
  %21 = load i8, i8* %scevgep50.21, align 1
  %conv.i.i.21 = zext i8 %21 to i32
  %conv1.i.i.21 = zext i8 %conv2.i.i.20 to i32
  %xor.i.i.21 = xor i32 %conv1.i.i.21, %conv.i.i.21
  %conv2.i.i.21 = trunc i32 %xor.i.i.21 to i8
  %scevgep50.22 = getelementptr i8, i8* %a, i64 22
  %22 = load i8, i8* %scevgep50.22, align 1
  %conv.i.i.22 = zext i8 %22 to i32
  %conv1.i.i.22 = zext i8 %conv2.i.i.21 to i32
  %xor.i.i.22 = xor i32 %conv1.i.i.22, %conv.i.i.22
  %conv2.i.i.22 = trunc i32 %xor.i.i.22 to i8
  %scevgep50.23 = getelementptr i8, i8* %a, i64 23
  %23 = load i8, i8* %scevgep50.23, align 1
  %conv.i.i.23 = zext i8 %23 to i32
  %conv1.i.i.23 = zext i8 %conv2.i.i.22 to i32
  %xor.i.i.23 = xor i32 %conv1.i.i.23, %conv.i.i.23
  %conv2.i.i.23 = trunc i32 %xor.i.i.23 to i8
  %scevgep50.24 = getelementptr i8, i8* %a, i64 24
  %24 = load i8, i8* %scevgep50.24, align 1
  %conv.i.i.24 = zext i8 %24 to i32
  %conv1.i.i.24 = zext i8 %conv2.i.i.23 to i32
  %xor.i.i.24 = xor i32 %conv1.i.i.24, %conv.i.i.24
  %conv2.i.i.24 = trunc i32 %xor.i.i.24 to i8
  %scevgep50.25 = getelementptr i8, i8* %a, i64 25
  %25 = load i8, i8* %scevgep50.25, align 1
  %conv.i.i.25 = zext i8 %25 to i32
  %conv1.i.i.25 = zext i8 %conv2.i.i.24 to i32
  %xor.i.i.25 = xor i32 %conv1.i.i.25, %conv.i.i.25
  %conv2.i.i.25 = trunc i32 %xor.i.i.25 to i8
  %scevgep50.26 = getelementptr i8, i8* %a, i64 26
  %26 = load i8, i8* %scevgep50.26, align 1
  %conv.i.i.26 = zext i8 %26 to i32
  %conv1.i.i.26 = zext i8 %conv2.i.i.25 to i32
  %xor.i.i.26 = xor i32 %conv1.i.i.26, %conv.i.i.26
  %conv2.i.i.26 = trunc i32 %xor.i.i.26 to i8
  %scevgep50.27 = getelementptr i8, i8* %a, i64 27
  %27 = load i8, i8* %scevgep50.27, align 1
  %conv.i.i.27 = zext i8 %27 to i32
  %conv1.i.i.27 = zext i8 %conv2.i.i.26 to i32
  %xor.i.i.27 = xor i32 %conv1.i.i.27, %conv.i.i.27
  %conv2.i.i.27 = trunc i32 %xor.i.i.27 to i8
  %scevgep50.28 = getelementptr i8, i8* %a, i64 28
  %28 = load i8, i8* %scevgep50.28, align 1
  %conv.i.i.28 = zext i8 %28 to i32
  %conv1.i.i.28 = zext i8 %conv2.i.i.27 to i32
  %xor.i.i.28 = xor i32 %conv1.i.i.28, %conv.i.i.28
  %conv2.i.i.28 = trunc i32 %xor.i.i.28 to i8
  %scevgep50.29 = getelementptr i8, i8* %a, i64 29
  %29 = load i8, i8* %scevgep50.29, align 1
  %conv.i.i.29 = zext i8 %29 to i32
  %conv1.i.i.29 = zext i8 %conv2.i.i.28 to i32
  %xor.i.i.29 = xor i32 %conv1.i.i.29, %conv.i.i.29
  %conv2.i.i.29 = trunc i32 %xor.i.i.29 to i8
  %scevgep50.30 = getelementptr i8, i8* %a, i64 30
  %30 = load i8, i8* %scevgep50.30, align 1
  %conv.i.i.30 = zext i8 %30 to i32
  %conv1.i.i.30 = zext i8 %conv2.i.i.29 to i32
  %xor.i.i.30 = xor i32 %conv1.i.i.30, %conv.i.i.30
  %conv2.i.i.30 = trunc i32 %xor.i.i.30 to i8
  %scevgep50.31 = getelementptr i8, i8* %a, i64 31
  %31 = load i8, i8* %scevgep50.31, align 1
  %conv.i.i.31 = zext i8 %31 to i32
  %conv1.i.i.31 = zext i8 %conv2.i.i.30 to i32
  %xor.i.i.31 = xor i32 %conv1.i.i.31, %conv.i.i.31
  %conv2.i.i.31 = trunc i32 %xor.i.i.31 to i8
  %scevgep50.32 = getelementptr i8, i8* %a, i64 32
  %32 = load i8, i8* %scevgep50.32, align 1
  %conv.i.i.32 = zext i8 %32 to i32
  %conv1.i.i.32 = zext i8 %conv2.i.i.31 to i32
  %xor.i.i.32 = xor i32 %conv1.i.i.32, %conv.i.i.32
  %conv2.i.i.32 = trunc i32 %xor.i.i.32 to i8
  %scevgep50.33 = getelementptr i8, i8* %a, i64 33
  %33 = load i8, i8* %scevgep50.33, align 1
  %conv.i.i.33 = zext i8 %33 to i32
  %conv1.i.i.33 = zext i8 %conv2.i.i.32 to i32
  %xor.i.i.33 = xor i32 %conv1.i.i.33, %conv.i.i.33
  %conv2.i.i.33 = trunc i32 %xor.i.i.33 to i8
  %scevgep50.34 = getelementptr i8, i8* %a, i64 34
  %34 = load i8, i8* %scevgep50.34, align 1
  %conv.i.i.34 = zext i8 %34 to i32
  %conv1.i.i.34 = zext i8 %conv2.i.i.33 to i32
  %xor.i.i.34 = xor i32 %conv1.i.i.34, %conv.i.i.34
  %conv2.i.i.34 = trunc i32 %xor.i.i.34 to i8
  %scevgep50.35 = getelementptr i8, i8* %a, i64 35
  %35 = load i8, i8* %scevgep50.35, align 1
  %conv.i.i.35 = zext i8 %35 to i32
  %conv1.i.i.35 = zext i8 %conv2.i.i.34 to i32
  %xor.i.i.35 = xor i32 %conv1.i.i.35, %conv.i.i.35
  %conv2.i.i.35 = trunc i32 %xor.i.i.35 to i8
  %scevgep50.36 = getelementptr i8, i8* %a, i64 36
  %36 = load i8, i8* %scevgep50.36, align 1
  %conv.i.i.36 = zext i8 %36 to i32
  %conv1.i.i.36 = zext i8 %conv2.i.i.35 to i32
  %xor.i.i.36 = xor i32 %conv1.i.i.36, %conv.i.i.36
  %conv2.i.i.36 = trunc i32 %xor.i.i.36 to i8
  %scevgep50.37 = getelementptr i8, i8* %a, i64 37
  %37 = load i8, i8* %scevgep50.37, align 1
  %conv.i.i.37 = zext i8 %37 to i32
  %conv1.i.i.37 = zext i8 %conv2.i.i.36 to i32
  %xor.i.i.37 = xor i32 %conv1.i.i.37, %conv.i.i.37
  %conv2.i.i.37 = trunc i32 %xor.i.i.37 to i8
  %scevgep50.38 = getelementptr i8, i8* %a, i64 38
  %38 = load i8, i8* %scevgep50.38, align 1
  %conv.i.i.38 = zext i8 %38 to i32
  %conv1.i.i.38 = zext i8 %conv2.i.i.37 to i32
  %xor.i.i.38 = xor i32 %conv1.i.i.38, %conv.i.i.38
  %conv2.i.i.38 = trunc i32 %xor.i.i.38 to i8
  %scevgep50.39 = getelementptr i8, i8* %a, i64 39
  %39 = load i8, i8* %scevgep50.39, align 1
  %conv.i.i.39 = zext i8 %39 to i32
  %conv1.i.i.39 = zext i8 %conv2.i.i.38 to i32
  %xor.i.i.39 = xor i32 %conv1.i.i.39, %conv.i.i.39
  %conv2.i.i.39 = trunc i32 %xor.i.i.39 to i8
  %scevgep50.40 = getelementptr i8, i8* %a, i64 40
  %40 = load i8, i8* %scevgep50.40, align 1
  %conv.i.i.40 = zext i8 %40 to i32
  %conv1.i.i.40 = zext i8 %conv2.i.i.39 to i32
  %xor.i.i.40 = xor i32 %conv1.i.i.40, %conv.i.i.40
  %conv2.i.i.40 = trunc i32 %xor.i.i.40 to i8
  %conv3 = zext i8 %conv2.i.i.40 to i32
  %cmp = icmp eq i32 %conv, %conv3
  call void @assume(i1 zeroext %cmp)
  %conv5 = zext i8 %call1 to i32
  %41 = load i8, i8* %b, align 1
  %scevgep46.1 = getelementptr i8, i8* %b, i64 1
  %42 = load i8, i8* %scevgep46.1, align 1
  %conv.i.i96.1 = zext i8 %42 to i32
  %conv1.i.i97.1 = zext i8 %41 to i32
  %xor.i.i98.1 = xor i32 %conv1.i.i97.1, %conv.i.i96.1
  %conv2.i.i99.1 = trunc i32 %xor.i.i98.1 to i8
  %scevgep46.2 = getelementptr i8, i8* %b, i64 2
  %43 = load i8, i8* %scevgep46.2, align 1
  %conv.i.i96.2 = zext i8 %43 to i32
  %conv1.i.i97.2 = zext i8 %conv2.i.i99.1 to i32
  %xor.i.i98.2 = xor i32 %conv1.i.i97.2, %conv.i.i96.2
  %conv2.i.i99.2 = trunc i32 %xor.i.i98.2 to i8
  %scevgep46.3 = getelementptr i8, i8* %b, i64 3
  %44 = load i8, i8* %scevgep46.3, align 1
  %conv.i.i96.3 = zext i8 %44 to i32
  %conv1.i.i97.3 = zext i8 %conv2.i.i99.2 to i32
  %xor.i.i98.3 = xor i32 %conv1.i.i97.3, %conv.i.i96.3
  %conv2.i.i99.3 = trunc i32 %xor.i.i98.3 to i8
  %scevgep46.4 = getelementptr i8, i8* %b, i64 4
  %45 = load i8, i8* %scevgep46.4, align 1
  %conv.i.i96.4 = zext i8 %45 to i32
  %conv1.i.i97.4 = zext i8 %conv2.i.i99.3 to i32
  %xor.i.i98.4 = xor i32 %conv1.i.i97.4, %conv.i.i96.4
  %conv2.i.i99.4 = trunc i32 %xor.i.i98.4 to i8
  %scevgep46.5 = getelementptr i8, i8* %b, i64 5
  %46 = load i8, i8* %scevgep46.5, align 1
  %conv.i.i96.5 = zext i8 %46 to i32
  %conv1.i.i97.5 = zext i8 %conv2.i.i99.4 to i32
  %xor.i.i98.5 = xor i32 %conv1.i.i97.5, %conv.i.i96.5
  %conv2.i.i99.5 = trunc i32 %xor.i.i98.5 to i8
  %scevgep46.6 = getelementptr i8, i8* %b, i64 6
  %47 = load i8, i8* %scevgep46.6, align 1
  %conv.i.i96.6 = zext i8 %47 to i32
  %conv1.i.i97.6 = zext i8 %conv2.i.i99.5 to i32
  %xor.i.i98.6 = xor i32 %conv1.i.i97.6, %conv.i.i96.6
  %conv2.i.i99.6 = trunc i32 %xor.i.i98.6 to i8
  %scevgep46.7 = getelementptr i8, i8* %b, i64 7
  %48 = load i8, i8* %scevgep46.7, align 1
  %conv.i.i96.7 = zext i8 %48 to i32
  %conv1.i.i97.7 = zext i8 %conv2.i.i99.6 to i32
  %xor.i.i98.7 = xor i32 %conv1.i.i97.7, %conv.i.i96.7
  %conv2.i.i99.7 = trunc i32 %xor.i.i98.7 to i8
  %scevgep46.8 = getelementptr i8, i8* %b, i64 8
  %49 = load i8, i8* %scevgep46.8, align 1
  %conv.i.i96.8 = zext i8 %49 to i32
  %conv1.i.i97.8 = zext i8 %conv2.i.i99.7 to i32
  %xor.i.i98.8 = xor i32 %conv1.i.i97.8, %conv.i.i96.8
  %conv2.i.i99.8 = trunc i32 %xor.i.i98.8 to i8
  %scevgep46.9 = getelementptr i8, i8* %b, i64 9
  %50 = load i8, i8* %scevgep46.9, align 1
  %conv.i.i96.9 = zext i8 %50 to i32
  %conv1.i.i97.9 = zext i8 %conv2.i.i99.8 to i32
  %xor.i.i98.9 = xor i32 %conv1.i.i97.9, %conv.i.i96.9
  %conv2.i.i99.9 = trunc i32 %xor.i.i98.9 to i8
  %scevgep46.10 = getelementptr i8, i8* %b, i64 10
  %51 = load i8, i8* %scevgep46.10, align 1
  %conv.i.i96.10 = zext i8 %51 to i32
  %conv1.i.i97.10 = zext i8 %conv2.i.i99.9 to i32
  %xor.i.i98.10 = xor i32 %conv1.i.i97.10, %conv.i.i96.10
  %conv2.i.i99.10 = trunc i32 %xor.i.i98.10 to i8
  %scevgep46.11 = getelementptr i8, i8* %b, i64 11
  %52 = load i8, i8* %scevgep46.11, align 1
  %conv.i.i96.11 = zext i8 %52 to i32
  %conv1.i.i97.11 = zext i8 %conv2.i.i99.10 to i32
  %xor.i.i98.11 = xor i32 %conv1.i.i97.11, %conv.i.i96.11
  %conv2.i.i99.11 = trunc i32 %xor.i.i98.11 to i8
  %scevgep46.12 = getelementptr i8, i8* %b, i64 12
  %53 = load i8, i8* %scevgep46.12, align 1
  %conv.i.i96.12 = zext i8 %53 to i32
  %conv1.i.i97.12 = zext i8 %conv2.i.i99.11 to i32
  %xor.i.i98.12 = xor i32 %conv1.i.i97.12, %conv.i.i96.12
  %conv2.i.i99.12 = trunc i32 %xor.i.i98.12 to i8
  %scevgep46.13 = getelementptr i8, i8* %b, i64 13
  %54 = load i8, i8* %scevgep46.13, align 1
  %conv.i.i96.13 = zext i8 %54 to i32
  %conv1.i.i97.13 = zext i8 %conv2.i.i99.12 to i32
  %xor.i.i98.13 = xor i32 %conv1.i.i97.13, %conv.i.i96.13
  %conv2.i.i99.13 = trunc i32 %xor.i.i98.13 to i8
  %scevgep46.14 = getelementptr i8, i8* %b, i64 14
  %55 = load i8, i8* %scevgep46.14, align 1
  %conv.i.i96.14 = zext i8 %55 to i32
  %conv1.i.i97.14 = zext i8 %conv2.i.i99.13 to i32
  %xor.i.i98.14 = xor i32 %conv1.i.i97.14, %conv.i.i96.14
  %conv2.i.i99.14 = trunc i32 %xor.i.i98.14 to i8
  %scevgep46.15 = getelementptr i8, i8* %b, i64 15
  %56 = load i8, i8* %scevgep46.15, align 1
  %conv.i.i96.15 = zext i8 %56 to i32
  %conv1.i.i97.15 = zext i8 %conv2.i.i99.14 to i32
  %xor.i.i98.15 = xor i32 %conv1.i.i97.15, %conv.i.i96.15
  %conv2.i.i99.15 = trunc i32 %xor.i.i98.15 to i8
  %scevgep46.16 = getelementptr i8, i8* %b, i64 16
  %57 = load i8, i8* %scevgep46.16, align 1
  %conv.i.i96.16 = zext i8 %57 to i32
  %conv1.i.i97.16 = zext i8 %conv2.i.i99.15 to i32
  %xor.i.i98.16 = xor i32 %conv1.i.i97.16, %conv.i.i96.16
  %conv2.i.i99.16 = trunc i32 %xor.i.i98.16 to i8
  %scevgep46.17 = getelementptr i8, i8* %b, i64 17
  %58 = load i8, i8* %scevgep46.17, align 1
  %conv.i.i96.17 = zext i8 %58 to i32
  %conv1.i.i97.17 = zext i8 %conv2.i.i99.16 to i32
  %xor.i.i98.17 = xor i32 %conv1.i.i97.17, %conv.i.i96.17
  %conv2.i.i99.17 = trunc i32 %xor.i.i98.17 to i8
  %scevgep46.18 = getelementptr i8, i8* %b, i64 18
  %59 = load i8, i8* %scevgep46.18, align 1
  %conv.i.i96.18 = zext i8 %59 to i32
  %conv1.i.i97.18 = zext i8 %conv2.i.i99.17 to i32
  %xor.i.i98.18 = xor i32 %conv1.i.i97.18, %conv.i.i96.18
  %conv2.i.i99.18 = trunc i32 %xor.i.i98.18 to i8
  %scevgep46.19 = getelementptr i8, i8* %b, i64 19
  %60 = load i8, i8* %scevgep46.19, align 1
  %conv.i.i96.19 = zext i8 %60 to i32
  %conv1.i.i97.19 = zext i8 %conv2.i.i99.18 to i32
  %xor.i.i98.19 = xor i32 %conv1.i.i97.19, %conv.i.i96.19
  %conv2.i.i99.19 = trunc i32 %xor.i.i98.19 to i8
  %scevgep46.20 = getelementptr i8, i8* %b, i64 20
  %61 = load i8, i8* %scevgep46.20, align 1
  %conv.i.i96.20 = zext i8 %61 to i32
  %conv1.i.i97.20 = zext i8 %conv2.i.i99.19 to i32
  %xor.i.i98.20 = xor i32 %conv1.i.i97.20, %conv.i.i96.20
  %conv2.i.i99.20 = trunc i32 %xor.i.i98.20 to i8
  %scevgep46.21 = getelementptr i8, i8* %b, i64 21
  %62 = load i8, i8* %scevgep46.21, align 1
  %conv.i.i96.21 = zext i8 %62 to i32
  %conv1.i.i97.21 = zext i8 %conv2.i.i99.20 to i32
  %xor.i.i98.21 = xor i32 %conv1.i.i97.21, %conv.i.i96.21
  %conv2.i.i99.21 = trunc i32 %xor.i.i98.21 to i8
  %scevgep46.22 = getelementptr i8, i8* %b, i64 22
  %63 = load i8, i8* %scevgep46.22, align 1
  %conv.i.i96.22 = zext i8 %63 to i32
  %conv1.i.i97.22 = zext i8 %conv2.i.i99.21 to i32
  %xor.i.i98.22 = xor i32 %conv1.i.i97.22, %conv.i.i96.22
  %conv2.i.i99.22 = trunc i32 %xor.i.i98.22 to i8
  %scevgep46.23 = getelementptr i8, i8* %b, i64 23
  %64 = load i8, i8* %scevgep46.23, align 1
  %conv.i.i96.23 = zext i8 %64 to i32
  %conv1.i.i97.23 = zext i8 %conv2.i.i99.22 to i32
  %xor.i.i98.23 = xor i32 %conv1.i.i97.23, %conv.i.i96.23
  %conv2.i.i99.23 = trunc i32 %xor.i.i98.23 to i8
  %scevgep46.24 = getelementptr i8, i8* %b, i64 24
  %65 = load i8, i8* %scevgep46.24, align 1
  %conv.i.i96.24 = zext i8 %65 to i32
  %conv1.i.i97.24 = zext i8 %conv2.i.i99.23 to i32
  %xor.i.i98.24 = xor i32 %conv1.i.i97.24, %conv.i.i96.24
  %conv2.i.i99.24 = trunc i32 %xor.i.i98.24 to i8
  %scevgep46.25 = getelementptr i8, i8* %b, i64 25
  %66 = load i8, i8* %scevgep46.25, align 1
  %conv.i.i96.25 = zext i8 %66 to i32
  %conv1.i.i97.25 = zext i8 %conv2.i.i99.24 to i32
  %xor.i.i98.25 = xor i32 %conv1.i.i97.25, %conv.i.i96.25
  %conv2.i.i99.25 = trunc i32 %xor.i.i98.25 to i8
  %scevgep46.26 = getelementptr i8, i8* %b, i64 26
  %67 = load i8, i8* %scevgep46.26, align 1
  %conv.i.i96.26 = zext i8 %67 to i32
  %conv1.i.i97.26 = zext i8 %conv2.i.i99.25 to i32
  %xor.i.i98.26 = xor i32 %conv1.i.i97.26, %conv.i.i96.26
  %conv2.i.i99.26 = trunc i32 %xor.i.i98.26 to i8
  %scevgep46.27 = getelementptr i8, i8* %b, i64 27
  %68 = load i8, i8* %scevgep46.27, align 1
  %conv.i.i96.27 = zext i8 %68 to i32
  %conv1.i.i97.27 = zext i8 %conv2.i.i99.26 to i32
  %xor.i.i98.27 = xor i32 %conv1.i.i97.27, %conv.i.i96.27
  %conv2.i.i99.27 = trunc i32 %xor.i.i98.27 to i8
  %scevgep46.28 = getelementptr i8, i8* %b, i64 28
  %69 = load i8, i8* %scevgep46.28, align 1
  %conv.i.i96.28 = zext i8 %69 to i32
  %conv1.i.i97.28 = zext i8 %conv2.i.i99.27 to i32
  %xor.i.i98.28 = xor i32 %conv1.i.i97.28, %conv.i.i96.28
  %conv2.i.i99.28 = trunc i32 %xor.i.i98.28 to i8
  %scevgep46.29 = getelementptr i8, i8* %b, i64 29
  %70 = load i8, i8* %scevgep46.29, align 1
  %conv.i.i96.29 = zext i8 %70 to i32
  %conv1.i.i97.29 = zext i8 %conv2.i.i99.28 to i32
  %xor.i.i98.29 = xor i32 %conv1.i.i97.29, %conv.i.i96.29
  %conv2.i.i99.29 = trunc i32 %xor.i.i98.29 to i8
  %scevgep46.30 = getelementptr i8, i8* %b, i64 30
  %71 = load i8, i8* %scevgep46.30, align 1
  %conv.i.i96.30 = zext i8 %71 to i32
  %conv1.i.i97.30 = zext i8 %conv2.i.i99.29 to i32
  %xor.i.i98.30 = xor i32 %conv1.i.i97.30, %conv.i.i96.30
  %conv2.i.i99.30 = trunc i32 %xor.i.i98.30 to i8
  %scevgep46.31 = getelementptr i8, i8* %b, i64 31
  %72 = load i8, i8* %scevgep46.31, align 1
  %conv.i.i96.31 = zext i8 %72 to i32
  %conv1.i.i97.31 = zext i8 %conv2.i.i99.30 to i32
  %xor.i.i98.31 = xor i32 %conv1.i.i97.31, %conv.i.i96.31
  %conv2.i.i99.31 = trunc i32 %xor.i.i98.31 to i8
  %scevgep46.32 = getelementptr i8, i8* %b, i64 32
  %73 = load i8, i8* %scevgep46.32, align 1
  %conv.i.i96.32 = zext i8 %73 to i32
  %conv1.i.i97.32 = zext i8 %conv2.i.i99.31 to i32
  %xor.i.i98.32 = xor i32 %conv1.i.i97.32, %conv.i.i96.32
  %conv2.i.i99.32 = trunc i32 %xor.i.i98.32 to i8
  %scevgep46.33 = getelementptr i8, i8* %b, i64 33
  %74 = load i8, i8* %scevgep46.33, align 1
  %conv.i.i96.33 = zext i8 %74 to i32
  %conv1.i.i97.33 = zext i8 %conv2.i.i99.32 to i32
  %xor.i.i98.33 = xor i32 %conv1.i.i97.33, %conv.i.i96.33
  %conv2.i.i99.33 = trunc i32 %xor.i.i98.33 to i8
  %scevgep46.34 = getelementptr i8, i8* %b, i64 34
  %75 = load i8, i8* %scevgep46.34, align 1
  %conv.i.i96.34 = zext i8 %75 to i32
  %conv1.i.i97.34 = zext i8 %conv2.i.i99.33 to i32
  %xor.i.i98.34 = xor i32 %conv1.i.i97.34, %conv.i.i96.34
  %conv2.i.i99.34 = trunc i32 %xor.i.i98.34 to i8
  %scevgep46.35 = getelementptr i8, i8* %b, i64 35
  %76 = load i8, i8* %scevgep46.35, align 1
  %conv.i.i96.35 = zext i8 %76 to i32
  %conv1.i.i97.35 = zext i8 %conv2.i.i99.34 to i32
  %xor.i.i98.35 = xor i32 %conv1.i.i97.35, %conv.i.i96.35
  %conv2.i.i99.35 = trunc i32 %xor.i.i98.35 to i8
  %scevgep46.36 = getelementptr i8, i8* %b, i64 36
  %77 = load i8, i8* %scevgep46.36, align 1
  %conv.i.i96.36 = zext i8 %77 to i32
  %conv1.i.i97.36 = zext i8 %conv2.i.i99.35 to i32
  %xor.i.i98.36 = xor i32 %conv1.i.i97.36, %conv.i.i96.36
  %conv2.i.i99.36 = trunc i32 %xor.i.i98.36 to i8
  %scevgep46.37 = getelementptr i8, i8* %b, i64 37
  %78 = load i8, i8* %scevgep46.37, align 1
  %conv.i.i96.37 = zext i8 %78 to i32
  %conv1.i.i97.37 = zext i8 %conv2.i.i99.36 to i32
  %xor.i.i98.37 = xor i32 %conv1.i.i97.37, %conv.i.i96.37
  %conv2.i.i99.37 = trunc i32 %xor.i.i98.37 to i8
  %scevgep46.38 = getelementptr i8, i8* %b, i64 38
  %79 = load i8, i8* %scevgep46.38, align 1
  %conv.i.i96.38 = zext i8 %79 to i32
  %conv1.i.i97.38 = zext i8 %conv2.i.i99.37 to i32
  %xor.i.i98.38 = xor i32 %conv1.i.i97.38, %conv.i.i96.38
  %conv2.i.i99.38 = trunc i32 %xor.i.i98.38 to i8
  %scevgep46.39 = getelementptr i8, i8* %b, i64 39
  %80 = load i8, i8* %scevgep46.39, align 1
  %conv.i.i96.39 = zext i8 %80 to i32
  %conv1.i.i97.39 = zext i8 %conv2.i.i99.38 to i32
  %xor.i.i98.39 = xor i32 %conv1.i.i97.39, %conv.i.i96.39
  %conv2.i.i99.39 = trunc i32 %xor.i.i98.39 to i8
  %scevgep46.40 = getelementptr i8, i8* %b, i64 40
  %81 = load i8, i8* %scevgep46.40, align 1
  %conv.i.i96.40 = zext i8 %81 to i32
  %conv1.i.i97.40 = zext i8 %conv2.i.i99.39 to i32
  %xor.i.i98.40 = xor i32 %conv1.i.i97.40, %conv.i.i96.40
  %conv2.i.i99.40 = trunc i32 %xor.i.i98.40 to i8
  %conv7 = zext i8 %conv2.i.i99.40 to i32
  %cmp8 = icmp eq i32 %conv5, %conv7
  call void @assume(i1 zeroext %cmp8)
  %scevgep23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 1
  %scevgep2324 = bitcast i8* %scevgep23 to [41 x [41 x i8]]*
  %scevgep36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 1, i64 0
  %scevgep3637 = bitcast i8* %scevgep36 to [41 x [41 x i8]]*
  %call16 = call zeroext i8 (...) @rand()
  store i8 %call16, i8* %scevgep23, align 1
  %82 = load i8, i8* %scevgep23, align 1
  %conv23 = zext i8 %82 to i32
  %83 = load i8, i8* %a, align 1
  %scevgep34 = getelementptr i8, i8* %b, i64 1
  %84 = load i8, i8* %scevgep34, align 1
  %call28 = call zeroext i8 @mult(i8 zeroext %83, i8 zeroext %84)
  %conv29 = zext i8 %call28 to i32
  %xor = xor i32 %conv23, %conv29
  %scevgep35 = getelementptr i8, i8* %a, i64 1
  %85 = load i8, i8* %scevgep35, align 1
  %86 = load i8, i8* %b, align 1
  %call34 = call zeroext i8 @mult(i8 zeroext %85, i8 zeroext %86)
  %conv35 = zext i8 %call34 to i32
  %xor36 = xor i32 %xor, %conv35
  %conv37 = trunc i32 %xor36 to i8
  store i8 %conv37, i8* %scevgep36, align 1
  %scevgep28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %scevgep2324, i64 0, i64 0, i64 1
  %87 = bitcast i8* %scevgep28 to [41 x [41 x i8]]*
  %scevgep41 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %scevgep3637, i64 0, i64 1, i64 0
  %88 = bitcast i8* %scevgep41 to [41 x [41 x i8]]*
  %call16.1452 = call zeroext i8 (...) @rand()
  store i8 %call16.1452, i8* %scevgep28, align 1
  %89 = load i8, i8* %scevgep28, align 1
  %conv23.1453 = zext i8 %89 to i32
  %90 = load i8, i8* %a, align 1
  %scevgep34.1454 = getelementptr i8, i8* %b, i64 2
  %91 = load i8, i8* %scevgep34.1454, align 1
  %call28.1455 = call zeroext i8 @mult(i8 zeroext %90, i8 zeroext %91)
  %conv29.1456 = zext i8 %call28.1455 to i32
  %xor.1457 = xor i32 %conv23.1453, %conv29.1456
  %scevgep35.1458 = getelementptr i8, i8* %a, i64 2
  %92 = load i8, i8* %scevgep35.1458, align 1
  %93 = load i8, i8* %b, align 1
  %call34.1459 = call zeroext i8 @mult(i8 zeroext %92, i8 zeroext %93)
  %conv35.1460 = zext i8 %call34.1459 to i32
  %xor36.1461 = xor i32 %xor.1457, %conv35.1460
  %conv37.1462 = trunc i32 %xor36.1461 to i8
  store i8 %conv37.1462, i8* %scevgep41, align 1
  %scevgep28.1463 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %87, i64 0, i64 0, i64 1
  %94 = bitcast i8* %scevgep28.1463 to [41 x [41 x i8]]*
  %scevgep41.1464 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %88, i64 0, i64 1, i64 0
  %95 = bitcast i8* %scevgep41.1464 to [41 x [41 x i8]]*
  %call16.2466 = call zeroext i8 (...) @rand()
  store i8 %call16.2466, i8* %scevgep28.1463, align 1
  %96 = load i8, i8* %scevgep28.1463, align 1
  %conv23.2467 = zext i8 %96 to i32
  %97 = load i8, i8* %a, align 1
  %scevgep34.2468 = getelementptr i8, i8* %b, i64 3
  %98 = load i8, i8* %scevgep34.2468, align 1
  %call28.2469 = call zeroext i8 @mult(i8 zeroext %97, i8 zeroext %98)
  %conv29.2470 = zext i8 %call28.2469 to i32
  %xor.2471 = xor i32 %conv23.2467, %conv29.2470
  %scevgep35.2472 = getelementptr i8, i8* %a, i64 3
  %99 = load i8, i8* %scevgep35.2472, align 1
  %100 = load i8, i8* %b, align 1
  %call34.2473 = call zeroext i8 @mult(i8 zeroext %99, i8 zeroext %100)
  %conv35.2474 = zext i8 %call34.2473 to i32
  %xor36.2475 = xor i32 %xor.2471, %conv35.2474
  %conv37.2476 = trunc i32 %xor36.2475 to i8
  store i8 %conv37.2476, i8* %scevgep41.1464, align 1
  %scevgep28.2477 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %94, i64 0, i64 0, i64 1
  %101 = bitcast i8* %scevgep28.2477 to [41 x [41 x i8]]*
  %scevgep41.2478 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %95, i64 0, i64 1, i64 0
  %102 = bitcast i8* %scevgep41.2478 to [41 x [41 x i8]]*
  %call16.3480 = call zeroext i8 (...) @rand()
  store i8 %call16.3480, i8* %scevgep28.2477, align 1
  %103 = load i8, i8* %scevgep28.2477, align 1
  %conv23.3481 = zext i8 %103 to i32
  %104 = load i8, i8* %a, align 1
  %scevgep34.3482 = getelementptr i8, i8* %b, i64 4
  %105 = load i8, i8* %scevgep34.3482, align 1
  %call28.3483 = call zeroext i8 @mult(i8 zeroext %104, i8 zeroext %105)
  %conv29.3484 = zext i8 %call28.3483 to i32
  %xor.3485 = xor i32 %conv23.3481, %conv29.3484
  %scevgep35.3486 = getelementptr i8, i8* %a, i64 4
  %106 = load i8, i8* %scevgep35.3486, align 1
  %107 = load i8, i8* %b, align 1
  %call34.3487 = call zeroext i8 @mult(i8 zeroext %106, i8 zeroext %107)
  %conv35.3488 = zext i8 %call34.3487 to i32
  %xor36.3489 = xor i32 %xor.3485, %conv35.3488
  %conv37.3490 = trunc i32 %xor36.3489 to i8
  store i8 %conv37.3490, i8* %scevgep41.2478, align 1
  %scevgep28.3491 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %101, i64 0, i64 0, i64 1
  %108 = bitcast i8* %scevgep28.3491 to [41 x [41 x i8]]*
  %scevgep41.3492 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %102, i64 0, i64 1, i64 0
  %109 = bitcast i8* %scevgep41.3492 to [41 x [41 x i8]]*
  %call16.4494 = call zeroext i8 (...) @rand()
  store i8 %call16.4494, i8* %scevgep28.3491, align 1
  %110 = load i8, i8* %scevgep28.3491, align 1
  %conv23.4495 = zext i8 %110 to i32
  %111 = load i8, i8* %a, align 1
  %scevgep34.4496 = getelementptr i8, i8* %b, i64 5
  %112 = load i8, i8* %scevgep34.4496, align 1
  %call28.4497 = call zeroext i8 @mult(i8 zeroext %111, i8 zeroext %112)
  %conv29.4498 = zext i8 %call28.4497 to i32
  %xor.4499 = xor i32 %conv23.4495, %conv29.4498
  %scevgep35.4500 = getelementptr i8, i8* %a, i64 5
  %113 = load i8, i8* %scevgep35.4500, align 1
  %114 = load i8, i8* %b, align 1
  %call34.4501 = call zeroext i8 @mult(i8 zeroext %113, i8 zeroext %114)
  %conv35.4502 = zext i8 %call34.4501 to i32
  %xor36.4503 = xor i32 %xor.4499, %conv35.4502
  %conv37.4504 = trunc i32 %xor36.4503 to i8
  store i8 %conv37.4504, i8* %scevgep41.3492, align 1
  %scevgep28.4505 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %108, i64 0, i64 0, i64 1
  %115 = bitcast i8* %scevgep28.4505 to [41 x [41 x i8]]*
  %scevgep41.4506 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %109, i64 0, i64 1, i64 0
  %116 = bitcast i8* %scevgep41.4506 to [41 x [41 x i8]]*
  %call16.5508 = call zeroext i8 (...) @rand()
  store i8 %call16.5508, i8* %scevgep28.4505, align 1
  %117 = load i8, i8* %scevgep28.4505, align 1
  %conv23.5509 = zext i8 %117 to i32
  %118 = load i8, i8* %a, align 1
  %scevgep34.5510 = getelementptr i8, i8* %b, i64 6
  %119 = load i8, i8* %scevgep34.5510, align 1
  %call28.5511 = call zeroext i8 @mult(i8 zeroext %118, i8 zeroext %119)
  %conv29.5512 = zext i8 %call28.5511 to i32
  %xor.5513 = xor i32 %conv23.5509, %conv29.5512
  %scevgep35.5514 = getelementptr i8, i8* %a, i64 6
  %120 = load i8, i8* %scevgep35.5514, align 1
  %121 = load i8, i8* %b, align 1
  %call34.5515 = call zeroext i8 @mult(i8 zeroext %120, i8 zeroext %121)
  %conv35.5516 = zext i8 %call34.5515 to i32
  %xor36.5517 = xor i32 %xor.5513, %conv35.5516
  %conv37.5518 = trunc i32 %xor36.5517 to i8
  store i8 %conv37.5518, i8* %scevgep41.4506, align 1
  %scevgep28.5519 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %115, i64 0, i64 0, i64 1
  %122 = bitcast i8* %scevgep28.5519 to [41 x [41 x i8]]*
  %scevgep41.5520 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %116, i64 0, i64 1, i64 0
  %123 = bitcast i8* %scevgep41.5520 to [41 x [41 x i8]]*
  %call16.6522 = call zeroext i8 (...) @rand()
  store i8 %call16.6522, i8* %scevgep28.5519, align 1
  %124 = load i8, i8* %scevgep28.5519, align 1
  %conv23.6523 = zext i8 %124 to i32
  %125 = load i8, i8* %a, align 1
  %scevgep34.6524 = getelementptr i8, i8* %b, i64 7
  %126 = load i8, i8* %scevgep34.6524, align 1
  %call28.6525 = call zeroext i8 @mult(i8 zeroext %125, i8 zeroext %126)
  %conv29.6526 = zext i8 %call28.6525 to i32
  %xor.6527 = xor i32 %conv23.6523, %conv29.6526
  %scevgep35.6528 = getelementptr i8, i8* %a, i64 7
  %127 = load i8, i8* %scevgep35.6528, align 1
  %128 = load i8, i8* %b, align 1
  %call34.6529 = call zeroext i8 @mult(i8 zeroext %127, i8 zeroext %128)
  %conv35.6530 = zext i8 %call34.6529 to i32
  %xor36.6531 = xor i32 %xor.6527, %conv35.6530
  %conv37.6532 = trunc i32 %xor36.6531 to i8
  store i8 %conv37.6532, i8* %scevgep41.5520, align 1
  %scevgep28.6533 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %122, i64 0, i64 0, i64 1
  %129 = bitcast i8* %scevgep28.6533 to [41 x [41 x i8]]*
  %scevgep41.6534 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %123, i64 0, i64 1, i64 0
  %130 = bitcast i8* %scevgep41.6534 to [41 x [41 x i8]]*
  %call16.7536 = call zeroext i8 (...) @rand()
  store i8 %call16.7536, i8* %scevgep28.6533, align 1
  %131 = load i8, i8* %scevgep28.6533, align 1
  %conv23.7537 = zext i8 %131 to i32
  %132 = load i8, i8* %a, align 1
  %scevgep34.7538 = getelementptr i8, i8* %b, i64 8
  %133 = load i8, i8* %scevgep34.7538, align 1
  %call28.7539 = call zeroext i8 @mult(i8 zeroext %132, i8 zeroext %133)
  %conv29.7540 = zext i8 %call28.7539 to i32
  %xor.7541 = xor i32 %conv23.7537, %conv29.7540
  %scevgep35.7542 = getelementptr i8, i8* %a, i64 8
  %134 = load i8, i8* %scevgep35.7542, align 1
  %135 = load i8, i8* %b, align 1
  %call34.7543 = call zeroext i8 @mult(i8 zeroext %134, i8 zeroext %135)
  %conv35.7544 = zext i8 %call34.7543 to i32
  %xor36.7545 = xor i32 %xor.7541, %conv35.7544
  %conv37.7546 = trunc i32 %xor36.7545 to i8
  store i8 %conv37.7546, i8* %scevgep41.6534, align 1
  %scevgep28.7547 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %129, i64 0, i64 0, i64 1
  %136 = bitcast i8* %scevgep28.7547 to [41 x [41 x i8]]*
  %scevgep41.7548 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %130, i64 0, i64 1, i64 0
  %137 = bitcast i8* %scevgep41.7548 to [41 x [41 x i8]]*
  %call16.8550 = call zeroext i8 (...) @rand()
  store i8 %call16.8550, i8* %scevgep28.7547, align 1
  %138 = load i8, i8* %scevgep28.7547, align 1
  %conv23.8551 = zext i8 %138 to i32
  %139 = load i8, i8* %a, align 1
  %scevgep34.8552 = getelementptr i8, i8* %b, i64 9
  %140 = load i8, i8* %scevgep34.8552, align 1
  %call28.8553 = call zeroext i8 @mult(i8 zeroext %139, i8 zeroext %140)
  %conv29.8554 = zext i8 %call28.8553 to i32
  %xor.8555 = xor i32 %conv23.8551, %conv29.8554
  %scevgep35.8556 = getelementptr i8, i8* %a, i64 9
  %141 = load i8, i8* %scevgep35.8556, align 1
  %142 = load i8, i8* %b, align 1
  %call34.8557 = call zeroext i8 @mult(i8 zeroext %141, i8 zeroext %142)
  %conv35.8558 = zext i8 %call34.8557 to i32
  %xor36.8559 = xor i32 %xor.8555, %conv35.8558
  %conv37.8560 = trunc i32 %xor36.8559 to i8
  store i8 %conv37.8560, i8* %scevgep41.7548, align 1
  %scevgep28.8561 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %136, i64 0, i64 0, i64 1
  %143 = bitcast i8* %scevgep28.8561 to [41 x [41 x i8]]*
  %scevgep41.8562 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %137, i64 0, i64 1, i64 0
  %144 = bitcast i8* %scevgep41.8562 to [41 x [41 x i8]]*
  %call16.9564 = call zeroext i8 (...) @rand()
  store i8 %call16.9564, i8* %scevgep28.8561, align 1
  %145 = load i8, i8* %scevgep28.8561, align 1
  %conv23.9565 = zext i8 %145 to i32
  %146 = load i8, i8* %a, align 1
  %scevgep34.9566 = getelementptr i8, i8* %b, i64 10
  %147 = load i8, i8* %scevgep34.9566, align 1
  %call28.9567 = call zeroext i8 @mult(i8 zeroext %146, i8 zeroext %147)
  %conv29.9568 = zext i8 %call28.9567 to i32
  %xor.9569 = xor i32 %conv23.9565, %conv29.9568
  %scevgep35.9570 = getelementptr i8, i8* %a, i64 10
  %148 = load i8, i8* %scevgep35.9570, align 1
  %149 = load i8, i8* %b, align 1
  %call34.9571 = call zeroext i8 @mult(i8 zeroext %148, i8 zeroext %149)
  %conv35.9572 = zext i8 %call34.9571 to i32
  %xor36.9573 = xor i32 %xor.9569, %conv35.9572
  %conv37.9574 = trunc i32 %xor36.9573 to i8
  store i8 %conv37.9574, i8* %scevgep41.8562, align 1
  %scevgep28.9575 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %143, i64 0, i64 0, i64 1
  %150 = bitcast i8* %scevgep28.9575 to [41 x [41 x i8]]*
  %scevgep41.9576 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %144, i64 0, i64 1, i64 0
  %151 = bitcast i8* %scevgep41.9576 to [41 x [41 x i8]]*
  %call16.10578 = call zeroext i8 (...) @rand()
  store i8 %call16.10578, i8* %scevgep28.9575, align 1
  %152 = load i8, i8* %scevgep28.9575, align 1
  %conv23.10579 = zext i8 %152 to i32
  %153 = load i8, i8* %a, align 1
  %scevgep34.10580 = getelementptr i8, i8* %b, i64 11
  %154 = load i8, i8* %scevgep34.10580, align 1
  %call28.10581 = call zeroext i8 @mult(i8 zeroext %153, i8 zeroext %154)
  %conv29.10582 = zext i8 %call28.10581 to i32
  %xor.10583 = xor i32 %conv23.10579, %conv29.10582
  %scevgep35.10584 = getelementptr i8, i8* %a, i64 11
  %155 = load i8, i8* %scevgep35.10584, align 1
  %156 = load i8, i8* %b, align 1
  %call34.10585 = call zeroext i8 @mult(i8 zeroext %155, i8 zeroext %156)
  %conv35.10586 = zext i8 %call34.10585 to i32
  %xor36.10587 = xor i32 %xor.10583, %conv35.10586
  %conv37.10588 = trunc i32 %xor36.10587 to i8
  store i8 %conv37.10588, i8* %scevgep41.9576, align 1
  %scevgep28.10589 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %150, i64 0, i64 0, i64 1
  %157 = bitcast i8* %scevgep28.10589 to [41 x [41 x i8]]*
  %scevgep41.10590 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %151, i64 0, i64 1, i64 0
  %158 = bitcast i8* %scevgep41.10590 to [41 x [41 x i8]]*
  %call16.11592 = call zeroext i8 (...) @rand()
  store i8 %call16.11592, i8* %scevgep28.10589, align 1
  %159 = load i8, i8* %scevgep28.10589, align 1
  %conv23.11593 = zext i8 %159 to i32
  %160 = load i8, i8* %a, align 1
  %scevgep34.11594 = getelementptr i8, i8* %b, i64 12
  %161 = load i8, i8* %scevgep34.11594, align 1
  %call28.11595 = call zeroext i8 @mult(i8 zeroext %160, i8 zeroext %161)
  %conv29.11596 = zext i8 %call28.11595 to i32
  %xor.11597 = xor i32 %conv23.11593, %conv29.11596
  %scevgep35.11598 = getelementptr i8, i8* %a, i64 12
  %162 = load i8, i8* %scevgep35.11598, align 1
  %163 = load i8, i8* %b, align 1
  %call34.11599 = call zeroext i8 @mult(i8 zeroext %162, i8 zeroext %163)
  %conv35.11600 = zext i8 %call34.11599 to i32
  %xor36.11601 = xor i32 %xor.11597, %conv35.11600
  %conv37.11602 = trunc i32 %xor36.11601 to i8
  store i8 %conv37.11602, i8* %scevgep41.10590, align 1
  %scevgep28.11603 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %157, i64 0, i64 0, i64 1
  %164 = bitcast i8* %scevgep28.11603 to [41 x [41 x i8]]*
  %scevgep41.11604 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %158, i64 0, i64 1, i64 0
  %165 = bitcast i8* %scevgep41.11604 to [41 x [41 x i8]]*
  %call16.12606 = call zeroext i8 (...) @rand()
  store i8 %call16.12606, i8* %scevgep28.11603, align 1
  %166 = load i8, i8* %scevgep28.11603, align 1
  %conv23.12607 = zext i8 %166 to i32
  %167 = load i8, i8* %a, align 1
  %scevgep34.12608 = getelementptr i8, i8* %b, i64 13
  %168 = load i8, i8* %scevgep34.12608, align 1
  %call28.12609 = call zeroext i8 @mult(i8 zeroext %167, i8 zeroext %168)
  %conv29.12610 = zext i8 %call28.12609 to i32
  %xor.12611 = xor i32 %conv23.12607, %conv29.12610
  %scevgep35.12612 = getelementptr i8, i8* %a, i64 13
  %169 = load i8, i8* %scevgep35.12612, align 1
  %170 = load i8, i8* %b, align 1
  %call34.12613 = call zeroext i8 @mult(i8 zeroext %169, i8 zeroext %170)
  %conv35.12614 = zext i8 %call34.12613 to i32
  %xor36.12615 = xor i32 %xor.12611, %conv35.12614
  %conv37.12616 = trunc i32 %xor36.12615 to i8
  store i8 %conv37.12616, i8* %scevgep41.11604, align 1
  %scevgep28.12617 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %164, i64 0, i64 0, i64 1
  %171 = bitcast i8* %scevgep28.12617 to [41 x [41 x i8]]*
  %scevgep41.12618 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %165, i64 0, i64 1, i64 0
  %172 = bitcast i8* %scevgep41.12618 to [41 x [41 x i8]]*
  %call16.13620 = call zeroext i8 (...) @rand()
  store i8 %call16.13620, i8* %scevgep28.12617, align 1
  %173 = load i8, i8* %scevgep28.12617, align 1
  %conv23.13621 = zext i8 %173 to i32
  %174 = load i8, i8* %a, align 1
  %scevgep34.13622 = getelementptr i8, i8* %b, i64 14
  %175 = load i8, i8* %scevgep34.13622, align 1
  %call28.13623 = call zeroext i8 @mult(i8 zeroext %174, i8 zeroext %175)
  %conv29.13624 = zext i8 %call28.13623 to i32
  %xor.13625 = xor i32 %conv23.13621, %conv29.13624
  %scevgep35.13626 = getelementptr i8, i8* %a, i64 14
  %176 = load i8, i8* %scevgep35.13626, align 1
  %177 = load i8, i8* %b, align 1
  %call34.13627 = call zeroext i8 @mult(i8 zeroext %176, i8 zeroext %177)
  %conv35.13628 = zext i8 %call34.13627 to i32
  %xor36.13629 = xor i32 %xor.13625, %conv35.13628
  %conv37.13630 = trunc i32 %xor36.13629 to i8
  store i8 %conv37.13630, i8* %scevgep41.12618, align 1
  %scevgep28.13631 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %171, i64 0, i64 0, i64 1
  %178 = bitcast i8* %scevgep28.13631 to [41 x [41 x i8]]*
  %scevgep41.13632 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %172, i64 0, i64 1, i64 0
  %179 = bitcast i8* %scevgep41.13632 to [41 x [41 x i8]]*
  %call16.14634 = call zeroext i8 (...) @rand()
  store i8 %call16.14634, i8* %scevgep28.13631, align 1
  %180 = load i8, i8* %scevgep28.13631, align 1
  %conv23.14635 = zext i8 %180 to i32
  %181 = load i8, i8* %a, align 1
  %scevgep34.14636 = getelementptr i8, i8* %b, i64 15
  %182 = load i8, i8* %scevgep34.14636, align 1
  %call28.14637 = call zeroext i8 @mult(i8 zeroext %181, i8 zeroext %182)
  %conv29.14638 = zext i8 %call28.14637 to i32
  %xor.14639 = xor i32 %conv23.14635, %conv29.14638
  %scevgep35.14640 = getelementptr i8, i8* %a, i64 15
  %183 = load i8, i8* %scevgep35.14640, align 1
  %184 = load i8, i8* %b, align 1
  %call34.14641 = call zeroext i8 @mult(i8 zeroext %183, i8 zeroext %184)
  %conv35.14642 = zext i8 %call34.14641 to i32
  %xor36.14643 = xor i32 %xor.14639, %conv35.14642
  %conv37.14644 = trunc i32 %xor36.14643 to i8
  store i8 %conv37.14644, i8* %scevgep41.13632, align 1
  %scevgep28.14645 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %178, i64 0, i64 0, i64 1
  %185 = bitcast i8* %scevgep28.14645 to [41 x [41 x i8]]*
  %scevgep41.14646 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %179, i64 0, i64 1, i64 0
  %186 = bitcast i8* %scevgep41.14646 to [41 x [41 x i8]]*
  %call16.15648 = call zeroext i8 (...) @rand()
  store i8 %call16.15648, i8* %scevgep28.14645, align 1
  %187 = load i8, i8* %scevgep28.14645, align 1
  %conv23.15649 = zext i8 %187 to i32
  %188 = load i8, i8* %a, align 1
  %scevgep34.15650 = getelementptr i8, i8* %b, i64 16
  %189 = load i8, i8* %scevgep34.15650, align 1
  %call28.15651 = call zeroext i8 @mult(i8 zeroext %188, i8 zeroext %189)
  %conv29.15652 = zext i8 %call28.15651 to i32
  %xor.15653 = xor i32 %conv23.15649, %conv29.15652
  %scevgep35.15654 = getelementptr i8, i8* %a, i64 16
  %190 = load i8, i8* %scevgep35.15654, align 1
  %191 = load i8, i8* %b, align 1
  %call34.15655 = call zeroext i8 @mult(i8 zeroext %190, i8 zeroext %191)
  %conv35.15656 = zext i8 %call34.15655 to i32
  %xor36.15657 = xor i32 %xor.15653, %conv35.15656
  %conv37.15658 = trunc i32 %xor36.15657 to i8
  store i8 %conv37.15658, i8* %scevgep41.14646, align 1
  %scevgep28.15659 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %185, i64 0, i64 0, i64 1
  %192 = bitcast i8* %scevgep28.15659 to [41 x [41 x i8]]*
  %scevgep41.15660 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %186, i64 0, i64 1, i64 0
  %193 = bitcast i8* %scevgep41.15660 to [41 x [41 x i8]]*
  %call16.16662 = call zeroext i8 (...) @rand()
  store i8 %call16.16662, i8* %scevgep28.15659, align 1
  %194 = load i8, i8* %scevgep28.15659, align 1
  %conv23.16663 = zext i8 %194 to i32
  %195 = load i8, i8* %a, align 1
  %scevgep34.16664 = getelementptr i8, i8* %b, i64 17
  %196 = load i8, i8* %scevgep34.16664, align 1
  %call28.16665 = call zeroext i8 @mult(i8 zeroext %195, i8 zeroext %196)
  %conv29.16666 = zext i8 %call28.16665 to i32
  %xor.16667 = xor i32 %conv23.16663, %conv29.16666
  %scevgep35.16668 = getelementptr i8, i8* %a, i64 17
  %197 = load i8, i8* %scevgep35.16668, align 1
  %198 = load i8, i8* %b, align 1
  %call34.16669 = call zeroext i8 @mult(i8 zeroext %197, i8 zeroext %198)
  %conv35.16670 = zext i8 %call34.16669 to i32
  %xor36.16671 = xor i32 %xor.16667, %conv35.16670
  %conv37.16672 = trunc i32 %xor36.16671 to i8
  store i8 %conv37.16672, i8* %scevgep41.15660, align 1
  %scevgep28.16673 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %192, i64 0, i64 0, i64 1
  %199 = bitcast i8* %scevgep28.16673 to [41 x [41 x i8]]*
  %scevgep41.16674 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %193, i64 0, i64 1, i64 0
  %200 = bitcast i8* %scevgep41.16674 to [41 x [41 x i8]]*
  %call16.17676 = call zeroext i8 (...) @rand()
  store i8 %call16.17676, i8* %scevgep28.16673, align 1
  %201 = load i8, i8* %scevgep28.16673, align 1
  %conv23.17677 = zext i8 %201 to i32
  %202 = load i8, i8* %a, align 1
  %scevgep34.17678 = getelementptr i8, i8* %b, i64 18
  %203 = load i8, i8* %scevgep34.17678, align 1
  %call28.17679 = call zeroext i8 @mult(i8 zeroext %202, i8 zeroext %203)
  %conv29.17680 = zext i8 %call28.17679 to i32
  %xor.17681 = xor i32 %conv23.17677, %conv29.17680
  %scevgep35.17682 = getelementptr i8, i8* %a, i64 18
  %204 = load i8, i8* %scevgep35.17682, align 1
  %205 = load i8, i8* %b, align 1
  %call34.17683 = call zeroext i8 @mult(i8 zeroext %204, i8 zeroext %205)
  %conv35.17684 = zext i8 %call34.17683 to i32
  %xor36.17685 = xor i32 %xor.17681, %conv35.17684
  %conv37.17686 = trunc i32 %xor36.17685 to i8
  store i8 %conv37.17686, i8* %scevgep41.16674, align 1
  %scevgep28.17687 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %199, i64 0, i64 0, i64 1
  %206 = bitcast i8* %scevgep28.17687 to [41 x [41 x i8]]*
  %scevgep41.17688 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %200, i64 0, i64 1, i64 0
  %207 = bitcast i8* %scevgep41.17688 to [41 x [41 x i8]]*
  %call16.18690 = call zeroext i8 (...) @rand()
  store i8 %call16.18690, i8* %scevgep28.17687, align 1
  %208 = load i8, i8* %scevgep28.17687, align 1
  %conv23.18691 = zext i8 %208 to i32
  %209 = load i8, i8* %a, align 1
  %scevgep34.18692 = getelementptr i8, i8* %b, i64 19
  %210 = load i8, i8* %scevgep34.18692, align 1
  %call28.18693 = call zeroext i8 @mult(i8 zeroext %209, i8 zeroext %210)
  %conv29.18694 = zext i8 %call28.18693 to i32
  %xor.18695 = xor i32 %conv23.18691, %conv29.18694
  %scevgep35.18696 = getelementptr i8, i8* %a, i64 19
  %211 = load i8, i8* %scevgep35.18696, align 1
  %212 = load i8, i8* %b, align 1
  %call34.18697 = call zeroext i8 @mult(i8 zeroext %211, i8 zeroext %212)
  %conv35.18698 = zext i8 %call34.18697 to i32
  %xor36.18699 = xor i32 %xor.18695, %conv35.18698
  %conv37.18700 = trunc i32 %xor36.18699 to i8
  store i8 %conv37.18700, i8* %scevgep41.17688, align 1
  %scevgep28.18701 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %206, i64 0, i64 0, i64 1
  %213 = bitcast i8* %scevgep28.18701 to [41 x [41 x i8]]*
  %scevgep41.18702 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %207, i64 0, i64 1, i64 0
  %214 = bitcast i8* %scevgep41.18702 to [41 x [41 x i8]]*
  %call16.19704 = call zeroext i8 (...) @rand()
  store i8 %call16.19704, i8* %scevgep28.18701, align 1
  %215 = load i8, i8* %scevgep28.18701, align 1
  %conv23.19705 = zext i8 %215 to i32
  %216 = load i8, i8* %a, align 1
  %scevgep34.19706 = getelementptr i8, i8* %b, i64 20
  %217 = load i8, i8* %scevgep34.19706, align 1
  %call28.19707 = call zeroext i8 @mult(i8 zeroext %216, i8 zeroext %217)
  %conv29.19708 = zext i8 %call28.19707 to i32
  %xor.19709 = xor i32 %conv23.19705, %conv29.19708
  %scevgep35.19710 = getelementptr i8, i8* %a, i64 20
  %218 = load i8, i8* %scevgep35.19710, align 1
  %219 = load i8, i8* %b, align 1
  %call34.19711 = call zeroext i8 @mult(i8 zeroext %218, i8 zeroext %219)
  %conv35.19712 = zext i8 %call34.19711 to i32
  %xor36.19713 = xor i32 %xor.19709, %conv35.19712
  %conv37.19714 = trunc i32 %xor36.19713 to i8
  store i8 %conv37.19714, i8* %scevgep41.18702, align 1
  %scevgep28.19715 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %213, i64 0, i64 0, i64 1
  %220 = bitcast i8* %scevgep28.19715 to [41 x [41 x i8]]*
  %scevgep41.19716 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %214, i64 0, i64 1, i64 0
  %221 = bitcast i8* %scevgep41.19716 to [41 x [41 x i8]]*
  %call16.20718 = call zeroext i8 (...) @rand()
  store i8 %call16.20718, i8* %scevgep28.19715, align 1
  %222 = load i8, i8* %scevgep28.19715, align 1
  %conv23.20719 = zext i8 %222 to i32
  %223 = load i8, i8* %a, align 1
  %scevgep34.20720 = getelementptr i8, i8* %b, i64 21
  %224 = load i8, i8* %scevgep34.20720, align 1
  %call28.20721 = call zeroext i8 @mult(i8 zeroext %223, i8 zeroext %224)
  %conv29.20722 = zext i8 %call28.20721 to i32
  %xor.20723 = xor i32 %conv23.20719, %conv29.20722
  %scevgep35.20724 = getelementptr i8, i8* %a, i64 21
  %225 = load i8, i8* %scevgep35.20724, align 1
  %226 = load i8, i8* %b, align 1
  %call34.20725 = call zeroext i8 @mult(i8 zeroext %225, i8 zeroext %226)
  %conv35.20726 = zext i8 %call34.20725 to i32
  %xor36.20727 = xor i32 %xor.20723, %conv35.20726
  %conv37.20728 = trunc i32 %xor36.20727 to i8
  store i8 %conv37.20728, i8* %scevgep41.19716, align 1
  %scevgep28.20729 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %220, i64 0, i64 0, i64 1
  %227 = bitcast i8* %scevgep28.20729 to [41 x [41 x i8]]*
  %scevgep41.20730 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %221, i64 0, i64 1, i64 0
  %228 = bitcast i8* %scevgep41.20730 to [41 x [41 x i8]]*
  %call16.21732 = call zeroext i8 (...) @rand()
  store i8 %call16.21732, i8* %scevgep28.20729, align 1
  %229 = load i8, i8* %scevgep28.20729, align 1
  %conv23.21733 = zext i8 %229 to i32
  %230 = load i8, i8* %a, align 1
  %scevgep34.21734 = getelementptr i8, i8* %b, i64 22
  %231 = load i8, i8* %scevgep34.21734, align 1
  %call28.21735 = call zeroext i8 @mult(i8 zeroext %230, i8 zeroext %231)
  %conv29.21736 = zext i8 %call28.21735 to i32
  %xor.21737 = xor i32 %conv23.21733, %conv29.21736
  %scevgep35.21738 = getelementptr i8, i8* %a, i64 22
  %232 = load i8, i8* %scevgep35.21738, align 1
  %233 = load i8, i8* %b, align 1
  %call34.21739 = call zeroext i8 @mult(i8 zeroext %232, i8 zeroext %233)
  %conv35.21740 = zext i8 %call34.21739 to i32
  %xor36.21741 = xor i32 %xor.21737, %conv35.21740
  %conv37.21742 = trunc i32 %xor36.21741 to i8
  store i8 %conv37.21742, i8* %scevgep41.20730, align 1
  %scevgep28.21743 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %227, i64 0, i64 0, i64 1
  %234 = bitcast i8* %scevgep28.21743 to [41 x [41 x i8]]*
  %scevgep41.21744 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %228, i64 0, i64 1, i64 0
  %235 = bitcast i8* %scevgep41.21744 to [41 x [41 x i8]]*
  %call16.22746 = call zeroext i8 (...) @rand()
  store i8 %call16.22746, i8* %scevgep28.21743, align 1
  %236 = load i8, i8* %scevgep28.21743, align 1
  %conv23.22747 = zext i8 %236 to i32
  %237 = load i8, i8* %a, align 1
  %scevgep34.22748 = getelementptr i8, i8* %b, i64 23
  %238 = load i8, i8* %scevgep34.22748, align 1
  %call28.22749 = call zeroext i8 @mult(i8 zeroext %237, i8 zeroext %238)
  %conv29.22750 = zext i8 %call28.22749 to i32
  %xor.22751 = xor i32 %conv23.22747, %conv29.22750
  %scevgep35.22752 = getelementptr i8, i8* %a, i64 23
  %239 = load i8, i8* %scevgep35.22752, align 1
  %240 = load i8, i8* %b, align 1
  %call34.22753 = call zeroext i8 @mult(i8 zeroext %239, i8 zeroext %240)
  %conv35.22754 = zext i8 %call34.22753 to i32
  %xor36.22755 = xor i32 %xor.22751, %conv35.22754
  %conv37.22756 = trunc i32 %xor36.22755 to i8
  store i8 %conv37.22756, i8* %scevgep41.21744, align 1
  %scevgep28.22757 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %234, i64 0, i64 0, i64 1
  %241 = bitcast i8* %scevgep28.22757 to [41 x [41 x i8]]*
  %scevgep41.22758 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %235, i64 0, i64 1, i64 0
  %242 = bitcast i8* %scevgep41.22758 to [41 x [41 x i8]]*
  %call16.23760 = call zeroext i8 (...) @rand()
  store i8 %call16.23760, i8* %scevgep28.22757, align 1
  %243 = load i8, i8* %scevgep28.22757, align 1
  %conv23.23761 = zext i8 %243 to i32
  %244 = load i8, i8* %a, align 1
  %scevgep34.23762 = getelementptr i8, i8* %b, i64 24
  %245 = load i8, i8* %scevgep34.23762, align 1
  %call28.23763 = call zeroext i8 @mult(i8 zeroext %244, i8 zeroext %245)
  %conv29.23764 = zext i8 %call28.23763 to i32
  %xor.23765 = xor i32 %conv23.23761, %conv29.23764
  %scevgep35.23766 = getelementptr i8, i8* %a, i64 24
  %246 = load i8, i8* %scevgep35.23766, align 1
  %247 = load i8, i8* %b, align 1
  %call34.23767 = call zeroext i8 @mult(i8 zeroext %246, i8 zeroext %247)
  %conv35.23768 = zext i8 %call34.23767 to i32
  %xor36.23769 = xor i32 %xor.23765, %conv35.23768
  %conv37.23770 = trunc i32 %xor36.23769 to i8
  store i8 %conv37.23770, i8* %scevgep41.22758, align 1
  %scevgep28.23771 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %241, i64 0, i64 0, i64 1
  %248 = bitcast i8* %scevgep28.23771 to [41 x [41 x i8]]*
  %scevgep41.23772 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %242, i64 0, i64 1, i64 0
  %249 = bitcast i8* %scevgep41.23772 to [41 x [41 x i8]]*
  %call16.24774 = call zeroext i8 (...) @rand()
  store i8 %call16.24774, i8* %scevgep28.23771, align 1
  %250 = load i8, i8* %scevgep28.23771, align 1
  %conv23.24775 = zext i8 %250 to i32
  %251 = load i8, i8* %a, align 1
  %scevgep34.24776 = getelementptr i8, i8* %b, i64 25
  %252 = load i8, i8* %scevgep34.24776, align 1
  %call28.24777 = call zeroext i8 @mult(i8 zeroext %251, i8 zeroext %252)
  %conv29.24778 = zext i8 %call28.24777 to i32
  %xor.24779 = xor i32 %conv23.24775, %conv29.24778
  %scevgep35.24780 = getelementptr i8, i8* %a, i64 25
  %253 = load i8, i8* %scevgep35.24780, align 1
  %254 = load i8, i8* %b, align 1
  %call34.24781 = call zeroext i8 @mult(i8 zeroext %253, i8 zeroext %254)
  %conv35.24782 = zext i8 %call34.24781 to i32
  %xor36.24783 = xor i32 %xor.24779, %conv35.24782
  %conv37.24784 = trunc i32 %xor36.24783 to i8
  store i8 %conv37.24784, i8* %scevgep41.23772, align 1
  %scevgep28.24785 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %248, i64 0, i64 0, i64 1
  %255 = bitcast i8* %scevgep28.24785 to [41 x [41 x i8]]*
  %scevgep41.24786 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %249, i64 0, i64 1, i64 0
  %256 = bitcast i8* %scevgep41.24786 to [41 x [41 x i8]]*
  %call16.25788 = call zeroext i8 (...) @rand()
  store i8 %call16.25788, i8* %scevgep28.24785, align 1
  %257 = load i8, i8* %scevgep28.24785, align 1
  %conv23.25789 = zext i8 %257 to i32
  %258 = load i8, i8* %a, align 1
  %scevgep34.25790 = getelementptr i8, i8* %b, i64 26
  %259 = load i8, i8* %scevgep34.25790, align 1
  %call28.25791 = call zeroext i8 @mult(i8 zeroext %258, i8 zeroext %259)
  %conv29.25792 = zext i8 %call28.25791 to i32
  %xor.25793 = xor i32 %conv23.25789, %conv29.25792
  %scevgep35.25794 = getelementptr i8, i8* %a, i64 26
  %260 = load i8, i8* %scevgep35.25794, align 1
  %261 = load i8, i8* %b, align 1
  %call34.25795 = call zeroext i8 @mult(i8 zeroext %260, i8 zeroext %261)
  %conv35.25796 = zext i8 %call34.25795 to i32
  %xor36.25797 = xor i32 %xor.25793, %conv35.25796
  %conv37.25798 = trunc i32 %xor36.25797 to i8
  store i8 %conv37.25798, i8* %scevgep41.24786, align 1
  %scevgep28.25799 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %255, i64 0, i64 0, i64 1
  %262 = bitcast i8* %scevgep28.25799 to [41 x [41 x i8]]*
  %scevgep41.25800 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %256, i64 0, i64 1, i64 0
  %263 = bitcast i8* %scevgep41.25800 to [41 x [41 x i8]]*
  %call16.26802 = call zeroext i8 (...) @rand()
  store i8 %call16.26802, i8* %scevgep28.25799, align 1
  %264 = load i8, i8* %scevgep28.25799, align 1
  %conv23.26803 = zext i8 %264 to i32
  %265 = load i8, i8* %a, align 1
  %scevgep34.26804 = getelementptr i8, i8* %b, i64 27
  %266 = load i8, i8* %scevgep34.26804, align 1
  %call28.26805 = call zeroext i8 @mult(i8 zeroext %265, i8 zeroext %266)
  %conv29.26806 = zext i8 %call28.26805 to i32
  %xor.26807 = xor i32 %conv23.26803, %conv29.26806
  %scevgep35.26808 = getelementptr i8, i8* %a, i64 27
  %267 = load i8, i8* %scevgep35.26808, align 1
  %268 = load i8, i8* %b, align 1
  %call34.26809 = call zeroext i8 @mult(i8 zeroext %267, i8 zeroext %268)
  %conv35.26810 = zext i8 %call34.26809 to i32
  %xor36.26811 = xor i32 %xor.26807, %conv35.26810
  %conv37.26812 = trunc i32 %xor36.26811 to i8
  store i8 %conv37.26812, i8* %scevgep41.25800, align 1
  %scevgep28.26813 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %262, i64 0, i64 0, i64 1
  %269 = bitcast i8* %scevgep28.26813 to [41 x [41 x i8]]*
  %scevgep41.26814 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %263, i64 0, i64 1, i64 0
  %270 = bitcast i8* %scevgep41.26814 to [41 x [41 x i8]]*
  %call16.27816 = call zeroext i8 (...) @rand()
  store i8 %call16.27816, i8* %scevgep28.26813, align 1
  %271 = load i8, i8* %scevgep28.26813, align 1
  %conv23.27817 = zext i8 %271 to i32
  %272 = load i8, i8* %a, align 1
  %scevgep34.27818 = getelementptr i8, i8* %b, i64 28
  %273 = load i8, i8* %scevgep34.27818, align 1
  %call28.27819 = call zeroext i8 @mult(i8 zeroext %272, i8 zeroext %273)
  %conv29.27820 = zext i8 %call28.27819 to i32
  %xor.27821 = xor i32 %conv23.27817, %conv29.27820
  %scevgep35.27822 = getelementptr i8, i8* %a, i64 28
  %274 = load i8, i8* %scevgep35.27822, align 1
  %275 = load i8, i8* %b, align 1
  %call34.27823 = call zeroext i8 @mult(i8 zeroext %274, i8 zeroext %275)
  %conv35.27824 = zext i8 %call34.27823 to i32
  %xor36.27825 = xor i32 %xor.27821, %conv35.27824
  %conv37.27826 = trunc i32 %xor36.27825 to i8
  store i8 %conv37.27826, i8* %scevgep41.26814, align 1
  %scevgep28.27827 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %269, i64 0, i64 0, i64 1
  %276 = bitcast i8* %scevgep28.27827 to [41 x [41 x i8]]*
  %scevgep41.27828 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %270, i64 0, i64 1, i64 0
  %277 = bitcast i8* %scevgep41.27828 to [41 x [41 x i8]]*
  %call16.28830 = call zeroext i8 (...) @rand()
  store i8 %call16.28830, i8* %scevgep28.27827, align 1
  %278 = load i8, i8* %scevgep28.27827, align 1
  %conv23.28831 = zext i8 %278 to i32
  %279 = load i8, i8* %a, align 1
  %scevgep34.28832 = getelementptr i8, i8* %b, i64 29
  %280 = load i8, i8* %scevgep34.28832, align 1
  %call28.28833 = call zeroext i8 @mult(i8 zeroext %279, i8 zeroext %280)
  %conv29.28834 = zext i8 %call28.28833 to i32
  %xor.28835 = xor i32 %conv23.28831, %conv29.28834
  %scevgep35.28836 = getelementptr i8, i8* %a, i64 29
  %281 = load i8, i8* %scevgep35.28836, align 1
  %282 = load i8, i8* %b, align 1
  %call34.28837 = call zeroext i8 @mult(i8 zeroext %281, i8 zeroext %282)
  %conv35.28838 = zext i8 %call34.28837 to i32
  %xor36.28839 = xor i32 %xor.28835, %conv35.28838
  %conv37.28840 = trunc i32 %xor36.28839 to i8
  store i8 %conv37.28840, i8* %scevgep41.27828, align 1
  %scevgep28.28841 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %276, i64 0, i64 0, i64 1
  %283 = bitcast i8* %scevgep28.28841 to [41 x [41 x i8]]*
  %scevgep41.28842 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %277, i64 0, i64 1, i64 0
  %284 = bitcast i8* %scevgep41.28842 to [41 x [41 x i8]]*
  %call16.29844 = call zeroext i8 (...) @rand()
  store i8 %call16.29844, i8* %scevgep28.28841, align 1
  %285 = load i8, i8* %scevgep28.28841, align 1
  %conv23.29845 = zext i8 %285 to i32
  %286 = load i8, i8* %a, align 1
  %scevgep34.29846 = getelementptr i8, i8* %b, i64 30
  %287 = load i8, i8* %scevgep34.29846, align 1
  %call28.29847 = call zeroext i8 @mult(i8 zeroext %286, i8 zeroext %287)
  %conv29.29848 = zext i8 %call28.29847 to i32
  %xor.29849 = xor i32 %conv23.29845, %conv29.29848
  %scevgep35.29850 = getelementptr i8, i8* %a, i64 30
  %288 = load i8, i8* %scevgep35.29850, align 1
  %289 = load i8, i8* %b, align 1
  %call34.29851 = call zeroext i8 @mult(i8 zeroext %288, i8 zeroext %289)
  %conv35.29852 = zext i8 %call34.29851 to i32
  %xor36.29853 = xor i32 %xor.29849, %conv35.29852
  %conv37.29854 = trunc i32 %xor36.29853 to i8
  store i8 %conv37.29854, i8* %scevgep41.28842, align 1
  %scevgep28.29855 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %283, i64 0, i64 0, i64 1
  %290 = bitcast i8* %scevgep28.29855 to [41 x [41 x i8]]*
  %scevgep41.29856 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %284, i64 0, i64 1, i64 0
  %291 = bitcast i8* %scevgep41.29856 to [41 x [41 x i8]]*
  %call16.30858 = call zeroext i8 (...) @rand()
  store i8 %call16.30858, i8* %scevgep28.29855, align 1
  %292 = load i8, i8* %scevgep28.29855, align 1
  %conv23.30859 = zext i8 %292 to i32
  %293 = load i8, i8* %a, align 1
  %scevgep34.30860 = getelementptr i8, i8* %b, i64 31
  %294 = load i8, i8* %scevgep34.30860, align 1
  %call28.30861 = call zeroext i8 @mult(i8 zeroext %293, i8 zeroext %294)
  %conv29.30862 = zext i8 %call28.30861 to i32
  %xor.30863 = xor i32 %conv23.30859, %conv29.30862
  %scevgep35.30864 = getelementptr i8, i8* %a, i64 31
  %295 = load i8, i8* %scevgep35.30864, align 1
  %296 = load i8, i8* %b, align 1
  %call34.30865 = call zeroext i8 @mult(i8 zeroext %295, i8 zeroext %296)
  %conv35.30866 = zext i8 %call34.30865 to i32
  %xor36.30867 = xor i32 %xor.30863, %conv35.30866
  %conv37.30868 = trunc i32 %xor36.30867 to i8
  store i8 %conv37.30868, i8* %scevgep41.29856, align 1
  %scevgep28.30869 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %290, i64 0, i64 0, i64 1
  %297 = bitcast i8* %scevgep28.30869 to [41 x [41 x i8]]*
  %scevgep41.30870 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %291, i64 0, i64 1, i64 0
  %298 = bitcast i8* %scevgep41.30870 to [41 x [41 x i8]]*
  %call16.31872 = call zeroext i8 (...) @rand()
  store i8 %call16.31872, i8* %scevgep28.30869, align 1
  %299 = load i8, i8* %scevgep28.30869, align 1
  %conv23.31873 = zext i8 %299 to i32
  %300 = load i8, i8* %a, align 1
  %scevgep34.31874 = getelementptr i8, i8* %b, i64 32
  %301 = load i8, i8* %scevgep34.31874, align 1
  %call28.31875 = call zeroext i8 @mult(i8 zeroext %300, i8 zeroext %301)
  %conv29.31876 = zext i8 %call28.31875 to i32
  %xor.31877 = xor i32 %conv23.31873, %conv29.31876
  %scevgep35.31878 = getelementptr i8, i8* %a, i64 32
  %302 = load i8, i8* %scevgep35.31878, align 1
  %303 = load i8, i8* %b, align 1
  %call34.31879 = call zeroext i8 @mult(i8 zeroext %302, i8 zeroext %303)
  %conv35.31880 = zext i8 %call34.31879 to i32
  %xor36.31881 = xor i32 %xor.31877, %conv35.31880
  %conv37.31882 = trunc i32 %xor36.31881 to i8
  store i8 %conv37.31882, i8* %scevgep41.30870, align 1
  %scevgep28.31883 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %297, i64 0, i64 0, i64 1
  %304 = bitcast i8* %scevgep28.31883 to [41 x [41 x i8]]*
  %scevgep41.31884 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %298, i64 0, i64 1, i64 0
  %305 = bitcast i8* %scevgep41.31884 to [41 x [41 x i8]]*
  %call16.32886 = call zeroext i8 (...) @rand()
  store i8 %call16.32886, i8* %scevgep28.31883, align 1
  %306 = load i8, i8* %scevgep28.31883, align 1
  %conv23.32887 = zext i8 %306 to i32
  %307 = load i8, i8* %a, align 1
  %scevgep34.32888 = getelementptr i8, i8* %b, i64 33
  %308 = load i8, i8* %scevgep34.32888, align 1
  %call28.32889 = call zeroext i8 @mult(i8 zeroext %307, i8 zeroext %308)
  %conv29.32890 = zext i8 %call28.32889 to i32
  %xor.32891 = xor i32 %conv23.32887, %conv29.32890
  %scevgep35.32892 = getelementptr i8, i8* %a, i64 33
  %309 = load i8, i8* %scevgep35.32892, align 1
  %310 = load i8, i8* %b, align 1
  %call34.32893 = call zeroext i8 @mult(i8 zeroext %309, i8 zeroext %310)
  %conv35.32894 = zext i8 %call34.32893 to i32
  %xor36.32895 = xor i32 %xor.32891, %conv35.32894
  %conv37.32896 = trunc i32 %xor36.32895 to i8
  store i8 %conv37.32896, i8* %scevgep41.31884, align 1
  %scevgep28.32897 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %304, i64 0, i64 0, i64 1
  %311 = bitcast i8* %scevgep28.32897 to [41 x [41 x i8]]*
  %scevgep41.32898 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %305, i64 0, i64 1, i64 0
  %312 = bitcast i8* %scevgep41.32898 to [41 x [41 x i8]]*
  %call16.33900 = call zeroext i8 (...) @rand()
  store i8 %call16.33900, i8* %scevgep28.32897, align 1
  %313 = load i8, i8* %scevgep28.32897, align 1
  %conv23.33901 = zext i8 %313 to i32
  %314 = load i8, i8* %a, align 1
  %scevgep34.33902 = getelementptr i8, i8* %b, i64 34
  %315 = load i8, i8* %scevgep34.33902, align 1
  %call28.33903 = call zeroext i8 @mult(i8 zeroext %314, i8 zeroext %315)
  %conv29.33904 = zext i8 %call28.33903 to i32
  %xor.33905 = xor i32 %conv23.33901, %conv29.33904
  %scevgep35.33906 = getelementptr i8, i8* %a, i64 34
  %316 = load i8, i8* %scevgep35.33906, align 1
  %317 = load i8, i8* %b, align 1
  %call34.33907 = call zeroext i8 @mult(i8 zeroext %316, i8 zeroext %317)
  %conv35.33908 = zext i8 %call34.33907 to i32
  %xor36.33909 = xor i32 %xor.33905, %conv35.33908
  %conv37.33910 = trunc i32 %xor36.33909 to i8
  store i8 %conv37.33910, i8* %scevgep41.32898, align 1
  %scevgep28.33911 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %311, i64 0, i64 0, i64 1
  %318 = bitcast i8* %scevgep28.33911 to [41 x [41 x i8]]*
  %scevgep41.33912 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %312, i64 0, i64 1, i64 0
  %319 = bitcast i8* %scevgep41.33912 to [41 x [41 x i8]]*
  %call16.34914 = call zeroext i8 (...) @rand()
  store i8 %call16.34914, i8* %scevgep28.33911, align 1
  %320 = load i8, i8* %scevgep28.33911, align 1
  %conv23.34915 = zext i8 %320 to i32
  %321 = load i8, i8* %a, align 1
  %scevgep34.34916 = getelementptr i8, i8* %b, i64 35
  %322 = load i8, i8* %scevgep34.34916, align 1
  %call28.34917 = call zeroext i8 @mult(i8 zeroext %321, i8 zeroext %322)
  %conv29.34918 = zext i8 %call28.34917 to i32
  %xor.34919 = xor i32 %conv23.34915, %conv29.34918
  %scevgep35.34920 = getelementptr i8, i8* %a, i64 35
  %323 = load i8, i8* %scevgep35.34920, align 1
  %324 = load i8, i8* %b, align 1
  %call34.34921 = call zeroext i8 @mult(i8 zeroext %323, i8 zeroext %324)
  %conv35.34922 = zext i8 %call34.34921 to i32
  %xor36.34923 = xor i32 %xor.34919, %conv35.34922
  %conv37.34924 = trunc i32 %xor36.34923 to i8
  store i8 %conv37.34924, i8* %scevgep41.33912, align 1
  %scevgep28.34925 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %318, i64 0, i64 0, i64 1
  %325 = bitcast i8* %scevgep28.34925 to [41 x [41 x i8]]*
  %scevgep41.34926 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %319, i64 0, i64 1, i64 0
  %326 = bitcast i8* %scevgep41.34926 to [41 x [41 x i8]]*
  %call16.35928 = call zeroext i8 (...) @rand()
  store i8 %call16.35928, i8* %scevgep28.34925, align 1
  %327 = load i8, i8* %scevgep28.34925, align 1
  %conv23.35929 = zext i8 %327 to i32
  %328 = load i8, i8* %a, align 1
  %scevgep34.35930 = getelementptr i8, i8* %b, i64 36
  %329 = load i8, i8* %scevgep34.35930, align 1
  %call28.35931 = call zeroext i8 @mult(i8 zeroext %328, i8 zeroext %329)
  %conv29.35932 = zext i8 %call28.35931 to i32
  %xor.35933 = xor i32 %conv23.35929, %conv29.35932
  %scevgep35.35934 = getelementptr i8, i8* %a, i64 36
  %330 = load i8, i8* %scevgep35.35934, align 1
  %331 = load i8, i8* %b, align 1
  %call34.35935 = call zeroext i8 @mult(i8 zeroext %330, i8 zeroext %331)
  %conv35.35936 = zext i8 %call34.35935 to i32
  %xor36.35937 = xor i32 %xor.35933, %conv35.35936
  %conv37.35938 = trunc i32 %xor36.35937 to i8
  store i8 %conv37.35938, i8* %scevgep41.34926, align 1
  %scevgep28.35939 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %325, i64 0, i64 0, i64 1
  %332 = bitcast i8* %scevgep28.35939 to [41 x [41 x i8]]*
  %scevgep41.35940 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %326, i64 0, i64 1, i64 0
  %333 = bitcast i8* %scevgep41.35940 to [41 x [41 x i8]]*
  %call16.36942 = call zeroext i8 (...) @rand()
  store i8 %call16.36942, i8* %scevgep28.35939, align 1
  %334 = load i8, i8* %scevgep28.35939, align 1
  %conv23.36943 = zext i8 %334 to i32
  %335 = load i8, i8* %a, align 1
  %scevgep34.36944 = getelementptr i8, i8* %b, i64 37
  %336 = load i8, i8* %scevgep34.36944, align 1
  %call28.36945 = call zeroext i8 @mult(i8 zeroext %335, i8 zeroext %336)
  %conv29.36946 = zext i8 %call28.36945 to i32
  %xor.36947 = xor i32 %conv23.36943, %conv29.36946
  %scevgep35.36948 = getelementptr i8, i8* %a, i64 37
  %337 = load i8, i8* %scevgep35.36948, align 1
  %338 = load i8, i8* %b, align 1
  %call34.36949 = call zeroext i8 @mult(i8 zeroext %337, i8 zeroext %338)
  %conv35.36950 = zext i8 %call34.36949 to i32
  %xor36.36951 = xor i32 %xor.36947, %conv35.36950
  %conv37.36952 = trunc i32 %xor36.36951 to i8
  store i8 %conv37.36952, i8* %scevgep41.35940, align 1
  %scevgep28.36953 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %332, i64 0, i64 0, i64 1
  %339 = bitcast i8* %scevgep28.36953 to [41 x [41 x i8]]*
  %scevgep41.36954 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %333, i64 0, i64 1, i64 0
  %340 = bitcast i8* %scevgep41.36954 to [41 x [41 x i8]]*
  %call16.37956 = call zeroext i8 (...) @rand()
  store i8 %call16.37956, i8* %scevgep28.36953, align 1
  %341 = load i8, i8* %scevgep28.36953, align 1
  %conv23.37957 = zext i8 %341 to i32
  %342 = load i8, i8* %a, align 1
  %scevgep34.37958 = getelementptr i8, i8* %b, i64 38
  %343 = load i8, i8* %scevgep34.37958, align 1
  %call28.37959 = call zeroext i8 @mult(i8 zeroext %342, i8 zeroext %343)
  %conv29.37960 = zext i8 %call28.37959 to i32
  %xor.37961 = xor i32 %conv23.37957, %conv29.37960
  %scevgep35.37962 = getelementptr i8, i8* %a, i64 38
  %344 = load i8, i8* %scevgep35.37962, align 1
  %345 = load i8, i8* %b, align 1
  %call34.37963 = call zeroext i8 @mult(i8 zeroext %344, i8 zeroext %345)
  %conv35.37964 = zext i8 %call34.37963 to i32
  %xor36.37965 = xor i32 %xor.37961, %conv35.37964
  %conv37.37966 = trunc i32 %xor36.37965 to i8
  store i8 %conv37.37966, i8* %scevgep41.36954, align 1
  %scevgep28.37967 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %339, i64 0, i64 0, i64 1
  %346 = bitcast i8* %scevgep28.37967 to [41 x [41 x i8]]*
  %scevgep41.37968 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %340, i64 0, i64 1, i64 0
  %347 = bitcast i8* %scevgep41.37968 to [41 x [41 x i8]]*
  %call16.38970 = call zeroext i8 (...) @rand()
  store i8 %call16.38970, i8* %scevgep28.37967, align 1
  %348 = load i8, i8* %scevgep28.37967, align 1
  %conv23.38971 = zext i8 %348 to i32
  %349 = load i8, i8* %a, align 1
  %scevgep34.38972 = getelementptr i8, i8* %b, i64 39
  %350 = load i8, i8* %scevgep34.38972, align 1
  %call28.38973 = call zeroext i8 @mult(i8 zeroext %349, i8 zeroext %350)
  %conv29.38974 = zext i8 %call28.38973 to i32
  %xor.38975 = xor i32 %conv23.38971, %conv29.38974
  %scevgep35.38976 = getelementptr i8, i8* %a, i64 39
  %351 = load i8, i8* %scevgep35.38976, align 1
  %352 = load i8, i8* %b, align 1
  %call34.38977 = call zeroext i8 @mult(i8 zeroext %351, i8 zeroext %352)
  %conv35.38978 = zext i8 %call34.38977 to i32
  %xor36.38979 = xor i32 %xor.38975, %conv35.38978
  %conv37.38980 = trunc i32 %xor36.38979 to i8
  store i8 %conv37.38980, i8* %scevgep41.37968, align 1
  %scevgep28.38981 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %346, i64 0, i64 0, i64 1
  %scevgep41.38982 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %347, i64 0, i64 1, i64 0
  %call16.39984 = call zeroext i8 (...) @rand()
  store i8 %call16.39984, i8* %scevgep28.38981, align 1
  %353 = load i8, i8* %scevgep28.38981, align 1
  %conv23.39985 = zext i8 %353 to i32
  %354 = load i8, i8* %a, align 1
  %scevgep34.39986 = getelementptr i8, i8* %b, i64 40
  %355 = load i8, i8* %scevgep34.39986, align 1
  %call28.39987 = call zeroext i8 @mult(i8 zeroext %354, i8 zeroext %355)
  %conv29.39988 = zext i8 %call28.39987 to i32
  %xor.39989 = xor i32 %conv23.39985, %conv29.39988
  %scevgep35.39990 = getelementptr i8, i8* %a, i64 40
  %356 = load i8, i8* %scevgep35.39990, align 1
  %357 = load i8, i8* %b, align 1
  %call34.39991 = call zeroext i8 @mult(i8 zeroext %356, i8 zeroext %357)
  %conv35.39992 = zext i8 %call34.39991 to i32
  %xor36.39993 = xor i32 %xor.39989, %conv35.39992
  %conv37.39994 = trunc i32 %xor36.39993 to i8
  store i8 %conv37.39994, i8* %scevgep41.38982, align 1
  %scevgep26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %scevgep2324, i64 0, i64 1, i64 1
  %358 = bitcast i8* %scevgep26 to [41 x [41 x i8]]*
  %scevgep39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %scevgep3637, i64 0, i64 1, i64 1
  %359 = bitcast i8* %scevgep39 to [41 x [41 x i8]]*
  %arrayidx25.1 = getelementptr inbounds i8, i8* %a, i64 1
  %arrayidx33.1 = getelementptr inbounds i8, i8* %b, i64 1
  %call16.1 = call zeroext i8 (...) @rand()
  store i8 %call16.1, i8* %scevgep26, align 1
  %360 = load i8, i8* %scevgep26, align 1
  %conv23.1 = zext i8 %360 to i32
  %361 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1 = getelementptr i8, i8* %b, i64 2
  %362 = load i8, i8* %scevgep34.1, align 1
  %call28.1 = call zeroext i8 @mult(i8 zeroext %361, i8 zeroext %362)
  %conv29.1 = zext i8 %call28.1 to i32
  %xor.1 = xor i32 %conv23.1, %conv29.1
  %scevgep35.1 = getelementptr i8, i8* %a, i64 2
  %363 = load i8, i8* %scevgep35.1, align 1
  %364 = load i8, i8* %arrayidx33.1, align 1
  %call34.1 = call zeroext i8 @mult(i8 zeroext %363, i8 zeroext %364)
  %conv35.1 = zext i8 %call34.1 to i32
  %xor36.1 = xor i32 %xor.1, %conv35.1
  %conv37.1 = trunc i32 %xor36.1 to i8
  store i8 %conv37.1, i8* %scevgep39, align 1
  %scevgep28.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %358, i64 0, i64 0, i64 1
  %365 = bitcast i8* %scevgep28.1 to [41 x [41 x i8]]*
  %scevgep41.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %359, i64 0, i64 1, i64 0
  %366 = bitcast i8* %scevgep41.1 to [41 x [41 x i8]]*
  %call16.1.1 = call zeroext i8 (...) @rand()
  store i8 %call16.1.1, i8* %scevgep28.1, align 1
  %367 = load i8, i8* %scevgep28.1, align 1
  %conv23.1.1 = zext i8 %367 to i32
  %368 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.1 = getelementptr i8, i8* %b, i64 3
  %369 = load i8, i8* %scevgep34.1.1, align 1
  %call28.1.1 = call zeroext i8 @mult(i8 zeroext %368, i8 zeroext %369)
  %conv29.1.1 = zext i8 %call28.1.1 to i32
  %xor.1.1 = xor i32 %conv23.1.1, %conv29.1.1
  %scevgep35.1.1 = getelementptr i8, i8* %a, i64 3
  %370 = load i8, i8* %scevgep35.1.1, align 1
  %371 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.1 = call zeroext i8 @mult(i8 zeroext %370, i8 zeroext %371)
  %conv35.1.1 = zext i8 %call34.1.1 to i32
  %xor36.1.1 = xor i32 %xor.1.1, %conv35.1.1
  %conv37.1.1 = trunc i32 %xor36.1.1 to i8
  store i8 %conv37.1.1, i8* %scevgep41.1, align 1
  %scevgep28.1.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %365, i64 0, i64 0, i64 1
  %372 = bitcast i8* %scevgep28.1.1 to [41 x [41 x i8]]*
  %scevgep41.1.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %366, i64 0, i64 1, i64 0
  %373 = bitcast i8* %scevgep41.1.1 to [41 x [41 x i8]]*
  %call16.1.2 = call zeroext i8 (...) @rand()
  store i8 %call16.1.2, i8* %scevgep28.1.1, align 1
  %374 = load i8, i8* %scevgep28.1.1, align 1
  %conv23.1.2 = zext i8 %374 to i32
  %375 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.2 = getelementptr i8, i8* %b, i64 4
  %376 = load i8, i8* %scevgep34.1.2, align 1
  %call28.1.2 = call zeroext i8 @mult(i8 zeroext %375, i8 zeroext %376)
  %conv29.1.2 = zext i8 %call28.1.2 to i32
  %xor.1.2 = xor i32 %conv23.1.2, %conv29.1.2
  %scevgep35.1.2 = getelementptr i8, i8* %a, i64 4
  %377 = load i8, i8* %scevgep35.1.2, align 1
  %378 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.2 = call zeroext i8 @mult(i8 zeroext %377, i8 zeroext %378)
  %conv35.1.2 = zext i8 %call34.1.2 to i32
  %xor36.1.2 = xor i32 %xor.1.2, %conv35.1.2
  %conv37.1.2 = trunc i32 %xor36.1.2 to i8
  store i8 %conv37.1.2, i8* %scevgep41.1.1, align 1
  %scevgep28.1.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %372, i64 0, i64 0, i64 1
  %379 = bitcast i8* %scevgep28.1.2 to [41 x [41 x i8]]*
  %scevgep41.1.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %373, i64 0, i64 1, i64 0
  %380 = bitcast i8* %scevgep41.1.2 to [41 x [41 x i8]]*
  %call16.1.3 = call zeroext i8 (...) @rand()
  store i8 %call16.1.3, i8* %scevgep28.1.2, align 1
  %381 = load i8, i8* %scevgep28.1.2, align 1
  %conv23.1.3 = zext i8 %381 to i32
  %382 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.3 = getelementptr i8, i8* %b, i64 5
  %383 = load i8, i8* %scevgep34.1.3, align 1
  %call28.1.3 = call zeroext i8 @mult(i8 zeroext %382, i8 zeroext %383)
  %conv29.1.3 = zext i8 %call28.1.3 to i32
  %xor.1.3 = xor i32 %conv23.1.3, %conv29.1.3
  %scevgep35.1.3 = getelementptr i8, i8* %a, i64 5
  %384 = load i8, i8* %scevgep35.1.3, align 1
  %385 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.3 = call zeroext i8 @mult(i8 zeroext %384, i8 zeroext %385)
  %conv35.1.3 = zext i8 %call34.1.3 to i32
  %xor36.1.3 = xor i32 %xor.1.3, %conv35.1.3
  %conv37.1.3 = trunc i32 %xor36.1.3 to i8
  store i8 %conv37.1.3, i8* %scevgep41.1.2, align 1
  %scevgep28.1.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %379, i64 0, i64 0, i64 1
  %386 = bitcast i8* %scevgep28.1.3 to [41 x [41 x i8]]*
  %scevgep41.1.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %380, i64 0, i64 1, i64 0
  %387 = bitcast i8* %scevgep41.1.3 to [41 x [41 x i8]]*
  %call16.1.4 = call zeroext i8 (...) @rand()
  store i8 %call16.1.4, i8* %scevgep28.1.3, align 1
  %388 = load i8, i8* %scevgep28.1.3, align 1
  %conv23.1.4 = zext i8 %388 to i32
  %389 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.4 = getelementptr i8, i8* %b, i64 6
  %390 = load i8, i8* %scevgep34.1.4, align 1
  %call28.1.4 = call zeroext i8 @mult(i8 zeroext %389, i8 zeroext %390)
  %conv29.1.4 = zext i8 %call28.1.4 to i32
  %xor.1.4 = xor i32 %conv23.1.4, %conv29.1.4
  %scevgep35.1.4 = getelementptr i8, i8* %a, i64 6
  %391 = load i8, i8* %scevgep35.1.4, align 1
  %392 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.4 = call zeroext i8 @mult(i8 zeroext %391, i8 zeroext %392)
  %conv35.1.4 = zext i8 %call34.1.4 to i32
  %xor36.1.4 = xor i32 %xor.1.4, %conv35.1.4
  %conv37.1.4 = trunc i32 %xor36.1.4 to i8
  store i8 %conv37.1.4, i8* %scevgep41.1.3, align 1
  %scevgep28.1.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %386, i64 0, i64 0, i64 1
  %393 = bitcast i8* %scevgep28.1.4 to [41 x [41 x i8]]*
  %scevgep41.1.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %387, i64 0, i64 1, i64 0
  %394 = bitcast i8* %scevgep41.1.4 to [41 x [41 x i8]]*
  %call16.1.5 = call zeroext i8 (...) @rand()
  store i8 %call16.1.5, i8* %scevgep28.1.4, align 1
  %395 = load i8, i8* %scevgep28.1.4, align 1
  %conv23.1.5 = zext i8 %395 to i32
  %396 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.5 = getelementptr i8, i8* %b, i64 7
  %397 = load i8, i8* %scevgep34.1.5, align 1
  %call28.1.5 = call zeroext i8 @mult(i8 zeroext %396, i8 zeroext %397)
  %conv29.1.5 = zext i8 %call28.1.5 to i32
  %xor.1.5 = xor i32 %conv23.1.5, %conv29.1.5
  %scevgep35.1.5 = getelementptr i8, i8* %a, i64 7
  %398 = load i8, i8* %scevgep35.1.5, align 1
  %399 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.5 = call zeroext i8 @mult(i8 zeroext %398, i8 zeroext %399)
  %conv35.1.5 = zext i8 %call34.1.5 to i32
  %xor36.1.5 = xor i32 %xor.1.5, %conv35.1.5
  %conv37.1.5 = trunc i32 %xor36.1.5 to i8
  store i8 %conv37.1.5, i8* %scevgep41.1.4, align 1
  %scevgep28.1.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %393, i64 0, i64 0, i64 1
  %400 = bitcast i8* %scevgep28.1.5 to [41 x [41 x i8]]*
  %scevgep41.1.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %394, i64 0, i64 1, i64 0
  %401 = bitcast i8* %scevgep41.1.5 to [41 x [41 x i8]]*
  %call16.1.6 = call zeroext i8 (...) @rand()
  store i8 %call16.1.6, i8* %scevgep28.1.5, align 1
  %402 = load i8, i8* %scevgep28.1.5, align 1
  %conv23.1.6 = zext i8 %402 to i32
  %403 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.6 = getelementptr i8, i8* %b, i64 8
  %404 = load i8, i8* %scevgep34.1.6, align 1
  %call28.1.6 = call zeroext i8 @mult(i8 zeroext %403, i8 zeroext %404)
  %conv29.1.6 = zext i8 %call28.1.6 to i32
  %xor.1.6 = xor i32 %conv23.1.6, %conv29.1.6
  %scevgep35.1.6 = getelementptr i8, i8* %a, i64 8
  %405 = load i8, i8* %scevgep35.1.6, align 1
  %406 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.6 = call zeroext i8 @mult(i8 zeroext %405, i8 zeroext %406)
  %conv35.1.6 = zext i8 %call34.1.6 to i32
  %xor36.1.6 = xor i32 %xor.1.6, %conv35.1.6
  %conv37.1.6 = trunc i32 %xor36.1.6 to i8
  store i8 %conv37.1.6, i8* %scevgep41.1.5, align 1
  %scevgep28.1.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %400, i64 0, i64 0, i64 1
  %407 = bitcast i8* %scevgep28.1.6 to [41 x [41 x i8]]*
  %scevgep41.1.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %401, i64 0, i64 1, i64 0
  %408 = bitcast i8* %scevgep41.1.6 to [41 x [41 x i8]]*
  %call16.1.7 = call zeroext i8 (...) @rand()
  store i8 %call16.1.7, i8* %scevgep28.1.6, align 1
  %409 = load i8, i8* %scevgep28.1.6, align 1
  %conv23.1.7 = zext i8 %409 to i32
  %410 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.7 = getelementptr i8, i8* %b, i64 9
  %411 = load i8, i8* %scevgep34.1.7, align 1
  %call28.1.7 = call zeroext i8 @mult(i8 zeroext %410, i8 zeroext %411)
  %conv29.1.7 = zext i8 %call28.1.7 to i32
  %xor.1.7 = xor i32 %conv23.1.7, %conv29.1.7
  %scevgep35.1.7 = getelementptr i8, i8* %a, i64 9
  %412 = load i8, i8* %scevgep35.1.7, align 1
  %413 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.7 = call zeroext i8 @mult(i8 zeroext %412, i8 zeroext %413)
  %conv35.1.7 = zext i8 %call34.1.7 to i32
  %xor36.1.7 = xor i32 %xor.1.7, %conv35.1.7
  %conv37.1.7 = trunc i32 %xor36.1.7 to i8
  store i8 %conv37.1.7, i8* %scevgep41.1.6, align 1
  %scevgep28.1.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %407, i64 0, i64 0, i64 1
  %414 = bitcast i8* %scevgep28.1.7 to [41 x [41 x i8]]*
  %scevgep41.1.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %408, i64 0, i64 1, i64 0
  %415 = bitcast i8* %scevgep41.1.7 to [41 x [41 x i8]]*
  %call16.1.8 = call zeroext i8 (...) @rand()
  store i8 %call16.1.8, i8* %scevgep28.1.7, align 1
  %416 = load i8, i8* %scevgep28.1.7, align 1
  %conv23.1.8 = zext i8 %416 to i32
  %417 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.8 = getelementptr i8, i8* %b, i64 10
  %418 = load i8, i8* %scevgep34.1.8, align 1
  %call28.1.8 = call zeroext i8 @mult(i8 zeroext %417, i8 zeroext %418)
  %conv29.1.8 = zext i8 %call28.1.8 to i32
  %xor.1.8 = xor i32 %conv23.1.8, %conv29.1.8
  %scevgep35.1.8 = getelementptr i8, i8* %a, i64 10
  %419 = load i8, i8* %scevgep35.1.8, align 1
  %420 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.8 = call zeroext i8 @mult(i8 zeroext %419, i8 zeroext %420)
  %conv35.1.8 = zext i8 %call34.1.8 to i32
  %xor36.1.8 = xor i32 %xor.1.8, %conv35.1.8
  %conv37.1.8 = trunc i32 %xor36.1.8 to i8
  store i8 %conv37.1.8, i8* %scevgep41.1.7, align 1
  %scevgep28.1.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %414, i64 0, i64 0, i64 1
  %421 = bitcast i8* %scevgep28.1.8 to [41 x [41 x i8]]*
  %scevgep41.1.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %415, i64 0, i64 1, i64 0
  %422 = bitcast i8* %scevgep41.1.8 to [41 x [41 x i8]]*
  %call16.1.9 = call zeroext i8 (...) @rand()
  store i8 %call16.1.9, i8* %scevgep28.1.8, align 1
  %423 = load i8, i8* %scevgep28.1.8, align 1
  %conv23.1.9 = zext i8 %423 to i32
  %424 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.9 = getelementptr i8, i8* %b, i64 11
  %425 = load i8, i8* %scevgep34.1.9, align 1
  %call28.1.9 = call zeroext i8 @mult(i8 zeroext %424, i8 zeroext %425)
  %conv29.1.9 = zext i8 %call28.1.9 to i32
  %xor.1.9 = xor i32 %conv23.1.9, %conv29.1.9
  %scevgep35.1.9 = getelementptr i8, i8* %a, i64 11
  %426 = load i8, i8* %scevgep35.1.9, align 1
  %427 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.9 = call zeroext i8 @mult(i8 zeroext %426, i8 zeroext %427)
  %conv35.1.9 = zext i8 %call34.1.9 to i32
  %xor36.1.9 = xor i32 %xor.1.9, %conv35.1.9
  %conv37.1.9 = trunc i32 %xor36.1.9 to i8
  store i8 %conv37.1.9, i8* %scevgep41.1.8, align 1
  %scevgep28.1.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %421, i64 0, i64 0, i64 1
  %428 = bitcast i8* %scevgep28.1.9 to [41 x [41 x i8]]*
  %scevgep41.1.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %422, i64 0, i64 1, i64 0
  %429 = bitcast i8* %scevgep41.1.9 to [41 x [41 x i8]]*
  %call16.1.10 = call zeroext i8 (...) @rand()
  store i8 %call16.1.10, i8* %scevgep28.1.9, align 1
  %430 = load i8, i8* %scevgep28.1.9, align 1
  %conv23.1.10 = zext i8 %430 to i32
  %431 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.10 = getelementptr i8, i8* %b, i64 12
  %432 = load i8, i8* %scevgep34.1.10, align 1
  %call28.1.10 = call zeroext i8 @mult(i8 zeroext %431, i8 zeroext %432)
  %conv29.1.10 = zext i8 %call28.1.10 to i32
  %xor.1.10 = xor i32 %conv23.1.10, %conv29.1.10
  %scevgep35.1.10 = getelementptr i8, i8* %a, i64 12
  %433 = load i8, i8* %scevgep35.1.10, align 1
  %434 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.10 = call zeroext i8 @mult(i8 zeroext %433, i8 zeroext %434)
  %conv35.1.10 = zext i8 %call34.1.10 to i32
  %xor36.1.10 = xor i32 %xor.1.10, %conv35.1.10
  %conv37.1.10 = trunc i32 %xor36.1.10 to i8
  store i8 %conv37.1.10, i8* %scevgep41.1.9, align 1
  %scevgep28.1.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %428, i64 0, i64 0, i64 1
  %435 = bitcast i8* %scevgep28.1.10 to [41 x [41 x i8]]*
  %scevgep41.1.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %429, i64 0, i64 1, i64 0
  %436 = bitcast i8* %scevgep41.1.10 to [41 x [41 x i8]]*
  %call16.1.11 = call zeroext i8 (...) @rand()
  store i8 %call16.1.11, i8* %scevgep28.1.10, align 1
  %437 = load i8, i8* %scevgep28.1.10, align 1
  %conv23.1.11 = zext i8 %437 to i32
  %438 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.11 = getelementptr i8, i8* %b, i64 13
  %439 = load i8, i8* %scevgep34.1.11, align 1
  %call28.1.11 = call zeroext i8 @mult(i8 zeroext %438, i8 zeroext %439)
  %conv29.1.11 = zext i8 %call28.1.11 to i32
  %xor.1.11 = xor i32 %conv23.1.11, %conv29.1.11
  %scevgep35.1.11 = getelementptr i8, i8* %a, i64 13
  %440 = load i8, i8* %scevgep35.1.11, align 1
  %441 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.11 = call zeroext i8 @mult(i8 zeroext %440, i8 zeroext %441)
  %conv35.1.11 = zext i8 %call34.1.11 to i32
  %xor36.1.11 = xor i32 %xor.1.11, %conv35.1.11
  %conv37.1.11 = trunc i32 %xor36.1.11 to i8
  store i8 %conv37.1.11, i8* %scevgep41.1.10, align 1
  %scevgep28.1.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %435, i64 0, i64 0, i64 1
  %442 = bitcast i8* %scevgep28.1.11 to [41 x [41 x i8]]*
  %scevgep41.1.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %436, i64 0, i64 1, i64 0
  %443 = bitcast i8* %scevgep41.1.11 to [41 x [41 x i8]]*
  %call16.1.12 = call zeroext i8 (...) @rand()
  store i8 %call16.1.12, i8* %scevgep28.1.11, align 1
  %444 = load i8, i8* %scevgep28.1.11, align 1
  %conv23.1.12 = zext i8 %444 to i32
  %445 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.12 = getelementptr i8, i8* %b, i64 14
  %446 = load i8, i8* %scevgep34.1.12, align 1
  %call28.1.12 = call zeroext i8 @mult(i8 zeroext %445, i8 zeroext %446)
  %conv29.1.12 = zext i8 %call28.1.12 to i32
  %xor.1.12 = xor i32 %conv23.1.12, %conv29.1.12
  %scevgep35.1.12 = getelementptr i8, i8* %a, i64 14
  %447 = load i8, i8* %scevgep35.1.12, align 1
  %448 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.12 = call zeroext i8 @mult(i8 zeroext %447, i8 zeroext %448)
  %conv35.1.12 = zext i8 %call34.1.12 to i32
  %xor36.1.12 = xor i32 %xor.1.12, %conv35.1.12
  %conv37.1.12 = trunc i32 %xor36.1.12 to i8
  store i8 %conv37.1.12, i8* %scevgep41.1.11, align 1
  %scevgep28.1.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %442, i64 0, i64 0, i64 1
  %449 = bitcast i8* %scevgep28.1.12 to [41 x [41 x i8]]*
  %scevgep41.1.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %443, i64 0, i64 1, i64 0
  %450 = bitcast i8* %scevgep41.1.12 to [41 x [41 x i8]]*
  %call16.1.13 = call zeroext i8 (...) @rand()
  store i8 %call16.1.13, i8* %scevgep28.1.12, align 1
  %451 = load i8, i8* %scevgep28.1.12, align 1
  %conv23.1.13 = zext i8 %451 to i32
  %452 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.13 = getelementptr i8, i8* %b, i64 15
  %453 = load i8, i8* %scevgep34.1.13, align 1
  %call28.1.13 = call zeroext i8 @mult(i8 zeroext %452, i8 zeroext %453)
  %conv29.1.13 = zext i8 %call28.1.13 to i32
  %xor.1.13 = xor i32 %conv23.1.13, %conv29.1.13
  %scevgep35.1.13 = getelementptr i8, i8* %a, i64 15
  %454 = load i8, i8* %scevgep35.1.13, align 1
  %455 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.13 = call zeroext i8 @mult(i8 zeroext %454, i8 zeroext %455)
  %conv35.1.13 = zext i8 %call34.1.13 to i32
  %xor36.1.13 = xor i32 %xor.1.13, %conv35.1.13
  %conv37.1.13 = trunc i32 %xor36.1.13 to i8
  store i8 %conv37.1.13, i8* %scevgep41.1.12, align 1
  %scevgep28.1.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %449, i64 0, i64 0, i64 1
  %456 = bitcast i8* %scevgep28.1.13 to [41 x [41 x i8]]*
  %scevgep41.1.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %450, i64 0, i64 1, i64 0
  %457 = bitcast i8* %scevgep41.1.13 to [41 x [41 x i8]]*
  %call16.1.14 = call zeroext i8 (...) @rand()
  store i8 %call16.1.14, i8* %scevgep28.1.13, align 1
  %458 = load i8, i8* %scevgep28.1.13, align 1
  %conv23.1.14 = zext i8 %458 to i32
  %459 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.14 = getelementptr i8, i8* %b, i64 16
  %460 = load i8, i8* %scevgep34.1.14, align 1
  %call28.1.14 = call zeroext i8 @mult(i8 zeroext %459, i8 zeroext %460)
  %conv29.1.14 = zext i8 %call28.1.14 to i32
  %xor.1.14 = xor i32 %conv23.1.14, %conv29.1.14
  %scevgep35.1.14 = getelementptr i8, i8* %a, i64 16
  %461 = load i8, i8* %scevgep35.1.14, align 1
  %462 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.14 = call zeroext i8 @mult(i8 zeroext %461, i8 zeroext %462)
  %conv35.1.14 = zext i8 %call34.1.14 to i32
  %xor36.1.14 = xor i32 %xor.1.14, %conv35.1.14
  %conv37.1.14 = trunc i32 %xor36.1.14 to i8
  store i8 %conv37.1.14, i8* %scevgep41.1.13, align 1
  %scevgep28.1.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %456, i64 0, i64 0, i64 1
  %463 = bitcast i8* %scevgep28.1.14 to [41 x [41 x i8]]*
  %scevgep41.1.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %457, i64 0, i64 1, i64 0
  %464 = bitcast i8* %scevgep41.1.14 to [41 x [41 x i8]]*
  %call16.1.15 = call zeroext i8 (...) @rand()
  store i8 %call16.1.15, i8* %scevgep28.1.14, align 1
  %465 = load i8, i8* %scevgep28.1.14, align 1
  %conv23.1.15 = zext i8 %465 to i32
  %466 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.15 = getelementptr i8, i8* %b, i64 17
  %467 = load i8, i8* %scevgep34.1.15, align 1
  %call28.1.15 = call zeroext i8 @mult(i8 zeroext %466, i8 zeroext %467)
  %conv29.1.15 = zext i8 %call28.1.15 to i32
  %xor.1.15 = xor i32 %conv23.1.15, %conv29.1.15
  %scevgep35.1.15 = getelementptr i8, i8* %a, i64 17
  %468 = load i8, i8* %scevgep35.1.15, align 1
  %469 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.15 = call zeroext i8 @mult(i8 zeroext %468, i8 zeroext %469)
  %conv35.1.15 = zext i8 %call34.1.15 to i32
  %xor36.1.15 = xor i32 %xor.1.15, %conv35.1.15
  %conv37.1.15 = trunc i32 %xor36.1.15 to i8
  store i8 %conv37.1.15, i8* %scevgep41.1.14, align 1
  %scevgep28.1.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %463, i64 0, i64 0, i64 1
  %470 = bitcast i8* %scevgep28.1.15 to [41 x [41 x i8]]*
  %scevgep41.1.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %464, i64 0, i64 1, i64 0
  %471 = bitcast i8* %scevgep41.1.15 to [41 x [41 x i8]]*
  %call16.1.16 = call zeroext i8 (...) @rand()
  store i8 %call16.1.16, i8* %scevgep28.1.15, align 1
  %472 = load i8, i8* %scevgep28.1.15, align 1
  %conv23.1.16 = zext i8 %472 to i32
  %473 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.16 = getelementptr i8, i8* %b, i64 18
  %474 = load i8, i8* %scevgep34.1.16, align 1
  %call28.1.16 = call zeroext i8 @mult(i8 zeroext %473, i8 zeroext %474)
  %conv29.1.16 = zext i8 %call28.1.16 to i32
  %xor.1.16 = xor i32 %conv23.1.16, %conv29.1.16
  %scevgep35.1.16 = getelementptr i8, i8* %a, i64 18
  %475 = load i8, i8* %scevgep35.1.16, align 1
  %476 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.16 = call zeroext i8 @mult(i8 zeroext %475, i8 zeroext %476)
  %conv35.1.16 = zext i8 %call34.1.16 to i32
  %xor36.1.16 = xor i32 %xor.1.16, %conv35.1.16
  %conv37.1.16 = trunc i32 %xor36.1.16 to i8
  store i8 %conv37.1.16, i8* %scevgep41.1.15, align 1
  %scevgep28.1.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %470, i64 0, i64 0, i64 1
  %477 = bitcast i8* %scevgep28.1.16 to [41 x [41 x i8]]*
  %scevgep41.1.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %471, i64 0, i64 1, i64 0
  %478 = bitcast i8* %scevgep41.1.16 to [41 x [41 x i8]]*
  %call16.1.17 = call zeroext i8 (...) @rand()
  store i8 %call16.1.17, i8* %scevgep28.1.16, align 1
  %479 = load i8, i8* %scevgep28.1.16, align 1
  %conv23.1.17 = zext i8 %479 to i32
  %480 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.17 = getelementptr i8, i8* %b, i64 19
  %481 = load i8, i8* %scevgep34.1.17, align 1
  %call28.1.17 = call zeroext i8 @mult(i8 zeroext %480, i8 zeroext %481)
  %conv29.1.17 = zext i8 %call28.1.17 to i32
  %xor.1.17 = xor i32 %conv23.1.17, %conv29.1.17
  %scevgep35.1.17 = getelementptr i8, i8* %a, i64 19
  %482 = load i8, i8* %scevgep35.1.17, align 1
  %483 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.17 = call zeroext i8 @mult(i8 zeroext %482, i8 zeroext %483)
  %conv35.1.17 = zext i8 %call34.1.17 to i32
  %xor36.1.17 = xor i32 %xor.1.17, %conv35.1.17
  %conv37.1.17 = trunc i32 %xor36.1.17 to i8
  store i8 %conv37.1.17, i8* %scevgep41.1.16, align 1
  %scevgep28.1.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %477, i64 0, i64 0, i64 1
  %484 = bitcast i8* %scevgep28.1.17 to [41 x [41 x i8]]*
  %scevgep41.1.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %478, i64 0, i64 1, i64 0
  %485 = bitcast i8* %scevgep41.1.17 to [41 x [41 x i8]]*
  %call16.1.18 = call zeroext i8 (...) @rand()
  store i8 %call16.1.18, i8* %scevgep28.1.17, align 1
  %486 = load i8, i8* %scevgep28.1.17, align 1
  %conv23.1.18 = zext i8 %486 to i32
  %487 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.18 = getelementptr i8, i8* %b, i64 20
  %488 = load i8, i8* %scevgep34.1.18, align 1
  %call28.1.18 = call zeroext i8 @mult(i8 zeroext %487, i8 zeroext %488)
  %conv29.1.18 = zext i8 %call28.1.18 to i32
  %xor.1.18 = xor i32 %conv23.1.18, %conv29.1.18
  %scevgep35.1.18 = getelementptr i8, i8* %a, i64 20
  %489 = load i8, i8* %scevgep35.1.18, align 1
  %490 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.18 = call zeroext i8 @mult(i8 zeroext %489, i8 zeroext %490)
  %conv35.1.18 = zext i8 %call34.1.18 to i32
  %xor36.1.18 = xor i32 %xor.1.18, %conv35.1.18
  %conv37.1.18 = trunc i32 %xor36.1.18 to i8
  store i8 %conv37.1.18, i8* %scevgep41.1.17, align 1
  %scevgep28.1.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %484, i64 0, i64 0, i64 1
  %491 = bitcast i8* %scevgep28.1.18 to [41 x [41 x i8]]*
  %scevgep41.1.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %485, i64 0, i64 1, i64 0
  %492 = bitcast i8* %scevgep41.1.18 to [41 x [41 x i8]]*
  %call16.1.19 = call zeroext i8 (...) @rand()
  store i8 %call16.1.19, i8* %scevgep28.1.18, align 1
  %493 = load i8, i8* %scevgep28.1.18, align 1
  %conv23.1.19 = zext i8 %493 to i32
  %494 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.19 = getelementptr i8, i8* %b, i64 21
  %495 = load i8, i8* %scevgep34.1.19, align 1
  %call28.1.19 = call zeroext i8 @mult(i8 zeroext %494, i8 zeroext %495)
  %conv29.1.19 = zext i8 %call28.1.19 to i32
  %xor.1.19 = xor i32 %conv23.1.19, %conv29.1.19
  %scevgep35.1.19 = getelementptr i8, i8* %a, i64 21
  %496 = load i8, i8* %scevgep35.1.19, align 1
  %497 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.19 = call zeroext i8 @mult(i8 zeroext %496, i8 zeroext %497)
  %conv35.1.19 = zext i8 %call34.1.19 to i32
  %xor36.1.19 = xor i32 %xor.1.19, %conv35.1.19
  %conv37.1.19 = trunc i32 %xor36.1.19 to i8
  store i8 %conv37.1.19, i8* %scevgep41.1.18, align 1
  %scevgep28.1.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %491, i64 0, i64 0, i64 1
  %498 = bitcast i8* %scevgep28.1.19 to [41 x [41 x i8]]*
  %scevgep41.1.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %492, i64 0, i64 1, i64 0
  %499 = bitcast i8* %scevgep41.1.19 to [41 x [41 x i8]]*
  %call16.1.20 = call zeroext i8 (...) @rand()
  store i8 %call16.1.20, i8* %scevgep28.1.19, align 1
  %500 = load i8, i8* %scevgep28.1.19, align 1
  %conv23.1.20 = zext i8 %500 to i32
  %501 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.20 = getelementptr i8, i8* %b, i64 22
  %502 = load i8, i8* %scevgep34.1.20, align 1
  %call28.1.20 = call zeroext i8 @mult(i8 zeroext %501, i8 zeroext %502)
  %conv29.1.20 = zext i8 %call28.1.20 to i32
  %xor.1.20 = xor i32 %conv23.1.20, %conv29.1.20
  %scevgep35.1.20 = getelementptr i8, i8* %a, i64 22
  %503 = load i8, i8* %scevgep35.1.20, align 1
  %504 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.20 = call zeroext i8 @mult(i8 zeroext %503, i8 zeroext %504)
  %conv35.1.20 = zext i8 %call34.1.20 to i32
  %xor36.1.20 = xor i32 %xor.1.20, %conv35.1.20
  %conv37.1.20 = trunc i32 %xor36.1.20 to i8
  store i8 %conv37.1.20, i8* %scevgep41.1.19, align 1
  %scevgep28.1.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %498, i64 0, i64 0, i64 1
  %505 = bitcast i8* %scevgep28.1.20 to [41 x [41 x i8]]*
  %scevgep41.1.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %499, i64 0, i64 1, i64 0
  %506 = bitcast i8* %scevgep41.1.20 to [41 x [41 x i8]]*
  %call16.1.21 = call zeroext i8 (...) @rand()
  store i8 %call16.1.21, i8* %scevgep28.1.20, align 1
  %507 = load i8, i8* %scevgep28.1.20, align 1
  %conv23.1.21 = zext i8 %507 to i32
  %508 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.21 = getelementptr i8, i8* %b, i64 23
  %509 = load i8, i8* %scevgep34.1.21, align 1
  %call28.1.21 = call zeroext i8 @mult(i8 zeroext %508, i8 zeroext %509)
  %conv29.1.21 = zext i8 %call28.1.21 to i32
  %xor.1.21 = xor i32 %conv23.1.21, %conv29.1.21
  %scevgep35.1.21 = getelementptr i8, i8* %a, i64 23
  %510 = load i8, i8* %scevgep35.1.21, align 1
  %511 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.21 = call zeroext i8 @mult(i8 zeroext %510, i8 zeroext %511)
  %conv35.1.21 = zext i8 %call34.1.21 to i32
  %xor36.1.21 = xor i32 %xor.1.21, %conv35.1.21
  %conv37.1.21 = trunc i32 %xor36.1.21 to i8
  store i8 %conv37.1.21, i8* %scevgep41.1.20, align 1
  %scevgep28.1.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %505, i64 0, i64 0, i64 1
  %512 = bitcast i8* %scevgep28.1.21 to [41 x [41 x i8]]*
  %scevgep41.1.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %506, i64 0, i64 1, i64 0
  %513 = bitcast i8* %scevgep41.1.21 to [41 x [41 x i8]]*
  %call16.1.22 = call zeroext i8 (...) @rand()
  store i8 %call16.1.22, i8* %scevgep28.1.21, align 1
  %514 = load i8, i8* %scevgep28.1.21, align 1
  %conv23.1.22 = zext i8 %514 to i32
  %515 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.22 = getelementptr i8, i8* %b, i64 24
  %516 = load i8, i8* %scevgep34.1.22, align 1
  %call28.1.22 = call zeroext i8 @mult(i8 zeroext %515, i8 zeroext %516)
  %conv29.1.22 = zext i8 %call28.1.22 to i32
  %xor.1.22 = xor i32 %conv23.1.22, %conv29.1.22
  %scevgep35.1.22 = getelementptr i8, i8* %a, i64 24
  %517 = load i8, i8* %scevgep35.1.22, align 1
  %518 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.22 = call zeroext i8 @mult(i8 zeroext %517, i8 zeroext %518)
  %conv35.1.22 = zext i8 %call34.1.22 to i32
  %xor36.1.22 = xor i32 %xor.1.22, %conv35.1.22
  %conv37.1.22 = trunc i32 %xor36.1.22 to i8
  store i8 %conv37.1.22, i8* %scevgep41.1.21, align 1
  %scevgep28.1.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %512, i64 0, i64 0, i64 1
  %519 = bitcast i8* %scevgep28.1.22 to [41 x [41 x i8]]*
  %scevgep41.1.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %513, i64 0, i64 1, i64 0
  %520 = bitcast i8* %scevgep41.1.22 to [41 x [41 x i8]]*
  %call16.1.23 = call zeroext i8 (...) @rand()
  store i8 %call16.1.23, i8* %scevgep28.1.22, align 1
  %521 = load i8, i8* %scevgep28.1.22, align 1
  %conv23.1.23 = zext i8 %521 to i32
  %522 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.23 = getelementptr i8, i8* %b, i64 25
  %523 = load i8, i8* %scevgep34.1.23, align 1
  %call28.1.23 = call zeroext i8 @mult(i8 zeroext %522, i8 zeroext %523)
  %conv29.1.23 = zext i8 %call28.1.23 to i32
  %xor.1.23 = xor i32 %conv23.1.23, %conv29.1.23
  %scevgep35.1.23 = getelementptr i8, i8* %a, i64 25
  %524 = load i8, i8* %scevgep35.1.23, align 1
  %525 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.23 = call zeroext i8 @mult(i8 zeroext %524, i8 zeroext %525)
  %conv35.1.23 = zext i8 %call34.1.23 to i32
  %xor36.1.23 = xor i32 %xor.1.23, %conv35.1.23
  %conv37.1.23 = trunc i32 %xor36.1.23 to i8
  store i8 %conv37.1.23, i8* %scevgep41.1.22, align 1
  %scevgep28.1.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %519, i64 0, i64 0, i64 1
  %526 = bitcast i8* %scevgep28.1.23 to [41 x [41 x i8]]*
  %scevgep41.1.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %520, i64 0, i64 1, i64 0
  %527 = bitcast i8* %scevgep41.1.23 to [41 x [41 x i8]]*
  %call16.1.24 = call zeroext i8 (...) @rand()
  store i8 %call16.1.24, i8* %scevgep28.1.23, align 1
  %528 = load i8, i8* %scevgep28.1.23, align 1
  %conv23.1.24 = zext i8 %528 to i32
  %529 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.24 = getelementptr i8, i8* %b, i64 26
  %530 = load i8, i8* %scevgep34.1.24, align 1
  %call28.1.24 = call zeroext i8 @mult(i8 zeroext %529, i8 zeroext %530)
  %conv29.1.24 = zext i8 %call28.1.24 to i32
  %xor.1.24 = xor i32 %conv23.1.24, %conv29.1.24
  %scevgep35.1.24 = getelementptr i8, i8* %a, i64 26
  %531 = load i8, i8* %scevgep35.1.24, align 1
  %532 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.24 = call zeroext i8 @mult(i8 zeroext %531, i8 zeroext %532)
  %conv35.1.24 = zext i8 %call34.1.24 to i32
  %xor36.1.24 = xor i32 %xor.1.24, %conv35.1.24
  %conv37.1.24 = trunc i32 %xor36.1.24 to i8
  store i8 %conv37.1.24, i8* %scevgep41.1.23, align 1
  %scevgep28.1.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %526, i64 0, i64 0, i64 1
  %533 = bitcast i8* %scevgep28.1.24 to [41 x [41 x i8]]*
  %scevgep41.1.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %527, i64 0, i64 1, i64 0
  %534 = bitcast i8* %scevgep41.1.24 to [41 x [41 x i8]]*
  %call16.1.25 = call zeroext i8 (...) @rand()
  store i8 %call16.1.25, i8* %scevgep28.1.24, align 1
  %535 = load i8, i8* %scevgep28.1.24, align 1
  %conv23.1.25 = zext i8 %535 to i32
  %536 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.25 = getelementptr i8, i8* %b, i64 27
  %537 = load i8, i8* %scevgep34.1.25, align 1
  %call28.1.25 = call zeroext i8 @mult(i8 zeroext %536, i8 zeroext %537)
  %conv29.1.25 = zext i8 %call28.1.25 to i32
  %xor.1.25 = xor i32 %conv23.1.25, %conv29.1.25
  %scevgep35.1.25 = getelementptr i8, i8* %a, i64 27
  %538 = load i8, i8* %scevgep35.1.25, align 1
  %539 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.25 = call zeroext i8 @mult(i8 zeroext %538, i8 zeroext %539)
  %conv35.1.25 = zext i8 %call34.1.25 to i32
  %xor36.1.25 = xor i32 %xor.1.25, %conv35.1.25
  %conv37.1.25 = trunc i32 %xor36.1.25 to i8
  store i8 %conv37.1.25, i8* %scevgep41.1.24, align 1
  %scevgep28.1.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %533, i64 0, i64 0, i64 1
  %540 = bitcast i8* %scevgep28.1.25 to [41 x [41 x i8]]*
  %scevgep41.1.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %534, i64 0, i64 1, i64 0
  %541 = bitcast i8* %scevgep41.1.25 to [41 x [41 x i8]]*
  %call16.1.26 = call zeroext i8 (...) @rand()
  store i8 %call16.1.26, i8* %scevgep28.1.25, align 1
  %542 = load i8, i8* %scevgep28.1.25, align 1
  %conv23.1.26 = zext i8 %542 to i32
  %543 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.26 = getelementptr i8, i8* %b, i64 28
  %544 = load i8, i8* %scevgep34.1.26, align 1
  %call28.1.26 = call zeroext i8 @mult(i8 zeroext %543, i8 zeroext %544)
  %conv29.1.26 = zext i8 %call28.1.26 to i32
  %xor.1.26 = xor i32 %conv23.1.26, %conv29.1.26
  %scevgep35.1.26 = getelementptr i8, i8* %a, i64 28
  %545 = load i8, i8* %scevgep35.1.26, align 1
  %546 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.26 = call zeroext i8 @mult(i8 zeroext %545, i8 zeroext %546)
  %conv35.1.26 = zext i8 %call34.1.26 to i32
  %xor36.1.26 = xor i32 %xor.1.26, %conv35.1.26
  %conv37.1.26 = trunc i32 %xor36.1.26 to i8
  store i8 %conv37.1.26, i8* %scevgep41.1.25, align 1
  %scevgep28.1.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %540, i64 0, i64 0, i64 1
  %547 = bitcast i8* %scevgep28.1.26 to [41 x [41 x i8]]*
  %scevgep41.1.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %541, i64 0, i64 1, i64 0
  %548 = bitcast i8* %scevgep41.1.26 to [41 x [41 x i8]]*
  %call16.1.27 = call zeroext i8 (...) @rand()
  store i8 %call16.1.27, i8* %scevgep28.1.26, align 1
  %549 = load i8, i8* %scevgep28.1.26, align 1
  %conv23.1.27 = zext i8 %549 to i32
  %550 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.27 = getelementptr i8, i8* %b, i64 29
  %551 = load i8, i8* %scevgep34.1.27, align 1
  %call28.1.27 = call zeroext i8 @mult(i8 zeroext %550, i8 zeroext %551)
  %conv29.1.27 = zext i8 %call28.1.27 to i32
  %xor.1.27 = xor i32 %conv23.1.27, %conv29.1.27
  %scevgep35.1.27 = getelementptr i8, i8* %a, i64 29
  %552 = load i8, i8* %scevgep35.1.27, align 1
  %553 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.27 = call zeroext i8 @mult(i8 zeroext %552, i8 zeroext %553)
  %conv35.1.27 = zext i8 %call34.1.27 to i32
  %xor36.1.27 = xor i32 %xor.1.27, %conv35.1.27
  %conv37.1.27 = trunc i32 %xor36.1.27 to i8
  store i8 %conv37.1.27, i8* %scevgep41.1.26, align 1
  %scevgep28.1.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %547, i64 0, i64 0, i64 1
  %554 = bitcast i8* %scevgep28.1.27 to [41 x [41 x i8]]*
  %scevgep41.1.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %548, i64 0, i64 1, i64 0
  %555 = bitcast i8* %scevgep41.1.27 to [41 x [41 x i8]]*
  %call16.1.28 = call zeroext i8 (...) @rand()
  store i8 %call16.1.28, i8* %scevgep28.1.27, align 1
  %556 = load i8, i8* %scevgep28.1.27, align 1
  %conv23.1.28 = zext i8 %556 to i32
  %557 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.28 = getelementptr i8, i8* %b, i64 30
  %558 = load i8, i8* %scevgep34.1.28, align 1
  %call28.1.28 = call zeroext i8 @mult(i8 zeroext %557, i8 zeroext %558)
  %conv29.1.28 = zext i8 %call28.1.28 to i32
  %xor.1.28 = xor i32 %conv23.1.28, %conv29.1.28
  %scevgep35.1.28 = getelementptr i8, i8* %a, i64 30
  %559 = load i8, i8* %scevgep35.1.28, align 1
  %560 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.28 = call zeroext i8 @mult(i8 zeroext %559, i8 zeroext %560)
  %conv35.1.28 = zext i8 %call34.1.28 to i32
  %xor36.1.28 = xor i32 %xor.1.28, %conv35.1.28
  %conv37.1.28 = trunc i32 %xor36.1.28 to i8
  store i8 %conv37.1.28, i8* %scevgep41.1.27, align 1
  %scevgep28.1.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %554, i64 0, i64 0, i64 1
  %561 = bitcast i8* %scevgep28.1.28 to [41 x [41 x i8]]*
  %scevgep41.1.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %555, i64 0, i64 1, i64 0
  %562 = bitcast i8* %scevgep41.1.28 to [41 x [41 x i8]]*
  %call16.1.29 = call zeroext i8 (...) @rand()
  store i8 %call16.1.29, i8* %scevgep28.1.28, align 1
  %563 = load i8, i8* %scevgep28.1.28, align 1
  %conv23.1.29 = zext i8 %563 to i32
  %564 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.29 = getelementptr i8, i8* %b, i64 31
  %565 = load i8, i8* %scevgep34.1.29, align 1
  %call28.1.29 = call zeroext i8 @mult(i8 zeroext %564, i8 zeroext %565)
  %conv29.1.29 = zext i8 %call28.1.29 to i32
  %xor.1.29 = xor i32 %conv23.1.29, %conv29.1.29
  %scevgep35.1.29 = getelementptr i8, i8* %a, i64 31
  %566 = load i8, i8* %scevgep35.1.29, align 1
  %567 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.29 = call zeroext i8 @mult(i8 zeroext %566, i8 zeroext %567)
  %conv35.1.29 = zext i8 %call34.1.29 to i32
  %xor36.1.29 = xor i32 %xor.1.29, %conv35.1.29
  %conv37.1.29 = trunc i32 %xor36.1.29 to i8
  store i8 %conv37.1.29, i8* %scevgep41.1.28, align 1
  %scevgep28.1.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %561, i64 0, i64 0, i64 1
  %568 = bitcast i8* %scevgep28.1.29 to [41 x [41 x i8]]*
  %scevgep41.1.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %562, i64 0, i64 1, i64 0
  %569 = bitcast i8* %scevgep41.1.29 to [41 x [41 x i8]]*
  %call16.1.30 = call zeroext i8 (...) @rand()
  store i8 %call16.1.30, i8* %scevgep28.1.29, align 1
  %570 = load i8, i8* %scevgep28.1.29, align 1
  %conv23.1.30 = zext i8 %570 to i32
  %571 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.30 = getelementptr i8, i8* %b, i64 32
  %572 = load i8, i8* %scevgep34.1.30, align 1
  %call28.1.30 = call zeroext i8 @mult(i8 zeroext %571, i8 zeroext %572)
  %conv29.1.30 = zext i8 %call28.1.30 to i32
  %xor.1.30 = xor i32 %conv23.1.30, %conv29.1.30
  %scevgep35.1.30 = getelementptr i8, i8* %a, i64 32
  %573 = load i8, i8* %scevgep35.1.30, align 1
  %574 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.30 = call zeroext i8 @mult(i8 zeroext %573, i8 zeroext %574)
  %conv35.1.30 = zext i8 %call34.1.30 to i32
  %xor36.1.30 = xor i32 %xor.1.30, %conv35.1.30
  %conv37.1.30 = trunc i32 %xor36.1.30 to i8
  store i8 %conv37.1.30, i8* %scevgep41.1.29, align 1
  %scevgep28.1.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %568, i64 0, i64 0, i64 1
  %575 = bitcast i8* %scevgep28.1.30 to [41 x [41 x i8]]*
  %scevgep41.1.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %569, i64 0, i64 1, i64 0
  %576 = bitcast i8* %scevgep41.1.30 to [41 x [41 x i8]]*
  %call16.1.31 = call zeroext i8 (...) @rand()
  store i8 %call16.1.31, i8* %scevgep28.1.30, align 1
  %577 = load i8, i8* %scevgep28.1.30, align 1
  %conv23.1.31 = zext i8 %577 to i32
  %578 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.31 = getelementptr i8, i8* %b, i64 33
  %579 = load i8, i8* %scevgep34.1.31, align 1
  %call28.1.31 = call zeroext i8 @mult(i8 zeroext %578, i8 zeroext %579)
  %conv29.1.31 = zext i8 %call28.1.31 to i32
  %xor.1.31 = xor i32 %conv23.1.31, %conv29.1.31
  %scevgep35.1.31 = getelementptr i8, i8* %a, i64 33
  %580 = load i8, i8* %scevgep35.1.31, align 1
  %581 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.31 = call zeroext i8 @mult(i8 zeroext %580, i8 zeroext %581)
  %conv35.1.31 = zext i8 %call34.1.31 to i32
  %xor36.1.31 = xor i32 %xor.1.31, %conv35.1.31
  %conv37.1.31 = trunc i32 %xor36.1.31 to i8
  store i8 %conv37.1.31, i8* %scevgep41.1.30, align 1
  %scevgep28.1.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %575, i64 0, i64 0, i64 1
  %582 = bitcast i8* %scevgep28.1.31 to [41 x [41 x i8]]*
  %scevgep41.1.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %576, i64 0, i64 1, i64 0
  %583 = bitcast i8* %scevgep41.1.31 to [41 x [41 x i8]]*
  %call16.1.32 = call zeroext i8 (...) @rand()
  store i8 %call16.1.32, i8* %scevgep28.1.31, align 1
  %584 = load i8, i8* %scevgep28.1.31, align 1
  %conv23.1.32 = zext i8 %584 to i32
  %585 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.32 = getelementptr i8, i8* %b, i64 34
  %586 = load i8, i8* %scevgep34.1.32, align 1
  %call28.1.32 = call zeroext i8 @mult(i8 zeroext %585, i8 zeroext %586)
  %conv29.1.32 = zext i8 %call28.1.32 to i32
  %xor.1.32 = xor i32 %conv23.1.32, %conv29.1.32
  %scevgep35.1.32 = getelementptr i8, i8* %a, i64 34
  %587 = load i8, i8* %scevgep35.1.32, align 1
  %588 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.32 = call zeroext i8 @mult(i8 zeroext %587, i8 zeroext %588)
  %conv35.1.32 = zext i8 %call34.1.32 to i32
  %xor36.1.32 = xor i32 %xor.1.32, %conv35.1.32
  %conv37.1.32 = trunc i32 %xor36.1.32 to i8
  store i8 %conv37.1.32, i8* %scevgep41.1.31, align 1
  %scevgep28.1.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %582, i64 0, i64 0, i64 1
  %589 = bitcast i8* %scevgep28.1.32 to [41 x [41 x i8]]*
  %scevgep41.1.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %583, i64 0, i64 1, i64 0
  %590 = bitcast i8* %scevgep41.1.32 to [41 x [41 x i8]]*
  %call16.1.33 = call zeroext i8 (...) @rand()
  store i8 %call16.1.33, i8* %scevgep28.1.32, align 1
  %591 = load i8, i8* %scevgep28.1.32, align 1
  %conv23.1.33 = zext i8 %591 to i32
  %592 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.33 = getelementptr i8, i8* %b, i64 35
  %593 = load i8, i8* %scevgep34.1.33, align 1
  %call28.1.33 = call zeroext i8 @mult(i8 zeroext %592, i8 zeroext %593)
  %conv29.1.33 = zext i8 %call28.1.33 to i32
  %xor.1.33 = xor i32 %conv23.1.33, %conv29.1.33
  %scevgep35.1.33 = getelementptr i8, i8* %a, i64 35
  %594 = load i8, i8* %scevgep35.1.33, align 1
  %595 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.33 = call zeroext i8 @mult(i8 zeroext %594, i8 zeroext %595)
  %conv35.1.33 = zext i8 %call34.1.33 to i32
  %xor36.1.33 = xor i32 %xor.1.33, %conv35.1.33
  %conv37.1.33 = trunc i32 %xor36.1.33 to i8
  store i8 %conv37.1.33, i8* %scevgep41.1.32, align 1
  %scevgep28.1.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %589, i64 0, i64 0, i64 1
  %596 = bitcast i8* %scevgep28.1.33 to [41 x [41 x i8]]*
  %scevgep41.1.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %590, i64 0, i64 1, i64 0
  %597 = bitcast i8* %scevgep41.1.33 to [41 x [41 x i8]]*
  %call16.1.34 = call zeroext i8 (...) @rand()
  store i8 %call16.1.34, i8* %scevgep28.1.33, align 1
  %598 = load i8, i8* %scevgep28.1.33, align 1
  %conv23.1.34 = zext i8 %598 to i32
  %599 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.34 = getelementptr i8, i8* %b, i64 36
  %600 = load i8, i8* %scevgep34.1.34, align 1
  %call28.1.34 = call zeroext i8 @mult(i8 zeroext %599, i8 zeroext %600)
  %conv29.1.34 = zext i8 %call28.1.34 to i32
  %xor.1.34 = xor i32 %conv23.1.34, %conv29.1.34
  %scevgep35.1.34 = getelementptr i8, i8* %a, i64 36
  %601 = load i8, i8* %scevgep35.1.34, align 1
  %602 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.34 = call zeroext i8 @mult(i8 zeroext %601, i8 zeroext %602)
  %conv35.1.34 = zext i8 %call34.1.34 to i32
  %xor36.1.34 = xor i32 %xor.1.34, %conv35.1.34
  %conv37.1.34 = trunc i32 %xor36.1.34 to i8
  store i8 %conv37.1.34, i8* %scevgep41.1.33, align 1
  %scevgep28.1.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %596, i64 0, i64 0, i64 1
  %603 = bitcast i8* %scevgep28.1.34 to [41 x [41 x i8]]*
  %scevgep41.1.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %597, i64 0, i64 1, i64 0
  %604 = bitcast i8* %scevgep41.1.34 to [41 x [41 x i8]]*
  %call16.1.35 = call zeroext i8 (...) @rand()
  store i8 %call16.1.35, i8* %scevgep28.1.34, align 1
  %605 = load i8, i8* %scevgep28.1.34, align 1
  %conv23.1.35 = zext i8 %605 to i32
  %606 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.35 = getelementptr i8, i8* %b, i64 37
  %607 = load i8, i8* %scevgep34.1.35, align 1
  %call28.1.35 = call zeroext i8 @mult(i8 zeroext %606, i8 zeroext %607)
  %conv29.1.35 = zext i8 %call28.1.35 to i32
  %xor.1.35 = xor i32 %conv23.1.35, %conv29.1.35
  %scevgep35.1.35 = getelementptr i8, i8* %a, i64 37
  %608 = load i8, i8* %scevgep35.1.35, align 1
  %609 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.35 = call zeroext i8 @mult(i8 zeroext %608, i8 zeroext %609)
  %conv35.1.35 = zext i8 %call34.1.35 to i32
  %xor36.1.35 = xor i32 %xor.1.35, %conv35.1.35
  %conv37.1.35 = trunc i32 %xor36.1.35 to i8
  store i8 %conv37.1.35, i8* %scevgep41.1.34, align 1
  %scevgep28.1.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %603, i64 0, i64 0, i64 1
  %610 = bitcast i8* %scevgep28.1.35 to [41 x [41 x i8]]*
  %scevgep41.1.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %604, i64 0, i64 1, i64 0
  %611 = bitcast i8* %scevgep41.1.35 to [41 x [41 x i8]]*
  %call16.1.36 = call zeroext i8 (...) @rand()
  store i8 %call16.1.36, i8* %scevgep28.1.35, align 1
  %612 = load i8, i8* %scevgep28.1.35, align 1
  %conv23.1.36 = zext i8 %612 to i32
  %613 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.36 = getelementptr i8, i8* %b, i64 38
  %614 = load i8, i8* %scevgep34.1.36, align 1
  %call28.1.36 = call zeroext i8 @mult(i8 zeroext %613, i8 zeroext %614)
  %conv29.1.36 = zext i8 %call28.1.36 to i32
  %xor.1.36 = xor i32 %conv23.1.36, %conv29.1.36
  %scevgep35.1.36 = getelementptr i8, i8* %a, i64 38
  %615 = load i8, i8* %scevgep35.1.36, align 1
  %616 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.36 = call zeroext i8 @mult(i8 zeroext %615, i8 zeroext %616)
  %conv35.1.36 = zext i8 %call34.1.36 to i32
  %xor36.1.36 = xor i32 %xor.1.36, %conv35.1.36
  %conv37.1.36 = trunc i32 %xor36.1.36 to i8
  store i8 %conv37.1.36, i8* %scevgep41.1.35, align 1
  %scevgep28.1.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %610, i64 0, i64 0, i64 1
  %617 = bitcast i8* %scevgep28.1.36 to [41 x [41 x i8]]*
  %scevgep41.1.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %611, i64 0, i64 1, i64 0
  %618 = bitcast i8* %scevgep41.1.36 to [41 x [41 x i8]]*
  %call16.1.37 = call zeroext i8 (...) @rand()
  store i8 %call16.1.37, i8* %scevgep28.1.36, align 1
  %619 = load i8, i8* %scevgep28.1.36, align 1
  %conv23.1.37 = zext i8 %619 to i32
  %620 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.37 = getelementptr i8, i8* %b, i64 39
  %621 = load i8, i8* %scevgep34.1.37, align 1
  %call28.1.37 = call zeroext i8 @mult(i8 zeroext %620, i8 zeroext %621)
  %conv29.1.37 = zext i8 %call28.1.37 to i32
  %xor.1.37 = xor i32 %conv23.1.37, %conv29.1.37
  %scevgep35.1.37 = getelementptr i8, i8* %a, i64 39
  %622 = load i8, i8* %scevgep35.1.37, align 1
  %623 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.37 = call zeroext i8 @mult(i8 zeroext %622, i8 zeroext %623)
  %conv35.1.37 = zext i8 %call34.1.37 to i32
  %xor36.1.37 = xor i32 %xor.1.37, %conv35.1.37
  %conv37.1.37 = trunc i32 %xor36.1.37 to i8
  store i8 %conv37.1.37, i8* %scevgep41.1.36, align 1
  %scevgep28.1.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %617, i64 0, i64 0, i64 1
  %scevgep41.1.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %618, i64 0, i64 1, i64 0
  %call16.1.38 = call zeroext i8 (...) @rand()
  store i8 %call16.1.38, i8* %scevgep28.1.37, align 1
  %624 = load i8, i8* %scevgep28.1.37, align 1
  %conv23.1.38 = zext i8 %624 to i32
  %625 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.38 = getelementptr i8, i8* %b, i64 40
  %626 = load i8, i8* %scevgep34.1.38, align 1
  %call28.1.38 = call zeroext i8 @mult(i8 zeroext %625, i8 zeroext %626)
  %conv29.1.38 = zext i8 %call28.1.38 to i32
  %xor.1.38 = xor i32 %conv23.1.38, %conv29.1.38
  %scevgep35.1.38 = getelementptr i8, i8* %a, i64 40
  %627 = load i8, i8* %scevgep35.1.38, align 1
  %628 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.38 = call zeroext i8 @mult(i8 zeroext %627, i8 zeroext %628)
  %conv35.1.38 = zext i8 %call34.1.38 to i32
  %xor36.1.38 = xor i32 %xor.1.38, %conv35.1.38
  %conv37.1.38 = trunc i32 %xor36.1.38 to i8
  store i8 %conv37.1.38, i8* %scevgep41.1.37, align 1
  %scevgep26.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %358, i64 0, i64 1, i64 1
  %629 = bitcast i8* %scevgep26.1 to [41 x [41 x i8]]*
  %scevgep39.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %359, i64 0, i64 1, i64 1
  %630 = bitcast i8* %scevgep39.1 to [41 x [41 x i8]]*
  %arrayidx25.2 = getelementptr inbounds i8, i8* %a, i64 2
  %arrayidx33.2 = getelementptr inbounds i8, i8* %b, i64 2
  %call16.2 = call zeroext i8 (...) @rand()
  store i8 %call16.2, i8* %scevgep26.1, align 1
  %631 = load i8, i8* %scevgep26.1, align 1
  %conv23.2 = zext i8 %631 to i32
  %632 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2 = getelementptr i8, i8* %b, i64 3
  %633 = load i8, i8* %scevgep34.2, align 1
  %call28.2 = call zeroext i8 @mult(i8 zeroext %632, i8 zeroext %633)
  %conv29.2 = zext i8 %call28.2 to i32
  %xor.2 = xor i32 %conv23.2, %conv29.2
  %scevgep35.2 = getelementptr i8, i8* %a, i64 3
  %634 = load i8, i8* %scevgep35.2, align 1
  %635 = load i8, i8* %arrayidx33.2, align 1
  %call34.2 = call zeroext i8 @mult(i8 zeroext %634, i8 zeroext %635)
  %conv35.2 = zext i8 %call34.2 to i32
  %xor36.2 = xor i32 %xor.2, %conv35.2
  %conv37.2 = trunc i32 %xor36.2 to i8
  store i8 %conv37.2, i8* %scevgep39.1, align 1
  %scevgep28.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %629, i64 0, i64 0, i64 1
  %636 = bitcast i8* %scevgep28.2 to [41 x [41 x i8]]*
  %scevgep41.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %630, i64 0, i64 1, i64 0
  %637 = bitcast i8* %scevgep41.2 to [41 x [41 x i8]]*
  %call16.2.1 = call zeroext i8 (...) @rand()
  store i8 %call16.2.1, i8* %scevgep28.2, align 1
  %638 = load i8, i8* %scevgep28.2, align 1
  %conv23.2.1 = zext i8 %638 to i32
  %639 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.1 = getelementptr i8, i8* %b, i64 4
  %640 = load i8, i8* %scevgep34.2.1, align 1
  %call28.2.1 = call zeroext i8 @mult(i8 zeroext %639, i8 zeroext %640)
  %conv29.2.1 = zext i8 %call28.2.1 to i32
  %xor.2.1 = xor i32 %conv23.2.1, %conv29.2.1
  %scevgep35.2.1 = getelementptr i8, i8* %a, i64 4
  %641 = load i8, i8* %scevgep35.2.1, align 1
  %642 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.1 = call zeroext i8 @mult(i8 zeroext %641, i8 zeroext %642)
  %conv35.2.1 = zext i8 %call34.2.1 to i32
  %xor36.2.1 = xor i32 %xor.2.1, %conv35.2.1
  %conv37.2.1 = trunc i32 %xor36.2.1 to i8
  store i8 %conv37.2.1, i8* %scevgep41.2, align 1
  %scevgep28.2.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %636, i64 0, i64 0, i64 1
  %643 = bitcast i8* %scevgep28.2.1 to [41 x [41 x i8]]*
  %scevgep41.2.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %637, i64 0, i64 1, i64 0
  %644 = bitcast i8* %scevgep41.2.1 to [41 x [41 x i8]]*
  %call16.2.2 = call zeroext i8 (...) @rand()
  store i8 %call16.2.2, i8* %scevgep28.2.1, align 1
  %645 = load i8, i8* %scevgep28.2.1, align 1
  %conv23.2.2 = zext i8 %645 to i32
  %646 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.2 = getelementptr i8, i8* %b, i64 5
  %647 = load i8, i8* %scevgep34.2.2, align 1
  %call28.2.2 = call zeroext i8 @mult(i8 zeroext %646, i8 zeroext %647)
  %conv29.2.2 = zext i8 %call28.2.2 to i32
  %xor.2.2 = xor i32 %conv23.2.2, %conv29.2.2
  %scevgep35.2.2 = getelementptr i8, i8* %a, i64 5
  %648 = load i8, i8* %scevgep35.2.2, align 1
  %649 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.2 = call zeroext i8 @mult(i8 zeroext %648, i8 zeroext %649)
  %conv35.2.2 = zext i8 %call34.2.2 to i32
  %xor36.2.2 = xor i32 %xor.2.2, %conv35.2.2
  %conv37.2.2 = trunc i32 %xor36.2.2 to i8
  store i8 %conv37.2.2, i8* %scevgep41.2.1, align 1
  %scevgep28.2.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %643, i64 0, i64 0, i64 1
  %650 = bitcast i8* %scevgep28.2.2 to [41 x [41 x i8]]*
  %scevgep41.2.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %644, i64 0, i64 1, i64 0
  %651 = bitcast i8* %scevgep41.2.2 to [41 x [41 x i8]]*
  %call16.2.3 = call zeroext i8 (...) @rand()
  store i8 %call16.2.3, i8* %scevgep28.2.2, align 1
  %652 = load i8, i8* %scevgep28.2.2, align 1
  %conv23.2.3 = zext i8 %652 to i32
  %653 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.3 = getelementptr i8, i8* %b, i64 6
  %654 = load i8, i8* %scevgep34.2.3, align 1
  %call28.2.3 = call zeroext i8 @mult(i8 zeroext %653, i8 zeroext %654)
  %conv29.2.3 = zext i8 %call28.2.3 to i32
  %xor.2.3 = xor i32 %conv23.2.3, %conv29.2.3
  %scevgep35.2.3 = getelementptr i8, i8* %a, i64 6
  %655 = load i8, i8* %scevgep35.2.3, align 1
  %656 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.3 = call zeroext i8 @mult(i8 zeroext %655, i8 zeroext %656)
  %conv35.2.3 = zext i8 %call34.2.3 to i32
  %xor36.2.3 = xor i32 %xor.2.3, %conv35.2.3
  %conv37.2.3 = trunc i32 %xor36.2.3 to i8
  store i8 %conv37.2.3, i8* %scevgep41.2.2, align 1
  %scevgep28.2.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %650, i64 0, i64 0, i64 1
  %657 = bitcast i8* %scevgep28.2.3 to [41 x [41 x i8]]*
  %scevgep41.2.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %651, i64 0, i64 1, i64 0
  %658 = bitcast i8* %scevgep41.2.3 to [41 x [41 x i8]]*
  %call16.2.4 = call zeroext i8 (...) @rand()
  store i8 %call16.2.4, i8* %scevgep28.2.3, align 1
  %659 = load i8, i8* %scevgep28.2.3, align 1
  %conv23.2.4 = zext i8 %659 to i32
  %660 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.4 = getelementptr i8, i8* %b, i64 7
  %661 = load i8, i8* %scevgep34.2.4, align 1
  %call28.2.4 = call zeroext i8 @mult(i8 zeroext %660, i8 zeroext %661)
  %conv29.2.4 = zext i8 %call28.2.4 to i32
  %xor.2.4 = xor i32 %conv23.2.4, %conv29.2.4
  %scevgep35.2.4 = getelementptr i8, i8* %a, i64 7
  %662 = load i8, i8* %scevgep35.2.4, align 1
  %663 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.4 = call zeroext i8 @mult(i8 zeroext %662, i8 zeroext %663)
  %conv35.2.4 = zext i8 %call34.2.4 to i32
  %xor36.2.4 = xor i32 %xor.2.4, %conv35.2.4
  %conv37.2.4 = trunc i32 %xor36.2.4 to i8
  store i8 %conv37.2.4, i8* %scevgep41.2.3, align 1
  %scevgep28.2.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %657, i64 0, i64 0, i64 1
  %664 = bitcast i8* %scevgep28.2.4 to [41 x [41 x i8]]*
  %scevgep41.2.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %658, i64 0, i64 1, i64 0
  %665 = bitcast i8* %scevgep41.2.4 to [41 x [41 x i8]]*
  %call16.2.5 = call zeroext i8 (...) @rand()
  store i8 %call16.2.5, i8* %scevgep28.2.4, align 1
  %666 = load i8, i8* %scevgep28.2.4, align 1
  %conv23.2.5 = zext i8 %666 to i32
  %667 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.5 = getelementptr i8, i8* %b, i64 8
  %668 = load i8, i8* %scevgep34.2.5, align 1
  %call28.2.5 = call zeroext i8 @mult(i8 zeroext %667, i8 zeroext %668)
  %conv29.2.5 = zext i8 %call28.2.5 to i32
  %xor.2.5 = xor i32 %conv23.2.5, %conv29.2.5
  %scevgep35.2.5 = getelementptr i8, i8* %a, i64 8
  %669 = load i8, i8* %scevgep35.2.5, align 1
  %670 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.5 = call zeroext i8 @mult(i8 zeroext %669, i8 zeroext %670)
  %conv35.2.5 = zext i8 %call34.2.5 to i32
  %xor36.2.5 = xor i32 %xor.2.5, %conv35.2.5
  %conv37.2.5 = trunc i32 %xor36.2.5 to i8
  store i8 %conv37.2.5, i8* %scevgep41.2.4, align 1
  %scevgep28.2.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %664, i64 0, i64 0, i64 1
  %671 = bitcast i8* %scevgep28.2.5 to [41 x [41 x i8]]*
  %scevgep41.2.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %665, i64 0, i64 1, i64 0
  %672 = bitcast i8* %scevgep41.2.5 to [41 x [41 x i8]]*
  %call16.2.6 = call zeroext i8 (...) @rand()
  store i8 %call16.2.6, i8* %scevgep28.2.5, align 1
  %673 = load i8, i8* %scevgep28.2.5, align 1
  %conv23.2.6 = zext i8 %673 to i32
  %674 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.6 = getelementptr i8, i8* %b, i64 9
  %675 = load i8, i8* %scevgep34.2.6, align 1
  %call28.2.6 = call zeroext i8 @mult(i8 zeroext %674, i8 zeroext %675)
  %conv29.2.6 = zext i8 %call28.2.6 to i32
  %xor.2.6 = xor i32 %conv23.2.6, %conv29.2.6
  %scevgep35.2.6 = getelementptr i8, i8* %a, i64 9
  %676 = load i8, i8* %scevgep35.2.6, align 1
  %677 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.6 = call zeroext i8 @mult(i8 zeroext %676, i8 zeroext %677)
  %conv35.2.6 = zext i8 %call34.2.6 to i32
  %xor36.2.6 = xor i32 %xor.2.6, %conv35.2.6
  %conv37.2.6 = trunc i32 %xor36.2.6 to i8
  store i8 %conv37.2.6, i8* %scevgep41.2.5, align 1
  %scevgep28.2.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %671, i64 0, i64 0, i64 1
  %678 = bitcast i8* %scevgep28.2.6 to [41 x [41 x i8]]*
  %scevgep41.2.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %672, i64 0, i64 1, i64 0
  %679 = bitcast i8* %scevgep41.2.6 to [41 x [41 x i8]]*
  %call16.2.7 = call zeroext i8 (...) @rand()
  store i8 %call16.2.7, i8* %scevgep28.2.6, align 1
  %680 = load i8, i8* %scevgep28.2.6, align 1
  %conv23.2.7 = zext i8 %680 to i32
  %681 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.7 = getelementptr i8, i8* %b, i64 10
  %682 = load i8, i8* %scevgep34.2.7, align 1
  %call28.2.7 = call zeroext i8 @mult(i8 zeroext %681, i8 zeroext %682)
  %conv29.2.7 = zext i8 %call28.2.7 to i32
  %xor.2.7 = xor i32 %conv23.2.7, %conv29.2.7
  %scevgep35.2.7 = getelementptr i8, i8* %a, i64 10
  %683 = load i8, i8* %scevgep35.2.7, align 1
  %684 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.7 = call zeroext i8 @mult(i8 zeroext %683, i8 zeroext %684)
  %conv35.2.7 = zext i8 %call34.2.7 to i32
  %xor36.2.7 = xor i32 %xor.2.7, %conv35.2.7
  %conv37.2.7 = trunc i32 %xor36.2.7 to i8
  store i8 %conv37.2.7, i8* %scevgep41.2.6, align 1
  %scevgep28.2.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %678, i64 0, i64 0, i64 1
  %685 = bitcast i8* %scevgep28.2.7 to [41 x [41 x i8]]*
  %scevgep41.2.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %679, i64 0, i64 1, i64 0
  %686 = bitcast i8* %scevgep41.2.7 to [41 x [41 x i8]]*
  %call16.2.8 = call zeroext i8 (...) @rand()
  store i8 %call16.2.8, i8* %scevgep28.2.7, align 1
  %687 = load i8, i8* %scevgep28.2.7, align 1
  %conv23.2.8 = zext i8 %687 to i32
  %688 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.8 = getelementptr i8, i8* %b, i64 11
  %689 = load i8, i8* %scevgep34.2.8, align 1
  %call28.2.8 = call zeroext i8 @mult(i8 zeroext %688, i8 zeroext %689)
  %conv29.2.8 = zext i8 %call28.2.8 to i32
  %xor.2.8 = xor i32 %conv23.2.8, %conv29.2.8
  %scevgep35.2.8 = getelementptr i8, i8* %a, i64 11
  %690 = load i8, i8* %scevgep35.2.8, align 1
  %691 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.8 = call zeroext i8 @mult(i8 zeroext %690, i8 zeroext %691)
  %conv35.2.8 = zext i8 %call34.2.8 to i32
  %xor36.2.8 = xor i32 %xor.2.8, %conv35.2.8
  %conv37.2.8 = trunc i32 %xor36.2.8 to i8
  store i8 %conv37.2.8, i8* %scevgep41.2.7, align 1
  %scevgep28.2.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %685, i64 0, i64 0, i64 1
  %692 = bitcast i8* %scevgep28.2.8 to [41 x [41 x i8]]*
  %scevgep41.2.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %686, i64 0, i64 1, i64 0
  %693 = bitcast i8* %scevgep41.2.8 to [41 x [41 x i8]]*
  %call16.2.9 = call zeroext i8 (...) @rand()
  store i8 %call16.2.9, i8* %scevgep28.2.8, align 1
  %694 = load i8, i8* %scevgep28.2.8, align 1
  %conv23.2.9 = zext i8 %694 to i32
  %695 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.9 = getelementptr i8, i8* %b, i64 12
  %696 = load i8, i8* %scevgep34.2.9, align 1
  %call28.2.9 = call zeroext i8 @mult(i8 zeroext %695, i8 zeroext %696)
  %conv29.2.9 = zext i8 %call28.2.9 to i32
  %xor.2.9 = xor i32 %conv23.2.9, %conv29.2.9
  %scevgep35.2.9 = getelementptr i8, i8* %a, i64 12
  %697 = load i8, i8* %scevgep35.2.9, align 1
  %698 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.9 = call zeroext i8 @mult(i8 zeroext %697, i8 zeroext %698)
  %conv35.2.9 = zext i8 %call34.2.9 to i32
  %xor36.2.9 = xor i32 %xor.2.9, %conv35.2.9
  %conv37.2.9 = trunc i32 %xor36.2.9 to i8
  store i8 %conv37.2.9, i8* %scevgep41.2.8, align 1
  %scevgep28.2.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %692, i64 0, i64 0, i64 1
  %699 = bitcast i8* %scevgep28.2.9 to [41 x [41 x i8]]*
  %scevgep41.2.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %693, i64 0, i64 1, i64 0
  %700 = bitcast i8* %scevgep41.2.9 to [41 x [41 x i8]]*
  %call16.2.10 = call zeroext i8 (...) @rand()
  store i8 %call16.2.10, i8* %scevgep28.2.9, align 1
  %701 = load i8, i8* %scevgep28.2.9, align 1
  %conv23.2.10 = zext i8 %701 to i32
  %702 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.10 = getelementptr i8, i8* %b, i64 13
  %703 = load i8, i8* %scevgep34.2.10, align 1
  %call28.2.10 = call zeroext i8 @mult(i8 zeroext %702, i8 zeroext %703)
  %conv29.2.10 = zext i8 %call28.2.10 to i32
  %xor.2.10 = xor i32 %conv23.2.10, %conv29.2.10
  %scevgep35.2.10 = getelementptr i8, i8* %a, i64 13
  %704 = load i8, i8* %scevgep35.2.10, align 1
  %705 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.10 = call zeroext i8 @mult(i8 zeroext %704, i8 zeroext %705)
  %conv35.2.10 = zext i8 %call34.2.10 to i32
  %xor36.2.10 = xor i32 %xor.2.10, %conv35.2.10
  %conv37.2.10 = trunc i32 %xor36.2.10 to i8
  store i8 %conv37.2.10, i8* %scevgep41.2.9, align 1
  %scevgep28.2.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %699, i64 0, i64 0, i64 1
  %706 = bitcast i8* %scevgep28.2.10 to [41 x [41 x i8]]*
  %scevgep41.2.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %700, i64 0, i64 1, i64 0
  %707 = bitcast i8* %scevgep41.2.10 to [41 x [41 x i8]]*
  %call16.2.11 = call zeroext i8 (...) @rand()
  store i8 %call16.2.11, i8* %scevgep28.2.10, align 1
  %708 = load i8, i8* %scevgep28.2.10, align 1
  %conv23.2.11 = zext i8 %708 to i32
  %709 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.11 = getelementptr i8, i8* %b, i64 14
  %710 = load i8, i8* %scevgep34.2.11, align 1
  %call28.2.11 = call zeroext i8 @mult(i8 zeroext %709, i8 zeroext %710)
  %conv29.2.11 = zext i8 %call28.2.11 to i32
  %xor.2.11 = xor i32 %conv23.2.11, %conv29.2.11
  %scevgep35.2.11 = getelementptr i8, i8* %a, i64 14
  %711 = load i8, i8* %scevgep35.2.11, align 1
  %712 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.11 = call zeroext i8 @mult(i8 zeroext %711, i8 zeroext %712)
  %conv35.2.11 = zext i8 %call34.2.11 to i32
  %xor36.2.11 = xor i32 %xor.2.11, %conv35.2.11
  %conv37.2.11 = trunc i32 %xor36.2.11 to i8
  store i8 %conv37.2.11, i8* %scevgep41.2.10, align 1
  %scevgep28.2.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %706, i64 0, i64 0, i64 1
  %713 = bitcast i8* %scevgep28.2.11 to [41 x [41 x i8]]*
  %scevgep41.2.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %707, i64 0, i64 1, i64 0
  %714 = bitcast i8* %scevgep41.2.11 to [41 x [41 x i8]]*
  %call16.2.12 = call zeroext i8 (...) @rand()
  store i8 %call16.2.12, i8* %scevgep28.2.11, align 1
  %715 = load i8, i8* %scevgep28.2.11, align 1
  %conv23.2.12 = zext i8 %715 to i32
  %716 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.12 = getelementptr i8, i8* %b, i64 15
  %717 = load i8, i8* %scevgep34.2.12, align 1
  %call28.2.12 = call zeroext i8 @mult(i8 zeroext %716, i8 zeroext %717)
  %conv29.2.12 = zext i8 %call28.2.12 to i32
  %xor.2.12 = xor i32 %conv23.2.12, %conv29.2.12
  %scevgep35.2.12 = getelementptr i8, i8* %a, i64 15
  %718 = load i8, i8* %scevgep35.2.12, align 1
  %719 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.12 = call zeroext i8 @mult(i8 zeroext %718, i8 zeroext %719)
  %conv35.2.12 = zext i8 %call34.2.12 to i32
  %xor36.2.12 = xor i32 %xor.2.12, %conv35.2.12
  %conv37.2.12 = trunc i32 %xor36.2.12 to i8
  store i8 %conv37.2.12, i8* %scevgep41.2.11, align 1
  %scevgep28.2.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %713, i64 0, i64 0, i64 1
  %720 = bitcast i8* %scevgep28.2.12 to [41 x [41 x i8]]*
  %scevgep41.2.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %714, i64 0, i64 1, i64 0
  %721 = bitcast i8* %scevgep41.2.12 to [41 x [41 x i8]]*
  %call16.2.13 = call zeroext i8 (...) @rand()
  store i8 %call16.2.13, i8* %scevgep28.2.12, align 1
  %722 = load i8, i8* %scevgep28.2.12, align 1
  %conv23.2.13 = zext i8 %722 to i32
  %723 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.13 = getelementptr i8, i8* %b, i64 16
  %724 = load i8, i8* %scevgep34.2.13, align 1
  %call28.2.13 = call zeroext i8 @mult(i8 zeroext %723, i8 zeroext %724)
  %conv29.2.13 = zext i8 %call28.2.13 to i32
  %xor.2.13 = xor i32 %conv23.2.13, %conv29.2.13
  %scevgep35.2.13 = getelementptr i8, i8* %a, i64 16
  %725 = load i8, i8* %scevgep35.2.13, align 1
  %726 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.13 = call zeroext i8 @mult(i8 zeroext %725, i8 zeroext %726)
  %conv35.2.13 = zext i8 %call34.2.13 to i32
  %xor36.2.13 = xor i32 %xor.2.13, %conv35.2.13
  %conv37.2.13 = trunc i32 %xor36.2.13 to i8
  store i8 %conv37.2.13, i8* %scevgep41.2.12, align 1
  %scevgep28.2.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %720, i64 0, i64 0, i64 1
  %727 = bitcast i8* %scevgep28.2.13 to [41 x [41 x i8]]*
  %scevgep41.2.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %721, i64 0, i64 1, i64 0
  %728 = bitcast i8* %scevgep41.2.13 to [41 x [41 x i8]]*
  %call16.2.14 = call zeroext i8 (...) @rand()
  store i8 %call16.2.14, i8* %scevgep28.2.13, align 1
  %729 = load i8, i8* %scevgep28.2.13, align 1
  %conv23.2.14 = zext i8 %729 to i32
  %730 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.14 = getelementptr i8, i8* %b, i64 17
  %731 = load i8, i8* %scevgep34.2.14, align 1
  %call28.2.14 = call zeroext i8 @mult(i8 zeroext %730, i8 zeroext %731)
  %conv29.2.14 = zext i8 %call28.2.14 to i32
  %xor.2.14 = xor i32 %conv23.2.14, %conv29.2.14
  %scevgep35.2.14 = getelementptr i8, i8* %a, i64 17
  %732 = load i8, i8* %scevgep35.2.14, align 1
  %733 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.14 = call zeroext i8 @mult(i8 zeroext %732, i8 zeroext %733)
  %conv35.2.14 = zext i8 %call34.2.14 to i32
  %xor36.2.14 = xor i32 %xor.2.14, %conv35.2.14
  %conv37.2.14 = trunc i32 %xor36.2.14 to i8
  store i8 %conv37.2.14, i8* %scevgep41.2.13, align 1
  %scevgep28.2.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %727, i64 0, i64 0, i64 1
  %734 = bitcast i8* %scevgep28.2.14 to [41 x [41 x i8]]*
  %scevgep41.2.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %728, i64 0, i64 1, i64 0
  %735 = bitcast i8* %scevgep41.2.14 to [41 x [41 x i8]]*
  %call16.2.15 = call zeroext i8 (...) @rand()
  store i8 %call16.2.15, i8* %scevgep28.2.14, align 1
  %736 = load i8, i8* %scevgep28.2.14, align 1
  %conv23.2.15 = zext i8 %736 to i32
  %737 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.15 = getelementptr i8, i8* %b, i64 18
  %738 = load i8, i8* %scevgep34.2.15, align 1
  %call28.2.15 = call zeroext i8 @mult(i8 zeroext %737, i8 zeroext %738)
  %conv29.2.15 = zext i8 %call28.2.15 to i32
  %xor.2.15 = xor i32 %conv23.2.15, %conv29.2.15
  %scevgep35.2.15 = getelementptr i8, i8* %a, i64 18
  %739 = load i8, i8* %scevgep35.2.15, align 1
  %740 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.15 = call zeroext i8 @mult(i8 zeroext %739, i8 zeroext %740)
  %conv35.2.15 = zext i8 %call34.2.15 to i32
  %xor36.2.15 = xor i32 %xor.2.15, %conv35.2.15
  %conv37.2.15 = trunc i32 %xor36.2.15 to i8
  store i8 %conv37.2.15, i8* %scevgep41.2.14, align 1
  %scevgep28.2.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %734, i64 0, i64 0, i64 1
  %741 = bitcast i8* %scevgep28.2.15 to [41 x [41 x i8]]*
  %scevgep41.2.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %735, i64 0, i64 1, i64 0
  %742 = bitcast i8* %scevgep41.2.15 to [41 x [41 x i8]]*
  %call16.2.16 = call zeroext i8 (...) @rand()
  store i8 %call16.2.16, i8* %scevgep28.2.15, align 1
  %743 = load i8, i8* %scevgep28.2.15, align 1
  %conv23.2.16 = zext i8 %743 to i32
  %744 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.16 = getelementptr i8, i8* %b, i64 19
  %745 = load i8, i8* %scevgep34.2.16, align 1
  %call28.2.16 = call zeroext i8 @mult(i8 zeroext %744, i8 zeroext %745)
  %conv29.2.16 = zext i8 %call28.2.16 to i32
  %xor.2.16 = xor i32 %conv23.2.16, %conv29.2.16
  %scevgep35.2.16 = getelementptr i8, i8* %a, i64 19
  %746 = load i8, i8* %scevgep35.2.16, align 1
  %747 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.16 = call zeroext i8 @mult(i8 zeroext %746, i8 zeroext %747)
  %conv35.2.16 = zext i8 %call34.2.16 to i32
  %xor36.2.16 = xor i32 %xor.2.16, %conv35.2.16
  %conv37.2.16 = trunc i32 %xor36.2.16 to i8
  store i8 %conv37.2.16, i8* %scevgep41.2.15, align 1
  %scevgep28.2.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %741, i64 0, i64 0, i64 1
  %748 = bitcast i8* %scevgep28.2.16 to [41 x [41 x i8]]*
  %scevgep41.2.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %742, i64 0, i64 1, i64 0
  %749 = bitcast i8* %scevgep41.2.16 to [41 x [41 x i8]]*
  %call16.2.17 = call zeroext i8 (...) @rand()
  store i8 %call16.2.17, i8* %scevgep28.2.16, align 1
  %750 = load i8, i8* %scevgep28.2.16, align 1
  %conv23.2.17 = zext i8 %750 to i32
  %751 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.17 = getelementptr i8, i8* %b, i64 20
  %752 = load i8, i8* %scevgep34.2.17, align 1
  %call28.2.17 = call zeroext i8 @mult(i8 zeroext %751, i8 zeroext %752)
  %conv29.2.17 = zext i8 %call28.2.17 to i32
  %xor.2.17 = xor i32 %conv23.2.17, %conv29.2.17
  %scevgep35.2.17 = getelementptr i8, i8* %a, i64 20
  %753 = load i8, i8* %scevgep35.2.17, align 1
  %754 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.17 = call zeroext i8 @mult(i8 zeroext %753, i8 zeroext %754)
  %conv35.2.17 = zext i8 %call34.2.17 to i32
  %xor36.2.17 = xor i32 %xor.2.17, %conv35.2.17
  %conv37.2.17 = trunc i32 %xor36.2.17 to i8
  store i8 %conv37.2.17, i8* %scevgep41.2.16, align 1
  %scevgep28.2.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %748, i64 0, i64 0, i64 1
  %755 = bitcast i8* %scevgep28.2.17 to [41 x [41 x i8]]*
  %scevgep41.2.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %749, i64 0, i64 1, i64 0
  %756 = bitcast i8* %scevgep41.2.17 to [41 x [41 x i8]]*
  %call16.2.18 = call zeroext i8 (...) @rand()
  store i8 %call16.2.18, i8* %scevgep28.2.17, align 1
  %757 = load i8, i8* %scevgep28.2.17, align 1
  %conv23.2.18 = zext i8 %757 to i32
  %758 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.18 = getelementptr i8, i8* %b, i64 21
  %759 = load i8, i8* %scevgep34.2.18, align 1
  %call28.2.18 = call zeroext i8 @mult(i8 zeroext %758, i8 zeroext %759)
  %conv29.2.18 = zext i8 %call28.2.18 to i32
  %xor.2.18 = xor i32 %conv23.2.18, %conv29.2.18
  %scevgep35.2.18 = getelementptr i8, i8* %a, i64 21
  %760 = load i8, i8* %scevgep35.2.18, align 1
  %761 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.18 = call zeroext i8 @mult(i8 zeroext %760, i8 zeroext %761)
  %conv35.2.18 = zext i8 %call34.2.18 to i32
  %xor36.2.18 = xor i32 %xor.2.18, %conv35.2.18
  %conv37.2.18 = trunc i32 %xor36.2.18 to i8
  store i8 %conv37.2.18, i8* %scevgep41.2.17, align 1
  %scevgep28.2.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %755, i64 0, i64 0, i64 1
  %762 = bitcast i8* %scevgep28.2.18 to [41 x [41 x i8]]*
  %scevgep41.2.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %756, i64 0, i64 1, i64 0
  %763 = bitcast i8* %scevgep41.2.18 to [41 x [41 x i8]]*
  %call16.2.19 = call zeroext i8 (...) @rand()
  store i8 %call16.2.19, i8* %scevgep28.2.18, align 1
  %764 = load i8, i8* %scevgep28.2.18, align 1
  %conv23.2.19 = zext i8 %764 to i32
  %765 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.19 = getelementptr i8, i8* %b, i64 22
  %766 = load i8, i8* %scevgep34.2.19, align 1
  %call28.2.19 = call zeroext i8 @mult(i8 zeroext %765, i8 zeroext %766)
  %conv29.2.19 = zext i8 %call28.2.19 to i32
  %xor.2.19 = xor i32 %conv23.2.19, %conv29.2.19
  %scevgep35.2.19 = getelementptr i8, i8* %a, i64 22
  %767 = load i8, i8* %scevgep35.2.19, align 1
  %768 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.19 = call zeroext i8 @mult(i8 zeroext %767, i8 zeroext %768)
  %conv35.2.19 = zext i8 %call34.2.19 to i32
  %xor36.2.19 = xor i32 %xor.2.19, %conv35.2.19
  %conv37.2.19 = trunc i32 %xor36.2.19 to i8
  store i8 %conv37.2.19, i8* %scevgep41.2.18, align 1
  %scevgep28.2.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %762, i64 0, i64 0, i64 1
  %769 = bitcast i8* %scevgep28.2.19 to [41 x [41 x i8]]*
  %scevgep41.2.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %763, i64 0, i64 1, i64 0
  %770 = bitcast i8* %scevgep41.2.19 to [41 x [41 x i8]]*
  %call16.2.20 = call zeroext i8 (...) @rand()
  store i8 %call16.2.20, i8* %scevgep28.2.19, align 1
  %771 = load i8, i8* %scevgep28.2.19, align 1
  %conv23.2.20 = zext i8 %771 to i32
  %772 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.20 = getelementptr i8, i8* %b, i64 23
  %773 = load i8, i8* %scevgep34.2.20, align 1
  %call28.2.20 = call zeroext i8 @mult(i8 zeroext %772, i8 zeroext %773)
  %conv29.2.20 = zext i8 %call28.2.20 to i32
  %xor.2.20 = xor i32 %conv23.2.20, %conv29.2.20
  %scevgep35.2.20 = getelementptr i8, i8* %a, i64 23
  %774 = load i8, i8* %scevgep35.2.20, align 1
  %775 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.20 = call zeroext i8 @mult(i8 zeroext %774, i8 zeroext %775)
  %conv35.2.20 = zext i8 %call34.2.20 to i32
  %xor36.2.20 = xor i32 %xor.2.20, %conv35.2.20
  %conv37.2.20 = trunc i32 %xor36.2.20 to i8
  store i8 %conv37.2.20, i8* %scevgep41.2.19, align 1
  %scevgep28.2.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %769, i64 0, i64 0, i64 1
  %776 = bitcast i8* %scevgep28.2.20 to [41 x [41 x i8]]*
  %scevgep41.2.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %770, i64 0, i64 1, i64 0
  %777 = bitcast i8* %scevgep41.2.20 to [41 x [41 x i8]]*
  %call16.2.21 = call zeroext i8 (...) @rand()
  store i8 %call16.2.21, i8* %scevgep28.2.20, align 1
  %778 = load i8, i8* %scevgep28.2.20, align 1
  %conv23.2.21 = zext i8 %778 to i32
  %779 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.21 = getelementptr i8, i8* %b, i64 24
  %780 = load i8, i8* %scevgep34.2.21, align 1
  %call28.2.21 = call zeroext i8 @mult(i8 zeroext %779, i8 zeroext %780)
  %conv29.2.21 = zext i8 %call28.2.21 to i32
  %xor.2.21 = xor i32 %conv23.2.21, %conv29.2.21
  %scevgep35.2.21 = getelementptr i8, i8* %a, i64 24
  %781 = load i8, i8* %scevgep35.2.21, align 1
  %782 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.21 = call zeroext i8 @mult(i8 zeroext %781, i8 zeroext %782)
  %conv35.2.21 = zext i8 %call34.2.21 to i32
  %xor36.2.21 = xor i32 %xor.2.21, %conv35.2.21
  %conv37.2.21 = trunc i32 %xor36.2.21 to i8
  store i8 %conv37.2.21, i8* %scevgep41.2.20, align 1
  %scevgep28.2.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %776, i64 0, i64 0, i64 1
  %783 = bitcast i8* %scevgep28.2.21 to [41 x [41 x i8]]*
  %scevgep41.2.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %777, i64 0, i64 1, i64 0
  %784 = bitcast i8* %scevgep41.2.21 to [41 x [41 x i8]]*
  %call16.2.22 = call zeroext i8 (...) @rand()
  store i8 %call16.2.22, i8* %scevgep28.2.21, align 1
  %785 = load i8, i8* %scevgep28.2.21, align 1
  %conv23.2.22 = zext i8 %785 to i32
  %786 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.22 = getelementptr i8, i8* %b, i64 25
  %787 = load i8, i8* %scevgep34.2.22, align 1
  %call28.2.22 = call zeroext i8 @mult(i8 zeroext %786, i8 zeroext %787)
  %conv29.2.22 = zext i8 %call28.2.22 to i32
  %xor.2.22 = xor i32 %conv23.2.22, %conv29.2.22
  %scevgep35.2.22 = getelementptr i8, i8* %a, i64 25
  %788 = load i8, i8* %scevgep35.2.22, align 1
  %789 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.22 = call zeroext i8 @mult(i8 zeroext %788, i8 zeroext %789)
  %conv35.2.22 = zext i8 %call34.2.22 to i32
  %xor36.2.22 = xor i32 %xor.2.22, %conv35.2.22
  %conv37.2.22 = trunc i32 %xor36.2.22 to i8
  store i8 %conv37.2.22, i8* %scevgep41.2.21, align 1
  %scevgep28.2.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %783, i64 0, i64 0, i64 1
  %790 = bitcast i8* %scevgep28.2.22 to [41 x [41 x i8]]*
  %scevgep41.2.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %784, i64 0, i64 1, i64 0
  %791 = bitcast i8* %scevgep41.2.22 to [41 x [41 x i8]]*
  %call16.2.23 = call zeroext i8 (...) @rand()
  store i8 %call16.2.23, i8* %scevgep28.2.22, align 1
  %792 = load i8, i8* %scevgep28.2.22, align 1
  %conv23.2.23 = zext i8 %792 to i32
  %793 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.23 = getelementptr i8, i8* %b, i64 26
  %794 = load i8, i8* %scevgep34.2.23, align 1
  %call28.2.23 = call zeroext i8 @mult(i8 zeroext %793, i8 zeroext %794)
  %conv29.2.23 = zext i8 %call28.2.23 to i32
  %xor.2.23 = xor i32 %conv23.2.23, %conv29.2.23
  %scevgep35.2.23 = getelementptr i8, i8* %a, i64 26
  %795 = load i8, i8* %scevgep35.2.23, align 1
  %796 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.23 = call zeroext i8 @mult(i8 zeroext %795, i8 zeroext %796)
  %conv35.2.23 = zext i8 %call34.2.23 to i32
  %xor36.2.23 = xor i32 %xor.2.23, %conv35.2.23
  %conv37.2.23 = trunc i32 %xor36.2.23 to i8
  store i8 %conv37.2.23, i8* %scevgep41.2.22, align 1
  %scevgep28.2.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %790, i64 0, i64 0, i64 1
  %797 = bitcast i8* %scevgep28.2.23 to [41 x [41 x i8]]*
  %scevgep41.2.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %791, i64 0, i64 1, i64 0
  %798 = bitcast i8* %scevgep41.2.23 to [41 x [41 x i8]]*
  %call16.2.24 = call zeroext i8 (...) @rand()
  store i8 %call16.2.24, i8* %scevgep28.2.23, align 1
  %799 = load i8, i8* %scevgep28.2.23, align 1
  %conv23.2.24 = zext i8 %799 to i32
  %800 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.24 = getelementptr i8, i8* %b, i64 27
  %801 = load i8, i8* %scevgep34.2.24, align 1
  %call28.2.24 = call zeroext i8 @mult(i8 zeroext %800, i8 zeroext %801)
  %conv29.2.24 = zext i8 %call28.2.24 to i32
  %xor.2.24 = xor i32 %conv23.2.24, %conv29.2.24
  %scevgep35.2.24 = getelementptr i8, i8* %a, i64 27
  %802 = load i8, i8* %scevgep35.2.24, align 1
  %803 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.24 = call zeroext i8 @mult(i8 zeroext %802, i8 zeroext %803)
  %conv35.2.24 = zext i8 %call34.2.24 to i32
  %xor36.2.24 = xor i32 %xor.2.24, %conv35.2.24
  %conv37.2.24 = trunc i32 %xor36.2.24 to i8
  store i8 %conv37.2.24, i8* %scevgep41.2.23, align 1
  %scevgep28.2.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %797, i64 0, i64 0, i64 1
  %804 = bitcast i8* %scevgep28.2.24 to [41 x [41 x i8]]*
  %scevgep41.2.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %798, i64 0, i64 1, i64 0
  %805 = bitcast i8* %scevgep41.2.24 to [41 x [41 x i8]]*
  %call16.2.25 = call zeroext i8 (...) @rand()
  store i8 %call16.2.25, i8* %scevgep28.2.24, align 1
  %806 = load i8, i8* %scevgep28.2.24, align 1
  %conv23.2.25 = zext i8 %806 to i32
  %807 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.25 = getelementptr i8, i8* %b, i64 28
  %808 = load i8, i8* %scevgep34.2.25, align 1
  %call28.2.25 = call zeroext i8 @mult(i8 zeroext %807, i8 zeroext %808)
  %conv29.2.25 = zext i8 %call28.2.25 to i32
  %xor.2.25 = xor i32 %conv23.2.25, %conv29.2.25
  %scevgep35.2.25 = getelementptr i8, i8* %a, i64 28
  %809 = load i8, i8* %scevgep35.2.25, align 1
  %810 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.25 = call zeroext i8 @mult(i8 zeroext %809, i8 zeroext %810)
  %conv35.2.25 = zext i8 %call34.2.25 to i32
  %xor36.2.25 = xor i32 %xor.2.25, %conv35.2.25
  %conv37.2.25 = trunc i32 %xor36.2.25 to i8
  store i8 %conv37.2.25, i8* %scevgep41.2.24, align 1
  %scevgep28.2.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %804, i64 0, i64 0, i64 1
  %811 = bitcast i8* %scevgep28.2.25 to [41 x [41 x i8]]*
  %scevgep41.2.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %805, i64 0, i64 1, i64 0
  %812 = bitcast i8* %scevgep41.2.25 to [41 x [41 x i8]]*
  %call16.2.26 = call zeroext i8 (...) @rand()
  store i8 %call16.2.26, i8* %scevgep28.2.25, align 1
  %813 = load i8, i8* %scevgep28.2.25, align 1
  %conv23.2.26 = zext i8 %813 to i32
  %814 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.26 = getelementptr i8, i8* %b, i64 29
  %815 = load i8, i8* %scevgep34.2.26, align 1
  %call28.2.26 = call zeroext i8 @mult(i8 zeroext %814, i8 zeroext %815)
  %conv29.2.26 = zext i8 %call28.2.26 to i32
  %xor.2.26 = xor i32 %conv23.2.26, %conv29.2.26
  %scevgep35.2.26 = getelementptr i8, i8* %a, i64 29
  %816 = load i8, i8* %scevgep35.2.26, align 1
  %817 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.26 = call zeroext i8 @mult(i8 zeroext %816, i8 zeroext %817)
  %conv35.2.26 = zext i8 %call34.2.26 to i32
  %xor36.2.26 = xor i32 %xor.2.26, %conv35.2.26
  %conv37.2.26 = trunc i32 %xor36.2.26 to i8
  store i8 %conv37.2.26, i8* %scevgep41.2.25, align 1
  %scevgep28.2.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %811, i64 0, i64 0, i64 1
  %818 = bitcast i8* %scevgep28.2.26 to [41 x [41 x i8]]*
  %scevgep41.2.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %812, i64 0, i64 1, i64 0
  %819 = bitcast i8* %scevgep41.2.26 to [41 x [41 x i8]]*
  %call16.2.27 = call zeroext i8 (...) @rand()
  store i8 %call16.2.27, i8* %scevgep28.2.26, align 1
  %820 = load i8, i8* %scevgep28.2.26, align 1
  %conv23.2.27 = zext i8 %820 to i32
  %821 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.27 = getelementptr i8, i8* %b, i64 30
  %822 = load i8, i8* %scevgep34.2.27, align 1
  %call28.2.27 = call zeroext i8 @mult(i8 zeroext %821, i8 zeroext %822)
  %conv29.2.27 = zext i8 %call28.2.27 to i32
  %xor.2.27 = xor i32 %conv23.2.27, %conv29.2.27
  %scevgep35.2.27 = getelementptr i8, i8* %a, i64 30
  %823 = load i8, i8* %scevgep35.2.27, align 1
  %824 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.27 = call zeroext i8 @mult(i8 zeroext %823, i8 zeroext %824)
  %conv35.2.27 = zext i8 %call34.2.27 to i32
  %xor36.2.27 = xor i32 %xor.2.27, %conv35.2.27
  %conv37.2.27 = trunc i32 %xor36.2.27 to i8
  store i8 %conv37.2.27, i8* %scevgep41.2.26, align 1
  %scevgep28.2.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %818, i64 0, i64 0, i64 1
  %825 = bitcast i8* %scevgep28.2.27 to [41 x [41 x i8]]*
  %scevgep41.2.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %819, i64 0, i64 1, i64 0
  %826 = bitcast i8* %scevgep41.2.27 to [41 x [41 x i8]]*
  %call16.2.28 = call zeroext i8 (...) @rand()
  store i8 %call16.2.28, i8* %scevgep28.2.27, align 1
  %827 = load i8, i8* %scevgep28.2.27, align 1
  %conv23.2.28 = zext i8 %827 to i32
  %828 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.28 = getelementptr i8, i8* %b, i64 31
  %829 = load i8, i8* %scevgep34.2.28, align 1
  %call28.2.28 = call zeroext i8 @mult(i8 zeroext %828, i8 zeroext %829)
  %conv29.2.28 = zext i8 %call28.2.28 to i32
  %xor.2.28 = xor i32 %conv23.2.28, %conv29.2.28
  %scevgep35.2.28 = getelementptr i8, i8* %a, i64 31
  %830 = load i8, i8* %scevgep35.2.28, align 1
  %831 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.28 = call zeroext i8 @mult(i8 zeroext %830, i8 zeroext %831)
  %conv35.2.28 = zext i8 %call34.2.28 to i32
  %xor36.2.28 = xor i32 %xor.2.28, %conv35.2.28
  %conv37.2.28 = trunc i32 %xor36.2.28 to i8
  store i8 %conv37.2.28, i8* %scevgep41.2.27, align 1
  %scevgep28.2.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %825, i64 0, i64 0, i64 1
  %832 = bitcast i8* %scevgep28.2.28 to [41 x [41 x i8]]*
  %scevgep41.2.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %826, i64 0, i64 1, i64 0
  %833 = bitcast i8* %scevgep41.2.28 to [41 x [41 x i8]]*
  %call16.2.29 = call zeroext i8 (...) @rand()
  store i8 %call16.2.29, i8* %scevgep28.2.28, align 1
  %834 = load i8, i8* %scevgep28.2.28, align 1
  %conv23.2.29 = zext i8 %834 to i32
  %835 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.29 = getelementptr i8, i8* %b, i64 32
  %836 = load i8, i8* %scevgep34.2.29, align 1
  %call28.2.29 = call zeroext i8 @mult(i8 zeroext %835, i8 zeroext %836)
  %conv29.2.29 = zext i8 %call28.2.29 to i32
  %xor.2.29 = xor i32 %conv23.2.29, %conv29.2.29
  %scevgep35.2.29 = getelementptr i8, i8* %a, i64 32
  %837 = load i8, i8* %scevgep35.2.29, align 1
  %838 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.29 = call zeroext i8 @mult(i8 zeroext %837, i8 zeroext %838)
  %conv35.2.29 = zext i8 %call34.2.29 to i32
  %xor36.2.29 = xor i32 %xor.2.29, %conv35.2.29
  %conv37.2.29 = trunc i32 %xor36.2.29 to i8
  store i8 %conv37.2.29, i8* %scevgep41.2.28, align 1
  %scevgep28.2.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %832, i64 0, i64 0, i64 1
  %839 = bitcast i8* %scevgep28.2.29 to [41 x [41 x i8]]*
  %scevgep41.2.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %833, i64 0, i64 1, i64 0
  %840 = bitcast i8* %scevgep41.2.29 to [41 x [41 x i8]]*
  %call16.2.30 = call zeroext i8 (...) @rand()
  store i8 %call16.2.30, i8* %scevgep28.2.29, align 1
  %841 = load i8, i8* %scevgep28.2.29, align 1
  %conv23.2.30 = zext i8 %841 to i32
  %842 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.30 = getelementptr i8, i8* %b, i64 33
  %843 = load i8, i8* %scevgep34.2.30, align 1
  %call28.2.30 = call zeroext i8 @mult(i8 zeroext %842, i8 zeroext %843)
  %conv29.2.30 = zext i8 %call28.2.30 to i32
  %xor.2.30 = xor i32 %conv23.2.30, %conv29.2.30
  %scevgep35.2.30 = getelementptr i8, i8* %a, i64 33
  %844 = load i8, i8* %scevgep35.2.30, align 1
  %845 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.30 = call zeroext i8 @mult(i8 zeroext %844, i8 zeroext %845)
  %conv35.2.30 = zext i8 %call34.2.30 to i32
  %xor36.2.30 = xor i32 %xor.2.30, %conv35.2.30
  %conv37.2.30 = trunc i32 %xor36.2.30 to i8
  store i8 %conv37.2.30, i8* %scevgep41.2.29, align 1
  %scevgep28.2.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %839, i64 0, i64 0, i64 1
  %846 = bitcast i8* %scevgep28.2.30 to [41 x [41 x i8]]*
  %scevgep41.2.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %840, i64 0, i64 1, i64 0
  %847 = bitcast i8* %scevgep41.2.30 to [41 x [41 x i8]]*
  %call16.2.31 = call zeroext i8 (...) @rand()
  store i8 %call16.2.31, i8* %scevgep28.2.30, align 1
  %848 = load i8, i8* %scevgep28.2.30, align 1
  %conv23.2.31 = zext i8 %848 to i32
  %849 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.31 = getelementptr i8, i8* %b, i64 34
  %850 = load i8, i8* %scevgep34.2.31, align 1
  %call28.2.31 = call zeroext i8 @mult(i8 zeroext %849, i8 zeroext %850)
  %conv29.2.31 = zext i8 %call28.2.31 to i32
  %xor.2.31 = xor i32 %conv23.2.31, %conv29.2.31
  %scevgep35.2.31 = getelementptr i8, i8* %a, i64 34
  %851 = load i8, i8* %scevgep35.2.31, align 1
  %852 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.31 = call zeroext i8 @mult(i8 zeroext %851, i8 zeroext %852)
  %conv35.2.31 = zext i8 %call34.2.31 to i32
  %xor36.2.31 = xor i32 %xor.2.31, %conv35.2.31
  %conv37.2.31 = trunc i32 %xor36.2.31 to i8
  store i8 %conv37.2.31, i8* %scevgep41.2.30, align 1
  %scevgep28.2.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %846, i64 0, i64 0, i64 1
  %853 = bitcast i8* %scevgep28.2.31 to [41 x [41 x i8]]*
  %scevgep41.2.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %847, i64 0, i64 1, i64 0
  %854 = bitcast i8* %scevgep41.2.31 to [41 x [41 x i8]]*
  %call16.2.32 = call zeroext i8 (...) @rand()
  store i8 %call16.2.32, i8* %scevgep28.2.31, align 1
  %855 = load i8, i8* %scevgep28.2.31, align 1
  %conv23.2.32 = zext i8 %855 to i32
  %856 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.32 = getelementptr i8, i8* %b, i64 35
  %857 = load i8, i8* %scevgep34.2.32, align 1
  %call28.2.32 = call zeroext i8 @mult(i8 zeroext %856, i8 zeroext %857)
  %conv29.2.32 = zext i8 %call28.2.32 to i32
  %xor.2.32 = xor i32 %conv23.2.32, %conv29.2.32
  %scevgep35.2.32 = getelementptr i8, i8* %a, i64 35
  %858 = load i8, i8* %scevgep35.2.32, align 1
  %859 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.32 = call zeroext i8 @mult(i8 zeroext %858, i8 zeroext %859)
  %conv35.2.32 = zext i8 %call34.2.32 to i32
  %xor36.2.32 = xor i32 %xor.2.32, %conv35.2.32
  %conv37.2.32 = trunc i32 %xor36.2.32 to i8
  store i8 %conv37.2.32, i8* %scevgep41.2.31, align 1
  %scevgep28.2.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %853, i64 0, i64 0, i64 1
  %860 = bitcast i8* %scevgep28.2.32 to [41 x [41 x i8]]*
  %scevgep41.2.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %854, i64 0, i64 1, i64 0
  %861 = bitcast i8* %scevgep41.2.32 to [41 x [41 x i8]]*
  %call16.2.33 = call zeroext i8 (...) @rand()
  store i8 %call16.2.33, i8* %scevgep28.2.32, align 1
  %862 = load i8, i8* %scevgep28.2.32, align 1
  %conv23.2.33 = zext i8 %862 to i32
  %863 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.33 = getelementptr i8, i8* %b, i64 36
  %864 = load i8, i8* %scevgep34.2.33, align 1
  %call28.2.33 = call zeroext i8 @mult(i8 zeroext %863, i8 zeroext %864)
  %conv29.2.33 = zext i8 %call28.2.33 to i32
  %xor.2.33 = xor i32 %conv23.2.33, %conv29.2.33
  %scevgep35.2.33 = getelementptr i8, i8* %a, i64 36
  %865 = load i8, i8* %scevgep35.2.33, align 1
  %866 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.33 = call zeroext i8 @mult(i8 zeroext %865, i8 zeroext %866)
  %conv35.2.33 = zext i8 %call34.2.33 to i32
  %xor36.2.33 = xor i32 %xor.2.33, %conv35.2.33
  %conv37.2.33 = trunc i32 %xor36.2.33 to i8
  store i8 %conv37.2.33, i8* %scevgep41.2.32, align 1
  %scevgep28.2.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %860, i64 0, i64 0, i64 1
  %867 = bitcast i8* %scevgep28.2.33 to [41 x [41 x i8]]*
  %scevgep41.2.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %861, i64 0, i64 1, i64 0
  %868 = bitcast i8* %scevgep41.2.33 to [41 x [41 x i8]]*
  %call16.2.34 = call zeroext i8 (...) @rand()
  store i8 %call16.2.34, i8* %scevgep28.2.33, align 1
  %869 = load i8, i8* %scevgep28.2.33, align 1
  %conv23.2.34 = zext i8 %869 to i32
  %870 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.34 = getelementptr i8, i8* %b, i64 37
  %871 = load i8, i8* %scevgep34.2.34, align 1
  %call28.2.34 = call zeroext i8 @mult(i8 zeroext %870, i8 zeroext %871)
  %conv29.2.34 = zext i8 %call28.2.34 to i32
  %xor.2.34 = xor i32 %conv23.2.34, %conv29.2.34
  %scevgep35.2.34 = getelementptr i8, i8* %a, i64 37
  %872 = load i8, i8* %scevgep35.2.34, align 1
  %873 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.34 = call zeroext i8 @mult(i8 zeroext %872, i8 zeroext %873)
  %conv35.2.34 = zext i8 %call34.2.34 to i32
  %xor36.2.34 = xor i32 %xor.2.34, %conv35.2.34
  %conv37.2.34 = trunc i32 %xor36.2.34 to i8
  store i8 %conv37.2.34, i8* %scevgep41.2.33, align 1
  %scevgep28.2.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %867, i64 0, i64 0, i64 1
  %874 = bitcast i8* %scevgep28.2.34 to [41 x [41 x i8]]*
  %scevgep41.2.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %868, i64 0, i64 1, i64 0
  %875 = bitcast i8* %scevgep41.2.34 to [41 x [41 x i8]]*
  %call16.2.35 = call zeroext i8 (...) @rand()
  store i8 %call16.2.35, i8* %scevgep28.2.34, align 1
  %876 = load i8, i8* %scevgep28.2.34, align 1
  %conv23.2.35 = zext i8 %876 to i32
  %877 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.35 = getelementptr i8, i8* %b, i64 38
  %878 = load i8, i8* %scevgep34.2.35, align 1
  %call28.2.35 = call zeroext i8 @mult(i8 zeroext %877, i8 zeroext %878)
  %conv29.2.35 = zext i8 %call28.2.35 to i32
  %xor.2.35 = xor i32 %conv23.2.35, %conv29.2.35
  %scevgep35.2.35 = getelementptr i8, i8* %a, i64 38
  %879 = load i8, i8* %scevgep35.2.35, align 1
  %880 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.35 = call zeroext i8 @mult(i8 zeroext %879, i8 zeroext %880)
  %conv35.2.35 = zext i8 %call34.2.35 to i32
  %xor36.2.35 = xor i32 %xor.2.35, %conv35.2.35
  %conv37.2.35 = trunc i32 %xor36.2.35 to i8
  store i8 %conv37.2.35, i8* %scevgep41.2.34, align 1
  %scevgep28.2.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %874, i64 0, i64 0, i64 1
  %881 = bitcast i8* %scevgep28.2.35 to [41 x [41 x i8]]*
  %scevgep41.2.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %875, i64 0, i64 1, i64 0
  %882 = bitcast i8* %scevgep41.2.35 to [41 x [41 x i8]]*
  %call16.2.36 = call zeroext i8 (...) @rand()
  store i8 %call16.2.36, i8* %scevgep28.2.35, align 1
  %883 = load i8, i8* %scevgep28.2.35, align 1
  %conv23.2.36 = zext i8 %883 to i32
  %884 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.36 = getelementptr i8, i8* %b, i64 39
  %885 = load i8, i8* %scevgep34.2.36, align 1
  %call28.2.36 = call zeroext i8 @mult(i8 zeroext %884, i8 zeroext %885)
  %conv29.2.36 = zext i8 %call28.2.36 to i32
  %xor.2.36 = xor i32 %conv23.2.36, %conv29.2.36
  %scevgep35.2.36 = getelementptr i8, i8* %a, i64 39
  %886 = load i8, i8* %scevgep35.2.36, align 1
  %887 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.36 = call zeroext i8 @mult(i8 zeroext %886, i8 zeroext %887)
  %conv35.2.36 = zext i8 %call34.2.36 to i32
  %xor36.2.36 = xor i32 %xor.2.36, %conv35.2.36
  %conv37.2.36 = trunc i32 %xor36.2.36 to i8
  store i8 %conv37.2.36, i8* %scevgep41.2.35, align 1
  %scevgep28.2.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %881, i64 0, i64 0, i64 1
  %scevgep41.2.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %882, i64 0, i64 1, i64 0
  %call16.2.37 = call zeroext i8 (...) @rand()
  store i8 %call16.2.37, i8* %scevgep28.2.36, align 1
  %888 = load i8, i8* %scevgep28.2.36, align 1
  %conv23.2.37 = zext i8 %888 to i32
  %889 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.37 = getelementptr i8, i8* %b, i64 40
  %890 = load i8, i8* %scevgep34.2.37, align 1
  %call28.2.37 = call zeroext i8 @mult(i8 zeroext %889, i8 zeroext %890)
  %conv29.2.37 = zext i8 %call28.2.37 to i32
  %xor.2.37 = xor i32 %conv23.2.37, %conv29.2.37
  %scevgep35.2.37 = getelementptr i8, i8* %a, i64 40
  %891 = load i8, i8* %scevgep35.2.37, align 1
  %892 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.37 = call zeroext i8 @mult(i8 zeroext %891, i8 zeroext %892)
  %conv35.2.37 = zext i8 %call34.2.37 to i32
  %xor36.2.37 = xor i32 %xor.2.37, %conv35.2.37
  %conv37.2.37 = trunc i32 %xor36.2.37 to i8
  store i8 %conv37.2.37, i8* %scevgep41.2.36, align 1
  %scevgep26.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %629, i64 0, i64 1, i64 1
  %893 = bitcast i8* %scevgep26.2 to [41 x [41 x i8]]*
  %scevgep39.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %630, i64 0, i64 1, i64 1
  %894 = bitcast i8* %scevgep39.2 to [41 x [41 x i8]]*
  %arrayidx25.3 = getelementptr inbounds i8, i8* %a, i64 3
  %arrayidx33.3 = getelementptr inbounds i8, i8* %b, i64 3
  %call16.3 = call zeroext i8 (...) @rand()
  store i8 %call16.3, i8* %scevgep26.2, align 1
  %895 = load i8, i8* %scevgep26.2, align 1
  %conv23.3 = zext i8 %895 to i32
  %896 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3 = getelementptr i8, i8* %b, i64 4
  %897 = load i8, i8* %scevgep34.3, align 1
  %call28.3 = call zeroext i8 @mult(i8 zeroext %896, i8 zeroext %897)
  %conv29.3 = zext i8 %call28.3 to i32
  %xor.3 = xor i32 %conv23.3, %conv29.3
  %scevgep35.3 = getelementptr i8, i8* %a, i64 4
  %898 = load i8, i8* %scevgep35.3, align 1
  %899 = load i8, i8* %arrayidx33.3, align 1
  %call34.3 = call zeroext i8 @mult(i8 zeroext %898, i8 zeroext %899)
  %conv35.3 = zext i8 %call34.3 to i32
  %xor36.3 = xor i32 %xor.3, %conv35.3
  %conv37.3 = trunc i32 %xor36.3 to i8
  store i8 %conv37.3, i8* %scevgep39.2, align 1
  %scevgep28.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %893, i64 0, i64 0, i64 1
  %900 = bitcast i8* %scevgep28.3 to [41 x [41 x i8]]*
  %scevgep41.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %894, i64 0, i64 1, i64 0
  %901 = bitcast i8* %scevgep41.3 to [41 x [41 x i8]]*
  %call16.3.1 = call zeroext i8 (...) @rand()
  store i8 %call16.3.1, i8* %scevgep28.3, align 1
  %902 = load i8, i8* %scevgep28.3, align 1
  %conv23.3.1 = zext i8 %902 to i32
  %903 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.1 = getelementptr i8, i8* %b, i64 5
  %904 = load i8, i8* %scevgep34.3.1, align 1
  %call28.3.1 = call zeroext i8 @mult(i8 zeroext %903, i8 zeroext %904)
  %conv29.3.1 = zext i8 %call28.3.1 to i32
  %xor.3.1 = xor i32 %conv23.3.1, %conv29.3.1
  %scevgep35.3.1 = getelementptr i8, i8* %a, i64 5
  %905 = load i8, i8* %scevgep35.3.1, align 1
  %906 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.1 = call zeroext i8 @mult(i8 zeroext %905, i8 zeroext %906)
  %conv35.3.1 = zext i8 %call34.3.1 to i32
  %xor36.3.1 = xor i32 %xor.3.1, %conv35.3.1
  %conv37.3.1 = trunc i32 %xor36.3.1 to i8
  store i8 %conv37.3.1, i8* %scevgep41.3, align 1
  %scevgep28.3.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %900, i64 0, i64 0, i64 1
  %907 = bitcast i8* %scevgep28.3.1 to [41 x [41 x i8]]*
  %scevgep41.3.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %901, i64 0, i64 1, i64 0
  %908 = bitcast i8* %scevgep41.3.1 to [41 x [41 x i8]]*
  %call16.3.2 = call zeroext i8 (...) @rand()
  store i8 %call16.3.2, i8* %scevgep28.3.1, align 1
  %909 = load i8, i8* %scevgep28.3.1, align 1
  %conv23.3.2 = zext i8 %909 to i32
  %910 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.2 = getelementptr i8, i8* %b, i64 6
  %911 = load i8, i8* %scevgep34.3.2, align 1
  %call28.3.2 = call zeroext i8 @mult(i8 zeroext %910, i8 zeroext %911)
  %conv29.3.2 = zext i8 %call28.3.2 to i32
  %xor.3.2 = xor i32 %conv23.3.2, %conv29.3.2
  %scevgep35.3.2 = getelementptr i8, i8* %a, i64 6
  %912 = load i8, i8* %scevgep35.3.2, align 1
  %913 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.2 = call zeroext i8 @mult(i8 zeroext %912, i8 zeroext %913)
  %conv35.3.2 = zext i8 %call34.3.2 to i32
  %xor36.3.2 = xor i32 %xor.3.2, %conv35.3.2
  %conv37.3.2 = trunc i32 %xor36.3.2 to i8
  store i8 %conv37.3.2, i8* %scevgep41.3.1, align 1
  %scevgep28.3.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %907, i64 0, i64 0, i64 1
  %914 = bitcast i8* %scevgep28.3.2 to [41 x [41 x i8]]*
  %scevgep41.3.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %908, i64 0, i64 1, i64 0
  %915 = bitcast i8* %scevgep41.3.2 to [41 x [41 x i8]]*
  %call16.3.3 = call zeroext i8 (...) @rand()
  store i8 %call16.3.3, i8* %scevgep28.3.2, align 1
  %916 = load i8, i8* %scevgep28.3.2, align 1
  %conv23.3.3 = zext i8 %916 to i32
  %917 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.3 = getelementptr i8, i8* %b, i64 7
  %918 = load i8, i8* %scevgep34.3.3, align 1
  %call28.3.3 = call zeroext i8 @mult(i8 zeroext %917, i8 zeroext %918)
  %conv29.3.3 = zext i8 %call28.3.3 to i32
  %xor.3.3 = xor i32 %conv23.3.3, %conv29.3.3
  %scevgep35.3.3 = getelementptr i8, i8* %a, i64 7
  %919 = load i8, i8* %scevgep35.3.3, align 1
  %920 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.3 = call zeroext i8 @mult(i8 zeroext %919, i8 zeroext %920)
  %conv35.3.3 = zext i8 %call34.3.3 to i32
  %xor36.3.3 = xor i32 %xor.3.3, %conv35.3.3
  %conv37.3.3 = trunc i32 %xor36.3.3 to i8
  store i8 %conv37.3.3, i8* %scevgep41.3.2, align 1
  %scevgep28.3.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %914, i64 0, i64 0, i64 1
  %921 = bitcast i8* %scevgep28.3.3 to [41 x [41 x i8]]*
  %scevgep41.3.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %915, i64 0, i64 1, i64 0
  %922 = bitcast i8* %scevgep41.3.3 to [41 x [41 x i8]]*
  %call16.3.4 = call zeroext i8 (...) @rand()
  store i8 %call16.3.4, i8* %scevgep28.3.3, align 1
  %923 = load i8, i8* %scevgep28.3.3, align 1
  %conv23.3.4 = zext i8 %923 to i32
  %924 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.4 = getelementptr i8, i8* %b, i64 8
  %925 = load i8, i8* %scevgep34.3.4, align 1
  %call28.3.4 = call zeroext i8 @mult(i8 zeroext %924, i8 zeroext %925)
  %conv29.3.4 = zext i8 %call28.3.4 to i32
  %xor.3.4 = xor i32 %conv23.3.4, %conv29.3.4
  %scevgep35.3.4 = getelementptr i8, i8* %a, i64 8
  %926 = load i8, i8* %scevgep35.3.4, align 1
  %927 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.4 = call zeroext i8 @mult(i8 zeroext %926, i8 zeroext %927)
  %conv35.3.4 = zext i8 %call34.3.4 to i32
  %xor36.3.4 = xor i32 %xor.3.4, %conv35.3.4
  %conv37.3.4 = trunc i32 %xor36.3.4 to i8
  store i8 %conv37.3.4, i8* %scevgep41.3.3, align 1
  %scevgep28.3.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %921, i64 0, i64 0, i64 1
  %928 = bitcast i8* %scevgep28.3.4 to [41 x [41 x i8]]*
  %scevgep41.3.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %922, i64 0, i64 1, i64 0
  %929 = bitcast i8* %scevgep41.3.4 to [41 x [41 x i8]]*
  %call16.3.5 = call zeroext i8 (...) @rand()
  store i8 %call16.3.5, i8* %scevgep28.3.4, align 1
  %930 = load i8, i8* %scevgep28.3.4, align 1
  %conv23.3.5 = zext i8 %930 to i32
  %931 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.5 = getelementptr i8, i8* %b, i64 9
  %932 = load i8, i8* %scevgep34.3.5, align 1
  %call28.3.5 = call zeroext i8 @mult(i8 zeroext %931, i8 zeroext %932)
  %conv29.3.5 = zext i8 %call28.3.5 to i32
  %xor.3.5 = xor i32 %conv23.3.5, %conv29.3.5
  %scevgep35.3.5 = getelementptr i8, i8* %a, i64 9
  %933 = load i8, i8* %scevgep35.3.5, align 1
  %934 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.5 = call zeroext i8 @mult(i8 zeroext %933, i8 zeroext %934)
  %conv35.3.5 = zext i8 %call34.3.5 to i32
  %xor36.3.5 = xor i32 %xor.3.5, %conv35.3.5
  %conv37.3.5 = trunc i32 %xor36.3.5 to i8
  store i8 %conv37.3.5, i8* %scevgep41.3.4, align 1
  %scevgep28.3.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %928, i64 0, i64 0, i64 1
  %935 = bitcast i8* %scevgep28.3.5 to [41 x [41 x i8]]*
  %scevgep41.3.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %929, i64 0, i64 1, i64 0
  %936 = bitcast i8* %scevgep41.3.5 to [41 x [41 x i8]]*
  %call16.3.6 = call zeroext i8 (...) @rand()
  store i8 %call16.3.6, i8* %scevgep28.3.5, align 1
  %937 = load i8, i8* %scevgep28.3.5, align 1
  %conv23.3.6 = zext i8 %937 to i32
  %938 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.6 = getelementptr i8, i8* %b, i64 10
  %939 = load i8, i8* %scevgep34.3.6, align 1
  %call28.3.6 = call zeroext i8 @mult(i8 zeroext %938, i8 zeroext %939)
  %conv29.3.6 = zext i8 %call28.3.6 to i32
  %xor.3.6 = xor i32 %conv23.3.6, %conv29.3.6
  %scevgep35.3.6 = getelementptr i8, i8* %a, i64 10
  %940 = load i8, i8* %scevgep35.3.6, align 1
  %941 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.6 = call zeroext i8 @mult(i8 zeroext %940, i8 zeroext %941)
  %conv35.3.6 = zext i8 %call34.3.6 to i32
  %xor36.3.6 = xor i32 %xor.3.6, %conv35.3.6
  %conv37.3.6 = trunc i32 %xor36.3.6 to i8
  store i8 %conv37.3.6, i8* %scevgep41.3.5, align 1
  %scevgep28.3.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %935, i64 0, i64 0, i64 1
  %942 = bitcast i8* %scevgep28.3.6 to [41 x [41 x i8]]*
  %scevgep41.3.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %936, i64 0, i64 1, i64 0
  %943 = bitcast i8* %scevgep41.3.6 to [41 x [41 x i8]]*
  %call16.3.7 = call zeroext i8 (...) @rand()
  store i8 %call16.3.7, i8* %scevgep28.3.6, align 1
  %944 = load i8, i8* %scevgep28.3.6, align 1
  %conv23.3.7 = zext i8 %944 to i32
  %945 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.7 = getelementptr i8, i8* %b, i64 11
  %946 = load i8, i8* %scevgep34.3.7, align 1
  %call28.3.7 = call zeroext i8 @mult(i8 zeroext %945, i8 zeroext %946)
  %conv29.3.7 = zext i8 %call28.3.7 to i32
  %xor.3.7 = xor i32 %conv23.3.7, %conv29.3.7
  %scevgep35.3.7 = getelementptr i8, i8* %a, i64 11
  %947 = load i8, i8* %scevgep35.3.7, align 1
  %948 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.7 = call zeroext i8 @mult(i8 zeroext %947, i8 zeroext %948)
  %conv35.3.7 = zext i8 %call34.3.7 to i32
  %xor36.3.7 = xor i32 %xor.3.7, %conv35.3.7
  %conv37.3.7 = trunc i32 %xor36.3.7 to i8
  store i8 %conv37.3.7, i8* %scevgep41.3.6, align 1
  %scevgep28.3.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %942, i64 0, i64 0, i64 1
  %949 = bitcast i8* %scevgep28.3.7 to [41 x [41 x i8]]*
  %scevgep41.3.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %943, i64 0, i64 1, i64 0
  %950 = bitcast i8* %scevgep41.3.7 to [41 x [41 x i8]]*
  %call16.3.8 = call zeroext i8 (...) @rand()
  store i8 %call16.3.8, i8* %scevgep28.3.7, align 1
  %951 = load i8, i8* %scevgep28.3.7, align 1
  %conv23.3.8 = zext i8 %951 to i32
  %952 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.8 = getelementptr i8, i8* %b, i64 12
  %953 = load i8, i8* %scevgep34.3.8, align 1
  %call28.3.8 = call zeroext i8 @mult(i8 zeroext %952, i8 zeroext %953)
  %conv29.3.8 = zext i8 %call28.3.8 to i32
  %xor.3.8 = xor i32 %conv23.3.8, %conv29.3.8
  %scevgep35.3.8 = getelementptr i8, i8* %a, i64 12
  %954 = load i8, i8* %scevgep35.3.8, align 1
  %955 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.8 = call zeroext i8 @mult(i8 zeroext %954, i8 zeroext %955)
  %conv35.3.8 = zext i8 %call34.3.8 to i32
  %xor36.3.8 = xor i32 %xor.3.8, %conv35.3.8
  %conv37.3.8 = trunc i32 %xor36.3.8 to i8
  store i8 %conv37.3.8, i8* %scevgep41.3.7, align 1
  %scevgep28.3.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %949, i64 0, i64 0, i64 1
  %956 = bitcast i8* %scevgep28.3.8 to [41 x [41 x i8]]*
  %scevgep41.3.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %950, i64 0, i64 1, i64 0
  %957 = bitcast i8* %scevgep41.3.8 to [41 x [41 x i8]]*
  %call16.3.9 = call zeroext i8 (...) @rand()
  store i8 %call16.3.9, i8* %scevgep28.3.8, align 1
  %958 = load i8, i8* %scevgep28.3.8, align 1
  %conv23.3.9 = zext i8 %958 to i32
  %959 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.9 = getelementptr i8, i8* %b, i64 13
  %960 = load i8, i8* %scevgep34.3.9, align 1
  %call28.3.9 = call zeroext i8 @mult(i8 zeroext %959, i8 zeroext %960)
  %conv29.3.9 = zext i8 %call28.3.9 to i32
  %xor.3.9 = xor i32 %conv23.3.9, %conv29.3.9
  %scevgep35.3.9 = getelementptr i8, i8* %a, i64 13
  %961 = load i8, i8* %scevgep35.3.9, align 1
  %962 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.9 = call zeroext i8 @mult(i8 zeroext %961, i8 zeroext %962)
  %conv35.3.9 = zext i8 %call34.3.9 to i32
  %xor36.3.9 = xor i32 %xor.3.9, %conv35.3.9
  %conv37.3.9 = trunc i32 %xor36.3.9 to i8
  store i8 %conv37.3.9, i8* %scevgep41.3.8, align 1
  %scevgep28.3.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %956, i64 0, i64 0, i64 1
  %963 = bitcast i8* %scevgep28.3.9 to [41 x [41 x i8]]*
  %scevgep41.3.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %957, i64 0, i64 1, i64 0
  %964 = bitcast i8* %scevgep41.3.9 to [41 x [41 x i8]]*
  %call16.3.10 = call zeroext i8 (...) @rand()
  store i8 %call16.3.10, i8* %scevgep28.3.9, align 1
  %965 = load i8, i8* %scevgep28.3.9, align 1
  %conv23.3.10 = zext i8 %965 to i32
  %966 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.10 = getelementptr i8, i8* %b, i64 14
  %967 = load i8, i8* %scevgep34.3.10, align 1
  %call28.3.10 = call zeroext i8 @mult(i8 zeroext %966, i8 zeroext %967)
  %conv29.3.10 = zext i8 %call28.3.10 to i32
  %xor.3.10 = xor i32 %conv23.3.10, %conv29.3.10
  %scevgep35.3.10 = getelementptr i8, i8* %a, i64 14
  %968 = load i8, i8* %scevgep35.3.10, align 1
  %969 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.10 = call zeroext i8 @mult(i8 zeroext %968, i8 zeroext %969)
  %conv35.3.10 = zext i8 %call34.3.10 to i32
  %xor36.3.10 = xor i32 %xor.3.10, %conv35.3.10
  %conv37.3.10 = trunc i32 %xor36.3.10 to i8
  store i8 %conv37.3.10, i8* %scevgep41.3.9, align 1
  %scevgep28.3.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %963, i64 0, i64 0, i64 1
  %970 = bitcast i8* %scevgep28.3.10 to [41 x [41 x i8]]*
  %scevgep41.3.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %964, i64 0, i64 1, i64 0
  %971 = bitcast i8* %scevgep41.3.10 to [41 x [41 x i8]]*
  %call16.3.11 = call zeroext i8 (...) @rand()
  store i8 %call16.3.11, i8* %scevgep28.3.10, align 1
  %972 = load i8, i8* %scevgep28.3.10, align 1
  %conv23.3.11 = zext i8 %972 to i32
  %973 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.11 = getelementptr i8, i8* %b, i64 15
  %974 = load i8, i8* %scevgep34.3.11, align 1
  %call28.3.11 = call zeroext i8 @mult(i8 zeroext %973, i8 zeroext %974)
  %conv29.3.11 = zext i8 %call28.3.11 to i32
  %xor.3.11 = xor i32 %conv23.3.11, %conv29.3.11
  %scevgep35.3.11 = getelementptr i8, i8* %a, i64 15
  %975 = load i8, i8* %scevgep35.3.11, align 1
  %976 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.11 = call zeroext i8 @mult(i8 zeroext %975, i8 zeroext %976)
  %conv35.3.11 = zext i8 %call34.3.11 to i32
  %xor36.3.11 = xor i32 %xor.3.11, %conv35.3.11
  %conv37.3.11 = trunc i32 %xor36.3.11 to i8
  store i8 %conv37.3.11, i8* %scevgep41.3.10, align 1
  %scevgep28.3.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %970, i64 0, i64 0, i64 1
  %977 = bitcast i8* %scevgep28.3.11 to [41 x [41 x i8]]*
  %scevgep41.3.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %971, i64 0, i64 1, i64 0
  %978 = bitcast i8* %scevgep41.3.11 to [41 x [41 x i8]]*
  %call16.3.12 = call zeroext i8 (...) @rand()
  store i8 %call16.3.12, i8* %scevgep28.3.11, align 1
  %979 = load i8, i8* %scevgep28.3.11, align 1
  %conv23.3.12 = zext i8 %979 to i32
  %980 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.12 = getelementptr i8, i8* %b, i64 16
  %981 = load i8, i8* %scevgep34.3.12, align 1
  %call28.3.12 = call zeroext i8 @mult(i8 zeroext %980, i8 zeroext %981)
  %conv29.3.12 = zext i8 %call28.3.12 to i32
  %xor.3.12 = xor i32 %conv23.3.12, %conv29.3.12
  %scevgep35.3.12 = getelementptr i8, i8* %a, i64 16
  %982 = load i8, i8* %scevgep35.3.12, align 1
  %983 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.12 = call zeroext i8 @mult(i8 zeroext %982, i8 zeroext %983)
  %conv35.3.12 = zext i8 %call34.3.12 to i32
  %xor36.3.12 = xor i32 %xor.3.12, %conv35.3.12
  %conv37.3.12 = trunc i32 %xor36.3.12 to i8
  store i8 %conv37.3.12, i8* %scevgep41.3.11, align 1
  %scevgep28.3.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %977, i64 0, i64 0, i64 1
  %984 = bitcast i8* %scevgep28.3.12 to [41 x [41 x i8]]*
  %scevgep41.3.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %978, i64 0, i64 1, i64 0
  %985 = bitcast i8* %scevgep41.3.12 to [41 x [41 x i8]]*
  %call16.3.13 = call zeroext i8 (...) @rand()
  store i8 %call16.3.13, i8* %scevgep28.3.12, align 1
  %986 = load i8, i8* %scevgep28.3.12, align 1
  %conv23.3.13 = zext i8 %986 to i32
  %987 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.13 = getelementptr i8, i8* %b, i64 17
  %988 = load i8, i8* %scevgep34.3.13, align 1
  %call28.3.13 = call zeroext i8 @mult(i8 zeroext %987, i8 zeroext %988)
  %conv29.3.13 = zext i8 %call28.3.13 to i32
  %xor.3.13 = xor i32 %conv23.3.13, %conv29.3.13
  %scevgep35.3.13 = getelementptr i8, i8* %a, i64 17
  %989 = load i8, i8* %scevgep35.3.13, align 1
  %990 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.13 = call zeroext i8 @mult(i8 zeroext %989, i8 zeroext %990)
  %conv35.3.13 = zext i8 %call34.3.13 to i32
  %xor36.3.13 = xor i32 %xor.3.13, %conv35.3.13
  %conv37.3.13 = trunc i32 %xor36.3.13 to i8
  store i8 %conv37.3.13, i8* %scevgep41.3.12, align 1
  %scevgep28.3.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %984, i64 0, i64 0, i64 1
  %991 = bitcast i8* %scevgep28.3.13 to [41 x [41 x i8]]*
  %scevgep41.3.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %985, i64 0, i64 1, i64 0
  %992 = bitcast i8* %scevgep41.3.13 to [41 x [41 x i8]]*
  %call16.3.14 = call zeroext i8 (...) @rand()
  store i8 %call16.3.14, i8* %scevgep28.3.13, align 1
  %993 = load i8, i8* %scevgep28.3.13, align 1
  %conv23.3.14 = zext i8 %993 to i32
  %994 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.14 = getelementptr i8, i8* %b, i64 18
  %995 = load i8, i8* %scevgep34.3.14, align 1
  %call28.3.14 = call zeroext i8 @mult(i8 zeroext %994, i8 zeroext %995)
  %conv29.3.14 = zext i8 %call28.3.14 to i32
  %xor.3.14 = xor i32 %conv23.3.14, %conv29.3.14
  %scevgep35.3.14 = getelementptr i8, i8* %a, i64 18
  %996 = load i8, i8* %scevgep35.3.14, align 1
  %997 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.14 = call zeroext i8 @mult(i8 zeroext %996, i8 zeroext %997)
  %conv35.3.14 = zext i8 %call34.3.14 to i32
  %xor36.3.14 = xor i32 %xor.3.14, %conv35.3.14
  %conv37.3.14 = trunc i32 %xor36.3.14 to i8
  store i8 %conv37.3.14, i8* %scevgep41.3.13, align 1
  %scevgep28.3.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %991, i64 0, i64 0, i64 1
  %998 = bitcast i8* %scevgep28.3.14 to [41 x [41 x i8]]*
  %scevgep41.3.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %992, i64 0, i64 1, i64 0
  %999 = bitcast i8* %scevgep41.3.14 to [41 x [41 x i8]]*
  %call16.3.15 = call zeroext i8 (...) @rand()
  store i8 %call16.3.15, i8* %scevgep28.3.14, align 1
  %1000 = load i8, i8* %scevgep28.3.14, align 1
  %conv23.3.15 = zext i8 %1000 to i32
  %1001 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.15 = getelementptr i8, i8* %b, i64 19
  %1002 = load i8, i8* %scevgep34.3.15, align 1
  %call28.3.15 = call zeroext i8 @mult(i8 zeroext %1001, i8 zeroext %1002)
  %conv29.3.15 = zext i8 %call28.3.15 to i32
  %xor.3.15 = xor i32 %conv23.3.15, %conv29.3.15
  %scevgep35.3.15 = getelementptr i8, i8* %a, i64 19
  %1003 = load i8, i8* %scevgep35.3.15, align 1
  %1004 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.15 = call zeroext i8 @mult(i8 zeroext %1003, i8 zeroext %1004)
  %conv35.3.15 = zext i8 %call34.3.15 to i32
  %xor36.3.15 = xor i32 %xor.3.15, %conv35.3.15
  %conv37.3.15 = trunc i32 %xor36.3.15 to i8
  store i8 %conv37.3.15, i8* %scevgep41.3.14, align 1
  %scevgep28.3.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %998, i64 0, i64 0, i64 1
  %1005 = bitcast i8* %scevgep28.3.15 to [41 x [41 x i8]]*
  %scevgep41.3.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %999, i64 0, i64 1, i64 0
  %1006 = bitcast i8* %scevgep41.3.15 to [41 x [41 x i8]]*
  %call16.3.16 = call zeroext i8 (...) @rand()
  store i8 %call16.3.16, i8* %scevgep28.3.15, align 1
  %1007 = load i8, i8* %scevgep28.3.15, align 1
  %conv23.3.16 = zext i8 %1007 to i32
  %1008 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.16 = getelementptr i8, i8* %b, i64 20
  %1009 = load i8, i8* %scevgep34.3.16, align 1
  %call28.3.16 = call zeroext i8 @mult(i8 zeroext %1008, i8 zeroext %1009)
  %conv29.3.16 = zext i8 %call28.3.16 to i32
  %xor.3.16 = xor i32 %conv23.3.16, %conv29.3.16
  %scevgep35.3.16 = getelementptr i8, i8* %a, i64 20
  %1010 = load i8, i8* %scevgep35.3.16, align 1
  %1011 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.16 = call zeroext i8 @mult(i8 zeroext %1010, i8 zeroext %1011)
  %conv35.3.16 = zext i8 %call34.3.16 to i32
  %xor36.3.16 = xor i32 %xor.3.16, %conv35.3.16
  %conv37.3.16 = trunc i32 %xor36.3.16 to i8
  store i8 %conv37.3.16, i8* %scevgep41.3.15, align 1
  %scevgep28.3.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1005, i64 0, i64 0, i64 1
  %1012 = bitcast i8* %scevgep28.3.16 to [41 x [41 x i8]]*
  %scevgep41.3.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1006, i64 0, i64 1, i64 0
  %1013 = bitcast i8* %scevgep41.3.16 to [41 x [41 x i8]]*
  %call16.3.17 = call zeroext i8 (...) @rand()
  store i8 %call16.3.17, i8* %scevgep28.3.16, align 1
  %1014 = load i8, i8* %scevgep28.3.16, align 1
  %conv23.3.17 = zext i8 %1014 to i32
  %1015 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.17 = getelementptr i8, i8* %b, i64 21
  %1016 = load i8, i8* %scevgep34.3.17, align 1
  %call28.3.17 = call zeroext i8 @mult(i8 zeroext %1015, i8 zeroext %1016)
  %conv29.3.17 = zext i8 %call28.3.17 to i32
  %xor.3.17 = xor i32 %conv23.3.17, %conv29.3.17
  %scevgep35.3.17 = getelementptr i8, i8* %a, i64 21
  %1017 = load i8, i8* %scevgep35.3.17, align 1
  %1018 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.17 = call zeroext i8 @mult(i8 zeroext %1017, i8 zeroext %1018)
  %conv35.3.17 = zext i8 %call34.3.17 to i32
  %xor36.3.17 = xor i32 %xor.3.17, %conv35.3.17
  %conv37.3.17 = trunc i32 %xor36.3.17 to i8
  store i8 %conv37.3.17, i8* %scevgep41.3.16, align 1
  %scevgep28.3.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1012, i64 0, i64 0, i64 1
  %1019 = bitcast i8* %scevgep28.3.17 to [41 x [41 x i8]]*
  %scevgep41.3.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1013, i64 0, i64 1, i64 0
  %1020 = bitcast i8* %scevgep41.3.17 to [41 x [41 x i8]]*
  %call16.3.18 = call zeroext i8 (...) @rand()
  store i8 %call16.3.18, i8* %scevgep28.3.17, align 1
  %1021 = load i8, i8* %scevgep28.3.17, align 1
  %conv23.3.18 = zext i8 %1021 to i32
  %1022 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.18 = getelementptr i8, i8* %b, i64 22
  %1023 = load i8, i8* %scevgep34.3.18, align 1
  %call28.3.18 = call zeroext i8 @mult(i8 zeroext %1022, i8 zeroext %1023)
  %conv29.3.18 = zext i8 %call28.3.18 to i32
  %xor.3.18 = xor i32 %conv23.3.18, %conv29.3.18
  %scevgep35.3.18 = getelementptr i8, i8* %a, i64 22
  %1024 = load i8, i8* %scevgep35.3.18, align 1
  %1025 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.18 = call zeroext i8 @mult(i8 zeroext %1024, i8 zeroext %1025)
  %conv35.3.18 = zext i8 %call34.3.18 to i32
  %xor36.3.18 = xor i32 %xor.3.18, %conv35.3.18
  %conv37.3.18 = trunc i32 %xor36.3.18 to i8
  store i8 %conv37.3.18, i8* %scevgep41.3.17, align 1
  %scevgep28.3.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1019, i64 0, i64 0, i64 1
  %1026 = bitcast i8* %scevgep28.3.18 to [41 x [41 x i8]]*
  %scevgep41.3.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1020, i64 0, i64 1, i64 0
  %1027 = bitcast i8* %scevgep41.3.18 to [41 x [41 x i8]]*
  %call16.3.19 = call zeroext i8 (...) @rand()
  store i8 %call16.3.19, i8* %scevgep28.3.18, align 1
  %1028 = load i8, i8* %scevgep28.3.18, align 1
  %conv23.3.19 = zext i8 %1028 to i32
  %1029 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.19 = getelementptr i8, i8* %b, i64 23
  %1030 = load i8, i8* %scevgep34.3.19, align 1
  %call28.3.19 = call zeroext i8 @mult(i8 zeroext %1029, i8 zeroext %1030)
  %conv29.3.19 = zext i8 %call28.3.19 to i32
  %xor.3.19 = xor i32 %conv23.3.19, %conv29.3.19
  %scevgep35.3.19 = getelementptr i8, i8* %a, i64 23
  %1031 = load i8, i8* %scevgep35.3.19, align 1
  %1032 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.19 = call zeroext i8 @mult(i8 zeroext %1031, i8 zeroext %1032)
  %conv35.3.19 = zext i8 %call34.3.19 to i32
  %xor36.3.19 = xor i32 %xor.3.19, %conv35.3.19
  %conv37.3.19 = trunc i32 %xor36.3.19 to i8
  store i8 %conv37.3.19, i8* %scevgep41.3.18, align 1
  %scevgep28.3.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1026, i64 0, i64 0, i64 1
  %1033 = bitcast i8* %scevgep28.3.19 to [41 x [41 x i8]]*
  %scevgep41.3.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1027, i64 0, i64 1, i64 0
  %1034 = bitcast i8* %scevgep41.3.19 to [41 x [41 x i8]]*
  %call16.3.20 = call zeroext i8 (...) @rand()
  store i8 %call16.3.20, i8* %scevgep28.3.19, align 1
  %1035 = load i8, i8* %scevgep28.3.19, align 1
  %conv23.3.20 = zext i8 %1035 to i32
  %1036 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.20 = getelementptr i8, i8* %b, i64 24
  %1037 = load i8, i8* %scevgep34.3.20, align 1
  %call28.3.20 = call zeroext i8 @mult(i8 zeroext %1036, i8 zeroext %1037)
  %conv29.3.20 = zext i8 %call28.3.20 to i32
  %xor.3.20 = xor i32 %conv23.3.20, %conv29.3.20
  %scevgep35.3.20 = getelementptr i8, i8* %a, i64 24
  %1038 = load i8, i8* %scevgep35.3.20, align 1
  %1039 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.20 = call zeroext i8 @mult(i8 zeroext %1038, i8 zeroext %1039)
  %conv35.3.20 = zext i8 %call34.3.20 to i32
  %xor36.3.20 = xor i32 %xor.3.20, %conv35.3.20
  %conv37.3.20 = trunc i32 %xor36.3.20 to i8
  store i8 %conv37.3.20, i8* %scevgep41.3.19, align 1
  %scevgep28.3.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1033, i64 0, i64 0, i64 1
  %1040 = bitcast i8* %scevgep28.3.20 to [41 x [41 x i8]]*
  %scevgep41.3.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1034, i64 0, i64 1, i64 0
  %1041 = bitcast i8* %scevgep41.3.20 to [41 x [41 x i8]]*
  %call16.3.21 = call zeroext i8 (...) @rand()
  store i8 %call16.3.21, i8* %scevgep28.3.20, align 1
  %1042 = load i8, i8* %scevgep28.3.20, align 1
  %conv23.3.21 = zext i8 %1042 to i32
  %1043 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.21 = getelementptr i8, i8* %b, i64 25
  %1044 = load i8, i8* %scevgep34.3.21, align 1
  %call28.3.21 = call zeroext i8 @mult(i8 zeroext %1043, i8 zeroext %1044)
  %conv29.3.21 = zext i8 %call28.3.21 to i32
  %xor.3.21 = xor i32 %conv23.3.21, %conv29.3.21
  %scevgep35.3.21 = getelementptr i8, i8* %a, i64 25
  %1045 = load i8, i8* %scevgep35.3.21, align 1
  %1046 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.21 = call zeroext i8 @mult(i8 zeroext %1045, i8 zeroext %1046)
  %conv35.3.21 = zext i8 %call34.3.21 to i32
  %xor36.3.21 = xor i32 %xor.3.21, %conv35.3.21
  %conv37.3.21 = trunc i32 %xor36.3.21 to i8
  store i8 %conv37.3.21, i8* %scevgep41.3.20, align 1
  %scevgep28.3.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1040, i64 0, i64 0, i64 1
  %1047 = bitcast i8* %scevgep28.3.21 to [41 x [41 x i8]]*
  %scevgep41.3.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1041, i64 0, i64 1, i64 0
  %1048 = bitcast i8* %scevgep41.3.21 to [41 x [41 x i8]]*
  %call16.3.22 = call zeroext i8 (...) @rand()
  store i8 %call16.3.22, i8* %scevgep28.3.21, align 1
  %1049 = load i8, i8* %scevgep28.3.21, align 1
  %conv23.3.22 = zext i8 %1049 to i32
  %1050 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.22 = getelementptr i8, i8* %b, i64 26
  %1051 = load i8, i8* %scevgep34.3.22, align 1
  %call28.3.22 = call zeroext i8 @mult(i8 zeroext %1050, i8 zeroext %1051)
  %conv29.3.22 = zext i8 %call28.3.22 to i32
  %xor.3.22 = xor i32 %conv23.3.22, %conv29.3.22
  %scevgep35.3.22 = getelementptr i8, i8* %a, i64 26
  %1052 = load i8, i8* %scevgep35.3.22, align 1
  %1053 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.22 = call zeroext i8 @mult(i8 zeroext %1052, i8 zeroext %1053)
  %conv35.3.22 = zext i8 %call34.3.22 to i32
  %xor36.3.22 = xor i32 %xor.3.22, %conv35.3.22
  %conv37.3.22 = trunc i32 %xor36.3.22 to i8
  store i8 %conv37.3.22, i8* %scevgep41.3.21, align 1
  %scevgep28.3.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1047, i64 0, i64 0, i64 1
  %1054 = bitcast i8* %scevgep28.3.22 to [41 x [41 x i8]]*
  %scevgep41.3.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1048, i64 0, i64 1, i64 0
  %1055 = bitcast i8* %scevgep41.3.22 to [41 x [41 x i8]]*
  %call16.3.23 = call zeroext i8 (...) @rand()
  store i8 %call16.3.23, i8* %scevgep28.3.22, align 1
  %1056 = load i8, i8* %scevgep28.3.22, align 1
  %conv23.3.23 = zext i8 %1056 to i32
  %1057 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.23 = getelementptr i8, i8* %b, i64 27
  %1058 = load i8, i8* %scevgep34.3.23, align 1
  %call28.3.23 = call zeroext i8 @mult(i8 zeroext %1057, i8 zeroext %1058)
  %conv29.3.23 = zext i8 %call28.3.23 to i32
  %xor.3.23 = xor i32 %conv23.3.23, %conv29.3.23
  %scevgep35.3.23 = getelementptr i8, i8* %a, i64 27
  %1059 = load i8, i8* %scevgep35.3.23, align 1
  %1060 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.23 = call zeroext i8 @mult(i8 zeroext %1059, i8 zeroext %1060)
  %conv35.3.23 = zext i8 %call34.3.23 to i32
  %xor36.3.23 = xor i32 %xor.3.23, %conv35.3.23
  %conv37.3.23 = trunc i32 %xor36.3.23 to i8
  store i8 %conv37.3.23, i8* %scevgep41.3.22, align 1
  %scevgep28.3.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1054, i64 0, i64 0, i64 1
  %1061 = bitcast i8* %scevgep28.3.23 to [41 x [41 x i8]]*
  %scevgep41.3.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1055, i64 0, i64 1, i64 0
  %1062 = bitcast i8* %scevgep41.3.23 to [41 x [41 x i8]]*
  %call16.3.24 = call zeroext i8 (...) @rand()
  store i8 %call16.3.24, i8* %scevgep28.3.23, align 1
  %1063 = load i8, i8* %scevgep28.3.23, align 1
  %conv23.3.24 = zext i8 %1063 to i32
  %1064 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.24 = getelementptr i8, i8* %b, i64 28
  %1065 = load i8, i8* %scevgep34.3.24, align 1
  %call28.3.24 = call zeroext i8 @mult(i8 zeroext %1064, i8 zeroext %1065)
  %conv29.3.24 = zext i8 %call28.3.24 to i32
  %xor.3.24 = xor i32 %conv23.3.24, %conv29.3.24
  %scevgep35.3.24 = getelementptr i8, i8* %a, i64 28
  %1066 = load i8, i8* %scevgep35.3.24, align 1
  %1067 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.24 = call zeroext i8 @mult(i8 zeroext %1066, i8 zeroext %1067)
  %conv35.3.24 = zext i8 %call34.3.24 to i32
  %xor36.3.24 = xor i32 %xor.3.24, %conv35.3.24
  %conv37.3.24 = trunc i32 %xor36.3.24 to i8
  store i8 %conv37.3.24, i8* %scevgep41.3.23, align 1
  %scevgep28.3.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1061, i64 0, i64 0, i64 1
  %1068 = bitcast i8* %scevgep28.3.24 to [41 x [41 x i8]]*
  %scevgep41.3.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1062, i64 0, i64 1, i64 0
  %1069 = bitcast i8* %scevgep41.3.24 to [41 x [41 x i8]]*
  %call16.3.25 = call zeroext i8 (...) @rand()
  store i8 %call16.3.25, i8* %scevgep28.3.24, align 1
  %1070 = load i8, i8* %scevgep28.3.24, align 1
  %conv23.3.25 = zext i8 %1070 to i32
  %1071 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.25 = getelementptr i8, i8* %b, i64 29
  %1072 = load i8, i8* %scevgep34.3.25, align 1
  %call28.3.25 = call zeroext i8 @mult(i8 zeroext %1071, i8 zeroext %1072)
  %conv29.3.25 = zext i8 %call28.3.25 to i32
  %xor.3.25 = xor i32 %conv23.3.25, %conv29.3.25
  %scevgep35.3.25 = getelementptr i8, i8* %a, i64 29
  %1073 = load i8, i8* %scevgep35.3.25, align 1
  %1074 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.25 = call zeroext i8 @mult(i8 zeroext %1073, i8 zeroext %1074)
  %conv35.3.25 = zext i8 %call34.3.25 to i32
  %xor36.3.25 = xor i32 %xor.3.25, %conv35.3.25
  %conv37.3.25 = trunc i32 %xor36.3.25 to i8
  store i8 %conv37.3.25, i8* %scevgep41.3.24, align 1
  %scevgep28.3.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1068, i64 0, i64 0, i64 1
  %1075 = bitcast i8* %scevgep28.3.25 to [41 x [41 x i8]]*
  %scevgep41.3.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1069, i64 0, i64 1, i64 0
  %1076 = bitcast i8* %scevgep41.3.25 to [41 x [41 x i8]]*
  %call16.3.26 = call zeroext i8 (...) @rand()
  store i8 %call16.3.26, i8* %scevgep28.3.25, align 1
  %1077 = load i8, i8* %scevgep28.3.25, align 1
  %conv23.3.26 = zext i8 %1077 to i32
  %1078 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.26 = getelementptr i8, i8* %b, i64 30
  %1079 = load i8, i8* %scevgep34.3.26, align 1
  %call28.3.26 = call zeroext i8 @mult(i8 zeroext %1078, i8 zeroext %1079)
  %conv29.3.26 = zext i8 %call28.3.26 to i32
  %xor.3.26 = xor i32 %conv23.3.26, %conv29.3.26
  %scevgep35.3.26 = getelementptr i8, i8* %a, i64 30
  %1080 = load i8, i8* %scevgep35.3.26, align 1
  %1081 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.26 = call zeroext i8 @mult(i8 zeroext %1080, i8 zeroext %1081)
  %conv35.3.26 = zext i8 %call34.3.26 to i32
  %xor36.3.26 = xor i32 %xor.3.26, %conv35.3.26
  %conv37.3.26 = trunc i32 %xor36.3.26 to i8
  store i8 %conv37.3.26, i8* %scevgep41.3.25, align 1
  %scevgep28.3.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1075, i64 0, i64 0, i64 1
  %1082 = bitcast i8* %scevgep28.3.26 to [41 x [41 x i8]]*
  %scevgep41.3.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1076, i64 0, i64 1, i64 0
  %1083 = bitcast i8* %scevgep41.3.26 to [41 x [41 x i8]]*
  %call16.3.27 = call zeroext i8 (...) @rand()
  store i8 %call16.3.27, i8* %scevgep28.3.26, align 1
  %1084 = load i8, i8* %scevgep28.3.26, align 1
  %conv23.3.27 = zext i8 %1084 to i32
  %1085 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.27 = getelementptr i8, i8* %b, i64 31
  %1086 = load i8, i8* %scevgep34.3.27, align 1
  %call28.3.27 = call zeroext i8 @mult(i8 zeroext %1085, i8 zeroext %1086)
  %conv29.3.27 = zext i8 %call28.3.27 to i32
  %xor.3.27 = xor i32 %conv23.3.27, %conv29.3.27
  %scevgep35.3.27 = getelementptr i8, i8* %a, i64 31
  %1087 = load i8, i8* %scevgep35.3.27, align 1
  %1088 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.27 = call zeroext i8 @mult(i8 zeroext %1087, i8 zeroext %1088)
  %conv35.3.27 = zext i8 %call34.3.27 to i32
  %xor36.3.27 = xor i32 %xor.3.27, %conv35.3.27
  %conv37.3.27 = trunc i32 %xor36.3.27 to i8
  store i8 %conv37.3.27, i8* %scevgep41.3.26, align 1
  %scevgep28.3.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1082, i64 0, i64 0, i64 1
  %1089 = bitcast i8* %scevgep28.3.27 to [41 x [41 x i8]]*
  %scevgep41.3.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1083, i64 0, i64 1, i64 0
  %1090 = bitcast i8* %scevgep41.3.27 to [41 x [41 x i8]]*
  %call16.3.28 = call zeroext i8 (...) @rand()
  store i8 %call16.3.28, i8* %scevgep28.3.27, align 1
  %1091 = load i8, i8* %scevgep28.3.27, align 1
  %conv23.3.28 = zext i8 %1091 to i32
  %1092 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.28 = getelementptr i8, i8* %b, i64 32
  %1093 = load i8, i8* %scevgep34.3.28, align 1
  %call28.3.28 = call zeroext i8 @mult(i8 zeroext %1092, i8 zeroext %1093)
  %conv29.3.28 = zext i8 %call28.3.28 to i32
  %xor.3.28 = xor i32 %conv23.3.28, %conv29.3.28
  %scevgep35.3.28 = getelementptr i8, i8* %a, i64 32
  %1094 = load i8, i8* %scevgep35.3.28, align 1
  %1095 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.28 = call zeroext i8 @mult(i8 zeroext %1094, i8 zeroext %1095)
  %conv35.3.28 = zext i8 %call34.3.28 to i32
  %xor36.3.28 = xor i32 %xor.3.28, %conv35.3.28
  %conv37.3.28 = trunc i32 %xor36.3.28 to i8
  store i8 %conv37.3.28, i8* %scevgep41.3.27, align 1
  %scevgep28.3.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1089, i64 0, i64 0, i64 1
  %1096 = bitcast i8* %scevgep28.3.28 to [41 x [41 x i8]]*
  %scevgep41.3.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1090, i64 0, i64 1, i64 0
  %1097 = bitcast i8* %scevgep41.3.28 to [41 x [41 x i8]]*
  %call16.3.29 = call zeroext i8 (...) @rand()
  store i8 %call16.3.29, i8* %scevgep28.3.28, align 1
  %1098 = load i8, i8* %scevgep28.3.28, align 1
  %conv23.3.29 = zext i8 %1098 to i32
  %1099 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.29 = getelementptr i8, i8* %b, i64 33
  %1100 = load i8, i8* %scevgep34.3.29, align 1
  %call28.3.29 = call zeroext i8 @mult(i8 zeroext %1099, i8 zeroext %1100)
  %conv29.3.29 = zext i8 %call28.3.29 to i32
  %xor.3.29 = xor i32 %conv23.3.29, %conv29.3.29
  %scevgep35.3.29 = getelementptr i8, i8* %a, i64 33
  %1101 = load i8, i8* %scevgep35.3.29, align 1
  %1102 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.29 = call zeroext i8 @mult(i8 zeroext %1101, i8 zeroext %1102)
  %conv35.3.29 = zext i8 %call34.3.29 to i32
  %xor36.3.29 = xor i32 %xor.3.29, %conv35.3.29
  %conv37.3.29 = trunc i32 %xor36.3.29 to i8
  store i8 %conv37.3.29, i8* %scevgep41.3.28, align 1
  %scevgep28.3.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1096, i64 0, i64 0, i64 1
  %1103 = bitcast i8* %scevgep28.3.29 to [41 x [41 x i8]]*
  %scevgep41.3.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1097, i64 0, i64 1, i64 0
  %1104 = bitcast i8* %scevgep41.3.29 to [41 x [41 x i8]]*
  %call16.3.30 = call zeroext i8 (...) @rand()
  store i8 %call16.3.30, i8* %scevgep28.3.29, align 1
  %1105 = load i8, i8* %scevgep28.3.29, align 1
  %conv23.3.30 = zext i8 %1105 to i32
  %1106 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.30 = getelementptr i8, i8* %b, i64 34
  %1107 = load i8, i8* %scevgep34.3.30, align 1
  %call28.3.30 = call zeroext i8 @mult(i8 zeroext %1106, i8 zeroext %1107)
  %conv29.3.30 = zext i8 %call28.3.30 to i32
  %xor.3.30 = xor i32 %conv23.3.30, %conv29.3.30
  %scevgep35.3.30 = getelementptr i8, i8* %a, i64 34
  %1108 = load i8, i8* %scevgep35.3.30, align 1
  %1109 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.30 = call zeroext i8 @mult(i8 zeroext %1108, i8 zeroext %1109)
  %conv35.3.30 = zext i8 %call34.3.30 to i32
  %xor36.3.30 = xor i32 %xor.3.30, %conv35.3.30
  %conv37.3.30 = trunc i32 %xor36.3.30 to i8
  store i8 %conv37.3.30, i8* %scevgep41.3.29, align 1
  %scevgep28.3.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1103, i64 0, i64 0, i64 1
  %1110 = bitcast i8* %scevgep28.3.30 to [41 x [41 x i8]]*
  %scevgep41.3.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1104, i64 0, i64 1, i64 0
  %1111 = bitcast i8* %scevgep41.3.30 to [41 x [41 x i8]]*
  %call16.3.31 = call zeroext i8 (...) @rand()
  store i8 %call16.3.31, i8* %scevgep28.3.30, align 1
  %1112 = load i8, i8* %scevgep28.3.30, align 1
  %conv23.3.31 = zext i8 %1112 to i32
  %1113 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.31 = getelementptr i8, i8* %b, i64 35
  %1114 = load i8, i8* %scevgep34.3.31, align 1
  %call28.3.31 = call zeroext i8 @mult(i8 zeroext %1113, i8 zeroext %1114)
  %conv29.3.31 = zext i8 %call28.3.31 to i32
  %xor.3.31 = xor i32 %conv23.3.31, %conv29.3.31
  %scevgep35.3.31 = getelementptr i8, i8* %a, i64 35
  %1115 = load i8, i8* %scevgep35.3.31, align 1
  %1116 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.31 = call zeroext i8 @mult(i8 zeroext %1115, i8 zeroext %1116)
  %conv35.3.31 = zext i8 %call34.3.31 to i32
  %xor36.3.31 = xor i32 %xor.3.31, %conv35.3.31
  %conv37.3.31 = trunc i32 %xor36.3.31 to i8
  store i8 %conv37.3.31, i8* %scevgep41.3.30, align 1
  %scevgep28.3.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1110, i64 0, i64 0, i64 1
  %1117 = bitcast i8* %scevgep28.3.31 to [41 x [41 x i8]]*
  %scevgep41.3.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1111, i64 0, i64 1, i64 0
  %1118 = bitcast i8* %scevgep41.3.31 to [41 x [41 x i8]]*
  %call16.3.32 = call zeroext i8 (...) @rand()
  store i8 %call16.3.32, i8* %scevgep28.3.31, align 1
  %1119 = load i8, i8* %scevgep28.3.31, align 1
  %conv23.3.32 = zext i8 %1119 to i32
  %1120 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.32 = getelementptr i8, i8* %b, i64 36
  %1121 = load i8, i8* %scevgep34.3.32, align 1
  %call28.3.32 = call zeroext i8 @mult(i8 zeroext %1120, i8 zeroext %1121)
  %conv29.3.32 = zext i8 %call28.3.32 to i32
  %xor.3.32 = xor i32 %conv23.3.32, %conv29.3.32
  %scevgep35.3.32 = getelementptr i8, i8* %a, i64 36
  %1122 = load i8, i8* %scevgep35.3.32, align 1
  %1123 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.32 = call zeroext i8 @mult(i8 zeroext %1122, i8 zeroext %1123)
  %conv35.3.32 = zext i8 %call34.3.32 to i32
  %xor36.3.32 = xor i32 %xor.3.32, %conv35.3.32
  %conv37.3.32 = trunc i32 %xor36.3.32 to i8
  store i8 %conv37.3.32, i8* %scevgep41.3.31, align 1
  %scevgep28.3.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1117, i64 0, i64 0, i64 1
  %1124 = bitcast i8* %scevgep28.3.32 to [41 x [41 x i8]]*
  %scevgep41.3.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1118, i64 0, i64 1, i64 0
  %1125 = bitcast i8* %scevgep41.3.32 to [41 x [41 x i8]]*
  %call16.3.33 = call zeroext i8 (...) @rand()
  store i8 %call16.3.33, i8* %scevgep28.3.32, align 1
  %1126 = load i8, i8* %scevgep28.3.32, align 1
  %conv23.3.33 = zext i8 %1126 to i32
  %1127 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.33 = getelementptr i8, i8* %b, i64 37
  %1128 = load i8, i8* %scevgep34.3.33, align 1
  %call28.3.33 = call zeroext i8 @mult(i8 zeroext %1127, i8 zeroext %1128)
  %conv29.3.33 = zext i8 %call28.3.33 to i32
  %xor.3.33 = xor i32 %conv23.3.33, %conv29.3.33
  %scevgep35.3.33 = getelementptr i8, i8* %a, i64 37
  %1129 = load i8, i8* %scevgep35.3.33, align 1
  %1130 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.33 = call zeroext i8 @mult(i8 zeroext %1129, i8 zeroext %1130)
  %conv35.3.33 = zext i8 %call34.3.33 to i32
  %xor36.3.33 = xor i32 %xor.3.33, %conv35.3.33
  %conv37.3.33 = trunc i32 %xor36.3.33 to i8
  store i8 %conv37.3.33, i8* %scevgep41.3.32, align 1
  %scevgep28.3.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1124, i64 0, i64 0, i64 1
  %1131 = bitcast i8* %scevgep28.3.33 to [41 x [41 x i8]]*
  %scevgep41.3.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1125, i64 0, i64 1, i64 0
  %1132 = bitcast i8* %scevgep41.3.33 to [41 x [41 x i8]]*
  %call16.3.34 = call zeroext i8 (...) @rand()
  store i8 %call16.3.34, i8* %scevgep28.3.33, align 1
  %1133 = load i8, i8* %scevgep28.3.33, align 1
  %conv23.3.34 = zext i8 %1133 to i32
  %1134 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.34 = getelementptr i8, i8* %b, i64 38
  %1135 = load i8, i8* %scevgep34.3.34, align 1
  %call28.3.34 = call zeroext i8 @mult(i8 zeroext %1134, i8 zeroext %1135)
  %conv29.3.34 = zext i8 %call28.3.34 to i32
  %xor.3.34 = xor i32 %conv23.3.34, %conv29.3.34
  %scevgep35.3.34 = getelementptr i8, i8* %a, i64 38
  %1136 = load i8, i8* %scevgep35.3.34, align 1
  %1137 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.34 = call zeroext i8 @mult(i8 zeroext %1136, i8 zeroext %1137)
  %conv35.3.34 = zext i8 %call34.3.34 to i32
  %xor36.3.34 = xor i32 %xor.3.34, %conv35.3.34
  %conv37.3.34 = trunc i32 %xor36.3.34 to i8
  store i8 %conv37.3.34, i8* %scevgep41.3.33, align 1
  %scevgep28.3.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1131, i64 0, i64 0, i64 1
  %1138 = bitcast i8* %scevgep28.3.34 to [41 x [41 x i8]]*
  %scevgep41.3.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1132, i64 0, i64 1, i64 0
  %1139 = bitcast i8* %scevgep41.3.34 to [41 x [41 x i8]]*
  %call16.3.35 = call zeroext i8 (...) @rand()
  store i8 %call16.3.35, i8* %scevgep28.3.34, align 1
  %1140 = load i8, i8* %scevgep28.3.34, align 1
  %conv23.3.35 = zext i8 %1140 to i32
  %1141 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.35 = getelementptr i8, i8* %b, i64 39
  %1142 = load i8, i8* %scevgep34.3.35, align 1
  %call28.3.35 = call zeroext i8 @mult(i8 zeroext %1141, i8 zeroext %1142)
  %conv29.3.35 = zext i8 %call28.3.35 to i32
  %xor.3.35 = xor i32 %conv23.3.35, %conv29.3.35
  %scevgep35.3.35 = getelementptr i8, i8* %a, i64 39
  %1143 = load i8, i8* %scevgep35.3.35, align 1
  %1144 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.35 = call zeroext i8 @mult(i8 zeroext %1143, i8 zeroext %1144)
  %conv35.3.35 = zext i8 %call34.3.35 to i32
  %xor36.3.35 = xor i32 %xor.3.35, %conv35.3.35
  %conv37.3.35 = trunc i32 %xor36.3.35 to i8
  store i8 %conv37.3.35, i8* %scevgep41.3.34, align 1
  %scevgep28.3.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1138, i64 0, i64 0, i64 1
  %scevgep41.3.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1139, i64 0, i64 1, i64 0
  %call16.3.36 = call zeroext i8 (...) @rand()
  store i8 %call16.3.36, i8* %scevgep28.3.35, align 1
  %1145 = load i8, i8* %scevgep28.3.35, align 1
  %conv23.3.36 = zext i8 %1145 to i32
  %1146 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.36 = getelementptr i8, i8* %b, i64 40
  %1147 = load i8, i8* %scevgep34.3.36, align 1
  %call28.3.36 = call zeroext i8 @mult(i8 zeroext %1146, i8 zeroext %1147)
  %conv29.3.36 = zext i8 %call28.3.36 to i32
  %xor.3.36 = xor i32 %conv23.3.36, %conv29.3.36
  %scevgep35.3.36 = getelementptr i8, i8* %a, i64 40
  %1148 = load i8, i8* %scevgep35.3.36, align 1
  %1149 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.36 = call zeroext i8 @mult(i8 zeroext %1148, i8 zeroext %1149)
  %conv35.3.36 = zext i8 %call34.3.36 to i32
  %xor36.3.36 = xor i32 %xor.3.36, %conv35.3.36
  %conv37.3.36 = trunc i32 %xor36.3.36 to i8
  store i8 %conv37.3.36, i8* %scevgep41.3.35, align 1
  %scevgep26.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %893, i64 0, i64 1, i64 1
  %1150 = bitcast i8* %scevgep26.3 to [41 x [41 x i8]]*
  %scevgep39.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %894, i64 0, i64 1, i64 1
  %1151 = bitcast i8* %scevgep39.3 to [41 x [41 x i8]]*
  %arrayidx25.4 = getelementptr inbounds i8, i8* %a, i64 4
  %arrayidx33.4 = getelementptr inbounds i8, i8* %b, i64 4
  %call16.4 = call zeroext i8 (...) @rand()
  store i8 %call16.4, i8* %scevgep26.3, align 1
  %1152 = load i8, i8* %scevgep26.3, align 1
  %conv23.4 = zext i8 %1152 to i32
  %1153 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4 = getelementptr i8, i8* %b, i64 5
  %1154 = load i8, i8* %scevgep34.4, align 1
  %call28.4 = call zeroext i8 @mult(i8 zeroext %1153, i8 zeroext %1154)
  %conv29.4 = zext i8 %call28.4 to i32
  %xor.4 = xor i32 %conv23.4, %conv29.4
  %scevgep35.4 = getelementptr i8, i8* %a, i64 5
  %1155 = load i8, i8* %scevgep35.4, align 1
  %1156 = load i8, i8* %arrayidx33.4, align 1
  %call34.4 = call zeroext i8 @mult(i8 zeroext %1155, i8 zeroext %1156)
  %conv35.4 = zext i8 %call34.4 to i32
  %xor36.4 = xor i32 %xor.4, %conv35.4
  %conv37.4 = trunc i32 %xor36.4 to i8
  store i8 %conv37.4, i8* %scevgep39.3, align 1
  %scevgep28.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1150, i64 0, i64 0, i64 1
  %1157 = bitcast i8* %scevgep28.4 to [41 x [41 x i8]]*
  %scevgep41.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1151, i64 0, i64 1, i64 0
  %1158 = bitcast i8* %scevgep41.4 to [41 x [41 x i8]]*
  %call16.4.1 = call zeroext i8 (...) @rand()
  store i8 %call16.4.1, i8* %scevgep28.4, align 1
  %1159 = load i8, i8* %scevgep28.4, align 1
  %conv23.4.1 = zext i8 %1159 to i32
  %1160 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.1 = getelementptr i8, i8* %b, i64 6
  %1161 = load i8, i8* %scevgep34.4.1, align 1
  %call28.4.1 = call zeroext i8 @mult(i8 zeroext %1160, i8 zeroext %1161)
  %conv29.4.1 = zext i8 %call28.4.1 to i32
  %xor.4.1 = xor i32 %conv23.4.1, %conv29.4.1
  %scevgep35.4.1 = getelementptr i8, i8* %a, i64 6
  %1162 = load i8, i8* %scevgep35.4.1, align 1
  %1163 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.1 = call zeroext i8 @mult(i8 zeroext %1162, i8 zeroext %1163)
  %conv35.4.1 = zext i8 %call34.4.1 to i32
  %xor36.4.1 = xor i32 %xor.4.1, %conv35.4.1
  %conv37.4.1 = trunc i32 %xor36.4.1 to i8
  store i8 %conv37.4.1, i8* %scevgep41.4, align 1
  %scevgep28.4.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1157, i64 0, i64 0, i64 1
  %1164 = bitcast i8* %scevgep28.4.1 to [41 x [41 x i8]]*
  %scevgep41.4.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1158, i64 0, i64 1, i64 0
  %1165 = bitcast i8* %scevgep41.4.1 to [41 x [41 x i8]]*
  %call16.4.2 = call zeroext i8 (...) @rand()
  store i8 %call16.4.2, i8* %scevgep28.4.1, align 1
  %1166 = load i8, i8* %scevgep28.4.1, align 1
  %conv23.4.2 = zext i8 %1166 to i32
  %1167 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.2 = getelementptr i8, i8* %b, i64 7
  %1168 = load i8, i8* %scevgep34.4.2, align 1
  %call28.4.2 = call zeroext i8 @mult(i8 zeroext %1167, i8 zeroext %1168)
  %conv29.4.2 = zext i8 %call28.4.2 to i32
  %xor.4.2 = xor i32 %conv23.4.2, %conv29.4.2
  %scevgep35.4.2 = getelementptr i8, i8* %a, i64 7
  %1169 = load i8, i8* %scevgep35.4.2, align 1
  %1170 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.2 = call zeroext i8 @mult(i8 zeroext %1169, i8 zeroext %1170)
  %conv35.4.2 = zext i8 %call34.4.2 to i32
  %xor36.4.2 = xor i32 %xor.4.2, %conv35.4.2
  %conv37.4.2 = trunc i32 %xor36.4.2 to i8
  store i8 %conv37.4.2, i8* %scevgep41.4.1, align 1
  %scevgep28.4.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1164, i64 0, i64 0, i64 1
  %1171 = bitcast i8* %scevgep28.4.2 to [41 x [41 x i8]]*
  %scevgep41.4.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1165, i64 0, i64 1, i64 0
  %1172 = bitcast i8* %scevgep41.4.2 to [41 x [41 x i8]]*
  %call16.4.3 = call zeroext i8 (...) @rand()
  store i8 %call16.4.3, i8* %scevgep28.4.2, align 1
  %1173 = load i8, i8* %scevgep28.4.2, align 1
  %conv23.4.3 = zext i8 %1173 to i32
  %1174 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.3 = getelementptr i8, i8* %b, i64 8
  %1175 = load i8, i8* %scevgep34.4.3, align 1
  %call28.4.3 = call zeroext i8 @mult(i8 zeroext %1174, i8 zeroext %1175)
  %conv29.4.3 = zext i8 %call28.4.3 to i32
  %xor.4.3 = xor i32 %conv23.4.3, %conv29.4.3
  %scevgep35.4.3 = getelementptr i8, i8* %a, i64 8
  %1176 = load i8, i8* %scevgep35.4.3, align 1
  %1177 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.3 = call zeroext i8 @mult(i8 zeroext %1176, i8 zeroext %1177)
  %conv35.4.3 = zext i8 %call34.4.3 to i32
  %xor36.4.3 = xor i32 %xor.4.3, %conv35.4.3
  %conv37.4.3 = trunc i32 %xor36.4.3 to i8
  store i8 %conv37.4.3, i8* %scevgep41.4.2, align 1
  %scevgep28.4.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1171, i64 0, i64 0, i64 1
  %1178 = bitcast i8* %scevgep28.4.3 to [41 x [41 x i8]]*
  %scevgep41.4.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1172, i64 0, i64 1, i64 0
  %1179 = bitcast i8* %scevgep41.4.3 to [41 x [41 x i8]]*
  %call16.4.4 = call zeroext i8 (...) @rand()
  store i8 %call16.4.4, i8* %scevgep28.4.3, align 1
  %1180 = load i8, i8* %scevgep28.4.3, align 1
  %conv23.4.4 = zext i8 %1180 to i32
  %1181 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.4 = getelementptr i8, i8* %b, i64 9
  %1182 = load i8, i8* %scevgep34.4.4, align 1
  %call28.4.4 = call zeroext i8 @mult(i8 zeroext %1181, i8 zeroext %1182)
  %conv29.4.4 = zext i8 %call28.4.4 to i32
  %xor.4.4 = xor i32 %conv23.4.4, %conv29.4.4
  %scevgep35.4.4 = getelementptr i8, i8* %a, i64 9
  %1183 = load i8, i8* %scevgep35.4.4, align 1
  %1184 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.4 = call zeroext i8 @mult(i8 zeroext %1183, i8 zeroext %1184)
  %conv35.4.4 = zext i8 %call34.4.4 to i32
  %xor36.4.4 = xor i32 %xor.4.4, %conv35.4.4
  %conv37.4.4 = trunc i32 %xor36.4.4 to i8
  store i8 %conv37.4.4, i8* %scevgep41.4.3, align 1
  %scevgep28.4.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1178, i64 0, i64 0, i64 1
  %1185 = bitcast i8* %scevgep28.4.4 to [41 x [41 x i8]]*
  %scevgep41.4.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1179, i64 0, i64 1, i64 0
  %1186 = bitcast i8* %scevgep41.4.4 to [41 x [41 x i8]]*
  %call16.4.5 = call zeroext i8 (...) @rand()
  store i8 %call16.4.5, i8* %scevgep28.4.4, align 1
  %1187 = load i8, i8* %scevgep28.4.4, align 1
  %conv23.4.5 = zext i8 %1187 to i32
  %1188 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.5 = getelementptr i8, i8* %b, i64 10
  %1189 = load i8, i8* %scevgep34.4.5, align 1
  %call28.4.5 = call zeroext i8 @mult(i8 zeroext %1188, i8 zeroext %1189)
  %conv29.4.5 = zext i8 %call28.4.5 to i32
  %xor.4.5 = xor i32 %conv23.4.5, %conv29.4.5
  %scevgep35.4.5 = getelementptr i8, i8* %a, i64 10
  %1190 = load i8, i8* %scevgep35.4.5, align 1
  %1191 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.5 = call zeroext i8 @mult(i8 zeroext %1190, i8 zeroext %1191)
  %conv35.4.5 = zext i8 %call34.4.5 to i32
  %xor36.4.5 = xor i32 %xor.4.5, %conv35.4.5
  %conv37.4.5 = trunc i32 %xor36.4.5 to i8
  store i8 %conv37.4.5, i8* %scevgep41.4.4, align 1
  %scevgep28.4.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1185, i64 0, i64 0, i64 1
  %1192 = bitcast i8* %scevgep28.4.5 to [41 x [41 x i8]]*
  %scevgep41.4.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1186, i64 0, i64 1, i64 0
  %1193 = bitcast i8* %scevgep41.4.5 to [41 x [41 x i8]]*
  %call16.4.6 = call zeroext i8 (...) @rand()
  store i8 %call16.4.6, i8* %scevgep28.4.5, align 1
  %1194 = load i8, i8* %scevgep28.4.5, align 1
  %conv23.4.6 = zext i8 %1194 to i32
  %1195 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.6 = getelementptr i8, i8* %b, i64 11
  %1196 = load i8, i8* %scevgep34.4.6, align 1
  %call28.4.6 = call zeroext i8 @mult(i8 zeroext %1195, i8 zeroext %1196)
  %conv29.4.6 = zext i8 %call28.4.6 to i32
  %xor.4.6 = xor i32 %conv23.4.6, %conv29.4.6
  %scevgep35.4.6 = getelementptr i8, i8* %a, i64 11
  %1197 = load i8, i8* %scevgep35.4.6, align 1
  %1198 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.6 = call zeroext i8 @mult(i8 zeroext %1197, i8 zeroext %1198)
  %conv35.4.6 = zext i8 %call34.4.6 to i32
  %xor36.4.6 = xor i32 %xor.4.6, %conv35.4.6
  %conv37.4.6 = trunc i32 %xor36.4.6 to i8
  store i8 %conv37.4.6, i8* %scevgep41.4.5, align 1
  %scevgep28.4.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1192, i64 0, i64 0, i64 1
  %1199 = bitcast i8* %scevgep28.4.6 to [41 x [41 x i8]]*
  %scevgep41.4.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1193, i64 0, i64 1, i64 0
  %1200 = bitcast i8* %scevgep41.4.6 to [41 x [41 x i8]]*
  %call16.4.7 = call zeroext i8 (...) @rand()
  store i8 %call16.4.7, i8* %scevgep28.4.6, align 1
  %1201 = load i8, i8* %scevgep28.4.6, align 1
  %conv23.4.7 = zext i8 %1201 to i32
  %1202 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.7 = getelementptr i8, i8* %b, i64 12
  %1203 = load i8, i8* %scevgep34.4.7, align 1
  %call28.4.7 = call zeroext i8 @mult(i8 zeroext %1202, i8 zeroext %1203)
  %conv29.4.7 = zext i8 %call28.4.7 to i32
  %xor.4.7 = xor i32 %conv23.4.7, %conv29.4.7
  %scevgep35.4.7 = getelementptr i8, i8* %a, i64 12
  %1204 = load i8, i8* %scevgep35.4.7, align 1
  %1205 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.7 = call zeroext i8 @mult(i8 zeroext %1204, i8 zeroext %1205)
  %conv35.4.7 = zext i8 %call34.4.7 to i32
  %xor36.4.7 = xor i32 %xor.4.7, %conv35.4.7
  %conv37.4.7 = trunc i32 %xor36.4.7 to i8
  store i8 %conv37.4.7, i8* %scevgep41.4.6, align 1
  %scevgep28.4.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1199, i64 0, i64 0, i64 1
  %1206 = bitcast i8* %scevgep28.4.7 to [41 x [41 x i8]]*
  %scevgep41.4.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1200, i64 0, i64 1, i64 0
  %1207 = bitcast i8* %scevgep41.4.7 to [41 x [41 x i8]]*
  %call16.4.8 = call zeroext i8 (...) @rand()
  store i8 %call16.4.8, i8* %scevgep28.4.7, align 1
  %1208 = load i8, i8* %scevgep28.4.7, align 1
  %conv23.4.8 = zext i8 %1208 to i32
  %1209 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.8 = getelementptr i8, i8* %b, i64 13
  %1210 = load i8, i8* %scevgep34.4.8, align 1
  %call28.4.8 = call zeroext i8 @mult(i8 zeroext %1209, i8 zeroext %1210)
  %conv29.4.8 = zext i8 %call28.4.8 to i32
  %xor.4.8 = xor i32 %conv23.4.8, %conv29.4.8
  %scevgep35.4.8 = getelementptr i8, i8* %a, i64 13
  %1211 = load i8, i8* %scevgep35.4.8, align 1
  %1212 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.8 = call zeroext i8 @mult(i8 zeroext %1211, i8 zeroext %1212)
  %conv35.4.8 = zext i8 %call34.4.8 to i32
  %xor36.4.8 = xor i32 %xor.4.8, %conv35.4.8
  %conv37.4.8 = trunc i32 %xor36.4.8 to i8
  store i8 %conv37.4.8, i8* %scevgep41.4.7, align 1
  %scevgep28.4.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1206, i64 0, i64 0, i64 1
  %1213 = bitcast i8* %scevgep28.4.8 to [41 x [41 x i8]]*
  %scevgep41.4.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1207, i64 0, i64 1, i64 0
  %1214 = bitcast i8* %scevgep41.4.8 to [41 x [41 x i8]]*
  %call16.4.9 = call zeroext i8 (...) @rand()
  store i8 %call16.4.9, i8* %scevgep28.4.8, align 1
  %1215 = load i8, i8* %scevgep28.4.8, align 1
  %conv23.4.9 = zext i8 %1215 to i32
  %1216 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.9 = getelementptr i8, i8* %b, i64 14
  %1217 = load i8, i8* %scevgep34.4.9, align 1
  %call28.4.9 = call zeroext i8 @mult(i8 zeroext %1216, i8 zeroext %1217)
  %conv29.4.9 = zext i8 %call28.4.9 to i32
  %xor.4.9 = xor i32 %conv23.4.9, %conv29.4.9
  %scevgep35.4.9 = getelementptr i8, i8* %a, i64 14
  %1218 = load i8, i8* %scevgep35.4.9, align 1
  %1219 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.9 = call zeroext i8 @mult(i8 zeroext %1218, i8 zeroext %1219)
  %conv35.4.9 = zext i8 %call34.4.9 to i32
  %xor36.4.9 = xor i32 %xor.4.9, %conv35.4.9
  %conv37.4.9 = trunc i32 %xor36.4.9 to i8
  store i8 %conv37.4.9, i8* %scevgep41.4.8, align 1
  %scevgep28.4.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1213, i64 0, i64 0, i64 1
  %1220 = bitcast i8* %scevgep28.4.9 to [41 x [41 x i8]]*
  %scevgep41.4.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1214, i64 0, i64 1, i64 0
  %1221 = bitcast i8* %scevgep41.4.9 to [41 x [41 x i8]]*
  %call16.4.10 = call zeroext i8 (...) @rand()
  store i8 %call16.4.10, i8* %scevgep28.4.9, align 1
  %1222 = load i8, i8* %scevgep28.4.9, align 1
  %conv23.4.10 = zext i8 %1222 to i32
  %1223 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.10 = getelementptr i8, i8* %b, i64 15
  %1224 = load i8, i8* %scevgep34.4.10, align 1
  %call28.4.10 = call zeroext i8 @mult(i8 zeroext %1223, i8 zeroext %1224)
  %conv29.4.10 = zext i8 %call28.4.10 to i32
  %xor.4.10 = xor i32 %conv23.4.10, %conv29.4.10
  %scevgep35.4.10 = getelementptr i8, i8* %a, i64 15
  %1225 = load i8, i8* %scevgep35.4.10, align 1
  %1226 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.10 = call zeroext i8 @mult(i8 zeroext %1225, i8 zeroext %1226)
  %conv35.4.10 = zext i8 %call34.4.10 to i32
  %xor36.4.10 = xor i32 %xor.4.10, %conv35.4.10
  %conv37.4.10 = trunc i32 %xor36.4.10 to i8
  store i8 %conv37.4.10, i8* %scevgep41.4.9, align 1
  %scevgep28.4.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1220, i64 0, i64 0, i64 1
  %1227 = bitcast i8* %scevgep28.4.10 to [41 x [41 x i8]]*
  %scevgep41.4.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1221, i64 0, i64 1, i64 0
  %1228 = bitcast i8* %scevgep41.4.10 to [41 x [41 x i8]]*
  %call16.4.11 = call zeroext i8 (...) @rand()
  store i8 %call16.4.11, i8* %scevgep28.4.10, align 1
  %1229 = load i8, i8* %scevgep28.4.10, align 1
  %conv23.4.11 = zext i8 %1229 to i32
  %1230 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.11 = getelementptr i8, i8* %b, i64 16
  %1231 = load i8, i8* %scevgep34.4.11, align 1
  %call28.4.11 = call zeroext i8 @mult(i8 zeroext %1230, i8 zeroext %1231)
  %conv29.4.11 = zext i8 %call28.4.11 to i32
  %xor.4.11 = xor i32 %conv23.4.11, %conv29.4.11
  %scevgep35.4.11 = getelementptr i8, i8* %a, i64 16
  %1232 = load i8, i8* %scevgep35.4.11, align 1
  %1233 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.11 = call zeroext i8 @mult(i8 zeroext %1232, i8 zeroext %1233)
  %conv35.4.11 = zext i8 %call34.4.11 to i32
  %xor36.4.11 = xor i32 %xor.4.11, %conv35.4.11
  %conv37.4.11 = trunc i32 %xor36.4.11 to i8
  store i8 %conv37.4.11, i8* %scevgep41.4.10, align 1
  %scevgep28.4.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1227, i64 0, i64 0, i64 1
  %1234 = bitcast i8* %scevgep28.4.11 to [41 x [41 x i8]]*
  %scevgep41.4.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1228, i64 0, i64 1, i64 0
  %1235 = bitcast i8* %scevgep41.4.11 to [41 x [41 x i8]]*
  %call16.4.12 = call zeroext i8 (...) @rand()
  store i8 %call16.4.12, i8* %scevgep28.4.11, align 1
  %1236 = load i8, i8* %scevgep28.4.11, align 1
  %conv23.4.12 = zext i8 %1236 to i32
  %1237 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.12 = getelementptr i8, i8* %b, i64 17
  %1238 = load i8, i8* %scevgep34.4.12, align 1
  %call28.4.12 = call zeroext i8 @mult(i8 zeroext %1237, i8 zeroext %1238)
  %conv29.4.12 = zext i8 %call28.4.12 to i32
  %xor.4.12 = xor i32 %conv23.4.12, %conv29.4.12
  %scevgep35.4.12 = getelementptr i8, i8* %a, i64 17
  %1239 = load i8, i8* %scevgep35.4.12, align 1
  %1240 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.12 = call zeroext i8 @mult(i8 zeroext %1239, i8 zeroext %1240)
  %conv35.4.12 = zext i8 %call34.4.12 to i32
  %xor36.4.12 = xor i32 %xor.4.12, %conv35.4.12
  %conv37.4.12 = trunc i32 %xor36.4.12 to i8
  store i8 %conv37.4.12, i8* %scevgep41.4.11, align 1
  %scevgep28.4.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1234, i64 0, i64 0, i64 1
  %1241 = bitcast i8* %scevgep28.4.12 to [41 x [41 x i8]]*
  %scevgep41.4.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1235, i64 0, i64 1, i64 0
  %1242 = bitcast i8* %scevgep41.4.12 to [41 x [41 x i8]]*
  %call16.4.13 = call zeroext i8 (...) @rand()
  store i8 %call16.4.13, i8* %scevgep28.4.12, align 1
  %1243 = load i8, i8* %scevgep28.4.12, align 1
  %conv23.4.13 = zext i8 %1243 to i32
  %1244 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.13 = getelementptr i8, i8* %b, i64 18
  %1245 = load i8, i8* %scevgep34.4.13, align 1
  %call28.4.13 = call zeroext i8 @mult(i8 zeroext %1244, i8 zeroext %1245)
  %conv29.4.13 = zext i8 %call28.4.13 to i32
  %xor.4.13 = xor i32 %conv23.4.13, %conv29.4.13
  %scevgep35.4.13 = getelementptr i8, i8* %a, i64 18
  %1246 = load i8, i8* %scevgep35.4.13, align 1
  %1247 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.13 = call zeroext i8 @mult(i8 zeroext %1246, i8 zeroext %1247)
  %conv35.4.13 = zext i8 %call34.4.13 to i32
  %xor36.4.13 = xor i32 %xor.4.13, %conv35.4.13
  %conv37.4.13 = trunc i32 %xor36.4.13 to i8
  store i8 %conv37.4.13, i8* %scevgep41.4.12, align 1
  %scevgep28.4.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1241, i64 0, i64 0, i64 1
  %1248 = bitcast i8* %scevgep28.4.13 to [41 x [41 x i8]]*
  %scevgep41.4.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1242, i64 0, i64 1, i64 0
  %1249 = bitcast i8* %scevgep41.4.13 to [41 x [41 x i8]]*
  %call16.4.14 = call zeroext i8 (...) @rand()
  store i8 %call16.4.14, i8* %scevgep28.4.13, align 1
  %1250 = load i8, i8* %scevgep28.4.13, align 1
  %conv23.4.14 = zext i8 %1250 to i32
  %1251 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.14 = getelementptr i8, i8* %b, i64 19
  %1252 = load i8, i8* %scevgep34.4.14, align 1
  %call28.4.14 = call zeroext i8 @mult(i8 zeroext %1251, i8 zeroext %1252)
  %conv29.4.14 = zext i8 %call28.4.14 to i32
  %xor.4.14 = xor i32 %conv23.4.14, %conv29.4.14
  %scevgep35.4.14 = getelementptr i8, i8* %a, i64 19
  %1253 = load i8, i8* %scevgep35.4.14, align 1
  %1254 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.14 = call zeroext i8 @mult(i8 zeroext %1253, i8 zeroext %1254)
  %conv35.4.14 = zext i8 %call34.4.14 to i32
  %xor36.4.14 = xor i32 %xor.4.14, %conv35.4.14
  %conv37.4.14 = trunc i32 %xor36.4.14 to i8
  store i8 %conv37.4.14, i8* %scevgep41.4.13, align 1
  %scevgep28.4.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1248, i64 0, i64 0, i64 1
  %1255 = bitcast i8* %scevgep28.4.14 to [41 x [41 x i8]]*
  %scevgep41.4.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1249, i64 0, i64 1, i64 0
  %1256 = bitcast i8* %scevgep41.4.14 to [41 x [41 x i8]]*
  %call16.4.15 = call zeroext i8 (...) @rand()
  store i8 %call16.4.15, i8* %scevgep28.4.14, align 1
  %1257 = load i8, i8* %scevgep28.4.14, align 1
  %conv23.4.15 = zext i8 %1257 to i32
  %1258 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.15 = getelementptr i8, i8* %b, i64 20
  %1259 = load i8, i8* %scevgep34.4.15, align 1
  %call28.4.15 = call zeroext i8 @mult(i8 zeroext %1258, i8 zeroext %1259)
  %conv29.4.15 = zext i8 %call28.4.15 to i32
  %xor.4.15 = xor i32 %conv23.4.15, %conv29.4.15
  %scevgep35.4.15 = getelementptr i8, i8* %a, i64 20
  %1260 = load i8, i8* %scevgep35.4.15, align 1
  %1261 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.15 = call zeroext i8 @mult(i8 zeroext %1260, i8 zeroext %1261)
  %conv35.4.15 = zext i8 %call34.4.15 to i32
  %xor36.4.15 = xor i32 %xor.4.15, %conv35.4.15
  %conv37.4.15 = trunc i32 %xor36.4.15 to i8
  store i8 %conv37.4.15, i8* %scevgep41.4.14, align 1
  %scevgep28.4.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1255, i64 0, i64 0, i64 1
  %1262 = bitcast i8* %scevgep28.4.15 to [41 x [41 x i8]]*
  %scevgep41.4.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1256, i64 0, i64 1, i64 0
  %1263 = bitcast i8* %scevgep41.4.15 to [41 x [41 x i8]]*
  %call16.4.16 = call zeroext i8 (...) @rand()
  store i8 %call16.4.16, i8* %scevgep28.4.15, align 1
  %1264 = load i8, i8* %scevgep28.4.15, align 1
  %conv23.4.16 = zext i8 %1264 to i32
  %1265 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.16 = getelementptr i8, i8* %b, i64 21
  %1266 = load i8, i8* %scevgep34.4.16, align 1
  %call28.4.16 = call zeroext i8 @mult(i8 zeroext %1265, i8 zeroext %1266)
  %conv29.4.16 = zext i8 %call28.4.16 to i32
  %xor.4.16 = xor i32 %conv23.4.16, %conv29.4.16
  %scevgep35.4.16 = getelementptr i8, i8* %a, i64 21
  %1267 = load i8, i8* %scevgep35.4.16, align 1
  %1268 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.16 = call zeroext i8 @mult(i8 zeroext %1267, i8 zeroext %1268)
  %conv35.4.16 = zext i8 %call34.4.16 to i32
  %xor36.4.16 = xor i32 %xor.4.16, %conv35.4.16
  %conv37.4.16 = trunc i32 %xor36.4.16 to i8
  store i8 %conv37.4.16, i8* %scevgep41.4.15, align 1
  %scevgep28.4.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1262, i64 0, i64 0, i64 1
  %1269 = bitcast i8* %scevgep28.4.16 to [41 x [41 x i8]]*
  %scevgep41.4.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1263, i64 0, i64 1, i64 0
  %1270 = bitcast i8* %scevgep41.4.16 to [41 x [41 x i8]]*
  %call16.4.17 = call zeroext i8 (...) @rand()
  store i8 %call16.4.17, i8* %scevgep28.4.16, align 1
  %1271 = load i8, i8* %scevgep28.4.16, align 1
  %conv23.4.17 = zext i8 %1271 to i32
  %1272 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.17 = getelementptr i8, i8* %b, i64 22
  %1273 = load i8, i8* %scevgep34.4.17, align 1
  %call28.4.17 = call zeroext i8 @mult(i8 zeroext %1272, i8 zeroext %1273)
  %conv29.4.17 = zext i8 %call28.4.17 to i32
  %xor.4.17 = xor i32 %conv23.4.17, %conv29.4.17
  %scevgep35.4.17 = getelementptr i8, i8* %a, i64 22
  %1274 = load i8, i8* %scevgep35.4.17, align 1
  %1275 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.17 = call zeroext i8 @mult(i8 zeroext %1274, i8 zeroext %1275)
  %conv35.4.17 = zext i8 %call34.4.17 to i32
  %xor36.4.17 = xor i32 %xor.4.17, %conv35.4.17
  %conv37.4.17 = trunc i32 %xor36.4.17 to i8
  store i8 %conv37.4.17, i8* %scevgep41.4.16, align 1
  %scevgep28.4.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1269, i64 0, i64 0, i64 1
  %1276 = bitcast i8* %scevgep28.4.17 to [41 x [41 x i8]]*
  %scevgep41.4.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1270, i64 0, i64 1, i64 0
  %1277 = bitcast i8* %scevgep41.4.17 to [41 x [41 x i8]]*
  %call16.4.18 = call zeroext i8 (...) @rand()
  store i8 %call16.4.18, i8* %scevgep28.4.17, align 1
  %1278 = load i8, i8* %scevgep28.4.17, align 1
  %conv23.4.18 = zext i8 %1278 to i32
  %1279 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.18 = getelementptr i8, i8* %b, i64 23
  %1280 = load i8, i8* %scevgep34.4.18, align 1
  %call28.4.18 = call zeroext i8 @mult(i8 zeroext %1279, i8 zeroext %1280)
  %conv29.4.18 = zext i8 %call28.4.18 to i32
  %xor.4.18 = xor i32 %conv23.4.18, %conv29.4.18
  %scevgep35.4.18 = getelementptr i8, i8* %a, i64 23
  %1281 = load i8, i8* %scevgep35.4.18, align 1
  %1282 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.18 = call zeroext i8 @mult(i8 zeroext %1281, i8 zeroext %1282)
  %conv35.4.18 = zext i8 %call34.4.18 to i32
  %xor36.4.18 = xor i32 %xor.4.18, %conv35.4.18
  %conv37.4.18 = trunc i32 %xor36.4.18 to i8
  store i8 %conv37.4.18, i8* %scevgep41.4.17, align 1
  %scevgep28.4.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1276, i64 0, i64 0, i64 1
  %1283 = bitcast i8* %scevgep28.4.18 to [41 x [41 x i8]]*
  %scevgep41.4.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1277, i64 0, i64 1, i64 0
  %1284 = bitcast i8* %scevgep41.4.18 to [41 x [41 x i8]]*
  %call16.4.19 = call zeroext i8 (...) @rand()
  store i8 %call16.4.19, i8* %scevgep28.4.18, align 1
  %1285 = load i8, i8* %scevgep28.4.18, align 1
  %conv23.4.19 = zext i8 %1285 to i32
  %1286 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.19 = getelementptr i8, i8* %b, i64 24
  %1287 = load i8, i8* %scevgep34.4.19, align 1
  %call28.4.19 = call zeroext i8 @mult(i8 zeroext %1286, i8 zeroext %1287)
  %conv29.4.19 = zext i8 %call28.4.19 to i32
  %xor.4.19 = xor i32 %conv23.4.19, %conv29.4.19
  %scevgep35.4.19 = getelementptr i8, i8* %a, i64 24
  %1288 = load i8, i8* %scevgep35.4.19, align 1
  %1289 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.19 = call zeroext i8 @mult(i8 zeroext %1288, i8 zeroext %1289)
  %conv35.4.19 = zext i8 %call34.4.19 to i32
  %xor36.4.19 = xor i32 %xor.4.19, %conv35.4.19
  %conv37.4.19 = trunc i32 %xor36.4.19 to i8
  store i8 %conv37.4.19, i8* %scevgep41.4.18, align 1
  %scevgep28.4.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1283, i64 0, i64 0, i64 1
  %1290 = bitcast i8* %scevgep28.4.19 to [41 x [41 x i8]]*
  %scevgep41.4.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1284, i64 0, i64 1, i64 0
  %1291 = bitcast i8* %scevgep41.4.19 to [41 x [41 x i8]]*
  %call16.4.20 = call zeroext i8 (...) @rand()
  store i8 %call16.4.20, i8* %scevgep28.4.19, align 1
  %1292 = load i8, i8* %scevgep28.4.19, align 1
  %conv23.4.20 = zext i8 %1292 to i32
  %1293 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.20 = getelementptr i8, i8* %b, i64 25
  %1294 = load i8, i8* %scevgep34.4.20, align 1
  %call28.4.20 = call zeroext i8 @mult(i8 zeroext %1293, i8 zeroext %1294)
  %conv29.4.20 = zext i8 %call28.4.20 to i32
  %xor.4.20 = xor i32 %conv23.4.20, %conv29.4.20
  %scevgep35.4.20 = getelementptr i8, i8* %a, i64 25
  %1295 = load i8, i8* %scevgep35.4.20, align 1
  %1296 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.20 = call zeroext i8 @mult(i8 zeroext %1295, i8 zeroext %1296)
  %conv35.4.20 = zext i8 %call34.4.20 to i32
  %xor36.4.20 = xor i32 %xor.4.20, %conv35.4.20
  %conv37.4.20 = trunc i32 %xor36.4.20 to i8
  store i8 %conv37.4.20, i8* %scevgep41.4.19, align 1
  %scevgep28.4.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1290, i64 0, i64 0, i64 1
  %1297 = bitcast i8* %scevgep28.4.20 to [41 x [41 x i8]]*
  %scevgep41.4.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1291, i64 0, i64 1, i64 0
  %1298 = bitcast i8* %scevgep41.4.20 to [41 x [41 x i8]]*
  %call16.4.21 = call zeroext i8 (...) @rand()
  store i8 %call16.4.21, i8* %scevgep28.4.20, align 1
  %1299 = load i8, i8* %scevgep28.4.20, align 1
  %conv23.4.21 = zext i8 %1299 to i32
  %1300 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.21 = getelementptr i8, i8* %b, i64 26
  %1301 = load i8, i8* %scevgep34.4.21, align 1
  %call28.4.21 = call zeroext i8 @mult(i8 zeroext %1300, i8 zeroext %1301)
  %conv29.4.21 = zext i8 %call28.4.21 to i32
  %xor.4.21 = xor i32 %conv23.4.21, %conv29.4.21
  %scevgep35.4.21 = getelementptr i8, i8* %a, i64 26
  %1302 = load i8, i8* %scevgep35.4.21, align 1
  %1303 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.21 = call zeroext i8 @mult(i8 zeroext %1302, i8 zeroext %1303)
  %conv35.4.21 = zext i8 %call34.4.21 to i32
  %xor36.4.21 = xor i32 %xor.4.21, %conv35.4.21
  %conv37.4.21 = trunc i32 %xor36.4.21 to i8
  store i8 %conv37.4.21, i8* %scevgep41.4.20, align 1
  %scevgep28.4.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1297, i64 0, i64 0, i64 1
  %1304 = bitcast i8* %scevgep28.4.21 to [41 x [41 x i8]]*
  %scevgep41.4.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1298, i64 0, i64 1, i64 0
  %1305 = bitcast i8* %scevgep41.4.21 to [41 x [41 x i8]]*
  %call16.4.22 = call zeroext i8 (...) @rand()
  store i8 %call16.4.22, i8* %scevgep28.4.21, align 1
  %1306 = load i8, i8* %scevgep28.4.21, align 1
  %conv23.4.22 = zext i8 %1306 to i32
  %1307 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.22 = getelementptr i8, i8* %b, i64 27
  %1308 = load i8, i8* %scevgep34.4.22, align 1
  %call28.4.22 = call zeroext i8 @mult(i8 zeroext %1307, i8 zeroext %1308)
  %conv29.4.22 = zext i8 %call28.4.22 to i32
  %xor.4.22 = xor i32 %conv23.4.22, %conv29.4.22
  %scevgep35.4.22 = getelementptr i8, i8* %a, i64 27
  %1309 = load i8, i8* %scevgep35.4.22, align 1
  %1310 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.22 = call zeroext i8 @mult(i8 zeroext %1309, i8 zeroext %1310)
  %conv35.4.22 = zext i8 %call34.4.22 to i32
  %xor36.4.22 = xor i32 %xor.4.22, %conv35.4.22
  %conv37.4.22 = trunc i32 %xor36.4.22 to i8
  store i8 %conv37.4.22, i8* %scevgep41.4.21, align 1
  %scevgep28.4.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1304, i64 0, i64 0, i64 1
  %1311 = bitcast i8* %scevgep28.4.22 to [41 x [41 x i8]]*
  %scevgep41.4.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1305, i64 0, i64 1, i64 0
  %1312 = bitcast i8* %scevgep41.4.22 to [41 x [41 x i8]]*
  %call16.4.23 = call zeroext i8 (...) @rand()
  store i8 %call16.4.23, i8* %scevgep28.4.22, align 1
  %1313 = load i8, i8* %scevgep28.4.22, align 1
  %conv23.4.23 = zext i8 %1313 to i32
  %1314 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.23 = getelementptr i8, i8* %b, i64 28
  %1315 = load i8, i8* %scevgep34.4.23, align 1
  %call28.4.23 = call zeroext i8 @mult(i8 zeroext %1314, i8 zeroext %1315)
  %conv29.4.23 = zext i8 %call28.4.23 to i32
  %xor.4.23 = xor i32 %conv23.4.23, %conv29.4.23
  %scevgep35.4.23 = getelementptr i8, i8* %a, i64 28
  %1316 = load i8, i8* %scevgep35.4.23, align 1
  %1317 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.23 = call zeroext i8 @mult(i8 zeroext %1316, i8 zeroext %1317)
  %conv35.4.23 = zext i8 %call34.4.23 to i32
  %xor36.4.23 = xor i32 %xor.4.23, %conv35.4.23
  %conv37.4.23 = trunc i32 %xor36.4.23 to i8
  store i8 %conv37.4.23, i8* %scevgep41.4.22, align 1
  %scevgep28.4.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1311, i64 0, i64 0, i64 1
  %1318 = bitcast i8* %scevgep28.4.23 to [41 x [41 x i8]]*
  %scevgep41.4.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1312, i64 0, i64 1, i64 0
  %1319 = bitcast i8* %scevgep41.4.23 to [41 x [41 x i8]]*
  %call16.4.24 = call zeroext i8 (...) @rand()
  store i8 %call16.4.24, i8* %scevgep28.4.23, align 1
  %1320 = load i8, i8* %scevgep28.4.23, align 1
  %conv23.4.24 = zext i8 %1320 to i32
  %1321 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.24 = getelementptr i8, i8* %b, i64 29
  %1322 = load i8, i8* %scevgep34.4.24, align 1
  %call28.4.24 = call zeroext i8 @mult(i8 zeroext %1321, i8 zeroext %1322)
  %conv29.4.24 = zext i8 %call28.4.24 to i32
  %xor.4.24 = xor i32 %conv23.4.24, %conv29.4.24
  %scevgep35.4.24 = getelementptr i8, i8* %a, i64 29
  %1323 = load i8, i8* %scevgep35.4.24, align 1
  %1324 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.24 = call zeroext i8 @mult(i8 zeroext %1323, i8 zeroext %1324)
  %conv35.4.24 = zext i8 %call34.4.24 to i32
  %xor36.4.24 = xor i32 %xor.4.24, %conv35.4.24
  %conv37.4.24 = trunc i32 %xor36.4.24 to i8
  store i8 %conv37.4.24, i8* %scevgep41.4.23, align 1
  %scevgep28.4.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1318, i64 0, i64 0, i64 1
  %1325 = bitcast i8* %scevgep28.4.24 to [41 x [41 x i8]]*
  %scevgep41.4.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1319, i64 0, i64 1, i64 0
  %1326 = bitcast i8* %scevgep41.4.24 to [41 x [41 x i8]]*
  %call16.4.25 = call zeroext i8 (...) @rand()
  store i8 %call16.4.25, i8* %scevgep28.4.24, align 1
  %1327 = load i8, i8* %scevgep28.4.24, align 1
  %conv23.4.25 = zext i8 %1327 to i32
  %1328 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.25 = getelementptr i8, i8* %b, i64 30
  %1329 = load i8, i8* %scevgep34.4.25, align 1
  %call28.4.25 = call zeroext i8 @mult(i8 zeroext %1328, i8 zeroext %1329)
  %conv29.4.25 = zext i8 %call28.4.25 to i32
  %xor.4.25 = xor i32 %conv23.4.25, %conv29.4.25
  %scevgep35.4.25 = getelementptr i8, i8* %a, i64 30
  %1330 = load i8, i8* %scevgep35.4.25, align 1
  %1331 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.25 = call zeroext i8 @mult(i8 zeroext %1330, i8 zeroext %1331)
  %conv35.4.25 = zext i8 %call34.4.25 to i32
  %xor36.4.25 = xor i32 %xor.4.25, %conv35.4.25
  %conv37.4.25 = trunc i32 %xor36.4.25 to i8
  store i8 %conv37.4.25, i8* %scevgep41.4.24, align 1
  %scevgep28.4.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1325, i64 0, i64 0, i64 1
  %1332 = bitcast i8* %scevgep28.4.25 to [41 x [41 x i8]]*
  %scevgep41.4.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1326, i64 0, i64 1, i64 0
  %1333 = bitcast i8* %scevgep41.4.25 to [41 x [41 x i8]]*
  %call16.4.26 = call zeroext i8 (...) @rand()
  store i8 %call16.4.26, i8* %scevgep28.4.25, align 1
  %1334 = load i8, i8* %scevgep28.4.25, align 1
  %conv23.4.26 = zext i8 %1334 to i32
  %1335 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.26 = getelementptr i8, i8* %b, i64 31
  %1336 = load i8, i8* %scevgep34.4.26, align 1
  %call28.4.26 = call zeroext i8 @mult(i8 zeroext %1335, i8 zeroext %1336)
  %conv29.4.26 = zext i8 %call28.4.26 to i32
  %xor.4.26 = xor i32 %conv23.4.26, %conv29.4.26
  %scevgep35.4.26 = getelementptr i8, i8* %a, i64 31
  %1337 = load i8, i8* %scevgep35.4.26, align 1
  %1338 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.26 = call zeroext i8 @mult(i8 zeroext %1337, i8 zeroext %1338)
  %conv35.4.26 = zext i8 %call34.4.26 to i32
  %xor36.4.26 = xor i32 %xor.4.26, %conv35.4.26
  %conv37.4.26 = trunc i32 %xor36.4.26 to i8
  store i8 %conv37.4.26, i8* %scevgep41.4.25, align 1
  %scevgep28.4.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1332, i64 0, i64 0, i64 1
  %1339 = bitcast i8* %scevgep28.4.26 to [41 x [41 x i8]]*
  %scevgep41.4.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1333, i64 0, i64 1, i64 0
  %1340 = bitcast i8* %scevgep41.4.26 to [41 x [41 x i8]]*
  %call16.4.27 = call zeroext i8 (...) @rand()
  store i8 %call16.4.27, i8* %scevgep28.4.26, align 1
  %1341 = load i8, i8* %scevgep28.4.26, align 1
  %conv23.4.27 = zext i8 %1341 to i32
  %1342 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.27 = getelementptr i8, i8* %b, i64 32
  %1343 = load i8, i8* %scevgep34.4.27, align 1
  %call28.4.27 = call zeroext i8 @mult(i8 zeroext %1342, i8 zeroext %1343)
  %conv29.4.27 = zext i8 %call28.4.27 to i32
  %xor.4.27 = xor i32 %conv23.4.27, %conv29.4.27
  %scevgep35.4.27 = getelementptr i8, i8* %a, i64 32
  %1344 = load i8, i8* %scevgep35.4.27, align 1
  %1345 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.27 = call zeroext i8 @mult(i8 zeroext %1344, i8 zeroext %1345)
  %conv35.4.27 = zext i8 %call34.4.27 to i32
  %xor36.4.27 = xor i32 %xor.4.27, %conv35.4.27
  %conv37.4.27 = trunc i32 %xor36.4.27 to i8
  store i8 %conv37.4.27, i8* %scevgep41.4.26, align 1
  %scevgep28.4.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1339, i64 0, i64 0, i64 1
  %1346 = bitcast i8* %scevgep28.4.27 to [41 x [41 x i8]]*
  %scevgep41.4.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1340, i64 0, i64 1, i64 0
  %1347 = bitcast i8* %scevgep41.4.27 to [41 x [41 x i8]]*
  %call16.4.28 = call zeroext i8 (...) @rand()
  store i8 %call16.4.28, i8* %scevgep28.4.27, align 1
  %1348 = load i8, i8* %scevgep28.4.27, align 1
  %conv23.4.28 = zext i8 %1348 to i32
  %1349 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.28 = getelementptr i8, i8* %b, i64 33
  %1350 = load i8, i8* %scevgep34.4.28, align 1
  %call28.4.28 = call zeroext i8 @mult(i8 zeroext %1349, i8 zeroext %1350)
  %conv29.4.28 = zext i8 %call28.4.28 to i32
  %xor.4.28 = xor i32 %conv23.4.28, %conv29.4.28
  %scevgep35.4.28 = getelementptr i8, i8* %a, i64 33
  %1351 = load i8, i8* %scevgep35.4.28, align 1
  %1352 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.28 = call zeroext i8 @mult(i8 zeroext %1351, i8 zeroext %1352)
  %conv35.4.28 = zext i8 %call34.4.28 to i32
  %xor36.4.28 = xor i32 %xor.4.28, %conv35.4.28
  %conv37.4.28 = trunc i32 %xor36.4.28 to i8
  store i8 %conv37.4.28, i8* %scevgep41.4.27, align 1
  %scevgep28.4.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1346, i64 0, i64 0, i64 1
  %1353 = bitcast i8* %scevgep28.4.28 to [41 x [41 x i8]]*
  %scevgep41.4.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1347, i64 0, i64 1, i64 0
  %1354 = bitcast i8* %scevgep41.4.28 to [41 x [41 x i8]]*
  %call16.4.29 = call zeroext i8 (...) @rand()
  store i8 %call16.4.29, i8* %scevgep28.4.28, align 1
  %1355 = load i8, i8* %scevgep28.4.28, align 1
  %conv23.4.29 = zext i8 %1355 to i32
  %1356 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.29 = getelementptr i8, i8* %b, i64 34
  %1357 = load i8, i8* %scevgep34.4.29, align 1
  %call28.4.29 = call zeroext i8 @mult(i8 zeroext %1356, i8 zeroext %1357)
  %conv29.4.29 = zext i8 %call28.4.29 to i32
  %xor.4.29 = xor i32 %conv23.4.29, %conv29.4.29
  %scevgep35.4.29 = getelementptr i8, i8* %a, i64 34
  %1358 = load i8, i8* %scevgep35.4.29, align 1
  %1359 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.29 = call zeroext i8 @mult(i8 zeroext %1358, i8 zeroext %1359)
  %conv35.4.29 = zext i8 %call34.4.29 to i32
  %xor36.4.29 = xor i32 %xor.4.29, %conv35.4.29
  %conv37.4.29 = trunc i32 %xor36.4.29 to i8
  store i8 %conv37.4.29, i8* %scevgep41.4.28, align 1
  %scevgep28.4.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1353, i64 0, i64 0, i64 1
  %1360 = bitcast i8* %scevgep28.4.29 to [41 x [41 x i8]]*
  %scevgep41.4.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1354, i64 0, i64 1, i64 0
  %1361 = bitcast i8* %scevgep41.4.29 to [41 x [41 x i8]]*
  %call16.4.30 = call zeroext i8 (...) @rand()
  store i8 %call16.4.30, i8* %scevgep28.4.29, align 1
  %1362 = load i8, i8* %scevgep28.4.29, align 1
  %conv23.4.30 = zext i8 %1362 to i32
  %1363 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.30 = getelementptr i8, i8* %b, i64 35
  %1364 = load i8, i8* %scevgep34.4.30, align 1
  %call28.4.30 = call zeroext i8 @mult(i8 zeroext %1363, i8 zeroext %1364)
  %conv29.4.30 = zext i8 %call28.4.30 to i32
  %xor.4.30 = xor i32 %conv23.4.30, %conv29.4.30
  %scevgep35.4.30 = getelementptr i8, i8* %a, i64 35
  %1365 = load i8, i8* %scevgep35.4.30, align 1
  %1366 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.30 = call zeroext i8 @mult(i8 zeroext %1365, i8 zeroext %1366)
  %conv35.4.30 = zext i8 %call34.4.30 to i32
  %xor36.4.30 = xor i32 %xor.4.30, %conv35.4.30
  %conv37.4.30 = trunc i32 %xor36.4.30 to i8
  store i8 %conv37.4.30, i8* %scevgep41.4.29, align 1
  %scevgep28.4.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1360, i64 0, i64 0, i64 1
  %1367 = bitcast i8* %scevgep28.4.30 to [41 x [41 x i8]]*
  %scevgep41.4.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1361, i64 0, i64 1, i64 0
  %1368 = bitcast i8* %scevgep41.4.30 to [41 x [41 x i8]]*
  %call16.4.31 = call zeroext i8 (...) @rand()
  store i8 %call16.4.31, i8* %scevgep28.4.30, align 1
  %1369 = load i8, i8* %scevgep28.4.30, align 1
  %conv23.4.31 = zext i8 %1369 to i32
  %1370 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.31 = getelementptr i8, i8* %b, i64 36
  %1371 = load i8, i8* %scevgep34.4.31, align 1
  %call28.4.31 = call zeroext i8 @mult(i8 zeroext %1370, i8 zeroext %1371)
  %conv29.4.31 = zext i8 %call28.4.31 to i32
  %xor.4.31 = xor i32 %conv23.4.31, %conv29.4.31
  %scevgep35.4.31 = getelementptr i8, i8* %a, i64 36
  %1372 = load i8, i8* %scevgep35.4.31, align 1
  %1373 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.31 = call zeroext i8 @mult(i8 zeroext %1372, i8 zeroext %1373)
  %conv35.4.31 = zext i8 %call34.4.31 to i32
  %xor36.4.31 = xor i32 %xor.4.31, %conv35.4.31
  %conv37.4.31 = trunc i32 %xor36.4.31 to i8
  store i8 %conv37.4.31, i8* %scevgep41.4.30, align 1
  %scevgep28.4.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1367, i64 0, i64 0, i64 1
  %1374 = bitcast i8* %scevgep28.4.31 to [41 x [41 x i8]]*
  %scevgep41.4.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1368, i64 0, i64 1, i64 0
  %1375 = bitcast i8* %scevgep41.4.31 to [41 x [41 x i8]]*
  %call16.4.32 = call zeroext i8 (...) @rand()
  store i8 %call16.4.32, i8* %scevgep28.4.31, align 1
  %1376 = load i8, i8* %scevgep28.4.31, align 1
  %conv23.4.32 = zext i8 %1376 to i32
  %1377 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.32 = getelementptr i8, i8* %b, i64 37
  %1378 = load i8, i8* %scevgep34.4.32, align 1
  %call28.4.32 = call zeroext i8 @mult(i8 zeroext %1377, i8 zeroext %1378)
  %conv29.4.32 = zext i8 %call28.4.32 to i32
  %xor.4.32 = xor i32 %conv23.4.32, %conv29.4.32
  %scevgep35.4.32 = getelementptr i8, i8* %a, i64 37
  %1379 = load i8, i8* %scevgep35.4.32, align 1
  %1380 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.32 = call zeroext i8 @mult(i8 zeroext %1379, i8 zeroext %1380)
  %conv35.4.32 = zext i8 %call34.4.32 to i32
  %xor36.4.32 = xor i32 %xor.4.32, %conv35.4.32
  %conv37.4.32 = trunc i32 %xor36.4.32 to i8
  store i8 %conv37.4.32, i8* %scevgep41.4.31, align 1
  %scevgep28.4.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1374, i64 0, i64 0, i64 1
  %1381 = bitcast i8* %scevgep28.4.32 to [41 x [41 x i8]]*
  %scevgep41.4.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1375, i64 0, i64 1, i64 0
  %1382 = bitcast i8* %scevgep41.4.32 to [41 x [41 x i8]]*
  %call16.4.33 = call zeroext i8 (...) @rand()
  store i8 %call16.4.33, i8* %scevgep28.4.32, align 1
  %1383 = load i8, i8* %scevgep28.4.32, align 1
  %conv23.4.33 = zext i8 %1383 to i32
  %1384 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.33 = getelementptr i8, i8* %b, i64 38
  %1385 = load i8, i8* %scevgep34.4.33, align 1
  %call28.4.33 = call zeroext i8 @mult(i8 zeroext %1384, i8 zeroext %1385)
  %conv29.4.33 = zext i8 %call28.4.33 to i32
  %xor.4.33 = xor i32 %conv23.4.33, %conv29.4.33
  %scevgep35.4.33 = getelementptr i8, i8* %a, i64 38
  %1386 = load i8, i8* %scevgep35.4.33, align 1
  %1387 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.33 = call zeroext i8 @mult(i8 zeroext %1386, i8 zeroext %1387)
  %conv35.4.33 = zext i8 %call34.4.33 to i32
  %xor36.4.33 = xor i32 %xor.4.33, %conv35.4.33
  %conv37.4.33 = trunc i32 %xor36.4.33 to i8
  store i8 %conv37.4.33, i8* %scevgep41.4.32, align 1
  %scevgep28.4.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1381, i64 0, i64 0, i64 1
  %1388 = bitcast i8* %scevgep28.4.33 to [41 x [41 x i8]]*
  %scevgep41.4.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1382, i64 0, i64 1, i64 0
  %1389 = bitcast i8* %scevgep41.4.33 to [41 x [41 x i8]]*
  %call16.4.34 = call zeroext i8 (...) @rand()
  store i8 %call16.4.34, i8* %scevgep28.4.33, align 1
  %1390 = load i8, i8* %scevgep28.4.33, align 1
  %conv23.4.34 = zext i8 %1390 to i32
  %1391 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.34 = getelementptr i8, i8* %b, i64 39
  %1392 = load i8, i8* %scevgep34.4.34, align 1
  %call28.4.34 = call zeroext i8 @mult(i8 zeroext %1391, i8 zeroext %1392)
  %conv29.4.34 = zext i8 %call28.4.34 to i32
  %xor.4.34 = xor i32 %conv23.4.34, %conv29.4.34
  %scevgep35.4.34 = getelementptr i8, i8* %a, i64 39
  %1393 = load i8, i8* %scevgep35.4.34, align 1
  %1394 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.34 = call zeroext i8 @mult(i8 zeroext %1393, i8 zeroext %1394)
  %conv35.4.34 = zext i8 %call34.4.34 to i32
  %xor36.4.34 = xor i32 %xor.4.34, %conv35.4.34
  %conv37.4.34 = trunc i32 %xor36.4.34 to i8
  store i8 %conv37.4.34, i8* %scevgep41.4.33, align 1
  %scevgep28.4.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1388, i64 0, i64 0, i64 1
  %scevgep41.4.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1389, i64 0, i64 1, i64 0
  %call16.4.35 = call zeroext i8 (...) @rand()
  store i8 %call16.4.35, i8* %scevgep28.4.34, align 1
  %1395 = load i8, i8* %scevgep28.4.34, align 1
  %conv23.4.35 = zext i8 %1395 to i32
  %1396 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.35 = getelementptr i8, i8* %b, i64 40
  %1397 = load i8, i8* %scevgep34.4.35, align 1
  %call28.4.35 = call zeroext i8 @mult(i8 zeroext %1396, i8 zeroext %1397)
  %conv29.4.35 = zext i8 %call28.4.35 to i32
  %xor.4.35 = xor i32 %conv23.4.35, %conv29.4.35
  %scevgep35.4.35 = getelementptr i8, i8* %a, i64 40
  %1398 = load i8, i8* %scevgep35.4.35, align 1
  %1399 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.35 = call zeroext i8 @mult(i8 zeroext %1398, i8 zeroext %1399)
  %conv35.4.35 = zext i8 %call34.4.35 to i32
  %xor36.4.35 = xor i32 %xor.4.35, %conv35.4.35
  %conv37.4.35 = trunc i32 %xor36.4.35 to i8
  store i8 %conv37.4.35, i8* %scevgep41.4.34, align 1
  %scevgep26.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1150, i64 0, i64 1, i64 1
  %1400 = bitcast i8* %scevgep26.4 to [41 x [41 x i8]]*
  %scevgep39.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1151, i64 0, i64 1, i64 1
  %1401 = bitcast i8* %scevgep39.4 to [41 x [41 x i8]]*
  %arrayidx25.5 = getelementptr inbounds i8, i8* %a, i64 5
  %arrayidx33.5 = getelementptr inbounds i8, i8* %b, i64 5
  %call16.5 = call zeroext i8 (...) @rand()
  store i8 %call16.5, i8* %scevgep26.4, align 1
  %1402 = load i8, i8* %scevgep26.4, align 1
  %conv23.5 = zext i8 %1402 to i32
  %1403 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5 = getelementptr i8, i8* %b, i64 6
  %1404 = load i8, i8* %scevgep34.5, align 1
  %call28.5 = call zeroext i8 @mult(i8 zeroext %1403, i8 zeroext %1404)
  %conv29.5 = zext i8 %call28.5 to i32
  %xor.5 = xor i32 %conv23.5, %conv29.5
  %scevgep35.5 = getelementptr i8, i8* %a, i64 6
  %1405 = load i8, i8* %scevgep35.5, align 1
  %1406 = load i8, i8* %arrayidx33.5, align 1
  %call34.5 = call zeroext i8 @mult(i8 zeroext %1405, i8 zeroext %1406)
  %conv35.5 = zext i8 %call34.5 to i32
  %xor36.5 = xor i32 %xor.5, %conv35.5
  %conv37.5 = trunc i32 %xor36.5 to i8
  store i8 %conv37.5, i8* %scevgep39.4, align 1
  %scevgep28.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1400, i64 0, i64 0, i64 1
  %1407 = bitcast i8* %scevgep28.5 to [41 x [41 x i8]]*
  %scevgep41.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1401, i64 0, i64 1, i64 0
  %1408 = bitcast i8* %scevgep41.5 to [41 x [41 x i8]]*
  %call16.5.1 = call zeroext i8 (...) @rand()
  store i8 %call16.5.1, i8* %scevgep28.5, align 1
  %1409 = load i8, i8* %scevgep28.5, align 1
  %conv23.5.1 = zext i8 %1409 to i32
  %1410 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.1 = getelementptr i8, i8* %b, i64 7
  %1411 = load i8, i8* %scevgep34.5.1, align 1
  %call28.5.1 = call zeroext i8 @mult(i8 zeroext %1410, i8 zeroext %1411)
  %conv29.5.1 = zext i8 %call28.5.1 to i32
  %xor.5.1 = xor i32 %conv23.5.1, %conv29.5.1
  %scevgep35.5.1 = getelementptr i8, i8* %a, i64 7
  %1412 = load i8, i8* %scevgep35.5.1, align 1
  %1413 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.1 = call zeroext i8 @mult(i8 zeroext %1412, i8 zeroext %1413)
  %conv35.5.1 = zext i8 %call34.5.1 to i32
  %xor36.5.1 = xor i32 %xor.5.1, %conv35.5.1
  %conv37.5.1 = trunc i32 %xor36.5.1 to i8
  store i8 %conv37.5.1, i8* %scevgep41.5, align 1
  %scevgep28.5.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1407, i64 0, i64 0, i64 1
  %1414 = bitcast i8* %scevgep28.5.1 to [41 x [41 x i8]]*
  %scevgep41.5.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1408, i64 0, i64 1, i64 0
  %1415 = bitcast i8* %scevgep41.5.1 to [41 x [41 x i8]]*
  %call16.5.2 = call zeroext i8 (...) @rand()
  store i8 %call16.5.2, i8* %scevgep28.5.1, align 1
  %1416 = load i8, i8* %scevgep28.5.1, align 1
  %conv23.5.2 = zext i8 %1416 to i32
  %1417 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.2 = getelementptr i8, i8* %b, i64 8
  %1418 = load i8, i8* %scevgep34.5.2, align 1
  %call28.5.2 = call zeroext i8 @mult(i8 zeroext %1417, i8 zeroext %1418)
  %conv29.5.2 = zext i8 %call28.5.2 to i32
  %xor.5.2 = xor i32 %conv23.5.2, %conv29.5.2
  %scevgep35.5.2 = getelementptr i8, i8* %a, i64 8
  %1419 = load i8, i8* %scevgep35.5.2, align 1
  %1420 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.2 = call zeroext i8 @mult(i8 zeroext %1419, i8 zeroext %1420)
  %conv35.5.2 = zext i8 %call34.5.2 to i32
  %xor36.5.2 = xor i32 %xor.5.2, %conv35.5.2
  %conv37.5.2 = trunc i32 %xor36.5.2 to i8
  store i8 %conv37.5.2, i8* %scevgep41.5.1, align 1
  %scevgep28.5.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1414, i64 0, i64 0, i64 1
  %1421 = bitcast i8* %scevgep28.5.2 to [41 x [41 x i8]]*
  %scevgep41.5.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1415, i64 0, i64 1, i64 0
  %1422 = bitcast i8* %scevgep41.5.2 to [41 x [41 x i8]]*
  %call16.5.3 = call zeroext i8 (...) @rand()
  store i8 %call16.5.3, i8* %scevgep28.5.2, align 1
  %1423 = load i8, i8* %scevgep28.5.2, align 1
  %conv23.5.3 = zext i8 %1423 to i32
  %1424 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.3 = getelementptr i8, i8* %b, i64 9
  %1425 = load i8, i8* %scevgep34.5.3, align 1
  %call28.5.3 = call zeroext i8 @mult(i8 zeroext %1424, i8 zeroext %1425)
  %conv29.5.3 = zext i8 %call28.5.3 to i32
  %xor.5.3 = xor i32 %conv23.5.3, %conv29.5.3
  %scevgep35.5.3 = getelementptr i8, i8* %a, i64 9
  %1426 = load i8, i8* %scevgep35.5.3, align 1
  %1427 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.3 = call zeroext i8 @mult(i8 zeroext %1426, i8 zeroext %1427)
  %conv35.5.3 = zext i8 %call34.5.3 to i32
  %xor36.5.3 = xor i32 %xor.5.3, %conv35.5.3
  %conv37.5.3 = trunc i32 %xor36.5.3 to i8
  store i8 %conv37.5.3, i8* %scevgep41.5.2, align 1
  %scevgep28.5.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1421, i64 0, i64 0, i64 1
  %1428 = bitcast i8* %scevgep28.5.3 to [41 x [41 x i8]]*
  %scevgep41.5.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1422, i64 0, i64 1, i64 0
  %1429 = bitcast i8* %scevgep41.5.3 to [41 x [41 x i8]]*
  %call16.5.4 = call zeroext i8 (...) @rand()
  store i8 %call16.5.4, i8* %scevgep28.5.3, align 1
  %1430 = load i8, i8* %scevgep28.5.3, align 1
  %conv23.5.4 = zext i8 %1430 to i32
  %1431 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.4 = getelementptr i8, i8* %b, i64 10
  %1432 = load i8, i8* %scevgep34.5.4, align 1
  %call28.5.4 = call zeroext i8 @mult(i8 zeroext %1431, i8 zeroext %1432)
  %conv29.5.4 = zext i8 %call28.5.4 to i32
  %xor.5.4 = xor i32 %conv23.5.4, %conv29.5.4
  %scevgep35.5.4 = getelementptr i8, i8* %a, i64 10
  %1433 = load i8, i8* %scevgep35.5.4, align 1
  %1434 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.4 = call zeroext i8 @mult(i8 zeroext %1433, i8 zeroext %1434)
  %conv35.5.4 = zext i8 %call34.5.4 to i32
  %xor36.5.4 = xor i32 %xor.5.4, %conv35.5.4
  %conv37.5.4 = trunc i32 %xor36.5.4 to i8
  store i8 %conv37.5.4, i8* %scevgep41.5.3, align 1
  %scevgep28.5.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1428, i64 0, i64 0, i64 1
  %1435 = bitcast i8* %scevgep28.5.4 to [41 x [41 x i8]]*
  %scevgep41.5.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1429, i64 0, i64 1, i64 0
  %1436 = bitcast i8* %scevgep41.5.4 to [41 x [41 x i8]]*
  %call16.5.5 = call zeroext i8 (...) @rand()
  store i8 %call16.5.5, i8* %scevgep28.5.4, align 1
  %1437 = load i8, i8* %scevgep28.5.4, align 1
  %conv23.5.5 = zext i8 %1437 to i32
  %1438 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.5 = getelementptr i8, i8* %b, i64 11
  %1439 = load i8, i8* %scevgep34.5.5, align 1
  %call28.5.5 = call zeroext i8 @mult(i8 zeroext %1438, i8 zeroext %1439)
  %conv29.5.5 = zext i8 %call28.5.5 to i32
  %xor.5.5 = xor i32 %conv23.5.5, %conv29.5.5
  %scevgep35.5.5 = getelementptr i8, i8* %a, i64 11
  %1440 = load i8, i8* %scevgep35.5.5, align 1
  %1441 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.5 = call zeroext i8 @mult(i8 zeroext %1440, i8 zeroext %1441)
  %conv35.5.5 = zext i8 %call34.5.5 to i32
  %xor36.5.5 = xor i32 %xor.5.5, %conv35.5.5
  %conv37.5.5 = trunc i32 %xor36.5.5 to i8
  store i8 %conv37.5.5, i8* %scevgep41.5.4, align 1
  %scevgep28.5.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1435, i64 0, i64 0, i64 1
  %1442 = bitcast i8* %scevgep28.5.5 to [41 x [41 x i8]]*
  %scevgep41.5.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1436, i64 0, i64 1, i64 0
  %1443 = bitcast i8* %scevgep41.5.5 to [41 x [41 x i8]]*
  %call16.5.6 = call zeroext i8 (...) @rand()
  store i8 %call16.5.6, i8* %scevgep28.5.5, align 1
  %1444 = load i8, i8* %scevgep28.5.5, align 1
  %conv23.5.6 = zext i8 %1444 to i32
  %1445 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.6 = getelementptr i8, i8* %b, i64 12
  %1446 = load i8, i8* %scevgep34.5.6, align 1
  %call28.5.6 = call zeroext i8 @mult(i8 zeroext %1445, i8 zeroext %1446)
  %conv29.5.6 = zext i8 %call28.5.6 to i32
  %xor.5.6 = xor i32 %conv23.5.6, %conv29.5.6
  %scevgep35.5.6 = getelementptr i8, i8* %a, i64 12
  %1447 = load i8, i8* %scevgep35.5.6, align 1
  %1448 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.6 = call zeroext i8 @mult(i8 zeroext %1447, i8 zeroext %1448)
  %conv35.5.6 = zext i8 %call34.5.6 to i32
  %xor36.5.6 = xor i32 %xor.5.6, %conv35.5.6
  %conv37.5.6 = trunc i32 %xor36.5.6 to i8
  store i8 %conv37.5.6, i8* %scevgep41.5.5, align 1
  %scevgep28.5.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1442, i64 0, i64 0, i64 1
  %1449 = bitcast i8* %scevgep28.5.6 to [41 x [41 x i8]]*
  %scevgep41.5.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1443, i64 0, i64 1, i64 0
  %1450 = bitcast i8* %scevgep41.5.6 to [41 x [41 x i8]]*
  %call16.5.7 = call zeroext i8 (...) @rand()
  store i8 %call16.5.7, i8* %scevgep28.5.6, align 1
  %1451 = load i8, i8* %scevgep28.5.6, align 1
  %conv23.5.7 = zext i8 %1451 to i32
  %1452 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.7 = getelementptr i8, i8* %b, i64 13
  %1453 = load i8, i8* %scevgep34.5.7, align 1
  %call28.5.7 = call zeroext i8 @mult(i8 zeroext %1452, i8 zeroext %1453)
  %conv29.5.7 = zext i8 %call28.5.7 to i32
  %xor.5.7 = xor i32 %conv23.5.7, %conv29.5.7
  %scevgep35.5.7 = getelementptr i8, i8* %a, i64 13
  %1454 = load i8, i8* %scevgep35.5.7, align 1
  %1455 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.7 = call zeroext i8 @mult(i8 zeroext %1454, i8 zeroext %1455)
  %conv35.5.7 = zext i8 %call34.5.7 to i32
  %xor36.5.7 = xor i32 %xor.5.7, %conv35.5.7
  %conv37.5.7 = trunc i32 %xor36.5.7 to i8
  store i8 %conv37.5.7, i8* %scevgep41.5.6, align 1
  %scevgep28.5.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1449, i64 0, i64 0, i64 1
  %1456 = bitcast i8* %scevgep28.5.7 to [41 x [41 x i8]]*
  %scevgep41.5.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1450, i64 0, i64 1, i64 0
  %1457 = bitcast i8* %scevgep41.5.7 to [41 x [41 x i8]]*
  %call16.5.8 = call zeroext i8 (...) @rand()
  store i8 %call16.5.8, i8* %scevgep28.5.7, align 1
  %1458 = load i8, i8* %scevgep28.5.7, align 1
  %conv23.5.8 = zext i8 %1458 to i32
  %1459 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.8 = getelementptr i8, i8* %b, i64 14
  %1460 = load i8, i8* %scevgep34.5.8, align 1
  %call28.5.8 = call zeroext i8 @mult(i8 zeroext %1459, i8 zeroext %1460)
  %conv29.5.8 = zext i8 %call28.5.8 to i32
  %xor.5.8 = xor i32 %conv23.5.8, %conv29.5.8
  %scevgep35.5.8 = getelementptr i8, i8* %a, i64 14
  %1461 = load i8, i8* %scevgep35.5.8, align 1
  %1462 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.8 = call zeroext i8 @mult(i8 zeroext %1461, i8 zeroext %1462)
  %conv35.5.8 = zext i8 %call34.5.8 to i32
  %xor36.5.8 = xor i32 %xor.5.8, %conv35.5.8
  %conv37.5.8 = trunc i32 %xor36.5.8 to i8
  store i8 %conv37.5.8, i8* %scevgep41.5.7, align 1
  %scevgep28.5.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1456, i64 0, i64 0, i64 1
  %1463 = bitcast i8* %scevgep28.5.8 to [41 x [41 x i8]]*
  %scevgep41.5.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1457, i64 0, i64 1, i64 0
  %1464 = bitcast i8* %scevgep41.5.8 to [41 x [41 x i8]]*
  %call16.5.9 = call zeroext i8 (...) @rand()
  store i8 %call16.5.9, i8* %scevgep28.5.8, align 1
  %1465 = load i8, i8* %scevgep28.5.8, align 1
  %conv23.5.9 = zext i8 %1465 to i32
  %1466 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.9 = getelementptr i8, i8* %b, i64 15
  %1467 = load i8, i8* %scevgep34.5.9, align 1
  %call28.5.9 = call zeroext i8 @mult(i8 zeroext %1466, i8 zeroext %1467)
  %conv29.5.9 = zext i8 %call28.5.9 to i32
  %xor.5.9 = xor i32 %conv23.5.9, %conv29.5.9
  %scevgep35.5.9 = getelementptr i8, i8* %a, i64 15
  %1468 = load i8, i8* %scevgep35.5.9, align 1
  %1469 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.9 = call zeroext i8 @mult(i8 zeroext %1468, i8 zeroext %1469)
  %conv35.5.9 = zext i8 %call34.5.9 to i32
  %xor36.5.9 = xor i32 %xor.5.9, %conv35.5.9
  %conv37.5.9 = trunc i32 %xor36.5.9 to i8
  store i8 %conv37.5.9, i8* %scevgep41.5.8, align 1
  %scevgep28.5.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1463, i64 0, i64 0, i64 1
  %1470 = bitcast i8* %scevgep28.5.9 to [41 x [41 x i8]]*
  %scevgep41.5.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1464, i64 0, i64 1, i64 0
  %1471 = bitcast i8* %scevgep41.5.9 to [41 x [41 x i8]]*
  %call16.5.10 = call zeroext i8 (...) @rand()
  store i8 %call16.5.10, i8* %scevgep28.5.9, align 1
  %1472 = load i8, i8* %scevgep28.5.9, align 1
  %conv23.5.10 = zext i8 %1472 to i32
  %1473 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.10 = getelementptr i8, i8* %b, i64 16
  %1474 = load i8, i8* %scevgep34.5.10, align 1
  %call28.5.10 = call zeroext i8 @mult(i8 zeroext %1473, i8 zeroext %1474)
  %conv29.5.10 = zext i8 %call28.5.10 to i32
  %xor.5.10 = xor i32 %conv23.5.10, %conv29.5.10
  %scevgep35.5.10 = getelementptr i8, i8* %a, i64 16
  %1475 = load i8, i8* %scevgep35.5.10, align 1
  %1476 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.10 = call zeroext i8 @mult(i8 zeroext %1475, i8 zeroext %1476)
  %conv35.5.10 = zext i8 %call34.5.10 to i32
  %xor36.5.10 = xor i32 %xor.5.10, %conv35.5.10
  %conv37.5.10 = trunc i32 %xor36.5.10 to i8
  store i8 %conv37.5.10, i8* %scevgep41.5.9, align 1
  %scevgep28.5.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1470, i64 0, i64 0, i64 1
  %1477 = bitcast i8* %scevgep28.5.10 to [41 x [41 x i8]]*
  %scevgep41.5.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1471, i64 0, i64 1, i64 0
  %1478 = bitcast i8* %scevgep41.5.10 to [41 x [41 x i8]]*
  %call16.5.11 = call zeroext i8 (...) @rand()
  store i8 %call16.5.11, i8* %scevgep28.5.10, align 1
  %1479 = load i8, i8* %scevgep28.5.10, align 1
  %conv23.5.11 = zext i8 %1479 to i32
  %1480 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.11 = getelementptr i8, i8* %b, i64 17
  %1481 = load i8, i8* %scevgep34.5.11, align 1
  %call28.5.11 = call zeroext i8 @mult(i8 zeroext %1480, i8 zeroext %1481)
  %conv29.5.11 = zext i8 %call28.5.11 to i32
  %xor.5.11 = xor i32 %conv23.5.11, %conv29.5.11
  %scevgep35.5.11 = getelementptr i8, i8* %a, i64 17
  %1482 = load i8, i8* %scevgep35.5.11, align 1
  %1483 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.11 = call zeroext i8 @mult(i8 zeroext %1482, i8 zeroext %1483)
  %conv35.5.11 = zext i8 %call34.5.11 to i32
  %xor36.5.11 = xor i32 %xor.5.11, %conv35.5.11
  %conv37.5.11 = trunc i32 %xor36.5.11 to i8
  store i8 %conv37.5.11, i8* %scevgep41.5.10, align 1
  %scevgep28.5.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1477, i64 0, i64 0, i64 1
  %1484 = bitcast i8* %scevgep28.5.11 to [41 x [41 x i8]]*
  %scevgep41.5.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1478, i64 0, i64 1, i64 0
  %1485 = bitcast i8* %scevgep41.5.11 to [41 x [41 x i8]]*
  %call16.5.12 = call zeroext i8 (...) @rand()
  store i8 %call16.5.12, i8* %scevgep28.5.11, align 1
  %1486 = load i8, i8* %scevgep28.5.11, align 1
  %conv23.5.12 = zext i8 %1486 to i32
  %1487 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.12 = getelementptr i8, i8* %b, i64 18
  %1488 = load i8, i8* %scevgep34.5.12, align 1
  %call28.5.12 = call zeroext i8 @mult(i8 zeroext %1487, i8 zeroext %1488)
  %conv29.5.12 = zext i8 %call28.5.12 to i32
  %xor.5.12 = xor i32 %conv23.5.12, %conv29.5.12
  %scevgep35.5.12 = getelementptr i8, i8* %a, i64 18
  %1489 = load i8, i8* %scevgep35.5.12, align 1
  %1490 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.12 = call zeroext i8 @mult(i8 zeroext %1489, i8 zeroext %1490)
  %conv35.5.12 = zext i8 %call34.5.12 to i32
  %xor36.5.12 = xor i32 %xor.5.12, %conv35.5.12
  %conv37.5.12 = trunc i32 %xor36.5.12 to i8
  store i8 %conv37.5.12, i8* %scevgep41.5.11, align 1
  %scevgep28.5.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1484, i64 0, i64 0, i64 1
  %1491 = bitcast i8* %scevgep28.5.12 to [41 x [41 x i8]]*
  %scevgep41.5.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1485, i64 0, i64 1, i64 0
  %1492 = bitcast i8* %scevgep41.5.12 to [41 x [41 x i8]]*
  %call16.5.13 = call zeroext i8 (...) @rand()
  store i8 %call16.5.13, i8* %scevgep28.5.12, align 1
  %1493 = load i8, i8* %scevgep28.5.12, align 1
  %conv23.5.13 = zext i8 %1493 to i32
  %1494 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.13 = getelementptr i8, i8* %b, i64 19
  %1495 = load i8, i8* %scevgep34.5.13, align 1
  %call28.5.13 = call zeroext i8 @mult(i8 zeroext %1494, i8 zeroext %1495)
  %conv29.5.13 = zext i8 %call28.5.13 to i32
  %xor.5.13 = xor i32 %conv23.5.13, %conv29.5.13
  %scevgep35.5.13 = getelementptr i8, i8* %a, i64 19
  %1496 = load i8, i8* %scevgep35.5.13, align 1
  %1497 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.13 = call zeroext i8 @mult(i8 zeroext %1496, i8 zeroext %1497)
  %conv35.5.13 = zext i8 %call34.5.13 to i32
  %xor36.5.13 = xor i32 %xor.5.13, %conv35.5.13
  %conv37.5.13 = trunc i32 %xor36.5.13 to i8
  store i8 %conv37.5.13, i8* %scevgep41.5.12, align 1
  %scevgep28.5.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1491, i64 0, i64 0, i64 1
  %1498 = bitcast i8* %scevgep28.5.13 to [41 x [41 x i8]]*
  %scevgep41.5.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1492, i64 0, i64 1, i64 0
  %1499 = bitcast i8* %scevgep41.5.13 to [41 x [41 x i8]]*
  %call16.5.14 = call zeroext i8 (...) @rand()
  store i8 %call16.5.14, i8* %scevgep28.5.13, align 1
  %1500 = load i8, i8* %scevgep28.5.13, align 1
  %conv23.5.14 = zext i8 %1500 to i32
  %1501 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.14 = getelementptr i8, i8* %b, i64 20
  %1502 = load i8, i8* %scevgep34.5.14, align 1
  %call28.5.14 = call zeroext i8 @mult(i8 zeroext %1501, i8 zeroext %1502)
  %conv29.5.14 = zext i8 %call28.5.14 to i32
  %xor.5.14 = xor i32 %conv23.5.14, %conv29.5.14
  %scevgep35.5.14 = getelementptr i8, i8* %a, i64 20
  %1503 = load i8, i8* %scevgep35.5.14, align 1
  %1504 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.14 = call zeroext i8 @mult(i8 zeroext %1503, i8 zeroext %1504)
  %conv35.5.14 = zext i8 %call34.5.14 to i32
  %xor36.5.14 = xor i32 %xor.5.14, %conv35.5.14
  %conv37.5.14 = trunc i32 %xor36.5.14 to i8
  store i8 %conv37.5.14, i8* %scevgep41.5.13, align 1
  %scevgep28.5.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1498, i64 0, i64 0, i64 1
  %1505 = bitcast i8* %scevgep28.5.14 to [41 x [41 x i8]]*
  %scevgep41.5.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1499, i64 0, i64 1, i64 0
  %1506 = bitcast i8* %scevgep41.5.14 to [41 x [41 x i8]]*
  %call16.5.15 = call zeroext i8 (...) @rand()
  store i8 %call16.5.15, i8* %scevgep28.5.14, align 1
  %1507 = load i8, i8* %scevgep28.5.14, align 1
  %conv23.5.15 = zext i8 %1507 to i32
  %1508 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.15 = getelementptr i8, i8* %b, i64 21
  %1509 = load i8, i8* %scevgep34.5.15, align 1
  %call28.5.15 = call zeroext i8 @mult(i8 zeroext %1508, i8 zeroext %1509)
  %conv29.5.15 = zext i8 %call28.5.15 to i32
  %xor.5.15 = xor i32 %conv23.5.15, %conv29.5.15
  %scevgep35.5.15 = getelementptr i8, i8* %a, i64 21
  %1510 = load i8, i8* %scevgep35.5.15, align 1
  %1511 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.15 = call zeroext i8 @mult(i8 zeroext %1510, i8 zeroext %1511)
  %conv35.5.15 = zext i8 %call34.5.15 to i32
  %xor36.5.15 = xor i32 %xor.5.15, %conv35.5.15
  %conv37.5.15 = trunc i32 %xor36.5.15 to i8
  store i8 %conv37.5.15, i8* %scevgep41.5.14, align 1
  %scevgep28.5.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1505, i64 0, i64 0, i64 1
  %1512 = bitcast i8* %scevgep28.5.15 to [41 x [41 x i8]]*
  %scevgep41.5.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1506, i64 0, i64 1, i64 0
  %1513 = bitcast i8* %scevgep41.5.15 to [41 x [41 x i8]]*
  %call16.5.16 = call zeroext i8 (...) @rand()
  store i8 %call16.5.16, i8* %scevgep28.5.15, align 1
  %1514 = load i8, i8* %scevgep28.5.15, align 1
  %conv23.5.16 = zext i8 %1514 to i32
  %1515 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.16 = getelementptr i8, i8* %b, i64 22
  %1516 = load i8, i8* %scevgep34.5.16, align 1
  %call28.5.16 = call zeroext i8 @mult(i8 zeroext %1515, i8 zeroext %1516)
  %conv29.5.16 = zext i8 %call28.5.16 to i32
  %xor.5.16 = xor i32 %conv23.5.16, %conv29.5.16
  %scevgep35.5.16 = getelementptr i8, i8* %a, i64 22
  %1517 = load i8, i8* %scevgep35.5.16, align 1
  %1518 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.16 = call zeroext i8 @mult(i8 zeroext %1517, i8 zeroext %1518)
  %conv35.5.16 = zext i8 %call34.5.16 to i32
  %xor36.5.16 = xor i32 %xor.5.16, %conv35.5.16
  %conv37.5.16 = trunc i32 %xor36.5.16 to i8
  store i8 %conv37.5.16, i8* %scevgep41.5.15, align 1
  %scevgep28.5.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1512, i64 0, i64 0, i64 1
  %1519 = bitcast i8* %scevgep28.5.16 to [41 x [41 x i8]]*
  %scevgep41.5.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1513, i64 0, i64 1, i64 0
  %1520 = bitcast i8* %scevgep41.5.16 to [41 x [41 x i8]]*
  %call16.5.17 = call zeroext i8 (...) @rand()
  store i8 %call16.5.17, i8* %scevgep28.5.16, align 1
  %1521 = load i8, i8* %scevgep28.5.16, align 1
  %conv23.5.17 = zext i8 %1521 to i32
  %1522 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.17 = getelementptr i8, i8* %b, i64 23
  %1523 = load i8, i8* %scevgep34.5.17, align 1
  %call28.5.17 = call zeroext i8 @mult(i8 zeroext %1522, i8 zeroext %1523)
  %conv29.5.17 = zext i8 %call28.5.17 to i32
  %xor.5.17 = xor i32 %conv23.5.17, %conv29.5.17
  %scevgep35.5.17 = getelementptr i8, i8* %a, i64 23
  %1524 = load i8, i8* %scevgep35.5.17, align 1
  %1525 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.17 = call zeroext i8 @mult(i8 zeroext %1524, i8 zeroext %1525)
  %conv35.5.17 = zext i8 %call34.5.17 to i32
  %xor36.5.17 = xor i32 %xor.5.17, %conv35.5.17
  %conv37.5.17 = trunc i32 %xor36.5.17 to i8
  store i8 %conv37.5.17, i8* %scevgep41.5.16, align 1
  %scevgep28.5.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1519, i64 0, i64 0, i64 1
  %1526 = bitcast i8* %scevgep28.5.17 to [41 x [41 x i8]]*
  %scevgep41.5.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1520, i64 0, i64 1, i64 0
  %1527 = bitcast i8* %scevgep41.5.17 to [41 x [41 x i8]]*
  %call16.5.18 = call zeroext i8 (...) @rand()
  store i8 %call16.5.18, i8* %scevgep28.5.17, align 1
  %1528 = load i8, i8* %scevgep28.5.17, align 1
  %conv23.5.18 = zext i8 %1528 to i32
  %1529 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.18 = getelementptr i8, i8* %b, i64 24
  %1530 = load i8, i8* %scevgep34.5.18, align 1
  %call28.5.18 = call zeroext i8 @mult(i8 zeroext %1529, i8 zeroext %1530)
  %conv29.5.18 = zext i8 %call28.5.18 to i32
  %xor.5.18 = xor i32 %conv23.5.18, %conv29.5.18
  %scevgep35.5.18 = getelementptr i8, i8* %a, i64 24
  %1531 = load i8, i8* %scevgep35.5.18, align 1
  %1532 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.18 = call zeroext i8 @mult(i8 zeroext %1531, i8 zeroext %1532)
  %conv35.5.18 = zext i8 %call34.5.18 to i32
  %xor36.5.18 = xor i32 %xor.5.18, %conv35.5.18
  %conv37.5.18 = trunc i32 %xor36.5.18 to i8
  store i8 %conv37.5.18, i8* %scevgep41.5.17, align 1
  %scevgep28.5.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1526, i64 0, i64 0, i64 1
  %1533 = bitcast i8* %scevgep28.5.18 to [41 x [41 x i8]]*
  %scevgep41.5.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1527, i64 0, i64 1, i64 0
  %1534 = bitcast i8* %scevgep41.5.18 to [41 x [41 x i8]]*
  %call16.5.19 = call zeroext i8 (...) @rand()
  store i8 %call16.5.19, i8* %scevgep28.5.18, align 1
  %1535 = load i8, i8* %scevgep28.5.18, align 1
  %conv23.5.19 = zext i8 %1535 to i32
  %1536 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.19 = getelementptr i8, i8* %b, i64 25
  %1537 = load i8, i8* %scevgep34.5.19, align 1
  %call28.5.19 = call zeroext i8 @mult(i8 zeroext %1536, i8 zeroext %1537)
  %conv29.5.19 = zext i8 %call28.5.19 to i32
  %xor.5.19 = xor i32 %conv23.5.19, %conv29.5.19
  %scevgep35.5.19 = getelementptr i8, i8* %a, i64 25
  %1538 = load i8, i8* %scevgep35.5.19, align 1
  %1539 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.19 = call zeroext i8 @mult(i8 zeroext %1538, i8 zeroext %1539)
  %conv35.5.19 = zext i8 %call34.5.19 to i32
  %xor36.5.19 = xor i32 %xor.5.19, %conv35.5.19
  %conv37.5.19 = trunc i32 %xor36.5.19 to i8
  store i8 %conv37.5.19, i8* %scevgep41.5.18, align 1
  %scevgep28.5.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1533, i64 0, i64 0, i64 1
  %1540 = bitcast i8* %scevgep28.5.19 to [41 x [41 x i8]]*
  %scevgep41.5.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1534, i64 0, i64 1, i64 0
  %1541 = bitcast i8* %scevgep41.5.19 to [41 x [41 x i8]]*
  %call16.5.20 = call zeroext i8 (...) @rand()
  store i8 %call16.5.20, i8* %scevgep28.5.19, align 1
  %1542 = load i8, i8* %scevgep28.5.19, align 1
  %conv23.5.20 = zext i8 %1542 to i32
  %1543 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.20 = getelementptr i8, i8* %b, i64 26
  %1544 = load i8, i8* %scevgep34.5.20, align 1
  %call28.5.20 = call zeroext i8 @mult(i8 zeroext %1543, i8 zeroext %1544)
  %conv29.5.20 = zext i8 %call28.5.20 to i32
  %xor.5.20 = xor i32 %conv23.5.20, %conv29.5.20
  %scevgep35.5.20 = getelementptr i8, i8* %a, i64 26
  %1545 = load i8, i8* %scevgep35.5.20, align 1
  %1546 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.20 = call zeroext i8 @mult(i8 zeroext %1545, i8 zeroext %1546)
  %conv35.5.20 = zext i8 %call34.5.20 to i32
  %xor36.5.20 = xor i32 %xor.5.20, %conv35.5.20
  %conv37.5.20 = trunc i32 %xor36.5.20 to i8
  store i8 %conv37.5.20, i8* %scevgep41.5.19, align 1
  %scevgep28.5.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1540, i64 0, i64 0, i64 1
  %1547 = bitcast i8* %scevgep28.5.20 to [41 x [41 x i8]]*
  %scevgep41.5.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1541, i64 0, i64 1, i64 0
  %1548 = bitcast i8* %scevgep41.5.20 to [41 x [41 x i8]]*
  %call16.5.21 = call zeroext i8 (...) @rand()
  store i8 %call16.5.21, i8* %scevgep28.5.20, align 1
  %1549 = load i8, i8* %scevgep28.5.20, align 1
  %conv23.5.21 = zext i8 %1549 to i32
  %1550 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.21 = getelementptr i8, i8* %b, i64 27
  %1551 = load i8, i8* %scevgep34.5.21, align 1
  %call28.5.21 = call zeroext i8 @mult(i8 zeroext %1550, i8 zeroext %1551)
  %conv29.5.21 = zext i8 %call28.5.21 to i32
  %xor.5.21 = xor i32 %conv23.5.21, %conv29.5.21
  %scevgep35.5.21 = getelementptr i8, i8* %a, i64 27
  %1552 = load i8, i8* %scevgep35.5.21, align 1
  %1553 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.21 = call zeroext i8 @mult(i8 zeroext %1552, i8 zeroext %1553)
  %conv35.5.21 = zext i8 %call34.5.21 to i32
  %xor36.5.21 = xor i32 %xor.5.21, %conv35.5.21
  %conv37.5.21 = trunc i32 %xor36.5.21 to i8
  store i8 %conv37.5.21, i8* %scevgep41.5.20, align 1
  %scevgep28.5.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1547, i64 0, i64 0, i64 1
  %1554 = bitcast i8* %scevgep28.5.21 to [41 x [41 x i8]]*
  %scevgep41.5.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1548, i64 0, i64 1, i64 0
  %1555 = bitcast i8* %scevgep41.5.21 to [41 x [41 x i8]]*
  %call16.5.22 = call zeroext i8 (...) @rand()
  store i8 %call16.5.22, i8* %scevgep28.5.21, align 1
  %1556 = load i8, i8* %scevgep28.5.21, align 1
  %conv23.5.22 = zext i8 %1556 to i32
  %1557 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.22 = getelementptr i8, i8* %b, i64 28
  %1558 = load i8, i8* %scevgep34.5.22, align 1
  %call28.5.22 = call zeroext i8 @mult(i8 zeroext %1557, i8 zeroext %1558)
  %conv29.5.22 = zext i8 %call28.5.22 to i32
  %xor.5.22 = xor i32 %conv23.5.22, %conv29.5.22
  %scevgep35.5.22 = getelementptr i8, i8* %a, i64 28
  %1559 = load i8, i8* %scevgep35.5.22, align 1
  %1560 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.22 = call zeroext i8 @mult(i8 zeroext %1559, i8 zeroext %1560)
  %conv35.5.22 = zext i8 %call34.5.22 to i32
  %xor36.5.22 = xor i32 %xor.5.22, %conv35.5.22
  %conv37.5.22 = trunc i32 %xor36.5.22 to i8
  store i8 %conv37.5.22, i8* %scevgep41.5.21, align 1
  %scevgep28.5.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1554, i64 0, i64 0, i64 1
  %1561 = bitcast i8* %scevgep28.5.22 to [41 x [41 x i8]]*
  %scevgep41.5.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1555, i64 0, i64 1, i64 0
  %1562 = bitcast i8* %scevgep41.5.22 to [41 x [41 x i8]]*
  %call16.5.23 = call zeroext i8 (...) @rand()
  store i8 %call16.5.23, i8* %scevgep28.5.22, align 1
  %1563 = load i8, i8* %scevgep28.5.22, align 1
  %conv23.5.23 = zext i8 %1563 to i32
  %1564 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.23 = getelementptr i8, i8* %b, i64 29
  %1565 = load i8, i8* %scevgep34.5.23, align 1
  %call28.5.23 = call zeroext i8 @mult(i8 zeroext %1564, i8 zeroext %1565)
  %conv29.5.23 = zext i8 %call28.5.23 to i32
  %xor.5.23 = xor i32 %conv23.5.23, %conv29.5.23
  %scevgep35.5.23 = getelementptr i8, i8* %a, i64 29
  %1566 = load i8, i8* %scevgep35.5.23, align 1
  %1567 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.23 = call zeroext i8 @mult(i8 zeroext %1566, i8 zeroext %1567)
  %conv35.5.23 = zext i8 %call34.5.23 to i32
  %xor36.5.23 = xor i32 %xor.5.23, %conv35.5.23
  %conv37.5.23 = trunc i32 %xor36.5.23 to i8
  store i8 %conv37.5.23, i8* %scevgep41.5.22, align 1
  %scevgep28.5.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1561, i64 0, i64 0, i64 1
  %1568 = bitcast i8* %scevgep28.5.23 to [41 x [41 x i8]]*
  %scevgep41.5.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1562, i64 0, i64 1, i64 0
  %1569 = bitcast i8* %scevgep41.5.23 to [41 x [41 x i8]]*
  %call16.5.24 = call zeroext i8 (...) @rand()
  store i8 %call16.5.24, i8* %scevgep28.5.23, align 1
  %1570 = load i8, i8* %scevgep28.5.23, align 1
  %conv23.5.24 = zext i8 %1570 to i32
  %1571 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.24 = getelementptr i8, i8* %b, i64 30
  %1572 = load i8, i8* %scevgep34.5.24, align 1
  %call28.5.24 = call zeroext i8 @mult(i8 zeroext %1571, i8 zeroext %1572)
  %conv29.5.24 = zext i8 %call28.5.24 to i32
  %xor.5.24 = xor i32 %conv23.5.24, %conv29.5.24
  %scevgep35.5.24 = getelementptr i8, i8* %a, i64 30
  %1573 = load i8, i8* %scevgep35.5.24, align 1
  %1574 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.24 = call zeroext i8 @mult(i8 zeroext %1573, i8 zeroext %1574)
  %conv35.5.24 = zext i8 %call34.5.24 to i32
  %xor36.5.24 = xor i32 %xor.5.24, %conv35.5.24
  %conv37.5.24 = trunc i32 %xor36.5.24 to i8
  store i8 %conv37.5.24, i8* %scevgep41.5.23, align 1
  %scevgep28.5.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1568, i64 0, i64 0, i64 1
  %1575 = bitcast i8* %scevgep28.5.24 to [41 x [41 x i8]]*
  %scevgep41.5.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1569, i64 0, i64 1, i64 0
  %1576 = bitcast i8* %scevgep41.5.24 to [41 x [41 x i8]]*
  %call16.5.25 = call zeroext i8 (...) @rand()
  store i8 %call16.5.25, i8* %scevgep28.5.24, align 1
  %1577 = load i8, i8* %scevgep28.5.24, align 1
  %conv23.5.25 = zext i8 %1577 to i32
  %1578 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.25 = getelementptr i8, i8* %b, i64 31
  %1579 = load i8, i8* %scevgep34.5.25, align 1
  %call28.5.25 = call zeroext i8 @mult(i8 zeroext %1578, i8 zeroext %1579)
  %conv29.5.25 = zext i8 %call28.5.25 to i32
  %xor.5.25 = xor i32 %conv23.5.25, %conv29.5.25
  %scevgep35.5.25 = getelementptr i8, i8* %a, i64 31
  %1580 = load i8, i8* %scevgep35.5.25, align 1
  %1581 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.25 = call zeroext i8 @mult(i8 zeroext %1580, i8 zeroext %1581)
  %conv35.5.25 = zext i8 %call34.5.25 to i32
  %xor36.5.25 = xor i32 %xor.5.25, %conv35.5.25
  %conv37.5.25 = trunc i32 %xor36.5.25 to i8
  store i8 %conv37.5.25, i8* %scevgep41.5.24, align 1
  %scevgep28.5.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1575, i64 0, i64 0, i64 1
  %1582 = bitcast i8* %scevgep28.5.25 to [41 x [41 x i8]]*
  %scevgep41.5.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1576, i64 0, i64 1, i64 0
  %1583 = bitcast i8* %scevgep41.5.25 to [41 x [41 x i8]]*
  %call16.5.26 = call zeroext i8 (...) @rand()
  store i8 %call16.5.26, i8* %scevgep28.5.25, align 1
  %1584 = load i8, i8* %scevgep28.5.25, align 1
  %conv23.5.26 = zext i8 %1584 to i32
  %1585 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.26 = getelementptr i8, i8* %b, i64 32
  %1586 = load i8, i8* %scevgep34.5.26, align 1
  %call28.5.26 = call zeroext i8 @mult(i8 zeroext %1585, i8 zeroext %1586)
  %conv29.5.26 = zext i8 %call28.5.26 to i32
  %xor.5.26 = xor i32 %conv23.5.26, %conv29.5.26
  %scevgep35.5.26 = getelementptr i8, i8* %a, i64 32
  %1587 = load i8, i8* %scevgep35.5.26, align 1
  %1588 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.26 = call zeroext i8 @mult(i8 zeroext %1587, i8 zeroext %1588)
  %conv35.5.26 = zext i8 %call34.5.26 to i32
  %xor36.5.26 = xor i32 %xor.5.26, %conv35.5.26
  %conv37.5.26 = trunc i32 %xor36.5.26 to i8
  store i8 %conv37.5.26, i8* %scevgep41.5.25, align 1
  %scevgep28.5.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1582, i64 0, i64 0, i64 1
  %1589 = bitcast i8* %scevgep28.5.26 to [41 x [41 x i8]]*
  %scevgep41.5.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1583, i64 0, i64 1, i64 0
  %1590 = bitcast i8* %scevgep41.5.26 to [41 x [41 x i8]]*
  %call16.5.27 = call zeroext i8 (...) @rand()
  store i8 %call16.5.27, i8* %scevgep28.5.26, align 1
  %1591 = load i8, i8* %scevgep28.5.26, align 1
  %conv23.5.27 = zext i8 %1591 to i32
  %1592 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.27 = getelementptr i8, i8* %b, i64 33
  %1593 = load i8, i8* %scevgep34.5.27, align 1
  %call28.5.27 = call zeroext i8 @mult(i8 zeroext %1592, i8 zeroext %1593)
  %conv29.5.27 = zext i8 %call28.5.27 to i32
  %xor.5.27 = xor i32 %conv23.5.27, %conv29.5.27
  %scevgep35.5.27 = getelementptr i8, i8* %a, i64 33
  %1594 = load i8, i8* %scevgep35.5.27, align 1
  %1595 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.27 = call zeroext i8 @mult(i8 zeroext %1594, i8 zeroext %1595)
  %conv35.5.27 = zext i8 %call34.5.27 to i32
  %xor36.5.27 = xor i32 %xor.5.27, %conv35.5.27
  %conv37.5.27 = trunc i32 %xor36.5.27 to i8
  store i8 %conv37.5.27, i8* %scevgep41.5.26, align 1
  %scevgep28.5.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1589, i64 0, i64 0, i64 1
  %1596 = bitcast i8* %scevgep28.5.27 to [41 x [41 x i8]]*
  %scevgep41.5.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1590, i64 0, i64 1, i64 0
  %1597 = bitcast i8* %scevgep41.5.27 to [41 x [41 x i8]]*
  %call16.5.28 = call zeroext i8 (...) @rand()
  store i8 %call16.5.28, i8* %scevgep28.5.27, align 1
  %1598 = load i8, i8* %scevgep28.5.27, align 1
  %conv23.5.28 = zext i8 %1598 to i32
  %1599 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.28 = getelementptr i8, i8* %b, i64 34
  %1600 = load i8, i8* %scevgep34.5.28, align 1
  %call28.5.28 = call zeroext i8 @mult(i8 zeroext %1599, i8 zeroext %1600)
  %conv29.5.28 = zext i8 %call28.5.28 to i32
  %xor.5.28 = xor i32 %conv23.5.28, %conv29.5.28
  %scevgep35.5.28 = getelementptr i8, i8* %a, i64 34
  %1601 = load i8, i8* %scevgep35.5.28, align 1
  %1602 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.28 = call zeroext i8 @mult(i8 zeroext %1601, i8 zeroext %1602)
  %conv35.5.28 = zext i8 %call34.5.28 to i32
  %xor36.5.28 = xor i32 %xor.5.28, %conv35.5.28
  %conv37.5.28 = trunc i32 %xor36.5.28 to i8
  store i8 %conv37.5.28, i8* %scevgep41.5.27, align 1
  %scevgep28.5.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1596, i64 0, i64 0, i64 1
  %1603 = bitcast i8* %scevgep28.5.28 to [41 x [41 x i8]]*
  %scevgep41.5.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1597, i64 0, i64 1, i64 0
  %1604 = bitcast i8* %scevgep41.5.28 to [41 x [41 x i8]]*
  %call16.5.29 = call zeroext i8 (...) @rand()
  store i8 %call16.5.29, i8* %scevgep28.5.28, align 1
  %1605 = load i8, i8* %scevgep28.5.28, align 1
  %conv23.5.29 = zext i8 %1605 to i32
  %1606 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.29 = getelementptr i8, i8* %b, i64 35
  %1607 = load i8, i8* %scevgep34.5.29, align 1
  %call28.5.29 = call zeroext i8 @mult(i8 zeroext %1606, i8 zeroext %1607)
  %conv29.5.29 = zext i8 %call28.5.29 to i32
  %xor.5.29 = xor i32 %conv23.5.29, %conv29.5.29
  %scevgep35.5.29 = getelementptr i8, i8* %a, i64 35
  %1608 = load i8, i8* %scevgep35.5.29, align 1
  %1609 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.29 = call zeroext i8 @mult(i8 zeroext %1608, i8 zeroext %1609)
  %conv35.5.29 = zext i8 %call34.5.29 to i32
  %xor36.5.29 = xor i32 %xor.5.29, %conv35.5.29
  %conv37.5.29 = trunc i32 %xor36.5.29 to i8
  store i8 %conv37.5.29, i8* %scevgep41.5.28, align 1
  %scevgep28.5.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1603, i64 0, i64 0, i64 1
  %1610 = bitcast i8* %scevgep28.5.29 to [41 x [41 x i8]]*
  %scevgep41.5.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1604, i64 0, i64 1, i64 0
  %1611 = bitcast i8* %scevgep41.5.29 to [41 x [41 x i8]]*
  %call16.5.30 = call zeroext i8 (...) @rand()
  store i8 %call16.5.30, i8* %scevgep28.5.29, align 1
  %1612 = load i8, i8* %scevgep28.5.29, align 1
  %conv23.5.30 = zext i8 %1612 to i32
  %1613 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.30 = getelementptr i8, i8* %b, i64 36
  %1614 = load i8, i8* %scevgep34.5.30, align 1
  %call28.5.30 = call zeroext i8 @mult(i8 zeroext %1613, i8 zeroext %1614)
  %conv29.5.30 = zext i8 %call28.5.30 to i32
  %xor.5.30 = xor i32 %conv23.5.30, %conv29.5.30
  %scevgep35.5.30 = getelementptr i8, i8* %a, i64 36
  %1615 = load i8, i8* %scevgep35.5.30, align 1
  %1616 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.30 = call zeroext i8 @mult(i8 zeroext %1615, i8 zeroext %1616)
  %conv35.5.30 = zext i8 %call34.5.30 to i32
  %xor36.5.30 = xor i32 %xor.5.30, %conv35.5.30
  %conv37.5.30 = trunc i32 %xor36.5.30 to i8
  store i8 %conv37.5.30, i8* %scevgep41.5.29, align 1
  %scevgep28.5.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1610, i64 0, i64 0, i64 1
  %1617 = bitcast i8* %scevgep28.5.30 to [41 x [41 x i8]]*
  %scevgep41.5.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1611, i64 0, i64 1, i64 0
  %1618 = bitcast i8* %scevgep41.5.30 to [41 x [41 x i8]]*
  %call16.5.31 = call zeroext i8 (...) @rand()
  store i8 %call16.5.31, i8* %scevgep28.5.30, align 1
  %1619 = load i8, i8* %scevgep28.5.30, align 1
  %conv23.5.31 = zext i8 %1619 to i32
  %1620 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.31 = getelementptr i8, i8* %b, i64 37
  %1621 = load i8, i8* %scevgep34.5.31, align 1
  %call28.5.31 = call zeroext i8 @mult(i8 zeroext %1620, i8 zeroext %1621)
  %conv29.5.31 = zext i8 %call28.5.31 to i32
  %xor.5.31 = xor i32 %conv23.5.31, %conv29.5.31
  %scevgep35.5.31 = getelementptr i8, i8* %a, i64 37
  %1622 = load i8, i8* %scevgep35.5.31, align 1
  %1623 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.31 = call zeroext i8 @mult(i8 zeroext %1622, i8 zeroext %1623)
  %conv35.5.31 = zext i8 %call34.5.31 to i32
  %xor36.5.31 = xor i32 %xor.5.31, %conv35.5.31
  %conv37.5.31 = trunc i32 %xor36.5.31 to i8
  store i8 %conv37.5.31, i8* %scevgep41.5.30, align 1
  %scevgep28.5.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1617, i64 0, i64 0, i64 1
  %1624 = bitcast i8* %scevgep28.5.31 to [41 x [41 x i8]]*
  %scevgep41.5.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1618, i64 0, i64 1, i64 0
  %1625 = bitcast i8* %scevgep41.5.31 to [41 x [41 x i8]]*
  %call16.5.32 = call zeroext i8 (...) @rand()
  store i8 %call16.5.32, i8* %scevgep28.5.31, align 1
  %1626 = load i8, i8* %scevgep28.5.31, align 1
  %conv23.5.32 = zext i8 %1626 to i32
  %1627 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.32 = getelementptr i8, i8* %b, i64 38
  %1628 = load i8, i8* %scevgep34.5.32, align 1
  %call28.5.32 = call zeroext i8 @mult(i8 zeroext %1627, i8 zeroext %1628)
  %conv29.5.32 = zext i8 %call28.5.32 to i32
  %xor.5.32 = xor i32 %conv23.5.32, %conv29.5.32
  %scevgep35.5.32 = getelementptr i8, i8* %a, i64 38
  %1629 = load i8, i8* %scevgep35.5.32, align 1
  %1630 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.32 = call zeroext i8 @mult(i8 zeroext %1629, i8 zeroext %1630)
  %conv35.5.32 = zext i8 %call34.5.32 to i32
  %xor36.5.32 = xor i32 %xor.5.32, %conv35.5.32
  %conv37.5.32 = trunc i32 %xor36.5.32 to i8
  store i8 %conv37.5.32, i8* %scevgep41.5.31, align 1
  %scevgep28.5.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1624, i64 0, i64 0, i64 1
  %1631 = bitcast i8* %scevgep28.5.32 to [41 x [41 x i8]]*
  %scevgep41.5.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1625, i64 0, i64 1, i64 0
  %1632 = bitcast i8* %scevgep41.5.32 to [41 x [41 x i8]]*
  %call16.5.33 = call zeroext i8 (...) @rand()
  store i8 %call16.5.33, i8* %scevgep28.5.32, align 1
  %1633 = load i8, i8* %scevgep28.5.32, align 1
  %conv23.5.33 = zext i8 %1633 to i32
  %1634 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.33 = getelementptr i8, i8* %b, i64 39
  %1635 = load i8, i8* %scevgep34.5.33, align 1
  %call28.5.33 = call zeroext i8 @mult(i8 zeroext %1634, i8 zeroext %1635)
  %conv29.5.33 = zext i8 %call28.5.33 to i32
  %xor.5.33 = xor i32 %conv23.5.33, %conv29.5.33
  %scevgep35.5.33 = getelementptr i8, i8* %a, i64 39
  %1636 = load i8, i8* %scevgep35.5.33, align 1
  %1637 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.33 = call zeroext i8 @mult(i8 zeroext %1636, i8 zeroext %1637)
  %conv35.5.33 = zext i8 %call34.5.33 to i32
  %xor36.5.33 = xor i32 %xor.5.33, %conv35.5.33
  %conv37.5.33 = trunc i32 %xor36.5.33 to i8
  store i8 %conv37.5.33, i8* %scevgep41.5.32, align 1
  %scevgep28.5.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1631, i64 0, i64 0, i64 1
  %scevgep41.5.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1632, i64 0, i64 1, i64 0
  %call16.5.34 = call zeroext i8 (...) @rand()
  store i8 %call16.5.34, i8* %scevgep28.5.33, align 1
  %1638 = load i8, i8* %scevgep28.5.33, align 1
  %conv23.5.34 = zext i8 %1638 to i32
  %1639 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.34 = getelementptr i8, i8* %b, i64 40
  %1640 = load i8, i8* %scevgep34.5.34, align 1
  %call28.5.34 = call zeroext i8 @mult(i8 zeroext %1639, i8 zeroext %1640)
  %conv29.5.34 = zext i8 %call28.5.34 to i32
  %xor.5.34 = xor i32 %conv23.5.34, %conv29.5.34
  %scevgep35.5.34 = getelementptr i8, i8* %a, i64 40
  %1641 = load i8, i8* %scevgep35.5.34, align 1
  %1642 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.34 = call zeroext i8 @mult(i8 zeroext %1641, i8 zeroext %1642)
  %conv35.5.34 = zext i8 %call34.5.34 to i32
  %xor36.5.34 = xor i32 %xor.5.34, %conv35.5.34
  %conv37.5.34 = trunc i32 %xor36.5.34 to i8
  store i8 %conv37.5.34, i8* %scevgep41.5.33, align 1
  %scevgep26.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1400, i64 0, i64 1, i64 1
  %1643 = bitcast i8* %scevgep26.5 to [41 x [41 x i8]]*
  %scevgep39.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1401, i64 0, i64 1, i64 1
  %1644 = bitcast i8* %scevgep39.5 to [41 x [41 x i8]]*
  %arrayidx25.6 = getelementptr inbounds i8, i8* %a, i64 6
  %arrayidx33.6 = getelementptr inbounds i8, i8* %b, i64 6
  %call16.6 = call zeroext i8 (...) @rand()
  store i8 %call16.6, i8* %scevgep26.5, align 1
  %1645 = load i8, i8* %scevgep26.5, align 1
  %conv23.6 = zext i8 %1645 to i32
  %1646 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6 = getelementptr i8, i8* %b, i64 7
  %1647 = load i8, i8* %scevgep34.6, align 1
  %call28.6 = call zeroext i8 @mult(i8 zeroext %1646, i8 zeroext %1647)
  %conv29.6 = zext i8 %call28.6 to i32
  %xor.6 = xor i32 %conv23.6, %conv29.6
  %scevgep35.6 = getelementptr i8, i8* %a, i64 7
  %1648 = load i8, i8* %scevgep35.6, align 1
  %1649 = load i8, i8* %arrayidx33.6, align 1
  %call34.6 = call zeroext i8 @mult(i8 zeroext %1648, i8 zeroext %1649)
  %conv35.6 = zext i8 %call34.6 to i32
  %xor36.6 = xor i32 %xor.6, %conv35.6
  %conv37.6 = trunc i32 %xor36.6 to i8
  store i8 %conv37.6, i8* %scevgep39.5, align 1
  %scevgep28.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1643, i64 0, i64 0, i64 1
  %1650 = bitcast i8* %scevgep28.6 to [41 x [41 x i8]]*
  %scevgep41.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1644, i64 0, i64 1, i64 0
  %1651 = bitcast i8* %scevgep41.6 to [41 x [41 x i8]]*
  %call16.6.1 = call zeroext i8 (...) @rand()
  store i8 %call16.6.1, i8* %scevgep28.6, align 1
  %1652 = load i8, i8* %scevgep28.6, align 1
  %conv23.6.1 = zext i8 %1652 to i32
  %1653 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.1 = getelementptr i8, i8* %b, i64 8
  %1654 = load i8, i8* %scevgep34.6.1, align 1
  %call28.6.1 = call zeroext i8 @mult(i8 zeroext %1653, i8 zeroext %1654)
  %conv29.6.1 = zext i8 %call28.6.1 to i32
  %xor.6.1 = xor i32 %conv23.6.1, %conv29.6.1
  %scevgep35.6.1 = getelementptr i8, i8* %a, i64 8
  %1655 = load i8, i8* %scevgep35.6.1, align 1
  %1656 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.1 = call zeroext i8 @mult(i8 zeroext %1655, i8 zeroext %1656)
  %conv35.6.1 = zext i8 %call34.6.1 to i32
  %xor36.6.1 = xor i32 %xor.6.1, %conv35.6.1
  %conv37.6.1 = trunc i32 %xor36.6.1 to i8
  store i8 %conv37.6.1, i8* %scevgep41.6, align 1
  %scevgep28.6.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1650, i64 0, i64 0, i64 1
  %1657 = bitcast i8* %scevgep28.6.1 to [41 x [41 x i8]]*
  %scevgep41.6.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1651, i64 0, i64 1, i64 0
  %1658 = bitcast i8* %scevgep41.6.1 to [41 x [41 x i8]]*
  %call16.6.2 = call zeroext i8 (...) @rand()
  store i8 %call16.6.2, i8* %scevgep28.6.1, align 1
  %1659 = load i8, i8* %scevgep28.6.1, align 1
  %conv23.6.2 = zext i8 %1659 to i32
  %1660 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.2 = getelementptr i8, i8* %b, i64 9
  %1661 = load i8, i8* %scevgep34.6.2, align 1
  %call28.6.2 = call zeroext i8 @mult(i8 zeroext %1660, i8 zeroext %1661)
  %conv29.6.2 = zext i8 %call28.6.2 to i32
  %xor.6.2 = xor i32 %conv23.6.2, %conv29.6.2
  %scevgep35.6.2 = getelementptr i8, i8* %a, i64 9
  %1662 = load i8, i8* %scevgep35.6.2, align 1
  %1663 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.2 = call zeroext i8 @mult(i8 zeroext %1662, i8 zeroext %1663)
  %conv35.6.2 = zext i8 %call34.6.2 to i32
  %xor36.6.2 = xor i32 %xor.6.2, %conv35.6.2
  %conv37.6.2 = trunc i32 %xor36.6.2 to i8
  store i8 %conv37.6.2, i8* %scevgep41.6.1, align 1
  %scevgep28.6.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1657, i64 0, i64 0, i64 1
  %1664 = bitcast i8* %scevgep28.6.2 to [41 x [41 x i8]]*
  %scevgep41.6.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1658, i64 0, i64 1, i64 0
  %1665 = bitcast i8* %scevgep41.6.2 to [41 x [41 x i8]]*
  %call16.6.3 = call zeroext i8 (...) @rand()
  store i8 %call16.6.3, i8* %scevgep28.6.2, align 1
  %1666 = load i8, i8* %scevgep28.6.2, align 1
  %conv23.6.3 = zext i8 %1666 to i32
  %1667 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.3 = getelementptr i8, i8* %b, i64 10
  %1668 = load i8, i8* %scevgep34.6.3, align 1
  %call28.6.3 = call zeroext i8 @mult(i8 zeroext %1667, i8 zeroext %1668)
  %conv29.6.3 = zext i8 %call28.6.3 to i32
  %xor.6.3 = xor i32 %conv23.6.3, %conv29.6.3
  %scevgep35.6.3 = getelementptr i8, i8* %a, i64 10
  %1669 = load i8, i8* %scevgep35.6.3, align 1
  %1670 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.3 = call zeroext i8 @mult(i8 zeroext %1669, i8 zeroext %1670)
  %conv35.6.3 = zext i8 %call34.6.3 to i32
  %xor36.6.3 = xor i32 %xor.6.3, %conv35.6.3
  %conv37.6.3 = trunc i32 %xor36.6.3 to i8
  store i8 %conv37.6.3, i8* %scevgep41.6.2, align 1
  %scevgep28.6.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1664, i64 0, i64 0, i64 1
  %1671 = bitcast i8* %scevgep28.6.3 to [41 x [41 x i8]]*
  %scevgep41.6.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1665, i64 0, i64 1, i64 0
  %1672 = bitcast i8* %scevgep41.6.3 to [41 x [41 x i8]]*
  %call16.6.4 = call zeroext i8 (...) @rand()
  store i8 %call16.6.4, i8* %scevgep28.6.3, align 1
  %1673 = load i8, i8* %scevgep28.6.3, align 1
  %conv23.6.4 = zext i8 %1673 to i32
  %1674 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.4 = getelementptr i8, i8* %b, i64 11
  %1675 = load i8, i8* %scevgep34.6.4, align 1
  %call28.6.4 = call zeroext i8 @mult(i8 zeroext %1674, i8 zeroext %1675)
  %conv29.6.4 = zext i8 %call28.6.4 to i32
  %xor.6.4 = xor i32 %conv23.6.4, %conv29.6.4
  %scevgep35.6.4 = getelementptr i8, i8* %a, i64 11
  %1676 = load i8, i8* %scevgep35.6.4, align 1
  %1677 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.4 = call zeroext i8 @mult(i8 zeroext %1676, i8 zeroext %1677)
  %conv35.6.4 = zext i8 %call34.6.4 to i32
  %xor36.6.4 = xor i32 %xor.6.4, %conv35.6.4
  %conv37.6.4 = trunc i32 %xor36.6.4 to i8
  store i8 %conv37.6.4, i8* %scevgep41.6.3, align 1
  %scevgep28.6.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1671, i64 0, i64 0, i64 1
  %1678 = bitcast i8* %scevgep28.6.4 to [41 x [41 x i8]]*
  %scevgep41.6.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1672, i64 0, i64 1, i64 0
  %1679 = bitcast i8* %scevgep41.6.4 to [41 x [41 x i8]]*
  %call16.6.5 = call zeroext i8 (...) @rand()
  store i8 %call16.6.5, i8* %scevgep28.6.4, align 1
  %1680 = load i8, i8* %scevgep28.6.4, align 1
  %conv23.6.5 = zext i8 %1680 to i32
  %1681 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.5 = getelementptr i8, i8* %b, i64 12
  %1682 = load i8, i8* %scevgep34.6.5, align 1
  %call28.6.5 = call zeroext i8 @mult(i8 zeroext %1681, i8 zeroext %1682)
  %conv29.6.5 = zext i8 %call28.6.5 to i32
  %xor.6.5 = xor i32 %conv23.6.5, %conv29.6.5
  %scevgep35.6.5 = getelementptr i8, i8* %a, i64 12
  %1683 = load i8, i8* %scevgep35.6.5, align 1
  %1684 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.5 = call zeroext i8 @mult(i8 zeroext %1683, i8 zeroext %1684)
  %conv35.6.5 = zext i8 %call34.6.5 to i32
  %xor36.6.5 = xor i32 %xor.6.5, %conv35.6.5
  %conv37.6.5 = trunc i32 %xor36.6.5 to i8
  store i8 %conv37.6.5, i8* %scevgep41.6.4, align 1
  %scevgep28.6.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1678, i64 0, i64 0, i64 1
  %1685 = bitcast i8* %scevgep28.6.5 to [41 x [41 x i8]]*
  %scevgep41.6.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1679, i64 0, i64 1, i64 0
  %1686 = bitcast i8* %scevgep41.6.5 to [41 x [41 x i8]]*
  %call16.6.6 = call zeroext i8 (...) @rand()
  store i8 %call16.6.6, i8* %scevgep28.6.5, align 1
  %1687 = load i8, i8* %scevgep28.6.5, align 1
  %conv23.6.6 = zext i8 %1687 to i32
  %1688 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.6 = getelementptr i8, i8* %b, i64 13
  %1689 = load i8, i8* %scevgep34.6.6, align 1
  %call28.6.6 = call zeroext i8 @mult(i8 zeroext %1688, i8 zeroext %1689)
  %conv29.6.6 = zext i8 %call28.6.6 to i32
  %xor.6.6 = xor i32 %conv23.6.6, %conv29.6.6
  %scevgep35.6.6 = getelementptr i8, i8* %a, i64 13
  %1690 = load i8, i8* %scevgep35.6.6, align 1
  %1691 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.6 = call zeroext i8 @mult(i8 zeroext %1690, i8 zeroext %1691)
  %conv35.6.6 = zext i8 %call34.6.6 to i32
  %xor36.6.6 = xor i32 %xor.6.6, %conv35.6.6
  %conv37.6.6 = trunc i32 %xor36.6.6 to i8
  store i8 %conv37.6.6, i8* %scevgep41.6.5, align 1
  %scevgep28.6.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1685, i64 0, i64 0, i64 1
  %1692 = bitcast i8* %scevgep28.6.6 to [41 x [41 x i8]]*
  %scevgep41.6.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1686, i64 0, i64 1, i64 0
  %1693 = bitcast i8* %scevgep41.6.6 to [41 x [41 x i8]]*
  %call16.6.7 = call zeroext i8 (...) @rand()
  store i8 %call16.6.7, i8* %scevgep28.6.6, align 1
  %1694 = load i8, i8* %scevgep28.6.6, align 1
  %conv23.6.7 = zext i8 %1694 to i32
  %1695 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.7 = getelementptr i8, i8* %b, i64 14
  %1696 = load i8, i8* %scevgep34.6.7, align 1
  %call28.6.7 = call zeroext i8 @mult(i8 zeroext %1695, i8 zeroext %1696)
  %conv29.6.7 = zext i8 %call28.6.7 to i32
  %xor.6.7 = xor i32 %conv23.6.7, %conv29.6.7
  %scevgep35.6.7 = getelementptr i8, i8* %a, i64 14
  %1697 = load i8, i8* %scevgep35.6.7, align 1
  %1698 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.7 = call zeroext i8 @mult(i8 zeroext %1697, i8 zeroext %1698)
  %conv35.6.7 = zext i8 %call34.6.7 to i32
  %xor36.6.7 = xor i32 %xor.6.7, %conv35.6.7
  %conv37.6.7 = trunc i32 %xor36.6.7 to i8
  store i8 %conv37.6.7, i8* %scevgep41.6.6, align 1
  %scevgep28.6.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1692, i64 0, i64 0, i64 1
  %1699 = bitcast i8* %scevgep28.6.7 to [41 x [41 x i8]]*
  %scevgep41.6.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1693, i64 0, i64 1, i64 0
  %1700 = bitcast i8* %scevgep41.6.7 to [41 x [41 x i8]]*
  %call16.6.8 = call zeroext i8 (...) @rand()
  store i8 %call16.6.8, i8* %scevgep28.6.7, align 1
  %1701 = load i8, i8* %scevgep28.6.7, align 1
  %conv23.6.8 = zext i8 %1701 to i32
  %1702 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.8 = getelementptr i8, i8* %b, i64 15
  %1703 = load i8, i8* %scevgep34.6.8, align 1
  %call28.6.8 = call zeroext i8 @mult(i8 zeroext %1702, i8 zeroext %1703)
  %conv29.6.8 = zext i8 %call28.6.8 to i32
  %xor.6.8 = xor i32 %conv23.6.8, %conv29.6.8
  %scevgep35.6.8 = getelementptr i8, i8* %a, i64 15
  %1704 = load i8, i8* %scevgep35.6.8, align 1
  %1705 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.8 = call zeroext i8 @mult(i8 zeroext %1704, i8 zeroext %1705)
  %conv35.6.8 = zext i8 %call34.6.8 to i32
  %xor36.6.8 = xor i32 %xor.6.8, %conv35.6.8
  %conv37.6.8 = trunc i32 %xor36.6.8 to i8
  store i8 %conv37.6.8, i8* %scevgep41.6.7, align 1
  %scevgep28.6.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1699, i64 0, i64 0, i64 1
  %1706 = bitcast i8* %scevgep28.6.8 to [41 x [41 x i8]]*
  %scevgep41.6.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1700, i64 0, i64 1, i64 0
  %1707 = bitcast i8* %scevgep41.6.8 to [41 x [41 x i8]]*
  %call16.6.9 = call zeroext i8 (...) @rand()
  store i8 %call16.6.9, i8* %scevgep28.6.8, align 1
  %1708 = load i8, i8* %scevgep28.6.8, align 1
  %conv23.6.9 = zext i8 %1708 to i32
  %1709 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.9 = getelementptr i8, i8* %b, i64 16
  %1710 = load i8, i8* %scevgep34.6.9, align 1
  %call28.6.9 = call zeroext i8 @mult(i8 zeroext %1709, i8 zeroext %1710)
  %conv29.6.9 = zext i8 %call28.6.9 to i32
  %xor.6.9 = xor i32 %conv23.6.9, %conv29.6.9
  %scevgep35.6.9 = getelementptr i8, i8* %a, i64 16
  %1711 = load i8, i8* %scevgep35.6.9, align 1
  %1712 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.9 = call zeroext i8 @mult(i8 zeroext %1711, i8 zeroext %1712)
  %conv35.6.9 = zext i8 %call34.6.9 to i32
  %xor36.6.9 = xor i32 %xor.6.9, %conv35.6.9
  %conv37.6.9 = trunc i32 %xor36.6.9 to i8
  store i8 %conv37.6.9, i8* %scevgep41.6.8, align 1
  %scevgep28.6.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1706, i64 0, i64 0, i64 1
  %1713 = bitcast i8* %scevgep28.6.9 to [41 x [41 x i8]]*
  %scevgep41.6.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1707, i64 0, i64 1, i64 0
  %1714 = bitcast i8* %scevgep41.6.9 to [41 x [41 x i8]]*
  %call16.6.10 = call zeroext i8 (...) @rand()
  store i8 %call16.6.10, i8* %scevgep28.6.9, align 1
  %1715 = load i8, i8* %scevgep28.6.9, align 1
  %conv23.6.10 = zext i8 %1715 to i32
  %1716 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.10 = getelementptr i8, i8* %b, i64 17
  %1717 = load i8, i8* %scevgep34.6.10, align 1
  %call28.6.10 = call zeroext i8 @mult(i8 zeroext %1716, i8 zeroext %1717)
  %conv29.6.10 = zext i8 %call28.6.10 to i32
  %xor.6.10 = xor i32 %conv23.6.10, %conv29.6.10
  %scevgep35.6.10 = getelementptr i8, i8* %a, i64 17
  %1718 = load i8, i8* %scevgep35.6.10, align 1
  %1719 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.10 = call zeroext i8 @mult(i8 zeroext %1718, i8 zeroext %1719)
  %conv35.6.10 = zext i8 %call34.6.10 to i32
  %xor36.6.10 = xor i32 %xor.6.10, %conv35.6.10
  %conv37.6.10 = trunc i32 %xor36.6.10 to i8
  store i8 %conv37.6.10, i8* %scevgep41.6.9, align 1
  %scevgep28.6.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1713, i64 0, i64 0, i64 1
  %1720 = bitcast i8* %scevgep28.6.10 to [41 x [41 x i8]]*
  %scevgep41.6.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1714, i64 0, i64 1, i64 0
  %1721 = bitcast i8* %scevgep41.6.10 to [41 x [41 x i8]]*
  %call16.6.11 = call zeroext i8 (...) @rand()
  store i8 %call16.6.11, i8* %scevgep28.6.10, align 1
  %1722 = load i8, i8* %scevgep28.6.10, align 1
  %conv23.6.11 = zext i8 %1722 to i32
  %1723 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.11 = getelementptr i8, i8* %b, i64 18
  %1724 = load i8, i8* %scevgep34.6.11, align 1
  %call28.6.11 = call zeroext i8 @mult(i8 zeroext %1723, i8 zeroext %1724)
  %conv29.6.11 = zext i8 %call28.6.11 to i32
  %xor.6.11 = xor i32 %conv23.6.11, %conv29.6.11
  %scevgep35.6.11 = getelementptr i8, i8* %a, i64 18
  %1725 = load i8, i8* %scevgep35.6.11, align 1
  %1726 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.11 = call zeroext i8 @mult(i8 zeroext %1725, i8 zeroext %1726)
  %conv35.6.11 = zext i8 %call34.6.11 to i32
  %xor36.6.11 = xor i32 %xor.6.11, %conv35.6.11
  %conv37.6.11 = trunc i32 %xor36.6.11 to i8
  store i8 %conv37.6.11, i8* %scevgep41.6.10, align 1
  %scevgep28.6.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1720, i64 0, i64 0, i64 1
  %1727 = bitcast i8* %scevgep28.6.11 to [41 x [41 x i8]]*
  %scevgep41.6.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1721, i64 0, i64 1, i64 0
  %1728 = bitcast i8* %scevgep41.6.11 to [41 x [41 x i8]]*
  %call16.6.12 = call zeroext i8 (...) @rand()
  store i8 %call16.6.12, i8* %scevgep28.6.11, align 1
  %1729 = load i8, i8* %scevgep28.6.11, align 1
  %conv23.6.12 = zext i8 %1729 to i32
  %1730 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.12 = getelementptr i8, i8* %b, i64 19
  %1731 = load i8, i8* %scevgep34.6.12, align 1
  %call28.6.12 = call zeroext i8 @mult(i8 zeroext %1730, i8 zeroext %1731)
  %conv29.6.12 = zext i8 %call28.6.12 to i32
  %xor.6.12 = xor i32 %conv23.6.12, %conv29.6.12
  %scevgep35.6.12 = getelementptr i8, i8* %a, i64 19
  %1732 = load i8, i8* %scevgep35.6.12, align 1
  %1733 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.12 = call zeroext i8 @mult(i8 zeroext %1732, i8 zeroext %1733)
  %conv35.6.12 = zext i8 %call34.6.12 to i32
  %xor36.6.12 = xor i32 %xor.6.12, %conv35.6.12
  %conv37.6.12 = trunc i32 %xor36.6.12 to i8
  store i8 %conv37.6.12, i8* %scevgep41.6.11, align 1
  %scevgep28.6.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1727, i64 0, i64 0, i64 1
  %1734 = bitcast i8* %scevgep28.6.12 to [41 x [41 x i8]]*
  %scevgep41.6.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1728, i64 0, i64 1, i64 0
  %1735 = bitcast i8* %scevgep41.6.12 to [41 x [41 x i8]]*
  %call16.6.13 = call zeroext i8 (...) @rand()
  store i8 %call16.6.13, i8* %scevgep28.6.12, align 1
  %1736 = load i8, i8* %scevgep28.6.12, align 1
  %conv23.6.13 = zext i8 %1736 to i32
  %1737 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.13 = getelementptr i8, i8* %b, i64 20
  %1738 = load i8, i8* %scevgep34.6.13, align 1
  %call28.6.13 = call zeroext i8 @mult(i8 zeroext %1737, i8 zeroext %1738)
  %conv29.6.13 = zext i8 %call28.6.13 to i32
  %xor.6.13 = xor i32 %conv23.6.13, %conv29.6.13
  %scevgep35.6.13 = getelementptr i8, i8* %a, i64 20
  %1739 = load i8, i8* %scevgep35.6.13, align 1
  %1740 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.13 = call zeroext i8 @mult(i8 zeroext %1739, i8 zeroext %1740)
  %conv35.6.13 = zext i8 %call34.6.13 to i32
  %xor36.6.13 = xor i32 %xor.6.13, %conv35.6.13
  %conv37.6.13 = trunc i32 %xor36.6.13 to i8
  store i8 %conv37.6.13, i8* %scevgep41.6.12, align 1
  %scevgep28.6.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1734, i64 0, i64 0, i64 1
  %1741 = bitcast i8* %scevgep28.6.13 to [41 x [41 x i8]]*
  %scevgep41.6.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1735, i64 0, i64 1, i64 0
  %1742 = bitcast i8* %scevgep41.6.13 to [41 x [41 x i8]]*
  %call16.6.14 = call zeroext i8 (...) @rand()
  store i8 %call16.6.14, i8* %scevgep28.6.13, align 1
  %1743 = load i8, i8* %scevgep28.6.13, align 1
  %conv23.6.14 = zext i8 %1743 to i32
  %1744 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.14 = getelementptr i8, i8* %b, i64 21
  %1745 = load i8, i8* %scevgep34.6.14, align 1
  %call28.6.14 = call zeroext i8 @mult(i8 zeroext %1744, i8 zeroext %1745)
  %conv29.6.14 = zext i8 %call28.6.14 to i32
  %xor.6.14 = xor i32 %conv23.6.14, %conv29.6.14
  %scevgep35.6.14 = getelementptr i8, i8* %a, i64 21
  %1746 = load i8, i8* %scevgep35.6.14, align 1
  %1747 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.14 = call zeroext i8 @mult(i8 zeroext %1746, i8 zeroext %1747)
  %conv35.6.14 = zext i8 %call34.6.14 to i32
  %xor36.6.14 = xor i32 %xor.6.14, %conv35.6.14
  %conv37.6.14 = trunc i32 %xor36.6.14 to i8
  store i8 %conv37.6.14, i8* %scevgep41.6.13, align 1
  %scevgep28.6.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1741, i64 0, i64 0, i64 1
  %1748 = bitcast i8* %scevgep28.6.14 to [41 x [41 x i8]]*
  %scevgep41.6.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1742, i64 0, i64 1, i64 0
  %1749 = bitcast i8* %scevgep41.6.14 to [41 x [41 x i8]]*
  %call16.6.15 = call zeroext i8 (...) @rand()
  store i8 %call16.6.15, i8* %scevgep28.6.14, align 1
  %1750 = load i8, i8* %scevgep28.6.14, align 1
  %conv23.6.15 = zext i8 %1750 to i32
  %1751 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.15 = getelementptr i8, i8* %b, i64 22
  %1752 = load i8, i8* %scevgep34.6.15, align 1
  %call28.6.15 = call zeroext i8 @mult(i8 zeroext %1751, i8 zeroext %1752)
  %conv29.6.15 = zext i8 %call28.6.15 to i32
  %xor.6.15 = xor i32 %conv23.6.15, %conv29.6.15
  %scevgep35.6.15 = getelementptr i8, i8* %a, i64 22
  %1753 = load i8, i8* %scevgep35.6.15, align 1
  %1754 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.15 = call zeroext i8 @mult(i8 zeroext %1753, i8 zeroext %1754)
  %conv35.6.15 = zext i8 %call34.6.15 to i32
  %xor36.6.15 = xor i32 %xor.6.15, %conv35.6.15
  %conv37.6.15 = trunc i32 %xor36.6.15 to i8
  store i8 %conv37.6.15, i8* %scevgep41.6.14, align 1
  %scevgep28.6.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1748, i64 0, i64 0, i64 1
  %1755 = bitcast i8* %scevgep28.6.15 to [41 x [41 x i8]]*
  %scevgep41.6.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1749, i64 0, i64 1, i64 0
  %1756 = bitcast i8* %scevgep41.6.15 to [41 x [41 x i8]]*
  %call16.6.16 = call zeroext i8 (...) @rand()
  store i8 %call16.6.16, i8* %scevgep28.6.15, align 1
  %1757 = load i8, i8* %scevgep28.6.15, align 1
  %conv23.6.16 = zext i8 %1757 to i32
  %1758 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.16 = getelementptr i8, i8* %b, i64 23
  %1759 = load i8, i8* %scevgep34.6.16, align 1
  %call28.6.16 = call zeroext i8 @mult(i8 zeroext %1758, i8 zeroext %1759)
  %conv29.6.16 = zext i8 %call28.6.16 to i32
  %xor.6.16 = xor i32 %conv23.6.16, %conv29.6.16
  %scevgep35.6.16 = getelementptr i8, i8* %a, i64 23
  %1760 = load i8, i8* %scevgep35.6.16, align 1
  %1761 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.16 = call zeroext i8 @mult(i8 zeroext %1760, i8 zeroext %1761)
  %conv35.6.16 = zext i8 %call34.6.16 to i32
  %xor36.6.16 = xor i32 %xor.6.16, %conv35.6.16
  %conv37.6.16 = trunc i32 %xor36.6.16 to i8
  store i8 %conv37.6.16, i8* %scevgep41.6.15, align 1
  %scevgep28.6.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1755, i64 0, i64 0, i64 1
  %1762 = bitcast i8* %scevgep28.6.16 to [41 x [41 x i8]]*
  %scevgep41.6.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1756, i64 0, i64 1, i64 0
  %1763 = bitcast i8* %scevgep41.6.16 to [41 x [41 x i8]]*
  %call16.6.17 = call zeroext i8 (...) @rand()
  store i8 %call16.6.17, i8* %scevgep28.6.16, align 1
  %1764 = load i8, i8* %scevgep28.6.16, align 1
  %conv23.6.17 = zext i8 %1764 to i32
  %1765 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.17 = getelementptr i8, i8* %b, i64 24
  %1766 = load i8, i8* %scevgep34.6.17, align 1
  %call28.6.17 = call zeroext i8 @mult(i8 zeroext %1765, i8 zeroext %1766)
  %conv29.6.17 = zext i8 %call28.6.17 to i32
  %xor.6.17 = xor i32 %conv23.6.17, %conv29.6.17
  %scevgep35.6.17 = getelementptr i8, i8* %a, i64 24
  %1767 = load i8, i8* %scevgep35.6.17, align 1
  %1768 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.17 = call zeroext i8 @mult(i8 zeroext %1767, i8 zeroext %1768)
  %conv35.6.17 = zext i8 %call34.6.17 to i32
  %xor36.6.17 = xor i32 %xor.6.17, %conv35.6.17
  %conv37.6.17 = trunc i32 %xor36.6.17 to i8
  store i8 %conv37.6.17, i8* %scevgep41.6.16, align 1
  %scevgep28.6.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1762, i64 0, i64 0, i64 1
  %1769 = bitcast i8* %scevgep28.6.17 to [41 x [41 x i8]]*
  %scevgep41.6.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1763, i64 0, i64 1, i64 0
  %1770 = bitcast i8* %scevgep41.6.17 to [41 x [41 x i8]]*
  %call16.6.18 = call zeroext i8 (...) @rand()
  store i8 %call16.6.18, i8* %scevgep28.6.17, align 1
  %1771 = load i8, i8* %scevgep28.6.17, align 1
  %conv23.6.18 = zext i8 %1771 to i32
  %1772 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.18 = getelementptr i8, i8* %b, i64 25
  %1773 = load i8, i8* %scevgep34.6.18, align 1
  %call28.6.18 = call zeroext i8 @mult(i8 zeroext %1772, i8 zeroext %1773)
  %conv29.6.18 = zext i8 %call28.6.18 to i32
  %xor.6.18 = xor i32 %conv23.6.18, %conv29.6.18
  %scevgep35.6.18 = getelementptr i8, i8* %a, i64 25
  %1774 = load i8, i8* %scevgep35.6.18, align 1
  %1775 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.18 = call zeroext i8 @mult(i8 zeroext %1774, i8 zeroext %1775)
  %conv35.6.18 = zext i8 %call34.6.18 to i32
  %xor36.6.18 = xor i32 %xor.6.18, %conv35.6.18
  %conv37.6.18 = trunc i32 %xor36.6.18 to i8
  store i8 %conv37.6.18, i8* %scevgep41.6.17, align 1
  %scevgep28.6.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1769, i64 0, i64 0, i64 1
  %1776 = bitcast i8* %scevgep28.6.18 to [41 x [41 x i8]]*
  %scevgep41.6.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1770, i64 0, i64 1, i64 0
  %1777 = bitcast i8* %scevgep41.6.18 to [41 x [41 x i8]]*
  %call16.6.19 = call zeroext i8 (...) @rand()
  store i8 %call16.6.19, i8* %scevgep28.6.18, align 1
  %1778 = load i8, i8* %scevgep28.6.18, align 1
  %conv23.6.19 = zext i8 %1778 to i32
  %1779 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.19 = getelementptr i8, i8* %b, i64 26
  %1780 = load i8, i8* %scevgep34.6.19, align 1
  %call28.6.19 = call zeroext i8 @mult(i8 zeroext %1779, i8 zeroext %1780)
  %conv29.6.19 = zext i8 %call28.6.19 to i32
  %xor.6.19 = xor i32 %conv23.6.19, %conv29.6.19
  %scevgep35.6.19 = getelementptr i8, i8* %a, i64 26
  %1781 = load i8, i8* %scevgep35.6.19, align 1
  %1782 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.19 = call zeroext i8 @mult(i8 zeroext %1781, i8 zeroext %1782)
  %conv35.6.19 = zext i8 %call34.6.19 to i32
  %xor36.6.19 = xor i32 %xor.6.19, %conv35.6.19
  %conv37.6.19 = trunc i32 %xor36.6.19 to i8
  store i8 %conv37.6.19, i8* %scevgep41.6.18, align 1
  %scevgep28.6.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1776, i64 0, i64 0, i64 1
  %1783 = bitcast i8* %scevgep28.6.19 to [41 x [41 x i8]]*
  %scevgep41.6.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1777, i64 0, i64 1, i64 0
  %1784 = bitcast i8* %scevgep41.6.19 to [41 x [41 x i8]]*
  %call16.6.20 = call zeroext i8 (...) @rand()
  store i8 %call16.6.20, i8* %scevgep28.6.19, align 1
  %1785 = load i8, i8* %scevgep28.6.19, align 1
  %conv23.6.20 = zext i8 %1785 to i32
  %1786 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.20 = getelementptr i8, i8* %b, i64 27
  %1787 = load i8, i8* %scevgep34.6.20, align 1
  %call28.6.20 = call zeroext i8 @mult(i8 zeroext %1786, i8 zeroext %1787)
  %conv29.6.20 = zext i8 %call28.6.20 to i32
  %xor.6.20 = xor i32 %conv23.6.20, %conv29.6.20
  %scevgep35.6.20 = getelementptr i8, i8* %a, i64 27
  %1788 = load i8, i8* %scevgep35.6.20, align 1
  %1789 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.20 = call zeroext i8 @mult(i8 zeroext %1788, i8 zeroext %1789)
  %conv35.6.20 = zext i8 %call34.6.20 to i32
  %xor36.6.20 = xor i32 %xor.6.20, %conv35.6.20
  %conv37.6.20 = trunc i32 %xor36.6.20 to i8
  store i8 %conv37.6.20, i8* %scevgep41.6.19, align 1
  %scevgep28.6.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1783, i64 0, i64 0, i64 1
  %1790 = bitcast i8* %scevgep28.6.20 to [41 x [41 x i8]]*
  %scevgep41.6.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1784, i64 0, i64 1, i64 0
  %1791 = bitcast i8* %scevgep41.6.20 to [41 x [41 x i8]]*
  %call16.6.21 = call zeroext i8 (...) @rand()
  store i8 %call16.6.21, i8* %scevgep28.6.20, align 1
  %1792 = load i8, i8* %scevgep28.6.20, align 1
  %conv23.6.21 = zext i8 %1792 to i32
  %1793 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.21 = getelementptr i8, i8* %b, i64 28
  %1794 = load i8, i8* %scevgep34.6.21, align 1
  %call28.6.21 = call zeroext i8 @mult(i8 zeroext %1793, i8 zeroext %1794)
  %conv29.6.21 = zext i8 %call28.6.21 to i32
  %xor.6.21 = xor i32 %conv23.6.21, %conv29.6.21
  %scevgep35.6.21 = getelementptr i8, i8* %a, i64 28
  %1795 = load i8, i8* %scevgep35.6.21, align 1
  %1796 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.21 = call zeroext i8 @mult(i8 zeroext %1795, i8 zeroext %1796)
  %conv35.6.21 = zext i8 %call34.6.21 to i32
  %xor36.6.21 = xor i32 %xor.6.21, %conv35.6.21
  %conv37.6.21 = trunc i32 %xor36.6.21 to i8
  store i8 %conv37.6.21, i8* %scevgep41.6.20, align 1
  %scevgep28.6.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1790, i64 0, i64 0, i64 1
  %1797 = bitcast i8* %scevgep28.6.21 to [41 x [41 x i8]]*
  %scevgep41.6.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1791, i64 0, i64 1, i64 0
  %1798 = bitcast i8* %scevgep41.6.21 to [41 x [41 x i8]]*
  %call16.6.22 = call zeroext i8 (...) @rand()
  store i8 %call16.6.22, i8* %scevgep28.6.21, align 1
  %1799 = load i8, i8* %scevgep28.6.21, align 1
  %conv23.6.22 = zext i8 %1799 to i32
  %1800 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.22 = getelementptr i8, i8* %b, i64 29
  %1801 = load i8, i8* %scevgep34.6.22, align 1
  %call28.6.22 = call zeroext i8 @mult(i8 zeroext %1800, i8 zeroext %1801)
  %conv29.6.22 = zext i8 %call28.6.22 to i32
  %xor.6.22 = xor i32 %conv23.6.22, %conv29.6.22
  %scevgep35.6.22 = getelementptr i8, i8* %a, i64 29
  %1802 = load i8, i8* %scevgep35.6.22, align 1
  %1803 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.22 = call zeroext i8 @mult(i8 zeroext %1802, i8 zeroext %1803)
  %conv35.6.22 = zext i8 %call34.6.22 to i32
  %xor36.6.22 = xor i32 %xor.6.22, %conv35.6.22
  %conv37.6.22 = trunc i32 %xor36.6.22 to i8
  store i8 %conv37.6.22, i8* %scevgep41.6.21, align 1
  %scevgep28.6.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1797, i64 0, i64 0, i64 1
  %1804 = bitcast i8* %scevgep28.6.22 to [41 x [41 x i8]]*
  %scevgep41.6.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1798, i64 0, i64 1, i64 0
  %1805 = bitcast i8* %scevgep41.6.22 to [41 x [41 x i8]]*
  %call16.6.23 = call zeroext i8 (...) @rand()
  store i8 %call16.6.23, i8* %scevgep28.6.22, align 1
  %1806 = load i8, i8* %scevgep28.6.22, align 1
  %conv23.6.23 = zext i8 %1806 to i32
  %1807 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.23 = getelementptr i8, i8* %b, i64 30
  %1808 = load i8, i8* %scevgep34.6.23, align 1
  %call28.6.23 = call zeroext i8 @mult(i8 zeroext %1807, i8 zeroext %1808)
  %conv29.6.23 = zext i8 %call28.6.23 to i32
  %xor.6.23 = xor i32 %conv23.6.23, %conv29.6.23
  %scevgep35.6.23 = getelementptr i8, i8* %a, i64 30
  %1809 = load i8, i8* %scevgep35.6.23, align 1
  %1810 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.23 = call zeroext i8 @mult(i8 zeroext %1809, i8 zeroext %1810)
  %conv35.6.23 = zext i8 %call34.6.23 to i32
  %xor36.6.23 = xor i32 %xor.6.23, %conv35.6.23
  %conv37.6.23 = trunc i32 %xor36.6.23 to i8
  store i8 %conv37.6.23, i8* %scevgep41.6.22, align 1
  %scevgep28.6.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1804, i64 0, i64 0, i64 1
  %1811 = bitcast i8* %scevgep28.6.23 to [41 x [41 x i8]]*
  %scevgep41.6.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1805, i64 0, i64 1, i64 0
  %1812 = bitcast i8* %scevgep41.6.23 to [41 x [41 x i8]]*
  %call16.6.24 = call zeroext i8 (...) @rand()
  store i8 %call16.6.24, i8* %scevgep28.6.23, align 1
  %1813 = load i8, i8* %scevgep28.6.23, align 1
  %conv23.6.24 = zext i8 %1813 to i32
  %1814 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.24 = getelementptr i8, i8* %b, i64 31
  %1815 = load i8, i8* %scevgep34.6.24, align 1
  %call28.6.24 = call zeroext i8 @mult(i8 zeroext %1814, i8 zeroext %1815)
  %conv29.6.24 = zext i8 %call28.6.24 to i32
  %xor.6.24 = xor i32 %conv23.6.24, %conv29.6.24
  %scevgep35.6.24 = getelementptr i8, i8* %a, i64 31
  %1816 = load i8, i8* %scevgep35.6.24, align 1
  %1817 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.24 = call zeroext i8 @mult(i8 zeroext %1816, i8 zeroext %1817)
  %conv35.6.24 = zext i8 %call34.6.24 to i32
  %xor36.6.24 = xor i32 %xor.6.24, %conv35.6.24
  %conv37.6.24 = trunc i32 %xor36.6.24 to i8
  store i8 %conv37.6.24, i8* %scevgep41.6.23, align 1
  %scevgep28.6.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1811, i64 0, i64 0, i64 1
  %1818 = bitcast i8* %scevgep28.6.24 to [41 x [41 x i8]]*
  %scevgep41.6.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1812, i64 0, i64 1, i64 0
  %1819 = bitcast i8* %scevgep41.6.24 to [41 x [41 x i8]]*
  %call16.6.25 = call zeroext i8 (...) @rand()
  store i8 %call16.6.25, i8* %scevgep28.6.24, align 1
  %1820 = load i8, i8* %scevgep28.6.24, align 1
  %conv23.6.25 = zext i8 %1820 to i32
  %1821 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.25 = getelementptr i8, i8* %b, i64 32
  %1822 = load i8, i8* %scevgep34.6.25, align 1
  %call28.6.25 = call zeroext i8 @mult(i8 zeroext %1821, i8 zeroext %1822)
  %conv29.6.25 = zext i8 %call28.6.25 to i32
  %xor.6.25 = xor i32 %conv23.6.25, %conv29.6.25
  %scevgep35.6.25 = getelementptr i8, i8* %a, i64 32
  %1823 = load i8, i8* %scevgep35.6.25, align 1
  %1824 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.25 = call zeroext i8 @mult(i8 zeroext %1823, i8 zeroext %1824)
  %conv35.6.25 = zext i8 %call34.6.25 to i32
  %xor36.6.25 = xor i32 %xor.6.25, %conv35.6.25
  %conv37.6.25 = trunc i32 %xor36.6.25 to i8
  store i8 %conv37.6.25, i8* %scevgep41.6.24, align 1
  %scevgep28.6.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1818, i64 0, i64 0, i64 1
  %1825 = bitcast i8* %scevgep28.6.25 to [41 x [41 x i8]]*
  %scevgep41.6.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1819, i64 0, i64 1, i64 0
  %1826 = bitcast i8* %scevgep41.6.25 to [41 x [41 x i8]]*
  %call16.6.26 = call zeroext i8 (...) @rand()
  store i8 %call16.6.26, i8* %scevgep28.6.25, align 1
  %1827 = load i8, i8* %scevgep28.6.25, align 1
  %conv23.6.26 = zext i8 %1827 to i32
  %1828 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.26 = getelementptr i8, i8* %b, i64 33
  %1829 = load i8, i8* %scevgep34.6.26, align 1
  %call28.6.26 = call zeroext i8 @mult(i8 zeroext %1828, i8 zeroext %1829)
  %conv29.6.26 = zext i8 %call28.6.26 to i32
  %xor.6.26 = xor i32 %conv23.6.26, %conv29.6.26
  %scevgep35.6.26 = getelementptr i8, i8* %a, i64 33
  %1830 = load i8, i8* %scevgep35.6.26, align 1
  %1831 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.26 = call zeroext i8 @mult(i8 zeroext %1830, i8 zeroext %1831)
  %conv35.6.26 = zext i8 %call34.6.26 to i32
  %xor36.6.26 = xor i32 %xor.6.26, %conv35.6.26
  %conv37.6.26 = trunc i32 %xor36.6.26 to i8
  store i8 %conv37.6.26, i8* %scevgep41.6.25, align 1
  %scevgep28.6.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1825, i64 0, i64 0, i64 1
  %1832 = bitcast i8* %scevgep28.6.26 to [41 x [41 x i8]]*
  %scevgep41.6.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1826, i64 0, i64 1, i64 0
  %1833 = bitcast i8* %scevgep41.6.26 to [41 x [41 x i8]]*
  %call16.6.27 = call zeroext i8 (...) @rand()
  store i8 %call16.6.27, i8* %scevgep28.6.26, align 1
  %1834 = load i8, i8* %scevgep28.6.26, align 1
  %conv23.6.27 = zext i8 %1834 to i32
  %1835 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.27 = getelementptr i8, i8* %b, i64 34
  %1836 = load i8, i8* %scevgep34.6.27, align 1
  %call28.6.27 = call zeroext i8 @mult(i8 zeroext %1835, i8 zeroext %1836)
  %conv29.6.27 = zext i8 %call28.6.27 to i32
  %xor.6.27 = xor i32 %conv23.6.27, %conv29.6.27
  %scevgep35.6.27 = getelementptr i8, i8* %a, i64 34
  %1837 = load i8, i8* %scevgep35.6.27, align 1
  %1838 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.27 = call zeroext i8 @mult(i8 zeroext %1837, i8 zeroext %1838)
  %conv35.6.27 = zext i8 %call34.6.27 to i32
  %xor36.6.27 = xor i32 %xor.6.27, %conv35.6.27
  %conv37.6.27 = trunc i32 %xor36.6.27 to i8
  store i8 %conv37.6.27, i8* %scevgep41.6.26, align 1
  %scevgep28.6.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1832, i64 0, i64 0, i64 1
  %1839 = bitcast i8* %scevgep28.6.27 to [41 x [41 x i8]]*
  %scevgep41.6.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1833, i64 0, i64 1, i64 0
  %1840 = bitcast i8* %scevgep41.6.27 to [41 x [41 x i8]]*
  %call16.6.28 = call zeroext i8 (...) @rand()
  store i8 %call16.6.28, i8* %scevgep28.6.27, align 1
  %1841 = load i8, i8* %scevgep28.6.27, align 1
  %conv23.6.28 = zext i8 %1841 to i32
  %1842 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.28 = getelementptr i8, i8* %b, i64 35
  %1843 = load i8, i8* %scevgep34.6.28, align 1
  %call28.6.28 = call zeroext i8 @mult(i8 zeroext %1842, i8 zeroext %1843)
  %conv29.6.28 = zext i8 %call28.6.28 to i32
  %xor.6.28 = xor i32 %conv23.6.28, %conv29.6.28
  %scevgep35.6.28 = getelementptr i8, i8* %a, i64 35
  %1844 = load i8, i8* %scevgep35.6.28, align 1
  %1845 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.28 = call zeroext i8 @mult(i8 zeroext %1844, i8 zeroext %1845)
  %conv35.6.28 = zext i8 %call34.6.28 to i32
  %xor36.6.28 = xor i32 %xor.6.28, %conv35.6.28
  %conv37.6.28 = trunc i32 %xor36.6.28 to i8
  store i8 %conv37.6.28, i8* %scevgep41.6.27, align 1
  %scevgep28.6.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1839, i64 0, i64 0, i64 1
  %1846 = bitcast i8* %scevgep28.6.28 to [41 x [41 x i8]]*
  %scevgep41.6.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1840, i64 0, i64 1, i64 0
  %1847 = bitcast i8* %scevgep41.6.28 to [41 x [41 x i8]]*
  %call16.6.29 = call zeroext i8 (...) @rand()
  store i8 %call16.6.29, i8* %scevgep28.6.28, align 1
  %1848 = load i8, i8* %scevgep28.6.28, align 1
  %conv23.6.29 = zext i8 %1848 to i32
  %1849 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.29 = getelementptr i8, i8* %b, i64 36
  %1850 = load i8, i8* %scevgep34.6.29, align 1
  %call28.6.29 = call zeroext i8 @mult(i8 zeroext %1849, i8 zeroext %1850)
  %conv29.6.29 = zext i8 %call28.6.29 to i32
  %xor.6.29 = xor i32 %conv23.6.29, %conv29.6.29
  %scevgep35.6.29 = getelementptr i8, i8* %a, i64 36
  %1851 = load i8, i8* %scevgep35.6.29, align 1
  %1852 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.29 = call zeroext i8 @mult(i8 zeroext %1851, i8 zeroext %1852)
  %conv35.6.29 = zext i8 %call34.6.29 to i32
  %xor36.6.29 = xor i32 %xor.6.29, %conv35.6.29
  %conv37.6.29 = trunc i32 %xor36.6.29 to i8
  store i8 %conv37.6.29, i8* %scevgep41.6.28, align 1
  %scevgep28.6.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1846, i64 0, i64 0, i64 1
  %1853 = bitcast i8* %scevgep28.6.29 to [41 x [41 x i8]]*
  %scevgep41.6.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1847, i64 0, i64 1, i64 0
  %1854 = bitcast i8* %scevgep41.6.29 to [41 x [41 x i8]]*
  %call16.6.30 = call zeroext i8 (...) @rand()
  store i8 %call16.6.30, i8* %scevgep28.6.29, align 1
  %1855 = load i8, i8* %scevgep28.6.29, align 1
  %conv23.6.30 = zext i8 %1855 to i32
  %1856 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.30 = getelementptr i8, i8* %b, i64 37
  %1857 = load i8, i8* %scevgep34.6.30, align 1
  %call28.6.30 = call zeroext i8 @mult(i8 zeroext %1856, i8 zeroext %1857)
  %conv29.6.30 = zext i8 %call28.6.30 to i32
  %xor.6.30 = xor i32 %conv23.6.30, %conv29.6.30
  %scevgep35.6.30 = getelementptr i8, i8* %a, i64 37
  %1858 = load i8, i8* %scevgep35.6.30, align 1
  %1859 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.30 = call zeroext i8 @mult(i8 zeroext %1858, i8 zeroext %1859)
  %conv35.6.30 = zext i8 %call34.6.30 to i32
  %xor36.6.30 = xor i32 %xor.6.30, %conv35.6.30
  %conv37.6.30 = trunc i32 %xor36.6.30 to i8
  store i8 %conv37.6.30, i8* %scevgep41.6.29, align 1
  %scevgep28.6.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1853, i64 0, i64 0, i64 1
  %1860 = bitcast i8* %scevgep28.6.30 to [41 x [41 x i8]]*
  %scevgep41.6.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1854, i64 0, i64 1, i64 0
  %1861 = bitcast i8* %scevgep41.6.30 to [41 x [41 x i8]]*
  %call16.6.31 = call zeroext i8 (...) @rand()
  store i8 %call16.6.31, i8* %scevgep28.6.30, align 1
  %1862 = load i8, i8* %scevgep28.6.30, align 1
  %conv23.6.31 = zext i8 %1862 to i32
  %1863 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.31 = getelementptr i8, i8* %b, i64 38
  %1864 = load i8, i8* %scevgep34.6.31, align 1
  %call28.6.31 = call zeroext i8 @mult(i8 zeroext %1863, i8 zeroext %1864)
  %conv29.6.31 = zext i8 %call28.6.31 to i32
  %xor.6.31 = xor i32 %conv23.6.31, %conv29.6.31
  %scevgep35.6.31 = getelementptr i8, i8* %a, i64 38
  %1865 = load i8, i8* %scevgep35.6.31, align 1
  %1866 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.31 = call zeroext i8 @mult(i8 zeroext %1865, i8 zeroext %1866)
  %conv35.6.31 = zext i8 %call34.6.31 to i32
  %xor36.6.31 = xor i32 %xor.6.31, %conv35.6.31
  %conv37.6.31 = trunc i32 %xor36.6.31 to i8
  store i8 %conv37.6.31, i8* %scevgep41.6.30, align 1
  %scevgep28.6.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1860, i64 0, i64 0, i64 1
  %1867 = bitcast i8* %scevgep28.6.31 to [41 x [41 x i8]]*
  %scevgep41.6.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1861, i64 0, i64 1, i64 0
  %1868 = bitcast i8* %scevgep41.6.31 to [41 x [41 x i8]]*
  %call16.6.32 = call zeroext i8 (...) @rand()
  store i8 %call16.6.32, i8* %scevgep28.6.31, align 1
  %1869 = load i8, i8* %scevgep28.6.31, align 1
  %conv23.6.32 = zext i8 %1869 to i32
  %1870 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.32 = getelementptr i8, i8* %b, i64 39
  %1871 = load i8, i8* %scevgep34.6.32, align 1
  %call28.6.32 = call zeroext i8 @mult(i8 zeroext %1870, i8 zeroext %1871)
  %conv29.6.32 = zext i8 %call28.6.32 to i32
  %xor.6.32 = xor i32 %conv23.6.32, %conv29.6.32
  %scevgep35.6.32 = getelementptr i8, i8* %a, i64 39
  %1872 = load i8, i8* %scevgep35.6.32, align 1
  %1873 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.32 = call zeroext i8 @mult(i8 zeroext %1872, i8 zeroext %1873)
  %conv35.6.32 = zext i8 %call34.6.32 to i32
  %xor36.6.32 = xor i32 %xor.6.32, %conv35.6.32
  %conv37.6.32 = trunc i32 %xor36.6.32 to i8
  store i8 %conv37.6.32, i8* %scevgep41.6.31, align 1
  %scevgep28.6.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1867, i64 0, i64 0, i64 1
  %scevgep41.6.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1868, i64 0, i64 1, i64 0
  %call16.6.33 = call zeroext i8 (...) @rand()
  store i8 %call16.6.33, i8* %scevgep28.6.32, align 1
  %1874 = load i8, i8* %scevgep28.6.32, align 1
  %conv23.6.33 = zext i8 %1874 to i32
  %1875 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.33 = getelementptr i8, i8* %b, i64 40
  %1876 = load i8, i8* %scevgep34.6.33, align 1
  %call28.6.33 = call zeroext i8 @mult(i8 zeroext %1875, i8 zeroext %1876)
  %conv29.6.33 = zext i8 %call28.6.33 to i32
  %xor.6.33 = xor i32 %conv23.6.33, %conv29.6.33
  %scevgep35.6.33 = getelementptr i8, i8* %a, i64 40
  %1877 = load i8, i8* %scevgep35.6.33, align 1
  %1878 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.33 = call zeroext i8 @mult(i8 zeroext %1877, i8 zeroext %1878)
  %conv35.6.33 = zext i8 %call34.6.33 to i32
  %xor36.6.33 = xor i32 %xor.6.33, %conv35.6.33
  %conv37.6.33 = trunc i32 %xor36.6.33 to i8
  store i8 %conv37.6.33, i8* %scevgep41.6.32, align 1
  %scevgep26.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1643, i64 0, i64 1, i64 1
  %1879 = bitcast i8* %scevgep26.6 to [41 x [41 x i8]]*
  %scevgep39.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1644, i64 0, i64 1, i64 1
  %1880 = bitcast i8* %scevgep39.6 to [41 x [41 x i8]]*
  %arrayidx25.7 = getelementptr inbounds i8, i8* %a, i64 7
  %arrayidx33.7 = getelementptr inbounds i8, i8* %b, i64 7
  %call16.7 = call zeroext i8 (...) @rand()
  store i8 %call16.7, i8* %scevgep26.6, align 1
  %1881 = load i8, i8* %scevgep26.6, align 1
  %conv23.7 = zext i8 %1881 to i32
  %1882 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7 = getelementptr i8, i8* %b, i64 8
  %1883 = load i8, i8* %scevgep34.7, align 1
  %call28.7 = call zeroext i8 @mult(i8 zeroext %1882, i8 zeroext %1883)
  %conv29.7 = zext i8 %call28.7 to i32
  %xor.7 = xor i32 %conv23.7, %conv29.7
  %scevgep35.7 = getelementptr i8, i8* %a, i64 8
  %1884 = load i8, i8* %scevgep35.7, align 1
  %1885 = load i8, i8* %arrayidx33.7, align 1
  %call34.7 = call zeroext i8 @mult(i8 zeroext %1884, i8 zeroext %1885)
  %conv35.7 = zext i8 %call34.7 to i32
  %xor36.7 = xor i32 %xor.7, %conv35.7
  %conv37.7 = trunc i32 %xor36.7 to i8
  store i8 %conv37.7, i8* %scevgep39.6, align 1
  %scevgep28.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1879, i64 0, i64 0, i64 1
  %1886 = bitcast i8* %scevgep28.7 to [41 x [41 x i8]]*
  %scevgep41.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1880, i64 0, i64 1, i64 0
  %1887 = bitcast i8* %scevgep41.7 to [41 x [41 x i8]]*
  %call16.7.1 = call zeroext i8 (...) @rand()
  store i8 %call16.7.1, i8* %scevgep28.7, align 1
  %1888 = load i8, i8* %scevgep28.7, align 1
  %conv23.7.1 = zext i8 %1888 to i32
  %1889 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.1 = getelementptr i8, i8* %b, i64 9
  %1890 = load i8, i8* %scevgep34.7.1, align 1
  %call28.7.1 = call zeroext i8 @mult(i8 zeroext %1889, i8 zeroext %1890)
  %conv29.7.1 = zext i8 %call28.7.1 to i32
  %xor.7.1 = xor i32 %conv23.7.1, %conv29.7.1
  %scevgep35.7.1 = getelementptr i8, i8* %a, i64 9
  %1891 = load i8, i8* %scevgep35.7.1, align 1
  %1892 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.1 = call zeroext i8 @mult(i8 zeroext %1891, i8 zeroext %1892)
  %conv35.7.1 = zext i8 %call34.7.1 to i32
  %xor36.7.1 = xor i32 %xor.7.1, %conv35.7.1
  %conv37.7.1 = trunc i32 %xor36.7.1 to i8
  store i8 %conv37.7.1, i8* %scevgep41.7, align 1
  %scevgep28.7.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1886, i64 0, i64 0, i64 1
  %1893 = bitcast i8* %scevgep28.7.1 to [41 x [41 x i8]]*
  %scevgep41.7.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1887, i64 0, i64 1, i64 0
  %1894 = bitcast i8* %scevgep41.7.1 to [41 x [41 x i8]]*
  %call16.7.2 = call zeroext i8 (...) @rand()
  store i8 %call16.7.2, i8* %scevgep28.7.1, align 1
  %1895 = load i8, i8* %scevgep28.7.1, align 1
  %conv23.7.2 = zext i8 %1895 to i32
  %1896 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.2 = getelementptr i8, i8* %b, i64 10
  %1897 = load i8, i8* %scevgep34.7.2, align 1
  %call28.7.2 = call zeroext i8 @mult(i8 zeroext %1896, i8 zeroext %1897)
  %conv29.7.2 = zext i8 %call28.7.2 to i32
  %xor.7.2 = xor i32 %conv23.7.2, %conv29.7.2
  %scevgep35.7.2 = getelementptr i8, i8* %a, i64 10
  %1898 = load i8, i8* %scevgep35.7.2, align 1
  %1899 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.2 = call zeroext i8 @mult(i8 zeroext %1898, i8 zeroext %1899)
  %conv35.7.2 = zext i8 %call34.7.2 to i32
  %xor36.7.2 = xor i32 %xor.7.2, %conv35.7.2
  %conv37.7.2 = trunc i32 %xor36.7.2 to i8
  store i8 %conv37.7.2, i8* %scevgep41.7.1, align 1
  %scevgep28.7.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1893, i64 0, i64 0, i64 1
  %1900 = bitcast i8* %scevgep28.7.2 to [41 x [41 x i8]]*
  %scevgep41.7.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1894, i64 0, i64 1, i64 0
  %1901 = bitcast i8* %scevgep41.7.2 to [41 x [41 x i8]]*
  %call16.7.3 = call zeroext i8 (...) @rand()
  store i8 %call16.7.3, i8* %scevgep28.7.2, align 1
  %1902 = load i8, i8* %scevgep28.7.2, align 1
  %conv23.7.3 = zext i8 %1902 to i32
  %1903 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.3 = getelementptr i8, i8* %b, i64 11
  %1904 = load i8, i8* %scevgep34.7.3, align 1
  %call28.7.3 = call zeroext i8 @mult(i8 zeroext %1903, i8 zeroext %1904)
  %conv29.7.3 = zext i8 %call28.7.3 to i32
  %xor.7.3 = xor i32 %conv23.7.3, %conv29.7.3
  %scevgep35.7.3 = getelementptr i8, i8* %a, i64 11
  %1905 = load i8, i8* %scevgep35.7.3, align 1
  %1906 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.3 = call zeroext i8 @mult(i8 zeroext %1905, i8 zeroext %1906)
  %conv35.7.3 = zext i8 %call34.7.3 to i32
  %xor36.7.3 = xor i32 %xor.7.3, %conv35.7.3
  %conv37.7.3 = trunc i32 %xor36.7.3 to i8
  store i8 %conv37.7.3, i8* %scevgep41.7.2, align 1
  %scevgep28.7.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1900, i64 0, i64 0, i64 1
  %1907 = bitcast i8* %scevgep28.7.3 to [41 x [41 x i8]]*
  %scevgep41.7.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1901, i64 0, i64 1, i64 0
  %1908 = bitcast i8* %scevgep41.7.3 to [41 x [41 x i8]]*
  %call16.7.4 = call zeroext i8 (...) @rand()
  store i8 %call16.7.4, i8* %scevgep28.7.3, align 1
  %1909 = load i8, i8* %scevgep28.7.3, align 1
  %conv23.7.4 = zext i8 %1909 to i32
  %1910 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.4 = getelementptr i8, i8* %b, i64 12
  %1911 = load i8, i8* %scevgep34.7.4, align 1
  %call28.7.4 = call zeroext i8 @mult(i8 zeroext %1910, i8 zeroext %1911)
  %conv29.7.4 = zext i8 %call28.7.4 to i32
  %xor.7.4 = xor i32 %conv23.7.4, %conv29.7.4
  %scevgep35.7.4 = getelementptr i8, i8* %a, i64 12
  %1912 = load i8, i8* %scevgep35.7.4, align 1
  %1913 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.4 = call zeroext i8 @mult(i8 zeroext %1912, i8 zeroext %1913)
  %conv35.7.4 = zext i8 %call34.7.4 to i32
  %xor36.7.4 = xor i32 %xor.7.4, %conv35.7.4
  %conv37.7.4 = trunc i32 %xor36.7.4 to i8
  store i8 %conv37.7.4, i8* %scevgep41.7.3, align 1
  %scevgep28.7.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1907, i64 0, i64 0, i64 1
  %1914 = bitcast i8* %scevgep28.7.4 to [41 x [41 x i8]]*
  %scevgep41.7.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1908, i64 0, i64 1, i64 0
  %1915 = bitcast i8* %scevgep41.7.4 to [41 x [41 x i8]]*
  %call16.7.5 = call zeroext i8 (...) @rand()
  store i8 %call16.7.5, i8* %scevgep28.7.4, align 1
  %1916 = load i8, i8* %scevgep28.7.4, align 1
  %conv23.7.5 = zext i8 %1916 to i32
  %1917 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.5 = getelementptr i8, i8* %b, i64 13
  %1918 = load i8, i8* %scevgep34.7.5, align 1
  %call28.7.5 = call zeroext i8 @mult(i8 zeroext %1917, i8 zeroext %1918)
  %conv29.7.5 = zext i8 %call28.7.5 to i32
  %xor.7.5 = xor i32 %conv23.7.5, %conv29.7.5
  %scevgep35.7.5 = getelementptr i8, i8* %a, i64 13
  %1919 = load i8, i8* %scevgep35.7.5, align 1
  %1920 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.5 = call zeroext i8 @mult(i8 zeroext %1919, i8 zeroext %1920)
  %conv35.7.5 = zext i8 %call34.7.5 to i32
  %xor36.7.5 = xor i32 %xor.7.5, %conv35.7.5
  %conv37.7.5 = trunc i32 %xor36.7.5 to i8
  store i8 %conv37.7.5, i8* %scevgep41.7.4, align 1
  %scevgep28.7.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1914, i64 0, i64 0, i64 1
  %1921 = bitcast i8* %scevgep28.7.5 to [41 x [41 x i8]]*
  %scevgep41.7.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1915, i64 0, i64 1, i64 0
  %1922 = bitcast i8* %scevgep41.7.5 to [41 x [41 x i8]]*
  %call16.7.6 = call zeroext i8 (...) @rand()
  store i8 %call16.7.6, i8* %scevgep28.7.5, align 1
  %1923 = load i8, i8* %scevgep28.7.5, align 1
  %conv23.7.6 = zext i8 %1923 to i32
  %1924 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.6 = getelementptr i8, i8* %b, i64 14
  %1925 = load i8, i8* %scevgep34.7.6, align 1
  %call28.7.6 = call zeroext i8 @mult(i8 zeroext %1924, i8 zeroext %1925)
  %conv29.7.6 = zext i8 %call28.7.6 to i32
  %xor.7.6 = xor i32 %conv23.7.6, %conv29.7.6
  %scevgep35.7.6 = getelementptr i8, i8* %a, i64 14
  %1926 = load i8, i8* %scevgep35.7.6, align 1
  %1927 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.6 = call zeroext i8 @mult(i8 zeroext %1926, i8 zeroext %1927)
  %conv35.7.6 = zext i8 %call34.7.6 to i32
  %xor36.7.6 = xor i32 %xor.7.6, %conv35.7.6
  %conv37.7.6 = trunc i32 %xor36.7.6 to i8
  store i8 %conv37.7.6, i8* %scevgep41.7.5, align 1
  %scevgep28.7.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1921, i64 0, i64 0, i64 1
  %1928 = bitcast i8* %scevgep28.7.6 to [41 x [41 x i8]]*
  %scevgep41.7.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1922, i64 0, i64 1, i64 0
  %1929 = bitcast i8* %scevgep41.7.6 to [41 x [41 x i8]]*
  %call16.7.7 = call zeroext i8 (...) @rand()
  store i8 %call16.7.7, i8* %scevgep28.7.6, align 1
  %1930 = load i8, i8* %scevgep28.7.6, align 1
  %conv23.7.7 = zext i8 %1930 to i32
  %1931 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.7 = getelementptr i8, i8* %b, i64 15
  %1932 = load i8, i8* %scevgep34.7.7, align 1
  %call28.7.7 = call zeroext i8 @mult(i8 zeroext %1931, i8 zeroext %1932)
  %conv29.7.7 = zext i8 %call28.7.7 to i32
  %xor.7.7 = xor i32 %conv23.7.7, %conv29.7.7
  %scevgep35.7.7 = getelementptr i8, i8* %a, i64 15
  %1933 = load i8, i8* %scevgep35.7.7, align 1
  %1934 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.7 = call zeroext i8 @mult(i8 zeroext %1933, i8 zeroext %1934)
  %conv35.7.7 = zext i8 %call34.7.7 to i32
  %xor36.7.7 = xor i32 %xor.7.7, %conv35.7.7
  %conv37.7.7 = trunc i32 %xor36.7.7 to i8
  store i8 %conv37.7.7, i8* %scevgep41.7.6, align 1
  %scevgep28.7.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1928, i64 0, i64 0, i64 1
  %1935 = bitcast i8* %scevgep28.7.7 to [41 x [41 x i8]]*
  %scevgep41.7.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1929, i64 0, i64 1, i64 0
  %1936 = bitcast i8* %scevgep41.7.7 to [41 x [41 x i8]]*
  %call16.7.8 = call zeroext i8 (...) @rand()
  store i8 %call16.7.8, i8* %scevgep28.7.7, align 1
  %1937 = load i8, i8* %scevgep28.7.7, align 1
  %conv23.7.8 = zext i8 %1937 to i32
  %1938 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.8 = getelementptr i8, i8* %b, i64 16
  %1939 = load i8, i8* %scevgep34.7.8, align 1
  %call28.7.8 = call zeroext i8 @mult(i8 zeroext %1938, i8 zeroext %1939)
  %conv29.7.8 = zext i8 %call28.7.8 to i32
  %xor.7.8 = xor i32 %conv23.7.8, %conv29.7.8
  %scevgep35.7.8 = getelementptr i8, i8* %a, i64 16
  %1940 = load i8, i8* %scevgep35.7.8, align 1
  %1941 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.8 = call zeroext i8 @mult(i8 zeroext %1940, i8 zeroext %1941)
  %conv35.7.8 = zext i8 %call34.7.8 to i32
  %xor36.7.8 = xor i32 %xor.7.8, %conv35.7.8
  %conv37.7.8 = trunc i32 %xor36.7.8 to i8
  store i8 %conv37.7.8, i8* %scevgep41.7.7, align 1
  %scevgep28.7.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1935, i64 0, i64 0, i64 1
  %1942 = bitcast i8* %scevgep28.7.8 to [41 x [41 x i8]]*
  %scevgep41.7.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1936, i64 0, i64 1, i64 0
  %1943 = bitcast i8* %scevgep41.7.8 to [41 x [41 x i8]]*
  %call16.7.9 = call zeroext i8 (...) @rand()
  store i8 %call16.7.9, i8* %scevgep28.7.8, align 1
  %1944 = load i8, i8* %scevgep28.7.8, align 1
  %conv23.7.9 = zext i8 %1944 to i32
  %1945 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.9 = getelementptr i8, i8* %b, i64 17
  %1946 = load i8, i8* %scevgep34.7.9, align 1
  %call28.7.9 = call zeroext i8 @mult(i8 zeroext %1945, i8 zeroext %1946)
  %conv29.7.9 = zext i8 %call28.7.9 to i32
  %xor.7.9 = xor i32 %conv23.7.9, %conv29.7.9
  %scevgep35.7.9 = getelementptr i8, i8* %a, i64 17
  %1947 = load i8, i8* %scevgep35.7.9, align 1
  %1948 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.9 = call zeroext i8 @mult(i8 zeroext %1947, i8 zeroext %1948)
  %conv35.7.9 = zext i8 %call34.7.9 to i32
  %xor36.7.9 = xor i32 %xor.7.9, %conv35.7.9
  %conv37.7.9 = trunc i32 %xor36.7.9 to i8
  store i8 %conv37.7.9, i8* %scevgep41.7.8, align 1
  %scevgep28.7.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1942, i64 0, i64 0, i64 1
  %1949 = bitcast i8* %scevgep28.7.9 to [41 x [41 x i8]]*
  %scevgep41.7.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1943, i64 0, i64 1, i64 0
  %1950 = bitcast i8* %scevgep41.7.9 to [41 x [41 x i8]]*
  %call16.7.10 = call zeroext i8 (...) @rand()
  store i8 %call16.7.10, i8* %scevgep28.7.9, align 1
  %1951 = load i8, i8* %scevgep28.7.9, align 1
  %conv23.7.10 = zext i8 %1951 to i32
  %1952 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.10 = getelementptr i8, i8* %b, i64 18
  %1953 = load i8, i8* %scevgep34.7.10, align 1
  %call28.7.10 = call zeroext i8 @mult(i8 zeroext %1952, i8 zeroext %1953)
  %conv29.7.10 = zext i8 %call28.7.10 to i32
  %xor.7.10 = xor i32 %conv23.7.10, %conv29.7.10
  %scevgep35.7.10 = getelementptr i8, i8* %a, i64 18
  %1954 = load i8, i8* %scevgep35.7.10, align 1
  %1955 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.10 = call zeroext i8 @mult(i8 zeroext %1954, i8 zeroext %1955)
  %conv35.7.10 = zext i8 %call34.7.10 to i32
  %xor36.7.10 = xor i32 %xor.7.10, %conv35.7.10
  %conv37.7.10 = trunc i32 %xor36.7.10 to i8
  store i8 %conv37.7.10, i8* %scevgep41.7.9, align 1
  %scevgep28.7.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1949, i64 0, i64 0, i64 1
  %1956 = bitcast i8* %scevgep28.7.10 to [41 x [41 x i8]]*
  %scevgep41.7.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1950, i64 0, i64 1, i64 0
  %1957 = bitcast i8* %scevgep41.7.10 to [41 x [41 x i8]]*
  %call16.7.11 = call zeroext i8 (...) @rand()
  store i8 %call16.7.11, i8* %scevgep28.7.10, align 1
  %1958 = load i8, i8* %scevgep28.7.10, align 1
  %conv23.7.11 = zext i8 %1958 to i32
  %1959 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.11 = getelementptr i8, i8* %b, i64 19
  %1960 = load i8, i8* %scevgep34.7.11, align 1
  %call28.7.11 = call zeroext i8 @mult(i8 zeroext %1959, i8 zeroext %1960)
  %conv29.7.11 = zext i8 %call28.7.11 to i32
  %xor.7.11 = xor i32 %conv23.7.11, %conv29.7.11
  %scevgep35.7.11 = getelementptr i8, i8* %a, i64 19
  %1961 = load i8, i8* %scevgep35.7.11, align 1
  %1962 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.11 = call zeroext i8 @mult(i8 zeroext %1961, i8 zeroext %1962)
  %conv35.7.11 = zext i8 %call34.7.11 to i32
  %xor36.7.11 = xor i32 %xor.7.11, %conv35.7.11
  %conv37.7.11 = trunc i32 %xor36.7.11 to i8
  store i8 %conv37.7.11, i8* %scevgep41.7.10, align 1
  %scevgep28.7.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1956, i64 0, i64 0, i64 1
  %1963 = bitcast i8* %scevgep28.7.11 to [41 x [41 x i8]]*
  %scevgep41.7.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1957, i64 0, i64 1, i64 0
  %1964 = bitcast i8* %scevgep41.7.11 to [41 x [41 x i8]]*
  %call16.7.12 = call zeroext i8 (...) @rand()
  store i8 %call16.7.12, i8* %scevgep28.7.11, align 1
  %1965 = load i8, i8* %scevgep28.7.11, align 1
  %conv23.7.12 = zext i8 %1965 to i32
  %1966 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.12 = getelementptr i8, i8* %b, i64 20
  %1967 = load i8, i8* %scevgep34.7.12, align 1
  %call28.7.12 = call zeroext i8 @mult(i8 zeroext %1966, i8 zeroext %1967)
  %conv29.7.12 = zext i8 %call28.7.12 to i32
  %xor.7.12 = xor i32 %conv23.7.12, %conv29.7.12
  %scevgep35.7.12 = getelementptr i8, i8* %a, i64 20
  %1968 = load i8, i8* %scevgep35.7.12, align 1
  %1969 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.12 = call zeroext i8 @mult(i8 zeroext %1968, i8 zeroext %1969)
  %conv35.7.12 = zext i8 %call34.7.12 to i32
  %xor36.7.12 = xor i32 %xor.7.12, %conv35.7.12
  %conv37.7.12 = trunc i32 %xor36.7.12 to i8
  store i8 %conv37.7.12, i8* %scevgep41.7.11, align 1
  %scevgep28.7.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1963, i64 0, i64 0, i64 1
  %1970 = bitcast i8* %scevgep28.7.12 to [41 x [41 x i8]]*
  %scevgep41.7.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1964, i64 0, i64 1, i64 0
  %1971 = bitcast i8* %scevgep41.7.12 to [41 x [41 x i8]]*
  %call16.7.13 = call zeroext i8 (...) @rand()
  store i8 %call16.7.13, i8* %scevgep28.7.12, align 1
  %1972 = load i8, i8* %scevgep28.7.12, align 1
  %conv23.7.13 = zext i8 %1972 to i32
  %1973 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.13 = getelementptr i8, i8* %b, i64 21
  %1974 = load i8, i8* %scevgep34.7.13, align 1
  %call28.7.13 = call zeroext i8 @mult(i8 zeroext %1973, i8 zeroext %1974)
  %conv29.7.13 = zext i8 %call28.7.13 to i32
  %xor.7.13 = xor i32 %conv23.7.13, %conv29.7.13
  %scevgep35.7.13 = getelementptr i8, i8* %a, i64 21
  %1975 = load i8, i8* %scevgep35.7.13, align 1
  %1976 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.13 = call zeroext i8 @mult(i8 zeroext %1975, i8 zeroext %1976)
  %conv35.7.13 = zext i8 %call34.7.13 to i32
  %xor36.7.13 = xor i32 %xor.7.13, %conv35.7.13
  %conv37.7.13 = trunc i32 %xor36.7.13 to i8
  store i8 %conv37.7.13, i8* %scevgep41.7.12, align 1
  %scevgep28.7.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1970, i64 0, i64 0, i64 1
  %1977 = bitcast i8* %scevgep28.7.13 to [41 x [41 x i8]]*
  %scevgep41.7.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1971, i64 0, i64 1, i64 0
  %1978 = bitcast i8* %scevgep41.7.13 to [41 x [41 x i8]]*
  %call16.7.14 = call zeroext i8 (...) @rand()
  store i8 %call16.7.14, i8* %scevgep28.7.13, align 1
  %1979 = load i8, i8* %scevgep28.7.13, align 1
  %conv23.7.14 = zext i8 %1979 to i32
  %1980 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.14 = getelementptr i8, i8* %b, i64 22
  %1981 = load i8, i8* %scevgep34.7.14, align 1
  %call28.7.14 = call zeroext i8 @mult(i8 zeroext %1980, i8 zeroext %1981)
  %conv29.7.14 = zext i8 %call28.7.14 to i32
  %xor.7.14 = xor i32 %conv23.7.14, %conv29.7.14
  %scevgep35.7.14 = getelementptr i8, i8* %a, i64 22
  %1982 = load i8, i8* %scevgep35.7.14, align 1
  %1983 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.14 = call zeroext i8 @mult(i8 zeroext %1982, i8 zeroext %1983)
  %conv35.7.14 = zext i8 %call34.7.14 to i32
  %xor36.7.14 = xor i32 %xor.7.14, %conv35.7.14
  %conv37.7.14 = trunc i32 %xor36.7.14 to i8
  store i8 %conv37.7.14, i8* %scevgep41.7.13, align 1
  %scevgep28.7.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1977, i64 0, i64 0, i64 1
  %1984 = bitcast i8* %scevgep28.7.14 to [41 x [41 x i8]]*
  %scevgep41.7.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1978, i64 0, i64 1, i64 0
  %1985 = bitcast i8* %scevgep41.7.14 to [41 x [41 x i8]]*
  %call16.7.15 = call zeroext i8 (...) @rand()
  store i8 %call16.7.15, i8* %scevgep28.7.14, align 1
  %1986 = load i8, i8* %scevgep28.7.14, align 1
  %conv23.7.15 = zext i8 %1986 to i32
  %1987 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.15 = getelementptr i8, i8* %b, i64 23
  %1988 = load i8, i8* %scevgep34.7.15, align 1
  %call28.7.15 = call zeroext i8 @mult(i8 zeroext %1987, i8 zeroext %1988)
  %conv29.7.15 = zext i8 %call28.7.15 to i32
  %xor.7.15 = xor i32 %conv23.7.15, %conv29.7.15
  %scevgep35.7.15 = getelementptr i8, i8* %a, i64 23
  %1989 = load i8, i8* %scevgep35.7.15, align 1
  %1990 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.15 = call zeroext i8 @mult(i8 zeroext %1989, i8 zeroext %1990)
  %conv35.7.15 = zext i8 %call34.7.15 to i32
  %xor36.7.15 = xor i32 %xor.7.15, %conv35.7.15
  %conv37.7.15 = trunc i32 %xor36.7.15 to i8
  store i8 %conv37.7.15, i8* %scevgep41.7.14, align 1
  %scevgep28.7.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1984, i64 0, i64 0, i64 1
  %1991 = bitcast i8* %scevgep28.7.15 to [41 x [41 x i8]]*
  %scevgep41.7.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1985, i64 0, i64 1, i64 0
  %1992 = bitcast i8* %scevgep41.7.15 to [41 x [41 x i8]]*
  %call16.7.16 = call zeroext i8 (...) @rand()
  store i8 %call16.7.16, i8* %scevgep28.7.15, align 1
  %1993 = load i8, i8* %scevgep28.7.15, align 1
  %conv23.7.16 = zext i8 %1993 to i32
  %1994 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.16 = getelementptr i8, i8* %b, i64 24
  %1995 = load i8, i8* %scevgep34.7.16, align 1
  %call28.7.16 = call zeroext i8 @mult(i8 zeroext %1994, i8 zeroext %1995)
  %conv29.7.16 = zext i8 %call28.7.16 to i32
  %xor.7.16 = xor i32 %conv23.7.16, %conv29.7.16
  %scevgep35.7.16 = getelementptr i8, i8* %a, i64 24
  %1996 = load i8, i8* %scevgep35.7.16, align 1
  %1997 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.16 = call zeroext i8 @mult(i8 zeroext %1996, i8 zeroext %1997)
  %conv35.7.16 = zext i8 %call34.7.16 to i32
  %xor36.7.16 = xor i32 %xor.7.16, %conv35.7.16
  %conv37.7.16 = trunc i32 %xor36.7.16 to i8
  store i8 %conv37.7.16, i8* %scevgep41.7.15, align 1
  %scevgep28.7.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1991, i64 0, i64 0, i64 1
  %1998 = bitcast i8* %scevgep28.7.16 to [41 x [41 x i8]]*
  %scevgep41.7.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1992, i64 0, i64 1, i64 0
  %1999 = bitcast i8* %scevgep41.7.16 to [41 x [41 x i8]]*
  %call16.7.17 = call zeroext i8 (...) @rand()
  store i8 %call16.7.17, i8* %scevgep28.7.16, align 1
  %2000 = load i8, i8* %scevgep28.7.16, align 1
  %conv23.7.17 = zext i8 %2000 to i32
  %2001 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.17 = getelementptr i8, i8* %b, i64 25
  %2002 = load i8, i8* %scevgep34.7.17, align 1
  %call28.7.17 = call zeroext i8 @mult(i8 zeroext %2001, i8 zeroext %2002)
  %conv29.7.17 = zext i8 %call28.7.17 to i32
  %xor.7.17 = xor i32 %conv23.7.17, %conv29.7.17
  %scevgep35.7.17 = getelementptr i8, i8* %a, i64 25
  %2003 = load i8, i8* %scevgep35.7.17, align 1
  %2004 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.17 = call zeroext i8 @mult(i8 zeroext %2003, i8 zeroext %2004)
  %conv35.7.17 = zext i8 %call34.7.17 to i32
  %xor36.7.17 = xor i32 %xor.7.17, %conv35.7.17
  %conv37.7.17 = trunc i32 %xor36.7.17 to i8
  store i8 %conv37.7.17, i8* %scevgep41.7.16, align 1
  %scevgep28.7.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1998, i64 0, i64 0, i64 1
  %2005 = bitcast i8* %scevgep28.7.17 to [41 x [41 x i8]]*
  %scevgep41.7.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1999, i64 0, i64 1, i64 0
  %2006 = bitcast i8* %scevgep41.7.17 to [41 x [41 x i8]]*
  %call16.7.18 = call zeroext i8 (...) @rand()
  store i8 %call16.7.18, i8* %scevgep28.7.17, align 1
  %2007 = load i8, i8* %scevgep28.7.17, align 1
  %conv23.7.18 = zext i8 %2007 to i32
  %2008 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.18 = getelementptr i8, i8* %b, i64 26
  %2009 = load i8, i8* %scevgep34.7.18, align 1
  %call28.7.18 = call zeroext i8 @mult(i8 zeroext %2008, i8 zeroext %2009)
  %conv29.7.18 = zext i8 %call28.7.18 to i32
  %xor.7.18 = xor i32 %conv23.7.18, %conv29.7.18
  %scevgep35.7.18 = getelementptr i8, i8* %a, i64 26
  %2010 = load i8, i8* %scevgep35.7.18, align 1
  %2011 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.18 = call zeroext i8 @mult(i8 zeroext %2010, i8 zeroext %2011)
  %conv35.7.18 = zext i8 %call34.7.18 to i32
  %xor36.7.18 = xor i32 %xor.7.18, %conv35.7.18
  %conv37.7.18 = trunc i32 %xor36.7.18 to i8
  store i8 %conv37.7.18, i8* %scevgep41.7.17, align 1
  %scevgep28.7.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2005, i64 0, i64 0, i64 1
  %2012 = bitcast i8* %scevgep28.7.18 to [41 x [41 x i8]]*
  %scevgep41.7.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2006, i64 0, i64 1, i64 0
  %2013 = bitcast i8* %scevgep41.7.18 to [41 x [41 x i8]]*
  %call16.7.19 = call zeroext i8 (...) @rand()
  store i8 %call16.7.19, i8* %scevgep28.7.18, align 1
  %2014 = load i8, i8* %scevgep28.7.18, align 1
  %conv23.7.19 = zext i8 %2014 to i32
  %2015 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.19 = getelementptr i8, i8* %b, i64 27
  %2016 = load i8, i8* %scevgep34.7.19, align 1
  %call28.7.19 = call zeroext i8 @mult(i8 zeroext %2015, i8 zeroext %2016)
  %conv29.7.19 = zext i8 %call28.7.19 to i32
  %xor.7.19 = xor i32 %conv23.7.19, %conv29.7.19
  %scevgep35.7.19 = getelementptr i8, i8* %a, i64 27
  %2017 = load i8, i8* %scevgep35.7.19, align 1
  %2018 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.19 = call zeroext i8 @mult(i8 zeroext %2017, i8 zeroext %2018)
  %conv35.7.19 = zext i8 %call34.7.19 to i32
  %xor36.7.19 = xor i32 %xor.7.19, %conv35.7.19
  %conv37.7.19 = trunc i32 %xor36.7.19 to i8
  store i8 %conv37.7.19, i8* %scevgep41.7.18, align 1
  %scevgep28.7.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2012, i64 0, i64 0, i64 1
  %2019 = bitcast i8* %scevgep28.7.19 to [41 x [41 x i8]]*
  %scevgep41.7.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2013, i64 0, i64 1, i64 0
  %2020 = bitcast i8* %scevgep41.7.19 to [41 x [41 x i8]]*
  %call16.7.20 = call zeroext i8 (...) @rand()
  store i8 %call16.7.20, i8* %scevgep28.7.19, align 1
  %2021 = load i8, i8* %scevgep28.7.19, align 1
  %conv23.7.20 = zext i8 %2021 to i32
  %2022 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.20 = getelementptr i8, i8* %b, i64 28
  %2023 = load i8, i8* %scevgep34.7.20, align 1
  %call28.7.20 = call zeroext i8 @mult(i8 zeroext %2022, i8 zeroext %2023)
  %conv29.7.20 = zext i8 %call28.7.20 to i32
  %xor.7.20 = xor i32 %conv23.7.20, %conv29.7.20
  %scevgep35.7.20 = getelementptr i8, i8* %a, i64 28
  %2024 = load i8, i8* %scevgep35.7.20, align 1
  %2025 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.20 = call zeroext i8 @mult(i8 zeroext %2024, i8 zeroext %2025)
  %conv35.7.20 = zext i8 %call34.7.20 to i32
  %xor36.7.20 = xor i32 %xor.7.20, %conv35.7.20
  %conv37.7.20 = trunc i32 %xor36.7.20 to i8
  store i8 %conv37.7.20, i8* %scevgep41.7.19, align 1
  %scevgep28.7.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2019, i64 0, i64 0, i64 1
  %2026 = bitcast i8* %scevgep28.7.20 to [41 x [41 x i8]]*
  %scevgep41.7.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2020, i64 0, i64 1, i64 0
  %2027 = bitcast i8* %scevgep41.7.20 to [41 x [41 x i8]]*
  %call16.7.21 = call zeroext i8 (...) @rand()
  store i8 %call16.7.21, i8* %scevgep28.7.20, align 1
  %2028 = load i8, i8* %scevgep28.7.20, align 1
  %conv23.7.21 = zext i8 %2028 to i32
  %2029 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.21 = getelementptr i8, i8* %b, i64 29
  %2030 = load i8, i8* %scevgep34.7.21, align 1
  %call28.7.21 = call zeroext i8 @mult(i8 zeroext %2029, i8 zeroext %2030)
  %conv29.7.21 = zext i8 %call28.7.21 to i32
  %xor.7.21 = xor i32 %conv23.7.21, %conv29.7.21
  %scevgep35.7.21 = getelementptr i8, i8* %a, i64 29
  %2031 = load i8, i8* %scevgep35.7.21, align 1
  %2032 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.21 = call zeroext i8 @mult(i8 zeroext %2031, i8 zeroext %2032)
  %conv35.7.21 = zext i8 %call34.7.21 to i32
  %xor36.7.21 = xor i32 %xor.7.21, %conv35.7.21
  %conv37.7.21 = trunc i32 %xor36.7.21 to i8
  store i8 %conv37.7.21, i8* %scevgep41.7.20, align 1
  %scevgep28.7.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2026, i64 0, i64 0, i64 1
  %2033 = bitcast i8* %scevgep28.7.21 to [41 x [41 x i8]]*
  %scevgep41.7.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2027, i64 0, i64 1, i64 0
  %2034 = bitcast i8* %scevgep41.7.21 to [41 x [41 x i8]]*
  %call16.7.22 = call zeroext i8 (...) @rand()
  store i8 %call16.7.22, i8* %scevgep28.7.21, align 1
  %2035 = load i8, i8* %scevgep28.7.21, align 1
  %conv23.7.22 = zext i8 %2035 to i32
  %2036 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.22 = getelementptr i8, i8* %b, i64 30
  %2037 = load i8, i8* %scevgep34.7.22, align 1
  %call28.7.22 = call zeroext i8 @mult(i8 zeroext %2036, i8 zeroext %2037)
  %conv29.7.22 = zext i8 %call28.7.22 to i32
  %xor.7.22 = xor i32 %conv23.7.22, %conv29.7.22
  %scevgep35.7.22 = getelementptr i8, i8* %a, i64 30
  %2038 = load i8, i8* %scevgep35.7.22, align 1
  %2039 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.22 = call zeroext i8 @mult(i8 zeroext %2038, i8 zeroext %2039)
  %conv35.7.22 = zext i8 %call34.7.22 to i32
  %xor36.7.22 = xor i32 %xor.7.22, %conv35.7.22
  %conv37.7.22 = trunc i32 %xor36.7.22 to i8
  store i8 %conv37.7.22, i8* %scevgep41.7.21, align 1
  %scevgep28.7.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2033, i64 0, i64 0, i64 1
  %2040 = bitcast i8* %scevgep28.7.22 to [41 x [41 x i8]]*
  %scevgep41.7.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2034, i64 0, i64 1, i64 0
  %2041 = bitcast i8* %scevgep41.7.22 to [41 x [41 x i8]]*
  %call16.7.23 = call zeroext i8 (...) @rand()
  store i8 %call16.7.23, i8* %scevgep28.7.22, align 1
  %2042 = load i8, i8* %scevgep28.7.22, align 1
  %conv23.7.23 = zext i8 %2042 to i32
  %2043 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.23 = getelementptr i8, i8* %b, i64 31
  %2044 = load i8, i8* %scevgep34.7.23, align 1
  %call28.7.23 = call zeroext i8 @mult(i8 zeroext %2043, i8 zeroext %2044)
  %conv29.7.23 = zext i8 %call28.7.23 to i32
  %xor.7.23 = xor i32 %conv23.7.23, %conv29.7.23
  %scevgep35.7.23 = getelementptr i8, i8* %a, i64 31
  %2045 = load i8, i8* %scevgep35.7.23, align 1
  %2046 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.23 = call zeroext i8 @mult(i8 zeroext %2045, i8 zeroext %2046)
  %conv35.7.23 = zext i8 %call34.7.23 to i32
  %xor36.7.23 = xor i32 %xor.7.23, %conv35.7.23
  %conv37.7.23 = trunc i32 %xor36.7.23 to i8
  store i8 %conv37.7.23, i8* %scevgep41.7.22, align 1
  %scevgep28.7.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2040, i64 0, i64 0, i64 1
  %2047 = bitcast i8* %scevgep28.7.23 to [41 x [41 x i8]]*
  %scevgep41.7.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2041, i64 0, i64 1, i64 0
  %2048 = bitcast i8* %scevgep41.7.23 to [41 x [41 x i8]]*
  %call16.7.24 = call zeroext i8 (...) @rand()
  store i8 %call16.7.24, i8* %scevgep28.7.23, align 1
  %2049 = load i8, i8* %scevgep28.7.23, align 1
  %conv23.7.24 = zext i8 %2049 to i32
  %2050 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.24 = getelementptr i8, i8* %b, i64 32
  %2051 = load i8, i8* %scevgep34.7.24, align 1
  %call28.7.24 = call zeroext i8 @mult(i8 zeroext %2050, i8 zeroext %2051)
  %conv29.7.24 = zext i8 %call28.7.24 to i32
  %xor.7.24 = xor i32 %conv23.7.24, %conv29.7.24
  %scevgep35.7.24 = getelementptr i8, i8* %a, i64 32
  %2052 = load i8, i8* %scevgep35.7.24, align 1
  %2053 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.24 = call zeroext i8 @mult(i8 zeroext %2052, i8 zeroext %2053)
  %conv35.7.24 = zext i8 %call34.7.24 to i32
  %xor36.7.24 = xor i32 %xor.7.24, %conv35.7.24
  %conv37.7.24 = trunc i32 %xor36.7.24 to i8
  store i8 %conv37.7.24, i8* %scevgep41.7.23, align 1
  %scevgep28.7.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2047, i64 0, i64 0, i64 1
  %2054 = bitcast i8* %scevgep28.7.24 to [41 x [41 x i8]]*
  %scevgep41.7.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2048, i64 0, i64 1, i64 0
  %2055 = bitcast i8* %scevgep41.7.24 to [41 x [41 x i8]]*
  %call16.7.25 = call zeroext i8 (...) @rand()
  store i8 %call16.7.25, i8* %scevgep28.7.24, align 1
  %2056 = load i8, i8* %scevgep28.7.24, align 1
  %conv23.7.25 = zext i8 %2056 to i32
  %2057 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.25 = getelementptr i8, i8* %b, i64 33
  %2058 = load i8, i8* %scevgep34.7.25, align 1
  %call28.7.25 = call zeroext i8 @mult(i8 zeroext %2057, i8 zeroext %2058)
  %conv29.7.25 = zext i8 %call28.7.25 to i32
  %xor.7.25 = xor i32 %conv23.7.25, %conv29.7.25
  %scevgep35.7.25 = getelementptr i8, i8* %a, i64 33
  %2059 = load i8, i8* %scevgep35.7.25, align 1
  %2060 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.25 = call zeroext i8 @mult(i8 zeroext %2059, i8 zeroext %2060)
  %conv35.7.25 = zext i8 %call34.7.25 to i32
  %xor36.7.25 = xor i32 %xor.7.25, %conv35.7.25
  %conv37.7.25 = trunc i32 %xor36.7.25 to i8
  store i8 %conv37.7.25, i8* %scevgep41.7.24, align 1
  %scevgep28.7.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2054, i64 0, i64 0, i64 1
  %2061 = bitcast i8* %scevgep28.7.25 to [41 x [41 x i8]]*
  %scevgep41.7.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2055, i64 0, i64 1, i64 0
  %2062 = bitcast i8* %scevgep41.7.25 to [41 x [41 x i8]]*
  %call16.7.26 = call zeroext i8 (...) @rand()
  store i8 %call16.7.26, i8* %scevgep28.7.25, align 1
  %2063 = load i8, i8* %scevgep28.7.25, align 1
  %conv23.7.26 = zext i8 %2063 to i32
  %2064 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.26 = getelementptr i8, i8* %b, i64 34
  %2065 = load i8, i8* %scevgep34.7.26, align 1
  %call28.7.26 = call zeroext i8 @mult(i8 zeroext %2064, i8 zeroext %2065)
  %conv29.7.26 = zext i8 %call28.7.26 to i32
  %xor.7.26 = xor i32 %conv23.7.26, %conv29.7.26
  %scevgep35.7.26 = getelementptr i8, i8* %a, i64 34
  %2066 = load i8, i8* %scevgep35.7.26, align 1
  %2067 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.26 = call zeroext i8 @mult(i8 zeroext %2066, i8 zeroext %2067)
  %conv35.7.26 = zext i8 %call34.7.26 to i32
  %xor36.7.26 = xor i32 %xor.7.26, %conv35.7.26
  %conv37.7.26 = trunc i32 %xor36.7.26 to i8
  store i8 %conv37.7.26, i8* %scevgep41.7.25, align 1
  %scevgep28.7.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2061, i64 0, i64 0, i64 1
  %2068 = bitcast i8* %scevgep28.7.26 to [41 x [41 x i8]]*
  %scevgep41.7.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2062, i64 0, i64 1, i64 0
  %2069 = bitcast i8* %scevgep41.7.26 to [41 x [41 x i8]]*
  %call16.7.27 = call zeroext i8 (...) @rand()
  store i8 %call16.7.27, i8* %scevgep28.7.26, align 1
  %2070 = load i8, i8* %scevgep28.7.26, align 1
  %conv23.7.27 = zext i8 %2070 to i32
  %2071 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.27 = getelementptr i8, i8* %b, i64 35
  %2072 = load i8, i8* %scevgep34.7.27, align 1
  %call28.7.27 = call zeroext i8 @mult(i8 zeroext %2071, i8 zeroext %2072)
  %conv29.7.27 = zext i8 %call28.7.27 to i32
  %xor.7.27 = xor i32 %conv23.7.27, %conv29.7.27
  %scevgep35.7.27 = getelementptr i8, i8* %a, i64 35
  %2073 = load i8, i8* %scevgep35.7.27, align 1
  %2074 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.27 = call zeroext i8 @mult(i8 zeroext %2073, i8 zeroext %2074)
  %conv35.7.27 = zext i8 %call34.7.27 to i32
  %xor36.7.27 = xor i32 %xor.7.27, %conv35.7.27
  %conv37.7.27 = trunc i32 %xor36.7.27 to i8
  store i8 %conv37.7.27, i8* %scevgep41.7.26, align 1
  %scevgep28.7.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2068, i64 0, i64 0, i64 1
  %2075 = bitcast i8* %scevgep28.7.27 to [41 x [41 x i8]]*
  %scevgep41.7.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2069, i64 0, i64 1, i64 0
  %2076 = bitcast i8* %scevgep41.7.27 to [41 x [41 x i8]]*
  %call16.7.28 = call zeroext i8 (...) @rand()
  store i8 %call16.7.28, i8* %scevgep28.7.27, align 1
  %2077 = load i8, i8* %scevgep28.7.27, align 1
  %conv23.7.28 = zext i8 %2077 to i32
  %2078 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.28 = getelementptr i8, i8* %b, i64 36
  %2079 = load i8, i8* %scevgep34.7.28, align 1
  %call28.7.28 = call zeroext i8 @mult(i8 zeroext %2078, i8 zeroext %2079)
  %conv29.7.28 = zext i8 %call28.7.28 to i32
  %xor.7.28 = xor i32 %conv23.7.28, %conv29.7.28
  %scevgep35.7.28 = getelementptr i8, i8* %a, i64 36
  %2080 = load i8, i8* %scevgep35.7.28, align 1
  %2081 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.28 = call zeroext i8 @mult(i8 zeroext %2080, i8 zeroext %2081)
  %conv35.7.28 = zext i8 %call34.7.28 to i32
  %xor36.7.28 = xor i32 %xor.7.28, %conv35.7.28
  %conv37.7.28 = trunc i32 %xor36.7.28 to i8
  store i8 %conv37.7.28, i8* %scevgep41.7.27, align 1
  %scevgep28.7.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2075, i64 0, i64 0, i64 1
  %2082 = bitcast i8* %scevgep28.7.28 to [41 x [41 x i8]]*
  %scevgep41.7.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2076, i64 0, i64 1, i64 0
  %2083 = bitcast i8* %scevgep41.7.28 to [41 x [41 x i8]]*
  %call16.7.29 = call zeroext i8 (...) @rand()
  store i8 %call16.7.29, i8* %scevgep28.7.28, align 1
  %2084 = load i8, i8* %scevgep28.7.28, align 1
  %conv23.7.29 = zext i8 %2084 to i32
  %2085 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.29 = getelementptr i8, i8* %b, i64 37
  %2086 = load i8, i8* %scevgep34.7.29, align 1
  %call28.7.29 = call zeroext i8 @mult(i8 zeroext %2085, i8 zeroext %2086)
  %conv29.7.29 = zext i8 %call28.7.29 to i32
  %xor.7.29 = xor i32 %conv23.7.29, %conv29.7.29
  %scevgep35.7.29 = getelementptr i8, i8* %a, i64 37
  %2087 = load i8, i8* %scevgep35.7.29, align 1
  %2088 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.29 = call zeroext i8 @mult(i8 zeroext %2087, i8 zeroext %2088)
  %conv35.7.29 = zext i8 %call34.7.29 to i32
  %xor36.7.29 = xor i32 %xor.7.29, %conv35.7.29
  %conv37.7.29 = trunc i32 %xor36.7.29 to i8
  store i8 %conv37.7.29, i8* %scevgep41.7.28, align 1
  %scevgep28.7.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2082, i64 0, i64 0, i64 1
  %2089 = bitcast i8* %scevgep28.7.29 to [41 x [41 x i8]]*
  %scevgep41.7.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2083, i64 0, i64 1, i64 0
  %2090 = bitcast i8* %scevgep41.7.29 to [41 x [41 x i8]]*
  %call16.7.30 = call zeroext i8 (...) @rand()
  store i8 %call16.7.30, i8* %scevgep28.7.29, align 1
  %2091 = load i8, i8* %scevgep28.7.29, align 1
  %conv23.7.30 = zext i8 %2091 to i32
  %2092 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.30 = getelementptr i8, i8* %b, i64 38
  %2093 = load i8, i8* %scevgep34.7.30, align 1
  %call28.7.30 = call zeroext i8 @mult(i8 zeroext %2092, i8 zeroext %2093)
  %conv29.7.30 = zext i8 %call28.7.30 to i32
  %xor.7.30 = xor i32 %conv23.7.30, %conv29.7.30
  %scevgep35.7.30 = getelementptr i8, i8* %a, i64 38
  %2094 = load i8, i8* %scevgep35.7.30, align 1
  %2095 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.30 = call zeroext i8 @mult(i8 zeroext %2094, i8 zeroext %2095)
  %conv35.7.30 = zext i8 %call34.7.30 to i32
  %xor36.7.30 = xor i32 %xor.7.30, %conv35.7.30
  %conv37.7.30 = trunc i32 %xor36.7.30 to i8
  store i8 %conv37.7.30, i8* %scevgep41.7.29, align 1
  %scevgep28.7.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2089, i64 0, i64 0, i64 1
  %2096 = bitcast i8* %scevgep28.7.30 to [41 x [41 x i8]]*
  %scevgep41.7.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2090, i64 0, i64 1, i64 0
  %2097 = bitcast i8* %scevgep41.7.30 to [41 x [41 x i8]]*
  %call16.7.31 = call zeroext i8 (...) @rand()
  store i8 %call16.7.31, i8* %scevgep28.7.30, align 1
  %2098 = load i8, i8* %scevgep28.7.30, align 1
  %conv23.7.31 = zext i8 %2098 to i32
  %2099 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.31 = getelementptr i8, i8* %b, i64 39
  %2100 = load i8, i8* %scevgep34.7.31, align 1
  %call28.7.31 = call zeroext i8 @mult(i8 zeroext %2099, i8 zeroext %2100)
  %conv29.7.31 = zext i8 %call28.7.31 to i32
  %xor.7.31 = xor i32 %conv23.7.31, %conv29.7.31
  %scevgep35.7.31 = getelementptr i8, i8* %a, i64 39
  %2101 = load i8, i8* %scevgep35.7.31, align 1
  %2102 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.31 = call zeroext i8 @mult(i8 zeroext %2101, i8 zeroext %2102)
  %conv35.7.31 = zext i8 %call34.7.31 to i32
  %xor36.7.31 = xor i32 %xor.7.31, %conv35.7.31
  %conv37.7.31 = trunc i32 %xor36.7.31 to i8
  store i8 %conv37.7.31, i8* %scevgep41.7.30, align 1
  %scevgep28.7.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2096, i64 0, i64 0, i64 1
  %scevgep41.7.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2097, i64 0, i64 1, i64 0
  %call16.7.32 = call zeroext i8 (...) @rand()
  store i8 %call16.7.32, i8* %scevgep28.7.31, align 1
  %2103 = load i8, i8* %scevgep28.7.31, align 1
  %conv23.7.32 = zext i8 %2103 to i32
  %2104 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.32 = getelementptr i8, i8* %b, i64 40
  %2105 = load i8, i8* %scevgep34.7.32, align 1
  %call28.7.32 = call zeroext i8 @mult(i8 zeroext %2104, i8 zeroext %2105)
  %conv29.7.32 = zext i8 %call28.7.32 to i32
  %xor.7.32 = xor i32 %conv23.7.32, %conv29.7.32
  %scevgep35.7.32 = getelementptr i8, i8* %a, i64 40
  %2106 = load i8, i8* %scevgep35.7.32, align 1
  %2107 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.32 = call zeroext i8 @mult(i8 zeroext %2106, i8 zeroext %2107)
  %conv35.7.32 = zext i8 %call34.7.32 to i32
  %xor36.7.32 = xor i32 %xor.7.32, %conv35.7.32
  %conv37.7.32 = trunc i32 %xor36.7.32 to i8
  store i8 %conv37.7.32, i8* %scevgep41.7.31, align 1
  %scevgep26.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1879, i64 0, i64 1, i64 1
  %2108 = bitcast i8* %scevgep26.7 to [41 x [41 x i8]]*
  %scevgep39.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %1880, i64 0, i64 1, i64 1
  %2109 = bitcast i8* %scevgep39.7 to [41 x [41 x i8]]*
  %arrayidx25.8 = getelementptr inbounds i8, i8* %a, i64 8
  %arrayidx33.8 = getelementptr inbounds i8, i8* %b, i64 8
  %call16.8 = call zeroext i8 (...) @rand()
  store i8 %call16.8, i8* %scevgep26.7, align 1
  %2110 = load i8, i8* %scevgep26.7, align 1
  %conv23.8 = zext i8 %2110 to i32
  %2111 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8 = getelementptr i8, i8* %b, i64 9
  %2112 = load i8, i8* %scevgep34.8, align 1
  %call28.8 = call zeroext i8 @mult(i8 zeroext %2111, i8 zeroext %2112)
  %conv29.8 = zext i8 %call28.8 to i32
  %xor.8 = xor i32 %conv23.8, %conv29.8
  %scevgep35.8 = getelementptr i8, i8* %a, i64 9
  %2113 = load i8, i8* %scevgep35.8, align 1
  %2114 = load i8, i8* %arrayidx33.8, align 1
  %call34.8 = call zeroext i8 @mult(i8 zeroext %2113, i8 zeroext %2114)
  %conv35.8 = zext i8 %call34.8 to i32
  %xor36.8 = xor i32 %xor.8, %conv35.8
  %conv37.8 = trunc i32 %xor36.8 to i8
  store i8 %conv37.8, i8* %scevgep39.7, align 1
  %scevgep28.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2108, i64 0, i64 0, i64 1
  %2115 = bitcast i8* %scevgep28.8 to [41 x [41 x i8]]*
  %scevgep41.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2109, i64 0, i64 1, i64 0
  %2116 = bitcast i8* %scevgep41.8 to [41 x [41 x i8]]*
  %call16.8.1 = call zeroext i8 (...) @rand()
  store i8 %call16.8.1, i8* %scevgep28.8, align 1
  %2117 = load i8, i8* %scevgep28.8, align 1
  %conv23.8.1 = zext i8 %2117 to i32
  %2118 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.1 = getelementptr i8, i8* %b, i64 10
  %2119 = load i8, i8* %scevgep34.8.1, align 1
  %call28.8.1 = call zeroext i8 @mult(i8 zeroext %2118, i8 zeroext %2119)
  %conv29.8.1 = zext i8 %call28.8.1 to i32
  %xor.8.1 = xor i32 %conv23.8.1, %conv29.8.1
  %scevgep35.8.1 = getelementptr i8, i8* %a, i64 10
  %2120 = load i8, i8* %scevgep35.8.1, align 1
  %2121 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.1 = call zeroext i8 @mult(i8 zeroext %2120, i8 zeroext %2121)
  %conv35.8.1 = zext i8 %call34.8.1 to i32
  %xor36.8.1 = xor i32 %xor.8.1, %conv35.8.1
  %conv37.8.1 = trunc i32 %xor36.8.1 to i8
  store i8 %conv37.8.1, i8* %scevgep41.8, align 1
  %scevgep28.8.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2115, i64 0, i64 0, i64 1
  %2122 = bitcast i8* %scevgep28.8.1 to [41 x [41 x i8]]*
  %scevgep41.8.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2116, i64 0, i64 1, i64 0
  %2123 = bitcast i8* %scevgep41.8.1 to [41 x [41 x i8]]*
  %call16.8.2 = call zeroext i8 (...) @rand()
  store i8 %call16.8.2, i8* %scevgep28.8.1, align 1
  %2124 = load i8, i8* %scevgep28.8.1, align 1
  %conv23.8.2 = zext i8 %2124 to i32
  %2125 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.2 = getelementptr i8, i8* %b, i64 11
  %2126 = load i8, i8* %scevgep34.8.2, align 1
  %call28.8.2 = call zeroext i8 @mult(i8 zeroext %2125, i8 zeroext %2126)
  %conv29.8.2 = zext i8 %call28.8.2 to i32
  %xor.8.2 = xor i32 %conv23.8.2, %conv29.8.2
  %scevgep35.8.2 = getelementptr i8, i8* %a, i64 11
  %2127 = load i8, i8* %scevgep35.8.2, align 1
  %2128 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.2 = call zeroext i8 @mult(i8 zeroext %2127, i8 zeroext %2128)
  %conv35.8.2 = zext i8 %call34.8.2 to i32
  %xor36.8.2 = xor i32 %xor.8.2, %conv35.8.2
  %conv37.8.2 = trunc i32 %xor36.8.2 to i8
  store i8 %conv37.8.2, i8* %scevgep41.8.1, align 1
  %scevgep28.8.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2122, i64 0, i64 0, i64 1
  %2129 = bitcast i8* %scevgep28.8.2 to [41 x [41 x i8]]*
  %scevgep41.8.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2123, i64 0, i64 1, i64 0
  %2130 = bitcast i8* %scevgep41.8.2 to [41 x [41 x i8]]*
  %call16.8.3 = call zeroext i8 (...) @rand()
  store i8 %call16.8.3, i8* %scevgep28.8.2, align 1
  %2131 = load i8, i8* %scevgep28.8.2, align 1
  %conv23.8.3 = zext i8 %2131 to i32
  %2132 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.3 = getelementptr i8, i8* %b, i64 12
  %2133 = load i8, i8* %scevgep34.8.3, align 1
  %call28.8.3 = call zeroext i8 @mult(i8 zeroext %2132, i8 zeroext %2133)
  %conv29.8.3 = zext i8 %call28.8.3 to i32
  %xor.8.3 = xor i32 %conv23.8.3, %conv29.8.3
  %scevgep35.8.3 = getelementptr i8, i8* %a, i64 12
  %2134 = load i8, i8* %scevgep35.8.3, align 1
  %2135 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.3 = call zeroext i8 @mult(i8 zeroext %2134, i8 zeroext %2135)
  %conv35.8.3 = zext i8 %call34.8.3 to i32
  %xor36.8.3 = xor i32 %xor.8.3, %conv35.8.3
  %conv37.8.3 = trunc i32 %xor36.8.3 to i8
  store i8 %conv37.8.3, i8* %scevgep41.8.2, align 1
  %scevgep28.8.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2129, i64 0, i64 0, i64 1
  %2136 = bitcast i8* %scevgep28.8.3 to [41 x [41 x i8]]*
  %scevgep41.8.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2130, i64 0, i64 1, i64 0
  %2137 = bitcast i8* %scevgep41.8.3 to [41 x [41 x i8]]*
  %call16.8.4 = call zeroext i8 (...) @rand()
  store i8 %call16.8.4, i8* %scevgep28.8.3, align 1
  %2138 = load i8, i8* %scevgep28.8.3, align 1
  %conv23.8.4 = zext i8 %2138 to i32
  %2139 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.4 = getelementptr i8, i8* %b, i64 13
  %2140 = load i8, i8* %scevgep34.8.4, align 1
  %call28.8.4 = call zeroext i8 @mult(i8 zeroext %2139, i8 zeroext %2140)
  %conv29.8.4 = zext i8 %call28.8.4 to i32
  %xor.8.4 = xor i32 %conv23.8.4, %conv29.8.4
  %scevgep35.8.4 = getelementptr i8, i8* %a, i64 13
  %2141 = load i8, i8* %scevgep35.8.4, align 1
  %2142 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.4 = call zeroext i8 @mult(i8 zeroext %2141, i8 zeroext %2142)
  %conv35.8.4 = zext i8 %call34.8.4 to i32
  %xor36.8.4 = xor i32 %xor.8.4, %conv35.8.4
  %conv37.8.4 = trunc i32 %xor36.8.4 to i8
  store i8 %conv37.8.4, i8* %scevgep41.8.3, align 1
  %scevgep28.8.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2136, i64 0, i64 0, i64 1
  %2143 = bitcast i8* %scevgep28.8.4 to [41 x [41 x i8]]*
  %scevgep41.8.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2137, i64 0, i64 1, i64 0
  %2144 = bitcast i8* %scevgep41.8.4 to [41 x [41 x i8]]*
  %call16.8.5 = call zeroext i8 (...) @rand()
  store i8 %call16.8.5, i8* %scevgep28.8.4, align 1
  %2145 = load i8, i8* %scevgep28.8.4, align 1
  %conv23.8.5 = zext i8 %2145 to i32
  %2146 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.5 = getelementptr i8, i8* %b, i64 14
  %2147 = load i8, i8* %scevgep34.8.5, align 1
  %call28.8.5 = call zeroext i8 @mult(i8 zeroext %2146, i8 zeroext %2147)
  %conv29.8.5 = zext i8 %call28.8.5 to i32
  %xor.8.5 = xor i32 %conv23.8.5, %conv29.8.5
  %scevgep35.8.5 = getelementptr i8, i8* %a, i64 14
  %2148 = load i8, i8* %scevgep35.8.5, align 1
  %2149 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.5 = call zeroext i8 @mult(i8 zeroext %2148, i8 zeroext %2149)
  %conv35.8.5 = zext i8 %call34.8.5 to i32
  %xor36.8.5 = xor i32 %xor.8.5, %conv35.8.5
  %conv37.8.5 = trunc i32 %xor36.8.5 to i8
  store i8 %conv37.8.5, i8* %scevgep41.8.4, align 1
  %scevgep28.8.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2143, i64 0, i64 0, i64 1
  %2150 = bitcast i8* %scevgep28.8.5 to [41 x [41 x i8]]*
  %scevgep41.8.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2144, i64 0, i64 1, i64 0
  %2151 = bitcast i8* %scevgep41.8.5 to [41 x [41 x i8]]*
  %call16.8.6 = call zeroext i8 (...) @rand()
  store i8 %call16.8.6, i8* %scevgep28.8.5, align 1
  %2152 = load i8, i8* %scevgep28.8.5, align 1
  %conv23.8.6 = zext i8 %2152 to i32
  %2153 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.6 = getelementptr i8, i8* %b, i64 15
  %2154 = load i8, i8* %scevgep34.8.6, align 1
  %call28.8.6 = call zeroext i8 @mult(i8 zeroext %2153, i8 zeroext %2154)
  %conv29.8.6 = zext i8 %call28.8.6 to i32
  %xor.8.6 = xor i32 %conv23.8.6, %conv29.8.6
  %scevgep35.8.6 = getelementptr i8, i8* %a, i64 15
  %2155 = load i8, i8* %scevgep35.8.6, align 1
  %2156 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.6 = call zeroext i8 @mult(i8 zeroext %2155, i8 zeroext %2156)
  %conv35.8.6 = zext i8 %call34.8.6 to i32
  %xor36.8.6 = xor i32 %xor.8.6, %conv35.8.6
  %conv37.8.6 = trunc i32 %xor36.8.6 to i8
  store i8 %conv37.8.6, i8* %scevgep41.8.5, align 1
  %scevgep28.8.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2150, i64 0, i64 0, i64 1
  %2157 = bitcast i8* %scevgep28.8.6 to [41 x [41 x i8]]*
  %scevgep41.8.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2151, i64 0, i64 1, i64 0
  %2158 = bitcast i8* %scevgep41.8.6 to [41 x [41 x i8]]*
  %call16.8.7 = call zeroext i8 (...) @rand()
  store i8 %call16.8.7, i8* %scevgep28.8.6, align 1
  %2159 = load i8, i8* %scevgep28.8.6, align 1
  %conv23.8.7 = zext i8 %2159 to i32
  %2160 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.7 = getelementptr i8, i8* %b, i64 16
  %2161 = load i8, i8* %scevgep34.8.7, align 1
  %call28.8.7 = call zeroext i8 @mult(i8 zeroext %2160, i8 zeroext %2161)
  %conv29.8.7 = zext i8 %call28.8.7 to i32
  %xor.8.7 = xor i32 %conv23.8.7, %conv29.8.7
  %scevgep35.8.7 = getelementptr i8, i8* %a, i64 16
  %2162 = load i8, i8* %scevgep35.8.7, align 1
  %2163 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.7 = call zeroext i8 @mult(i8 zeroext %2162, i8 zeroext %2163)
  %conv35.8.7 = zext i8 %call34.8.7 to i32
  %xor36.8.7 = xor i32 %xor.8.7, %conv35.8.7
  %conv37.8.7 = trunc i32 %xor36.8.7 to i8
  store i8 %conv37.8.7, i8* %scevgep41.8.6, align 1
  %scevgep28.8.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2157, i64 0, i64 0, i64 1
  %2164 = bitcast i8* %scevgep28.8.7 to [41 x [41 x i8]]*
  %scevgep41.8.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2158, i64 0, i64 1, i64 0
  %2165 = bitcast i8* %scevgep41.8.7 to [41 x [41 x i8]]*
  %call16.8.8 = call zeroext i8 (...) @rand()
  store i8 %call16.8.8, i8* %scevgep28.8.7, align 1
  %2166 = load i8, i8* %scevgep28.8.7, align 1
  %conv23.8.8 = zext i8 %2166 to i32
  %2167 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.8 = getelementptr i8, i8* %b, i64 17
  %2168 = load i8, i8* %scevgep34.8.8, align 1
  %call28.8.8 = call zeroext i8 @mult(i8 zeroext %2167, i8 zeroext %2168)
  %conv29.8.8 = zext i8 %call28.8.8 to i32
  %xor.8.8 = xor i32 %conv23.8.8, %conv29.8.8
  %scevgep35.8.8 = getelementptr i8, i8* %a, i64 17
  %2169 = load i8, i8* %scevgep35.8.8, align 1
  %2170 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.8 = call zeroext i8 @mult(i8 zeroext %2169, i8 zeroext %2170)
  %conv35.8.8 = zext i8 %call34.8.8 to i32
  %xor36.8.8 = xor i32 %xor.8.8, %conv35.8.8
  %conv37.8.8 = trunc i32 %xor36.8.8 to i8
  store i8 %conv37.8.8, i8* %scevgep41.8.7, align 1
  %scevgep28.8.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2164, i64 0, i64 0, i64 1
  %2171 = bitcast i8* %scevgep28.8.8 to [41 x [41 x i8]]*
  %scevgep41.8.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2165, i64 0, i64 1, i64 0
  %2172 = bitcast i8* %scevgep41.8.8 to [41 x [41 x i8]]*
  %call16.8.9 = call zeroext i8 (...) @rand()
  store i8 %call16.8.9, i8* %scevgep28.8.8, align 1
  %2173 = load i8, i8* %scevgep28.8.8, align 1
  %conv23.8.9 = zext i8 %2173 to i32
  %2174 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.9 = getelementptr i8, i8* %b, i64 18
  %2175 = load i8, i8* %scevgep34.8.9, align 1
  %call28.8.9 = call zeroext i8 @mult(i8 zeroext %2174, i8 zeroext %2175)
  %conv29.8.9 = zext i8 %call28.8.9 to i32
  %xor.8.9 = xor i32 %conv23.8.9, %conv29.8.9
  %scevgep35.8.9 = getelementptr i8, i8* %a, i64 18
  %2176 = load i8, i8* %scevgep35.8.9, align 1
  %2177 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.9 = call zeroext i8 @mult(i8 zeroext %2176, i8 zeroext %2177)
  %conv35.8.9 = zext i8 %call34.8.9 to i32
  %xor36.8.9 = xor i32 %xor.8.9, %conv35.8.9
  %conv37.8.9 = trunc i32 %xor36.8.9 to i8
  store i8 %conv37.8.9, i8* %scevgep41.8.8, align 1
  %scevgep28.8.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2171, i64 0, i64 0, i64 1
  %2178 = bitcast i8* %scevgep28.8.9 to [41 x [41 x i8]]*
  %scevgep41.8.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2172, i64 0, i64 1, i64 0
  %2179 = bitcast i8* %scevgep41.8.9 to [41 x [41 x i8]]*
  %call16.8.10 = call zeroext i8 (...) @rand()
  store i8 %call16.8.10, i8* %scevgep28.8.9, align 1
  %2180 = load i8, i8* %scevgep28.8.9, align 1
  %conv23.8.10 = zext i8 %2180 to i32
  %2181 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.10 = getelementptr i8, i8* %b, i64 19
  %2182 = load i8, i8* %scevgep34.8.10, align 1
  %call28.8.10 = call zeroext i8 @mult(i8 zeroext %2181, i8 zeroext %2182)
  %conv29.8.10 = zext i8 %call28.8.10 to i32
  %xor.8.10 = xor i32 %conv23.8.10, %conv29.8.10
  %scevgep35.8.10 = getelementptr i8, i8* %a, i64 19
  %2183 = load i8, i8* %scevgep35.8.10, align 1
  %2184 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.10 = call zeroext i8 @mult(i8 zeroext %2183, i8 zeroext %2184)
  %conv35.8.10 = zext i8 %call34.8.10 to i32
  %xor36.8.10 = xor i32 %xor.8.10, %conv35.8.10
  %conv37.8.10 = trunc i32 %xor36.8.10 to i8
  store i8 %conv37.8.10, i8* %scevgep41.8.9, align 1
  %scevgep28.8.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2178, i64 0, i64 0, i64 1
  %2185 = bitcast i8* %scevgep28.8.10 to [41 x [41 x i8]]*
  %scevgep41.8.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2179, i64 0, i64 1, i64 0
  %2186 = bitcast i8* %scevgep41.8.10 to [41 x [41 x i8]]*
  %call16.8.11 = call zeroext i8 (...) @rand()
  store i8 %call16.8.11, i8* %scevgep28.8.10, align 1
  %2187 = load i8, i8* %scevgep28.8.10, align 1
  %conv23.8.11 = zext i8 %2187 to i32
  %2188 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.11 = getelementptr i8, i8* %b, i64 20
  %2189 = load i8, i8* %scevgep34.8.11, align 1
  %call28.8.11 = call zeroext i8 @mult(i8 zeroext %2188, i8 zeroext %2189)
  %conv29.8.11 = zext i8 %call28.8.11 to i32
  %xor.8.11 = xor i32 %conv23.8.11, %conv29.8.11
  %scevgep35.8.11 = getelementptr i8, i8* %a, i64 20
  %2190 = load i8, i8* %scevgep35.8.11, align 1
  %2191 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.11 = call zeroext i8 @mult(i8 zeroext %2190, i8 zeroext %2191)
  %conv35.8.11 = zext i8 %call34.8.11 to i32
  %xor36.8.11 = xor i32 %xor.8.11, %conv35.8.11
  %conv37.8.11 = trunc i32 %xor36.8.11 to i8
  store i8 %conv37.8.11, i8* %scevgep41.8.10, align 1
  %scevgep28.8.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2185, i64 0, i64 0, i64 1
  %2192 = bitcast i8* %scevgep28.8.11 to [41 x [41 x i8]]*
  %scevgep41.8.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2186, i64 0, i64 1, i64 0
  %2193 = bitcast i8* %scevgep41.8.11 to [41 x [41 x i8]]*
  %call16.8.12 = call zeroext i8 (...) @rand()
  store i8 %call16.8.12, i8* %scevgep28.8.11, align 1
  %2194 = load i8, i8* %scevgep28.8.11, align 1
  %conv23.8.12 = zext i8 %2194 to i32
  %2195 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.12 = getelementptr i8, i8* %b, i64 21
  %2196 = load i8, i8* %scevgep34.8.12, align 1
  %call28.8.12 = call zeroext i8 @mult(i8 zeroext %2195, i8 zeroext %2196)
  %conv29.8.12 = zext i8 %call28.8.12 to i32
  %xor.8.12 = xor i32 %conv23.8.12, %conv29.8.12
  %scevgep35.8.12 = getelementptr i8, i8* %a, i64 21
  %2197 = load i8, i8* %scevgep35.8.12, align 1
  %2198 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.12 = call zeroext i8 @mult(i8 zeroext %2197, i8 zeroext %2198)
  %conv35.8.12 = zext i8 %call34.8.12 to i32
  %xor36.8.12 = xor i32 %xor.8.12, %conv35.8.12
  %conv37.8.12 = trunc i32 %xor36.8.12 to i8
  store i8 %conv37.8.12, i8* %scevgep41.8.11, align 1
  %scevgep28.8.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2192, i64 0, i64 0, i64 1
  %2199 = bitcast i8* %scevgep28.8.12 to [41 x [41 x i8]]*
  %scevgep41.8.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2193, i64 0, i64 1, i64 0
  %2200 = bitcast i8* %scevgep41.8.12 to [41 x [41 x i8]]*
  %call16.8.13 = call zeroext i8 (...) @rand()
  store i8 %call16.8.13, i8* %scevgep28.8.12, align 1
  %2201 = load i8, i8* %scevgep28.8.12, align 1
  %conv23.8.13 = zext i8 %2201 to i32
  %2202 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.13 = getelementptr i8, i8* %b, i64 22
  %2203 = load i8, i8* %scevgep34.8.13, align 1
  %call28.8.13 = call zeroext i8 @mult(i8 zeroext %2202, i8 zeroext %2203)
  %conv29.8.13 = zext i8 %call28.8.13 to i32
  %xor.8.13 = xor i32 %conv23.8.13, %conv29.8.13
  %scevgep35.8.13 = getelementptr i8, i8* %a, i64 22
  %2204 = load i8, i8* %scevgep35.8.13, align 1
  %2205 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.13 = call zeroext i8 @mult(i8 zeroext %2204, i8 zeroext %2205)
  %conv35.8.13 = zext i8 %call34.8.13 to i32
  %xor36.8.13 = xor i32 %xor.8.13, %conv35.8.13
  %conv37.8.13 = trunc i32 %xor36.8.13 to i8
  store i8 %conv37.8.13, i8* %scevgep41.8.12, align 1
  %scevgep28.8.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2199, i64 0, i64 0, i64 1
  %2206 = bitcast i8* %scevgep28.8.13 to [41 x [41 x i8]]*
  %scevgep41.8.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2200, i64 0, i64 1, i64 0
  %2207 = bitcast i8* %scevgep41.8.13 to [41 x [41 x i8]]*
  %call16.8.14 = call zeroext i8 (...) @rand()
  store i8 %call16.8.14, i8* %scevgep28.8.13, align 1
  %2208 = load i8, i8* %scevgep28.8.13, align 1
  %conv23.8.14 = zext i8 %2208 to i32
  %2209 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.14 = getelementptr i8, i8* %b, i64 23
  %2210 = load i8, i8* %scevgep34.8.14, align 1
  %call28.8.14 = call zeroext i8 @mult(i8 zeroext %2209, i8 zeroext %2210)
  %conv29.8.14 = zext i8 %call28.8.14 to i32
  %xor.8.14 = xor i32 %conv23.8.14, %conv29.8.14
  %scevgep35.8.14 = getelementptr i8, i8* %a, i64 23
  %2211 = load i8, i8* %scevgep35.8.14, align 1
  %2212 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.14 = call zeroext i8 @mult(i8 zeroext %2211, i8 zeroext %2212)
  %conv35.8.14 = zext i8 %call34.8.14 to i32
  %xor36.8.14 = xor i32 %xor.8.14, %conv35.8.14
  %conv37.8.14 = trunc i32 %xor36.8.14 to i8
  store i8 %conv37.8.14, i8* %scevgep41.8.13, align 1
  %scevgep28.8.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2206, i64 0, i64 0, i64 1
  %2213 = bitcast i8* %scevgep28.8.14 to [41 x [41 x i8]]*
  %scevgep41.8.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2207, i64 0, i64 1, i64 0
  %2214 = bitcast i8* %scevgep41.8.14 to [41 x [41 x i8]]*
  %call16.8.15 = call zeroext i8 (...) @rand()
  store i8 %call16.8.15, i8* %scevgep28.8.14, align 1
  %2215 = load i8, i8* %scevgep28.8.14, align 1
  %conv23.8.15 = zext i8 %2215 to i32
  %2216 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.15 = getelementptr i8, i8* %b, i64 24
  %2217 = load i8, i8* %scevgep34.8.15, align 1
  %call28.8.15 = call zeroext i8 @mult(i8 zeroext %2216, i8 zeroext %2217)
  %conv29.8.15 = zext i8 %call28.8.15 to i32
  %xor.8.15 = xor i32 %conv23.8.15, %conv29.8.15
  %scevgep35.8.15 = getelementptr i8, i8* %a, i64 24
  %2218 = load i8, i8* %scevgep35.8.15, align 1
  %2219 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.15 = call zeroext i8 @mult(i8 zeroext %2218, i8 zeroext %2219)
  %conv35.8.15 = zext i8 %call34.8.15 to i32
  %xor36.8.15 = xor i32 %xor.8.15, %conv35.8.15
  %conv37.8.15 = trunc i32 %xor36.8.15 to i8
  store i8 %conv37.8.15, i8* %scevgep41.8.14, align 1
  %scevgep28.8.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2213, i64 0, i64 0, i64 1
  %2220 = bitcast i8* %scevgep28.8.15 to [41 x [41 x i8]]*
  %scevgep41.8.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2214, i64 0, i64 1, i64 0
  %2221 = bitcast i8* %scevgep41.8.15 to [41 x [41 x i8]]*
  %call16.8.16 = call zeroext i8 (...) @rand()
  store i8 %call16.8.16, i8* %scevgep28.8.15, align 1
  %2222 = load i8, i8* %scevgep28.8.15, align 1
  %conv23.8.16 = zext i8 %2222 to i32
  %2223 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.16 = getelementptr i8, i8* %b, i64 25
  %2224 = load i8, i8* %scevgep34.8.16, align 1
  %call28.8.16 = call zeroext i8 @mult(i8 zeroext %2223, i8 zeroext %2224)
  %conv29.8.16 = zext i8 %call28.8.16 to i32
  %xor.8.16 = xor i32 %conv23.8.16, %conv29.8.16
  %scevgep35.8.16 = getelementptr i8, i8* %a, i64 25
  %2225 = load i8, i8* %scevgep35.8.16, align 1
  %2226 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.16 = call zeroext i8 @mult(i8 zeroext %2225, i8 zeroext %2226)
  %conv35.8.16 = zext i8 %call34.8.16 to i32
  %xor36.8.16 = xor i32 %xor.8.16, %conv35.8.16
  %conv37.8.16 = trunc i32 %xor36.8.16 to i8
  store i8 %conv37.8.16, i8* %scevgep41.8.15, align 1
  %scevgep28.8.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2220, i64 0, i64 0, i64 1
  %2227 = bitcast i8* %scevgep28.8.16 to [41 x [41 x i8]]*
  %scevgep41.8.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2221, i64 0, i64 1, i64 0
  %2228 = bitcast i8* %scevgep41.8.16 to [41 x [41 x i8]]*
  %call16.8.17 = call zeroext i8 (...) @rand()
  store i8 %call16.8.17, i8* %scevgep28.8.16, align 1
  %2229 = load i8, i8* %scevgep28.8.16, align 1
  %conv23.8.17 = zext i8 %2229 to i32
  %2230 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.17 = getelementptr i8, i8* %b, i64 26
  %2231 = load i8, i8* %scevgep34.8.17, align 1
  %call28.8.17 = call zeroext i8 @mult(i8 zeroext %2230, i8 zeroext %2231)
  %conv29.8.17 = zext i8 %call28.8.17 to i32
  %xor.8.17 = xor i32 %conv23.8.17, %conv29.8.17
  %scevgep35.8.17 = getelementptr i8, i8* %a, i64 26
  %2232 = load i8, i8* %scevgep35.8.17, align 1
  %2233 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.17 = call zeroext i8 @mult(i8 zeroext %2232, i8 zeroext %2233)
  %conv35.8.17 = zext i8 %call34.8.17 to i32
  %xor36.8.17 = xor i32 %xor.8.17, %conv35.8.17
  %conv37.8.17 = trunc i32 %xor36.8.17 to i8
  store i8 %conv37.8.17, i8* %scevgep41.8.16, align 1
  %scevgep28.8.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2227, i64 0, i64 0, i64 1
  %2234 = bitcast i8* %scevgep28.8.17 to [41 x [41 x i8]]*
  %scevgep41.8.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2228, i64 0, i64 1, i64 0
  %2235 = bitcast i8* %scevgep41.8.17 to [41 x [41 x i8]]*
  %call16.8.18 = call zeroext i8 (...) @rand()
  store i8 %call16.8.18, i8* %scevgep28.8.17, align 1
  %2236 = load i8, i8* %scevgep28.8.17, align 1
  %conv23.8.18 = zext i8 %2236 to i32
  %2237 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.18 = getelementptr i8, i8* %b, i64 27
  %2238 = load i8, i8* %scevgep34.8.18, align 1
  %call28.8.18 = call zeroext i8 @mult(i8 zeroext %2237, i8 zeroext %2238)
  %conv29.8.18 = zext i8 %call28.8.18 to i32
  %xor.8.18 = xor i32 %conv23.8.18, %conv29.8.18
  %scevgep35.8.18 = getelementptr i8, i8* %a, i64 27
  %2239 = load i8, i8* %scevgep35.8.18, align 1
  %2240 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.18 = call zeroext i8 @mult(i8 zeroext %2239, i8 zeroext %2240)
  %conv35.8.18 = zext i8 %call34.8.18 to i32
  %xor36.8.18 = xor i32 %xor.8.18, %conv35.8.18
  %conv37.8.18 = trunc i32 %xor36.8.18 to i8
  store i8 %conv37.8.18, i8* %scevgep41.8.17, align 1
  %scevgep28.8.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2234, i64 0, i64 0, i64 1
  %2241 = bitcast i8* %scevgep28.8.18 to [41 x [41 x i8]]*
  %scevgep41.8.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2235, i64 0, i64 1, i64 0
  %2242 = bitcast i8* %scevgep41.8.18 to [41 x [41 x i8]]*
  %call16.8.19 = call zeroext i8 (...) @rand()
  store i8 %call16.8.19, i8* %scevgep28.8.18, align 1
  %2243 = load i8, i8* %scevgep28.8.18, align 1
  %conv23.8.19 = zext i8 %2243 to i32
  %2244 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.19 = getelementptr i8, i8* %b, i64 28
  %2245 = load i8, i8* %scevgep34.8.19, align 1
  %call28.8.19 = call zeroext i8 @mult(i8 zeroext %2244, i8 zeroext %2245)
  %conv29.8.19 = zext i8 %call28.8.19 to i32
  %xor.8.19 = xor i32 %conv23.8.19, %conv29.8.19
  %scevgep35.8.19 = getelementptr i8, i8* %a, i64 28
  %2246 = load i8, i8* %scevgep35.8.19, align 1
  %2247 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.19 = call zeroext i8 @mult(i8 zeroext %2246, i8 zeroext %2247)
  %conv35.8.19 = zext i8 %call34.8.19 to i32
  %xor36.8.19 = xor i32 %xor.8.19, %conv35.8.19
  %conv37.8.19 = trunc i32 %xor36.8.19 to i8
  store i8 %conv37.8.19, i8* %scevgep41.8.18, align 1
  %scevgep28.8.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2241, i64 0, i64 0, i64 1
  %2248 = bitcast i8* %scevgep28.8.19 to [41 x [41 x i8]]*
  %scevgep41.8.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2242, i64 0, i64 1, i64 0
  %2249 = bitcast i8* %scevgep41.8.19 to [41 x [41 x i8]]*
  %call16.8.20 = call zeroext i8 (...) @rand()
  store i8 %call16.8.20, i8* %scevgep28.8.19, align 1
  %2250 = load i8, i8* %scevgep28.8.19, align 1
  %conv23.8.20 = zext i8 %2250 to i32
  %2251 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.20 = getelementptr i8, i8* %b, i64 29
  %2252 = load i8, i8* %scevgep34.8.20, align 1
  %call28.8.20 = call zeroext i8 @mult(i8 zeroext %2251, i8 zeroext %2252)
  %conv29.8.20 = zext i8 %call28.8.20 to i32
  %xor.8.20 = xor i32 %conv23.8.20, %conv29.8.20
  %scevgep35.8.20 = getelementptr i8, i8* %a, i64 29
  %2253 = load i8, i8* %scevgep35.8.20, align 1
  %2254 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.20 = call zeroext i8 @mult(i8 zeroext %2253, i8 zeroext %2254)
  %conv35.8.20 = zext i8 %call34.8.20 to i32
  %xor36.8.20 = xor i32 %xor.8.20, %conv35.8.20
  %conv37.8.20 = trunc i32 %xor36.8.20 to i8
  store i8 %conv37.8.20, i8* %scevgep41.8.19, align 1
  %scevgep28.8.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2248, i64 0, i64 0, i64 1
  %2255 = bitcast i8* %scevgep28.8.20 to [41 x [41 x i8]]*
  %scevgep41.8.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2249, i64 0, i64 1, i64 0
  %2256 = bitcast i8* %scevgep41.8.20 to [41 x [41 x i8]]*
  %call16.8.21 = call zeroext i8 (...) @rand()
  store i8 %call16.8.21, i8* %scevgep28.8.20, align 1
  %2257 = load i8, i8* %scevgep28.8.20, align 1
  %conv23.8.21 = zext i8 %2257 to i32
  %2258 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.21 = getelementptr i8, i8* %b, i64 30
  %2259 = load i8, i8* %scevgep34.8.21, align 1
  %call28.8.21 = call zeroext i8 @mult(i8 zeroext %2258, i8 zeroext %2259)
  %conv29.8.21 = zext i8 %call28.8.21 to i32
  %xor.8.21 = xor i32 %conv23.8.21, %conv29.8.21
  %scevgep35.8.21 = getelementptr i8, i8* %a, i64 30
  %2260 = load i8, i8* %scevgep35.8.21, align 1
  %2261 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.21 = call zeroext i8 @mult(i8 zeroext %2260, i8 zeroext %2261)
  %conv35.8.21 = zext i8 %call34.8.21 to i32
  %xor36.8.21 = xor i32 %xor.8.21, %conv35.8.21
  %conv37.8.21 = trunc i32 %xor36.8.21 to i8
  store i8 %conv37.8.21, i8* %scevgep41.8.20, align 1
  %scevgep28.8.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2255, i64 0, i64 0, i64 1
  %2262 = bitcast i8* %scevgep28.8.21 to [41 x [41 x i8]]*
  %scevgep41.8.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2256, i64 0, i64 1, i64 0
  %2263 = bitcast i8* %scevgep41.8.21 to [41 x [41 x i8]]*
  %call16.8.22 = call zeroext i8 (...) @rand()
  store i8 %call16.8.22, i8* %scevgep28.8.21, align 1
  %2264 = load i8, i8* %scevgep28.8.21, align 1
  %conv23.8.22 = zext i8 %2264 to i32
  %2265 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.22 = getelementptr i8, i8* %b, i64 31
  %2266 = load i8, i8* %scevgep34.8.22, align 1
  %call28.8.22 = call zeroext i8 @mult(i8 zeroext %2265, i8 zeroext %2266)
  %conv29.8.22 = zext i8 %call28.8.22 to i32
  %xor.8.22 = xor i32 %conv23.8.22, %conv29.8.22
  %scevgep35.8.22 = getelementptr i8, i8* %a, i64 31
  %2267 = load i8, i8* %scevgep35.8.22, align 1
  %2268 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.22 = call zeroext i8 @mult(i8 zeroext %2267, i8 zeroext %2268)
  %conv35.8.22 = zext i8 %call34.8.22 to i32
  %xor36.8.22 = xor i32 %xor.8.22, %conv35.8.22
  %conv37.8.22 = trunc i32 %xor36.8.22 to i8
  store i8 %conv37.8.22, i8* %scevgep41.8.21, align 1
  %scevgep28.8.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2262, i64 0, i64 0, i64 1
  %2269 = bitcast i8* %scevgep28.8.22 to [41 x [41 x i8]]*
  %scevgep41.8.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2263, i64 0, i64 1, i64 0
  %2270 = bitcast i8* %scevgep41.8.22 to [41 x [41 x i8]]*
  %call16.8.23 = call zeroext i8 (...) @rand()
  store i8 %call16.8.23, i8* %scevgep28.8.22, align 1
  %2271 = load i8, i8* %scevgep28.8.22, align 1
  %conv23.8.23 = zext i8 %2271 to i32
  %2272 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.23 = getelementptr i8, i8* %b, i64 32
  %2273 = load i8, i8* %scevgep34.8.23, align 1
  %call28.8.23 = call zeroext i8 @mult(i8 zeroext %2272, i8 zeroext %2273)
  %conv29.8.23 = zext i8 %call28.8.23 to i32
  %xor.8.23 = xor i32 %conv23.8.23, %conv29.8.23
  %scevgep35.8.23 = getelementptr i8, i8* %a, i64 32
  %2274 = load i8, i8* %scevgep35.8.23, align 1
  %2275 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.23 = call zeroext i8 @mult(i8 zeroext %2274, i8 zeroext %2275)
  %conv35.8.23 = zext i8 %call34.8.23 to i32
  %xor36.8.23 = xor i32 %xor.8.23, %conv35.8.23
  %conv37.8.23 = trunc i32 %xor36.8.23 to i8
  store i8 %conv37.8.23, i8* %scevgep41.8.22, align 1
  %scevgep28.8.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2269, i64 0, i64 0, i64 1
  %2276 = bitcast i8* %scevgep28.8.23 to [41 x [41 x i8]]*
  %scevgep41.8.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2270, i64 0, i64 1, i64 0
  %2277 = bitcast i8* %scevgep41.8.23 to [41 x [41 x i8]]*
  %call16.8.24 = call zeroext i8 (...) @rand()
  store i8 %call16.8.24, i8* %scevgep28.8.23, align 1
  %2278 = load i8, i8* %scevgep28.8.23, align 1
  %conv23.8.24 = zext i8 %2278 to i32
  %2279 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.24 = getelementptr i8, i8* %b, i64 33
  %2280 = load i8, i8* %scevgep34.8.24, align 1
  %call28.8.24 = call zeroext i8 @mult(i8 zeroext %2279, i8 zeroext %2280)
  %conv29.8.24 = zext i8 %call28.8.24 to i32
  %xor.8.24 = xor i32 %conv23.8.24, %conv29.8.24
  %scevgep35.8.24 = getelementptr i8, i8* %a, i64 33
  %2281 = load i8, i8* %scevgep35.8.24, align 1
  %2282 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.24 = call zeroext i8 @mult(i8 zeroext %2281, i8 zeroext %2282)
  %conv35.8.24 = zext i8 %call34.8.24 to i32
  %xor36.8.24 = xor i32 %xor.8.24, %conv35.8.24
  %conv37.8.24 = trunc i32 %xor36.8.24 to i8
  store i8 %conv37.8.24, i8* %scevgep41.8.23, align 1
  %scevgep28.8.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2276, i64 0, i64 0, i64 1
  %2283 = bitcast i8* %scevgep28.8.24 to [41 x [41 x i8]]*
  %scevgep41.8.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2277, i64 0, i64 1, i64 0
  %2284 = bitcast i8* %scevgep41.8.24 to [41 x [41 x i8]]*
  %call16.8.25 = call zeroext i8 (...) @rand()
  store i8 %call16.8.25, i8* %scevgep28.8.24, align 1
  %2285 = load i8, i8* %scevgep28.8.24, align 1
  %conv23.8.25 = zext i8 %2285 to i32
  %2286 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.25 = getelementptr i8, i8* %b, i64 34
  %2287 = load i8, i8* %scevgep34.8.25, align 1
  %call28.8.25 = call zeroext i8 @mult(i8 zeroext %2286, i8 zeroext %2287)
  %conv29.8.25 = zext i8 %call28.8.25 to i32
  %xor.8.25 = xor i32 %conv23.8.25, %conv29.8.25
  %scevgep35.8.25 = getelementptr i8, i8* %a, i64 34
  %2288 = load i8, i8* %scevgep35.8.25, align 1
  %2289 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.25 = call zeroext i8 @mult(i8 zeroext %2288, i8 zeroext %2289)
  %conv35.8.25 = zext i8 %call34.8.25 to i32
  %xor36.8.25 = xor i32 %xor.8.25, %conv35.8.25
  %conv37.8.25 = trunc i32 %xor36.8.25 to i8
  store i8 %conv37.8.25, i8* %scevgep41.8.24, align 1
  %scevgep28.8.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2283, i64 0, i64 0, i64 1
  %2290 = bitcast i8* %scevgep28.8.25 to [41 x [41 x i8]]*
  %scevgep41.8.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2284, i64 0, i64 1, i64 0
  %2291 = bitcast i8* %scevgep41.8.25 to [41 x [41 x i8]]*
  %call16.8.26 = call zeroext i8 (...) @rand()
  store i8 %call16.8.26, i8* %scevgep28.8.25, align 1
  %2292 = load i8, i8* %scevgep28.8.25, align 1
  %conv23.8.26 = zext i8 %2292 to i32
  %2293 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.26 = getelementptr i8, i8* %b, i64 35
  %2294 = load i8, i8* %scevgep34.8.26, align 1
  %call28.8.26 = call zeroext i8 @mult(i8 zeroext %2293, i8 zeroext %2294)
  %conv29.8.26 = zext i8 %call28.8.26 to i32
  %xor.8.26 = xor i32 %conv23.8.26, %conv29.8.26
  %scevgep35.8.26 = getelementptr i8, i8* %a, i64 35
  %2295 = load i8, i8* %scevgep35.8.26, align 1
  %2296 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.26 = call zeroext i8 @mult(i8 zeroext %2295, i8 zeroext %2296)
  %conv35.8.26 = zext i8 %call34.8.26 to i32
  %xor36.8.26 = xor i32 %xor.8.26, %conv35.8.26
  %conv37.8.26 = trunc i32 %xor36.8.26 to i8
  store i8 %conv37.8.26, i8* %scevgep41.8.25, align 1
  %scevgep28.8.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2290, i64 0, i64 0, i64 1
  %2297 = bitcast i8* %scevgep28.8.26 to [41 x [41 x i8]]*
  %scevgep41.8.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2291, i64 0, i64 1, i64 0
  %2298 = bitcast i8* %scevgep41.8.26 to [41 x [41 x i8]]*
  %call16.8.27 = call zeroext i8 (...) @rand()
  store i8 %call16.8.27, i8* %scevgep28.8.26, align 1
  %2299 = load i8, i8* %scevgep28.8.26, align 1
  %conv23.8.27 = zext i8 %2299 to i32
  %2300 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.27 = getelementptr i8, i8* %b, i64 36
  %2301 = load i8, i8* %scevgep34.8.27, align 1
  %call28.8.27 = call zeroext i8 @mult(i8 zeroext %2300, i8 zeroext %2301)
  %conv29.8.27 = zext i8 %call28.8.27 to i32
  %xor.8.27 = xor i32 %conv23.8.27, %conv29.8.27
  %scevgep35.8.27 = getelementptr i8, i8* %a, i64 36
  %2302 = load i8, i8* %scevgep35.8.27, align 1
  %2303 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.27 = call zeroext i8 @mult(i8 zeroext %2302, i8 zeroext %2303)
  %conv35.8.27 = zext i8 %call34.8.27 to i32
  %xor36.8.27 = xor i32 %xor.8.27, %conv35.8.27
  %conv37.8.27 = trunc i32 %xor36.8.27 to i8
  store i8 %conv37.8.27, i8* %scevgep41.8.26, align 1
  %scevgep28.8.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2297, i64 0, i64 0, i64 1
  %2304 = bitcast i8* %scevgep28.8.27 to [41 x [41 x i8]]*
  %scevgep41.8.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2298, i64 0, i64 1, i64 0
  %2305 = bitcast i8* %scevgep41.8.27 to [41 x [41 x i8]]*
  %call16.8.28 = call zeroext i8 (...) @rand()
  store i8 %call16.8.28, i8* %scevgep28.8.27, align 1
  %2306 = load i8, i8* %scevgep28.8.27, align 1
  %conv23.8.28 = zext i8 %2306 to i32
  %2307 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.28 = getelementptr i8, i8* %b, i64 37
  %2308 = load i8, i8* %scevgep34.8.28, align 1
  %call28.8.28 = call zeroext i8 @mult(i8 zeroext %2307, i8 zeroext %2308)
  %conv29.8.28 = zext i8 %call28.8.28 to i32
  %xor.8.28 = xor i32 %conv23.8.28, %conv29.8.28
  %scevgep35.8.28 = getelementptr i8, i8* %a, i64 37
  %2309 = load i8, i8* %scevgep35.8.28, align 1
  %2310 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.28 = call zeroext i8 @mult(i8 zeroext %2309, i8 zeroext %2310)
  %conv35.8.28 = zext i8 %call34.8.28 to i32
  %xor36.8.28 = xor i32 %xor.8.28, %conv35.8.28
  %conv37.8.28 = trunc i32 %xor36.8.28 to i8
  store i8 %conv37.8.28, i8* %scevgep41.8.27, align 1
  %scevgep28.8.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2304, i64 0, i64 0, i64 1
  %2311 = bitcast i8* %scevgep28.8.28 to [41 x [41 x i8]]*
  %scevgep41.8.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2305, i64 0, i64 1, i64 0
  %2312 = bitcast i8* %scevgep41.8.28 to [41 x [41 x i8]]*
  %call16.8.29 = call zeroext i8 (...) @rand()
  store i8 %call16.8.29, i8* %scevgep28.8.28, align 1
  %2313 = load i8, i8* %scevgep28.8.28, align 1
  %conv23.8.29 = zext i8 %2313 to i32
  %2314 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.29 = getelementptr i8, i8* %b, i64 38
  %2315 = load i8, i8* %scevgep34.8.29, align 1
  %call28.8.29 = call zeroext i8 @mult(i8 zeroext %2314, i8 zeroext %2315)
  %conv29.8.29 = zext i8 %call28.8.29 to i32
  %xor.8.29 = xor i32 %conv23.8.29, %conv29.8.29
  %scevgep35.8.29 = getelementptr i8, i8* %a, i64 38
  %2316 = load i8, i8* %scevgep35.8.29, align 1
  %2317 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.29 = call zeroext i8 @mult(i8 zeroext %2316, i8 zeroext %2317)
  %conv35.8.29 = zext i8 %call34.8.29 to i32
  %xor36.8.29 = xor i32 %xor.8.29, %conv35.8.29
  %conv37.8.29 = trunc i32 %xor36.8.29 to i8
  store i8 %conv37.8.29, i8* %scevgep41.8.28, align 1
  %scevgep28.8.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2311, i64 0, i64 0, i64 1
  %2318 = bitcast i8* %scevgep28.8.29 to [41 x [41 x i8]]*
  %scevgep41.8.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2312, i64 0, i64 1, i64 0
  %2319 = bitcast i8* %scevgep41.8.29 to [41 x [41 x i8]]*
  %call16.8.30 = call zeroext i8 (...) @rand()
  store i8 %call16.8.30, i8* %scevgep28.8.29, align 1
  %2320 = load i8, i8* %scevgep28.8.29, align 1
  %conv23.8.30 = zext i8 %2320 to i32
  %2321 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.30 = getelementptr i8, i8* %b, i64 39
  %2322 = load i8, i8* %scevgep34.8.30, align 1
  %call28.8.30 = call zeroext i8 @mult(i8 zeroext %2321, i8 zeroext %2322)
  %conv29.8.30 = zext i8 %call28.8.30 to i32
  %xor.8.30 = xor i32 %conv23.8.30, %conv29.8.30
  %scevgep35.8.30 = getelementptr i8, i8* %a, i64 39
  %2323 = load i8, i8* %scevgep35.8.30, align 1
  %2324 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.30 = call zeroext i8 @mult(i8 zeroext %2323, i8 zeroext %2324)
  %conv35.8.30 = zext i8 %call34.8.30 to i32
  %xor36.8.30 = xor i32 %xor.8.30, %conv35.8.30
  %conv37.8.30 = trunc i32 %xor36.8.30 to i8
  store i8 %conv37.8.30, i8* %scevgep41.8.29, align 1
  %scevgep28.8.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2318, i64 0, i64 0, i64 1
  %scevgep41.8.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2319, i64 0, i64 1, i64 0
  %call16.8.31 = call zeroext i8 (...) @rand()
  store i8 %call16.8.31, i8* %scevgep28.8.30, align 1
  %2325 = load i8, i8* %scevgep28.8.30, align 1
  %conv23.8.31 = zext i8 %2325 to i32
  %2326 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.31 = getelementptr i8, i8* %b, i64 40
  %2327 = load i8, i8* %scevgep34.8.31, align 1
  %call28.8.31 = call zeroext i8 @mult(i8 zeroext %2326, i8 zeroext %2327)
  %conv29.8.31 = zext i8 %call28.8.31 to i32
  %xor.8.31 = xor i32 %conv23.8.31, %conv29.8.31
  %scevgep35.8.31 = getelementptr i8, i8* %a, i64 40
  %2328 = load i8, i8* %scevgep35.8.31, align 1
  %2329 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.31 = call zeroext i8 @mult(i8 zeroext %2328, i8 zeroext %2329)
  %conv35.8.31 = zext i8 %call34.8.31 to i32
  %xor36.8.31 = xor i32 %xor.8.31, %conv35.8.31
  %conv37.8.31 = trunc i32 %xor36.8.31 to i8
  store i8 %conv37.8.31, i8* %scevgep41.8.30, align 1
  %scevgep26.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2108, i64 0, i64 1, i64 1
  %2330 = bitcast i8* %scevgep26.8 to [41 x [41 x i8]]*
  %scevgep39.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2109, i64 0, i64 1, i64 1
  %2331 = bitcast i8* %scevgep39.8 to [41 x [41 x i8]]*
  %arrayidx25.9 = getelementptr inbounds i8, i8* %a, i64 9
  %arrayidx33.9 = getelementptr inbounds i8, i8* %b, i64 9
  %call16.9 = call zeroext i8 (...) @rand()
  store i8 %call16.9, i8* %scevgep26.8, align 1
  %2332 = load i8, i8* %scevgep26.8, align 1
  %conv23.9 = zext i8 %2332 to i32
  %2333 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9 = getelementptr i8, i8* %b, i64 10
  %2334 = load i8, i8* %scevgep34.9, align 1
  %call28.9 = call zeroext i8 @mult(i8 zeroext %2333, i8 zeroext %2334)
  %conv29.9 = zext i8 %call28.9 to i32
  %xor.9 = xor i32 %conv23.9, %conv29.9
  %scevgep35.9 = getelementptr i8, i8* %a, i64 10
  %2335 = load i8, i8* %scevgep35.9, align 1
  %2336 = load i8, i8* %arrayidx33.9, align 1
  %call34.9 = call zeroext i8 @mult(i8 zeroext %2335, i8 zeroext %2336)
  %conv35.9 = zext i8 %call34.9 to i32
  %xor36.9 = xor i32 %xor.9, %conv35.9
  %conv37.9 = trunc i32 %xor36.9 to i8
  store i8 %conv37.9, i8* %scevgep39.8, align 1
  %scevgep28.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2330, i64 0, i64 0, i64 1
  %2337 = bitcast i8* %scevgep28.9 to [41 x [41 x i8]]*
  %scevgep41.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2331, i64 0, i64 1, i64 0
  %2338 = bitcast i8* %scevgep41.9 to [41 x [41 x i8]]*
  %call16.9.1 = call zeroext i8 (...) @rand()
  store i8 %call16.9.1, i8* %scevgep28.9, align 1
  %2339 = load i8, i8* %scevgep28.9, align 1
  %conv23.9.1 = zext i8 %2339 to i32
  %2340 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.1 = getelementptr i8, i8* %b, i64 11
  %2341 = load i8, i8* %scevgep34.9.1, align 1
  %call28.9.1 = call zeroext i8 @mult(i8 zeroext %2340, i8 zeroext %2341)
  %conv29.9.1 = zext i8 %call28.9.1 to i32
  %xor.9.1 = xor i32 %conv23.9.1, %conv29.9.1
  %scevgep35.9.1 = getelementptr i8, i8* %a, i64 11
  %2342 = load i8, i8* %scevgep35.9.1, align 1
  %2343 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.1 = call zeroext i8 @mult(i8 zeroext %2342, i8 zeroext %2343)
  %conv35.9.1 = zext i8 %call34.9.1 to i32
  %xor36.9.1 = xor i32 %xor.9.1, %conv35.9.1
  %conv37.9.1 = trunc i32 %xor36.9.1 to i8
  store i8 %conv37.9.1, i8* %scevgep41.9, align 1
  %scevgep28.9.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2337, i64 0, i64 0, i64 1
  %2344 = bitcast i8* %scevgep28.9.1 to [41 x [41 x i8]]*
  %scevgep41.9.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2338, i64 0, i64 1, i64 0
  %2345 = bitcast i8* %scevgep41.9.1 to [41 x [41 x i8]]*
  %call16.9.2 = call zeroext i8 (...) @rand()
  store i8 %call16.9.2, i8* %scevgep28.9.1, align 1
  %2346 = load i8, i8* %scevgep28.9.1, align 1
  %conv23.9.2 = zext i8 %2346 to i32
  %2347 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.2 = getelementptr i8, i8* %b, i64 12
  %2348 = load i8, i8* %scevgep34.9.2, align 1
  %call28.9.2 = call zeroext i8 @mult(i8 zeroext %2347, i8 zeroext %2348)
  %conv29.9.2 = zext i8 %call28.9.2 to i32
  %xor.9.2 = xor i32 %conv23.9.2, %conv29.9.2
  %scevgep35.9.2 = getelementptr i8, i8* %a, i64 12
  %2349 = load i8, i8* %scevgep35.9.2, align 1
  %2350 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.2 = call zeroext i8 @mult(i8 zeroext %2349, i8 zeroext %2350)
  %conv35.9.2 = zext i8 %call34.9.2 to i32
  %xor36.9.2 = xor i32 %xor.9.2, %conv35.9.2
  %conv37.9.2 = trunc i32 %xor36.9.2 to i8
  store i8 %conv37.9.2, i8* %scevgep41.9.1, align 1
  %scevgep28.9.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2344, i64 0, i64 0, i64 1
  %2351 = bitcast i8* %scevgep28.9.2 to [41 x [41 x i8]]*
  %scevgep41.9.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2345, i64 0, i64 1, i64 0
  %2352 = bitcast i8* %scevgep41.9.2 to [41 x [41 x i8]]*
  %call16.9.3 = call zeroext i8 (...) @rand()
  store i8 %call16.9.3, i8* %scevgep28.9.2, align 1
  %2353 = load i8, i8* %scevgep28.9.2, align 1
  %conv23.9.3 = zext i8 %2353 to i32
  %2354 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.3 = getelementptr i8, i8* %b, i64 13
  %2355 = load i8, i8* %scevgep34.9.3, align 1
  %call28.9.3 = call zeroext i8 @mult(i8 zeroext %2354, i8 zeroext %2355)
  %conv29.9.3 = zext i8 %call28.9.3 to i32
  %xor.9.3 = xor i32 %conv23.9.3, %conv29.9.3
  %scevgep35.9.3 = getelementptr i8, i8* %a, i64 13
  %2356 = load i8, i8* %scevgep35.9.3, align 1
  %2357 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.3 = call zeroext i8 @mult(i8 zeroext %2356, i8 zeroext %2357)
  %conv35.9.3 = zext i8 %call34.9.3 to i32
  %xor36.9.3 = xor i32 %xor.9.3, %conv35.9.3
  %conv37.9.3 = trunc i32 %xor36.9.3 to i8
  store i8 %conv37.9.3, i8* %scevgep41.9.2, align 1
  %scevgep28.9.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2351, i64 0, i64 0, i64 1
  %2358 = bitcast i8* %scevgep28.9.3 to [41 x [41 x i8]]*
  %scevgep41.9.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2352, i64 0, i64 1, i64 0
  %2359 = bitcast i8* %scevgep41.9.3 to [41 x [41 x i8]]*
  %call16.9.4 = call zeroext i8 (...) @rand()
  store i8 %call16.9.4, i8* %scevgep28.9.3, align 1
  %2360 = load i8, i8* %scevgep28.9.3, align 1
  %conv23.9.4 = zext i8 %2360 to i32
  %2361 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.4 = getelementptr i8, i8* %b, i64 14
  %2362 = load i8, i8* %scevgep34.9.4, align 1
  %call28.9.4 = call zeroext i8 @mult(i8 zeroext %2361, i8 zeroext %2362)
  %conv29.9.4 = zext i8 %call28.9.4 to i32
  %xor.9.4 = xor i32 %conv23.9.4, %conv29.9.4
  %scevgep35.9.4 = getelementptr i8, i8* %a, i64 14
  %2363 = load i8, i8* %scevgep35.9.4, align 1
  %2364 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.4 = call zeroext i8 @mult(i8 zeroext %2363, i8 zeroext %2364)
  %conv35.9.4 = zext i8 %call34.9.4 to i32
  %xor36.9.4 = xor i32 %xor.9.4, %conv35.9.4
  %conv37.9.4 = trunc i32 %xor36.9.4 to i8
  store i8 %conv37.9.4, i8* %scevgep41.9.3, align 1
  %scevgep28.9.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2358, i64 0, i64 0, i64 1
  %2365 = bitcast i8* %scevgep28.9.4 to [41 x [41 x i8]]*
  %scevgep41.9.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2359, i64 0, i64 1, i64 0
  %2366 = bitcast i8* %scevgep41.9.4 to [41 x [41 x i8]]*
  %call16.9.5 = call zeroext i8 (...) @rand()
  store i8 %call16.9.5, i8* %scevgep28.9.4, align 1
  %2367 = load i8, i8* %scevgep28.9.4, align 1
  %conv23.9.5 = zext i8 %2367 to i32
  %2368 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.5 = getelementptr i8, i8* %b, i64 15
  %2369 = load i8, i8* %scevgep34.9.5, align 1
  %call28.9.5 = call zeroext i8 @mult(i8 zeroext %2368, i8 zeroext %2369)
  %conv29.9.5 = zext i8 %call28.9.5 to i32
  %xor.9.5 = xor i32 %conv23.9.5, %conv29.9.5
  %scevgep35.9.5 = getelementptr i8, i8* %a, i64 15
  %2370 = load i8, i8* %scevgep35.9.5, align 1
  %2371 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.5 = call zeroext i8 @mult(i8 zeroext %2370, i8 zeroext %2371)
  %conv35.9.5 = zext i8 %call34.9.5 to i32
  %xor36.9.5 = xor i32 %xor.9.5, %conv35.9.5
  %conv37.9.5 = trunc i32 %xor36.9.5 to i8
  store i8 %conv37.9.5, i8* %scevgep41.9.4, align 1
  %scevgep28.9.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2365, i64 0, i64 0, i64 1
  %2372 = bitcast i8* %scevgep28.9.5 to [41 x [41 x i8]]*
  %scevgep41.9.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2366, i64 0, i64 1, i64 0
  %2373 = bitcast i8* %scevgep41.9.5 to [41 x [41 x i8]]*
  %call16.9.6 = call zeroext i8 (...) @rand()
  store i8 %call16.9.6, i8* %scevgep28.9.5, align 1
  %2374 = load i8, i8* %scevgep28.9.5, align 1
  %conv23.9.6 = zext i8 %2374 to i32
  %2375 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.6 = getelementptr i8, i8* %b, i64 16
  %2376 = load i8, i8* %scevgep34.9.6, align 1
  %call28.9.6 = call zeroext i8 @mult(i8 zeroext %2375, i8 zeroext %2376)
  %conv29.9.6 = zext i8 %call28.9.6 to i32
  %xor.9.6 = xor i32 %conv23.9.6, %conv29.9.6
  %scevgep35.9.6 = getelementptr i8, i8* %a, i64 16
  %2377 = load i8, i8* %scevgep35.9.6, align 1
  %2378 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.6 = call zeroext i8 @mult(i8 zeroext %2377, i8 zeroext %2378)
  %conv35.9.6 = zext i8 %call34.9.6 to i32
  %xor36.9.6 = xor i32 %xor.9.6, %conv35.9.6
  %conv37.9.6 = trunc i32 %xor36.9.6 to i8
  store i8 %conv37.9.6, i8* %scevgep41.9.5, align 1
  %scevgep28.9.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2372, i64 0, i64 0, i64 1
  %2379 = bitcast i8* %scevgep28.9.6 to [41 x [41 x i8]]*
  %scevgep41.9.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2373, i64 0, i64 1, i64 0
  %2380 = bitcast i8* %scevgep41.9.6 to [41 x [41 x i8]]*
  %call16.9.7 = call zeroext i8 (...) @rand()
  store i8 %call16.9.7, i8* %scevgep28.9.6, align 1
  %2381 = load i8, i8* %scevgep28.9.6, align 1
  %conv23.9.7 = zext i8 %2381 to i32
  %2382 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.7 = getelementptr i8, i8* %b, i64 17
  %2383 = load i8, i8* %scevgep34.9.7, align 1
  %call28.9.7 = call zeroext i8 @mult(i8 zeroext %2382, i8 zeroext %2383)
  %conv29.9.7 = zext i8 %call28.9.7 to i32
  %xor.9.7 = xor i32 %conv23.9.7, %conv29.9.7
  %scevgep35.9.7 = getelementptr i8, i8* %a, i64 17
  %2384 = load i8, i8* %scevgep35.9.7, align 1
  %2385 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.7 = call zeroext i8 @mult(i8 zeroext %2384, i8 zeroext %2385)
  %conv35.9.7 = zext i8 %call34.9.7 to i32
  %xor36.9.7 = xor i32 %xor.9.7, %conv35.9.7
  %conv37.9.7 = trunc i32 %xor36.9.7 to i8
  store i8 %conv37.9.7, i8* %scevgep41.9.6, align 1
  %scevgep28.9.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2379, i64 0, i64 0, i64 1
  %2386 = bitcast i8* %scevgep28.9.7 to [41 x [41 x i8]]*
  %scevgep41.9.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2380, i64 0, i64 1, i64 0
  %2387 = bitcast i8* %scevgep41.9.7 to [41 x [41 x i8]]*
  %call16.9.8 = call zeroext i8 (...) @rand()
  store i8 %call16.9.8, i8* %scevgep28.9.7, align 1
  %2388 = load i8, i8* %scevgep28.9.7, align 1
  %conv23.9.8 = zext i8 %2388 to i32
  %2389 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.8 = getelementptr i8, i8* %b, i64 18
  %2390 = load i8, i8* %scevgep34.9.8, align 1
  %call28.9.8 = call zeroext i8 @mult(i8 zeroext %2389, i8 zeroext %2390)
  %conv29.9.8 = zext i8 %call28.9.8 to i32
  %xor.9.8 = xor i32 %conv23.9.8, %conv29.9.8
  %scevgep35.9.8 = getelementptr i8, i8* %a, i64 18
  %2391 = load i8, i8* %scevgep35.9.8, align 1
  %2392 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.8 = call zeroext i8 @mult(i8 zeroext %2391, i8 zeroext %2392)
  %conv35.9.8 = zext i8 %call34.9.8 to i32
  %xor36.9.8 = xor i32 %xor.9.8, %conv35.9.8
  %conv37.9.8 = trunc i32 %xor36.9.8 to i8
  store i8 %conv37.9.8, i8* %scevgep41.9.7, align 1
  %scevgep28.9.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2386, i64 0, i64 0, i64 1
  %2393 = bitcast i8* %scevgep28.9.8 to [41 x [41 x i8]]*
  %scevgep41.9.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2387, i64 0, i64 1, i64 0
  %2394 = bitcast i8* %scevgep41.9.8 to [41 x [41 x i8]]*
  %call16.9.9 = call zeroext i8 (...) @rand()
  store i8 %call16.9.9, i8* %scevgep28.9.8, align 1
  %2395 = load i8, i8* %scevgep28.9.8, align 1
  %conv23.9.9 = zext i8 %2395 to i32
  %2396 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.9 = getelementptr i8, i8* %b, i64 19
  %2397 = load i8, i8* %scevgep34.9.9, align 1
  %call28.9.9 = call zeroext i8 @mult(i8 zeroext %2396, i8 zeroext %2397)
  %conv29.9.9 = zext i8 %call28.9.9 to i32
  %xor.9.9 = xor i32 %conv23.9.9, %conv29.9.9
  %scevgep35.9.9 = getelementptr i8, i8* %a, i64 19
  %2398 = load i8, i8* %scevgep35.9.9, align 1
  %2399 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.9 = call zeroext i8 @mult(i8 zeroext %2398, i8 zeroext %2399)
  %conv35.9.9 = zext i8 %call34.9.9 to i32
  %xor36.9.9 = xor i32 %xor.9.9, %conv35.9.9
  %conv37.9.9 = trunc i32 %xor36.9.9 to i8
  store i8 %conv37.9.9, i8* %scevgep41.9.8, align 1
  %scevgep28.9.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2393, i64 0, i64 0, i64 1
  %2400 = bitcast i8* %scevgep28.9.9 to [41 x [41 x i8]]*
  %scevgep41.9.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2394, i64 0, i64 1, i64 0
  %2401 = bitcast i8* %scevgep41.9.9 to [41 x [41 x i8]]*
  %call16.9.10 = call zeroext i8 (...) @rand()
  store i8 %call16.9.10, i8* %scevgep28.9.9, align 1
  %2402 = load i8, i8* %scevgep28.9.9, align 1
  %conv23.9.10 = zext i8 %2402 to i32
  %2403 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.10 = getelementptr i8, i8* %b, i64 20
  %2404 = load i8, i8* %scevgep34.9.10, align 1
  %call28.9.10 = call zeroext i8 @mult(i8 zeroext %2403, i8 zeroext %2404)
  %conv29.9.10 = zext i8 %call28.9.10 to i32
  %xor.9.10 = xor i32 %conv23.9.10, %conv29.9.10
  %scevgep35.9.10 = getelementptr i8, i8* %a, i64 20
  %2405 = load i8, i8* %scevgep35.9.10, align 1
  %2406 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.10 = call zeroext i8 @mult(i8 zeroext %2405, i8 zeroext %2406)
  %conv35.9.10 = zext i8 %call34.9.10 to i32
  %xor36.9.10 = xor i32 %xor.9.10, %conv35.9.10
  %conv37.9.10 = trunc i32 %xor36.9.10 to i8
  store i8 %conv37.9.10, i8* %scevgep41.9.9, align 1
  %scevgep28.9.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2400, i64 0, i64 0, i64 1
  %2407 = bitcast i8* %scevgep28.9.10 to [41 x [41 x i8]]*
  %scevgep41.9.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2401, i64 0, i64 1, i64 0
  %2408 = bitcast i8* %scevgep41.9.10 to [41 x [41 x i8]]*
  %call16.9.11 = call zeroext i8 (...) @rand()
  store i8 %call16.9.11, i8* %scevgep28.9.10, align 1
  %2409 = load i8, i8* %scevgep28.9.10, align 1
  %conv23.9.11 = zext i8 %2409 to i32
  %2410 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.11 = getelementptr i8, i8* %b, i64 21
  %2411 = load i8, i8* %scevgep34.9.11, align 1
  %call28.9.11 = call zeroext i8 @mult(i8 zeroext %2410, i8 zeroext %2411)
  %conv29.9.11 = zext i8 %call28.9.11 to i32
  %xor.9.11 = xor i32 %conv23.9.11, %conv29.9.11
  %scevgep35.9.11 = getelementptr i8, i8* %a, i64 21
  %2412 = load i8, i8* %scevgep35.9.11, align 1
  %2413 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.11 = call zeroext i8 @mult(i8 zeroext %2412, i8 zeroext %2413)
  %conv35.9.11 = zext i8 %call34.9.11 to i32
  %xor36.9.11 = xor i32 %xor.9.11, %conv35.9.11
  %conv37.9.11 = trunc i32 %xor36.9.11 to i8
  store i8 %conv37.9.11, i8* %scevgep41.9.10, align 1
  %scevgep28.9.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2407, i64 0, i64 0, i64 1
  %2414 = bitcast i8* %scevgep28.9.11 to [41 x [41 x i8]]*
  %scevgep41.9.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2408, i64 0, i64 1, i64 0
  %2415 = bitcast i8* %scevgep41.9.11 to [41 x [41 x i8]]*
  %call16.9.12 = call zeroext i8 (...) @rand()
  store i8 %call16.9.12, i8* %scevgep28.9.11, align 1
  %2416 = load i8, i8* %scevgep28.9.11, align 1
  %conv23.9.12 = zext i8 %2416 to i32
  %2417 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.12 = getelementptr i8, i8* %b, i64 22
  %2418 = load i8, i8* %scevgep34.9.12, align 1
  %call28.9.12 = call zeroext i8 @mult(i8 zeroext %2417, i8 zeroext %2418)
  %conv29.9.12 = zext i8 %call28.9.12 to i32
  %xor.9.12 = xor i32 %conv23.9.12, %conv29.9.12
  %scevgep35.9.12 = getelementptr i8, i8* %a, i64 22
  %2419 = load i8, i8* %scevgep35.9.12, align 1
  %2420 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.12 = call zeroext i8 @mult(i8 zeroext %2419, i8 zeroext %2420)
  %conv35.9.12 = zext i8 %call34.9.12 to i32
  %xor36.9.12 = xor i32 %xor.9.12, %conv35.9.12
  %conv37.9.12 = trunc i32 %xor36.9.12 to i8
  store i8 %conv37.9.12, i8* %scevgep41.9.11, align 1
  %scevgep28.9.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2414, i64 0, i64 0, i64 1
  %2421 = bitcast i8* %scevgep28.9.12 to [41 x [41 x i8]]*
  %scevgep41.9.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2415, i64 0, i64 1, i64 0
  %2422 = bitcast i8* %scevgep41.9.12 to [41 x [41 x i8]]*
  %call16.9.13 = call zeroext i8 (...) @rand()
  store i8 %call16.9.13, i8* %scevgep28.9.12, align 1
  %2423 = load i8, i8* %scevgep28.9.12, align 1
  %conv23.9.13 = zext i8 %2423 to i32
  %2424 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.13 = getelementptr i8, i8* %b, i64 23
  %2425 = load i8, i8* %scevgep34.9.13, align 1
  %call28.9.13 = call zeroext i8 @mult(i8 zeroext %2424, i8 zeroext %2425)
  %conv29.9.13 = zext i8 %call28.9.13 to i32
  %xor.9.13 = xor i32 %conv23.9.13, %conv29.9.13
  %scevgep35.9.13 = getelementptr i8, i8* %a, i64 23
  %2426 = load i8, i8* %scevgep35.9.13, align 1
  %2427 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.13 = call zeroext i8 @mult(i8 zeroext %2426, i8 zeroext %2427)
  %conv35.9.13 = zext i8 %call34.9.13 to i32
  %xor36.9.13 = xor i32 %xor.9.13, %conv35.9.13
  %conv37.9.13 = trunc i32 %xor36.9.13 to i8
  store i8 %conv37.9.13, i8* %scevgep41.9.12, align 1
  %scevgep28.9.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2421, i64 0, i64 0, i64 1
  %2428 = bitcast i8* %scevgep28.9.13 to [41 x [41 x i8]]*
  %scevgep41.9.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2422, i64 0, i64 1, i64 0
  %2429 = bitcast i8* %scevgep41.9.13 to [41 x [41 x i8]]*
  %call16.9.14 = call zeroext i8 (...) @rand()
  store i8 %call16.9.14, i8* %scevgep28.9.13, align 1
  %2430 = load i8, i8* %scevgep28.9.13, align 1
  %conv23.9.14 = zext i8 %2430 to i32
  %2431 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.14 = getelementptr i8, i8* %b, i64 24
  %2432 = load i8, i8* %scevgep34.9.14, align 1
  %call28.9.14 = call zeroext i8 @mult(i8 zeroext %2431, i8 zeroext %2432)
  %conv29.9.14 = zext i8 %call28.9.14 to i32
  %xor.9.14 = xor i32 %conv23.9.14, %conv29.9.14
  %scevgep35.9.14 = getelementptr i8, i8* %a, i64 24
  %2433 = load i8, i8* %scevgep35.9.14, align 1
  %2434 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.14 = call zeroext i8 @mult(i8 zeroext %2433, i8 zeroext %2434)
  %conv35.9.14 = zext i8 %call34.9.14 to i32
  %xor36.9.14 = xor i32 %xor.9.14, %conv35.9.14
  %conv37.9.14 = trunc i32 %xor36.9.14 to i8
  store i8 %conv37.9.14, i8* %scevgep41.9.13, align 1
  %scevgep28.9.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2428, i64 0, i64 0, i64 1
  %2435 = bitcast i8* %scevgep28.9.14 to [41 x [41 x i8]]*
  %scevgep41.9.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2429, i64 0, i64 1, i64 0
  %2436 = bitcast i8* %scevgep41.9.14 to [41 x [41 x i8]]*
  %call16.9.15 = call zeroext i8 (...) @rand()
  store i8 %call16.9.15, i8* %scevgep28.9.14, align 1
  %2437 = load i8, i8* %scevgep28.9.14, align 1
  %conv23.9.15 = zext i8 %2437 to i32
  %2438 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.15 = getelementptr i8, i8* %b, i64 25
  %2439 = load i8, i8* %scevgep34.9.15, align 1
  %call28.9.15 = call zeroext i8 @mult(i8 zeroext %2438, i8 zeroext %2439)
  %conv29.9.15 = zext i8 %call28.9.15 to i32
  %xor.9.15 = xor i32 %conv23.9.15, %conv29.9.15
  %scevgep35.9.15 = getelementptr i8, i8* %a, i64 25
  %2440 = load i8, i8* %scevgep35.9.15, align 1
  %2441 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.15 = call zeroext i8 @mult(i8 zeroext %2440, i8 zeroext %2441)
  %conv35.9.15 = zext i8 %call34.9.15 to i32
  %xor36.9.15 = xor i32 %xor.9.15, %conv35.9.15
  %conv37.9.15 = trunc i32 %xor36.9.15 to i8
  store i8 %conv37.9.15, i8* %scevgep41.9.14, align 1
  %scevgep28.9.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2435, i64 0, i64 0, i64 1
  %2442 = bitcast i8* %scevgep28.9.15 to [41 x [41 x i8]]*
  %scevgep41.9.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2436, i64 0, i64 1, i64 0
  %2443 = bitcast i8* %scevgep41.9.15 to [41 x [41 x i8]]*
  %call16.9.16 = call zeroext i8 (...) @rand()
  store i8 %call16.9.16, i8* %scevgep28.9.15, align 1
  %2444 = load i8, i8* %scevgep28.9.15, align 1
  %conv23.9.16 = zext i8 %2444 to i32
  %2445 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.16 = getelementptr i8, i8* %b, i64 26
  %2446 = load i8, i8* %scevgep34.9.16, align 1
  %call28.9.16 = call zeroext i8 @mult(i8 zeroext %2445, i8 zeroext %2446)
  %conv29.9.16 = zext i8 %call28.9.16 to i32
  %xor.9.16 = xor i32 %conv23.9.16, %conv29.9.16
  %scevgep35.9.16 = getelementptr i8, i8* %a, i64 26
  %2447 = load i8, i8* %scevgep35.9.16, align 1
  %2448 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.16 = call zeroext i8 @mult(i8 zeroext %2447, i8 zeroext %2448)
  %conv35.9.16 = zext i8 %call34.9.16 to i32
  %xor36.9.16 = xor i32 %xor.9.16, %conv35.9.16
  %conv37.9.16 = trunc i32 %xor36.9.16 to i8
  store i8 %conv37.9.16, i8* %scevgep41.9.15, align 1
  %scevgep28.9.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2442, i64 0, i64 0, i64 1
  %2449 = bitcast i8* %scevgep28.9.16 to [41 x [41 x i8]]*
  %scevgep41.9.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2443, i64 0, i64 1, i64 0
  %2450 = bitcast i8* %scevgep41.9.16 to [41 x [41 x i8]]*
  %call16.9.17 = call zeroext i8 (...) @rand()
  store i8 %call16.9.17, i8* %scevgep28.9.16, align 1
  %2451 = load i8, i8* %scevgep28.9.16, align 1
  %conv23.9.17 = zext i8 %2451 to i32
  %2452 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.17 = getelementptr i8, i8* %b, i64 27
  %2453 = load i8, i8* %scevgep34.9.17, align 1
  %call28.9.17 = call zeroext i8 @mult(i8 zeroext %2452, i8 zeroext %2453)
  %conv29.9.17 = zext i8 %call28.9.17 to i32
  %xor.9.17 = xor i32 %conv23.9.17, %conv29.9.17
  %scevgep35.9.17 = getelementptr i8, i8* %a, i64 27
  %2454 = load i8, i8* %scevgep35.9.17, align 1
  %2455 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.17 = call zeroext i8 @mult(i8 zeroext %2454, i8 zeroext %2455)
  %conv35.9.17 = zext i8 %call34.9.17 to i32
  %xor36.9.17 = xor i32 %xor.9.17, %conv35.9.17
  %conv37.9.17 = trunc i32 %xor36.9.17 to i8
  store i8 %conv37.9.17, i8* %scevgep41.9.16, align 1
  %scevgep28.9.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2449, i64 0, i64 0, i64 1
  %2456 = bitcast i8* %scevgep28.9.17 to [41 x [41 x i8]]*
  %scevgep41.9.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2450, i64 0, i64 1, i64 0
  %2457 = bitcast i8* %scevgep41.9.17 to [41 x [41 x i8]]*
  %call16.9.18 = call zeroext i8 (...) @rand()
  store i8 %call16.9.18, i8* %scevgep28.9.17, align 1
  %2458 = load i8, i8* %scevgep28.9.17, align 1
  %conv23.9.18 = zext i8 %2458 to i32
  %2459 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.18 = getelementptr i8, i8* %b, i64 28
  %2460 = load i8, i8* %scevgep34.9.18, align 1
  %call28.9.18 = call zeroext i8 @mult(i8 zeroext %2459, i8 zeroext %2460)
  %conv29.9.18 = zext i8 %call28.9.18 to i32
  %xor.9.18 = xor i32 %conv23.9.18, %conv29.9.18
  %scevgep35.9.18 = getelementptr i8, i8* %a, i64 28
  %2461 = load i8, i8* %scevgep35.9.18, align 1
  %2462 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.18 = call zeroext i8 @mult(i8 zeroext %2461, i8 zeroext %2462)
  %conv35.9.18 = zext i8 %call34.9.18 to i32
  %xor36.9.18 = xor i32 %xor.9.18, %conv35.9.18
  %conv37.9.18 = trunc i32 %xor36.9.18 to i8
  store i8 %conv37.9.18, i8* %scevgep41.9.17, align 1
  %scevgep28.9.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2456, i64 0, i64 0, i64 1
  %2463 = bitcast i8* %scevgep28.9.18 to [41 x [41 x i8]]*
  %scevgep41.9.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2457, i64 0, i64 1, i64 0
  %2464 = bitcast i8* %scevgep41.9.18 to [41 x [41 x i8]]*
  %call16.9.19 = call zeroext i8 (...) @rand()
  store i8 %call16.9.19, i8* %scevgep28.9.18, align 1
  %2465 = load i8, i8* %scevgep28.9.18, align 1
  %conv23.9.19 = zext i8 %2465 to i32
  %2466 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.19 = getelementptr i8, i8* %b, i64 29
  %2467 = load i8, i8* %scevgep34.9.19, align 1
  %call28.9.19 = call zeroext i8 @mult(i8 zeroext %2466, i8 zeroext %2467)
  %conv29.9.19 = zext i8 %call28.9.19 to i32
  %xor.9.19 = xor i32 %conv23.9.19, %conv29.9.19
  %scevgep35.9.19 = getelementptr i8, i8* %a, i64 29
  %2468 = load i8, i8* %scevgep35.9.19, align 1
  %2469 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.19 = call zeroext i8 @mult(i8 zeroext %2468, i8 zeroext %2469)
  %conv35.9.19 = zext i8 %call34.9.19 to i32
  %xor36.9.19 = xor i32 %xor.9.19, %conv35.9.19
  %conv37.9.19 = trunc i32 %xor36.9.19 to i8
  store i8 %conv37.9.19, i8* %scevgep41.9.18, align 1
  %scevgep28.9.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2463, i64 0, i64 0, i64 1
  %2470 = bitcast i8* %scevgep28.9.19 to [41 x [41 x i8]]*
  %scevgep41.9.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2464, i64 0, i64 1, i64 0
  %2471 = bitcast i8* %scevgep41.9.19 to [41 x [41 x i8]]*
  %call16.9.20 = call zeroext i8 (...) @rand()
  store i8 %call16.9.20, i8* %scevgep28.9.19, align 1
  %2472 = load i8, i8* %scevgep28.9.19, align 1
  %conv23.9.20 = zext i8 %2472 to i32
  %2473 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.20 = getelementptr i8, i8* %b, i64 30
  %2474 = load i8, i8* %scevgep34.9.20, align 1
  %call28.9.20 = call zeroext i8 @mult(i8 zeroext %2473, i8 zeroext %2474)
  %conv29.9.20 = zext i8 %call28.9.20 to i32
  %xor.9.20 = xor i32 %conv23.9.20, %conv29.9.20
  %scevgep35.9.20 = getelementptr i8, i8* %a, i64 30
  %2475 = load i8, i8* %scevgep35.9.20, align 1
  %2476 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.20 = call zeroext i8 @mult(i8 zeroext %2475, i8 zeroext %2476)
  %conv35.9.20 = zext i8 %call34.9.20 to i32
  %xor36.9.20 = xor i32 %xor.9.20, %conv35.9.20
  %conv37.9.20 = trunc i32 %xor36.9.20 to i8
  store i8 %conv37.9.20, i8* %scevgep41.9.19, align 1
  %scevgep28.9.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2470, i64 0, i64 0, i64 1
  %2477 = bitcast i8* %scevgep28.9.20 to [41 x [41 x i8]]*
  %scevgep41.9.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2471, i64 0, i64 1, i64 0
  %2478 = bitcast i8* %scevgep41.9.20 to [41 x [41 x i8]]*
  %call16.9.21 = call zeroext i8 (...) @rand()
  store i8 %call16.9.21, i8* %scevgep28.9.20, align 1
  %2479 = load i8, i8* %scevgep28.9.20, align 1
  %conv23.9.21 = zext i8 %2479 to i32
  %2480 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.21 = getelementptr i8, i8* %b, i64 31
  %2481 = load i8, i8* %scevgep34.9.21, align 1
  %call28.9.21 = call zeroext i8 @mult(i8 zeroext %2480, i8 zeroext %2481)
  %conv29.9.21 = zext i8 %call28.9.21 to i32
  %xor.9.21 = xor i32 %conv23.9.21, %conv29.9.21
  %scevgep35.9.21 = getelementptr i8, i8* %a, i64 31
  %2482 = load i8, i8* %scevgep35.9.21, align 1
  %2483 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.21 = call zeroext i8 @mult(i8 zeroext %2482, i8 zeroext %2483)
  %conv35.9.21 = zext i8 %call34.9.21 to i32
  %xor36.9.21 = xor i32 %xor.9.21, %conv35.9.21
  %conv37.9.21 = trunc i32 %xor36.9.21 to i8
  store i8 %conv37.9.21, i8* %scevgep41.9.20, align 1
  %scevgep28.9.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2477, i64 0, i64 0, i64 1
  %2484 = bitcast i8* %scevgep28.9.21 to [41 x [41 x i8]]*
  %scevgep41.9.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2478, i64 0, i64 1, i64 0
  %2485 = bitcast i8* %scevgep41.9.21 to [41 x [41 x i8]]*
  %call16.9.22 = call zeroext i8 (...) @rand()
  store i8 %call16.9.22, i8* %scevgep28.9.21, align 1
  %2486 = load i8, i8* %scevgep28.9.21, align 1
  %conv23.9.22 = zext i8 %2486 to i32
  %2487 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.22 = getelementptr i8, i8* %b, i64 32
  %2488 = load i8, i8* %scevgep34.9.22, align 1
  %call28.9.22 = call zeroext i8 @mult(i8 zeroext %2487, i8 zeroext %2488)
  %conv29.9.22 = zext i8 %call28.9.22 to i32
  %xor.9.22 = xor i32 %conv23.9.22, %conv29.9.22
  %scevgep35.9.22 = getelementptr i8, i8* %a, i64 32
  %2489 = load i8, i8* %scevgep35.9.22, align 1
  %2490 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.22 = call zeroext i8 @mult(i8 zeroext %2489, i8 zeroext %2490)
  %conv35.9.22 = zext i8 %call34.9.22 to i32
  %xor36.9.22 = xor i32 %xor.9.22, %conv35.9.22
  %conv37.9.22 = trunc i32 %xor36.9.22 to i8
  store i8 %conv37.9.22, i8* %scevgep41.9.21, align 1
  %scevgep28.9.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2484, i64 0, i64 0, i64 1
  %2491 = bitcast i8* %scevgep28.9.22 to [41 x [41 x i8]]*
  %scevgep41.9.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2485, i64 0, i64 1, i64 0
  %2492 = bitcast i8* %scevgep41.9.22 to [41 x [41 x i8]]*
  %call16.9.23 = call zeroext i8 (...) @rand()
  store i8 %call16.9.23, i8* %scevgep28.9.22, align 1
  %2493 = load i8, i8* %scevgep28.9.22, align 1
  %conv23.9.23 = zext i8 %2493 to i32
  %2494 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.23 = getelementptr i8, i8* %b, i64 33
  %2495 = load i8, i8* %scevgep34.9.23, align 1
  %call28.9.23 = call zeroext i8 @mult(i8 zeroext %2494, i8 zeroext %2495)
  %conv29.9.23 = zext i8 %call28.9.23 to i32
  %xor.9.23 = xor i32 %conv23.9.23, %conv29.9.23
  %scevgep35.9.23 = getelementptr i8, i8* %a, i64 33
  %2496 = load i8, i8* %scevgep35.9.23, align 1
  %2497 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.23 = call zeroext i8 @mult(i8 zeroext %2496, i8 zeroext %2497)
  %conv35.9.23 = zext i8 %call34.9.23 to i32
  %xor36.9.23 = xor i32 %xor.9.23, %conv35.9.23
  %conv37.9.23 = trunc i32 %xor36.9.23 to i8
  store i8 %conv37.9.23, i8* %scevgep41.9.22, align 1
  %scevgep28.9.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2491, i64 0, i64 0, i64 1
  %2498 = bitcast i8* %scevgep28.9.23 to [41 x [41 x i8]]*
  %scevgep41.9.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2492, i64 0, i64 1, i64 0
  %2499 = bitcast i8* %scevgep41.9.23 to [41 x [41 x i8]]*
  %call16.9.24 = call zeroext i8 (...) @rand()
  store i8 %call16.9.24, i8* %scevgep28.9.23, align 1
  %2500 = load i8, i8* %scevgep28.9.23, align 1
  %conv23.9.24 = zext i8 %2500 to i32
  %2501 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.24 = getelementptr i8, i8* %b, i64 34
  %2502 = load i8, i8* %scevgep34.9.24, align 1
  %call28.9.24 = call zeroext i8 @mult(i8 zeroext %2501, i8 zeroext %2502)
  %conv29.9.24 = zext i8 %call28.9.24 to i32
  %xor.9.24 = xor i32 %conv23.9.24, %conv29.9.24
  %scevgep35.9.24 = getelementptr i8, i8* %a, i64 34
  %2503 = load i8, i8* %scevgep35.9.24, align 1
  %2504 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.24 = call zeroext i8 @mult(i8 zeroext %2503, i8 zeroext %2504)
  %conv35.9.24 = zext i8 %call34.9.24 to i32
  %xor36.9.24 = xor i32 %xor.9.24, %conv35.9.24
  %conv37.9.24 = trunc i32 %xor36.9.24 to i8
  store i8 %conv37.9.24, i8* %scevgep41.9.23, align 1
  %scevgep28.9.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2498, i64 0, i64 0, i64 1
  %2505 = bitcast i8* %scevgep28.9.24 to [41 x [41 x i8]]*
  %scevgep41.9.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2499, i64 0, i64 1, i64 0
  %2506 = bitcast i8* %scevgep41.9.24 to [41 x [41 x i8]]*
  %call16.9.25 = call zeroext i8 (...) @rand()
  store i8 %call16.9.25, i8* %scevgep28.9.24, align 1
  %2507 = load i8, i8* %scevgep28.9.24, align 1
  %conv23.9.25 = zext i8 %2507 to i32
  %2508 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.25 = getelementptr i8, i8* %b, i64 35
  %2509 = load i8, i8* %scevgep34.9.25, align 1
  %call28.9.25 = call zeroext i8 @mult(i8 zeroext %2508, i8 zeroext %2509)
  %conv29.9.25 = zext i8 %call28.9.25 to i32
  %xor.9.25 = xor i32 %conv23.9.25, %conv29.9.25
  %scevgep35.9.25 = getelementptr i8, i8* %a, i64 35
  %2510 = load i8, i8* %scevgep35.9.25, align 1
  %2511 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.25 = call zeroext i8 @mult(i8 zeroext %2510, i8 zeroext %2511)
  %conv35.9.25 = zext i8 %call34.9.25 to i32
  %xor36.9.25 = xor i32 %xor.9.25, %conv35.9.25
  %conv37.9.25 = trunc i32 %xor36.9.25 to i8
  store i8 %conv37.9.25, i8* %scevgep41.9.24, align 1
  %scevgep28.9.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2505, i64 0, i64 0, i64 1
  %2512 = bitcast i8* %scevgep28.9.25 to [41 x [41 x i8]]*
  %scevgep41.9.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2506, i64 0, i64 1, i64 0
  %2513 = bitcast i8* %scevgep41.9.25 to [41 x [41 x i8]]*
  %call16.9.26 = call zeroext i8 (...) @rand()
  store i8 %call16.9.26, i8* %scevgep28.9.25, align 1
  %2514 = load i8, i8* %scevgep28.9.25, align 1
  %conv23.9.26 = zext i8 %2514 to i32
  %2515 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.26 = getelementptr i8, i8* %b, i64 36
  %2516 = load i8, i8* %scevgep34.9.26, align 1
  %call28.9.26 = call zeroext i8 @mult(i8 zeroext %2515, i8 zeroext %2516)
  %conv29.9.26 = zext i8 %call28.9.26 to i32
  %xor.9.26 = xor i32 %conv23.9.26, %conv29.9.26
  %scevgep35.9.26 = getelementptr i8, i8* %a, i64 36
  %2517 = load i8, i8* %scevgep35.9.26, align 1
  %2518 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.26 = call zeroext i8 @mult(i8 zeroext %2517, i8 zeroext %2518)
  %conv35.9.26 = zext i8 %call34.9.26 to i32
  %xor36.9.26 = xor i32 %xor.9.26, %conv35.9.26
  %conv37.9.26 = trunc i32 %xor36.9.26 to i8
  store i8 %conv37.9.26, i8* %scevgep41.9.25, align 1
  %scevgep28.9.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2512, i64 0, i64 0, i64 1
  %2519 = bitcast i8* %scevgep28.9.26 to [41 x [41 x i8]]*
  %scevgep41.9.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2513, i64 0, i64 1, i64 0
  %2520 = bitcast i8* %scevgep41.9.26 to [41 x [41 x i8]]*
  %call16.9.27 = call zeroext i8 (...) @rand()
  store i8 %call16.9.27, i8* %scevgep28.9.26, align 1
  %2521 = load i8, i8* %scevgep28.9.26, align 1
  %conv23.9.27 = zext i8 %2521 to i32
  %2522 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.27 = getelementptr i8, i8* %b, i64 37
  %2523 = load i8, i8* %scevgep34.9.27, align 1
  %call28.9.27 = call zeroext i8 @mult(i8 zeroext %2522, i8 zeroext %2523)
  %conv29.9.27 = zext i8 %call28.9.27 to i32
  %xor.9.27 = xor i32 %conv23.9.27, %conv29.9.27
  %scevgep35.9.27 = getelementptr i8, i8* %a, i64 37
  %2524 = load i8, i8* %scevgep35.9.27, align 1
  %2525 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.27 = call zeroext i8 @mult(i8 zeroext %2524, i8 zeroext %2525)
  %conv35.9.27 = zext i8 %call34.9.27 to i32
  %xor36.9.27 = xor i32 %xor.9.27, %conv35.9.27
  %conv37.9.27 = trunc i32 %xor36.9.27 to i8
  store i8 %conv37.9.27, i8* %scevgep41.9.26, align 1
  %scevgep28.9.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2519, i64 0, i64 0, i64 1
  %2526 = bitcast i8* %scevgep28.9.27 to [41 x [41 x i8]]*
  %scevgep41.9.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2520, i64 0, i64 1, i64 0
  %2527 = bitcast i8* %scevgep41.9.27 to [41 x [41 x i8]]*
  %call16.9.28 = call zeroext i8 (...) @rand()
  store i8 %call16.9.28, i8* %scevgep28.9.27, align 1
  %2528 = load i8, i8* %scevgep28.9.27, align 1
  %conv23.9.28 = zext i8 %2528 to i32
  %2529 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.28 = getelementptr i8, i8* %b, i64 38
  %2530 = load i8, i8* %scevgep34.9.28, align 1
  %call28.9.28 = call zeroext i8 @mult(i8 zeroext %2529, i8 zeroext %2530)
  %conv29.9.28 = zext i8 %call28.9.28 to i32
  %xor.9.28 = xor i32 %conv23.9.28, %conv29.9.28
  %scevgep35.9.28 = getelementptr i8, i8* %a, i64 38
  %2531 = load i8, i8* %scevgep35.9.28, align 1
  %2532 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.28 = call zeroext i8 @mult(i8 zeroext %2531, i8 zeroext %2532)
  %conv35.9.28 = zext i8 %call34.9.28 to i32
  %xor36.9.28 = xor i32 %xor.9.28, %conv35.9.28
  %conv37.9.28 = trunc i32 %xor36.9.28 to i8
  store i8 %conv37.9.28, i8* %scevgep41.9.27, align 1
  %scevgep28.9.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2526, i64 0, i64 0, i64 1
  %2533 = bitcast i8* %scevgep28.9.28 to [41 x [41 x i8]]*
  %scevgep41.9.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2527, i64 0, i64 1, i64 0
  %2534 = bitcast i8* %scevgep41.9.28 to [41 x [41 x i8]]*
  %call16.9.29 = call zeroext i8 (...) @rand()
  store i8 %call16.9.29, i8* %scevgep28.9.28, align 1
  %2535 = load i8, i8* %scevgep28.9.28, align 1
  %conv23.9.29 = zext i8 %2535 to i32
  %2536 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.29 = getelementptr i8, i8* %b, i64 39
  %2537 = load i8, i8* %scevgep34.9.29, align 1
  %call28.9.29 = call zeroext i8 @mult(i8 zeroext %2536, i8 zeroext %2537)
  %conv29.9.29 = zext i8 %call28.9.29 to i32
  %xor.9.29 = xor i32 %conv23.9.29, %conv29.9.29
  %scevgep35.9.29 = getelementptr i8, i8* %a, i64 39
  %2538 = load i8, i8* %scevgep35.9.29, align 1
  %2539 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.29 = call zeroext i8 @mult(i8 zeroext %2538, i8 zeroext %2539)
  %conv35.9.29 = zext i8 %call34.9.29 to i32
  %xor36.9.29 = xor i32 %xor.9.29, %conv35.9.29
  %conv37.9.29 = trunc i32 %xor36.9.29 to i8
  store i8 %conv37.9.29, i8* %scevgep41.9.28, align 1
  %scevgep28.9.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2533, i64 0, i64 0, i64 1
  %scevgep41.9.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2534, i64 0, i64 1, i64 0
  %call16.9.30 = call zeroext i8 (...) @rand()
  store i8 %call16.9.30, i8* %scevgep28.9.29, align 1
  %2540 = load i8, i8* %scevgep28.9.29, align 1
  %conv23.9.30 = zext i8 %2540 to i32
  %2541 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.30 = getelementptr i8, i8* %b, i64 40
  %2542 = load i8, i8* %scevgep34.9.30, align 1
  %call28.9.30 = call zeroext i8 @mult(i8 zeroext %2541, i8 zeroext %2542)
  %conv29.9.30 = zext i8 %call28.9.30 to i32
  %xor.9.30 = xor i32 %conv23.9.30, %conv29.9.30
  %scevgep35.9.30 = getelementptr i8, i8* %a, i64 40
  %2543 = load i8, i8* %scevgep35.9.30, align 1
  %2544 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.30 = call zeroext i8 @mult(i8 zeroext %2543, i8 zeroext %2544)
  %conv35.9.30 = zext i8 %call34.9.30 to i32
  %xor36.9.30 = xor i32 %xor.9.30, %conv35.9.30
  %conv37.9.30 = trunc i32 %xor36.9.30 to i8
  store i8 %conv37.9.30, i8* %scevgep41.9.29, align 1
  %scevgep26.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2330, i64 0, i64 1, i64 1
  %2545 = bitcast i8* %scevgep26.9 to [41 x [41 x i8]]*
  %scevgep39.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2331, i64 0, i64 1, i64 1
  %2546 = bitcast i8* %scevgep39.9 to [41 x [41 x i8]]*
  %arrayidx25.10 = getelementptr inbounds i8, i8* %a, i64 10
  %arrayidx33.10 = getelementptr inbounds i8, i8* %b, i64 10
  %call16.10 = call zeroext i8 (...) @rand()
  store i8 %call16.10, i8* %scevgep26.9, align 1
  %2547 = load i8, i8* %scevgep26.9, align 1
  %conv23.10 = zext i8 %2547 to i32
  %2548 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10 = getelementptr i8, i8* %b, i64 11
  %2549 = load i8, i8* %scevgep34.10, align 1
  %call28.10 = call zeroext i8 @mult(i8 zeroext %2548, i8 zeroext %2549)
  %conv29.10 = zext i8 %call28.10 to i32
  %xor.10 = xor i32 %conv23.10, %conv29.10
  %scevgep35.10 = getelementptr i8, i8* %a, i64 11
  %2550 = load i8, i8* %scevgep35.10, align 1
  %2551 = load i8, i8* %arrayidx33.10, align 1
  %call34.10 = call zeroext i8 @mult(i8 zeroext %2550, i8 zeroext %2551)
  %conv35.10 = zext i8 %call34.10 to i32
  %xor36.10 = xor i32 %xor.10, %conv35.10
  %conv37.10 = trunc i32 %xor36.10 to i8
  store i8 %conv37.10, i8* %scevgep39.9, align 1
  %scevgep28.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2545, i64 0, i64 0, i64 1
  %2552 = bitcast i8* %scevgep28.10 to [41 x [41 x i8]]*
  %scevgep41.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2546, i64 0, i64 1, i64 0
  %2553 = bitcast i8* %scevgep41.10 to [41 x [41 x i8]]*
  %call16.10.1 = call zeroext i8 (...) @rand()
  store i8 %call16.10.1, i8* %scevgep28.10, align 1
  %2554 = load i8, i8* %scevgep28.10, align 1
  %conv23.10.1 = zext i8 %2554 to i32
  %2555 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.1 = getelementptr i8, i8* %b, i64 12
  %2556 = load i8, i8* %scevgep34.10.1, align 1
  %call28.10.1 = call zeroext i8 @mult(i8 zeroext %2555, i8 zeroext %2556)
  %conv29.10.1 = zext i8 %call28.10.1 to i32
  %xor.10.1 = xor i32 %conv23.10.1, %conv29.10.1
  %scevgep35.10.1 = getelementptr i8, i8* %a, i64 12
  %2557 = load i8, i8* %scevgep35.10.1, align 1
  %2558 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.1 = call zeroext i8 @mult(i8 zeroext %2557, i8 zeroext %2558)
  %conv35.10.1 = zext i8 %call34.10.1 to i32
  %xor36.10.1 = xor i32 %xor.10.1, %conv35.10.1
  %conv37.10.1 = trunc i32 %xor36.10.1 to i8
  store i8 %conv37.10.1, i8* %scevgep41.10, align 1
  %scevgep28.10.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2552, i64 0, i64 0, i64 1
  %2559 = bitcast i8* %scevgep28.10.1 to [41 x [41 x i8]]*
  %scevgep41.10.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2553, i64 0, i64 1, i64 0
  %2560 = bitcast i8* %scevgep41.10.1 to [41 x [41 x i8]]*
  %call16.10.2 = call zeroext i8 (...) @rand()
  store i8 %call16.10.2, i8* %scevgep28.10.1, align 1
  %2561 = load i8, i8* %scevgep28.10.1, align 1
  %conv23.10.2 = zext i8 %2561 to i32
  %2562 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.2 = getelementptr i8, i8* %b, i64 13
  %2563 = load i8, i8* %scevgep34.10.2, align 1
  %call28.10.2 = call zeroext i8 @mult(i8 zeroext %2562, i8 zeroext %2563)
  %conv29.10.2 = zext i8 %call28.10.2 to i32
  %xor.10.2 = xor i32 %conv23.10.2, %conv29.10.2
  %scevgep35.10.2 = getelementptr i8, i8* %a, i64 13
  %2564 = load i8, i8* %scevgep35.10.2, align 1
  %2565 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.2 = call zeroext i8 @mult(i8 zeroext %2564, i8 zeroext %2565)
  %conv35.10.2 = zext i8 %call34.10.2 to i32
  %xor36.10.2 = xor i32 %xor.10.2, %conv35.10.2
  %conv37.10.2 = trunc i32 %xor36.10.2 to i8
  store i8 %conv37.10.2, i8* %scevgep41.10.1, align 1
  %scevgep28.10.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2559, i64 0, i64 0, i64 1
  %2566 = bitcast i8* %scevgep28.10.2 to [41 x [41 x i8]]*
  %scevgep41.10.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2560, i64 0, i64 1, i64 0
  %2567 = bitcast i8* %scevgep41.10.2 to [41 x [41 x i8]]*
  %call16.10.3 = call zeroext i8 (...) @rand()
  store i8 %call16.10.3, i8* %scevgep28.10.2, align 1
  %2568 = load i8, i8* %scevgep28.10.2, align 1
  %conv23.10.3 = zext i8 %2568 to i32
  %2569 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.3 = getelementptr i8, i8* %b, i64 14
  %2570 = load i8, i8* %scevgep34.10.3, align 1
  %call28.10.3 = call zeroext i8 @mult(i8 zeroext %2569, i8 zeroext %2570)
  %conv29.10.3 = zext i8 %call28.10.3 to i32
  %xor.10.3 = xor i32 %conv23.10.3, %conv29.10.3
  %scevgep35.10.3 = getelementptr i8, i8* %a, i64 14
  %2571 = load i8, i8* %scevgep35.10.3, align 1
  %2572 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.3 = call zeroext i8 @mult(i8 zeroext %2571, i8 zeroext %2572)
  %conv35.10.3 = zext i8 %call34.10.3 to i32
  %xor36.10.3 = xor i32 %xor.10.3, %conv35.10.3
  %conv37.10.3 = trunc i32 %xor36.10.3 to i8
  store i8 %conv37.10.3, i8* %scevgep41.10.2, align 1
  %scevgep28.10.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2566, i64 0, i64 0, i64 1
  %2573 = bitcast i8* %scevgep28.10.3 to [41 x [41 x i8]]*
  %scevgep41.10.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2567, i64 0, i64 1, i64 0
  %2574 = bitcast i8* %scevgep41.10.3 to [41 x [41 x i8]]*
  %call16.10.4 = call zeroext i8 (...) @rand()
  store i8 %call16.10.4, i8* %scevgep28.10.3, align 1
  %2575 = load i8, i8* %scevgep28.10.3, align 1
  %conv23.10.4 = zext i8 %2575 to i32
  %2576 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.4 = getelementptr i8, i8* %b, i64 15
  %2577 = load i8, i8* %scevgep34.10.4, align 1
  %call28.10.4 = call zeroext i8 @mult(i8 zeroext %2576, i8 zeroext %2577)
  %conv29.10.4 = zext i8 %call28.10.4 to i32
  %xor.10.4 = xor i32 %conv23.10.4, %conv29.10.4
  %scevgep35.10.4 = getelementptr i8, i8* %a, i64 15
  %2578 = load i8, i8* %scevgep35.10.4, align 1
  %2579 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.4 = call zeroext i8 @mult(i8 zeroext %2578, i8 zeroext %2579)
  %conv35.10.4 = zext i8 %call34.10.4 to i32
  %xor36.10.4 = xor i32 %xor.10.4, %conv35.10.4
  %conv37.10.4 = trunc i32 %xor36.10.4 to i8
  store i8 %conv37.10.4, i8* %scevgep41.10.3, align 1
  %scevgep28.10.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2573, i64 0, i64 0, i64 1
  %2580 = bitcast i8* %scevgep28.10.4 to [41 x [41 x i8]]*
  %scevgep41.10.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2574, i64 0, i64 1, i64 0
  %2581 = bitcast i8* %scevgep41.10.4 to [41 x [41 x i8]]*
  %call16.10.5 = call zeroext i8 (...) @rand()
  store i8 %call16.10.5, i8* %scevgep28.10.4, align 1
  %2582 = load i8, i8* %scevgep28.10.4, align 1
  %conv23.10.5 = zext i8 %2582 to i32
  %2583 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.5 = getelementptr i8, i8* %b, i64 16
  %2584 = load i8, i8* %scevgep34.10.5, align 1
  %call28.10.5 = call zeroext i8 @mult(i8 zeroext %2583, i8 zeroext %2584)
  %conv29.10.5 = zext i8 %call28.10.5 to i32
  %xor.10.5 = xor i32 %conv23.10.5, %conv29.10.5
  %scevgep35.10.5 = getelementptr i8, i8* %a, i64 16
  %2585 = load i8, i8* %scevgep35.10.5, align 1
  %2586 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.5 = call zeroext i8 @mult(i8 zeroext %2585, i8 zeroext %2586)
  %conv35.10.5 = zext i8 %call34.10.5 to i32
  %xor36.10.5 = xor i32 %xor.10.5, %conv35.10.5
  %conv37.10.5 = trunc i32 %xor36.10.5 to i8
  store i8 %conv37.10.5, i8* %scevgep41.10.4, align 1
  %scevgep28.10.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2580, i64 0, i64 0, i64 1
  %2587 = bitcast i8* %scevgep28.10.5 to [41 x [41 x i8]]*
  %scevgep41.10.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2581, i64 0, i64 1, i64 0
  %2588 = bitcast i8* %scevgep41.10.5 to [41 x [41 x i8]]*
  %call16.10.6 = call zeroext i8 (...) @rand()
  store i8 %call16.10.6, i8* %scevgep28.10.5, align 1
  %2589 = load i8, i8* %scevgep28.10.5, align 1
  %conv23.10.6 = zext i8 %2589 to i32
  %2590 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.6 = getelementptr i8, i8* %b, i64 17
  %2591 = load i8, i8* %scevgep34.10.6, align 1
  %call28.10.6 = call zeroext i8 @mult(i8 zeroext %2590, i8 zeroext %2591)
  %conv29.10.6 = zext i8 %call28.10.6 to i32
  %xor.10.6 = xor i32 %conv23.10.6, %conv29.10.6
  %scevgep35.10.6 = getelementptr i8, i8* %a, i64 17
  %2592 = load i8, i8* %scevgep35.10.6, align 1
  %2593 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.6 = call zeroext i8 @mult(i8 zeroext %2592, i8 zeroext %2593)
  %conv35.10.6 = zext i8 %call34.10.6 to i32
  %xor36.10.6 = xor i32 %xor.10.6, %conv35.10.6
  %conv37.10.6 = trunc i32 %xor36.10.6 to i8
  store i8 %conv37.10.6, i8* %scevgep41.10.5, align 1
  %scevgep28.10.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2587, i64 0, i64 0, i64 1
  %2594 = bitcast i8* %scevgep28.10.6 to [41 x [41 x i8]]*
  %scevgep41.10.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2588, i64 0, i64 1, i64 0
  %2595 = bitcast i8* %scevgep41.10.6 to [41 x [41 x i8]]*
  %call16.10.7 = call zeroext i8 (...) @rand()
  store i8 %call16.10.7, i8* %scevgep28.10.6, align 1
  %2596 = load i8, i8* %scevgep28.10.6, align 1
  %conv23.10.7 = zext i8 %2596 to i32
  %2597 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.7 = getelementptr i8, i8* %b, i64 18
  %2598 = load i8, i8* %scevgep34.10.7, align 1
  %call28.10.7 = call zeroext i8 @mult(i8 zeroext %2597, i8 zeroext %2598)
  %conv29.10.7 = zext i8 %call28.10.7 to i32
  %xor.10.7 = xor i32 %conv23.10.7, %conv29.10.7
  %scevgep35.10.7 = getelementptr i8, i8* %a, i64 18
  %2599 = load i8, i8* %scevgep35.10.7, align 1
  %2600 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.7 = call zeroext i8 @mult(i8 zeroext %2599, i8 zeroext %2600)
  %conv35.10.7 = zext i8 %call34.10.7 to i32
  %xor36.10.7 = xor i32 %xor.10.7, %conv35.10.7
  %conv37.10.7 = trunc i32 %xor36.10.7 to i8
  store i8 %conv37.10.7, i8* %scevgep41.10.6, align 1
  %scevgep28.10.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2594, i64 0, i64 0, i64 1
  %2601 = bitcast i8* %scevgep28.10.7 to [41 x [41 x i8]]*
  %scevgep41.10.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2595, i64 0, i64 1, i64 0
  %2602 = bitcast i8* %scevgep41.10.7 to [41 x [41 x i8]]*
  %call16.10.8 = call zeroext i8 (...) @rand()
  store i8 %call16.10.8, i8* %scevgep28.10.7, align 1
  %2603 = load i8, i8* %scevgep28.10.7, align 1
  %conv23.10.8 = zext i8 %2603 to i32
  %2604 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.8 = getelementptr i8, i8* %b, i64 19
  %2605 = load i8, i8* %scevgep34.10.8, align 1
  %call28.10.8 = call zeroext i8 @mult(i8 zeroext %2604, i8 zeroext %2605)
  %conv29.10.8 = zext i8 %call28.10.8 to i32
  %xor.10.8 = xor i32 %conv23.10.8, %conv29.10.8
  %scevgep35.10.8 = getelementptr i8, i8* %a, i64 19
  %2606 = load i8, i8* %scevgep35.10.8, align 1
  %2607 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.8 = call zeroext i8 @mult(i8 zeroext %2606, i8 zeroext %2607)
  %conv35.10.8 = zext i8 %call34.10.8 to i32
  %xor36.10.8 = xor i32 %xor.10.8, %conv35.10.8
  %conv37.10.8 = trunc i32 %xor36.10.8 to i8
  store i8 %conv37.10.8, i8* %scevgep41.10.7, align 1
  %scevgep28.10.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2601, i64 0, i64 0, i64 1
  %2608 = bitcast i8* %scevgep28.10.8 to [41 x [41 x i8]]*
  %scevgep41.10.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2602, i64 0, i64 1, i64 0
  %2609 = bitcast i8* %scevgep41.10.8 to [41 x [41 x i8]]*
  %call16.10.9 = call zeroext i8 (...) @rand()
  store i8 %call16.10.9, i8* %scevgep28.10.8, align 1
  %2610 = load i8, i8* %scevgep28.10.8, align 1
  %conv23.10.9 = zext i8 %2610 to i32
  %2611 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.9 = getelementptr i8, i8* %b, i64 20
  %2612 = load i8, i8* %scevgep34.10.9, align 1
  %call28.10.9 = call zeroext i8 @mult(i8 zeroext %2611, i8 zeroext %2612)
  %conv29.10.9 = zext i8 %call28.10.9 to i32
  %xor.10.9 = xor i32 %conv23.10.9, %conv29.10.9
  %scevgep35.10.9 = getelementptr i8, i8* %a, i64 20
  %2613 = load i8, i8* %scevgep35.10.9, align 1
  %2614 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.9 = call zeroext i8 @mult(i8 zeroext %2613, i8 zeroext %2614)
  %conv35.10.9 = zext i8 %call34.10.9 to i32
  %xor36.10.9 = xor i32 %xor.10.9, %conv35.10.9
  %conv37.10.9 = trunc i32 %xor36.10.9 to i8
  store i8 %conv37.10.9, i8* %scevgep41.10.8, align 1
  %scevgep28.10.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2608, i64 0, i64 0, i64 1
  %2615 = bitcast i8* %scevgep28.10.9 to [41 x [41 x i8]]*
  %scevgep41.10.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2609, i64 0, i64 1, i64 0
  %2616 = bitcast i8* %scevgep41.10.9 to [41 x [41 x i8]]*
  %call16.10.10 = call zeroext i8 (...) @rand()
  store i8 %call16.10.10, i8* %scevgep28.10.9, align 1
  %2617 = load i8, i8* %scevgep28.10.9, align 1
  %conv23.10.10 = zext i8 %2617 to i32
  %2618 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.10 = getelementptr i8, i8* %b, i64 21
  %2619 = load i8, i8* %scevgep34.10.10, align 1
  %call28.10.10 = call zeroext i8 @mult(i8 zeroext %2618, i8 zeroext %2619)
  %conv29.10.10 = zext i8 %call28.10.10 to i32
  %xor.10.10 = xor i32 %conv23.10.10, %conv29.10.10
  %scevgep35.10.10 = getelementptr i8, i8* %a, i64 21
  %2620 = load i8, i8* %scevgep35.10.10, align 1
  %2621 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.10 = call zeroext i8 @mult(i8 zeroext %2620, i8 zeroext %2621)
  %conv35.10.10 = zext i8 %call34.10.10 to i32
  %xor36.10.10 = xor i32 %xor.10.10, %conv35.10.10
  %conv37.10.10 = trunc i32 %xor36.10.10 to i8
  store i8 %conv37.10.10, i8* %scevgep41.10.9, align 1
  %scevgep28.10.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2615, i64 0, i64 0, i64 1
  %2622 = bitcast i8* %scevgep28.10.10 to [41 x [41 x i8]]*
  %scevgep41.10.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2616, i64 0, i64 1, i64 0
  %2623 = bitcast i8* %scevgep41.10.10 to [41 x [41 x i8]]*
  %call16.10.11 = call zeroext i8 (...) @rand()
  store i8 %call16.10.11, i8* %scevgep28.10.10, align 1
  %2624 = load i8, i8* %scevgep28.10.10, align 1
  %conv23.10.11 = zext i8 %2624 to i32
  %2625 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.11 = getelementptr i8, i8* %b, i64 22
  %2626 = load i8, i8* %scevgep34.10.11, align 1
  %call28.10.11 = call zeroext i8 @mult(i8 zeroext %2625, i8 zeroext %2626)
  %conv29.10.11 = zext i8 %call28.10.11 to i32
  %xor.10.11 = xor i32 %conv23.10.11, %conv29.10.11
  %scevgep35.10.11 = getelementptr i8, i8* %a, i64 22
  %2627 = load i8, i8* %scevgep35.10.11, align 1
  %2628 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.11 = call zeroext i8 @mult(i8 zeroext %2627, i8 zeroext %2628)
  %conv35.10.11 = zext i8 %call34.10.11 to i32
  %xor36.10.11 = xor i32 %xor.10.11, %conv35.10.11
  %conv37.10.11 = trunc i32 %xor36.10.11 to i8
  store i8 %conv37.10.11, i8* %scevgep41.10.10, align 1
  %scevgep28.10.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2622, i64 0, i64 0, i64 1
  %2629 = bitcast i8* %scevgep28.10.11 to [41 x [41 x i8]]*
  %scevgep41.10.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2623, i64 0, i64 1, i64 0
  %2630 = bitcast i8* %scevgep41.10.11 to [41 x [41 x i8]]*
  %call16.10.12 = call zeroext i8 (...) @rand()
  store i8 %call16.10.12, i8* %scevgep28.10.11, align 1
  %2631 = load i8, i8* %scevgep28.10.11, align 1
  %conv23.10.12 = zext i8 %2631 to i32
  %2632 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.12 = getelementptr i8, i8* %b, i64 23
  %2633 = load i8, i8* %scevgep34.10.12, align 1
  %call28.10.12 = call zeroext i8 @mult(i8 zeroext %2632, i8 zeroext %2633)
  %conv29.10.12 = zext i8 %call28.10.12 to i32
  %xor.10.12 = xor i32 %conv23.10.12, %conv29.10.12
  %scevgep35.10.12 = getelementptr i8, i8* %a, i64 23
  %2634 = load i8, i8* %scevgep35.10.12, align 1
  %2635 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.12 = call zeroext i8 @mult(i8 zeroext %2634, i8 zeroext %2635)
  %conv35.10.12 = zext i8 %call34.10.12 to i32
  %xor36.10.12 = xor i32 %xor.10.12, %conv35.10.12
  %conv37.10.12 = trunc i32 %xor36.10.12 to i8
  store i8 %conv37.10.12, i8* %scevgep41.10.11, align 1
  %scevgep28.10.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2629, i64 0, i64 0, i64 1
  %2636 = bitcast i8* %scevgep28.10.12 to [41 x [41 x i8]]*
  %scevgep41.10.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2630, i64 0, i64 1, i64 0
  %2637 = bitcast i8* %scevgep41.10.12 to [41 x [41 x i8]]*
  %call16.10.13 = call zeroext i8 (...) @rand()
  store i8 %call16.10.13, i8* %scevgep28.10.12, align 1
  %2638 = load i8, i8* %scevgep28.10.12, align 1
  %conv23.10.13 = zext i8 %2638 to i32
  %2639 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.13 = getelementptr i8, i8* %b, i64 24
  %2640 = load i8, i8* %scevgep34.10.13, align 1
  %call28.10.13 = call zeroext i8 @mult(i8 zeroext %2639, i8 zeroext %2640)
  %conv29.10.13 = zext i8 %call28.10.13 to i32
  %xor.10.13 = xor i32 %conv23.10.13, %conv29.10.13
  %scevgep35.10.13 = getelementptr i8, i8* %a, i64 24
  %2641 = load i8, i8* %scevgep35.10.13, align 1
  %2642 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.13 = call zeroext i8 @mult(i8 zeroext %2641, i8 zeroext %2642)
  %conv35.10.13 = zext i8 %call34.10.13 to i32
  %xor36.10.13 = xor i32 %xor.10.13, %conv35.10.13
  %conv37.10.13 = trunc i32 %xor36.10.13 to i8
  store i8 %conv37.10.13, i8* %scevgep41.10.12, align 1
  %scevgep28.10.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2636, i64 0, i64 0, i64 1
  %2643 = bitcast i8* %scevgep28.10.13 to [41 x [41 x i8]]*
  %scevgep41.10.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2637, i64 0, i64 1, i64 0
  %2644 = bitcast i8* %scevgep41.10.13 to [41 x [41 x i8]]*
  %call16.10.14 = call zeroext i8 (...) @rand()
  store i8 %call16.10.14, i8* %scevgep28.10.13, align 1
  %2645 = load i8, i8* %scevgep28.10.13, align 1
  %conv23.10.14 = zext i8 %2645 to i32
  %2646 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.14 = getelementptr i8, i8* %b, i64 25
  %2647 = load i8, i8* %scevgep34.10.14, align 1
  %call28.10.14 = call zeroext i8 @mult(i8 zeroext %2646, i8 zeroext %2647)
  %conv29.10.14 = zext i8 %call28.10.14 to i32
  %xor.10.14 = xor i32 %conv23.10.14, %conv29.10.14
  %scevgep35.10.14 = getelementptr i8, i8* %a, i64 25
  %2648 = load i8, i8* %scevgep35.10.14, align 1
  %2649 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.14 = call zeroext i8 @mult(i8 zeroext %2648, i8 zeroext %2649)
  %conv35.10.14 = zext i8 %call34.10.14 to i32
  %xor36.10.14 = xor i32 %xor.10.14, %conv35.10.14
  %conv37.10.14 = trunc i32 %xor36.10.14 to i8
  store i8 %conv37.10.14, i8* %scevgep41.10.13, align 1
  %scevgep28.10.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2643, i64 0, i64 0, i64 1
  %2650 = bitcast i8* %scevgep28.10.14 to [41 x [41 x i8]]*
  %scevgep41.10.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2644, i64 0, i64 1, i64 0
  %2651 = bitcast i8* %scevgep41.10.14 to [41 x [41 x i8]]*
  %call16.10.15 = call zeroext i8 (...) @rand()
  store i8 %call16.10.15, i8* %scevgep28.10.14, align 1
  %2652 = load i8, i8* %scevgep28.10.14, align 1
  %conv23.10.15 = zext i8 %2652 to i32
  %2653 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.15 = getelementptr i8, i8* %b, i64 26
  %2654 = load i8, i8* %scevgep34.10.15, align 1
  %call28.10.15 = call zeroext i8 @mult(i8 zeroext %2653, i8 zeroext %2654)
  %conv29.10.15 = zext i8 %call28.10.15 to i32
  %xor.10.15 = xor i32 %conv23.10.15, %conv29.10.15
  %scevgep35.10.15 = getelementptr i8, i8* %a, i64 26
  %2655 = load i8, i8* %scevgep35.10.15, align 1
  %2656 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.15 = call zeroext i8 @mult(i8 zeroext %2655, i8 zeroext %2656)
  %conv35.10.15 = zext i8 %call34.10.15 to i32
  %xor36.10.15 = xor i32 %xor.10.15, %conv35.10.15
  %conv37.10.15 = trunc i32 %xor36.10.15 to i8
  store i8 %conv37.10.15, i8* %scevgep41.10.14, align 1
  %scevgep28.10.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2650, i64 0, i64 0, i64 1
  %2657 = bitcast i8* %scevgep28.10.15 to [41 x [41 x i8]]*
  %scevgep41.10.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2651, i64 0, i64 1, i64 0
  %2658 = bitcast i8* %scevgep41.10.15 to [41 x [41 x i8]]*
  %call16.10.16 = call zeroext i8 (...) @rand()
  store i8 %call16.10.16, i8* %scevgep28.10.15, align 1
  %2659 = load i8, i8* %scevgep28.10.15, align 1
  %conv23.10.16 = zext i8 %2659 to i32
  %2660 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.16 = getelementptr i8, i8* %b, i64 27
  %2661 = load i8, i8* %scevgep34.10.16, align 1
  %call28.10.16 = call zeroext i8 @mult(i8 zeroext %2660, i8 zeroext %2661)
  %conv29.10.16 = zext i8 %call28.10.16 to i32
  %xor.10.16 = xor i32 %conv23.10.16, %conv29.10.16
  %scevgep35.10.16 = getelementptr i8, i8* %a, i64 27
  %2662 = load i8, i8* %scevgep35.10.16, align 1
  %2663 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.16 = call zeroext i8 @mult(i8 zeroext %2662, i8 zeroext %2663)
  %conv35.10.16 = zext i8 %call34.10.16 to i32
  %xor36.10.16 = xor i32 %xor.10.16, %conv35.10.16
  %conv37.10.16 = trunc i32 %xor36.10.16 to i8
  store i8 %conv37.10.16, i8* %scevgep41.10.15, align 1
  %scevgep28.10.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2657, i64 0, i64 0, i64 1
  %2664 = bitcast i8* %scevgep28.10.16 to [41 x [41 x i8]]*
  %scevgep41.10.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2658, i64 0, i64 1, i64 0
  %2665 = bitcast i8* %scevgep41.10.16 to [41 x [41 x i8]]*
  %call16.10.17 = call zeroext i8 (...) @rand()
  store i8 %call16.10.17, i8* %scevgep28.10.16, align 1
  %2666 = load i8, i8* %scevgep28.10.16, align 1
  %conv23.10.17 = zext i8 %2666 to i32
  %2667 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.17 = getelementptr i8, i8* %b, i64 28
  %2668 = load i8, i8* %scevgep34.10.17, align 1
  %call28.10.17 = call zeroext i8 @mult(i8 zeroext %2667, i8 zeroext %2668)
  %conv29.10.17 = zext i8 %call28.10.17 to i32
  %xor.10.17 = xor i32 %conv23.10.17, %conv29.10.17
  %scevgep35.10.17 = getelementptr i8, i8* %a, i64 28
  %2669 = load i8, i8* %scevgep35.10.17, align 1
  %2670 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.17 = call zeroext i8 @mult(i8 zeroext %2669, i8 zeroext %2670)
  %conv35.10.17 = zext i8 %call34.10.17 to i32
  %xor36.10.17 = xor i32 %xor.10.17, %conv35.10.17
  %conv37.10.17 = trunc i32 %xor36.10.17 to i8
  store i8 %conv37.10.17, i8* %scevgep41.10.16, align 1
  %scevgep28.10.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2664, i64 0, i64 0, i64 1
  %2671 = bitcast i8* %scevgep28.10.17 to [41 x [41 x i8]]*
  %scevgep41.10.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2665, i64 0, i64 1, i64 0
  %2672 = bitcast i8* %scevgep41.10.17 to [41 x [41 x i8]]*
  %call16.10.18 = call zeroext i8 (...) @rand()
  store i8 %call16.10.18, i8* %scevgep28.10.17, align 1
  %2673 = load i8, i8* %scevgep28.10.17, align 1
  %conv23.10.18 = zext i8 %2673 to i32
  %2674 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.18 = getelementptr i8, i8* %b, i64 29
  %2675 = load i8, i8* %scevgep34.10.18, align 1
  %call28.10.18 = call zeroext i8 @mult(i8 zeroext %2674, i8 zeroext %2675)
  %conv29.10.18 = zext i8 %call28.10.18 to i32
  %xor.10.18 = xor i32 %conv23.10.18, %conv29.10.18
  %scevgep35.10.18 = getelementptr i8, i8* %a, i64 29
  %2676 = load i8, i8* %scevgep35.10.18, align 1
  %2677 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.18 = call zeroext i8 @mult(i8 zeroext %2676, i8 zeroext %2677)
  %conv35.10.18 = zext i8 %call34.10.18 to i32
  %xor36.10.18 = xor i32 %xor.10.18, %conv35.10.18
  %conv37.10.18 = trunc i32 %xor36.10.18 to i8
  store i8 %conv37.10.18, i8* %scevgep41.10.17, align 1
  %scevgep28.10.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2671, i64 0, i64 0, i64 1
  %2678 = bitcast i8* %scevgep28.10.18 to [41 x [41 x i8]]*
  %scevgep41.10.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2672, i64 0, i64 1, i64 0
  %2679 = bitcast i8* %scevgep41.10.18 to [41 x [41 x i8]]*
  %call16.10.19 = call zeroext i8 (...) @rand()
  store i8 %call16.10.19, i8* %scevgep28.10.18, align 1
  %2680 = load i8, i8* %scevgep28.10.18, align 1
  %conv23.10.19 = zext i8 %2680 to i32
  %2681 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.19 = getelementptr i8, i8* %b, i64 30
  %2682 = load i8, i8* %scevgep34.10.19, align 1
  %call28.10.19 = call zeroext i8 @mult(i8 zeroext %2681, i8 zeroext %2682)
  %conv29.10.19 = zext i8 %call28.10.19 to i32
  %xor.10.19 = xor i32 %conv23.10.19, %conv29.10.19
  %scevgep35.10.19 = getelementptr i8, i8* %a, i64 30
  %2683 = load i8, i8* %scevgep35.10.19, align 1
  %2684 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.19 = call zeroext i8 @mult(i8 zeroext %2683, i8 zeroext %2684)
  %conv35.10.19 = zext i8 %call34.10.19 to i32
  %xor36.10.19 = xor i32 %xor.10.19, %conv35.10.19
  %conv37.10.19 = trunc i32 %xor36.10.19 to i8
  store i8 %conv37.10.19, i8* %scevgep41.10.18, align 1
  %scevgep28.10.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2678, i64 0, i64 0, i64 1
  %2685 = bitcast i8* %scevgep28.10.19 to [41 x [41 x i8]]*
  %scevgep41.10.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2679, i64 0, i64 1, i64 0
  %2686 = bitcast i8* %scevgep41.10.19 to [41 x [41 x i8]]*
  %call16.10.20 = call zeroext i8 (...) @rand()
  store i8 %call16.10.20, i8* %scevgep28.10.19, align 1
  %2687 = load i8, i8* %scevgep28.10.19, align 1
  %conv23.10.20 = zext i8 %2687 to i32
  %2688 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.20 = getelementptr i8, i8* %b, i64 31
  %2689 = load i8, i8* %scevgep34.10.20, align 1
  %call28.10.20 = call zeroext i8 @mult(i8 zeroext %2688, i8 zeroext %2689)
  %conv29.10.20 = zext i8 %call28.10.20 to i32
  %xor.10.20 = xor i32 %conv23.10.20, %conv29.10.20
  %scevgep35.10.20 = getelementptr i8, i8* %a, i64 31
  %2690 = load i8, i8* %scevgep35.10.20, align 1
  %2691 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.20 = call zeroext i8 @mult(i8 zeroext %2690, i8 zeroext %2691)
  %conv35.10.20 = zext i8 %call34.10.20 to i32
  %xor36.10.20 = xor i32 %xor.10.20, %conv35.10.20
  %conv37.10.20 = trunc i32 %xor36.10.20 to i8
  store i8 %conv37.10.20, i8* %scevgep41.10.19, align 1
  %scevgep28.10.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2685, i64 0, i64 0, i64 1
  %2692 = bitcast i8* %scevgep28.10.20 to [41 x [41 x i8]]*
  %scevgep41.10.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2686, i64 0, i64 1, i64 0
  %2693 = bitcast i8* %scevgep41.10.20 to [41 x [41 x i8]]*
  %call16.10.21 = call zeroext i8 (...) @rand()
  store i8 %call16.10.21, i8* %scevgep28.10.20, align 1
  %2694 = load i8, i8* %scevgep28.10.20, align 1
  %conv23.10.21 = zext i8 %2694 to i32
  %2695 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.21 = getelementptr i8, i8* %b, i64 32
  %2696 = load i8, i8* %scevgep34.10.21, align 1
  %call28.10.21 = call zeroext i8 @mult(i8 zeroext %2695, i8 zeroext %2696)
  %conv29.10.21 = zext i8 %call28.10.21 to i32
  %xor.10.21 = xor i32 %conv23.10.21, %conv29.10.21
  %scevgep35.10.21 = getelementptr i8, i8* %a, i64 32
  %2697 = load i8, i8* %scevgep35.10.21, align 1
  %2698 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.21 = call zeroext i8 @mult(i8 zeroext %2697, i8 zeroext %2698)
  %conv35.10.21 = zext i8 %call34.10.21 to i32
  %xor36.10.21 = xor i32 %xor.10.21, %conv35.10.21
  %conv37.10.21 = trunc i32 %xor36.10.21 to i8
  store i8 %conv37.10.21, i8* %scevgep41.10.20, align 1
  %scevgep28.10.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2692, i64 0, i64 0, i64 1
  %2699 = bitcast i8* %scevgep28.10.21 to [41 x [41 x i8]]*
  %scevgep41.10.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2693, i64 0, i64 1, i64 0
  %2700 = bitcast i8* %scevgep41.10.21 to [41 x [41 x i8]]*
  %call16.10.22 = call zeroext i8 (...) @rand()
  store i8 %call16.10.22, i8* %scevgep28.10.21, align 1
  %2701 = load i8, i8* %scevgep28.10.21, align 1
  %conv23.10.22 = zext i8 %2701 to i32
  %2702 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.22 = getelementptr i8, i8* %b, i64 33
  %2703 = load i8, i8* %scevgep34.10.22, align 1
  %call28.10.22 = call zeroext i8 @mult(i8 zeroext %2702, i8 zeroext %2703)
  %conv29.10.22 = zext i8 %call28.10.22 to i32
  %xor.10.22 = xor i32 %conv23.10.22, %conv29.10.22
  %scevgep35.10.22 = getelementptr i8, i8* %a, i64 33
  %2704 = load i8, i8* %scevgep35.10.22, align 1
  %2705 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.22 = call zeroext i8 @mult(i8 zeroext %2704, i8 zeroext %2705)
  %conv35.10.22 = zext i8 %call34.10.22 to i32
  %xor36.10.22 = xor i32 %xor.10.22, %conv35.10.22
  %conv37.10.22 = trunc i32 %xor36.10.22 to i8
  store i8 %conv37.10.22, i8* %scevgep41.10.21, align 1
  %scevgep28.10.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2699, i64 0, i64 0, i64 1
  %2706 = bitcast i8* %scevgep28.10.22 to [41 x [41 x i8]]*
  %scevgep41.10.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2700, i64 0, i64 1, i64 0
  %2707 = bitcast i8* %scevgep41.10.22 to [41 x [41 x i8]]*
  %call16.10.23 = call zeroext i8 (...) @rand()
  store i8 %call16.10.23, i8* %scevgep28.10.22, align 1
  %2708 = load i8, i8* %scevgep28.10.22, align 1
  %conv23.10.23 = zext i8 %2708 to i32
  %2709 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.23 = getelementptr i8, i8* %b, i64 34
  %2710 = load i8, i8* %scevgep34.10.23, align 1
  %call28.10.23 = call zeroext i8 @mult(i8 zeroext %2709, i8 zeroext %2710)
  %conv29.10.23 = zext i8 %call28.10.23 to i32
  %xor.10.23 = xor i32 %conv23.10.23, %conv29.10.23
  %scevgep35.10.23 = getelementptr i8, i8* %a, i64 34
  %2711 = load i8, i8* %scevgep35.10.23, align 1
  %2712 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.23 = call zeroext i8 @mult(i8 zeroext %2711, i8 zeroext %2712)
  %conv35.10.23 = zext i8 %call34.10.23 to i32
  %xor36.10.23 = xor i32 %xor.10.23, %conv35.10.23
  %conv37.10.23 = trunc i32 %xor36.10.23 to i8
  store i8 %conv37.10.23, i8* %scevgep41.10.22, align 1
  %scevgep28.10.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2706, i64 0, i64 0, i64 1
  %2713 = bitcast i8* %scevgep28.10.23 to [41 x [41 x i8]]*
  %scevgep41.10.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2707, i64 0, i64 1, i64 0
  %2714 = bitcast i8* %scevgep41.10.23 to [41 x [41 x i8]]*
  %call16.10.24 = call zeroext i8 (...) @rand()
  store i8 %call16.10.24, i8* %scevgep28.10.23, align 1
  %2715 = load i8, i8* %scevgep28.10.23, align 1
  %conv23.10.24 = zext i8 %2715 to i32
  %2716 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.24 = getelementptr i8, i8* %b, i64 35
  %2717 = load i8, i8* %scevgep34.10.24, align 1
  %call28.10.24 = call zeroext i8 @mult(i8 zeroext %2716, i8 zeroext %2717)
  %conv29.10.24 = zext i8 %call28.10.24 to i32
  %xor.10.24 = xor i32 %conv23.10.24, %conv29.10.24
  %scevgep35.10.24 = getelementptr i8, i8* %a, i64 35
  %2718 = load i8, i8* %scevgep35.10.24, align 1
  %2719 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.24 = call zeroext i8 @mult(i8 zeroext %2718, i8 zeroext %2719)
  %conv35.10.24 = zext i8 %call34.10.24 to i32
  %xor36.10.24 = xor i32 %xor.10.24, %conv35.10.24
  %conv37.10.24 = trunc i32 %xor36.10.24 to i8
  store i8 %conv37.10.24, i8* %scevgep41.10.23, align 1
  %scevgep28.10.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2713, i64 0, i64 0, i64 1
  %2720 = bitcast i8* %scevgep28.10.24 to [41 x [41 x i8]]*
  %scevgep41.10.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2714, i64 0, i64 1, i64 0
  %2721 = bitcast i8* %scevgep41.10.24 to [41 x [41 x i8]]*
  %call16.10.25 = call zeroext i8 (...) @rand()
  store i8 %call16.10.25, i8* %scevgep28.10.24, align 1
  %2722 = load i8, i8* %scevgep28.10.24, align 1
  %conv23.10.25 = zext i8 %2722 to i32
  %2723 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.25 = getelementptr i8, i8* %b, i64 36
  %2724 = load i8, i8* %scevgep34.10.25, align 1
  %call28.10.25 = call zeroext i8 @mult(i8 zeroext %2723, i8 zeroext %2724)
  %conv29.10.25 = zext i8 %call28.10.25 to i32
  %xor.10.25 = xor i32 %conv23.10.25, %conv29.10.25
  %scevgep35.10.25 = getelementptr i8, i8* %a, i64 36
  %2725 = load i8, i8* %scevgep35.10.25, align 1
  %2726 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.25 = call zeroext i8 @mult(i8 zeroext %2725, i8 zeroext %2726)
  %conv35.10.25 = zext i8 %call34.10.25 to i32
  %xor36.10.25 = xor i32 %xor.10.25, %conv35.10.25
  %conv37.10.25 = trunc i32 %xor36.10.25 to i8
  store i8 %conv37.10.25, i8* %scevgep41.10.24, align 1
  %scevgep28.10.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2720, i64 0, i64 0, i64 1
  %2727 = bitcast i8* %scevgep28.10.25 to [41 x [41 x i8]]*
  %scevgep41.10.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2721, i64 0, i64 1, i64 0
  %2728 = bitcast i8* %scevgep41.10.25 to [41 x [41 x i8]]*
  %call16.10.26 = call zeroext i8 (...) @rand()
  store i8 %call16.10.26, i8* %scevgep28.10.25, align 1
  %2729 = load i8, i8* %scevgep28.10.25, align 1
  %conv23.10.26 = zext i8 %2729 to i32
  %2730 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.26 = getelementptr i8, i8* %b, i64 37
  %2731 = load i8, i8* %scevgep34.10.26, align 1
  %call28.10.26 = call zeroext i8 @mult(i8 zeroext %2730, i8 zeroext %2731)
  %conv29.10.26 = zext i8 %call28.10.26 to i32
  %xor.10.26 = xor i32 %conv23.10.26, %conv29.10.26
  %scevgep35.10.26 = getelementptr i8, i8* %a, i64 37
  %2732 = load i8, i8* %scevgep35.10.26, align 1
  %2733 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.26 = call zeroext i8 @mult(i8 zeroext %2732, i8 zeroext %2733)
  %conv35.10.26 = zext i8 %call34.10.26 to i32
  %xor36.10.26 = xor i32 %xor.10.26, %conv35.10.26
  %conv37.10.26 = trunc i32 %xor36.10.26 to i8
  store i8 %conv37.10.26, i8* %scevgep41.10.25, align 1
  %scevgep28.10.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2727, i64 0, i64 0, i64 1
  %2734 = bitcast i8* %scevgep28.10.26 to [41 x [41 x i8]]*
  %scevgep41.10.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2728, i64 0, i64 1, i64 0
  %2735 = bitcast i8* %scevgep41.10.26 to [41 x [41 x i8]]*
  %call16.10.27 = call zeroext i8 (...) @rand()
  store i8 %call16.10.27, i8* %scevgep28.10.26, align 1
  %2736 = load i8, i8* %scevgep28.10.26, align 1
  %conv23.10.27 = zext i8 %2736 to i32
  %2737 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.27 = getelementptr i8, i8* %b, i64 38
  %2738 = load i8, i8* %scevgep34.10.27, align 1
  %call28.10.27 = call zeroext i8 @mult(i8 zeroext %2737, i8 zeroext %2738)
  %conv29.10.27 = zext i8 %call28.10.27 to i32
  %xor.10.27 = xor i32 %conv23.10.27, %conv29.10.27
  %scevgep35.10.27 = getelementptr i8, i8* %a, i64 38
  %2739 = load i8, i8* %scevgep35.10.27, align 1
  %2740 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.27 = call zeroext i8 @mult(i8 zeroext %2739, i8 zeroext %2740)
  %conv35.10.27 = zext i8 %call34.10.27 to i32
  %xor36.10.27 = xor i32 %xor.10.27, %conv35.10.27
  %conv37.10.27 = trunc i32 %xor36.10.27 to i8
  store i8 %conv37.10.27, i8* %scevgep41.10.26, align 1
  %scevgep28.10.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2734, i64 0, i64 0, i64 1
  %2741 = bitcast i8* %scevgep28.10.27 to [41 x [41 x i8]]*
  %scevgep41.10.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2735, i64 0, i64 1, i64 0
  %2742 = bitcast i8* %scevgep41.10.27 to [41 x [41 x i8]]*
  %call16.10.28 = call zeroext i8 (...) @rand()
  store i8 %call16.10.28, i8* %scevgep28.10.27, align 1
  %2743 = load i8, i8* %scevgep28.10.27, align 1
  %conv23.10.28 = zext i8 %2743 to i32
  %2744 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.28 = getelementptr i8, i8* %b, i64 39
  %2745 = load i8, i8* %scevgep34.10.28, align 1
  %call28.10.28 = call zeroext i8 @mult(i8 zeroext %2744, i8 zeroext %2745)
  %conv29.10.28 = zext i8 %call28.10.28 to i32
  %xor.10.28 = xor i32 %conv23.10.28, %conv29.10.28
  %scevgep35.10.28 = getelementptr i8, i8* %a, i64 39
  %2746 = load i8, i8* %scevgep35.10.28, align 1
  %2747 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.28 = call zeroext i8 @mult(i8 zeroext %2746, i8 zeroext %2747)
  %conv35.10.28 = zext i8 %call34.10.28 to i32
  %xor36.10.28 = xor i32 %xor.10.28, %conv35.10.28
  %conv37.10.28 = trunc i32 %xor36.10.28 to i8
  store i8 %conv37.10.28, i8* %scevgep41.10.27, align 1
  %scevgep28.10.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2741, i64 0, i64 0, i64 1
  %scevgep41.10.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2742, i64 0, i64 1, i64 0
  %call16.10.29 = call zeroext i8 (...) @rand()
  store i8 %call16.10.29, i8* %scevgep28.10.28, align 1
  %2748 = load i8, i8* %scevgep28.10.28, align 1
  %conv23.10.29 = zext i8 %2748 to i32
  %2749 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.29 = getelementptr i8, i8* %b, i64 40
  %2750 = load i8, i8* %scevgep34.10.29, align 1
  %call28.10.29 = call zeroext i8 @mult(i8 zeroext %2749, i8 zeroext %2750)
  %conv29.10.29 = zext i8 %call28.10.29 to i32
  %xor.10.29 = xor i32 %conv23.10.29, %conv29.10.29
  %scevgep35.10.29 = getelementptr i8, i8* %a, i64 40
  %2751 = load i8, i8* %scevgep35.10.29, align 1
  %2752 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.29 = call zeroext i8 @mult(i8 zeroext %2751, i8 zeroext %2752)
  %conv35.10.29 = zext i8 %call34.10.29 to i32
  %xor36.10.29 = xor i32 %xor.10.29, %conv35.10.29
  %conv37.10.29 = trunc i32 %xor36.10.29 to i8
  store i8 %conv37.10.29, i8* %scevgep41.10.28, align 1
  %scevgep26.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2545, i64 0, i64 1, i64 1
  %2753 = bitcast i8* %scevgep26.10 to [41 x [41 x i8]]*
  %scevgep39.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2546, i64 0, i64 1, i64 1
  %2754 = bitcast i8* %scevgep39.10 to [41 x [41 x i8]]*
  %arrayidx25.11 = getelementptr inbounds i8, i8* %a, i64 11
  %arrayidx33.11 = getelementptr inbounds i8, i8* %b, i64 11
  %call16.11 = call zeroext i8 (...) @rand()
  store i8 %call16.11, i8* %scevgep26.10, align 1
  %2755 = load i8, i8* %scevgep26.10, align 1
  %conv23.11 = zext i8 %2755 to i32
  %2756 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11 = getelementptr i8, i8* %b, i64 12
  %2757 = load i8, i8* %scevgep34.11, align 1
  %call28.11 = call zeroext i8 @mult(i8 zeroext %2756, i8 zeroext %2757)
  %conv29.11 = zext i8 %call28.11 to i32
  %xor.11 = xor i32 %conv23.11, %conv29.11
  %scevgep35.11 = getelementptr i8, i8* %a, i64 12
  %2758 = load i8, i8* %scevgep35.11, align 1
  %2759 = load i8, i8* %arrayidx33.11, align 1
  %call34.11 = call zeroext i8 @mult(i8 zeroext %2758, i8 zeroext %2759)
  %conv35.11 = zext i8 %call34.11 to i32
  %xor36.11 = xor i32 %xor.11, %conv35.11
  %conv37.11 = trunc i32 %xor36.11 to i8
  store i8 %conv37.11, i8* %scevgep39.10, align 1
  %scevgep28.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2753, i64 0, i64 0, i64 1
  %2760 = bitcast i8* %scevgep28.11 to [41 x [41 x i8]]*
  %scevgep41.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2754, i64 0, i64 1, i64 0
  %2761 = bitcast i8* %scevgep41.11 to [41 x [41 x i8]]*
  %call16.11.1 = call zeroext i8 (...) @rand()
  store i8 %call16.11.1, i8* %scevgep28.11, align 1
  %2762 = load i8, i8* %scevgep28.11, align 1
  %conv23.11.1 = zext i8 %2762 to i32
  %2763 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.1 = getelementptr i8, i8* %b, i64 13
  %2764 = load i8, i8* %scevgep34.11.1, align 1
  %call28.11.1 = call zeroext i8 @mult(i8 zeroext %2763, i8 zeroext %2764)
  %conv29.11.1 = zext i8 %call28.11.1 to i32
  %xor.11.1 = xor i32 %conv23.11.1, %conv29.11.1
  %scevgep35.11.1 = getelementptr i8, i8* %a, i64 13
  %2765 = load i8, i8* %scevgep35.11.1, align 1
  %2766 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.1 = call zeroext i8 @mult(i8 zeroext %2765, i8 zeroext %2766)
  %conv35.11.1 = zext i8 %call34.11.1 to i32
  %xor36.11.1 = xor i32 %xor.11.1, %conv35.11.1
  %conv37.11.1 = trunc i32 %xor36.11.1 to i8
  store i8 %conv37.11.1, i8* %scevgep41.11, align 1
  %scevgep28.11.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2760, i64 0, i64 0, i64 1
  %2767 = bitcast i8* %scevgep28.11.1 to [41 x [41 x i8]]*
  %scevgep41.11.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2761, i64 0, i64 1, i64 0
  %2768 = bitcast i8* %scevgep41.11.1 to [41 x [41 x i8]]*
  %call16.11.2 = call zeroext i8 (...) @rand()
  store i8 %call16.11.2, i8* %scevgep28.11.1, align 1
  %2769 = load i8, i8* %scevgep28.11.1, align 1
  %conv23.11.2 = zext i8 %2769 to i32
  %2770 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.2 = getelementptr i8, i8* %b, i64 14
  %2771 = load i8, i8* %scevgep34.11.2, align 1
  %call28.11.2 = call zeroext i8 @mult(i8 zeroext %2770, i8 zeroext %2771)
  %conv29.11.2 = zext i8 %call28.11.2 to i32
  %xor.11.2 = xor i32 %conv23.11.2, %conv29.11.2
  %scevgep35.11.2 = getelementptr i8, i8* %a, i64 14
  %2772 = load i8, i8* %scevgep35.11.2, align 1
  %2773 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.2 = call zeroext i8 @mult(i8 zeroext %2772, i8 zeroext %2773)
  %conv35.11.2 = zext i8 %call34.11.2 to i32
  %xor36.11.2 = xor i32 %xor.11.2, %conv35.11.2
  %conv37.11.2 = trunc i32 %xor36.11.2 to i8
  store i8 %conv37.11.2, i8* %scevgep41.11.1, align 1
  %scevgep28.11.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2767, i64 0, i64 0, i64 1
  %2774 = bitcast i8* %scevgep28.11.2 to [41 x [41 x i8]]*
  %scevgep41.11.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2768, i64 0, i64 1, i64 0
  %2775 = bitcast i8* %scevgep41.11.2 to [41 x [41 x i8]]*
  %call16.11.3 = call zeroext i8 (...) @rand()
  store i8 %call16.11.3, i8* %scevgep28.11.2, align 1
  %2776 = load i8, i8* %scevgep28.11.2, align 1
  %conv23.11.3 = zext i8 %2776 to i32
  %2777 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.3 = getelementptr i8, i8* %b, i64 15
  %2778 = load i8, i8* %scevgep34.11.3, align 1
  %call28.11.3 = call zeroext i8 @mult(i8 zeroext %2777, i8 zeroext %2778)
  %conv29.11.3 = zext i8 %call28.11.3 to i32
  %xor.11.3 = xor i32 %conv23.11.3, %conv29.11.3
  %scevgep35.11.3 = getelementptr i8, i8* %a, i64 15
  %2779 = load i8, i8* %scevgep35.11.3, align 1
  %2780 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.3 = call zeroext i8 @mult(i8 zeroext %2779, i8 zeroext %2780)
  %conv35.11.3 = zext i8 %call34.11.3 to i32
  %xor36.11.3 = xor i32 %xor.11.3, %conv35.11.3
  %conv37.11.3 = trunc i32 %xor36.11.3 to i8
  store i8 %conv37.11.3, i8* %scevgep41.11.2, align 1
  %scevgep28.11.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2774, i64 0, i64 0, i64 1
  %2781 = bitcast i8* %scevgep28.11.3 to [41 x [41 x i8]]*
  %scevgep41.11.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2775, i64 0, i64 1, i64 0
  %2782 = bitcast i8* %scevgep41.11.3 to [41 x [41 x i8]]*
  %call16.11.4 = call zeroext i8 (...) @rand()
  store i8 %call16.11.4, i8* %scevgep28.11.3, align 1
  %2783 = load i8, i8* %scevgep28.11.3, align 1
  %conv23.11.4 = zext i8 %2783 to i32
  %2784 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.4 = getelementptr i8, i8* %b, i64 16
  %2785 = load i8, i8* %scevgep34.11.4, align 1
  %call28.11.4 = call zeroext i8 @mult(i8 zeroext %2784, i8 zeroext %2785)
  %conv29.11.4 = zext i8 %call28.11.4 to i32
  %xor.11.4 = xor i32 %conv23.11.4, %conv29.11.4
  %scevgep35.11.4 = getelementptr i8, i8* %a, i64 16
  %2786 = load i8, i8* %scevgep35.11.4, align 1
  %2787 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.4 = call zeroext i8 @mult(i8 zeroext %2786, i8 zeroext %2787)
  %conv35.11.4 = zext i8 %call34.11.4 to i32
  %xor36.11.4 = xor i32 %xor.11.4, %conv35.11.4
  %conv37.11.4 = trunc i32 %xor36.11.4 to i8
  store i8 %conv37.11.4, i8* %scevgep41.11.3, align 1
  %scevgep28.11.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2781, i64 0, i64 0, i64 1
  %2788 = bitcast i8* %scevgep28.11.4 to [41 x [41 x i8]]*
  %scevgep41.11.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2782, i64 0, i64 1, i64 0
  %2789 = bitcast i8* %scevgep41.11.4 to [41 x [41 x i8]]*
  %call16.11.5 = call zeroext i8 (...) @rand()
  store i8 %call16.11.5, i8* %scevgep28.11.4, align 1
  %2790 = load i8, i8* %scevgep28.11.4, align 1
  %conv23.11.5 = zext i8 %2790 to i32
  %2791 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.5 = getelementptr i8, i8* %b, i64 17
  %2792 = load i8, i8* %scevgep34.11.5, align 1
  %call28.11.5 = call zeroext i8 @mult(i8 zeroext %2791, i8 zeroext %2792)
  %conv29.11.5 = zext i8 %call28.11.5 to i32
  %xor.11.5 = xor i32 %conv23.11.5, %conv29.11.5
  %scevgep35.11.5 = getelementptr i8, i8* %a, i64 17
  %2793 = load i8, i8* %scevgep35.11.5, align 1
  %2794 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.5 = call zeroext i8 @mult(i8 zeroext %2793, i8 zeroext %2794)
  %conv35.11.5 = zext i8 %call34.11.5 to i32
  %xor36.11.5 = xor i32 %xor.11.5, %conv35.11.5
  %conv37.11.5 = trunc i32 %xor36.11.5 to i8
  store i8 %conv37.11.5, i8* %scevgep41.11.4, align 1
  %scevgep28.11.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2788, i64 0, i64 0, i64 1
  %2795 = bitcast i8* %scevgep28.11.5 to [41 x [41 x i8]]*
  %scevgep41.11.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2789, i64 0, i64 1, i64 0
  %2796 = bitcast i8* %scevgep41.11.5 to [41 x [41 x i8]]*
  %call16.11.6 = call zeroext i8 (...) @rand()
  store i8 %call16.11.6, i8* %scevgep28.11.5, align 1
  %2797 = load i8, i8* %scevgep28.11.5, align 1
  %conv23.11.6 = zext i8 %2797 to i32
  %2798 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.6 = getelementptr i8, i8* %b, i64 18
  %2799 = load i8, i8* %scevgep34.11.6, align 1
  %call28.11.6 = call zeroext i8 @mult(i8 zeroext %2798, i8 zeroext %2799)
  %conv29.11.6 = zext i8 %call28.11.6 to i32
  %xor.11.6 = xor i32 %conv23.11.6, %conv29.11.6
  %scevgep35.11.6 = getelementptr i8, i8* %a, i64 18
  %2800 = load i8, i8* %scevgep35.11.6, align 1
  %2801 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.6 = call zeroext i8 @mult(i8 zeroext %2800, i8 zeroext %2801)
  %conv35.11.6 = zext i8 %call34.11.6 to i32
  %xor36.11.6 = xor i32 %xor.11.6, %conv35.11.6
  %conv37.11.6 = trunc i32 %xor36.11.6 to i8
  store i8 %conv37.11.6, i8* %scevgep41.11.5, align 1
  %scevgep28.11.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2795, i64 0, i64 0, i64 1
  %2802 = bitcast i8* %scevgep28.11.6 to [41 x [41 x i8]]*
  %scevgep41.11.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2796, i64 0, i64 1, i64 0
  %2803 = bitcast i8* %scevgep41.11.6 to [41 x [41 x i8]]*
  %call16.11.7 = call zeroext i8 (...) @rand()
  store i8 %call16.11.7, i8* %scevgep28.11.6, align 1
  %2804 = load i8, i8* %scevgep28.11.6, align 1
  %conv23.11.7 = zext i8 %2804 to i32
  %2805 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.7 = getelementptr i8, i8* %b, i64 19
  %2806 = load i8, i8* %scevgep34.11.7, align 1
  %call28.11.7 = call zeroext i8 @mult(i8 zeroext %2805, i8 zeroext %2806)
  %conv29.11.7 = zext i8 %call28.11.7 to i32
  %xor.11.7 = xor i32 %conv23.11.7, %conv29.11.7
  %scevgep35.11.7 = getelementptr i8, i8* %a, i64 19
  %2807 = load i8, i8* %scevgep35.11.7, align 1
  %2808 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.7 = call zeroext i8 @mult(i8 zeroext %2807, i8 zeroext %2808)
  %conv35.11.7 = zext i8 %call34.11.7 to i32
  %xor36.11.7 = xor i32 %xor.11.7, %conv35.11.7
  %conv37.11.7 = trunc i32 %xor36.11.7 to i8
  store i8 %conv37.11.7, i8* %scevgep41.11.6, align 1
  %scevgep28.11.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2802, i64 0, i64 0, i64 1
  %2809 = bitcast i8* %scevgep28.11.7 to [41 x [41 x i8]]*
  %scevgep41.11.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2803, i64 0, i64 1, i64 0
  %2810 = bitcast i8* %scevgep41.11.7 to [41 x [41 x i8]]*
  %call16.11.8 = call zeroext i8 (...) @rand()
  store i8 %call16.11.8, i8* %scevgep28.11.7, align 1
  %2811 = load i8, i8* %scevgep28.11.7, align 1
  %conv23.11.8 = zext i8 %2811 to i32
  %2812 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.8 = getelementptr i8, i8* %b, i64 20
  %2813 = load i8, i8* %scevgep34.11.8, align 1
  %call28.11.8 = call zeroext i8 @mult(i8 zeroext %2812, i8 zeroext %2813)
  %conv29.11.8 = zext i8 %call28.11.8 to i32
  %xor.11.8 = xor i32 %conv23.11.8, %conv29.11.8
  %scevgep35.11.8 = getelementptr i8, i8* %a, i64 20
  %2814 = load i8, i8* %scevgep35.11.8, align 1
  %2815 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.8 = call zeroext i8 @mult(i8 zeroext %2814, i8 zeroext %2815)
  %conv35.11.8 = zext i8 %call34.11.8 to i32
  %xor36.11.8 = xor i32 %xor.11.8, %conv35.11.8
  %conv37.11.8 = trunc i32 %xor36.11.8 to i8
  store i8 %conv37.11.8, i8* %scevgep41.11.7, align 1
  %scevgep28.11.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2809, i64 0, i64 0, i64 1
  %2816 = bitcast i8* %scevgep28.11.8 to [41 x [41 x i8]]*
  %scevgep41.11.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2810, i64 0, i64 1, i64 0
  %2817 = bitcast i8* %scevgep41.11.8 to [41 x [41 x i8]]*
  %call16.11.9 = call zeroext i8 (...) @rand()
  store i8 %call16.11.9, i8* %scevgep28.11.8, align 1
  %2818 = load i8, i8* %scevgep28.11.8, align 1
  %conv23.11.9 = zext i8 %2818 to i32
  %2819 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.9 = getelementptr i8, i8* %b, i64 21
  %2820 = load i8, i8* %scevgep34.11.9, align 1
  %call28.11.9 = call zeroext i8 @mult(i8 zeroext %2819, i8 zeroext %2820)
  %conv29.11.9 = zext i8 %call28.11.9 to i32
  %xor.11.9 = xor i32 %conv23.11.9, %conv29.11.9
  %scevgep35.11.9 = getelementptr i8, i8* %a, i64 21
  %2821 = load i8, i8* %scevgep35.11.9, align 1
  %2822 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.9 = call zeroext i8 @mult(i8 zeroext %2821, i8 zeroext %2822)
  %conv35.11.9 = zext i8 %call34.11.9 to i32
  %xor36.11.9 = xor i32 %xor.11.9, %conv35.11.9
  %conv37.11.9 = trunc i32 %xor36.11.9 to i8
  store i8 %conv37.11.9, i8* %scevgep41.11.8, align 1
  %scevgep28.11.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2816, i64 0, i64 0, i64 1
  %2823 = bitcast i8* %scevgep28.11.9 to [41 x [41 x i8]]*
  %scevgep41.11.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2817, i64 0, i64 1, i64 0
  %2824 = bitcast i8* %scevgep41.11.9 to [41 x [41 x i8]]*
  %call16.11.10 = call zeroext i8 (...) @rand()
  store i8 %call16.11.10, i8* %scevgep28.11.9, align 1
  %2825 = load i8, i8* %scevgep28.11.9, align 1
  %conv23.11.10 = zext i8 %2825 to i32
  %2826 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.10 = getelementptr i8, i8* %b, i64 22
  %2827 = load i8, i8* %scevgep34.11.10, align 1
  %call28.11.10 = call zeroext i8 @mult(i8 zeroext %2826, i8 zeroext %2827)
  %conv29.11.10 = zext i8 %call28.11.10 to i32
  %xor.11.10 = xor i32 %conv23.11.10, %conv29.11.10
  %scevgep35.11.10 = getelementptr i8, i8* %a, i64 22
  %2828 = load i8, i8* %scevgep35.11.10, align 1
  %2829 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.10 = call zeroext i8 @mult(i8 zeroext %2828, i8 zeroext %2829)
  %conv35.11.10 = zext i8 %call34.11.10 to i32
  %xor36.11.10 = xor i32 %xor.11.10, %conv35.11.10
  %conv37.11.10 = trunc i32 %xor36.11.10 to i8
  store i8 %conv37.11.10, i8* %scevgep41.11.9, align 1
  %scevgep28.11.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2823, i64 0, i64 0, i64 1
  %2830 = bitcast i8* %scevgep28.11.10 to [41 x [41 x i8]]*
  %scevgep41.11.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2824, i64 0, i64 1, i64 0
  %2831 = bitcast i8* %scevgep41.11.10 to [41 x [41 x i8]]*
  %call16.11.11 = call zeroext i8 (...) @rand()
  store i8 %call16.11.11, i8* %scevgep28.11.10, align 1
  %2832 = load i8, i8* %scevgep28.11.10, align 1
  %conv23.11.11 = zext i8 %2832 to i32
  %2833 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.11 = getelementptr i8, i8* %b, i64 23
  %2834 = load i8, i8* %scevgep34.11.11, align 1
  %call28.11.11 = call zeroext i8 @mult(i8 zeroext %2833, i8 zeroext %2834)
  %conv29.11.11 = zext i8 %call28.11.11 to i32
  %xor.11.11 = xor i32 %conv23.11.11, %conv29.11.11
  %scevgep35.11.11 = getelementptr i8, i8* %a, i64 23
  %2835 = load i8, i8* %scevgep35.11.11, align 1
  %2836 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.11 = call zeroext i8 @mult(i8 zeroext %2835, i8 zeroext %2836)
  %conv35.11.11 = zext i8 %call34.11.11 to i32
  %xor36.11.11 = xor i32 %xor.11.11, %conv35.11.11
  %conv37.11.11 = trunc i32 %xor36.11.11 to i8
  store i8 %conv37.11.11, i8* %scevgep41.11.10, align 1
  %scevgep28.11.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2830, i64 0, i64 0, i64 1
  %2837 = bitcast i8* %scevgep28.11.11 to [41 x [41 x i8]]*
  %scevgep41.11.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2831, i64 0, i64 1, i64 0
  %2838 = bitcast i8* %scevgep41.11.11 to [41 x [41 x i8]]*
  %call16.11.12 = call zeroext i8 (...) @rand()
  store i8 %call16.11.12, i8* %scevgep28.11.11, align 1
  %2839 = load i8, i8* %scevgep28.11.11, align 1
  %conv23.11.12 = zext i8 %2839 to i32
  %2840 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.12 = getelementptr i8, i8* %b, i64 24
  %2841 = load i8, i8* %scevgep34.11.12, align 1
  %call28.11.12 = call zeroext i8 @mult(i8 zeroext %2840, i8 zeroext %2841)
  %conv29.11.12 = zext i8 %call28.11.12 to i32
  %xor.11.12 = xor i32 %conv23.11.12, %conv29.11.12
  %scevgep35.11.12 = getelementptr i8, i8* %a, i64 24
  %2842 = load i8, i8* %scevgep35.11.12, align 1
  %2843 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.12 = call zeroext i8 @mult(i8 zeroext %2842, i8 zeroext %2843)
  %conv35.11.12 = zext i8 %call34.11.12 to i32
  %xor36.11.12 = xor i32 %xor.11.12, %conv35.11.12
  %conv37.11.12 = trunc i32 %xor36.11.12 to i8
  store i8 %conv37.11.12, i8* %scevgep41.11.11, align 1
  %scevgep28.11.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2837, i64 0, i64 0, i64 1
  %2844 = bitcast i8* %scevgep28.11.12 to [41 x [41 x i8]]*
  %scevgep41.11.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2838, i64 0, i64 1, i64 0
  %2845 = bitcast i8* %scevgep41.11.12 to [41 x [41 x i8]]*
  %call16.11.13 = call zeroext i8 (...) @rand()
  store i8 %call16.11.13, i8* %scevgep28.11.12, align 1
  %2846 = load i8, i8* %scevgep28.11.12, align 1
  %conv23.11.13 = zext i8 %2846 to i32
  %2847 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.13 = getelementptr i8, i8* %b, i64 25
  %2848 = load i8, i8* %scevgep34.11.13, align 1
  %call28.11.13 = call zeroext i8 @mult(i8 zeroext %2847, i8 zeroext %2848)
  %conv29.11.13 = zext i8 %call28.11.13 to i32
  %xor.11.13 = xor i32 %conv23.11.13, %conv29.11.13
  %scevgep35.11.13 = getelementptr i8, i8* %a, i64 25
  %2849 = load i8, i8* %scevgep35.11.13, align 1
  %2850 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.13 = call zeroext i8 @mult(i8 zeroext %2849, i8 zeroext %2850)
  %conv35.11.13 = zext i8 %call34.11.13 to i32
  %xor36.11.13 = xor i32 %xor.11.13, %conv35.11.13
  %conv37.11.13 = trunc i32 %xor36.11.13 to i8
  store i8 %conv37.11.13, i8* %scevgep41.11.12, align 1
  %scevgep28.11.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2844, i64 0, i64 0, i64 1
  %2851 = bitcast i8* %scevgep28.11.13 to [41 x [41 x i8]]*
  %scevgep41.11.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2845, i64 0, i64 1, i64 0
  %2852 = bitcast i8* %scevgep41.11.13 to [41 x [41 x i8]]*
  %call16.11.14 = call zeroext i8 (...) @rand()
  store i8 %call16.11.14, i8* %scevgep28.11.13, align 1
  %2853 = load i8, i8* %scevgep28.11.13, align 1
  %conv23.11.14 = zext i8 %2853 to i32
  %2854 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.14 = getelementptr i8, i8* %b, i64 26
  %2855 = load i8, i8* %scevgep34.11.14, align 1
  %call28.11.14 = call zeroext i8 @mult(i8 zeroext %2854, i8 zeroext %2855)
  %conv29.11.14 = zext i8 %call28.11.14 to i32
  %xor.11.14 = xor i32 %conv23.11.14, %conv29.11.14
  %scevgep35.11.14 = getelementptr i8, i8* %a, i64 26
  %2856 = load i8, i8* %scevgep35.11.14, align 1
  %2857 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.14 = call zeroext i8 @mult(i8 zeroext %2856, i8 zeroext %2857)
  %conv35.11.14 = zext i8 %call34.11.14 to i32
  %xor36.11.14 = xor i32 %xor.11.14, %conv35.11.14
  %conv37.11.14 = trunc i32 %xor36.11.14 to i8
  store i8 %conv37.11.14, i8* %scevgep41.11.13, align 1
  %scevgep28.11.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2851, i64 0, i64 0, i64 1
  %2858 = bitcast i8* %scevgep28.11.14 to [41 x [41 x i8]]*
  %scevgep41.11.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2852, i64 0, i64 1, i64 0
  %2859 = bitcast i8* %scevgep41.11.14 to [41 x [41 x i8]]*
  %call16.11.15 = call zeroext i8 (...) @rand()
  store i8 %call16.11.15, i8* %scevgep28.11.14, align 1
  %2860 = load i8, i8* %scevgep28.11.14, align 1
  %conv23.11.15 = zext i8 %2860 to i32
  %2861 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.15 = getelementptr i8, i8* %b, i64 27
  %2862 = load i8, i8* %scevgep34.11.15, align 1
  %call28.11.15 = call zeroext i8 @mult(i8 zeroext %2861, i8 zeroext %2862)
  %conv29.11.15 = zext i8 %call28.11.15 to i32
  %xor.11.15 = xor i32 %conv23.11.15, %conv29.11.15
  %scevgep35.11.15 = getelementptr i8, i8* %a, i64 27
  %2863 = load i8, i8* %scevgep35.11.15, align 1
  %2864 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.15 = call zeroext i8 @mult(i8 zeroext %2863, i8 zeroext %2864)
  %conv35.11.15 = zext i8 %call34.11.15 to i32
  %xor36.11.15 = xor i32 %xor.11.15, %conv35.11.15
  %conv37.11.15 = trunc i32 %xor36.11.15 to i8
  store i8 %conv37.11.15, i8* %scevgep41.11.14, align 1
  %scevgep28.11.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2858, i64 0, i64 0, i64 1
  %2865 = bitcast i8* %scevgep28.11.15 to [41 x [41 x i8]]*
  %scevgep41.11.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2859, i64 0, i64 1, i64 0
  %2866 = bitcast i8* %scevgep41.11.15 to [41 x [41 x i8]]*
  %call16.11.16 = call zeroext i8 (...) @rand()
  store i8 %call16.11.16, i8* %scevgep28.11.15, align 1
  %2867 = load i8, i8* %scevgep28.11.15, align 1
  %conv23.11.16 = zext i8 %2867 to i32
  %2868 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.16 = getelementptr i8, i8* %b, i64 28
  %2869 = load i8, i8* %scevgep34.11.16, align 1
  %call28.11.16 = call zeroext i8 @mult(i8 zeroext %2868, i8 zeroext %2869)
  %conv29.11.16 = zext i8 %call28.11.16 to i32
  %xor.11.16 = xor i32 %conv23.11.16, %conv29.11.16
  %scevgep35.11.16 = getelementptr i8, i8* %a, i64 28
  %2870 = load i8, i8* %scevgep35.11.16, align 1
  %2871 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.16 = call zeroext i8 @mult(i8 zeroext %2870, i8 zeroext %2871)
  %conv35.11.16 = zext i8 %call34.11.16 to i32
  %xor36.11.16 = xor i32 %xor.11.16, %conv35.11.16
  %conv37.11.16 = trunc i32 %xor36.11.16 to i8
  store i8 %conv37.11.16, i8* %scevgep41.11.15, align 1
  %scevgep28.11.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2865, i64 0, i64 0, i64 1
  %2872 = bitcast i8* %scevgep28.11.16 to [41 x [41 x i8]]*
  %scevgep41.11.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2866, i64 0, i64 1, i64 0
  %2873 = bitcast i8* %scevgep41.11.16 to [41 x [41 x i8]]*
  %call16.11.17 = call zeroext i8 (...) @rand()
  store i8 %call16.11.17, i8* %scevgep28.11.16, align 1
  %2874 = load i8, i8* %scevgep28.11.16, align 1
  %conv23.11.17 = zext i8 %2874 to i32
  %2875 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.17 = getelementptr i8, i8* %b, i64 29
  %2876 = load i8, i8* %scevgep34.11.17, align 1
  %call28.11.17 = call zeroext i8 @mult(i8 zeroext %2875, i8 zeroext %2876)
  %conv29.11.17 = zext i8 %call28.11.17 to i32
  %xor.11.17 = xor i32 %conv23.11.17, %conv29.11.17
  %scevgep35.11.17 = getelementptr i8, i8* %a, i64 29
  %2877 = load i8, i8* %scevgep35.11.17, align 1
  %2878 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.17 = call zeroext i8 @mult(i8 zeroext %2877, i8 zeroext %2878)
  %conv35.11.17 = zext i8 %call34.11.17 to i32
  %xor36.11.17 = xor i32 %xor.11.17, %conv35.11.17
  %conv37.11.17 = trunc i32 %xor36.11.17 to i8
  store i8 %conv37.11.17, i8* %scevgep41.11.16, align 1
  %scevgep28.11.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2872, i64 0, i64 0, i64 1
  %2879 = bitcast i8* %scevgep28.11.17 to [41 x [41 x i8]]*
  %scevgep41.11.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2873, i64 0, i64 1, i64 0
  %2880 = bitcast i8* %scevgep41.11.17 to [41 x [41 x i8]]*
  %call16.11.18 = call zeroext i8 (...) @rand()
  store i8 %call16.11.18, i8* %scevgep28.11.17, align 1
  %2881 = load i8, i8* %scevgep28.11.17, align 1
  %conv23.11.18 = zext i8 %2881 to i32
  %2882 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.18 = getelementptr i8, i8* %b, i64 30
  %2883 = load i8, i8* %scevgep34.11.18, align 1
  %call28.11.18 = call zeroext i8 @mult(i8 zeroext %2882, i8 zeroext %2883)
  %conv29.11.18 = zext i8 %call28.11.18 to i32
  %xor.11.18 = xor i32 %conv23.11.18, %conv29.11.18
  %scevgep35.11.18 = getelementptr i8, i8* %a, i64 30
  %2884 = load i8, i8* %scevgep35.11.18, align 1
  %2885 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.18 = call zeroext i8 @mult(i8 zeroext %2884, i8 zeroext %2885)
  %conv35.11.18 = zext i8 %call34.11.18 to i32
  %xor36.11.18 = xor i32 %xor.11.18, %conv35.11.18
  %conv37.11.18 = trunc i32 %xor36.11.18 to i8
  store i8 %conv37.11.18, i8* %scevgep41.11.17, align 1
  %scevgep28.11.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2879, i64 0, i64 0, i64 1
  %2886 = bitcast i8* %scevgep28.11.18 to [41 x [41 x i8]]*
  %scevgep41.11.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2880, i64 0, i64 1, i64 0
  %2887 = bitcast i8* %scevgep41.11.18 to [41 x [41 x i8]]*
  %call16.11.19 = call zeroext i8 (...) @rand()
  store i8 %call16.11.19, i8* %scevgep28.11.18, align 1
  %2888 = load i8, i8* %scevgep28.11.18, align 1
  %conv23.11.19 = zext i8 %2888 to i32
  %2889 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.19 = getelementptr i8, i8* %b, i64 31
  %2890 = load i8, i8* %scevgep34.11.19, align 1
  %call28.11.19 = call zeroext i8 @mult(i8 zeroext %2889, i8 zeroext %2890)
  %conv29.11.19 = zext i8 %call28.11.19 to i32
  %xor.11.19 = xor i32 %conv23.11.19, %conv29.11.19
  %scevgep35.11.19 = getelementptr i8, i8* %a, i64 31
  %2891 = load i8, i8* %scevgep35.11.19, align 1
  %2892 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.19 = call zeroext i8 @mult(i8 zeroext %2891, i8 zeroext %2892)
  %conv35.11.19 = zext i8 %call34.11.19 to i32
  %xor36.11.19 = xor i32 %xor.11.19, %conv35.11.19
  %conv37.11.19 = trunc i32 %xor36.11.19 to i8
  store i8 %conv37.11.19, i8* %scevgep41.11.18, align 1
  %scevgep28.11.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2886, i64 0, i64 0, i64 1
  %2893 = bitcast i8* %scevgep28.11.19 to [41 x [41 x i8]]*
  %scevgep41.11.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2887, i64 0, i64 1, i64 0
  %2894 = bitcast i8* %scevgep41.11.19 to [41 x [41 x i8]]*
  %call16.11.20 = call zeroext i8 (...) @rand()
  store i8 %call16.11.20, i8* %scevgep28.11.19, align 1
  %2895 = load i8, i8* %scevgep28.11.19, align 1
  %conv23.11.20 = zext i8 %2895 to i32
  %2896 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.20 = getelementptr i8, i8* %b, i64 32
  %2897 = load i8, i8* %scevgep34.11.20, align 1
  %call28.11.20 = call zeroext i8 @mult(i8 zeroext %2896, i8 zeroext %2897)
  %conv29.11.20 = zext i8 %call28.11.20 to i32
  %xor.11.20 = xor i32 %conv23.11.20, %conv29.11.20
  %scevgep35.11.20 = getelementptr i8, i8* %a, i64 32
  %2898 = load i8, i8* %scevgep35.11.20, align 1
  %2899 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.20 = call zeroext i8 @mult(i8 zeroext %2898, i8 zeroext %2899)
  %conv35.11.20 = zext i8 %call34.11.20 to i32
  %xor36.11.20 = xor i32 %xor.11.20, %conv35.11.20
  %conv37.11.20 = trunc i32 %xor36.11.20 to i8
  store i8 %conv37.11.20, i8* %scevgep41.11.19, align 1
  %scevgep28.11.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2893, i64 0, i64 0, i64 1
  %2900 = bitcast i8* %scevgep28.11.20 to [41 x [41 x i8]]*
  %scevgep41.11.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2894, i64 0, i64 1, i64 0
  %2901 = bitcast i8* %scevgep41.11.20 to [41 x [41 x i8]]*
  %call16.11.21 = call zeroext i8 (...) @rand()
  store i8 %call16.11.21, i8* %scevgep28.11.20, align 1
  %2902 = load i8, i8* %scevgep28.11.20, align 1
  %conv23.11.21 = zext i8 %2902 to i32
  %2903 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.21 = getelementptr i8, i8* %b, i64 33
  %2904 = load i8, i8* %scevgep34.11.21, align 1
  %call28.11.21 = call zeroext i8 @mult(i8 zeroext %2903, i8 zeroext %2904)
  %conv29.11.21 = zext i8 %call28.11.21 to i32
  %xor.11.21 = xor i32 %conv23.11.21, %conv29.11.21
  %scevgep35.11.21 = getelementptr i8, i8* %a, i64 33
  %2905 = load i8, i8* %scevgep35.11.21, align 1
  %2906 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.21 = call zeroext i8 @mult(i8 zeroext %2905, i8 zeroext %2906)
  %conv35.11.21 = zext i8 %call34.11.21 to i32
  %xor36.11.21 = xor i32 %xor.11.21, %conv35.11.21
  %conv37.11.21 = trunc i32 %xor36.11.21 to i8
  store i8 %conv37.11.21, i8* %scevgep41.11.20, align 1
  %scevgep28.11.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2900, i64 0, i64 0, i64 1
  %2907 = bitcast i8* %scevgep28.11.21 to [41 x [41 x i8]]*
  %scevgep41.11.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2901, i64 0, i64 1, i64 0
  %2908 = bitcast i8* %scevgep41.11.21 to [41 x [41 x i8]]*
  %call16.11.22 = call zeroext i8 (...) @rand()
  store i8 %call16.11.22, i8* %scevgep28.11.21, align 1
  %2909 = load i8, i8* %scevgep28.11.21, align 1
  %conv23.11.22 = zext i8 %2909 to i32
  %2910 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.22 = getelementptr i8, i8* %b, i64 34
  %2911 = load i8, i8* %scevgep34.11.22, align 1
  %call28.11.22 = call zeroext i8 @mult(i8 zeroext %2910, i8 zeroext %2911)
  %conv29.11.22 = zext i8 %call28.11.22 to i32
  %xor.11.22 = xor i32 %conv23.11.22, %conv29.11.22
  %scevgep35.11.22 = getelementptr i8, i8* %a, i64 34
  %2912 = load i8, i8* %scevgep35.11.22, align 1
  %2913 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.22 = call zeroext i8 @mult(i8 zeroext %2912, i8 zeroext %2913)
  %conv35.11.22 = zext i8 %call34.11.22 to i32
  %xor36.11.22 = xor i32 %xor.11.22, %conv35.11.22
  %conv37.11.22 = trunc i32 %xor36.11.22 to i8
  store i8 %conv37.11.22, i8* %scevgep41.11.21, align 1
  %scevgep28.11.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2907, i64 0, i64 0, i64 1
  %2914 = bitcast i8* %scevgep28.11.22 to [41 x [41 x i8]]*
  %scevgep41.11.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2908, i64 0, i64 1, i64 0
  %2915 = bitcast i8* %scevgep41.11.22 to [41 x [41 x i8]]*
  %call16.11.23 = call zeroext i8 (...) @rand()
  store i8 %call16.11.23, i8* %scevgep28.11.22, align 1
  %2916 = load i8, i8* %scevgep28.11.22, align 1
  %conv23.11.23 = zext i8 %2916 to i32
  %2917 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.23 = getelementptr i8, i8* %b, i64 35
  %2918 = load i8, i8* %scevgep34.11.23, align 1
  %call28.11.23 = call zeroext i8 @mult(i8 zeroext %2917, i8 zeroext %2918)
  %conv29.11.23 = zext i8 %call28.11.23 to i32
  %xor.11.23 = xor i32 %conv23.11.23, %conv29.11.23
  %scevgep35.11.23 = getelementptr i8, i8* %a, i64 35
  %2919 = load i8, i8* %scevgep35.11.23, align 1
  %2920 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.23 = call zeroext i8 @mult(i8 zeroext %2919, i8 zeroext %2920)
  %conv35.11.23 = zext i8 %call34.11.23 to i32
  %xor36.11.23 = xor i32 %xor.11.23, %conv35.11.23
  %conv37.11.23 = trunc i32 %xor36.11.23 to i8
  store i8 %conv37.11.23, i8* %scevgep41.11.22, align 1
  %scevgep28.11.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2914, i64 0, i64 0, i64 1
  %2921 = bitcast i8* %scevgep28.11.23 to [41 x [41 x i8]]*
  %scevgep41.11.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2915, i64 0, i64 1, i64 0
  %2922 = bitcast i8* %scevgep41.11.23 to [41 x [41 x i8]]*
  %call16.11.24 = call zeroext i8 (...) @rand()
  store i8 %call16.11.24, i8* %scevgep28.11.23, align 1
  %2923 = load i8, i8* %scevgep28.11.23, align 1
  %conv23.11.24 = zext i8 %2923 to i32
  %2924 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.24 = getelementptr i8, i8* %b, i64 36
  %2925 = load i8, i8* %scevgep34.11.24, align 1
  %call28.11.24 = call zeroext i8 @mult(i8 zeroext %2924, i8 zeroext %2925)
  %conv29.11.24 = zext i8 %call28.11.24 to i32
  %xor.11.24 = xor i32 %conv23.11.24, %conv29.11.24
  %scevgep35.11.24 = getelementptr i8, i8* %a, i64 36
  %2926 = load i8, i8* %scevgep35.11.24, align 1
  %2927 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.24 = call zeroext i8 @mult(i8 zeroext %2926, i8 zeroext %2927)
  %conv35.11.24 = zext i8 %call34.11.24 to i32
  %xor36.11.24 = xor i32 %xor.11.24, %conv35.11.24
  %conv37.11.24 = trunc i32 %xor36.11.24 to i8
  store i8 %conv37.11.24, i8* %scevgep41.11.23, align 1
  %scevgep28.11.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2921, i64 0, i64 0, i64 1
  %2928 = bitcast i8* %scevgep28.11.24 to [41 x [41 x i8]]*
  %scevgep41.11.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2922, i64 0, i64 1, i64 0
  %2929 = bitcast i8* %scevgep41.11.24 to [41 x [41 x i8]]*
  %call16.11.25 = call zeroext i8 (...) @rand()
  store i8 %call16.11.25, i8* %scevgep28.11.24, align 1
  %2930 = load i8, i8* %scevgep28.11.24, align 1
  %conv23.11.25 = zext i8 %2930 to i32
  %2931 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.25 = getelementptr i8, i8* %b, i64 37
  %2932 = load i8, i8* %scevgep34.11.25, align 1
  %call28.11.25 = call zeroext i8 @mult(i8 zeroext %2931, i8 zeroext %2932)
  %conv29.11.25 = zext i8 %call28.11.25 to i32
  %xor.11.25 = xor i32 %conv23.11.25, %conv29.11.25
  %scevgep35.11.25 = getelementptr i8, i8* %a, i64 37
  %2933 = load i8, i8* %scevgep35.11.25, align 1
  %2934 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.25 = call zeroext i8 @mult(i8 zeroext %2933, i8 zeroext %2934)
  %conv35.11.25 = zext i8 %call34.11.25 to i32
  %xor36.11.25 = xor i32 %xor.11.25, %conv35.11.25
  %conv37.11.25 = trunc i32 %xor36.11.25 to i8
  store i8 %conv37.11.25, i8* %scevgep41.11.24, align 1
  %scevgep28.11.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2928, i64 0, i64 0, i64 1
  %2935 = bitcast i8* %scevgep28.11.25 to [41 x [41 x i8]]*
  %scevgep41.11.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2929, i64 0, i64 1, i64 0
  %2936 = bitcast i8* %scevgep41.11.25 to [41 x [41 x i8]]*
  %call16.11.26 = call zeroext i8 (...) @rand()
  store i8 %call16.11.26, i8* %scevgep28.11.25, align 1
  %2937 = load i8, i8* %scevgep28.11.25, align 1
  %conv23.11.26 = zext i8 %2937 to i32
  %2938 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.26 = getelementptr i8, i8* %b, i64 38
  %2939 = load i8, i8* %scevgep34.11.26, align 1
  %call28.11.26 = call zeroext i8 @mult(i8 zeroext %2938, i8 zeroext %2939)
  %conv29.11.26 = zext i8 %call28.11.26 to i32
  %xor.11.26 = xor i32 %conv23.11.26, %conv29.11.26
  %scevgep35.11.26 = getelementptr i8, i8* %a, i64 38
  %2940 = load i8, i8* %scevgep35.11.26, align 1
  %2941 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.26 = call zeroext i8 @mult(i8 zeroext %2940, i8 zeroext %2941)
  %conv35.11.26 = zext i8 %call34.11.26 to i32
  %xor36.11.26 = xor i32 %xor.11.26, %conv35.11.26
  %conv37.11.26 = trunc i32 %xor36.11.26 to i8
  store i8 %conv37.11.26, i8* %scevgep41.11.25, align 1
  %scevgep28.11.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2935, i64 0, i64 0, i64 1
  %2942 = bitcast i8* %scevgep28.11.26 to [41 x [41 x i8]]*
  %scevgep41.11.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2936, i64 0, i64 1, i64 0
  %2943 = bitcast i8* %scevgep41.11.26 to [41 x [41 x i8]]*
  %call16.11.27 = call zeroext i8 (...) @rand()
  store i8 %call16.11.27, i8* %scevgep28.11.26, align 1
  %2944 = load i8, i8* %scevgep28.11.26, align 1
  %conv23.11.27 = zext i8 %2944 to i32
  %2945 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.27 = getelementptr i8, i8* %b, i64 39
  %2946 = load i8, i8* %scevgep34.11.27, align 1
  %call28.11.27 = call zeroext i8 @mult(i8 zeroext %2945, i8 zeroext %2946)
  %conv29.11.27 = zext i8 %call28.11.27 to i32
  %xor.11.27 = xor i32 %conv23.11.27, %conv29.11.27
  %scevgep35.11.27 = getelementptr i8, i8* %a, i64 39
  %2947 = load i8, i8* %scevgep35.11.27, align 1
  %2948 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.27 = call zeroext i8 @mult(i8 zeroext %2947, i8 zeroext %2948)
  %conv35.11.27 = zext i8 %call34.11.27 to i32
  %xor36.11.27 = xor i32 %xor.11.27, %conv35.11.27
  %conv37.11.27 = trunc i32 %xor36.11.27 to i8
  store i8 %conv37.11.27, i8* %scevgep41.11.26, align 1
  %scevgep28.11.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2942, i64 0, i64 0, i64 1
  %scevgep41.11.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2943, i64 0, i64 1, i64 0
  %call16.11.28 = call zeroext i8 (...) @rand()
  store i8 %call16.11.28, i8* %scevgep28.11.27, align 1
  %2949 = load i8, i8* %scevgep28.11.27, align 1
  %conv23.11.28 = zext i8 %2949 to i32
  %2950 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.28 = getelementptr i8, i8* %b, i64 40
  %2951 = load i8, i8* %scevgep34.11.28, align 1
  %call28.11.28 = call zeroext i8 @mult(i8 zeroext %2950, i8 zeroext %2951)
  %conv29.11.28 = zext i8 %call28.11.28 to i32
  %xor.11.28 = xor i32 %conv23.11.28, %conv29.11.28
  %scevgep35.11.28 = getelementptr i8, i8* %a, i64 40
  %2952 = load i8, i8* %scevgep35.11.28, align 1
  %2953 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.28 = call zeroext i8 @mult(i8 zeroext %2952, i8 zeroext %2953)
  %conv35.11.28 = zext i8 %call34.11.28 to i32
  %xor36.11.28 = xor i32 %xor.11.28, %conv35.11.28
  %conv37.11.28 = trunc i32 %xor36.11.28 to i8
  store i8 %conv37.11.28, i8* %scevgep41.11.27, align 1
  %scevgep26.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2753, i64 0, i64 1, i64 1
  %2954 = bitcast i8* %scevgep26.11 to [41 x [41 x i8]]*
  %scevgep39.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2754, i64 0, i64 1, i64 1
  %2955 = bitcast i8* %scevgep39.11 to [41 x [41 x i8]]*
  %arrayidx25.12 = getelementptr inbounds i8, i8* %a, i64 12
  %arrayidx33.12 = getelementptr inbounds i8, i8* %b, i64 12
  %call16.12 = call zeroext i8 (...) @rand()
  store i8 %call16.12, i8* %scevgep26.11, align 1
  %2956 = load i8, i8* %scevgep26.11, align 1
  %conv23.12 = zext i8 %2956 to i32
  %2957 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12 = getelementptr i8, i8* %b, i64 13
  %2958 = load i8, i8* %scevgep34.12, align 1
  %call28.12 = call zeroext i8 @mult(i8 zeroext %2957, i8 zeroext %2958)
  %conv29.12 = zext i8 %call28.12 to i32
  %xor.12 = xor i32 %conv23.12, %conv29.12
  %scevgep35.12 = getelementptr i8, i8* %a, i64 13
  %2959 = load i8, i8* %scevgep35.12, align 1
  %2960 = load i8, i8* %arrayidx33.12, align 1
  %call34.12 = call zeroext i8 @mult(i8 zeroext %2959, i8 zeroext %2960)
  %conv35.12 = zext i8 %call34.12 to i32
  %xor36.12 = xor i32 %xor.12, %conv35.12
  %conv37.12 = trunc i32 %xor36.12 to i8
  store i8 %conv37.12, i8* %scevgep39.11, align 1
  %scevgep28.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2954, i64 0, i64 0, i64 1
  %2961 = bitcast i8* %scevgep28.12 to [41 x [41 x i8]]*
  %scevgep41.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2955, i64 0, i64 1, i64 0
  %2962 = bitcast i8* %scevgep41.12 to [41 x [41 x i8]]*
  %call16.12.1 = call zeroext i8 (...) @rand()
  store i8 %call16.12.1, i8* %scevgep28.12, align 1
  %2963 = load i8, i8* %scevgep28.12, align 1
  %conv23.12.1 = zext i8 %2963 to i32
  %2964 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.1 = getelementptr i8, i8* %b, i64 14
  %2965 = load i8, i8* %scevgep34.12.1, align 1
  %call28.12.1 = call zeroext i8 @mult(i8 zeroext %2964, i8 zeroext %2965)
  %conv29.12.1 = zext i8 %call28.12.1 to i32
  %xor.12.1 = xor i32 %conv23.12.1, %conv29.12.1
  %scevgep35.12.1 = getelementptr i8, i8* %a, i64 14
  %2966 = load i8, i8* %scevgep35.12.1, align 1
  %2967 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.1 = call zeroext i8 @mult(i8 zeroext %2966, i8 zeroext %2967)
  %conv35.12.1 = zext i8 %call34.12.1 to i32
  %xor36.12.1 = xor i32 %xor.12.1, %conv35.12.1
  %conv37.12.1 = trunc i32 %xor36.12.1 to i8
  store i8 %conv37.12.1, i8* %scevgep41.12, align 1
  %scevgep28.12.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2961, i64 0, i64 0, i64 1
  %2968 = bitcast i8* %scevgep28.12.1 to [41 x [41 x i8]]*
  %scevgep41.12.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2962, i64 0, i64 1, i64 0
  %2969 = bitcast i8* %scevgep41.12.1 to [41 x [41 x i8]]*
  %call16.12.2 = call zeroext i8 (...) @rand()
  store i8 %call16.12.2, i8* %scevgep28.12.1, align 1
  %2970 = load i8, i8* %scevgep28.12.1, align 1
  %conv23.12.2 = zext i8 %2970 to i32
  %2971 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.2 = getelementptr i8, i8* %b, i64 15
  %2972 = load i8, i8* %scevgep34.12.2, align 1
  %call28.12.2 = call zeroext i8 @mult(i8 zeroext %2971, i8 zeroext %2972)
  %conv29.12.2 = zext i8 %call28.12.2 to i32
  %xor.12.2 = xor i32 %conv23.12.2, %conv29.12.2
  %scevgep35.12.2 = getelementptr i8, i8* %a, i64 15
  %2973 = load i8, i8* %scevgep35.12.2, align 1
  %2974 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.2 = call zeroext i8 @mult(i8 zeroext %2973, i8 zeroext %2974)
  %conv35.12.2 = zext i8 %call34.12.2 to i32
  %xor36.12.2 = xor i32 %xor.12.2, %conv35.12.2
  %conv37.12.2 = trunc i32 %xor36.12.2 to i8
  store i8 %conv37.12.2, i8* %scevgep41.12.1, align 1
  %scevgep28.12.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2968, i64 0, i64 0, i64 1
  %2975 = bitcast i8* %scevgep28.12.2 to [41 x [41 x i8]]*
  %scevgep41.12.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2969, i64 0, i64 1, i64 0
  %2976 = bitcast i8* %scevgep41.12.2 to [41 x [41 x i8]]*
  %call16.12.3 = call zeroext i8 (...) @rand()
  store i8 %call16.12.3, i8* %scevgep28.12.2, align 1
  %2977 = load i8, i8* %scevgep28.12.2, align 1
  %conv23.12.3 = zext i8 %2977 to i32
  %2978 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.3 = getelementptr i8, i8* %b, i64 16
  %2979 = load i8, i8* %scevgep34.12.3, align 1
  %call28.12.3 = call zeroext i8 @mult(i8 zeroext %2978, i8 zeroext %2979)
  %conv29.12.3 = zext i8 %call28.12.3 to i32
  %xor.12.3 = xor i32 %conv23.12.3, %conv29.12.3
  %scevgep35.12.3 = getelementptr i8, i8* %a, i64 16
  %2980 = load i8, i8* %scevgep35.12.3, align 1
  %2981 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.3 = call zeroext i8 @mult(i8 zeroext %2980, i8 zeroext %2981)
  %conv35.12.3 = zext i8 %call34.12.3 to i32
  %xor36.12.3 = xor i32 %xor.12.3, %conv35.12.3
  %conv37.12.3 = trunc i32 %xor36.12.3 to i8
  store i8 %conv37.12.3, i8* %scevgep41.12.2, align 1
  %scevgep28.12.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2975, i64 0, i64 0, i64 1
  %2982 = bitcast i8* %scevgep28.12.3 to [41 x [41 x i8]]*
  %scevgep41.12.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2976, i64 0, i64 1, i64 0
  %2983 = bitcast i8* %scevgep41.12.3 to [41 x [41 x i8]]*
  %call16.12.4 = call zeroext i8 (...) @rand()
  store i8 %call16.12.4, i8* %scevgep28.12.3, align 1
  %2984 = load i8, i8* %scevgep28.12.3, align 1
  %conv23.12.4 = zext i8 %2984 to i32
  %2985 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.4 = getelementptr i8, i8* %b, i64 17
  %2986 = load i8, i8* %scevgep34.12.4, align 1
  %call28.12.4 = call zeroext i8 @mult(i8 zeroext %2985, i8 zeroext %2986)
  %conv29.12.4 = zext i8 %call28.12.4 to i32
  %xor.12.4 = xor i32 %conv23.12.4, %conv29.12.4
  %scevgep35.12.4 = getelementptr i8, i8* %a, i64 17
  %2987 = load i8, i8* %scevgep35.12.4, align 1
  %2988 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.4 = call zeroext i8 @mult(i8 zeroext %2987, i8 zeroext %2988)
  %conv35.12.4 = zext i8 %call34.12.4 to i32
  %xor36.12.4 = xor i32 %xor.12.4, %conv35.12.4
  %conv37.12.4 = trunc i32 %xor36.12.4 to i8
  store i8 %conv37.12.4, i8* %scevgep41.12.3, align 1
  %scevgep28.12.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2982, i64 0, i64 0, i64 1
  %2989 = bitcast i8* %scevgep28.12.4 to [41 x [41 x i8]]*
  %scevgep41.12.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2983, i64 0, i64 1, i64 0
  %2990 = bitcast i8* %scevgep41.12.4 to [41 x [41 x i8]]*
  %call16.12.5 = call zeroext i8 (...) @rand()
  store i8 %call16.12.5, i8* %scevgep28.12.4, align 1
  %2991 = load i8, i8* %scevgep28.12.4, align 1
  %conv23.12.5 = zext i8 %2991 to i32
  %2992 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.5 = getelementptr i8, i8* %b, i64 18
  %2993 = load i8, i8* %scevgep34.12.5, align 1
  %call28.12.5 = call zeroext i8 @mult(i8 zeroext %2992, i8 zeroext %2993)
  %conv29.12.5 = zext i8 %call28.12.5 to i32
  %xor.12.5 = xor i32 %conv23.12.5, %conv29.12.5
  %scevgep35.12.5 = getelementptr i8, i8* %a, i64 18
  %2994 = load i8, i8* %scevgep35.12.5, align 1
  %2995 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.5 = call zeroext i8 @mult(i8 zeroext %2994, i8 zeroext %2995)
  %conv35.12.5 = zext i8 %call34.12.5 to i32
  %xor36.12.5 = xor i32 %xor.12.5, %conv35.12.5
  %conv37.12.5 = trunc i32 %xor36.12.5 to i8
  store i8 %conv37.12.5, i8* %scevgep41.12.4, align 1
  %scevgep28.12.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2989, i64 0, i64 0, i64 1
  %2996 = bitcast i8* %scevgep28.12.5 to [41 x [41 x i8]]*
  %scevgep41.12.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2990, i64 0, i64 1, i64 0
  %2997 = bitcast i8* %scevgep41.12.5 to [41 x [41 x i8]]*
  %call16.12.6 = call zeroext i8 (...) @rand()
  store i8 %call16.12.6, i8* %scevgep28.12.5, align 1
  %2998 = load i8, i8* %scevgep28.12.5, align 1
  %conv23.12.6 = zext i8 %2998 to i32
  %2999 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.6 = getelementptr i8, i8* %b, i64 19
  %3000 = load i8, i8* %scevgep34.12.6, align 1
  %call28.12.6 = call zeroext i8 @mult(i8 zeroext %2999, i8 zeroext %3000)
  %conv29.12.6 = zext i8 %call28.12.6 to i32
  %xor.12.6 = xor i32 %conv23.12.6, %conv29.12.6
  %scevgep35.12.6 = getelementptr i8, i8* %a, i64 19
  %3001 = load i8, i8* %scevgep35.12.6, align 1
  %3002 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.6 = call zeroext i8 @mult(i8 zeroext %3001, i8 zeroext %3002)
  %conv35.12.6 = zext i8 %call34.12.6 to i32
  %xor36.12.6 = xor i32 %xor.12.6, %conv35.12.6
  %conv37.12.6 = trunc i32 %xor36.12.6 to i8
  store i8 %conv37.12.6, i8* %scevgep41.12.5, align 1
  %scevgep28.12.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2996, i64 0, i64 0, i64 1
  %3003 = bitcast i8* %scevgep28.12.6 to [41 x [41 x i8]]*
  %scevgep41.12.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2997, i64 0, i64 1, i64 0
  %3004 = bitcast i8* %scevgep41.12.6 to [41 x [41 x i8]]*
  %call16.12.7 = call zeroext i8 (...) @rand()
  store i8 %call16.12.7, i8* %scevgep28.12.6, align 1
  %3005 = load i8, i8* %scevgep28.12.6, align 1
  %conv23.12.7 = zext i8 %3005 to i32
  %3006 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.7 = getelementptr i8, i8* %b, i64 20
  %3007 = load i8, i8* %scevgep34.12.7, align 1
  %call28.12.7 = call zeroext i8 @mult(i8 zeroext %3006, i8 zeroext %3007)
  %conv29.12.7 = zext i8 %call28.12.7 to i32
  %xor.12.7 = xor i32 %conv23.12.7, %conv29.12.7
  %scevgep35.12.7 = getelementptr i8, i8* %a, i64 20
  %3008 = load i8, i8* %scevgep35.12.7, align 1
  %3009 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.7 = call zeroext i8 @mult(i8 zeroext %3008, i8 zeroext %3009)
  %conv35.12.7 = zext i8 %call34.12.7 to i32
  %xor36.12.7 = xor i32 %xor.12.7, %conv35.12.7
  %conv37.12.7 = trunc i32 %xor36.12.7 to i8
  store i8 %conv37.12.7, i8* %scevgep41.12.6, align 1
  %scevgep28.12.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3003, i64 0, i64 0, i64 1
  %3010 = bitcast i8* %scevgep28.12.7 to [41 x [41 x i8]]*
  %scevgep41.12.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3004, i64 0, i64 1, i64 0
  %3011 = bitcast i8* %scevgep41.12.7 to [41 x [41 x i8]]*
  %call16.12.8 = call zeroext i8 (...) @rand()
  store i8 %call16.12.8, i8* %scevgep28.12.7, align 1
  %3012 = load i8, i8* %scevgep28.12.7, align 1
  %conv23.12.8 = zext i8 %3012 to i32
  %3013 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.8 = getelementptr i8, i8* %b, i64 21
  %3014 = load i8, i8* %scevgep34.12.8, align 1
  %call28.12.8 = call zeroext i8 @mult(i8 zeroext %3013, i8 zeroext %3014)
  %conv29.12.8 = zext i8 %call28.12.8 to i32
  %xor.12.8 = xor i32 %conv23.12.8, %conv29.12.8
  %scevgep35.12.8 = getelementptr i8, i8* %a, i64 21
  %3015 = load i8, i8* %scevgep35.12.8, align 1
  %3016 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.8 = call zeroext i8 @mult(i8 zeroext %3015, i8 zeroext %3016)
  %conv35.12.8 = zext i8 %call34.12.8 to i32
  %xor36.12.8 = xor i32 %xor.12.8, %conv35.12.8
  %conv37.12.8 = trunc i32 %xor36.12.8 to i8
  store i8 %conv37.12.8, i8* %scevgep41.12.7, align 1
  %scevgep28.12.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3010, i64 0, i64 0, i64 1
  %3017 = bitcast i8* %scevgep28.12.8 to [41 x [41 x i8]]*
  %scevgep41.12.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3011, i64 0, i64 1, i64 0
  %3018 = bitcast i8* %scevgep41.12.8 to [41 x [41 x i8]]*
  %call16.12.9 = call zeroext i8 (...) @rand()
  store i8 %call16.12.9, i8* %scevgep28.12.8, align 1
  %3019 = load i8, i8* %scevgep28.12.8, align 1
  %conv23.12.9 = zext i8 %3019 to i32
  %3020 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.9 = getelementptr i8, i8* %b, i64 22
  %3021 = load i8, i8* %scevgep34.12.9, align 1
  %call28.12.9 = call zeroext i8 @mult(i8 zeroext %3020, i8 zeroext %3021)
  %conv29.12.9 = zext i8 %call28.12.9 to i32
  %xor.12.9 = xor i32 %conv23.12.9, %conv29.12.9
  %scevgep35.12.9 = getelementptr i8, i8* %a, i64 22
  %3022 = load i8, i8* %scevgep35.12.9, align 1
  %3023 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.9 = call zeroext i8 @mult(i8 zeroext %3022, i8 zeroext %3023)
  %conv35.12.9 = zext i8 %call34.12.9 to i32
  %xor36.12.9 = xor i32 %xor.12.9, %conv35.12.9
  %conv37.12.9 = trunc i32 %xor36.12.9 to i8
  store i8 %conv37.12.9, i8* %scevgep41.12.8, align 1
  %scevgep28.12.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3017, i64 0, i64 0, i64 1
  %3024 = bitcast i8* %scevgep28.12.9 to [41 x [41 x i8]]*
  %scevgep41.12.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3018, i64 0, i64 1, i64 0
  %3025 = bitcast i8* %scevgep41.12.9 to [41 x [41 x i8]]*
  %call16.12.10 = call zeroext i8 (...) @rand()
  store i8 %call16.12.10, i8* %scevgep28.12.9, align 1
  %3026 = load i8, i8* %scevgep28.12.9, align 1
  %conv23.12.10 = zext i8 %3026 to i32
  %3027 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.10 = getelementptr i8, i8* %b, i64 23
  %3028 = load i8, i8* %scevgep34.12.10, align 1
  %call28.12.10 = call zeroext i8 @mult(i8 zeroext %3027, i8 zeroext %3028)
  %conv29.12.10 = zext i8 %call28.12.10 to i32
  %xor.12.10 = xor i32 %conv23.12.10, %conv29.12.10
  %scevgep35.12.10 = getelementptr i8, i8* %a, i64 23
  %3029 = load i8, i8* %scevgep35.12.10, align 1
  %3030 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.10 = call zeroext i8 @mult(i8 zeroext %3029, i8 zeroext %3030)
  %conv35.12.10 = zext i8 %call34.12.10 to i32
  %xor36.12.10 = xor i32 %xor.12.10, %conv35.12.10
  %conv37.12.10 = trunc i32 %xor36.12.10 to i8
  store i8 %conv37.12.10, i8* %scevgep41.12.9, align 1
  %scevgep28.12.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3024, i64 0, i64 0, i64 1
  %3031 = bitcast i8* %scevgep28.12.10 to [41 x [41 x i8]]*
  %scevgep41.12.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3025, i64 0, i64 1, i64 0
  %3032 = bitcast i8* %scevgep41.12.10 to [41 x [41 x i8]]*
  %call16.12.11 = call zeroext i8 (...) @rand()
  store i8 %call16.12.11, i8* %scevgep28.12.10, align 1
  %3033 = load i8, i8* %scevgep28.12.10, align 1
  %conv23.12.11 = zext i8 %3033 to i32
  %3034 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.11 = getelementptr i8, i8* %b, i64 24
  %3035 = load i8, i8* %scevgep34.12.11, align 1
  %call28.12.11 = call zeroext i8 @mult(i8 zeroext %3034, i8 zeroext %3035)
  %conv29.12.11 = zext i8 %call28.12.11 to i32
  %xor.12.11 = xor i32 %conv23.12.11, %conv29.12.11
  %scevgep35.12.11 = getelementptr i8, i8* %a, i64 24
  %3036 = load i8, i8* %scevgep35.12.11, align 1
  %3037 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.11 = call zeroext i8 @mult(i8 zeroext %3036, i8 zeroext %3037)
  %conv35.12.11 = zext i8 %call34.12.11 to i32
  %xor36.12.11 = xor i32 %xor.12.11, %conv35.12.11
  %conv37.12.11 = trunc i32 %xor36.12.11 to i8
  store i8 %conv37.12.11, i8* %scevgep41.12.10, align 1
  %scevgep28.12.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3031, i64 0, i64 0, i64 1
  %3038 = bitcast i8* %scevgep28.12.11 to [41 x [41 x i8]]*
  %scevgep41.12.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3032, i64 0, i64 1, i64 0
  %3039 = bitcast i8* %scevgep41.12.11 to [41 x [41 x i8]]*
  %call16.12.12 = call zeroext i8 (...) @rand()
  store i8 %call16.12.12, i8* %scevgep28.12.11, align 1
  %3040 = load i8, i8* %scevgep28.12.11, align 1
  %conv23.12.12 = zext i8 %3040 to i32
  %3041 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.12 = getelementptr i8, i8* %b, i64 25
  %3042 = load i8, i8* %scevgep34.12.12, align 1
  %call28.12.12 = call zeroext i8 @mult(i8 zeroext %3041, i8 zeroext %3042)
  %conv29.12.12 = zext i8 %call28.12.12 to i32
  %xor.12.12 = xor i32 %conv23.12.12, %conv29.12.12
  %scevgep35.12.12 = getelementptr i8, i8* %a, i64 25
  %3043 = load i8, i8* %scevgep35.12.12, align 1
  %3044 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.12 = call zeroext i8 @mult(i8 zeroext %3043, i8 zeroext %3044)
  %conv35.12.12 = zext i8 %call34.12.12 to i32
  %xor36.12.12 = xor i32 %xor.12.12, %conv35.12.12
  %conv37.12.12 = trunc i32 %xor36.12.12 to i8
  store i8 %conv37.12.12, i8* %scevgep41.12.11, align 1
  %scevgep28.12.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3038, i64 0, i64 0, i64 1
  %3045 = bitcast i8* %scevgep28.12.12 to [41 x [41 x i8]]*
  %scevgep41.12.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3039, i64 0, i64 1, i64 0
  %3046 = bitcast i8* %scevgep41.12.12 to [41 x [41 x i8]]*
  %call16.12.13 = call zeroext i8 (...) @rand()
  store i8 %call16.12.13, i8* %scevgep28.12.12, align 1
  %3047 = load i8, i8* %scevgep28.12.12, align 1
  %conv23.12.13 = zext i8 %3047 to i32
  %3048 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.13 = getelementptr i8, i8* %b, i64 26
  %3049 = load i8, i8* %scevgep34.12.13, align 1
  %call28.12.13 = call zeroext i8 @mult(i8 zeroext %3048, i8 zeroext %3049)
  %conv29.12.13 = zext i8 %call28.12.13 to i32
  %xor.12.13 = xor i32 %conv23.12.13, %conv29.12.13
  %scevgep35.12.13 = getelementptr i8, i8* %a, i64 26
  %3050 = load i8, i8* %scevgep35.12.13, align 1
  %3051 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.13 = call zeroext i8 @mult(i8 zeroext %3050, i8 zeroext %3051)
  %conv35.12.13 = zext i8 %call34.12.13 to i32
  %xor36.12.13 = xor i32 %xor.12.13, %conv35.12.13
  %conv37.12.13 = trunc i32 %xor36.12.13 to i8
  store i8 %conv37.12.13, i8* %scevgep41.12.12, align 1
  %scevgep28.12.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3045, i64 0, i64 0, i64 1
  %3052 = bitcast i8* %scevgep28.12.13 to [41 x [41 x i8]]*
  %scevgep41.12.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3046, i64 0, i64 1, i64 0
  %3053 = bitcast i8* %scevgep41.12.13 to [41 x [41 x i8]]*
  %call16.12.14 = call zeroext i8 (...) @rand()
  store i8 %call16.12.14, i8* %scevgep28.12.13, align 1
  %3054 = load i8, i8* %scevgep28.12.13, align 1
  %conv23.12.14 = zext i8 %3054 to i32
  %3055 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.14 = getelementptr i8, i8* %b, i64 27
  %3056 = load i8, i8* %scevgep34.12.14, align 1
  %call28.12.14 = call zeroext i8 @mult(i8 zeroext %3055, i8 zeroext %3056)
  %conv29.12.14 = zext i8 %call28.12.14 to i32
  %xor.12.14 = xor i32 %conv23.12.14, %conv29.12.14
  %scevgep35.12.14 = getelementptr i8, i8* %a, i64 27
  %3057 = load i8, i8* %scevgep35.12.14, align 1
  %3058 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.14 = call zeroext i8 @mult(i8 zeroext %3057, i8 zeroext %3058)
  %conv35.12.14 = zext i8 %call34.12.14 to i32
  %xor36.12.14 = xor i32 %xor.12.14, %conv35.12.14
  %conv37.12.14 = trunc i32 %xor36.12.14 to i8
  store i8 %conv37.12.14, i8* %scevgep41.12.13, align 1
  %scevgep28.12.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3052, i64 0, i64 0, i64 1
  %3059 = bitcast i8* %scevgep28.12.14 to [41 x [41 x i8]]*
  %scevgep41.12.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3053, i64 0, i64 1, i64 0
  %3060 = bitcast i8* %scevgep41.12.14 to [41 x [41 x i8]]*
  %call16.12.15 = call zeroext i8 (...) @rand()
  store i8 %call16.12.15, i8* %scevgep28.12.14, align 1
  %3061 = load i8, i8* %scevgep28.12.14, align 1
  %conv23.12.15 = zext i8 %3061 to i32
  %3062 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.15 = getelementptr i8, i8* %b, i64 28
  %3063 = load i8, i8* %scevgep34.12.15, align 1
  %call28.12.15 = call zeroext i8 @mult(i8 zeroext %3062, i8 zeroext %3063)
  %conv29.12.15 = zext i8 %call28.12.15 to i32
  %xor.12.15 = xor i32 %conv23.12.15, %conv29.12.15
  %scevgep35.12.15 = getelementptr i8, i8* %a, i64 28
  %3064 = load i8, i8* %scevgep35.12.15, align 1
  %3065 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.15 = call zeroext i8 @mult(i8 zeroext %3064, i8 zeroext %3065)
  %conv35.12.15 = zext i8 %call34.12.15 to i32
  %xor36.12.15 = xor i32 %xor.12.15, %conv35.12.15
  %conv37.12.15 = trunc i32 %xor36.12.15 to i8
  store i8 %conv37.12.15, i8* %scevgep41.12.14, align 1
  %scevgep28.12.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3059, i64 0, i64 0, i64 1
  %3066 = bitcast i8* %scevgep28.12.15 to [41 x [41 x i8]]*
  %scevgep41.12.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3060, i64 0, i64 1, i64 0
  %3067 = bitcast i8* %scevgep41.12.15 to [41 x [41 x i8]]*
  %call16.12.16 = call zeroext i8 (...) @rand()
  store i8 %call16.12.16, i8* %scevgep28.12.15, align 1
  %3068 = load i8, i8* %scevgep28.12.15, align 1
  %conv23.12.16 = zext i8 %3068 to i32
  %3069 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.16 = getelementptr i8, i8* %b, i64 29
  %3070 = load i8, i8* %scevgep34.12.16, align 1
  %call28.12.16 = call zeroext i8 @mult(i8 zeroext %3069, i8 zeroext %3070)
  %conv29.12.16 = zext i8 %call28.12.16 to i32
  %xor.12.16 = xor i32 %conv23.12.16, %conv29.12.16
  %scevgep35.12.16 = getelementptr i8, i8* %a, i64 29
  %3071 = load i8, i8* %scevgep35.12.16, align 1
  %3072 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.16 = call zeroext i8 @mult(i8 zeroext %3071, i8 zeroext %3072)
  %conv35.12.16 = zext i8 %call34.12.16 to i32
  %xor36.12.16 = xor i32 %xor.12.16, %conv35.12.16
  %conv37.12.16 = trunc i32 %xor36.12.16 to i8
  store i8 %conv37.12.16, i8* %scevgep41.12.15, align 1
  %scevgep28.12.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3066, i64 0, i64 0, i64 1
  %3073 = bitcast i8* %scevgep28.12.16 to [41 x [41 x i8]]*
  %scevgep41.12.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3067, i64 0, i64 1, i64 0
  %3074 = bitcast i8* %scevgep41.12.16 to [41 x [41 x i8]]*
  %call16.12.17 = call zeroext i8 (...) @rand()
  store i8 %call16.12.17, i8* %scevgep28.12.16, align 1
  %3075 = load i8, i8* %scevgep28.12.16, align 1
  %conv23.12.17 = zext i8 %3075 to i32
  %3076 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.17 = getelementptr i8, i8* %b, i64 30
  %3077 = load i8, i8* %scevgep34.12.17, align 1
  %call28.12.17 = call zeroext i8 @mult(i8 zeroext %3076, i8 zeroext %3077)
  %conv29.12.17 = zext i8 %call28.12.17 to i32
  %xor.12.17 = xor i32 %conv23.12.17, %conv29.12.17
  %scevgep35.12.17 = getelementptr i8, i8* %a, i64 30
  %3078 = load i8, i8* %scevgep35.12.17, align 1
  %3079 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.17 = call zeroext i8 @mult(i8 zeroext %3078, i8 zeroext %3079)
  %conv35.12.17 = zext i8 %call34.12.17 to i32
  %xor36.12.17 = xor i32 %xor.12.17, %conv35.12.17
  %conv37.12.17 = trunc i32 %xor36.12.17 to i8
  store i8 %conv37.12.17, i8* %scevgep41.12.16, align 1
  %scevgep28.12.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3073, i64 0, i64 0, i64 1
  %3080 = bitcast i8* %scevgep28.12.17 to [41 x [41 x i8]]*
  %scevgep41.12.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3074, i64 0, i64 1, i64 0
  %3081 = bitcast i8* %scevgep41.12.17 to [41 x [41 x i8]]*
  %call16.12.18 = call zeroext i8 (...) @rand()
  store i8 %call16.12.18, i8* %scevgep28.12.17, align 1
  %3082 = load i8, i8* %scevgep28.12.17, align 1
  %conv23.12.18 = zext i8 %3082 to i32
  %3083 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.18 = getelementptr i8, i8* %b, i64 31
  %3084 = load i8, i8* %scevgep34.12.18, align 1
  %call28.12.18 = call zeroext i8 @mult(i8 zeroext %3083, i8 zeroext %3084)
  %conv29.12.18 = zext i8 %call28.12.18 to i32
  %xor.12.18 = xor i32 %conv23.12.18, %conv29.12.18
  %scevgep35.12.18 = getelementptr i8, i8* %a, i64 31
  %3085 = load i8, i8* %scevgep35.12.18, align 1
  %3086 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.18 = call zeroext i8 @mult(i8 zeroext %3085, i8 zeroext %3086)
  %conv35.12.18 = zext i8 %call34.12.18 to i32
  %xor36.12.18 = xor i32 %xor.12.18, %conv35.12.18
  %conv37.12.18 = trunc i32 %xor36.12.18 to i8
  store i8 %conv37.12.18, i8* %scevgep41.12.17, align 1
  %scevgep28.12.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3080, i64 0, i64 0, i64 1
  %3087 = bitcast i8* %scevgep28.12.18 to [41 x [41 x i8]]*
  %scevgep41.12.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3081, i64 0, i64 1, i64 0
  %3088 = bitcast i8* %scevgep41.12.18 to [41 x [41 x i8]]*
  %call16.12.19 = call zeroext i8 (...) @rand()
  store i8 %call16.12.19, i8* %scevgep28.12.18, align 1
  %3089 = load i8, i8* %scevgep28.12.18, align 1
  %conv23.12.19 = zext i8 %3089 to i32
  %3090 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.19 = getelementptr i8, i8* %b, i64 32
  %3091 = load i8, i8* %scevgep34.12.19, align 1
  %call28.12.19 = call zeroext i8 @mult(i8 zeroext %3090, i8 zeroext %3091)
  %conv29.12.19 = zext i8 %call28.12.19 to i32
  %xor.12.19 = xor i32 %conv23.12.19, %conv29.12.19
  %scevgep35.12.19 = getelementptr i8, i8* %a, i64 32
  %3092 = load i8, i8* %scevgep35.12.19, align 1
  %3093 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.19 = call zeroext i8 @mult(i8 zeroext %3092, i8 zeroext %3093)
  %conv35.12.19 = zext i8 %call34.12.19 to i32
  %xor36.12.19 = xor i32 %xor.12.19, %conv35.12.19
  %conv37.12.19 = trunc i32 %xor36.12.19 to i8
  store i8 %conv37.12.19, i8* %scevgep41.12.18, align 1
  %scevgep28.12.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3087, i64 0, i64 0, i64 1
  %3094 = bitcast i8* %scevgep28.12.19 to [41 x [41 x i8]]*
  %scevgep41.12.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3088, i64 0, i64 1, i64 0
  %3095 = bitcast i8* %scevgep41.12.19 to [41 x [41 x i8]]*
  %call16.12.20 = call zeroext i8 (...) @rand()
  store i8 %call16.12.20, i8* %scevgep28.12.19, align 1
  %3096 = load i8, i8* %scevgep28.12.19, align 1
  %conv23.12.20 = zext i8 %3096 to i32
  %3097 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.20 = getelementptr i8, i8* %b, i64 33
  %3098 = load i8, i8* %scevgep34.12.20, align 1
  %call28.12.20 = call zeroext i8 @mult(i8 zeroext %3097, i8 zeroext %3098)
  %conv29.12.20 = zext i8 %call28.12.20 to i32
  %xor.12.20 = xor i32 %conv23.12.20, %conv29.12.20
  %scevgep35.12.20 = getelementptr i8, i8* %a, i64 33
  %3099 = load i8, i8* %scevgep35.12.20, align 1
  %3100 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.20 = call zeroext i8 @mult(i8 zeroext %3099, i8 zeroext %3100)
  %conv35.12.20 = zext i8 %call34.12.20 to i32
  %xor36.12.20 = xor i32 %xor.12.20, %conv35.12.20
  %conv37.12.20 = trunc i32 %xor36.12.20 to i8
  store i8 %conv37.12.20, i8* %scevgep41.12.19, align 1
  %scevgep28.12.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3094, i64 0, i64 0, i64 1
  %3101 = bitcast i8* %scevgep28.12.20 to [41 x [41 x i8]]*
  %scevgep41.12.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3095, i64 0, i64 1, i64 0
  %3102 = bitcast i8* %scevgep41.12.20 to [41 x [41 x i8]]*
  %call16.12.21 = call zeroext i8 (...) @rand()
  store i8 %call16.12.21, i8* %scevgep28.12.20, align 1
  %3103 = load i8, i8* %scevgep28.12.20, align 1
  %conv23.12.21 = zext i8 %3103 to i32
  %3104 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.21 = getelementptr i8, i8* %b, i64 34
  %3105 = load i8, i8* %scevgep34.12.21, align 1
  %call28.12.21 = call zeroext i8 @mult(i8 zeroext %3104, i8 zeroext %3105)
  %conv29.12.21 = zext i8 %call28.12.21 to i32
  %xor.12.21 = xor i32 %conv23.12.21, %conv29.12.21
  %scevgep35.12.21 = getelementptr i8, i8* %a, i64 34
  %3106 = load i8, i8* %scevgep35.12.21, align 1
  %3107 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.21 = call zeroext i8 @mult(i8 zeroext %3106, i8 zeroext %3107)
  %conv35.12.21 = zext i8 %call34.12.21 to i32
  %xor36.12.21 = xor i32 %xor.12.21, %conv35.12.21
  %conv37.12.21 = trunc i32 %xor36.12.21 to i8
  store i8 %conv37.12.21, i8* %scevgep41.12.20, align 1
  %scevgep28.12.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3101, i64 0, i64 0, i64 1
  %3108 = bitcast i8* %scevgep28.12.21 to [41 x [41 x i8]]*
  %scevgep41.12.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3102, i64 0, i64 1, i64 0
  %3109 = bitcast i8* %scevgep41.12.21 to [41 x [41 x i8]]*
  %call16.12.22 = call zeroext i8 (...) @rand()
  store i8 %call16.12.22, i8* %scevgep28.12.21, align 1
  %3110 = load i8, i8* %scevgep28.12.21, align 1
  %conv23.12.22 = zext i8 %3110 to i32
  %3111 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.22 = getelementptr i8, i8* %b, i64 35
  %3112 = load i8, i8* %scevgep34.12.22, align 1
  %call28.12.22 = call zeroext i8 @mult(i8 zeroext %3111, i8 zeroext %3112)
  %conv29.12.22 = zext i8 %call28.12.22 to i32
  %xor.12.22 = xor i32 %conv23.12.22, %conv29.12.22
  %scevgep35.12.22 = getelementptr i8, i8* %a, i64 35
  %3113 = load i8, i8* %scevgep35.12.22, align 1
  %3114 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.22 = call zeroext i8 @mult(i8 zeroext %3113, i8 zeroext %3114)
  %conv35.12.22 = zext i8 %call34.12.22 to i32
  %xor36.12.22 = xor i32 %xor.12.22, %conv35.12.22
  %conv37.12.22 = trunc i32 %xor36.12.22 to i8
  store i8 %conv37.12.22, i8* %scevgep41.12.21, align 1
  %scevgep28.12.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3108, i64 0, i64 0, i64 1
  %3115 = bitcast i8* %scevgep28.12.22 to [41 x [41 x i8]]*
  %scevgep41.12.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3109, i64 0, i64 1, i64 0
  %3116 = bitcast i8* %scevgep41.12.22 to [41 x [41 x i8]]*
  %call16.12.23 = call zeroext i8 (...) @rand()
  store i8 %call16.12.23, i8* %scevgep28.12.22, align 1
  %3117 = load i8, i8* %scevgep28.12.22, align 1
  %conv23.12.23 = zext i8 %3117 to i32
  %3118 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.23 = getelementptr i8, i8* %b, i64 36
  %3119 = load i8, i8* %scevgep34.12.23, align 1
  %call28.12.23 = call zeroext i8 @mult(i8 zeroext %3118, i8 zeroext %3119)
  %conv29.12.23 = zext i8 %call28.12.23 to i32
  %xor.12.23 = xor i32 %conv23.12.23, %conv29.12.23
  %scevgep35.12.23 = getelementptr i8, i8* %a, i64 36
  %3120 = load i8, i8* %scevgep35.12.23, align 1
  %3121 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.23 = call zeroext i8 @mult(i8 zeroext %3120, i8 zeroext %3121)
  %conv35.12.23 = zext i8 %call34.12.23 to i32
  %xor36.12.23 = xor i32 %xor.12.23, %conv35.12.23
  %conv37.12.23 = trunc i32 %xor36.12.23 to i8
  store i8 %conv37.12.23, i8* %scevgep41.12.22, align 1
  %scevgep28.12.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3115, i64 0, i64 0, i64 1
  %3122 = bitcast i8* %scevgep28.12.23 to [41 x [41 x i8]]*
  %scevgep41.12.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3116, i64 0, i64 1, i64 0
  %3123 = bitcast i8* %scevgep41.12.23 to [41 x [41 x i8]]*
  %call16.12.24 = call zeroext i8 (...) @rand()
  store i8 %call16.12.24, i8* %scevgep28.12.23, align 1
  %3124 = load i8, i8* %scevgep28.12.23, align 1
  %conv23.12.24 = zext i8 %3124 to i32
  %3125 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.24 = getelementptr i8, i8* %b, i64 37
  %3126 = load i8, i8* %scevgep34.12.24, align 1
  %call28.12.24 = call zeroext i8 @mult(i8 zeroext %3125, i8 zeroext %3126)
  %conv29.12.24 = zext i8 %call28.12.24 to i32
  %xor.12.24 = xor i32 %conv23.12.24, %conv29.12.24
  %scevgep35.12.24 = getelementptr i8, i8* %a, i64 37
  %3127 = load i8, i8* %scevgep35.12.24, align 1
  %3128 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.24 = call zeroext i8 @mult(i8 zeroext %3127, i8 zeroext %3128)
  %conv35.12.24 = zext i8 %call34.12.24 to i32
  %xor36.12.24 = xor i32 %xor.12.24, %conv35.12.24
  %conv37.12.24 = trunc i32 %xor36.12.24 to i8
  store i8 %conv37.12.24, i8* %scevgep41.12.23, align 1
  %scevgep28.12.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3122, i64 0, i64 0, i64 1
  %3129 = bitcast i8* %scevgep28.12.24 to [41 x [41 x i8]]*
  %scevgep41.12.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3123, i64 0, i64 1, i64 0
  %3130 = bitcast i8* %scevgep41.12.24 to [41 x [41 x i8]]*
  %call16.12.25 = call zeroext i8 (...) @rand()
  store i8 %call16.12.25, i8* %scevgep28.12.24, align 1
  %3131 = load i8, i8* %scevgep28.12.24, align 1
  %conv23.12.25 = zext i8 %3131 to i32
  %3132 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.25 = getelementptr i8, i8* %b, i64 38
  %3133 = load i8, i8* %scevgep34.12.25, align 1
  %call28.12.25 = call zeroext i8 @mult(i8 zeroext %3132, i8 zeroext %3133)
  %conv29.12.25 = zext i8 %call28.12.25 to i32
  %xor.12.25 = xor i32 %conv23.12.25, %conv29.12.25
  %scevgep35.12.25 = getelementptr i8, i8* %a, i64 38
  %3134 = load i8, i8* %scevgep35.12.25, align 1
  %3135 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.25 = call zeroext i8 @mult(i8 zeroext %3134, i8 zeroext %3135)
  %conv35.12.25 = zext i8 %call34.12.25 to i32
  %xor36.12.25 = xor i32 %xor.12.25, %conv35.12.25
  %conv37.12.25 = trunc i32 %xor36.12.25 to i8
  store i8 %conv37.12.25, i8* %scevgep41.12.24, align 1
  %scevgep28.12.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3129, i64 0, i64 0, i64 1
  %3136 = bitcast i8* %scevgep28.12.25 to [41 x [41 x i8]]*
  %scevgep41.12.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3130, i64 0, i64 1, i64 0
  %3137 = bitcast i8* %scevgep41.12.25 to [41 x [41 x i8]]*
  %call16.12.26 = call zeroext i8 (...) @rand()
  store i8 %call16.12.26, i8* %scevgep28.12.25, align 1
  %3138 = load i8, i8* %scevgep28.12.25, align 1
  %conv23.12.26 = zext i8 %3138 to i32
  %3139 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.26 = getelementptr i8, i8* %b, i64 39
  %3140 = load i8, i8* %scevgep34.12.26, align 1
  %call28.12.26 = call zeroext i8 @mult(i8 zeroext %3139, i8 zeroext %3140)
  %conv29.12.26 = zext i8 %call28.12.26 to i32
  %xor.12.26 = xor i32 %conv23.12.26, %conv29.12.26
  %scevgep35.12.26 = getelementptr i8, i8* %a, i64 39
  %3141 = load i8, i8* %scevgep35.12.26, align 1
  %3142 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.26 = call zeroext i8 @mult(i8 zeroext %3141, i8 zeroext %3142)
  %conv35.12.26 = zext i8 %call34.12.26 to i32
  %xor36.12.26 = xor i32 %xor.12.26, %conv35.12.26
  %conv37.12.26 = trunc i32 %xor36.12.26 to i8
  store i8 %conv37.12.26, i8* %scevgep41.12.25, align 1
  %scevgep28.12.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3136, i64 0, i64 0, i64 1
  %scevgep41.12.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3137, i64 0, i64 1, i64 0
  %call16.12.27 = call zeroext i8 (...) @rand()
  store i8 %call16.12.27, i8* %scevgep28.12.26, align 1
  %3143 = load i8, i8* %scevgep28.12.26, align 1
  %conv23.12.27 = zext i8 %3143 to i32
  %3144 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.27 = getelementptr i8, i8* %b, i64 40
  %3145 = load i8, i8* %scevgep34.12.27, align 1
  %call28.12.27 = call zeroext i8 @mult(i8 zeroext %3144, i8 zeroext %3145)
  %conv29.12.27 = zext i8 %call28.12.27 to i32
  %xor.12.27 = xor i32 %conv23.12.27, %conv29.12.27
  %scevgep35.12.27 = getelementptr i8, i8* %a, i64 40
  %3146 = load i8, i8* %scevgep35.12.27, align 1
  %3147 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.27 = call zeroext i8 @mult(i8 zeroext %3146, i8 zeroext %3147)
  %conv35.12.27 = zext i8 %call34.12.27 to i32
  %xor36.12.27 = xor i32 %xor.12.27, %conv35.12.27
  %conv37.12.27 = trunc i32 %xor36.12.27 to i8
  store i8 %conv37.12.27, i8* %scevgep41.12.26, align 1
  %scevgep26.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2954, i64 0, i64 1, i64 1
  %3148 = bitcast i8* %scevgep26.12 to [41 x [41 x i8]]*
  %scevgep39.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %2955, i64 0, i64 1, i64 1
  %3149 = bitcast i8* %scevgep39.12 to [41 x [41 x i8]]*
  %arrayidx25.13 = getelementptr inbounds i8, i8* %a, i64 13
  %arrayidx33.13 = getelementptr inbounds i8, i8* %b, i64 13
  %call16.13 = call zeroext i8 (...) @rand()
  store i8 %call16.13, i8* %scevgep26.12, align 1
  %3150 = load i8, i8* %scevgep26.12, align 1
  %conv23.13 = zext i8 %3150 to i32
  %3151 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13 = getelementptr i8, i8* %b, i64 14
  %3152 = load i8, i8* %scevgep34.13, align 1
  %call28.13 = call zeroext i8 @mult(i8 zeroext %3151, i8 zeroext %3152)
  %conv29.13 = zext i8 %call28.13 to i32
  %xor.13 = xor i32 %conv23.13, %conv29.13
  %scevgep35.13 = getelementptr i8, i8* %a, i64 14
  %3153 = load i8, i8* %scevgep35.13, align 1
  %3154 = load i8, i8* %arrayidx33.13, align 1
  %call34.13 = call zeroext i8 @mult(i8 zeroext %3153, i8 zeroext %3154)
  %conv35.13 = zext i8 %call34.13 to i32
  %xor36.13 = xor i32 %xor.13, %conv35.13
  %conv37.13 = trunc i32 %xor36.13 to i8
  store i8 %conv37.13, i8* %scevgep39.12, align 1
  %scevgep28.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3148, i64 0, i64 0, i64 1
  %3155 = bitcast i8* %scevgep28.13 to [41 x [41 x i8]]*
  %scevgep41.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3149, i64 0, i64 1, i64 0
  %3156 = bitcast i8* %scevgep41.13 to [41 x [41 x i8]]*
  %call16.13.1 = call zeroext i8 (...) @rand()
  store i8 %call16.13.1, i8* %scevgep28.13, align 1
  %3157 = load i8, i8* %scevgep28.13, align 1
  %conv23.13.1 = zext i8 %3157 to i32
  %3158 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.1 = getelementptr i8, i8* %b, i64 15
  %3159 = load i8, i8* %scevgep34.13.1, align 1
  %call28.13.1 = call zeroext i8 @mult(i8 zeroext %3158, i8 zeroext %3159)
  %conv29.13.1 = zext i8 %call28.13.1 to i32
  %xor.13.1 = xor i32 %conv23.13.1, %conv29.13.1
  %scevgep35.13.1 = getelementptr i8, i8* %a, i64 15
  %3160 = load i8, i8* %scevgep35.13.1, align 1
  %3161 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.1 = call zeroext i8 @mult(i8 zeroext %3160, i8 zeroext %3161)
  %conv35.13.1 = zext i8 %call34.13.1 to i32
  %xor36.13.1 = xor i32 %xor.13.1, %conv35.13.1
  %conv37.13.1 = trunc i32 %xor36.13.1 to i8
  store i8 %conv37.13.1, i8* %scevgep41.13, align 1
  %scevgep28.13.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3155, i64 0, i64 0, i64 1
  %3162 = bitcast i8* %scevgep28.13.1 to [41 x [41 x i8]]*
  %scevgep41.13.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3156, i64 0, i64 1, i64 0
  %3163 = bitcast i8* %scevgep41.13.1 to [41 x [41 x i8]]*
  %call16.13.2 = call zeroext i8 (...) @rand()
  store i8 %call16.13.2, i8* %scevgep28.13.1, align 1
  %3164 = load i8, i8* %scevgep28.13.1, align 1
  %conv23.13.2 = zext i8 %3164 to i32
  %3165 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.2 = getelementptr i8, i8* %b, i64 16
  %3166 = load i8, i8* %scevgep34.13.2, align 1
  %call28.13.2 = call zeroext i8 @mult(i8 zeroext %3165, i8 zeroext %3166)
  %conv29.13.2 = zext i8 %call28.13.2 to i32
  %xor.13.2 = xor i32 %conv23.13.2, %conv29.13.2
  %scevgep35.13.2 = getelementptr i8, i8* %a, i64 16
  %3167 = load i8, i8* %scevgep35.13.2, align 1
  %3168 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.2 = call zeroext i8 @mult(i8 zeroext %3167, i8 zeroext %3168)
  %conv35.13.2 = zext i8 %call34.13.2 to i32
  %xor36.13.2 = xor i32 %xor.13.2, %conv35.13.2
  %conv37.13.2 = trunc i32 %xor36.13.2 to i8
  store i8 %conv37.13.2, i8* %scevgep41.13.1, align 1
  %scevgep28.13.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3162, i64 0, i64 0, i64 1
  %3169 = bitcast i8* %scevgep28.13.2 to [41 x [41 x i8]]*
  %scevgep41.13.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3163, i64 0, i64 1, i64 0
  %3170 = bitcast i8* %scevgep41.13.2 to [41 x [41 x i8]]*
  %call16.13.3 = call zeroext i8 (...) @rand()
  store i8 %call16.13.3, i8* %scevgep28.13.2, align 1
  %3171 = load i8, i8* %scevgep28.13.2, align 1
  %conv23.13.3 = zext i8 %3171 to i32
  %3172 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.3 = getelementptr i8, i8* %b, i64 17
  %3173 = load i8, i8* %scevgep34.13.3, align 1
  %call28.13.3 = call zeroext i8 @mult(i8 zeroext %3172, i8 zeroext %3173)
  %conv29.13.3 = zext i8 %call28.13.3 to i32
  %xor.13.3 = xor i32 %conv23.13.3, %conv29.13.3
  %scevgep35.13.3 = getelementptr i8, i8* %a, i64 17
  %3174 = load i8, i8* %scevgep35.13.3, align 1
  %3175 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.3 = call zeroext i8 @mult(i8 zeroext %3174, i8 zeroext %3175)
  %conv35.13.3 = zext i8 %call34.13.3 to i32
  %xor36.13.3 = xor i32 %xor.13.3, %conv35.13.3
  %conv37.13.3 = trunc i32 %xor36.13.3 to i8
  store i8 %conv37.13.3, i8* %scevgep41.13.2, align 1
  %scevgep28.13.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3169, i64 0, i64 0, i64 1
  %3176 = bitcast i8* %scevgep28.13.3 to [41 x [41 x i8]]*
  %scevgep41.13.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3170, i64 0, i64 1, i64 0
  %3177 = bitcast i8* %scevgep41.13.3 to [41 x [41 x i8]]*
  %call16.13.4 = call zeroext i8 (...) @rand()
  store i8 %call16.13.4, i8* %scevgep28.13.3, align 1
  %3178 = load i8, i8* %scevgep28.13.3, align 1
  %conv23.13.4 = zext i8 %3178 to i32
  %3179 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.4 = getelementptr i8, i8* %b, i64 18
  %3180 = load i8, i8* %scevgep34.13.4, align 1
  %call28.13.4 = call zeroext i8 @mult(i8 zeroext %3179, i8 zeroext %3180)
  %conv29.13.4 = zext i8 %call28.13.4 to i32
  %xor.13.4 = xor i32 %conv23.13.4, %conv29.13.4
  %scevgep35.13.4 = getelementptr i8, i8* %a, i64 18
  %3181 = load i8, i8* %scevgep35.13.4, align 1
  %3182 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.4 = call zeroext i8 @mult(i8 zeroext %3181, i8 zeroext %3182)
  %conv35.13.4 = zext i8 %call34.13.4 to i32
  %xor36.13.4 = xor i32 %xor.13.4, %conv35.13.4
  %conv37.13.4 = trunc i32 %xor36.13.4 to i8
  store i8 %conv37.13.4, i8* %scevgep41.13.3, align 1
  %scevgep28.13.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3176, i64 0, i64 0, i64 1
  %3183 = bitcast i8* %scevgep28.13.4 to [41 x [41 x i8]]*
  %scevgep41.13.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3177, i64 0, i64 1, i64 0
  %3184 = bitcast i8* %scevgep41.13.4 to [41 x [41 x i8]]*
  %call16.13.5 = call zeroext i8 (...) @rand()
  store i8 %call16.13.5, i8* %scevgep28.13.4, align 1
  %3185 = load i8, i8* %scevgep28.13.4, align 1
  %conv23.13.5 = zext i8 %3185 to i32
  %3186 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.5 = getelementptr i8, i8* %b, i64 19
  %3187 = load i8, i8* %scevgep34.13.5, align 1
  %call28.13.5 = call zeroext i8 @mult(i8 zeroext %3186, i8 zeroext %3187)
  %conv29.13.5 = zext i8 %call28.13.5 to i32
  %xor.13.5 = xor i32 %conv23.13.5, %conv29.13.5
  %scevgep35.13.5 = getelementptr i8, i8* %a, i64 19
  %3188 = load i8, i8* %scevgep35.13.5, align 1
  %3189 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.5 = call zeroext i8 @mult(i8 zeroext %3188, i8 zeroext %3189)
  %conv35.13.5 = zext i8 %call34.13.5 to i32
  %xor36.13.5 = xor i32 %xor.13.5, %conv35.13.5
  %conv37.13.5 = trunc i32 %xor36.13.5 to i8
  store i8 %conv37.13.5, i8* %scevgep41.13.4, align 1
  %scevgep28.13.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3183, i64 0, i64 0, i64 1
  %3190 = bitcast i8* %scevgep28.13.5 to [41 x [41 x i8]]*
  %scevgep41.13.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3184, i64 0, i64 1, i64 0
  %3191 = bitcast i8* %scevgep41.13.5 to [41 x [41 x i8]]*
  %call16.13.6 = call zeroext i8 (...) @rand()
  store i8 %call16.13.6, i8* %scevgep28.13.5, align 1
  %3192 = load i8, i8* %scevgep28.13.5, align 1
  %conv23.13.6 = zext i8 %3192 to i32
  %3193 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.6 = getelementptr i8, i8* %b, i64 20
  %3194 = load i8, i8* %scevgep34.13.6, align 1
  %call28.13.6 = call zeroext i8 @mult(i8 zeroext %3193, i8 zeroext %3194)
  %conv29.13.6 = zext i8 %call28.13.6 to i32
  %xor.13.6 = xor i32 %conv23.13.6, %conv29.13.6
  %scevgep35.13.6 = getelementptr i8, i8* %a, i64 20
  %3195 = load i8, i8* %scevgep35.13.6, align 1
  %3196 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.6 = call zeroext i8 @mult(i8 zeroext %3195, i8 zeroext %3196)
  %conv35.13.6 = zext i8 %call34.13.6 to i32
  %xor36.13.6 = xor i32 %xor.13.6, %conv35.13.6
  %conv37.13.6 = trunc i32 %xor36.13.6 to i8
  store i8 %conv37.13.6, i8* %scevgep41.13.5, align 1
  %scevgep28.13.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3190, i64 0, i64 0, i64 1
  %3197 = bitcast i8* %scevgep28.13.6 to [41 x [41 x i8]]*
  %scevgep41.13.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3191, i64 0, i64 1, i64 0
  %3198 = bitcast i8* %scevgep41.13.6 to [41 x [41 x i8]]*
  %call16.13.7 = call zeroext i8 (...) @rand()
  store i8 %call16.13.7, i8* %scevgep28.13.6, align 1
  %3199 = load i8, i8* %scevgep28.13.6, align 1
  %conv23.13.7 = zext i8 %3199 to i32
  %3200 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.7 = getelementptr i8, i8* %b, i64 21
  %3201 = load i8, i8* %scevgep34.13.7, align 1
  %call28.13.7 = call zeroext i8 @mult(i8 zeroext %3200, i8 zeroext %3201)
  %conv29.13.7 = zext i8 %call28.13.7 to i32
  %xor.13.7 = xor i32 %conv23.13.7, %conv29.13.7
  %scevgep35.13.7 = getelementptr i8, i8* %a, i64 21
  %3202 = load i8, i8* %scevgep35.13.7, align 1
  %3203 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.7 = call zeroext i8 @mult(i8 zeroext %3202, i8 zeroext %3203)
  %conv35.13.7 = zext i8 %call34.13.7 to i32
  %xor36.13.7 = xor i32 %xor.13.7, %conv35.13.7
  %conv37.13.7 = trunc i32 %xor36.13.7 to i8
  store i8 %conv37.13.7, i8* %scevgep41.13.6, align 1
  %scevgep28.13.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3197, i64 0, i64 0, i64 1
  %3204 = bitcast i8* %scevgep28.13.7 to [41 x [41 x i8]]*
  %scevgep41.13.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3198, i64 0, i64 1, i64 0
  %3205 = bitcast i8* %scevgep41.13.7 to [41 x [41 x i8]]*
  %call16.13.8 = call zeroext i8 (...) @rand()
  store i8 %call16.13.8, i8* %scevgep28.13.7, align 1
  %3206 = load i8, i8* %scevgep28.13.7, align 1
  %conv23.13.8 = zext i8 %3206 to i32
  %3207 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.8 = getelementptr i8, i8* %b, i64 22
  %3208 = load i8, i8* %scevgep34.13.8, align 1
  %call28.13.8 = call zeroext i8 @mult(i8 zeroext %3207, i8 zeroext %3208)
  %conv29.13.8 = zext i8 %call28.13.8 to i32
  %xor.13.8 = xor i32 %conv23.13.8, %conv29.13.8
  %scevgep35.13.8 = getelementptr i8, i8* %a, i64 22
  %3209 = load i8, i8* %scevgep35.13.8, align 1
  %3210 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.8 = call zeroext i8 @mult(i8 zeroext %3209, i8 zeroext %3210)
  %conv35.13.8 = zext i8 %call34.13.8 to i32
  %xor36.13.8 = xor i32 %xor.13.8, %conv35.13.8
  %conv37.13.8 = trunc i32 %xor36.13.8 to i8
  store i8 %conv37.13.8, i8* %scevgep41.13.7, align 1
  %scevgep28.13.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3204, i64 0, i64 0, i64 1
  %3211 = bitcast i8* %scevgep28.13.8 to [41 x [41 x i8]]*
  %scevgep41.13.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3205, i64 0, i64 1, i64 0
  %3212 = bitcast i8* %scevgep41.13.8 to [41 x [41 x i8]]*
  %call16.13.9 = call zeroext i8 (...) @rand()
  store i8 %call16.13.9, i8* %scevgep28.13.8, align 1
  %3213 = load i8, i8* %scevgep28.13.8, align 1
  %conv23.13.9 = zext i8 %3213 to i32
  %3214 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.9 = getelementptr i8, i8* %b, i64 23
  %3215 = load i8, i8* %scevgep34.13.9, align 1
  %call28.13.9 = call zeroext i8 @mult(i8 zeroext %3214, i8 zeroext %3215)
  %conv29.13.9 = zext i8 %call28.13.9 to i32
  %xor.13.9 = xor i32 %conv23.13.9, %conv29.13.9
  %scevgep35.13.9 = getelementptr i8, i8* %a, i64 23
  %3216 = load i8, i8* %scevgep35.13.9, align 1
  %3217 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.9 = call zeroext i8 @mult(i8 zeroext %3216, i8 zeroext %3217)
  %conv35.13.9 = zext i8 %call34.13.9 to i32
  %xor36.13.9 = xor i32 %xor.13.9, %conv35.13.9
  %conv37.13.9 = trunc i32 %xor36.13.9 to i8
  store i8 %conv37.13.9, i8* %scevgep41.13.8, align 1
  %scevgep28.13.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3211, i64 0, i64 0, i64 1
  %3218 = bitcast i8* %scevgep28.13.9 to [41 x [41 x i8]]*
  %scevgep41.13.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3212, i64 0, i64 1, i64 0
  %3219 = bitcast i8* %scevgep41.13.9 to [41 x [41 x i8]]*
  %call16.13.10 = call zeroext i8 (...) @rand()
  store i8 %call16.13.10, i8* %scevgep28.13.9, align 1
  %3220 = load i8, i8* %scevgep28.13.9, align 1
  %conv23.13.10 = zext i8 %3220 to i32
  %3221 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.10 = getelementptr i8, i8* %b, i64 24
  %3222 = load i8, i8* %scevgep34.13.10, align 1
  %call28.13.10 = call zeroext i8 @mult(i8 zeroext %3221, i8 zeroext %3222)
  %conv29.13.10 = zext i8 %call28.13.10 to i32
  %xor.13.10 = xor i32 %conv23.13.10, %conv29.13.10
  %scevgep35.13.10 = getelementptr i8, i8* %a, i64 24
  %3223 = load i8, i8* %scevgep35.13.10, align 1
  %3224 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.10 = call zeroext i8 @mult(i8 zeroext %3223, i8 zeroext %3224)
  %conv35.13.10 = zext i8 %call34.13.10 to i32
  %xor36.13.10 = xor i32 %xor.13.10, %conv35.13.10
  %conv37.13.10 = trunc i32 %xor36.13.10 to i8
  store i8 %conv37.13.10, i8* %scevgep41.13.9, align 1
  %scevgep28.13.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3218, i64 0, i64 0, i64 1
  %3225 = bitcast i8* %scevgep28.13.10 to [41 x [41 x i8]]*
  %scevgep41.13.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3219, i64 0, i64 1, i64 0
  %3226 = bitcast i8* %scevgep41.13.10 to [41 x [41 x i8]]*
  %call16.13.11 = call zeroext i8 (...) @rand()
  store i8 %call16.13.11, i8* %scevgep28.13.10, align 1
  %3227 = load i8, i8* %scevgep28.13.10, align 1
  %conv23.13.11 = zext i8 %3227 to i32
  %3228 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.11 = getelementptr i8, i8* %b, i64 25
  %3229 = load i8, i8* %scevgep34.13.11, align 1
  %call28.13.11 = call zeroext i8 @mult(i8 zeroext %3228, i8 zeroext %3229)
  %conv29.13.11 = zext i8 %call28.13.11 to i32
  %xor.13.11 = xor i32 %conv23.13.11, %conv29.13.11
  %scevgep35.13.11 = getelementptr i8, i8* %a, i64 25
  %3230 = load i8, i8* %scevgep35.13.11, align 1
  %3231 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.11 = call zeroext i8 @mult(i8 zeroext %3230, i8 zeroext %3231)
  %conv35.13.11 = zext i8 %call34.13.11 to i32
  %xor36.13.11 = xor i32 %xor.13.11, %conv35.13.11
  %conv37.13.11 = trunc i32 %xor36.13.11 to i8
  store i8 %conv37.13.11, i8* %scevgep41.13.10, align 1
  %scevgep28.13.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3225, i64 0, i64 0, i64 1
  %3232 = bitcast i8* %scevgep28.13.11 to [41 x [41 x i8]]*
  %scevgep41.13.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3226, i64 0, i64 1, i64 0
  %3233 = bitcast i8* %scevgep41.13.11 to [41 x [41 x i8]]*
  %call16.13.12 = call zeroext i8 (...) @rand()
  store i8 %call16.13.12, i8* %scevgep28.13.11, align 1
  %3234 = load i8, i8* %scevgep28.13.11, align 1
  %conv23.13.12 = zext i8 %3234 to i32
  %3235 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.12 = getelementptr i8, i8* %b, i64 26
  %3236 = load i8, i8* %scevgep34.13.12, align 1
  %call28.13.12 = call zeroext i8 @mult(i8 zeroext %3235, i8 zeroext %3236)
  %conv29.13.12 = zext i8 %call28.13.12 to i32
  %xor.13.12 = xor i32 %conv23.13.12, %conv29.13.12
  %scevgep35.13.12 = getelementptr i8, i8* %a, i64 26
  %3237 = load i8, i8* %scevgep35.13.12, align 1
  %3238 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.12 = call zeroext i8 @mult(i8 zeroext %3237, i8 zeroext %3238)
  %conv35.13.12 = zext i8 %call34.13.12 to i32
  %xor36.13.12 = xor i32 %xor.13.12, %conv35.13.12
  %conv37.13.12 = trunc i32 %xor36.13.12 to i8
  store i8 %conv37.13.12, i8* %scevgep41.13.11, align 1
  %scevgep28.13.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3232, i64 0, i64 0, i64 1
  %3239 = bitcast i8* %scevgep28.13.12 to [41 x [41 x i8]]*
  %scevgep41.13.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3233, i64 0, i64 1, i64 0
  %3240 = bitcast i8* %scevgep41.13.12 to [41 x [41 x i8]]*
  %call16.13.13 = call zeroext i8 (...) @rand()
  store i8 %call16.13.13, i8* %scevgep28.13.12, align 1
  %3241 = load i8, i8* %scevgep28.13.12, align 1
  %conv23.13.13 = zext i8 %3241 to i32
  %3242 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.13 = getelementptr i8, i8* %b, i64 27
  %3243 = load i8, i8* %scevgep34.13.13, align 1
  %call28.13.13 = call zeroext i8 @mult(i8 zeroext %3242, i8 zeroext %3243)
  %conv29.13.13 = zext i8 %call28.13.13 to i32
  %xor.13.13 = xor i32 %conv23.13.13, %conv29.13.13
  %scevgep35.13.13 = getelementptr i8, i8* %a, i64 27
  %3244 = load i8, i8* %scevgep35.13.13, align 1
  %3245 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.13 = call zeroext i8 @mult(i8 zeroext %3244, i8 zeroext %3245)
  %conv35.13.13 = zext i8 %call34.13.13 to i32
  %xor36.13.13 = xor i32 %xor.13.13, %conv35.13.13
  %conv37.13.13 = trunc i32 %xor36.13.13 to i8
  store i8 %conv37.13.13, i8* %scevgep41.13.12, align 1
  %scevgep28.13.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3239, i64 0, i64 0, i64 1
  %3246 = bitcast i8* %scevgep28.13.13 to [41 x [41 x i8]]*
  %scevgep41.13.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3240, i64 0, i64 1, i64 0
  %3247 = bitcast i8* %scevgep41.13.13 to [41 x [41 x i8]]*
  %call16.13.14 = call zeroext i8 (...) @rand()
  store i8 %call16.13.14, i8* %scevgep28.13.13, align 1
  %3248 = load i8, i8* %scevgep28.13.13, align 1
  %conv23.13.14 = zext i8 %3248 to i32
  %3249 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.14 = getelementptr i8, i8* %b, i64 28
  %3250 = load i8, i8* %scevgep34.13.14, align 1
  %call28.13.14 = call zeroext i8 @mult(i8 zeroext %3249, i8 zeroext %3250)
  %conv29.13.14 = zext i8 %call28.13.14 to i32
  %xor.13.14 = xor i32 %conv23.13.14, %conv29.13.14
  %scevgep35.13.14 = getelementptr i8, i8* %a, i64 28
  %3251 = load i8, i8* %scevgep35.13.14, align 1
  %3252 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.14 = call zeroext i8 @mult(i8 zeroext %3251, i8 zeroext %3252)
  %conv35.13.14 = zext i8 %call34.13.14 to i32
  %xor36.13.14 = xor i32 %xor.13.14, %conv35.13.14
  %conv37.13.14 = trunc i32 %xor36.13.14 to i8
  store i8 %conv37.13.14, i8* %scevgep41.13.13, align 1
  %scevgep28.13.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3246, i64 0, i64 0, i64 1
  %3253 = bitcast i8* %scevgep28.13.14 to [41 x [41 x i8]]*
  %scevgep41.13.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3247, i64 0, i64 1, i64 0
  %3254 = bitcast i8* %scevgep41.13.14 to [41 x [41 x i8]]*
  %call16.13.15 = call zeroext i8 (...) @rand()
  store i8 %call16.13.15, i8* %scevgep28.13.14, align 1
  %3255 = load i8, i8* %scevgep28.13.14, align 1
  %conv23.13.15 = zext i8 %3255 to i32
  %3256 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.15 = getelementptr i8, i8* %b, i64 29
  %3257 = load i8, i8* %scevgep34.13.15, align 1
  %call28.13.15 = call zeroext i8 @mult(i8 zeroext %3256, i8 zeroext %3257)
  %conv29.13.15 = zext i8 %call28.13.15 to i32
  %xor.13.15 = xor i32 %conv23.13.15, %conv29.13.15
  %scevgep35.13.15 = getelementptr i8, i8* %a, i64 29
  %3258 = load i8, i8* %scevgep35.13.15, align 1
  %3259 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.15 = call zeroext i8 @mult(i8 zeroext %3258, i8 zeroext %3259)
  %conv35.13.15 = zext i8 %call34.13.15 to i32
  %xor36.13.15 = xor i32 %xor.13.15, %conv35.13.15
  %conv37.13.15 = trunc i32 %xor36.13.15 to i8
  store i8 %conv37.13.15, i8* %scevgep41.13.14, align 1
  %scevgep28.13.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3253, i64 0, i64 0, i64 1
  %3260 = bitcast i8* %scevgep28.13.15 to [41 x [41 x i8]]*
  %scevgep41.13.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3254, i64 0, i64 1, i64 0
  %3261 = bitcast i8* %scevgep41.13.15 to [41 x [41 x i8]]*
  %call16.13.16 = call zeroext i8 (...) @rand()
  store i8 %call16.13.16, i8* %scevgep28.13.15, align 1
  %3262 = load i8, i8* %scevgep28.13.15, align 1
  %conv23.13.16 = zext i8 %3262 to i32
  %3263 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.16 = getelementptr i8, i8* %b, i64 30
  %3264 = load i8, i8* %scevgep34.13.16, align 1
  %call28.13.16 = call zeroext i8 @mult(i8 zeroext %3263, i8 zeroext %3264)
  %conv29.13.16 = zext i8 %call28.13.16 to i32
  %xor.13.16 = xor i32 %conv23.13.16, %conv29.13.16
  %scevgep35.13.16 = getelementptr i8, i8* %a, i64 30
  %3265 = load i8, i8* %scevgep35.13.16, align 1
  %3266 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.16 = call zeroext i8 @mult(i8 zeroext %3265, i8 zeroext %3266)
  %conv35.13.16 = zext i8 %call34.13.16 to i32
  %xor36.13.16 = xor i32 %xor.13.16, %conv35.13.16
  %conv37.13.16 = trunc i32 %xor36.13.16 to i8
  store i8 %conv37.13.16, i8* %scevgep41.13.15, align 1
  %scevgep28.13.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3260, i64 0, i64 0, i64 1
  %3267 = bitcast i8* %scevgep28.13.16 to [41 x [41 x i8]]*
  %scevgep41.13.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3261, i64 0, i64 1, i64 0
  %3268 = bitcast i8* %scevgep41.13.16 to [41 x [41 x i8]]*
  %call16.13.17 = call zeroext i8 (...) @rand()
  store i8 %call16.13.17, i8* %scevgep28.13.16, align 1
  %3269 = load i8, i8* %scevgep28.13.16, align 1
  %conv23.13.17 = zext i8 %3269 to i32
  %3270 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.17 = getelementptr i8, i8* %b, i64 31
  %3271 = load i8, i8* %scevgep34.13.17, align 1
  %call28.13.17 = call zeroext i8 @mult(i8 zeroext %3270, i8 zeroext %3271)
  %conv29.13.17 = zext i8 %call28.13.17 to i32
  %xor.13.17 = xor i32 %conv23.13.17, %conv29.13.17
  %scevgep35.13.17 = getelementptr i8, i8* %a, i64 31
  %3272 = load i8, i8* %scevgep35.13.17, align 1
  %3273 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.17 = call zeroext i8 @mult(i8 zeroext %3272, i8 zeroext %3273)
  %conv35.13.17 = zext i8 %call34.13.17 to i32
  %xor36.13.17 = xor i32 %xor.13.17, %conv35.13.17
  %conv37.13.17 = trunc i32 %xor36.13.17 to i8
  store i8 %conv37.13.17, i8* %scevgep41.13.16, align 1
  %scevgep28.13.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3267, i64 0, i64 0, i64 1
  %3274 = bitcast i8* %scevgep28.13.17 to [41 x [41 x i8]]*
  %scevgep41.13.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3268, i64 0, i64 1, i64 0
  %3275 = bitcast i8* %scevgep41.13.17 to [41 x [41 x i8]]*
  %call16.13.18 = call zeroext i8 (...) @rand()
  store i8 %call16.13.18, i8* %scevgep28.13.17, align 1
  %3276 = load i8, i8* %scevgep28.13.17, align 1
  %conv23.13.18 = zext i8 %3276 to i32
  %3277 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.18 = getelementptr i8, i8* %b, i64 32
  %3278 = load i8, i8* %scevgep34.13.18, align 1
  %call28.13.18 = call zeroext i8 @mult(i8 zeroext %3277, i8 zeroext %3278)
  %conv29.13.18 = zext i8 %call28.13.18 to i32
  %xor.13.18 = xor i32 %conv23.13.18, %conv29.13.18
  %scevgep35.13.18 = getelementptr i8, i8* %a, i64 32
  %3279 = load i8, i8* %scevgep35.13.18, align 1
  %3280 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.18 = call zeroext i8 @mult(i8 zeroext %3279, i8 zeroext %3280)
  %conv35.13.18 = zext i8 %call34.13.18 to i32
  %xor36.13.18 = xor i32 %xor.13.18, %conv35.13.18
  %conv37.13.18 = trunc i32 %xor36.13.18 to i8
  store i8 %conv37.13.18, i8* %scevgep41.13.17, align 1
  %scevgep28.13.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3274, i64 0, i64 0, i64 1
  %3281 = bitcast i8* %scevgep28.13.18 to [41 x [41 x i8]]*
  %scevgep41.13.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3275, i64 0, i64 1, i64 0
  %3282 = bitcast i8* %scevgep41.13.18 to [41 x [41 x i8]]*
  %call16.13.19 = call zeroext i8 (...) @rand()
  store i8 %call16.13.19, i8* %scevgep28.13.18, align 1
  %3283 = load i8, i8* %scevgep28.13.18, align 1
  %conv23.13.19 = zext i8 %3283 to i32
  %3284 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.19 = getelementptr i8, i8* %b, i64 33
  %3285 = load i8, i8* %scevgep34.13.19, align 1
  %call28.13.19 = call zeroext i8 @mult(i8 zeroext %3284, i8 zeroext %3285)
  %conv29.13.19 = zext i8 %call28.13.19 to i32
  %xor.13.19 = xor i32 %conv23.13.19, %conv29.13.19
  %scevgep35.13.19 = getelementptr i8, i8* %a, i64 33
  %3286 = load i8, i8* %scevgep35.13.19, align 1
  %3287 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.19 = call zeroext i8 @mult(i8 zeroext %3286, i8 zeroext %3287)
  %conv35.13.19 = zext i8 %call34.13.19 to i32
  %xor36.13.19 = xor i32 %xor.13.19, %conv35.13.19
  %conv37.13.19 = trunc i32 %xor36.13.19 to i8
  store i8 %conv37.13.19, i8* %scevgep41.13.18, align 1
  %scevgep28.13.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3281, i64 0, i64 0, i64 1
  %3288 = bitcast i8* %scevgep28.13.19 to [41 x [41 x i8]]*
  %scevgep41.13.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3282, i64 0, i64 1, i64 0
  %3289 = bitcast i8* %scevgep41.13.19 to [41 x [41 x i8]]*
  %call16.13.20 = call zeroext i8 (...) @rand()
  store i8 %call16.13.20, i8* %scevgep28.13.19, align 1
  %3290 = load i8, i8* %scevgep28.13.19, align 1
  %conv23.13.20 = zext i8 %3290 to i32
  %3291 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.20 = getelementptr i8, i8* %b, i64 34
  %3292 = load i8, i8* %scevgep34.13.20, align 1
  %call28.13.20 = call zeroext i8 @mult(i8 zeroext %3291, i8 zeroext %3292)
  %conv29.13.20 = zext i8 %call28.13.20 to i32
  %xor.13.20 = xor i32 %conv23.13.20, %conv29.13.20
  %scevgep35.13.20 = getelementptr i8, i8* %a, i64 34
  %3293 = load i8, i8* %scevgep35.13.20, align 1
  %3294 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.20 = call zeroext i8 @mult(i8 zeroext %3293, i8 zeroext %3294)
  %conv35.13.20 = zext i8 %call34.13.20 to i32
  %xor36.13.20 = xor i32 %xor.13.20, %conv35.13.20
  %conv37.13.20 = trunc i32 %xor36.13.20 to i8
  store i8 %conv37.13.20, i8* %scevgep41.13.19, align 1
  %scevgep28.13.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3288, i64 0, i64 0, i64 1
  %3295 = bitcast i8* %scevgep28.13.20 to [41 x [41 x i8]]*
  %scevgep41.13.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3289, i64 0, i64 1, i64 0
  %3296 = bitcast i8* %scevgep41.13.20 to [41 x [41 x i8]]*
  %call16.13.21 = call zeroext i8 (...) @rand()
  store i8 %call16.13.21, i8* %scevgep28.13.20, align 1
  %3297 = load i8, i8* %scevgep28.13.20, align 1
  %conv23.13.21 = zext i8 %3297 to i32
  %3298 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.21 = getelementptr i8, i8* %b, i64 35
  %3299 = load i8, i8* %scevgep34.13.21, align 1
  %call28.13.21 = call zeroext i8 @mult(i8 zeroext %3298, i8 zeroext %3299)
  %conv29.13.21 = zext i8 %call28.13.21 to i32
  %xor.13.21 = xor i32 %conv23.13.21, %conv29.13.21
  %scevgep35.13.21 = getelementptr i8, i8* %a, i64 35
  %3300 = load i8, i8* %scevgep35.13.21, align 1
  %3301 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.21 = call zeroext i8 @mult(i8 zeroext %3300, i8 zeroext %3301)
  %conv35.13.21 = zext i8 %call34.13.21 to i32
  %xor36.13.21 = xor i32 %xor.13.21, %conv35.13.21
  %conv37.13.21 = trunc i32 %xor36.13.21 to i8
  store i8 %conv37.13.21, i8* %scevgep41.13.20, align 1
  %scevgep28.13.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3295, i64 0, i64 0, i64 1
  %3302 = bitcast i8* %scevgep28.13.21 to [41 x [41 x i8]]*
  %scevgep41.13.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3296, i64 0, i64 1, i64 0
  %3303 = bitcast i8* %scevgep41.13.21 to [41 x [41 x i8]]*
  %call16.13.22 = call zeroext i8 (...) @rand()
  store i8 %call16.13.22, i8* %scevgep28.13.21, align 1
  %3304 = load i8, i8* %scevgep28.13.21, align 1
  %conv23.13.22 = zext i8 %3304 to i32
  %3305 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.22 = getelementptr i8, i8* %b, i64 36
  %3306 = load i8, i8* %scevgep34.13.22, align 1
  %call28.13.22 = call zeroext i8 @mult(i8 zeroext %3305, i8 zeroext %3306)
  %conv29.13.22 = zext i8 %call28.13.22 to i32
  %xor.13.22 = xor i32 %conv23.13.22, %conv29.13.22
  %scevgep35.13.22 = getelementptr i8, i8* %a, i64 36
  %3307 = load i8, i8* %scevgep35.13.22, align 1
  %3308 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.22 = call zeroext i8 @mult(i8 zeroext %3307, i8 zeroext %3308)
  %conv35.13.22 = zext i8 %call34.13.22 to i32
  %xor36.13.22 = xor i32 %xor.13.22, %conv35.13.22
  %conv37.13.22 = trunc i32 %xor36.13.22 to i8
  store i8 %conv37.13.22, i8* %scevgep41.13.21, align 1
  %scevgep28.13.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3302, i64 0, i64 0, i64 1
  %3309 = bitcast i8* %scevgep28.13.22 to [41 x [41 x i8]]*
  %scevgep41.13.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3303, i64 0, i64 1, i64 0
  %3310 = bitcast i8* %scevgep41.13.22 to [41 x [41 x i8]]*
  %call16.13.23 = call zeroext i8 (...) @rand()
  store i8 %call16.13.23, i8* %scevgep28.13.22, align 1
  %3311 = load i8, i8* %scevgep28.13.22, align 1
  %conv23.13.23 = zext i8 %3311 to i32
  %3312 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.23 = getelementptr i8, i8* %b, i64 37
  %3313 = load i8, i8* %scevgep34.13.23, align 1
  %call28.13.23 = call zeroext i8 @mult(i8 zeroext %3312, i8 zeroext %3313)
  %conv29.13.23 = zext i8 %call28.13.23 to i32
  %xor.13.23 = xor i32 %conv23.13.23, %conv29.13.23
  %scevgep35.13.23 = getelementptr i8, i8* %a, i64 37
  %3314 = load i8, i8* %scevgep35.13.23, align 1
  %3315 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.23 = call zeroext i8 @mult(i8 zeroext %3314, i8 zeroext %3315)
  %conv35.13.23 = zext i8 %call34.13.23 to i32
  %xor36.13.23 = xor i32 %xor.13.23, %conv35.13.23
  %conv37.13.23 = trunc i32 %xor36.13.23 to i8
  store i8 %conv37.13.23, i8* %scevgep41.13.22, align 1
  %scevgep28.13.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3309, i64 0, i64 0, i64 1
  %3316 = bitcast i8* %scevgep28.13.23 to [41 x [41 x i8]]*
  %scevgep41.13.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3310, i64 0, i64 1, i64 0
  %3317 = bitcast i8* %scevgep41.13.23 to [41 x [41 x i8]]*
  %call16.13.24 = call zeroext i8 (...) @rand()
  store i8 %call16.13.24, i8* %scevgep28.13.23, align 1
  %3318 = load i8, i8* %scevgep28.13.23, align 1
  %conv23.13.24 = zext i8 %3318 to i32
  %3319 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.24 = getelementptr i8, i8* %b, i64 38
  %3320 = load i8, i8* %scevgep34.13.24, align 1
  %call28.13.24 = call zeroext i8 @mult(i8 zeroext %3319, i8 zeroext %3320)
  %conv29.13.24 = zext i8 %call28.13.24 to i32
  %xor.13.24 = xor i32 %conv23.13.24, %conv29.13.24
  %scevgep35.13.24 = getelementptr i8, i8* %a, i64 38
  %3321 = load i8, i8* %scevgep35.13.24, align 1
  %3322 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.24 = call zeroext i8 @mult(i8 zeroext %3321, i8 zeroext %3322)
  %conv35.13.24 = zext i8 %call34.13.24 to i32
  %xor36.13.24 = xor i32 %xor.13.24, %conv35.13.24
  %conv37.13.24 = trunc i32 %xor36.13.24 to i8
  store i8 %conv37.13.24, i8* %scevgep41.13.23, align 1
  %scevgep28.13.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3316, i64 0, i64 0, i64 1
  %3323 = bitcast i8* %scevgep28.13.24 to [41 x [41 x i8]]*
  %scevgep41.13.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3317, i64 0, i64 1, i64 0
  %3324 = bitcast i8* %scevgep41.13.24 to [41 x [41 x i8]]*
  %call16.13.25 = call zeroext i8 (...) @rand()
  store i8 %call16.13.25, i8* %scevgep28.13.24, align 1
  %3325 = load i8, i8* %scevgep28.13.24, align 1
  %conv23.13.25 = zext i8 %3325 to i32
  %3326 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.25 = getelementptr i8, i8* %b, i64 39
  %3327 = load i8, i8* %scevgep34.13.25, align 1
  %call28.13.25 = call zeroext i8 @mult(i8 zeroext %3326, i8 zeroext %3327)
  %conv29.13.25 = zext i8 %call28.13.25 to i32
  %xor.13.25 = xor i32 %conv23.13.25, %conv29.13.25
  %scevgep35.13.25 = getelementptr i8, i8* %a, i64 39
  %3328 = load i8, i8* %scevgep35.13.25, align 1
  %3329 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.25 = call zeroext i8 @mult(i8 zeroext %3328, i8 zeroext %3329)
  %conv35.13.25 = zext i8 %call34.13.25 to i32
  %xor36.13.25 = xor i32 %xor.13.25, %conv35.13.25
  %conv37.13.25 = trunc i32 %xor36.13.25 to i8
  store i8 %conv37.13.25, i8* %scevgep41.13.24, align 1
  %scevgep28.13.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3323, i64 0, i64 0, i64 1
  %scevgep41.13.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3324, i64 0, i64 1, i64 0
  %call16.13.26 = call zeroext i8 (...) @rand()
  store i8 %call16.13.26, i8* %scevgep28.13.25, align 1
  %3330 = load i8, i8* %scevgep28.13.25, align 1
  %conv23.13.26 = zext i8 %3330 to i32
  %3331 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.26 = getelementptr i8, i8* %b, i64 40
  %3332 = load i8, i8* %scevgep34.13.26, align 1
  %call28.13.26 = call zeroext i8 @mult(i8 zeroext %3331, i8 zeroext %3332)
  %conv29.13.26 = zext i8 %call28.13.26 to i32
  %xor.13.26 = xor i32 %conv23.13.26, %conv29.13.26
  %scevgep35.13.26 = getelementptr i8, i8* %a, i64 40
  %3333 = load i8, i8* %scevgep35.13.26, align 1
  %3334 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.26 = call zeroext i8 @mult(i8 zeroext %3333, i8 zeroext %3334)
  %conv35.13.26 = zext i8 %call34.13.26 to i32
  %xor36.13.26 = xor i32 %xor.13.26, %conv35.13.26
  %conv37.13.26 = trunc i32 %xor36.13.26 to i8
  store i8 %conv37.13.26, i8* %scevgep41.13.25, align 1
  %scevgep26.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3148, i64 0, i64 1, i64 1
  %3335 = bitcast i8* %scevgep26.13 to [41 x [41 x i8]]*
  %scevgep39.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3149, i64 0, i64 1, i64 1
  %3336 = bitcast i8* %scevgep39.13 to [41 x [41 x i8]]*
  %arrayidx25.14 = getelementptr inbounds i8, i8* %a, i64 14
  %arrayidx33.14 = getelementptr inbounds i8, i8* %b, i64 14
  %call16.14 = call zeroext i8 (...) @rand()
  store i8 %call16.14, i8* %scevgep26.13, align 1
  %3337 = load i8, i8* %scevgep26.13, align 1
  %conv23.14 = zext i8 %3337 to i32
  %3338 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14 = getelementptr i8, i8* %b, i64 15
  %3339 = load i8, i8* %scevgep34.14, align 1
  %call28.14 = call zeroext i8 @mult(i8 zeroext %3338, i8 zeroext %3339)
  %conv29.14 = zext i8 %call28.14 to i32
  %xor.14 = xor i32 %conv23.14, %conv29.14
  %scevgep35.14 = getelementptr i8, i8* %a, i64 15
  %3340 = load i8, i8* %scevgep35.14, align 1
  %3341 = load i8, i8* %arrayidx33.14, align 1
  %call34.14 = call zeroext i8 @mult(i8 zeroext %3340, i8 zeroext %3341)
  %conv35.14 = zext i8 %call34.14 to i32
  %xor36.14 = xor i32 %xor.14, %conv35.14
  %conv37.14 = trunc i32 %xor36.14 to i8
  store i8 %conv37.14, i8* %scevgep39.13, align 1
  %scevgep28.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3335, i64 0, i64 0, i64 1
  %3342 = bitcast i8* %scevgep28.14 to [41 x [41 x i8]]*
  %scevgep41.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3336, i64 0, i64 1, i64 0
  %3343 = bitcast i8* %scevgep41.14 to [41 x [41 x i8]]*
  %call16.14.1 = call zeroext i8 (...) @rand()
  store i8 %call16.14.1, i8* %scevgep28.14, align 1
  %3344 = load i8, i8* %scevgep28.14, align 1
  %conv23.14.1 = zext i8 %3344 to i32
  %3345 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.1 = getelementptr i8, i8* %b, i64 16
  %3346 = load i8, i8* %scevgep34.14.1, align 1
  %call28.14.1 = call zeroext i8 @mult(i8 zeroext %3345, i8 zeroext %3346)
  %conv29.14.1 = zext i8 %call28.14.1 to i32
  %xor.14.1 = xor i32 %conv23.14.1, %conv29.14.1
  %scevgep35.14.1 = getelementptr i8, i8* %a, i64 16
  %3347 = load i8, i8* %scevgep35.14.1, align 1
  %3348 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.1 = call zeroext i8 @mult(i8 zeroext %3347, i8 zeroext %3348)
  %conv35.14.1 = zext i8 %call34.14.1 to i32
  %xor36.14.1 = xor i32 %xor.14.1, %conv35.14.1
  %conv37.14.1 = trunc i32 %xor36.14.1 to i8
  store i8 %conv37.14.1, i8* %scevgep41.14, align 1
  %scevgep28.14.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3342, i64 0, i64 0, i64 1
  %3349 = bitcast i8* %scevgep28.14.1 to [41 x [41 x i8]]*
  %scevgep41.14.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3343, i64 0, i64 1, i64 0
  %3350 = bitcast i8* %scevgep41.14.1 to [41 x [41 x i8]]*
  %call16.14.2 = call zeroext i8 (...) @rand()
  store i8 %call16.14.2, i8* %scevgep28.14.1, align 1
  %3351 = load i8, i8* %scevgep28.14.1, align 1
  %conv23.14.2 = zext i8 %3351 to i32
  %3352 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.2 = getelementptr i8, i8* %b, i64 17
  %3353 = load i8, i8* %scevgep34.14.2, align 1
  %call28.14.2 = call zeroext i8 @mult(i8 zeroext %3352, i8 zeroext %3353)
  %conv29.14.2 = zext i8 %call28.14.2 to i32
  %xor.14.2 = xor i32 %conv23.14.2, %conv29.14.2
  %scevgep35.14.2 = getelementptr i8, i8* %a, i64 17
  %3354 = load i8, i8* %scevgep35.14.2, align 1
  %3355 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.2 = call zeroext i8 @mult(i8 zeroext %3354, i8 zeroext %3355)
  %conv35.14.2 = zext i8 %call34.14.2 to i32
  %xor36.14.2 = xor i32 %xor.14.2, %conv35.14.2
  %conv37.14.2 = trunc i32 %xor36.14.2 to i8
  store i8 %conv37.14.2, i8* %scevgep41.14.1, align 1
  %scevgep28.14.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3349, i64 0, i64 0, i64 1
  %3356 = bitcast i8* %scevgep28.14.2 to [41 x [41 x i8]]*
  %scevgep41.14.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3350, i64 0, i64 1, i64 0
  %3357 = bitcast i8* %scevgep41.14.2 to [41 x [41 x i8]]*
  %call16.14.3 = call zeroext i8 (...) @rand()
  store i8 %call16.14.3, i8* %scevgep28.14.2, align 1
  %3358 = load i8, i8* %scevgep28.14.2, align 1
  %conv23.14.3 = zext i8 %3358 to i32
  %3359 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.3 = getelementptr i8, i8* %b, i64 18
  %3360 = load i8, i8* %scevgep34.14.3, align 1
  %call28.14.3 = call zeroext i8 @mult(i8 zeroext %3359, i8 zeroext %3360)
  %conv29.14.3 = zext i8 %call28.14.3 to i32
  %xor.14.3 = xor i32 %conv23.14.3, %conv29.14.3
  %scevgep35.14.3 = getelementptr i8, i8* %a, i64 18
  %3361 = load i8, i8* %scevgep35.14.3, align 1
  %3362 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.3 = call zeroext i8 @mult(i8 zeroext %3361, i8 zeroext %3362)
  %conv35.14.3 = zext i8 %call34.14.3 to i32
  %xor36.14.3 = xor i32 %xor.14.3, %conv35.14.3
  %conv37.14.3 = trunc i32 %xor36.14.3 to i8
  store i8 %conv37.14.3, i8* %scevgep41.14.2, align 1
  %scevgep28.14.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3356, i64 0, i64 0, i64 1
  %3363 = bitcast i8* %scevgep28.14.3 to [41 x [41 x i8]]*
  %scevgep41.14.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3357, i64 0, i64 1, i64 0
  %3364 = bitcast i8* %scevgep41.14.3 to [41 x [41 x i8]]*
  %call16.14.4 = call zeroext i8 (...) @rand()
  store i8 %call16.14.4, i8* %scevgep28.14.3, align 1
  %3365 = load i8, i8* %scevgep28.14.3, align 1
  %conv23.14.4 = zext i8 %3365 to i32
  %3366 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.4 = getelementptr i8, i8* %b, i64 19
  %3367 = load i8, i8* %scevgep34.14.4, align 1
  %call28.14.4 = call zeroext i8 @mult(i8 zeroext %3366, i8 zeroext %3367)
  %conv29.14.4 = zext i8 %call28.14.4 to i32
  %xor.14.4 = xor i32 %conv23.14.4, %conv29.14.4
  %scevgep35.14.4 = getelementptr i8, i8* %a, i64 19
  %3368 = load i8, i8* %scevgep35.14.4, align 1
  %3369 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.4 = call zeroext i8 @mult(i8 zeroext %3368, i8 zeroext %3369)
  %conv35.14.4 = zext i8 %call34.14.4 to i32
  %xor36.14.4 = xor i32 %xor.14.4, %conv35.14.4
  %conv37.14.4 = trunc i32 %xor36.14.4 to i8
  store i8 %conv37.14.4, i8* %scevgep41.14.3, align 1
  %scevgep28.14.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3363, i64 0, i64 0, i64 1
  %3370 = bitcast i8* %scevgep28.14.4 to [41 x [41 x i8]]*
  %scevgep41.14.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3364, i64 0, i64 1, i64 0
  %3371 = bitcast i8* %scevgep41.14.4 to [41 x [41 x i8]]*
  %call16.14.5 = call zeroext i8 (...) @rand()
  store i8 %call16.14.5, i8* %scevgep28.14.4, align 1
  %3372 = load i8, i8* %scevgep28.14.4, align 1
  %conv23.14.5 = zext i8 %3372 to i32
  %3373 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.5 = getelementptr i8, i8* %b, i64 20
  %3374 = load i8, i8* %scevgep34.14.5, align 1
  %call28.14.5 = call zeroext i8 @mult(i8 zeroext %3373, i8 zeroext %3374)
  %conv29.14.5 = zext i8 %call28.14.5 to i32
  %xor.14.5 = xor i32 %conv23.14.5, %conv29.14.5
  %scevgep35.14.5 = getelementptr i8, i8* %a, i64 20
  %3375 = load i8, i8* %scevgep35.14.5, align 1
  %3376 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.5 = call zeroext i8 @mult(i8 zeroext %3375, i8 zeroext %3376)
  %conv35.14.5 = zext i8 %call34.14.5 to i32
  %xor36.14.5 = xor i32 %xor.14.5, %conv35.14.5
  %conv37.14.5 = trunc i32 %xor36.14.5 to i8
  store i8 %conv37.14.5, i8* %scevgep41.14.4, align 1
  %scevgep28.14.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3370, i64 0, i64 0, i64 1
  %3377 = bitcast i8* %scevgep28.14.5 to [41 x [41 x i8]]*
  %scevgep41.14.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3371, i64 0, i64 1, i64 0
  %3378 = bitcast i8* %scevgep41.14.5 to [41 x [41 x i8]]*
  %call16.14.6 = call zeroext i8 (...) @rand()
  store i8 %call16.14.6, i8* %scevgep28.14.5, align 1
  %3379 = load i8, i8* %scevgep28.14.5, align 1
  %conv23.14.6 = zext i8 %3379 to i32
  %3380 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.6 = getelementptr i8, i8* %b, i64 21
  %3381 = load i8, i8* %scevgep34.14.6, align 1
  %call28.14.6 = call zeroext i8 @mult(i8 zeroext %3380, i8 zeroext %3381)
  %conv29.14.6 = zext i8 %call28.14.6 to i32
  %xor.14.6 = xor i32 %conv23.14.6, %conv29.14.6
  %scevgep35.14.6 = getelementptr i8, i8* %a, i64 21
  %3382 = load i8, i8* %scevgep35.14.6, align 1
  %3383 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.6 = call zeroext i8 @mult(i8 zeroext %3382, i8 zeroext %3383)
  %conv35.14.6 = zext i8 %call34.14.6 to i32
  %xor36.14.6 = xor i32 %xor.14.6, %conv35.14.6
  %conv37.14.6 = trunc i32 %xor36.14.6 to i8
  store i8 %conv37.14.6, i8* %scevgep41.14.5, align 1
  %scevgep28.14.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3377, i64 0, i64 0, i64 1
  %3384 = bitcast i8* %scevgep28.14.6 to [41 x [41 x i8]]*
  %scevgep41.14.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3378, i64 0, i64 1, i64 0
  %3385 = bitcast i8* %scevgep41.14.6 to [41 x [41 x i8]]*
  %call16.14.7 = call zeroext i8 (...) @rand()
  store i8 %call16.14.7, i8* %scevgep28.14.6, align 1
  %3386 = load i8, i8* %scevgep28.14.6, align 1
  %conv23.14.7 = zext i8 %3386 to i32
  %3387 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.7 = getelementptr i8, i8* %b, i64 22
  %3388 = load i8, i8* %scevgep34.14.7, align 1
  %call28.14.7 = call zeroext i8 @mult(i8 zeroext %3387, i8 zeroext %3388)
  %conv29.14.7 = zext i8 %call28.14.7 to i32
  %xor.14.7 = xor i32 %conv23.14.7, %conv29.14.7
  %scevgep35.14.7 = getelementptr i8, i8* %a, i64 22
  %3389 = load i8, i8* %scevgep35.14.7, align 1
  %3390 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.7 = call zeroext i8 @mult(i8 zeroext %3389, i8 zeroext %3390)
  %conv35.14.7 = zext i8 %call34.14.7 to i32
  %xor36.14.7 = xor i32 %xor.14.7, %conv35.14.7
  %conv37.14.7 = trunc i32 %xor36.14.7 to i8
  store i8 %conv37.14.7, i8* %scevgep41.14.6, align 1
  %scevgep28.14.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3384, i64 0, i64 0, i64 1
  %3391 = bitcast i8* %scevgep28.14.7 to [41 x [41 x i8]]*
  %scevgep41.14.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3385, i64 0, i64 1, i64 0
  %3392 = bitcast i8* %scevgep41.14.7 to [41 x [41 x i8]]*
  %call16.14.8 = call zeroext i8 (...) @rand()
  store i8 %call16.14.8, i8* %scevgep28.14.7, align 1
  %3393 = load i8, i8* %scevgep28.14.7, align 1
  %conv23.14.8 = zext i8 %3393 to i32
  %3394 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.8 = getelementptr i8, i8* %b, i64 23
  %3395 = load i8, i8* %scevgep34.14.8, align 1
  %call28.14.8 = call zeroext i8 @mult(i8 zeroext %3394, i8 zeroext %3395)
  %conv29.14.8 = zext i8 %call28.14.8 to i32
  %xor.14.8 = xor i32 %conv23.14.8, %conv29.14.8
  %scevgep35.14.8 = getelementptr i8, i8* %a, i64 23
  %3396 = load i8, i8* %scevgep35.14.8, align 1
  %3397 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.8 = call zeroext i8 @mult(i8 zeroext %3396, i8 zeroext %3397)
  %conv35.14.8 = zext i8 %call34.14.8 to i32
  %xor36.14.8 = xor i32 %xor.14.8, %conv35.14.8
  %conv37.14.8 = trunc i32 %xor36.14.8 to i8
  store i8 %conv37.14.8, i8* %scevgep41.14.7, align 1
  %scevgep28.14.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3391, i64 0, i64 0, i64 1
  %3398 = bitcast i8* %scevgep28.14.8 to [41 x [41 x i8]]*
  %scevgep41.14.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3392, i64 0, i64 1, i64 0
  %3399 = bitcast i8* %scevgep41.14.8 to [41 x [41 x i8]]*
  %call16.14.9 = call zeroext i8 (...) @rand()
  store i8 %call16.14.9, i8* %scevgep28.14.8, align 1
  %3400 = load i8, i8* %scevgep28.14.8, align 1
  %conv23.14.9 = zext i8 %3400 to i32
  %3401 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.9 = getelementptr i8, i8* %b, i64 24
  %3402 = load i8, i8* %scevgep34.14.9, align 1
  %call28.14.9 = call zeroext i8 @mult(i8 zeroext %3401, i8 zeroext %3402)
  %conv29.14.9 = zext i8 %call28.14.9 to i32
  %xor.14.9 = xor i32 %conv23.14.9, %conv29.14.9
  %scevgep35.14.9 = getelementptr i8, i8* %a, i64 24
  %3403 = load i8, i8* %scevgep35.14.9, align 1
  %3404 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.9 = call zeroext i8 @mult(i8 zeroext %3403, i8 zeroext %3404)
  %conv35.14.9 = zext i8 %call34.14.9 to i32
  %xor36.14.9 = xor i32 %xor.14.9, %conv35.14.9
  %conv37.14.9 = trunc i32 %xor36.14.9 to i8
  store i8 %conv37.14.9, i8* %scevgep41.14.8, align 1
  %scevgep28.14.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3398, i64 0, i64 0, i64 1
  %3405 = bitcast i8* %scevgep28.14.9 to [41 x [41 x i8]]*
  %scevgep41.14.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3399, i64 0, i64 1, i64 0
  %3406 = bitcast i8* %scevgep41.14.9 to [41 x [41 x i8]]*
  %call16.14.10 = call zeroext i8 (...) @rand()
  store i8 %call16.14.10, i8* %scevgep28.14.9, align 1
  %3407 = load i8, i8* %scevgep28.14.9, align 1
  %conv23.14.10 = zext i8 %3407 to i32
  %3408 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.10 = getelementptr i8, i8* %b, i64 25
  %3409 = load i8, i8* %scevgep34.14.10, align 1
  %call28.14.10 = call zeroext i8 @mult(i8 zeroext %3408, i8 zeroext %3409)
  %conv29.14.10 = zext i8 %call28.14.10 to i32
  %xor.14.10 = xor i32 %conv23.14.10, %conv29.14.10
  %scevgep35.14.10 = getelementptr i8, i8* %a, i64 25
  %3410 = load i8, i8* %scevgep35.14.10, align 1
  %3411 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.10 = call zeroext i8 @mult(i8 zeroext %3410, i8 zeroext %3411)
  %conv35.14.10 = zext i8 %call34.14.10 to i32
  %xor36.14.10 = xor i32 %xor.14.10, %conv35.14.10
  %conv37.14.10 = trunc i32 %xor36.14.10 to i8
  store i8 %conv37.14.10, i8* %scevgep41.14.9, align 1
  %scevgep28.14.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3405, i64 0, i64 0, i64 1
  %3412 = bitcast i8* %scevgep28.14.10 to [41 x [41 x i8]]*
  %scevgep41.14.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3406, i64 0, i64 1, i64 0
  %3413 = bitcast i8* %scevgep41.14.10 to [41 x [41 x i8]]*
  %call16.14.11 = call zeroext i8 (...) @rand()
  store i8 %call16.14.11, i8* %scevgep28.14.10, align 1
  %3414 = load i8, i8* %scevgep28.14.10, align 1
  %conv23.14.11 = zext i8 %3414 to i32
  %3415 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.11 = getelementptr i8, i8* %b, i64 26
  %3416 = load i8, i8* %scevgep34.14.11, align 1
  %call28.14.11 = call zeroext i8 @mult(i8 zeroext %3415, i8 zeroext %3416)
  %conv29.14.11 = zext i8 %call28.14.11 to i32
  %xor.14.11 = xor i32 %conv23.14.11, %conv29.14.11
  %scevgep35.14.11 = getelementptr i8, i8* %a, i64 26
  %3417 = load i8, i8* %scevgep35.14.11, align 1
  %3418 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.11 = call zeroext i8 @mult(i8 zeroext %3417, i8 zeroext %3418)
  %conv35.14.11 = zext i8 %call34.14.11 to i32
  %xor36.14.11 = xor i32 %xor.14.11, %conv35.14.11
  %conv37.14.11 = trunc i32 %xor36.14.11 to i8
  store i8 %conv37.14.11, i8* %scevgep41.14.10, align 1
  %scevgep28.14.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3412, i64 0, i64 0, i64 1
  %3419 = bitcast i8* %scevgep28.14.11 to [41 x [41 x i8]]*
  %scevgep41.14.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3413, i64 0, i64 1, i64 0
  %3420 = bitcast i8* %scevgep41.14.11 to [41 x [41 x i8]]*
  %call16.14.12 = call zeroext i8 (...) @rand()
  store i8 %call16.14.12, i8* %scevgep28.14.11, align 1
  %3421 = load i8, i8* %scevgep28.14.11, align 1
  %conv23.14.12 = zext i8 %3421 to i32
  %3422 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.12 = getelementptr i8, i8* %b, i64 27
  %3423 = load i8, i8* %scevgep34.14.12, align 1
  %call28.14.12 = call zeroext i8 @mult(i8 zeroext %3422, i8 zeroext %3423)
  %conv29.14.12 = zext i8 %call28.14.12 to i32
  %xor.14.12 = xor i32 %conv23.14.12, %conv29.14.12
  %scevgep35.14.12 = getelementptr i8, i8* %a, i64 27
  %3424 = load i8, i8* %scevgep35.14.12, align 1
  %3425 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.12 = call zeroext i8 @mult(i8 zeroext %3424, i8 zeroext %3425)
  %conv35.14.12 = zext i8 %call34.14.12 to i32
  %xor36.14.12 = xor i32 %xor.14.12, %conv35.14.12
  %conv37.14.12 = trunc i32 %xor36.14.12 to i8
  store i8 %conv37.14.12, i8* %scevgep41.14.11, align 1
  %scevgep28.14.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3419, i64 0, i64 0, i64 1
  %3426 = bitcast i8* %scevgep28.14.12 to [41 x [41 x i8]]*
  %scevgep41.14.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3420, i64 0, i64 1, i64 0
  %3427 = bitcast i8* %scevgep41.14.12 to [41 x [41 x i8]]*
  %call16.14.13 = call zeroext i8 (...) @rand()
  store i8 %call16.14.13, i8* %scevgep28.14.12, align 1
  %3428 = load i8, i8* %scevgep28.14.12, align 1
  %conv23.14.13 = zext i8 %3428 to i32
  %3429 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.13 = getelementptr i8, i8* %b, i64 28
  %3430 = load i8, i8* %scevgep34.14.13, align 1
  %call28.14.13 = call zeroext i8 @mult(i8 zeroext %3429, i8 zeroext %3430)
  %conv29.14.13 = zext i8 %call28.14.13 to i32
  %xor.14.13 = xor i32 %conv23.14.13, %conv29.14.13
  %scevgep35.14.13 = getelementptr i8, i8* %a, i64 28
  %3431 = load i8, i8* %scevgep35.14.13, align 1
  %3432 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.13 = call zeroext i8 @mult(i8 zeroext %3431, i8 zeroext %3432)
  %conv35.14.13 = zext i8 %call34.14.13 to i32
  %xor36.14.13 = xor i32 %xor.14.13, %conv35.14.13
  %conv37.14.13 = trunc i32 %xor36.14.13 to i8
  store i8 %conv37.14.13, i8* %scevgep41.14.12, align 1
  %scevgep28.14.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3426, i64 0, i64 0, i64 1
  %3433 = bitcast i8* %scevgep28.14.13 to [41 x [41 x i8]]*
  %scevgep41.14.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3427, i64 0, i64 1, i64 0
  %3434 = bitcast i8* %scevgep41.14.13 to [41 x [41 x i8]]*
  %call16.14.14 = call zeroext i8 (...) @rand()
  store i8 %call16.14.14, i8* %scevgep28.14.13, align 1
  %3435 = load i8, i8* %scevgep28.14.13, align 1
  %conv23.14.14 = zext i8 %3435 to i32
  %3436 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.14 = getelementptr i8, i8* %b, i64 29
  %3437 = load i8, i8* %scevgep34.14.14, align 1
  %call28.14.14 = call zeroext i8 @mult(i8 zeroext %3436, i8 zeroext %3437)
  %conv29.14.14 = zext i8 %call28.14.14 to i32
  %xor.14.14 = xor i32 %conv23.14.14, %conv29.14.14
  %scevgep35.14.14 = getelementptr i8, i8* %a, i64 29
  %3438 = load i8, i8* %scevgep35.14.14, align 1
  %3439 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.14 = call zeroext i8 @mult(i8 zeroext %3438, i8 zeroext %3439)
  %conv35.14.14 = zext i8 %call34.14.14 to i32
  %xor36.14.14 = xor i32 %xor.14.14, %conv35.14.14
  %conv37.14.14 = trunc i32 %xor36.14.14 to i8
  store i8 %conv37.14.14, i8* %scevgep41.14.13, align 1
  %scevgep28.14.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3433, i64 0, i64 0, i64 1
  %3440 = bitcast i8* %scevgep28.14.14 to [41 x [41 x i8]]*
  %scevgep41.14.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3434, i64 0, i64 1, i64 0
  %3441 = bitcast i8* %scevgep41.14.14 to [41 x [41 x i8]]*
  %call16.14.15 = call zeroext i8 (...) @rand()
  store i8 %call16.14.15, i8* %scevgep28.14.14, align 1
  %3442 = load i8, i8* %scevgep28.14.14, align 1
  %conv23.14.15 = zext i8 %3442 to i32
  %3443 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.15 = getelementptr i8, i8* %b, i64 30
  %3444 = load i8, i8* %scevgep34.14.15, align 1
  %call28.14.15 = call zeroext i8 @mult(i8 zeroext %3443, i8 zeroext %3444)
  %conv29.14.15 = zext i8 %call28.14.15 to i32
  %xor.14.15 = xor i32 %conv23.14.15, %conv29.14.15
  %scevgep35.14.15 = getelementptr i8, i8* %a, i64 30
  %3445 = load i8, i8* %scevgep35.14.15, align 1
  %3446 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.15 = call zeroext i8 @mult(i8 zeroext %3445, i8 zeroext %3446)
  %conv35.14.15 = zext i8 %call34.14.15 to i32
  %xor36.14.15 = xor i32 %xor.14.15, %conv35.14.15
  %conv37.14.15 = trunc i32 %xor36.14.15 to i8
  store i8 %conv37.14.15, i8* %scevgep41.14.14, align 1
  %scevgep28.14.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3440, i64 0, i64 0, i64 1
  %3447 = bitcast i8* %scevgep28.14.15 to [41 x [41 x i8]]*
  %scevgep41.14.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3441, i64 0, i64 1, i64 0
  %3448 = bitcast i8* %scevgep41.14.15 to [41 x [41 x i8]]*
  %call16.14.16 = call zeroext i8 (...) @rand()
  store i8 %call16.14.16, i8* %scevgep28.14.15, align 1
  %3449 = load i8, i8* %scevgep28.14.15, align 1
  %conv23.14.16 = zext i8 %3449 to i32
  %3450 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.16 = getelementptr i8, i8* %b, i64 31
  %3451 = load i8, i8* %scevgep34.14.16, align 1
  %call28.14.16 = call zeroext i8 @mult(i8 zeroext %3450, i8 zeroext %3451)
  %conv29.14.16 = zext i8 %call28.14.16 to i32
  %xor.14.16 = xor i32 %conv23.14.16, %conv29.14.16
  %scevgep35.14.16 = getelementptr i8, i8* %a, i64 31
  %3452 = load i8, i8* %scevgep35.14.16, align 1
  %3453 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.16 = call zeroext i8 @mult(i8 zeroext %3452, i8 zeroext %3453)
  %conv35.14.16 = zext i8 %call34.14.16 to i32
  %xor36.14.16 = xor i32 %xor.14.16, %conv35.14.16
  %conv37.14.16 = trunc i32 %xor36.14.16 to i8
  store i8 %conv37.14.16, i8* %scevgep41.14.15, align 1
  %scevgep28.14.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3447, i64 0, i64 0, i64 1
  %3454 = bitcast i8* %scevgep28.14.16 to [41 x [41 x i8]]*
  %scevgep41.14.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3448, i64 0, i64 1, i64 0
  %3455 = bitcast i8* %scevgep41.14.16 to [41 x [41 x i8]]*
  %call16.14.17 = call zeroext i8 (...) @rand()
  store i8 %call16.14.17, i8* %scevgep28.14.16, align 1
  %3456 = load i8, i8* %scevgep28.14.16, align 1
  %conv23.14.17 = zext i8 %3456 to i32
  %3457 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.17 = getelementptr i8, i8* %b, i64 32
  %3458 = load i8, i8* %scevgep34.14.17, align 1
  %call28.14.17 = call zeroext i8 @mult(i8 zeroext %3457, i8 zeroext %3458)
  %conv29.14.17 = zext i8 %call28.14.17 to i32
  %xor.14.17 = xor i32 %conv23.14.17, %conv29.14.17
  %scevgep35.14.17 = getelementptr i8, i8* %a, i64 32
  %3459 = load i8, i8* %scevgep35.14.17, align 1
  %3460 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.17 = call zeroext i8 @mult(i8 zeroext %3459, i8 zeroext %3460)
  %conv35.14.17 = zext i8 %call34.14.17 to i32
  %xor36.14.17 = xor i32 %xor.14.17, %conv35.14.17
  %conv37.14.17 = trunc i32 %xor36.14.17 to i8
  store i8 %conv37.14.17, i8* %scevgep41.14.16, align 1
  %scevgep28.14.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3454, i64 0, i64 0, i64 1
  %3461 = bitcast i8* %scevgep28.14.17 to [41 x [41 x i8]]*
  %scevgep41.14.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3455, i64 0, i64 1, i64 0
  %3462 = bitcast i8* %scevgep41.14.17 to [41 x [41 x i8]]*
  %call16.14.18 = call zeroext i8 (...) @rand()
  store i8 %call16.14.18, i8* %scevgep28.14.17, align 1
  %3463 = load i8, i8* %scevgep28.14.17, align 1
  %conv23.14.18 = zext i8 %3463 to i32
  %3464 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.18 = getelementptr i8, i8* %b, i64 33
  %3465 = load i8, i8* %scevgep34.14.18, align 1
  %call28.14.18 = call zeroext i8 @mult(i8 zeroext %3464, i8 zeroext %3465)
  %conv29.14.18 = zext i8 %call28.14.18 to i32
  %xor.14.18 = xor i32 %conv23.14.18, %conv29.14.18
  %scevgep35.14.18 = getelementptr i8, i8* %a, i64 33
  %3466 = load i8, i8* %scevgep35.14.18, align 1
  %3467 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.18 = call zeroext i8 @mult(i8 zeroext %3466, i8 zeroext %3467)
  %conv35.14.18 = zext i8 %call34.14.18 to i32
  %xor36.14.18 = xor i32 %xor.14.18, %conv35.14.18
  %conv37.14.18 = trunc i32 %xor36.14.18 to i8
  store i8 %conv37.14.18, i8* %scevgep41.14.17, align 1
  %scevgep28.14.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3461, i64 0, i64 0, i64 1
  %3468 = bitcast i8* %scevgep28.14.18 to [41 x [41 x i8]]*
  %scevgep41.14.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3462, i64 0, i64 1, i64 0
  %3469 = bitcast i8* %scevgep41.14.18 to [41 x [41 x i8]]*
  %call16.14.19 = call zeroext i8 (...) @rand()
  store i8 %call16.14.19, i8* %scevgep28.14.18, align 1
  %3470 = load i8, i8* %scevgep28.14.18, align 1
  %conv23.14.19 = zext i8 %3470 to i32
  %3471 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.19 = getelementptr i8, i8* %b, i64 34
  %3472 = load i8, i8* %scevgep34.14.19, align 1
  %call28.14.19 = call zeroext i8 @mult(i8 zeroext %3471, i8 zeroext %3472)
  %conv29.14.19 = zext i8 %call28.14.19 to i32
  %xor.14.19 = xor i32 %conv23.14.19, %conv29.14.19
  %scevgep35.14.19 = getelementptr i8, i8* %a, i64 34
  %3473 = load i8, i8* %scevgep35.14.19, align 1
  %3474 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.19 = call zeroext i8 @mult(i8 zeroext %3473, i8 zeroext %3474)
  %conv35.14.19 = zext i8 %call34.14.19 to i32
  %xor36.14.19 = xor i32 %xor.14.19, %conv35.14.19
  %conv37.14.19 = trunc i32 %xor36.14.19 to i8
  store i8 %conv37.14.19, i8* %scevgep41.14.18, align 1
  %scevgep28.14.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3468, i64 0, i64 0, i64 1
  %3475 = bitcast i8* %scevgep28.14.19 to [41 x [41 x i8]]*
  %scevgep41.14.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3469, i64 0, i64 1, i64 0
  %3476 = bitcast i8* %scevgep41.14.19 to [41 x [41 x i8]]*
  %call16.14.20 = call zeroext i8 (...) @rand()
  store i8 %call16.14.20, i8* %scevgep28.14.19, align 1
  %3477 = load i8, i8* %scevgep28.14.19, align 1
  %conv23.14.20 = zext i8 %3477 to i32
  %3478 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.20 = getelementptr i8, i8* %b, i64 35
  %3479 = load i8, i8* %scevgep34.14.20, align 1
  %call28.14.20 = call zeroext i8 @mult(i8 zeroext %3478, i8 zeroext %3479)
  %conv29.14.20 = zext i8 %call28.14.20 to i32
  %xor.14.20 = xor i32 %conv23.14.20, %conv29.14.20
  %scevgep35.14.20 = getelementptr i8, i8* %a, i64 35
  %3480 = load i8, i8* %scevgep35.14.20, align 1
  %3481 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.20 = call zeroext i8 @mult(i8 zeroext %3480, i8 zeroext %3481)
  %conv35.14.20 = zext i8 %call34.14.20 to i32
  %xor36.14.20 = xor i32 %xor.14.20, %conv35.14.20
  %conv37.14.20 = trunc i32 %xor36.14.20 to i8
  store i8 %conv37.14.20, i8* %scevgep41.14.19, align 1
  %scevgep28.14.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3475, i64 0, i64 0, i64 1
  %3482 = bitcast i8* %scevgep28.14.20 to [41 x [41 x i8]]*
  %scevgep41.14.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3476, i64 0, i64 1, i64 0
  %3483 = bitcast i8* %scevgep41.14.20 to [41 x [41 x i8]]*
  %call16.14.21 = call zeroext i8 (...) @rand()
  store i8 %call16.14.21, i8* %scevgep28.14.20, align 1
  %3484 = load i8, i8* %scevgep28.14.20, align 1
  %conv23.14.21 = zext i8 %3484 to i32
  %3485 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.21 = getelementptr i8, i8* %b, i64 36
  %3486 = load i8, i8* %scevgep34.14.21, align 1
  %call28.14.21 = call zeroext i8 @mult(i8 zeroext %3485, i8 zeroext %3486)
  %conv29.14.21 = zext i8 %call28.14.21 to i32
  %xor.14.21 = xor i32 %conv23.14.21, %conv29.14.21
  %scevgep35.14.21 = getelementptr i8, i8* %a, i64 36
  %3487 = load i8, i8* %scevgep35.14.21, align 1
  %3488 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.21 = call zeroext i8 @mult(i8 zeroext %3487, i8 zeroext %3488)
  %conv35.14.21 = zext i8 %call34.14.21 to i32
  %xor36.14.21 = xor i32 %xor.14.21, %conv35.14.21
  %conv37.14.21 = trunc i32 %xor36.14.21 to i8
  store i8 %conv37.14.21, i8* %scevgep41.14.20, align 1
  %scevgep28.14.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3482, i64 0, i64 0, i64 1
  %3489 = bitcast i8* %scevgep28.14.21 to [41 x [41 x i8]]*
  %scevgep41.14.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3483, i64 0, i64 1, i64 0
  %3490 = bitcast i8* %scevgep41.14.21 to [41 x [41 x i8]]*
  %call16.14.22 = call zeroext i8 (...) @rand()
  store i8 %call16.14.22, i8* %scevgep28.14.21, align 1
  %3491 = load i8, i8* %scevgep28.14.21, align 1
  %conv23.14.22 = zext i8 %3491 to i32
  %3492 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.22 = getelementptr i8, i8* %b, i64 37
  %3493 = load i8, i8* %scevgep34.14.22, align 1
  %call28.14.22 = call zeroext i8 @mult(i8 zeroext %3492, i8 zeroext %3493)
  %conv29.14.22 = zext i8 %call28.14.22 to i32
  %xor.14.22 = xor i32 %conv23.14.22, %conv29.14.22
  %scevgep35.14.22 = getelementptr i8, i8* %a, i64 37
  %3494 = load i8, i8* %scevgep35.14.22, align 1
  %3495 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.22 = call zeroext i8 @mult(i8 zeroext %3494, i8 zeroext %3495)
  %conv35.14.22 = zext i8 %call34.14.22 to i32
  %xor36.14.22 = xor i32 %xor.14.22, %conv35.14.22
  %conv37.14.22 = trunc i32 %xor36.14.22 to i8
  store i8 %conv37.14.22, i8* %scevgep41.14.21, align 1
  %scevgep28.14.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3489, i64 0, i64 0, i64 1
  %3496 = bitcast i8* %scevgep28.14.22 to [41 x [41 x i8]]*
  %scevgep41.14.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3490, i64 0, i64 1, i64 0
  %3497 = bitcast i8* %scevgep41.14.22 to [41 x [41 x i8]]*
  %call16.14.23 = call zeroext i8 (...) @rand()
  store i8 %call16.14.23, i8* %scevgep28.14.22, align 1
  %3498 = load i8, i8* %scevgep28.14.22, align 1
  %conv23.14.23 = zext i8 %3498 to i32
  %3499 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.23 = getelementptr i8, i8* %b, i64 38
  %3500 = load i8, i8* %scevgep34.14.23, align 1
  %call28.14.23 = call zeroext i8 @mult(i8 zeroext %3499, i8 zeroext %3500)
  %conv29.14.23 = zext i8 %call28.14.23 to i32
  %xor.14.23 = xor i32 %conv23.14.23, %conv29.14.23
  %scevgep35.14.23 = getelementptr i8, i8* %a, i64 38
  %3501 = load i8, i8* %scevgep35.14.23, align 1
  %3502 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.23 = call zeroext i8 @mult(i8 zeroext %3501, i8 zeroext %3502)
  %conv35.14.23 = zext i8 %call34.14.23 to i32
  %xor36.14.23 = xor i32 %xor.14.23, %conv35.14.23
  %conv37.14.23 = trunc i32 %xor36.14.23 to i8
  store i8 %conv37.14.23, i8* %scevgep41.14.22, align 1
  %scevgep28.14.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3496, i64 0, i64 0, i64 1
  %3503 = bitcast i8* %scevgep28.14.23 to [41 x [41 x i8]]*
  %scevgep41.14.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3497, i64 0, i64 1, i64 0
  %3504 = bitcast i8* %scevgep41.14.23 to [41 x [41 x i8]]*
  %call16.14.24 = call zeroext i8 (...) @rand()
  store i8 %call16.14.24, i8* %scevgep28.14.23, align 1
  %3505 = load i8, i8* %scevgep28.14.23, align 1
  %conv23.14.24 = zext i8 %3505 to i32
  %3506 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.24 = getelementptr i8, i8* %b, i64 39
  %3507 = load i8, i8* %scevgep34.14.24, align 1
  %call28.14.24 = call zeroext i8 @mult(i8 zeroext %3506, i8 zeroext %3507)
  %conv29.14.24 = zext i8 %call28.14.24 to i32
  %xor.14.24 = xor i32 %conv23.14.24, %conv29.14.24
  %scevgep35.14.24 = getelementptr i8, i8* %a, i64 39
  %3508 = load i8, i8* %scevgep35.14.24, align 1
  %3509 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.24 = call zeroext i8 @mult(i8 zeroext %3508, i8 zeroext %3509)
  %conv35.14.24 = zext i8 %call34.14.24 to i32
  %xor36.14.24 = xor i32 %xor.14.24, %conv35.14.24
  %conv37.14.24 = trunc i32 %xor36.14.24 to i8
  store i8 %conv37.14.24, i8* %scevgep41.14.23, align 1
  %scevgep28.14.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3503, i64 0, i64 0, i64 1
  %scevgep41.14.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3504, i64 0, i64 1, i64 0
  %call16.14.25 = call zeroext i8 (...) @rand()
  store i8 %call16.14.25, i8* %scevgep28.14.24, align 1
  %3510 = load i8, i8* %scevgep28.14.24, align 1
  %conv23.14.25 = zext i8 %3510 to i32
  %3511 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.25 = getelementptr i8, i8* %b, i64 40
  %3512 = load i8, i8* %scevgep34.14.25, align 1
  %call28.14.25 = call zeroext i8 @mult(i8 zeroext %3511, i8 zeroext %3512)
  %conv29.14.25 = zext i8 %call28.14.25 to i32
  %xor.14.25 = xor i32 %conv23.14.25, %conv29.14.25
  %scevgep35.14.25 = getelementptr i8, i8* %a, i64 40
  %3513 = load i8, i8* %scevgep35.14.25, align 1
  %3514 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.25 = call zeroext i8 @mult(i8 zeroext %3513, i8 zeroext %3514)
  %conv35.14.25 = zext i8 %call34.14.25 to i32
  %xor36.14.25 = xor i32 %xor.14.25, %conv35.14.25
  %conv37.14.25 = trunc i32 %xor36.14.25 to i8
  store i8 %conv37.14.25, i8* %scevgep41.14.24, align 1
  %scevgep26.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3335, i64 0, i64 1, i64 1
  %3515 = bitcast i8* %scevgep26.14 to [41 x [41 x i8]]*
  %scevgep39.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3336, i64 0, i64 1, i64 1
  %3516 = bitcast i8* %scevgep39.14 to [41 x [41 x i8]]*
  %arrayidx25.15 = getelementptr inbounds i8, i8* %a, i64 15
  %arrayidx33.15 = getelementptr inbounds i8, i8* %b, i64 15
  %call16.15 = call zeroext i8 (...) @rand()
  store i8 %call16.15, i8* %scevgep26.14, align 1
  %3517 = load i8, i8* %scevgep26.14, align 1
  %conv23.15 = zext i8 %3517 to i32
  %3518 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15 = getelementptr i8, i8* %b, i64 16
  %3519 = load i8, i8* %scevgep34.15, align 1
  %call28.15 = call zeroext i8 @mult(i8 zeroext %3518, i8 zeroext %3519)
  %conv29.15 = zext i8 %call28.15 to i32
  %xor.15 = xor i32 %conv23.15, %conv29.15
  %scevgep35.15 = getelementptr i8, i8* %a, i64 16
  %3520 = load i8, i8* %scevgep35.15, align 1
  %3521 = load i8, i8* %arrayidx33.15, align 1
  %call34.15 = call zeroext i8 @mult(i8 zeroext %3520, i8 zeroext %3521)
  %conv35.15 = zext i8 %call34.15 to i32
  %xor36.15 = xor i32 %xor.15, %conv35.15
  %conv37.15 = trunc i32 %xor36.15 to i8
  store i8 %conv37.15, i8* %scevgep39.14, align 1
  %scevgep28.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3515, i64 0, i64 0, i64 1
  %3522 = bitcast i8* %scevgep28.15 to [41 x [41 x i8]]*
  %scevgep41.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3516, i64 0, i64 1, i64 0
  %3523 = bitcast i8* %scevgep41.15 to [41 x [41 x i8]]*
  %call16.15.1 = call zeroext i8 (...) @rand()
  store i8 %call16.15.1, i8* %scevgep28.15, align 1
  %3524 = load i8, i8* %scevgep28.15, align 1
  %conv23.15.1 = zext i8 %3524 to i32
  %3525 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.1 = getelementptr i8, i8* %b, i64 17
  %3526 = load i8, i8* %scevgep34.15.1, align 1
  %call28.15.1 = call zeroext i8 @mult(i8 zeroext %3525, i8 zeroext %3526)
  %conv29.15.1 = zext i8 %call28.15.1 to i32
  %xor.15.1 = xor i32 %conv23.15.1, %conv29.15.1
  %scevgep35.15.1 = getelementptr i8, i8* %a, i64 17
  %3527 = load i8, i8* %scevgep35.15.1, align 1
  %3528 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.1 = call zeroext i8 @mult(i8 zeroext %3527, i8 zeroext %3528)
  %conv35.15.1 = zext i8 %call34.15.1 to i32
  %xor36.15.1 = xor i32 %xor.15.1, %conv35.15.1
  %conv37.15.1 = trunc i32 %xor36.15.1 to i8
  store i8 %conv37.15.1, i8* %scevgep41.15, align 1
  %scevgep28.15.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3522, i64 0, i64 0, i64 1
  %3529 = bitcast i8* %scevgep28.15.1 to [41 x [41 x i8]]*
  %scevgep41.15.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3523, i64 0, i64 1, i64 0
  %3530 = bitcast i8* %scevgep41.15.1 to [41 x [41 x i8]]*
  %call16.15.2 = call zeroext i8 (...) @rand()
  store i8 %call16.15.2, i8* %scevgep28.15.1, align 1
  %3531 = load i8, i8* %scevgep28.15.1, align 1
  %conv23.15.2 = zext i8 %3531 to i32
  %3532 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.2 = getelementptr i8, i8* %b, i64 18
  %3533 = load i8, i8* %scevgep34.15.2, align 1
  %call28.15.2 = call zeroext i8 @mult(i8 zeroext %3532, i8 zeroext %3533)
  %conv29.15.2 = zext i8 %call28.15.2 to i32
  %xor.15.2 = xor i32 %conv23.15.2, %conv29.15.2
  %scevgep35.15.2 = getelementptr i8, i8* %a, i64 18
  %3534 = load i8, i8* %scevgep35.15.2, align 1
  %3535 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.2 = call zeroext i8 @mult(i8 zeroext %3534, i8 zeroext %3535)
  %conv35.15.2 = zext i8 %call34.15.2 to i32
  %xor36.15.2 = xor i32 %xor.15.2, %conv35.15.2
  %conv37.15.2 = trunc i32 %xor36.15.2 to i8
  store i8 %conv37.15.2, i8* %scevgep41.15.1, align 1
  %scevgep28.15.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3529, i64 0, i64 0, i64 1
  %3536 = bitcast i8* %scevgep28.15.2 to [41 x [41 x i8]]*
  %scevgep41.15.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3530, i64 0, i64 1, i64 0
  %3537 = bitcast i8* %scevgep41.15.2 to [41 x [41 x i8]]*
  %call16.15.3 = call zeroext i8 (...) @rand()
  store i8 %call16.15.3, i8* %scevgep28.15.2, align 1
  %3538 = load i8, i8* %scevgep28.15.2, align 1
  %conv23.15.3 = zext i8 %3538 to i32
  %3539 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.3 = getelementptr i8, i8* %b, i64 19
  %3540 = load i8, i8* %scevgep34.15.3, align 1
  %call28.15.3 = call zeroext i8 @mult(i8 zeroext %3539, i8 zeroext %3540)
  %conv29.15.3 = zext i8 %call28.15.3 to i32
  %xor.15.3 = xor i32 %conv23.15.3, %conv29.15.3
  %scevgep35.15.3 = getelementptr i8, i8* %a, i64 19
  %3541 = load i8, i8* %scevgep35.15.3, align 1
  %3542 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.3 = call zeroext i8 @mult(i8 zeroext %3541, i8 zeroext %3542)
  %conv35.15.3 = zext i8 %call34.15.3 to i32
  %xor36.15.3 = xor i32 %xor.15.3, %conv35.15.3
  %conv37.15.3 = trunc i32 %xor36.15.3 to i8
  store i8 %conv37.15.3, i8* %scevgep41.15.2, align 1
  %scevgep28.15.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3536, i64 0, i64 0, i64 1
  %3543 = bitcast i8* %scevgep28.15.3 to [41 x [41 x i8]]*
  %scevgep41.15.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3537, i64 0, i64 1, i64 0
  %3544 = bitcast i8* %scevgep41.15.3 to [41 x [41 x i8]]*
  %call16.15.4 = call zeroext i8 (...) @rand()
  store i8 %call16.15.4, i8* %scevgep28.15.3, align 1
  %3545 = load i8, i8* %scevgep28.15.3, align 1
  %conv23.15.4 = zext i8 %3545 to i32
  %3546 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.4 = getelementptr i8, i8* %b, i64 20
  %3547 = load i8, i8* %scevgep34.15.4, align 1
  %call28.15.4 = call zeroext i8 @mult(i8 zeroext %3546, i8 zeroext %3547)
  %conv29.15.4 = zext i8 %call28.15.4 to i32
  %xor.15.4 = xor i32 %conv23.15.4, %conv29.15.4
  %scevgep35.15.4 = getelementptr i8, i8* %a, i64 20
  %3548 = load i8, i8* %scevgep35.15.4, align 1
  %3549 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.4 = call zeroext i8 @mult(i8 zeroext %3548, i8 zeroext %3549)
  %conv35.15.4 = zext i8 %call34.15.4 to i32
  %xor36.15.4 = xor i32 %xor.15.4, %conv35.15.4
  %conv37.15.4 = trunc i32 %xor36.15.4 to i8
  store i8 %conv37.15.4, i8* %scevgep41.15.3, align 1
  %scevgep28.15.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3543, i64 0, i64 0, i64 1
  %3550 = bitcast i8* %scevgep28.15.4 to [41 x [41 x i8]]*
  %scevgep41.15.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3544, i64 0, i64 1, i64 0
  %3551 = bitcast i8* %scevgep41.15.4 to [41 x [41 x i8]]*
  %call16.15.5 = call zeroext i8 (...) @rand()
  store i8 %call16.15.5, i8* %scevgep28.15.4, align 1
  %3552 = load i8, i8* %scevgep28.15.4, align 1
  %conv23.15.5 = zext i8 %3552 to i32
  %3553 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.5 = getelementptr i8, i8* %b, i64 21
  %3554 = load i8, i8* %scevgep34.15.5, align 1
  %call28.15.5 = call zeroext i8 @mult(i8 zeroext %3553, i8 zeroext %3554)
  %conv29.15.5 = zext i8 %call28.15.5 to i32
  %xor.15.5 = xor i32 %conv23.15.5, %conv29.15.5
  %scevgep35.15.5 = getelementptr i8, i8* %a, i64 21
  %3555 = load i8, i8* %scevgep35.15.5, align 1
  %3556 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.5 = call zeroext i8 @mult(i8 zeroext %3555, i8 zeroext %3556)
  %conv35.15.5 = zext i8 %call34.15.5 to i32
  %xor36.15.5 = xor i32 %xor.15.5, %conv35.15.5
  %conv37.15.5 = trunc i32 %xor36.15.5 to i8
  store i8 %conv37.15.5, i8* %scevgep41.15.4, align 1
  %scevgep28.15.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3550, i64 0, i64 0, i64 1
  %3557 = bitcast i8* %scevgep28.15.5 to [41 x [41 x i8]]*
  %scevgep41.15.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3551, i64 0, i64 1, i64 0
  %3558 = bitcast i8* %scevgep41.15.5 to [41 x [41 x i8]]*
  %call16.15.6 = call zeroext i8 (...) @rand()
  store i8 %call16.15.6, i8* %scevgep28.15.5, align 1
  %3559 = load i8, i8* %scevgep28.15.5, align 1
  %conv23.15.6 = zext i8 %3559 to i32
  %3560 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.6 = getelementptr i8, i8* %b, i64 22
  %3561 = load i8, i8* %scevgep34.15.6, align 1
  %call28.15.6 = call zeroext i8 @mult(i8 zeroext %3560, i8 zeroext %3561)
  %conv29.15.6 = zext i8 %call28.15.6 to i32
  %xor.15.6 = xor i32 %conv23.15.6, %conv29.15.6
  %scevgep35.15.6 = getelementptr i8, i8* %a, i64 22
  %3562 = load i8, i8* %scevgep35.15.6, align 1
  %3563 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.6 = call zeroext i8 @mult(i8 zeroext %3562, i8 zeroext %3563)
  %conv35.15.6 = zext i8 %call34.15.6 to i32
  %xor36.15.6 = xor i32 %xor.15.6, %conv35.15.6
  %conv37.15.6 = trunc i32 %xor36.15.6 to i8
  store i8 %conv37.15.6, i8* %scevgep41.15.5, align 1
  %scevgep28.15.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3557, i64 0, i64 0, i64 1
  %3564 = bitcast i8* %scevgep28.15.6 to [41 x [41 x i8]]*
  %scevgep41.15.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3558, i64 0, i64 1, i64 0
  %3565 = bitcast i8* %scevgep41.15.6 to [41 x [41 x i8]]*
  %call16.15.7 = call zeroext i8 (...) @rand()
  store i8 %call16.15.7, i8* %scevgep28.15.6, align 1
  %3566 = load i8, i8* %scevgep28.15.6, align 1
  %conv23.15.7 = zext i8 %3566 to i32
  %3567 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.7 = getelementptr i8, i8* %b, i64 23
  %3568 = load i8, i8* %scevgep34.15.7, align 1
  %call28.15.7 = call zeroext i8 @mult(i8 zeroext %3567, i8 zeroext %3568)
  %conv29.15.7 = zext i8 %call28.15.7 to i32
  %xor.15.7 = xor i32 %conv23.15.7, %conv29.15.7
  %scevgep35.15.7 = getelementptr i8, i8* %a, i64 23
  %3569 = load i8, i8* %scevgep35.15.7, align 1
  %3570 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.7 = call zeroext i8 @mult(i8 zeroext %3569, i8 zeroext %3570)
  %conv35.15.7 = zext i8 %call34.15.7 to i32
  %xor36.15.7 = xor i32 %xor.15.7, %conv35.15.7
  %conv37.15.7 = trunc i32 %xor36.15.7 to i8
  store i8 %conv37.15.7, i8* %scevgep41.15.6, align 1
  %scevgep28.15.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3564, i64 0, i64 0, i64 1
  %3571 = bitcast i8* %scevgep28.15.7 to [41 x [41 x i8]]*
  %scevgep41.15.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3565, i64 0, i64 1, i64 0
  %3572 = bitcast i8* %scevgep41.15.7 to [41 x [41 x i8]]*
  %call16.15.8 = call zeroext i8 (...) @rand()
  store i8 %call16.15.8, i8* %scevgep28.15.7, align 1
  %3573 = load i8, i8* %scevgep28.15.7, align 1
  %conv23.15.8 = zext i8 %3573 to i32
  %3574 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.8 = getelementptr i8, i8* %b, i64 24
  %3575 = load i8, i8* %scevgep34.15.8, align 1
  %call28.15.8 = call zeroext i8 @mult(i8 zeroext %3574, i8 zeroext %3575)
  %conv29.15.8 = zext i8 %call28.15.8 to i32
  %xor.15.8 = xor i32 %conv23.15.8, %conv29.15.8
  %scevgep35.15.8 = getelementptr i8, i8* %a, i64 24
  %3576 = load i8, i8* %scevgep35.15.8, align 1
  %3577 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.8 = call zeroext i8 @mult(i8 zeroext %3576, i8 zeroext %3577)
  %conv35.15.8 = zext i8 %call34.15.8 to i32
  %xor36.15.8 = xor i32 %xor.15.8, %conv35.15.8
  %conv37.15.8 = trunc i32 %xor36.15.8 to i8
  store i8 %conv37.15.8, i8* %scevgep41.15.7, align 1
  %scevgep28.15.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3571, i64 0, i64 0, i64 1
  %3578 = bitcast i8* %scevgep28.15.8 to [41 x [41 x i8]]*
  %scevgep41.15.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3572, i64 0, i64 1, i64 0
  %3579 = bitcast i8* %scevgep41.15.8 to [41 x [41 x i8]]*
  %call16.15.9 = call zeroext i8 (...) @rand()
  store i8 %call16.15.9, i8* %scevgep28.15.8, align 1
  %3580 = load i8, i8* %scevgep28.15.8, align 1
  %conv23.15.9 = zext i8 %3580 to i32
  %3581 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.9 = getelementptr i8, i8* %b, i64 25
  %3582 = load i8, i8* %scevgep34.15.9, align 1
  %call28.15.9 = call zeroext i8 @mult(i8 zeroext %3581, i8 zeroext %3582)
  %conv29.15.9 = zext i8 %call28.15.9 to i32
  %xor.15.9 = xor i32 %conv23.15.9, %conv29.15.9
  %scevgep35.15.9 = getelementptr i8, i8* %a, i64 25
  %3583 = load i8, i8* %scevgep35.15.9, align 1
  %3584 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.9 = call zeroext i8 @mult(i8 zeroext %3583, i8 zeroext %3584)
  %conv35.15.9 = zext i8 %call34.15.9 to i32
  %xor36.15.9 = xor i32 %xor.15.9, %conv35.15.9
  %conv37.15.9 = trunc i32 %xor36.15.9 to i8
  store i8 %conv37.15.9, i8* %scevgep41.15.8, align 1
  %scevgep28.15.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3578, i64 0, i64 0, i64 1
  %3585 = bitcast i8* %scevgep28.15.9 to [41 x [41 x i8]]*
  %scevgep41.15.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3579, i64 0, i64 1, i64 0
  %3586 = bitcast i8* %scevgep41.15.9 to [41 x [41 x i8]]*
  %call16.15.10 = call zeroext i8 (...) @rand()
  store i8 %call16.15.10, i8* %scevgep28.15.9, align 1
  %3587 = load i8, i8* %scevgep28.15.9, align 1
  %conv23.15.10 = zext i8 %3587 to i32
  %3588 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.10 = getelementptr i8, i8* %b, i64 26
  %3589 = load i8, i8* %scevgep34.15.10, align 1
  %call28.15.10 = call zeroext i8 @mult(i8 zeroext %3588, i8 zeroext %3589)
  %conv29.15.10 = zext i8 %call28.15.10 to i32
  %xor.15.10 = xor i32 %conv23.15.10, %conv29.15.10
  %scevgep35.15.10 = getelementptr i8, i8* %a, i64 26
  %3590 = load i8, i8* %scevgep35.15.10, align 1
  %3591 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.10 = call zeroext i8 @mult(i8 zeroext %3590, i8 zeroext %3591)
  %conv35.15.10 = zext i8 %call34.15.10 to i32
  %xor36.15.10 = xor i32 %xor.15.10, %conv35.15.10
  %conv37.15.10 = trunc i32 %xor36.15.10 to i8
  store i8 %conv37.15.10, i8* %scevgep41.15.9, align 1
  %scevgep28.15.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3585, i64 0, i64 0, i64 1
  %3592 = bitcast i8* %scevgep28.15.10 to [41 x [41 x i8]]*
  %scevgep41.15.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3586, i64 0, i64 1, i64 0
  %3593 = bitcast i8* %scevgep41.15.10 to [41 x [41 x i8]]*
  %call16.15.11 = call zeroext i8 (...) @rand()
  store i8 %call16.15.11, i8* %scevgep28.15.10, align 1
  %3594 = load i8, i8* %scevgep28.15.10, align 1
  %conv23.15.11 = zext i8 %3594 to i32
  %3595 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.11 = getelementptr i8, i8* %b, i64 27
  %3596 = load i8, i8* %scevgep34.15.11, align 1
  %call28.15.11 = call zeroext i8 @mult(i8 zeroext %3595, i8 zeroext %3596)
  %conv29.15.11 = zext i8 %call28.15.11 to i32
  %xor.15.11 = xor i32 %conv23.15.11, %conv29.15.11
  %scevgep35.15.11 = getelementptr i8, i8* %a, i64 27
  %3597 = load i8, i8* %scevgep35.15.11, align 1
  %3598 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.11 = call zeroext i8 @mult(i8 zeroext %3597, i8 zeroext %3598)
  %conv35.15.11 = zext i8 %call34.15.11 to i32
  %xor36.15.11 = xor i32 %xor.15.11, %conv35.15.11
  %conv37.15.11 = trunc i32 %xor36.15.11 to i8
  store i8 %conv37.15.11, i8* %scevgep41.15.10, align 1
  %scevgep28.15.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3592, i64 0, i64 0, i64 1
  %3599 = bitcast i8* %scevgep28.15.11 to [41 x [41 x i8]]*
  %scevgep41.15.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3593, i64 0, i64 1, i64 0
  %3600 = bitcast i8* %scevgep41.15.11 to [41 x [41 x i8]]*
  %call16.15.12 = call zeroext i8 (...) @rand()
  store i8 %call16.15.12, i8* %scevgep28.15.11, align 1
  %3601 = load i8, i8* %scevgep28.15.11, align 1
  %conv23.15.12 = zext i8 %3601 to i32
  %3602 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.12 = getelementptr i8, i8* %b, i64 28
  %3603 = load i8, i8* %scevgep34.15.12, align 1
  %call28.15.12 = call zeroext i8 @mult(i8 zeroext %3602, i8 zeroext %3603)
  %conv29.15.12 = zext i8 %call28.15.12 to i32
  %xor.15.12 = xor i32 %conv23.15.12, %conv29.15.12
  %scevgep35.15.12 = getelementptr i8, i8* %a, i64 28
  %3604 = load i8, i8* %scevgep35.15.12, align 1
  %3605 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.12 = call zeroext i8 @mult(i8 zeroext %3604, i8 zeroext %3605)
  %conv35.15.12 = zext i8 %call34.15.12 to i32
  %xor36.15.12 = xor i32 %xor.15.12, %conv35.15.12
  %conv37.15.12 = trunc i32 %xor36.15.12 to i8
  store i8 %conv37.15.12, i8* %scevgep41.15.11, align 1
  %scevgep28.15.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3599, i64 0, i64 0, i64 1
  %3606 = bitcast i8* %scevgep28.15.12 to [41 x [41 x i8]]*
  %scevgep41.15.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3600, i64 0, i64 1, i64 0
  %3607 = bitcast i8* %scevgep41.15.12 to [41 x [41 x i8]]*
  %call16.15.13 = call zeroext i8 (...) @rand()
  store i8 %call16.15.13, i8* %scevgep28.15.12, align 1
  %3608 = load i8, i8* %scevgep28.15.12, align 1
  %conv23.15.13 = zext i8 %3608 to i32
  %3609 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.13 = getelementptr i8, i8* %b, i64 29
  %3610 = load i8, i8* %scevgep34.15.13, align 1
  %call28.15.13 = call zeroext i8 @mult(i8 zeroext %3609, i8 zeroext %3610)
  %conv29.15.13 = zext i8 %call28.15.13 to i32
  %xor.15.13 = xor i32 %conv23.15.13, %conv29.15.13
  %scevgep35.15.13 = getelementptr i8, i8* %a, i64 29
  %3611 = load i8, i8* %scevgep35.15.13, align 1
  %3612 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.13 = call zeroext i8 @mult(i8 zeroext %3611, i8 zeroext %3612)
  %conv35.15.13 = zext i8 %call34.15.13 to i32
  %xor36.15.13 = xor i32 %xor.15.13, %conv35.15.13
  %conv37.15.13 = trunc i32 %xor36.15.13 to i8
  store i8 %conv37.15.13, i8* %scevgep41.15.12, align 1
  %scevgep28.15.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3606, i64 0, i64 0, i64 1
  %3613 = bitcast i8* %scevgep28.15.13 to [41 x [41 x i8]]*
  %scevgep41.15.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3607, i64 0, i64 1, i64 0
  %3614 = bitcast i8* %scevgep41.15.13 to [41 x [41 x i8]]*
  %call16.15.14 = call zeroext i8 (...) @rand()
  store i8 %call16.15.14, i8* %scevgep28.15.13, align 1
  %3615 = load i8, i8* %scevgep28.15.13, align 1
  %conv23.15.14 = zext i8 %3615 to i32
  %3616 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.14 = getelementptr i8, i8* %b, i64 30
  %3617 = load i8, i8* %scevgep34.15.14, align 1
  %call28.15.14 = call zeroext i8 @mult(i8 zeroext %3616, i8 zeroext %3617)
  %conv29.15.14 = zext i8 %call28.15.14 to i32
  %xor.15.14 = xor i32 %conv23.15.14, %conv29.15.14
  %scevgep35.15.14 = getelementptr i8, i8* %a, i64 30
  %3618 = load i8, i8* %scevgep35.15.14, align 1
  %3619 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.14 = call zeroext i8 @mult(i8 zeroext %3618, i8 zeroext %3619)
  %conv35.15.14 = zext i8 %call34.15.14 to i32
  %xor36.15.14 = xor i32 %xor.15.14, %conv35.15.14
  %conv37.15.14 = trunc i32 %xor36.15.14 to i8
  store i8 %conv37.15.14, i8* %scevgep41.15.13, align 1
  %scevgep28.15.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3613, i64 0, i64 0, i64 1
  %3620 = bitcast i8* %scevgep28.15.14 to [41 x [41 x i8]]*
  %scevgep41.15.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3614, i64 0, i64 1, i64 0
  %3621 = bitcast i8* %scevgep41.15.14 to [41 x [41 x i8]]*
  %call16.15.15 = call zeroext i8 (...) @rand()
  store i8 %call16.15.15, i8* %scevgep28.15.14, align 1
  %3622 = load i8, i8* %scevgep28.15.14, align 1
  %conv23.15.15 = zext i8 %3622 to i32
  %3623 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.15 = getelementptr i8, i8* %b, i64 31
  %3624 = load i8, i8* %scevgep34.15.15, align 1
  %call28.15.15 = call zeroext i8 @mult(i8 zeroext %3623, i8 zeroext %3624)
  %conv29.15.15 = zext i8 %call28.15.15 to i32
  %xor.15.15 = xor i32 %conv23.15.15, %conv29.15.15
  %scevgep35.15.15 = getelementptr i8, i8* %a, i64 31
  %3625 = load i8, i8* %scevgep35.15.15, align 1
  %3626 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.15 = call zeroext i8 @mult(i8 zeroext %3625, i8 zeroext %3626)
  %conv35.15.15 = zext i8 %call34.15.15 to i32
  %xor36.15.15 = xor i32 %xor.15.15, %conv35.15.15
  %conv37.15.15 = trunc i32 %xor36.15.15 to i8
  store i8 %conv37.15.15, i8* %scevgep41.15.14, align 1
  %scevgep28.15.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3620, i64 0, i64 0, i64 1
  %3627 = bitcast i8* %scevgep28.15.15 to [41 x [41 x i8]]*
  %scevgep41.15.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3621, i64 0, i64 1, i64 0
  %3628 = bitcast i8* %scevgep41.15.15 to [41 x [41 x i8]]*
  %call16.15.16 = call zeroext i8 (...) @rand()
  store i8 %call16.15.16, i8* %scevgep28.15.15, align 1
  %3629 = load i8, i8* %scevgep28.15.15, align 1
  %conv23.15.16 = zext i8 %3629 to i32
  %3630 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.16 = getelementptr i8, i8* %b, i64 32
  %3631 = load i8, i8* %scevgep34.15.16, align 1
  %call28.15.16 = call zeroext i8 @mult(i8 zeroext %3630, i8 zeroext %3631)
  %conv29.15.16 = zext i8 %call28.15.16 to i32
  %xor.15.16 = xor i32 %conv23.15.16, %conv29.15.16
  %scevgep35.15.16 = getelementptr i8, i8* %a, i64 32
  %3632 = load i8, i8* %scevgep35.15.16, align 1
  %3633 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.16 = call zeroext i8 @mult(i8 zeroext %3632, i8 zeroext %3633)
  %conv35.15.16 = zext i8 %call34.15.16 to i32
  %xor36.15.16 = xor i32 %xor.15.16, %conv35.15.16
  %conv37.15.16 = trunc i32 %xor36.15.16 to i8
  store i8 %conv37.15.16, i8* %scevgep41.15.15, align 1
  %scevgep28.15.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3627, i64 0, i64 0, i64 1
  %3634 = bitcast i8* %scevgep28.15.16 to [41 x [41 x i8]]*
  %scevgep41.15.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3628, i64 0, i64 1, i64 0
  %3635 = bitcast i8* %scevgep41.15.16 to [41 x [41 x i8]]*
  %call16.15.17 = call zeroext i8 (...) @rand()
  store i8 %call16.15.17, i8* %scevgep28.15.16, align 1
  %3636 = load i8, i8* %scevgep28.15.16, align 1
  %conv23.15.17 = zext i8 %3636 to i32
  %3637 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.17 = getelementptr i8, i8* %b, i64 33
  %3638 = load i8, i8* %scevgep34.15.17, align 1
  %call28.15.17 = call zeroext i8 @mult(i8 zeroext %3637, i8 zeroext %3638)
  %conv29.15.17 = zext i8 %call28.15.17 to i32
  %xor.15.17 = xor i32 %conv23.15.17, %conv29.15.17
  %scevgep35.15.17 = getelementptr i8, i8* %a, i64 33
  %3639 = load i8, i8* %scevgep35.15.17, align 1
  %3640 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.17 = call zeroext i8 @mult(i8 zeroext %3639, i8 zeroext %3640)
  %conv35.15.17 = zext i8 %call34.15.17 to i32
  %xor36.15.17 = xor i32 %xor.15.17, %conv35.15.17
  %conv37.15.17 = trunc i32 %xor36.15.17 to i8
  store i8 %conv37.15.17, i8* %scevgep41.15.16, align 1
  %scevgep28.15.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3634, i64 0, i64 0, i64 1
  %3641 = bitcast i8* %scevgep28.15.17 to [41 x [41 x i8]]*
  %scevgep41.15.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3635, i64 0, i64 1, i64 0
  %3642 = bitcast i8* %scevgep41.15.17 to [41 x [41 x i8]]*
  %call16.15.18 = call zeroext i8 (...) @rand()
  store i8 %call16.15.18, i8* %scevgep28.15.17, align 1
  %3643 = load i8, i8* %scevgep28.15.17, align 1
  %conv23.15.18 = zext i8 %3643 to i32
  %3644 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.18 = getelementptr i8, i8* %b, i64 34
  %3645 = load i8, i8* %scevgep34.15.18, align 1
  %call28.15.18 = call zeroext i8 @mult(i8 zeroext %3644, i8 zeroext %3645)
  %conv29.15.18 = zext i8 %call28.15.18 to i32
  %xor.15.18 = xor i32 %conv23.15.18, %conv29.15.18
  %scevgep35.15.18 = getelementptr i8, i8* %a, i64 34
  %3646 = load i8, i8* %scevgep35.15.18, align 1
  %3647 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.18 = call zeroext i8 @mult(i8 zeroext %3646, i8 zeroext %3647)
  %conv35.15.18 = zext i8 %call34.15.18 to i32
  %xor36.15.18 = xor i32 %xor.15.18, %conv35.15.18
  %conv37.15.18 = trunc i32 %xor36.15.18 to i8
  store i8 %conv37.15.18, i8* %scevgep41.15.17, align 1
  %scevgep28.15.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3641, i64 0, i64 0, i64 1
  %3648 = bitcast i8* %scevgep28.15.18 to [41 x [41 x i8]]*
  %scevgep41.15.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3642, i64 0, i64 1, i64 0
  %3649 = bitcast i8* %scevgep41.15.18 to [41 x [41 x i8]]*
  %call16.15.19 = call zeroext i8 (...) @rand()
  store i8 %call16.15.19, i8* %scevgep28.15.18, align 1
  %3650 = load i8, i8* %scevgep28.15.18, align 1
  %conv23.15.19 = zext i8 %3650 to i32
  %3651 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.19 = getelementptr i8, i8* %b, i64 35
  %3652 = load i8, i8* %scevgep34.15.19, align 1
  %call28.15.19 = call zeroext i8 @mult(i8 zeroext %3651, i8 zeroext %3652)
  %conv29.15.19 = zext i8 %call28.15.19 to i32
  %xor.15.19 = xor i32 %conv23.15.19, %conv29.15.19
  %scevgep35.15.19 = getelementptr i8, i8* %a, i64 35
  %3653 = load i8, i8* %scevgep35.15.19, align 1
  %3654 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.19 = call zeroext i8 @mult(i8 zeroext %3653, i8 zeroext %3654)
  %conv35.15.19 = zext i8 %call34.15.19 to i32
  %xor36.15.19 = xor i32 %xor.15.19, %conv35.15.19
  %conv37.15.19 = trunc i32 %xor36.15.19 to i8
  store i8 %conv37.15.19, i8* %scevgep41.15.18, align 1
  %scevgep28.15.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3648, i64 0, i64 0, i64 1
  %3655 = bitcast i8* %scevgep28.15.19 to [41 x [41 x i8]]*
  %scevgep41.15.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3649, i64 0, i64 1, i64 0
  %3656 = bitcast i8* %scevgep41.15.19 to [41 x [41 x i8]]*
  %call16.15.20 = call zeroext i8 (...) @rand()
  store i8 %call16.15.20, i8* %scevgep28.15.19, align 1
  %3657 = load i8, i8* %scevgep28.15.19, align 1
  %conv23.15.20 = zext i8 %3657 to i32
  %3658 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.20 = getelementptr i8, i8* %b, i64 36
  %3659 = load i8, i8* %scevgep34.15.20, align 1
  %call28.15.20 = call zeroext i8 @mult(i8 zeroext %3658, i8 zeroext %3659)
  %conv29.15.20 = zext i8 %call28.15.20 to i32
  %xor.15.20 = xor i32 %conv23.15.20, %conv29.15.20
  %scevgep35.15.20 = getelementptr i8, i8* %a, i64 36
  %3660 = load i8, i8* %scevgep35.15.20, align 1
  %3661 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.20 = call zeroext i8 @mult(i8 zeroext %3660, i8 zeroext %3661)
  %conv35.15.20 = zext i8 %call34.15.20 to i32
  %xor36.15.20 = xor i32 %xor.15.20, %conv35.15.20
  %conv37.15.20 = trunc i32 %xor36.15.20 to i8
  store i8 %conv37.15.20, i8* %scevgep41.15.19, align 1
  %scevgep28.15.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3655, i64 0, i64 0, i64 1
  %3662 = bitcast i8* %scevgep28.15.20 to [41 x [41 x i8]]*
  %scevgep41.15.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3656, i64 0, i64 1, i64 0
  %3663 = bitcast i8* %scevgep41.15.20 to [41 x [41 x i8]]*
  %call16.15.21 = call zeroext i8 (...) @rand()
  store i8 %call16.15.21, i8* %scevgep28.15.20, align 1
  %3664 = load i8, i8* %scevgep28.15.20, align 1
  %conv23.15.21 = zext i8 %3664 to i32
  %3665 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.21 = getelementptr i8, i8* %b, i64 37
  %3666 = load i8, i8* %scevgep34.15.21, align 1
  %call28.15.21 = call zeroext i8 @mult(i8 zeroext %3665, i8 zeroext %3666)
  %conv29.15.21 = zext i8 %call28.15.21 to i32
  %xor.15.21 = xor i32 %conv23.15.21, %conv29.15.21
  %scevgep35.15.21 = getelementptr i8, i8* %a, i64 37
  %3667 = load i8, i8* %scevgep35.15.21, align 1
  %3668 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.21 = call zeroext i8 @mult(i8 zeroext %3667, i8 zeroext %3668)
  %conv35.15.21 = zext i8 %call34.15.21 to i32
  %xor36.15.21 = xor i32 %xor.15.21, %conv35.15.21
  %conv37.15.21 = trunc i32 %xor36.15.21 to i8
  store i8 %conv37.15.21, i8* %scevgep41.15.20, align 1
  %scevgep28.15.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3662, i64 0, i64 0, i64 1
  %3669 = bitcast i8* %scevgep28.15.21 to [41 x [41 x i8]]*
  %scevgep41.15.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3663, i64 0, i64 1, i64 0
  %3670 = bitcast i8* %scevgep41.15.21 to [41 x [41 x i8]]*
  %call16.15.22 = call zeroext i8 (...) @rand()
  store i8 %call16.15.22, i8* %scevgep28.15.21, align 1
  %3671 = load i8, i8* %scevgep28.15.21, align 1
  %conv23.15.22 = zext i8 %3671 to i32
  %3672 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.22 = getelementptr i8, i8* %b, i64 38
  %3673 = load i8, i8* %scevgep34.15.22, align 1
  %call28.15.22 = call zeroext i8 @mult(i8 zeroext %3672, i8 zeroext %3673)
  %conv29.15.22 = zext i8 %call28.15.22 to i32
  %xor.15.22 = xor i32 %conv23.15.22, %conv29.15.22
  %scevgep35.15.22 = getelementptr i8, i8* %a, i64 38
  %3674 = load i8, i8* %scevgep35.15.22, align 1
  %3675 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.22 = call zeroext i8 @mult(i8 zeroext %3674, i8 zeroext %3675)
  %conv35.15.22 = zext i8 %call34.15.22 to i32
  %xor36.15.22 = xor i32 %xor.15.22, %conv35.15.22
  %conv37.15.22 = trunc i32 %xor36.15.22 to i8
  store i8 %conv37.15.22, i8* %scevgep41.15.21, align 1
  %scevgep28.15.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3669, i64 0, i64 0, i64 1
  %3676 = bitcast i8* %scevgep28.15.22 to [41 x [41 x i8]]*
  %scevgep41.15.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3670, i64 0, i64 1, i64 0
  %3677 = bitcast i8* %scevgep41.15.22 to [41 x [41 x i8]]*
  %call16.15.23 = call zeroext i8 (...) @rand()
  store i8 %call16.15.23, i8* %scevgep28.15.22, align 1
  %3678 = load i8, i8* %scevgep28.15.22, align 1
  %conv23.15.23 = zext i8 %3678 to i32
  %3679 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.23 = getelementptr i8, i8* %b, i64 39
  %3680 = load i8, i8* %scevgep34.15.23, align 1
  %call28.15.23 = call zeroext i8 @mult(i8 zeroext %3679, i8 zeroext %3680)
  %conv29.15.23 = zext i8 %call28.15.23 to i32
  %xor.15.23 = xor i32 %conv23.15.23, %conv29.15.23
  %scevgep35.15.23 = getelementptr i8, i8* %a, i64 39
  %3681 = load i8, i8* %scevgep35.15.23, align 1
  %3682 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.23 = call zeroext i8 @mult(i8 zeroext %3681, i8 zeroext %3682)
  %conv35.15.23 = zext i8 %call34.15.23 to i32
  %xor36.15.23 = xor i32 %xor.15.23, %conv35.15.23
  %conv37.15.23 = trunc i32 %xor36.15.23 to i8
  store i8 %conv37.15.23, i8* %scevgep41.15.22, align 1
  %scevgep28.15.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3676, i64 0, i64 0, i64 1
  %scevgep41.15.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3677, i64 0, i64 1, i64 0
  %call16.15.24 = call zeroext i8 (...) @rand()
  store i8 %call16.15.24, i8* %scevgep28.15.23, align 1
  %3683 = load i8, i8* %scevgep28.15.23, align 1
  %conv23.15.24 = zext i8 %3683 to i32
  %3684 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.24 = getelementptr i8, i8* %b, i64 40
  %3685 = load i8, i8* %scevgep34.15.24, align 1
  %call28.15.24 = call zeroext i8 @mult(i8 zeroext %3684, i8 zeroext %3685)
  %conv29.15.24 = zext i8 %call28.15.24 to i32
  %xor.15.24 = xor i32 %conv23.15.24, %conv29.15.24
  %scevgep35.15.24 = getelementptr i8, i8* %a, i64 40
  %3686 = load i8, i8* %scevgep35.15.24, align 1
  %3687 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.24 = call zeroext i8 @mult(i8 zeroext %3686, i8 zeroext %3687)
  %conv35.15.24 = zext i8 %call34.15.24 to i32
  %xor36.15.24 = xor i32 %xor.15.24, %conv35.15.24
  %conv37.15.24 = trunc i32 %xor36.15.24 to i8
  store i8 %conv37.15.24, i8* %scevgep41.15.23, align 1
  %scevgep26.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3515, i64 0, i64 1, i64 1
  %3688 = bitcast i8* %scevgep26.15 to [41 x [41 x i8]]*
  %scevgep39.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3516, i64 0, i64 1, i64 1
  %3689 = bitcast i8* %scevgep39.15 to [41 x [41 x i8]]*
  %arrayidx25.16 = getelementptr inbounds i8, i8* %a, i64 16
  %arrayidx33.16 = getelementptr inbounds i8, i8* %b, i64 16
  %call16.16 = call zeroext i8 (...) @rand()
  store i8 %call16.16, i8* %scevgep26.15, align 1
  %3690 = load i8, i8* %scevgep26.15, align 1
  %conv23.16 = zext i8 %3690 to i32
  %3691 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16 = getelementptr i8, i8* %b, i64 17
  %3692 = load i8, i8* %scevgep34.16, align 1
  %call28.16 = call zeroext i8 @mult(i8 zeroext %3691, i8 zeroext %3692)
  %conv29.16 = zext i8 %call28.16 to i32
  %xor.16 = xor i32 %conv23.16, %conv29.16
  %scevgep35.16 = getelementptr i8, i8* %a, i64 17
  %3693 = load i8, i8* %scevgep35.16, align 1
  %3694 = load i8, i8* %arrayidx33.16, align 1
  %call34.16 = call zeroext i8 @mult(i8 zeroext %3693, i8 zeroext %3694)
  %conv35.16 = zext i8 %call34.16 to i32
  %xor36.16 = xor i32 %xor.16, %conv35.16
  %conv37.16 = trunc i32 %xor36.16 to i8
  store i8 %conv37.16, i8* %scevgep39.15, align 1
  %scevgep28.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3688, i64 0, i64 0, i64 1
  %3695 = bitcast i8* %scevgep28.16 to [41 x [41 x i8]]*
  %scevgep41.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3689, i64 0, i64 1, i64 0
  %3696 = bitcast i8* %scevgep41.16 to [41 x [41 x i8]]*
  %call16.16.1 = call zeroext i8 (...) @rand()
  store i8 %call16.16.1, i8* %scevgep28.16, align 1
  %3697 = load i8, i8* %scevgep28.16, align 1
  %conv23.16.1 = zext i8 %3697 to i32
  %3698 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.1 = getelementptr i8, i8* %b, i64 18
  %3699 = load i8, i8* %scevgep34.16.1, align 1
  %call28.16.1 = call zeroext i8 @mult(i8 zeroext %3698, i8 zeroext %3699)
  %conv29.16.1 = zext i8 %call28.16.1 to i32
  %xor.16.1 = xor i32 %conv23.16.1, %conv29.16.1
  %scevgep35.16.1 = getelementptr i8, i8* %a, i64 18
  %3700 = load i8, i8* %scevgep35.16.1, align 1
  %3701 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.1 = call zeroext i8 @mult(i8 zeroext %3700, i8 zeroext %3701)
  %conv35.16.1 = zext i8 %call34.16.1 to i32
  %xor36.16.1 = xor i32 %xor.16.1, %conv35.16.1
  %conv37.16.1 = trunc i32 %xor36.16.1 to i8
  store i8 %conv37.16.1, i8* %scevgep41.16, align 1
  %scevgep28.16.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3695, i64 0, i64 0, i64 1
  %3702 = bitcast i8* %scevgep28.16.1 to [41 x [41 x i8]]*
  %scevgep41.16.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3696, i64 0, i64 1, i64 0
  %3703 = bitcast i8* %scevgep41.16.1 to [41 x [41 x i8]]*
  %call16.16.2 = call zeroext i8 (...) @rand()
  store i8 %call16.16.2, i8* %scevgep28.16.1, align 1
  %3704 = load i8, i8* %scevgep28.16.1, align 1
  %conv23.16.2 = zext i8 %3704 to i32
  %3705 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.2 = getelementptr i8, i8* %b, i64 19
  %3706 = load i8, i8* %scevgep34.16.2, align 1
  %call28.16.2 = call zeroext i8 @mult(i8 zeroext %3705, i8 zeroext %3706)
  %conv29.16.2 = zext i8 %call28.16.2 to i32
  %xor.16.2 = xor i32 %conv23.16.2, %conv29.16.2
  %scevgep35.16.2 = getelementptr i8, i8* %a, i64 19
  %3707 = load i8, i8* %scevgep35.16.2, align 1
  %3708 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.2 = call zeroext i8 @mult(i8 zeroext %3707, i8 zeroext %3708)
  %conv35.16.2 = zext i8 %call34.16.2 to i32
  %xor36.16.2 = xor i32 %xor.16.2, %conv35.16.2
  %conv37.16.2 = trunc i32 %xor36.16.2 to i8
  store i8 %conv37.16.2, i8* %scevgep41.16.1, align 1
  %scevgep28.16.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3702, i64 0, i64 0, i64 1
  %3709 = bitcast i8* %scevgep28.16.2 to [41 x [41 x i8]]*
  %scevgep41.16.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3703, i64 0, i64 1, i64 0
  %3710 = bitcast i8* %scevgep41.16.2 to [41 x [41 x i8]]*
  %call16.16.3 = call zeroext i8 (...) @rand()
  store i8 %call16.16.3, i8* %scevgep28.16.2, align 1
  %3711 = load i8, i8* %scevgep28.16.2, align 1
  %conv23.16.3 = zext i8 %3711 to i32
  %3712 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.3 = getelementptr i8, i8* %b, i64 20
  %3713 = load i8, i8* %scevgep34.16.3, align 1
  %call28.16.3 = call zeroext i8 @mult(i8 zeroext %3712, i8 zeroext %3713)
  %conv29.16.3 = zext i8 %call28.16.3 to i32
  %xor.16.3 = xor i32 %conv23.16.3, %conv29.16.3
  %scevgep35.16.3 = getelementptr i8, i8* %a, i64 20
  %3714 = load i8, i8* %scevgep35.16.3, align 1
  %3715 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.3 = call zeroext i8 @mult(i8 zeroext %3714, i8 zeroext %3715)
  %conv35.16.3 = zext i8 %call34.16.3 to i32
  %xor36.16.3 = xor i32 %xor.16.3, %conv35.16.3
  %conv37.16.3 = trunc i32 %xor36.16.3 to i8
  store i8 %conv37.16.3, i8* %scevgep41.16.2, align 1
  %scevgep28.16.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3709, i64 0, i64 0, i64 1
  %3716 = bitcast i8* %scevgep28.16.3 to [41 x [41 x i8]]*
  %scevgep41.16.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3710, i64 0, i64 1, i64 0
  %3717 = bitcast i8* %scevgep41.16.3 to [41 x [41 x i8]]*
  %call16.16.4 = call zeroext i8 (...) @rand()
  store i8 %call16.16.4, i8* %scevgep28.16.3, align 1
  %3718 = load i8, i8* %scevgep28.16.3, align 1
  %conv23.16.4 = zext i8 %3718 to i32
  %3719 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.4 = getelementptr i8, i8* %b, i64 21
  %3720 = load i8, i8* %scevgep34.16.4, align 1
  %call28.16.4 = call zeroext i8 @mult(i8 zeroext %3719, i8 zeroext %3720)
  %conv29.16.4 = zext i8 %call28.16.4 to i32
  %xor.16.4 = xor i32 %conv23.16.4, %conv29.16.4
  %scevgep35.16.4 = getelementptr i8, i8* %a, i64 21
  %3721 = load i8, i8* %scevgep35.16.4, align 1
  %3722 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.4 = call zeroext i8 @mult(i8 zeroext %3721, i8 zeroext %3722)
  %conv35.16.4 = zext i8 %call34.16.4 to i32
  %xor36.16.4 = xor i32 %xor.16.4, %conv35.16.4
  %conv37.16.4 = trunc i32 %xor36.16.4 to i8
  store i8 %conv37.16.4, i8* %scevgep41.16.3, align 1
  %scevgep28.16.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3716, i64 0, i64 0, i64 1
  %3723 = bitcast i8* %scevgep28.16.4 to [41 x [41 x i8]]*
  %scevgep41.16.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3717, i64 0, i64 1, i64 0
  %3724 = bitcast i8* %scevgep41.16.4 to [41 x [41 x i8]]*
  %call16.16.5 = call zeroext i8 (...) @rand()
  store i8 %call16.16.5, i8* %scevgep28.16.4, align 1
  %3725 = load i8, i8* %scevgep28.16.4, align 1
  %conv23.16.5 = zext i8 %3725 to i32
  %3726 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.5 = getelementptr i8, i8* %b, i64 22
  %3727 = load i8, i8* %scevgep34.16.5, align 1
  %call28.16.5 = call zeroext i8 @mult(i8 zeroext %3726, i8 zeroext %3727)
  %conv29.16.5 = zext i8 %call28.16.5 to i32
  %xor.16.5 = xor i32 %conv23.16.5, %conv29.16.5
  %scevgep35.16.5 = getelementptr i8, i8* %a, i64 22
  %3728 = load i8, i8* %scevgep35.16.5, align 1
  %3729 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.5 = call zeroext i8 @mult(i8 zeroext %3728, i8 zeroext %3729)
  %conv35.16.5 = zext i8 %call34.16.5 to i32
  %xor36.16.5 = xor i32 %xor.16.5, %conv35.16.5
  %conv37.16.5 = trunc i32 %xor36.16.5 to i8
  store i8 %conv37.16.5, i8* %scevgep41.16.4, align 1
  %scevgep28.16.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3723, i64 0, i64 0, i64 1
  %3730 = bitcast i8* %scevgep28.16.5 to [41 x [41 x i8]]*
  %scevgep41.16.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3724, i64 0, i64 1, i64 0
  %3731 = bitcast i8* %scevgep41.16.5 to [41 x [41 x i8]]*
  %call16.16.6 = call zeroext i8 (...) @rand()
  store i8 %call16.16.6, i8* %scevgep28.16.5, align 1
  %3732 = load i8, i8* %scevgep28.16.5, align 1
  %conv23.16.6 = zext i8 %3732 to i32
  %3733 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.6 = getelementptr i8, i8* %b, i64 23
  %3734 = load i8, i8* %scevgep34.16.6, align 1
  %call28.16.6 = call zeroext i8 @mult(i8 zeroext %3733, i8 zeroext %3734)
  %conv29.16.6 = zext i8 %call28.16.6 to i32
  %xor.16.6 = xor i32 %conv23.16.6, %conv29.16.6
  %scevgep35.16.6 = getelementptr i8, i8* %a, i64 23
  %3735 = load i8, i8* %scevgep35.16.6, align 1
  %3736 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.6 = call zeroext i8 @mult(i8 zeroext %3735, i8 zeroext %3736)
  %conv35.16.6 = zext i8 %call34.16.6 to i32
  %xor36.16.6 = xor i32 %xor.16.6, %conv35.16.6
  %conv37.16.6 = trunc i32 %xor36.16.6 to i8
  store i8 %conv37.16.6, i8* %scevgep41.16.5, align 1
  %scevgep28.16.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3730, i64 0, i64 0, i64 1
  %3737 = bitcast i8* %scevgep28.16.6 to [41 x [41 x i8]]*
  %scevgep41.16.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3731, i64 0, i64 1, i64 0
  %3738 = bitcast i8* %scevgep41.16.6 to [41 x [41 x i8]]*
  %call16.16.7 = call zeroext i8 (...) @rand()
  store i8 %call16.16.7, i8* %scevgep28.16.6, align 1
  %3739 = load i8, i8* %scevgep28.16.6, align 1
  %conv23.16.7 = zext i8 %3739 to i32
  %3740 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.7 = getelementptr i8, i8* %b, i64 24
  %3741 = load i8, i8* %scevgep34.16.7, align 1
  %call28.16.7 = call zeroext i8 @mult(i8 zeroext %3740, i8 zeroext %3741)
  %conv29.16.7 = zext i8 %call28.16.7 to i32
  %xor.16.7 = xor i32 %conv23.16.7, %conv29.16.7
  %scevgep35.16.7 = getelementptr i8, i8* %a, i64 24
  %3742 = load i8, i8* %scevgep35.16.7, align 1
  %3743 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.7 = call zeroext i8 @mult(i8 zeroext %3742, i8 zeroext %3743)
  %conv35.16.7 = zext i8 %call34.16.7 to i32
  %xor36.16.7 = xor i32 %xor.16.7, %conv35.16.7
  %conv37.16.7 = trunc i32 %xor36.16.7 to i8
  store i8 %conv37.16.7, i8* %scevgep41.16.6, align 1
  %scevgep28.16.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3737, i64 0, i64 0, i64 1
  %3744 = bitcast i8* %scevgep28.16.7 to [41 x [41 x i8]]*
  %scevgep41.16.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3738, i64 0, i64 1, i64 0
  %3745 = bitcast i8* %scevgep41.16.7 to [41 x [41 x i8]]*
  %call16.16.8 = call zeroext i8 (...) @rand()
  store i8 %call16.16.8, i8* %scevgep28.16.7, align 1
  %3746 = load i8, i8* %scevgep28.16.7, align 1
  %conv23.16.8 = zext i8 %3746 to i32
  %3747 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.8 = getelementptr i8, i8* %b, i64 25
  %3748 = load i8, i8* %scevgep34.16.8, align 1
  %call28.16.8 = call zeroext i8 @mult(i8 zeroext %3747, i8 zeroext %3748)
  %conv29.16.8 = zext i8 %call28.16.8 to i32
  %xor.16.8 = xor i32 %conv23.16.8, %conv29.16.8
  %scevgep35.16.8 = getelementptr i8, i8* %a, i64 25
  %3749 = load i8, i8* %scevgep35.16.8, align 1
  %3750 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.8 = call zeroext i8 @mult(i8 zeroext %3749, i8 zeroext %3750)
  %conv35.16.8 = zext i8 %call34.16.8 to i32
  %xor36.16.8 = xor i32 %xor.16.8, %conv35.16.8
  %conv37.16.8 = trunc i32 %xor36.16.8 to i8
  store i8 %conv37.16.8, i8* %scevgep41.16.7, align 1
  %scevgep28.16.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3744, i64 0, i64 0, i64 1
  %3751 = bitcast i8* %scevgep28.16.8 to [41 x [41 x i8]]*
  %scevgep41.16.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3745, i64 0, i64 1, i64 0
  %3752 = bitcast i8* %scevgep41.16.8 to [41 x [41 x i8]]*
  %call16.16.9 = call zeroext i8 (...) @rand()
  store i8 %call16.16.9, i8* %scevgep28.16.8, align 1
  %3753 = load i8, i8* %scevgep28.16.8, align 1
  %conv23.16.9 = zext i8 %3753 to i32
  %3754 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.9 = getelementptr i8, i8* %b, i64 26
  %3755 = load i8, i8* %scevgep34.16.9, align 1
  %call28.16.9 = call zeroext i8 @mult(i8 zeroext %3754, i8 zeroext %3755)
  %conv29.16.9 = zext i8 %call28.16.9 to i32
  %xor.16.9 = xor i32 %conv23.16.9, %conv29.16.9
  %scevgep35.16.9 = getelementptr i8, i8* %a, i64 26
  %3756 = load i8, i8* %scevgep35.16.9, align 1
  %3757 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.9 = call zeroext i8 @mult(i8 zeroext %3756, i8 zeroext %3757)
  %conv35.16.9 = zext i8 %call34.16.9 to i32
  %xor36.16.9 = xor i32 %xor.16.9, %conv35.16.9
  %conv37.16.9 = trunc i32 %xor36.16.9 to i8
  store i8 %conv37.16.9, i8* %scevgep41.16.8, align 1
  %scevgep28.16.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3751, i64 0, i64 0, i64 1
  %3758 = bitcast i8* %scevgep28.16.9 to [41 x [41 x i8]]*
  %scevgep41.16.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3752, i64 0, i64 1, i64 0
  %3759 = bitcast i8* %scevgep41.16.9 to [41 x [41 x i8]]*
  %call16.16.10 = call zeroext i8 (...) @rand()
  store i8 %call16.16.10, i8* %scevgep28.16.9, align 1
  %3760 = load i8, i8* %scevgep28.16.9, align 1
  %conv23.16.10 = zext i8 %3760 to i32
  %3761 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.10 = getelementptr i8, i8* %b, i64 27
  %3762 = load i8, i8* %scevgep34.16.10, align 1
  %call28.16.10 = call zeroext i8 @mult(i8 zeroext %3761, i8 zeroext %3762)
  %conv29.16.10 = zext i8 %call28.16.10 to i32
  %xor.16.10 = xor i32 %conv23.16.10, %conv29.16.10
  %scevgep35.16.10 = getelementptr i8, i8* %a, i64 27
  %3763 = load i8, i8* %scevgep35.16.10, align 1
  %3764 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.10 = call zeroext i8 @mult(i8 zeroext %3763, i8 zeroext %3764)
  %conv35.16.10 = zext i8 %call34.16.10 to i32
  %xor36.16.10 = xor i32 %xor.16.10, %conv35.16.10
  %conv37.16.10 = trunc i32 %xor36.16.10 to i8
  store i8 %conv37.16.10, i8* %scevgep41.16.9, align 1
  %scevgep28.16.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3758, i64 0, i64 0, i64 1
  %3765 = bitcast i8* %scevgep28.16.10 to [41 x [41 x i8]]*
  %scevgep41.16.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3759, i64 0, i64 1, i64 0
  %3766 = bitcast i8* %scevgep41.16.10 to [41 x [41 x i8]]*
  %call16.16.11 = call zeroext i8 (...) @rand()
  store i8 %call16.16.11, i8* %scevgep28.16.10, align 1
  %3767 = load i8, i8* %scevgep28.16.10, align 1
  %conv23.16.11 = zext i8 %3767 to i32
  %3768 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.11 = getelementptr i8, i8* %b, i64 28
  %3769 = load i8, i8* %scevgep34.16.11, align 1
  %call28.16.11 = call zeroext i8 @mult(i8 zeroext %3768, i8 zeroext %3769)
  %conv29.16.11 = zext i8 %call28.16.11 to i32
  %xor.16.11 = xor i32 %conv23.16.11, %conv29.16.11
  %scevgep35.16.11 = getelementptr i8, i8* %a, i64 28
  %3770 = load i8, i8* %scevgep35.16.11, align 1
  %3771 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.11 = call zeroext i8 @mult(i8 zeroext %3770, i8 zeroext %3771)
  %conv35.16.11 = zext i8 %call34.16.11 to i32
  %xor36.16.11 = xor i32 %xor.16.11, %conv35.16.11
  %conv37.16.11 = trunc i32 %xor36.16.11 to i8
  store i8 %conv37.16.11, i8* %scevgep41.16.10, align 1
  %scevgep28.16.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3765, i64 0, i64 0, i64 1
  %3772 = bitcast i8* %scevgep28.16.11 to [41 x [41 x i8]]*
  %scevgep41.16.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3766, i64 0, i64 1, i64 0
  %3773 = bitcast i8* %scevgep41.16.11 to [41 x [41 x i8]]*
  %call16.16.12 = call zeroext i8 (...) @rand()
  store i8 %call16.16.12, i8* %scevgep28.16.11, align 1
  %3774 = load i8, i8* %scevgep28.16.11, align 1
  %conv23.16.12 = zext i8 %3774 to i32
  %3775 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.12 = getelementptr i8, i8* %b, i64 29
  %3776 = load i8, i8* %scevgep34.16.12, align 1
  %call28.16.12 = call zeroext i8 @mult(i8 zeroext %3775, i8 zeroext %3776)
  %conv29.16.12 = zext i8 %call28.16.12 to i32
  %xor.16.12 = xor i32 %conv23.16.12, %conv29.16.12
  %scevgep35.16.12 = getelementptr i8, i8* %a, i64 29
  %3777 = load i8, i8* %scevgep35.16.12, align 1
  %3778 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.12 = call zeroext i8 @mult(i8 zeroext %3777, i8 zeroext %3778)
  %conv35.16.12 = zext i8 %call34.16.12 to i32
  %xor36.16.12 = xor i32 %xor.16.12, %conv35.16.12
  %conv37.16.12 = trunc i32 %xor36.16.12 to i8
  store i8 %conv37.16.12, i8* %scevgep41.16.11, align 1
  %scevgep28.16.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3772, i64 0, i64 0, i64 1
  %3779 = bitcast i8* %scevgep28.16.12 to [41 x [41 x i8]]*
  %scevgep41.16.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3773, i64 0, i64 1, i64 0
  %3780 = bitcast i8* %scevgep41.16.12 to [41 x [41 x i8]]*
  %call16.16.13 = call zeroext i8 (...) @rand()
  store i8 %call16.16.13, i8* %scevgep28.16.12, align 1
  %3781 = load i8, i8* %scevgep28.16.12, align 1
  %conv23.16.13 = zext i8 %3781 to i32
  %3782 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.13 = getelementptr i8, i8* %b, i64 30
  %3783 = load i8, i8* %scevgep34.16.13, align 1
  %call28.16.13 = call zeroext i8 @mult(i8 zeroext %3782, i8 zeroext %3783)
  %conv29.16.13 = zext i8 %call28.16.13 to i32
  %xor.16.13 = xor i32 %conv23.16.13, %conv29.16.13
  %scevgep35.16.13 = getelementptr i8, i8* %a, i64 30
  %3784 = load i8, i8* %scevgep35.16.13, align 1
  %3785 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.13 = call zeroext i8 @mult(i8 zeroext %3784, i8 zeroext %3785)
  %conv35.16.13 = zext i8 %call34.16.13 to i32
  %xor36.16.13 = xor i32 %xor.16.13, %conv35.16.13
  %conv37.16.13 = trunc i32 %xor36.16.13 to i8
  store i8 %conv37.16.13, i8* %scevgep41.16.12, align 1
  %scevgep28.16.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3779, i64 0, i64 0, i64 1
  %3786 = bitcast i8* %scevgep28.16.13 to [41 x [41 x i8]]*
  %scevgep41.16.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3780, i64 0, i64 1, i64 0
  %3787 = bitcast i8* %scevgep41.16.13 to [41 x [41 x i8]]*
  %call16.16.14 = call zeroext i8 (...) @rand()
  store i8 %call16.16.14, i8* %scevgep28.16.13, align 1
  %3788 = load i8, i8* %scevgep28.16.13, align 1
  %conv23.16.14 = zext i8 %3788 to i32
  %3789 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.14 = getelementptr i8, i8* %b, i64 31
  %3790 = load i8, i8* %scevgep34.16.14, align 1
  %call28.16.14 = call zeroext i8 @mult(i8 zeroext %3789, i8 zeroext %3790)
  %conv29.16.14 = zext i8 %call28.16.14 to i32
  %xor.16.14 = xor i32 %conv23.16.14, %conv29.16.14
  %scevgep35.16.14 = getelementptr i8, i8* %a, i64 31
  %3791 = load i8, i8* %scevgep35.16.14, align 1
  %3792 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.14 = call zeroext i8 @mult(i8 zeroext %3791, i8 zeroext %3792)
  %conv35.16.14 = zext i8 %call34.16.14 to i32
  %xor36.16.14 = xor i32 %xor.16.14, %conv35.16.14
  %conv37.16.14 = trunc i32 %xor36.16.14 to i8
  store i8 %conv37.16.14, i8* %scevgep41.16.13, align 1
  %scevgep28.16.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3786, i64 0, i64 0, i64 1
  %3793 = bitcast i8* %scevgep28.16.14 to [41 x [41 x i8]]*
  %scevgep41.16.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3787, i64 0, i64 1, i64 0
  %3794 = bitcast i8* %scevgep41.16.14 to [41 x [41 x i8]]*
  %call16.16.15 = call zeroext i8 (...) @rand()
  store i8 %call16.16.15, i8* %scevgep28.16.14, align 1
  %3795 = load i8, i8* %scevgep28.16.14, align 1
  %conv23.16.15 = zext i8 %3795 to i32
  %3796 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.15 = getelementptr i8, i8* %b, i64 32
  %3797 = load i8, i8* %scevgep34.16.15, align 1
  %call28.16.15 = call zeroext i8 @mult(i8 zeroext %3796, i8 zeroext %3797)
  %conv29.16.15 = zext i8 %call28.16.15 to i32
  %xor.16.15 = xor i32 %conv23.16.15, %conv29.16.15
  %scevgep35.16.15 = getelementptr i8, i8* %a, i64 32
  %3798 = load i8, i8* %scevgep35.16.15, align 1
  %3799 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.15 = call zeroext i8 @mult(i8 zeroext %3798, i8 zeroext %3799)
  %conv35.16.15 = zext i8 %call34.16.15 to i32
  %xor36.16.15 = xor i32 %xor.16.15, %conv35.16.15
  %conv37.16.15 = trunc i32 %xor36.16.15 to i8
  store i8 %conv37.16.15, i8* %scevgep41.16.14, align 1
  %scevgep28.16.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3793, i64 0, i64 0, i64 1
  %3800 = bitcast i8* %scevgep28.16.15 to [41 x [41 x i8]]*
  %scevgep41.16.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3794, i64 0, i64 1, i64 0
  %3801 = bitcast i8* %scevgep41.16.15 to [41 x [41 x i8]]*
  %call16.16.16 = call zeroext i8 (...) @rand()
  store i8 %call16.16.16, i8* %scevgep28.16.15, align 1
  %3802 = load i8, i8* %scevgep28.16.15, align 1
  %conv23.16.16 = zext i8 %3802 to i32
  %3803 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.16 = getelementptr i8, i8* %b, i64 33
  %3804 = load i8, i8* %scevgep34.16.16, align 1
  %call28.16.16 = call zeroext i8 @mult(i8 zeroext %3803, i8 zeroext %3804)
  %conv29.16.16 = zext i8 %call28.16.16 to i32
  %xor.16.16 = xor i32 %conv23.16.16, %conv29.16.16
  %scevgep35.16.16 = getelementptr i8, i8* %a, i64 33
  %3805 = load i8, i8* %scevgep35.16.16, align 1
  %3806 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.16 = call zeroext i8 @mult(i8 zeroext %3805, i8 zeroext %3806)
  %conv35.16.16 = zext i8 %call34.16.16 to i32
  %xor36.16.16 = xor i32 %xor.16.16, %conv35.16.16
  %conv37.16.16 = trunc i32 %xor36.16.16 to i8
  store i8 %conv37.16.16, i8* %scevgep41.16.15, align 1
  %scevgep28.16.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3800, i64 0, i64 0, i64 1
  %3807 = bitcast i8* %scevgep28.16.16 to [41 x [41 x i8]]*
  %scevgep41.16.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3801, i64 0, i64 1, i64 0
  %3808 = bitcast i8* %scevgep41.16.16 to [41 x [41 x i8]]*
  %call16.16.17 = call zeroext i8 (...) @rand()
  store i8 %call16.16.17, i8* %scevgep28.16.16, align 1
  %3809 = load i8, i8* %scevgep28.16.16, align 1
  %conv23.16.17 = zext i8 %3809 to i32
  %3810 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.17 = getelementptr i8, i8* %b, i64 34
  %3811 = load i8, i8* %scevgep34.16.17, align 1
  %call28.16.17 = call zeroext i8 @mult(i8 zeroext %3810, i8 zeroext %3811)
  %conv29.16.17 = zext i8 %call28.16.17 to i32
  %xor.16.17 = xor i32 %conv23.16.17, %conv29.16.17
  %scevgep35.16.17 = getelementptr i8, i8* %a, i64 34
  %3812 = load i8, i8* %scevgep35.16.17, align 1
  %3813 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.17 = call zeroext i8 @mult(i8 zeroext %3812, i8 zeroext %3813)
  %conv35.16.17 = zext i8 %call34.16.17 to i32
  %xor36.16.17 = xor i32 %xor.16.17, %conv35.16.17
  %conv37.16.17 = trunc i32 %xor36.16.17 to i8
  store i8 %conv37.16.17, i8* %scevgep41.16.16, align 1
  %scevgep28.16.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3807, i64 0, i64 0, i64 1
  %3814 = bitcast i8* %scevgep28.16.17 to [41 x [41 x i8]]*
  %scevgep41.16.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3808, i64 0, i64 1, i64 0
  %3815 = bitcast i8* %scevgep41.16.17 to [41 x [41 x i8]]*
  %call16.16.18 = call zeroext i8 (...) @rand()
  store i8 %call16.16.18, i8* %scevgep28.16.17, align 1
  %3816 = load i8, i8* %scevgep28.16.17, align 1
  %conv23.16.18 = zext i8 %3816 to i32
  %3817 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.18 = getelementptr i8, i8* %b, i64 35
  %3818 = load i8, i8* %scevgep34.16.18, align 1
  %call28.16.18 = call zeroext i8 @mult(i8 zeroext %3817, i8 zeroext %3818)
  %conv29.16.18 = zext i8 %call28.16.18 to i32
  %xor.16.18 = xor i32 %conv23.16.18, %conv29.16.18
  %scevgep35.16.18 = getelementptr i8, i8* %a, i64 35
  %3819 = load i8, i8* %scevgep35.16.18, align 1
  %3820 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.18 = call zeroext i8 @mult(i8 zeroext %3819, i8 zeroext %3820)
  %conv35.16.18 = zext i8 %call34.16.18 to i32
  %xor36.16.18 = xor i32 %xor.16.18, %conv35.16.18
  %conv37.16.18 = trunc i32 %xor36.16.18 to i8
  store i8 %conv37.16.18, i8* %scevgep41.16.17, align 1
  %scevgep28.16.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3814, i64 0, i64 0, i64 1
  %3821 = bitcast i8* %scevgep28.16.18 to [41 x [41 x i8]]*
  %scevgep41.16.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3815, i64 0, i64 1, i64 0
  %3822 = bitcast i8* %scevgep41.16.18 to [41 x [41 x i8]]*
  %call16.16.19 = call zeroext i8 (...) @rand()
  store i8 %call16.16.19, i8* %scevgep28.16.18, align 1
  %3823 = load i8, i8* %scevgep28.16.18, align 1
  %conv23.16.19 = zext i8 %3823 to i32
  %3824 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.19 = getelementptr i8, i8* %b, i64 36
  %3825 = load i8, i8* %scevgep34.16.19, align 1
  %call28.16.19 = call zeroext i8 @mult(i8 zeroext %3824, i8 zeroext %3825)
  %conv29.16.19 = zext i8 %call28.16.19 to i32
  %xor.16.19 = xor i32 %conv23.16.19, %conv29.16.19
  %scevgep35.16.19 = getelementptr i8, i8* %a, i64 36
  %3826 = load i8, i8* %scevgep35.16.19, align 1
  %3827 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.19 = call zeroext i8 @mult(i8 zeroext %3826, i8 zeroext %3827)
  %conv35.16.19 = zext i8 %call34.16.19 to i32
  %xor36.16.19 = xor i32 %xor.16.19, %conv35.16.19
  %conv37.16.19 = trunc i32 %xor36.16.19 to i8
  store i8 %conv37.16.19, i8* %scevgep41.16.18, align 1
  %scevgep28.16.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3821, i64 0, i64 0, i64 1
  %3828 = bitcast i8* %scevgep28.16.19 to [41 x [41 x i8]]*
  %scevgep41.16.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3822, i64 0, i64 1, i64 0
  %3829 = bitcast i8* %scevgep41.16.19 to [41 x [41 x i8]]*
  %call16.16.20 = call zeroext i8 (...) @rand()
  store i8 %call16.16.20, i8* %scevgep28.16.19, align 1
  %3830 = load i8, i8* %scevgep28.16.19, align 1
  %conv23.16.20 = zext i8 %3830 to i32
  %3831 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.20 = getelementptr i8, i8* %b, i64 37
  %3832 = load i8, i8* %scevgep34.16.20, align 1
  %call28.16.20 = call zeroext i8 @mult(i8 zeroext %3831, i8 zeroext %3832)
  %conv29.16.20 = zext i8 %call28.16.20 to i32
  %xor.16.20 = xor i32 %conv23.16.20, %conv29.16.20
  %scevgep35.16.20 = getelementptr i8, i8* %a, i64 37
  %3833 = load i8, i8* %scevgep35.16.20, align 1
  %3834 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.20 = call zeroext i8 @mult(i8 zeroext %3833, i8 zeroext %3834)
  %conv35.16.20 = zext i8 %call34.16.20 to i32
  %xor36.16.20 = xor i32 %xor.16.20, %conv35.16.20
  %conv37.16.20 = trunc i32 %xor36.16.20 to i8
  store i8 %conv37.16.20, i8* %scevgep41.16.19, align 1
  %scevgep28.16.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3828, i64 0, i64 0, i64 1
  %3835 = bitcast i8* %scevgep28.16.20 to [41 x [41 x i8]]*
  %scevgep41.16.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3829, i64 0, i64 1, i64 0
  %3836 = bitcast i8* %scevgep41.16.20 to [41 x [41 x i8]]*
  %call16.16.21 = call zeroext i8 (...) @rand()
  store i8 %call16.16.21, i8* %scevgep28.16.20, align 1
  %3837 = load i8, i8* %scevgep28.16.20, align 1
  %conv23.16.21 = zext i8 %3837 to i32
  %3838 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.21 = getelementptr i8, i8* %b, i64 38
  %3839 = load i8, i8* %scevgep34.16.21, align 1
  %call28.16.21 = call zeroext i8 @mult(i8 zeroext %3838, i8 zeroext %3839)
  %conv29.16.21 = zext i8 %call28.16.21 to i32
  %xor.16.21 = xor i32 %conv23.16.21, %conv29.16.21
  %scevgep35.16.21 = getelementptr i8, i8* %a, i64 38
  %3840 = load i8, i8* %scevgep35.16.21, align 1
  %3841 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.21 = call zeroext i8 @mult(i8 zeroext %3840, i8 zeroext %3841)
  %conv35.16.21 = zext i8 %call34.16.21 to i32
  %xor36.16.21 = xor i32 %xor.16.21, %conv35.16.21
  %conv37.16.21 = trunc i32 %xor36.16.21 to i8
  store i8 %conv37.16.21, i8* %scevgep41.16.20, align 1
  %scevgep28.16.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3835, i64 0, i64 0, i64 1
  %3842 = bitcast i8* %scevgep28.16.21 to [41 x [41 x i8]]*
  %scevgep41.16.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3836, i64 0, i64 1, i64 0
  %3843 = bitcast i8* %scevgep41.16.21 to [41 x [41 x i8]]*
  %call16.16.22 = call zeroext i8 (...) @rand()
  store i8 %call16.16.22, i8* %scevgep28.16.21, align 1
  %3844 = load i8, i8* %scevgep28.16.21, align 1
  %conv23.16.22 = zext i8 %3844 to i32
  %3845 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.22 = getelementptr i8, i8* %b, i64 39
  %3846 = load i8, i8* %scevgep34.16.22, align 1
  %call28.16.22 = call zeroext i8 @mult(i8 zeroext %3845, i8 zeroext %3846)
  %conv29.16.22 = zext i8 %call28.16.22 to i32
  %xor.16.22 = xor i32 %conv23.16.22, %conv29.16.22
  %scevgep35.16.22 = getelementptr i8, i8* %a, i64 39
  %3847 = load i8, i8* %scevgep35.16.22, align 1
  %3848 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.22 = call zeroext i8 @mult(i8 zeroext %3847, i8 zeroext %3848)
  %conv35.16.22 = zext i8 %call34.16.22 to i32
  %xor36.16.22 = xor i32 %xor.16.22, %conv35.16.22
  %conv37.16.22 = trunc i32 %xor36.16.22 to i8
  store i8 %conv37.16.22, i8* %scevgep41.16.21, align 1
  %scevgep28.16.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3842, i64 0, i64 0, i64 1
  %scevgep41.16.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3843, i64 0, i64 1, i64 0
  %call16.16.23 = call zeroext i8 (...) @rand()
  store i8 %call16.16.23, i8* %scevgep28.16.22, align 1
  %3849 = load i8, i8* %scevgep28.16.22, align 1
  %conv23.16.23 = zext i8 %3849 to i32
  %3850 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.23 = getelementptr i8, i8* %b, i64 40
  %3851 = load i8, i8* %scevgep34.16.23, align 1
  %call28.16.23 = call zeroext i8 @mult(i8 zeroext %3850, i8 zeroext %3851)
  %conv29.16.23 = zext i8 %call28.16.23 to i32
  %xor.16.23 = xor i32 %conv23.16.23, %conv29.16.23
  %scevgep35.16.23 = getelementptr i8, i8* %a, i64 40
  %3852 = load i8, i8* %scevgep35.16.23, align 1
  %3853 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.23 = call zeroext i8 @mult(i8 zeroext %3852, i8 zeroext %3853)
  %conv35.16.23 = zext i8 %call34.16.23 to i32
  %xor36.16.23 = xor i32 %xor.16.23, %conv35.16.23
  %conv37.16.23 = trunc i32 %xor36.16.23 to i8
  store i8 %conv37.16.23, i8* %scevgep41.16.22, align 1
  %scevgep26.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3688, i64 0, i64 1, i64 1
  %3854 = bitcast i8* %scevgep26.16 to [41 x [41 x i8]]*
  %scevgep39.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3689, i64 0, i64 1, i64 1
  %3855 = bitcast i8* %scevgep39.16 to [41 x [41 x i8]]*
  %arrayidx25.17 = getelementptr inbounds i8, i8* %a, i64 17
  %arrayidx33.17 = getelementptr inbounds i8, i8* %b, i64 17
  %call16.17 = call zeroext i8 (...) @rand()
  store i8 %call16.17, i8* %scevgep26.16, align 1
  %3856 = load i8, i8* %scevgep26.16, align 1
  %conv23.17 = zext i8 %3856 to i32
  %3857 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17 = getelementptr i8, i8* %b, i64 18
  %3858 = load i8, i8* %scevgep34.17, align 1
  %call28.17 = call zeroext i8 @mult(i8 zeroext %3857, i8 zeroext %3858)
  %conv29.17 = zext i8 %call28.17 to i32
  %xor.17 = xor i32 %conv23.17, %conv29.17
  %scevgep35.17 = getelementptr i8, i8* %a, i64 18
  %3859 = load i8, i8* %scevgep35.17, align 1
  %3860 = load i8, i8* %arrayidx33.17, align 1
  %call34.17 = call zeroext i8 @mult(i8 zeroext %3859, i8 zeroext %3860)
  %conv35.17 = zext i8 %call34.17 to i32
  %xor36.17 = xor i32 %xor.17, %conv35.17
  %conv37.17 = trunc i32 %xor36.17 to i8
  store i8 %conv37.17, i8* %scevgep39.16, align 1
  %scevgep28.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3854, i64 0, i64 0, i64 1
  %3861 = bitcast i8* %scevgep28.17 to [41 x [41 x i8]]*
  %scevgep41.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3855, i64 0, i64 1, i64 0
  %3862 = bitcast i8* %scevgep41.17 to [41 x [41 x i8]]*
  %call16.17.1 = call zeroext i8 (...) @rand()
  store i8 %call16.17.1, i8* %scevgep28.17, align 1
  %3863 = load i8, i8* %scevgep28.17, align 1
  %conv23.17.1 = zext i8 %3863 to i32
  %3864 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.1 = getelementptr i8, i8* %b, i64 19
  %3865 = load i8, i8* %scevgep34.17.1, align 1
  %call28.17.1 = call zeroext i8 @mult(i8 zeroext %3864, i8 zeroext %3865)
  %conv29.17.1 = zext i8 %call28.17.1 to i32
  %xor.17.1 = xor i32 %conv23.17.1, %conv29.17.1
  %scevgep35.17.1 = getelementptr i8, i8* %a, i64 19
  %3866 = load i8, i8* %scevgep35.17.1, align 1
  %3867 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.1 = call zeroext i8 @mult(i8 zeroext %3866, i8 zeroext %3867)
  %conv35.17.1 = zext i8 %call34.17.1 to i32
  %xor36.17.1 = xor i32 %xor.17.1, %conv35.17.1
  %conv37.17.1 = trunc i32 %xor36.17.1 to i8
  store i8 %conv37.17.1, i8* %scevgep41.17, align 1
  %scevgep28.17.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3861, i64 0, i64 0, i64 1
  %3868 = bitcast i8* %scevgep28.17.1 to [41 x [41 x i8]]*
  %scevgep41.17.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3862, i64 0, i64 1, i64 0
  %3869 = bitcast i8* %scevgep41.17.1 to [41 x [41 x i8]]*
  %call16.17.2 = call zeroext i8 (...) @rand()
  store i8 %call16.17.2, i8* %scevgep28.17.1, align 1
  %3870 = load i8, i8* %scevgep28.17.1, align 1
  %conv23.17.2 = zext i8 %3870 to i32
  %3871 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.2 = getelementptr i8, i8* %b, i64 20
  %3872 = load i8, i8* %scevgep34.17.2, align 1
  %call28.17.2 = call zeroext i8 @mult(i8 zeroext %3871, i8 zeroext %3872)
  %conv29.17.2 = zext i8 %call28.17.2 to i32
  %xor.17.2 = xor i32 %conv23.17.2, %conv29.17.2
  %scevgep35.17.2 = getelementptr i8, i8* %a, i64 20
  %3873 = load i8, i8* %scevgep35.17.2, align 1
  %3874 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.2 = call zeroext i8 @mult(i8 zeroext %3873, i8 zeroext %3874)
  %conv35.17.2 = zext i8 %call34.17.2 to i32
  %xor36.17.2 = xor i32 %xor.17.2, %conv35.17.2
  %conv37.17.2 = trunc i32 %xor36.17.2 to i8
  store i8 %conv37.17.2, i8* %scevgep41.17.1, align 1
  %scevgep28.17.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3868, i64 0, i64 0, i64 1
  %3875 = bitcast i8* %scevgep28.17.2 to [41 x [41 x i8]]*
  %scevgep41.17.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3869, i64 0, i64 1, i64 0
  %3876 = bitcast i8* %scevgep41.17.2 to [41 x [41 x i8]]*
  %call16.17.3 = call zeroext i8 (...) @rand()
  store i8 %call16.17.3, i8* %scevgep28.17.2, align 1
  %3877 = load i8, i8* %scevgep28.17.2, align 1
  %conv23.17.3 = zext i8 %3877 to i32
  %3878 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.3 = getelementptr i8, i8* %b, i64 21
  %3879 = load i8, i8* %scevgep34.17.3, align 1
  %call28.17.3 = call zeroext i8 @mult(i8 zeroext %3878, i8 zeroext %3879)
  %conv29.17.3 = zext i8 %call28.17.3 to i32
  %xor.17.3 = xor i32 %conv23.17.3, %conv29.17.3
  %scevgep35.17.3 = getelementptr i8, i8* %a, i64 21
  %3880 = load i8, i8* %scevgep35.17.3, align 1
  %3881 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.3 = call zeroext i8 @mult(i8 zeroext %3880, i8 zeroext %3881)
  %conv35.17.3 = zext i8 %call34.17.3 to i32
  %xor36.17.3 = xor i32 %xor.17.3, %conv35.17.3
  %conv37.17.3 = trunc i32 %xor36.17.3 to i8
  store i8 %conv37.17.3, i8* %scevgep41.17.2, align 1
  %scevgep28.17.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3875, i64 0, i64 0, i64 1
  %3882 = bitcast i8* %scevgep28.17.3 to [41 x [41 x i8]]*
  %scevgep41.17.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3876, i64 0, i64 1, i64 0
  %3883 = bitcast i8* %scevgep41.17.3 to [41 x [41 x i8]]*
  %call16.17.4 = call zeroext i8 (...) @rand()
  store i8 %call16.17.4, i8* %scevgep28.17.3, align 1
  %3884 = load i8, i8* %scevgep28.17.3, align 1
  %conv23.17.4 = zext i8 %3884 to i32
  %3885 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.4 = getelementptr i8, i8* %b, i64 22
  %3886 = load i8, i8* %scevgep34.17.4, align 1
  %call28.17.4 = call zeroext i8 @mult(i8 zeroext %3885, i8 zeroext %3886)
  %conv29.17.4 = zext i8 %call28.17.4 to i32
  %xor.17.4 = xor i32 %conv23.17.4, %conv29.17.4
  %scevgep35.17.4 = getelementptr i8, i8* %a, i64 22
  %3887 = load i8, i8* %scevgep35.17.4, align 1
  %3888 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.4 = call zeroext i8 @mult(i8 zeroext %3887, i8 zeroext %3888)
  %conv35.17.4 = zext i8 %call34.17.4 to i32
  %xor36.17.4 = xor i32 %xor.17.4, %conv35.17.4
  %conv37.17.4 = trunc i32 %xor36.17.4 to i8
  store i8 %conv37.17.4, i8* %scevgep41.17.3, align 1
  %scevgep28.17.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3882, i64 0, i64 0, i64 1
  %3889 = bitcast i8* %scevgep28.17.4 to [41 x [41 x i8]]*
  %scevgep41.17.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3883, i64 0, i64 1, i64 0
  %3890 = bitcast i8* %scevgep41.17.4 to [41 x [41 x i8]]*
  %call16.17.5 = call zeroext i8 (...) @rand()
  store i8 %call16.17.5, i8* %scevgep28.17.4, align 1
  %3891 = load i8, i8* %scevgep28.17.4, align 1
  %conv23.17.5 = zext i8 %3891 to i32
  %3892 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.5 = getelementptr i8, i8* %b, i64 23
  %3893 = load i8, i8* %scevgep34.17.5, align 1
  %call28.17.5 = call zeroext i8 @mult(i8 zeroext %3892, i8 zeroext %3893)
  %conv29.17.5 = zext i8 %call28.17.5 to i32
  %xor.17.5 = xor i32 %conv23.17.5, %conv29.17.5
  %scevgep35.17.5 = getelementptr i8, i8* %a, i64 23
  %3894 = load i8, i8* %scevgep35.17.5, align 1
  %3895 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.5 = call zeroext i8 @mult(i8 zeroext %3894, i8 zeroext %3895)
  %conv35.17.5 = zext i8 %call34.17.5 to i32
  %xor36.17.5 = xor i32 %xor.17.5, %conv35.17.5
  %conv37.17.5 = trunc i32 %xor36.17.5 to i8
  store i8 %conv37.17.5, i8* %scevgep41.17.4, align 1
  %scevgep28.17.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3889, i64 0, i64 0, i64 1
  %3896 = bitcast i8* %scevgep28.17.5 to [41 x [41 x i8]]*
  %scevgep41.17.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3890, i64 0, i64 1, i64 0
  %3897 = bitcast i8* %scevgep41.17.5 to [41 x [41 x i8]]*
  %call16.17.6 = call zeroext i8 (...) @rand()
  store i8 %call16.17.6, i8* %scevgep28.17.5, align 1
  %3898 = load i8, i8* %scevgep28.17.5, align 1
  %conv23.17.6 = zext i8 %3898 to i32
  %3899 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.6 = getelementptr i8, i8* %b, i64 24
  %3900 = load i8, i8* %scevgep34.17.6, align 1
  %call28.17.6 = call zeroext i8 @mult(i8 zeroext %3899, i8 zeroext %3900)
  %conv29.17.6 = zext i8 %call28.17.6 to i32
  %xor.17.6 = xor i32 %conv23.17.6, %conv29.17.6
  %scevgep35.17.6 = getelementptr i8, i8* %a, i64 24
  %3901 = load i8, i8* %scevgep35.17.6, align 1
  %3902 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.6 = call zeroext i8 @mult(i8 zeroext %3901, i8 zeroext %3902)
  %conv35.17.6 = zext i8 %call34.17.6 to i32
  %xor36.17.6 = xor i32 %xor.17.6, %conv35.17.6
  %conv37.17.6 = trunc i32 %xor36.17.6 to i8
  store i8 %conv37.17.6, i8* %scevgep41.17.5, align 1
  %scevgep28.17.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3896, i64 0, i64 0, i64 1
  %3903 = bitcast i8* %scevgep28.17.6 to [41 x [41 x i8]]*
  %scevgep41.17.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3897, i64 0, i64 1, i64 0
  %3904 = bitcast i8* %scevgep41.17.6 to [41 x [41 x i8]]*
  %call16.17.7 = call zeroext i8 (...) @rand()
  store i8 %call16.17.7, i8* %scevgep28.17.6, align 1
  %3905 = load i8, i8* %scevgep28.17.6, align 1
  %conv23.17.7 = zext i8 %3905 to i32
  %3906 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.7 = getelementptr i8, i8* %b, i64 25
  %3907 = load i8, i8* %scevgep34.17.7, align 1
  %call28.17.7 = call zeroext i8 @mult(i8 zeroext %3906, i8 zeroext %3907)
  %conv29.17.7 = zext i8 %call28.17.7 to i32
  %xor.17.7 = xor i32 %conv23.17.7, %conv29.17.7
  %scevgep35.17.7 = getelementptr i8, i8* %a, i64 25
  %3908 = load i8, i8* %scevgep35.17.7, align 1
  %3909 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.7 = call zeroext i8 @mult(i8 zeroext %3908, i8 zeroext %3909)
  %conv35.17.7 = zext i8 %call34.17.7 to i32
  %xor36.17.7 = xor i32 %xor.17.7, %conv35.17.7
  %conv37.17.7 = trunc i32 %xor36.17.7 to i8
  store i8 %conv37.17.7, i8* %scevgep41.17.6, align 1
  %scevgep28.17.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3903, i64 0, i64 0, i64 1
  %3910 = bitcast i8* %scevgep28.17.7 to [41 x [41 x i8]]*
  %scevgep41.17.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3904, i64 0, i64 1, i64 0
  %3911 = bitcast i8* %scevgep41.17.7 to [41 x [41 x i8]]*
  %call16.17.8 = call zeroext i8 (...) @rand()
  store i8 %call16.17.8, i8* %scevgep28.17.7, align 1
  %3912 = load i8, i8* %scevgep28.17.7, align 1
  %conv23.17.8 = zext i8 %3912 to i32
  %3913 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.8 = getelementptr i8, i8* %b, i64 26
  %3914 = load i8, i8* %scevgep34.17.8, align 1
  %call28.17.8 = call zeroext i8 @mult(i8 zeroext %3913, i8 zeroext %3914)
  %conv29.17.8 = zext i8 %call28.17.8 to i32
  %xor.17.8 = xor i32 %conv23.17.8, %conv29.17.8
  %scevgep35.17.8 = getelementptr i8, i8* %a, i64 26
  %3915 = load i8, i8* %scevgep35.17.8, align 1
  %3916 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.8 = call zeroext i8 @mult(i8 zeroext %3915, i8 zeroext %3916)
  %conv35.17.8 = zext i8 %call34.17.8 to i32
  %xor36.17.8 = xor i32 %xor.17.8, %conv35.17.8
  %conv37.17.8 = trunc i32 %xor36.17.8 to i8
  store i8 %conv37.17.8, i8* %scevgep41.17.7, align 1
  %scevgep28.17.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3910, i64 0, i64 0, i64 1
  %3917 = bitcast i8* %scevgep28.17.8 to [41 x [41 x i8]]*
  %scevgep41.17.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3911, i64 0, i64 1, i64 0
  %3918 = bitcast i8* %scevgep41.17.8 to [41 x [41 x i8]]*
  %call16.17.9 = call zeroext i8 (...) @rand()
  store i8 %call16.17.9, i8* %scevgep28.17.8, align 1
  %3919 = load i8, i8* %scevgep28.17.8, align 1
  %conv23.17.9 = zext i8 %3919 to i32
  %3920 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.9 = getelementptr i8, i8* %b, i64 27
  %3921 = load i8, i8* %scevgep34.17.9, align 1
  %call28.17.9 = call zeroext i8 @mult(i8 zeroext %3920, i8 zeroext %3921)
  %conv29.17.9 = zext i8 %call28.17.9 to i32
  %xor.17.9 = xor i32 %conv23.17.9, %conv29.17.9
  %scevgep35.17.9 = getelementptr i8, i8* %a, i64 27
  %3922 = load i8, i8* %scevgep35.17.9, align 1
  %3923 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.9 = call zeroext i8 @mult(i8 zeroext %3922, i8 zeroext %3923)
  %conv35.17.9 = zext i8 %call34.17.9 to i32
  %xor36.17.9 = xor i32 %xor.17.9, %conv35.17.9
  %conv37.17.9 = trunc i32 %xor36.17.9 to i8
  store i8 %conv37.17.9, i8* %scevgep41.17.8, align 1
  %scevgep28.17.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3917, i64 0, i64 0, i64 1
  %3924 = bitcast i8* %scevgep28.17.9 to [41 x [41 x i8]]*
  %scevgep41.17.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3918, i64 0, i64 1, i64 0
  %3925 = bitcast i8* %scevgep41.17.9 to [41 x [41 x i8]]*
  %call16.17.10 = call zeroext i8 (...) @rand()
  store i8 %call16.17.10, i8* %scevgep28.17.9, align 1
  %3926 = load i8, i8* %scevgep28.17.9, align 1
  %conv23.17.10 = zext i8 %3926 to i32
  %3927 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.10 = getelementptr i8, i8* %b, i64 28
  %3928 = load i8, i8* %scevgep34.17.10, align 1
  %call28.17.10 = call zeroext i8 @mult(i8 zeroext %3927, i8 zeroext %3928)
  %conv29.17.10 = zext i8 %call28.17.10 to i32
  %xor.17.10 = xor i32 %conv23.17.10, %conv29.17.10
  %scevgep35.17.10 = getelementptr i8, i8* %a, i64 28
  %3929 = load i8, i8* %scevgep35.17.10, align 1
  %3930 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.10 = call zeroext i8 @mult(i8 zeroext %3929, i8 zeroext %3930)
  %conv35.17.10 = zext i8 %call34.17.10 to i32
  %xor36.17.10 = xor i32 %xor.17.10, %conv35.17.10
  %conv37.17.10 = trunc i32 %xor36.17.10 to i8
  store i8 %conv37.17.10, i8* %scevgep41.17.9, align 1
  %scevgep28.17.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3924, i64 0, i64 0, i64 1
  %3931 = bitcast i8* %scevgep28.17.10 to [41 x [41 x i8]]*
  %scevgep41.17.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3925, i64 0, i64 1, i64 0
  %3932 = bitcast i8* %scevgep41.17.10 to [41 x [41 x i8]]*
  %call16.17.11 = call zeroext i8 (...) @rand()
  store i8 %call16.17.11, i8* %scevgep28.17.10, align 1
  %3933 = load i8, i8* %scevgep28.17.10, align 1
  %conv23.17.11 = zext i8 %3933 to i32
  %3934 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.11 = getelementptr i8, i8* %b, i64 29
  %3935 = load i8, i8* %scevgep34.17.11, align 1
  %call28.17.11 = call zeroext i8 @mult(i8 zeroext %3934, i8 zeroext %3935)
  %conv29.17.11 = zext i8 %call28.17.11 to i32
  %xor.17.11 = xor i32 %conv23.17.11, %conv29.17.11
  %scevgep35.17.11 = getelementptr i8, i8* %a, i64 29
  %3936 = load i8, i8* %scevgep35.17.11, align 1
  %3937 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.11 = call zeroext i8 @mult(i8 zeroext %3936, i8 zeroext %3937)
  %conv35.17.11 = zext i8 %call34.17.11 to i32
  %xor36.17.11 = xor i32 %xor.17.11, %conv35.17.11
  %conv37.17.11 = trunc i32 %xor36.17.11 to i8
  store i8 %conv37.17.11, i8* %scevgep41.17.10, align 1
  %scevgep28.17.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3931, i64 0, i64 0, i64 1
  %3938 = bitcast i8* %scevgep28.17.11 to [41 x [41 x i8]]*
  %scevgep41.17.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3932, i64 0, i64 1, i64 0
  %3939 = bitcast i8* %scevgep41.17.11 to [41 x [41 x i8]]*
  %call16.17.12 = call zeroext i8 (...) @rand()
  store i8 %call16.17.12, i8* %scevgep28.17.11, align 1
  %3940 = load i8, i8* %scevgep28.17.11, align 1
  %conv23.17.12 = zext i8 %3940 to i32
  %3941 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.12 = getelementptr i8, i8* %b, i64 30
  %3942 = load i8, i8* %scevgep34.17.12, align 1
  %call28.17.12 = call zeroext i8 @mult(i8 zeroext %3941, i8 zeroext %3942)
  %conv29.17.12 = zext i8 %call28.17.12 to i32
  %xor.17.12 = xor i32 %conv23.17.12, %conv29.17.12
  %scevgep35.17.12 = getelementptr i8, i8* %a, i64 30
  %3943 = load i8, i8* %scevgep35.17.12, align 1
  %3944 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.12 = call zeroext i8 @mult(i8 zeroext %3943, i8 zeroext %3944)
  %conv35.17.12 = zext i8 %call34.17.12 to i32
  %xor36.17.12 = xor i32 %xor.17.12, %conv35.17.12
  %conv37.17.12 = trunc i32 %xor36.17.12 to i8
  store i8 %conv37.17.12, i8* %scevgep41.17.11, align 1
  %scevgep28.17.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3938, i64 0, i64 0, i64 1
  %3945 = bitcast i8* %scevgep28.17.12 to [41 x [41 x i8]]*
  %scevgep41.17.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3939, i64 0, i64 1, i64 0
  %3946 = bitcast i8* %scevgep41.17.12 to [41 x [41 x i8]]*
  %call16.17.13 = call zeroext i8 (...) @rand()
  store i8 %call16.17.13, i8* %scevgep28.17.12, align 1
  %3947 = load i8, i8* %scevgep28.17.12, align 1
  %conv23.17.13 = zext i8 %3947 to i32
  %3948 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.13 = getelementptr i8, i8* %b, i64 31
  %3949 = load i8, i8* %scevgep34.17.13, align 1
  %call28.17.13 = call zeroext i8 @mult(i8 zeroext %3948, i8 zeroext %3949)
  %conv29.17.13 = zext i8 %call28.17.13 to i32
  %xor.17.13 = xor i32 %conv23.17.13, %conv29.17.13
  %scevgep35.17.13 = getelementptr i8, i8* %a, i64 31
  %3950 = load i8, i8* %scevgep35.17.13, align 1
  %3951 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.13 = call zeroext i8 @mult(i8 zeroext %3950, i8 zeroext %3951)
  %conv35.17.13 = zext i8 %call34.17.13 to i32
  %xor36.17.13 = xor i32 %xor.17.13, %conv35.17.13
  %conv37.17.13 = trunc i32 %xor36.17.13 to i8
  store i8 %conv37.17.13, i8* %scevgep41.17.12, align 1
  %scevgep28.17.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3945, i64 0, i64 0, i64 1
  %3952 = bitcast i8* %scevgep28.17.13 to [41 x [41 x i8]]*
  %scevgep41.17.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3946, i64 0, i64 1, i64 0
  %3953 = bitcast i8* %scevgep41.17.13 to [41 x [41 x i8]]*
  %call16.17.14 = call zeroext i8 (...) @rand()
  store i8 %call16.17.14, i8* %scevgep28.17.13, align 1
  %3954 = load i8, i8* %scevgep28.17.13, align 1
  %conv23.17.14 = zext i8 %3954 to i32
  %3955 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.14 = getelementptr i8, i8* %b, i64 32
  %3956 = load i8, i8* %scevgep34.17.14, align 1
  %call28.17.14 = call zeroext i8 @mult(i8 zeroext %3955, i8 zeroext %3956)
  %conv29.17.14 = zext i8 %call28.17.14 to i32
  %xor.17.14 = xor i32 %conv23.17.14, %conv29.17.14
  %scevgep35.17.14 = getelementptr i8, i8* %a, i64 32
  %3957 = load i8, i8* %scevgep35.17.14, align 1
  %3958 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.14 = call zeroext i8 @mult(i8 zeroext %3957, i8 zeroext %3958)
  %conv35.17.14 = zext i8 %call34.17.14 to i32
  %xor36.17.14 = xor i32 %xor.17.14, %conv35.17.14
  %conv37.17.14 = trunc i32 %xor36.17.14 to i8
  store i8 %conv37.17.14, i8* %scevgep41.17.13, align 1
  %scevgep28.17.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3952, i64 0, i64 0, i64 1
  %3959 = bitcast i8* %scevgep28.17.14 to [41 x [41 x i8]]*
  %scevgep41.17.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3953, i64 0, i64 1, i64 0
  %3960 = bitcast i8* %scevgep41.17.14 to [41 x [41 x i8]]*
  %call16.17.15 = call zeroext i8 (...) @rand()
  store i8 %call16.17.15, i8* %scevgep28.17.14, align 1
  %3961 = load i8, i8* %scevgep28.17.14, align 1
  %conv23.17.15 = zext i8 %3961 to i32
  %3962 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.15 = getelementptr i8, i8* %b, i64 33
  %3963 = load i8, i8* %scevgep34.17.15, align 1
  %call28.17.15 = call zeroext i8 @mult(i8 zeroext %3962, i8 zeroext %3963)
  %conv29.17.15 = zext i8 %call28.17.15 to i32
  %xor.17.15 = xor i32 %conv23.17.15, %conv29.17.15
  %scevgep35.17.15 = getelementptr i8, i8* %a, i64 33
  %3964 = load i8, i8* %scevgep35.17.15, align 1
  %3965 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.15 = call zeroext i8 @mult(i8 zeroext %3964, i8 zeroext %3965)
  %conv35.17.15 = zext i8 %call34.17.15 to i32
  %xor36.17.15 = xor i32 %xor.17.15, %conv35.17.15
  %conv37.17.15 = trunc i32 %xor36.17.15 to i8
  store i8 %conv37.17.15, i8* %scevgep41.17.14, align 1
  %scevgep28.17.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3959, i64 0, i64 0, i64 1
  %3966 = bitcast i8* %scevgep28.17.15 to [41 x [41 x i8]]*
  %scevgep41.17.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3960, i64 0, i64 1, i64 0
  %3967 = bitcast i8* %scevgep41.17.15 to [41 x [41 x i8]]*
  %call16.17.16 = call zeroext i8 (...) @rand()
  store i8 %call16.17.16, i8* %scevgep28.17.15, align 1
  %3968 = load i8, i8* %scevgep28.17.15, align 1
  %conv23.17.16 = zext i8 %3968 to i32
  %3969 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.16 = getelementptr i8, i8* %b, i64 34
  %3970 = load i8, i8* %scevgep34.17.16, align 1
  %call28.17.16 = call zeroext i8 @mult(i8 zeroext %3969, i8 zeroext %3970)
  %conv29.17.16 = zext i8 %call28.17.16 to i32
  %xor.17.16 = xor i32 %conv23.17.16, %conv29.17.16
  %scevgep35.17.16 = getelementptr i8, i8* %a, i64 34
  %3971 = load i8, i8* %scevgep35.17.16, align 1
  %3972 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.16 = call zeroext i8 @mult(i8 zeroext %3971, i8 zeroext %3972)
  %conv35.17.16 = zext i8 %call34.17.16 to i32
  %xor36.17.16 = xor i32 %xor.17.16, %conv35.17.16
  %conv37.17.16 = trunc i32 %xor36.17.16 to i8
  store i8 %conv37.17.16, i8* %scevgep41.17.15, align 1
  %scevgep28.17.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3966, i64 0, i64 0, i64 1
  %3973 = bitcast i8* %scevgep28.17.16 to [41 x [41 x i8]]*
  %scevgep41.17.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3967, i64 0, i64 1, i64 0
  %3974 = bitcast i8* %scevgep41.17.16 to [41 x [41 x i8]]*
  %call16.17.17 = call zeroext i8 (...) @rand()
  store i8 %call16.17.17, i8* %scevgep28.17.16, align 1
  %3975 = load i8, i8* %scevgep28.17.16, align 1
  %conv23.17.17 = zext i8 %3975 to i32
  %3976 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.17 = getelementptr i8, i8* %b, i64 35
  %3977 = load i8, i8* %scevgep34.17.17, align 1
  %call28.17.17 = call zeroext i8 @mult(i8 zeroext %3976, i8 zeroext %3977)
  %conv29.17.17 = zext i8 %call28.17.17 to i32
  %xor.17.17 = xor i32 %conv23.17.17, %conv29.17.17
  %scevgep35.17.17 = getelementptr i8, i8* %a, i64 35
  %3978 = load i8, i8* %scevgep35.17.17, align 1
  %3979 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.17 = call zeroext i8 @mult(i8 zeroext %3978, i8 zeroext %3979)
  %conv35.17.17 = zext i8 %call34.17.17 to i32
  %xor36.17.17 = xor i32 %xor.17.17, %conv35.17.17
  %conv37.17.17 = trunc i32 %xor36.17.17 to i8
  store i8 %conv37.17.17, i8* %scevgep41.17.16, align 1
  %scevgep28.17.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3973, i64 0, i64 0, i64 1
  %3980 = bitcast i8* %scevgep28.17.17 to [41 x [41 x i8]]*
  %scevgep41.17.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3974, i64 0, i64 1, i64 0
  %3981 = bitcast i8* %scevgep41.17.17 to [41 x [41 x i8]]*
  %call16.17.18 = call zeroext i8 (...) @rand()
  store i8 %call16.17.18, i8* %scevgep28.17.17, align 1
  %3982 = load i8, i8* %scevgep28.17.17, align 1
  %conv23.17.18 = zext i8 %3982 to i32
  %3983 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.18 = getelementptr i8, i8* %b, i64 36
  %3984 = load i8, i8* %scevgep34.17.18, align 1
  %call28.17.18 = call zeroext i8 @mult(i8 zeroext %3983, i8 zeroext %3984)
  %conv29.17.18 = zext i8 %call28.17.18 to i32
  %xor.17.18 = xor i32 %conv23.17.18, %conv29.17.18
  %scevgep35.17.18 = getelementptr i8, i8* %a, i64 36
  %3985 = load i8, i8* %scevgep35.17.18, align 1
  %3986 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.18 = call zeroext i8 @mult(i8 zeroext %3985, i8 zeroext %3986)
  %conv35.17.18 = zext i8 %call34.17.18 to i32
  %xor36.17.18 = xor i32 %xor.17.18, %conv35.17.18
  %conv37.17.18 = trunc i32 %xor36.17.18 to i8
  store i8 %conv37.17.18, i8* %scevgep41.17.17, align 1
  %scevgep28.17.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3980, i64 0, i64 0, i64 1
  %3987 = bitcast i8* %scevgep28.17.18 to [41 x [41 x i8]]*
  %scevgep41.17.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3981, i64 0, i64 1, i64 0
  %3988 = bitcast i8* %scevgep41.17.18 to [41 x [41 x i8]]*
  %call16.17.19 = call zeroext i8 (...) @rand()
  store i8 %call16.17.19, i8* %scevgep28.17.18, align 1
  %3989 = load i8, i8* %scevgep28.17.18, align 1
  %conv23.17.19 = zext i8 %3989 to i32
  %3990 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.19 = getelementptr i8, i8* %b, i64 37
  %3991 = load i8, i8* %scevgep34.17.19, align 1
  %call28.17.19 = call zeroext i8 @mult(i8 zeroext %3990, i8 zeroext %3991)
  %conv29.17.19 = zext i8 %call28.17.19 to i32
  %xor.17.19 = xor i32 %conv23.17.19, %conv29.17.19
  %scevgep35.17.19 = getelementptr i8, i8* %a, i64 37
  %3992 = load i8, i8* %scevgep35.17.19, align 1
  %3993 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.19 = call zeroext i8 @mult(i8 zeroext %3992, i8 zeroext %3993)
  %conv35.17.19 = zext i8 %call34.17.19 to i32
  %xor36.17.19 = xor i32 %xor.17.19, %conv35.17.19
  %conv37.17.19 = trunc i32 %xor36.17.19 to i8
  store i8 %conv37.17.19, i8* %scevgep41.17.18, align 1
  %scevgep28.17.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3987, i64 0, i64 0, i64 1
  %3994 = bitcast i8* %scevgep28.17.19 to [41 x [41 x i8]]*
  %scevgep41.17.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3988, i64 0, i64 1, i64 0
  %3995 = bitcast i8* %scevgep41.17.19 to [41 x [41 x i8]]*
  %call16.17.20 = call zeroext i8 (...) @rand()
  store i8 %call16.17.20, i8* %scevgep28.17.19, align 1
  %3996 = load i8, i8* %scevgep28.17.19, align 1
  %conv23.17.20 = zext i8 %3996 to i32
  %3997 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.20 = getelementptr i8, i8* %b, i64 38
  %3998 = load i8, i8* %scevgep34.17.20, align 1
  %call28.17.20 = call zeroext i8 @mult(i8 zeroext %3997, i8 zeroext %3998)
  %conv29.17.20 = zext i8 %call28.17.20 to i32
  %xor.17.20 = xor i32 %conv23.17.20, %conv29.17.20
  %scevgep35.17.20 = getelementptr i8, i8* %a, i64 38
  %3999 = load i8, i8* %scevgep35.17.20, align 1
  %4000 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.20 = call zeroext i8 @mult(i8 zeroext %3999, i8 zeroext %4000)
  %conv35.17.20 = zext i8 %call34.17.20 to i32
  %xor36.17.20 = xor i32 %xor.17.20, %conv35.17.20
  %conv37.17.20 = trunc i32 %xor36.17.20 to i8
  store i8 %conv37.17.20, i8* %scevgep41.17.19, align 1
  %scevgep28.17.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3994, i64 0, i64 0, i64 1
  %4001 = bitcast i8* %scevgep28.17.20 to [41 x [41 x i8]]*
  %scevgep41.17.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3995, i64 0, i64 1, i64 0
  %4002 = bitcast i8* %scevgep41.17.20 to [41 x [41 x i8]]*
  %call16.17.21 = call zeroext i8 (...) @rand()
  store i8 %call16.17.21, i8* %scevgep28.17.20, align 1
  %4003 = load i8, i8* %scevgep28.17.20, align 1
  %conv23.17.21 = zext i8 %4003 to i32
  %4004 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.21 = getelementptr i8, i8* %b, i64 39
  %4005 = load i8, i8* %scevgep34.17.21, align 1
  %call28.17.21 = call zeroext i8 @mult(i8 zeroext %4004, i8 zeroext %4005)
  %conv29.17.21 = zext i8 %call28.17.21 to i32
  %xor.17.21 = xor i32 %conv23.17.21, %conv29.17.21
  %scevgep35.17.21 = getelementptr i8, i8* %a, i64 39
  %4006 = load i8, i8* %scevgep35.17.21, align 1
  %4007 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.21 = call zeroext i8 @mult(i8 zeroext %4006, i8 zeroext %4007)
  %conv35.17.21 = zext i8 %call34.17.21 to i32
  %xor36.17.21 = xor i32 %xor.17.21, %conv35.17.21
  %conv37.17.21 = trunc i32 %xor36.17.21 to i8
  store i8 %conv37.17.21, i8* %scevgep41.17.20, align 1
  %scevgep28.17.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4001, i64 0, i64 0, i64 1
  %scevgep41.17.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4002, i64 0, i64 1, i64 0
  %call16.17.22 = call zeroext i8 (...) @rand()
  store i8 %call16.17.22, i8* %scevgep28.17.21, align 1
  %4008 = load i8, i8* %scevgep28.17.21, align 1
  %conv23.17.22 = zext i8 %4008 to i32
  %4009 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.22 = getelementptr i8, i8* %b, i64 40
  %4010 = load i8, i8* %scevgep34.17.22, align 1
  %call28.17.22 = call zeroext i8 @mult(i8 zeroext %4009, i8 zeroext %4010)
  %conv29.17.22 = zext i8 %call28.17.22 to i32
  %xor.17.22 = xor i32 %conv23.17.22, %conv29.17.22
  %scevgep35.17.22 = getelementptr i8, i8* %a, i64 40
  %4011 = load i8, i8* %scevgep35.17.22, align 1
  %4012 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.22 = call zeroext i8 @mult(i8 zeroext %4011, i8 zeroext %4012)
  %conv35.17.22 = zext i8 %call34.17.22 to i32
  %xor36.17.22 = xor i32 %xor.17.22, %conv35.17.22
  %conv37.17.22 = trunc i32 %xor36.17.22 to i8
  store i8 %conv37.17.22, i8* %scevgep41.17.21, align 1
  %scevgep26.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3854, i64 0, i64 1, i64 1
  %4013 = bitcast i8* %scevgep26.17 to [41 x [41 x i8]]*
  %scevgep39.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %3855, i64 0, i64 1, i64 1
  %4014 = bitcast i8* %scevgep39.17 to [41 x [41 x i8]]*
  %arrayidx25.18 = getelementptr inbounds i8, i8* %a, i64 18
  %arrayidx33.18 = getelementptr inbounds i8, i8* %b, i64 18
  %call16.18 = call zeroext i8 (...) @rand()
  store i8 %call16.18, i8* %scevgep26.17, align 1
  %4015 = load i8, i8* %scevgep26.17, align 1
  %conv23.18 = zext i8 %4015 to i32
  %4016 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18 = getelementptr i8, i8* %b, i64 19
  %4017 = load i8, i8* %scevgep34.18, align 1
  %call28.18 = call zeroext i8 @mult(i8 zeroext %4016, i8 zeroext %4017)
  %conv29.18 = zext i8 %call28.18 to i32
  %xor.18 = xor i32 %conv23.18, %conv29.18
  %scevgep35.18 = getelementptr i8, i8* %a, i64 19
  %4018 = load i8, i8* %scevgep35.18, align 1
  %4019 = load i8, i8* %arrayidx33.18, align 1
  %call34.18 = call zeroext i8 @mult(i8 zeroext %4018, i8 zeroext %4019)
  %conv35.18 = zext i8 %call34.18 to i32
  %xor36.18 = xor i32 %xor.18, %conv35.18
  %conv37.18 = trunc i32 %xor36.18 to i8
  store i8 %conv37.18, i8* %scevgep39.17, align 1
  %scevgep28.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4013, i64 0, i64 0, i64 1
  %4020 = bitcast i8* %scevgep28.18 to [41 x [41 x i8]]*
  %scevgep41.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4014, i64 0, i64 1, i64 0
  %4021 = bitcast i8* %scevgep41.18 to [41 x [41 x i8]]*
  %call16.18.1 = call zeroext i8 (...) @rand()
  store i8 %call16.18.1, i8* %scevgep28.18, align 1
  %4022 = load i8, i8* %scevgep28.18, align 1
  %conv23.18.1 = zext i8 %4022 to i32
  %4023 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.1 = getelementptr i8, i8* %b, i64 20
  %4024 = load i8, i8* %scevgep34.18.1, align 1
  %call28.18.1 = call zeroext i8 @mult(i8 zeroext %4023, i8 zeroext %4024)
  %conv29.18.1 = zext i8 %call28.18.1 to i32
  %xor.18.1 = xor i32 %conv23.18.1, %conv29.18.1
  %scevgep35.18.1 = getelementptr i8, i8* %a, i64 20
  %4025 = load i8, i8* %scevgep35.18.1, align 1
  %4026 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.1 = call zeroext i8 @mult(i8 zeroext %4025, i8 zeroext %4026)
  %conv35.18.1 = zext i8 %call34.18.1 to i32
  %xor36.18.1 = xor i32 %xor.18.1, %conv35.18.1
  %conv37.18.1 = trunc i32 %xor36.18.1 to i8
  store i8 %conv37.18.1, i8* %scevgep41.18, align 1
  %scevgep28.18.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4020, i64 0, i64 0, i64 1
  %4027 = bitcast i8* %scevgep28.18.1 to [41 x [41 x i8]]*
  %scevgep41.18.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4021, i64 0, i64 1, i64 0
  %4028 = bitcast i8* %scevgep41.18.1 to [41 x [41 x i8]]*
  %call16.18.2 = call zeroext i8 (...) @rand()
  store i8 %call16.18.2, i8* %scevgep28.18.1, align 1
  %4029 = load i8, i8* %scevgep28.18.1, align 1
  %conv23.18.2 = zext i8 %4029 to i32
  %4030 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.2 = getelementptr i8, i8* %b, i64 21
  %4031 = load i8, i8* %scevgep34.18.2, align 1
  %call28.18.2 = call zeroext i8 @mult(i8 zeroext %4030, i8 zeroext %4031)
  %conv29.18.2 = zext i8 %call28.18.2 to i32
  %xor.18.2 = xor i32 %conv23.18.2, %conv29.18.2
  %scevgep35.18.2 = getelementptr i8, i8* %a, i64 21
  %4032 = load i8, i8* %scevgep35.18.2, align 1
  %4033 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.2 = call zeroext i8 @mult(i8 zeroext %4032, i8 zeroext %4033)
  %conv35.18.2 = zext i8 %call34.18.2 to i32
  %xor36.18.2 = xor i32 %xor.18.2, %conv35.18.2
  %conv37.18.2 = trunc i32 %xor36.18.2 to i8
  store i8 %conv37.18.2, i8* %scevgep41.18.1, align 1
  %scevgep28.18.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4027, i64 0, i64 0, i64 1
  %4034 = bitcast i8* %scevgep28.18.2 to [41 x [41 x i8]]*
  %scevgep41.18.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4028, i64 0, i64 1, i64 0
  %4035 = bitcast i8* %scevgep41.18.2 to [41 x [41 x i8]]*
  %call16.18.3 = call zeroext i8 (...) @rand()
  store i8 %call16.18.3, i8* %scevgep28.18.2, align 1
  %4036 = load i8, i8* %scevgep28.18.2, align 1
  %conv23.18.3 = zext i8 %4036 to i32
  %4037 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.3 = getelementptr i8, i8* %b, i64 22
  %4038 = load i8, i8* %scevgep34.18.3, align 1
  %call28.18.3 = call zeroext i8 @mult(i8 zeroext %4037, i8 zeroext %4038)
  %conv29.18.3 = zext i8 %call28.18.3 to i32
  %xor.18.3 = xor i32 %conv23.18.3, %conv29.18.3
  %scevgep35.18.3 = getelementptr i8, i8* %a, i64 22
  %4039 = load i8, i8* %scevgep35.18.3, align 1
  %4040 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.3 = call zeroext i8 @mult(i8 zeroext %4039, i8 zeroext %4040)
  %conv35.18.3 = zext i8 %call34.18.3 to i32
  %xor36.18.3 = xor i32 %xor.18.3, %conv35.18.3
  %conv37.18.3 = trunc i32 %xor36.18.3 to i8
  store i8 %conv37.18.3, i8* %scevgep41.18.2, align 1
  %scevgep28.18.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4034, i64 0, i64 0, i64 1
  %4041 = bitcast i8* %scevgep28.18.3 to [41 x [41 x i8]]*
  %scevgep41.18.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4035, i64 0, i64 1, i64 0
  %4042 = bitcast i8* %scevgep41.18.3 to [41 x [41 x i8]]*
  %call16.18.4 = call zeroext i8 (...) @rand()
  store i8 %call16.18.4, i8* %scevgep28.18.3, align 1
  %4043 = load i8, i8* %scevgep28.18.3, align 1
  %conv23.18.4 = zext i8 %4043 to i32
  %4044 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.4 = getelementptr i8, i8* %b, i64 23
  %4045 = load i8, i8* %scevgep34.18.4, align 1
  %call28.18.4 = call zeroext i8 @mult(i8 zeroext %4044, i8 zeroext %4045)
  %conv29.18.4 = zext i8 %call28.18.4 to i32
  %xor.18.4 = xor i32 %conv23.18.4, %conv29.18.4
  %scevgep35.18.4 = getelementptr i8, i8* %a, i64 23
  %4046 = load i8, i8* %scevgep35.18.4, align 1
  %4047 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.4 = call zeroext i8 @mult(i8 zeroext %4046, i8 zeroext %4047)
  %conv35.18.4 = zext i8 %call34.18.4 to i32
  %xor36.18.4 = xor i32 %xor.18.4, %conv35.18.4
  %conv37.18.4 = trunc i32 %xor36.18.4 to i8
  store i8 %conv37.18.4, i8* %scevgep41.18.3, align 1
  %scevgep28.18.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4041, i64 0, i64 0, i64 1
  %4048 = bitcast i8* %scevgep28.18.4 to [41 x [41 x i8]]*
  %scevgep41.18.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4042, i64 0, i64 1, i64 0
  %4049 = bitcast i8* %scevgep41.18.4 to [41 x [41 x i8]]*
  %call16.18.5 = call zeroext i8 (...) @rand()
  store i8 %call16.18.5, i8* %scevgep28.18.4, align 1
  %4050 = load i8, i8* %scevgep28.18.4, align 1
  %conv23.18.5 = zext i8 %4050 to i32
  %4051 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.5 = getelementptr i8, i8* %b, i64 24
  %4052 = load i8, i8* %scevgep34.18.5, align 1
  %call28.18.5 = call zeroext i8 @mult(i8 zeroext %4051, i8 zeroext %4052)
  %conv29.18.5 = zext i8 %call28.18.5 to i32
  %xor.18.5 = xor i32 %conv23.18.5, %conv29.18.5
  %scevgep35.18.5 = getelementptr i8, i8* %a, i64 24
  %4053 = load i8, i8* %scevgep35.18.5, align 1
  %4054 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.5 = call zeroext i8 @mult(i8 zeroext %4053, i8 zeroext %4054)
  %conv35.18.5 = zext i8 %call34.18.5 to i32
  %xor36.18.5 = xor i32 %xor.18.5, %conv35.18.5
  %conv37.18.5 = trunc i32 %xor36.18.5 to i8
  store i8 %conv37.18.5, i8* %scevgep41.18.4, align 1
  %scevgep28.18.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4048, i64 0, i64 0, i64 1
  %4055 = bitcast i8* %scevgep28.18.5 to [41 x [41 x i8]]*
  %scevgep41.18.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4049, i64 0, i64 1, i64 0
  %4056 = bitcast i8* %scevgep41.18.5 to [41 x [41 x i8]]*
  %call16.18.6 = call zeroext i8 (...) @rand()
  store i8 %call16.18.6, i8* %scevgep28.18.5, align 1
  %4057 = load i8, i8* %scevgep28.18.5, align 1
  %conv23.18.6 = zext i8 %4057 to i32
  %4058 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.6 = getelementptr i8, i8* %b, i64 25
  %4059 = load i8, i8* %scevgep34.18.6, align 1
  %call28.18.6 = call zeroext i8 @mult(i8 zeroext %4058, i8 zeroext %4059)
  %conv29.18.6 = zext i8 %call28.18.6 to i32
  %xor.18.6 = xor i32 %conv23.18.6, %conv29.18.6
  %scevgep35.18.6 = getelementptr i8, i8* %a, i64 25
  %4060 = load i8, i8* %scevgep35.18.6, align 1
  %4061 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.6 = call zeroext i8 @mult(i8 zeroext %4060, i8 zeroext %4061)
  %conv35.18.6 = zext i8 %call34.18.6 to i32
  %xor36.18.6 = xor i32 %xor.18.6, %conv35.18.6
  %conv37.18.6 = trunc i32 %xor36.18.6 to i8
  store i8 %conv37.18.6, i8* %scevgep41.18.5, align 1
  %scevgep28.18.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4055, i64 0, i64 0, i64 1
  %4062 = bitcast i8* %scevgep28.18.6 to [41 x [41 x i8]]*
  %scevgep41.18.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4056, i64 0, i64 1, i64 0
  %4063 = bitcast i8* %scevgep41.18.6 to [41 x [41 x i8]]*
  %call16.18.7 = call zeroext i8 (...) @rand()
  store i8 %call16.18.7, i8* %scevgep28.18.6, align 1
  %4064 = load i8, i8* %scevgep28.18.6, align 1
  %conv23.18.7 = zext i8 %4064 to i32
  %4065 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.7 = getelementptr i8, i8* %b, i64 26
  %4066 = load i8, i8* %scevgep34.18.7, align 1
  %call28.18.7 = call zeroext i8 @mult(i8 zeroext %4065, i8 zeroext %4066)
  %conv29.18.7 = zext i8 %call28.18.7 to i32
  %xor.18.7 = xor i32 %conv23.18.7, %conv29.18.7
  %scevgep35.18.7 = getelementptr i8, i8* %a, i64 26
  %4067 = load i8, i8* %scevgep35.18.7, align 1
  %4068 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.7 = call zeroext i8 @mult(i8 zeroext %4067, i8 zeroext %4068)
  %conv35.18.7 = zext i8 %call34.18.7 to i32
  %xor36.18.7 = xor i32 %xor.18.7, %conv35.18.7
  %conv37.18.7 = trunc i32 %xor36.18.7 to i8
  store i8 %conv37.18.7, i8* %scevgep41.18.6, align 1
  %scevgep28.18.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4062, i64 0, i64 0, i64 1
  %4069 = bitcast i8* %scevgep28.18.7 to [41 x [41 x i8]]*
  %scevgep41.18.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4063, i64 0, i64 1, i64 0
  %4070 = bitcast i8* %scevgep41.18.7 to [41 x [41 x i8]]*
  %call16.18.8 = call zeroext i8 (...) @rand()
  store i8 %call16.18.8, i8* %scevgep28.18.7, align 1
  %4071 = load i8, i8* %scevgep28.18.7, align 1
  %conv23.18.8 = zext i8 %4071 to i32
  %4072 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.8 = getelementptr i8, i8* %b, i64 27
  %4073 = load i8, i8* %scevgep34.18.8, align 1
  %call28.18.8 = call zeroext i8 @mult(i8 zeroext %4072, i8 zeroext %4073)
  %conv29.18.8 = zext i8 %call28.18.8 to i32
  %xor.18.8 = xor i32 %conv23.18.8, %conv29.18.8
  %scevgep35.18.8 = getelementptr i8, i8* %a, i64 27
  %4074 = load i8, i8* %scevgep35.18.8, align 1
  %4075 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.8 = call zeroext i8 @mult(i8 zeroext %4074, i8 zeroext %4075)
  %conv35.18.8 = zext i8 %call34.18.8 to i32
  %xor36.18.8 = xor i32 %xor.18.8, %conv35.18.8
  %conv37.18.8 = trunc i32 %xor36.18.8 to i8
  store i8 %conv37.18.8, i8* %scevgep41.18.7, align 1
  %scevgep28.18.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4069, i64 0, i64 0, i64 1
  %4076 = bitcast i8* %scevgep28.18.8 to [41 x [41 x i8]]*
  %scevgep41.18.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4070, i64 0, i64 1, i64 0
  %4077 = bitcast i8* %scevgep41.18.8 to [41 x [41 x i8]]*
  %call16.18.9 = call zeroext i8 (...) @rand()
  store i8 %call16.18.9, i8* %scevgep28.18.8, align 1
  %4078 = load i8, i8* %scevgep28.18.8, align 1
  %conv23.18.9 = zext i8 %4078 to i32
  %4079 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.9 = getelementptr i8, i8* %b, i64 28
  %4080 = load i8, i8* %scevgep34.18.9, align 1
  %call28.18.9 = call zeroext i8 @mult(i8 zeroext %4079, i8 zeroext %4080)
  %conv29.18.9 = zext i8 %call28.18.9 to i32
  %xor.18.9 = xor i32 %conv23.18.9, %conv29.18.9
  %scevgep35.18.9 = getelementptr i8, i8* %a, i64 28
  %4081 = load i8, i8* %scevgep35.18.9, align 1
  %4082 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.9 = call zeroext i8 @mult(i8 zeroext %4081, i8 zeroext %4082)
  %conv35.18.9 = zext i8 %call34.18.9 to i32
  %xor36.18.9 = xor i32 %xor.18.9, %conv35.18.9
  %conv37.18.9 = trunc i32 %xor36.18.9 to i8
  store i8 %conv37.18.9, i8* %scevgep41.18.8, align 1
  %scevgep28.18.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4076, i64 0, i64 0, i64 1
  %4083 = bitcast i8* %scevgep28.18.9 to [41 x [41 x i8]]*
  %scevgep41.18.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4077, i64 0, i64 1, i64 0
  %4084 = bitcast i8* %scevgep41.18.9 to [41 x [41 x i8]]*
  %call16.18.10 = call zeroext i8 (...) @rand()
  store i8 %call16.18.10, i8* %scevgep28.18.9, align 1
  %4085 = load i8, i8* %scevgep28.18.9, align 1
  %conv23.18.10 = zext i8 %4085 to i32
  %4086 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.10 = getelementptr i8, i8* %b, i64 29
  %4087 = load i8, i8* %scevgep34.18.10, align 1
  %call28.18.10 = call zeroext i8 @mult(i8 zeroext %4086, i8 zeroext %4087)
  %conv29.18.10 = zext i8 %call28.18.10 to i32
  %xor.18.10 = xor i32 %conv23.18.10, %conv29.18.10
  %scevgep35.18.10 = getelementptr i8, i8* %a, i64 29
  %4088 = load i8, i8* %scevgep35.18.10, align 1
  %4089 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.10 = call zeroext i8 @mult(i8 zeroext %4088, i8 zeroext %4089)
  %conv35.18.10 = zext i8 %call34.18.10 to i32
  %xor36.18.10 = xor i32 %xor.18.10, %conv35.18.10
  %conv37.18.10 = trunc i32 %xor36.18.10 to i8
  store i8 %conv37.18.10, i8* %scevgep41.18.9, align 1
  %scevgep28.18.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4083, i64 0, i64 0, i64 1
  %4090 = bitcast i8* %scevgep28.18.10 to [41 x [41 x i8]]*
  %scevgep41.18.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4084, i64 0, i64 1, i64 0
  %4091 = bitcast i8* %scevgep41.18.10 to [41 x [41 x i8]]*
  %call16.18.11 = call zeroext i8 (...) @rand()
  store i8 %call16.18.11, i8* %scevgep28.18.10, align 1
  %4092 = load i8, i8* %scevgep28.18.10, align 1
  %conv23.18.11 = zext i8 %4092 to i32
  %4093 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.11 = getelementptr i8, i8* %b, i64 30
  %4094 = load i8, i8* %scevgep34.18.11, align 1
  %call28.18.11 = call zeroext i8 @mult(i8 zeroext %4093, i8 zeroext %4094)
  %conv29.18.11 = zext i8 %call28.18.11 to i32
  %xor.18.11 = xor i32 %conv23.18.11, %conv29.18.11
  %scevgep35.18.11 = getelementptr i8, i8* %a, i64 30
  %4095 = load i8, i8* %scevgep35.18.11, align 1
  %4096 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.11 = call zeroext i8 @mult(i8 zeroext %4095, i8 zeroext %4096)
  %conv35.18.11 = zext i8 %call34.18.11 to i32
  %xor36.18.11 = xor i32 %xor.18.11, %conv35.18.11
  %conv37.18.11 = trunc i32 %xor36.18.11 to i8
  store i8 %conv37.18.11, i8* %scevgep41.18.10, align 1
  %scevgep28.18.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4090, i64 0, i64 0, i64 1
  %4097 = bitcast i8* %scevgep28.18.11 to [41 x [41 x i8]]*
  %scevgep41.18.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4091, i64 0, i64 1, i64 0
  %4098 = bitcast i8* %scevgep41.18.11 to [41 x [41 x i8]]*
  %call16.18.12 = call zeroext i8 (...) @rand()
  store i8 %call16.18.12, i8* %scevgep28.18.11, align 1
  %4099 = load i8, i8* %scevgep28.18.11, align 1
  %conv23.18.12 = zext i8 %4099 to i32
  %4100 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.12 = getelementptr i8, i8* %b, i64 31
  %4101 = load i8, i8* %scevgep34.18.12, align 1
  %call28.18.12 = call zeroext i8 @mult(i8 zeroext %4100, i8 zeroext %4101)
  %conv29.18.12 = zext i8 %call28.18.12 to i32
  %xor.18.12 = xor i32 %conv23.18.12, %conv29.18.12
  %scevgep35.18.12 = getelementptr i8, i8* %a, i64 31
  %4102 = load i8, i8* %scevgep35.18.12, align 1
  %4103 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.12 = call zeroext i8 @mult(i8 zeroext %4102, i8 zeroext %4103)
  %conv35.18.12 = zext i8 %call34.18.12 to i32
  %xor36.18.12 = xor i32 %xor.18.12, %conv35.18.12
  %conv37.18.12 = trunc i32 %xor36.18.12 to i8
  store i8 %conv37.18.12, i8* %scevgep41.18.11, align 1
  %scevgep28.18.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4097, i64 0, i64 0, i64 1
  %4104 = bitcast i8* %scevgep28.18.12 to [41 x [41 x i8]]*
  %scevgep41.18.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4098, i64 0, i64 1, i64 0
  %4105 = bitcast i8* %scevgep41.18.12 to [41 x [41 x i8]]*
  %call16.18.13 = call zeroext i8 (...) @rand()
  store i8 %call16.18.13, i8* %scevgep28.18.12, align 1
  %4106 = load i8, i8* %scevgep28.18.12, align 1
  %conv23.18.13 = zext i8 %4106 to i32
  %4107 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.13 = getelementptr i8, i8* %b, i64 32
  %4108 = load i8, i8* %scevgep34.18.13, align 1
  %call28.18.13 = call zeroext i8 @mult(i8 zeroext %4107, i8 zeroext %4108)
  %conv29.18.13 = zext i8 %call28.18.13 to i32
  %xor.18.13 = xor i32 %conv23.18.13, %conv29.18.13
  %scevgep35.18.13 = getelementptr i8, i8* %a, i64 32
  %4109 = load i8, i8* %scevgep35.18.13, align 1
  %4110 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.13 = call zeroext i8 @mult(i8 zeroext %4109, i8 zeroext %4110)
  %conv35.18.13 = zext i8 %call34.18.13 to i32
  %xor36.18.13 = xor i32 %xor.18.13, %conv35.18.13
  %conv37.18.13 = trunc i32 %xor36.18.13 to i8
  store i8 %conv37.18.13, i8* %scevgep41.18.12, align 1
  %scevgep28.18.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4104, i64 0, i64 0, i64 1
  %4111 = bitcast i8* %scevgep28.18.13 to [41 x [41 x i8]]*
  %scevgep41.18.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4105, i64 0, i64 1, i64 0
  %4112 = bitcast i8* %scevgep41.18.13 to [41 x [41 x i8]]*
  %call16.18.14 = call zeroext i8 (...) @rand()
  store i8 %call16.18.14, i8* %scevgep28.18.13, align 1
  %4113 = load i8, i8* %scevgep28.18.13, align 1
  %conv23.18.14 = zext i8 %4113 to i32
  %4114 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.14 = getelementptr i8, i8* %b, i64 33
  %4115 = load i8, i8* %scevgep34.18.14, align 1
  %call28.18.14 = call zeroext i8 @mult(i8 zeroext %4114, i8 zeroext %4115)
  %conv29.18.14 = zext i8 %call28.18.14 to i32
  %xor.18.14 = xor i32 %conv23.18.14, %conv29.18.14
  %scevgep35.18.14 = getelementptr i8, i8* %a, i64 33
  %4116 = load i8, i8* %scevgep35.18.14, align 1
  %4117 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.14 = call zeroext i8 @mult(i8 zeroext %4116, i8 zeroext %4117)
  %conv35.18.14 = zext i8 %call34.18.14 to i32
  %xor36.18.14 = xor i32 %xor.18.14, %conv35.18.14
  %conv37.18.14 = trunc i32 %xor36.18.14 to i8
  store i8 %conv37.18.14, i8* %scevgep41.18.13, align 1
  %scevgep28.18.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4111, i64 0, i64 0, i64 1
  %4118 = bitcast i8* %scevgep28.18.14 to [41 x [41 x i8]]*
  %scevgep41.18.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4112, i64 0, i64 1, i64 0
  %4119 = bitcast i8* %scevgep41.18.14 to [41 x [41 x i8]]*
  %call16.18.15 = call zeroext i8 (...) @rand()
  store i8 %call16.18.15, i8* %scevgep28.18.14, align 1
  %4120 = load i8, i8* %scevgep28.18.14, align 1
  %conv23.18.15 = zext i8 %4120 to i32
  %4121 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.15 = getelementptr i8, i8* %b, i64 34
  %4122 = load i8, i8* %scevgep34.18.15, align 1
  %call28.18.15 = call zeroext i8 @mult(i8 zeroext %4121, i8 zeroext %4122)
  %conv29.18.15 = zext i8 %call28.18.15 to i32
  %xor.18.15 = xor i32 %conv23.18.15, %conv29.18.15
  %scevgep35.18.15 = getelementptr i8, i8* %a, i64 34
  %4123 = load i8, i8* %scevgep35.18.15, align 1
  %4124 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.15 = call zeroext i8 @mult(i8 zeroext %4123, i8 zeroext %4124)
  %conv35.18.15 = zext i8 %call34.18.15 to i32
  %xor36.18.15 = xor i32 %xor.18.15, %conv35.18.15
  %conv37.18.15 = trunc i32 %xor36.18.15 to i8
  store i8 %conv37.18.15, i8* %scevgep41.18.14, align 1
  %scevgep28.18.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4118, i64 0, i64 0, i64 1
  %4125 = bitcast i8* %scevgep28.18.15 to [41 x [41 x i8]]*
  %scevgep41.18.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4119, i64 0, i64 1, i64 0
  %4126 = bitcast i8* %scevgep41.18.15 to [41 x [41 x i8]]*
  %call16.18.16 = call zeroext i8 (...) @rand()
  store i8 %call16.18.16, i8* %scevgep28.18.15, align 1
  %4127 = load i8, i8* %scevgep28.18.15, align 1
  %conv23.18.16 = zext i8 %4127 to i32
  %4128 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.16 = getelementptr i8, i8* %b, i64 35
  %4129 = load i8, i8* %scevgep34.18.16, align 1
  %call28.18.16 = call zeroext i8 @mult(i8 zeroext %4128, i8 zeroext %4129)
  %conv29.18.16 = zext i8 %call28.18.16 to i32
  %xor.18.16 = xor i32 %conv23.18.16, %conv29.18.16
  %scevgep35.18.16 = getelementptr i8, i8* %a, i64 35
  %4130 = load i8, i8* %scevgep35.18.16, align 1
  %4131 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.16 = call zeroext i8 @mult(i8 zeroext %4130, i8 zeroext %4131)
  %conv35.18.16 = zext i8 %call34.18.16 to i32
  %xor36.18.16 = xor i32 %xor.18.16, %conv35.18.16
  %conv37.18.16 = trunc i32 %xor36.18.16 to i8
  store i8 %conv37.18.16, i8* %scevgep41.18.15, align 1
  %scevgep28.18.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4125, i64 0, i64 0, i64 1
  %4132 = bitcast i8* %scevgep28.18.16 to [41 x [41 x i8]]*
  %scevgep41.18.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4126, i64 0, i64 1, i64 0
  %4133 = bitcast i8* %scevgep41.18.16 to [41 x [41 x i8]]*
  %call16.18.17 = call zeroext i8 (...) @rand()
  store i8 %call16.18.17, i8* %scevgep28.18.16, align 1
  %4134 = load i8, i8* %scevgep28.18.16, align 1
  %conv23.18.17 = zext i8 %4134 to i32
  %4135 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.17 = getelementptr i8, i8* %b, i64 36
  %4136 = load i8, i8* %scevgep34.18.17, align 1
  %call28.18.17 = call zeroext i8 @mult(i8 zeroext %4135, i8 zeroext %4136)
  %conv29.18.17 = zext i8 %call28.18.17 to i32
  %xor.18.17 = xor i32 %conv23.18.17, %conv29.18.17
  %scevgep35.18.17 = getelementptr i8, i8* %a, i64 36
  %4137 = load i8, i8* %scevgep35.18.17, align 1
  %4138 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.17 = call zeroext i8 @mult(i8 zeroext %4137, i8 zeroext %4138)
  %conv35.18.17 = zext i8 %call34.18.17 to i32
  %xor36.18.17 = xor i32 %xor.18.17, %conv35.18.17
  %conv37.18.17 = trunc i32 %xor36.18.17 to i8
  store i8 %conv37.18.17, i8* %scevgep41.18.16, align 1
  %scevgep28.18.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4132, i64 0, i64 0, i64 1
  %4139 = bitcast i8* %scevgep28.18.17 to [41 x [41 x i8]]*
  %scevgep41.18.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4133, i64 0, i64 1, i64 0
  %4140 = bitcast i8* %scevgep41.18.17 to [41 x [41 x i8]]*
  %call16.18.18 = call zeroext i8 (...) @rand()
  store i8 %call16.18.18, i8* %scevgep28.18.17, align 1
  %4141 = load i8, i8* %scevgep28.18.17, align 1
  %conv23.18.18 = zext i8 %4141 to i32
  %4142 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.18 = getelementptr i8, i8* %b, i64 37
  %4143 = load i8, i8* %scevgep34.18.18, align 1
  %call28.18.18 = call zeroext i8 @mult(i8 zeroext %4142, i8 zeroext %4143)
  %conv29.18.18 = zext i8 %call28.18.18 to i32
  %xor.18.18 = xor i32 %conv23.18.18, %conv29.18.18
  %scevgep35.18.18 = getelementptr i8, i8* %a, i64 37
  %4144 = load i8, i8* %scevgep35.18.18, align 1
  %4145 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.18 = call zeroext i8 @mult(i8 zeroext %4144, i8 zeroext %4145)
  %conv35.18.18 = zext i8 %call34.18.18 to i32
  %xor36.18.18 = xor i32 %xor.18.18, %conv35.18.18
  %conv37.18.18 = trunc i32 %xor36.18.18 to i8
  store i8 %conv37.18.18, i8* %scevgep41.18.17, align 1
  %scevgep28.18.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4139, i64 0, i64 0, i64 1
  %4146 = bitcast i8* %scevgep28.18.18 to [41 x [41 x i8]]*
  %scevgep41.18.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4140, i64 0, i64 1, i64 0
  %4147 = bitcast i8* %scevgep41.18.18 to [41 x [41 x i8]]*
  %call16.18.19 = call zeroext i8 (...) @rand()
  store i8 %call16.18.19, i8* %scevgep28.18.18, align 1
  %4148 = load i8, i8* %scevgep28.18.18, align 1
  %conv23.18.19 = zext i8 %4148 to i32
  %4149 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.19 = getelementptr i8, i8* %b, i64 38
  %4150 = load i8, i8* %scevgep34.18.19, align 1
  %call28.18.19 = call zeroext i8 @mult(i8 zeroext %4149, i8 zeroext %4150)
  %conv29.18.19 = zext i8 %call28.18.19 to i32
  %xor.18.19 = xor i32 %conv23.18.19, %conv29.18.19
  %scevgep35.18.19 = getelementptr i8, i8* %a, i64 38
  %4151 = load i8, i8* %scevgep35.18.19, align 1
  %4152 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.19 = call zeroext i8 @mult(i8 zeroext %4151, i8 zeroext %4152)
  %conv35.18.19 = zext i8 %call34.18.19 to i32
  %xor36.18.19 = xor i32 %xor.18.19, %conv35.18.19
  %conv37.18.19 = trunc i32 %xor36.18.19 to i8
  store i8 %conv37.18.19, i8* %scevgep41.18.18, align 1
  %scevgep28.18.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4146, i64 0, i64 0, i64 1
  %4153 = bitcast i8* %scevgep28.18.19 to [41 x [41 x i8]]*
  %scevgep41.18.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4147, i64 0, i64 1, i64 0
  %4154 = bitcast i8* %scevgep41.18.19 to [41 x [41 x i8]]*
  %call16.18.20 = call zeroext i8 (...) @rand()
  store i8 %call16.18.20, i8* %scevgep28.18.19, align 1
  %4155 = load i8, i8* %scevgep28.18.19, align 1
  %conv23.18.20 = zext i8 %4155 to i32
  %4156 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.20 = getelementptr i8, i8* %b, i64 39
  %4157 = load i8, i8* %scevgep34.18.20, align 1
  %call28.18.20 = call zeroext i8 @mult(i8 zeroext %4156, i8 zeroext %4157)
  %conv29.18.20 = zext i8 %call28.18.20 to i32
  %xor.18.20 = xor i32 %conv23.18.20, %conv29.18.20
  %scevgep35.18.20 = getelementptr i8, i8* %a, i64 39
  %4158 = load i8, i8* %scevgep35.18.20, align 1
  %4159 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.20 = call zeroext i8 @mult(i8 zeroext %4158, i8 zeroext %4159)
  %conv35.18.20 = zext i8 %call34.18.20 to i32
  %xor36.18.20 = xor i32 %xor.18.20, %conv35.18.20
  %conv37.18.20 = trunc i32 %xor36.18.20 to i8
  store i8 %conv37.18.20, i8* %scevgep41.18.19, align 1
  %scevgep28.18.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4153, i64 0, i64 0, i64 1
  %scevgep41.18.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4154, i64 0, i64 1, i64 0
  %call16.18.21 = call zeroext i8 (...) @rand()
  store i8 %call16.18.21, i8* %scevgep28.18.20, align 1
  %4160 = load i8, i8* %scevgep28.18.20, align 1
  %conv23.18.21 = zext i8 %4160 to i32
  %4161 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.21 = getelementptr i8, i8* %b, i64 40
  %4162 = load i8, i8* %scevgep34.18.21, align 1
  %call28.18.21 = call zeroext i8 @mult(i8 zeroext %4161, i8 zeroext %4162)
  %conv29.18.21 = zext i8 %call28.18.21 to i32
  %xor.18.21 = xor i32 %conv23.18.21, %conv29.18.21
  %scevgep35.18.21 = getelementptr i8, i8* %a, i64 40
  %4163 = load i8, i8* %scevgep35.18.21, align 1
  %4164 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.21 = call zeroext i8 @mult(i8 zeroext %4163, i8 zeroext %4164)
  %conv35.18.21 = zext i8 %call34.18.21 to i32
  %xor36.18.21 = xor i32 %xor.18.21, %conv35.18.21
  %conv37.18.21 = trunc i32 %xor36.18.21 to i8
  store i8 %conv37.18.21, i8* %scevgep41.18.20, align 1
  %scevgep26.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4013, i64 0, i64 1, i64 1
  %4165 = bitcast i8* %scevgep26.18 to [41 x [41 x i8]]*
  %scevgep39.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4014, i64 0, i64 1, i64 1
  %4166 = bitcast i8* %scevgep39.18 to [41 x [41 x i8]]*
  %arrayidx25.19 = getelementptr inbounds i8, i8* %a, i64 19
  %arrayidx33.19 = getelementptr inbounds i8, i8* %b, i64 19
  %call16.19 = call zeroext i8 (...) @rand()
  store i8 %call16.19, i8* %scevgep26.18, align 1
  %4167 = load i8, i8* %scevgep26.18, align 1
  %conv23.19 = zext i8 %4167 to i32
  %4168 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19 = getelementptr i8, i8* %b, i64 20
  %4169 = load i8, i8* %scevgep34.19, align 1
  %call28.19 = call zeroext i8 @mult(i8 zeroext %4168, i8 zeroext %4169)
  %conv29.19 = zext i8 %call28.19 to i32
  %xor.19 = xor i32 %conv23.19, %conv29.19
  %scevgep35.19 = getelementptr i8, i8* %a, i64 20
  %4170 = load i8, i8* %scevgep35.19, align 1
  %4171 = load i8, i8* %arrayidx33.19, align 1
  %call34.19 = call zeroext i8 @mult(i8 zeroext %4170, i8 zeroext %4171)
  %conv35.19 = zext i8 %call34.19 to i32
  %xor36.19 = xor i32 %xor.19, %conv35.19
  %conv37.19 = trunc i32 %xor36.19 to i8
  store i8 %conv37.19, i8* %scevgep39.18, align 1
  %scevgep28.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4165, i64 0, i64 0, i64 1
  %4172 = bitcast i8* %scevgep28.19 to [41 x [41 x i8]]*
  %scevgep41.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4166, i64 0, i64 1, i64 0
  %4173 = bitcast i8* %scevgep41.19 to [41 x [41 x i8]]*
  %call16.19.1 = call zeroext i8 (...) @rand()
  store i8 %call16.19.1, i8* %scevgep28.19, align 1
  %4174 = load i8, i8* %scevgep28.19, align 1
  %conv23.19.1 = zext i8 %4174 to i32
  %4175 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.1 = getelementptr i8, i8* %b, i64 21
  %4176 = load i8, i8* %scevgep34.19.1, align 1
  %call28.19.1 = call zeroext i8 @mult(i8 zeroext %4175, i8 zeroext %4176)
  %conv29.19.1 = zext i8 %call28.19.1 to i32
  %xor.19.1 = xor i32 %conv23.19.1, %conv29.19.1
  %scevgep35.19.1 = getelementptr i8, i8* %a, i64 21
  %4177 = load i8, i8* %scevgep35.19.1, align 1
  %4178 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.1 = call zeroext i8 @mult(i8 zeroext %4177, i8 zeroext %4178)
  %conv35.19.1 = zext i8 %call34.19.1 to i32
  %xor36.19.1 = xor i32 %xor.19.1, %conv35.19.1
  %conv37.19.1 = trunc i32 %xor36.19.1 to i8
  store i8 %conv37.19.1, i8* %scevgep41.19, align 1
  %scevgep28.19.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4172, i64 0, i64 0, i64 1
  %4179 = bitcast i8* %scevgep28.19.1 to [41 x [41 x i8]]*
  %scevgep41.19.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4173, i64 0, i64 1, i64 0
  %4180 = bitcast i8* %scevgep41.19.1 to [41 x [41 x i8]]*
  %call16.19.2 = call zeroext i8 (...) @rand()
  store i8 %call16.19.2, i8* %scevgep28.19.1, align 1
  %4181 = load i8, i8* %scevgep28.19.1, align 1
  %conv23.19.2 = zext i8 %4181 to i32
  %4182 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.2 = getelementptr i8, i8* %b, i64 22
  %4183 = load i8, i8* %scevgep34.19.2, align 1
  %call28.19.2 = call zeroext i8 @mult(i8 zeroext %4182, i8 zeroext %4183)
  %conv29.19.2 = zext i8 %call28.19.2 to i32
  %xor.19.2 = xor i32 %conv23.19.2, %conv29.19.2
  %scevgep35.19.2 = getelementptr i8, i8* %a, i64 22
  %4184 = load i8, i8* %scevgep35.19.2, align 1
  %4185 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.2 = call zeroext i8 @mult(i8 zeroext %4184, i8 zeroext %4185)
  %conv35.19.2 = zext i8 %call34.19.2 to i32
  %xor36.19.2 = xor i32 %xor.19.2, %conv35.19.2
  %conv37.19.2 = trunc i32 %xor36.19.2 to i8
  store i8 %conv37.19.2, i8* %scevgep41.19.1, align 1
  %scevgep28.19.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4179, i64 0, i64 0, i64 1
  %4186 = bitcast i8* %scevgep28.19.2 to [41 x [41 x i8]]*
  %scevgep41.19.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4180, i64 0, i64 1, i64 0
  %4187 = bitcast i8* %scevgep41.19.2 to [41 x [41 x i8]]*
  %call16.19.3 = call zeroext i8 (...) @rand()
  store i8 %call16.19.3, i8* %scevgep28.19.2, align 1
  %4188 = load i8, i8* %scevgep28.19.2, align 1
  %conv23.19.3 = zext i8 %4188 to i32
  %4189 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.3 = getelementptr i8, i8* %b, i64 23
  %4190 = load i8, i8* %scevgep34.19.3, align 1
  %call28.19.3 = call zeroext i8 @mult(i8 zeroext %4189, i8 zeroext %4190)
  %conv29.19.3 = zext i8 %call28.19.3 to i32
  %xor.19.3 = xor i32 %conv23.19.3, %conv29.19.3
  %scevgep35.19.3 = getelementptr i8, i8* %a, i64 23
  %4191 = load i8, i8* %scevgep35.19.3, align 1
  %4192 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.3 = call zeroext i8 @mult(i8 zeroext %4191, i8 zeroext %4192)
  %conv35.19.3 = zext i8 %call34.19.3 to i32
  %xor36.19.3 = xor i32 %xor.19.3, %conv35.19.3
  %conv37.19.3 = trunc i32 %xor36.19.3 to i8
  store i8 %conv37.19.3, i8* %scevgep41.19.2, align 1
  %scevgep28.19.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4186, i64 0, i64 0, i64 1
  %4193 = bitcast i8* %scevgep28.19.3 to [41 x [41 x i8]]*
  %scevgep41.19.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4187, i64 0, i64 1, i64 0
  %4194 = bitcast i8* %scevgep41.19.3 to [41 x [41 x i8]]*
  %call16.19.4 = call zeroext i8 (...) @rand()
  store i8 %call16.19.4, i8* %scevgep28.19.3, align 1
  %4195 = load i8, i8* %scevgep28.19.3, align 1
  %conv23.19.4 = zext i8 %4195 to i32
  %4196 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.4 = getelementptr i8, i8* %b, i64 24
  %4197 = load i8, i8* %scevgep34.19.4, align 1
  %call28.19.4 = call zeroext i8 @mult(i8 zeroext %4196, i8 zeroext %4197)
  %conv29.19.4 = zext i8 %call28.19.4 to i32
  %xor.19.4 = xor i32 %conv23.19.4, %conv29.19.4
  %scevgep35.19.4 = getelementptr i8, i8* %a, i64 24
  %4198 = load i8, i8* %scevgep35.19.4, align 1
  %4199 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.4 = call zeroext i8 @mult(i8 zeroext %4198, i8 zeroext %4199)
  %conv35.19.4 = zext i8 %call34.19.4 to i32
  %xor36.19.4 = xor i32 %xor.19.4, %conv35.19.4
  %conv37.19.4 = trunc i32 %xor36.19.4 to i8
  store i8 %conv37.19.4, i8* %scevgep41.19.3, align 1
  %scevgep28.19.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4193, i64 0, i64 0, i64 1
  %4200 = bitcast i8* %scevgep28.19.4 to [41 x [41 x i8]]*
  %scevgep41.19.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4194, i64 0, i64 1, i64 0
  %4201 = bitcast i8* %scevgep41.19.4 to [41 x [41 x i8]]*
  %call16.19.5 = call zeroext i8 (...) @rand()
  store i8 %call16.19.5, i8* %scevgep28.19.4, align 1
  %4202 = load i8, i8* %scevgep28.19.4, align 1
  %conv23.19.5 = zext i8 %4202 to i32
  %4203 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.5 = getelementptr i8, i8* %b, i64 25
  %4204 = load i8, i8* %scevgep34.19.5, align 1
  %call28.19.5 = call zeroext i8 @mult(i8 zeroext %4203, i8 zeroext %4204)
  %conv29.19.5 = zext i8 %call28.19.5 to i32
  %xor.19.5 = xor i32 %conv23.19.5, %conv29.19.5
  %scevgep35.19.5 = getelementptr i8, i8* %a, i64 25
  %4205 = load i8, i8* %scevgep35.19.5, align 1
  %4206 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.5 = call zeroext i8 @mult(i8 zeroext %4205, i8 zeroext %4206)
  %conv35.19.5 = zext i8 %call34.19.5 to i32
  %xor36.19.5 = xor i32 %xor.19.5, %conv35.19.5
  %conv37.19.5 = trunc i32 %xor36.19.5 to i8
  store i8 %conv37.19.5, i8* %scevgep41.19.4, align 1
  %scevgep28.19.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4200, i64 0, i64 0, i64 1
  %4207 = bitcast i8* %scevgep28.19.5 to [41 x [41 x i8]]*
  %scevgep41.19.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4201, i64 0, i64 1, i64 0
  %4208 = bitcast i8* %scevgep41.19.5 to [41 x [41 x i8]]*
  %call16.19.6 = call zeroext i8 (...) @rand()
  store i8 %call16.19.6, i8* %scevgep28.19.5, align 1
  %4209 = load i8, i8* %scevgep28.19.5, align 1
  %conv23.19.6 = zext i8 %4209 to i32
  %4210 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.6 = getelementptr i8, i8* %b, i64 26
  %4211 = load i8, i8* %scevgep34.19.6, align 1
  %call28.19.6 = call zeroext i8 @mult(i8 zeroext %4210, i8 zeroext %4211)
  %conv29.19.6 = zext i8 %call28.19.6 to i32
  %xor.19.6 = xor i32 %conv23.19.6, %conv29.19.6
  %scevgep35.19.6 = getelementptr i8, i8* %a, i64 26
  %4212 = load i8, i8* %scevgep35.19.6, align 1
  %4213 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.6 = call zeroext i8 @mult(i8 zeroext %4212, i8 zeroext %4213)
  %conv35.19.6 = zext i8 %call34.19.6 to i32
  %xor36.19.6 = xor i32 %xor.19.6, %conv35.19.6
  %conv37.19.6 = trunc i32 %xor36.19.6 to i8
  store i8 %conv37.19.6, i8* %scevgep41.19.5, align 1
  %scevgep28.19.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4207, i64 0, i64 0, i64 1
  %4214 = bitcast i8* %scevgep28.19.6 to [41 x [41 x i8]]*
  %scevgep41.19.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4208, i64 0, i64 1, i64 0
  %4215 = bitcast i8* %scevgep41.19.6 to [41 x [41 x i8]]*
  %call16.19.7 = call zeroext i8 (...) @rand()
  store i8 %call16.19.7, i8* %scevgep28.19.6, align 1
  %4216 = load i8, i8* %scevgep28.19.6, align 1
  %conv23.19.7 = zext i8 %4216 to i32
  %4217 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.7 = getelementptr i8, i8* %b, i64 27
  %4218 = load i8, i8* %scevgep34.19.7, align 1
  %call28.19.7 = call zeroext i8 @mult(i8 zeroext %4217, i8 zeroext %4218)
  %conv29.19.7 = zext i8 %call28.19.7 to i32
  %xor.19.7 = xor i32 %conv23.19.7, %conv29.19.7
  %scevgep35.19.7 = getelementptr i8, i8* %a, i64 27
  %4219 = load i8, i8* %scevgep35.19.7, align 1
  %4220 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.7 = call zeroext i8 @mult(i8 zeroext %4219, i8 zeroext %4220)
  %conv35.19.7 = zext i8 %call34.19.7 to i32
  %xor36.19.7 = xor i32 %xor.19.7, %conv35.19.7
  %conv37.19.7 = trunc i32 %xor36.19.7 to i8
  store i8 %conv37.19.7, i8* %scevgep41.19.6, align 1
  %scevgep28.19.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4214, i64 0, i64 0, i64 1
  %4221 = bitcast i8* %scevgep28.19.7 to [41 x [41 x i8]]*
  %scevgep41.19.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4215, i64 0, i64 1, i64 0
  %4222 = bitcast i8* %scevgep41.19.7 to [41 x [41 x i8]]*
  %call16.19.8 = call zeroext i8 (...) @rand()
  store i8 %call16.19.8, i8* %scevgep28.19.7, align 1
  %4223 = load i8, i8* %scevgep28.19.7, align 1
  %conv23.19.8 = zext i8 %4223 to i32
  %4224 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.8 = getelementptr i8, i8* %b, i64 28
  %4225 = load i8, i8* %scevgep34.19.8, align 1
  %call28.19.8 = call zeroext i8 @mult(i8 zeroext %4224, i8 zeroext %4225)
  %conv29.19.8 = zext i8 %call28.19.8 to i32
  %xor.19.8 = xor i32 %conv23.19.8, %conv29.19.8
  %scevgep35.19.8 = getelementptr i8, i8* %a, i64 28
  %4226 = load i8, i8* %scevgep35.19.8, align 1
  %4227 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.8 = call zeroext i8 @mult(i8 zeroext %4226, i8 zeroext %4227)
  %conv35.19.8 = zext i8 %call34.19.8 to i32
  %xor36.19.8 = xor i32 %xor.19.8, %conv35.19.8
  %conv37.19.8 = trunc i32 %xor36.19.8 to i8
  store i8 %conv37.19.8, i8* %scevgep41.19.7, align 1
  %scevgep28.19.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4221, i64 0, i64 0, i64 1
  %4228 = bitcast i8* %scevgep28.19.8 to [41 x [41 x i8]]*
  %scevgep41.19.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4222, i64 0, i64 1, i64 0
  %4229 = bitcast i8* %scevgep41.19.8 to [41 x [41 x i8]]*
  %call16.19.9 = call zeroext i8 (...) @rand()
  store i8 %call16.19.9, i8* %scevgep28.19.8, align 1
  %4230 = load i8, i8* %scevgep28.19.8, align 1
  %conv23.19.9 = zext i8 %4230 to i32
  %4231 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.9 = getelementptr i8, i8* %b, i64 29
  %4232 = load i8, i8* %scevgep34.19.9, align 1
  %call28.19.9 = call zeroext i8 @mult(i8 zeroext %4231, i8 zeroext %4232)
  %conv29.19.9 = zext i8 %call28.19.9 to i32
  %xor.19.9 = xor i32 %conv23.19.9, %conv29.19.9
  %scevgep35.19.9 = getelementptr i8, i8* %a, i64 29
  %4233 = load i8, i8* %scevgep35.19.9, align 1
  %4234 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.9 = call zeroext i8 @mult(i8 zeroext %4233, i8 zeroext %4234)
  %conv35.19.9 = zext i8 %call34.19.9 to i32
  %xor36.19.9 = xor i32 %xor.19.9, %conv35.19.9
  %conv37.19.9 = trunc i32 %xor36.19.9 to i8
  store i8 %conv37.19.9, i8* %scevgep41.19.8, align 1
  %scevgep28.19.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4228, i64 0, i64 0, i64 1
  %4235 = bitcast i8* %scevgep28.19.9 to [41 x [41 x i8]]*
  %scevgep41.19.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4229, i64 0, i64 1, i64 0
  %4236 = bitcast i8* %scevgep41.19.9 to [41 x [41 x i8]]*
  %call16.19.10 = call zeroext i8 (...) @rand()
  store i8 %call16.19.10, i8* %scevgep28.19.9, align 1
  %4237 = load i8, i8* %scevgep28.19.9, align 1
  %conv23.19.10 = zext i8 %4237 to i32
  %4238 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.10 = getelementptr i8, i8* %b, i64 30
  %4239 = load i8, i8* %scevgep34.19.10, align 1
  %call28.19.10 = call zeroext i8 @mult(i8 zeroext %4238, i8 zeroext %4239)
  %conv29.19.10 = zext i8 %call28.19.10 to i32
  %xor.19.10 = xor i32 %conv23.19.10, %conv29.19.10
  %scevgep35.19.10 = getelementptr i8, i8* %a, i64 30
  %4240 = load i8, i8* %scevgep35.19.10, align 1
  %4241 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.10 = call zeroext i8 @mult(i8 zeroext %4240, i8 zeroext %4241)
  %conv35.19.10 = zext i8 %call34.19.10 to i32
  %xor36.19.10 = xor i32 %xor.19.10, %conv35.19.10
  %conv37.19.10 = trunc i32 %xor36.19.10 to i8
  store i8 %conv37.19.10, i8* %scevgep41.19.9, align 1
  %scevgep28.19.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4235, i64 0, i64 0, i64 1
  %4242 = bitcast i8* %scevgep28.19.10 to [41 x [41 x i8]]*
  %scevgep41.19.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4236, i64 0, i64 1, i64 0
  %4243 = bitcast i8* %scevgep41.19.10 to [41 x [41 x i8]]*
  %call16.19.11 = call zeroext i8 (...) @rand()
  store i8 %call16.19.11, i8* %scevgep28.19.10, align 1
  %4244 = load i8, i8* %scevgep28.19.10, align 1
  %conv23.19.11 = zext i8 %4244 to i32
  %4245 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.11 = getelementptr i8, i8* %b, i64 31
  %4246 = load i8, i8* %scevgep34.19.11, align 1
  %call28.19.11 = call zeroext i8 @mult(i8 zeroext %4245, i8 zeroext %4246)
  %conv29.19.11 = zext i8 %call28.19.11 to i32
  %xor.19.11 = xor i32 %conv23.19.11, %conv29.19.11
  %scevgep35.19.11 = getelementptr i8, i8* %a, i64 31
  %4247 = load i8, i8* %scevgep35.19.11, align 1
  %4248 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.11 = call zeroext i8 @mult(i8 zeroext %4247, i8 zeroext %4248)
  %conv35.19.11 = zext i8 %call34.19.11 to i32
  %xor36.19.11 = xor i32 %xor.19.11, %conv35.19.11
  %conv37.19.11 = trunc i32 %xor36.19.11 to i8
  store i8 %conv37.19.11, i8* %scevgep41.19.10, align 1
  %scevgep28.19.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4242, i64 0, i64 0, i64 1
  %4249 = bitcast i8* %scevgep28.19.11 to [41 x [41 x i8]]*
  %scevgep41.19.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4243, i64 0, i64 1, i64 0
  %4250 = bitcast i8* %scevgep41.19.11 to [41 x [41 x i8]]*
  %call16.19.12 = call zeroext i8 (...) @rand()
  store i8 %call16.19.12, i8* %scevgep28.19.11, align 1
  %4251 = load i8, i8* %scevgep28.19.11, align 1
  %conv23.19.12 = zext i8 %4251 to i32
  %4252 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.12 = getelementptr i8, i8* %b, i64 32
  %4253 = load i8, i8* %scevgep34.19.12, align 1
  %call28.19.12 = call zeroext i8 @mult(i8 zeroext %4252, i8 zeroext %4253)
  %conv29.19.12 = zext i8 %call28.19.12 to i32
  %xor.19.12 = xor i32 %conv23.19.12, %conv29.19.12
  %scevgep35.19.12 = getelementptr i8, i8* %a, i64 32
  %4254 = load i8, i8* %scevgep35.19.12, align 1
  %4255 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.12 = call zeroext i8 @mult(i8 zeroext %4254, i8 zeroext %4255)
  %conv35.19.12 = zext i8 %call34.19.12 to i32
  %xor36.19.12 = xor i32 %xor.19.12, %conv35.19.12
  %conv37.19.12 = trunc i32 %xor36.19.12 to i8
  store i8 %conv37.19.12, i8* %scevgep41.19.11, align 1
  %scevgep28.19.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4249, i64 0, i64 0, i64 1
  %4256 = bitcast i8* %scevgep28.19.12 to [41 x [41 x i8]]*
  %scevgep41.19.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4250, i64 0, i64 1, i64 0
  %4257 = bitcast i8* %scevgep41.19.12 to [41 x [41 x i8]]*
  %call16.19.13 = call zeroext i8 (...) @rand()
  store i8 %call16.19.13, i8* %scevgep28.19.12, align 1
  %4258 = load i8, i8* %scevgep28.19.12, align 1
  %conv23.19.13 = zext i8 %4258 to i32
  %4259 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.13 = getelementptr i8, i8* %b, i64 33
  %4260 = load i8, i8* %scevgep34.19.13, align 1
  %call28.19.13 = call zeroext i8 @mult(i8 zeroext %4259, i8 zeroext %4260)
  %conv29.19.13 = zext i8 %call28.19.13 to i32
  %xor.19.13 = xor i32 %conv23.19.13, %conv29.19.13
  %scevgep35.19.13 = getelementptr i8, i8* %a, i64 33
  %4261 = load i8, i8* %scevgep35.19.13, align 1
  %4262 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.13 = call zeroext i8 @mult(i8 zeroext %4261, i8 zeroext %4262)
  %conv35.19.13 = zext i8 %call34.19.13 to i32
  %xor36.19.13 = xor i32 %xor.19.13, %conv35.19.13
  %conv37.19.13 = trunc i32 %xor36.19.13 to i8
  store i8 %conv37.19.13, i8* %scevgep41.19.12, align 1
  %scevgep28.19.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4256, i64 0, i64 0, i64 1
  %4263 = bitcast i8* %scevgep28.19.13 to [41 x [41 x i8]]*
  %scevgep41.19.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4257, i64 0, i64 1, i64 0
  %4264 = bitcast i8* %scevgep41.19.13 to [41 x [41 x i8]]*
  %call16.19.14 = call zeroext i8 (...) @rand()
  store i8 %call16.19.14, i8* %scevgep28.19.13, align 1
  %4265 = load i8, i8* %scevgep28.19.13, align 1
  %conv23.19.14 = zext i8 %4265 to i32
  %4266 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.14 = getelementptr i8, i8* %b, i64 34
  %4267 = load i8, i8* %scevgep34.19.14, align 1
  %call28.19.14 = call zeroext i8 @mult(i8 zeroext %4266, i8 zeroext %4267)
  %conv29.19.14 = zext i8 %call28.19.14 to i32
  %xor.19.14 = xor i32 %conv23.19.14, %conv29.19.14
  %scevgep35.19.14 = getelementptr i8, i8* %a, i64 34
  %4268 = load i8, i8* %scevgep35.19.14, align 1
  %4269 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.14 = call zeroext i8 @mult(i8 zeroext %4268, i8 zeroext %4269)
  %conv35.19.14 = zext i8 %call34.19.14 to i32
  %xor36.19.14 = xor i32 %xor.19.14, %conv35.19.14
  %conv37.19.14 = trunc i32 %xor36.19.14 to i8
  store i8 %conv37.19.14, i8* %scevgep41.19.13, align 1
  %scevgep28.19.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4263, i64 0, i64 0, i64 1
  %4270 = bitcast i8* %scevgep28.19.14 to [41 x [41 x i8]]*
  %scevgep41.19.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4264, i64 0, i64 1, i64 0
  %4271 = bitcast i8* %scevgep41.19.14 to [41 x [41 x i8]]*
  %call16.19.15 = call zeroext i8 (...) @rand()
  store i8 %call16.19.15, i8* %scevgep28.19.14, align 1
  %4272 = load i8, i8* %scevgep28.19.14, align 1
  %conv23.19.15 = zext i8 %4272 to i32
  %4273 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.15 = getelementptr i8, i8* %b, i64 35
  %4274 = load i8, i8* %scevgep34.19.15, align 1
  %call28.19.15 = call zeroext i8 @mult(i8 zeroext %4273, i8 zeroext %4274)
  %conv29.19.15 = zext i8 %call28.19.15 to i32
  %xor.19.15 = xor i32 %conv23.19.15, %conv29.19.15
  %scevgep35.19.15 = getelementptr i8, i8* %a, i64 35
  %4275 = load i8, i8* %scevgep35.19.15, align 1
  %4276 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.15 = call zeroext i8 @mult(i8 zeroext %4275, i8 zeroext %4276)
  %conv35.19.15 = zext i8 %call34.19.15 to i32
  %xor36.19.15 = xor i32 %xor.19.15, %conv35.19.15
  %conv37.19.15 = trunc i32 %xor36.19.15 to i8
  store i8 %conv37.19.15, i8* %scevgep41.19.14, align 1
  %scevgep28.19.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4270, i64 0, i64 0, i64 1
  %4277 = bitcast i8* %scevgep28.19.15 to [41 x [41 x i8]]*
  %scevgep41.19.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4271, i64 0, i64 1, i64 0
  %4278 = bitcast i8* %scevgep41.19.15 to [41 x [41 x i8]]*
  %call16.19.16 = call zeroext i8 (...) @rand()
  store i8 %call16.19.16, i8* %scevgep28.19.15, align 1
  %4279 = load i8, i8* %scevgep28.19.15, align 1
  %conv23.19.16 = zext i8 %4279 to i32
  %4280 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.16 = getelementptr i8, i8* %b, i64 36
  %4281 = load i8, i8* %scevgep34.19.16, align 1
  %call28.19.16 = call zeroext i8 @mult(i8 zeroext %4280, i8 zeroext %4281)
  %conv29.19.16 = zext i8 %call28.19.16 to i32
  %xor.19.16 = xor i32 %conv23.19.16, %conv29.19.16
  %scevgep35.19.16 = getelementptr i8, i8* %a, i64 36
  %4282 = load i8, i8* %scevgep35.19.16, align 1
  %4283 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.16 = call zeroext i8 @mult(i8 zeroext %4282, i8 zeroext %4283)
  %conv35.19.16 = zext i8 %call34.19.16 to i32
  %xor36.19.16 = xor i32 %xor.19.16, %conv35.19.16
  %conv37.19.16 = trunc i32 %xor36.19.16 to i8
  store i8 %conv37.19.16, i8* %scevgep41.19.15, align 1
  %scevgep28.19.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4277, i64 0, i64 0, i64 1
  %4284 = bitcast i8* %scevgep28.19.16 to [41 x [41 x i8]]*
  %scevgep41.19.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4278, i64 0, i64 1, i64 0
  %4285 = bitcast i8* %scevgep41.19.16 to [41 x [41 x i8]]*
  %call16.19.17 = call zeroext i8 (...) @rand()
  store i8 %call16.19.17, i8* %scevgep28.19.16, align 1
  %4286 = load i8, i8* %scevgep28.19.16, align 1
  %conv23.19.17 = zext i8 %4286 to i32
  %4287 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.17 = getelementptr i8, i8* %b, i64 37
  %4288 = load i8, i8* %scevgep34.19.17, align 1
  %call28.19.17 = call zeroext i8 @mult(i8 zeroext %4287, i8 zeroext %4288)
  %conv29.19.17 = zext i8 %call28.19.17 to i32
  %xor.19.17 = xor i32 %conv23.19.17, %conv29.19.17
  %scevgep35.19.17 = getelementptr i8, i8* %a, i64 37
  %4289 = load i8, i8* %scevgep35.19.17, align 1
  %4290 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.17 = call zeroext i8 @mult(i8 zeroext %4289, i8 zeroext %4290)
  %conv35.19.17 = zext i8 %call34.19.17 to i32
  %xor36.19.17 = xor i32 %xor.19.17, %conv35.19.17
  %conv37.19.17 = trunc i32 %xor36.19.17 to i8
  store i8 %conv37.19.17, i8* %scevgep41.19.16, align 1
  %scevgep28.19.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4284, i64 0, i64 0, i64 1
  %4291 = bitcast i8* %scevgep28.19.17 to [41 x [41 x i8]]*
  %scevgep41.19.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4285, i64 0, i64 1, i64 0
  %4292 = bitcast i8* %scevgep41.19.17 to [41 x [41 x i8]]*
  %call16.19.18 = call zeroext i8 (...) @rand()
  store i8 %call16.19.18, i8* %scevgep28.19.17, align 1
  %4293 = load i8, i8* %scevgep28.19.17, align 1
  %conv23.19.18 = zext i8 %4293 to i32
  %4294 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.18 = getelementptr i8, i8* %b, i64 38
  %4295 = load i8, i8* %scevgep34.19.18, align 1
  %call28.19.18 = call zeroext i8 @mult(i8 zeroext %4294, i8 zeroext %4295)
  %conv29.19.18 = zext i8 %call28.19.18 to i32
  %xor.19.18 = xor i32 %conv23.19.18, %conv29.19.18
  %scevgep35.19.18 = getelementptr i8, i8* %a, i64 38
  %4296 = load i8, i8* %scevgep35.19.18, align 1
  %4297 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.18 = call zeroext i8 @mult(i8 zeroext %4296, i8 zeroext %4297)
  %conv35.19.18 = zext i8 %call34.19.18 to i32
  %xor36.19.18 = xor i32 %xor.19.18, %conv35.19.18
  %conv37.19.18 = trunc i32 %xor36.19.18 to i8
  store i8 %conv37.19.18, i8* %scevgep41.19.17, align 1
  %scevgep28.19.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4291, i64 0, i64 0, i64 1
  %4298 = bitcast i8* %scevgep28.19.18 to [41 x [41 x i8]]*
  %scevgep41.19.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4292, i64 0, i64 1, i64 0
  %4299 = bitcast i8* %scevgep41.19.18 to [41 x [41 x i8]]*
  %call16.19.19 = call zeroext i8 (...) @rand()
  store i8 %call16.19.19, i8* %scevgep28.19.18, align 1
  %4300 = load i8, i8* %scevgep28.19.18, align 1
  %conv23.19.19 = zext i8 %4300 to i32
  %4301 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.19 = getelementptr i8, i8* %b, i64 39
  %4302 = load i8, i8* %scevgep34.19.19, align 1
  %call28.19.19 = call zeroext i8 @mult(i8 zeroext %4301, i8 zeroext %4302)
  %conv29.19.19 = zext i8 %call28.19.19 to i32
  %xor.19.19 = xor i32 %conv23.19.19, %conv29.19.19
  %scevgep35.19.19 = getelementptr i8, i8* %a, i64 39
  %4303 = load i8, i8* %scevgep35.19.19, align 1
  %4304 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.19 = call zeroext i8 @mult(i8 zeroext %4303, i8 zeroext %4304)
  %conv35.19.19 = zext i8 %call34.19.19 to i32
  %xor36.19.19 = xor i32 %xor.19.19, %conv35.19.19
  %conv37.19.19 = trunc i32 %xor36.19.19 to i8
  store i8 %conv37.19.19, i8* %scevgep41.19.18, align 1
  %scevgep28.19.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4298, i64 0, i64 0, i64 1
  %scevgep41.19.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4299, i64 0, i64 1, i64 0
  %call16.19.20 = call zeroext i8 (...) @rand()
  store i8 %call16.19.20, i8* %scevgep28.19.19, align 1
  %4305 = load i8, i8* %scevgep28.19.19, align 1
  %conv23.19.20 = zext i8 %4305 to i32
  %4306 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.20 = getelementptr i8, i8* %b, i64 40
  %4307 = load i8, i8* %scevgep34.19.20, align 1
  %call28.19.20 = call zeroext i8 @mult(i8 zeroext %4306, i8 zeroext %4307)
  %conv29.19.20 = zext i8 %call28.19.20 to i32
  %xor.19.20 = xor i32 %conv23.19.20, %conv29.19.20
  %scevgep35.19.20 = getelementptr i8, i8* %a, i64 40
  %4308 = load i8, i8* %scevgep35.19.20, align 1
  %4309 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.20 = call zeroext i8 @mult(i8 zeroext %4308, i8 zeroext %4309)
  %conv35.19.20 = zext i8 %call34.19.20 to i32
  %xor36.19.20 = xor i32 %xor.19.20, %conv35.19.20
  %conv37.19.20 = trunc i32 %xor36.19.20 to i8
  store i8 %conv37.19.20, i8* %scevgep41.19.19, align 1
  %scevgep26.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4165, i64 0, i64 1, i64 1
  %4310 = bitcast i8* %scevgep26.19 to [41 x [41 x i8]]*
  %scevgep39.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4166, i64 0, i64 1, i64 1
  %4311 = bitcast i8* %scevgep39.19 to [41 x [41 x i8]]*
  %arrayidx25.20 = getelementptr inbounds i8, i8* %a, i64 20
  %arrayidx33.20 = getelementptr inbounds i8, i8* %b, i64 20
  %call16.20 = call zeroext i8 (...) @rand()
  store i8 %call16.20, i8* %scevgep26.19, align 1
  %4312 = load i8, i8* %scevgep26.19, align 1
  %conv23.20 = zext i8 %4312 to i32
  %4313 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20 = getelementptr i8, i8* %b, i64 21
  %4314 = load i8, i8* %scevgep34.20, align 1
  %call28.20 = call zeroext i8 @mult(i8 zeroext %4313, i8 zeroext %4314)
  %conv29.20 = zext i8 %call28.20 to i32
  %xor.20 = xor i32 %conv23.20, %conv29.20
  %scevgep35.20 = getelementptr i8, i8* %a, i64 21
  %4315 = load i8, i8* %scevgep35.20, align 1
  %4316 = load i8, i8* %arrayidx33.20, align 1
  %call34.20 = call zeroext i8 @mult(i8 zeroext %4315, i8 zeroext %4316)
  %conv35.20 = zext i8 %call34.20 to i32
  %xor36.20 = xor i32 %xor.20, %conv35.20
  %conv37.20 = trunc i32 %xor36.20 to i8
  store i8 %conv37.20, i8* %scevgep39.19, align 1
  %scevgep28.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4310, i64 0, i64 0, i64 1
  %4317 = bitcast i8* %scevgep28.20 to [41 x [41 x i8]]*
  %scevgep41.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4311, i64 0, i64 1, i64 0
  %4318 = bitcast i8* %scevgep41.20 to [41 x [41 x i8]]*
  %call16.20.1 = call zeroext i8 (...) @rand()
  store i8 %call16.20.1, i8* %scevgep28.20, align 1
  %4319 = load i8, i8* %scevgep28.20, align 1
  %conv23.20.1 = zext i8 %4319 to i32
  %4320 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.1 = getelementptr i8, i8* %b, i64 22
  %4321 = load i8, i8* %scevgep34.20.1, align 1
  %call28.20.1 = call zeroext i8 @mult(i8 zeroext %4320, i8 zeroext %4321)
  %conv29.20.1 = zext i8 %call28.20.1 to i32
  %xor.20.1 = xor i32 %conv23.20.1, %conv29.20.1
  %scevgep35.20.1 = getelementptr i8, i8* %a, i64 22
  %4322 = load i8, i8* %scevgep35.20.1, align 1
  %4323 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.1 = call zeroext i8 @mult(i8 zeroext %4322, i8 zeroext %4323)
  %conv35.20.1 = zext i8 %call34.20.1 to i32
  %xor36.20.1 = xor i32 %xor.20.1, %conv35.20.1
  %conv37.20.1 = trunc i32 %xor36.20.1 to i8
  store i8 %conv37.20.1, i8* %scevgep41.20, align 1
  %scevgep28.20.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4317, i64 0, i64 0, i64 1
  %4324 = bitcast i8* %scevgep28.20.1 to [41 x [41 x i8]]*
  %scevgep41.20.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4318, i64 0, i64 1, i64 0
  %4325 = bitcast i8* %scevgep41.20.1 to [41 x [41 x i8]]*
  %call16.20.2 = call zeroext i8 (...) @rand()
  store i8 %call16.20.2, i8* %scevgep28.20.1, align 1
  %4326 = load i8, i8* %scevgep28.20.1, align 1
  %conv23.20.2 = zext i8 %4326 to i32
  %4327 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.2 = getelementptr i8, i8* %b, i64 23
  %4328 = load i8, i8* %scevgep34.20.2, align 1
  %call28.20.2 = call zeroext i8 @mult(i8 zeroext %4327, i8 zeroext %4328)
  %conv29.20.2 = zext i8 %call28.20.2 to i32
  %xor.20.2 = xor i32 %conv23.20.2, %conv29.20.2
  %scevgep35.20.2 = getelementptr i8, i8* %a, i64 23
  %4329 = load i8, i8* %scevgep35.20.2, align 1
  %4330 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.2 = call zeroext i8 @mult(i8 zeroext %4329, i8 zeroext %4330)
  %conv35.20.2 = zext i8 %call34.20.2 to i32
  %xor36.20.2 = xor i32 %xor.20.2, %conv35.20.2
  %conv37.20.2 = trunc i32 %xor36.20.2 to i8
  store i8 %conv37.20.2, i8* %scevgep41.20.1, align 1
  %scevgep28.20.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4324, i64 0, i64 0, i64 1
  %4331 = bitcast i8* %scevgep28.20.2 to [41 x [41 x i8]]*
  %scevgep41.20.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4325, i64 0, i64 1, i64 0
  %4332 = bitcast i8* %scevgep41.20.2 to [41 x [41 x i8]]*
  %call16.20.3 = call zeroext i8 (...) @rand()
  store i8 %call16.20.3, i8* %scevgep28.20.2, align 1
  %4333 = load i8, i8* %scevgep28.20.2, align 1
  %conv23.20.3 = zext i8 %4333 to i32
  %4334 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.3 = getelementptr i8, i8* %b, i64 24
  %4335 = load i8, i8* %scevgep34.20.3, align 1
  %call28.20.3 = call zeroext i8 @mult(i8 zeroext %4334, i8 zeroext %4335)
  %conv29.20.3 = zext i8 %call28.20.3 to i32
  %xor.20.3 = xor i32 %conv23.20.3, %conv29.20.3
  %scevgep35.20.3 = getelementptr i8, i8* %a, i64 24
  %4336 = load i8, i8* %scevgep35.20.3, align 1
  %4337 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.3 = call zeroext i8 @mult(i8 zeroext %4336, i8 zeroext %4337)
  %conv35.20.3 = zext i8 %call34.20.3 to i32
  %xor36.20.3 = xor i32 %xor.20.3, %conv35.20.3
  %conv37.20.3 = trunc i32 %xor36.20.3 to i8
  store i8 %conv37.20.3, i8* %scevgep41.20.2, align 1
  %scevgep28.20.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4331, i64 0, i64 0, i64 1
  %4338 = bitcast i8* %scevgep28.20.3 to [41 x [41 x i8]]*
  %scevgep41.20.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4332, i64 0, i64 1, i64 0
  %4339 = bitcast i8* %scevgep41.20.3 to [41 x [41 x i8]]*
  %call16.20.4 = call zeroext i8 (...) @rand()
  store i8 %call16.20.4, i8* %scevgep28.20.3, align 1
  %4340 = load i8, i8* %scevgep28.20.3, align 1
  %conv23.20.4 = zext i8 %4340 to i32
  %4341 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.4 = getelementptr i8, i8* %b, i64 25
  %4342 = load i8, i8* %scevgep34.20.4, align 1
  %call28.20.4 = call zeroext i8 @mult(i8 zeroext %4341, i8 zeroext %4342)
  %conv29.20.4 = zext i8 %call28.20.4 to i32
  %xor.20.4 = xor i32 %conv23.20.4, %conv29.20.4
  %scevgep35.20.4 = getelementptr i8, i8* %a, i64 25
  %4343 = load i8, i8* %scevgep35.20.4, align 1
  %4344 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.4 = call zeroext i8 @mult(i8 zeroext %4343, i8 zeroext %4344)
  %conv35.20.4 = zext i8 %call34.20.4 to i32
  %xor36.20.4 = xor i32 %xor.20.4, %conv35.20.4
  %conv37.20.4 = trunc i32 %xor36.20.4 to i8
  store i8 %conv37.20.4, i8* %scevgep41.20.3, align 1
  %scevgep28.20.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4338, i64 0, i64 0, i64 1
  %4345 = bitcast i8* %scevgep28.20.4 to [41 x [41 x i8]]*
  %scevgep41.20.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4339, i64 0, i64 1, i64 0
  %4346 = bitcast i8* %scevgep41.20.4 to [41 x [41 x i8]]*
  %call16.20.5 = call zeroext i8 (...) @rand()
  store i8 %call16.20.5, i8* %scevgep28.20.4, align 1
  %4347 = load i8, i8* %scevgep28.20.4, align 1
  %conv23.20.5 = zext i8 %4347 to i32
  %4348 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.5 = getelementptr i8, i8* %b, i64 26
  %4349 = load i8, i8* %scevgep34.20.5, align 1
  %call28.20.5 = call zeroext i8 @mult(i8 zeroext %4348, i8 zeroext %4349)
  %conv29.20.5 = zext i8 %call28.20.5 to i32
  %xor.20.5 = xor i32 %conv23.20.5, %conv29.20.5
  %scevgep35.20.5 = getelementptr i8, i8* %a, i64 26
  %4350 = load i8, i8* %scevgep35.20.5, align 1
  %4351 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.5 = call zeroext i8 @mult(i8 zeroext %4350, i8 zeroext %4351)
  %conv35.20.5 = zext i8 %call34.20.5 to i32
  %xor36.20.5 = xor i32 %xor.20.5, %conv35.20.5
  %conv37.20.5 = trunc i32 %xor36.20.5 to i8
  store i8 %conv37.20.5, i8* %scevgep41.20.4, align 1
  %scevgep28.20.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4345, i64 0, i64 0, i64 1
  %4352 = bitcast i8* %scevgep28.20.5 to [41 x [41 x i8]]*
  %scevgep41.20.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4346, i64 0, i64 1, i64 0
  %4353 = bitcast i8* %scevgep41.20.5 to [41 x [41 x i8]]*
  %call16.20.6 = call zeroext i8 (...) @rand()
  store i8 %call16.20.6, i8* %scevgep28.20.5, align 1
  %4354 = load i8, i8* %scevgep28.20.5, align 1
  %conv23.20.6 = zext i8 %4354 to i32
  %4355 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.6 = getelementptr i8, i8* %b, i64 27
  %4356 = load i8, i8* %scevgep34.20.6, align 1
  %call28.20.6 = call zeroext i8 @mult(i8 zeroext %4355, i8 zeroext %4356)
  %conv29.20.6 = zext i8 %call28.20.6 to i32
  %xor.20.6 = xor i32 %conv23.20.6, %conv29.20.6
  %scevgep35.20.6 = getelementptr i8, i8* %a, i64 27
  %4357 = load i8, i8* %scevgep35.20.6, align 1
  %4358 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.6 = call zeroext i8 @mult(i8 zeroext %4357, i8 zeroext %4358)
  %conv35.20.6 = zext i8 %call34.20.6 to i32
  %xor36.20.6 = xor i32 %xor.20.6, %conv35.20.6
  %conv37.20.6 = trunc i32 %xor36.20.6 to i8
  store i8 %conv37.20.6, i8* %scevgep41.20.5, align 1
  %scevgep28.20.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4352, i64 0, i64 0, i64 1
  %4359 = bitcast i8* %scevgep28.20.6 to [41 x [41 x i8]]*
  %scevgep41.20.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4353, i64 0, i64 1, i64 0
  %4360 = bitcast i8* %scevgep41.20.6 to [41 x [41 x i8]]*
  %call16.20.7 = call zeroext i8 (...) @rand()
  store i8 %call16.20.7, i8* %scevgep28.20.6, align 1
  %4361 = load i8, i8* %scevgep28.20.6, align 1
  %conv23.20.7 = zext i8 %4361 to i32
  %4362 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.7 = getelementptr i8, i8* %b, i64 28
  %4363 = load i8, i8* %scevgep34.20.7, align 1
  %call28.20.7 = call zeroext i8 @mult(i8 zeroext %4362, i8 zeroext %4363)
  %conv29.20.7 = zext i8 %call28.20.7 to i32
  %xor.20.7 = xor i32 %conv23.20.7, %conv29.20.7
  %scevgep35.20.7 = getelementptr i8, i8* %a, i64 28
  %4364 = load i8, i8* %scevgep35.20.7, align 1
  %4365 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.7 = call zeroext i8 @mult(i8 zeroext %4364, i8 zeroext %4365)
  %conv35.20.7 = zext i8 %call34.20.7 to i32
  %xor36.20.7 = xor i32 %xor.20.7, %conv35.20.7
  %conv37.20.7 = trunc i32 %xor36.20.7 to i8
  store i8 %conv37.20.7, i8* %scevgep41.20.6, align 1
  %scevgep28.20.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4359, i64 0, i64 0, i64 1
  %4366 = bitcast i8* %scevgep28.20.7 to [41 x [41 x i8]]*
  %scevgep41.20.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4360, i64 0, i64 1, i64 0
  %4367 = bitcast i8* %scevgep41.20.7 to [41 x [41 x i8]]*
  %call16.20.8 = call zeroext i8 (...) @rand()
  store i8 %call16.20.8, i8* %scevgep28.20.7, align 1
  %4368 = load i8, i8* %scevgep28.20.7, align 1
  %conv23.20.8 = zext i8 %4368 to i32
  %4369 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.8 = getelementptr i8, i8* %b, i64 29
  %4370 = load i8, i8* %scevgep34.20.8, align 1
  %call28.20.8 = call zeroext i8 @mult(i8 zeroext %4369, i8 zeroext %4370)
  %conv29.20.8 = zext i8 %call28.20.8 to i32
  %xor.20.8 = xor i32 %conv23.20.8, %conv29.20.8
  %scevgep35.20.8 = getelementptr i8, i8* %a, i64 29
  %4371 = load i8, i8* %scevgep35.20.8, align 1
  %4372 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.8 = call zeroext i8 @mult(i8 zeroext %4371, i8 zeroext %4372)
  %conv35.20.8 = zext i8 %call34.20.8 to i32
  %xor36.20.8 = xor i32 %xor.20.8, %conv35.20.8
  %conv37.20.8 = trunc i32 %xor36.20.8 to i8
  store i8 %conv37.20.8, i8* %scevgep41.20.7, align 1
  %scevgep28.20.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4366, i64 0, i64 0, i64 1
  %4373 = bitcast i8* %scevgep28.20.8 to [41 x [41 x i8]]*
  %scevgep41.20.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4367, i64 0, i64 1, i64 0
  %4374 = bitcast i8* %scevgep41.20.8 to [41 x [41 x i8]]*
  %call16.20.9 = call zeroext i8 (...) @rand()
  store i8 %call16.20.9, i8* %scevgep28.20.8, align 1
  %4375 = load i8, i8* %scevgep28.20.8, align 1
  %conv23.20.9 = zext i8 %4375 to i32
  %4376 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.9 = getelementptr i8, i8* %b, i64 30
  %4377 = load i8, i8* %scevgep34.20.9, align 1
  %call28.20.9 = call zeroext i8 @mult(i8 zeroext %4376, i8 zeroext %4377)
  %conv29.20.9 = zext i8 %call28.20.9 to i32
  %xor.20.9 = xor i32 %conv23.20.9, %conv29.20.9
  %scevgep35.20.9 = getelementptr i8, i8* %a, i64 30
  %4378 = load i8, i8* %scevgep35.20.9, align 1
  %4379 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.9 = call zeroext i8 @mult(i8 zeroext %4378, i8 zeroext %4379)
  %conv35.20.9 = zext i8 %call34.20.9 to i32
  %xor36.20.9 = xor i32 %xor.20.9, %conv35.20.9
  %conv37.20.9 = trunc i32 %xor36.20.9 to i8
  store i8 %conv37.20.9, i8* %scevgep41.20.8, align 1
  %scevgep28.20.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4373, i64 0, i64 0, i64 1
  %4380 = bitcast i8* %scevgep28.20.9 to [41 x [41 x i8]]*
  %scevgep41.20.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4374, i64 0, i64 1, i64 0
  %4381 = bitcast i8* %scevgep41.20.9 to [41 x [41 x i8]]*
  %call16.20.10 = call zeroext i8 (...) @rand()
  store i8 %call16.20.10, i8* %scevgep28.20.9, align 1
  %4382 = load i8, i8* %scevgep28.20.9, align 1
  %conv23.20.10 = zext i8 %4382 to i32
  %4383 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.10 = getelementptr i8, i8* %b, i64 31
  %4384 = load i8, i8* %scevgep34.20.10, align 1
  %call28.20.10 = call zeroext i8 @mult(i8 zeroext %4383, i8 zeroext %4384)
  %conv29.20.10 = zext i8 %call28.20.10 to i32
  %xor.20.10 = xor i32 %conv23.20.10, %conv29.20.10
  %scevgep35.20.10 = getelementptr i8, i8* %a, i64 31
  %4385 = load i8, i8* %scevgep35.20.10, align 1
  %4386 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.10 = call zeroext i8 @mult(i8 zeroext %4385, i8 zeroext %4386)
  %conv35.20.10 = zext i8 %call34.20.10 to i32
  %xor36.20.10 = xor i32 %xor.20.10, %conv35.20.10
  %conv37.20.10 = trunc i32 %xor36.20.10 to i8
  store i8 %conv37.20.10, i8* %scevgep41.20.9, align 1
  %scevgep28.20.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4380, i64 0, i64 0, i64 1
  %4387 = bitcast i8* %scevgep28.20.10 to [41 x [41 x i8]]*
  %scevgep41.20.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4381, i64 0, i64 1, i64 0
  %4388 = bitcast i8* %scevgep41.20.10 to [41 x [41 x i8]]*
  %call16.20.11 = call zeroext i8 (...) @rand()
  store i8 %call16.20.11, i8* %scevgep28.20.10, align 1
  %4389 = load i8, i8* %scevgep28.20.10, align 1
  %conv23.20.11 = zext i8 %4389 to i32
  %4390 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.11 = getelementptr i8, i8* %b, i64 32
  %4391 = load i8, i8* %scevgep34.20.11, align 1
  %call28.20.11 = call zeroext i8 @mult(i8 zeroext %4390, i8 zeroext %4391)
  %conv29.20.11 = zext i8 %call28.20.11 to i32
  %xor.20.11 = xor i32 %conv23.20.11, %conv29.20.11
  %scevgep35.20.11 = getelementptr i8, i8* %a, i64 32
  %4392 = load i8, i8* %scevgep35.20.11, align 1
  %4393 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.11 = call zeroext i8 @mult(i8 zeroext %4392, i8 zeroext %4393)
  %conv35.20.11 = zext i8 %call34.20.11 to i32
  %xor36.20.11 = xor i32 %xor.20.11, %conv35.20.11
  %conv37.20.11 = trunc i32 %xor36.20.11 to i8
  store i8 %conv37.20.11, i8* %scevgep41.20.10, align 1
  %scevgep28.20.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4387, i64 0, i64 0, i64 1
  %4394 = bitcast i8* %scevgep28.20.11 to [41 x [41 x i8]]*
  %scevgep41.20.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4388, i64 0, i64 1, i64 0
  %4395 = bitcast i8* %scevgep41.20.11 to [41 x [41 x i8]]*
  %call16.20.12 = call zeroext i8 (...) @rand()
  store i8 %call16.20.12, i8* %scevgep28.20.11, align 1
  %4396 = load i8, i8* %scevgep28.20.11, align 1
  %conv23.20.12 = zext i8 %4396 to i32
  %4397 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.12 = getelementptr i8, i8* %b, i64 33
  %4398 = load i8, i8* %scevgep34.20.12, align 1
  %call28.20.12 = call zeroext i8 @mult(i8 zeroext %4397, i8 zeroext %4398)
  %conv29.20.12 = zext i8 %call28.20.12 to i32
  %xor.20.12 = xor i32 %conv23.20.12, %conv29.20.12
  %scevgep35.20.12 = getelementptr i8, i8* %a, i64 33
  %4399 = load i8, i8* %scevgep35.20.12, align 1
  %4400 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.12 = call zeroext i8 @mult(i8 zeroext %4399, i8 zeroext %4400)
  %conv35.20.12 = zext i8 %call34.20.12 to i32
  %xor36.20.12 = xor i32 %xor.20.12, %conv35.20.12
  %conv37.20.12 = trunc i32 %xor36.20.12 to i8
  store i8 %conv37.20.12, i8* %scevgep41.20.11, align 1
  %scevgep28.20.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4394, i64 0, i64 0, i64 1
  %4401 = bitcast i8* %scevgep28.20.12 to [41 x [41 x i8]]*
  %scevgep41.20.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4395, i64 0, i64 1, i64 0
  %4402 = bitcast i8* %scevgep41.20.12 to [41 x [41 x i8]]*
  %call16.20.13 = call zeroext i8 (...) @rand()
  store i8 %call16.20.13, i8* %scevgep28.20.12, align 1
  %4403 = load i8, i8* %scevgep28.20.12, align 1
  %conv23.20.13 = zext i8 %4403 to i32
  %4404 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.13 = getelementptr i8, i8* %b, i64 34
  %4405 = load i8, i8* %scevgep34.20.13, align 1
  %call28.20.13 = call zeroext i8 @mult(i8 zeroext %4404, i8 zeroext %4405)
  %conv29.20.13 = zext i8 %call28.20.13 to i32
  %xor.20.13 = xor i32 %conv23.20.13, %conv29.20.13
  %scevgep35.20.13 = getelementptr i8, i8* %a, i64 34
  %4406 = load i8, i8* %scevgep35.20.13, align 1
  %4407 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.13 = call zeroext i8 @mult(i8 zeroext %4406, i8 zeroext %4407)
  %conv35.20.13 = zext i8 %call34.20.13 to i32
  %xor36.20.13 = xor i32 %xor.20.13, %conv35.20.13
  %conv37.20.13 = trunc i32 %xor36.20.13 to i8
  store i8 %conv37.20.13, i8* %scevgep41.20.12, align 1
  %scevgep28.20.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4401, i64 0, i64 0, i64 1
  %4408 = bitcast i8* %scevgep28.20.13 to [41 x [41 x i8]]*
  %scevgep41.20.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4402, i64 0, i64 1, i64 0
  %4409 = bitcast i8* %scevgep41.20.13 to [41 x [41 x i8]]*
  %call16.20.14 = call zeroext i8 (...) @rand()
  store i8 %call16.20.14, i8* %scevgep28.20.13, align 1
  %4410 = load i8, i8* %scevgep28.20.13, align 1
  %conv23.20.14 = zext i8 %4410 to i32
  %4411 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.14 = getelementptr i8, i8* %b, i64 35
  %4412 = load i8, i8* %scevgep34.20.14, align 1
  %call28.20.14 = call zeroext i8 @mult(i8 zeroext %4411, i8 zeroext %4412)
  %conv29.20.14 = zext i8 %call28.20.14 to i32
  %xor.20.14 = xor i32 %conv23.20.14, %conv29.20.14
  %scevgep35.20.14 = getelementptr i8, i8* %a, i64 35
  %4413 = load i8, i8* %scevgep35.20.14, align 1
  %4414 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.14 = call zeroext i8 @mult(i8 zeroext %4413, i8 zeroext %4414)
  %conv35.20.14 = zext i8 %call34.20.14 to i32
  %xor36.20.14 = xor i32 %xor.20.14, %conv35.20.14
  %conv37.20.14 = trunc i32 %xor36.20.14 to i8
  store i8 %conv37.20.14, i8* %scevgep41.20.13, align 1
  %scevgep28.20.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4408, i64 0, i64 0, i64 1
  %4415 = bitcast i8* %scevgep28.20.14 to [41 x [41 x i8]]*
  %scevgep41.20.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4409, i64 0, i64 1, i64 0
  %4416 = bitcast i8* %scevgep41.20.14 to [41 x [41 x i8]]*
  %call16.20.15 = call zeroext i8 (...) @rand()
  store i8 %call16.20.15, i8* %scevgep28.20.14, align 1
  %4417 = load i8, i8* %scevgep28.20.14, align 1
  %conv23.20.15 = zext i8 %4417 to i32
  %4418 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.15 = getelementptr i8, i8* %b, i64 36
  %4419 = load i8, i8* %scevgep34.20.15, align 1
  %call28.20.15 = call zeroext i8 @mult(i8 zeroext %4418, i8 zeroext %4419)
  %conv29.20.15 = zext i8 %call28.20.15 to i32
  %xor.20.15 = xor i32 %conv23.20.15, %conv29.20.15
  %scevgep35.20.15 = getelementptr i8, i8* %a, i64 36
  %4420 = load i8, i8* %scevgep35.20.15, align 1
  %4421 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.15 = call zeroext i8 @mult(i8 zeroext %4420, i8 zeroext %4421)
  %conv35.20.15 = zext i8 %call34.20.15 to i32
  %xor36.20.15 = xor i32 %xor.20.15, %conv35.20.15
  %conv37.20.15 = trunc i32 %xor36.20.15 to i8
  store i8 %conv37.20.15, i8* %scevgep41.20.14, align 1
  %scevgep28.20.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4415, i64 0, i64 0, i64 1
  %4422 = bitcast i8* %scevgep28.20.15 to [41 x [41 x i8]]*
  %scevgep41.20.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4416, i64 0, i64 1, i64 0
  %4423 = bitcast i8* %scevgep41.20.15 to [41 x [41 x i8]]*
  %call16.20.16 = call zeroext i8 (...) @rand()
  store i8 %call16.20.16, i8* %scevgep28.20.15, align 1
  %4424 = load i8, i8* %scevgep28.20.15, align 1
  %conv23.20.16 = zext i8 %4424 to i32
  %4425 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.16 = getelementptr i8, i8* %b, i64 37
  %4426 = load i8, i8* %scevgep34.20.16, align 1
  %call28.20.16 = call zeroext i8 @mult(i8 zeroext %4425, i8 zeroext %4426)
  %conv29.20.16 = zext i8 %call28.20.16 to i32
  %xor.20.16 = xor i32 %conv23.20.16, %conv29.20.16
  %scevgep35.20.16 = getelementptr i8, i8* %a, i64 37
  %4427 = load i8, i8* %scevgep35.20.16, align 1
  %4428 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.16 = call zeroext i8 @mult(i8 zeroext %4427, i8 zeroext %4428)
  %conv35.20.16 = zext i8 %call34.20.16 to i32
  %xor36.20.16 = xor i32 %xor.20.16, %conv35.20.16
  %conv37.20.16 = trunc i32 %xor36.20.16 to i8
  store i8 %conv37.20.16, i8* %scevgep41.20.15, align 1
  %scevgep28.20.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4422, i64 0, i64 0, i64 1
  %4429 = bitcast i8* %scevgep28.20.16 to [41 x [41 x i8]]*
  %scevgep41.20.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4423, i64 0, i64 1, i64 0
  %4430 = bitcast i8* %scevgep41.20.16 to [41 x [41 x i8]]*
  %call16.20.17 = call zeroext i8 (...) @rand()
  store i8 %call16.20.17, i8* %scevgep28.20.16, align 1
  %4431 = load i8, i8* %scevgep28.20.16, align 1
  %conv23.20.17 = zext i8 %4431 to i32
  %4432 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.17 = getelementptr i8, i8* %b, i64 38
  %4433 = load i8, i8* %scevgep34.20.17, align 1
  %call28.20.17 = call zeroext i8 @mult(i8 zeroext %4432, i8 zeroext %4433)
  %conv29.20.17 = zext i8 %call28.20.17 to i32
  %xor.20.17 = xor i32 %conv23.20.17, %conv29.20.17
  %scevgep35.20.17 = getelementptr i8, i8* %a, i64 38
  %4434 = load i8, i8* %scevgep35.20.17, align 1
  %4435 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.17 = call zeroext i8 @mult(i8 zeroext %4434, i8 zeroext %4435)
  %conv35.20.17 = zext i8 %call34.20.17 to i32
  %xor36.20.17 = xor i32 %xor.20.17, %conv35.20.17
  %conv37.20.17 = trunc i32 %xor36.20.17 to i8
  store i8 %conv37.20.17, i8* %scevgep41.20.16, align 1
  %scevgep28.20.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4429, i64 0, i64 0, i64 1
  %4436 = bitcast i8* %scevgep28.20.17 to [41 x [41 x i8]]*
  %scevgep41.20.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4430, i64 0, i64 1, i64 0
  %4437 = bitcast i8* %scevgep41.20.17 to [41 x [41 x i8]]*
  %call16.20.18 = call zeroext i8 (...) @rand()
  store i8 %call16.20.18, i8* %scevgep28.20.17, align 1
  %4438 = load i8, i8* %scevgep28.20.17, align 1
  %conv23.20.18 = zext i8 %4438 to i32
  %4439 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.18 = getelementptr i8, i8* %b, i64 39
  %4440 = load i8, i8* %scevgep34.20.18, align 1
  %call28.20.18 = call zeroext i8 @mult(i8 zeroext %4439, i8 zeroext %4440)
  %conv29.20.18 = zext i8 %call28.20.18 to i32
  %xor.20.18 = xor i32 %conv23.20.18, %conv29.20.18
  %scevgep35.20.18 = getelementptr i8, i8* %a, i64 39
  %4441 = load i8, i8* %scevgep35.20.18, align 1
  %4442 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.18 = call zeroext i8 @mult(i8 zeroext %4441, i8 zeroext %4442)
  %conv35.20.18 = zext i8 %call34.20.18 to i32
  %xor36.20.18 = xor i32 %xor.20.18, %conv35.20.18
  %conv37.20.18 = trunc i32 %xor36.20.18 to i8
  store i8 %conv37.20.18, i8* %scevgep41.20.17, align 1
  %scevgep28.20.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4436, i64 0, i64 0, i64 1
  %scevgep41.20.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4437, i64 0, i64 1, i64 0
  %call16.20.19 = call zeroext i8 (...) @rand()
  store i8 %call16.20.19, i8* %scevgep28.20.18, align 1
  %4443 = load i8, i8* %scevgep28.20.18, align 1
  %conv23.20.19 = zext i8 %4443 to i32
  %4444 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.19 = getelementptr i8, i8* %b, i64 40
  %4445 = load i8, i8* %scevgep34.20.19, align 1
  %call28.20.19 = call zeroext i8 @mult(i8 zeroext %4444, i8 zeroext %4445)
  %conv29.20.19 = zext i8 %call28.20.19 to i32
  %xor.20.19 = xor i32 %conv23.20.19, %conv29.20.19
  %scevgep35.20.19 = getelementptr i8, i8* %a, i64 40
  %4446 = load i8, i8* %scevgep35.20.19, align 1
  %4447 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.19 = call zeroext i8 @mult(i8 zeroext %4446, i8 zeroext %4447)
  %conv35.20.19 = zext i8 %call34.20.19 to i32
  %xor36.20.19 = xor i32 %xor.20.19, %conv35.20.19
  %conv37.20.19 = trunc i32 %xor36.20.19 to i8
  store i8 %conv37.20.19, i8* %scevgep41.20.18, align 1
  %scevgep26.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4310, i64 0, i64 1, i64 1
  %4448 = bitcast i8* %scevgep26.20 to [41 x [41 x i8]]*
  %scevgep39.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4311, i64 0, i64 1, i64 1
  %4449 = bitcast i8* %scevgep39.20 to [41 x [41 x i8]]*
  %arrayidx25.21 = getelementptr inbounds i8, i8* %a, i64 21
  %arrayidx33.21 = getelementptr inbounds i8, i8* %b, i64 21
  %call16.21 = call zeroext i8 (...) @rand()
  store i8 %call16.21, i8* %scevgep26.20, align 1
  %4450 = load i8, i8* %scevgep26.20, align 1
  %conv23.21 = zext i8 %4450 to i32
  %4451 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21 = getelementptr i8, i8* %b, i64 22
  %4452 = load i8, i8* %scevgep34.21, align 1
  %call28.21 = call zeroext i8 @mult(i8 zeroext %4451, i8 zeroext %4452)
  %conv29.21 = zext i8 %call28.21 to i32
  %xor.21 = xor i32 %conv23.21, %conv29.21
  %scevgep35.21 = getelementptr i8, i8* %a, i64 22
  %4453 = load i8, i8* %scevgep35.21, align 1
  %4454 = load i8, i8* %arrayidx33.21, align 1
  %call34.21 = call zeroext i8 @mult(i8 zeroext %4453, i8 zeroext %4454)
  %conv35.21 = zext i8 %call34.21 to i32
  %xor36.21 = xor i32 %xor.21, %conv35.21
  %conv37.21 = trunc i32 %xor36.21 to i8
  store i8 %conv37.21, i8* %scevgep39.20, align 1
  %scevgep28.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4448, i64 0, i64 0, i64 1
  %4455 = bitcast i8* %scevgep28.21 to [41 x [41 x i8]]*
  %scevgep41.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4449, i64 0, i64 1, i64 0
  %4456 = bitcast i8* %scevgep41.21 to [41 x [41 x i8]]*
  %call16.21.1 = call zeroext i8 (...) @rand()
  store i8 %call16.21.1, i8* %scevgep28.21, align 1
  %4457 = load i8, i8* %scevgep28.21, align 1
  %conv23.21.1 = zext i8 %4457 to i32
  %4458 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.1 = getelementptr i8, i8* %b, i64 23
  %4459 = load i8, i8* %scevgep34.21.1, align 1
  %call28.21.1 = call zeroext i8 @mult(i8 zeroext %4458, i8 zeroext %4459)
  %conv29.21.1 = zext i8 %call28.21.1 to i32
  %xor.21.1 = xor i32 %conv23.21.1, %conv29.21.1
  %scevgep35.21.1 = getelementptr i8, i8* %a, i64 23
  %4460 = load i8, i8* %scevgep35.21.1, align 1
  %4461 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.1 = call zeroext i8 @mult(i8 zeroext %4460, i8 zeroext %4461)
  %conv35.21.1 = zext i8 %call34.21.1 to i32
  %xor36.21.1 = xor i32 %xor.21.1, %conv35.21.1
  %conv37.21.1 = trunc i32 %xor36.21.1 to i8
  store i8 %conv37.21.1, i8* %scevgep41.21, align 1
  %scevgep28.21.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4455, i64 0, i64 0, i64 1
  %4462 = bitcast i8* %scevgep28.21.1 to [41 x [41 x i8]]*
  %scevgep41.21.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4456, i64 0, i64 1, i64 0
  %4463 = bitcast i8* %scevgep41.21.1 to [41 x [41 x i8]]*
  %call16.21.2 = call zeroext i8 (...) @rand()
  store i8 %call16.21.2, i8* %scevgep28.21.1, align 1
  %4464 = load i8, i8* %scevgep28.21.1, align 1
  %conv23.21.2 = zext i8 %4464 to i32
  %4465 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.2 = getelementptr i8, i8* %b, i64 24
  %4466 = load i8, i8* %scevgep34.21.2, align 1
  %call28.21.2 = call zeroext i8 @mult(i8 zeroext %4465, i8 zeroext %4466)
  %conv29.21.2 = zext i8 %call28.21.2 to i32
  %xor.21.2 = xor i32 %conv23.21.2, %conv29.21.2
  %scevgep35.21.2 = getelementptr i8, i8* %a, i64 24
  %4467 = load i8, i8* %scevgep35.21.2, align 1
  %4468 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.2 = call zeroext i8 @mult(i8 zeroext %4467, i8 zeroext %4468)
  %conv35.21.2 = zext i8 %call34.21.2 to i32
  %xor36.21.2 = xor i32 %xor.21.2, %conv35.21.2
  %conv37.21.2 = trunc i32 %xor36.21.2 to i8
  store i8 %conv37.21.2, i8* %scevgep41.21.1, align 1
  %scevgep28.21.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4462, i64 0, i64 0, i64 1
  %4469 = bitcast i8* %scevgep28.21.2 to [41 x [41 x i8]]*
  %scevgep41.21.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4463, i64 0, i64 1, i64 0
  %4470 = bitcast i8* %scevgep41.21.2 to [41 x [41 x i8]]*
  %call16.21.3 = call zeroext i8 (...) @rand()
  store i8 %call16.21.3, i8* %scevgep28.21.2, align 1
  %4471 = load i8, i8* %scevgep28.21.2, align 1
  %conv23.21.3 = zext i8 %4471 to i32
  %4472 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.3 = getelementptr i8, i8* %b, i64 25
  %4473 = load i8, i8* %scevgep34.21.3, align 1
  %call28.21.3 = call zeroext i8 @mult(i8 zeroext %4472, i8 zeroext %4473)
  %conv29.21.3 = zext i8 %call28.21.3 to i32
  %xor.21.3 = xor i32 %conv23.21.3, %conv29.21.3
  %scevgep35.21.3 = getelementptr i8, i8* %a, i64 25
  %4474 = load i8, i8* %scevgep35.21.3, align 1
  %4475 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.3 = call zeroext i8 @mult(i8 zeroext %4474, i8 zeroext %4475)
  %conv35.21.3 = zext i8 %call34.21.3 to i32
  %xor36.21.3 = xor i32 %xor.21.3, %conv35.21.3
  %conv37.21.3 = trunc i32 %xor36.21.3 to i8
  store i8 %conv37.21.3, i8* %scevgep41.21.2, align 1
  %scevgep28.21.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4469, i64 0, i64 0, i64 1
  %4476 = bitcast i8* %scevgep28.21.3 to [41 x [41 x i8]]*
  %scevgep41.21.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4470, i64 0, i64 1, i64 0
  %4477 = bitcast i8* %scevgep41.21.3 to [41 x [41 x i8]]*
  %call16.21.4 = call zeroext i8 (...) @rand()
  store i8 %call16.21.4, i8* %scevgep28.21.3, align 1
  %4478 = load i8, i8* %scevgep28.21.3, align 1
  %conv23.21.4 = zext i8 %4478 to i32
  %4479 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.4 = getelementptr i8, i8* %b, i64 26
  %4480 = load i8, i8* %scevgep34.21.4, align 1
  %call28.21.4 = call zeroext i8 @mult(i8 zeroext %4479, i8 zeroext %4480)
  %conv29.21.4 = zext i8 %call28.21.4 to i32
  %xor.21.4 = xor i32 %conv23.21.4, %conv29.21.4
  %scevgep35.21.4 = getelementptr i8, i8* %a, i64 26
  %4481 = load i8, i8* %scevgep35.21.4, align 1
  %4482 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.4 = call zeroext i8 @mult(i8 zeroext %4481, i8 zeroext %4482)
  %conv35.21.4 = zext i8 %call34.21.4 to i32
  %xor36.21.4 = xor i32 %xor.21.4, %conv35.21.4
  %conv37.21.4 = trunc i32 %xor36.21.4 to i8
  store i8 %conv37.21.4, i8* %scevgep41.21.3, align 1
  %scevgep28.21.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4476, i64 0, i64 0, i64 1
  %4483 = bitcast i8* %scevgep28.21.4 to [41 x [41 x i8]]*
  %scevgep41.21.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4477, i64 0, i64 1, i64 0
  %4484 = bitcast i8* %scevgep41.21.4 to [41 x [41 x i8]]*
  %call16.21.5 = call zeroext i8 (...) @rand()
  store i8 %call16.21.5, i8* %scevgep28.21.4, align 1
  %4485 = load i8, i8* %scevgep28.21.4, align 1
  %conv23.21.5 = zext i8 %4485 to i32
  %4486 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.5 = getelementptr i8, i8* %b, i64 27
  %4487 = load i8, i8* %scevgep34.21.5, align 1
  %call28.21.5 = call zeroext i8 @mult(i8 zeroext %4486, i8 zeroext %4487)
  %conv29.21.5 = zext i8 %call28.21.5 to i32
  %xor.21.5 = xor i32 %conv23.21.5, %conv29.21.5
  %scevgep35.21.5 = getelementptr i8, i8* %a, i64 27
  %4488 = load i8, i8* %scevgep35.21.5, align 1
  %4489 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.5 = call zeroext i8 @mult(i8 zeroext %4488, i8 zeroext %4489)
  %conv35.21.5 = zext i8 %call34.21.5 to i32
  %xor36.21.5 = xor i32 %xor.21.5, %conv35.21.5
  %conv37.21.5 = trunc i32 %xor36.21.5 to i8
  store i8 %conv37.21.5, i8* %scevgep41.21.4, align 1
  %scevgep28.21.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4483, i64 0, i64 0, i64 1
  %4490 = bitcast i8* %scevgep28.21.5 to [41 x [41 x i8]]*
  %scevgep41.21.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4484, i64 0, i64 1, i64 0
  %4491 = bitcast i8* %scevgep41.21.5 to [41 x [41 x i8]]*
  %call16.21.6 = call zeroext i8 (...) @rand()
  store i8 %call16.21.6, i8* %scevgep28.21.5, align 1
  %4492 = load i8, i8* %scevgep28.21.5, align 1
  %conv23.21.6 = zext i8 %4492 to i32
  %4493 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.6 = getelementptr i8, i8* %b, i64 28
  %4494 = load i8, i8* %scevgep34.21.6, align 1
  %call28.21.6 = call zeroext i8 @mult(i8 zeroext %4493, i8 zeroext %4494)
  %conv29.21.6 = zext i8 %call28.21.6 to i32
  %xor.21.6 = xor i32 %conv23.21.6, %conv29.21.6
  %scevgep35.21.6 = getelementptr i8, i8* %a, i64 28
  %4495 = load i8, i8* %scevgep35.21.6, align 1
  %4496 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.6 = call zeroext i8 @mult(i8 zeroext %4495, i8 zeroext %4496)
  %conv35.21.6 = zext i8 %call34.21.6 to i32
  %xor36.21.6 = xor i32 %xor.21.6, %conv35.21.6
  %conv37.21.6 = trunc i32 %xor36.21.6 to i8
  store i8 %conv37.21.6, i8* %scevgep41.21.5, align 1
  %scevgep28.21.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4490, i64 0, i64 0, i64 1
  %4497 = bitcast i8* %scevgep28.21.6 to [41 x [41 x i8]]*
  %scevgep41.21.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4491, i64 0, i64 1, i64 0
  %4498 = bitcast i8* %scevgep41.21.6 to [41 x [41 x i8]]*
  %call16.21.7 = call zeroext i8 (...) @rand()
  store i8 %call16.21.7, i8* %scevgep28.21.6, align 1
  %4499 = load i8, i8* %scevgep28.21.6, align 1
  %conv23.21.7 = zext i8 %4499 to i32
  %4500 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.7 = getelementptr i8, i8* %b, i64 29
  %4501 = load i8, i8* %scevgep34.21.7, align 1
  %call28.21.7 = call zeroext i8 @mult(i8 zeroext %4500, i8 zeroext %4501)
  %conv29.21.7 = zext i8 %call28.21.7 to i32
  %xor.21.7 = xor i32 %conv23.21.7, %conv29.21.7
  %scevgep35.21.7 = getelementptr i8, i8* %a, i64 29
  %4502 = load i8, i8* %scevgep35.21.7, align 1
  %4503 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.7 = call zeroext i8 @mult(i8 zeroext %4502, i8 zeroext %4503)
  %conv35.21.7 = zext i8 %call34.21.7 to i32
  %xor36.21.7 = xor i32 %xor.21.7, %conv35.21.7
  %conv37.21.7 = trunc i32 %xor36.21.7 to i8
  store i8 %conv37.21.7, i8* %scevgep41.21.6, align 1
  %scevgep28.21.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4497, i64 0, i64 0, i64 1
  %4504 = bitcast i8* %scevgep28.21.7 to [41 x [41 x i8]]*
  %scevgep41.21.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4498, i64 0, i64 1, i64 0
  %4505 = bitcast i8* %scevgep41.21.7 to [41 x [41 x i8]]*
  %call16.21.8 = call zeroext i8 (...) @rand()
  store i8 %call16.21.8, i8* %scevgep28.21.7, align 1
  %4506 = load i8, i8* %scevgep28.21.7, align 1
  %conv23.21.8 = zext i8 %4506 to i32
  %4507 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.8 = getelementptr i8, i8* %b, i64 30
  %4508 = load i8, i8* %scevgep34.21.8, align 1
  %call28.21.8 = call zeroext i8 @mult(i8 zeroext %4507, i8 zeroext %4508)
  %conv29.21.8 = zext i8 %call28.21.8 to i32
  %xor.21.8 = xor i32 %conv23.21.8, %conv29.21.8
  %scevgep35.21.8 = getelementptr i8, i8* %a, i64 30
  %4509 = load i8, i8* %scevgep35.21.8, align 1
  %4510 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.8 = call zeroext i8 @mult(i8 zeroext %4509, i8 zeroext %4510)
  %conv35.21.8 = zext i8 %call34.21.8 to i32
  %xor36.21.8 = xor i32 %xor.21.8, %conv35.21.8
  %conv37.21.8 = trunc i32 %xor36.21.8 to i8
  store i8 %conv37.21.8, i8* %scevgep41.21.7, align 1
  %scevgep28.21.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4504, i64 0, i64 0, i64 1
  %4511 = bitcast i8* %scevgep28.21.8 to [41 x [41 x i8]]*
  %scevgep41.21.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4505, i64 0, i64 1, i64 0
  %4512 = bitcast i8* %scevgep41.21.8 to [41 x [41 x i8]]*
  %call16.21.9 = call zeroext i8 (...) @rand()
  store i8 %call16.21.9, i8* %scevgep28.21.8, align 1
  %4513 = load i8, i8* %scevgep28.21.8, align 1
  %conv23.21.9 = zext i8 %4513 to i32
  %4514 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.9 = getelementptr i8, i8* %b, i64 31
  %4515 = load i8, i8* %scevgep34.21.9, align 1
  %call28.21.9 = call zeroext i8 @mult(i8 zeroext %4514, i8 zeroext %4515)
  %conv29.21.9 = zext i8 %call28.21.9 to i32
  %xor.21.9 = xor i32 %conv23.21.9, %conv29.21.9
  %scevgep35.21.9 = getelementptr i8, i8* %a, i64 31
  %4516 = load i8, i8* %scevgep35.21.9, align 1
  %4517 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.9 = call zeroext i8 @mult(i8 zeroext %4516, i8 zeroext %4517)
  %conv35.21.9 = zext i8 %call34.21.9 to i32
  %xor36.21.9 = xor i32 %xor.21.9, %conv35.21.9
  %conv37.21.9 = trunc i32 %xor36.21.9 to i8
  store i8 %conv37.21.9, i8* %scevgep41.21.8, align 1
  %scevgep28.21.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4511, i64 0, i64 0, i64 1
  %4518 = bitcast i8* %scevgep28.21.9 to [41 x [41 x i8]]*
  %scevgep41.21.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4512, i64 0, i64 1, i64 0
  %4519 = bitcast i8* %scevgep41.21.9 to [41 x [41 x i8]]*
  %call16.21.10 = call zeroext i8 (...) @rand()
  store i8 %call16.21.10, i8* %scevgep28.21.9, align 1
  %4520 = load i8, i8* %scevgep28.21.9, align 1
  %conv23.21.10 = zext i8 %4520 to i32
  %4521 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.10 = getelementptr i8, i8* %b, i64 32
  %4522 = load i8, i8* %scevgep34.21.10, align 1
  %call28.21.10 = call zeroext i8 @mult(i8 zeroext %4521, i8 zeroext %4522)
  %conv29.21.10 = zext i8 %call28.21.10 to i32
  %xor.21.10 = xor i32 %conv23.21.10, %conv29.21.10
  %scevgep35.21.10 = getelementptr i8, i8* %a, i64 32
  %4523 = load i8, i8* %scevgep35.21.10, align 1
  %4524 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.10 = call zeroext i8 @mult(i8 zeroext %4523, i8 zeroext %4524)
  %conv35.21.10 = zext i8 %call34.21.10 to i32
  %xor36.21.10 = xor i32 %xor.21.10, %conv35.21.10
  %conv37.21.10 = trunc i32 %xor36.21.10 to i8
  store i8 %conv37.21.10, i8* %scevgep41.21.9, align 1
  %scevgep28.21.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4518, i64 0, i64 0, i64 1
  %4525 = bitcast i8* %scevgep28.21.10 to [41 x [41 x i8]]*
  %scevgep41.21.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4519, i64 0, i64 1, i64 0
  %4526 = bitcast i8* %scevgep41.21.10 to [41 x [41 x i8]]*
  %call16.21.11 = call zeroext i8 (...) @rand()
  store i8 %call16.21.11, i8* %scevgep28.21.10, align 1
  %4527 = load i8, i8* %scevgep28.21.10, align 1
  %conv23.21.11 = zext i8 %4527 to i32
  %4528 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.11 = getelementptr i8, i8* %b, i64 33
  %4529 = load i8, i8* %scevgep34.21.11, align 1
  %call28.21.11 = call zeroext i8 @mult(i8 zeroext %4528, i8 zeroext %4529)
  %conv29.21.11 = zext i8 %call28.21.11 to i32
  %xor.21.11 = xor i32 %conv23.21.11, %conv29.21.11
  %scevgep35.21.11 = getelementptr i8, i8* %a, i64 33
  %4530 = load i8, i8* %scevgep35.21.11, align 1
  %4531 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.11 = call zeroext i8 @mult(i8 zeroext %4530, i8 zeroext %4531)
  %conv35.21.11 = zext i8 %call34.21.11 to i32
  %xor36.21.11 = xor i32 %xor.21.11, %conv35.21.11
  %conv37.21.11 = trunc i32 %xor36.21.11 to i8
  store i8 %conv37.21.11, i8* %scevgep41.21.10, align 1
  %scevgep28.21.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4525, i64 0, i64 0, i64 1
  %4532 = bitcast i8* %scevgep28.21.11 to [41 x [41 x i8]]*
  %scevgep41.21.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4526, i64 0, i64 1, i64 0
  %4533 = bitcast i8* %scevgep41.21.11 to [41 x [41 x i8]]*
  %call16.21.12 = call zeroext i8 (...) @rand()
  store i8 %call16.21.12, i8* %scevgep28.21.11, align 1
  %4534 = load i8, i8* %scevgep28.21.11, align 1
  %conv23.21.12 = zext i8 %4534 to i32
  %4535 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.12 = getelementptr i8, i8* %b, i64 34
  %4536 = load i8, i8* %scevgep34.21.12, align 1
  %call28.21.12 = call zeroext i8 @mult(i8 zeroext %4535, i8 zeroext %4536)
  %conv29.21.12 = zext i8 %call28.21.12 to i32
  %xor.21.12 = xor i32 %conv23.21.12, %conv29.21.12
  %scevgep35.21.12 = getelementptr i8, i8* %a, i64 34
  %4537 = load i8, i8* %scevgep35.21.12, align 1
  %4538 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.12 = call zeroext i8 @mult(i8 zeroext %4537, i8 zeroext %4538)
  %conv35.21.12 = zext i8 %call34.21.12 to i32
  %xor36.21.12 = xor i32 %xor.21.12, %conv35.21.12
  %conv37.21.12 = trunc i32 %xor36.21.12 to i8
  store i8 %conv37.21.12, i8* %scevgep41.21.11, align 1
  %scevgep28.21.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4532, i64 0, i64 0, i64 1
  %4539 = bitcast i8* %scevgep28.21.12 to [41 x [41 x i8]]*
  %scevgep41.21.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4533, i64 0, i64 1, i64 0
  %4540 = bitcast i8* %scevgep41.21.12 to [41 x [41 x i8]]*
  %call16.21.13 = call zeroext i8 (...) @rand()
  store i8 %call16.21.13, i8* %scevgep28.21.12, align 1
  %4541 = load i8, i8* %scevgep28.21.12, align 1
  %conv23.21.13 = zext i8 %4541 to i32
  %4542 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.13 = getelementptr i8, i8* %b, i64 35
  %4543 = load i8, i8* %scevgep34.21.13, align 1
  %call28.21.13 = call zeroext i8 @mult(i8 zeroext %4542, i8 zeroext %4543)
  %conv29.21.13 = zext i8 %call28.21.13 to i32
  %xor.21.13 = xor i32 %conv23.21.13, %conv29.21.13
  %scevgep35.21.13 = getelementptr i8, i8* %a, i64 35
  %4544 = load i8, i8* %scevgep35.21.13, align 1
  %4545 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.13 = call zeroext i8 @mult(i8 zeroext %4544, i8 zeroext %4545)
  %conv35.21.13 = zext i8 %call34.21.13 to i32
  %xor36.21.13 = xor i32 %xor.21.13, %conv35.21.13
  %conv37.21.13 = trunc i32 %xor36.21.13 to i8
  store i8 %conv37.21.13, i8* %scevgep41.21.12, align 1
  %scevgep28.21.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4539, i64 0, i64 0, i64 1
  %4546 = bitcast i8* %scevgep28.21.13 to [41 x [41 x i8]]*
  %scevgep41.21.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4540, i64 0, i64 1, i64 0
  %4547 = bitcast i8* %scevgep41.21.13 to [41 x [41 x i8]]*
  %call16.21.14 = call zeroext i8 (...) @rand()
  store i8 %call16.21.14, i8* %scevgep28.21.13, align 1
  %4548 = load i8, i8* %scevgep28.21.13, align 1
  %conv23.21.14 = zext i8 %4548 to i32
  %4549 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.14 = getelementptr i8, i8* %b, i64 36
  %4550 = load i8, i8* %scevgep34.21.14, align 1
  %call28.21.14 = call zeroext i8 @mult(i8 zeroext %4549, i8 zeroext %4550)
  %conv29.21.14 = zext i8 %call28.21.14 to i32
  %xor.21.14 = xor i32 %conv23.21.14, %conv29.21.14
  %scevgep35.21.14 = getelementptr i8, i8* %a, i64 36
  %4551 = load i8, i8* %scevgep35.21.14, align 1
  %4552 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.14 = call zeroext i8 @mult(i8 zeroext %4551, i8 zeroext %4552)
  %conv35.21.14 = zext i8 %call34.21.14 to i32
  %xor36.21.14 = xor i32 %xor.21.14, %conv35.21.14
  %conv37.21.14 = trunc i32 %xor36.21.14 to i8
  store i8 %conv37.21.14, i8* %scevgep41.21.13, align 1
  %scevgep28.21.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4546, i64 0, i64 0, i64 1
  %4553 = bitcast i8* %scevgep28.21.14 to [41 x [41 x i8]]*
  %scevgep41.21.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4547, i64 0, i64 1, i64 0
  %4554 = bitcast i8* %scevgep41.21.14 to [41 x [41 x i8]]*
  %call16.21.15 = call zeroext i8 (...) @rand()
  store i8 %call16.21.15, i8* %scevgep28.21.14, align 1
  %4555 = load i8, i8* %scevgep28.21.14, align 1
  %conv23.21.15 = zext i8 %4555 to i32
  %4556 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.15 = getelementptr i8, i8* %b, i64 37
  %4557 = load i8, i8* %scevgep34.21.15, align 1
  %call28.21.15 = call zeroext i8 @mult(i8 zeroext %4556, i8 zeroext %4557)
  %conv29.21.15 = zext i8 %call28.21.15 to i32
  %xor.21.15 = xor i32 %conv23.21.15, %conv29.21.15
  %scevgep35.21.15 = getelementptr i8, i8* %a, i64 37
  %4558 = load i8, i8* %scevgep35.21.15, align 1
  %4559 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.15 = call zeroext i8 @mult(i8 zeroext %4558, i8 zeroext %4559)
  %conv35.21.15 = zext i8 %call34.21.15 to i32
  %xor36.21.15 = xor i32 %xor.21.15, %conv35.21.15
  %conv37.21.15 = trunc i32 %xor36.21.15 to i8
  store i8 %conv37.21.15, i8* %scevgep41.21.14, align 1
  %scevgep28.21.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4553, i64 0, i64 0, i64 1
  %4560 = bitcast i8* %scevgep28.21.15 to [41 x [41 x i8]]*
  %scevgep41.21.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4554, i64 0, i64 1, i64 0
  %4561 = bitcast i8* %scevgep41.21.15 to [41 x [41 x i8]]*
  %call16.21.16 = call zeroext i8 (...) @rand()
  store i8 %call16.21.16, i8* %scevgep28.21.15, align 1
  %4562 = load i8, i8* %scevgep28.21.15, align 1
  %conv23.21.16 = zext i8 %4562 to i32
  %4563 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.16 = getelementptr i8, i8* %b, i64 38
  %4564 = load i8, i8* %scevgep34.21.16, align 1
  %call28.21.16 = call zeroext i8 @mult(i8 zeroext %4563, i8 zeroext %4564)
  %conv29.21.16 = zext i8 %call28.21.16 to i32
  %xor.21.16 = xor i32 %conv23.21.16, %conv29.21.16
  %scevgep35.21.16 = getelementptr i8, i8* %a, i64 38
  %4565 = load i8, i8* %scevgep35.21.16, align 1
  %4566 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.16 = call zeroext i8 @mult(i8 zeroext %4565, i8 zeroext %4566)
  %conv35.21.16 = zext i8 %call34.21.16 to i32
  %xor36.21.16 = xor i32 %xor.21.16, %conv35.21.16
  %conv37.21.16 = trunc i32 %xor36.21.16 to i8
  store i8 %conv37.21.16, i8* %scevgep41.21.15, align 1
  %scevgep28.21.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4560, i64 0, i64 0, i64 1
  %4567 = bitcast i8* %scevgep28.21.16 to [41 x [41 x i8]]*
  %scevgep41.21.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4561, i64 0, i64 1, i64 0
  %4568 = bitcast i8* %scevgep41.21.16 to [41 x [41 x i8]]*
  %call16.21.17 = call zeroext i8 (...) @rand()
  store i8 %call16.21.17, i8* %scevgep28.21.16, align 1
  %4569 = load i8, i8* %scevgep28.21.16, align 1
  %conv23.21.17 = zext i8 %4569 to i32
  %4570 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.17 = getelementptr i8, i8* %b, i64 39
  %4571 = load i8, i8* %scevgep34.21.17, align 1
  %call28.21.17 = call zeroext i8 @mult(i8 zeroext %4570, i8 zeroext %4571)
  %conv29.21.17 = zext i8 %call28.21.17 to i32
  %xor.21.17 = xor i32 %conv23.21.17, %conv29.21.17
  %scevgep35.21.17 = getelementptr i8, i8* %a, i64 39
  %4572 = load i8, i8* %scevgep35.21.17, align 1
  %4573 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.17 = call zeroext i8 @mult(i8 zeroext %4572, i8 zeroext %4573)
  %conv35.21.17 = zext i8 %call34.21.17 to i32
  %xor36.21.17 = xor i32 %xor.21.17, %conv35.21.17
  %conv37.21.17 = trunc i32 %xor36.21.17 to i8
  store i8 %conv37.21.17, i8* %scevgep41.21.16, align 1
  %scevgep28.21.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4567, i64 0, i64 0, i64 1
  %scevgep41.21.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4568, i64 0, i64 1, i64 0
  %call16.21.18 = call zeroext i8 (...) @rand()
  store i8 %call16.21.18, i8* %scevgep28.21.17, align 1
  %4574 = load i8, i8* %scevgep28.21.17, align 1
  %conv23.21.18 = zext i8 %4574 to i32
  %4575 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.18 = getelementptr i8, i8* %b, i64 40
  %4576 = load i8, i8* %scevgep34.21.18, align 1
  %call28.21.18 = call zeroext i8 @mult(i8 zeroext %4575, i8 zeroext %4576)
  %conv29.21.18 = zext i8 %call28.21.18 to i32
  %xor.21.18 = xor i32 %conv23.21.18, %conv29.21.18
  %scevgep35.21.18 = getelementptr i8, i8* %a, i64 40
  %4577 = load i8, i8* %scevgep35.21.18, align 1
  %4578 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.18 = call zeroext i8 @mult(i8 zeroext %4577, i8 zeroext %4578)
  %conv35.21.18 = zext i8 %call34.21.18 to i32
  %xor36.21.18 = xor i32 %xor.21.18, %conv35.21.18
  %conv37.21.18 = trunc i32 %xor36.21.18 to i8
  store i8 %conv37.21.18, i8* %scevgep41.21.17, align 1
  %scevgep26.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4448, i64 0, i64 1, i64 1
  %4579 = bitcast i8* %scevgep26.21 to [41 x [41 x i8]]*
  %scevgep39.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4449, i64 0, i64 1, i64 1
  %4580 = bitcast i8* %scevgep39.21 to [41 x [41 x i8]]*
  %arrayidx25.22 = getelementptr inbounds i8, i8* %a, i64 22
  %arrayidx33.22 = getelementptr inbounds i8, i8* %b, i64 22
  %call16.22 = call zeroext i8 (...) @rand()
  store i8 %call16.22, i8* %scevgep26.21, align 1
  %4581 = load i8, i8* %scevgep26.21, align 1
  %conv23.22 = zext i8 %4581 to i32
  %4582 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22 = getelementptr i8, i8* %b, i64 23
  %4583 = load i8, i8* %scevgep34.22, align 1
  %call28.22 = call zeroext i8 @mult(i8 zeroext %4582, i8 zeroext %4583)
  %conv29.22 = zext i8 %call28.22 to i32
  %xor.22 = xor i32 %conv23.22, %conv29.22
  %scevgep35.22 = getelementptr i8, i8* %a, i64 23
  %4584 = load i8, i8* %scevgep35.22, align 1
  %4585 = load i8, i8* %arrayidx33.22, align 1
  %call34.22 = call zeroext i8 @mult(i8 zeroext %4584, i8 zeroext %4585)
  %conv35.22 = zext i8 %call34.22 to i32
  %xor36.22 = xor i32 %xor.22, %conv35.22
  %conv37.22 = trunc i32 %xor36.22 to i8
  store i8 %conv37.22, i8* %scevgep39.21, align 1
  %scevgep28.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4579, i64 0, i64 0, i64 1
  %4586 = bitcast i8* %scevgep28.22 to [41 x [41 x i8]]*
  %scevgep41.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4580, i64 0, i64 1, i64 0
  %4587 = bitcast i8* %scevgep41.22 to [41 x [41 x i8]]*
  %call16.22.1 = call zeroext i8 (...) @rand()
  store i8 %call16.22.1, i8* %scevgep28.22, align 1
  %4588 = load i8, i8* %scevgep28.22, align 1
  %conv23.22.1 = zext i8 %4588 to i32
  %4589 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.1 = getelementptr i8, i8* %b, i64 24
  %4590 = load i8, i8* %scevgep34.22.1, align 1
  %call28.22.1 = call zeroext i8 @mult(i8 zeroext %4589, i8 zeroext %4590)
  %conv29.22.1 = zext i8 %call28.22.1 to i32
  %xor.22.1 = xor i32 %conv23.22.1, %conv29.22.1
  %scevgep35.22.1 = getelementptr i8, i8* %a, i64 24
  %4591 = load i8, i8* %scevgep35.22.1, align 1
  %4592 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.1 = call zeroext i8 @mult(i8 zeroext %4591, i8 zeroext %4592)
  %conv35.22.1 = zext i8 %call34.22.1 to i32
  %xor36.22.1 = xor i32 %xor.22.1, %conv35.22.1
  %conv37.22.1 = trunc i32 %xor36.22.1 to i8
  store i8 %conv37.22.1, i8* %scevgep41.22, align 1
  %scevgep28.22.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4586, i64 0, i64 0, i64 1
  %4593 = bitcast i8* %scevgep28.22.1 to [41 x [41 x i8]]*
  %scevgep41.22.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4587, i64 0, i64 1, i64 0
  %4594 = bitcast i8* %scevgep41.22.1 to [41 x [41 x i8]]*
  %call16.22.2 = call zeroext i8 (...) @rand()
  store i8 %call16.22.2, i8* %scevgep28.22.1, align 1
  %4595 = load i8, i8* %scevgep28.22.1, align 1
  %conv23.22.2 = zext i8 %4595 to i32
  %4596 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.2 = getelementptr i8, i8* %b, i64 25
  %4597 = load i8, i8* %scevgep34.22.2, align 1
  %call28.22.2 = call zeroext i8 @mult(i8 zeroext %4596, i8 zeroext %4597)
  %conv29.22.2 = zext i8 %call28.22.2 to i32
  %xor.22.2 = xor i32 %conv23.22.2, %conv29.22.2
  %scevgep35.22.2 = getelementptr i8, i8* %a, i64 25
  %4598 = load i8, i8* %scevgep35.22.2, align 1
  %4599 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.2 = call zeroext i8 @mult(i8 zeroext %4598, i8 zeroext %4599)
  %conv35.22.2 = zext i8 %call34.22.2 to i32
  %xor36.22.2 = xor i32 %xor.22.2, %conv35.22.2
  %conv37.22.2 = trunc i32 %xor36.22.2 to i8
  store i8 %conv37.22.2, i8* %scevgep41.22.1, align 1
  %scevgep28.22.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4593, i64 0, i64 0, i64 1
  %4600 = bitcast i8* %scevgep28.22.2 to [41 x [41 x i8]]*
  %scevgep41.22.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4594, i64 0, i64 1, i64 0
  %4601 = bitcast i8* %scevgep41.22.2 to [41 x [41 x i8]]*
  %call16.22.3 = call zeroext i8 (...) @rand()
  store i8 %call16.22.3, i8* %scevgep28.22.2, align 1
  %4602 = load i8, i8* %scevgep28.22.2, align 1
  %conv23.22.3 = zext i8 %4602 to i32
  %4603 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.3 = getelementptr i8, i8* %b, i64 26
  %4604 = load i8, i8* %scevgep34.22.3, align 1
  %call28.22.3 = call zeroext i8 @mult(i8 zeroext %4603, i8 zeroext %4604)
  %conv29.22.3 = zext i8 %call28.22.3 to i32
  %xor.22.3 = xor i32 %conv23.22.3, %conv29.22.3
  %scevgep35.22.3 = getelementptr i8, i8* %a, i64 26
  %4605 = load i8, i8* %scevgep35.22.3, align 1
  %4606 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.3 = call zeroext i8 @mult(i8 zeroext %4605, i8 zeroext %4606)
  %conv35.22.3 = zext i8 %call34.22.3 to i32
  %xor36.22.3 = xor i32 %xor.22.3, %conv35.22.3
  %conv37.22.3 = trunc i32 %xor36.22.3 to i8
  store i8 %conv37.22.3, i8* %scevgep41.22.2, align 1
  %scevgep28.22.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4600, i64 0, i64 0, i64 1
  %4607 = bitcast i8* %scevgep28.22.3 to [41 x [41 x i8]]*
  %scevgep41.22.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4601, i64 0, i64 1, i64 0
  %4608 = bitcast i8* %scevgep41.22.3 to [41 x [41 x i8]]*
  %call16.22.4 = call zeroext i8 (...) @rand()
  store i8 %call16.22.4, i8* %scevgep28.22.3, align 1
  %4609 = load i8, i8* %scevgep28.22.3, align 1
  %conv23.22.4 = zext i8 %4609 to i32
  %4610 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.4 = getelementptr i8, i8* %b, i64 27
  %4611 = load i8, i8* %scevgep34.22.4, align 1
  %call28.22.4 = call zeroext i8 @mult(i8 zeroext %4610, i8 zeroext %4611)
  %conv29.22.4 = zext i8 %call28.22.4 to i32
  %xor.22.4 = xor i32 %conv23.22.4, %conv29.22.4
  %scevgep35.22.4 = getelementptr i8, i8* %a, i64 27
  %4612 = load i8, i8* %scevgep35.22.4, align 1
  %4613 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.4 = call zeroext i8 @mult(i8 zeroext %4612, i8 zeroext %4613)
  %conv35.22.4 = zext i8 %call34.22.4 to i32
  %xor36.22.4 = xor i32 %xor.22.4, %conv35.22.4
  %conv37.22.4 = trunc i32 %xor36.22.4 to i8
  store i8 %conv37.22.4, i8* %scevgep41.22.3, align 1
  %scevgep28.22.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4607, i64 0, i64 0, i64 1
  %4614 = bitcast i8* %scevgep28.22.4 to [41 x [41 x i8]]*
  %scevgep41.22.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4608, i64 0, i64 1, i64 0
  %4615 = bitcast i8* %scevgep41.22.4 to [41 x [41 x i8]]*
  %call16.22.5 = call zeroext i8 (...) @rand()
  store i8 %call16.22.5, i8* %scevgep28.22.4, align 1
  %4616 = load i8, i8* %scevgep28.22.4, align 1
  %conv23.22.5 = zext i8 %4616 to i32
  %4617 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.5 = getelementptr i8, i8* %b, i64 28
  %4618 = load i8, i8* %scevgep34.22.5, align 1
  %call28.22.5 = call zeroext i8 @mult(i8 zeroext %4617, i8 zeroext %4618)
  %conv29.22.5 = zext i8 %call28.22.5 to i32
  %xor.22.5 = xor i32 %conv23.22.5, %conv29.22.5
  %scevgep35.22.5 = getelementptr i8, i8* %a, i64 28
  %4619 = load i8, i8* %scevgep35.22.5, align 1
  %4620 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.5 = call zeroext i8 @mult(i8 zeroext %4619, i8 zeroext %4620)
  %conv35.22.5 = zext i8 %call34.22.5 to i32
  %xor36.22.5 = xor i32 %xor.22.5, %conv35.22.5
  %conv37.22.5 = trunc i32 %xor36.22.5 to i8
  store i8 %conv37.22.5, i8* %scevgep41.22.4, align 1
  %scevgep28.22.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4614, i64 0, i64 0, i64 1
  %4621 = bitcast i8* %scevgep28.22.5 to [41 x [41 x i8]]*
  %scevgep41.22.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4615, i64 0, i64 1, i64 0
  %4622 = bitcast i8* %scevgep41.22.5 to [41 x [41 x i8]]*
  %call16.22.6 = call zeroext i8 (...) @rand()
  store i8 %call16.22.6, i8* %scevgep28.22.5, align 1
  %4623 = load i8, i8* %scevgep28.22.5, align 1
  %conv23.22.6 = zext i8 %4623 to i32
  %4624 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.6 = getelementptr i8, i8* %b, i64 29
  %4625 = load i8, i8* %scevgep34.22.6, align 1
  %call28.22.6 = call zeroext i8 @mult(i8 zeroext %4624, i8 zeroext %4625)
  %conv29.22.6 = zext i8 %call28.22.6 to i32
  %xor.22.6 = xor i32 %conv23.22.6, %conv29.22.6
  %scevgep35.22.6 = getelementptr i8, i8* %a, i64 29
  %4626 = load i8, i8* %scevgep35.22.6, align 1
  %4627 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.6 = call zeroext i8 @mult(i8 zeroext %4626, i8 zeroext %4627)
  %conv35.22.6 = zext i8 %call34.22.6 to i32
  %xor36.22.6 = xor i32 %xor.22.6, %conv35.22.6
  %conv37.22.6 = trunc i32 %xor36.22.6 to i8
  store i8 %conv37.22.6, i8* %scevgep41.22.5, align 1
  %scevgep28.22.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4621, i64 0, i64 0, i64 1
  %4628 = bitcast i8* %scevgep28.22.6 to [41 x [41 x i8]]*
  %scevgep41.22.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4622, i64 0, i64 1, i64 0
  %4629 = bitcast i8* %scevgep41.22.6 to [41 x [41 x i8]]*
  %call16.22.7 = call zeroext i8 (...) @rand()
  store i8 %call16.22.7, i8* %scevgep28.22.6, align 1
  %4630 = load i8, i8* %scevgep28.22.6, align 1
  %conv23.22.7 = zext i8 %4630 to i32
  %4631 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.7 = getelementptr i8, i8* %b, i64 30
  %4632 = load i8, i8* %scevgep34.22.7, align 1
  %call28.22.7 = call zeroext i8 @mult(i8 zeroext %4631, i8 zeroext %4632)
  %conv29.22.7 = zext i8 %call28.22.7 to i32
  %xor.22.7 = xor i32 %conv23.22.7, %conv29.22.7
  %scevgep35.22.7 = getelementptr i8, i8* %a, i64 30
  %4633 = load i8, i8* %scevgep35.22.7, align 1
  %4634 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.7 = call zeroext i8 @mult(i8 zeroext %4633, i8 zeroext %4634)
  %conv35.22.7 = zext i8 %call34.22.7 to i32
  %xor36.22.7 = xor i32 %xor.22.7, %conv35.22.7
  %conv37.22.7 = trunc i32 %xor36.22.7 to i8
  store i8 %conv37.22.7, i8* %scevgep41.22.6, align 1
  %scevgep28.22.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4628, i64 0, i64 0, i64 1
  %4635 = bitcast i8* %scevgep28.22.7 to [41 x [41 x i8]]*
  %scevgep41.22.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4629, i64 0, i64 1, i64 0
  %4636 = bitcast i8* %scevgep41.22.7 to [41 x [41 x i8]]*
  %call16.22.8 = call zeroext i8 (...) @rand()
  store i8 %call16.22.8, i8* %scevgep28.22.7, align 1
  %4637 = load i8, i8* %scevgep28.22.7, align 1
  %conv23.22.8 = zext i8 %4637 to i32
  %4638 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.8 = getelementptr i8, i8* %b, i64 31
  %4639 = load i8, i8* %scevgep34.22.8, align 1
  %call28.22.8 = call zeroext i8 @mult(i8 zeroext %4638, i8 zeroext %4639)
  %conv29.22.8 = zext i8 %call28.22.8 to i32
  %xor.22.8 = xor i32 %conv23.22.8, %conv29.22.8
  %scevgep35.22.8 = getelementptr i8, i8* %a, i64 31
  %4640 = load i8, i8* %scevgep35.22.8, align 1
  %4641 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.8 = call zeroext i8 @mult(i8 zeroext %4640, i8 zeroext %4641)
  %conv35.22.8 = zext i8 %call34.22.8 to i32
  %xor36.22.8 = xor i32 %xor.22.8, %conv35.22.8
  %conv37.22.8 = trunc i32 %xor36.22.8 to i8
  store i8 %conv37.22.8, i8* %scevgep41.22.7, align 1
  %scevgep28.22.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4635, i64 0, i64 0, i64 1
  %4642 = bitcast i8* %scevgep28.22.8 to [41 x [41 x i8]]*
  %scevgep41.22.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4636, i64 0, i64 1, i64 0
  %4643 = bitcast i8* %scevgep41.22.8 to [41 x [41 x i8]]*
  %call16.22.9 = call zeroext i8 (...) @rand()
  store i8 %call16.22.9, i8* %scevgep28.22.8, align 1
  %4644 = load i8, i8* %scevgep28.22.8, align 1
  %conv23.22.9 = zext i8 %4644 to i32
  %4645 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.9 = getelementptr i8, i8* %b, i64 32
  %4646 = load i8, i8* %scevgep34.22.9, align 1
  %call28.22.9 = call zeroext i8 @mult(i8 zeroext %4645, i8 zeroext %4646)
  %conv29.22.9 = zext i8 %call28.22.9 to i32
  %xor.22.9 = xor i32 %conv23.22.9, %conv29.22.9
  %scevgep35.22.9 = getelementptr i8, i8* %a, i64 32
  %4647 = load i8, i8* %scevgep35.22.9, align 1
  %4648 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.9 = call zeroext i8 @mult(i8 zeroext %4647, i8 zeroext %4648)
  %conv35.22.9 = zext i8 %call34.22.9 to i32
  %xor36.22.9 = xor i32 %xor.22.9, %conv35.22.9
  %conv37.22.9 = trunc i32 %xor36.22.9 to i8
  store i8 %conv37.22.9, i8* %scevgep41.22.8, align 1
  %scevgep28.22.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4642, i64 0, i64 0, i64 1
  %4649 = bitcast i8* %scevgep28.22.9 to [41 x [41 x i8]]*
  %scevgep41.22.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4643, i64 0, i64 1, i64 0
  %4650 = bitcast i8* %scevgep41.22.9 to [41 x [41 x i8]]*
  %call16.22.10 = call zeroext i8 (...) @rand()
  store i8 %call16.22.10, i8* %scevgep28.22.9, align 1
  %4651 = load i8, i8* %scevgep28.22.9, align 1
  %conv23.22.10 = zext i8 %4651 to i32
  %4652 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.10 = getelementptr i8, i8* %b, i64 33
  %4653 = load i8, i8* %scevgep34.22.10, align 1
  %call28.22.10 = call zeroext i8 @mult(i8 zeroext %4652, i8 zeroext %4653)
  %conv29.22.10 = zext i8 %call28.22.10 to i32
  %xor.22.10 = xor i32 %conv23.22.10, %conv29.22.10
  %scevgep35.22.10 = getelementptr i8, i8* %a, i64 33
  %4654 = load i8, i8* %scevgep35.22.10, align 1
  %4655 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.10 = call zeroext i8 @mult(i8 zeroext %4654, i8 zeroext %4655)
  %conv35.22.10 = zext i8 %call34.22.10 to i32
  %xor36.22.10 = xor i32 %xor.22.10, %conv35.22.10
  %conv37.22.10 = trunc i32 %xor36.22.10 to i8
  store i8 %conv37.22.10, i8* %scevgep41.22.9, align 1
  %scevgep28.22.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4649, i64 0, i64 0, i64 1
  %4656 = bitcast i8* %scevgep28.22.10 to [41 x [41 x i8]]*
  %scevgep41.22.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4650, i64 0, i64 1, i64 0
  %4657 = bitcast i8* %scevgep41.22.10 to [41 x [41 x i8]]*
  %call16.22.11 = call zeroext i8 (...) @rand()
  store i8 %call16.22.11, i8* %scevgep28.22.10, align 1
  %4658 = load i8, i8* %scevgep28.22.10, align 1
  %conv23.22.11 = zext i8 %4658 to i32
  %4659 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.11 = getelementptr i8, i8* %b, i64 34
  %4660 = load i8, i8* %scevgep34.22.11, align 1
  %call28.22.11 = call zeroext i8 @mult(i8 zeroext %4659, i8 zeroext %4660)
  %conv29.22.11 = zext i8 %call28.22.11 to i32
  %xor.22.11 = xor i32 %conv23.22.11, %conv29.22.11
  %scevgep35.22.11 = getelementptr i8, i8* %a, i64 34
  %4661 = load i8, i8* %scevgep35.22.11, align 1
  %4662 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.11 = call zeroext i8 @mult(i8 zeroext %4661, i8 zeroext %4662)
  %conv35.22.11 = zext i8 %call34.22.11 to i32
  %xor36.22.11 = xor i32 %xor.22.11, %conv35.22.11
  %conv37.22.11 = trunc i32 %xor36.22.11 to i8
  store i8 %conv37.22.11, i8* %scevgep41.22.10, align 1
  %scevgep28.22.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4656, i64 0, i64 0, i64 1
  %4663 = bitcast i8* %scevgep28.22.11 to [41 x [41 x i8]]*
  %scevgep41.22.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4657, i64 0, i64 1, i64 0
  %4664 = bitcast i8* %scevgep41.22.11 to [41 x [41 x i8]]*
  %call16.22.12 = call zeroext i8 (...) @rand()
  store i8 %call16.22.12, i8* %scevgep28.22.11, align 1
  %4665 = load i8, i8* %scevgep28.22.11, align 1
  %conv23.22.12 = zext i8 %4665 to i32
  %4666 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.12 = getelementptr i8, i8* %b, i64 35
  %4667 = load i8, i8* %scevgep34.22.12, align 1
  %call28.22.12 = call zeroext i8 @mult(i8 zeroext %4666, i8 zeroext %4667)
  %conv29.22.12 = zext i8 %call28.22.12 to i32
  %xor.22.12 = xor i32 %conv23.22.12, %conv29.22.12
  %scevgep35.22.12 = getelementptr i8, i8* %a, i64 35
  %4668 = load i8, i8* %scevgep35.22.12, align 1
  %4669 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.12 = call zeroext i8 @mult(i8 zeroext %4668, i8 zeroext %4669)
  %conv35.22.12 = zext i8 %call34.22.12 to i32
  %xor36.22.12 = xor i32 %xor.22.12, %conv35.22.12
  %conv37.22.12 = trunc i32 %xor36.22.12 to i8
  store i8 %conv37.22.12, i8* %scevgep41.22.11, align 1
  %scevgep28.22.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4663, i64 0, i64 0, i64 1
  %4670 = bitcast i8* %scevgep28.22.12 to [41 x [41 x i8]]*
  %scevgep41.22.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4664, i64 0, i64 1, i64 0
  %4671 = bitcast i8* %scevgep41.22.12 to [41 x [41 x i8]]*
  %call16.22.13 = call zeroext i8 (...) @rand()
  store i8 %call16.22.13, i8* %scevgep28.22.12, align 1
  %4672 = load i8, i8* %scevgep28.22.12, align 1
  %conv23.22.13 = zext i8 %4672 to i32
  %4673 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.13 = getelementptr i8, i8* %b, i64 36
  %4674 = load i8, i8* %scevgep34.22.13, align 1
  %call28.22.13 = call zeroext i8 @mult(i8 zeroext %4673, i8 zeroext %4674)
  %conv29.22.13 = zext i8 %call28.22.13 to i32
  %xor.22.13 = xor i32 %conv23.22.13, %conv29.22.13
  %scevgep35.22.13 = getelementptr i8, i8* %a, i64 36
  %4675 = load i8, i8* %scevgep35.22.13, align 1
  %4676 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.13 = call zeroext i8 @mult(i8 zeroext %4675, i8 zeroext %4676)
  %conv35.22.13 = zext i8 %call34.22.13 to i32
  %xor36.22.13 = xor i32 %xor.22.13, %conv35.22.13
  %conv37.22.13 = trunc i32 %xor36.22.13 to i8
  store i8 %conv37.22.13, i8* %scevgep41.22.12, align 1
  %scevgep28.22.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4670, i64 0, i64 0, i64 1
  %4677 = bitcast i8* %scevgep28.22.13 to [41 x [41 x i8]]*
  %scevgep41.22.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4671, i64 0, i64 1, i64 0
  %4678 = bitcast i8* %scevgep41.22.13 to [41 x [41 x i8]]*
  %call16.22.14 = call zeroext i8 (...) @rand()
  store i8 %call16.22.14, i8* %scevgep28.22.13, align 1
  %4679 = load i8, i8* %scevgep28.22.13, align 1
  %conv23.22.14 = zext i8 %4679 to i32
  %4680 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.14 = getelementptr i8, i8* %b, i64 37
  %4681 = load i8, i8* %scevgep34.22.14, align 1
  %call28.22.14 = call zeroext i8 @mult(i8 zeroext %4680, i8 zeroext %4681)
  %conv29.22.14 = zext i8 %call28.22.14 to i32
  %xor.22.14 = xor i32 %conv23.22.14, %conv29.22.14
  %scevgep35.22.14 = getelementptr i8, i8* %a, i64 37
  %4682 = load i8, i8* %scevgep35.22.14, align 1
  %4683 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.14 = call zeroext i8 @mult(i8 zeroext %4682, i8 zeroext %4683)
  %conv35.22.14 = zext i8 %call34.22.14 to i32
  %xor36.22.14 = xor i32 %xor.22.14, %conv35.22.14
  %conv37.22.14 = trunc i32 %xor36.22.14 to i8
  store i8 %conv37.22.14, i8* %scevgep41.22.13, align 1
  %scevgep28.22.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4677, i64 0, i64 0, i64 1
  %4684 = bitcast i8* %scevgep28.22.14 to [41 x [41 x i8]]*
  %scevgep41.22.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4678, i64 0, i64 1, i64 0
  %4685 = bitcast i8* %scevgep41.22.14 to [41 x [41 x i8]]*
  %call16.22.15 = call zeroext i8 (...) @rand()
  store i8 %call16.22.15, i8* %scevgep28.22.14, align 1
  %4686 = load i8, i8* %scevgep28.22.14, align 1
  %conv23.22.15 = zext i8 %4686 to i32
  %4687 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.15 = getelementptr i8, i8* %b, i64 38
  %4688 = load i8, i8* %scevgep34.22.15, align 1
  %call28.22.15 = call zeroext i8 @mult(i8 zeroext %4687, i8 zeroext %4688)
  %conv29.22.15 = zext i8 %call28.22.15 to i32
  %xor.22.15 = xor i32 %conv23.22.15, %conv29.22.15
  %scevgep35.22.15 = getelementptr i8, i8* %a, i64 38
  %4689 = load i8, i8* %scevgep35.22.15, align 1
  %4690 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.15 = call zeroext i8 @mult(i8 zeroext %4689, i8 zeroext %4690)
  %conv35.22.15 = zext i8 %call34.22.15 to i32
  %xor36.22.15 = xor i32 %xor.22.15, %conv35.22.15
  %conv37.22.15 = trunc i32 %xor36.22.15 to i8
  store i8 %conv37.22.15, i8* %scevgep41.22.14, align 1
  %scevgep28.22.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4684, i64 0, i64 0, i64 1
  %4691 = bitcast i8* %scevgep28.22.15 to [41 x [41 x i8]]*
  %scevgep41.22.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4685, i64 0, i64 1, i64 0
  %4692 = bitcast i8* %scevgep41.22.15 to [41 x [41 x i8]]*
  %call16.22.16 = call zeroext i8 (...) @rand()
  store i8 %call16.22.16, i8* %scevgep28.22.15, align 1
  %4693 = load i8, i8* %scevgep28.22.15, align 1
  %conv23.22.16 = zext i8 %4693 to i32
  %4694 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.16 = getelementptr i8, i8* %b, i64 39
  %4695 = load i8, i8* %scevgep34.22.16, align 1
  %call28.22.16 = call zeroext i8 @mult(i8 zeroext %4694, i8 zeroext %4695)
  %conv29.22.16 = zext i8 %call28.22.16 to i32
  %xor.22.16 = xor i32 %conv23.22.16, %conv29.22.16
  %scevgep35.22.16 = getelementptr i8, i8* %a, i64 39
  %4696 = load i8, i8* %scevgep35.22.16, align 1
  %4697 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.16 = call zeroext i8 @mult(i8 zeroext %4696, i8 zeroext %4697)
  %conv35.22.16 = zext i8 %call34.22.16 to i32
  %xor36.22.16 = xor i32 %xor.22.16, %conv35.22.16
  %conv37.22.16 = trunc i32 %xor36.22.16 to i8
  store i8 %conv37.22.16, i8* %scevgep41.22.15, align 1
  %scevgep28.22.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4691, i64 0, i64 0, i64 1
  %scevgep41.22.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4692, i64 0, i64 1, i64 0
  %call16.22.17 = call zeroext i8 (...) @rand()
  store i8 %call16.22.17, i8* %scevgep28.22.16, align 1
  %4698 = load i8, i8* %scevgep28.22.16, align 1
  %conv23.22.17 = zext i8 %4698 to i32
  %4699 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.17 = getelementptr i8, i8* %b, i64 40
  %4700 = load i8, i8* %scevgep34.22.17, align 1
  %call28.22.17 = call zeroext i8 @mult(i8 zeroext %4699, i8 zeroext %4700)
  %conv29.22.17 = zext i8 %call28.22.17 to i32
  %xor.22.17 = xor i32 %conv23.22.17, %conv29.22.17
  %scevgep35.22.17 = getelementptr i8, i8* %a, i64 40
  %4701 = load i8, i8* %scevgep35.22.17, align 1
  %4702 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.17 = call zeroext i8 @mult(i8 zeroext %4701, i8 zeroext %4702)
  %conv35.22.17 = zext i8 %call34.22.17 to i32
  %xor36.22.17 = xor i32 %xor.22.17, %conv35.22.17
  %conv37.22.17 = trunc i32 %xor36.22.17 to i8
  store i8 %conv37.22.17, i8* %scevgep41.22.16, align 1
  %scevgep26.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4579, i64 0, i64 1, i64 1
  %4703 = bitcast i8* %scevgep26.22 to [41 x [41 x i8]]*
  %scevgep39.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4580, i64 0, i64 1, i64 1
  %4704 = bitcast i8* %scevgep39.22 to [41 x [41 x i8]]*
  %arrayidx25.23 = getelementptr inbounds i8, i8* %a, i64 23
  %arrayidx33.23 = getelementptr inbounds i8, i8* %b, i64 23
  %call16.23 = call zeroext i8 (...) @rand()
  store i8 %call16.23, i8* %scevgep26.22, align 1
  %4705 = load i8, i8* %scevgep26.22, align 1
  %conv23.23 = zext i8 %4705 to i32
  %4706 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23 = getelementptr i8, i8* %b, i64 24
  %4707 = load i8, i8* %scevgep34.23, align 1
  %call28.23 = call zeroext i8 @mult(i8 zeroext %4706, i8 zeroext %4707)
  %conv29.23 = zext i8 %call28.23 to i32
  %xor.23 = xor i32 %conv23.23, %conv29.23
  %scevgep35.23 = getelementptr i8, i8* %a, i64 24
  %4708 = load i8, i8* %scevgep35.23, align 1
  %4709 = load i8, i8* %arrayidx33.23, align 1
  %call34.23 = call zeroext i8 @mult(i8 zeroext %4708, i8 zeroext %4709)
  %conv35.23 = zext i8 %call34.23 to i32
  %xor36.23 = xor i32 %xor.23, %conv35.23
  %conv37.23 = trunc i32 %xor36.23 to i8
  store i8 %conv37.23, i8* %scevgep39.22, align 1
  %scevgep28.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4703, i64 0, i64 0, i64 1
  %4710 = bitcast i8* %scevgep28.23 to [41 x [41 x i8]]*
  %scevgep41.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4704, i64 0, i64 1, i64 0
  %4711 = bitcast i8* %scevgep41.23 to [41 x [41 x i8]]*
  %call16.23.1 = call zeroext i8 (...) @rand()
  store i8 %call16.23.1, i8* %scevgep28.23, align 1
  %4712 = load i8, i8* %scevgep28.23, align 1
  %conv23.23.1 = zext i8 %4712 to i32
  %4713 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.1 = getelementptr i8, i8* %b, i64 25
  %4714 = load i8, i8* %scevgep34.23.1, align 1
  %call28.23.1 = call zeroext i8 @mult(i8 zeroext %4713, i8 zeroext %4714)
  %conv29.23.1 = zext i8 %call28.23.1 to i32
  %xor.23.1 = xor i32 %conv23.23.1, %conv29.23.1
  %scevgep35.23.1 = getelementptr i8, i8* %a, i64 25
  %4715 = load i8, i8* %scevgep35.23.1, align 1
  %4716 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.1 = call zeroext i8 @mult(i8 zeroext %4715, i8 zeroext %4716)
  %conv35.23.1 = zext i8 %call34.23.1 to i32
  %xor36.23.1 = xor i32 %xor.23.1, %conv35.23.1
  %conv37.23.1 = trunc i32 %xor36.23.1 to i8
  store i8 %conv37.23.1, i8* %scevgep41.23, align 1
  %scevgep28.23.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4710, i64 0, i64 0, i64 1
  %4717 = bitcast i8* %scevgep28.23.1 to [41 x [41 x i8]]*
  %scevgep41.23.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4711, i64 0, i64 1, i64 0
  %4718 = bitcast i8* %scevgep41.23.1 to [41 x [41 x i8]]*
  %call16.23.2 = call zeroext i8 (...) @rand()
  store i8 %call16.23.2, i8* %scevgep28.23.1, align 1
  %4719 = load i8, i8* %scevgep28.23.1, align 1
  %conv23.23.2 = zext i8 %4719 to i32
  %4720 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.2 = getelementptr i8, i8* %b, i64 26
  %4721 = load i8, i8* %scevgep34.23.2, align 1
  %call28.23.2 = call zeroext i8 @mult(i8 zeroext %4720, i8 zeroext %4721)
  %conv29.23.2 = zext i8 %call28.23.2 to i32
  %xor.23.2 = xor i32 %conv23.23.2, %conv29.23.2
  %scevgep35.23.2 = getelementptr i8, i8* %a, i64 26
  %4722 = load i8, i8* %scevgep35.23.2, align 1
  %4723 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.2 = call zeroext i8 @mult(i8 zeroext %4722, i8 zeroext %4723)
  %conv35.23.2 = zext i8 %call34.23.2 to i32
  %xor36.23.2 = xor i32 %xor.23.2, %conv35.23.2
  %conv37.23.2 = trunc i32 %xor36.23.2 to i8
  store i8 %conv37.23.2, i8* %scevgep41.23.1, align 1
  %scevgep28.23.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4717, i64 0, i64 0, i64 1
  %4724 = bitcast i8* %scevgep28.23.2 to [41 x [41 x i8]]*
  %scevgep41.23.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4718, i64 0, i64 1, i64 0
  %4725 = bitcast i8* %scevgep41.23.2 to [41 x [41 x i8]]*
  %call16.23.3 = call zeroext i8 (...) @rand()
  store i8 %call16.23.3, i8* %scevgep28.23.2, align 1
  %4726 = load i8, i8* %scevgep28.23.2, align 1
  %conv23.23.3 = zext i8 %4726 to i32
  %4727 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.3 = getelementptr i8, i8* %b, i64 27
  %4728 = load i8, i8* %scevgep34.23.3, align 1
  %call28.23.3 = call zeroext i8 @mult(i8 zeroext %4727, i8 zeroext %4728)
  %conv29.23.3 = zext i8 %call28.23.3 to i32
  %xor.23.3 = xor i32 %conv23.23.3, %conv29.23.3
  %scevgep35.23.3 = getelementptr i8, i8* %a, i64 27
  %4729 = load i8, i8* %scevgep35.23.3, align 1
  %4730 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.3 = call zeroext i8 @mult(i8 zeroext %4729, i8 zeroext %4730)
  %conv35.23.3 = zext i8 %call34.23.3 to i32
  %xor36.23.3 = xor i32 %xor.23.3, %conv35.23.3
  %conv37.23.3 = trunc i32 %xor36.23.3 to i8
  store i8 %conv37.23.3, i8* %scevgep41.23.2, align 1
  %scevgep28.23.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4724, i64 0, i64 0, i64 1
  %4731 = bitcast i8* %scevgep28.23.3 to [41 x [41 x i8]]*
  %scevgep41.23.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4725, i64 0, i64 1, i64 0
  %4732 = bitcast i8* %scevgep41.23.3 to [41 x [41 x i8]]*
  %call16.23.4 = call zeroext i8 (...) @rand()
  store i8 %call16.23.4, i8* %scevgep28.23.3, align 1
  %4733 = load i8, i8* %scevgep28.23.3, align 1
  %conv23.23.4 = zext i8 %4733 to i32
  %4734 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.4 = getelementptr i8, i8* %b, i64 28
  %4735 = load i8, i8* %scevgep34.23.4, align 1
  %call28.23.4 = call zeroext i8 @mult(i8 zeroext %4734, i8 zeroext %4735)
  %conv29.23.4 = zext i8 %call28.23.4 to i32
  %xor.23.4 = xor i32 %conv23.23.4, %conv29.23.4
  %scevgep35.23.4 = getelementptr i8, i8* %a, i64 28
  %4736 = load i8, i8* %scevgep35.23.4, align 1
  %4737 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.4 = call zeroext i8 @mult(i8 zeroext %4736, i8 zeroext %4737)
  %conv35.23.4 = zext i8 %call34.23.4 to i32
  %xor36.23.4 = xor i32 %xor.23.4, %conv35.23.4
  %conv37.23.4 = trunc i32 %xor36.23.4 to i8
  store i8 %conv37.23.4, i8* %scevgep41.23.3, align 1
  %scevgep28.23.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4731, i64 0, i64 0, i64 1
  %4738 = bitcast i8* %scevgep28.23.4 to [41 x [41 x i8]]*
  %scevgep41.23.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4732, i64 0, i64 1, i64 0
  %4739 = bitcast i8* %scevgep41.23.4 to [41 x [41 x i8]]*
  %call16.23.5 = call zeroext i8 (...) @rand()
  store i8 %call16.23.5, i8* %scevgep28.23.4, align 1
  %4740 = load i8, i8* %scevgep28.23.4, align 1
  %conv23.23.5 = zext i8 %4740 to i32
  %4741 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.5 = getelementptr i8, i8* %b, i64 29
  %4742 = load i8, i8* %scevgep34.23.5, align 1
  %call28.23.5 = call zeroext i8 @mult(i8 zeroext %4741, i8 zeroext %4742)
  %conv29.23.5 = zext i8 %call28.23.5 to i32
  %xor.23.5 = xor i32 %conv23.23.5, %conv29.23.5
  %scevgep35.23.5 = getelementptr i8, i8* %a, i64 29
  %4743 = load i8, i8* %scevgep35.23.5, align 1
  %4744 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.5 = call zeroext i8 @mult(i8 zeroext %4743, i8 zeroext %4744)
  %conv35.23.5 = zext i8 %call34.23.5 to i32
  %xor36.23.5 = xor i32 %xor.23.5, %conv35.23.5
  %conv37.23.5 = trunc i32 %xor36.23.5 to i8
  store i8 %conv37.23.5, i8* %scevgep41.23.4, align 1
  %scevgep28.23.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4738, i64 0, i64 0, i64 1
  %4745 = bitcast i8* %scevgep28.23.5 to [41 x [41 x i8]]*
  %scevgep41.23.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4739, i64 0, i64 1, i64 0
  %4746 = bitcast i8* %scevgep41.23.5 to [41 x [41 x i8]]*
  %call16.23.6 = call zeroext i8 (...) @rand()
  store i8 %call16.23.6, i8* %scevgep28.23.5, align 1
  %4747 = load i8, i8* %scevgep28.23.5, align 1
  %conv23.23.6 = zext i8 %4747 to i32
  %4748 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.6 = getelementptr i8, i8* %b, i64 30
  %4749 = load i8, i8* %scevgep34.23.6, align 1
  %call28.23.6 = call zeroext i8 @mult(i8 zeroext %4748, i8 zeroext %4749)
  %conv29.23.6 = zext i8 %call28.23.6 to i32
  %xor.23.6 = xor i32 %conv23.23.6, %conv29.23.6
  %scevgep35.23.6 = getelementptr i8, i8* %a, i64 30
  %4750 = load i8, i8* %scevgep35.23.6, align 1
  %4751 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.6 = call zeroext i8 @mult(i8 zeroext %4750, i8 zeroext %4751)
  %conv35.23.6 = zext i8 %call34.23.6 to i32
  %xor36.23.6 = xor i32 %xor.23.6, %conv35.23.6
  %conv37.23.6 = trunc i32 %xor36.23.6 to i8
  store i8 %conv37.23.6, i8* %scevgep41.23.5, align 1
  %scevgep28.23.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4745, i64 0, i64 0, i64 1
  %4752 = bitcast i8* %scevgep28.23.6 to [41 x [41 x i8]]*
  %scevgep41.23.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4746, i64 0, i64 1, i64 0
  %4753 = bitcast i8* %scevgep41.23.6 to [41 x [41 x i8]]*
  %call16.23.7 = call zeroext i8 (...) @rand()
  store i8 %call16.23.7, i8* %scevgep28.23.6, align 1
  %4754 = load i8, i8* %scevgep28.23.6, align 1
  %conv23.23.7 = zext i8 %4754 to i32
  %4755 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.7 = getelementptr i8, i8* %b, i64 31
  %4756 = load i8, i8* %scevgep34.23.7, align 1
  %call28.23.7 = call zeroext i8 @mult(i8 zeroext %4755, i8 zeroext %4756)
  %conv29.23.7 = zext i8 %call28.23.7 to i32
  %xor.23.7 = xor i32 %conv23.23.7, %conv29.23.7
  %scevgep35.23.7 = getelementptr i8, i8* %a, i64 31
  %4757 = load i8, i8* %scevgep35.23.7, align 1
  %4758 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.7 = call zeroext i8 @mult(i8 zeroext %4757, i8 zeroext %4758)
  %conv35.23.7 = zext i8 %call34.23.7 to i32
  %xor36.23.7 = xor i32 %xor.23.7, %conv35.23.7
  %conv37.23.7 = trunc i32 %xor36.23.7 to i8
  store i8 %conv37.23.7, i8* %scevgep41.23.6, align 1
  %scevgep28.23.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4752, i64 0, i64 0, i64 1
  %4759 = bitcast i8* %scevgep28.23.7 to [41 x [41 x i8]]*
  %scevgep41.23.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4753, i64 0, i64 1, i64 0
  %4760 = bitcast i8* %scevgep41.23.7 to [41 x [41 x i8]]*
  %call16.23.8 = call zeroext i8 (...) @rand()
  store i8 %call16.23.8, i8* %scevgep28.23.7, align 1
  %4761 = load i8, i8* %scevgep28.23.7, align 1
  %conv23.23.8 = zext i8 %4761 to i32
  %4762 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.8 = getelementptr i8, i8* %b, i64 32
  %4763 = load i8, i8* %scevgep34.23.8, align 1
  %call28.23.8 = call zeroext i8 @mult(i8 zeroext %4762, i8 zeroext %4763)
  %conv29.23.8 = zext i8 %call28.23.8 to i32
  %xor.23.8 = xor i32 %conv23.23.8, %conv29.23.8
  %scevgep35.23.8 = getelementptr i8, i8* %a, i64 32
  %4764 = load i8, i8* %scevgep35.23.8, align 1
  %4765 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.8 = call zeroext i8 @mult(i8 zeroext %4764, i8 zeroext %4765)
  %conv35.23.8 = zext i8 %call34.23.8 to i32
  %xor36.23.8 = xor i32 %xor.23.8, %conv35.23.8
  %conv37.23.8 = trunc i32 %xor36.23.8 to i8
  store i8 %conv37.23.8, i8* %scevgep41.23.7, align 1
  %scevgep28.23.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4759, i64 0, i64 0, i64 1
  %4766 = bitcast i8* %scevgep28.23.8 to [41 x [41 x i8]]*
  %scevgep41.23.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4760, i64 0, i64 1, i64 0
  %4767 = bitcast i8* %scevgep41.23.8 to [41 x [41 x i8]]*
  %call16.23.9 = call zeroext i8 (...) @rand()
  store i8 %call16.23.9, i8* %scevgep28.23.8, align 1
  %4768 = load i8, i8* %scevgep28.23.8, align 1
  %conv23.23.9 = zext i8 %4768 to i32
  %4769 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.9 = getelementptr i8, i8* %b, i64 33
  %4770 = load i8, i8* %scevgep34.23.9, align 1
  %call28.23.9 = call zeroext i8 @mult(i8 zeroext %4769, i8 zeroext %4770)
  %conv29.23.9 = zext i8 %call28.23.9 to i32
  %xor.23.9 = xor i32 %conv23.23.9, %conv29.23.9
  %scevgep35.23.9 = getelementptr i8, i8* %a, i64 33
  %4771 = load i8, i8* %scevgep35.23.9, align 1
  %4772 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.9 = call zeroext i8 @mult(i8 zeroext %4771, i8 zeroext %4772)
  %conv35.23.9 = zext i8 %call34.23.9 to i32
  %xor36.23.9 = xor i32 %xor.23.9, %conv35.23.9
  %conv37.23.9 = trunc i32 %xor36.23.9 to i8
  store i8 %conv37.23.9, i8* %scevgep41.23.8, align 1
  %scevgep28.23.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4766, i64 0, i64 0, i64 1
  %4773 = bitcast i8* %scevgep28.23.9 to [41 x [41 x i8]]*
  %scevgep41.23.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4767, i64 0, i64 1, i64 0
  %4774 = bitcast i8* %scevgep41.23.9 to [41 x [41 x i8]]*
  %call16.23.10 = call zeroext i8 (...) @rand()
  store i8 %call16.23.10, i8* %scevgep28.23.9, align 1
  %4775 = load i8, i8* %scevgep28.23.9, align 1
  %conv23.23.10 = zext i8 %4775 to i32
  %4776 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.10 = getelementptr i8, i8* %b, i64 34
  %4777 = load i8, i8* %scevgep34.23.10, align 1
  %call28.23.10 = call zeroext i8 @mult(i8 zeroext %4776, i8 zeroext %4777)
  %conv29.23.10 = zext i8 %call28.23.10 to i32
  %xor.23.10 = xor i32 %conv23.23.10, %conv29.23.10
  %scevgep35.23.10 = getelementptr i8, i8* %a, i64 34
  %4778 = load i8, i8* %scevgep35.23.10, align 1
  %4779 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.10 = call zeroext i8 @mult(i8 zeroext %4778, i8 zeroext %4779)
  %conv35.23.10 = zext i8 %call34.23.10 to i32
  %xor36.23.10 = xor i32 %xor.23.10, %conv35.23.10
  %conv37.23.10 = trunc i32 %xor36.23.10 to i8
  store i8 %conv37.23.10, i8* %scevgep41.23.9, align 1
  %scevgep28.23.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4773, i64 0, i64 0, i64 1
  %4780 = bitcast i8* %scevgep28.23.10 to [41 x [41 x i8]]*
  %scevgep41.23.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4774, i64 0, i64 1, i64 0
  %4781 = bitcast i8* %scevgep41.23.10 to [41 x [41 x i8]]*
  %call16.23.11 = call zeroext i8 (...) @rand()
  store i8 %call16.23.11, i8* %scevgep28.23.10, align 1
  %4782 = load i8, i8* %scevgep28.23.10, align 1
  %conv23.23.11 = zext i8 %4782 to i32
  %4783 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.11 = getelementptr i8, i8* %b, i64 35
  %4784 = load i8, i8* %scevgep34.23.11, align 1
  %call28.23.11 = call zeroext i8 @mult(i8 zeroext %4783, i8 zeroext %4784)
  %conv29.23.11 = zext i8 %call28.23.11 to i32
  %xor.23.11 = xor i32 %conv23.23.11, %conv29.23.11
  %scevgep35.23.11 = getelementptr i8, i8* %a, i64 35
  %4785 = load i8, i8* %scevgep35.23.11, align 1
  %4786 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.11 = call zeroext i8 @mult(i8 zeroext %4785, i8 zeroext %4786)
  %conv35.23.11 = zext i8 %call34.23.11 to i32
  %xor36.23.11 = xor i32 %xor.23.11, %conv35.23.11
  %conv37.23.11 = trunc i32 %xor36.23.11 to i8
  store i8 %conv37.23.11, i8* %scevgep41.23.10, align 1
  %scevgep28.23.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4780, i64 0, i64 0, i64 1
  %4787 = bitcast i8* %scevgep28.23.11 to [41 x [41 x i8]]*
  %scevgep41.23.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4781, i64 0, i64 1, i64 0
  %4788 = bitcast i8* %scevgep41.23.11 to [41 x [41 x i8]]*
  %call16.23.12 = call zeroext i8 (...) @rand()
  store i8 %call16.23.12, i8* %scevgep28.23.11, align 1
  %4789 = load i8, i8* %scevgep28.23.11, align 1
  %conv23.23.12 = zext i8 %4789 to i32
  %4790 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.12 = getelementptr i8, i8* %b, i64 36
  %4791 = load i8, i8* %scevgep34.23.12, align 1
  %call28.23.12 = call zeroext i8 @mult(i8 zeroext %4790, i8 zeroext %4791)
  %conv29.23.12 = zext i8 %call28.23.12 to i32
  %xor.23.12 = xor i32 %conv23.23.12, %conv29.23.12
  %scevgep35.23.12 = getelementptr i8, i8* %a, i64 36
  %4792 = load i8, i8* %scevgep35.23.12, align 1
  %4793 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.12 = call zeroext i8 @mult(i8 zeroext %4792, i8 zeroext %4793)
  %conv35.23.12 = zext i8 %call34.23.12 to i32
  %xor36.23.12 = xor i32 %xor.23.12, %conv35.23.12
  %conv37.23.12 = trunc i32 %xor36.23.12 to i8
  store i8 %conv37.23.12, i8* %scevgep41.23.11, align 1
  %scevgep28.23.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4787, i64 0, i64 0, i64 1
  %4794 = bitcast i8* %scevgep28.23.12 to [41 x [41 x i8]]*
  %scevgep41.23.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4788, i64 0, i64 1, i64 0
  %4795 = bitcast i8* %scevgep41.23.12 to [41 x [41 x i8]]*
  %call16.23.13 = call zeroext i8 (...) @rand()
  store i8 %call16.23.13, i8* %scevgep28.23.12, align 1
  %4796 = load i8, i8* %scevgep28.23.12, align 1
  %conv23.23.13 = zext i8 %4796 to i32
  %4797 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.13 = getelementptr i8, i8* %b, i64 37
  %4798 = load i8, i8* %scevgep34.23.13, align 1
  %call28.23.13 = call zeroext i8 @mult(i8 zeroext %4797, i8 zeroext %4798)
  %conv29.23.13 = zext i8 %call28.23.13 to i32
  %xor.23.13 = xor i32 %conv23.23.13, %conv29.23.13
  %scevgep35.23.13 = getelementptr i8, i8* %a, i64 37
  %4799 = load i8, i8* %scevgep35.23.13, align 1
  %4800 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.13 = call zeroext i8 @mult(i8 zeroext %4799, i8 zeroext %4800)
  %conv35.23.13 = zext i8 %call34.23.13 to i32
  %xor36.23.13 = xor i32 %xor.23.13, %conv35.23.13
  %conv37.23.13 = trunc i32 %xor36.23.13 to i8
  store i8 %conv37.23.13, i8* %scevgep41.23.12, align 1
  %scevgep28.23.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4794, i64 0, i64 0, i64 1
  %4801 = bitcast i8* %scevgep28.23.13 to [41 x [41 x i8]]*
  %scevgep41.23.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4795, i64 0, i64 1, i64 0
  %4802 = bitcast i8* %scevgep41.23.13 to [41 x [41 x i8]]*
  %call16.23.14 = call zeroext i8 (...) @rand()
  store i8 %call16.23.14, i8* %scevgep28.23.13, align 1
  %4803 = load i8, i8* %scevgep28.23.13, align 1
  %conv23.23.14 = zext i8 %4803 to i32
  %4804 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.14 = getelementptr i8, i8* %b, i64 38
  %4805 = load i8, i8* %scevgep34.23.14, align 1
  %call28.23.14 = call zeroext i8 @mult(i8 zeroext %4804, i8 zeroext %4805)
  %conv29.23.14 = zext i8 %call28.23.14 to i32
  %xor.23.14 = xor i32 %conv23.23.14, %conv29.23.14
  %scevgep35.23.14 = getelementptr i8, i8* %a, i64 38
  %4806 = load i8, i8* %scevgep35.23.14, align 1
  %4807 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.14 = call zeroext i8 @mult(i8 zeroext %4806, i8 zeroext %4807)
  %conv35.23.14 = zext i8 %call34.23.14 to i32
  %xor36.23.14 = xor i32 %xor.23.14, %conv35.23.14
  %conv37.23.14 = trunc i32 %xor36.23.14 to i8
  store i8 %conv37.23.14, i8* %scevgep41.23.13, align 1
  %scevgep28.23.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4801, i64 0, i64 0, i64 1
  %4808 = bitcast i8* %scevgep28.23.14 to [41 x [41 x i8]]*
  %scevgep41.23.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4802, i64 0, i64 1, i64 0
  %4809 = bitcast i8* %scevgep41.23.14 to [41 x [41 x i8]]*
  %call16.23.15 = call zeroext i8 (...) @rand()
  store i8 %call16.23.15, i8* %scevgep28.23.14, align 1
  %4810 = load i8, i8* %scevgep28.23.14, align 1
  %conv23.23.15 = zext i8 %4810 to i32
  %4811 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.15 = getelementptr i8, i8* %b, i64 39
  %4812 = load i8, i8* %scevgep34.23.15, align 1
  %call28.23.15 = call zeroext i8 @mult(i8 zeroext %4811, i8 zeroext %4812)
  %conv29.23.15 = zext i8 %call28.23.15 to i32
  %xor.23.15 = xor i32 %conv23.23.15, %conv29.23.15
  %scevgep35.23.15 = getelementptr i8, i8* %a, i64 39
  %4813 = load i8, i8* %scevgep35.23.15, align 1
  %4814 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.15 = call zeroext i8 @mult(i8 zeroext %4813, i8 zeroext %4814)
  %conv35.23.15 = zext i8 %call34.23.15 to i32
  %xor36.23.15 = xor i32 %xor.23.15, %conv35.23.15
  %conv37.23.15 = trunc i32 %xor36.23.15 to i8
  store i8 %conv37.23.15, i8* %scevgep41.23.14, align 1
  %scevgep28.23.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4808, i64 0, i64 0, i64 1
  %scevgep41.23.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4809, i64 0, i64 1, i64 0
  %call16.23.16 = call zeroext i8 (...) @rand()
  store i8 %call16.23.16, i8* %scevgep28.23.15, align 1
  %4815 = load i8, i8* %scevgep28.23.15, align 1
  %conv23.23.16 = zext i8 %4815 to i32
  %4816 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.16 = getelementptr i8, i8* %b, i64 40
  %4817 = load i8, i8* %scevgep34.23.16, align 1
  %call28.23.16 = call zeroext i8 @mult(i8 zeroext %4816, i8 zeroext %4817)
  %conv29.23.16 = zext i8 %call28.23.16 to i32
  %xor.23.16 = xor i32 %conv23.23.16, %conv29.23.16
  %scevgep35.23.16 = getelementptr i8, i8* %a, i64 40
  %4818 = load i8, i8* %scevgep35.23.16, align 1
  %4819 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.16 = call zeroext i8 @mult(i8 zeroext %4818, i8 zeroext %4819)
  %conv35.23.16 = zext i8 %call34.23.16 to i32
  %xor36.23.16 = xor i32 %xor.23.16, %conv35.23.16
  %conv37.23.16 = trunc i32 %xor36.23.16 to i8
  store i8 %conv37.23.16, i8* %scevgep41.23.15, align 1
  %scevgep26.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4703, i64 0, i64 1, i64 1
  %4820 = bitcast i8* %scevgep26.23 to [41 x [41 x i8]]*
  %scevgep39.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4704, i64 0, i64 1, i64 1
  %4821 = bitcast i8* %scevgep39.23 to [41 x [41 x i8]]*
  %arrayidx25.24 = getelementptr inbounds i8, i8* %a, i64 24
  %arrayidx33.24 = getelementptr inbounds i8, i8* %b, i64 24
  %call16.24 = call zeroext i8 (...) @rand()
  store i8 %call16.24, i8* %scevgep26.23, align 1
  %4822 = load i8, i8* %scevgep26.23, align 1
  %conv23.24 = zext i8 %4822 to i32
  %4823 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24 = getelementptr i8, i8* %b, i64 25
  %4824 = load i8, i8* %scevgep34.24, align 1
  %call28.24 = call zeroext i8 @mult(i8 zeroext %4823, i8 zeroext %4824)
  %conv29.24 = zext i8 %call28.24 to i32
  %xor.24 = xor i32 %conv23.24, %conv29.24
  %scevgep35.24 = getelementptr i8, i8* %a, i64 25
  %4825 = load i8, i8* %scevgep35.24, align 1
  %4826 = load i8, i8* %arrayidx33.24, align 1
  %call34.24 = call zeroext i8 @mult(i8 zeroext %4825, i8 zeroext %4826)
  %conv35.24 = zext i8 %call34.24 to i32
  %xor36.24 = xor i32 %xor.24, %conv35.24
  %conv37.24 = trunc i32 %xor36.24 to i8
  store i8 %conv37.24, i8* %scevgep39.23, align 1
  %scevgep28.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4820, i64 0, i64 0, i64 1
  %4827 = bitcast i8* %scevgep28.24 to [41 x [41 x i8]]*
  %scevgep41.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4821, i64 0, i64 1, i64 0
  %4828 = bitcast i8* %scevgep41.24 to [41 x [41 x i8]]*
  %call16.24.1 = call zeroext i8 (...) @rand()
  store i8 %call16.24.1, i8* %scevgep28.24, align 1
  %4829 = load i8, i8* %scevgep28.24, align 1
  %conv23.24.1 = zext i8 %4829 to i32
  %4830 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.1 = getelementptr i8, i8* %b, i64 26
  %4831 = load i8, i8* %scevgep34.24.1, align 1
  %call28.24.1 = call zeroext i8 @mult(i8 zeroext %4830, i8 zeroext %4831)
  %conv29.24.1 = zext i8 %call28.24.1 to i32
  %xor.24.1 = xor i32 %conv23.24.1, %conv29.24.1
  %scevgep35.24.1 = getelementptr i8, i8* %a, i64 26
  %4832 = load i8, i8* %scevgep35.24.1, align 1
  %4833 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.1 = call zeroext i8 @mult(i8 zeroext %4832, i8 zeroext %4833)
  %conv35.24.1 = zext i8 %call34.24.1 to i32
  %xor36.24.1 = xor i32 %xor.24.1, %conv35.24.1
  %conv37.24.1 = trunc i32 %xor36.24.1 to i8
  store i8 %conv37.24.1, i8* %scevgep41.24, align 1
  %scevgep28.24.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4827, i64 0, i64 0, i64 1
  %4834 = bitcast i8* %scevgep28.24.1 to [41 x [41 x i8]]*
  %scevgep41.24.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4828, i64 0, i64 1, i64 0
  %4835 = bitcast i8* %scevgep41.24.1 to [41 x [41 x i8]]*
  %call16.24.2 = call zeroext i8 (...) @rand()
  store i8 %call16.24.2, i8* %scevgep28.24.1, align 1
  %4836 = load i8, i8* %scevgep28.24.1, align 1
  %conv23.24.2 = zext i8 %4836 to i32
  %4837 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.2 = getelementptr i8, i8* %b, i64 27
  %4838 = load i8, i8* %scevgep34.24.2, align 1
  %call28.24.2 = call zeroext i8 @mult(i8 zeroext %4837, i8 zeroext %4838)
  %conv29.24.2 = zext i8 %call28.24.2 to i32
  %xor.24.2 = xor i32 %conv23.24.2, %conv29.24.2
  %scevgep35.24.2 = getelementptr i8, i8* %a, i64 27
  %4839 = load i8, i8* %scevgep35.24.2, align 1
  %4840 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.2 = call zeroext i8 @mult(i8 zeroext %4839, i8 zeroext %4840)
  %conv35.24.2 = zext i8 %call34.24.2 to i32
  %xor36.24.2 = xor i32 %xor.24.2, %conv35.24.2
  %conv37.24.2 = trunc i32 %xor36.24.2 to i8
  store i8 %conv37.24.2, i8* %scevgep41.24.1, align 1
  %scevgep28.24.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4834, i64 0, i64 0, i64 1
  %4841 = bitcast i8* %scevgep28.24.2 to [41 x [41 x i8]]*
  %scevgep41.24.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4835, i64 0, i64 1, i64 0
  %4842 = bitcast i8* %scevgep41.24.2 to [41 x [41 x i8]]*
  %call16.24.3 = call zeroext i8 (...) @rand()
  store i8 %call16.24.3, i8* %scevgep28.24.2, align 1
  %4843 = load i8, i8* %scevgep28.24.2, align 1
  %conv23.24.3 = zext i8 %4843 to i32
  %4844 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.3 = getelementptr i8, i8* %b, i64 28
  %4845 = load i8, i8* %scevgep34.24.3, align 1
  %call28.24.3 = call zeroext i8 @mult(i8 zeroext %4844, i8 zeroext %4845)
  %conv29.24.3 = zext i8 %call28.24.3 to i32
  %xor.24.3 = xor i32 %conv23.24.3, %conv29.24.3
  %scevgep35.24.3 = getelementptr i8, i8* %a, i64 28
  %4846 = load i8, i8* %scevgep35.24.3, align 1
  %4847 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.3 = call zeroext i8 @mult(i8 zeroext %4846, i8 zeroext %4847)
  %conv35.24.3 = zext i8 %call34.24.3 to i32
  %xor36.24.3 = xor i32 %xor.24.3, %conv35.24.3
  %conv37.24.3 = trunc i32 %xor36.24.3 to i8
  store i8 %conv37.24.3, i8* %scevgep41.24.2, align 1
  %scevgep28.24.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4841, i64 0, i64 0, i64 1
  %4848 = bitcast i8* %scevgep28.24.3 to [41 x [41 x i8]]*
  %scevgep41.24.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4842, i64 0, i64 1, i64 0
  %4849 = bitcast i8* %scevgep41.24.3 to [41 x [41 x i8]]*
  %call16.24.4 = call zeroext i8 (...) @rand()
  store i8 %call16.24.4, i8* %scevgep28.24.3, align 1
  %4850 = load i8, i8* %scevgep28.24.3, align 1
  %conv23.24.4 = zext i8 %4850 to i32
  %4851 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.4 = getelementptr i8, i8* %b, i64 29
  %4852 = load i8, i8* %scevgep34.24.4, align 1
  %call28.24.4 = call zeroext i8 @mult(i8 zeroext %4851, i8 zeroext %4852)
  %conv29.24.4 = zext i8 %call28.24.4 to i32
  %xor.24.4 = xor i32 %conv23.24.4, %conv29.24.4
  %scevgep35.24.4 = getelementptr i8, i8* %a, i64 29
  %4853 = load i8, i8* %scevgep35.24.4, align 1
  %4854 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.4 = call zeroext i8 @mult(i8 zeroext %4853, i8 zeroext %4854)
  %conv35.24.4 = zext i8 %call34.24.4 to i32
  %xor36.24.4 = xor i32 %xor.24.4, %conv35.24.4
  %conv37.24.4 = trunc i32 %xor36.24.4 to i8
  store i8 %conv37.24.4, i8* %scevgep41.24.3, align 1
  %scevgep28.24.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4848, i64 0, i64 0, i64 1
  %4855 = bitcast i8* %scevgep28.24.4 to [41 x [41 x i8]]*
  %scevgep41.24.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4849, i64 0, i64 1, i64 0
  %4856 = bitcast i8* %scevgep41.24.4 to [41 x [41 x i8]]*
  %call16.24.5 = call zeroext i8 (...) @rand()
  store i8 %call16.24.5, i8* %scevgep28.24.4, align 1
  %4857 = load i8, i8* %scevgep28.24.4, align 1
  %conv23.24.5 = zext i8 %4857 to i32
  %4858 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.5 = getelementptr i8, i8* %b, i64 30
  %4859 = load i8, i8* %scevgep34.24.5, align 1
  %call28.24.5 = call zeroext i8 @mult(i8 zeroext %4858, i8 zeroext %4859)
  %conv29.24.5 = zext i8 %call28.24.5 to i32
  %xor.24.5 = xor i32 %conv23.24.5, %conv29.24.5
  %scevgep35.24.5 = getelementptr i8, i8* %a, i64 30
  %4860 = load i8, i8* %scevgep35.24.5, align 1
  %4861 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.5 = call zeroext i8 @mult(i8 zeroext %4860, i8 zeroext %4861)
  %conv35.24.5 = zext i8 %call34.24.5 to i32
  %xor36.24.5 = xor i32 %xor.24.5, %conv35.24.5
  %conv37.24.5 = trunc i32 %xor36.24.5 to i8
  store i8 %conv37.24.5, i8* %scevgep41.24.4, align 1
  %scevgep28.24.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4855, i64 0, i64 0, i64 1
  %4862 = bitcast i8* %scevgep28.24.5 to [41 x [41 x i8]]*
  %scevgep41.24.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4856, i64 0, i64 1, i64 0
  %4863 = bitcast i8* %scevgep41.24.5 to [41 x [41 x i8]]*
  %call16.24.6 = call zeroext i8 (...) @rand()
  store i8 %call16.24.6, i8* %scevgep28.24.5, align 1
  %4864 = load i8, i8* %scevgep28.24.5, align 1
  %conv23.24.6 = zext i8 %4864 to i32
  %4865 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.6 = getelementptr i8, i8* %b, i64 31
  %4866 = load i8, i8* %scevgep34.24.6, align 1
  %call28.24.6 = call zeroext i8 @mult(i8 zeroext %4865, i8 zeroext %4866)
  %conv29.24.6 = zext i8 %call28.24.6 to i32
  %xor.24.6 = xor i32 %conv23.24.6, %conv29.24.6
  %scevgep35.24.6 = getelementptr i8, i8* %a, i64 31
  %4867 = load i8, i8* %scevgep35.24.6, align 1
  %4868 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.6 = call zeroext i8 @mult(i8 zeroext %4867, i8 zeroext %4868)
  %conv35.24.6 = zext i8 %call34.24.6 to i32
  %xor36.24.6 = xor i32 %xor.24.6, %conv35.24.6
  %conv37.24.6 = trunc i32 %xor36.24.6 to i8
  store i8 %conv37.24.6, i8* %scevgep41.24.5, align 1
  %scevgep28.24.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4862, i64 0, i64 0, i64 1
  %4869 = bitcast i8* %scevgep28.24.6 to [41 x [41 x i8]]*
  %scevgep41.24.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4863, i64 0, i64 1, i64 0
  %4870 = bitcast i8* %scevgep41.24.6 to [41 x [41 x i8]]*
  %call16.24.7 = call zeroext i8 (...) @rand()
  store i8 %call16.24.7, i8* %scevgep28.24.6, align 1
  %4871 = load i8, i8* %scevgep28.24.6, align 1
  %conv23.24.7 = zext i8 %4871 to i32
  %4872 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.7 = getelementptr i8, i8* %b, i64 32
  %4873 = load i8, i8* %scevgep34.24.7, align 1
  %call28.24.7 = call zeroext i8 @mult(i8 zeroext %4872, i8 zeroext %4873)
  %conv29.24.7 = zext i8 %call28.24.7 to i32
  %xor.24.7 = xor i32 %conv23.24.7, %conv29.24.7
  %scevgep35.24.7 = getelementptr i8, i8* %a, i64 32
  %4874 = load i8, i8* %scevgep35.24.7, align 1
  %4875 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.7 = call zeroext i8 @mult(i8 zeroext %4874, i8 zeroext %4875)
  %conv35.24.7 = zext i8 %call34.24.7 to i32
  %xor36.24.7 = xor i32 %xor.24.7, %conv35.24.7
  %conv37.24.7 = trunc i32 %xor36.24.7 to i8
  store i8 %conv37.24.7, i8* %scevgep41.24.6, align 1
  %scevgep28.24.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4869, i64 0, i64 0, i64 1
  %4876 = bitcast i8* %scevgep28.24.7 to [41 x [41 x i8]]*
  %scevgep41.24.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4870, i64 0, i64 1, i64 0
  %4877 = bitcast i8* %scevgep41.24.7 to [41 x [41 x i8]]*
  %call16.24.8 = call zeroext i8 (...) @rand()
  store i8 %call16.24.8, i8* %scevgep28.24.7, align 1
  %4878 = load i8, i8* %scevgep28.24.7, align 1
  %conv23.24.8 = zext i8 %4878 to i32
  %4879 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.8 = getelementptr i8, i8* %b, i64 33
  %4880 = load i8, i8* %scevgep34.24.8, align 1
  %call28.24.8 = call zeroext i8 @mult(i8 zeroext %4879, i8 zeroext %4880)
  %conv29.24.8 = zext i8 %call28.24.8 to i32
  %xor.24.8 = xor i32 %conv23.24.8, %conv29.24.8
  %scevgep35.24.8 = getelementptr i8, i8* %a, i64 33
  %4881 = load i8, i8* %scevgep35.24.8, align 1
  %4882 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.8 = call zeroext i8 @mult(i8 zeroext %4881, i8 zeroext %4882)
  %conv35.24.8 = zext i8 %call34.24.8 to i32
  %xor36.24.8 = xor i32 %xor.24.8, %conv35.24.8
  %conv37.24.8 = trunc i32 %xor36.24.8 to i8
  store i8 %conv37.24.8, i8* %scevgep41.24.7, align 1
  %scevgep28.24.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4876, i64 0, i64 0, i64 1
  %4883 = bitcast i8* %scevgep28.24.8 to [41 x [41 x i8]]*
  %scevgep41.24.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4877, i64 0, i64 1, i64 0
  %4884 = bitcast i8* %scevgep41.24.8 to [41 x [41 x i8]]*
  %call16.24.9 = call zeroext i8 (...) @rand()
  store i8 %call16.24.9, i8* %scevgep28.24.8, align 1
  %4885 = load i8, i8* %scevgep28.24.8, align 1
  %conv23.24.9 = zext i8 %4885 to i32
  %4886 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.9 = getelementptr i8, i8* %b, i64 34
  %4887 = load i8, i8* %scevgep34.24.9, align 1
  %call28.24.9 = call zeroext i8 @mult(i8 zeroext %4886, i8 zeroext %4887)
  %conv29.24.9 = zext i8 %call28.24.9 to i32
  %xor.24.9 = xor i32 %conv23.24.9, %conv29.24.9
  %scevgep35.24.9 = getelementptr i8, i8* %a, i64 34
  %4888 = load i8, i8* %scevgep35.24.9, align 1
  %4889 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.9 = call zeroext i8 @mult(i8 zeroext %4888, i8 zeroext %4889)
  %conv35.24.9 = zext i8 %call34.24.9 to i32
  %xor36.24.9 = xor i32 %xor.24.9, %conv35.24.9
  %conv37.24.9 = trunc i32 %xor36.24.9 to i8
  store i8 %conv37.24.9, i8* %scevgep41.24.8, align 1
  %scevgep28.24.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4883, i64 0, i64 0, i64 1
  %4890 = bitcast i8* %scevgep28.24.9 to [41 x [41 x i8]]*
  %scevgep41.24.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4884, i64 0, i64 1, i64 0
  %4891 = bitcast i8* %scevgep41.24.9 to [41 x [41 x i8]]*
  %call16.24.10 = call zeroext i8 (...) @rand()
  store i8 %call16.24.10, i8* %scevgep28.24.9, align 1
  %4892 = load i8, i8* %scevgep28.24.9, align 1
  %conv23.24.10 = zext i8 %4892 to i32
  %4893 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.10 = getelementptr i8, i8* %b, i64 35
  %4894 = load i8, i8* %scevgep34.24.10, align 1
  %call28.24.10 = call zeroext i8 @mult(i8 zeroext %4893, i8 zeroext %4894)
  %conv29.24.10 = zext i8 %call28.24.10 to i32
  %xor.24.10 = xor i32 %conv23.24.10, %conv29.24.10
  %scevgep35.24.10 = getelementptr i8, i8* %a, i64 35
  %4895 = load i8, i8* %scevgep35.24.10, align 1
  %4896 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.10 = call zeroext i8 @mult(i8 zeroext %4895, i8 zeroext %4896)
  %conv35.24.10 = zext i8 %call34.24.10 to i32
  %xor36.24.10 = xor i32 %xor.24.10, %conv35.24.10
  %conv37.24.10 = trunc i32 %xor36.24.10 to i8
  store i8 %conv37.24.10, i8* %scevgep41.24.9, align 1
  %scevgep28.24.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4890, i64 0, i64 0, i64 1
  %4897 = bitcast i8* %scevgep28.24.10 to [41 x [41 x i8]]*
  %scevgep41.24.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4891, i64 0, i64 1, i64 0
  %4898 = bitcast i8* %scevgep41.24.10 to [41 x [41 x i8]]*
  %call16.24.11 = call zeroext i8 (...) @rand()
  store i8 %call16.24.11, i8* %scevgep28.24.10, align 1
  %4899 = load i8, i8* %scevgep28.24.10, align 1
  %conv23.24.11 = zext i8 %4899 to i32
  %4900 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.11 = getelementptr i8, i8* %b, i64 36
  %4901 = load i8, i8* %scevgep34.24.11, align 1
  %call28.24.11 = call zeroext i8 @mult(i8 zeroext %4900, i8 zeroext %4901)
  %conv29.24.11 = zext i8 %call28.24.11 to i32
  %xor.24.11 = xor i32 %conv23.24.11, %conv29.24.11
  %scevgep35.24.11 = getelementptr i8, i8* %a, i64 36
  %4902 = load i8, i8* %scevgep35.24.11, align 1
  %4903 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.11 = call zeroext i8 @mult(i8 zeroext %4902, i8 zeroext %4903)
  %conv35.24.11 = zext i8 %call34.24.11 to i32
  %xor36.24.11 = xor i32 %xor.24.11, %conv35.24.11
  %conv37.24.11 = trunc i32 %xor36.24.11 to i8
  store i8 %conv37.24.11, i8* %scevgep41.24.10, align 1
  %scevgep28.24.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4897, i64 0, i64 0, i64 1
  %4904 = bitcast i8* %scevgep28.24.11 to [41 x [41 x i8]]*
  %scevgep41.24.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4898, i64 0, i64 1, i64 0
  %4905 = bitcast i8* %scevgep41.24.11 to [41 x [41 x i8]]*
  %call16.24.12 = call zeroext i8 (...) @rand()
  store i8 %call16.24.12, i8* %scevgep28.24.11, align 1
  %4906 = load i8, i8* %scevgep28.24.11, align 1
  %conv23.24.12 = zext i8 %4906 to i32
  %4907 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.12 = getelementptr i8, i8* %b, i64 37
  %4908 = load i8, i8* %scevgep34.24.12, align 1
  %call28.24.12 = call zeroext i8 @mult(i8 zeroext %4907, i8 zeroext %4908)
  %conv29.24.12 = zext i8 %call28.24.12 to i32
  %xor.24.12 = xor i32 %conv23.24.12, %conv29.24.12
  %scevgep35.24.12 = getelementptr i8, i8* %a, i64 37
  %4909 = load i8, i8* %scevgep35.24.12, align 1
  %4910 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.12 = call zeroext i8 @mult(i8 zeroext %4909, i8 zeroext %4910)
  %conv35.24.12 = zext i8 %call34.24.12 to i32
  %xor36.24.12 = xor i32 %xor.24.12, %conv35.24.12
  %conv37.24.12 = trunc i32 %xor36.24.12 to i8
  store i8 %conv37.24.12, i8* %scevgep41.24.11, align 1
  %scevgep28.24.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4904, i64 0, i64 0, i64 1
  %4911 = bitcast i8* %scevgep28.24.12 to [41 x [41 x i8]]*
  %scevgep41.24.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4905, i64 0, i64 1, i64 0
  %4912 = bitcast i8* %scevgep41.24.12 to [41 x [41 x i8]]*
  %call16.24.13 = call zeroext i8 (...) @rand()
  store i8 %call16.24.13, i8* %scevgep28.24.12, align 1
  %4913 = load i8, i8* %scevgep28.24.12, align 1
  %conv23.24.13 = zext i8 %4913 to i32
  %4914 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.13 = getelementptr i8, i8* %b, i64 38
  %4915 = load i8, i8* %scevgep34.24.13, align 1
  %call28.24.13 = call zeroext i8 @mult(i8 zeroext %4914, i8 zeroext %4915)
  %conv29.24.13 = zext i8 %call28.24.13 to i32
  %xor.24.13 = xor i32 %conv23.24.13, %conv29.24.13
  %scevgep35.24.13 = getelementptr i8, i8* %a, i64 38
  %4916 = load i8, i8* %scevgep35.24.13, align 1
  %4917 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.13 = call zeroext i8 @mult(i8 zeroext %4916, i8 zeroext %4917)
  %conv35.24.13 = zext i8 %call34.24.13 to i32
  %xor36.24.13 = xor i32 %xor.24.13, %conv35.24.13
  %conv37.24.13 = trunc i32 %xor36.24.13 to i8
  store i8 %conv37.24.13, i8* %scevgep41.24.12, align 1
  %scevgep28.24.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4911, i64 0, i64 0, i64 1
  %4918 = bitcast i8* %scevgep28.24.13 to [41 x [41 x i8]]*
  %scevgep41.24.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4912, i64 0, i64 1, i64 0
  %4919 = bitcast i8* %scevgep41.24.13 to [41 x [41 x i8]]*
  %call16.24.14 = call zeroext i8 (...) @rand()
  store i8 %call16.24.14, i8* %scevgep28.24.13, align 1
  %4920 = load i8, i8* %scevgep28.24.13, align 1
  %conv23.24.14 = zext i8 %4920 to i32
  %4921 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.14 = getelementptr i8, i8* %b, i64 39
  %4922 = load i8, i8* %scevgep34.24.14, align 1
  %call28.24.14 = call zeroext i8 @mult(i8 zeroext %4921, i8 zeroext %4922)
  %conv29.24.14 = zext i8 %call28.24.14 to i32
  %xor.24.14 = xor i32 %conv23.24.14, %conv29.24.14
  %scevgep35.24.14 = getelementptr i8, i8* %a, i64 39
  %4923 = load i8, i8* %scevgep35.24.14, align 1
  %4924 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.14 = call zeroext i8 @mult(i8 zeroext %4923, i8 zeroext %4924)
  %conv35.24.14 = zext i8 %call34.24.14 to i32
  %xor36.24.14 = xor i32 %xor.24.14, %conv35.24.14
  %conv37.24.14 = trunc i32 %xor36.24.14 to i8
  store i8 %conv37.24.14, i8* %scevgep41.24.13, align 1
  %scevgep28.24.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4918, i64 0, i64 0, i64 1
  %scevgep41.24.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4919, i64 0, i64 1, i64 0
  %call16.24.15 = call zeroext i8 (...) @rand()
  store i8 %call16.24.15, i8* %scevgep28.24.14, align 1
  %4925 = load i8, i8* %scevgep28.24.14, align 1
  %conv23.24.15 = zext i8 %4925 to i32
  %4926 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.15 = getelementptr i8, i8* %b, i64 40
  %4927 = load i8, i8* %scevgep34.24.15, align 1
  %call28.24.15 = call zeroext i8 @mult(i8 zeroext %4926, i8 zeroext %4927)
  %conv29.24.15 = zext i8 %call28.24.15 to i32
  %xor.24.15 = xor i32 %conv23.24.15, %conv29.24.15
  %scevgep35.24.15 = getelementptr i8, i8* %a, i64 40
  %4928 = load i8, i8* %scevgep35.24.15, align 1
  %4929 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.15 = call zeroext i8 @mult(i8 zeroext %4928, i8 zeroext %4929)
  %conv35.24.15 = zext i8 %call34.24.15 to i32
  %xor36.24.15 = xor i32 %xor.24.15, %conv35.24.15
  %conv37.24.15 = trunc i32 %xor36.24.15 to i8
  store i8 %conv37.24.15, i8* %scevgep41.24.14, align 1
  %scevgep26.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4820, i64 0, i64 1, i64 1
  %4930 = bitcast i8* %scevgep26.24 to [41 x [41 x i8]]*
  %scevgep39.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4821, i64 0, i64 1, i64 1
  %4931 = bitcast i8* %scevgep39.24 to [41 x [41 x i8]]*
  %arrayidx25.25 = getelementptr inbounds i8, i8* %a, i64 25
  %arrayidx33.25 = getelementptr inbounds i8, i8* %b, i64 25
  %call16.25 = call zeroext i8 (...) @rand()
  store i8 %call16.25, i8* %scevgep26.24, align 1
  %4932 = load i8, i8* %scevgep26.24, align 1
  %conv23.25 = zext i8 %4932 to i32
  %4933 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25 = getelementptr i8, i8* %b, i64 26
  %4934 = load i8, i8* %scevgep34.25, align 1
  %call28.25 = call zeroext i8 @mult(i8 zeroext %4933, i8 zeroext %4934)
  %conv29.25 = zext i8 %call28.25 to i32
  %xor.25 = xor i32 %conv23.25, %conv29.25
  %scevgep35.25 = getelementptr i8, i8* %a, i64 26
  %4935 = load i8, i8* %scevgep35.25, align 1
  %4936 = load i8, i8* %arrayidx33.25, align 1
  %call34.25 = call zeroext i8 @mult(i8 zeroext %4935, i8 zeroext %4936)
  %conv35.25 = zext i8 %call34.25 to i32
  %xor36.25 = xor i32 %xor.25, %conv35.25
  %conv37.25 = trunc i32 %xor36.25 to i8
  store i8 %conv37.25, i8* %scevgep39.24, align 1
  %scevgep28.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4930, i64 0, i64 0, i64 1
  %4937 = bitcast i8* %scevgep28.25 to [41 x [41 x i8]]*
  %scevgep41.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4931, i64 0, i64 1, i64 0
  %4938 = bitcast i8* %scevgep41.25 to [41 x [41 x i8]]*
  %call16.25.1 = call zeroext i8 (...) @rand()
  store i8 %call16.25.1, i8* %scevgep28.25, align 1
  %4939 = load i8, i8* %scevgep28.25, align 1
  %conv23.25.1 = zext i8 %4939 to i32
  %4940 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.1 = getelementptr i8, i8* %b, i64 27
  %4941 = load i8, i8* %scevgep34.25.1, align 1
  %call28.25.1 = call zeroext i8 @mult(i8 zeroext %4940, i8 zeroext %4941)
  %conv29.25.1 = zext i8 %call28.25.1 to i32
  %xor.25.1 = xor i32 %conv23.25.1, %conv29.25.1
  %scevgep35.25.1 = getelementptr i8, i8* %a, i64 27
  %4942 = load i8, i8* %scevgep35.25.1, align 1
  %4943 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.1 = call zeroext i8 @mult(i8 zeroext %4942, i8 zeroext %4943)
  %conv35.25.1 = zext i8 %call34.25.1 to i32
  %xor36.25.1 = xor i32 %xor.25.1, %conv35.25.1
  %conv37.25.1 = trunc i32 %xor36.25.1 to i8
  store i8 %conv37.25.1, i8* %scevgep41.25, align 1
  %scevgep28.25.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4937, i64 0, i64 0, i64 1
  %4944 = bitcast i8* %scevgep28.25.1 to [41 x [41 x i8]]*
  %scevgep41.25.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4938, i64 0, i64 1, i64 0
  %4945 = bitcast i8* %scevgep41.25.1 to [41 x [41 x i8]]*
  %call16.25.2 = call zeroext i8 (...) @rand()
  store i8 %call16.25.2, i8* %scevgep28.25.1, align 1
  %4946 = load i8, i8* %scevgep28.25.1, align 1
  %conv23.25.2 = zext i8 %4946 to i32
  %4947 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.2 = getelementptr i8, i8* %b, i64 28
  %4948 = load i8, i8* %scevgep34.25.2, align 1
  %call28.25.2 = call zeroext i8 @mult(i8 zeroext %4947, i8 zeroext %4948)
  %conv29.25.2 = zext i8 %call28.25.2 to i32
  %xor.25.2 = xor i32 %conv23.25.2, %conv29.25.2
  %scevgep35.25.2 = getelementptr i8, i8* %a, i64 28
  %4949 = load i8, i8* %scevgep35.25.2, align 1
  %4950 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.2 = call zeroext i8 @mult(i8 zeroext %4949, i8 zeroext %4950)
  %conv35.25.2 = zext i8 %call34.25.2 to i32
  %xor36.25.2 = xor i32 %xor.25.2, %conv35.25.2
  %conv37.25.2 = trunc i32 %xor36.25.2 to i8
  store i8 %conv37.25.2, i8* %scevgep41.25.1, align 1
  %scevgep28.25.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4944, i64 0, i64 0, i64 1
  %4951 = bitcast i8* %scevgep28.25.2 to [41 x [41 x i8]]*
  %scevgep41.25.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4945, i64 0, i64 1, i64 0
  %4952 = bitcast i8* %scevgep41.25.2 to [41 x [41 x i8]]*
  %call16.25.3 = call zeroext i8 (...) @rand()
  store i8 %call16.25.3, i8* %scevgep28.25.2, align 1
  %4953 = load i8, i8* %scevgep28.25.2, align 1
  %conv23.25.3 = zext i8 %4953 to i32
  %4954 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.3 = getelementptr i8, i8* %b, i64 29
  %4955 = load i8, i8* %scevgep34.25.3, align 1
  %call28.25.3 = call zeroext i8 @mult(i8 zeroext %4954, i8 zeroext %4955)
  %conv29.25.3 = zext i8 %call28.25.3 to i32
  %xor.25.3 = xor i32 %conv23.25.3, %conv29.25.3
  %scevgep35.25.3 = getelementptr i8, i8* %a, i64 29
  %4956 = load i8, i8* %scevgep35.25.3, align 1
  %4957 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.3 = call zeroext i8 @mult(i8 zeroext %4956, i8 zeroext %4957)
  %conv35.25.3 = zext i8 %call34.25.3 to i32
  %xor36.25.3 = xor i32 %xor.25.3, %conv35.25.3
  %conv37.25.3 = trunc i32 %xor36.25.3 to i8
  store i8 %conv37.25.3, i8* %scevgep41.25.2, align 1
  %scevgep28.25.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4951, i64 0, i64 0, i64 1
  %4958 = bitcast i8* %scevgep28.25.3 to [41 x [41 x i8]]*
  %scevgep41.25.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4952, i64 0, i64 1, i64 0
  %4959 = bitcast i8* %scevgep41.25.3 to [41 x [41 x i8]]*
  %call16.25.4 = call zeroext i8 (...) @rand()
  store i8 %call16.25.4, i8* %scevgep28.25.3, align 1
  %4960 = load i8, i8* %scevgep28.25.3, align 1
  %conv23.25.4 = zext i8 %4960 to i32
  %4961 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.4 = getelementptr i8, i8* %b, i64 30
  %4962 = load i8, i8* %scevgep34.25.4, align 1
  %call28.25.4 = call zeroext i8 @mult(i8 zeroext %4961, i8 zeroext %4962)
  %conv29.25.4 = zext i8 %call28.25.4 to i32
  %xor.25.4 = xor i32 %conv23.25.4, %conv29.25.4
  %scevgep35.25.4 = getelementptr i8, i8* %a, i64 30
  %4963 = load i8, i8* %scevgep35.25.4, align 1
  %4964 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.4 = call zeroext i8 @mult(i8 zeroext %4963, i8 zeroext %4964)
  %conv35.25.4 = zext i8 %call34.25.4 to i32
  %xor36.25.4 = xor i32 %xor.25.4, %conv35.25.4
  %conv37.25.4 = trunc i32 %xor36.25.4 to i8
  store i8 %conv37.25.4, i8* %scevgep41.25.3, align 1
  %scevgep28.25.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4958, i64 0, i64 0, i64 1
  %4965 = bitcast i8* %scevgep28.25.4 to [41 x [41 x i8]]*
  %scevgep41.25.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4959, i64 0, i64 1, i64 0
  %4966 = bitcast i8* %scevgep41.25.4 to [41 x [41 x i8]]*
  %call16.25.5 = call zeroext i8 (...) @rand()
  store i8 %call16.25.5, i8* %scevgep28.25.4, align 1
  %4967 = load i8, i8* %scevgep28.25.4, align 1
  %conv23.25.5 = zext i8 %4967 to i32
  %4968 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.5 = getelementptr i8, i8* %b, i64 31
  %4969 = load i8, i8* %scevgep34.25.5, align 1
  %call28.25.5 = call zeroext i8 @mult(i8 zeroext %4968, i8 zeroext %4969)
  %conv29.25.5 = zext i8 %call28.25.5 to i32
  %xor.25.5 = xor i32 %conv23.25.5, %conv29.25.5
  %scevgep35.25.5 = getelementptr i8, i8* %a, i64 31
  %4970 = load i8, i8* %scevgep35.25.5, align 1
  %4971 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.5 = call zeroext i8 @mult(i8 zeroext %4970, i8 zeroext %4971)
  %conv35.25.5 = zext i8 %call34.25.5 to i32
  %xor36.25.5 = xor i32 %xor.25.5, %conv35.25.5
  %conv37.25.5 = trunc i32 %xor36.25.5 to i8
  store i8 %conv37.25.5, i8* %scevgep41.25.4, align 1
  %scevgep28.25.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4965, i64 0, i64 0, i64 1
  %4972 = bitcast i8* %scevgep28.25.5 to [41 x [41 x i8]]*
  %scevgep41.25.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4966, i64 0, i64 1, i64 0
  %4973 = bitcast i8* %scevgep41.25.5 to [41 x [41 x i8]]*
  %call16.25.6 = call zeroext i8 (...) @rand()
  store i8 %call16.25.6, i8* %scevgep28.25.5, align 1
  %4974 = load i8, i8* %scevgep28.25.5, align 1
  %conv23.25.6 = zext i8 %4974 to i32
  %4975 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.6 = getelementptr i8, i8* %b, i64 32
  %4976 = load i8, i8* %scevgep34.25.6, align 1
  %call28.25.6 = call zeroext i8 @mult(i8 zeroext %4975, i8 zeroext %4976)
  %conv29.25.6 = zext i8 %call28.25.6 to i32
  %xor.25.6 = xor i32 %conv23.25.6, %conv29.25.6
  %scevgep35.25.6 = getelementptr i8, i8* %a, i64 32
  %4977 = load i8, i8* %scevgep35.25.6, align 1
  %4978 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.6 = call zeroext i8 @mult(i8 zeroext %4977, i8 zeroext %4978)
  %conv35.25.6 = zext i8 %call34.25.6 to i32
  %xor36.25.6 = xor i32 %xor.25.6, %conv35.25.6
  %conv37.25.6 = trunc i32 %xor36.25.6 to i8
  store i8 %conv37.25.6, i8* %scevgep41.25.5, align 1
  %scevgep28.25.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4972, i64 0, i64 0, i64 1
  %4979 = bitcast i8* %scevgep28.25.6 to [41 x [41 x i8]]*
  %scevgep41.25.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4973, i64 0, i64 1, i64 0
  %4980 = bitcast i8* %scevgep41.25.6 to [41 x [41 x i8]]*
  %call16.25.7 = call zeroext i8 (...) @rand()
  store i8 %call16.25.7, i8* %scevgep28.25.6, align 1
  %4981 = load i8, i8* %scevgep28.25.6, align 1
  %conv23.25.7 = zext i8 %4981 to i32
  %4982 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.7 = getelementptr i8, i8* %b, i64 33
  %4983 = load i8, i8* %scevgep34.25.7, align 1
  %call28.25.7 = call zeroext i8 @mult(i8 zeroext %4982, i8 zeroext %4983)
  %conv29.25.7 = zext i8 %call28.25.7 to i32
  %xor.25.7 = xor i32 %conv23.25.7, %conv29.25.7
  %scevgep35.25.7 = getelementptr i8, i8* %a, i64 33
  %4984 = load i8, i8* %scevgep35.25.7, align 1
  %4985 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.7 = call zeroext i8 @mult(i8 zeroext %4984, i8 zeroext %4985)
  %conv35.25.7 = zext i8 %call34.25.7 to i32
  %xor36.25.7 = xor i32 %xor.25.7, %conv35.25.7
  %conv37.25.7 = trunc i32 %xor36.25.7 to i8
  store i8 %conv37.25.7, i8* %scevgep41.25.6, align 1
  %scevgep28.25.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4979, i64 0, i64 0, i64 1
  %4986 = bitcast i8* %scevgep28.25.7 to [41 x [41 x i8]]*
  %scevgep41.25.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4980, i64 0, i64 1, i64 0
  %4987 = bitcast i8* %scevgep41.25.7 to [41 x [41 x i8]]*
  %call16.25.8 = call zeroext i8 (...) @rand()
  store i8 %call16.25.8, i8* %scevgep28.25.7, align 1
  %4988 = load i8, i8* %scevgep28.25.7, align 1
  %conv23.25.8 = zext i8 %4988 to i32
  %4989 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.8 = getelementptr i8, i8* %b, i64 34
  %4990 = load i8, i8* %scevgep34.25.8, align 1
  %call28.25.8 = call zeroext i8 @mult(i8 zeroext %4989, i8 zeroext %4990)
  %conv29.25.8 = zext i8 %call28.25.8 to i32
  %xor.25.8 = xor i32 %conv23.25.8, %conv29.25.8
  %scevgep35.25.8 = getelementptr i8, i8* %a, i64 34
  %4991 = load i8, i8* %scevgep35.25.8, align 1
  %4992 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.8 = call zeroext i8 @mult(i8 zeroext %4991, i8 zeroext %4992)
  %conv35.25.8 = zext i8 %call34.25.8 to i32
  %xor36.25.8 = xor i32 %xor.25.8, %conv35.25.8
  %conv37.25.8 = trunc i32 %xor36.25.8 to i8
  store i8 %conv37.25.8, i8* %scevgep41.25.7, align 1
  %scevgep28.25.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4986, i64 0, i64 0, i64 1
  %4993 = bitcast i8* %scevgep28.25.8 to [41 x [41 x i8]]*
  %scevgep41.25.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4987, i64 0, i64 1, i64 0
  %4994 = bitcast i8* %scevgep41.25.8 to [41 x [41 x i8]]*
  %call16.25.9 = call zeroext i8 (...) @rand()
  store i8 %call16.25.9, i8* %scevgep28.25.8, align 1
  %4995 = load i8, i8* %scevgep28.25.8, align 1
  %conv23.25.9 = zext i8 %4995 to i32
  %4996 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.9 = getelementptr i8, i8* %b, i64 35
  %4997 = load i8, i8* %scevgep34.25.9, align 1
  %call28.25.9 = call zeroext i8 @mult(i8 zeroext %4996, i8 zeroext %4997)
  %conv29.25.9 = zext i8 %call28.25.9 to i32
  %xor.25.9 = xor i32 %conv23.25.9, %conv29.25.9
  %scevgep35.25.9 = getelementptr i8, i8* %a, i64 35
  %4998 = load i8, i8* %scevgep35.25.9, align 1
  %4999 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.9 = call zeroext i8 @mult(i8 zeroext %4998, i8 zeroext %4999)
  %conv35.25.9 = zext i8 %call34.25.9 to i32
  %xor36.25.9 = xor i32 %xor.25.9, %conv35.25.9
  %conv37.25.9 = trunc i32 %xor36.25.9 to i8
  store i8 %conv37.25.9, i8* %scevgep41.25.8, align 1
  %scevgep28.25.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4993, i64 0, i64 0, i64 1
  %5000 = bitcast i8* %scevgep28.25.9 to [41 x [41 x i8]]*
  %scevgep41.25.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4994, i64 0, i64 1, i64 0
  %5001 = bitcast i8* %scevgep41.25.9 to [41 x [41 x i8]]*
  %call16.25.10 = call zeroext i8 (...) @rand()
  store i8 %call16.25.10, i8* %scevgep28.25.9, align 1
  %5002 = load i8, i8* %scevgep28.25.9, align 1
  %conv23.25.10 = zext i8 %5002 to i32
  %5003 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.10 = getelementptr i8, i8* %b, i64 36
  %5004 = load i8, i8* %scevgep34.25.10, align 1
  %call28.25.10 = call zeroext i8 @mult(i8 zeroext %5003, i8 zeroext %5004)
  %conv29.25.10 = zext i8 %call28.25.10 to i32
  %xor.25.10 = xor i32 %conv23.25.10, %conv29.25.10
  %scevgep35.25.10 = getelementptr i8, i8* %a, i64 36
  %5005 = load i8, i8* %scevgep35.25.10, align 1
  %5006 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.10 = call zeroext i8 @mult(i8 zeroext %5005, i8 zeroext %5006)
  %conv35.25.10 = zext i8 %call34.25.10 to i32
  %xor36.25.10 = xor i32 %xor.25.10, %conv35.25.10
  %conv37.25.10 = trunc i32 %xor36.25.10 to i8
  store i8 %conv37.25.10, i8* %scevgep41.25.9, align 1
  %scevgep28.25.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5000, i64 0, i64 0, i64 1
  %5007 = bitcast i8* %scevgep28.25.10 to [41 x [41 x i8]]*
  %scevgep41.25.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5001, i64 0, i64 1, i64 0
  %5008 = bitcast i8* %scevgep41.25.10 to [41 x [41 x i8]]*
  %call16.25.11 = call zeroext i8 (...) @rand()
  store i8 %call16.25.11, i8* %scevgep28.25.10, align 1
  %5009 = load i8, i8* %scevgep28.25.10, align 1
  %conv23.25.11 = zext i8 %5009 to i32
  %5010 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.11 = getelementptr i8, i8* %b, i64 37
  %5011 = load i8, i8* %scevgep34.25.11, align 1
  %call28.25.11 = call zeroext i8 @mult(i8 zeroext %5010, i8 zeroext %5011)
  %conv29.25.11 = zext i8 %call28.25.11 to i32
  %xor.25.11 = xor i32 %conv23.25.11, %conv29.25.11
  %scevgep35.25.11 = getelementptr i8, i8* %a, i64 37
  %5012 = load i8, i8* %scevgep35.25.11, align 1
  %5013 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.11 = call zeroext i8 @mult(i8 zeroext %5012, i8 zeroext %5013)
  %conv35.25.11 = zext i8 %call34.25.11 to i32
  %xor36.25.11 = xor i32 %xor.25.11, %conv35.25.11
  %conv37.25.11 = trunc i32 %xor36.25.11 to i8
  store i8 %conv37.25.11, i8* %scevgep41.25.10, align 1
  %scevgep28.25.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5007, i64 0, i64 0, i64 1
  %5014 = bitcast i8* %scevgep28.25.11 to [41 x [41 x i8]]*
  %scevgep41.25.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5008, i64 0, i64 1, i64 0
  %5015 = bitcast i8* %scevgep41.25.11 to [41 x [41 x i8]]*
  %call16.25.12 = call zeroext i8 (...) @rand()
  store i8 %call16.25.12, i8* %scevgep28.25.11, align 1
  %5016 = load i8, i8* %scevgep28.25.11, align 1
  %conv23.25.12 = zext i8 %5016 to i32
  %5017 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.12 = getelementptr i8, i8* %b, i64 38
  %5018 = load i8, i8* %scevgep34.25.12, align 1
  %call28.25.12 = call zeroext i8 @mult(i8 zeroext %5017, i8 zeroext %5018)
  %conv29.25.12 = zext i8 %call28.25.12 to i32
  %xor.25.12 = xor i32 %conv23.25.12, %conv29.25.12
  %scevgep35.25.12 = getelementptr i8, i8* %a, i64 38
  %5019 = load i8, i8* %scevgep35.25.12, align 1
  %5020 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.12 = call zeroext i8 @mult(i8 zeroext %5019, i8 zeroext %5020)
  %conv35.25.12 = zext i8 %call34.25.12 to i32
  %xor36.25.12 = xor i32 %xor.25.12, %conv35.25.12
  %conv37.25.12 = trunc i32 %xor36.25.12 to i8
  store i8 %conv37.25.12, i8* %scevgep41.25.11, align 1
  %scevgep28.25.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5014, i64 0, i64 0, i64 1
  %5021 = bitcast i8* %scevgep28.25.12 to [41 x [41 x i8]]*
  %scevgep41.25.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5015, i64 0, i64 1, i64 0
  %5022 = bitcast i8* %scevgep41.25.12 to [41 x [41 x i8]]*
  %call16.25.13 = call zeroext i8 (...) @rand()
  store i8 %call16.25.13, i8* %scevgep28.25.12, align 1
  %5023 = load i8, i8* %scevgep28.25.12, align 1
  %conv23.25.13 = zext i8 %5023 to i32
  %5024 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.13 = getelementptr i8, i8* %b, i64 39
  %5025 = load i8, i8* %scevgep34.25.13, align 1
  %call28.25.13 = call zeroext i8 @mult(i8 zeroext %5024, i8 zeroext %5025)
  %conv29.25.13 = zext i8 %call28.25.13 to i32
  %xor.25.13 = xor i32 %conv23.25.13, %conv29.25.13
  %scevgep35.25.13 = getelementptr i8, i8* %a, i64 39
  %5026 = load i8, i8* %scevgep35.25.13, align 1
  %5027 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.13 = call zeroext i8 @mult(i8 zeroext %5026, i8 zeroext %5027)
  %conv35.25.13 = zext i8 %call34.25.13 to i32
  %xor36.25.13 = xor i32 %xor.25.13, %conv35.25.13
  %conv37.25.13 = trunc i32 %xor36.25.13 to i8
  store i8 %conv37.25.13, i8* %scevgep41.25.12, align 1
  %scevgep28.25.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5021, i64 0, i64 0, i64 1
  %scevgep41.25.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5022, i64 0, i64 1, i64 0
  %call16.25.14 = call zeroext i8 (...) @rand()
  store i8 %call16.25.14, i8* %scevgep28.25.13, align 1
  %5028 = load i8, i8* %scevgep28.25.13, align 1
  %conv23.25.14 = zext i8 %5028 to i32
  %5029 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.14 = getelementptr i8, i8* %b, i64 40
  %5030 = load i8, i8* %scevgep34.25.14, align 1
  %call28.25.14 = call zeroext i8 @mult(i8 zeroext %5029, i8 zeroext %5030)
  %conv29.25.14 = zext i8 %call28.25.14 to i32
  %xor.25.14 = xor i32 %conv23.25.14, %conv29.25.14
  %scevgep35.25.14 = getelementptr i8, i8* %a, i64 40
  %5031 = load i8, i8* %scevgep35.25.14, align 1
  %5032 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.14 = call zeroext i8 @mult(i8 zeroext %5031, i8 zeroext %5032)
  %conv35.25.14 = zext i8 %call34.25.14 to i32
  %xor36.25.14 = xor i32 %xor.25.14, %conv35.25.14
  %conv37.25.14 = trunc i32 %xor36.25.14 to i8
  store i8 %conv37.25.14, i8* %scevgep41.25.13, align 1
  %scevgep26.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4930, i64 0, i64 1, i64 1
  %5033 = bitcast i8* %scevgep26.25 to [41 x [41 x i8]]*
  %scevgep39.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %4931, i64 0, i64 1, i64 1
  %5034 = bitcast i8* %scevgep39.25 to [41 x [41 x i8]]*
  %arrayidx25.26 = getelementptr inbounds i8, i8* %a, i64 26
  %arrayidx33.26 = getelementptr inbounds i8, i8* %b, i64 26
  %call16.26 = call zeroext i8 (...) @rand()
  store i8 %call16.26, i8* %scevgep26.25, align 1
  %5035 = load i8, i8* %scevgep26.25, align 1
  %conv23.26 = zext i8 %5035 to i32
  %5036 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26 = getelementptr i8, i8* %b, i64 27
  %5037 = load i8, i8* %scevgep34.26, align 1
  %call28.26 = call zeroext i8 @mult(i8 zeroext %5036, i8 zeroext %5037)
  %conv29.26 = zext i8 %call28.26 to i32
  %xor.26 = xor i32 %conv23.26, %conv29.26
  %scevgep35.26 = getelementptr i8, i8* %a, i64 27
  %5038 = load i8, i8* %scevgep35.26, align 1
  %5039 = load i8, i8* %arrayidx33.26, align 1
  %call34.26 = call zeroext i8 @mult(i8 zeroext %5038, i8 zeroext %5039)
  %conv35.26 = zext i8 %call34.26 to i32
  %xor36.26 = xor i32 %xor.26, %conv35.26
  %conv37.26 = trunc i32 %xor36.26 to i8
  store i8 %conv37.26, i8* %scevgep39.25, align 1
  %scevgep28.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5033, i64 0, i64 0, i64 1
  %5040 = bitcast i8* %scevgep28.26 to [41 x [41 x i8]]*
  %scevgep41.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5034, i64 0, i64 1, i64 0
  %5041 = bitcast i8* %scevgep41.26 to [41 x [41 x i8]]*
  %call16.26.1 = call zeroext i8 (...) @rand()
  store i8 %call16.26.1, i8* %scevgep28.26, align 1
  %5042 = load i8, i8* %scevgep28.26, align 1
  %conv23.26.1 = zext i8 %5042 to i32
  %5043 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.1 = getelementptr i8, i8* %b, i64 28
  %5044 = load i8, i8* %scevgep34.26.1, align 1
  %call28.26.1 = call zeroext i8 @mult(i8 zeroext %5043, i8 zeroext %5044)
  %conv29.26.1 = zext i8 %call28.26.1 to i32
  %xor.26.1 = xor i32 %conv23.26.1, %conv29.26.1
  %scevgep35.26.1 = getelementptr i8, i8* %a, i64 28
  %5045 = load i8, i8* %scevgep35.26.1, align 1
  %5046 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.1 = call zeroext i8 @mult(i8 zeroext %5045, i8 zeroext %5046)
  %conv35.26.1 = zext i8 %call34.26.1 to i32
  %xor36.26.1 = xor i32 %xor.26.1, %conv35.26.1
  %conv37.26.1 = trunc i32 %xor36.26.1 to i8
  store i8 %conv37.26.1, i8* %scevgep41.26, align 1
  %scevgep28.26.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5040, i64 0, i64 0, i64 1
  %5047 = bitcast i8* %scevgep28.26.1 to [41 x [41 x i8]]*
  %scevgep41.26.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5041, i64 0, i64 1, i64 0
  %5048 = bitcast i8* %scevgep41.26.1 to [41 x [41 x i8]]*
  %call16.26.2 = call zeroext i8 (...) @rand()
  store i8 %call16.26.2, i8* %scevgep28.26.1, align 1
  %5049 = load i8, i8* %scevgep28.26.1, align 1
  %conv23.26.2 = zext i8 %5049 to i32
  %5050 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.2 = getelementptr i8, i8* %b, i64 29
  %5051 = load i8, i8* %scevgep34.26.2, align 1
  %call28.26.2 = call zeroext i8 @mult(i8 zeroext %5050, i8 zeroext %5051)
  %conv29.26.2 = zext i8 %call28.26.2 to i32
  %xor.26.2 = xor i32 %conv23.26.2, %conv29.26.2
  %scevgep35.26.2 = getelementptr i8, i8* %a, i64 29
  %5052 = load i8, i8* %scevgep35.26.2, align 1
  %5053 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.2 = call zeroext i8 @mult(i8 zeroext %5052, i8 zeroext %5053)
  %conv35.26.2 = zext i8 %call34.26.2 to i32
  %xor36.26.2 = xor i32 %xor.26.2, %conv35.26.2
  %conv37.26.2 = trunc i32 %xor36.26.2 to i8
  store i8 %conv37.26.2, i8* %scevgep41.26.1, align 1
  %scevgep28.26.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5047, i64 0, i64 0, i64 1
  %5054 = bitcast i8* %scevgep28.26.2 to [41 x [41 x i8]]*
  %scevgep41.26.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5048, i64 0, i64 1, i64 0
  %5055 = bitcast i8* %scevgep41.26.2 to [41 x [41 x i8]]*
  %call16.26.3 = call zeroext i8 (...) @rand()
  store i8 %call16.26.3, i8* %scevgep28.26.2, align 1
  %5056 = load i8, i8* %scevgep28.26.2, align 1
  %conv23.26.3 = zext i8 %5056 to i32
  %5057 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.3 = getelementptr i8, i8* %b, i64 30
  %5058 = load i8, i8* %scevgep34.26.3, align 1
  %call28.26.3 = call zeroext i8 @mult(i8 zeroext %5057, i8 zeroext %5058)
  %conv29.26.3 = zext i8 %call28.26.3 to i32
  %xor.26.3 = xor i32 %conv23.26.3, %conv29.26.3
  %scevgep35.26.3 = getelementptr i8, i8* %a, i64 30
  %5059 = load i8, i8* %scevgep35.26.3, align 1
  %5060 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.3 = call zeroext i8 @mult(i8 zeroext %5059, i8 zeroext %5060)
  %conv35.26.3 = zext i8 %call34.26.3 to i32
  %xor36.26.3 = xor i32 %xor.26.3, %conv35.26.3
  %conv37.26.3 = trunc i32 %xor36.26.3 to i8
  store i8 %conv37.26.3, i8* %scevgep41.26.2, align 1
  %scevgep28.26.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5054, i64 0, i64 0, i64 1
  %5061 = bitcast i8* %scevgep28.26.3 to [41 x [41 x i8]]*
  %scevgep41.26.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5055, i64 0, i64 1, i64 0
  %5062 = bitcast i8* %scevgep41.26.3 to [41 x [41 x i8]]*
  %call16.26.4 = call zeroext i8 (...) @rand()
  store i8 %call16.26.4, i8* %scevgep28.26.3, align 1
  %5063 = load i8, i8* %scevgep28.26.3, align 1
  %conv23.26.4 = zext i8 %5063 to i32
  %5064 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.4 = getelementptr i8, i8* %b, i64 31
  %5065 = load i8, i8* %scevgep34.26.4, align 1
  %call28.26.4 = call zeroext i8 @mult(i8 zeroext %5064, i8 zeroext %5065)
  %conv29.26.4 = zext i8 %call28.26.4 to i32
  %xor.26.4 = xor i32 %conv23.26.4, %conv29.26.4
  %scevgep35.26.4 = getelementptr i8, i8* %a, i64 31
  %5066 = load i8, i8* %scevgep35.26.4, align 1
  %5067 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.4 = call zeroext i8 @mult(i8 zeroext %5066, i8 zeroext %5067)
  %conv35.26.4 = zext i8 %call34.26.4 to i32
  %xor36.26.4 = xor i32 %xor.26.4, %conv35.26.4
  %conv37.26.4 = trunc i32 %xor36.26.4 to i8
  store i8 %conv37.26.4, i8* %scevgep41.26.3, align 1
  %scevgep28.26.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5061, i64 0, i64 0, i64 1
  %5068 = bitcast i8* %scevgep28.26.4 to [41 x [41 x i8]]*
  %scevgep41.26.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5062, i64 0, i64 1, i64 0
  %5069 = bitcast i8* %scevgep41.26.4 to [41 x [41 x i8]]*
  %call16.26.5 = call zeroext i8 (...) @rand()
  store i8 %call16.26.5, i8* %scevgep28.26.4, align 1
  %5070 = load i8, i8* %scevgep28.26.4, align 1
  %conv23.26.5 = zext i8 %5070 to i32
  %5071 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.5 = getelementptr i8, i8* %b, i64 32
  %5072 = load i8, i8* %scevgep34.26.5, align 1
  %call28.26.5 = call zeroext i8 @mult(i8 zeroext %5071, i8 zeroext %5072)
  %conv29.26.5 = zext i8 %call28.26.5 to i32
  %xor.26.5 = xor i32 %conv23.26.5, %conv29.26.5
  %scevgep35.26.5 = getelementptr i8, i8* %a, i64 32
  %5073 = load i8, i8* %scevgep35.26.5, align 1
  %5074 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.5 = call zeroext i8 @mult(i8 zeroext %5073, i8 zeroext %5074)
  %conv35.26.5 = zext i8 %call34.26.5 to i32
  %xor36.26.5 = xor i32 %xor.26.5, %conv35.26.5
  %conv37.26.5 = trunc i32 %xor36.26.5 to i8
  store i8 %conv37.26.5, i8* %scevgep41.26.4, align 1
  %scevgep28.26.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5068, i64 0, i64 0, i64 1
  %5075 = bitcast i8* %scevgep28.26.5 to [41 x [41 x i8]]*
  %scevgep41.26.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5069, i64 0, i64 1, i64 0
  %5076 = bitcast i8* %scevgep41.26.5 to [41 x [41 x i8]]*
  %call16.26.6 = call zeroext i8 (...) @rand()
  store i8 %call16.26.6, i8* %scevgep28.26.5, align 1
  %5077 = load i8, i8* %scevgep28.26.5, align 1
  %conv23.26.6 = zext i8 %5077 to i32
  %5078 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.6 = getelementptr i8, i8* %b, i64 33
  %5079 = load i8, i8* %scevgep34.26.6, align 1
  %call28.26.6 = call zeroext i8 @mult(i8 zeroext %5078, i8 zeroext %5079)
  %conv29.26.6 = zext i8 %call28.26.6 to i32
  %xor.26.6 = xor i32 %conv23.26.6, %conv29.26.6
  %scevgep35.26.6 = getelementptr i8, i8* %a, i64 33
  %5080 = load i8, i8* %scevgep35.26.6, align 1
  %5081 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.6 = call zeroext i8 @mult(i8 zeroext %5080, i8 zeroext %5081)
  %conv35.26.6 = zext i8 %call34.26.6 to i32
  %xor36.26.6 = xor i32 %xor.26.6, %conv35.26.6
  %conv37.26.6 = trunc i32 %xor36.26.6 to i8
  store i8 %conv37.26.6, i8* %scevgep41.26.5, align 1
  %scevgep28.26.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5075, i64 0, i64 0, i64 1
  %5082 = bitcast i8* %scevgep28.26.6 to [41 x [41 x i8]]*
  %scevgep41.26.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5076, i64 0, i64 1, i64 0
  %5083 = bitcast i8* %scevgep41.26.6 to [41 x [41 x i8]]*
  %call16.26.7 = call zeroext i8 (...) @rand()
  store i8 %call16.26.7, i8* %scevgep28.26.6, align 1
  %5084 = load i8, i8* %scevgep28.26.6, align 1
  %conv23.26.7 = zext i8 %5084 to i32
  %5085 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.7 = getelementptr i8, i8* %b, i64 34
  %5086 = load i8, i8* %scevgep34.26.7, align 1
  %call28.26.7 = call zeroext i8 @mult(i8 zeroext %5085, i8 zeroext %5086)
  %conv29.26.7 = zext i8 %call28.26.7 to i32
  %xor.26.7 = xor i32 %conv23.26.7, %conv29.26.7
  %scevgep35.26.7 = getelementptr i8, i8* %a, i64 34
  %5087 = load i8, i8* %scevgep35.26.7, align 1
  %5088 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.7 = call zeroext i8 @mult(i8 zeroext %5087, i8 zeroext %5088)
  %conv35.26.7 = zext i8 %call34.26.7 to i32
  %xor36.26.7 = xor i32 %xor.26.7, %conv35.26.7
  %conv37.26.7 = trunc i32 %xor36.26.7 to i8
  store i8 %conv37.26.7, i8* %scevgep41.26.6, align 1
  %scevgep28.26.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5082, i64 0, i64 0, i64 1
  %5089 = bitcast i8* %scevgep28.26.7 to [41 x [41 x i8]]*
  %scevgep41.26.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5083, i64 0, i64 1, i64 0
  %5090 = bitcast i8* %scevgep41.26.7 to [41 x [41 x i8]]*
  %call16.26.8 = call zeroext i8 (...) @rand()
  store i8 %call16.26.8, i8* %scevgep28.26.7, align 1
  %5091 = load i8, i8* %scevgep28.26.7, align 1
  %conv23.26.8 = zext i8 %5091 to i32
  %5092 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.8 = getelementptr i8, i8* %b, i64 35
  %5093 = load i8, i8* %scevgep34.26.8, align 1
  %call28.26.8 = call zeroext i8 @mult(i8 zeroext %5092, i8 zeroext %5093)
  %conv29.26.8 = zext i8 %call28.26.8 to i32
  %xor.26.8 = xor i32 %conv23.26.8, %conv29.26.8
  %scevgep35.26.8 = getelementptr i8, i8* %a, i64 35
  %5094 = load i8, i8* %scevgep35.26.8, align 1
  %5095 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.8 = call zeroext i8 @mult(i8 zeroext %5094, i8 zeroext %5095)
  %conv35.26.8 = zext i8 %call34.26.8 to i32
  %xor36.26.8 = xor i32 %xor.26.8, %conv35.26.8
  %conv37.26.8 = trunc i32 %xor36.26.8 to i8
  store i8 %conv37.26.8, i8* %scevgep41.26.7, align 1
  %scevgep28.26.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5089, i64 0, i64 0, i64 1
  %5096 = bitcast i8* %scevgep28.26.8 to [41 x [41 x i8]]*
  %scevgep41.26.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5090, i64 0, i64 1, i64 0
  %5097 = bitcast i8* %scevgep41.26.8 to [41 x [41 x i8]]*
  %call16.26.9 = call zeroext i8 (...) @rand()
  store i8 %call16.26.9, i8* %scevgep28.26.8, align 1
  %5098 = load i8, i8* %scevgep28.26.8, align 1
  %conv23.26.9 = zext i8 %5098 to i32
  %5099 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.9 = getelementptr i8, i8* %b, i64 36
  %5100 = load i8, i8* %scevgep34.26.9, align 1
  %call28.26.9 = call zeroext i8 @mult(i8 zeroext %5099, i8 zeroext %5100)
  %conv29.26.9 = zext i8 %call28.26.9 to i32
  %xor.26.9 = xor i32 %conv23.26.9, %conv29.26.9
  %scevgep35.26.9 = getelementptr i8, i8* %a, i64 36
  %5101 = load i8, i8* %scevgep35.26.9, align 1
  %5102 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.9 = call zeroext i8 @mult(i8 zeroext %5101, i8 zeroext %5102)
  %conv35.26.9 = zext i8 %call34.26.9 to i32
  %xor36.26.9 = xor i32 %xor.26.9, %conv35.26.9
  %conv37.26.9 = trunc i32 %xor36.26.9 to i8
  store i8 %conv37.26.9, i8* %scevgep41.26.8, align 1
  %scevgep28.26.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5096, i64 0, i64 0, i64 1
  %5103 = bitcast i8* %scevgep28.26.9 to [41 x [41 x i8]]*
  %scevgep41.26.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5097, i64 0, i64 1, i64 0
  %5104 = bitcast i8* %scevgep41.26.9 to [41 x [41 x i8]]*
  %call16.26.10 = call zeroext i8 (...) @rand()
  store i8 %call16.26.10, i8* %scevgep28.26.9, align 1
  %5105 = load i8, i8* %scevgep28.26.9, align 1
  %conv23.26.10 = zext i8 %5105 to i32
  %5106 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.10 = getelementptr i8, i8* %b, i64 37
  %5107 = load i8, i8* %scevgep34.26.10, align 1
  %call28.26.10 = call zeroext i8 @mult(i8 zeroext %5106, i8 zeroext %5107)
  %conv29.26.10 = zext i8 %call28.26.10 to i32
  %xor.26.10 = xor i32 %conv23.26.10, %conv29.26.10
  %scevgep35.26.10 = getelementptr i8, i8* %a, i64 37
  %5108 = load i8, i8* %scevgep35.26.10, align 1
  %5109 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.10 = call zeroext i8 @mult(i8 zeroext %5108, i8 zeroext %5109)
  %conv35.26.10 = zext i8 %call34.26.10 to i32
  %xor36.26.10 = xor i32 %xor.26.10, %conv35.26.10
  %conv37.26.10 = trunc i32 %xor36.26.10 to i8
  store i8 %conv37.26.10, i8* %scevgep41.26.9, align 1
  %scevgep28.26.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5103, i64 0, i64 0, i64 1
  %5110 = bitcast i8* %scevgep28.26.10 to [41 x [41 x i8]]*
  %scevgep41.26.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5104, i64 0, i64 1, i64 0
  %5111 = bitcast i8* %scevgep41.26.10 to [41 x [41 x i8]]*
  %call16.26.11 = call zeroext i8 (...) @rand()
  store i8 %call16.26.11, i8* %scevgep28.26.10, align 1
  %5112 = load i8, i8* %scevgep28.26.10, align 1
  %conv23.26.11 = zext i8 %5112 to i32
  %5113 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.11 = getelementptr i8, i8* %b, i64 38
  %5114 = load i8, i8* %scevgep34.26.11, align 1
  %call28.26.11 = call zeroext i8 @mult(i8 zeroext %5113, i8 zeroext %5114)
  %conv29.26.11 = zext i8 %call28.26.11 to i32
  %xor.26.11 = xor i32 %conv23.26.11, %conv29.26.11
  %scevgep35.26.11 = getelementptr i8, i8* %a, i64 38
  %5115 = load i8, i8* %scevgep35.26.11, align 1
  %5116 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.11 = call zeroext i8 @mult(i8 zeroext %5115, i8 zeroext %5116)
  %conv35.26.11 = zext i8 %call34.26.11 to i32
  %xor36.26.11 = xor i32 %xor.26.11, %conv35.26.11
  %conv37.26.11 = trunc i32 %xor36.26.11 to i8
  store i8 %conv37.26.11, i8* %scevgep41.26.10, align 1
  %scevgep28.26.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5110, i64 0, i64 0, i64 1
  %5117 = bitcast i8* %scevgep28.26.11 to [41 x [41 x i8]]*
  %scevgep41.26.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5111, i64 0, i64 1, i64 0
  %5118 = bitcast i8* %scevgep41.26.11 to [41 x [41 x i8]]*
  %call16.26.12 = call zeroext i8 (...) @rand()
  store i8 %call16.26.12, i8* %scevgep28.26.11, align 1
  %5119 = load i8, i8* %scevgep28.26.11, align 1
  %conv23.26.12 = zext i8 %5119 to i32
  %5120 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.12 = getelementptr i8, i8* %b, i64 39
  %5121 = load i8, i8* %scevgep34.26.12, align 1
  %call28.26.12 = call zeroext i8 @mult(i8 zeroext %5120, i8 zeroext %5121)
  %conv29.26.12 = zext i8 %call28.26.12 to i32
  %xor.26.12 = xor i32 %conv23.26.12, %conv29.26.12
  %scevgep35.26.12 = getelementptr i8, i8* %a, i64 39
  %5122 = load i8, i8* %scevgep35.26.12, align 1
  %5123 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.12 = call zeroext i8 @mult(i8 zeroext %5122, i8 zeroext %5123)
  %conv35.26.12 = zext i8 %call34.26.12 to i32
  %xor36.26.12 = xor i32 %xor.26.12, %conv35.26.12
  %conv37.26.12 = trunc i32 %xor36.26.12 to i8
  store i8 %conv37.26.12, i8* %scevgep41.26.11, align 1
  %scevgep28.26.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5117, i64 0, i64 0, i64 1
  %scevgep41.26.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5118, i64 0, i64 1, i64 0
  %call16.26.13 = call zeroext i8 (...) @rand()
  store i8 %call16.26.13, i8* %scevgep28.26.12, align 1
  %5124 = load i8, i8* %scevgep28.26.12, align 1
  %conv23.26.13 = zext i8 %5124 to i32
  %5125 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.13 = getelementptr i8, i8* %b, i64 40
  %5126 = load i8, i8* %scevgep34.26.13, align 1
  %call28.26.13 = call zeroext i8 @mult(i8 zeroext %5125, i8 zeroext %5126)
  %conv29.26.13 = zext i8 %call28.26.13 to i32
  %xor.26.13 = xor i32 %conv23.26.13, %conv29.26.13
  %scevgep35.26.13 = getelementptr i8, i8* %a, i64 40
  %5127 = load i8, i8* %scevgep35.26.13, align 1
  %5128 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.13 = call zeroext i8 @mult(i8 zeroext %5127, i8 zeroext %5128)
  %conv35.26.13 = zext i8 %call34.26.13 to i32
  %xor36.26.13 = xor i32 %xor.26.13, %conv35.26.13
  %conv37.26.13 = trunc i32 %xor36.26.13 to i8
  store i8 %conv37.26.13, i8* %scevgep41.26.12, align 1
  %scevgep26.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5033, i64 0, i64 1, i64 1
  %5129 = bitcast i8* %scevgep26.26 to [41 x [41 x i8]]*
  %scevgep39.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5034, i64 0, i64 1, i64 1
  %5130 = bitcast i8* %scevgep39.26 to [41 x [41 x i8]]*
  %arrayidx25.27 = getelementptr inbounds i8, i8* %a, i64 27
  %arrayidx33.27 = getelementptr inbounds i8, i8* %b, i64 27
  %call16.27 = call zeroext i8 (...) @rand()
  store i8 %call16.27, i8* %scevgep26.26, align 1
  %5131 = load i8, i8* %scevgep26.26, align 1
  %conv23.27 = zext i8 %5131 to i32
  %5132 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27 = getelementptr i8, i8* %b, i64 28
  %5133 = load i8, i8* %scevgep34.27, align 1
  %call28.27 = call zeroext i8 @mult(i8 zeroext %5132, i8 zeroext %5133)
  %conv29.27 = zext i8 %call28.27 to i32
  %xor.27 = xor i32 %conv23.27, %conv29.27
  %scevgep35.27 = getelementptr i8, i8* %a, i64 28
  %5134 = load i8, i8* %scevgep35.27, align 1
  %5135 = load i8, i8* %arrayidx33.27, align 1
  %call34.27 = call zeroext i8 @mult(i8 zeroext %5134, i8 zeroext %5135)
  %conv35.27 = zext i8 %call34.27 to i32
  %xor36.27 = xor i32 %xor.27, %conv35.27
  %conv37.27 = trunc i32 %xor36.27 to i8
  store i8 %conv37.27, i8* %scevgep39.26, align 1
  %scevgep28.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5129, i64 0, i64 0, i64 1
  %5136 = bitcast i8* %scevgep28.27 to [41 x [41 x i8]]*
  %scevgep41.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5130, i64 0, i64 1, i64 0
  %5137 = bitcast i8* %scevgep41.27 to [41 x [41 x i8]]*
  %call16.27.1 = call zeroext i8 (...) @rand()
  store i8 %call16.27.1, i8* %scevgep28.27, align 1
  %5138 = load i8, i8* %scevgep28.27, align 1
  %conv23.27.1 = zext i8 %5138 to i32
  %5139 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.1 = getelementptr i8, i8* %b, i64 29
  %5140 = load i8, i8* %scevgep34.27.1, align 1
  %call28.27.1 = call zeroext i8 @mult(i8 zeroext %5139, i8 zeroext %5140)
  %conv29.27.1 = zext i8 %call28.27.1 to i32
  %xor.27.1 = xor i32 %conv23.27.1, %conv29.27.1
  %scevgep35.27.1 = getelementptr i8, i8* %a, i64 29
  %5141 = load i8, i8* %scevgep35.27.1, align 1
  %5142 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.1 = call zeroext i8 @mult(i8 zeroext %5141, i8 zeroext %5142)
  %conv35.27.1 = zext i8 %call34.27.1 to i32
  %xor36.27.1 = xor i32 %xor.27.1, %conv35.27.1
  %conv37.27.1 = trunc i32 %xor36.27.1 to i8
  store i8 %conv37.27.1, i8* %scevgep41.27, align 1
  %scevgep28.27.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5136, i64 0, i64 0, i64 1
  %5143 = bitcast i8* %scevgep28.27.1 to [41 x [41 x i8]]*
  %scevgep41.27.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5137, i64 0, i64 1, i64 0
  %5144 = bitcast i8* %scevgep41.27.1 to [41 x [41 x i8]]*
  %call16.27.2 = call zeroext i8 (...) @rand()
  store i8 %call16.27.2, i8* %scevgep28.27.1, align 1
  %5145 = load i8, i8* %scevgep28.27.1, align 1
  %conv23.27.2 = zext i8 %5145 to i32
  %5146 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.2 = getelementptr i8, i8* %b, i64 30
  %5147 = load i8, i8* %scevgep34.27.2, align 1
  %call28.27.2 = call zeroext i8 @mult(i8 zeroext %5146, i8 zeroext %5147)
  %conv29.27.2 = zext i8 %call28.27.2 to i32
  %xor.27.2 = xor i32 %conv23.27.2, %conv29.27.2
  %scevgep35.27.2 = getelementptr i8, i8* %a, i64 30
  %5148 = load i8, i8* %scevgep35.27.2, align 1
  %5149 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.2 = call zeroext i8 @mult(i8 zeroext %5148, i8 zeroext %5149)
  %conv35.27.2 = zext i8 %call34.27.2 to i32
  %xor36.27.2 = xor i32 %xor.27.2, %conv35.27.2
  %conv37.27.2 = trunc i32 %xor36.27.2 to i8
  store i8 %conv37.27.2, i8* %scevgep41.27.1, align 1
  %scevgep28.27.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5143, i64 0, i64 0, i64 1
  %5150 = bitcast i8* %scevgep28.27.2 to [41 x [41 x i8]]*
  %scevgep41.27.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5144, i64 0, i64 1, i64 0
  %5151 = bitcast i8* %scevgep41.27.2 to [41 x [41 x i8]]*
  %call16.27.3 = call zeroext i8 (...) @rand()
  store i8 %call16.27.3, i8* %scevgep28.27.2, align 1
  %5152 = load i8, i8* %scevgep28.27.2, align 1
  %conv23.27.3 = zext i8 %5152 to i32
  %5153 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.3 = getelementptr i8, i8* %b, i64 31
  %5154 = load i8, i8* %scevgep34.27.3, align 1
  %call28.27.3 = call zeroext i8 @mult(i8 zeroext %5153, i8 zeroext %5154)
  %conv29.27.3 = zext i8 %call28.27.3 to i32
  %xor.27.3 = xor i32 %conv23.27.3, %conv29.27.3
  %scevgep35.27.3 = getelementptr i8, i8* %a, i64 31
  %5155 = load i8, i8* %scevgep35.27.3, align 1
  %5156 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.3 = call zeroext i8 @mult(i8 zeroext %5155, i8 zeroext %5156)
  %conv35.27.3 = zext i8 %call34.27.3 to i32
  %xor36.27.3 = xor i32 %xor.27.3, %conv35.27.3
  %conv37.27.3 = trunc i32 %xor36.27.3 to i8
  store i8 %conv37.27.3, i8* %scevgep41.27.2, align 1
  %scevgep28.27.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5150, i64 0, i64 0, i64 1
  %5157 = bitcast i8* %scevgep28.27.3 to [41 x [41 x i8]]*
  %scevgep41.27.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5151, i64 0, i64 1, i64 0
  %5158 = bitcast i8* %scevgep41.27.3 to [41 x [41 x i8]]*
  %call16.27.4 = call zeroext i8 (...) @rand()
  store i8 %call16.27.4, i8* %scevgep28.27.3, align 1
  %5159 = load i8, i8* %scevgep28.27.3, align 1
  %conv23.27.4 = zext i8 %5159 to i32
  %5160 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.4 = getelementptr i8, i8* %b, i64 32
  %5161 = load i8, i8* %scevgep34.27.4, align 1
  %call28.27.4 = call zeroext i8 @mult(i8 zeroext %5160, i8 zeroext %5161)
  %conv29.27.4 = zext i8 %call28.27.4 to i32
  %xor.27.4 = xor i32 %conv23.27.4, %conv29.27.4
  %scevgep35.27.4 = getelementptr i8, i8* %a, i64 32
  %5162 = load i8, i8* %scevgep35.27.4, align 1
  %5163 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.4 = call zeroext i8 @mult(i8 zeroext %5162, i8 zeroext %5163)
  %conv35.27.4 = zext i8 %call34.27.4 to i32
  %xor36.27.4 = xor i32 %xor.27.4, %conv35.27.4
  %conv37.27.4 = trunc i32 %xor36.27.4 to i8
  store i8 %conv37.27.4, i8* %scevgep41.27.3, align 1
  %scevgep28.27.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5157, i64 0, i64 0, i64 1
  %5164 = bitcast i8* %scevgep28.27.4 to [41 x [41 x i8]]*
  %scevgep41.27.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5158, i64 0, i64 1, i64 0
  %5165 = bitcast i8* %scevgep41.27.4 to [41 x [41 x i8]]*
  %call16.27.5 = call zeroext i8 (...) @rand()
  store i8 %call16.27.5, i8* %scevgep28.27.4, align 1
  %5166 = load i8, i8* %scevgep28.27.4, align 1
  %conv23.27.5 = zext i8 %5166 to i32
  %5167 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.5 = getelementptr i8, i8* %b, i64 33
  %5168 = load i8, i8* %scevgep34.27.5, align 1
  %call28.27.5 = call zeroext i8 @mult(i8 zeroext %5167, i8 zeroext %5168)
  %conv29.27.5 = zext i8 %call28.27.5 to i32
  %xor.27.5 = xor i32 %conv23.27.5, %conv29.27.5
  %scevgep35.27.5 = getelementptr i8, i8* %a, i64 33
  %5169 = load i8, i8* %scevgep35.27.5, align 1
  %5170 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.5 = call zeroext i8 @mult(i8 zeroext %5169, i8 zeroext %5170)
  %conv35.27.5 = zext i8 %call34.27.5 to i32
  %xor36.27.5 = xor i32 %xor.27.5, %conv35.27.5
  %conv37.27.5 = trunc i32 %xor36.27.5 to i8
  store i8 %conv37.27.5, i8* %scevgep41.27.4, align 1
  %scevgep28.27.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5164, i64 0, i64 0, i64 1
  %5171 = bitcast i8* %scevgep28.27.5 to [41 x [41 x i8]]*
  %scevgep41.27.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5165, i64 0, i64 1, i64 0
  %5172 = bitcast i8* %scevgep41.27.5 to [41 x [41 x i8]]*
  %call16.27.6 = call zeroext i8 (...) @rand()
  store i8 %call16.27.6, i8* %scevgep28.27.5, align 1
  %5173 = load i8, i8* %scevgep28.27.5, align 1
  %conv23.27.6 = zext i8 %5173 to i32
  %5174 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.6 = getelementptr i8, i8* %b, i64 34
  %5175 = load i8, i8* %scevgep34.27.6, align 1
  %call28.27.6 = call zeroext i8 @mult(i8 zeroext %5174, i8 zeroext %5175)
  %conv29.27.6 = zext i8 %call28.27.6 to i32
  %xor.27.6 = xor i32 %conv23.27.6, %conv29.27.6
  %scevgep35.27.6 = getelementptr i8, i8* %a, i64 34
  %5176 = load i8, i8* %scevgep35.27.6, align 1
  %5177 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.6 = call zeroext i8 @mult(i8 zeroext %5176, i8 zeroext %5177)
  %conv35.27.6 = zext i8 %call34.27.6 to i32
  %xor36.27.6 = xor i32 %xor.27.6, %conv35.27.6
  %conv37.27.6 = trunc i32 %xor36.27.6 to i8
  store i8 %conv37.27.6, i8* %scevgep41.27.5, align 1
  %scevgep28.27.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5171, i64 0, i64 0, i64 1
  %5178 = bitcast i8* %scevgep28.27.6 to [41 x [41 x i8]]*
  %scevgep41.27.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5172, i64 0, i64 1, i64 0
  %5179 = bitcast i8* %scevgep41.27.6 to [41 x [41 x i8]]*
  %call16.27.7 = call zeroext i8 (...) @rand()
  store i8 %call16.27.7, i8* %scevgep28.27.6, align 1
  %5180 = load i8, i8* %scevgep28.27.6, align 1
  %conv23.27.7 = zext i8 %5180 to i32
  %5181 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.7 = getelementptr i8, i8* %b, i64 35
  %5182 = load i8, i8* %scevgep34.27.7, align 1
  %call28.27.7 = call zeroext i8 @mult(i8 zeroext %5181, i8 zeroext %5182)
  %conv29.27.7 = zext i8 %call28.27.7 to i32
  %xor.27.7 = xor i32 %conv23.27.7, %conv29.27.7
  %scevgep35.27.7 = getelementptr i8, i8* %a, i64 35
  %5183 = load i8, i8* %scevgep35.27.7, align 1
  %5184 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.7 = call zeroext i8 @mult(i8 zeroext %5183, i8 zeroext %5184)
  %conv35.27.7 = zext i8 %call34.27.7 to i32
  %xor36.27.7 = xor i32 %xor.27.7, %conv35.27.7
  %conv37.27.7 = trunc i32 %xor36.27.7 to i8
  store i8 %conv37.27.7, i8* %scevgep41.27.6, align 1
  %scevgep28.27.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5178, i64 0, i64 0, i64 1
  %5185 = bitcast i8* %scevgep28.27.7 to [41 x [41 x i8]]*
  %scevgep41.27.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5179, i64 0, i64 1, i64 0
  %5186 = bitcast i8* %scevgep41.27.7 to [41 x [41 x i8]]*
  %call16.27.8 = call zeroext i8 (...) @rand()
  store i8 %call16.27.8, i8* %scevgep28.27.7, align 1
  %5187 = load i8, i8* %scevgep28.27.7, align 1
  %conv23.27.8 = zext i8 %5187 to i32
  %5188 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.8 = getelementptr i8, i8* %b, i64 36
  %5189 = load i8, i8* %scevgep34.27.8, align 1
  %call28.27.8 = call zeroext i8 @mult(i8 zeroext %5188, i8 zeroext %5189)
  %conv29.27.8 = zext i8 %call28.27.8 to i32
  %xor.27.8 = xor i32 %conv23.27.8, %conv29.27.8
  %scevgep35.27.8 = getelementptr i8, i8* %a, i64 36
  %5190 = load i8, i8* %scevgep35.27.8, align 1
  %5191 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.8 = call zeroext i8 @mult(i8 zeroext %5190, i8 zeroext %5191)
  %conv35.27.8 = zext i8 %call34.27.8 to i32
  %xor36.27.8 = xor i32 %xor.27.8, %conv35.27.8
  %conv37.27.8 = trunc i32 %xor36.27.8 to i8
  store i8 %conv37.27.8, i8* %scevgep41.27.7, align 1
  %scevgep28.27.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5185, i64 0, i64 0, i64 1
  %5192 = bitcast i8* %scevgep28.27.8 to [41 x [41 x i8]]*
  %scevgep41.27.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5186, i64 0, i64 1, i64 0
  %5193 = bitcast i8* %scevgep41.27.8 to [41 x [41 x i8]]*
  %call16.27.9 = call zeroext i8 (...) @rand()
  store i8 %call16.27.9, i8* %scevgep28.27.8, align 1
  %5194 = load i8, i8* %scevgep28.27.8, align 1
  %conv23.27.9 = zext i8 %5194 to i32
  %5195 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.9 = getelementptr i8, i8* %b, i64 37
  %5196 = load i8, i8* %scevgep34.27.9, align 1
  %call28.27.9 = call zeroext i8 @mult(i8 zeroext %5195, i8 zeroext %5196)
  %conv29.27.9 = zext i8 %call28.27.9 to i32
  %xor.27.9 = xor i32 %conv23.27.9, %conv29.27.9
  %scevgep35.27.9 = getelementptr i8, i8* %a, i64 37
  %5197 = load i8, i8* %scevgep35.27.9, align 1
  %5198 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.9 = call zeroext i8 @mult(i8 zeroext %5197, i8 zeroext %5198)
  %conv35.27.9 = zext i8 %call34.27.9 to i32
  %xor36.27.9 = xor i32 %xor.27.9, %conv35.27.9
  %conv37.27.9 = trunc i32 %xor36.27.9 to i8
  store i8 %conv37.27.9, i8* %scevgep41.27.8, align 1
  %scevgep28.27.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5192, i64 0, i64 0, i64 1
  %5199 = bitcast i8* %scevgep28.27.9 to [41 x [41 x i8]]*
  %scevgep41.27.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5193, i64 0, i64 1, i64 0
  %5200 = bitcast i8* %scevgep41.27.9 to [41 x [41 x i8]]*
  %call16.27.10 = call zeroext i8 (...) @rand()
  store i8 %call16.27.10, i8* %scevgep28.27.9, align 1
  %5201 = load i8, i8* %scevgep28.27.9, align 1
  %conv23.27.10 = zext i8 %5201 to i32
  %5202 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.10 = getelementptr i8, i8* %b, i64 38
  %5203 = load i8, i8* %scevgep34.27.10, align 1
  %call28.27.10 = call zeroext i8 @mult(i8 zeroext %5202, i8 zeroext %5203)
  %conv29.27.10 = zext i8 %call28.27.10 to i32
  %xor.27.10 = xor i32 %conv23.27.10, %conv29.27.10
  %scevgep35.27.10 = getelementptr i8, i8* %a, i64 38
  %5204 = load i8, i8* %scevgep35.27.10, align 1
  %5205 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.10 = call zeroext i8 @mult(i8 zeroext %5204, i8 zeroext %5205)
  %conv35.27.10 = zext i8 %call34.27.10 to i32
  %xor36.27.10 = xor i32 %xor.27.10, %conv35.27.10
  %conv37.27.10 = trunc i32 %xor36.27.10 to i8
  store i8 %conv37.27.10, i8* %scevgep41.27.9, align 1
  %scevgep28.27.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5199, i64 0, i64 0, i64 1
  %5206 = bitcast i8* %scevgep28.27.10 to [41 x [41 x i8]]*
  %scevgep41.27.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5200, i64 0, i64 1, i64 0
  %5207 = bitcast i8* %scevgep41.27.10 to [41 x [41 x i8]]*
  %call16.27.11 = call zeroext i8 (...) @rand()
  store i8 %call16.27.11, i8* %scevgep28.27.10, align 1
  %5208 = load i8, i8* %scevgep28.27.10, align 1
  %conv23.27.11 = zext i8 %5208 to i32
  %5209 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.11 = getelementptr i8, i8* %b, i64 39
  %5210 = load i8, i8* %scevgep34.27.11, align 1
  %call28.27.11 = call zeroext i8 @mult(i8 zeroext %5209, i8 zeroext %5210)
  %conv29.27.11 = zext i8 %call28.27.11 to i32
  %xor.27.11 = xor i32 %conv23.27.11, %conv29.27.11
  %scevgep35.27.11 = getelementptr i8, i8* %a, i64 39
  %5211 = load i8, i8* %scevgep35.27.11, align 1
  %5212 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.11 = call zeroext i8 @mult(i8 zeroext %5211, i8 zeroext %5212)
  %conv35.27.11 = zext i8 %call34.27.11 to i32
  %xor36.27.11 = xor i32 %xor.27.11, %conv35.27.11
  %conv37.27.11 = trunc i32 %xor36.27.11 to i8
  store i8 %conv37.27.11, i8* %scevgep41.27.10, align 1
  %scevgep28.27.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5206, i64 0, i64 0, i64 1
  %scevgep41.27.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5207, i64 0, i64 1, i64 0
  %call16.27.12 = call zeroext i8 (...) @rand()
  store i8 %call16.27.12, i8* %scevgep28.27.11, align 1
  %5213 = load i8, i8* %scevgep28.27.11, align 1
  %conv23.27.12 = zext i8 %5213 to i32
  %5214 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.12 = getelementptr i8, i8* %b, i64 40
  %5215 = load i8, i8* %scevgep34.27.12, align 1
  %call28.27.12 = call zeroext i8 @mult(i8 zeroext %5214, i8 zeroext %5215)
  %conv29.27.12 = zext i8 %call28.27.12 to i32
  %xor.27.12 = xor i32 %conv23.27.12, %conv29.27.12
  %scevgep35.27.12 = getelementptr i8, i8* %a, i64 40
  %5216 = load i8, i8* %scevgep35.27.12, align 1
  %5217 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.12 = call zeroext i8 @mult(i8 zeroext %5216, i8 zeroext %5217)
  %conv35.27.12 = zext i8 %call34.27.12 to i32
  %xor36.27.12 = xor i32 %xor.27.12, %conv35.27.12
  %conv37.27.12 = trunc i32 %xor36.27.12 to i8
  store i8 %conv37.27.12, i8* %scevgep41.27.11, align 1
  %scevgep26.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5129, i64 0, i64 1, i64 1
  %5218 = bitcast i8* %scevgep26.27 to [41 x [41 x i8]]*
  %scevgep39.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5130, i64 0, i64 1, i64 1
  %5219 = bitcast i8* %scevgep39.27 to [41 x [41 x i8]]*
  %arrayidx25.28 = getelementptr inbounds i8, i8* %a, i64 28
  %arrayidx33.28 = getelementptr inbounds i8, i8* %b, i64 28
  %call16.28 = call zeroext i8 (...) @rand()
  store i8 %call16.28, i8* %scevgep26.27, align 1
  %5220 = load i8, i8* %scevgep26.27, align 1
  %conv23.28 = zext i8 %5220 to i32
  %5221 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28 = getelementptr i8, i8* %b, i64 29
  %5222 = load i8, i8* %scevgep34.28, align 1
  %call28.28 = call zeroext i8 @mult(i8 zeroext %5221, i8 zeroext %5222)
  %conv29.28 = zext i8 %call28.28 to i32
  %xor.28 = xor i32 %conv23.28, %conv29.28
  %scevgep35.28 = getelementptr i8, i8* %a, i64 29
  %5223 = load i8, i8* %scevgep35.28, align 1
  %5224 = load i8, i8* %arrayidx33.28, align 1
  %call34.28 = call zeroext i8 @mult(i8 zeroext %5223, i8 zeroext %5224)
  %conv35.28 = zext i8 %call34.28 to i32
  %xor36.28 = xor i32 %xor.28, %conv35.28
  %conv37.28 = trunc i32 %xor36.28 to i8
  store i8 %conv37.28, i8* %scevgep39.27, align 1
  %scevgep28.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5218, i64 0, i64 0, i64 1
  %5225 = bitcast i8* %scevgep28.28 to [41 x [41 x i8]]*
  %scevgep41.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5219, i64 0, i64 1, i64 0
  %5226 = bitcast i8* %scevgep41.28 to [41 x [41 x i8]]*
  %call16.28.1 = call zeroext i8 (...) @rand()
  store i8 %call16.28.1, i8* %scevgep28.28, align 1
  %5227 = load i8, i8* %scevgep28.28, align 1
  %conv23.28.1 = zext i8 %5227 to i32
  %5228 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.1 = getelementptr i8, i8* %b, i64 30
  %5229 = load i8, i8* %scevgep34.28.1, align 1
  %call28.28.1 = call zeroext i8 @mult(i8 zeroext %5228, i8 zeroext %5229)
  %conv29.28.1 = zext i8 %call28.28.1 to i32
  %xor.28.1 = xor i32 %conv23.28.1, %conv29.28.1
  %scevgep35.28.1 = getelementptr i8, i8* %a, i64 30
  %5230 = load i8, i8* %scevgep35.28.1, align 1
  %5231 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.1 = call zeroext i8 @mult(i8 zeroext %5230, i8 zeroext %5231)
  %conv35.28.1 = zext i8 %call34.28.1 to i32
  %xor36.28.1 = xor i32 %xor.28.1, %conv35.28.1
  %conv37.28.1 = trunc i32 %xor36.28.1 to i8
  store i8 %conv37.28.1, i8* %scevgep41.28, align 1
  %scevgep28.28.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5225, i64 0, i64 0, i64 1
  %5232 = bitcast i8* %scevgep28.28.1 to [41 x [41 x i8]]*
  %scevgep41.28.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5226, i64 0, i64 1, i64 0
  %5233 = bitcast i8* %scevgep41.28.1 to [41 x [41 x i8]]*
  %call16.28.2 = call zeroext i8 (...) @rand()
  store i8 %call16.28.2, i8* %scevgep28.28.1, align 1
  %5234 = load i8, i8* %scevgep28.28.1, align 1
  %conv23.28.2 = zext i8 %5234 to i32
  %5235 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.2 = getelementptr i8, i8* %b, i64 31
  %5236 = load i8, i8* %scevgep34.28.2, align 1
  %call28.28.2 = call zeroext i8 @mult(i8 zeroext %5235, i8 zeroext %5236)
  %conv29.28.2 = zext i8 %call28.28.2 to i32
  %xor.28.2 = xor i32 %conv23.28.2, %conv29.28.2
  %scevgep35.28.2 = getelementptr i8, i8* %a, i64 31
  %5237 = load i8, i8* %scevgep35.28.2, align 1
  %5238 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.2 = call zeroext i8 @mult(i8 zeroext %5237, i8 zeroext %5238)
  %conv35.28.2 = zext i8 %call34.28.2 to i32
  %xor36.28.2 = xor i32 %xor.28.2, %conv35.28.2
  %conv37.28.2 = trunc i32 %xor36.28.2 to i8
  store i8 %conv37.28.2, i8* %scevgep41.28.1, align 1
  %scevgep28.28.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5232, i64 0, i64 0, i64 1
  %5239 = bitcast i8* %scevgep28.28.2 to [41 x [41 x i8]]*
  %scevgep41.28.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5233, i64 0, i64 1, i64 0
  %5240 = bitcast i8* %scevgep41.28.2 to [41 x [41 x i8]]*
  %call16.28.3 = call zeroext i8 (...) @rand()
  store i8 %call16.28.3, i8* %scevgep28.28.2, align 1
  %5241 = load i8, i8* %scevgep28.28.2, align 1
  %conv23.28.3 = zext i8 %5241 to i32
  %5242 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.3 = getelementptr i8, i8* %b, i64 32
  %5243 = load i8, i8* %scevgep34.28.3, align 1
  %call28.28.3 = call zeroext i8 @mult(i8 zeroext %5242, i8 zeroext %5243)
  %conv29.28.3 = zext i8 %call28.28.3 to i32
  %xor.28.3 = xor i32 %conv23.28.3, %conv29.28.3
  %scevgep35.28.3 = getelementptr i8, i8* %a, i64 32
  %5244 = load i8, i8* %scevgep35.28.3, align 1
  %5245 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.3 = call zeroext i8 @mult(i8 zeroext %5244, i8 zeroext %5245)
  %conv35.28.3 = zext i8 %call34.28.3 to i32
  %xor36.28.3 = xor i32 %xor.28.3, %conv35.28.3
  %conv37.28.3 = trunc i32 %xor36.28.3 to i8
  store i8 %conv37.28.3, i8* %scevgep41.28.2, align 1
  %scevgep28.28.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5239, i64 0, i64 0, i64 1
  %5246 = bitcast i8* %scevgep28.28.3 to [41 x [41 x i8]]*
  %scevgep41.28.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5240, i64 0, i64 1, i64 0
  %5247 = bitcast i8* %scevgep41.28.3 to [41 x [41 x i8]]*
  %call16.28.4 = call zeroext i8 (...) @rand()
  store i8 %call16.28.4, i8* %scevgep28.28.3, align 1
  %5248 = load i8, i8* %scevgep28.28.3, align 1
  %conv23.28.4 = zext i8 %5248 to i32
  %5249 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.4 = getelementptr i8, i8* %b, i64 33
  %5250 = load i8, i8* %scevgep34.28.4, align 1
  %call28.28.4 = call zeroext i8 @mult(i8 zeroext %5249, i8 zeroext %5250)
  %conv29.28.4 = zext i8 %call28.28.4 to i32
  %xor.28.4 = xor i32 %conv23.28.4, %conv29.28.4
  %scevgep35.28.4 = getelementptr i8, i8* %a, i64 33
  %5251 = load i8, i8* %scevgep35.28.4, align 1
  %5252 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.4 = call zeroext i8 @mult(i8 zeroext %5251, i8 zeroext %5252)
  %conv35.28.4 = zext i8 %call34.28.4 to i32
  %xor36.28.4 = xor i32 %xor.28.4, %conv35.28.4
  %conv37.28.4 = trunc i32 %xor36.28.4 to i8
  store i8 %conv37.28.4, i8* %scevgep41.28.3, align 1
  %scevgep28.28.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5246, i64 0, i64 0, i64 1
  %5253 = bitcast i8* %scevgep28.28.4 to [41 x [41 x i8]]*
  %scevgep41.28.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5247, i64 0, i64 1, i64 0
  %5254 = bitcast i8* %scevgep41.28.4 to [41 x [41 x i8]]*
  %call16.28.5 = call zeroext i8 (...) @rand()
  store i8 %call16.28.5, i8* %scevgep28.28.4, align 1
  %5255 = load i8, i8* %scevgep28.28.4, align 1
  %conv23.28.5 = zext i8 %5255 to i32
  %5256 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.5 = getelementptr i8, i8* %b, i64 34
  %5257 = load i8, i8* %scevgep34.28.5, align 1
  %call28.28.5 = call zeroext i8 @mult(i8 zeroext %5256, i8 zeroext %5257)
  %conv29.28.5 = zext i8 %call28.28.5 to i32
  %xor.28.5 = xor i32 %conv23.28.5, %conv29.28.5
  %scevgep35.28.5 = getelementptr i8, i8* %a, i64 34
  %5258 = load i8, i8* %scevgep35.28.5, align 1
  %5259 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.5 = call zeroext i8 @mult(i8 zeroext %5258, i8 zeroext %5259)
  %conv35.28.5 = zext i8 %call34.28.5 to i32
  %xor36.28.5 = xor i32 %xor.28.5, %conv35.28.5
  %conv37.28.5 = trunc i32 %xor36.28.5 to i8
  store i8 %conv37.28.5, i8* %scevgep41.28.4, align 1
  %scevgep28.28.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5253, i64 0, i64 0, i64 1
  %5260 = bitcast i8* %scevgep28.28.5 to [41 x [41 x i8]]*
  %scevgep41.28.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5254, i64 0, i64 1, i64 0
  %5261 = bitcast i8* %scevgep41.28.5 to [41 x [41 x i8]]*
  %call16.28.6 = call zeroext i8 (...) @rand()
  store i8 %call16.28.6, i8* %scevgep28.28.5, align 1
  %5262 = load i8, i8* %scevgep28.28.5, align 1
  %conv23.28.6 = zext i8 %5262 to i32
  %5263 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.6 = getelementptr i8, i8* %b, i64 35
  %5264 = load i8, i8* %scevgep34.28.6, align 1
  %call28.28.6 = call zeroext i8 @mult(i8 zeroext %5263, i8 zeroext %5264)
  %conv29.28.6 = zext i8 %call28.28.6 to i32
  %xor.28.6 = xor i32 %conv23.28.6, %conv29.28.6
  %scevgep35.28.6 = getelementptr i8, i8* %a, i64 35
  %5265 = load i8, i8* %scevgep35.28.6, align 1
  %5266 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.6 = call zeroext i8 @mult(i8 zeroext %5265, i8 zeroext %5266)
  %conv35.28.6 = zext i8 %call34.28.6 to i32
  %xor36.28.6 = xor i32 %xor.28.6, %conv35.28.6
  %conv37.28.6 = trunc i32 %xor36.28.6 to i8
  store i8 %conv37.28.6, i8* %scevgep41.28.5, align 1
  %scevgep28.28.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5260, i64 0, i64 0, i64 1
  %5267 = bitcast i8* %scevgep28.28.6 to [41 x [41 x i8]]*
  %scevgep41.28.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5261, i64 0, i64 1, i64 0
  %5268 = bitcast i8* %scevgep41.28.6 to [41 x [41 x i8]]*
  %call16.28.7 = call zeroext i8 (...) @rand()
  store i8 %call16.28.7, i8* %scevgep28.28.6, align 1
  %5269 = load i8, i8* %scevgep28.28.6, align 1
  %conv23.28.7 = zext i8 %5269 to i32
  %5270 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.7 = getelementptr i8, i8* %b, i64 36
  %5271 = load i8, i8* %scevgep34.28.7, align 1
  %call28.28.7 = call zeroext i8 @mult(i8 zeroext %5270, i8 zeroext %5271)
  %conv29.28.7 = zext i8 %call28.28.7 to i32
  %xor.28.7 = xor i32 %conv23.28.7, %conv29.28.7
  %scevgep35.28.7 = getelementptr i8, i8* %a, i64 36
  %5272 = load i8, i8* %scevgep35.28.7, align 1
  %5273 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.7 = call zeroext i8 @mult(i8 zeroext %5272, i8 zeroext %5273)
  %conv35.28.7 = zext i8 %call34.28.7 to i32
  %xor36.28.7 = xor i32 %xor.28.7, %conv35.28.7
  %conv37.28.7 = trunc i32 %xor36.28.7 to i8
  store i8 %conv37.28.7, i8* %scevgep41.28.6, align 1
  %scevgep28.28.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5267, i64 0, i64 0, i64 1
  %5274 = bitcast i8* %scevgep28.28.7 to [41 x [41 x i8]]*
  %scevgep41.28.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5268, i64 0, i64 1, i64 0
  %5275 = bitcast i8* %scevgep41.28.7 to [41 x [41 x i8]]*
  %call16.28.8 = call zeroext i8 (...) @rand()
  store i8 %call16.28.8, i8* %scevgep28.28.7, align 1
  %5276 = load i8, i8* %scevgep28.28.7, align 1
  %conv23.28.8 = zext i8 %5276 to i32
  %5277 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.8 = getelementptr i8, i8* %b, i64 37
  %5278 = load i8, i8* %scevgep34.28.8, align 1
  %call28.28.8 = call zeroext i8 @mult(i8 zeroext %5277, i8 zeroext %5278)
  %conv29.28.8 = zext i8 %call28.28.8 to i32
  %xor.28.8 = xor i32 %conv23.28.8, %conv29.28.8
  %scevgep35.28.8 = getelementptr i8, i8* %a, i64 37
  %5279 = load i8, i8* %scevgep35.28.8, align 1
  %5280 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.8 = call zeroext i8 @mult(i8 zeroext %5279, i8 zeroext %5280)
  %conv35.28.8 = zext i8 %call34.28.8 to i32
  %xor36.28.8 = xor i32 %xor.28.8, %conv35.28.8
  %conv37.28.8 = trunc i32 %xor36.28.8 to i8
  store i8 %conv37.28.8, i8* %scevgep41.28.7, align 1
  %scevgep28.28.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5274, i64 0, i64 0, i64 1
  %5281 = bitcast i8* %scevgep28.28.8 to [41 x [41 x i8]]*
  %scevgep41.28.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5275, i64 0, i64 1, i64 0
  %5282 = bitcast i8* %scevgep41.28.8 to [41 x [41 x i8]]*
  %call16.28.9 = call zeroext i8 (...) @rand()
  store i8 %call16.28.9, i8* %scevgep28.28.8, align 1
  %5283 = load i8, i8* %scevgep28.28.8, align 1
  %conv23.28.9 = zext i8 %5283 to i32
  %5284 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.9 = getelementptr i8, i8* %b, i64 38
  %5285 = load i8, i8* %scevgep34.28.9, align 1
  %call28.28.9 = call zeroext i8 @mult(i8 zeroext %5284, i8 zeroext %5285)
  %conv29.28.9 = zext i8 %call28.28.9 to i32
  %xor.28.9 = xor i32 %conv23.28.9, %conv29.28.9
  %scevgep35.28.9 = getelementptr i8, i8* %a, i64 38
  %5286 = load i8, i8* %scevgep35.28.9, align 1
  %5287 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.9 = call zeroext i8 @mult(i8 zeroext %5286, i8 zeroext %5287)
  %conv35.28.9 = zext i8 %call34.28.9 to i32
  %xor36.28.9 = xor i32 %xor.28.9, %conv35.28.9
  %conv37.28.9 = trunc i32 %xor36.28.9 to i8
  store i8 %conv37.28.9, i8* %scevgep41.28.8, align 1
  %scevgep28.28.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5281, i64 0, i64 0, i64 1
  %5288 = bitcast i8* %scevgep28.28.9 to [41 x [41 x i8]]*
  %scevgep41.28.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5282, i64 0, i64 1, i64 0
  %5289 = bitcast i8* %scevgep41.28.9 to [41 x [41 x i8]]*
  %call16.28.10 = call zeroext i8 (...) @rand()
  store i8 %call16.28.10, i8* %scevgep28.28.9, align 1
  %5290 = load i8, i8* %scevgep28.28.9, align 1
  %conv23.28.10 = zext i8 %5290 to i32
  %5291 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.10 = getelementptr i8, i8* %b, i64 39
  %5292 = load i8, i8* %scevgep34.28.10, align 1
  %call28.28.10 = call zeroext i8 @mult(i8 zeroext %5291, i8 zeroext %5292)
  %conv29.28.10 = zext i8 %call28.28.10 to i32
  %xor.28.10 = xor i32 %conv23.28.10, %conv29.28.10
  %scevgep35.28.10 = getelementptr i8, i8* %a, i64 39
  %5293 = load i8, i8* %scevgep35.28.10, align 1
  %5294 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.10 = call zeroext i8 @mult(i8 zeroext %5293, i8 zeroext %5294)
  %conv35.28.10 = zext i8 %call34.28.10 to i32
  %xor36.28.10 = xor i32 %xor.28.10, %conv35.28.10
  %conv37.28.10 = trunc i32 %xor36.28.10 to i8
  store i8 %conv37.28.10, i8* %scevgep41.28.9, align 1
  %scevgep28.28.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5288, i64 0, i64 0, i64 1
  %scevgep41.28.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5289, i64 0, i64 1, i64 0
  %call16.28.11 = call zeroext i8 (...) @rand()
  store i8 %call16.28.11, i8* %scevgep28.28.10, align 1
  %5295 = load i8, i8* %scevgep28.28.10, align 1
  %conv23.28.11 = zext i8 %5295 to i32
  %5296 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.11 = getelementptr i8, i8* %b, i64 40
  %5297 = load i8, i8* %scevgep34.28.11, align 1
  %call28.28.11 = call zeroext i8 @mult(i8 zeroext %5296, i8 zeroext %5297)
  %conv29.28.11 = zext i8 %call28.28.11 to i32
  %xor.28.11 = xor i32 %conv23.28.11, %conv29.28.11
  %scevgep35.28.11 = getelementptr i8, i8* %a, i64 40
  %5298 = load i8, i8* %scevgep35.28.11, align 1
  %5299 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.11 = call zeroext i8 @mult(i8 zeroext %5298, i8 zeroext %5299)
  %conv35.28.11 = zext i8 %call34.28.11 to i32
  %xor36.28.11 = xor i32 %xor.28.11, %conv35.28.11
  %conv37.28.11 = trunc i32 %xor36.28.11 to i8
  store i8 %conv37.28.11, i8* %scevgep41.28.10, align 1
  %scevgep26.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5218, i64 0, i64 1, i64 1
  %5300 = bitcast i8* %scevgep26.28 to [41 x [41 x i8]]*
  %scevgep39.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5219, i64 0, i64 1, i64 1
  %5301 = bitcast i8* %scevgep39.28 to [41 x [41 x i8]]*
  %arrayidx25.29 = getelementptr inbounds i8, i8* %a, i64 29
  %arrayidx33.29 = getelementptr inbounds i8, i8* %b, i64 29
  %call16.29 = call zeroext i8 (...) @rand()
  store i8 %call16.29, i8* %scevgep26.28, align 1
  %5302 = load i8, i8* %scevgep26.28, align 1
  %conv23.29 = zext i8 %5302 to i32
  %5303 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29 = getelementptr i8, i8* %b, i64 30
  %5304 = load i8, i8* %scevgep34.29, align 1
  %call28.29 = call zeroext i8 @mult(i8 zeroext %5303, i8 zeroext %5304)
  %conv29.29 = zext i8 %call28.29 to i32
  %xor.29 = xor i32 %conv23.29, %conv29.29
  %scevgep35.29 = getelementptr i8, i8* %a, i64 30
  %5305 = load i8, i8* %scevgep35.29, align 1
  %5306 = load i8, i8* %arrayidx33.29, align 1
  %call34.29 = call zeroext i8 @mult(i8 zeroext %5305, i8 zeroext %5306)
  %conv35.29 = zext i8 %call34.29 to i32
  %xor36.29 = xor i32 %xor.29, %conv35.29
  %conv37.29 = trunc i32 %xor36.29 to i8
  store i8 %conv37.29, i8* %scevgep39.28, align 1
  %scevgep28.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5300, i64 0, i64 0, i64 1
  %5307 = bitcast i8* %scevgep28.29 to [41 x [41 x i8]]*
  %scevgep41.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5301, i64 0, i64 1, i64 0
  %5308 = bitcast i8* %scevgep41.29 to [41 x [41 x i8]]*
  %call16.29.1 = call zeroext i8 (...) @rand()
  store i8 %call16.29.1, i8* %scevgep28.29, align 1
  %5309 = load i8, i8* %scevgep28.29, align 1
  %conv23.29.1 = zext i8 %5309 to i32
  %5310 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.1 = getelementptr i8, i8* %b, i64 31
  %5311 = load i8, i8* %scevgep34.29.1, align 1
  %call28.29.1 = call zeroext i8 @mult(i8 zeroext %5310, i8 zeroext %5311)
  %conv29.29.1 = zext i8 %call28.29.1 to i32
  %xor.29.1 = xor i32 %conv23.29.1, %conv29.29.1
  %scevgep35.29.1 = getelementptr i8, i8* %a, i64 31
  %5312 = load i8, i8* %scevgep35.29.1, align 1
  %5313 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.1 = call zeroext i8 @mult(i8 zeroext %5312, i8 zeroext %5313)
  %conv35.29.1 = zext i8 %call34.29.1 to i32
  %xor36.29.1 = xor i32 %xor.29.1, %conv35.29.1
  %conv37.29.1 = trunc i32 %xor36.29.1 to i8
  store i8 %conv37.29.1, i8* %scevgep41.29, align 1
  %scevgep28.29.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5307, i64 0, i64 0, i64 1
  %5314 = bitcast i8* %scevgep28.29.1 to [41 x [41 x i8]]*
  %scevgep41.29.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5308, i64 0, i64 1, i64 0
  %5315 = bitcast i8* %scevgep41.29.1 to [41 x [41 x i8]]*
  %call16.29.2 = call zeroext i8 (...) @rand()
  store i8 %call16.29.2, i8* %scevgep28.29.1, align 1
  %5316 = load i8, i8* %scevgep28.29.1, align 1
  %conv23.29.2 = zext i8 %5316 to i32
  %5317 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.2 = getelementptr i8, i8* %b, i64 32
  %5318 = load i8, i8* %scevgep34.29.2, align 1
  %call28.29.2 = call zeroext i8 @mult(i8 zeroext %5317, i8 zeroext %5318)
  %conv29.29.2 = zext i8 %call28.29.2 to i32
  %xor.29.2 = xor i32 %conv23.29.2, %conv29.29.2
  %scevgep35.29.2 = getelementptr i8, i8* %a, i64 32
  %5319 = load i8, i8* %scevgep35.29.2, align 1
  %5320 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.2 = call zeroext i8 @mult(i8 zeroext %5319, i8 zeroext %5320)
  %conv35.29.2 = zext i8 %call34.29.2 to i32
  %xor36.29.2 = xor i32 %xor.29.2, %conv35.29.2
  %conv37.29.2 = trunc i32 %xor36.29.2 to i8
  store i8 %conv37.29.2, i8* %scevgep41.29.1, align 1
  %scevgep28.29.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5314, i64 0, i64 0, i64 1
  %5321 = bitcast i8* %scevgep28.29.2 to [41 x [41 x i8]]*
  %scevgep41.29.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5315, i64 0, i64 1, i64 0
  %5322 = bitcast i8* %scevgep41.29.2 to [41 x [41 x i8]]*
  %call16.29.3 = call zeroext i8 (...) @rand()
  store i8 %call16.29.3, i8* %scevgep28.29.2, align 1
  %5323 = load i8, i8* %scevgep28.29.2, align 1
  %conv23.29.3 = zext i8 %5323 to i32
  %5324 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.3 = getelementptr i8, i8* %b, i64 33
  %5325 = load i8, i8* %scevgep34.29.3, align 1
  %call28.29.3 = call zeroext i8 @mult(i8 zeroext %5324, i8 zeroext %5325)
  %conv29.29.3 = zext i8 %call28.29.3 to i32
  %xor.29.3 = xor i32 %conv23.29.3, %conv29.29.3
  %scevgep35.29.3 = getelementptr i8, i8* %a, i64 33
  %5326 = load i8, i8* %scevgep35.29.3, align 1
  %5327 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.3 = call zeroext i8 @mult(i8 zeroext %5326, i8 zeroext %5327)
  %conv35.29.3 = zext i8 %call34.29.3 to i32
  %xor36.29.3 = xor i32 %xor.29.3, %conv35.29.3
  %conv37.29.3 = trunc i32 %xor36.29.3 to i8
  store i8 %conv37.29.3, i8* %scevgep41.29.2, align 1
  %scevgep28.29.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5321, i64 0, i64 0, i64 1
  %5328 = bitcast i8* %scevgep28.29.3 to [41 x [41 x i8]]*
  %scevgep41.29.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5322, i64 0, i64 1, i64 0
  %5329 = bitcast i8* %scevgep41.29.3 to [41 x [41 x i8]]*
  %call16.29.4 = call zeroext i8 (...) @rand()
  store i8 %call16.29.4, i8* %scevgep28.29.3, align 1
  %5330 = load i8, i8* %scevgep28.29.3, align 1
  %conv23.29.4 = zext i8 %5330 to i32
  %5331 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.4 = getelementptr i8, i8* %b, i64 34
  %5332 = load i8, i8* %scevgep34.29.4, align 1
  %call28.29.4 = call zeroext i8 @mult(i8 zeroext %5331, i8 zeroext %5332)
  %conv29.29.4 = zext i8 %call28.29.4 to i32
  %xor.29.4 = xor i32 %conv23.29.4, %conv29.29.4
  %scevgep35.29.4 = getelementptr i8, i8* %a, i64 34
  %5333 = load i8, i8* %scevgep35.29.4, align 1
  %5334 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.4 = call zeroext i8 @mult(i8 zeroext %5333, i8 zeroext %5334)
  %conv35.29.4 = zext i8 %call34.29.4 to i32
  %xor36.29.4 = xor i32 %xor.29.4, %conv35.29.4
  %conv37.29.4 = trunc i32 %xor36.29.4 to i8
  store i8 %conv37.29.4, i8* %scevgep41.29.3, align 1
  %scevgep28.29.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5328, i64 0, i64 0, i64 1
  %5335 = bitcast i8* %scevgep28.29.4 to [41 x [41 x i8]]*
  %scevgep41.29.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5329, i64 0, i64 1, i64 0
  %5336 = bitcast i8* %scevgep41.29.4 to [41 x [41 x i8]]*
  %call16.29.5 = call zeroext i8 (...) @rand()
  store i8 %call16.29.5, i8* %scevgep28.29.4, align 1
  %5337 = load i8, i8* %scevgep28.29.4, align 1
  %conv23.29.5 = zext i8 %5337 to i32
  %5338 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.5 = getelementptr i8, i8* %b, i64 35
  %5339 = load i8, i8* %scevgep34.29.5, align 1
  %call28.29.5 = call zeroext i8 @mult(i8 zeroext %5338, i8 zeroext %5339)
  %conv29.29.5 = zext i8 %call28.29.5 to i32
  %xor.29.5 = xor i32 %conv23.29.5, %conv29.29.5
  %scevgep35.29.5 = getelementptr i8, i8* %a, i64 35
  %5340 = load i8, i8* %scevgep35.29.5, align 1
  %5341 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.5 = call zeroext i8 @mult(i8 zeroext %5340, i8 zeroext %5341)
  %conv35.29.5 = zext i8 %call34.29.5 to i32
  %xor36.29.5 = xor i32 %xor.29.5, %conv35.29.5
  %conv37.29.5 = trunc i32 %xor36.29.5 to i8
  store i8 %conv37.29.5, i8* %scevgep41.29.4, align 1
  %scevgep28.29.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5335, i64 0, i64 0, i64 1
  %5342 = bitcast i8* %scevgep28.29.5 to [41 x [41 x i8]]*
  %scevgep41.29.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5336, i64 0, i64 1, i64 0
  %5343 = bitcast i8* %scevgep41.29.5 to [41 x [41 x i8]]*
  %call16.29.6 = call zeroext i8 (...) @rand()
  store i8 %call16.29.6, i8* %scevgep28.29.5, align 1
  %5344 = load i8, i8* %scevgep28.29.5, align 1
  %conv23.29.6 = zext i8 %5344 to i32
  %5345 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.6 = getelementptr i8, i8* %b, i64 36
  %5346 = load i8, i8* %scevgep34.29.6, align 1
  %call28.29.6 = call zeroext i8 @mult(i8 zeroext %5345, i8 zeroext %5346)
  %conv29.29.6 = zext i8 %call28.29.6 to i32
  %xor.29.6 = xor i32 %conv23.29.6, %conv29.29.6
  %scevgep35.29.6 = getelementptr i8, i8* %a, i64 36
  %5347 = load i8, i8* %scevgep35.29.6, align 1
  %5348 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.6 = call zeroext i8 @mult(i8 zeroext %5347, i8 zeroext %5348)
  %conv35.29.6 = zext i8 %call34.29.6 to i32
  %xor36.29.6 = xor i32 %xor.29.6, %conv35.29.6
  %conv37.29.6 = trunc i32 %xor36.29.6 to i8
  store i8 %conv37.29.6, i8* %scevgep41.29.5, align 1
  %scevgep28.29.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5342, i64 0, i64 0, i64 1
  %5349 = bitcast i8* %scevgep28.29.6 to [41 x [41 x i8]]*
  %scevgep41.29.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5343, i64 0, i64 1, i64 0
  %5350 = bitcast i8* %scevgep41.29.6 to [41 x [41 x i8]]*
  %call16.29.7 = call zeroext i8 (...) @rand()
  store i8 %call16.29.7, i8* %scevgep28.29.6, align 1
  %5351 = load i8, i8* %scevgep28.29.6, align 1
  %conv23.29.7 = zext i8 %5351 to i32
  %5352 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.7 = getelementptr i8, i8* %b, i64 37
  %5353 = load i8, i8* %scevgep34.29.7, align 1
  %call28.29.7 = call zeroext i8 @mult(i8 zeroext %5352, i8 zeroext %5353)
  %conv29.29.7 = zext i8 %call28.29.7 to i32
  %xor.29.7 = xor i32 %conv23.29.7, %conv29.29.7
  %scevgep35.29.7 = getelementptr i8, i8* %a, i64 37
  %5354 = load i8, i8* %scevgep35.29.7, align 1
  %5355 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.7 = call zeroext i8 @mult(i8 zeroext %5354, i8 zeroext %5355)
  %conv35.29.7 = zext i8 %call34.29.7 to i32
  %xor36.29.7 = xor i32 %xor.29.7, %conv35.29.7
  %conv37.29.7 = trunc i32 %xor36.29.7 to i8
  store i8 %conv37.29.7, i8* %scevgep41.29.6, align 1
  %scevgep28.29.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5349, i64 0, i64 0, i64 1
  %5356 = bitcast i8* %scevgep28.29.7 to [41 x [41 x i8]]*
  %scevgep41.29.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5350, i64 0, i64 1, i64 0
  %5357 = bitcast i8* %scevgep41.29.7 to [41 x [41 x i8]]*
  %call16.29.8 = call zeroext i8 (...) @rand()
  store i8 %call16.29.8, i8* %scevgep28.29.7, align 1
  %5358 = load i8, i8* %scevgep28.29.7, align 1
  %conv23.29.8 = zext i8 %5358 to i32
  %5359 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.8 = getelementptr i8, i8* %b, i64 38
  %5360 = load i8, i8* %scevgep34.29.8, align 1
  %call28.29.8 = call zeroext i8 @mult(i8 zeroext %5359, i8 zeroext %5360)
  %conv29.29.8 = zext i8 %call28.29.8 to i32
  %xor.29.8 = xor i32 %conv23.29.8, %conv29.29.8
  %scevgep35.29.8 = getelementptr i8, i8* %a, i64 38
  %5361 = load i8, i8* %scevgep35.29.8, align 1
  %5362 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.8 = call zeroext i8 @mult(i8 zeroext %5361, i8 zeroext %5362)
  %conv35.29.8 = zext i8 %call34.29.8 to i32
  %xor36.29.8 = xor i32 %xor.29.8, %conv35.29.8
  %conv37.29.8 = trunc i32 %xor36.29.8 to i8
  store i8 %conv37.29.8, i8* %scevgep41.29.7, align 1
  %scevgep28.29.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5356, i64 0, i64 0, i64 1
  %5363 = bitcast i8* %scevgep28.29.8 to [41 x [41 x i8]]*
  %scevgep41.29.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5357, i64 0, i64 1, i64 0
  %5364 = bitcast i8* %scevgep41.29.8 to [41 x [41 x i8]]*
  %call16.29.9 = call zeroext i8 (...) @rand()
  store i8 %call16.29.9, i8* %scevgep28.29.8, align 1
  %5365 = load i8, i8* %scevgep28.29.8, align 1
  %conv23.29.9 = zext i8 %5365 to i32
  %5366 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.9 = getelementptr i8, i8* %b, i64 39
  %5367 = load i8, i8* %scevgep34.29.9, align 1
  %call28.29.9 = call zeroext i8 @mult(i8 zeroext %5366, i8 zeroext %5367)
  %conv29.29.9 = zext i8 %call28.29.9 to i32
  %xor.29.9 = xor i32 %conv23.29.9, %conv29.29.9
  %scevgep35.29.9 = getelementptr i8, i8* %a, i64 39
  %5368 = load i8, i8* %scevgep35.29.9, align 1
  %5369 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.9 = call zeroext i8 @mult(i8 zeroext %5368, i8 zeroext %5369)
  %conv35.29.9 = zext i8 %call34.29.9 to i32
  %xor36.29.9 = xor i32 %xor.29.9, %conv35.29.9
  %conv37.29.9 = trunc i32 %xor36.29.9 to i8
  store i8 %conv37.29.9, i8* %scevgep41.29.8, align 1
  %scevgep28.29.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5363, i64 0, i64 0, i64 1
  %scevgep41.29.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5364, i64 0, i64 1, i64 0
  %call16.29.10 = call zeroext i8 (...) @rand()
  store i8 %call16.29.10, i8* %scevgep28.29.9, align 1
  %5370 = load i8, i8* %scevgep28.29.9, align 1
  %conv23.29.10 = zext i8 %5370 to i32
  %5371 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.10 = getelementptr i8, i8* %b, i64 40
  %5372 = load i8, i8* %scevgep34.29.10, align 1
  %call28.29.10 = call zeroext i8 @mult(i8 zeroext %5371, i8 zeroext %5372)
  %conv29.29.10 = zext i8 %call28.29.10 to i32
  %xor.29.10 = xor i32 %conv23.29.10, %conv29.29.10
  %scevgep35.29.10 = getelementptr i8, i8* %a, i64 40
  %5373 = load i8, i8* %scevgep35.29.10, align 1
  %5374 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.10 = call zeroext i8 @mult(i8 zeroext %5373, i8 zeroext %5374)
  %conv35.29.10 = zext i8 %call34.29.10 to i32
  %xor36.29.10 = xor i32 %xor.29.10, %conv35.29.10
  %conv37.29.10 = trunc i32 %xor36.29.10 to i8
  store i8 %conv37.29.10, i8* %scevgep41.29.9, align 1
  %scevgep26.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5300, i64 0, i64 1, i64 1
  %5375 = bitcast i8* %scevgep26.29 to [41 x [41 x i8]]*
  %scevgep39.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5301, i64 0, i64 1, i64 1
  %5376 = bitcast i8* %scevgep39.29 to [41 x [41 x i8]]*
  %arrayidx25.30 = getelementptr inbounds i8, i8* %a, i64 30
  %arrayidx33.30 = getelementptr inbounds i8, i8* %b, i64 30
  %call16.30 = call zeroext i8 (...) @rand()
  store i8 %call16.30, i8* %scevgep26.29, align 1
  %5377 = load i8, i8* %scevgep26.29, align 1
  %conv23.30 = zext i8 %5377 to i32
  %5378 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30 = getelementptr i8, i8* %b, i64 31
  %5379 = load i8, i8* %scevgep34.30, align 1
  %call28.30 = call zeroext i8 @mult(i8 zeroext %5378, i8 zeroext %5379)
  %conv29.30 = zext i8 %call28.30 to i32
  %xor.30 = xor i32 %conv23.30, %conv29.30
  %scevgep35.30 = getelementptr i8, i8* %a, i64 31
  %5380 = load i8, i8* %scevgep35.30, align 1
  %5381 = load i8, i8* %arrayidx33.30, align 1
  %call34.30 = call zeroext i8 @mult(i8 zeroext %5380, i8 zeroext %5381)
  %conv35.30 = zext i8 %call34.30 to i32
  %xor36.30 = xor i32 %xor.30, %conv35.30
  %conv37.30 = trunc i32 %xor36.30 to i8
  store i8 %conv37.30, i8* %scevgep39.29, align 1
  %scevgep28.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5375, i64 0, i64 0, i64 1
  %5382 = bitcast i8* %scevgep28.30 to [41 x [41 x i8]]*
  %scevgep41.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5376, i64 0, i64 1, i64 0
  %5383 = bitcast i8* %scevgep41.30 to [41 x [41 x i8]]*
  %call16.30.1 = call zeroext i8 (...) @rand()
  store i8 %call16.30.1, i8* %scevgep28.30, align 1
  %5384 = load i8, i8* %scevgep28.30, align 1
  %conv23.30.1 = zext i8 %5384 to i32
  %5385 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.1 = getelementptr i8, i8* %b, i64 32
  %5386 = load i8, i8* %scevgep34.30.1, align 1
  %call28.30.1 = call zeroext i8 @mult(i8 zeroext %5385, i8 zeroext %5386)
  %conv29.30.1 = zext i8 %call28.30.1 to i32
  %xor.30.1 = xor i32 %conv23.30.1, %conv29.30.1
  %scevgep35.30.1 = getelementptr i8, i8* %a, i64 32
  %5387 = load i8, i8* %scevgep35.30.1, align 1
  %5388 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.1 = call zeroext i8 @mult(i8 zeroext %5387, i8 zeroext %5388)
  %conv35.30.1 = zext i8 %call34.30.1 to i32
  %xor36.30.1 = xor i32 %xor.30.1, %conv35.30.1
  %conv37.30.1 = trunc i32 %xor36.30.1 to i8
  store i8 %conv37.30.1, i8* %scevgep41.30, align 1
  %scevgep28.30.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5382, i64 0, i64 0, i64 1
  %5389 = bitcast i8* %scevgep28.30.1 to [41 x [41 x i8]]*
  %scevgep41.30.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5383, i64 0, i64 1, i64 0
  %5390 = bitcast i8* %scevgep41.30.1 to [41 x [41 x i8]]*
  %call16.30.2 = call zeroext i8 (...) @rand()
  store i8 %call16.30.2, i8* %scevgep28.30.1, align 1
  %5391 = load i8, i8* %scevgep28.30.1, align 1
  %conv23.30.2 = zext i8 %5391 to i32
  %5392 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.2 = getelementptr i8, i8* %b, i64 33
  %5393 = load i8, i8* %scevgep34.30.2, align 1
  %call28.30.2 = call zeroext i8 @mult(i8 zeroext %5392, i8 zeroext %5393)
  %conv29.30.2 = zext i8 %call28.30.2 to i32
  %xor.30.2 = xor i32 %conv23.30.2, %conv29.30.2
  %scevgep35.30.2 = getelementptr i8, i8* %a, i64 33
  %5394 = load i8, i8* %scevgep35.30.2, align 1
  %5395 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.2 = call zeroext i8 @mult(i8 zeroext %5394, i8 zeroext %5395)
  %conv35.30.2 = zext i8 %call34.30.2 to i32
  %xor36.30.2 = xor i32 %xor.30.2, %conv35.30.2
  %conv37.30.2 = trunc i32 %xor36.30.2 to i8
  store i8 %conv37.30.2, i8* %scevgep41.30.1, align 1
  %scevgep28.30.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5389, i64 0, i64 0, i64 1
  %5396 = bitcast i8* %scevgep28.30.2 to [41 x [41 x i8]]*
  %scevgep41.30.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5390, i64 0, i64 1, i64 0
  %5397 = bitcast i8* %scevgep41.30.2 to [41 x [41 x i8]]*
  %call16.30.3 = call zeroext i8 (...) @rand()
  store i8 %call16.30.3, i8* %scevgep28.30.2, align 1
  %5398 = load i8, i8* %scevgep28.30.2, align 1
  %conv23.30.3 = zext i8 %5398 to i32
  %5399 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.3 = getelementptr i8, i8* %b, i64 34
  %5400 = load i8, i8* %scevgep34.30.3, align 1
  %call28.30.3 = call zeroext i8 @mult(i8 zeroext %5399, i8 zeroext %5400)
  %conv29.30.3 = zext i8 %call28.30.3 to i32
  %xor.30.3 = xor i32 %conv23.30.3, %conv29.30.3
  %scevgep35.30.3 = getelementptr i8, i8* %a, i64 34
  %5401 = load i8, i8* %scevgep35.30.3, align 1
  %5402 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.3 = call zeroext i8 @mult(i8 zeroext %5401, i8 zeroext %5402)
  %conv35.30.3 = zext i8 %call34.30.3 to i32
  %xor36.30.3 = xor i32 %xor.30.3, %conv35.30.3
  %conv37.30.3 = trunc i32 %xor36.30.3 to i8
  store i8 %conv37.30.3, i8* %scevgep41.30.2, align 1
  %scevgep28.30.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5396, i64 0, i64 0, i64 1
  %5403 = bitcast i8* %scevgep28.30.3 to [41 x [41 x i8]]*
  %scevgep41.30.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5397, i64 0, i64 1, i64 0
  %5404 = bitcast i8* %scevgep41.30.3 to [41 x [41 x i8]]*
  %call16.30.4 = call zeroext i8 (...) @rand()
  store i8 %call16.30.4, i8* %scevgep28.30.3, align 1
  %5405 = load i8, i8* %scevgep28.30.3, align 1
  %conv23.30.4 = zext i8 %5405 to i32
  %5406 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.4 = getelementptr i8, i8* %b, i64 35
  %5407 = load i8, i8* %scevgep34.30.4, align 1
  %call28.30.4 = call zeroext i8 @mult(i8 zeroext %5406, i8 zeroext %5407)
  %conv29.30.4 = zext i8 %call28.30.4 to i32
  %xor.30.4 = xor i32 %conv23.30.4, %conv29.30.4
  %scevgep35.30.4 = getelementptr i8, i8* %a, i64 35
  %5408 = load i8, i8* %scevgep35.30.4, align 1
  %5409 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.4 = call zeroext i8 @mult(i8 zeroext %5408, i8 zeroext %5409)
  %conv35.30.4 = zext i8 %call34.30.4 to i32
  %xor36.30.4 = xor i32 %xor.30.4, %conv35.30.4
  %conv37.30.4 = trunc i32 %xor36.30.4 to i8
  store i8 %conv37.30.4, i8* %scevgep41.30.3, align 1
  %scevgep28.30.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5403, i64 0, i64 0, i64 1
  %5410 = bitcast i8* %scevgep28.30.4 to [41 x [41 x i8]]*
  %scevgep41.30.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5404, i64 0, i64 1, i64 0
  %5411 = bitcast i8* %scevgep41.30.4 to [41 x [41 x i8]]*
  %call16.30.5 = call zeroext i8 (...) @rand()
  store i8 %call16.30.5, i8* %scevgep28.30.4, align 1
  %5412 = load i8, i8* %scevgep28.30.4, align 1
  %conv23.30.5 = zext i8 %5412 to i32
  %5413 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.5 = getelementptr i8, i8* %b, i64 36
  %5414 = load i8, i8* %scevgep34.30.5, align 1
  %call28.30.5 = call zeroext i8 @mult(i8 zeroext %5413, i8 zeroext %5414)
  %conv29.30.5 = zext i8 %call28.30.5 to i32
  %xor.30.5 = xor i32 %conv23.30.5, %conv29.30.5
  %scevgep35.30.5 = getelementptr i8, i8* %a, i64 36
  %5415 = load i8, i8* %scevgep35.30.5, align 1
  %5416 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.5 = call zeroext i8 @mult(i8 zeroext %5415, i8 zeroext %5416)
  %conv35.30.5 = zext i8 %call34.30.5 to i32
  %xor36.30.5 = xor i32 %xor.30.5, %conv35.30.5
  %conv37.30.5 = trunc i32 %xor36.30.5 to i8
  store i8 %conv37.30.5, i8* %scevgep41.30.4, align 1
  %scevgep28.30.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5410, i64 0, i64 0, i64 1
  %5417 = bitcast i8* %scevgep28.30.5 to [41 x [41 x i8]]*
  %scevgep41.30.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5411, i64 0, i64 1, i64 0
  %5418 = bitcast i8* %scevgep41.30.5 to [41 x [41 x i8]]*
  %call16.30.6 = call zeroext i8 (...) @rand()
  store i8 %call16.30.6, i8* %scevgep28.30.5, align 1
  %5419 = load i8, i8* %scevgep28.30.5, align 1
  %conv23.30.6 = zext i8 %5419 to i32
  %5420 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.6 = getelementptr i8, i8* %b, i64 37
  %5421 = load i8, i8* %scevgep34.30.6, align 1
  %call28.30.6 = call zeroext i8 @mult(i8 zeroext %5420, i8 zeroext %5421)
  %conv29.30.6 = zext i8 %call28.30.6 to i32
  %xor.30.6 = xor i32 %conv23.30.6, %conv29.30.6
  %scevgep35.30.6 = getelementptr i8, i8* %a, i64 37
  %5422 = load i8, i8* %scevgep35.30.6, align 1
  %5423 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.6 = call zeroext i8 @mult(i8 zeroext %5422, i8 zeroext %5423)
  %conv35.30.6 = zext i8 %call34.30.6 to i32
  %xor36.30.6 = xor i32 %xor.30.6, %conv35.30.6
  %conv37.30.6 = trunc i32 %xor36.30.6 to i8
  store i8 %conv37.30.6, i8* %scevgep41.30.5, align 1
  %scevgep28.30.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5417, i64 0, i64 0, i64 1
  %5424 = bitcast i8* %scevgep28.30.6 to [41 x [41 x i8]]*
  %scevgep41.30.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5418, i64 0, i64 1, i64 0
  %5425 = bitcast i8* %scevgep41.30.6 to [41 x [41 x i8]]*
  %call16.30.7 = call zeroext i8 (...) @rand()
  store i8 %call16.30.7, i8* %scevgep28.30.6, align 1
  %5426 = load i8, i8* %scevgep28.30.6, align 1
  %conv23.30.7 = zext i8 %5426 to i32
  %5427 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.7 = getelementptr i8, i8* %b, i64 38
  %5428 = load i8, i8* %scevgep34.30.7, align 1
  %call28.30.7 = call zeroext i8 @mult(i8 zeroext %5427, i8 zeroext %5428)
  %conv29.30.7 = zext i8 %call28.30.7 to i32
  %xor.30.7 = xor i32 %conv23.30.7, %conv29.30.7
  %scevgep35.30.7 = getelementptr i8, i8* %a, i64 38
  %5429 = load i8, i8* %scevgep35.30.7, align 1
  %5430 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.7 = call zeroext i8 @mult(i8 zeroext %5429, i8 zeroext %5430)
  %conv35.30.7 = zext i8 %call34.30.7 to i32
  %xor36.30.7 = xor i32 %xor.30.7, %conv35.30.7
  %conv37.30.7 = trunc i32 %xor36.30.7 to i8
  store i8 %conv37.30.7, i8* %scevgep41.30.6, align 1
  %scevgep28.30.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5424, i64 0, i64 0, i64 1
  %5431 = bitcast i8* %scevgep28.30.7 to [41 x [41 x i8]]*
  %scevgep41.30.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5425, i64 0, i64 1, i64 0
  %5432 = bitcast i8* %scevgep41.30.7 to [41 x [41 x i8]]*
  %call16.30.8 = call zeroext i8 (...) @rand()
  store i8 %call16.30.8, i8* %scevgep28.30.7, align 1
  %5433 = load i8, i8* %scevgep28.30.7, align 1
  %conv23.30.8 = zext i8 %5433 to i32
  %5434 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.8 = getelementptr i8, i8* %b, i64 39
  %5435 = load i8, i8* %scevgep34.30.8, align 1
  %call28.30.8 = call zeroext i8 @mult(i8 zeroext %5434, i8 zeroext %5435)
  %conv29.30.8 = zext i8 %call28.30.8 to i32
  %xor.30.8 = xor i32 %conv23.30.8, %conv29.30.8
  %scevgep35.30.8 = getelementptr i8, i8* %a, i64 39
  %5436 = load i8, i8* %scevgep35.30.8, align 1
  %5437 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.8 = call zeroext i8 @mult(i8 zeroext %5436, i8 zeroext %5437)
  %conv35.30.8 = zext i8 %call34.30.8 to i32
  %xor36.30.8 = xor i32 %xor.30.8, %conv35.30.8
  %conv37.30.8 = trunc i32 %xor36.30.8 to i8
  store i8 %conv37.30.8, i8* %scevgep41.30.7, align 1
  %scevgep28.30.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5431, i64 0, i64 0, i64 1
  %scevgep41.30.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5432, i64 0, i64 1, i64 0
  %call16.30.9 = call zeroext i8 (...) @rand()
  store i8 %call16.30.9, i8* %scevgep28.30.8, align 1
  %5438 = load i8, i8* %scevgep28.30.8, align 1
  %conv23.30.9 = zext i8 %5438 to i32
  %5439 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.9 = getelementptr i8, i8* %b, i64 40
  %5440 = load i8, i8* %scevgep34.30.9, align 1
  %call28.30.9 = call zeroext i8 @mult(i8 zeroext %5439, i8 zeroext %5440)
  %conv29.30.9 = zext i8 %call28.30.9 to i32
  %xor.30.9 = xor i32 %conv23.30.9, %conv29.30.9
  %scevgep35.30.9 = getelementptr i8, i8* %a, i64 40
  %5441 = load i8, i8* %scevgep35.30.9, align 1
  %5442 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.9 = call zeroext i8 @mult(i8 zeroext %5441, i8 zeroext %5442)
  %conv35.30.9 = zext i8 %call34.30.9 to i32
  %xor36.30.9 = xor i32 %xor.30.9, %conv35.30.9
  %conv37.30.9 = trunc i32 %xor36.30.9 to i8
  store i8 %conv37.30.9, i8* %scevgep41.30.8, align 1
  %scevgep26.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5375, i64 0, i64 1, i64 1
  %5443 = bitcast i8* %scevgep26.30 to [41 x [41 x i8]]*
  %scevgep39.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5376, i64 0, i64 1, i64 1
  %5444 = bitcast i8* %scevgep39.30 to [41 x [41 x i8]]*
  %arrayidx25.31 = getelementptr inbounds i8, i8* %a, i64 31
  %arrayidx33.31 = getelementptr inbounds i8, i8* %b, i64 31
  %call16.31 = call zeroext i8 (...) @rand()
  store i8 %call16.31, i8* %scevgep26.30, align 1
  %5445 = load i8, i8* %scevgep26.30, align 1
  %conv23.31 = zext i8 %5445 to i32
  %5446 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31 = getelementptr i8, i8* %b, i64 32
  %5447 = load i8, i8* %scevgep34.31, align 1
  %call28.31 = call zeroext i8 @mult(i8 zeroext %5446, i8 zeroext %5447)
  %conv29.31 = zext i8 %call28.31 to i32
  %xor.31 = xor i32 %conv23.31, %conv29.31
  %scevgep35.31 = getelementptr i8, i8* %a, i64 32
  %5448 = load i8, i8* %scevgep35.31, align 1
  %5449 = load i8, i8* %arrayidx33.31, align 1
  %call34.31 = call zeroext i8 @mult(i8 zeroext %5448, i8 zeroext %5449)
  %conv35.31 = zext i8 %call34.31 to i32
  %xor36.31 = xor i32 %xor.31, %conv35.31
  %conv37.31 = trunc i32 %xor36.31 to i8
  store i8 %conv37.31, i8* %scevgep39.30, align 1
  %scevgep28.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5443, i64 0, i64 0, i64 1
  %5450 = bitcast i8* %scevgep28.31 to [41 x [41 x i8]]*
  %scevgep41.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5444, i64 0, i64 1, i64 0
  %5451 = bitcast i8* %scevgep41.31 to [41 x [41 x i8]]*
  %call16.31.1 = call zeroext i8 (...) @rand()
  store i8 %call16.31.1, i8* %scevgep28.31, align 1
  %5452 = load i8, i8* %scevgep28.31, align 1
  %conv23.31.1 = zext i8 %5452 to i32
  %5453 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.1 = getelementptr i8, i8* %b, i64 33
  %5454 = load i8, i8* %scevgep34.31.1, align 1
  %call28.31.1 = call zeroext i8 @mult(i8 zeroext %5453, i8 zeroext %5454)
  %conv29.31.1 = zext i8 %call28.31.1 to i32
  %xor.31.1 = xor i32 %conv23.31.1, %conv29.31.1
  %scevgep35.31.1 = getelementptr i8, i8* %a, i64 33
  %5455 = load i8, i8* %scevgep35.31.1, align 1
  %5456 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.1 = call zeroext i8 @mult(i8 zeroext %5455, i8 zeroext %5456)
  %conv35.31.1 = zext i8 %call34.31.1 to i32
  %xor36.31.1 = xor i32 %xor.31.1, %conv35.31.1
  %conv37.31.1 = trunc i32 %xor36.31.1 to i8
  store i8 %conv37.31.1, i8* %scevgep41.31, align 1
  %scevgep28.31.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5450, i64 0, i64 0, i64 1
  %5457 = bitcast i8* %scevgep28.31.1 to [41 x [41 x i8]]*
  %scevgep41.31.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5451, i64 0, i64 1, i64 0
  %5458 = bitcast i8* %scevgep41.31.1 to [41 x [41 x i8]]*
  %call16.31.2 = call zeroext i8 (...) @rand()
  store i8 %call16.31.2, i8* %scevgep28.31.1, align 1
  %5459 = load i8, i8* %scevgep28.31.1, align 1
  %conv23.31.2 = zext i8 %5459 to i32
  %5460 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.2 = getelementptr i8, i8* %b, i64 34
  %5461 = load i8, i8* %scevgep34.31.2, align 1
  %call28.31.2 = call zeroext i8 @mult(i8 zeroext %5460, i8 zeroext %5461)
  %conv29.31.2 = zext i8 %call28.31.2 to i32
  %xor.31.2 = xor i32 %conv23.31.2, %conv29.31.2
  %scevgep35.31.2 = getelementptr i8, i8* %a, i64 34
  %5462 = load i8, i8* %scevgep35.31.2, align 1
  %5463 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.2 = call zeroext i8 @mult(i8 zeroext %5462, i8 zeroext %5463)
  %conv35.31.2 = zext i8 %call34.31.2 to i32
  %xor36.31.2 = xor i32 %xor.31.2, %conv35.31.2
  %conv37.31.2 = trunc i32 %xor36.31.2 to i8
  store i8 %conv37.31.2, i8* %scevgep41.31.1, align 1
  %scevgep28.31.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5457, i64 0, i64 0, i64 1
  %5464 = bitcast i8* %scevgep28.31.2 to [41 x [41 x i8]]*
  %scevgep41.31.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5458, i64 0, i64 1, i64 0
  %5465 = bitcast i8* %scevgep41.31.2 to [41 x [41 x i8]]*
  %call16.31.3 = call zeroext i8 (...) @rand()
  store i8 %call16.31.3, i8* %scevgep28.31.2, align 1
  %5466 = load i8, i8* %scevgep28.31.2, align 1
  %conv23.31.3 = zext i8 %5466 to i32
  %5467 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.3 = getelementptr i8, i8* %b, i64 35
  %5468 = load i8, i8* %scevgep34.31.3, align 1
  %call28.31.3 = call zeroext i8 @mult(i8 zeroext %5467, i8 zeroext %5468)
  %conv29.31.3 = zext i8 %call28.31.3 to i32
  %xor.31.3 = xor i32 %conv23.31.3, %conv29.31.3
  %scevgep35.31.3 = getelementptr i8, i8* %a, i64 35
  %5469 = load i8, i8* %scevgep35.31.3, align 1
  %5470 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.3 = call zeroext i8 @mult(i8 zeroext %5469, i8 zeroext %5470)
  %conv35.31.3 = zext i8 %call34.31.3 to i32
  %xor36.31.3 = xor i32 %xor.31.3, %conv35.31.3
  %conv37.31.3 = trunc i32 %xor36.31.3 to i8
  store i8 %conv37.31.3, i8* %scevgep41.31.2, align 1
  %scevgep28.31.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5464, i64 0, i64 0, i64 1
  %5471 = bitcast i8* %scevgep28.31.3 to [41 x [41 x i8]]*
  %scevgep41.31.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5465, i64 0, i64 1, i64 0
  %5472 = bitcast i8* %scevgep41.31.3 to [41 x [41 x i8]]*
  %call16.31.4 = call zeroext i8 (...) @rand()
  store i8 %call16.31.4, i8* %scevgep28.31.3, align 1
  %5473 = load i8, i8* %scevgep28.31.3, align 1
  %conv23.31.4 = zext i8 %5473 to i32
  %5474 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.4 = getelementptr i8, i8* %b, i64 36
  %5475 = load i8, i8* %scevgep34.31.4, align 1
  %call28.31.4 = call zeroext i8 @mult(i8 zeroext %5474, i8 zeroext %5475)
  %conv29.31.4 = zext i8 %call28.31.4 to i32
  %xor.31.4 = xor i32 %conv23.31.4, %conv29.31.4
  %scevgep35.31.4 = getelementptr i8, i8* %a, i64 36
  %5476 = load i8, i8* %scevgep35.31.4, align 1
  %5477 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.4 = call zeroext i8 @mult(i8 zeroext %5476, i8 zeroext %5477)
  %conv35.31.4 = zext i8 %call34.31.4 to i32
  %xor36.31.4 = xor i32 %xor.31.4, %conv35.31.4
  %conv37.31.4 = trunc i32 %xor36.31.4 to i8
  store i8 %conv37.31.4, i8* %scevgep41.31.3, align 1
  %scevgep28.31.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5471, i64 0, i64 0, i64 1
  %5478 = bitcast i8* %scevgep28.31.4 to [41 x [41 x i8]]*
  %scevgep41.31.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5472, i64 0, i64 1, i64 0
  %5479 = bitcast i8* %scevgep41.31.4 to [41 x [41 x i8]]*
  %call16.31.5 = call zeroext i8 (...) @rand()
  store i8 %call16.31.5, i8* %scevgep28.31.4, align 1
  %5480 = load i8, i8* %scevgep28.31.4, align 1
  %conv23.31.5 = zext i8 %5480 to i32
  %5481 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.5 = getelementptr i8, i8* %b, i64 37
  %5482 = load i8, i8* %scevgep34.31.5, align 1
  %call28.31.5 = call zeroext i8 @mult(i8 zeroext %5481, i8 zeroext %5482)
  %conv29.31.5 = zext i8 %call28.31.5 to i32
  %xor.31.5 = xor i32 %conv23.31.5, %conv29.31.5
  %scevgep35.31.5 = getelementptr i8, i8* %a, i64 37
  %5483 = load i8, i8* %scevgep35.31.5, align 1
  %5484 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.5 = call zeroext i8 @mult(i8 zeroext %5483, i8 zeroext %5484)
  %conv35.31.5 = zext i8 %call34.31.5 to i32
  %xor36.31.5 = xor i32 %xor.31.5, %conv35.31.5
  %conv37.31.5 = trunc i32 %xor36.31.5 to i8
  store i8 %conv37.31.5, i8* %scevgep41.31.4, align 1
  %scevgep28.31.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5478, i64 0, i64 0, i64 1
  %5485 = bitcast i8* %scevgep28.31.5 to [41 x [41 x i8]]*
  %scevgep41.31.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5479, i64 0, i64 1, i64 0
  %5486 = bitcast i8* %scevgep41.31.5 to [41 x [41 x i8]]*
  %call16.31.6 = call zeroext i8 (...) @rand()
  store i8 %call16.31.6, i8* %scevgep28.31.5, align 1
  %5487 = load i8, i8* %scevgep28.31.5, align 1
  %conv23.31.6 = zext i8 %5487 to i32
  %5488 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.6 = getelementptr i8, i8* %b, i64 38
  %5489 = load i8, i8* %scevgep34.31.6, align 1
  %call28.31.6 = call zeroext i8 @mult(i8 zeroext %5488, i8 zeroext %5489)
  %conv29.31.6 = zext i8 %call28.31.6 to i32
  %xor.31.6 = xor i32 %conv23.31.6, %conv29.31.6
  %scevgep35.31.6 = getelementptr i8, i8* %a, i64 38
  %5490 = load i8, i8* %scevgep35.31.6, align 1
  %5491 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.6 = call zeroext i8 @mult(i8 zeroext %5490, i8 zeroext %5491)
  %conv35.31.6 = zext i8 %call34.31.6 to i32
  %xor36.31.6 = xor i32 %xor.31.6, %conv35.31.6
  %conv37.31.6 = trunc i32 %xor36.31.6 to i8
  store i8 %conv37.31.6, i8* %scevgep41.31.5, align 1
  %scevgep28.31.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5485, i64 0, i64 0, i64 1
  %5492 = bitcast i8* %scevgep28.31.6 to [41 x [41 x i8]]*
  %scevgep41.31.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5486, i64 0, i64 1, i64 0
  %5493 = bitcast i8* %scevgep41.31.6 to [41 x [41 x i8]]*
  %call16.31.7 = call zeroext i8 (...) @rand()
  store i8 %call16.31.7, i8* %scevgep28.31.6, align 1
  %5494 = load i8, i8* %scevgep28.31.6, align 1
  %conv23.31.7 = zext i8 %5494 to i32
  %5495 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.7 = getelementptr i8, i8* %b, i64 39
  %5496 = load i8, i8* %scevgep34.31.7, align 1
  %call28.31.7 = call zeroext i8 @mult(i8 zeroext %5495, i8 zeroext %5496)
  %conv29.31.7 = zext i8 %call28.31.7 to i32
  %xor.31.7 = xor i32 %conv23.31.7, %conv29.31.7
  %scevgep35.31.7 = getelementptr i8, i8* %a, i64 39
  %5497 = load i8, i8* %scevgep35.31.7, align 1
  %5498 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.7 = call zeroext i8 @mult(i8 zeroext %5497, i8 zeroext %5498)
  %conv35.31.7 = zext i8 %call34.31.7 to i32
  %xor36.31.7 = xor i32 %xor.31.7, %conv35.31.7
  %conv37.31.7 = trunc i32 %xor36.31.7 to i8
  store i8 %conv37.31.7, i8* %scevgep41.31.6, align 1
  %scevgep28.31.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5492, i64 0, i64 0, i64 1
  %scevgep41.31.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5493, i64 0, i64 1, i64 0
  %call16.31.8 = call zeroext i8 (...) @rand()
  store i8 %call16.31.8, i8* %scevgep28.31.7, align 1
  %5499 = load i8, i8* %scevgep28.31.7, align 1
  %conv23.31.8 = zext i8 %5499 to i32
  %5500 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.8 = getelementptr i8, i8* %b, i64 40
  %5501 = load i8, i8* %scevgep34.31.8, align 1
  %call28.31.8 = call zeroext i8 @mult(i8 zeroext %5500, i8 zeroext %5501)
  %conv29.31.8 = zext i8 %call28.31.8 to i32
  %xor.31.8 = xor i32 %conv23.31.8, %conv29.31.8
  %scevgep35.31.8 = getelementptr i8, i8* %a, i64 40
  %5502 = load i8, i8* %scevgep35.31.8, align 1
  %5503 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.8 = call zeroext i8 @mult(i8 zeroext %5502, i8 zeroext %5503)
  %conv35.31.8 = zext i8 %call34.31.8 to i32
  %xor36.31.8 = xor i32 %xor.31.8, %conv35.31.8
  %conv37.31.8 = trunc i32 %xor36.31.8 to i8
  store i8 %conv37.31.8, i8* %scevgep41.31.7, align 1
  %scevgep26.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5443, i64 0, i64 1, i64 1
  %5504 = bitcast i8* %scevgep26.31 to [41 x [41 x i8]]*
  %scevgep39.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5444, i64 0, i64 1, i64 1
  %5505 = bitcast i8* %scevgep39.31 to [41 x [41 x i8]]*
  %arrayidx25.32 = getelementptr inbounds i8, i8* %a, i64 32
  %arrayidx33.32 = getelementptr inbounds i8, i8* %b, i64 32
  %call16.32 = call zeroext i8 (...) @rand()
  store i8 %call16.32, i8* %scevgep26.31, align 1
  %5506 = load i8, i8* %scevgep26.31, align 1
  %conv23.32 = zext i8 %5506 to i32
  %5507 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32 = getelementptr i8, i8* %b, i64 33
  %5508 = load i8, i8* %scevgep34.32, align 1
  %call28.32 = call zeroext i8 @mult(i8 zeroext %5507, i8 zeroext %5508)
  %conv29.32 = zext i8 %call28.32 to i32
  %xor.32 = xor i32 %conv23.32, %conv29.32
  %scevgep35.32 = getelementptr i8, i8* %a, i64 33
  %5509 = load i8, i8* %scevgep35.32, align 1
  %5510 = load i8, i8* %arrayidx33.32, align 1
  %call34.32 = call zeroext i8 @mult(i8 zeroext %5509, i8 zeroext %5510)
  %conv35.32 = zext i8 %call34.32 to i32
  %xor36.32 = xor i32 %xor.32, %conv35.32
  %conv37.32 = trunc i32 %xor36.32 to i8
  store i8 %conv37.32, i8* %scevgep39.31, align 1
  %scevgep28.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5504, i64 0, i64 0, i64 1
  %5511 = bitcast i8* %scevgep28.32 to [41 x [41 x i8]]*
  %scevgep41.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5505, i64 0, i64 1, i64 0
  %5512 = bitcast i8* %scevgep41.32 to [41 x [41 x i8]]*
  %call16.32.1 = call zeroext i8 (...) @rand()
  store i8 %call16.32.1, i8* %scevgep28.32, align 1
  %5513 = load i8, i8* %scevgep28.32, align 1
  %conv23.32.1 = zext i8 %5513 to i32
  %5514 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.1 = getelementptr i8, i8* %b, i64 34
  %5515 = load i8, i8* %scevgep34.32.1, align 1
  %call28.32.1 = call zeroext i8 @mult(i8 zeroext %5514, i8 zeroext %5515)
  %conv29.32.1 = zext i8 %call28.32.1 to i32
  %xor.32.1 = xor i32 %conv23.32.1, %conv29.32.1
  %scevgep35.32.1 = getelementptr i8, i8* %a, i64 34
  %5516 = load i8, i8* %scevgep35.32.1, align 1
  %5517 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.1 = call zeroext i8 @mult(i8 zeroext %5516, i8 zeroext %5517)
  %conv35.32.1 = zext i8 %call34.32.1 to i32
  %xor36.32.1 = xor i32 %xor.32.1, %conv35.32.1
  %conv37.32.1 = trunc i32 %xor36.32.1 to i8
  store i8 %conv37.32.1, i8* %scevgep41.32, align 1
  %scevgep28.32.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5511, i64 0, i64 0, i64 1
  %5518 = bitcast i8* %scevgep28.32.1 to [41 x [41 x i8]]*
  %scevgep41.32.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5512, i64 0, i64 1, i64 0
  %5519 = bitcast i8* %scevgep41.32.1 to [41 x [41 x i8]]*
  %call16.32.2 = call zeroext i8 (...) @rand()
  store i8 %call16.32.2, i8* %scevgep28.32.1, align 1
  %5520 = load i8, i8* %scevgep28.32.1, align 1
  %conv23.32.2 = zext i8 %5520 to i32
  %5521 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.2 = getelementptr i8, i8* %b, i64 35
  %5522 = load i8, i8* %scevgep34.32.2, align 1
  %call28.32.2 = call zeroext i8 @mult(i8 zeroext %5521, i8 zeroext %5522)
  %conv29.32.2 = zext i8 %call28.32.2 to i32
  %xor.32.2 = xor i32 %conv23.32.2, %conv29.32.2
  %scevgep35.32.2 = getelementptr i8, i8* %a, i64 35
  %5523 = load i8, i8* %scevgep35.32.2, align 1
  %5524 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.2 = call zeroext i8 @mult(i8 zeroext %5523, i8 zeroext %5524)
  %conv35.32.2 = zext i8 %call34.32.2 to i32
  %xor36.32.2 = xor i32 %xor.32.2, %conv35.32.2
  %conv37.32.2 = trunc i32 %xor36.32.2 to i8
  store i8 %conv37.32.2, i8* %scevgep41.32.1, align 1
  %scevgep28.32.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5518, i64 0, i64 0, i64 1
  %5525 = bitcast i8* %scevgep28.32.2 to [41 x [41 x i8]]*
  %scevgep41.32.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5519, i64 0, i64 1, i64 0
  %5526 = bitcast i8* %scevgep41.32.2 to [41 x [41 x i8]]*
  %call16.32.3 = call zeroext i8 (...) @rand()
  store i8 %call16.32.3, i8* %scevgep28.32.2, align 1
  %5527 = load i8, i8* %scevgep28.32.2, align 1
  %conv23.32.3 = zext i8 %5527 to i32
  %5528 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.3 = getelementptr i8, i8* %b, i64 36
  %5529 = load i8, i8* %scevgep34.32.3, align 1
  %call28.32.3 = call zeroext i8 @mult(i8 zeroext %5528, i8 zeroext %5529)
  %conv29.32.3 = zext i8 %call28.32.3 to i32
  %xor.32.3 = xor i32 %conv23.32.3, %conv29.32.3
  %scevgep35.32.3 = getelementptr i8, i8* %a, i64 36
  %5530 = load i8, i8* %scevgep35.32.3, align 1
  %5531 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.3 = call zeroext i8 @mult(i8 zeroext %5530, i8 zeroext %5531)
  %conv35.32.3 = zext i8 %call34.32.3 to i32
  %xor36.32.3 = xor i32 %xor.32.3, %conv35.32.3
  %conv37.32.3 = trunc i32 %xor36.32.3 to i8
  store i8 %conv37.32.3, i8* %scevgep41.32.2, align 1
  %scevgep28.32.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5525, i64 0, i64 0, i64 1
  %5532 = bitcast i8* %scevgep28.32.3 to [41 x [41 x i8]]*
  %scevgep41.32.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5526, i64 0, i64 1, i64 0
  %5533 = bitcast i8* %scevgep41.32.3 to [41 x [41 x i8]]*
  %call16.32.4 = call zeroext i8 (...) @rand()
  store i8 %call16.32.4, i8* %scevgep28.32.3, align 1
  %5534 = load i8, i8* %scevgep28.32.3, align 1
  %conv23.32.4 = zext i8 %5534 to i32
  %5535 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.4 = getelementptr i8, i8* %b, i64 37
  %5536 = load i8, i8* %scevgep34.32.4, align 1
  %call28.32.4 = call zeroext i8 @mult(i8 zeroext %5535, i8 zeroext %5536)
  %conv29.32.4 = zext i8 %call28.32.4 to i32
  %xor.32.4 = xor i32 %conv23.32.4, %conv29.32.4
  %scevgep35.32.4 = getelementptr i8, i8* %a, i64 37
  %5537 = load i8, i8* %scevgep35.32.4, align 1
  %5538 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.4 = call zeroext i8 @mult(i8 zeroext %5537, i8 zeroext %5538)
  %conv35.32.4 = zext i8 %call34.32.4 to i32
  %xor36.32.4 = xor i32 %xor.32.4, %conv35.32.4
  %conv37.32.4 = trunc i32 %xor36.32.4 to i8
  store i8 %conv37.32.4, i8* %scevgep41.32.3, align 1
  %scevgep28.32.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5532, i64 0, i64 0, i64 1
  %5539 = bitcast i8* %scevgep28.32.4 to [41 x [41 x i8]]*
  %scevgep41.32.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5533, i64 0, i64 1, i64 0
  %5540 = bitcast i8* %scevgep41.32.4 to [41 x [41 x i8]]*
  %call16.32.5 = call zeroext i8 (...) @rand()
  store i8 %call16.32.5, i8* %scevgep28.32.4, align 1
  %5541 = load i8, i8* %scevgep28.32.4, align 1
  %conv23.32.5 = zext i8 %5541 to i32
  %5542 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.5 = getelementptr i8, i8* %b, i64 38
  %5543 = load i8, i8* %scevgep34.32.5, align 1
  %call28.32.5 = call zeroext i8 @mult(i8 zeroext %5542, i8 zeroext %5543)
  %conv29.32.5 = zext i8 %call28.32.5 to i32
  %xor.32.5 = xor i32 %conv23.32.5, %conv29.32.5
  %scevgep35.32.5 = getelementptr i8, i8* %a, i64 38
  %5544 = load i8, i8* %scevgep35.32.5, align 1
  %5545 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.5 = call zeroext i8 @mult(i8 zeroext %5544, i8 zeroext %5545)
  %conv35.32.5 = zext i8 %call34.32.5 to i32
  %xor36.32.5 = xor i32 %xor.32.5, %conv35.32.5
  %conv37.32.5 = trunc i32 %xor36.32.5 to i8
  store i8 %conv37.32.5, i8* %scevgep41.32.4, align 1
  %scevgep28.32.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5539, i64 0, i64 0, i64 1
  %5546 = bitcast i8* %scevgep28.32.5 to [41 x [41 x i8]]*
  %scevgep41.32.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5540, i64 0, i64 1, i64 0
  %5547 = bitcast i8* %scevgep41.32.5 to [41 x [41 x i8]]*
  %call16.32.6 = call zeroext i8 (...) @rand()
  store i8 %call16.32.6, i8* %scevgep28.32.5, align 1
  %5548 = load i8, i8* %scevgep28.32.5, align 1
  %conv23.32.6 = zext i8 %5548 to i32
  %5549 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.6 = getelementptr i8, i8* %b, i64 39
  %5550 = load i8, i8* %scevgep34.32.6, align 1
  %call28.32.6 = call zeroext i8 @mult(i8 zeroext %5549, i8 zeroext %5550)
  %conv29.32.6 = zext i8 %call28.32.6 to i32
  %xor.32.6 = xor i32 %conv23.32.6, %conv29.32.6
  %scevgep35.32.6 = getelementptr i8, i8* %a, i64 39
  %5551 = load i8, i8* %scevgep35.32.6, align 1
  %5552 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.6 = call zeroext i8 @mult(i8 zeroext %5551, i8 zeroext %5552)
  %conv35.32.6 = zext i8 %call34.32.6 to i32
  %xor36.32.6 = xor i32 %xor.32.6, %conv35.32.6
  %conv37.32.6 = trunc i32 %xor36.32.6 to i8
  store i8 %conv37.32.6, i8* %scevgep41.32.5, align 1
  %scevgep28.32.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5546, i64 0, i64 0, i64 1
  %scevgep41.32.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5547, i64 0, i64 1, i64 0
  %call16.32.7 = call zeroext i8 (...) @rand()
  store i8 %call16.32.7, i8* %scevgep28.32.6, align 1
  %5553 = load i8, i8* %scevgep28.32.6, align 1
  %conv23.32.7 = zext i8 %5553 to i32
  %5554 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.7 = getelementptr i8, i8* %b, i64 40
  %5555 = load i8, i8* %scevgep34.32.7, align 1
  %call28.32.7 = call zeroext i8 @mult(i8 zeroext %5554, i8 zeroext %5555)
  %conv29.32.7 = zext i8 %call28.32.7 to i32
  %xor.32.7 = xor i32 %conv23.32.7, %conv29.32.7
  %scevgep35.32.7 = getelementptr i8, i8* %a, i64 40
  %5556 = load i8, i8* %scevgep35.32.7, align 1
  %5557 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.7 = call zeroext i8 @mult(i8 zeroext %5556, i8 zeroext %5557)
  %conv35.32.7 = zext i8 %call34.32.7 to i32
  %xor36.32.7 = xor i32 %xor.32.7, %conv35.32.7
  %conv37.32.7 = trunc i32 %xor36.32.7 to i8
  store i8 %conv37.32.7, i8* %scevgep41.32.6, align 1
  %scevgep26.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5504, i64 0, i64 1, i64 1
  %5558 = bitcast i8* %scevgep26.32 to [41 x [41 x i8]]*
  %scevgep39.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5505, i64 0, i64 1, i64 1
  %5559 = bitcast i8* %scevgep39.32 to [41 x [41 x i8]]*
  %arrayidx25.33 = getelementptr inbounds i8, i8* %a, i64 33
  %arrayidx33.33 = getelementptr inbounds i8, i8* %b, i64 33
  %call16.33 = call zeroext i8 (...) @rand()
  store i8 %call16.33, i8* %scevgep26.32, align 1
  %5560 = load i8, i8* %scevgep26.32, align 1
  %conv23.33 = zext i8 %5560 to i32
  %5561 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33 = getelementptr i8, i8* %b, i64 34
  %5562 = load i8, i8* %scevgep34.33, align 1
  %call28.33 = call zeroext i8 @mult(i8 zeroext %5561, i8 zeroext %5562)
  %conv29.33 = zext i8 %call28.33 to i32
  %xor.33 = xor i32 %conv23.33, %conv29.33
  %scevgep35.33 = getelementptr i8, i8* %a, i64 34
  %5563 = load i8, i8* %scevgep35.33, align 1
  %5564 = load i8, i8* %arrayidx33.33, align 1
  %call34.33 = call zeroext i8 @mult(i8 zeroext %5563, i8 zeroext %5564)
  %conv35.33 = zext i8 %call34.33 to i32
  %xor36.33 = xor i32 %xor.33, %conv35.33
  %conv37.33 = trunc i32 %xor36.33 to i8
  store i8 %conv37.33, i8* %scevgep39.32, align 1
  %scevgep28.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5558, i64 0, i64 0, i64 1
  %5565 = bitcast i8* %scevgep28.33 to [41 x [41 x i8]]*
  %scevgep41.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5559, i64 0, i64 1, i64 0
  %5566 = bitcast i8* %scevgep41.33 to [41 x [41 x i8]]*
  %call16.33.1 = call zeroext i8 (...) @rand()
  store i8 %call16.33.1, i8* %scevgep28.33, align 1
  %5567 = load i8, i8* %scevgep28.33, align 1
  %conv23.33.1 = zext i8 %5567 to i32
  %5568 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.1 = getelementptr i8, i8* %b, i64 35
  %5569 = load i8, i8* %scevgep34.33.1, align 1
  %call28.33.1 = call zeroext i8 @mult(i8 zeroext %5568, i8 zeroext %5569)
  %conv29.33.1 = zext i8 %call28.33.1 to i32
  %xor.33.1 = xor i32 %conv23.33.1, %conv29.33.1
  %scevgep35.33.1 = getelementptr i8, i8* %a, i64 35
  %5570 = load i8, i8* %scevgep35.33.1, align 1
  %5571 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.1 = call zeroext i8 @mult(i8 zeroext %5570, i8 zeroext %5571)
  %conv35.33.1 = zext i8 %call34.33.1 to i32
  %xor36.33.1 = xor i32 %xor.33.1, %conv35.33.1
  %conv37.33.1 = trunc i32 %xor36.33.1 to i8
  store i8 %conv37.33.1, i8* %scevgep41.33, align 1
  %scevgep28.33.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5565, i64 0, i64 0, i64 1
  %5572 = bitcast i8* %scevgep28.33.1 to [41 x [41 x i8]]*
  %scevgep41.33.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5566, i64 0, i64 1, i64 0
  %5573 = bitcast i8* %scevgep41.33.1 to [41 x [41 x i8]]*
  %call16.33.2 = call zeroext i8 (...) @rand()
  store i8 %call16.33.2, i8* %scevgep28.33.1, align 1
  %5574 = load i8, i8* %scevgep28.33.1, align 1
  %conv23.33.2 = zext i8 %5574 to i32
  %5575 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.2 = getelementptr i8, i8* %b, i64 36
  %5576 = load i8, i8* %scevgep34.33.2, align 1
  %call28.33.2 = call zeroext i8 @mult(i8 zeroext %5575, i8 zeroext %5576)
  %conv29.33.2 = zext i8 %call28.33.2 to i32
  %xor.33.2 = xor i32 %conv23.33.2, %conv29.33.2
  %scevgep35.33.2 = getelementptr i8, i8* %a, i64 36
  %5577 = load i8, i8* %scevgep35.33.2, align 1
  %5578 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.2 = call zeroext i8 @mult(i8 zeroext %5577, i8 zeroext %5578)
  %conv35.33.2 = zext i8 %call34.33.2 to i32
  %xor36.33.2 = xor i32 %xor.33.2, %conv35.33.2
  %conv37.33.2 = trunc i32 %xor36.33.2 to i8
  store i8 %conv37.33.2, i8* %scevgep41.33.1, align 1
  %scevgep28.33.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5572, i64 0, i64 0, i64 1
  %5579 = bitcast i8* %scevgep28.33.2 to [41 x [41 x i8]]*
  %scevgep41.33.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5573, i64 0, i64 1, i64 0
  %5580 = bitcast i8* %scevgep41.33.2 to [41 x [41 x i8]]*
  %call16.33.3 = call zeroext i8 (...) @rand()
  store i8 %call16.33.3, i8* %scevgep28.33.2, align 1
  %5581 = load i8, i8* %scevgep28.33.2, align 1
  %conv23.33.3 = zext i8 %5581 to i32
  %5582 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.3 = getelementptr i8, i8* %b, i64 37
  %5583 = load i8, i8* %scevgep34.33.3, align 1
  %call28.33.3 = call zeroext i8 @mult(i8 zeroext %5582, i8 zeroext %5583)
  %conv29.33.3 = zext i8 %call28.33.3 to i32
  %xor.33.3 = xor i32 %conv23.33.3, %conv29.33.3
  %scevgep35.33.3 = getelementptr i8, i8* %a, i64 37
  %5584 = load i8, i8* %scevgep35.33.3, align 1
  %5585 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.3 = call zeroext i8 @mult(i8 zeroext %5584, i8 zeroext %5585)
  %conv35.33.3 = zext i8 %call34.33.3 to i32
  %xor36.33.3 = xor i32 %xor.33.3, %conv35.33.3
  %conv37.33.3 = trunc i32 %xor36.33.3 to i8
  store i8 %conv37.33.3, i8* %scevgep41.33.2, align 1
  %scevgep28.33.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5579, i64 0, i64 0, i64 1
  %5586 = bitcast i8* %scevgep28.33.3 to [41 x [41 x i8]]*
  %scevgep41.33.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5580, i64 0, i64 1, i64 0
  %5587 = bitcast i8* %scevgep41.33.3 to [41 x [41 x i8]]*
  %call16.33.4 = call zeroext i8 (...) @rand()
  store i8 %call16.33.4, i8* %scevgep28.33.3, align 1
  %5588 = load i8, i8* %scevgep28.33.3, align 1
  %conv23.33.4 = zext i8 %5588 to i32
  %5589 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.4 = getelementptr i8, i8* %b, i64 38
  %5590 = load i8, i8* %scevgep34.33.4, align 1
  %call28.33.4 = call zeroext i8 @mult(i8 zeroext %5589, i8 zeroext %5590)
  %conv29.33.4 = zext i8 %call28.33.4 to i32
  %xor.33.4 = xor i32 %conv23.33.4, %conv29.33.4
  %scevgep35.33.4 = getelementptr i8, i8* %a, i64 38
  %5591 = load i8, i8* %scevgep35.33.4, align 1
  %5592 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.4 = call zeroext i8 @mult(i8 zeroext %5591, i8 zeroext %5592)
  %conv35.33.4 = zext i8 %call34.33.4 to i32
  %xor36.33.4 = xor i32 %xor.33.4, %conv35.33.4
  %conv37.33.4 = trunc i32 %xor36.33.4 to i8
  store i8 %conv37.33.4, i8* %scevgep41.33.3, align 1
  %scevgep28.33.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5586, i64 0, i64 0, i64 1
  %5593 = bitcast i8* %scevgep28.33.4 to [41 x [41 x i8]]*
  %scevgep41.33.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5587, i64 0, i64 1, i64 0
  %5594 = bitcast i8* %scevgep41.33.4 to [41 x [41 x i8]]*
  %call16.33.5 = call zeroext i8 (...) @rand()
  store i8 %call16.33.5, i8* %scevgep28.33.4, align 1
  %5595 = load i8, i8* %scevgep28.33.4, align 1
  %conv23.33.5 = zext i8 %5595 to i32
  %5596 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.5 = getelementptr i8, i8* %b, i64 39
  %5597 = load i8, i8* %scevgep34.33.5, align 1
  %call28.33.5 = call zeroext i8 @mult(i8 zeroext %5596, i8 zeroext %5597)
  %conv29.33.5 = zext i8 %call28.33.5 to i32
  %xor.33.5 = xor i32 %conv23.33.5, %conv29.33.5
  %scevgep35.33.5 = getelementptr i8, i8* %a, i64 39
  %5598 = load i8, i8* %scevgep35.33.5, align 1
  %5599 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.5 = call zeroext i8 @mult(i8 zeroext %5598, i8 zeroext %5599)
  %conv35.33.5 = zext i8 %call34.33.5 to i32
  %xor36.33.5 = xor i32 %xor.33.5, %conv35.33.5
  %conv37.33.5 = trunc i32 %xor36.33.5 to i8
  store i8 %conv37.33.5, i8* %scevgep41.33.4, align 1
  %scevgep28.33.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5593, i64 0, i64 0, i64 1
  %scevgep41.33.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5594, i64 0, i64 1, i64 0
  %call16.33.6 = call zeroext i8 (...) @rand()
  store i8 %call16.33.6, i8* %scevgep28.33.5, align 1
  %5600 = load i8, i8* %scevgep28.33.5, align 1
  %conv23.33.6 = zext i8 %5600 to i32
  %5601 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.6 = getelementptr i8, i8* %b, i64 40
  %5602 = load i8, i8* %scevgep34.33.6, align 1
  %call28.33.6 = call zeroext i8 @mult(i8 zeroext %5601, i8 zeroext %5602)
  %conv29.33.6 = zext i8 %call28.33.6 to i32
  %xor.33.6 = xor i32 %conv23.33.6, %conv29.33.6
  %scevgep35.33.6 = getelementptr i8, i8* %a, i64 40
  %5603 = load i8, i8* %scevgep35.33.6, align 1
  %5604 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.6 = call zeroext i8 @mult(i8 zeroext %5603, i8 zeroext %5604)
  %conv35.33.6 = zext i8 %call34.33.6 to i32
  %xor36.33.6 = xor i32 %xor.33.6, %conv35.33.6
  %conv37.33.6 = trunc i32 %xor36.33.6 to i8
  store i8 %conv37.33.6, i8* %scevgep41.33.5, align 1
  %scevgep26.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5558, i64 0, i64 1, i64 1
  %5605 = bitcast i8* %scevgep26.33 to [41 x [41 x i8]]*
  %scevgep39.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5559, i64 0, i64 1, i64 1
  %5606 = bitcast i8* %scevgep39.33 to [41 x [41 x i8]]*
  %arrayidx25.34 = getelementptr inbounds i8, i8* %a, i64 34
  %arrayidx33.34 = getelementptr inbounds i8, i8* %b, i64 34
  %call16.34 = call zeroext i8 (...) @rand()
  store i8 %call16.34, i8* %scevgep26.33, align 1
  %5607 = load i8, i8* %scevgep26.33, align 1
  %conv23.34 = zext i8 %5607 to i32
  %5608 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34 = getelementptr i8, i8* %b, i64 35
  %5609 = load i8, i8* %scevgep34.34, align 1
  %call28.34 = call zeroext i8 @mult(i8 zeroext %5608, i8 zeroext %5609)
  %conv29.34 = zext i8 %call28.34 to i32
  %xor.34 = xor i32 %conv23.34, %conv29.34
  %scevgep35.34 = getelementptr i8, i8* %a, i64 35
  %5610 = load i8, i8* %scevgep35.34, align 1
  %5611 = load i8, i8* %arrayidx33.34, align 1
  %call34.34 = call zeroext i8 @mult(i8 zeroext %5610, i8 zeroext %5611)
  %conv35.34 = zext i8 %call34.34 to i32
  %xor36.34 = xor i32 %xor.34, %conv35.34
  %conv37.34 = trunc i32 %xor36.34 to i8
  store i8 %conv37.34, i8* %scevgep39.33, align 1
  %scevgep28.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5605, i64 0, i64 0, i64 1
  %5612 = bitcast i8* %scevgep28.34 to [41 x [41 x i8]]*
  %scevgep41.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5606, i64 0, i64 1, i64 0
  %5613 = bitcast i8* %scevgep41.34 to [41 x [41 x i8]]*
  %call16.34.1 = call zeroext i8 (...) @rand()
  store i8 %call16.34.1, i8* %scevgep28.34, align 1
  %5614 = load i8, i8* %scevgep28.34, align 1
  %conv23.34.1 = zext i8 %5614 to i32
  %5615 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.1 = getelementptr i8, i8* %b, i64 36
  %5616 = load i8, i8* %scevgep34.34.1, align 1
  %call28.34.1 = call zeroext i8 @mult(i8 zeroext %5615, i8 zeroext %5616)
  %conv29.34.1 = zext i8 %call28.34.1 to i32
  %xor.34.1 = xor i32 %conv23.34.1, %conv29.34.1
  %scevgep35.34.1 = getelementptr i8, i8* %a, i64 36
  %5617 = load i8, i8* %scevgep35.34.1, align 1
  %5618 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.1 = call zeroext i8 @mult(i8 zeroext %5617, i8 zeroext %5618)
  %conv35.34.1 = zext i8 %call34.34.1 to i32
  %xor36.34.1 = xor i32 %xor.34.1, %conv35.34.1
  %conv37.34.1 = trunc i32 %xor36.34.1 to i8
  store i8 %conv37.34.1, i8* %scevgep41.34, align 1
  %scevgep28.34.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5612, i64 0, i64 0, i64 1
  %5619 = bitcast i8* %scevgep28.34.1 to [41 x [41 x i8]]*
  %scevgep41.34.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5613, i64 0, i64 1, i64 0
  %5620 = bitcast i8* %scevgep41.34.1 to [41 x [41 x i8]]*
  %call16.34.2 = call zeroext i8 (...) @rand()
  store i8 %call16.34.2, i8* %scevgep28.34.1, align 1
  %5621 = load i8, i8* %scevgep28.34.1, align 1
  %conv23.34.2 = zext i8 %5621 to i32
  %5622 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.2 = getelementptr i8, i8* %b, i64 37
  %5623 = load i8, i8* %scevgep34.34.2, align 1
  %call28.34.2 = call zeroext i8 @mult(i8 zeroext %5622, i8 zeroext %5623)
  %conv29.34.2 = zext i8 %call28.34.2 to i32
  %xor.34.2 = xor i32 %conv23.34.2, %conv29.34.2
  %scevgep35.34.2 = getelementptr i8, i8* %a, i64 37
  %5624 = load i8, i8* %scevgep35.34.2, align 1
  %5625 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.2 = call zeroext i8 @mult(i8 zeroext %5624, i8 zeroext %5625)
  %conv35.34.2 = zext i8 %call34.34.2 to i32
  %xor36.34.2 = xor i32 %xor.34.2, %conv35.34.2
  %conv37.34.2 = trunc i32 %xor36.34.2 to i8
  store i8 %conv37.34.2, i8* %scevgep41.34.1, align 1
  %scevgep28.34.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5619, i64 0, i64 0, i64 1
  %5626 = bitcast i8* %scevgep28.34.2 to [41 x [41 x i8]]*
  %scevgep41.34.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5620, i64 0, i64 1, i64 0
  %5627 = bitcast i8* %scevgep41.34.2 to [41 x [41 x i8]]*
  %call16.34.3 = call zeroext i8 (...) @rand()
  store i8 %call16.34.3, i8* %scevgep28.34.2, align 1
  %5628 = load i8, i8* %scevgep28.34.2, align 1
  %conv23.34.3 = zext i8 %5628 to i32
  %5629 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.3 = getelementptr i8, i8* %b, i64 38
  %5630 = load i8, i8* %scevgep34.34.3, align 1
  %call28.34.3 = call zeroext i8 @mult(i8 zeroext %5629, i8 zeroext %5630)
  %conv29.34.3 = zext i8 %call28.34.3 to i32
  %xor.34.3 = xor i32 %conv23.34.3, %conv29.34.3
  %scevgep35.34.3 = getelementptr i8, i8* %a, i64 38
  %5631 = load i8, i8* %scevgep35.34.3, align 1
  %5632 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.3 = call zeroext i8 @mult(i8 zeroext %5631, i8 zeroext %5632)
  %conv35.34.3 = zext i8 %call34.34.3 to i32
  %xor36.34.3 = xor i32 %xor.34.3, %conv35.34.3
  %conv37.34.3 = trunc i32 %xor36.34.3 to i8
  store i8 %conv37.34.3, i8* %scevgep41.34.2, align 1
  %scevgep28.34.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5626, i64 0, i64 0, i64 1
  %5633 = bitcast i8* %scevgep28.34.3 to [41 x [41 x i8]]*
  %scevgep41.34.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5627, i64 0, i64 1, i64 0
  %5634 = bitcast i8* %scevgep41.34.3 to [41 x [41 x i8]]*
  %call16.34.4 = call zeroext i8 (...) @rand()
  store i8 %call16.34.4, i8* %scevgep28.34.3, align 1
  %5635 = load i8, i8* %scevgep28.34.3, align 1
  %conv23.34.4 = zext i8 %5635 to i32
  %5636 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.4 = getelementptr i8, i8* %b, i64 39
  %5637 = load i8, i8* %scevgep34.34.4, align 1
  %call28.34.4 = call zeroext i8 @mult(i8 zeroext %5636, i8 zeroext %5637)
  %conv29.34.4 = zext i8 %call28.34.4 to i32
  %xor.34.4 = xor i32 %conv23.34.4, %conv29.34.4
  %scevgep35.34.4 = getelementptr i8, i8* %a, i64 39
  %5638 = load i8, i8* %scevgep35.34.4, align 1
  %5639 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.4 = call zeroext i8 @mult(i8 zeroext %5638, i8 zeroext %5639)
  %conv35.34.4 = zext i8 %call34.34.4 to i32
  %xor36.34.4 = xor i32 %xor.34.4, %conv35.34.4
  %conv37.34.4 = trunc i32 %xor36.34.4 to i8
  store i8 %conv37.34.4, i8* %scevgep41.34.3, align 1
  %scevgep28.34.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5633, i64 0, i64 0, i64 1
  %scevgep41.34.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5634, i64 0, i64 1, i64 0
  %call16.34.5 = call zeroext i8 (...) @rand()
  store i8 %call16.34.5, i8* %scevgep28.34.4, align 1
  %5640 = load i8, i8* %scevgep28.34.4, align 1
  %conv23.34.5 = zext i8 %5640 to i32
  %5641 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.5 = getelementptr i8, i8* %b, i64 40
  %5642 = load i8, i8* %scevgep34.34.5, align 1
  %call28.34.5 = call zeroext i8 @mult(i8 zeroext %5641, i8 zeroext %5642)
  %conv29.34.5 = zext i8 %call28.34.5 to i32
  %xor.34.5 = xor i32 %conv23.34.5, %conv29.34.5
  %scevgep35.34.5 = getelementptr i8, i8* %a, i64 40
  %5643 = load i8, i8* %scevgep35.34.5, align 1
  %5644 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.5 = call zeroext i8 @mult(i8 zeroext %5643, i8 zeroext %5644)
  %conv35.34.5 = zext i8 %call34.34.5 to i32
  %xor36.34.5 = xor i32 %xor.34.5, %conv35.34.5
  %conv37.34.5 = trunc i32 %xor36.34.5 to i8
  store i8 %conv37.34.5, i8* %scevgep41.34.4, align 1
  %scevgep26.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5605, i64 0, i64 1, i64 1
  %5645 = bitcast i8* %scevgep26.34 to [41 x [41 x i8]]*
  %scevgep39.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5606, i64 0, i64 1, i64 1
  %5646 = bitcast i8* %scevgep39.34 to [41 x [41 x i8]]*
  %arrayidx25.35 = getelementptr inbounds i8, i8* %a, i64 35
  %arrayidx33.35 = getelementptr inbounds i8, i8* %b, i64 35
  %call16.35 = call zeroext i8 (...) @rand()
  store i8 %call16.35, i8* %scevgep26.34, align 1
  %5647 = load i8, i8* %scevgep26.34, align 1
  %conv23.35 = zext i8 %5647 to i32
  %5648 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35 = getelementptr i8, i8* %b, i64 36
  %5649 = load i8, i8* %scevgep34.35, align 1
  %call28.35 = call zeroext i8 @mult(i8 zeroext %5648, i8 zeroext %5649)
  %conv29.35 = zext i8 %call28.35 to i32
  %xor.35 = xor i32 %conv23.35, %conv29.35
  %scevgep35.35 = getelementptr i8, i8* %a, i64 36
  %5650 = load i8, i8* %scevgep35.35, align 1
  %5651 = load i8, i8* %arrayidx33.35, align 1
  %call34.35 = call zeroext i8 @mult(i8 zeroext %5650, i8 zeroext %5651)
  %conv35.35 = zext i8 %call34.35 to i32
  %xor36.35 = xor i32 %xor.35, %conv35.35
  %conv37.35 = trunc i32 %xor36.35 to i8
  store i8 %conv37.35, i8* %scevgep39.34, align 1
  %scevgep28.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5645, i64 0, i64 0, i64 1
  %5652 = bitcast i8* %scevgep28.35 to [41 x [41 x i8]]*
  %scevgep41.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5646, i64 0, i64 1, i64 0
  %5653 = bitcast i8* %scevgep41.35 to [41 x [41 x i8]]*
  %call16.35.1 = call zeroext i8 (...) @rand()
  store i8 %call16.35.1, i8* %scevgep28.35, align 1
  %5654 = load i8, i8* %scevgep28.35, align 1
  %conv23.35.1 = zext i8 %5654 to i32
  %5655 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.1 = getelementptr i8, i8* %b, i64 37
  %5656 = load i8, i8* %scevgep34.35.1, align 1
  %call28.35.1 = call zeroext i8 @mult(i8 zeroext %5655, i8 zeroext %5656)
  %conv29.35.1 = zext i8 %call28.35.1 to i32
  %xor.35.1 = xor i32 %conv23.35.1, %conv29.35.1
  %scevgep35.35.1 = getelementptr i8, i8* %a, i64 37
  %5657 = load i8, i8* %scevgep35.35.1, align 1
  %5658 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.1 = call zeroext i8 @mult(i8 zeroext %5657, i8 zeroext %5658)
  %conv35.35.1 = zext i8 %call34.35.1 to i32
  %xor36.35.1 = xor i32 %xor.35.1, %conv35.35.1
  %conv37.35.1 = trunc i32 %xor36.35.1 to i8
  store i8 %conv37.35.1, i8* %scevgep41.35, align 1
  %scevgep28.35.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5652, i64 0, i64 0, i64 1
  %5659 = bitcast i8* %scevgep28.35.1 to [41 x [41 x i8]]*
  %scevgep41.35.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5653, i64 0, i64 1, i64 0
  %5660 = bitcast i8* %scevgep41.35.1 to [41 x [41 x i8]]*
  %call16.35.2 = call zeroext i8 (...) @rand()
  store i8 %call16.35.2, i8* %scevgep28.35.1, align 1
  %5661 = load i8, i8* %scevgep28.35.1, align 1
  %conv23.35.2 = zext i8 %5661 to i32
  %5662 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.2 = getelementptr i8, i8* %b, i64 38
  %5663 = load i8, i8* %scevgep34.35.2, align 1
  %call28.35.2 = call zeroext i8 @mult(i8 zeroext %5662, i8 zeroext %5663)
  %conv29.35.2 = zext i8 %call28.35.2 to i32
  %xor.35.2 = xor i32 %conv23.35.2, %conv29.35.2
  %scevgep35.35.2 = getelementptr i8, i8* %a, i64 38
  %5664 = load i8, i8* %scevgep35.35.2, align 1
  %5665 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.2 = call zeroext i8 @mult(i8 zeroext %5664, i8 zeroext %5665)
  %conv35.35.2 = zext i8 %call34.35.2 to i32
  %xor36.35.2 = xor i32 %xor.35.2, %conv35.35.2
  %conv37.35.2 = trunc i32 %xor36.35.2 to i8
  store i8 %conv37.35.2, i8* %scevgep41.35.1, align 1
  %scevgep28.35.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5659, i64 0, i64 0, i64 1
  %5666 = bitcast i8* %scevgep28.35.2 to [41 x [41 x i8]]*
  %scevgep41.35.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5660, i64 0, i64 1, i64 0
  %5667 = bitcast i8* %scevgep41.35.2 to [41 x [41 x i8]]*
  %call16.35.3 = call zeroext i8 (...) @rand()
  store i8 %call16.35.3, i8* %scevgep28.35.2, align 1
  %5668 = load i8, i8* %scevgep28.35.2, align 1
  %conv23.35.3 = zext i8 %5668 to i32
  %5669 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.3 = getelementptr i8, i8* %b, i64 39
  %5670 = load i8, i8* %scevgep34.35.3, align 1
  %call28.35.3 = call zeroext i8 @mult(i8 zeroext %5669, i8 zeroext %5670)
  %conv29.35.3 = zext i8 %call28.35.3 to i32
  %xor.35.3 = xor i32 %conv23.35.3, %conv29.35.3
  %scevgep35.35.3 = getelementptr i8, i8* %a, i64 39
  %5671 = load i8, i8* %scevgep35.35.3, align 1
  %5672 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.3 = call zeroext i8 @mult(i8 zeroext %5671, i8 zeroext %5672)
  %conv35.35.3 = zext i8 %call34.35.3 to i32
  %xor36.35.3 = xor i32 %xor.35.3, %conv35.35.3
  %conv37.35.3 = trunc i32 %xor36.35.3 to i8
  store i8 %conv37.35.3, i8* %scevgep41.35.2, align 1
  %scevgep28.35.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5666, i64 0, i64 0, i64 1
  %scevgep41.35.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5667, i64 0, i64 1, i64 0
  %call16.35.4 = call zeroext i8 (...) @rand()
  store i8 %call16.35.4, i8* %scevgep28.35.3, align 1
  %5673 = load i8, i8* %scevgep28.35.3, align 1
  %conv23.35.4 = zext i8 %5673 to i32
  %5674 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.4 = getelementptr i8, i8* %b, i64 40
  %5675 = load i8, i8* %scevgep34.35.4, align 1
  %call28.35.4 = call zeroext i8 @mult(i8 zeroext %5674, i8 zeroext %5675)
  %conv29.35.4 = zext i8 %call28.35.4 to i32
  %xor.35.4 = xor i32 %conv23.35.4, %conv29.35.4
  %scevgep35.35.4 = getelementptr i8, i8* %a, i64 40
  %5676 = load i8, i8* %scevgep35.35.4, align 1
  %5677 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.4 = call zeroext i8 @mult(i8 zeroext %5676, i8 zeroext %5677)
  %conv35.35.4 = zext i8 %call34.35.4 to i32
  %xor36.35.4 = xor i32 %xor.35.4, %conv35.35.4
  %conv37.35.4 = trunc i32 %xor36.35.4 to i8
  store i8 %conv37.35.4, i8* %scevgep41.35.3, align 1
  %scevgep26.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5645, i64 0, i64 1, i64 1
  %5678 = bitcast i8* %scevgep26.35 to [41 x [41 x i8]]*
  %scevgep39.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5646, i64 0, i64 1, i64 1
  %5679 = bitcast i8* %scevgep39.35 to [41 x [41 x i8]]*
  %arrayidx25.36 = getelementptr inbounds i8, i8* %a, i64 36
  %arrayidx33.36 = getelementptr inbounds i8, i8* %b, i64 36
  %call16.36 = call zeroext i8 (...) @rand()
  store i8 %call16.36, i8* %scevgep26.35, align 1
  %5680 = load i8, i8* %scevgep26.35, align 1
  %conv23.36 = zext i8 %5680 to i32
  %5681 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36 = getelementptr i8, i8* %b, i64 37
  %5682 = load i8, i8* %scevgep34.36, align 1
  %call28.36 = call zeroext i8 @mult(i8 zeroext %5681, i8 zeroext %5682)
  %conv29.36 = zext i8 %call28.36 to i32
  %xor.36 = xor i32 %conv23.36, %conv29.36
  %scevgep35.36 = getelementptr i8, i8* %a, i64 37
  %5683 = load i8, i8* %scevgep35.36, align 1
  %5684 = load i8, i8* %arrayidx33.36, align 1
  %call34.36 = call zeroext i8 @mult(i8 zeroext %5683, i8 zeroext %5684)
  %conv35.36 = zext i8 %call34.36 to i32
  %xor36.36 = xor i32 %xor.36, %conv35.36
  %conv37.36 = trunc i32 %xor36.36 to i8
  store i8 %conv37.36, i8* %scevgep39.35, align 1
  %scevgep28.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5678, i64 0, i64 0, i64 1
  %5685 = bitcast i8* %scevgep28.36 to [41 x [41 x i8]]*
  %scevgep41.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5679, i64 0, i64 1, i64 0
  %5686 = bitcast i8* %scevgep41.36 to [41 x [41 x i8]]*
  %call16.36.1 = call zeroext i8 (...) @rand()
  store i8 %call16.36.1, i8* %scevgep28.36, align 1
  %5687 = load i8, i8* %scevgep28.36, align 1
  %conv23.36.1 = zext i8 %5687 to i32
  %5688 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.1 = getelementptr i8, i8* %b, i64 38
  %5689 = load i8, i8* %scevgep34.36.1, align 1
  %call28.36.1 = call zeroext i8 @mult(i8 zeroext %5688, i8 zeroext %5689)
  %conv29.36.1 = zext i8 %call28.36.1 to i32
  %xor.36.1 = xor i32 %conv23.36.1, %conv29.36.1
  %scevgep35.36.1 = getelementptr i8, i8* %a, i64 38
  %5690 = load i8, i8* %scevgep35.36.1, align 1
  %5691 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.1 = call zeroext i8 @mult(i8 zeroext %5690, i8 zeroext %5691)
  %conv35.36.1 = zext i8 %call34.36.1 to i32
  %xor36.36.1 = xor i32 %xor.36.1, %conv35.36.1
  %conv37.36.1 = trunc i32 %xor36.36.1 to i8
  store i8 %conv37.36.1, i8* %scevgep41.36, align 1
  %scevgep28.36.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5685, i64 0, i64 0, i64 1
  %5692 = bitcast i8* %scevgep28.36.1 to [41 x [41 x i8]]*
  %scevgep41.36.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5686, i64 0, i64 1, i64 0
  %5693 = bitcast i8* %scevgep41.36.1 to [41 x [41 x i8]]*
  %call16.36.2 = call zeroext i8 (...) @rand()
  store i8 %call16.36.2, i8* %scevgep28.36.1, align 1
  %5694 = load i8, i8* %scevgep28.36.1, align 1
  %conv23.36.2 = zext i8 %5694 to i32
  %5695 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.2 = getelementptr i8, i8* %b, i64 39
  %5696 = load i8, i8* %scevgep34.36.2, align 1
  %call28.36.2 = call zeroext i8 @mult(i8 zeroext %5695, i8 zeroext %5696)
  %conv29.36.2 = zext i8 %call28.36.2 to i32
  %xor.36.2 = xor i32 %conv23.36.2, %conv29.36.2
  %scevgep35.36.2 = getelementptr i8, i8* %a, i64 39
  %5697 = load i8, i8* %scevgep35.36.2, align 1
  %5698 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.2 = call zeroext i8 @mult(i8 zeroext %5697, i8 zeroext %5698)
  %conv35.36.2 = zext i8 %call34.36.2 to i32
  %xor36.36.2 = xor i32 %xor.36.2, %conv35.36.2
  %conv37.36.2 = trunc i32 %xor36.36.2 to i8
  store i8 %conv37.36.2, i8* %scevgep41.36.1, align 1
  %scevgep28.36.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5692, i64 0, i64 0, i64 1
  %scevgep41.36.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5693, i64 0, i64 1, i64 0
  %call16.36.3 = call zeroext i8 (...) @rand()
  store i8 %call16.36.3, i8* %scevgep28.36.2, align 1
  %5699 = load i8, i8* %scevgep28.36.2, align 1
  %conv23.36.3 = zext i8 %5699 to i32
  %5700 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.3 = getelementptr i8, i8* %b, i64 40
  %5701 = load i8, i8* %scevgep34.36.3, align 1
  %call28.36.3 = call zeroext i8 @mult(i8 zeroext %5700, i8 zeroext %5701)
  %conv29.36.3 = zext i8 %call28.36.3 to i32
  %xor.36.3 = xor i32 %conv23.36.3, %conv29.36.3
  %scevgep35.36.3 = getelementptr i8, i8* %a, i64 40
  %5702 = load i8, i8* %scevgep35.36.3, align 1
  %5703 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.3 = call zeroext i8 @mult(i8 zeroext %5702, i8 zeroext %5703)
  %conv35.36.3 = zext i8 %call34.36.3 to i32
  %xor36.36.3 = xor i32 %xor.36.3, %conv35.36.3
  %conv37.36.3 = trunc i32 %xor36.36.3 to i8
  store i8 %conv37.36.3, i8* %scevgep41.36.2, align 1
  %scevgep26.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5678, i64 0, i64 1, i64 1
  %5704 = bitcast i8* %scevgep26.36 to [41 x [41 x i8]]*
  %scevgep39.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5679, i64 0, i64 1, i64 1
  %5705 = bitcast i8* %scevgep39.36 to [41 x [41 x i8]]*
  %arrayidx25.37 = getelementptr inbounds i8, i8* %a, i64 37
  %arrayidx33.37 = getelementptr inbounds i8, i8* %b, i64 37
  %call16.37 = call zeroext i8 (...) @rand()
  store i8 %call16.37, i8* %scevgep26.36, align 1
  %5706 = load i8, i8* %scevgep26.36, align 1
  %conv23.37 = zext i8 %5706 to i32
  %5707 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37 = getelementptr i8, i8* %b, i64 38
  %5708 = load i8, i8* %scevgep34.37, align 1
  %call28.37 = call zeroext i8 @mult(i8 zeroext %5707, i8 zeroext %5708)
  %conv29.37 = zext i8 %call28.37 to i32
  %xor.37 = xor i32 %conv23.37, %conv29.37
  %scevgep35.37 = getelementptr i8, i8* %a, i64 38
  %5709 = load i8, i8* %scevgep35.37, align 1
  %5710 = load i8, i8* %arrayidx33.37, align 1
  %call34.37 = call zeroext i8 @mult(i8 zeroext %5709, i8 zeroext %5710)
  %conv35.37 = zext i8 %call34.37 to i32
  %xor36.37 = xor i32 %xor.37, %conv35.37
  %conv37.37 = trunc i32 %xor36.37 to i8
  store i8 %conv37.37, i8* %scevgep39.36, align 1
  %scevgep28.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5704, i64 0, i64 0, i64 1
  %5711 = bitcast i8* %scevgep28.37 to [41 x [41 x i8]]*
  %scevgep41.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5705, i64 0, i64 1, i64 0
  %5712 = bitcast i8* %scevgep41.37 to [41 x [41 x i8]]*
  %call16.37.1 = call zeroext i8 (...) @rand()
  store i8 %call16.37.1, i8* %scevgep28.37, align 1
  %5713 = load i8, i8* %scevgep28.37, align 1
  %conv23.37.1 = zext i8 %5713 to i32
  %5714 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.1 = getelementptr i8, i8* %b, i64 39
  %5715 = load i8, i8* %scevgep34.37.1, align 1
  %call28.37.1 = call zeroext i8 @mult(i8 zeroext %5714, i8 zeroext %5715)
  %conv29.37.1 = zext i8 %call28.37.1 to i32
  %xor.37.1 = xor i32 %conv23.37.1, %conv29.37.1
  %scevgep35.37.1 = getelementptr i8, i8* %a, i64 39
  %5716 = load i8, i8* %scevgep35.37.1, align 1
  %5717 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.1 = call zeroext i8 @mult(i8 zeroext %5716, i8 zeroext %5717)
  %conv35.37.1 = zext i8 %call34.37.1 to i32
  %xor36.37.1 = xor i32 %xor.37.1, %conv35.37.1
  %conv37.37.1 = trunc i32 %xor36.37.1 to i8
  store i8 %conv37.37.1, i8* %scevgep41.37, align 1
  %scevgep28.37.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5711, i64 0, i64 0, i64 1
  %scevgep41.37.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5712, i64 0, i64 1, i64 0
  %call16.37.2 = call zeroext i8 (...) @rand()
  store i8 %call16.37.2, i8* %scevgep28.37.1, align 1
  %5718 = load i8, i8* %scevgep28.37.1, align 1
  %conv23.37.2 = zext i8 %5718 to i32
  %5719 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.2 = getelementptr i8, i8* %b, i64 40
  %5720 = load i8, i8* %scevgep34.37.2, align 1
  %call28.37.2 = call zeroext i8 @mult(i8 zeroext %5719, i8 zeroext %5720)
  %conv29.37.2 = zext i8 %call28.37.2 to i32
  %xor.37.2 = xor i32 %conv23.37.2, %conv29.37.2
  %scevgep35.37.2 = getelementptr i8, i8* %a, i64 40
  %5721 = load i8, i8* %scevgep35.37.2, align 1
  %5722 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.2 = call zeroext i8 @mult(i8 zeroext %5721, i8 zeroext %5722)
  %conv35.37.2 = zext i8 %call34.37.2 to i32
  %xor36.37.2 = xor i32 %xor.37.2, %conv35.37.2
  %conv37.37.2 = trunc i32 %xor36.37.2 to i8
  store i8 %conv37.37.2, i8* %scevgep41.37.1, align 1
  %scevgep26.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5704, i64 0, i64 1, i64 1
  %5723 = bitcast i8* %scevgep26.37 to [41 x [41 x i8]]*
  %scevgep39.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5705, i64 0, i64 1, i64 1
  %5724 = bitcast i8* %scevgep39.37 to [41 x [41 x i8]]*
  %arrayidx25.38 = getelementptr inbounds i8, i8* %a, i64 38
  %arrayidx33.38 = getelementptr inbounds i8, i8* %b, i64 38
  %call16.38 = call zeroext i8 (...) @rand()
  store i8 %call16.38, i8* %scevgep26.37, align 1
  %5725 = load i8, i8* %scevgep26.37, align 1
  %conv23.38 = zext i8 %5725 to i32
  %5726 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38 = getelementptr i8, i8* %b, i64 39
  %5727 = load i8, i8* %scevgep34.38, align 1
  %call28.38 = call zeroext i8 @mult(i8 zeroext %5726, i8 zeroext %5727)
  %conv29.38 = zext i8 %call28.38 to i32
  %xor.38 = xor i32 %conv23.38, %conv29.38
  %scevgep35.38 = getelementptr i8, i8* %a, i64 39
  %5728 = load i8, i8* %scevgep35.38, align 1
  %5729 = load i8, i8* %arrayidx33.38, align 1
  %call34.38 = call zeroext i8 @mult(i8 zeroext %5728, i8 zeroext %5729)
  %conv35.38 = zext i8 %call34.38 to i32
  %xor36.38 = xor i32 %xor.38, %conv35.38
  %conv37.38 = trunc i32 %xor36.38 to i8
  store i8 %conv37.38, i8* %scevgep39.37, align 1
  %scevgep28.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5723, i64 0, i64 0, i64 1
  %scevgep41.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5724, i64 0, i64 1, i64 0
  %call16.38.1 = call zeroext i8 (...) @rand()
  store i8 %call16.38.1, i8* %scevgep28.38, align 1
  %5730 = load i8, i8* %scevgep28.38, align 1
  %conv23.38.1 = zext i8 %5730 to i32
  %5731 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.1 = getelementptr i8, i8* %b, i64 40
  %5732 = load i8, i8* %scevgep34.38.1, align 1
  %call28.38.1 = call zeroext i8 @mult(i8 zeroext %5731, i8 zeroext %5732)
  %conv29.38.1 = zext i8 %call28.38.1 to i32
  %xor.38.1 = xor i32 %conv23.38.1, %conv29.38.1
  %scevgep35.38.1 = getelementptr i8, i8* %a, i64 40
  %5733 = load i8, i8* %scevgep35.38.1, align 1
  %5734 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.1 = call zeroext i8 @mult(i8 zeroext %5733, i8 zeroext %5734)
  %conv35.38.1 = zext i8 %call34.38.1 to i32
  %xor36.38.1 = xor i32 %xor.38.1, %conv35.38.1
  %conv37.38.1 = trunc i32 %xor36.38.1 to i8
  store i8 %conv37.38.1, i8* %scevgep41.38, align 1
  %scevgep26.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5723, i64 0, i64 1, i64 1
  %scevgep39.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5724, i64 0, i64 1, i64 1
  %arrayidx25.39 = getelementptr inbounds i8, i8* %a, i64 39
  %arrayidx33.39 = getelementptr inbounds i8, i8* %b, i64 39
  %call16.39 = call zeroext i8 (...) @rand()
  store i8 %call16.39, i8* %scevgep26.38, align 1
  %5735 = load i8, i8* %scevgep26.38, align 1
  %conv23.39 = zext i8 %5735 to i32
  %5736 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39 = getelementptr i8, i8* %b, i64 40
  %5737 = load i8, i8* %scevgep34.39, align 1
  %call28.39 = call zeroext i8 @mult(i8 zeroext %5736, i8 zeroext %5737)
  %conv29.39 = zext i8 %call28.39 to i32
  %xor.39 = xor i32 %conv23.39, %conv29.39
  %scevgep35.39 = getelementptr i8, i8* %a, i64 40
  %5738 = load i8, i8* %scevgep35.39, align 1
  %5739 = load i8, i8* %arrayidx33.39, align 1
  %call34.39 = call zeroext i8 @mult(i8 zeroext %5738, i8 zeroext %5739)
  %conv35.39 = zext i8 %call34.39 to i32
  %xor36.39 = xor i32 %xor.39, %conv35.39
  %conv37.39 = trunc i32 %xor36.39 to i8
  store i8 %conv37.39, i8* %scevgep39.38, align 1
  %5740 = load i8, i8* %a, align 1
  %5741 = load i8, i8* %b, align 1
  %call54 = call zeroext i8 @mult(i8 zeroext %5740, i8 zeroext %5741)
  store i8 %call54, i8* %c, align 1
  %scevgep20.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 1
  %5742 = load i8, i8* %scevgep20.1, align 1
  %conv68.1 = zext i8 %5742 to i32
  %5743 = load i8, i8* %c, align 1
  %conv71.1 = zext i8 %5743 to i32
  %xor72.1 = xor i32 %conv71.1, %conv68.1
  %conv73.1 = trunc i32 %xor72.1 to i8
  store i8 %conv73.1, i8* %c, align 1
  %scevgep20.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 2
  %5744 = load i8, i8* %scevgep20.2, align 1
  %conv68.2 = zext i8 %5744 to i32
  %5745 = load i8, i8* %c, align 1
  %conv71.2 = zext i8 %5745 to i32
  %xor72.2 = xor i32 %conv71.2, %conv68.2
  %conv73.2 = trunc i32 %xor72.2 to i8
  store i8 %conv73.2, i8* %c, align 1
  %scevgep20.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 3
  %5746 = load i8, i8* %scevgep20.3, align 1
  %conv68.3 = zext i8 %5746 to i32
  %5747 = load i8, i8* %c, align 1
  %conv71.3 = zext i8 %5747 to i32
  %xor72.3 = xor i32 %conv71.3, %conv68.3
  %conv73.3 = trunc i32 %xor72.3 to i8
  store i8 %conv73.3, i8* %c, align 1
  %scevgep20.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 4
  %5748 = load i8, i8* %scevgep20.4, align 1
  %conv68.4 = zext i8 %5748 to i32
  %5749 = load i8, i8* %c, align 1
  %conv71.4 = zext i8 %5749 to i32
  %xor72.4 = xor i32 %conv71.4, %conv68.4
  %conv73.4 = trunc i32 %xor72.4 to i8
  store i8 %conv73.4, i8* %c, align 1
  %scevgep20.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 5
  %5750 = load i8, i8* %scevgep20.5, align 1
  %conv68.5 = zext i8 %5750 to i32
  %5751 = load i8, i8* %c, align 1
  %conv71.5 = zext i8 %5751 to i32
  %xor72.5 = xor i32 %conv71.5, %conv68.5
  %conv73.5 = trunc i32 %xor72.5 to i8
  store i8 %conv73.5, i8* %c, align 1
  %scevgep20.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 6
  %5752 = load i8, i8* %scevgep20.6, align 1
  %conv68.6 = zext i8 %5752 to i32
  %5753 = load i8, i8* %c, align 1
  %conv71.6 = zext i8 %5753 to i32
  %xor72.6 = xor i32 %conv71.6, %conv68.6
  %conv73.6 = trunc i32 %xor72.6 to i8
  store i8 %conv73.6, i8* %c, align 1
  %scevgep20.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 7
  %5754 = load i8, i8* %scevgep20.7, align 1
  %conv68.7 = zext i8 %5754 to i32
  %5755 = load i8, i8* %c, align 1
  %conv71.7 = zext i8 %5755 to i32
  %xor72.7 = xor i32 %conv71.7, %conv68.7
  %conv73.7 = trunc i32 %xor72.7 to i8
  store i8 %conv73.7, i8* %c, align 1
  %scevgep20.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 8
  %5756 = load i8, i8* %scevgep20.8, align 1
  %conv68.8 = zext i8 %5756 to i32
  %5757 = load i8, i8* %c, align 1
  %conv71.8 = zext i8 %5757 to i32
  %xor72.8 = xor i32 %conv71.8, %conv68.8
  %conv73.8 = trunc i32 %xor72.8 to i8
  store i8 %conv73.8, i8* %c, align 1
  %scevgep20.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 9
  %5758 = load i8, i8* %scevgep20.9, align 1
  %conv68.9 = zext i8 %5758 to i32
  %5759 = load i8, i8* %c, align 1
  %conv71.9 = zext i8 %5759 to i32
  %xor72.9 = xor i32 %conv71.9, %conv68.9
  %conv73.9 = trunc i32 %xor72.9 to i8
  store i8 %conv73.9, i8* %c, align 1
  %scevgep20.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 10
  %5760 = load i8, i8* %scevgep20.10, align 1
  %conv68.10 = zext i8 %5760 to i32
  %5761 = load i8, i8* %c, align 1
  %conv71.10 = zext i8 %5761 to i32
  %xor72.10 = xor i32 %conv71.10, %conv68.10
  %conv73.10 = trunc i32 %xor72.10 to i8
  store i8 %conv73.10, i8* %c, align 1
  %scevgep20.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 11
  %5762 = load i8, i8* %scevgep20.11, align 1
  %conv68.11 = zext i8 %5762 to i32
  %5763 = load i8, i8* %c, align 1
  %conv71.11 = zext i8 %5763 to i32
  %xor72.11 = xor i32 %conv71.11, %conv68.11
  %conv73.11 = trunc i32 %xor72.11 to i8
  store i8 %conv73.11, i8* %c, align 1
  %scevgep20.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 12
  %5764 = load i8, i8* %scevgep20.12, align 1
  %conv68.12 = zext i8 %5764 to i32
  %5765 = load i8, i8* %c, align 1
  %conv71.12 = zext i8 %5765 to i32
  %xor72.12 = xor i32 %conv71.12, %conv68.12
  %conv73.12 = trunc i32 %xor72.12 to i8
  store i8 %conv73.12, i8* %c, align 1
  %scevgep20.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 13
  %5766 = load i8, i8* %scevgep20.13, align 1
  %conv68.13 = zext i8 %5766 to i32
  %5767 = load i8, i8* %c, align 1
  %conv71.13 = zext i8 %5767 to i32
  %xor72.13 = xor i32 %conv71.13, %conv68.13
  %conv73.13 = trunc i32 %xor72.13 to i8
  store i8 %conv73.13, i8* %c, align 1
  %scevgep20.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 14
  %5768 = load i8, i8* %scevgep20.14, align 1
  %conv68.14 = zext i8 %5768 to i32
  %5769 = load i8, i8* %c, align 1
  %conv71.14 = zext i8 %5769 to i32
  %xor72.14 = xor i32 %conv71.14, %conv68.14
  %conv73.14 = trunc i32 %xor72.14 to i8
  store i8 %conv73.14, i8* %c, align 1
  %scevgep20.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 15
  %5770 = load i8, i8* %scevgep20.15, align 1
  %conv68.15 = zext i8 %5770 to i32
  %5771 = load i8, i8* %c, align 1
  %conv71.15 = zext i8 %5771 to i32
  %xor72.15 = xor i32 %conv71.15, %conv68.15
  %conv73.15 = trunc i32 %xor72.15 to i8
  store i8 %conv73.15, i8* %c, align 1
  %scevgep20.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 16
  %5772 = load i8, i8* %scevgep20.16, align 1
  %conv68.16 = zext i8 %5772 to i32
  %5773 = load i8, i8* %c, align 1
  %conv71.16 = zext i8 %5773 to i32
  %xor72.16 = xor i32 %conv71.16, %conv68.16
  %conv73.16 = trunc i32 %xor72.16 to i8
  store i8 %conv73.16, i8* %c, align 1
  %scevgep20.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 17
  %5774 = load i8, i8* %scevgep20.17, align 1
  %conv68.17 = zext i8 %5774 to i32
  %5775 = load i8, i8* %c, align 1
  %conv71.17 = zext i8 %5775 to i32
  %xor72.17 = xor i32 %conv71.17, %conv68.17
  %conv73.17 = trunc i32 %xor72.17 to i8
  store i8 %conv73.17, i8* %c, align 1
  %scevgep20.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 18
  %5776 = load i8, i8* %scevgep20.18, align 1
  %conv68.18 = zext i8 %5776 to i32
  %5777 = load i8, i8* %c, align 1
  %conv71.18 = zext i8 %5777 to i32
  %xor72.18 = xor i32 %conv71.18, %conv68.18
  %conv73.18 = trunc i32 %xor72.18 to i8
  store i8 %conv73.18, i8* %c, align 1
  %scevgep20.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 19
  %5778 = load i8, i8* %scevgep20.19, align 1
  %conv68.19 = zext i8 %5778 to i32
  %5779 = load i8, i8* %c, align 1
  %conv71.19 = zext i8 %5779 to i32
  %xor72.19 = xor i32 %conv71.19, %conv68.19
  %conv73.19 = trunc i32 %xor72.19 to i8
  store i8 %conv73.19, i8* %c, align 1
  %scevgep20.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 20
  %5780 = load i8, i8* %scevgep20.20, align 1
  %conv68.20 = zext i8 %5780 to i32
  %5781 = load i8, i8* %c, align 1
  %conv71.20 = zext i8 %5781 to i32
  %xor72.20 = xor i32 %conv71.20, %conv68.20
  %conv73.20 = trunc i32 %xor72.20 to i8
  store i8 %conv73.20, i8* %c, align 1
  %scevgep20.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 21
  %5782 = load i8, i8* %scevgep20.21, align 1
  %conv68.21 = zext i8 %5782 to i32
  %5783 = load i8, i8* %c, align 1
  %conv71.21 = zext i8 %5783 to i32
  %xor72.21 = xor i32 %conv71.21, %conv68.21
  %conv73.21 = trunc i32 %xor72.21 to i8
  store i8 %conv73.21, i8* %c, align 1
  %scevgep20.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 22
  %5784 = load i8, i8* %scevgep20.22, align 1
  %conv68.22 = zext i8 %5784 to i32
  %5785 = load i8, i8* %c, align 1
  %conv71.22 = zext i8 %5785 to i32
  %xor72.22 = xor i32 %conv71.22, %conv68.22
  %conv73.22 = trunc i32 %xor72.22 to i8
  store i8 %conv73.22, i8* %c, align 1
  %scevgep20.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 23
  %5786 = load i8, i8* %scevgep20.23, align 1
  %conv68.23 = zext i8 %5786 to i32
  %5787 = load i8, i8* %c, align 1
  %conv71.23 = zext i8 %5787 to i32
  %xor72.23 = xor i32 %conv71.23, %conv68.23
  %conv73.23 = trunc i32 %xor72.23 to i8
  store i8 %conv73.23, i8* %c, align 1
  %scevgep20.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 24
  %5788 = load i8, i8* %scevgep20.24, align 1
  %conv68.24 = zext i8 %5788 to i32
  %5789 = load i8, i8* %c, align 1
  %conv71.24 = zext i8 %5789 to i32
  %xor72.24 = xor i32 %conv71.24, %conv68.24
  %conv73.24 = trunc i32 %xor72.24 to i8
  store i8 %conv73.24, i8* %c, align 1
  %scevgep20.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 25
  %5790 = load i8, i8* %scevgep20.25, align 1
  %conv68.25 = zext i8 %5790 to i32
  %5791 = load i8, i8* %c, align 1
  %conv71.25 = zext i8 %5791 to i32
  %xor72.25 = xor i32 %conv71.25, %conv68.25
  %conv73.25 = trunc i32 %xor72.25 to i8
  store i8 %conv73.25, i8* %c, align 1
  %scevgep20.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 26
  %5792 = load i8, i8* %scevgep20.26, align 1
  %conv68.26 = zext i8 %5792 to i32
  %5793 = load i8, i8* %c, align 1
  %conv71.26 = zext i8 %5793 to i32
  %xor72.26 = xor i32 %conv71.26, %conv68.26
  %conv73.26 = trunc i32 %xor72.26 to i8
  store i8 %conv73.26, i8* %c, align 1
  %scevgep20.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 27
  %5794 = load i8, i8* %scevgep20.27, align 1
  %conv68.27 = zext i8 %5794 to i32
  %5795 = load i8, i8* %c, align 1
  %conv71.27 = zext i8 %5795 to i32
  %xor72.27 = xor i32 %conv71.27, %conv68.27
  %conv73.27 = trunc i32 %xor72.27 to i8
  store i8 %conv73.27, i8* %c, align 1
  %scevgep20.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 28
  %5796 = load i8, i8* %scevgep20.28, align 1
  %conv68.28 = zext i8 %5796 to i32
  %5797 = load i8, i8* %c, align 1
  %conv71.28 = zext i8 %5797 to i32
  %xor72.28 = xor i32 %conv71.28, %conv68.28
  %conv73.28 = trunc i32 %xor72.28 to i8
  store i8 %conv73.28, i8* %c, align 1
  %scevgep20.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 29
  %5798 = load i8, i8* %scevgep20.29, align 1
  %conv68.29 = zext i8 %5798 to i32
  %5799 = load i8, i8* %c, align 1
  %conv71.29 = zext i8 %5799 to i32
  %xor72.29 = xor i32 %conv71.29, %conv68.29
  %conv73.29 = trunc i32 %xor72.29 to i8
  store i8 %conv73.29, i8* %c, align 1
  %scevgep20.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 30
  %5800 = load i8, i8* %scevgep20.30, align 1
  %conv68.30 = zext i8 %5800 to i32
  %5801 = load i8, i8* %c, align 1
  %conv71.30 = zext i8 %5801 to i32
  %xor72.30 = xor i32 %conv71.30, %conv68.30
  %conv73.30 = trunc i32 %xor72.30 to i8
  store i8 %conv73.30, i8* %c, align 1
  %scevgep20.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 31
  %5802 = load i8, i8* %scevgep20.31, align 1
  %conv68.31 = zext i8 %5802 to i32
  %5803 = load i8, i8* %c, align 1
  %conv71.31 = zext i8 %5803 to i32
  %xor72.31 = xor i32 %conv71.31, %conv68.31
  %conv73.31 = trunc i32 %xor72.31 to i8
  store i8 %conv73.31, i8* %c, align 1
  %scevgep20.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 32
  %5804 = load i8, i8* %scevgep20.32, align 1
  %conv68.32 = zext i8 %5804 to i32
  %5805 = load i8, i8* %c, align 1
  %conv71.32 = zext i8 %5805 to i32
  %xor72.32 = xor i32 %conv71.32, %conv68.32
  %conv73.32 = trunc i32 %xor72.32 to i8
  store i8 %conv73.32, i8* %c, align 1
  %scevgep20.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 33
  %5806 = load i8, i8* %scevgep20.33, align 1
  %conv68.33 = zext i8 %5806 to i32
  %5807 = load i8, i8* %c, align 1
  %conv71.33 = zext i8 %5807 to i32
  %xor72.33 = xor i32 %conv71.33, %conv68.33
  %conv73.33 = trunc i32 %xor72.33 to i8
  store i8 %conv73.33, i8* %c, align 1
  %scevgep20.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 34
  %5808 = load i8, i8* %scevgep20.34, align 1
  %conv68.34 = zext i8 %5808 to i32
  %5809 = load i8, i8* %c, align 1
  %conv71.34 = zext i8 %5809 to i32
  %xor72.34 = xor i32 %conv71.34, %conv68.34
  %conv73.34 = trunc i32 %xor72.34 to i8
  store i8 %conv73.34, i8* %c, align 1
  %scevgep20.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 35
  %5810 = load i8, i8* %scevgep20.35, align 1
  %conv68.35 = zext i8 %5810 to i32
  %5811 = load i8, i8* %c, align 1
  %conv71.35 = zext i8 %5811 to i32
  %xor72.35 = xor i32 %conv71.35, %conv68.35
  %conv73.35 = trunc i32 %xor72.35 to i8
  store i8 %conv73.35, i8* %c, align 1
  %scevgep20.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 36
  %5812 = load i8, i8* %scevgep20.36, align 1
  %conv68.36 = zext i8 %5812 to i32
  %5813 = load i8, i8* %c, align 1
  %conv71.36 = zext i8 %5813 to i32
  %xor72.36 = xor i32 %conv71.36, %conv68.36
  %conv73.36 = trunc i32 %xor72.36 to i8
  store i8 %conv73.36, i8* %c, align 1
  %scevgep20.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 37
  %5814 = load i8, i8* %scevgep20.37, align 1
  %conv68.37 = zext i8 %5814 to i32
  %5815 = load i8, i8* %c, align 1
  %conv71.37 = zext i8 %5815 to i32
  %xor72.37 = xor i32 %conv71.37, %conv68.37
  %conv73.37 = trunc i32 %xor72.37 to i8
  store i8 %conv73.37, i8* %c, align 1
  %scevgep20.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 38
  %5816 = load i8, i8* %scevgep20.38, align 1
  %conv68.38 = zext i8 %5816 to i32
  %5817 = load i8, i8* %c, align 1
  %conv71.38 = zext i8 %5817 to i32
  %xor72.38 = xor i32 %conv71.38, %conv68.38
  %conv73.38 = trunc i32 %xor72.38 to i8
  store i8 %conv73.38, i8* %c, align 1
  %scevgep20.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 39
  %5818 = load i8, i8* %scevgep20.39, align 1
  %conv68.39 = zext i8 %5818 to i32
  %5819 = load i8, i8* %c, align 1
  %conv71.39 = zext i8 %5819 to i32
  %xor72.39 = xor i32 %conv71.39, %conv68.39
  %conv73.39 = trunc i32 %xor72.39 to i8
  store i8 %conv73.39, i8* %c, align 1
  %scevgep20.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 0, i64 40
  %5820 = load i8, i8* %scevgep20.40, align 1
  %conv68.40 = zext i8 %5820 to i32
  %5821 = load i8, i8* %c, align 1
  %conv71.40 = zext i8 %5821 to i32
  %xor72.40 = xor i32 %conv71.40, %conv68.40
  %conv73.40 = trunc i32 %xor72.40 to i8
  store i8 %conv73.40, i8* %c, align 1
  %scevgep19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %r, i64 0, i64 1, i64 0
  %5822 = bitcast i8* %scevgep19 to [41 x [41 x i8]]*
  %arrayidx51.1 = getelementptr inbounds i8, i8* %a, i64 1
  %5823 = load i8, i8* %arrayidx51.1, align 1
  %arrayidx53.1 = getelementptr inbounds i8, i8* %b, i64 1
  %5824 = load i8, i8* %arrayidx53.1, align 1
  %call54.1 = call zeroext i8 @mult(i8 zeroext %5823, i8 zeroext %5824)
  %arrayidx56.1 = getelementptr inbounds i8, i8* %c, i64 1
  store i8 %call54.1, i8* %arrayidx56.1, align 1
  %arrayidx70.1 = getelementptr inbounds i8, i8* %c, i64 1
  %scevgep20.154 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 0
  %5825 = load i8, i8* %scevgep20.154, align 1
  %conv68.155 = zext i8 %5825 to i32
  %5826 = load i8, i8* %arrayidx70.1, align 1
  %conv71.156 = zext i8 %5826 to i32
  %xor72.157 = xor i32 %conv71.156, %conv68.155
  %conv73.158 = trunc i32 %xor72.157 to i8
  store i8 %conv73.158, i8* %arrayidx70.1, align 1
  %scevgep20.2.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 2
  %5827 = load i8, i8* %scevgep20.2.1, align 1
  %conv68.2.1 = zext i8 %5827 to i32
  %5828 = load i8, i8* %arrayidx70.1, align 1
  %conv71.2.1 = zext i8 %5828 to i32
  %xor72.2.1 = xor i32 %conv71.2.1, %conv68.2.1
  %conv73.2.1 = trunc i32 %xor72.2.1 to i8
  store i8 %conv73.2.1, i8* %arrayidx70.1, align 1
  %scevgep20.3.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 3
  %5829 = load i8, i8* %scevgep20.3.1, align 1
  %conv68.3.1 = zext i8 %5829 to i32
  %5830 = load i8, i8* %arrayidx70.1, align 1
  %conv71.3.1 = zext i8 %5830 to i32
  %xor72.3.1 = xor i32 %conv71.3.1, %conv68.3.1
  %conv73.3.1 = trunc i32 %xor72.3.1 to i8
  store i8 %conv73.3.1, i8* %arrayidx70.1, align 1
  %scevgep20.4.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 4
  %5831 = load i8, i8* %scevgep20.4.1, align 1
  %conv68.4.1 = zext i8 %5831 to i32
  %5832 = load i8, i8* %arrayidx70.1, align 1
  %conv71.4.1 = zext i8 %5832 to i32
  %xor72.4.1 = xor i32 %conv71.4.1, %conv68.4.1
  %conv73.4.1 = trunc i32 %xor72.4.1 to i8
  store i8 %conv73.4.1, i8* %arrayidx70.1, align 1
  %scevgep20.5.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 5
  %5833 = load i8, i8* %scevgep20.5.1, align 1
  %conv68.5.1 = zext i8 %5833 to i32
  %5834 = load i8, i8* %arrayidx70.1, align 1
  %conv71.5.1 = zext i8 %5834 to i32
  %xor72.5.1 = xor i32 %conv71.5.1, %conv68.5.1
  %conv73.5.1 = trunc i32 %xor72.5.1 to i8
  store i8 %conv73.5.1, i8* %arrayidx70.1, align 1
  %scevgep20.6.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 6
  %5835 = load i8, i8* %scevgep20.6.1, align 1
  %conv68.6.1 = zext i8 %5835 to i32
  %5836 = load i8, i8* %arrayidx70.1, align 1
  %conv71.6.1 = zext i8 %5836 to i32
  %xor72.6.1 = xor i32 %conv71.6.1, %conv68.6.1
  %conv73.6.1 = trunc i32 %xor72.6.1 to i8
  store i8 %conv73.6.1, i8* %arrayidx70.1, align 1
  %scevgep20.7.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 7
  %5837 = load i8, i8* %scevgep20.7.1, align 1
  %conv68.7.1 = zext i8 %5837 to i32
  %5838 = load i8, i8* %arrayidx70.1, align 1
  %conv71.7.1 = zext i8 %5838 to i32
  %xor72.7.1 = xor i32 %conv71.7.1, %conv68.7.1
  %conv73.7.1 = trunc i32 %xor72.7.1 to i8
  store i8 %conv73.7.1, i8* %arrayidx70.1, align 1
  %scevgep20.8.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 8
  %5839 = load i8, i8* %scevgep20.8.1, align 1
  %conv68.8.1 = zext i8 %5839 to i32
  %5840 = load i8, i8* %arrayidx70.1, align 1
  %conv71.8.1 = zext i8 %5840 to i32
  %xor72.8.1 = xor i32 %conv71.8.1, %conv68.8.1
  %conv73.8.1 = trunc i32 %xor72.8.1 to i8
  store i8 %conv73.8.1, i8* %arrayidx70.1, align 1
  %scevgep20.9.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 9
  %5841 = load i8, i8* %scevgep20.9.1, align 1
  %conv68.9.1 = zext i8 %5841 to i32
  %5842 = load i8, i8* %arrayidx70.1, align 1
  %conv71.9.1 = zext i8 %5842 to i32
  %xor72.9.1 = xor i32 %conv71.9.1, %conv68.9.1
  %conv73.9.1 = trunc i32 %xor72.9.1 to i8
  store i8 %conv73.9.1, i8* %arrayidx70.1, align 1
  %scevgep20.10.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 10
  %5843 = load i8, i8* %scevgep20.10.1, align 1
  %conv68.10.1 = zext i8 %5843 to i32
  %5844 = load i8, i8* %arrayidx70.1, align 1
  %conv71.10.1 = zext i8 %5844 to i32
  %xor72.10.1 = xor i32 %conv71.10.1, %conv68.10.1
  %conv73.10.1 = trunc i32 %xor72.10.1 to i8
  store i8 %conv73.10.1, i8* %arrayidx70.1, align 1
  %scevgep20.11.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 11
  %5845 = load i8, i8* %scevgep20.11.1, align 1
  %conv68.11.1 = zext i8 %5845 to i32
  %5846 = load i8, i8* %arrayidx70.1, align 1
  %conv71.11.1 = zext i8 %5846 to i32
  %xor72.11.1 = xor i32 %conv71.11.1, %conv68.11.1
  %conv73.11.1 = trunc i32 %xor72.11.1 to i8
  store i8 %conv73.11.1, i8* %arrayidx70.1, align 1
  %scevgep20.12.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 12
  %5847 = load i8, i8* %scevgep20.12.1, align 1
  %conv68.12.1 = zext i8 %5847 to i32
  %5848 = load i8, i8* %arrayidx70.1, align 1
  %conv71.12.1 = zext i8 %5848 to i32
  %xor72.12.1 = xor i32 %conv71.12.1, %conv68.12.1
  %conv73.12.1 = trunc i32 %xor72.12.1 to i8
  store i8 %conv73.12.1, i8* %arrayidx70.1, align 1
  %scevgep20.13.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 13
  %5849 = load i8, i8* %scevgep20.13.1, align 1
  %conv68.13.1 = zext i8 %5849 to i32
  %5850 = load i8, i8* %arrayidx70.1, align 1
  %conv71.13.1 = zext i8 %5850 to i32
  %xor72.13.1 = xor i32 %conv71.13.1, %conv68.13.1
  %conv73.13.1 = trunc i32 %xor72.13.1 to i8
  store i8 %conv73.13.1, i8* %arrayidx70.1, align 1
  %scevgep20.14.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 14
  %5851 = load i8, i8* %scevgep20.14.1, align 1
  %conv68.14.1 = zext i8 %5851 to i32
  %5852 = load i8, i8* %arrayidx70.1, align 1
  %conv71.14.1 = zext i8 %5852 to i32
  %xor72.14.1 = xor i32 %conv71.14.1, %conv68.14.1
  %conv73.14.1 = trunc i32 %xor72.14.1 to i8
  store i8 %conv73.14.1, i8* %arrayidx70.1, align 1
  %scevgep20.15.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 15
  %5853 = load i8, i8* %scevgep20.15.1, align 1
  %conv68.15.1 = zext i8 %5853 to i32
  %5854 = load i8, i8* %arrayidx70.1, align 1
  %conv71.15.1 = zext i8 %5854 to i32
  %xor72.15.1 = xor i32 %conv71.15.1, %conv68.15.1
  %conv73.15.1 = trunc i32 %xor72.15.1 to i8
  store i8 %conv73.15.1, i8* %arrayidx70.1, align 1
  %scevgep20.16.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 16
  %5855 = load i8, i8* %scevgep20.16.1, align 1
  %conv68.16.1 = zext i8 %5855 to i32
  %5856 = load i8, i8* %arrayidx70.1, align 1
  %conv71.16.1 = zext i8 %5856 to i32
  %xor72.16.1 = xor i32 %conv71.16.1, %conv68.16.1
  %conv73.16.1 = trunc i32 %xor72.16.1 to i8
  store i8 %conv73.16.1, i8* %arrayidx70.1, align 1
  %scevgep20.17.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 17
  %5857 = load i8, i8* %scevgep20.17.1, align 1
  %conv68.17.1 = zext i8 %5857 to i32
  %5858 = load i8, i8* %arrayidx70.1, align 1
  %conv71.17.1 = zext i8 %5858 to i32
  %xor72.17.1 = xor i32 %conv71.17.1, %conv68.17.1
  %conv73.17.1 = trunc i32 %xor72.17.1 to i8
  store i8 %conv73.17.1, i8* %arrayidx70.1, align 1
  %scevgep20.18.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 18
  %5859 = load i8, i8* %scevgep20.18.1, align 1
  %conv68.18.1 = zext i8 %5859 to i32
  %5860 = load i8, i8* %arrayidx70.1, align 1
  %conv71.18.1 = zext i8 %5860 to i32
  %xor72.18.1 = xor i32 %conv71.18.1, %conv68.18.1
  %conv73.18.1 = trunc i32 %xor72.18.1 to i8
  store i8 %conv73.18.1, i8* %arrayidx70.1, align 1
  %scevgep20.19.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 19
  %5861 = load i8, i8* %scevgep20.19.1, align 1
  %conv68.19.1 = zext i8 %5861 to i32
  %5862 = load i8, i8* %arrayidx70.1, align 1
  %conv71.19.1 = zext i8 %5862 to i32
  %xor72.19.1 = xor i32 %conv71.19.1, %conv68.19.1
  %conv73.19.1 = trunc i32 %xor72.19.1 to i8
  store i8 %conv73.19.1, i8* %arrayidx70.1, align 1
  %scevgep20.20.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 20
  %5863 = load i8, i8* %scevgep20.20.1, align 1
  %conv68.20.1 = zext i8 %5863 to i32
  %5864 = load i8, i8* %arrayidx70.1, align 1
  %conv71.20.1 = zext i8 %5864 to i32
  %xor72.20.1 = xor i32 %conv71.20.1, %conv68.20.1
  %conv73.20.1 = trunc i32 %xor72.20.1 to i8
  store i8 %conv73.20.1, i8* %arrayidx70.1, align 1
  %scevgep20.21.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 21
  %5865 = load i8, i8* %scevgep20.21.1, align 1
  %conv68.21.1 = zext i8 %5865 to i32
  %5866 = load i8, i8* %arrayidx70.1, align 1
  %conv71.21.1 = zext i8 %5866 to i32
  %xor72.21.1 = xor i32 %conv71.21.1, %conv68.21.1
  %conv73.21.1 = trunc i32 %xor72.21.1 to i8
  store i8 %conv73.21.1, i8* %arrayidx70.1, align 1
  %scevgep20.22.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 22
  %5867 = load i8, i8* %scevgep20.22.1, align 1
  %conv68.22.1 = zext i8 %5867 to i32
  %5868 = load i8, i8* %arrayidx70.1, align 1
  %conv71.22.1 = zext i8 %5868 to i32
  %xor72.22.1 = xor i32 %conv71.22.1, %conv68.22.1
  %conv73.22.1 = trunc i32 %xor72.22.1 to i8
  store i8 %conv73.22.1, i8* %arrayidx70.1, align 1
  %scevgep20.23.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 23
  %5869 = load i8, i8* %scevgep20.23.1, align 1
  %conv68.23.1 = zext i8 %5869 to i32
  %5870 = load i8, i8* %arrayidx70.1, align 1
  %conv71.23.1 = zext i8 %5870 to i32
  %xor72.23.1 = xor i32 %conv71.23.1, %conv68.23.1
  %conv73.23.1 = trunc i32 %xor72.23.1 to i8
  store i8 %conv73.23.1, i8* %arrayidx70.1, align 1
  %scevgep20.24.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 24
  %5871 = load i8, i8* %scevgep20.24.1, align 1
  %conv68.24.1 = zext i8 %5871 to i32
  %5872 = load i8, i8* %arrayidx70.1, align 1
  %conv71.24.1 = zext i8 %5872 to i32
  %xor72.24.1 = xor i32 %conv71.24.1, %conv68.24.1
  %conv73.24.1 = trunc i32 %xor72.24.1 to i8
  store i8 %conv73.24.1, i8* %arrayidx70.1, align 1
  %scevgep20.25.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 25
  %5873 = load i8, i8* %scevgep20.25.1, align 1
  %conv68.25.1 = zext i8 %5873 to i32
  %5874 = load i8, i8* %arrayidx70.1, align 1
  %conv71.25.1 = zext i8 %5874 to i32
  %xor72.25.1 = xor i32 %conv71.25.1, %conv68.25.1
  %conv73.25.1 = trunc i32 %xor72.25.1 to i8
  store i8 %conv73.25.1, i8* %arrayidx70.1, align 1
  %scevgep20.26.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 26
  %5875 = load i8, i8* %scevgep20.26.1, align 1
  %conv68.26.1 = zext i8 %5875 to i32
  %5876 = load i8, i8* %arrayidx70.1, align 1
  %conv71.26.1 = zext i8 %5876 to i32
  %xor72.26.1 = xor i32 %conv71.26.1, %conv68.26.1
  %conv73.26.1 = trunc i32 %xor72.26.1 to i8
  store i8 %conv73.26.1, i8* %arrayidx70.1, align 1
  %scevgep20.27.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 27
  %5877 = load i8, i8* %scevgep20.27.1, align 1
  %conv68.27.1 = zext i8 %5877 to i32
  %5878 = load i8, i8* %arrayidx70.1, align 1
  %conv71.27.1 = zext i8 %5878 to i32
  %xor72.27.1 = xor i32 %conv71.27.1, %conv68.27.1
  %conv73.27.1 = trunc i32 %xor72.27.1 to i8
  store i8 %conv73.27.1, i8* %arrayidx70.1, align 1
  %scevgep20.28.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 28
  %5879 = load i8, i8* %scevgep20.28.1, align 1
  %conv68.28.1 = zext i8 %5879 to i32
  %5880 = load i8, i8* %arrayidx70.1, align 1
  %conv71.28.1 = zext i8 %5880 to i32
  %xor72.28.1 = xor i32 %conv71.28.1, %conv68.28.1
  %conv73.28.1 = trunc i32 %xor72.28.1 to i8
  store i8 %conv73.28.1, i8* %arrayidx70.1, align 1
  %scevgep20.29.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 29
  %5881 = load i8, i8* %scevgep20.29.1, align 1
  %conv68.29.1 = zext i8 %5881 to i32
  %5882 = load i8, i8* %arrayidx70.1, align 1
  %conv71.29.1 = zext i8 %5882 to i32
  %xor72.29.1 = xor i32 %conv71.29.1, %conv68.29.1
  %conv73.29.1 = trunc i32 %xor72.29.1 to i8
  store i8 %conv73.29.1, i8* %arrayidx70.1, align 1
  %scevgep20.30.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 30
  %5883 = load i8, i8* %scevgep20.30.1, align 1
  %conv68.30.1 = zext i8 %5883 to i32
  %5884 = load i8, i8* %arrayidx70.1, align 1
  %conv71.30.1 = zext i8 %5884 to i32
  %xor72.30.1 = xor i32 %conv71.30.1, %conv68.30.1
  %conv73.30.1 = trunc i32 %xor72.30.1 to i8
  store i8 %conv73.30.1, i8* %arrayidx70.1, align 1
  %scevgep20.31.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 31
  %5885 = load i8, i8* %scevgep20.31.1, align 1
  %conv68.31.1 = zext i8 %5885 to i32
  %5886 = load i8, i8* %arrayidx70.1, align 1
  %conv71.31.1 = zext i8 %5886 to i32
  %xor72.31.1 = xor i32 %conv71.31.1, %conv68.31.1
  %conv73.31.1 = trunc i32 %xor72.31.1 to i8
  store i8 %conv73.31.1, i8* %arrayidx70.1, align 1
  %scevgep20.32.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 32
  %5887 = load i8, i8* %scevgep20.32.1, align 1
  %conv68.32.1 = zext i8 %5887 to i32
  %5888 = load i8, i8* %arrayidx70.1, align 1
  %conv71.32.1 = zext i8 %5888 to i32
  %xor72.32.1 = xor i32 %conv71.32.1, %conv68.32.1
  %conv73.32.1 = trunc i32 %xor72.32.1 to i8
  store i8 %conv73.32.1, i8* %arrayidx70.1, align 1
  %scevgep20.33.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 33
  %5889 = load i8, i8* %scevgep20.33.1, align 1
  %conv68.33.1 = zext i8 %5889 to i32
  %5890 = load i8, i8* %arrayidx70.1, align 1
  %conv71.33.1 = zext i8 %5890 to i32
  %xor72.33.1 = xor i32 %conv71.33.1, %conv68.33.1
  %conv73.33.1 = trunc i32 %xor72.33.1 to i8
  store i8 %conv73.33.1, i8* %arrayidx70.1, align 1
  %scevgep20.34.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 34
  %5891 = load i8, i8* %scevgep20.34.1, align 1
  %conv68.34.1 = zext i8 %5891 to i32
  %5892 = load i8, i8* %arrayidx70.1, align 1
  %conv71.34.1 = zext i8 %5892 to i32
  %xor72.34.1 = xor i32 %conv71.34.1, %conv68.34.1
  %conv73.34.1 = trunc i32 %xor72.34.1 to i8
  store i8 %conv73.34.1, i8* %arrayidx70.1, align 1
  %scevgep20.35.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 35
  %5893 = load i8, i8* %scevgep20.35.1, align 1
  %conv68.35.1 = zext i8 %5893 to i32
  %5894 = load i8, i8* %arrayidx70.1, align 1
  %conv71.35.1 = zext i8 %5894 to i32
  %xor72.35.1 = xor i32 %conv71.35.1, %conv68.35.1
  %conv73.35.1 = trunc i32 %xor72.35.1 to i8
  store i8 %conv73.35.1, i8* %arrayidx70.1, align 1
  %scevgep20.36.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 36
  %5895 = load i8, i8* %scevgep20.36.1, align 1
  %conv68.36.1 = zext i8 %5895 to i32
  %5896 = load i8, i8* %arrayidx70.1, align 1
  %conv71.36.1 = zext i8 %5896 to i32
  %xor72.36.1 = xor i32 %conv71.36.1, %conv68.36.1
  %conv73.36.1 = trunc i32 %xor72.36.1 to i8
  store i8 %conv73.36.1, i8* %arrayidx70.1, align 1
  %scevgep20.37.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 37
  %5897 = load i8, i8* %scevgep20.37.1, align 1
  %conv68.37.1 = zext i8 %5897 to i32
  %5898 = load i8, i8* %arrayidx70.1, align 1
  %conv71.37.1 = zext i8 %5898 to i32
  %xor72.37.1 = xor i32 %conv71.37.1, %conv68.37.1
  %conv73.37.1 = trunc i32 %xor72.37.1 to i8
  store i8 %conv73.37.1, i8* %arrayidx70.1, align 1
  %scevgep20.38.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 38
  %5899 = load i8, i8* %scevgep20.38.1, align 1
  %conv68.38.1 = zext i8 %5899 to i32
  %5900 = load i8, i8* %arrayidx70.1, align 1
  %conv71.38.1 = zext i8 %5900 to i32
  %xor72.38.1 = xor i32 %conv71.38.1, %conv68.38.1
  %conv73.38.1 = trunc i32 %xor72.38.1 to i8
  store i8 %conv73.38.1, i8* %arrayidx70.1, align 1
  %scevgep20.39.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 39
  %5901 = load i8, i8* %scevgep20.39.1, align 1
  %conv68.39.1 = zext i8 %5901 to i32
  %5902 = load i8, i8* %arrayidx70.1, align 1
  %conv71.39.1 = zext i8 %5902 to i32
  %xor72.39.1 = xor i32 %conv71.39.1, %conv68.39.1
  %conv73.39.1 = trunc i32 %xor72.39.1 to i8
  store i8 %conv73.39.1, i8* %arrayidx70.1, align 1
  %scevgep20.40.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 0, i64 40
  %5903 = load i8, i8* %scevgep20.40.1, align 1
  %conv68.40.1 = zext i8 %5903 to i32
  %5904 = load i8, i8* %arrayidx70.1, align 1
  %conv71.40.1 = zext i8 %5904 to i32
  %xor72.40.1 = xor i32 %conv71.40.1, %conv68.40.1
  %conv73.40.1 = trunc i32 %xor72.40.1 to i8
  store i8 %conv73.40.1, i8* %arrayidx70.1, align 1
  %scevgep19.1 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5822, i64 0, i64 1, i64 0
  %5905 = bitcast i8* %scevgep19.1 to [41 x [41 x i8]]*
  %arrayidx51.2 = getelementptr inbounds i8, i8* %a, i64 2
  %5906 = load i8, i8* %arrayidx51.2, align 1
  %arrayidx53.2 = getelementptr inbounds i8, i8* %b, i64 2
  %5907 = load i8, i8* %arrayidx53.2, align 1
  %call54.2 = call zeroext i8 @mult(i8 zeroext %5906, i8 zeroext %5907)
  %arrayidx56.2 = getelementptr inbounds i8, i8* %c, i64 2
  store i8 %call54.2, i8* %arrayidx56.2, align 1
  %arrayidx70.2 = getelementptr inbounds i8, i8* %c, i64 2
  %scevgep20.264 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 0
  %5908 = load i8, i8* %scevgep20.264, align 1
  %conv68.265 = zext i8 %5908 to i32
  %5909 = load i8, i8* %arrayidx70.2, align 1
  %conv71.266 = zext i8 %5909 to i32
  %xor72.267 = xor i32 %conv71.266, %conv68.265
  %conv73.268 = trunc i32 %xor72.267 to i8
  store i8 %conv73.268, i8* %arrayidx70.2, align 1
  %scevgep20.1.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 1
  %5910 = load i8, i8* %scevgep20.1.2, align 1
  %conv68.1.2 = zext i8 %5910 to i32
  %5911 = load i8, i8* %arrayidx70.2, align 1
  %conv71.1.2 = zext i8 %5911 to i32
  %xor72.1.2 = xor i32 %conv71.1.2, %conv68.1.2
  %conv73.1.2 = trunc i32 %xor72.1.2 to i8
  store i8 %conv73.1.2, i8* %arrayidx70.2, align 1
  %scevgep20.3.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 3
  %5912 = load i8, i8* %scevgep20.3.2, align 1
  %conv68.3.2 = zext i8 %5912 to i32
  %5913 = load i8, i8* %arrayidx70.2, align 1
  %conv71.3.2 = zext i8 %5913 to i32
  %xor72.3.2 = xor i32 %conv71.3.2, %conv68.3.2
  %conv73.3.2 = trunc i32 %xor72.3.2 to i8
  store i8 %conv73.3.2, i8* %arrayidx70.2, align 1
  %scevgep20.4.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 4
  %5914 = load i8, i8* %scevgep20.4.2, align 1
  %conv68.4.2 = zext i8 %5914 to i32
  %5915 = load i8, i8* %arrayidx70.2, align 1
  %conv71.4.2 = zext i8 %5915 to i32
  %xor72.4.2 = xor i32 %conv71.4.2, %conv68.4.2
  %conv73.4.2 = trunc i32 %xor72.4.2 to i8
  store i8 %conv73.4.2, i8* %arrayidx70.2, align 1
  %scevgep20.5.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 5
  %5916 = load i8, i8* %scevgep20.5.2, align 1
  %conv68.5.2 = zext i8 %5916 to i32
  %5917 = load i8, i8* %arrayidx70.2, align 1
  %conv71.5.2 = zext i8 %5917 to i32
  %xor72.5.2 = xor i32 %conv71.5.2, %conv68.5.2
  %conv73.5.2 = trunc i32 %xor72.5.2 to i8
  store i8 %conv73.5.2, i8* %arrayidx70.2, align 1
  %scevgep20.6.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 6
  %5918 = load i8, i8* %scevgep20.6.2, align 1
  %conv68.6.2 = zext i8 %5918 to i32
  %5919 = load i8, i8* %arrayidx70.2, align 1
  %conv71.6.2 = zext i8 %5919 to i32
  %xor72.6.2 = xor i32 %conv71.6.2, %conv68.6.2
  %conv73.6.2 = trunc i32 %xor72.6.2 to i8
  store i8 %conv73.6.2, i8* %arrayidx70.2, align 1
  %scevgep20.7.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 7
  %5920 = load i8, i8* %scevgep20.7.2, align 1
  %conv68.7.2 = zext i8 %5920 to i32
  %5921 = load i8, i8* %arrayidx70.2, align 1
  %conv71.7.2 = zext i8 %5921 to i32
  %xor72.7.2 = xor i32 %conv71.7.2, %conv68.7.2
  %conv73.7.2 = trunc i32 %xor72.7.2 to i8
  store i8 %conv73.7.2, i8* %arrayidx70.2, align 1
  %scevgep20.8.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 8
  %5922 = load i8, i8* %scevgep20.8.2, align 1
  %conv68.8.2 = zext i8 %5922 to i32
  %5923 = load i8, i8* %arrayidx70.2, align 1
  %conv71.8.2 = zext i8 %5923 to i32
  %xor72.8.2 = xor i32 %conv71.8.2, %conv68.8.2
  %conv73.8.2 = trunc i32 %xor72.8.2 to i8
  store i8 %conv73.8.2, i8* %arrayidx70.2, align 1
  %scevgep20.9.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 9
  %5924 = load i8, i8* %scevgep20.9.2, align 1
  %conv68.9.2 = zext i8 %5924 to i32
  %5925 = load i8, i8* %arrayidx70.2, align 1
  %conv71.9.2 = zext i8 %5925 to i32
  %xor72.9.2 = xor i32 %conv71.9.2, %conv68.9.2
  %conv73.9.2 = trunc i32 %xor72.9.2 to i8
  store i8 %conv73.9.2, i8* %arrayidx70.2, align 1
  %scevgep20.10.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 10
  %5926 = load i8, i8* %scevgep20.10.2, align 1
  %conv68.10.2 = zext i8 %5926 to i32
  %5927 = load i8, i8* %arrayidx70.2, align 1
  %conv71.10.2 = zext i8 %5927 to i32
  %xor72.10.2 = xor i32 %conv71.10.2, %conv68.10.2
  %conv73.10.2 = trunc i32 %xor72.10.2 to i8
  store i8 %conv73.10.2, i8* %arrayidx70.2, align 1
  %scevgep20.11.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 11
  %5928 = load i8, i8* %scevgep20.11.2, align 1
  %conv68.11.2 = zext i8 %5928 to i32
  %5929 = load i8, i8* %arrayidx70.2, align 1
  %conv71.11.2 = zext i8 %5929 to i32
  %xor72.11.2 = xor i32 %conv71.11.2, %conv68.11.2
  %conv73.11.2 = trunc i32 %xor72.11.2 to i8
  store i8 %conv73.11.2, i8* %arrayidx70.2, align 1
  %scevgep20.12.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 12
  %5930 = load i8, i8* %scevgep20.12.2, align 1
  %conv68.12.2 = zext i8 %5930 to i32
  %5931 = load i8, i8* %arrayidx70.2, align 1
  %conv71.12.2 = zext i8 %5931 to i32
  %xor72.12.2 = xor i32 %conv71.12.2, %conv68.12.2
  %conv73.12.2 = trunc i32 %xor72.12.2 to i8
  store i8 %conv73.12.2, i8* %arrayidx70.2, align 1
  %scevgep20.13.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 13
  %5932 = load i8, i8* %scevgep20.13.2, align 1
  %conv68.13.2 = zext i8 %5932 to i32
  %5933 = load i8, i8* %arrayidx70.2, align 1
  %conv71.13.2 = zext i8 %5933 to i32
  %xor72.13.2 = xor i32 %conv71.13.2, %conv68.13.2
  %conv73.13.2 = trunc i32 %xor72.13.2 to i8
  store i8 %conv73.13.2, i8* %arrayidx70.2, align 1
  %scevgep20.14.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 14
  %5934 = load i8, i8* %scevgep20.14.2, align 1
  %conv68.14.2 = zext i8 %5934 to i32
  %5935 = load i8, i8* %arrayidx70.2, align 1
  %conv71.14.2 = zext i8 %5935 to i32
  %xor72.14.2 = xor i32 %conv71.14.2, %conv68.14.2
  %conv73.14.2 = trunc i32 %xor72.14.2 to i8
  store i8 %conv73.14.2, i8* %arrayidx70.2, align 1
  %scevgep20.15.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 15
  %5936 = load i8, i8* %scevgep20.15.2, align 1
  %conv68.15.2 = zext i8 %5936 to i32
  %5937 = load i8, i8* %arrayidx70.2, align 1
  %conv71.15.2 = zext i8 %5937 to i32
  %xor72.15.2 = xor i32 %conv71.15.2, %conv68.15.2
  %conv73.15.2 = trunc i32 %xor72.15.2 to i8
  store i8 %conv73.15.2, i8* %arrayidx70.2, align 1
  %scevgep20.16.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 16
  %5938 = load i8, i8* %scevgep20.16.2, align 1
  %conv68.16.2 = zext i8 %5938 to i32
  %5939 = load i8, i8* %arrayidx70.2, align 1
  %conv71.16.2 = zext i8 %5939 to i32
  %xor72.16.2 = xor i32 %conv71.16.2, %conv68.16.2
  %conv73.16.2 = trunc i32 %xor72.16.2 to i8
  store i8 %conv73.16.2, i8* %arrayidx70.2, align 1
  %scevgep20.17.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 17
  %5940 = load i8, i8* %scevgep20.17.2, align 1
  %conv68.17.2 = zext i8 %5940 to i32
  %5941 = load i8, i8* %arrayidx70.2, align 1
  %conv71.17.2 = zext i8 %5941 to i32
  %xor72.17.2 = xor i32 %conv71.17.2, %conv68.17.2
  %conv73.17.2 = trunc i32 %xor72.17.2 to i8
  store i8 %conv73.17.2, i8* %arrayidx70.2, align 1
  %scevgep20.18.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 18
  %5942 = load i8, i8* %scevgep20.18.2, align 1
  %conv68.18.2 = zext i8 %5942 to i32
  %5943 = load i8, i8* %arrayidx70.2, align 1
  %conv71.18.2 = zext i8 %5943 to i32
  %xor72.18.2 = xor i32 %conv71.18.2, %conv68.18.2
  %conv73.18.2 = trunc i32 %xor72.18.2 to i8
  store i8 %conv73.18.2, i8* %arrayidx70.2, align 1
  %scevgep20.19.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 19
  %5944 = load i8, i8* %scevgep20.19.2, align 1
  %conv68.19.2 = zext i8 %5944 to i32
  %5945 = load i8, i8* %arrayidx70.2, align 1
  %conv71.19.2 = zext i8 %5945 to i32
  %xor72.19.2 = xor i32 %conv71.19.2, %conv68.19.2
  %conv73.19.2 = trunc i32 %xor72.19.2 to i8
  store i8 %conv73.19.2, i8* %arrayidx70.2, align 1
  %scevgep20.20.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 20
  %5946 = load i8, i8* %scevgep20.20.2, align 1
  %conv68.20.2 = zext i8 %5946 to i32
  %5947 = load i8, i8* %arrayidx70.2, align 1
  %conv71.20.2 = zext i8 %5947 to i32
  %xor72.20.2 = xor i32 %conv71.20.2, %conv68.20.2
  %conv73.20.2 = trunc i32 %xor72.20.2 to i8
  store i8 %conv73.20.2, i8* %arrayidx70.2, align 1
  %scevgep20.21.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 21
  %5948 = load i8, i8* %scevgep20.21.2, align 1
  %conv68.21.2 = zext i8 %5948 to i32
  %5949 = load i8, i8* %arrayidx70.2, align 1
  %conv71.21.2 = zext i8 %5949 to i32
  %xor72.21.2 = xor i32 %conv71.21.2, %conv68.21.2
  %conv73.21.2 = trunc i32 %xor72.21.2 to i8
  store i8 %conv73.21.2, i8* %arrayidx70.2, align 1
  %scevgep20.22.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 22
  %5950 = load i8, i8* %scevgep20.22.2, align 1
  %conv68.22.2 = zext i8 %5950 to i32
  %5951 = load i8, i8* %arrayidx70.2, align 1
  %conv71.22.2 = zext i8 %5951 to i32
  %xor72.22.2 = xor i32 %conv71.22.2, %conv68.22.2
  %conv73.22.2 = trunc i32 %xor72.22.2 to i8
  store i8 %conv73.22.2, i8* %arrayidx70.2, align 1
  %scevgep20.23.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 23
  %5952 = load i8, i8* %scevgep20.23.2, align 1
  %conv68.23.2 = zext i8 %5952 to i32
  %5953 = load i8, i8* %arrayidx70.2, align 1
  %conv71.23.2 = zext i8 %5953 to i32
  %xor72.23.2 = xor i32 %conv71.23.2, %conv68.23.2
  %conv73.23.2 = trunc i32 %xor72.23.2 to i8
  store i8 %conv73.23.2, i8* %arrayidx70.2, align 1
  %scevgep20.24.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 24
  %5954 = load i8, i8* %scevgep20.24.2, align 1
  %conv68.24.2 = zext i8 %5954 to i32
  %5955 = load i8, i8* %arrayidx70.2, align 1
  %conv71.24.2 = zext i8 %5955 to i32
  %xor72.24.2 = xor i32 %conv71.24.2, %conv68.24.2
  %conv73.24.2 = trunc i32 %xor72.24.2 to i8
  store i8 %conv73.24.2, i8* %arrayidx70.2, align 1
  %scevgep20.25.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 25
  %5956 = load i8, i8* %scevgep20.25.2, align 1
  %conv68.25.2 = zext i8 %5956 to i32
  %5957 = load i8, i8* %arrayidx70.2, align 1
  %conv71.25.2 = zext i8 %5957 to i32
  %xor72.25.2 = xor i32 %conv71.25.2, %conv68.25.2
  %conv73.25.2 = trunc i32 %xor72.25.2 to i8
  store i8 %conv73.25.2, i8* %arrayidx70.2, align 1
  %scevgep20.26.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 26
  %5958 = load i8, i8* %scevgep20.26.2, align 1
  %conv68.26.2 = zext i8 %5958 to i32
  %5959 = load i8, i8* %arrayidx70.2, align 1
  %conv71.26.2 = zext i8 %5959 to i32
  %xor72.26.2 = xor i32 %conv71.26.2, %conv68.26.2
  %conv73.26.2 = trunc i32 %xor72.26.2 to i8
  store i8 %conv73.26.2, i8* %arrayidx70.2, align 1
  %scevgep20.27.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 27
  %5960 = load i8, i8* %scevgep20.27.2, align 1
  %conv68.27.2 = zext i8 %5960 to i32
  %5961 = load i8, i8* %arrayidx70.2, align 1
  %conv71.27.2 = zext i8 %5961 to i32
  %xor72.27.2 = xor i32 %conv71.27.2, %conv68.27.2
  %conv73.27.2 = trunc i32 %xor72.27.2 to i8
  store i8 %conv73.27.2, i8* %arrayidx70.2, align 1
  %scevgep20.28.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 28
  %5962 = load i8, i8* %scevgep20.28.2, align 1
  %conv68.28.2 = zext i8 %5962 to i32
  %5963 = load i8, i8* %arrayidx70.2, align 1
  %conv71.28.2 = zext i8 %5963 to i32
  %xor72.28.2 = xor i32 %conv71.28.2, %conv68.28.2
  %conv73.28.2 = trunc i32 %xor72.28.2 to i8
  store i8 %conv73.28.2, i8* %arrayidx70.2, align 1
  %scevgep20.29.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 29
  %5964 = load i8, i8* %scevgep20.29.2, align 1
  %conv68.29.2 = zext i8 %5964 to i32
  %5965 = load i8, i8* %arrayidx70.2, align 1
  %conv71.29.2 = zext i8 %5965 to i32
  %xor72.29.2 = xor i32 %conv71.29.2, %conv68.29.2
  %conv73.29.2 = trunc i32 %xor72.29.2 to i8
  store i8 %conv73.29.2, i8* %arrayidx70.2, align 1
  %scevgep20.30.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 30
  %5966 = load i8, i8* %scevgep20.30.2, align 1
  %conv68.30.2 = zext i8 %5966 to i32
  %5967 = load i8, i8* %arrayidx70.2, align 1
  %conv71.30.2 = zext i8 %5967 to i32
  %xor72.30.2 = xor i32 %conv71.30.2, %conv68.30.2
  %conv73.30.2 = trunc i32 %xor72.30.2 to i8
  store i8 %conv73.30.2, i8* %arrayidx70.2, align 1
  %scevgep20.31.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 31
  %5968 = load i8, i8* %scevgep20.31.2, align 1
  %conv68.31.2 = zext i8 %5968 to i32
  %5969 = load i8, i8* %arrayidx70.2, align 1
  %conv71.31.2 = zext i8 %5969 to i32
  %xor72.31.2 = xor i32 %conv71.31.2, %conv68.31.2
  %conv73.31.2 = trunc i32 %xor72.31.2 to i8
  store i8 %conv73.31.2, i8* %arrayidx70.2, align 1
  %scevgep20.32.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 32
  %5970 = load i8, i8* %scevgep20.32.2, align 1
  %conv68.32.2 = zext i8 %5970 to i32
  %5971 = load i8, i8* %arrayidx70.2, align 1
  %conv71.32.2 = zext i8 %5971 to i32
  %xor72.32.2 = xor i32 %conv71.32.2, %conv68.32.2
  %conv73.32.2 = trunc i32 %xor72.32.2 to i8
  store i8 %conv73.32.2, i8* %arrayidx70.2, align 1
  %scevgep20.33.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 33
  %5972 = load i8, i8* %scevgep20.33.2, align 1
  %conv68.33.2 = zext i8 %5972 to i32
  %5973 = load i8, i8* %arrayidx70.2, align 1
  %conv71.33.2 = zext i8 %5973 to i32
  %xor72.33.2 = xor i32 %conv71.33.2, %conv68.33.2
  %conv73.33.2 = trunc i32 %xor72.33.2 to i8
  store i8 %conv73.33.2, i8* %arrayidx70.2, align 1
  %scevgep20.34.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 34
  %5974 = load i8, i8* %scevgep20.34.2, align 1
  %conv68.34.2 = zext i8 %5974 to i32
  %5975 = load i8, i8* %arrayidx70.2, align 1
  %conv71.34.2 = zext i8 %5975 to i32
  %xor72.34.2 = xor i32 %conv71.34.2, %conv68.34.2
  %conv73.34.2 = trunc i32 %xor72.34.2 to i8
  store i8 %conv73.34.2, i8* %arrayidx70.2, align 1
  %scevgep20.35.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 35
  %5976 = load i8, i8* %scevgep20.35.2, align 1
  %conv68.35.2 = zext i8 %5976 to i32
  %5977 = load i8, i8* %arrayidx70.2, align 1
  %conv71.35.2 = zext i8 %5977 to i32
  %xor72.35.2 = xor i32 %conv71.35.2, %conv68.35.2
  %conv73.35.2 = trunc i32 %xor72.35.2 to i8
  store i8 %conv73.35.2, i8* %arrayidx70.2, align 1
  %scevgep20.36.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 36
  %5978 = load i8, i8* %scevgep20.36.2, align 1
  %conv68.36.2 = zext i8 %5978 to i32
  %5979 = load i8, i8* %arrayidx70.2, align 1
  %conv71.36.2 = zext i8 %5979 to i32
  %xor72.36.2 = xor i32 %conv71.36.2, %conv68.36.2
  %conv73.36.2 = trunc i32 %xor72.36.2 to i8
  store i8 %conv73.36.2, i8* %arrayidx70.2, align 1
  %scevgep20.37.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 37
  %5980 = load i8, i8* %scevgep20.37.2, align 1
  %conv68.37.2 = zext i8 %5980 to i32
  %5981 = load i8, i8* %arrayidx70.2, align 1
  %conv71.37.2 = zext i8 %5981 to i32
  %xor72.37.2 = xor i32 %conv71.37.2, %conv68.37.2
  %conv73.37.2 = trunc i32 %xor72.37.2 to i8
  store i8 %conv73.37.2, i8* %arrayidx70.2, align 1
  %scevgep20.38.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 38
  %5982 = load i8, i8* %scevgep20.38.2, align 1
  %conv68.38.2 = zext i8 %5982 to i32
  %5983 = load i8, i8* %arrayidx70.2, align 1
  %conv71.38.2 = zext i8 %5983 to i32
  %xor72.38.2 = xor i32 %conv71.38.2, %conv68.38.2
  %conv73.38.2 = trunc i32 %xor72.38.2 to i8
  store i8 %conv73.38.2, i8* %arrayidx70.2, align 1
  %scevgep20.39.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 39
  %5984 = load i8, i8* %scevgep20.39.2, align 1
  %conv68.39.2 = zext i8 %5984 to i32
  %5985 = load i8, i8* %arrayidx70.2, align 1
  %conv71.39.2 = zext i8 %5985 to i32
  %xor72.39.2 = xor i32 %conv71.39.2, %conv68.39.2
  %conv73.39.2 = trunc i32 %xor72.39.2 to i8
  store i8 %conv73.39.2, i8* %arrayidx70.2, align 1
  %scevgep20.40.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 0, i64 40
  %5986 = load i8, i8* %scevgep20.40.2, align 1
  %conv68.40.2 = zext i8 %5986 to i32
  %5987 = load i8, i8* %arrayidx70.2, align 1
  %conv71.40.2 = zext i8 %5987 to i32
  %xor72.40.2 = xor i32 %conv71.40.2, %conv68.40.2
  %conv73.40.2 = trunc i32 %xor72.40.2 to i8
  store i8 %conv73.40.2, i8* %arrayidx70.2, align 1
  %scevgep19.2 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5905, i64 0, i64 1, i64 0
  %5988 = bitcast i8* %scevgep19.2 to [41 x [41 x i8]]*
  %arrayidx51.3 = getelementptr inbounds i8, i8* %a, i64 3
  %5989 = load i8, i8* %arrayidx51.3, align 1
  %arrayidx53.3 = getelementptr inbounds i8, i8* %b, i64 3
  %5990 = load i8, i8* %arrayidx53.3, align 1
  %call54.3 = call zeroext i8 @mult(i8 zeroext %5989, i8 zeroext %5990)
  %arrayidx56.3 = getelementptr inbounds i8, i8* %c, i64 3
  store i8 %call54.3, i8* %arrayidx56.3, align 1
  %arrayidx70.3 = getelementptr inbounds i8, i8* %c, i64 3
  %scevgep20.374 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 0
  %5991 = load i8, i8* %scevgep20.374, align 1
  %conv68.375 = zext i8 %5991 to i32
  %5992 = load i8, i8* %arrayidx70.3, align 1
  %conv71.376 = zext i8 %5992 to i32
  %xor72.377 = xor i32 %conv71.376, %conv68.375
  %conv73.378 = trunc i32 %xor72.377 to i8
  store i8 %conv73.378, i8* %arrayidx70.3, align 1
  %scevgep20.1.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 1
  %5993 = load i8, i8* %scevgep20.1.3, align 1
  %conv68.1.3 = zext i8 %5993 to i32
  %5994 = load i8, i8* %arrayidx70.3, align 1
  %conv71.1.3 = zext i8 %5994 to i32
  %xor72.1.3 = xor i32 %conv71.1.3, %conv68.1.3
  %conv73.1.3 = trunc i32 %xor72.1.3 to i8
  store i8 %conv73.1.3, i8* %arrayidx70.3, align 1
  %scevgep20.2.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 2
  %5995 = load i8, i8* %scevgep20.2.3, align 1
  %conv68.2.3 = zext i8 %5995 to i32
  %5996 = load i8, i8* %arrayidx70.3, align 1
  %conv71.2.3 = zext i8 %5996 to i32
  %xor72.2.3 = xor i32 %conv71.2.3, %conv68.2.3
  %conv73.2.3 = trunc i32 %xor72.2.3 to i8
  store i8 %conv73.2.3, i8* %arrayidx70.3, align 1
  %scevgep20.4.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 4
  %5997 = load i8, i8* %scevgep20.4.3, align 1
  %conv68.4.3 = zext i8 %5997 to i32
  %5998 = load i8, i8* %arrayidx70.3, align 1
  %conv71.4.3 = zext i8 %5998 to i32
  %xor72.4.3 = xor i32 %conv71.4.3, %conv68.4.3
  %conv73.4.3 = trunc i32 %xor72.4.3 to i8
  store i8 %conv73.4.3, i8* %arrayidx70.3, align 1
  %scevgep20.5.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 5
  %5999 = load i8, i8* %scevgep20.5.3, align 1
  %conv68.5.3 = zext i8 %5999 to i32
  %6000 = load i8, i8* %arrayidx70.3, align 1
  %conv71.5.3 = zext i8 %6000 to i32
  %xor72.5.3 = xor i32 %conv71.5.3, %conv68.5.3
  %conv73.5.3 = trunc i32 %xor72.5.3 to i8
  store i8 %conv73.5.3, i8* %arrayidx70.3, align 1
  %scevgep20.6.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 6
  %6001 = load i8, i8* %scevgep20.6.3, align 1
  %conv68.6.3 = zext i8 %6001 to i32
  %6002 = load i8, i8* %arrayidx70.3, align 1
  %conv71.6.3 = zext i8 %6002 to i32
  %xor72.6.3 = xor i32 %conv71.6.3, %conv68.6.3
  %conv73.6.3 = trunc i32 %xor72.6.3 to i8
  store i8 %conv73.6.3, i8* %arrayidx70.3, align 1
  %scevgep20.7.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 7
  %6003 = load i8, i8* %scevgep20.7.3, align 1
  %conv68.7.3 = zext i8 %6003 to i32
  %6004 = load i8, i8* %arrayidx70.3, align 1
  %conv71.7.3 = zext i8 %6004 to i32
  %xor72.7.3 = xor i32 %conv71.7.3, %conv68.7.3
  %conv73.7.3 = trunc i32 %xor72.7.3 to i8
  store i8 %conv73.7.3, i8* %arrayidx70.3, align 1
  %scevgep20.8.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 8
  %6005 = load i8, i8* %scevgep20.8.3, align 1
  %conv68.8.3 = zext i8 %6005 to i32
  %6006 = load i8, i8* %arrayidx70.3, align 1
  %conv71.8.3 = zext i8 %6006 to i32
  %xor72.8.3 = xor i32 %conv71.8.3, %conv68.8.3
  %conv73.8.3 = trunc i32 %xor72.8.3 to i8
  store i8 %conv73.8.3, i8* %arrayidx70.3, align 1
  %scevgep20.9.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 9
  %6007 = load i8, i8* %scevgep20.9.3, align 1
  %conv68.9.3 = zext i8 %6007 to i32
  %6008 = load i8, i8* %arrayidx70.3, align 1
  %conv71.9.3 = zext i8 %6008 to i32
  %xor72.9.3 = xor i32 %conv71.9.3, %conv68.9.3
  %conv73.9.3 = trunc i32 %xor72.9.3 to i8
  store i8 %conv73.9.3, i8* %arrayidx70.3, align 1
  %scevgep20.10.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 10
  %6009 = load i8, i8* %scevgep20.10.3, align 1
  %conv68.10.3 = zext i8 %6009 to i32
  %6010 = load i8, i8* %arrayidx70.3, align 1
  %conv71.10.3 = zext i8 %6010 to i32
  %xor72.10.3 = xor i32 %conv71.10.3, %conv68.10.3
  %conv73.10.3 = trunc i32 %xor72.10.3 to i8
  store i8 %conv73.10.3, i8* %arrayidx70.3, align 1
  %scevgep20.11.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 11
  %6011 = load i8, i8* %scevgep20.11.3, align 1
  %conv68.11.3 = zext i8 %6011 to i32
  %6012 = load i8, i8* %arrayidx70.3, align 1
  %conv71.11.3 = zext i8 %6012 to i32
  %xor72.11.3 = xor i32 %conv71.11.3, %conv68.11.3
  %conv73.11.3 = trunc i32 %xor72.11.3 to i8
  store i8 %conv73.11.3, i8* %arrayidx70.3, align 1
  %scevgep20.12.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 12
  %6013 = load i8, i8* %scevgep20.12.3, align 1
  %conv68.12.3 = zext i8 %6013 to i32
  %6014 = load i8, i8* %arrayidx70.3, align 1
  %conv71.12.3 = zext i8 %6014 to i32
  %xor72.12.3 = xor i32 %conv71.12.3, %conv68.12.3
  %conv73.12.3 = trunc i32 %xor72.12.3 to i8
  store i8 %conv73.12.3, i8* %arrayidx70.3, align 1
  %scevgep20.13.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 13
  %6015 = load i8, i8* %scevgep20.13.3, align 1
  %conv68.13.3 = zext i8 %6015 to i32
  %6016 = load i8, i8* %arrayidx70.3, align 1
  %conv71.13.3 = zext i8 %6016 to i32
  %xor72.13.3 = xor i32 %conv71.13.3, %conv68.13.3
  %conv73.13.3 = trunc i32 %xor72.13.3 to i8
  store i8 %conv73.13.3, i8* %arrayidx70.3, align 1
  %scevgep20.14.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 14
  %6017 = load i8, i8* %scevgep20.14.3, align 1
  %conv68.14.3 = zext i8 %6017 to i32
  %6018 = load i8, i8* %arrayidx70.3, align 1
  %conv71.14.3 = zext i8 %6018 to i32
  %xor72.14.3 = xor i32 %conv71.14.3, %conv68.14.3
  %conv73.14.3 = trunc i32 %xor72.14.3 to i8
  store i8 %conv73.14.3, i8* %arrayidx70.3, align 1
  %scevgep20.15.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 15
  %6019 = load i8, i8* %scevgep20.15.3, align 1
  %conv68.15.3 = zext i8 %6019 to i32
  %6020 = load i8, i8* %arrayidx70.3, align 1
  %conv71.15.3 = zext i8 %6020 to i32
  %xor72.15.3 = xor i32 %conv71.15.3, %conv68.15.3
  %conv73.15.3 = trunc i32 %xor72.15.3 to i8
  store i8 %conv73.15.3, i8* %arrayidx70.3, align 1
  %scevgep20.16.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 16
  %6021 = load i8, i8* %scevgep20.16.3, align 1
  %conv68.16.3 = zext i8 %6021 to i32
  %6022 = load i8, i8* %arrayidx70.3, align 1
  %conv71.16.3 = zext i8 %6022 to i32
  %xor72.16.3 = xor i32 %conv71.16.3, %conv68.16.3
  %conv73.16.3 = trunc i32 %xor72.16.3 to i8
  store i8 %conv73.16.3, i8* %arrayidx70.3, align 1
  %scevgep20.17.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 17
  %6023 = load i8, i8* %scevgep20.17.3, align 1
  %conv68.17.3 = zext i8 %6023 to i32
  %6024 = load i8, i8* %arrayidx70.3, align 1
  %conv71.17.3 = zext i8 %6024 to i32
  %xor72.17.3 = xor i32 %conv71.17.3, %conv68.17.3
  %conv73.17.3 = trunc i32 %xor72.17.3 to i8
  store i8 %conv73.17.3, i8* %arrayidx70.3, align 1
  %scevgep20.18.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 18
  %6025 = load i8, i8* %scevgep20.18.3, align 1
  %conv68.18.3 = zext i8 %6025 to i32
  %6026 = load i8, i8* %arrayidx70.3, align 1
  %conv71.18.3 = zext i8 %6026 to i32
  %xor72.18.3 = xor i32 %conv71.18.3, %conv68.18.3
  %conv73.18.3 = trunc i32 %xor72.18.3 to i8
  store i8 %conv73.18.3, i8* %arrayidx70.3, align 1
  %scevgep20.19.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 19
  %6027 = load i8, i8* %scevgep20.19.3, align 1
  %conv68.19.3 = zext i8 %6027 to i32
  %6028 = load i8, i8* %arrayidx70.3, align 1
  %conv71.19.3 = zext i8 %6028 to i32
  %xor72.19.3 = xor i32 %conv71.19.3, %conv68.19.3
  %conv73.19.3 = trunc i32 %xor72.19.3 to i8
  store i8 %conv73.19.3, i8* %arrayidx70.3, align 1
  %scevgep20.20.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 20
  %6029 = load i8, i8* %scevgep20.20.3, align 1
  %conv68.20.3 = zext i8 %6029 to i32
  %6030 = load i8, i8* %arrayidx70.3, align 1
  %conv71.20.3 = zext i8 %6030 to i32
  %xor72.20.3 = xor i32 %conv71.20.3, %conv68.20.3
  %conv73.20.3 = trunc i32 %xor72.20.3 to i8
  store i8 %conv73.20.3, i8* %arrayidx70.3, align 1
  %scevgep20.21.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 21
  %6031 = load i8, i8* %scevgep20.21.3, align 1
  %conv68.21.3 = zext i8 %6031 to i32
  %6032 = load i8, i8* %arrayidx70.3, align 1
  %conv71.21.3 = zext i8 %6032 to i32
  %xor72.21.3 = xor i32 %conv71.21.3, %conv68.21.3
  %conv73.21.3 = trunc i32 %xor72.21.3 to i8
  store i8 %conv73.21.3, i8* %arrayidx70.3, align 1
  %scevgep20.22.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 22
  %6033 = load i8, i8* %scevgep20.22.3, align 1
  %conv68.22.3 = zext i8 %6033 to i32
  %6034 = load i8, i8* %arrayidx70.3, align 1
  %conv71.22.3 = zext i8 %6034 to i32
  %xor72.22.3 = xor i32 %conv71.22.3, %conv68.22.3
  %conv73.22.3 = trunc i32 %xor72.22.3 to i8
  store i8 %conv73.22.3, i8* %arrayidx70.3, align 1
  %scevgep20.23.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 23
  %6035 = load i8, i8* %scevgep20.23.3, align 1
  %conv68.23.3 = zext i8 %6035 to i32
  %6036 = load i8, i8* %arrayidx70.3, align 1
  %conv71.23.3 = zext i8 %6036 to i32
  %xor72.23.3 = xor i32 %conv71.23.3, %conv68.23.3
  %conv73.23.3 = trunc i32 %xor72.23.3 to i8
  store i8 %conv73.23.3, i8* %arrayidx70.3, align 1
  %scevgep20.24.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 24
  %6037 = load i8, i8* %scevgep20.24.3, align 1
  %conv68.24.3 = zext i8 %6037 to i32
  %6038 = load i8, i8* %arrayidx70.3, align 1
  %conv71.24.3 = zext i8 %6038 to i32
  %xor72.24.3 = xor i32 %conv71.24.3, %conv68.24.3
  %conv73.24.3 = trunc i32 %xor72.24.3 to i8
  store i8 %conv73.24.3, i8* %arrayidx70.3, align 1
  %scevgep20.25.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 25
  %6039 = load i8, i8* %scevgep20.25.3, align 1
  %conv68.25.3 = zext i8 %6039 to i32
  %6040 = load i8, i8* %arrayidx70.3, align 1
  %conv71.25.3 = zext i8 %6040 to i32
  %xor72.25.3 = xor i32 %conv71.25.3, %conv68.25.3
  %conv73.25.3 = trunc i32 %xor72.25.3 to i8
  store i8 %conv73.25.3, i8* %arrayidx70.3, align 1
  %scevgep20.26.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 26
  %6041 = load i8, i8* %scevgep20.26.3, align 1
  %conv68.26.3 = zext i8 %6041 to i32
  %6042 = load i8, i8* %arrayidx70.3, align 1
  %conv71.26.3 = zext i8 %6042 to i32
  %xor72.26.3 = xor i32 %conv71.26.3, %conv68.26.3
  %conv73.26.3 = trunc i32 %xor72.26.3 to i8
  store i8 %conv73.26.3, i8* %arrayidx70.3, align 1
  %scevgep20.27.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 27
  %6043 = load i8, i8* %scevgep20.27.3, align 1
  %conv68.27.3 = zext i8 %6043 to i32
  %6044 = load i8, i8* %arrayidx70.3, align 1
  %conv71.27.3 = zext i8 %6044 to i32
  %xor72.27.3 = xor i32 %conv71.27.3, %conv68.27.3
  %conv73.27.3 = trunc i32 %xor72.27.3 to i8
  store i8 %conv73.27.3, i8* %arrayidx70.3, align 1
  %scevgep20.28.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 28
  %6045 = load i8, i8* %scevgep20.28.3, align 1
  %conv68.28.3 = zext i8 %6045 to i32
  %6046 = load i8, i8* %arrayidx70.3, align 1
  %conv71.28.3 = zext i8 %6046 to i32
  %xor72.28.3 = xor i32 %conv71.28.3, %conv68.28.3
  %conv73.28.3 = trunc i32 %xor72.28.3 to i8
  store i8 %conv73.28.3, i8* %arrayidx70.3, align 1
  %scevgep20.29.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 29
  %6047 = load i8, i8* %scevgep20.29.3, align 1
  %conv68.29.3 = zext i8 %6047 to i32
  %6048 = load i8, i8* %arrayidx70.3, align 1
  %conv71.29.3 = zext i8 %6048 to i32
  %xor72.29.3 = xor i32 %conv71.29.3, %conv68.29.3
  %conv73.29.3 = trunc i32 %xor72.29.3 to i8
  store i8 %conv73.29.3, i8* %arrayidx70.3, align 1
  %scevgep20.30.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 30
  %6049 = load i8, i8* %scevgep20.30.3, align 1
  %conv68.30.3 = zext i8 %6049 to i32
  %6050 = load i8, i8* %arrayidx70.3, align 1
  %conv71.30.3 = zext i8 %6050 to i32
  %xor72.30.3 = xor i32 %conv71.30.3, %conv68.30.3
  %conv73.30.3 = trunc i32 %xor72.30.3 to i8
  store i8 %conv73.30.3, i8* %arrayidx70.3, align 1
  %scevgep20.31.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 31
  %6051 = load i8, i8* %scevgep20.31.3, align 1
  %conv68.31.3 = zext i8 %6051 to i32
  %6052 = load i8, i8* %arrayidx70.3, align 1
  %conv71.31.3 = zext i8 %6052 to i32
  %xor72.31.3 = xor i32 %conv71.31.3, %conv68.31.3
  %conv73.31.3 = trunc i32 %xor72.31.3 to i8
  store i8 %conv73.31.3, i8* %arrayidx70.3, align 1
  %scevgep20.32.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 32
  %6053 = load i8, i8* %scevgep20.32.3, align 1
  %conv68.32.3 = zext i8 %6053 to i32
  %6054 = load i8, i8* %arrayidx70.3, align 1
  %conv71.32.3 = zext i8 %6054 to i32
  %xor72.32.3 = xor i32 %conv71.32.3, %conv68.32.3
  %conv73.32.3 = trunc i32 %xor72.32.3 to i8
  store i8 %conv73.32.3, i8* %arrayidx70.3, align 1
  %scevgep20.33.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 33
  %6055 = load i8, i8* %scevgep20.33.3, align 1
  %conv68.33.3 = zext i8 %6055 to i32
  %6056 = load i8, i8* %arrayidx70.3, align 1
  %conv71.33.3 = zext i8 %6056 to i32
  %xor72.33.3 = xor i32 %conv71.33.3, %conv68.33.3
  %conv73.33.3 = trunc i32 %xor72.33.3 to i8
  store i8 %conv73.33.3, i8* %arrayidx70.3, align 1
  %scevgep20.34.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 34
  %6057 = load i8, i8* %scevgep20.34.3, align 1
  %conv68.34.3 = zext i8 %6057 to i32
  %6058 = load i8, i8* %arrayidx70.3, align 1
  %conv71.34.3 = zext i8 %6058 to i32
  %xor72.34.3 = xor i32 %conv71.34.3, %conv68.34.3
  %conv73.34.3 = trunc i32 %xor72.34.3 to i8
  store i8 %conv73.34.3, i8* %arrayidx70.3, align 1
  %scevgep20.35.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 35
  %6059 = load i8, i8* %scevgep20.35.3, align 1
  %conv68.35.3 = zext i8 %6059 to i32
  %6060 = load i8, i8* %arrayidx70.3, align 1
  %conv71.35.3 = zext i8 %6060 to i32
  %xor72.35.3 = xor i32 %conv71.35.3, %conv68.35.3
  %conv73.35.3 = trunc i32 %xor72.35.3 to i8
  store i8 %conv73.35.3, i8* %arrayidx70.3, align 1
  %scevgep20.36.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 36
  %6061 = load i8, i8* %scevgep20.36.3, align 1
  %conv68.36.3 = zext i8 %6061 to i32
  %6062 = load i8, i8* %arrayidx70.3, align 1
  %conv71.36.3 = zext i8 %6062 to i32
  %xor72.36.3 = xor i32 %conv71.36.3, %conv68.36.3
  %conv73.36.3 = trunc i32 %xor72.36.3 to i8
  store i8 %conv73.36.3, i8* %arrayidx70.3, align 1
  %scevgep20.37.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 37
  %6063 = load i8, i8* %scevgep20.37.3, align 1
  %conv68.37.3 = zext i8 %6063 to i32
  %6064 = load i8, i8* %arrayidx70.3, align 1
  %conv71.37.3 = zext i8 %6064 to i32
  %xor72.37.3 = xor i32 %conv71.37.3, %conv68.37.3
  %conv73.37.3 = trunc i32 %xor72.37.3 to i8
  store i8 %conv73.37.3, i8* %arrayidx70.3, align 1
  %scevgep20.38.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 38
  %6065 = load i8, i8* %scevgep20.38.3, align 1
  %conv68.38.3 = zext i8 %6065 to i32
  %6066 = load i8, i8* %arrayidx70.3, align 1
  %conv71.38.3 = zext i8 %6066 to i32
  %xor72.38.3 = xor i32 %conv71.38.3, %conv68.38.3
  %conv73.38.3 = trunc i32 %xor72.38.3 to i8
  store i8 %conv73.38.3, i8* %arrayidx70.3, align 1
  %scevgep20.39.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 39
  %6067 = load i8, i8* %scevgep20.39.3, align 1
  %conv68.39.3 = zext i8 %6067 to i32
  %6068 = load i8, i8* %arrayidx70.3, align 1
  %conv71.39.3 = zext i8 %6068 to i32
  %xor72.39.3 = xor i32 %conv71.39.3, %conv68.39.3
  %conv73.39.3 = trunc i32 %xor72.39.3 to i8
  store i8 %conv73.39.3, i8* %arrayidx70.3, align 1
  %scevgep20.40.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 0, i64 40
  %6069 = load i8, i8* %scevgep20.40.3, align 1
  %conv68.40.3 = zext i8 %6069 to i32
  %6070 = load i8, i8* %arrayidx70.3, align 1
  %conv71.40.3 = zext i8 %6070 to i32
  %xor72.40.3 = xor i32 %conv71.40.3, %conv68.40.3
  %conv73.40.3 = trunc i32 %xor72.40.3 to i8
  store i8 %conv73.40.3, i8* %arrayidx70.3, align 1
  %scevgep19.3 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %5988, i64 0, i64 1, i64 0
  %6071 = bitcast i8* %scevgep19.3 to [41 x [41 x i8]]*
  %arrayidx51.4 = getelementptr inbounds i8, i8* %a, i64 4
  %6072 = load i8, i8* %arrayidx51.4, align 1
  %arrayidx53.4 = getelementptr inbounds i8, i8* %b, i64 4
  %6073 = load i8, i8* %arrayidx53.4, align 1
  %call54.4 = call zeroext i8 @mult(i8 zeroext %6072, i8 zeroext %6073)
  %arrayidx56.4 = getelementptr inbounds i8, i8* %c, i64 4
  store i8 %call54.4, i8* %arrayidx56.4, align 1
  %arrayidx70.4 = getelementptr inbounds i8, i8* %c, i64 4
  %scevgep20.484 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 0
  %6074 = load i8, i8* %scevgep20.484, align 1
  %conv68.485 = zext i8 %6074 to i32
  %6075 = load i8, i8* %arrayidx70.4, align 1
  %conv71.486 = zext i8 %6075 to i32
  %xor72.487 = xor i32 %conv71.486, %conv68.485
  %conv73.488 = trunc i32 %xor72.487 to i8
  store i8 %conv73.488, i8* %arrayidx70.4, align 1
  %scevgep20.1.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 1
  %6076 = load i8, i8* %scevgep20.1.4, align 1
  %conv68.1.4 = zext i8 %6076 to i32
  %6077 = load i8, i8* %arrayidx70.4, align 1
  %conv71.1.4 = zext i8 %6077 to i32
  %xor72.1.4 = xor i32 %conv71.1.4, %conv68.1.4
  %conv73.1.4 = trunc i32 %xor72.1.4 to i8
  store i8 %conv73.1.4, i8* %arrayidx70.4, align 1
  %scevgep20.2.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 2
  %6078 = load i8, i8* %scevgep20.2.4, align 1
  %conv68.2.4 = zext i8 %6078 to i32
  %6079 = load i8, i8* %arrayidx70.4, align 1
  %conv71.2.4 = zext i8 %6079 to i32
  %xor72.2.4 = xor i32 %conv71.2.4, %conv68.2.4
  %conv73.2.4 = trunc i32 %xor72.2.4 to i8
  store i8 %conv73.2.4, i8* %arrayidx70.4, align 1
  %scevgep20.3.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 3
  %6080 = load i8, i8* %scevgep20.3.4, align 1
  %conv68.3.4 = zext i8 %6080 to i32
  %6081 = load i8, i8* %arrayidx70.4, align 1
  %conv71.3.4 = zext i8 %6081 to i32
  %xor72.3.4 = xor i32 %conv71.3.4, %conv68.3.4
  %conv73.3.4 = trunc i32 %xor72.3.4 to i8
  store i8 %conv73.3.4, i8* %arrayidx70.4, align 1
  %scevgep20.5.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 5
  %6082 = load i8, i8* %scevgep20.5.4, align 1
  %conv68.5.4 = zext i8 %6082 to i32
  %6083 = load i8, i8* %arrayidx70.4, align 1
  %conv71.5.4 = zext i8 %6083 to i32
  %xor72.5.4 = xor i32 %conv71.5.4, %conv68.5.4
  %conv73.5.4 = trunc i32 %xor72.5.4 to i8
  store i8 %conv73.5.4, i8* %arrayidx70.4, align 1
  %scevgep20.6.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 6
  %6084 = load i8, i8* %scevgep20.6.4, align 1
  %conv68.6.4 = zext i8 %6084 to i32
  %6085 = load i8, i8* %arrayidx70.4, align 1
  %conv71.6.4 = zext i8 %6085 to i32
  %xor72.6.4 = xor i32 %conv71.6.4, %conv68.6.4
  %conv73.6.4 = trunc i32 %xor72.6.4 to i8
  store i8 %conv73.6.4, i8* %arrayidx70.4, align 1
  %scevgep20.7.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 7
  %6086 = load i8, i8* %scevgep20.7.4, align 1
  %conv68.7.4 = zext i8 %6086 to i32
  %6087 = load i8, i8* %arrayidx70.4, align 1
  %conv71.7.4 = zext i8 %6087 to i32
  %xor72.7.4 = xor i32 %conv71.7.4, %conv68.7.4
  %conv73.7.4 = trunc i32 %xor72.7.4 to i8
  store i8 %conv73.7.4, i8* %arrayidx70.4, align 1
  %scevgep20.8.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 8
  %6088 = load i8, i8* %scevgep20.8.4, align 1
  %conv68.8.4 = zext i8 %6088 to i32
  %6089 = load i8, i8* %arrayidx70.4, align 1
  %conv71.8.4 = zext i8 %6089 to i32
  %xor72.8.4 = xor i32 %conv71.8.4, %conv68.8.4
  %conv73.8.4 = trunc i32 %xor72.8.4 to i8
  store i8 %conv73.8.4, i8* %arrayidx70.4, align 1
  %scevgep20.9.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 9
  %6090 = load i8, i8* %scevgep20.9.4, align 1
  %conv68.9.4 = zext i8 %6090 to i32
  %6091 = load i8, i8* %arrayidx70.4, align 1
  %conv71.9.4 = zext i8 %6091 to i32
  %xor72.9.4 = xor i32 %conv71.9.4, %conv68.9.4
  %conv73.9.4 = trunc i32 %xor72.9.4 to i8
  store i8 %conv73.9.4, i8* %arrayidx70.4, align 1
  %scevgep20.10.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 10
  %6092 = load i8, i8* %scevgep20.10.4, align 1
  %conv68.10.4 = zext i8 %6092 to i32
  %6093 = load i8, i8* %arrayidx70.4, align 1
  %conv71.10.4 = zext i8 %6093 to i32
  %xor72.10.4 = xor i32 %conv71.10.4, %conv68.10.4
  %conv73.10.4 = trunc i32 %xor72.10.4 to i8
  store i8 %conv73.10.4, i8* %arrayidx70.4, align 1
  %scevgep20.11.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 11
  %6094 = load i8, i8* %scevgep20.11.4, align 1
  %conv68.11.4 = zext i8 %6094 to i32
  %6095 = load i8, i8* %arrayidx70.4, align 1
  %conv71.11.4 = zext i8 %6095 to i32
  %xor72.11.4 = xor i32 %conv71.11.4, %conv68.11.4
  %conv73.11.4 = trunc i32 %xor72.11.4 to i8
  store i8 %conv73.11.4, i8* %arrayidx70.4, align 1
  %scevgep20.12.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 12
  %6096 = load i8, i8* %scevgep20.12.4, align 1
  %conv68.12.4 = zext i8 %6096 to i32
  %6097 = load i8, i8* %arrayidx70.4, align 1
  %conv71.12.4 = zext i8 %6097 to i32
  %xor72.12.4 = xor i32 %conv71.12.4, %conv68.12.4
  %conv73.12.4 = trunc i32 %xor72.12.4 to i8
  store i8 %conv73.12.4, i8* %arrayidx70.4, align 1
  %scevgep20.13.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 13
  %6098 = load i8, i8* %scevgep20.13.4, align 1
  %conv68.13.4 = zext i8 %6098 to i32
  %6099 = load i8, i8* %arrayidx70.4, align 1
  %conv71.13.4 = zext i8 %6099 to i32
  %xor72.13.4 = xor i32 %conv71.13.4, %conv68.13.4
  %conv73.13.4 = trunc i32 %xor72.13.4 to i8
  store i8 %conv73.13.4, i8* %arrayidx70.4, align 1
  %scevgep20.14.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 14
  %6100 = load i8, i8* %scevgep20.14.4, align 1
  %conv68.14.4 = zext i8 %6100 to i32
  %6101 = load i8, i8* %arrayidx70.4, align 1
  %conv71.14.4 = zext i8 %6101 to i32
  %xor72.14.4 = xor i32 %conv71.14.4, %conv68.14.4
  %conv73.14.4 = trunc i32 %xor72.14.4 to i8
  store i8 %conv73.14.4, i8* %arrayidx70.4, align 1
  %scevgep20.15.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 15
  %6102 = load i8, i8* %scevgep20.15.4, align 1
  %conv68.15.4 = zext i8 %6102 to i32
  %6103 = load i8, i8* %arrayidx70.4, align 1
  %conv71.15.4 = zext i8 %6103 to i32
  %xor72.15.4 = xor i32 %conv71.15.4, %conv68.15.4
  %conv73.15.4 = trunc i32 %xor72.15.4 to i8
  store i8 %conv73.15.4, i8* %arrayidx70.4, align 1
  %scevgep20.16.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 16
  %6104 = load i8, i8* %scevgep20.16.4, align 1
  %conv68.16.4 = zext i8 %6104 to i32
  %6105 = load i8, i8* %arrayidx70.4, align 1
  %conv71.16.4 = zext i8 %6105 to i32
  %xor72.16.4 = xor i32 %conv71.16.4, %conv68.16.4
  %conv73.16.4 = trunc i32 %xor72.16.4 to i8
  store i8 %conv73.16.4, i8* %arrayidx70.4, align 1
  %scevgep20.17.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 17
  %6106 = load i8, i8* %scevgep20.17.4, align 1
  %conv68.17.4 = zext i8 %6106 to i32
  %6107 = load i8, i8* %arrayidx70.4, align 1
  %conv71.17.4 = zext i8 %6107 to i32
  %xor72.17.4 = xor i32 %conv71.17.4, %conv68.17.4
  %conv73.17.4 = trunc i32 %xor72.17.4 to i8
  store i8 %conv73.17.4, i8* %arrayidx70.4, align 1
  %scevgep20.18.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 18
  %6108 = load i8, i8* %scevgep20.18.4, align 1
  %conv68.18.4 = zext i8 %6108 to i32
  %6109 = load i8, i8* %arrayidx70.4, align 1
  %conv71.18.4 = zext i8 %6109 to i32
  %xor72.18.4 = xor i32 %conv71.18.4, %conv68.18.4
  %conv73.18.4 = trunc i32 %xor72.18.4 to i8
  store i8 %conv73.18.4, i8* %arrayidx70.4, align 1
  %scevgep20.19.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 19
  %6110 = load i8, i8* %scevgep20.19.4, align 1
  %conv68.19.4 = zext i8 %6110 to i32
  %6111 = load i8, i8* %arrayidx70.4, align 1
  %conv71.19.4 = zext i8 %6111 to i32
  %xor72.19.4 = xor i32 %conv71.19.4, %conv68.19.4
  %conv73.19.4 = trunc i32 %xor72.19.4 to i8
  store i8 %conv73.19.4, i8* %arrayidx70.4, align 1
  %scevgep20.20.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 20
  %6112 = load i8, i8* %scevgep20.20.4, align 1
  %conv68.20.4 = zext i8 %6112 to i32
  %6113 = load i8, i8* %arrayidx70.4, align 1
  %conv71.20.4 = zext i8 %6113 to i32
  %xor72.20.4 = xor i32 %conv71.20.4, %conv68.20.4
  %conv73.20.4 = trunc i32 %xor72.20.4 to i8
  store i8 %conv73.20.4, i8* %arrayidx70.4, align 1
  %scevgep20.21.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 21
  %6114 = load i8, i8* %scevgep20.21.4, align 1
  %conv68.21.4 = zext i8 %6114 to i32
  %6115 = load i8, i8* %arrayidx70.4, align 1
  %conv71.21.4 = zext i8 %6115 to i32
  %xor72.21.4 = xor i32 %conv71.21.4, %conv68.21.4
  %conv73.21.4 = trunc i32 %xor72.21.4 to i8
  store i8 %conv73.21.4, i8* %arrayidx70.4, align 1
  %scevgep20.22.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 22
  %6116 = load i8, i8* %scevgep20.22.4, align 1
  %conv68.22.4 = zext i8 %6116 to i32
  %6117 = load i8, i8* %arrayidx70.4, align 1
  %conv71.22.4 = zext i8 %6117 to i32
  %xor72.22.4 = xor i32 %conv71.22.4, %conv68.22.4
  %conv73.22.4 = trunc i32 %xor72.22.4 to i8
  store i8 %conv73.22.4, i8* %arrayidx70.4, align 1
  %scevgep20.23.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 23
  %6118 = load i8, i8* %scevgep20.23.4, align 1
  %conv68.23.4 = zext i8 %6118 to i32
  %6119 = load i8, i8* %arrayidx70.4, align 1
  %conv71.23.4 = zext i8 %6119 to i32
  %xor72.23.4 = xor i32 %conv71.23.4, %conv68.23.4
  %conv73.23.4 = trunc i32 %xor72.23.4 to i8
  store i8 %conv73.23.4, i8* %arrayidx70.4, align 1
  %scevgep20.24.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 24
  %6120 = load i8, i8* %scevgep20.24.4, align 1
  %conv68.24.4 = zext i8 %6120 to i32
  %6121 = load i8, i8* %arrayidx70.4, align 1
  %conv71.24.4 = zext i8 %6121 to i32
  %xor72.24.4 = xor i32 %conv71.24.4, %conv68.24.4
  %conv73.24.4 = trunc i32 %xor72.24.4 to i8
  store i8 %conv73.24.4, i8* %arrayidx70.4, align 1
  %scevgep20.25.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 25
  %6122 = load i8, i8* %scevgep20.25.4, align 1
  %conv68.25.4 = zext i8 %6122 to i32
  %6123 = load i8, i8* %arrayidx70.4, align 1
  %conv71.25.4 = zext i8 %6123 to i32
  %xor72.25.4 = xor i32 %conv71.25.4, %conv68.25.4
  %conv73.25.4 = trunc i32 %xor72.25.4 to i8
  store i8 %conv73.25.4, i8* %arrayidx70.4, align 1
  %scevgep20.26.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 26
  %6124 = load i8, i8* %scevgep20.26.4, align 1
  %conv68.26.4 = zext i8 %6124 to i32
  %6125 = load i8, i8* %arrayidx70.4, align 1
  %conv71.26.4 = zext i8 %6125 to i32
  %xor72.26.4 = xor i32 %conv71.26.4, %conv68.26.4
  %conv73.26.4 = trunc i32 %xor72.26.4 to i8
  store i8 %conv73.26.4, i8* %arrayidx70.4, align 1
  %scevgep20.27.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 27
  %6126 = load i8, i8* %scevgep20.27.4, align 1
  %conv68.27.4 = zext i8 %6126 to i32
  %6127 = load i8, i8* %arrayidx70.4, align 1
  %conv71.27.4 = zext i8 %6127 to i32
  %xor72.27.4 = xor i32 %conv71.27.4, %conv68.27.4
  %conv73.27.4 = trunc i32 %xor72.27.4 to i8
  store i8 %conv73.27.4, i8* %arrayidx70.4, align 1
  %scevgep20.28.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 28
  %6128 = load i8, i8* %scevgep20.28.4, align 1
  %conv68.28.4 = zext i8 %6128 to i32
  %6129 = load i8, i8* %arrayidx70.4, align 1
  %conv71.28.4 = zext i8 %6129 to i32
  %xor72.28.4 = xor i32 %conv71.28.4, %conv68.28.4
  %conv73.28.4 = trunc i32 %xor72.28.4 to i8
  store i8 %conv73.28.4, i8* %arrayidx70.4, align 1
  %scevgep20.29.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 29
  %6130 = load i8, i8* %scevgep20.29.4, align 1
  %conv68.29.4 = zext i8 %6130 to i32
  %6131 = load i8, i8* %arrayidx70.4, align 1
  %conv71.29.4 = zext i8 %6131 to i32
  %xor72.29.4 = xor i32 %conv71.29.4, %conv68.29.4
  %conv73.29.4 = trunc i32 %xor72.29.4 to i8
  store i8 %conv73.29.4, i8* %arrayidx70.4, align 1
  %scevgep20.30.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 30
  %6132 = load i8, i8* %scevgep20.30.4, align 1
  %conv68.30.4 = zext i8 %6132 to i32
  %6133 = load i8, i8* %arrayidx70.4, align 1
  %conv71.30.4 = zext i8 %6133 to i32
  %xor72.30.4 = xor i32 %conv71.30.4, %conv68.30.4
  %conv73.30.4 = trunc i32 %xor72.30.4 to i8
  store i8 %conv73.30.4, i8* %arrayidx70.4, align 1
  %scevgep20.31.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 31
  %6134 = load i8, i8* %scevgep20.31.4, align 1
  %conv68.31.4 = zext i8 %6134 to i32
  %6135 = load i8, i8* %arrayidx70.4, align 1
  %conv71.31.4 = zext i8 %6135 to i32
  %xor72.31.4 = xor i32 %conv71.31.4, %conv68.31.4
  %conv73.31.4 = trunc i32 %xor72.31.4 to i8
  store i8 %conv73.31.4, i8* %arrayidx70.4, align 1
  %scevgep20.32.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 32
  %6136 = load i8, i8* %scevgep20.32.4, align 1
  %conv68.32.4 = zext i8 %6136 to i32
  %6137 = load i8, i8* %arrayidx70.4, align 1
  %conv71.32.4 = zext i8 %6137 to i32
  %xor72.32.4 = xor i32 %conv71.32.4, %conv68.32.4
  %conv73.32.4 = trunc i32 %xor72.32.4 to i8
  store i8 %conv73.32.4, i8* %arrayidx70.4, align 1
  %scevgep20.33.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 33
  %6138 = load i8, i8* %scevgep20.33.4, align 1
  %conv68.33.4 = zext i8 %6138 to i32
  %6139 = load i8, i8* %arrayidx70.4, align 1
  %conv71.33.4 = zext i8 %6139 to i32
  %xor72.33.4 = xor i32 %conv71.33.4, %conv68.33.4
  %conv73.33.4 = trunc i32 %xor72.33.4 to i8
  store i8 %conv73.33.4, i8* %arrayidx70.4, align 1
  %scevgep20.34.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 34
  %6140 = load i8, i8* %scevgep20.34.4, align 1
  %conv68.34.4 = zext i8 %6140 to i32
  %6141 = load i8, i8* %arrayidx70.4, align 1
  %conv71.34.4 = zext i8 %6141 to i32
  %xor72.34.4 = xor i32 %conv71.34.4, %conv68.34.4
  %conv73.34.4 = trunc i32 %xor72.34.4 to i8
  store i8 %conv73.34.4, i8* %arrayidx70.4, align 1
  %scevgep20.35.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 35
  %6142 = load i8, i8* %scevgep20.35.4, align 1
  %conv68.35.4 = zext i8 %6142 to i32
  %6143 = load i8, i8* %arrayidx70.4, align 1
  %conv71.35.4 = zext i8 %6143 to i32
  %xor72.35.4 = xor i32 %conv71.35.4, %conv68.35.4
  %conv73.35.4 = trunc i32 %xor72.35.4 to i8
  store i8 %conv73.35.4, i8* %arrayidx70.4, align 1
  %scevgep20.36.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 36
  %6144 = load i8, i8* %scevgep20.36.4, align 1
  %conv68.36.4 = zext i8 %6144 to i32
  %6145 = load i8, i8* %arrayidx70.4, align 1
  %conv71.36.4 = zext i8 %6145 to i32
  %xor72.36.4 = xor i32 %conv71.36.4, %conv68.36.4
  %conv73.36.4 = trunc i32 %xor72.36.4 to i8
  store i8 %conv73.36.4, i8* %arrayidx70.4, align 1
  %scevgep20.37.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 37
  %6146 = load i8, i8* %scevgep20.37.4, align 1
  %conv68.37.4 = zext i8 %6146 to i32
  %6147 = load i8, i8* %arrayidx70.4, align 1
  %conv71.37.4 = zext i8 %6147 to i32
  %xor72.37.4 = xor i32 %conv71.37.4, %conv68.37.4
  %conv73.37.4 = trunc i32 %xor72.37.4 to i8
  store i8 %conv73.37.4, i8* %arrayidx70.4, align 1
  %scevgep20.38.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 38
  %6148 = load i8, i8* %scevgep20.38.4, align 1
  %conv68.38.4 = zext i8 %6148 to i32
  %6149 = load i8, i8* %arrayidx70.4, align 1
  %conv71.38.4 = zext i8 %6149 to i32
  %xor72.38.4 = xor i32 %conv71.38.4, %conv68.38.4
  %conv73.38.4 = trunc i32 %xor72.38.4 to i8
  store i8 %conv73.38.4, i8* %arrayidx70.4, align 1
  %scevgep20.39.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 39
  %6150 = load i8, i8* %scevgep20.39.4, align 1
  %conv68.39.4 = zext i8 %6150 to i32
  %6151 = load i8, i8* %arrayidx70.4, align 1
  %conv71.39.4 = zext i8 %6151 to i32
  %xor72.39.4 = xor i32 %conv71.39.4, %conv68.39.4
  %conv73.39.4 = trunc i32 %xor72.39.4 to i8
  store i8 %conv73.39.4, i8* %arrayidx70.4, align 1
  %scevgep20.40.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 0, i64 40
  %6152 = load i8, i8* %scevgep20.40.4, align 1
  %conv68.40.4 = zext i8 %6152 to i32
  %6153 = load i8, i8* %arrayidx70.4, align 1
  %conv71.40.4 = zext i8 %6153 to i32
  %xor72.40.4 = xor i32 %conv71.40.4, %conv68.40.4
  %conv73.40.4 = trunc i32 %xor72.40.4 to i8
  store i8 %conv73.40.4, i8* %arrayidx70.4, align 1
  %scevgep19.4 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6071, i64 0, i64 1, i64 0
  %6154 = bitcast i8* %scevgep19.4 to [41 x [41 x i8]]*
  %arrayidx51.5 = getelementptr inbounds i8, i8* %a, i64 5
  %6155 = load i8, i8* %arrayidx51.5, align 1
  %arrayidx53.5 = getelementptr inbounds i8, i8* %b, i64 5
  %6156 = load i8, i8* %arrayidx53.5, align 1
  %call54.5 = call zeroext i8 @mult(i8 zeroext %6155, i8 zeroext %6156)
  %arrayidx56.5 = getelementptr inbounds i8, i8* %c, i64 5
  store i8 %call54.5, i8* %arrayidx56.5, align 1
  %arrayidx70.5 = getelementptr inbounds i8, i8* %c, i64 5
  %scevgep20.594 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 0
  %6157 = load i8, i8* %scevgep20.594, align 1
  %conv68.595 = zext i8 %6157 to i32
  %6158 = load i8, i8* %arrayidx70.5, align 1
  %conv71.596 = zext i8 %6158 to i32
  %xor72.597 = xor i32 %conv71.596, %conv68.595
  %conv73.598 = trunc i32 %xor72.597 to i8
  store i8 %conv73.598, i8* %arrayidx70.5, align 1
  %scevgep20.1.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 1
  %6159 = load i8, i8* %scevgep20.1.5, align 1
  %conv68.1.5 = zext i8 %6159 to i32
  %6160 = load i8, i8* %arrayidx70.5, align 1
  %conv71.1.5 = zext i8 %6160 to i32
  %xor72.1.5 = xor i32 %conv71.1.5, %conv68.1.5
  %conv73.1.5 = trunc i32 %xor72.1.5 to i8
  store i8 %conv73.1.5, i8* %arrayidx70.5, align 1
  %scevgep20.2.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 2
  %6161 = load i8, i8* %scevgep20.2.5, align 1
  %conv68.2.5 = zext i8 %6161 to i32
  %6162 = load i8, i8* %arrayidx70.5, align 1
  %conv71.2.5 = zext i8 %6162 to i32
  %xor72.2.5 = xor i32 %conv71.2.5, %conv68.2.5
  %conv73.2.5 = trunc i32 %xor72.2.5 to i8
  store i8 %conv73.2.5, i8* %arrayidx70.5, align 1
  %scevgep20.3.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 3
  %6163 = load i8, i8* %scevgep20.3.5, align 1
  %conv68.3.5 = zext i8 %6163 to i32
  %6164 = load i8, i8* %arrayidx70.5, align 1
  %conv71.3.5 = zext i8 %6164 to i32
  %xor72.3.5 = xor i32 %conv71.3.5, %conv68.3.5
  %conv73.3.5 = trunc i32 %xor72.3.5 to i8
  store i8 %conv73.3.5, i8* %arrayidx70.5, align 1
  %scevgep20.4.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 4
  %6165 = load i8, i8* %scevgep20.4.5, align 1
  %conv68.4.5 = zext i8 %6165 to i32
  %6166 = load i8, i8* %arrayidx70.5, align 1
  %conv71.4.5 = zext i8 %6166 to i32
  %xor72.4.5 = xor i32 %conv71.4.5, %conv68.4.5
  %conv73.4.5 = trunc i32 %xor72.4.5 to i8
  store i8 %conv73.4.5, i8* %arrayidx70.5, align 1
  %scevgep20.6.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 6
  %6167 = load i8, i8* %scevgep20.6.5, align 1
  %conv68.6.5 = zext i8 %6167 to i32
  %6168 = load i8, i8* %arrayidx70.5, align 1
  %conv71.6.5 = zext i8 %6168 to i32
  %xor72.6.5 = xor i32 %conv71.6.5, %conv68.6.5
  %conv73.6.5 = trunc i32 %xor72.6.5 to i8
  store i8 %conv73.6.5, i8* %arrayidx70.5, align 1
  %scevgep20.7.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 7
  %6169 = load i8, i8* %scevgep20.7.5, align 1
  %conv68.7.5 = zext i8 %6169 to i32
  %6170 = load i8, i8* %arrayidx70.5, align 1
  %conv71.7.5 = zext i8 %6170 to i32
  %xor72.7.5 = xor i32 %conv71.7.5, %conv68.7.5
  %conv73.7.5 = trunc i32 %xor72.7.5 to i8
  store i8 %conv73.7.5, i8* %arrayidx70.5, align 1
  %scevgep20.8.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 8
  %6171 = load i8, i8* %scevgep20.8.5, align 1
  %conv68.8.5 = zext i8 %6171 to i32
  %6172 = load i8, i8* %arrayidx70.5, align 1
  %conv71.8.5 = zext i8 %6172 to i32
  %xor72.8.5 = xor i32 %conv71.8.5, %conv68.8.5
  %conv73.8.5 = trunc i32 %xor72.8.5 to i8
  store i8 %conv73.8.5, i8* %arrayidx70.5, align 1
  %scevgep20.9.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 9
  %6173 = load i8, i8* %scevgep20.9.5, align 1
  %conv68.9.5 = zext i8 %6173 to i32
  %6174 = load i8, i8* %arrayidx70.5, align 1
  %conv71.9.5 = zext i8 %6174 to i32
  %xor72.9.5 = xor i32 %conv71.9.5, %conv68.9.5
  %conv73.9.5 = trunc i32 %xor72.9.5 to i8
  store i8 %conv73.9.5, i8* %arrayidx70.5, align 1
  %scevgep20.10.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 10
  %6175 = load i8, i8* %scevgep20.10.5, align 1
  %conv68.10.5 = zext i8 %6175 to i32
  %6176 = load i8, i8* %arrayidx70.5, align 1
  %conv71.10.5 = zext i8 %6176 to i32
  %xor72.10.5 = xor i32 %conv71.10.5, %conv68.10.5
  %conv73.10.5 = trunc i32 %xor72.10.5 to i8
  store i8 %conv73.10.5, i8* %arrayidx70.5, align 1
  %scevgep20.11.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 11
  %6177 = load i8, i8* %scevgep20.11.5, align 1
  %conv68.11.5 = zext i8 %6177 to i32
  %6178 = load i8, i8* %arrayidx70.5, align 1
  %conv71.11.5 = zext i8 %6178 to i32
  %xor72.11.5 = xor i32 %conv71.11.5, %conv68.11.5
  %conv73.11.5 = trunc i32 %xor72.11.5 to i8
  store i8 %conv73.11.5, i8* %arrayidx70.5, align 1
  %scevgep20.12.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 12
  %6179 = load i8, i8* %scevgep20.12.5, align 1
  %conv68.12.5 = zext i8 %6179 to i32
  %6180 = load i8, i8* %arrayidx70.5, align 1
  %conv71.12.5 = zext i8 %6180 to i32
  %xor72.12.5 = xor i32 %conv71.12.5, %conv68.12.5
  %conv73.12.5 = trunc i32 %xor72.12.5 to i8
  store i8 %conv73.12.5, i8* %arrayidx70.5, align 1
  %scevgep20.13.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 13
  %6181 = load i8, i8* %scevgep20.13.5, align 1
  %conv68.13.5 = zext i8 %6181 to i32
  %6182 = load i8, i8* %arrayidx70.5, align 1
  %conv71.13.5 = zext i8 %6182 to i32
  %xor72.13.5 = xor i32 %conv71.13.5, %conv68.13.5
  %conv73.13.5 = trunc i32 %xor72.13.5 to i8
  store i8 %conv73.13.5, i8* %arrayidx70.5, align 1
  %scevgep20.14.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 14
  %6183 = load i8, i8* %scevgep20.14.5, align 1
  %conv68.14.5 = zext i8 %6183 to i32
  %6184 = load i8, i8* %arrayidx70.5, align 1
  %conv71.14.5 = zext i8 %6184 to i32
  %xor72.14.5 = xor i32 %conv71.14.5, %conv68.14.5
  %conv73.14.5 = trunc i32 %xor72.14.5 to i8
  store i8 %conv73.14.5, i8* %arrayidx70.5, align 1
  %scevgep20.15.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 15
  %6185 = load i8, i8* %scevgep20.15.5, align 1
  %conv68.15.5 = zext i8 %6185 to i32
  %6186 = load i8, i8* %arrayidx70.5, align 1
  %conv71.15.5 = zext i8 %6186 to i32
  %xor72.15.5 = xor i32 %conv71.15.5, %conv68.15.5
  %conv73.15.5 = trunc i32 %xor72.15.5 to i8
  store i8 %conv73.15.5, i8* %arrayidx70.5, align 1
  %scevgep20.16.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 16
  %6187 = load i8, i8* %scevgep20.16.5, align 1
  %conv68.16.5 = zext i8 %6187 to i32
  %6188 = load i8, i8* %arrayidx70.5, align 1
  %conv71.16.5 = zext i8 %6188 to i32
  %xor72.16.5 = xor i32 %conv71.16.5, %conv68.16.5
  %conv73.16.5 = trunc i32 %xor72.16.5 to i8
  store i8 %conv73.16.5, i8* %arrayidx70.5, align 1
  %scevgep20.17.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 17
  %6189 = load i8, i8* %scevgep20.17.5, align 1
  %conv68.17.5 = zext i8 %6189 to i32
  %6190 = load i8, i8* %arrayidx70.5, align 1
  %conv71.17.5 = zext i8 %6190 to i32
  %xor72.17.5 = xor i32 %conv71.17.5, %conv68.17.5
  %conv73.17.5 = trunc i32 %xor72.17.5 to i8
  store i8 %conv73.17.5, i8* %arrayidx70.5, align 1
  %scevgep20.18.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 18
  %6191 = load i8, i8* %scevgep20.18.5, align 1
  %conv68.18.5 = zext i8 %6191 to i32
  %6192 = load i8, i8* %arrayidx70.5, align 1
  %conv71.18.5 = zext i8 %6192 to i32
  %xor72.18.5 = xor i32 %conv71.18.5, %conv68.18.5
  %conv73.18.5 = trunc i32 %xor72.18.5 to i8
  store i8 %conv73.18.5, i8* %arrayidx70.5, align 1
  %scevgep20.19.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 19
  %6193 = load i8, i8* %scevgep20.19.5, align 1
  %conv68.19.5 = zext i8 %6193 to i32
  %6194 = load i8, i8* %arrayidx70.5, align 1
  %conv71.19.5 = zext i8 %6194 to i32
  %xor72.19.5 = xor i32 %conv71.19.5, %conv68.19.5
  %conv73.19.5 = trunc i32 %xor72.19.5 to i8
  store i8 %conv73.19.5, i8* %arrayidx70.5, align 1
  %scevgep20.20.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 20
  %6195 = load i8, i8* %scevgep20.20.5, align 1
  %conv68.20.5 = zext i8 %6195 to i32
  %6196 = load i8, i8* %arrayidx70.5, align 1
  %conv71.20.5 = zext i8 %6196 to i32
  %xor72.20.5 = xor i32 %conv71.20.5, %conv68.20.5
  %conv73.20.5 = trunc i32 %xor72.20.5 to i8
  store i8 %conv73.20.5, i8* %arrayidx70.5, align 1
  %scevgep20.21.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 21
  %6197 = load i8, i8* %scevgep20.21.5, align 1
  %conv68.21.5 = zext i8 %6197 to i32
  %6198 = load i8, i8* %arrayidx70.5, align 1
  %conv71.21.5 = zext i8 %6198 to i32
  %xor72.21.5 = xor i32 %conv71.21.5, %conv68.21.5
  %conv73.21.5 = trunc i32 %xor72.21.5 to i8
  store i8 %conv73.21.5, i8* %arrayidx70.5, align 1
  %scevgep20.22.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 22
  %6199 = load i8, i8* %scevgep20.22.5, align 1
  %conv68.22.5 = zext i8 %6199 to i32
  %6200 = load i8, i8* %arrayidx70.5, align 1
  %conv71.22.5 = zext i8 %6200 to i32
  %xor72.22.5 = xor i32 %conv71.22.5, %conv68.22.5
  %conv73.22.5 = trunc i32 %xor72.22.5 to i8
  store i8 %conv73.22.5, i8* %arrayidx70.5, align 1
  %scevgep20.23.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 23
  %6201 = load i8, i8* %scevgep20.23.5, align 1
  %conv68.23.5 = zext i8 %6201 to i32
  %6202 = load i8, i8* %arrayidx70.5, align 1
  %conv71.23.5 = zext i8 %6202 to i32
  %xor72.23.5 = xor i32 %conv71.23.5, %conv68.23.5
  %conv73.23.5 = trunc i32 %xor72.23.5 to i8
  store i8 %conv73.23.5, i8* %arrayidx70.5, align 1
  %scevgep20.24.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 24
  %6203 = load i8, i8* %scevgep20.24.5, align 1
  %conv68.24.5 = zext i8 %6203 to i32
  %6204 = load i8, i8* %arrayidx70.5, align 1
  %conv71.24.5 = zext i8 %6204 to i32
  %xor72.24.5 = xor i32 %conv71.24.5, %conv68.24.5
  %conv73.24.5 = trunc i32 %xor72.24.5 to i8
  store i8 %conv73.24.5, i8* %arrayidx70.5, align 1
  %scevgep20.25.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 25
  %6205 = load i8, i8* %scevgep20.25.5, align 1
  %conv68.25.5 = zext i8 %6205 to i32
  %6206 = load i8, i8* %arrayidx70.5, align 1
  %conv71.25.5 = zext i8 %6206 to i32
  %xor72.25.5 = xor i32 %conv71.25.5, %conv68.25.5
  %conv73.25.5 = trunc i32 %xor72.25.5 to i8
  store i8 %conv73.25.5, i8* %arrayidx70.5, align 1
  %scevgep20.26.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 26
  %6207 = load i8, i8* %scevgep20.26.5, align 1
  %conv68.26.5 = zext i8 %6207 to i32
  %6208 = load i8, i8* %arrayidx70.5, align 1
  %conv71.26.5 = zext i8 %6208 to i32
  %xor72.26.5 = xor i32 %conv71.26.5, %conv68.26.5
  %conv73.26.5 = trunc i32 %xor72.26.5 to i8
  store i8 %conv73.26.5, i8* %arrayidx70.5, align 1
  %scevgep20.27.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 27
  %6209 = load i8, i8* %scevgep20.27.5, align 1
  %conv68.27.5 = zext i8 %6209 to i32
  %6210 = load i8, i8* %arrayidx70.5, align 1
  %conv71.27.5 = zext i8 %6210 to i32
  %xor72.27.5 = xor i32 %conv71.27.5, %conv68.27.5
  %conv73.27.5 = trunc i32 %xor72.27.5 to i8
  store i8 %conv73.27.5, i8* %arrayidx70.5, align 1
  %scevgep20.28.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 28
  %6211 = load i8, i8* %scevgep20.28.5, align 1
  %conv68.28.5 = zext i8 %6211 to i32
  %6212 = load i8, i8* %arrayidx70.5, align 1
  %conv71.28.5 = zext i8 %6212 to i32
  %xor72.28.5 = xor i32 %conv71.28.5, %conv68.28.5
  %conv73.28.5 = trunc i32 %xor72.28.5 to i8
  store i8 %conv73.28.5, i8* %arrayidx70.5, align 1
  %scevgep20.29.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 29
  %6213 = load i8, i8* %scevgep20.29.5, align 1
  %conv68.29.5 = zext i8 %6213 to i32
  %6214 = load i8, i8* %arrayidx70.5, align 1
  %conv71.29.5 = zext i8 %6214 to i32
  %xor72.29.5 = xor i32 %conv71.29.5, %conv68.29.5
  %conv73.29.5 = trunc i32 %xor72.29.5 to i8
  store i8 %conv73.29.5, i8* %arrayidx70.5, align 1
  %scevgep20.30.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 30
  %6215 = load i8, i8* %scevgep20.30.5, align 1
  %conv68.30.5 = zext i8 %6215 to i32
  %6216 = load i8, i8* %arrayidx70.5, align 1
  %conv71.30.5 = zext i8 %6216 to i32
  %xor72.30.5 = xor i32 %conv71.30.5, %conv68.30.5
  %conv73.30.5 = trunc i32 %xor72.30.5 to i8
  store i8 %conv73.30.5, i8* %arrayidx70.5, align 1
  %scevgep20.31.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 31
  %6217 = load i8, i8* %scevgep20.31.5, align 1
  %conv68.31.5 = zext i8 %6217 to i32
  %6218 = load i8, i8* %arrayidx70.5, align 1
  %conv71.31.5 = zext i8 %6218 to i32
  %xor72.31.5 = xor i32 %conv71.31.5, %conv68.31.5
  %conv73.31.5 = trunc i32 %xor72.31.5 to i8
  store i8 %conv73.31.5, i8* %arrayidx70.5, align 1
  %scevgep20.32.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 32
  %6219 = load i8, i8* %scevgep20.32.5, align 1
  %conv68.32.5 = zext i8 %6219 to i32
  %6220 = load i8, i8* %arrayidx70.5, align 1
  %conv71.32.5 = zext i8 %6220 to i32
  %xor72.32.5 = xor i32 %conv71.32.5, %conv68.32.5
  %conv73.32.5 = trunc i32 %xor72.32.5 to i8
  store i8 %conv73.32.5, i8* %arrayidx70.5, align 1
  %scevgep20.33.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 33
  %6221 = load i8, i8* %scevgep20.33.5, align 1
  %conv68.33.5 = zext i8 %6221 to i32
  %6222 = load i8, i8* %arrayidx70.5, align 1
  %conv71.33.5 = zext i8 %6222 to i32
  %xor72.33.5 = xor i32 %conv71.33.5, %conv68.33.5
  %conv73.33.5 = trunc i32 %xor72.33.5 to i8
  store i8 %conv73.33.5, i8* %arrayidx70.5, align 1
  %scevgep20.34.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 34
  %6223 = load i8, i8* %scevgep20.34.5, align 1
  %conv68.34.5 = zext i8 %6223 to i32
  %6224 = load i8, i8* %arrayidx70.5, align 1
  %conv71.34.5 = zext i8 %6224 to i32
  %xor72.34.5 = xor i32 %conv71.34.5, %conv68.34.5
  %conv73.34.5 = trunc i32 %xor72.34.5 to i8
  store i8 %conv73.34.5, i8* %arrayidx70.5, align 1
  %scevgep20.35.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 35
  %6225 = load i8, i8* %scevgep20.35.5, align 1
  %conv68.35.5 = zext i8 %6225 to i32
  %6226 = load i8, i8* %arrayidx70.5, align 1
  %conv71.35.5 = zext i8 %6226 to i32
  %xor72.35.5 = xor i32 %conv71.35.5, %conv68.35.5
  %conv73.35.5 = trunc i32 %xor72.35.5 to i8
  store i8 %conv73.35.5, i8* %arrayidx70.5, align 1
  %scevgep20.36.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 36
  %6227 = load i8, i8* %scevgep20.36.5, align 1
  %conv68.36.5 = zext i8 %6227 to i32
  %6228 = load i8, i8* %arrayidx70.5, align 1
  %conv71.36.5 = zext i8 %6228 to i32
  %xor72.36.5 = xor i32 %conv71.36.5, %conv68.36.5
  %conv73.36.5 = trunc i32 %xor72.36.5 to i8
  store i8 %conv73.36.5, i8* %arrayidx70.5, align 1
  %scevgep20.37.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 37
  %6229 = load i8, i8* %scevgep20.37.5, align 1
  %conv68.37.5 = zext i8 %6229 to i32
  %6230 = load i8, i8* %arrayidx70.5, align 1
  %conv71.37.5 = zext i8 %6230 to i32
  %xor72.37.5 = xor i32 %conv71.37.5, %conv68.37.5
  %conv73.37.5 = trunc i32 %xor72.37.5 to i8
  store i8 %conv73.37.5, i8* %arrayidx70.5, align 1
  %scevgep20.38.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 38
  %6231 = load i8, i8* %scevgep20.38.5, align 1
  %conv68.38.5 = zext i8 %6231 to i32
  %6232 = load i8, i8* %arrayidx70.5, align 1
  %conv71.38.5 = zext i8 %6232 to i32
  %xor72.38.5 = xor i32 %conv71.38.5, %conv68.38.5
  %conv73.38.5 = trunc i32 %xor72.38.5 to i8
  store i8 %conv73.38.5, i8* %arrayidx70.5, align 1
  %scevgep20.39.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 39
  %6233 = load i8, i8* %scevgep20.39.5, align 1
  %conv68.39.5 = zext i8 %6233 to i32
  %6234 = load i8, i8* %arrayidx70.5, align 1
  %conv71.39.5 = zext i8 %6234 to i32
  %xor72.39.5 = xor i32 %conv71.39.5, %conv68.39.5
  %conv73.39.5 = trunc i32 %xor72.39.5 to i8
  store i8 %conv73.39.5, i8* %arrayidx70.5, align 1
  %scevgep20.40.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 0, i64 40
  %6235 = load i8, i8* %scevgep20.40.5, align 1
  %conv68.40.5 = zext i8 %6235 to i32
  %6236 = load i8, i8* %arrayidx70.5, align 1
  %conv71.40.5 = zext i8 %6236 to i32
  %xor72.40.5 = xor i32 %conv71.40.5, %conv68.40.5
  %conv73.40.5 = trunc i32 %xor72.40.5 to i8
  store i8 %conv73.40.5, i8* %arrayidx70.5, align 1
  %scevgep19.5 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6154, i64 0, i64 1, i64 0
  %6237 = bitcast i8* %scevgep19.5 to [41 x [41 x i8]]*
  %arrayidx51.6 = getelementptr inbounds i8, i8* %a, i64 6
  %6238 = load i8, i8* %arrayidx51.6, align 1
  %arrayidx53.6 = getelementptr inbounds i8, i8* %b, i64 6
  %6239 = load i8, i8* %arrayidx53.6, align 1
  %call54.6 = call zeroext i8 @mult(i8 zeroext %6238, i8 zeroext %6239)
  %arrayidx56.6 = getelementptr inbounds i8, i8* %c, i64 6
  store i8 %call54.6, i8* %arrayidx56.6, align 1
  %arrayidx70.6 = getelementptr inbounds i8, i8* %c, i64 6
  %scevgep20.6104 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 0
  %6240 = load i8, i8* %scevgep20.6104, align 1
  %conv68.6105 = zext i8 %6240 to i32
  %6241 = load i8, i8* %arrayidx70.6, align 1
  %conv71.6106 = zext i8 %6241 to i32
  %xor72.6107 = xor i32 %conv71.6106, %conv68.6105
  %conv73.6108 = trunc i32 %xor72.6107 to i8
  store i8 %conv73.6108, i8* %arrayidx70.6, align 1
  %scevgep20.1.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 1
  %6242 = load i8, i8* %scevgep20.1.6, align 1
  %conv68.1.6 = zext i8 %6242 to i32
  %6243 = load i8, i8* %arrayidx70.6, align 1
  %conv71.1.6 = zext i8 %6243 to i32
  %xor72.1.6 = xor i32 %conv71.1.6, %conv68.1.6
  %conv73.1.6 = trunc i32 %xor72.1.6 to i8
  store i8 %conv73.1.6, i8* %arrayidx70.6, align 1
  %scevgep20.2.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 2
  %6244 = load i8, i8* %scevgep20.2.6, align 1
  %conv68.2.6 = zext i8 %6244 to i32
  %6245 = load i8, i8* %arrayidx70.6, align 1
  %conv71.2.6 = zext i8 %6245 to i32
  %xor72.2.6 = xor i32 %conv71.2.6, %conv68.2.6
  %conv73.2.6 = trunc i32 %xor72.2.6 to i8
  store i8 %conv73.2.6, i8* %arrayidx70.6, align 1
  %scevgep20.3.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 3
  %6246 = load i8, i8* %scevgep20.3.6, align 1
  %conv68.3.6 = zext i8 %6246 to i32
  %6247 = load i8, i8* %arrayidx70.6, align 1
  %conv71.3.6 = zext i8 %6247 to i32
  %xor72.3.6 = xor i32 %conv71.3.6, %conv68.3.6
  %conv73.3.6 = trunc i32 %xor72.3.6 to i8
  store i8 %conv73.3.6, i8* %arrayidx70.6, align 1
  %scevgep20.4.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 4
  %6248 = load i8, i8* %scevgep20.4.6, align 1
  %conv68.4.6 = zext i8 %6248 to i32
  %6249 = load i8, i8* %arrayidx70.6, align 1
  %conv71.4.6 = zext i8 %6249 to i32
  %xor72.4.6 = xor i32 %conv71.4.6, %conv68.4.6
  %conv73.4.6 = trunc i32 %xor72.4.6 to i8
  store i8 %conv73.4.6, i8* %arrayidx70.6, align 1
  %scevgep20.5.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 5
  %6250 = load i8, i8* %scevgep20.5.6, align 1
  %conv68.5.6 = zext i8 %6250 to i32
  %6251 = load i8, i8* %arrayidx70.6, align 1
  %conv71.5.6 = zext i8 %6251 to i32
  %xor72.5.6 = xor i32 %conv71.5.6, %conv68.5.6
  %conv73.5.6 = trunc i32 %xor72.5.6 to i8
  store i8 %conv73.5.6, i8* %arrayidx70.6, align 1
  %scevgep20.7.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 7
  %6252 = load i8, i8* %scevgep20.7.6, align 1
  %conv68.7.6 = zext i8 %6252 to i32
  %6253 = load i8, i8* %arrayidx70.6, align 1
  %conv71.7.6 = zext i8 %6253 to i32
  %xor72.7.6 = xor i32 %conv71.7.6, %conv68.7.6
  %conv73.7.6 = trunc i32 %xor72.7.6 to i8
  store i8 %conv73.7.6, i8* %arrayidx70.6, align 1
  %scevgep20.8.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 8
  %6254 = load i8, i8* %scevgep20.8.6, align 1
  %conv68.8.6 = zext i8 %6254 to i32
  %6255 = load i8, i8* %arrayidx70.6, align 1
  %conv71.8.6 = zext i8 %6255 to i32
  %xor72.8.6 = xor i32 %conv71.8.6, %conv68.8.6
  %conv73.8.6 = trunc i32 %xor72.8.6 to i8
  store i8 %conv73.8.6, i8* %arrayidx70.6, align 1
  %scevgep20.9.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 9
  %6256 = load i8, i8* %scevgep20.9.6, align 1
  %conv68.9.6 = zext i8 %6256 to i32
  %6257 = load i8, i8* %arrayidx70.6, align 1
  %conv71.9.6 = zext i8 %6257 to i32
  %xor72.9.6 = xor i32 %conv71.9.6, %conv68.9.6
  %conv73.9.6 = trunc i32 %xor72.9.6 to i8
  store i8 %conv73.9.6, i8* %arrayidx70.6, align 1
  %scevgep20.10.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 10
  %6258 = load i8, i8* %scevgep20.10.6, align 1
  %conv68.10.6 = zext i8 %6258 to i32
  %6259 = load i8, i8* %arrayidx70.6, align 1
  %conv71.10.6 = zext i8 %6259 to i32
  %xor72.10.6 = xor i32 %conv71.10.6, %conv68.10.6
  %conv73.10.6 = trunc i32 %xor72.10.6 to i8
  store i8 %conv73.10.6, i8* %arrayidx70.6, align 1
  %scevgep20.11.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 11
  %6260 = load i8, i8* %scevgep20.11.6, align 1
  %conv68.11.6 = zext i8 %6260 to i32
  %6261 = load i8, i8* %arrayidx70.6, align 1
  %conv71.11.6 = zext i8 %6261 to i32
  %xor72.11.6 = xor i32 %conv71.11.6, %conv68.11.6
  %conv73.11.6 = trunc i32 %xor72.11.6 to i8
  store i8 %conv73.11.6, i8* %arrayidx70.6, align 1
  %scevgep20.12.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 12
  %6262 = load i8, i8* %scevgep20.12.6, align 1
  %conv68.12.6 = zext i8 %6262 to i32
  %6263 = load i8, i8* %arrayidx70.6, align 1
  %conv71.12.6 = zext i8 %6263 to i32
  %xor72.12.6 = xor i32 %conv71.12.6, %conv68.12.6
  %conv73.12.6 = trunc i32 %xor72.12.6 to i8
  store i8 %conv73.12.6, i8* %arrayidx70.6, align 1
  %scevgep20.13.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 13
  %6264 = load i8, i8* %scevgep20.13.6, align 1
  %conv68.13.6 = zext i8 %6264 to i32
  %6265 = load i8, i8* %arrayidx70.6, align 1
  %conv71.13.6 = zext i8 %6265 to i32
  %xor72.13.6 = xor i32 %conv71.13.6, %conv68.13.6
  %conv73.13.6 = trunc i32 %xor72.13.6 to i8
  store i8 %conv73.13.6, i8* %arrayidx70.6, align 1
  %scevgep20.14.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 14
  %6266 = load i8, i8* %scevgep20.14.6, align 1
  %conv68.14.6 = zext i8 %6266 to i32
  %6267 = load i8, i8* %arrayidx70.6, align 1
  %conv71.14.6 = zext i8 %6267 to i32
  %xor72.14.6 = xor i32 %conv71.14.6, %conv68.14.6
  %conv73.14.6 = trunc i32 %xor72.14.6 to i8
  store i8 %conv73.14.6, i8* %arrayidx70.6, align 1
  %scevgep20.15.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 15
  %6268 = load i8, i8* %scevgep20.15.6, align 1
  %conv68.15.6 = zext i8 %6268 to i32
  %6269 = load i8, i8* %arrayidx70.6, align 1
  %conv71.15.6 = zext i8 %6269 to i32
  %xor72.15.6 = xor i32 %conv71.15.6, %conv68.15.6
  %conv73.15.6 = trunc i32 %xor72.15.6 to i8
  store i8 %conv73.15.6, i8* %arrayidx70.6, align 1
  %scevgep20.16.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 16
  %6270 = load i8, i8* %scevgep20.16.6, align 1
  %conv68.16.6 = zext i8 %6270 to i32
  %6271 = load i8, i8* %arrayidx70.6, align 1
  %conv71.16.6 = zext i8 %6271 to i32
  %xor72.16.6 = xor i32 %conv71.16.6, %conv68.16.6
  %conv73.16.6 = trunc i32 %xor72.16.6 to i8
  store i8 %conv73.16.6, i8* %arrayidx70.6, align 1
  %scevgep20.17.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 17
  %6272 = load i8, i8* %scevgep20.17.6, align 1
  %conv68.17.6 = zext i8 %6272 to i32
  %6273 = load i8, i8* %arrayidx70.6, align 1
  %conv71.17.6 = zext i8 %6273 to i32
  %xor72.17.6 = xor i32 %conv71.17.6, %conv68.17.6
  %conv73.17.6 = trunc i32 %xor72.17.6 to i8
  store i8 %conv73.17.6, i8* %arrayidx70.6, align 1
  %scevgep20.18.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 18
  %6274 = load i8, i8* %scevgep20.18.6, align 1
  %conv68.18.6 = zext i8 %6274 to i32
  %6275 = load i8, i8* %arrayidx70.6, align 1
  %conv71.18.6 = zext i8 %6275 to i32
  %xor72.18.6 = xor i32 %conv71.18.6, %conv68.18.6
  %conv73.18.6 = trunc i32 %xor72.18.6 to i8
  store i8 %conv73.18.6, i8* %arrayidx70.6, align 1
  %scevgep20.19.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 19
  %6276 = load i8, i8* %scevgep20.19.6, align 1
  %conv68.19.6 = zext i8 %6276 to i32
  %6277 = load i8, i8* %arrayidx70.6, align 1
  %conv71.19.6 = zext i8 %6277 to i32
  %xor72.19.6 = xor i32 %conv71.19.6, %conv68.19.6
  %conv73.19.6 = trunc i32 %xor72.19.6 to i8
  store i8 %conv73.19.6, i8* %arrayidx70.6, align 1
  %scevgep20.20.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 20
  %6278 = load i8, i8* %scevgep20.20.6, align 1
  %conv68.20.6 = zext i8 %6278 to i32
  %6279 = load i8, i8* %arrayidx70.6, align 1
  %conv71.20.6 = zext i8 %6279 to i32
  %xor72.20.6 = xor i32 %conv71.20.6, %conv68.20.6
  %conv73.20.6 = trunc i32 %xor72.20.6 to i8
  store i8 %conv73.20.6, i8* %arrayidx70.6, align 1
  %scevgep20.21.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 21
  %6280 = load i8, i8* %scevgep20.21.6, align 1
  %conv68.21.6 = zext i8 %6280 to i32
  %6281 = load i8, i8* %arrayidx70.6, align 1
  %conv71.21.6 = zext i8 %6281 to i32
  %xor72.21.6 = xor i32 %conv71.21.6, %conv68.21.6
  %conv73.21.6 = trunc i32 %xor72.21.6 to i8
  store i8 %conv73.21.6, i8* %arrayidx70.6, align 1
  %scevgep20.22.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 22
  %6282 = load i8, i8* %scevgep20.22.6, align 1
  %conv68.22.6 = zext i8 %6282 to i32
  %6283 = load i8, i8* %arrayidx70.6, align 1
  %conv71.22.6 = zext i8 %6283 to i32
  %xor72.22.6 = xor i32 %conv71.22.6, %conv68.22.6
  %conv73.22.6 = trunc i32 %xor72.22.6 to i8
  store i8 %conv73.22.6, i8* %arrayidx70.6, align 1
  %scevgep20.23.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 23
  %6284 = load i8, i8* %scevgep20.23.6, align 1
  %conv68.23.6 = zext i8 %6284 to i32
  %6285 = load i8, i8* %arrayidx70.6, align 1
  %conv71.23.6 = zext i8 %6285 to i32
  %xor72.23.6 = xor i32 %conv71.23.6, %conv68.23.6
  %conv73.23.6 = trunc i32 %xor72.23.6 to i8
  store i8 %conv73.23.6, i8* %arrayidx70.6, align 1
  %scevgep20.24.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 24
  %6286 = load i8, i8* %scevgep20.24.6, align 1
  %conv68.24.6 = zext i8 %6286 to i32
  %6287 = load i8, i8* %arrayidx70.6, align 1
  %conv71.24.6 = zext i8 %6287 to i32
  %xor72.24.6 = xor i32 %conv71.24.6, %conv68.24.6
  %conv73.24.6 = trunc i32 %xor72.24.6 to i8
  store i8 %conv73.24.6, i8* %arrayidx70.6, align 1
  %scevgep20.25.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 25
  %6288 = load i8, i8* %scevgep20.25.6, align 1
  %conv68.25.6 = zext i8 %6288 to i32
  %6289 = load i8, i8* %arrayidx70.6, align 1
  %conv71.25.6 = zext i8 %6289 to i32
  %xor72.25.6 = xor i32 %conv71.25.6, %conv68.25.6
  %conv73.25.6 = trunc i32 %xor72.25.6 to i8
  store i8 %conv73.25.6, i8* %arrayidx70.6, align 1
  %scevgep20.26.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 26
  %6290 = load i8, i8* %scevgep20.26.6, align 1
  %conv68.26.6 = zext i8 %6290 to i32
  %6291 = load i8, i8* %arrayidx70.6, align 1
  %conv71.26.6 = zext i8 %6291 to i32
  %xor72.26.6 = xor i32 %conv71.26.6, %conv68.26.6
  %conv73.26.6 = trunc i32 %xor72.26.6 to i8
  store i8 %conv73.26.6, i8* %arrayidx70.6, align 1
  %scevgep20.27.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 27
  %6292 = load i8, i8* %scevgep20.27.6, align 1
  %conv68.27.6 = zext i8 %6292 to i32
  %6293 = load i8, i8* %arrayidx70.6, align 1
  %conv71.27.6 = zext i8 %6293 to i32
  %xor72.27.6 = xor i32 %conv71.27.6, %conv68.27.6
  %conv73.27.6 = trunc i32 %xor72.27.6 to i8
  store i8 %conv73.27.6, i8* %arrayidx70.6, align 1
  %scevgep20.28.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 28
  %6294 = load i8, i8* %scevgep20.28.6, align 1
  %conv68.28.6 = zext i8 %6294 to i32
  %6295 = load i8, i8* %arrayidx70.6, align 1
  %conv71.28.6 = zext i8 %6295 to i32
  %xor72.28.6 = xor i32 %conv71.28.6, %conv68.28.6
  %conv73.28.6 = trunc i32 %xor72.28.6 to i8
  store i8 %conv73.28.6, i8* %arrayidx70.6, align 1
  %scevgep20.29.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 29
  %6296 = load i8, i8* %scevgep20.29.6, align 1
  %conv68.29.6 = zext i8 %6296 to i32
  %6297 = load i8, i8* %arrayidx70.6, align 1
  %conv71.29.6 = zext i8 %6297 to i32
  %xor72.29.6 = xor i32 %conv71.29.6, %conv68.29.6
  %conv73.29.6 = trunc i32 %xor72.29.6 to i8
  store i8 %conv73.29.6, i8* %arrayidx70.6, align 1
  %scevgep20.30.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 30
  %6298 = load i8, i8* %scevgep20.30.6, align 1
  %conv68.30.6 = zext i8 %6298 to i32
  %6299 = load i8, i8* %arrayidx70.6, align 1
  %conv71.30.6 = zext i8 %6299 to i32
  %xor72.30.6 = xor i32 %conv71.30.6, %conv68.30.6
  %conv73.30.6 = trunc i32 %xor72.30.6 to i8
  store i8 %conv73.30.6, i8* %arrayidx70.6, align 1
  %scevgep20.31.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 31
  %6300 = load i8, i8* %scevgep20.31.6, align 1
  %conv68.31.6 = zext i8 %6300 to i32
  %6301 = load i8, i8* %arrayidx70.6, align 1
  %conv71.31.6 = zext i8 %6301 to i32
  %xor72.31.6 = xor i32 %conv71.31.6, %conv68.31.6
  %conv73.31.6 = trunc i32 %xor72.31.6 to i8
  store i8 %conv73.31.6, i8* %arrayidx70.6, align 1
  %scevgep20.32.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 32
  %6302 = load i8, i8* %scevgep20.32.6, align 1
  %conv68.32.6 = zext i8 %6302 to i32
  %6303 = load i8, i8* %arrayidx70.6, align 1
  %conv71.32.6 = zext i8 %6303 to i32
  %xor72.32.6 = xor i32 %conv71.32.6, %conv68.32.6
  %conv73.32.6 = trunc i32 %xor72.32.6 to i8
  store i8 %conv73.32.6, i8* %arrayidx70.6, align 1
  %scevgep20.33.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 33
  %6304 = load i8, i8* %scevgep20.33.6, align 1
  %conv68.33.6 = zext i8 %6304 to i32
  %6305 = load i8, i8* %arrayidx70.6, align 1
  %conv71.33.6 = zext i8 %6305 to i32
  %xor72.33.6 = xor i32 %conv71.33.6, %conv68.33.6
  %conv73.33.6 = trunc i32 %xor72.33.6 to i8
  store i8 %conv73.33.6, i8* %arrayidx70.6, align 1
  %scevgep20.34.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 34
  %6306 = load i8, i8* %scevgep20.34.6, align 1
  %conv68.34.6 = zext i8 %6306 to i32
  %6307 = load i8, i8* %arrayidx70.6, align 1
  %conv71.34.6 = zext i8 %6307 to i32
  %xor72.34.6 = xor i32 %conv71.34.6, %conv68.34.6
  %conv73.34.6 = trunc i32 %xor72.34.6 to i8
  store i8 %conv73.34.6, i8* %arrayidx70.6, align 1
  %scevgep20.35.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 35
  %6308 = load i8, i8* %scevgep20.35.6, align 1
  %conv68.35.6 = zext i8 %6308 to i32
  %6309 = load i8, i8* %arrayidx70.6, align 1
  %conv71.35.6 = zext i8 %6309 to i32
  %xor72.35.6 = xor i32 %conv71.35.6, %conv68.35.6
  %conv73.35.6 = trunc i32 %xor72.35.6 to i8
  store i8 %conv73.35.6, i8* %arrayidx70.6, align 1
  %scevgep20.36.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 36
  %6310 = load i8, i8* %scevgep20.36.6, align 1
  %conv68.36.6 = zext i8 %6310 to i32
  %6311 = load i8, i8* %arrayidx70.6, align 1
  %conv71.36.6 = zext i8 %6311 to i32
  %xor72.36.6 = xor i32 %conv71.36.6, %conv68.36.6
  %conv73.36.6 = trunc i32 %xor72.36.6 to i8
  store i8 %conv73.36.6, i8* %arrayidx70.6, align 1
  %scevgep20.37.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 37
  %6312 = load i8, i8* %scevgep20.37.6, align 1
  %conv68.37.6 = zext i8 %6312 to i32
  %6313 = load i8, i8* %arrayidx70.6, align 1
  %conv71.37.6 = zext i8 %6313 to i32
  %xor72.37.6 = xor i32 %conv71.37.6, %conv68.37.6
  %conv73.37.6 = trunc i32 %xor72.37.6 to i8
  store i8 %conv73.37.6, i8* %arrayidx70.6, align 1
  %scevgep20.38.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 38
  %6314 = load i8, i8* %scevgep20.38.6, align 1
  %conv68.38.6 = zext i8 %6314 to i32
  %6315 = load i8, i8* %arrayidx70.6, align 1
  %conv71.38.6 = zext i8 %6315 to i32
  %xor72.38.6 = xor i32 %conv71.38.6, %conv68.38.6
  %conv73.38.6 = trunc i32 %xor72.38.6 to i8
  store i8 %conv73.38.6, i8* %arrayidx70.6, align 1
  %scevgep20.39.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 39
  %6316 = load i8, i8* %scevgep20.39.6, align 1
  %conv68.39.6 = zext i8 %6316 to i32
  %6317 = load i8, i8* %arrayidx70.6, align 1
  %conv71.39.6 = zext i8 %6317 to i32
  %xor72.39.6 = xor i32 %conv71.39.6, %conv68.39.6
  %conv73.39.6 = trunc i32 %xor72.39.6 to i8
  store i8 %conv73.39.6, i8* %arrayidx70.6, align 1
  %scevgep20.40.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 0, i64 40
  %6318 = load i8, i8* %scevgep20.40.6, align 1
  %conv68.40.6 = zext i8 %6318 to i32
  %6319 = load i8, i8* %arrayidx70.6, align 1
  %conv71.40.6 = zext i8 %6319 to i32
  %xor72.40.6 = xor i32 %conv71.40.6, %conv68.40.6
  %conv73.40.6 = trunc i32 %xor72.40.6 to i8
  store i8 %conv73.40.6, i8* %arrayidx70.6, align 1
  %scevgep19.6 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6237, i64 0, i64 1, i64 0
  %6320 = bitcast i8* %scevgep19.6 to [41 x [41 x i8]]*
  %arrayidx51.7 = getelementptr inbounds i8, i8* %a, i64 7
  %6321 = load i8, i8* %arrayidx51.7, align 1
  %arrayidx53.7 = getelementptr inbounds i8, i8* %b, i64 7
  %6322 = load i8, i8* %arrayidx53.7, align 1
  %call54.7 = call zeroext i8 @mult(i8 zeroext %6321, i8 zeroext %6322)
  %arrayidx56.7 = getelementptr inbounds i8, i8* %c, i64 7
  store i8 %call54.7, i8* %arrayidx56.7, align 1
  %arrayidx70.7 = getelementptr inbounds i8, i8* %c, i64 7
  %scevgep20.7114 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 0
  %6323 = load i8, i8* %scevgep20.7114, align 1
  %conv68.7115 = zext i8 %6323 to i32
  %6324 = load i8, i8* %arrayidx70.7, align 1
  %conv71.7116 = zext i8 %6324 to i32
  %xor72.7117 = xor i32 %conv71.7116, %conv68.7115
  %conv73.7118 = trunc i32 %xor72.7117 to i8
  store i8 %conv73.7118, i8* %arrayidx70.7, align 1
  %scevgep20.1.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 1
  %6325 = load i8, i8* %scevgep20.1.7, align 1
  %conv68.1.7 = zext i8 %6325 to i32
  %6326 = load i8, i8* %arrayidx70.7, align 1
  %conv71.1.7 = zext i8 %6326 to i32
  %xor72.1.7 = xor i32 %conv71.1.7, %conv68.1.7
  %conv73.1.7 = trunc i32 %xor72.1.7 to i8
  store i8 %conv73.1.7, i8* %arrayidx70.7, align 1
  %scevgep20.2.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 2
  %6327 = load i8, i8* %scevgep20.2.7, align 1
  %conv68.2.7 = zext i8 %6327 to i32
  %6328 = load i8, i8* %arrayidx70.7, align 1
  %conv71.2.7 = zext i8 %6328 to i32
  %xor72.2.7 = xor i32 %conv71.2.7, %conv68.2.7
  %conv73.2.7 = trunc i32 %xor72.2.7 to i8
  store i8 %conv73.2.7, i8* %arrayidx70.7, align 1
  %scevgep20.3.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 3
  %6329 = load i8, i8* %scevgep20.3.7, align 1
  %conv68.3.7 = zext i8 %6329 to i32
  %6330 = load i8, i8* %arrayidx70.7, align 1
  %conv71.3.7 = zext i8 %6330 to i32
  %xor72.3.7 = xor i32 %conv71.3.7, %conv68.3.7
  %conv73.3.7 = trunc i32 %xor72.3.7 to i8
  store i8 %conv73.3.7, i8* %arrayidx70.7, align 1
  %scevgep20.4.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 4
  %6331 = load i8, i8* %scevgep20.4.7, align 1
  %conv68.4.7 = zext i8 %6331 to i32
  %6332 = load i8, i8* %arrayidx70.7, align 1
  %conv71.4.7 = zext i8 %6332 to i32
  %xor72.4.7 = xor i32 %conv71.4.7, %conv68.4.7
  %conv73.4.7 = trunc i32 %xor72.4.7 to i8
  store i8 %conv73.4.7, i8* %arrayidx70.7, align 1
  %scevgep20.5.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 5
  %6333 = load i8, i8* %scevgep20.5.7, align 1
  %conv68.5.7 = zext i8 %6333 to i32
  %6334 = load i8, i8* %arrayidx70.7, align 1
  %conv71.5.7 = zext i8 %6334 to i32
  %xor72.5.7 = xor i32 %conv71.5.7, %conv68.5.7
  %conv73.5.7 = trunc i32 %xor72.5.7 to i8
  store i8 %conv73.5.7, i8* %arrayidx70.7, align 1
  %scevgep20.6.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 6
  %6335 = load i8, i8* %scevgep20.6.7, align 1
  %conv68.6.7 = zext i8 %6335 to i32
  %6336 = load i8, i8* %arrayidx70.7, align 1
  %conv71.6.7 = zext i8 %6336 to i32
  %xor72.6.7 = xor i32 %conv71.6.7, %conv68.6.7
  %conv73.6.7 = trunc i32 %xor72.6.7 to i8
  store i8 %conv73.6.7, i8* %arrayidx70.7, align 1
  %scevgep20.8.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 8
  %6337 = load i8, i8* %scevgep20.8.7, align 1
  %conv68.8.7 = zext i8 %6337 to i32
  %6338 = load i8, i8* %arrayidx70.7, align 1
  %conv71.8.7 = zext i8 %6338 to i32
  %xor72.8.7 = xor i32 %conv71.8.7, %conv68.8.7
  %conv73.8.7 = trunc i32 %xor72.8.7 to i8
  store i8 %conv73.8.7, i8* %arrayidx70.7, align 1
  %scevgep20.9.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 9
  %6339 = load i8, i8* %scevgep20.9.7, align 1
  %conv68.9.7 = zext i8 %6339 to i32
  %6340 = load i8, i8* %arrayidx70.7, align 1
  %conv71.9.7 = zext i8 %6340 to i32
  %xor72.9.7 = xor i32 %conv71.9.7, %conv68.9.7
  %conv73.9.7 = trunc i32 %xor72.9.7 to i8
  store i8 %conv73.9.7, i8* %arrayidx70.7, align 1
  %scevgep20.10.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 10
  %6341 = load i8, i8* %scevgep20.10.7, align 1
  %conv68.10.7 = zext i8 %6341 to i32
  %6342 = load i8, i8* %arrayidx70.7, align 1
  %conv71.10.7 = zext i8 %6342 to i32
  %xor72.10.7 = xor i32 %conv71.10.7, %conv68.10.7
  %conv73.10.7 = trunc i32 %xor72.10.7 to i8
  store i8 %conv73.10.7, i8* %arrayidx70.7, align 1
  %scevgep20.11.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 11
  %6343 = load i8, i8* %scevgep20.11.7, align 1
  %conv68.11.7 = zext i8 %6343 to i32
  %6344 = load i8, i8* %arrayidx70.7, align 1
  %conv71.11.7 = zext i8 %6344 to i32
  %xor72.11.7 = xor i32 %conv71.11.7, %conv68.11.7
  %conv73.11.7 = trunc i32 %xor72.11.7 to i8
  store i8 %conv73.11.7, i8* %arrayidx70.7, align 1
  %scevgep20.12.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 12
  %6345 = load i8, i8* %scevgep20.12.7, align 1
  %conv68.12.7 = zext i8 %6345 to i32
  %6346 = load i8, i8* %arrayidx70.7, align 1
  %conv71.12.7 = zext i8 %6346 to i32
  %xor72.12.7 = xor i32 %conv71.12.7, %conv68.12.7
  %conv73.12.7 = trunc i32 %xor72.12.7 to i8
  store i8 %conv73.12.7, i8* %arrayidx70.7, align 1
  %scevgep20.13.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 13
  %6347 = load i8, i8* %scevgep20.13.7, align 1
  %conv68.13.7 = zext i8 %6347 to i32
  %6348 = load i8, i8* %arrayidx70.7, align 1
  %conv71.13.7 = zext i8 %6348 to i32
  %xor72.13.7 = xor i32 %conv71.13.7, %conv68.13.7
  %conv73.13.7 = trunc i32 %xor72.13.7 to i8
  store i8 %conv73.13.7, i8* %arrayidx70.7, align 1
  %scevgep20.14.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 14
  %6349 = load i8, i8* %scevgep20.14.7, align 1
  %conv68.14.7 = zext i8 %6349 to i32
  %6350 = load i8, i8* %arrayidx70.7, align 1
  %conv71.14.7 = zext i8 %6350 to i32
  %xor72.14.7 = xor i32 %conv71.14.7, %conv68.14.7
  %conv73.14.7 = trunc i32 %xor72.14.7 to i8
  store i8 %conv73.14.7, i8* %arrayidx70.7, align 1
  %scevgep20.15.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 15
  %6351 = load i8, i8* %scevgep20.15.7, align 1
  %conv68.15.7 = zext i8 %6351 to i32
  %6352 = load i8, i8* %arrayidx70.7, align 1
  %conv71.15.7 = zext i8 %6352 to i32
  %xor72.15.7 = xor i32 %conv71.15.7, %conv68.15.7
  %conv73.15.7 = trunc i32 %xor72.15.7 to i8
  store i8 %conv73.15.7, i8* %arrayidx70.7, align 1
  %scevgep20.16.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 16
  %6353 = load i8, i8* %scevgep20.16.7, align 1
  %conv68.16.7 = zext i8 %6353 to i32
  %6354 = load i8, i8* %arrayidx70.7, align 1
  %conv71.16.7 = zext i8 %6354 to i32
  %xor72.16.7 = xor i32 %conv71.16.7, %conv68.16.7
  %conv73.16.7 = trunc i32 %xor72.16.7 to i8
  store i8 %conv73.16.7, i8* %arrayidx70.7, align 1
  %scevgep20.17.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 17
  %6355 = load i8, i8* %scevgep20.17.7, align 1
  %conv68.17.7 = zext i8 %6355 to i32
  %6356 = load i8, i8* %arrayidx70.7, align 1
  %conv71.17.7 = zext i8 %6356 to i32
  %xor72.17.7 = xor i32 %conv71.17.7, %conv68.17.7
  %conv73.17.7 = trunc i32 %xor72.17.7 to i8
  store i8 %conv73.17.7, i8* %arrayidx70.7, align 1
  %scevgep20.18.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 18
  %6357 = load i8, i8* %scevgep20.18.7, align 1
  %conv68.18.7 = zext i8 %6357 to i32
  %6358 = load i8, i8* %arrayidx70.7, align 1
  %conv71.18.7 = zext i8 %6358 to i32
  %xor72.18.7 = xor i32 %conv71.18.7, %conv68.18.7
  %conv73.18.7 = trunc i32 %xor72.18.7 to i8
  store i8 %conv73.18.7, i8* %arrayidx70.7, align 1
  %scevgep20.19.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 19
  %6359 = load i8, i8* %scevgep20.19.7, align 1
  %conv68.19.7 = zext i8 %6359 to i32
  %6360 = load i8, i8* %arrayidx70.7, align 1
  %conv71.19.7 = zext i8 %6360 to i32
  %xor72.19.7 = xor i32 %conv71.19.7, %conv68.19.7
  %conv73.19.7 = trunc i32 %xor72.19.7 to i8
  store i8 %conv73.19.7, i8* %arrayidx70.7, align 1
  %scevgep20.20.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 20
  %6361 = load i8, i8* %scevgep20.20.7, align 1
  %conv68.20.7 = zext i8 %6361 to i32
  %6362 = load i8, i8* %arrayidx70.7, align 1
  %conv71.20.7 = zext i8 %6362 to i32
  %xor72.20.7 = xor i32 %conv71.20.7, %conv68.20.7
  %conv73.20.7 = trunc i32 %xor72.20.7 to i8
  store i8 %conv73.20.7, i8* %arrayidx70.7, align 1
  %scevgep20.21.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 21
  %6363 = load i8, i8* %scevgep20.21.7, align 1
  %conv68.21.7 = zext i8 %6363 to i32
  %6364 = load i8, i8* %arrayidx70.7, align 1
  %conv71.21.7 = zext i8 %6364 to i32
  %xor72.21.7 = xor i32 %conv71.21.7, %conv68.21.7
  %conv73.21.7 = trunc i32 %xor72.21.7 to i8
  store i8 %conv73.21.7, i8* %arrayidx70.7, align 1
  %scevgep20.22.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 22
  %6365 = load i8, i8* %scevgep20.22.7, align 1
  %conv68.22.7 = zext i8 %6365 to i32
  %6366 = load i8, i8* %arrayidx70.7, align 1
  %conv71.22.7 = zext i8 %6366 to i32
  %xor72.22.7 = xor i32 %conv71.22.7, %conv68.22.7
  %conv73.22.7 = trunc i32 %xor72.22.7 to i8
  store i8 %conv73.22.7, i8* %arrayidx70.7, align 1
  %scevgep20.23.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 23
  %6367 = load i8, i8* %scevgep20.23.7, align 1
  %conv68.23.7 = zext i8 %6367 to i32
  %6368 = load i8, i8* %arrayidx70.7, align 1
  %conv71.23.7 = zext i8 %6368 to i32
  %xor72.23.7 = xor i32 %conv71.23.7, %conv68.23.7
  %conv73.23.7 = trunc i32 %xor72.23.7 to i8
  store i8 %conv73.23.7, i8* %arrayidx70.7, align 1
  %scevgep20.24.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 24
  %6369 = load i8, i8* %scevgep20.24.7, align 1
  %conv68.24.7 = zext i8 %6369 to i32
  %6370 = load i8, i8* %arrayidx70.7, align 1
  %conv71.24.7 = zext i8 %6370 to i32
  %xor72.24.7 = xor i32 %conv71.24.7, %conv68.24.7
  %conv73.24.7 = trunc i32 %xor72.24.7 to i8
  store i8 %conv73.24.7, i8* %arrayidx70.7, align 1
  %scevgep20.25.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 25
  %6371 = load i8, i8* %scevgep20.25.7, align 1
  %conv68.25.7 = zext i8 %6371 to i32
  %6372 = load i8, i8* %arrayidx70.7, align 1
  %conv71.25.7 = zext i8 %6372 to i32
  %xor72.25.7 = xor i32 %conv71.25.7, %conv68.25.7
  %conv73.25.7 = trunc i32 %xor72.25.7 to i8
  store i8 %conv73.25.7, i8* %arrayidx70.7, align 1
  %scevgep20.26.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 26
  %6373 = load i8, i8* %scevgep20.26.7, align 1
  %conv68.26.7 = zext i8 %6373 to i32
  %6374 = load i8, i8* %arrayidx70.7, align 1
  %conv71.26.7 = zext i8 %6374 to i32
  %xor72.26.7 = xor i32 %conv71.26.7, %conv68.26.7
  %conv73.26.7 = trunc i32 %xor72.26.7 to i8
  store i8 %conv73.26.7, i8* %arrayidx70.7, align 1
  %scevgep20.27.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 27
  %6375 = load i8, i8* %scevgep20.27.7, align 1
  %conv68.27.7 = zext i8 %6375 to i32
  %6376 = load i8, i8* %arrayidx70.7, align 1
  %conv71.27.7 = zext i8 %6376 to i32
  %xor72.27.7 = xor i32 %conv71.27.7, %conv68.27.7
  %conv73.27.7 = trunc i32 %xor72.27.7 to i8
  store i8 %conv73.27.7, i8* %arrayidx70.7, align 1
  %scevgep20.28.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 28
  %6377 = load i8, i8* %scevgep20.28.7, align 1
  %conv68.28.7 = zext i8 %6377 to i32
  %6378 = load i8, i8* %arrayidx70.7, align 1
  %conv71.28.7 = zext i8 %6378 to i32
  %xor72.28.7 = xor i32 %conv71.28.7, %conv68.28.7
  %conv73.28.7 = trunc i32 %xor72.28.7 to i8
  store i8 %conv73.28.7, i8* %arrayidx70.7, align 1
  %scevgep20.29.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 29
  %6379 = load i8, i8* %scevgep20.29.7, align 1
  %conv68.29.7 = zext i8 %6379 to i32
  %6380 = load i8, i8* %arrayidx70.7, align 1
  %conv71.29.7 = zext i8 %6380 to i32
  %xor72.29.7 = xor i32 %conv71.29.7, %conv68.29.7
  %conv73.29.7 = trunc i32 %xor72.29.7 to i8
  store i8 %conv73.29.7, i8* %arrayidx70.7, align 1
  %scevgep20.30.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 30
  %6381 = load i8, i8* %scevgep20.30.7, align 1
  %conv68.30.7 = zext i8 %6381 to i32
  %6382 = load i8, i8* %arrayidx70.7, align 1
  %conv71.30.7 = zext i8 %6382 to i32
  %xor72.30.7 = xor i32 %conv71.30.7, %conv68.30.7
  %conv73.30.7 = trunc i32 %xor72.30.7 to i8
  store i8 %conv73.30.7, i8* %arrayidx70.7, align 1
  %scevgep20.31.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 31
  %6383 = load i8, i8* %scevgep20.31.7, align 1
  %conv68.31.7 = zext i8 %6383 to i32
  %6384 = load i8, i8* %arrayidx70.7, align 1
  %conv71.31.7 = zext i8 %6384 to i32
  %xor72.31.7 = xor i32 %conv71.31.7, %conv68.31.7
  %conv73.31.7 = trunc i32 %xor72.31.7 to i8
  store i8 %conv73.31.7, i8* %arrayidx70.7, align 1
  %scevgep20.32.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 32
  %6385 = load i8, i8* %scevgep20.32.7, align 1
  %conv68.32.7 = zext i8 %6385 to i32
  %6386 = load i8, i8* %arrayidx70.7, align 1
  %conv71.32.7 = zext i8 %6386 to i32
  %xor72.32.7 = xor i32 %conv71.32.7, %conv68.32.7
  %conv73.32.7 = trunc i32 %xor72.32.7 to i8
  store i8 %conv73.32.7, i8* %arrayidx70.7, align 1
  %scevgep20.33.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 33
  %6387 = load i8, i8* %scevgep20.33.7, align 1
  %conv68.33.7 = zext i8 %6387 to i32
  %6388 = load i8, i8* %arrayidx70.7, align 1
  %conv71.33.7 = zext i8 %6388 to i32
  %xor72.33.7 = xor i32 %conv71.33.7, %conv68.33.7
  %conv73.33.7 = trunc i32 %xor72.33.7 to i8
  store i8 %conv73.33.7, i8* %arrayidx70.7, align 1
  %scevgep20.34.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 34
  %6389 = load i8, i8* %scevgep20.34.7, align 1
  %conv68.34.7 = zext i8 %6389 to i32
  %6390 = load i8, i8* %arrayidx70.7, align 1
  %conv71.34.7 = zext i8 %6390 to i32
  %xor72.34.7 = xor i32 %conv71.34.7, %conv68.34.7
  %conv73.34.7 = trunc i32 %xor72.34.7 to i8
  store i8 %conv73.34.7, i8* %arrayidx70.7, align 1
  %scevgep20.35.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 35
  %6391 = load i8, i8* %scevgep20.35.7, align 1
  %conv68.35.7 = zext i8 %6391 to i32
  %6392 = load i8, i8* %arrayidx70.7, align 1
  %conv71.35.7 = zext i8 %6392 to i32
  %xor72.35.7 = xor i32 %conv71.35.7, %conv68.35.7
  %conv73.35.7 = trunc i32 %xor72.35.7 to i8
  store i8 %conv73.35.7, i8* %arrayidx70.7, align 1
  %scevgep20.36.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 36
  %6393 = load i8, i8* %scevgep20.36.7, align 1
  %conv68.36.7 = zext i8 %6393 to i32
  %6394 = load i8, i8* %arrayidx70.7, align 1
  %conv71.36.7 = zext i8 %6394 to i32
  %xor72.36.7 = xor i32 %conv71.36.7, %conv68.36.7
  %conv73.36.7 = trunc i32 %xor72.36.7 to i8
  store i8 %conv73.36.7, i8* %arrayidx70.7, align 1
  %scevgep20.37.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 37
  %6395 = load i8, i8* %scevgep20.37.7, align 1
  %conv68.37.7 = zext i8 %6395 to i32
  %6396 = load i8, i8* %arrayidx70.7, align 1
  %conv71.37.7 = zext i8 %6396 to i32
  %xor72.37.7 = xor i32 %conv71.37.7, %conv68.37.7
  %conv73.37.7 = trunc i32 %xor72.37.7 to i8
  store i8 %conv73.37.7, i8* %arrayidx70.7, align 1
  %scevgep20.38.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 38
  %6397 = load i8, i8* %scevgep20.38.7, align 1
  %conv68.38.7 = zext i8 %6397 to i32
  %6398 = load i8, i8* %arrayidx70.7, align 1
  %conv71.38.7 = zext i8 %6398 to i32
  %xor72.38.7 = xor i32 %conv71.38.7, %conv68.38.7
  %conv73.38.7 = trunc i32 %xor72.38.7 to i8
  store i8 %conv73.38.7, i8* %arrayidx70.7, align 1
  %scevgep20.39.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 39
  %6399 = load i8, i8* %scevgep20.39.7, align 1
  %conv68.39.7 = zext i8 %6399 to i32
  %6400 = load i8, i8* %arrayidx70.7, align 1
  %conv71.39.7 = zext i8 %6400 to i32
  %xor72.39.7 = xor i32 %conv71.39.7, %conv68.39.7
  %conv73.39.7 = trunc i32 %xor72.39.7 to i8
  store i8 %conv73.39.7, i8* %arrayidx70.7, align 1
  %scevgep20.40.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 0, i64 40
  %6401 = load i8, i8* %scevgep20.40.7, align 1
  %conv68.40.7 = zext i8 %6401 to i32
  %6402 = load i8, i8* %arrayidx70.7, align 1
  %conv71.40.7 = zext i8 %6402 to i32
  %xor72.40.7 = xor i32 %conv71.40.7, %conv68.40.7
  %conv73.40.7 = trunc i32 %xor72.40.7 to i8
  store i8 %conv73.40.7, i8* %arrayidx70.7, align 1
  %scevgep19.7 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6320, i64 0, i64 1, i64 0
  %6403 = bitcast i8* %scevgep19.7 to [41 x [41 x i8]]*
  %arrayidx51.8 = getelementptr inbounds i8, i8* %a, i64 8
  %6404 = load i8, i8* %arrayidx51.8, align 1
  %arrayidx53.8 = getelementptr inbounds i8, i8* %b, i64 8
  %6405 = load i8, i8* %arrayidx53.8, align 1
  %call54.8 = call zeroext i8 @mult(i8 zeroext %6404, i8 zeroext %6405)
  %arrayidx56.8 = getelementptr inbounds i8, i8* %c, i64 8
  store i8 %call54.8, i8* %arrayidx56.8, align 1
  %arrayidx70.8 = getelementptr inbounds i8, i8* %c, i64 8
  %scevgep20.8124 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 0
  %6406 = load i8, i8* %scevgep20.8124, align 1
  %conv68.8125 = zext i8 %6406 to i32
  %6407 = load i8, i8* %arrayidx70.8, align 1
  %conv71.8126 = zext i8 %6407 to i32
  %xor72.8127 = xor i32 %conv71.8126, %conv68.8125
  %conv73.8128 = trunc i32 %xor72.8127 to i8
  store i8 %conv73.8128, i8* %arrayidx70.8, align 1
  %scevgep20.1.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 1
  %6408 = load i8, i8* %scevgep20.1.8, align 1
  %conv68.1.8 = zext i8 %6408 to i32
  %6409 = load i8, i8* %arrayidx70.8, align 1
  %conv71.1.8 = zext i8 %6409 to i32
  %xor72.1.8 = xor i32 %conv71.1.8, %conv68.1.8
  %conv73.1.8 = trunc i32 %xor72.1.8 to i8
  store i8 %conv73.1.8, i8* %arrayidx70.8, align 1
  %scevgep20.2.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 2
  %6410 = load i8, i8* %scevgep20.2.8, align 1
  %conv68.2.8 = zext i8 %6410 to i32
  %6411 = load i8, i8* %arrayidx70.8, align 1
  %conv71.2.8 = zext i8 %6411 to i32
  %xor72.2.8 = xor i32 %conv71.2.8, %conv68.2.8
  %conv73.2.8 = trunc i32 %xor72.2.8 to i8
  store i8 %conv73.2.8, i8* %arrayidx70.8, align 1
  %scevgep20.3.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 3
  %6412 = load i8, i8* %scevgep20.3.8, align 1
  %conv68.3.8 = zext i8 %6412 to i32
  %6413 = load i8, i8* %arrayidx70.8, align 1
  %conv71.3.8 = zext i8 %6413 to i32
  %xor72.3.8 = xor i32 %conv71.3.8, %conv68.3.8
  %conv73.3.8 = trunc i32 %xor72.3.8 to i8
  store i8 %conv73.3.8, i8* %arrayidx70.8, align 1
  %scevgep20.4.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 4
  %6414 = load i8, i8* %scevgep20.4.8, align 1
  %conv68.4.8 = zext i8 %6414 to i32
  %6415 = load i8, i8* %arrayidx70.8, align 1
  %conv71.4.8 = zext i8 %6415 to i32
  %xor72.4.8 = xor i32 %conv71.4.8, %conv68.4.8
  %conv73.4.8 = trunc i32 %xor72.4.8 to i8
  store i8 %conv73.4.8, i8* %arrayidx70.8, align 1
  %scevgep20.5.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 5
  %6416 = load i8, i8* %scevgep20.5.8, align 1
  %conv68.5.8 = zext i8 %6416 to i32
  %6417 = load i8, i8* %arrayidx70.8, align 1
  %conv71.5.8 = zext i8 %6417 to i32
  %xor72.5.8 = xor i32 %conv71.5.8, %conv68.5.8
  %conv73.5.8 = trunc i32 %xor72.5.8 to i8
  store i8 %conv73.5.8, i8* %arrayidx70.8, align 1
  %scevgep20.6.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 6
  %6418 = load i8, i8* %scevgep20.6.8, align 1
  %conv68.6.8 = zext i8 %6418 to i32
  %6419 = load i8, i8* %arrayidx70.8, align 1
  %conv71.6.8 = zext i8 %6419 to i32
  %xor72.6.8 = xor i32 %conv71.6.8, %conv68.6.8
  %conv73.6.8 = trunc i32 %xor72.6.8 to i8
  store i8 %conv73.6.8, i8* %arrayidx70.8, align 1
  %scevgep20.7.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 7
  %6420 = load i8, i8* %scevgep20.7.8, align 1
  %conv68.7.8 = zext i8 %6420 to i32
  %6421 = load i8, i8* %arrayidx70.8, align 1
  %conv71.7.8 = zext i8 %6421 to i32
  %xor72.7.8 = xor i32 %conv71.7.8, %conv68.7.8
  %conv73.7.8 = trunc i32 %xor72.7.8 to i8
  store i8 %conv73.7.8, i8* %arrayidx70.8, align 1
  %scevgep20.9.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 9
  %6422 = load i8, i8* %scevgep20.9.8, align 1
  %conv68.9.8 = zext i8 %6422 to i32
  %6423 = load i8, i8* %arrayidx70.8, align 1
  %conv71.9.8 = zext i8 %6423 to i32
  %xor72.9.8 = xor i32 %conv71.9.8, %conv68.9.8
  %conv73.9.8 = trunc i32 %xor72.9.8 to i8
  store i8 %conv73.9.8, i8* %arrayidx70.8, align 1
  %scevgep20.10.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 10
  %6424 = load i8, i8* %scevgep20.10.8, align 1
  %conv68.10.8 = zext i8 %6424 to i32
  %6425 = load i8, i8* %arrayidx70.8, align 1
  %conv71.10.8 = zext i8 %6425 to i32
  %xor72.10.8 = xor i32 %conv71.10.8, %conv68.10.8
  %conv73.10.8 = trunc i32 %xor72.10.8 to i8
  store i8 %conv73.10.8, i8* %arrayidx70.8, align 1
  %scevgep20.11.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 11
  %6426 = load i8, i8* %scevgep20.11.8, align 1
  %conv68.11.8 = zext i8 %6426 to i32
  %6427 = load i8, i8* %arrayidx70.8, align 1
  %conv71.11.8 = zext i8 %6427 to i32
  %xor72.11.8 = xor i32 %conv71.11.8, %conv68.11.8
  %conv73.11.8 = trunc i32 %xor72.11.8 to i8
  store i8 %conv73.11.8, i8* %arrayidx70.8, align 1
  %scevgep20.12.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 12
  %6428 = load i8, i8* %scevgep20.12.8, align 1
  %conv68.12.8 = zext i8 %6428 to i32
  %6429 = load i8, i8* %arrayidx70.8, align 1
  %conv71.12.8 = zext i8 %6429 to i32
  %xor72.12.8 = xor i32 %conv71.12.8, %conv68.12.8
  %conv73.12.8 = trunc i32 %xor72.12.8 to i8
  store i8 %conv73.12.8, i8* %arrayidx70.8, align 1
  %scevgep20.13.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 13
  %6430 = load i8, i8* %scevgep20.13.8, align 1
  %conv68.13.8 = zext i8 %6430 to i32
  %6431 = load i8, i8* %arrayidx70.8, align 1
  %conv71.13.8 = zext i8 %6431 to i32
  %xor72.13.8 = xor i32 %conv71.13.8, %conv68.13.8
  %conv73.13.8 = trunc i32 %xor72.13.8 to i8
  store i8 %conv73.13.8, i8* %arrayidx70.8, align 1
  %scevgep20.14.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 14
  %6432 = load i8, i8* %scevgep20.14.8, align 1
  %conv68.14.8 = zext i8 %6432 to i32
  %6433 = load i8, i8* %arrayidx70.8, align 1
  %conv71.14.8 = zext i8 %6433 to i32
  %xor72.14.8 = xor i32 %conv71.14.8, %conv68.14.8
  %conv73.14.8 = trunc i32 %xor72.14.8 to i8
  store i8 %conv73.14.8, i8* %arrayidx70.8, align 1
  %scevgep20.15.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 15
  %6434 = load i8, i8* %scevgep20.15.8, align 1
  %conv68.15.8 = zext i8 %6434 to i32
  %6435 = load i8, i8* %arrayidx70.8, align 1
  %conv71.15.8 = zext i8 %6435 to i32
  %xor72.15.8 = xor i32 %conv71.15.8, %conv68.15.8
  %conv73.15.8 = trunc i32 %xor72.15.8 to i8
  store i8 %conv73.15.8, i8* %arrayidx70.8, align 1
  %scevgep20.16.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 16
  %6436 = load i8, i8* %scevgep20.16.8, align 1
  %conv68.16.8 = zext i8 %6436 to i32
  %6437 = load i8, i8* %arrayidx70.8, align 1
  %conv71.16.8 = zext i8 %6437 to i32
  %xor72.16.8 = xor i32 %conv71.16.8, %conv68.16.8
  %conv73.16.8 = trunc i32 %xor72.16.8 to i8
  store i8 %conv73.16.8, i8* %arrayidx70.8, align 1
  %scevgep20.17.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 17
  %6438 = load i8, i8* %scevgep20.17.8, align 1
  %conv68.17.8 = zext i8 %6438 to i32
  %6439 = load i8, i8* %arrayidx70.8, align 1
  %conv71.17.8 = zext i8 %6439 to i32
  %xor72.17.8 = xor i32 %conv71.17.8, %conv68.17.8
  %conv73.17.8 = trunc i32 %xor72.17.8 to i8
  store i8 %conv73.17.8, i8* %arrayidx70.8, align 1
  %scevgep20.18.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 18
  %6440 = load i8, i8* %scevgep20.18.8, align 1
  %conv68.18.8 = zext i8 %6440 to i32
  %6441 = load i8, i8* %arrayidx70.8, align 1
  %conv71.18.8 = zext i8 %6441 to i32
  %xor72.18.8 = xor i32 %conv71.18.8, %conv68.18.8
  %conv73.18.8 = trunc i32 %xor72.18.8 to i8
  store i8 %conv73.18.8, i8* %arrayidx70.8, align 1
  %scevgep20.19.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 19
  %6442 = load i8, i8* %scevgep20.19.8, align 1
  %conv68.19.8 = zext i8 %6442 to i32
  %6443 = load i8, i8* %arrayidx70.8, align 1
  %conv71.19.8 = zext i8 %6443 to i32
  %xor72.19.8 = xor i32 %conv71.19.8, %conv68.19.8
  %conv73.19.8 = trunc i32 %xor72.19.8 to i8
  store i8 %conv73.19.8, i8* %arrayidx70.8, align 1
  %scevgep20.20.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 20
  %6444 = load i8, i8* %scevgep20.20.8, align 1
  %conv68.20.8 = zext i8 %6444 to i32
  %6445 = load i8, i8* %arrayidx70.8, align 1
  %conv71.20.8 = zext i8 %6445 to i32
  %xor72.20.8 = xor i32 %conv71.20.8, %conv68.20.8
  %conv73.20.8 = trunc i32 %xor72.20.8 to i8
  store i8 %conv73.20.8, i8* %arrayidx70.8, align 1
  %scevgep20.21.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 21
  %6446 = load i8, i8* %scevgep20.21.8, align 1
  %conv68.21.8 = zext i8 %6446 to i32
  %6447 = load i8, i8* %arrayidx70.8, align 1
  %conv71.21.8 = zext i8 %6447 to i32
  %xor72.21.8 = xor i32 %conv71.21.8, %conv68.21.8
  %conv73.21.8 = trunc i32 %xor72.21.8 to i8
  store i8 %conv73.21.8, i8* %arrayidx70.8, align 1
  %scevgep20.22.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 22
  %6448 = load i8, i8* %scevgep20.22.8, align 1
  %conv68.22.8 = zext i8 %6448 to i32
  %6449 = load i8, i8* %arrayidx70.8, align 1
  %conv71.22.8 = zext i8 %6449 to i32
  %xor72.22.8 = xor i32 %conv71.22.8, %conv68.22.8
  %conv73.22.8 = trunc i32 %xor72.22.8 to i8
  store i8 %conv73.22.8, i8* %arrayidx70.8, align 1
  %scevgep20.23.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 23
  %6450 = load i8, i8* %scevgep20.23.8, align 1
  %conv68.23.8 = zext i8 %6450 to i32
  %6451 = load i8, i8* %arrayidx70.8, align 1
  %conv71.23.8 = zext i8 %6451 to i32
  %xor72.23.8 = xor i32 %conv71.23.8, %conv68.23.8
  %conv73.23.8 = trunc i32 %xor72.23.8 to i8
  store i8 %conv73.23.8, i8* %arrayidx70.8, align 1
  %scevgep20.24.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 24
  %6452 = load i8, i8* %scevgep20.24.8, align 1
  %conv68.24.8 = zext i8 %6452 to i32
  %6453 = load i8, i8* %arrayidx70.8, align 1
  %conv71.24.8 = zext i8 %6453 to i32
  %xor72.24.8 = xor i32 %conv71.24.8, %conv68.24.8
  %conv73.24.8 = trunc i32 %xor72.24.8 to i8
  store i8 %conv73.24.8, i8* %arrayidx70.8, align 1
  %scevgep20.25.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 25
  %6454 = load i8, i8* %scevgep20.25.8, align 1
  %conv68.25.8 = zext i8 %6454 to i32
  %6455 = load i8, i8* %arrayidx70.8, align 1
  %conv71.25.8 = zext i8 %6455 to i32
  %xor72.25.8 = xor i32 %conv71.25.8, %conv68.25.8
  %conv73.25.8 = trunc i32 %xor72.25.8 to i8
  store i8 %conv73.25.8, i8* %arrayidx70.8, align 1
  %scevgep20.26.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 26
  %6456 = load i8, i8* %scevgep20.26.8, align 1
  %conv68.26.8 = zext i8 %6456 to i32
  %6457 = load i8, i8* %arrayidx70.8, align 1
  %conv71.26.8 = zext i8 %6457 to i32
  %xor72.26.8 = xor i32 %conv71.26.8, %conv68.26.8
  %conv73.26.8 = trunc i32 %xor72.26.8 to i8
  store i8 %conv73.26.8, i8* %arrayidx70.8, align 1
  %scevgep20.27.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 27
  %6458 = load i8, i8* %scevgep20.27.8, align 1
  %conv68.27.8 = zext i8 %6458 to i32
  %6459 = load i8, i8* %arrayidx70.8, align 1
  %conv71.27.8 = zext i8 %6459 to i32
  %xor72.27.8 = xor i32 %conv71.27.8, %conv68.27.8
  %conv73.27.8 = trunc i32 %xor72.27.8 to i8
  store i8 %conv73.27.8, i8* %arrayidx70.8, align 1
  %scevgep20.28.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 28
  %6460 = load i8, i8* %scevgep20.28.8, align 1
  %conv68.28.8 = zext i8 %6460 to i32
  %6461 = load i8, i8* %arrayidx70.8, align 1
  %conv71.28.8 = zext i8 %6461 to i32
  %xor72.28.8 = xor i32 %conv71.28.8, %conv68.28.8
  %conv73.28.8 = trunc i32 %xor72.28.8 to i8
  store i8 %conv73.28.8, i8* %arrayidx70.8, align 1
  %scevgep20.29.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 29
  %6462 = load i8, i8* %scevgep20.29.8, align 1
  %conv68.29.8 = zext i8 %6462 to i32
  %6463 = load i8, i8* %arrayidx70.8, align 1
  %conv71.29.8 = zext i8 %6463 to i32
  %xor72.29.8 = xor i32 %conv71.29.8, %conv68.29.8
  %conv73.29.8 = trunc i32 %xor72.29.8 to i8
  store i8 %conv73.29.8, i8* %arrayidx70.8, align 1
  %scevgep20.30.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 30
  %6464 = load i8, i8* %scevgep20.30.8, align 1
  %conv68.30.8 = zext i8 %6464 to i32
  %6465 = load i8, i8* %arrayidx70.8, align 1
  %conv71.30.8 = zext i8 %6465 to i32
  %xor72.30.8 = xor i32 %conv71.30.8, %conv68.30.8
  %conv73.30.8 = trunc i32 %xor72.30.8 to i8
  store i8 %conv73.30.8, i8* %arrayidx70.8, align 1
  %scevgep20.31.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 31
  %6466 = load i8, i8* %scevgep20.31.8, align 1
  %conv68.31.8 = zext i8 %6466 to i32
  %6467 = load i8, i8* %arrayidx70.8, align 1
  %conv71.31.8 = zext i8 %6467 to i32
  %xor72.31.8 = xor i32 %conv71.31.8, %conv68.31.8
  %conv73.31.8 = trunc i32 %xor72.31.8 to i8
  store i8 %conv73.31.8, i8* %arrayidx70.8, align 1
  %scevgep20.32.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 32
  %6468 = load i8, i8* %scevgep20.32.8, align 1
  %conv68.32.8 = zext i8 %6468 to i32
  %6469 = load i8, i8* %arrayidx70.8, align 1
  %conv71.32.8 = zext i8 %6469 to i32
  %xor72.32.8 = xor i32 %conv71.32.8, %conv68.32.8
  %conv73.32.8 = trunc i32 %xor72.32.8 to i8
  store i8 %conv73.32.8, i8* %arrayidx70.8, align 1
  %scevgep20.33.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 33
  %6470 = load i8, i8* %scevgep20.33.8, align 1
  %conv68.33.8 = zext i8 %6470 to i32
  %6471 = load i8, i8* %arrayidx70.8, align 1
  %conv71.33.8 = zext i8 %6471 to i32
  %xor72.33.8 = xor i32 %conv71.33.8, %conv68.33.8
  %conv73.33.8 = trunc i32 %xor72.33.8 to i8
  store i8 %conv73.33.8, i8* %arrayidx70.8, align 1
  %scevgep20.34.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 34
  %6472 = load i8, i8* %scevgep20.34.8, align 1
  %conv68.34.8 = zext i8 %6472 to i32
  %6473 = load i8, i8* %arrayidx70.8, align 1
  %conv71.34.8 = zext i8 %6473 to i32
  %xor72.34.8 = xor i32 %conv71.34.8, %conv68.34.8
  %conv73.34.8 = trunc i32 %xor72.34.8 to i8
  store i8 %conv73.34.8, i8* %arrayidx70.8, align 1
  %scevgep20.35.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 35
  %6474 = load i8, i8* %scevgep20.35.8, align 1
  %conv68.35.8 = zext i8 %6474 to i32
  %6475 = load i8, i8* %arrayidx70.8, align 1
  %conv71.35.8 = zext i8 %6475 to i32
  %xor72.35.8 = xor i32 %conv71.35.8, %conv68.35.8
  %conv73.35.8 = trunc i32 %xor72.35.8 to i8
  store i8 %conv73.35.8, i8* %arrayidx70.8, align 1
  %scevgep20.36.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 36
  %6476 = load i8, i8* %scevgep20.36.8, align 1
  %conv68.36.8 = zext i8 %6476 to i32
  %6477 = load i8, i8* %arrayidx70.8, align 1
  %conv71.36.8 = zext i8 %6477 to i32
  %xor72.36.8 = xor i32 %conv71.36.8, %conv68.36.8
  %conv73.36.8 = trunc i32 %xor72.36.8 to i8
  store i8 %conv73.36.8, i8* %arrayidx70.8, align 1
  %scevgep20.37.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 37
  %6478 = load i8, i8* %scevgep20.37.8, align 1
  %conv68.37.8 = zext i8 %6478 to i32
  %6479 = load i8, i8* %arrayidx70.8, align 1
  %conv71.37.8 = zext i8 %6479 to i32
  %xor72.37.8 = xor i32 %conv71.37.8, %conv68.37.8
  %conv73.37.8 = trunc i32 %xor72.37.8 to i8
  store i8 %conv73.37.8, i8* %arrayidx70.8, align 1
  %scevgep20.38.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 38
  %6480 = load i8, i8* %scevgep20.38.8, align 1
  %conv68.38.8 = zext i8 %6480 to i32
  %6481 = load i8, i8* %arrayidx70.8, align 1
  %conv71.38.8 = zext i8 %6481 to i32
  %xor72.38.8 = xor i32 %conv71.38.8, %conv68.38.8
  %conv73.38.8 = trunc i32 %xor72.38.8 to i8
  store i8 %conv73.38.8, i8* %arrayidx70.8, align 1
  %scevgep20.39.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 39
  %6482 = load i8, i8* %scevgep20.39.8, align 1
  %conv68.39.8 = zext i8 %6482 to i32
  %6483 = load i8, i8* %arrayidx70.8, align 1
  %conv71.39.8 = zext i8 %6483 to i32
  %xor72.39.8 = xor i32 %conv71.39.8, %conv68.39.8
  %conv73.39.8 = trunc i32 %xor72.39.8 to i8
  store i8 %conv73.39.8, i8* %arrayidx70.8, align 1
  %scevgep20.40.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 0, i64 40
  %6484 = load i8, i8* %scevgep20.40.8, align 1
  %conv68.40.8 = zext i8 %6484 to i32
  %6485 = load i8, i8* %arrayidx70.8, align 1
  %conv71.40.8 = zext i8 %6485 to i32
  %xor72.40.8 = xor i32 %conv71.40.8, %conv68.40.8
  %conv73.40.8 = trunc i32 %xor72.40.8 to i8
  store i8 %conv73.40.8, i8* %arrayidx70.8, align 1
  %scevgep19.8 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6403, i64 0, i64 1, i64 0
  %6486 = bitcast i8* %scevgep19.8 to [41 x [41 x i8]]*
  %arrayidx51.9 = getelementptr inbounds i8, i8* %a, i64 9
  %6487 = load i8, i8* %arrayidx51.9, align 1
  %arrayidx53.9 = getelementptr inbounds i8, i8* %b, i64 9
  %6488 = load i8, i8* %arrayidx53.9, align 1
  %call54.9 = call zeroext i8 @mult(i8 zeroext %6487, i8 zeroext %6488)
  %arrayidx56.9 = getelementptr inbounds i8, i8* %c, i64 9
  store i8 %call54.9, i8* %arrayidx56.9, align 1
  %arrayidx70.9 = getelementptr inbounds i8, i8* %c, i64 9
  %scevgep20.9134 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 0
  %6489 = load i8, i8* %scevgep20.9134, align 1
  %conv68.9135 = zext i8 %6489 to i32
  %6490 = load i8, i8* %arrayidx70.9, align 1
  %conv71.9136 = zext i8 %6490 to i32
  %xor72.9137 = xor i32 %conv71.9136, %conv68.9135
  %conv73.9138 = trunc i32 %xor72.9137 to i8
  store i8 %conv73.9138, i8* %arrayidx70.9, align 1
  %scevgep20.1.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 1
  %6491 = load i8, i8* %scevgep20.1.9, align 1
  %conv68.1.9 = zext i8 %6491 to i32
  %6492 = load i8, i8* %arrayidx70.9, align 1
  %conv71.1.9 = zext i8 %6492 to i32
  %xor72.1.9 = xor i32 %conv71.1.9, %conv68.1.9
  %conv73.1.9 = trunc i32 %xor72.1.9 to i8
  store i8 %conv73.1.9, i8* %arrayidx70.9, align 1
  %scevgep20.2.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 2
  %6493 = load i8, i8* %scevgep20.2.9, align 1
  %conv68.2.9 = zext i8 %6493 to i32
  %6494 = load i8, i8* %arrayidx70.9, align 1
  %conv71.2.9 = zext i8 %6494 to i32
  %xor72.2.9 = xor i32 %conv71.2.9, %conv68.2.9
  %conv73.2.9 = trunc i32 %xor72.2.9 to i8
  store i8 %conv73.2.9, i8* %arrayidx70.9, align 1
  %scevgep20.3.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 3
  %6495 = load i8, i8* %scevgep20.3.9, align 1
  %conv68.3.9 = zext i8 %6495 to i32
  %6496 = load i8, i8* %arrayidx70.9, align 1
  %conv71.3.9 = zext i8 %6496 to i32
  %xor72.3.9 = xor i32 %conv71.3.9, %conv68.3.9
  %conv73.3.9 = trunc i32 %xor72.3.9 to i8
  store i8 %conv73.3.9, i8* %arrayidx70.9, align 1
  %scevgep20.4.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 4
  %6497 = load i8, i8* %scevgep20.4.9, align 1
  %conv68.4.9 = zext i8 %6497 to i32
  %6498 = load i8, i8* %arrayidx70.9, align 1
  %conv71.4.9 = zext i8 %6498 to i32
  %xor72.4.9 = xor i32 %conv71.4.9, %conv68.4.9
  %conv73.4.9 = trunc i32 %xor72.4.9 to i8
  store i8 %conv73.4.9, i8* %arrayidx70.9, align 1
  %scevgep20.5.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 5
  %6499 = load i8, i8* %scevgep20.5.9, align 1
  %conv68.5.9 = zext i8 %6499 to i32
  %6500 = load i8, i8* %arrayidx70.9, align 1
  %conv71.5.9 = zext i8 %6500 to i32
  %xor72.5.9 = xor i32 %conv71.5.9, %conv68.5.9
  %conv73.5.9 = trunc i32 %xor72.5.9 to i8
  store i8 %conv73.5.9, i8* %arrayidx70.9, align 1
  %scevgep20.6.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 6
  %6501 = load i8, i8* %scevgep20.6.9, align 1
  %conv68.6.9 = zext i8 %6501 to i32
  %6502 = load i8, i8* %arrayidx70.9, align 1
  %conv71.6.9 = zext i8 %6502 to i32
  %xor72.6.9 = xor i32 %conv71.6.9, %conv68.6.9
  %conv73.6.9 = trunc i32 %xor72.6.9 to i8
  store i8 %conv73.6.9, i8* %arrayidx70.9, align 1
  %scevgep20.7.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 7
  %6503 = load i8, i8* %scevgep20.7.9, align 1
  %conv68.7.9 = zext i8 %6503 to i32
  %6504 = load i8, i8* %arrayidx70.9, align 1
  %conv71.7.9 = zext i8 %6504 to i32
  %xor72.7.9 = xor i32 %conv71.7.9, %conv68.7.9
  %conv73.7.9 = trunc i32 %xor72.7.9 to i8
  store i8 %conv73.7.9, i8* %arrayidx70.9, align 1
  %scevgep20.8.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 8
  %6505 = load i8, i8* %scevgep20.8.9, align 1
  %conv68.8.9 = zext i8 %6505 to i32
  %6506 = load i8, i8* %arrayidx70.9, align 1
  %conv71.8.9 = zext i8 %6506 to i32
  %xor72.8.9 = xor i32 %conv71.8.9, %conv68.8.9
  %conv73.8.9 = trunc i32 %xor72.8.9 to i8
  store i8 %conv73.8.9, i8* %arrayidx70.9, align 1
  %scevgep20.10.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 10
  %6507 = load i8, i8* %scevgep20.10.9, align 1
  %conv68.10.9 = zext i8 %6507 to i32
  %6508 = load i8, i8* %arrayidx70.9, align 1
  %conv71.10.9 = zext i8 %6508 to i32
  %xor72.10.9 = xor i32 %conv71.10.9, %conv68.10.9
  %conv73.10.9 = trunc i32 %xor72.10.9 to i8
  store i8 %conv73.10.9, i8* %arrayidx70.9, align 1
  %scevgep20.11.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 11
  %6509 = load i8, i8* %scevgep20.11.9, align 1
  %conv68.11.9 = zext i8 %6509 to i32
  %6510 = load i8, i8* %arrayidx70.9, align 1
  %conv71.11.9 = zext i8 %6510 to i32
  %xor72.11.9 = xor i32 %conv71.11.9, %conv68.11.9
  %conv73.11.9 = trunc i32 %xor72.11.9 to i8
  store i8 %conv73.11.9, i8* %arrayidx70.9, align 1
  %scevgep20.12.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 12
  %6511 = load i8, i8* %scevgep20.12.9, align 1
  %conv68.12.9 = zext i8 %6511 to i32
  %6512 = load i8, i8* %arrayidx70.9, align 1
  %conv71.12.9 = zext i8 %6512 to i32
  %xor72.12.9 = xor i32 %conv71.12.9, %conv68.12.9
  %conv73.12.9 = trunc i32 %xor72.12.9 to i8
  store i8 %conv73.12.9, i8* %arrayidx70.9, align 1
  %scevgep20.13.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 13
  %6513 = load i8, i8* %scevgep20.13.9, align 1
  %conv68.13.9 = zext i8 %6513 to i32
  %6514 = load i8, i8* %arrayidx70.9, align 1
  %conv71.13.9 = zext i8 %6514 to i32
  %xor72.13.9 = xor i32 %conv71.13.9, %conv68.13.9
  %conv73.13.9 = trunc i32 %xor72.13.9 to i8
  store i8 %conv73.13.9, i8* %arrayidx70.9, align 1
  %scevgep20.14.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 14
  %6515 = load i8, i8* %scevgep20.14.9, align 1
  %conv68.14.9 = zext i8 %6515 to i32
  %6516 = load i8, i8* %arrayidx70.9, align 1
  %conv71.14.9 = zext i8 %6516 to i32
  %xor72.14.9 = xor i32 %conv71.14.9, %conv68.14.9
  %conv73.14.9 = trunc i32 %xor72.14.9 to i8
  store i8 %conv73.14.9, i8* %arrayidx70.9, align 1
  %scevgep20.15.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 15
  %6517 = load i8, i8* %scevgep20.15.9, align 1
  %conv68.15.9 = zext i8 %6517 to i32
  %6518 = load i8, i8* %arrayidx70.9, align 1
  %conv71.15.9 = zext i8 %6518 to i32
  %xor72.15.9 = xor i32 %conv71.15.9, %conv68.15.9
  %conv73.15.9 = trunc i32 %xor72.15.9 to i8
  store i8 %conv73.15.9, i8* %arrayidx70.9, align 1
  %scevgep20.16.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 16
  %6519 = load i8, i8* %scevgep20.16.9, align 1
  %conv68.16.9 = zext i8 %6519 to i32
  %6520 = load i8, i8* %arrayidx70.9, align 1
  %conv71.16.9 = zext i8 %6520 to i32
  %xor72.16.9 = xor i32 %conv71.16.9, %conv68.16.9
  %conv73.16.9 = trunc i32 %xor72.16.9 to i8
  store i8 %conv73.16.9, i8* %arrayidx70.9, align 1
  %scevgep20.17.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 17
  %6521 = load i8, i8* %scevgep20.17.9, align 1
  %conv68.17.9 = zext i8 %6521 to i32
  %6522 = load i8, i8* %arrayidx70.9, align 1
  %conv71.17.9 = zext i8 %6522 to i32
  %xor72.17.9 = xor i32 %conv71.17.9, %conv68.17.9
  %conv73.17.9 = trunc i32 %xor72.17.9 to i8
  store i8 %conv73.17.9, i8* %arrayidx70.9, align 1
  %scevgep20.18.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 18
  %6523 = load i8, i8* %scevgep20.18.9, align 1
  %conv68.18.9 = zext i8 %6523 to i32
  %6524 = load i8, i8* %arrayidx70.9, align 1
  %conv71.18.9 = zext i8 %6524 to i32
  %xor72.18.9 = xor i32 %conv71.18.9, %conv68.18.9
  %conv73.18.9 = trunc i32 %xor72.18.9 to i8
  store i8 %conv73.18.9, i8* %arrayidx70.9, align 1
  %scevgep20.19.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 19
  %6525 = load i8, i8* %scevgep20.19.9, align 1
  %conv68.19.9 = zext i8 %6525 to i32
  %6526 = load i8, i8* %arrayidx70.9, align 1
  %conv71.19.9 = zext i8 %6526 to i32
  %xor72.19.9 = xor i32 %conv71.19.9, %conv68.19.9
  %conv73.19.9 = trunc i32 %xor72.19.9 to i8
  store i8 %conv73.19.9, i8* %arrayidx70.9, align 1
  %scevgep20.20.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 20
  %6527 = load i8, i8* %scevgep20.20.9, align 1
  %conv68.20.9 = zext i8 %6527 to i32
  %6528 = load i8, i8* %arrayidx70.9, align 1
  %conv71.20.9 = zext i8 %6528 to i32
  %xor72.20.9 = xor i32 %conv71.20.9, %conv68.20.9
  %conv73.20.9 = trunc i32 %xor72.20.9 to i8
  store i8 %conv73.20.9, i8* %arrayidx70.9, align 1
  %scevgep20.21.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 21
  %6529 = load i8, i8* %scevgep20.21.9, align 1
  %conv68.21.9 = zext i8 %6529 to i32
  %6530 = load i8, i8* %arrayidx70.9, align 1
  %conv71.21.9 = zext i8 %6530 to i32
  %xor72.21.9 = xor i32 %conv71.21.9, %conv68.21.9
  %conv73.21.9 = trunc i32 %xor72.21.9 to i8
  store i8 %conv73.21.9, i8* %arrayidx70.9, align 1
  %scevgep20.22.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 22
  %6531 = load i8, i8* %scevgep20.22.9, align 1
  %conv68.22.9 = zext i8 %6531 to i32
  %6532 = load i8, i8* %arrayidx70.9, align 1
  %conv71.22.9 = zext i8 %6532 to i32
  %xor72.22.9 = xor i32 %conv71.22.9, %conv68.22.9
  %conv73.22.9 = trunc i32 %xor72.22.9 to i8
  store i8 %conv73.22.9, i8* %arrayidx70.9, align 1
  %scevgep20.23.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 23
  %6533 = load i8, i8* %scevgep20.23.9, align 1
  %conv68.23.9 = zext i8 %6533 to i32
  %6534 = load i8, i8* %arrayidx70.9, align 1
  %conv71.23.9 = zext i8 %6534 to i32
  %xor72.23.9 = xor i32 %conv71.23.9, %conv68.23.9
  %conv73.23.9 = trunc i32 %xor72.23.9 to i8
  store i8 %conv73.23.9, i8* %arrayidx70.9, align 1
  %scevgep20.24.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 24
  %6535 = load i8, i8* %scevgep20.24.9, align 1
  %conv68.24.9 = zext i8 %6535 to i32
  %6536 = load i8, i8* %arrayidx70.9, align 1
  %conv71.24.9 = zext i8 %6536 to i32
  %xor72.24.9 = xor i32 %conv71.24.9, %conv68.24.9
  %conv73.24.9 = trunc i32 %xor72.24.9 to i8
  store i8 %conv73.24.9, i8* %arrayidx70.9, align 1
  %scevgep20.25.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 25
  %6537 = load i8, i8* %scevgep20.25.9, align 1
  %conv68.25.9 = zext i8 %6537 to i32
  %6538 = load i8, i8* %arrayidx70.9, align 1
  %conv71.25.9 = zext i8 %6538 to i32
  %xor72.25.9 = xor i32 %conv71.25.9, %conv68.25.9
  %conv73.25.9 = trunc i32 %xor72.25.9 to i8
  store i8 %conv73.25.9, i8* %arrayidx70.9, align 1
  %scevgep20.26.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 26
  %6539 = load i8, i8* %scevgep20.26.9, align 1
  %conv68.26.9 = zext i8 %6539 to i32
  %6540 = load i8, i8* %arrayidx70.9, align 1
  %conv71.26.9 = zext i8 %6540 to i32
  %xor72.26.9 = xor i32 %conv71.26.9, %conv68.26.9
  %conv73.26.9 = trunc i32 %xor72.26.9 to i8
  store i8 %conv73.26.9, i8* %arrayidx70.9, align 1
  %scevgep20.27.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 27
  %6541 = load i8, i8* %scevgep20.27.9, align 1
  %conv68.27.9 = zext i8 %6541 to i32
  %6542 = load i8, i8* %arrayidx70.9, align 1
  %conv71.27.9 = zext i8 %6542 to i32
  %xor72.27.9 = xor i32 %conv71.27.9, %conv68.27.9
  %conv73.27.9 = trunc i32 %xor72.27.9 to i8
  store i8 %conv73.27.9, i8* %arrayidx70.9, align 1
  %scevgep20.28.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 28
  %6543 = load i8, i8* %scevgep20.28.9, align 1
  %conv68.28.9 = zext i8 %6543 to i32
  %6544 = load i8, i8* %arrayidx70.9, align 1
  %conv71.28.9 = zext i8 %6544 to i32
  %xor72.28.9 = xor i32 %conv71.28.9, %conv68.28.9
  %conv73.28.9 = trunc i32 %xor72.28.9 to i8
  store i8 %conv73.28.9, i8* %arrayidx70.9, align 1
  %scevgep20.29.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 29
  %6545 = load i8, i8* %scevgep20.29.9, align 1
  %conv68.29.9 = zext i8 %6545 to i32
  %6546 = load i8, i8* %arrayidx70.9, align 1
  %conv71.29.9 = zext i8 %6546 to i32
  %xor72.29.9 = xor i32 %conv71.29.9, %conv68.29.9
  %conv73.29.9 = trunc i32 %xor72.29.9 to i8
  store i8 %conv73.29.9, i8* %arrayidx70.9, align 1
  %scevgep20.30.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 30
  %6547 = load i8, i8* %scevgep20.30.9, align 1
  %conv68.30.9 = zext i8 %6547 to i32
  %6548 = load i8, i8* %arrayidx70.9, align 1
  %conv71.30.9 = zext i8 %6548 to i32
  %xor72.30.9 = xor i32 %conv71.30.9, %conv68.30.9
  %conv73.30.9 = trunc i32 %xor72.30.9 to i8
  store i8 %conv73.30.9, i8* %arrayidx70.9, align 1
  %scevgep20.31.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 31
  %6549 = load i8, i8* %scevgep20.31.9, align 1
  %conv68.31.9 = zext i8 %6549 to i32
  %6550 = load i8, i8* %arrayidx70.9, align 1
  %conv71.31.9 = zext i8 %6550 to i32
  %xor72.31.9 = xor i32 %conv71.31.9, %conv68.31.9
  %conv73.31.9 = trunc i32 %xor72.31.9 to i8
  store i8 %conv73.31.9, i8* %arrayidx70.9, align 1
  %scevgep20.32.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 32
  %6551 = load i8, i8* %scevgep20.32.9, align 1
  %conv68.32.9 = zext i8 %6551 to i32
  %6552 = load i8, i8* %arrayidx70.9, align 1
  %conv71.32.9 = zext i8 %6552 to i32
  %xor72.32.9 = xor i32 %conv71.32.9, %conv68.32.9
  %conv73.32.9 = trunc i32 %xor72.32.9 to i8
  store i8 %conv73.32.9, i8* %arrayidx70.9, align 1
  %scevgep20.33.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 33
  %6553 = load i8, i8* %scevgep20.33.9, align 1
  %conv68.33.9 = zext i8 %6553 to i32
  %6554 = load i8, i8* %arrayidx70.9, align 1
  %conv71.33.9 = zext i8 %6554 to i32
  %xor72.33.9 = xor i32 %conv71.33.9, %conv68.33.9
  %conv73.33.9 = trunc i32 %xor72.33.9 to i8
  store i8 %conv73.33.9, i8* %arrayidx70.9, align 1
  %scevgep20.34.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 34
  %6555 = load i8, i8* %scevgep20.34.9, align 1
  %conv68.34.9 = zext i8 %6555 to i32
  %6556 = load i8, i8* %arrayidx70.9, align 1
  %conv71.34.9 = zext i8 %6556 to i32
  %xor72.34.9 = xor i32 %conv71.34.9, %conv68.34.9
  %conv73.34.9 = trunc i32 %xor72.34.9 to i8
  store i8 %conv73.34.9, i8* %arrayidx70.9, align 1
  %scevgep20.35.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 35
  %6557 = load i8, i8* %scevgep20.35.9, align 1
  %conv68.35.9 = zext i8 %6557 to i32
  %6558 = load i8, i8* %arrayidx70.9, align 1
  %conv71.35.9 = zext i8 %6558 to i32
  %xor72.35.9 = xor i32 %conv71.35.9, %conv68.35.9
  %conv73.35.9 = trunc i32 %xor72.35.9 to i8
  store i8 %conv73.35.9, i8* %arrayidx70.9, align 1
  %scevgep20.36.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 36
  %6559 = load i8, i8* %scevgep20.36.9, align 1
  %conv68.36.9 = zext i8 %6559 to i32
  %6560 = load i8, i8* %arrayidx70.9, align 1
  %conv71.36.9 = zext i8 %6560 to i32
  %xor72.36.9 = xor i32 %conv71.36.9, %conv68.36.9
  %conv73.36.9 = trunc i32 %xor72.36.9 to i8
  store i8 %conv73.36.9, i8* %arrayidx70.9, align 1
  %scevgep20.37.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 37
  %6561 = load i8, i8* %scevgep20.37.9, align 1
  %conv68.37.9 = zext i8 %6561 to i32
  %6562 = load i8, i8* %arrayidx70.9, align 1
  %conv71.37.9 = zext i8 %6562 to i32
  %xor72.37.9 = xor i32 %conv71.37.9, %conv68.37.9
  %conv73.37.9 = trunc i32 %xor72.37.9 to i8
  store i8 %conv73.37.9, i8* %arrayidx70.9, align 1
  %scevgep20.38.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 38
  %6563 = load i8, i8* %scevgep20.38.9, align 1
  %conv68.38.9 = zext i8 %6563 to i32
  %6564 = load i8, i8* %arrayidx70.9, align 1
  %conv71.38.9 = zext i8 %6564 to i32
  %xor72.38.9 = xor i32 %conv71.38.9, %conv68.38.9
  %conv73.38.9 = trunc i32 %xor72.38.9 to i8
  store i8 %conv73.38.9, i8* %arrayidx70.9, align 1
  %scevgep20.39.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 39
  %6565 = load i8, i8* %scevgep20.39.9, align 1
  %conv68.39.9 = zext i8 %6565 to i32
  %6566 = load i8, i8* %arrayidx70.9, align 1
  %conv71.39.9 = zext i8 %6566 to i32
  %xor72.39.9 = xor i32 %conv71.39.9, %conv68.39.9
  %conv73.39.9 = trunc i32 %xor72.39.9 to i8
  store i8 %conv73.39.9, i8* %arrayidx70.9, align 1
  %scevgep20.40.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 0, i64 40
  %6567 = load i8, i8* %scevgep20.40.9, align 1
  %conv68.40.9 = zext i8 %6567 to i32
  %6568 = load i8, i8* %arrayidx70.9, align 1
  %conv71.40.9 = zext i8 %6568 to i32
  %xor72.40.9 = xor i32 %conv71.40.9, %conv68.40.9
  %conv73.40.9 = trunc i32 %xor72.40.9 to i8
  store i8 %conv73.40.9, i8* %arrayidx70.9, align 1
  %scevgep19.9 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6486, i64 0, i64 1, i64 0
  %6569 = bitcast i8* %scevgep19.9 to [41 x [41 x i8]]*
  %arrayidx51.10 = getelementptr inbounds i8, i8* %a, i64 10
  %6570 = load i8, i8* %arrayidx51.10, align 1
  %arrayidx53.10 = getelementptr inbounds i8, i8* %b, i64 10
  %6571 = load i8, i8* %arrayidx53.10, align 1
  %call54.10 = call zeroext i8 @mult(i8 zeroext %6570, i8 zeroext %6571)
  %arrayidx56.10 = getelementptr inbounds i8, i8* %c, i64 10
  store i8 %call54.10, i8* %arrayidx56.10, align 1
  %arrayidx70.10 = getelementptr inbounds i8, i8* %c, i64 10
  %scevgep20.10144 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 0
  %6572 = load i8, i8* %scevgep20.10144, align 1
  %conv68.10145 = zext i8 %6572 to i32
  %6573 = load i8, i8* %arrayidx70.10, align 1
  %conv71.10146 = zext i8 %6573 to i32
  %xor72.10147 = xor i32 %conv71.10146, %conv68.10145
  %conv73.10148 = trunc i32 %xor72.10147 to i8
  store i8 %conv73.10148, i8* %arrayidx70.10, align 1
  %scevgep20.1.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 1
  %6574 = load i8, i8* %scevgep20.1.10, align 1
  %conv68.1.10 = zext i8 %6574 to i32
  %6575 = load i8, i8* %arrayidx70.10, align 1
  %conv71.1.10 = zext i8 %6575 to i32
  %xor72.1.10 = xor i32 %conv71.1.10, %conv68.1.10
  %conv73.1.10 = trunc i32 %xor72.1.10 to i8
  store i8 %conv73.1.10, i8* %arrayidx70.10, align 1
  %scevgep20.2.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 2
  %6576 = load i8, i8* %scevgep20.2.10, align 1
  %conv68.2.10 = zext i8 %6576 to i32
  %6577 = load i8, i8* %arrayidx70.10, align 1
  %conv71.2.10 = zext i8 %6577 to i32
  %xor72.2.10 = xor i32 %conv71.2.10, %conv68.2.10
  %conv73.2.10 = trunc i32 %xor72.2.10 to i8
  store i8 %conv73.2.10, i8* %arrayidx70.10, align 1
  %scevgep20.3.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 3
  %6578 = load i8, i8* %scevgep20.3.10, align 1
  %conv68.3.10 = zext i8 %6578 to i32
  %6579 = load i8, i8* %arrayidx70.10, align 1
  %conv71.3.10 = zext i8 %6579 to i32
  %xor72.3.10 = xor i32 %conv71.3.10, %conv68.3.10
  %conv73.3.10 = trunc i32 %xor72.3.10 to i8
  store i8 %conv73.3.10, i8* %arrayidx70.10, align 1
  %scevgep20.4.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 4
  %6580 = load i8, i8* %scevgep20.4.10, align 1
  %conv68.4.10 = zext i8 %6580 to i32
  %6581 = load i8, i8* %arrayidx70.10, align 1
  %conv71.4.10 = zext i8 %6581 to i32
  %xor72.4.10 = xor i32 %conv71.4.10, %conv68.4.10
  %conv73.4.10 = trunc i32 %xor72.4.10 to i8
  store i8 %conv73.4.10, i8* %arrayidx70.10, align 1
  %scevgep20.5.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 5
  %6582 = load i8, i8* %scevgep20.5.10, align 1
  %conv68.5.10 = zext i8 %6582 to i32
  %6583 = load i8, i8* %arrayidx70.10, align 1
  %conv71.5.10 = zext i8 %6583 to i32
  %xor72.5.10 = xor i32 %conv71.5.10, %conv68.5.10
  %conv73.5.10 = trunc i32 %xor72.5.10 to i8
  store i8 %conv73.5.10, i8* %arrayidx70.10, align 1
  %scevgep20.6.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 6
  %6584 = load i8, i8* %scevgep20.6.10, align 1
  %conv68.6.10 = zext i8 %6584 to i32
  %6585 = load i8, i8* %arrayidx70.10, align 1
  %conv71.6.10 = zext i8 %6585 to i32
  %xor72.6.10 = xor i32 %conv71.6.10, %conv68.6.10
  %conv73.6.10 = trunc i32 %xor72.6.10 to i8
  store i8 %conv73.6.10, i8* %arrayidx70.10, align 1
  %scevgep20.7.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 7
  %6586 = load i8, i8* %scevgep20.7.10, align 1
  %conv68.7.10 = zext i8 %6586 to i32
  %6587 = load i8, i8* %arrayidx70.10, align 1
  %conv71.7.10 = zext i8 %6587 to i32
  %xor72.7.10 = xor i32 %conv71.7.10, %conv68.7.10
  %conv73.7.10 = trunc i32 %xor72.7.10 to i8
  store i8 %conv73.7.10, i8* %arrayidx70.10, align 1
  %scevgep20.8.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 8
  %6588 = load i8, i8* %scevgep20.8.10, align 1
  %conv68.8.10 = zext i8 %6588 to i32
  %6589 = load i8, i8* %arrayidx70.10, align 1
  %conv71.8.10 = zext i8 %6589 to i32
  %xor72.8.10 = xor i32 %conv71.8.10, %conv68.8.10
  %conv73.8.10 = trunc i32 %xor72.8.10 to i8
  store i8 %conv73.8.10, i8* %arrayidx70.10, align 1
  %scevgep20.9.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 9
  %6590 = load i8, i8* %scevgep20.9.10, align 1
  %conv68.9.10 = zext i8 %6590 to i32
  %6591 = load i8, i8* %arrayidx70.10, align 1
  %conv71.9.10 = zext i8 %6591 to i32
  %xor72.9.10 = xor i32 %conv71.9.10, %conv68.9.10
  %conv73.9.10 = trunc i32 %xor72.9.10 to i8
  store i8 %conv73.9.10, i8* %arrayidx70.10, align 1
  %scevgep20.11.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 11
  %6592 = load i8, i8* %scevgep20.11.10, align 1
  %conv68.11.10 = zext i8 %6592 to i32
  %6593 = load i8, i8* %arrayidx70.10, align 1
  %conv71.11.10 = zext i8 %6593 to i32
  %xor72.11.10 = xor i32 %conv71.11.10, %conv68.11.10
  %conv73.11.10 = trunc i32 %xor72.11.10 to i8
  store i8 %conv73.11.10, i8* %arrayidx70.10, align 1
  %scevgep20.12.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 12
  %6594 = load i8, i8* %scevgep20.12.10, align 1
  %conv68.12.10 = zext i8 %6594 to i32
  %6595 = load i8, i8* %arrayidx70.10, align 1
  %conv71.12.10 = zext i8 %6595 to i32
  %xor72.12.10 = xor i32 %conv71.12.10, %conv68.12.10
  %conv73.12.10 = trunc i32 %xor72.12.10 to i8
  store i8 %conv73.12.10, i8* %arrayidx70.10, align 1
  %scevgep20.13.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 13
  %6596 = load i8, i8* %scevgep20.13.10, align 1
  %conv68.13.10 = zext i8 %6596 to i32
  %6597 = load i8, i8* %arrayidx70.10, align 1
  %conv71.13.10 = zext i8 %6597 to i32
  %xor72.13.10 = xor i32 %conv71.13.10, %conv68.13.10
  %conv73.13.10 = trunc i32 %xor72.13.10 to i8
  store i8 %conv73.13.10, i8* %arrayidx70.10, align 1
  %scevgep20.14.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 14
  %6598 = load i8, i8* %scevgep20.14.10, align 1
  %conv68.14.10 = zext i8 %6598 to i32
  %6599 = load i8, i8* %arrayidx70.10, align 1
  %conv71.14.10 = zext i8 %6599 to i32
  %xor72.14.10 = xor i32 %conv71.14.10, %conv68.14.10
  %conv73.14.10 = trunc i32 %xor72.14.10 to i8
  store i8 %conv73.14.10, i8* %arrayidx70.10, align 1
  %scevgep20.15.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 15
  %6600 = load i8, i8* %scevgep20.15.10, align 1
  %conv68.15.10 = zext i8 %6600 to i32
  %6601 = load i8, i8* %arrayidx70.10, align 1
  %conv71.15.10 = zext i8 %6601 to i32
  %xor72.15.10 = xor i32 %conv71.15.10, %conv68.15.10
  %conv73.15.10 = trunc i32 %xor72.15.10 to i8
  store i8 %conv73.15.10, i8* %arrayidx70.10, align 1
  %scevgep20.16.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 16
  %6602 = load i8, i8* %scevgep20.16.10, align 1
  %conv68.16.10 = zext i8 %6602 to i32
  %6603 = load i8, i8* %arrayidx70.10, align 1
  %conv71.16.10 = zext i8 %6603 to i32
  %xor72.16.10 = xor i32 %conv71.16.10, %conv68.16.10
  %conv73.16.10 = trunc i32 %xor72.16.10 to i8
  store i8 %conv73.16.10, i8* %arrayidx70.10, align 1
  %scevgep20.17.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 17
  %6604 = load i8, i8* %scevgep20.17.10, align 1
  %conv68.17.10 = zext i8 %6604 to i32
  %6605 = load i8, i8* %arrayidx70.10, align 1
  %conv71.17.10 = zext i8 %6605 to i32
  %xor72.17.10 = xor i32 %conv71.17.10, %conv68.17.10
  %conv73.17.10 = trunc i32 %xor72.17.10 to i8
  store i8 %conv73.17.10, i8* %arrayidx70.10, align 1
  %scevgep20.18.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 18
  %6606 = load i8, i8* %scevgep20.18.10, align 1
  %conv68.18.10 = zext i8 %6606 to i32
  %6607 = load i8, i8* %arrayidx70.10, align 1
  %conv71.18.10 = zext i8 %6607 to i32
  %xor72.18.10 = xor i32 %conv71.18.10, %conv68.18.10
  %conv73.18.10 = trunc i32 %xor72.18.10 to i8
  store i8 %conv73.18.10, i8* %arrayidx70.10, align 1
  %scevgep20.19.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 19
  %6608 = load i8, i8* %scevgep20.19.10, align 1
  %conv68.19.10 = zext i8 %6608 to i32
  %6609 = load i8, i8* %arrayidx70.10, align 1
  %conv71.19.10 = zext i8 %6609 to i32
  %xor72.19.10 = xor i32 %conv71.19.10, %conv68.19.10
  %conv73.19.10 = trunc i32 %xor72.19.10 to i8
  store i8 %conv73.19.10, i8* %arrayidx70.10, align 1
  %scevgep20.20.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 20
  %6610 = load i8, i8* %scevgep20.20.10, align 1
  %conv68.20.10 = zext i8 %6610 to i32
  %6611 = load i8, i8* %arrayidx70.10, align 1
  %conv71.20.10 = zext i8 %6611 to i32
  %xor72.20.10 = xor i32 %conv71.20.10, %conv68.20.10
  %conv73.20.10 = trunc i32 %xor72.20.10 to i8
  store i8 %conv73.20.10, i8* %arrayidx70.10, align 1
  %scevgep20.21.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 21
  %6612 = load i8, i8* %scevgep20.21.10, align 1
  %conv68.21.10 = zext i8 %6612 to i32
  %6613 = load i8, i8* %arrayidx70.10, align 1
  %conv71.21.10 = zext i8 %6613 to i32
  %xor72.21.10 = xor i32 %conv71.21.10, %conv68.21.10
  %conv73.21.10 = trunc i32 %xor72.21.10 to i8
  store i8 %conv73.21.10, i8* %arrayidx70.10, align 1
  %scevgep20.22.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 22
  %6614 = load i8, i8* %scevgep20.22.10, align 1
  %conv68.22.10 = zext i8 %6614 to i32
  %6615 = load i8, i8* %arrayidx70.10, align 1
  %conv71.22.10 = zext i8 %6615 to i32
  %xor72.22.10 = xor i32 %conv71.22.10, %conv68.22.10
  %conv73.22.10 = trunc i32 %xor72.22.10 to i8
  store i8 %conv73.22.10, i8* %arrayidx70.10, align 1
  %scevgep20.23.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 23
  %6616 = load i8, i8* %scevgep20.23.10, align 1
  %conv68.23.10 = zext i8 %6616 to i32
  %6617 = load i8, i8* %arrayidx70.10, align 1
  %conv71.23.10 = zext i8 %6617 to i32
  %xor72.23.10 = xor i32 %conv71.23.10, %conv68.23.10
  %conv73.23.10 = trunc i32 %xor72.23.10 to i8
  store i8 %conv73.23.10, i8* %arrayidx70.10, align 1
  %scevgep20.24.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 24
  %6618 = load i8, i8* %scevgep20.24.10, align 1
  %conv68.24.10 = zext i8 %6618 to i32
  %6619 = load i8, i8* %arrayidx70.10, align 1
  %conv71.24.10 = zext i8 %6619 to i32
  %xor72.24.10 = xor i32 %conv71.24.10, %conv68.24.10
  %conv73.24.10 = trunc i32 %xor72.24.10 to i8
  store i8 %conv73.24.10, i8* %arrayidx70.10, align 1
  %scevgep20.25.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 25
  %6620 = load i8, i8* %scevgep20.25.10, align 1
  %conv68.25.10 = zext i8 %6620 to i32
  %6621 = load i8, i8* %arrayidx70.10, align 1
  %conv71.25.10 = zext i8 %6621 to i32
  %xor72.25.10 = xor i32 %conv71.25.10, %conv68.25.10
  %conv73.25.10 = trunc i32 %xor72.25.10 to i8
  store i8 %conv73.25.10, i8* %arrayidx70.10, align 1
  %scevgep20.26.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 26
  %6622 = load i8, i8* %scevgep20.26.10, align 1
  %conv68.26.10 = zext i8 %6622 to i32
  %6623 = load i8, i8* %arrayidx70.10, align 1
  %conv71.26.10 = zext i8 %6623 to i32
  %xor72.26.10 = xor i32 %conv71.26.10, %conv68.26.10
  %conv73.26.10 = trunc i32 %xor72.26.10 to i8
  store i8 %conv73.26.10, i8* %arrayidx70.10, align 1
  %scevgep20.27.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 27
  %6624 = load i8, i8* %scevgep20.27.10, align 1
  %conv68.27.10 = zext i8 %6624 to i32
  %6625 = load i8, i8* %arrayidx70.10, align 1
  %conv71.27.10 = zext i8 %6625 to i32
  %xor72.27.10 = xor i32 %conv71.27.10, %conv68.27.10
  %conv73.27.10 = trunc i32 %xor72.27.10 to i8
  store i8 %conv73.27.10, i8* %arrayidx70.10, align 1
  %scevgep20.28.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 28
  %6626 = load i8, i8* %scevgep20.28.10, align 1
  %conv68.28.10 = zext i8 %6626 to i32
  %6627 = load i8, i8* %arrayidx70.10, align 1
  %conv71.28.10 = zext i8 %6627 to i32
  %xor72.28.10 = xor i32 %conv71.28.10, %conv68.28.10
  %conv73.28.10 = trunc i32 %xor72.28.10 to i8
  store i8 %conv73.28.10, i8* %arrayidx70.10, align 1
  %scevgep20.29.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 29
  %6628 = load i8, i8* %scevgep20.29.10, align 1
  %conv68.29.10 = zext i8 %6628 to i32
  %6629 = load i8, i8* %arrayidx70.10, align 1
  %conv71.29.10 = zext i8 %6629 to i32
  %xor72.29.10 = xor i32 %conv71.29.10, %conv68.29.10
  %conv73.29.10 = trunc i32 %xor72.29.10 to i8
  store i8 %conv73.29.10, i8* %arrayidx70.10, align 1
  %scevgep20.30.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 30
  %6630 = load i8, i8* %scevgep20.30.10, align 1
  %conv68.30.10 = zext i8 %6630 to i32
  %6631 = load i8, i8* %arrayidx70.10, align 1
  %conv71.30.10 = zext i8 %6631 to i32
  %xor72.30.10 = xor i32 %conv71.30.10, %conv68.30.10
  %conv73.30.10 = trunc i32 %xor72.30.10 to i8
  store i8 %conv73.30.10, i8* %arrayidx70.10, align 1
  %scevgep20.31.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 31
  %6632 = load i8, i8* %scevgep20.31.10, align 1
  %conv68.31.10 = zext i8 %6632 to i32
  %6633 = load i8, i8* %arrayidx70.10, align 1
  %conv71.31.10 = zext i8 %6633 to i32
  %xor72.31.10 = xor i32 %conv71.31.10, %conv68.31.10
  %conv73.31.10 = trunc i32 %xor72.31.10 to i8
  store i8 %conv73.31.10, i8* %arrayidx70.10, align 1
  %scevgep20.32.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 32
  %6634 = load i8, i8* %scevgep20.32.10, align 1
  %conv68.32.10 = zext i8 %6634 to i32
  %6635 = load i8, i8* %arrayidx70.10, align 1
  %conv71.32.10 = zext i8 %6635 to i32
  %xor72.32.10 = xor i32 %conv71.32.10, %conv68.32.10
  %conv73.32.10 = trunc i32 %xor72.32.10 to i8
  store i8 %conv73.32.10, i8* %arrayidx70.10, align 1
  %scevgep20.33.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 33
  %6636 = load i8, i8* %scevgep20.33.10, align 1
  %conv68.33.10 = zext i8 %6636 to i32
  %6637 = load i8, i8* %arrayidx70.10, align 1
  %conv71.33.10 = zext i8 %6637 to i32
  %xor72.33.10 = xor i32 %conv71.33.10, %conv68.33.10
  %conv73.33.10 = trunc i32 %xor72.33.10 to i8
  store i8 %conv73.33.10, i8* %arrayidx70.10, align 1
  %scevgep20.34.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 34
  %6638 = load i8, i8* %scevgep20.34.10, align 1
  %conv68.34.10 = zext i8 %6638 to i32
  %6639 = load i8, i8* %arrayidx70.10, align 1
  %conv71.34.10 = zext i8 %6639 to i32
  %xor72.34.10 = xor i32 %conv71.34.10, %conv68.34.10
  %conv73.34.10 = trunc i32 %xor72.34.10 to i8
  store i8 %conv73.34.10, i8* %arrayidx70.10, align 1
  %scevgep20.35.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 35
  %6640 = load i8, i8* %scevgep20.35.10, align 1
  %conv68.35.10 = zext i8 %6640 to i32
  %6641 = load i8, i8* %arrayidx70.10, align 1
  %conv71.35.10 = zext i8 %6641 to i32
  %xor72.35.10 = xor i32 %conv71.35.10, %conv68.35.10
  %conv73.35.10 = trunc i32 %xor72.35.10 to i8
  store i8 %conv73.35.10, i8* %arrayidx70.10, align 1
  %scevgep20.36.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 36
  %6642 = load i8, i8* %scevgep20.36.10, align 1
  %conv68.36.10 = zext i8 %6642 to i32
  %6643 = load i8, i8* %arrayidx70.10, align 1
  %conv71.36.10 = zext i8 %6643 to i32
  %xor72.36.10 = xor i32 %conv71.36.10, %conv68.36.10
  %conv73.36.10 = trunc i32 %xor72.36.10 to i8
  store i8 %conv73.36.10, i8* %arrayidx70.10, align 1
  %scevgep20.37.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 37
  %6644 = load i8, i8* %scevgep20.37.10, align 1
  %conv68.37.10 = zext i8 %6644 to i32
  %6645 = load i8, i8* %arrayidx70.10, align 1
  %conv71.37.10 = zext i8 %6645 to i32
  %xor72.37.10 = xor i32 %conv71.37.10, %conv68.37.10
  %conv73.37.10 = trunc i32 %xor72.37.10 to i8
  store i8 %conv73.37.10, i8* %arrayidx70.10, align 1
  %scevgep20.38.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 38
  %6646 = load i8, i8* %scevgep20.38.10, align 1
  %conv68.38.10 = zext i8 %6646 to i32
  %6647 = load i8, i8* %arrayidx70.10, align 1
  %conv71.38.10 = zext i8 %6647 to i32
  %xor72.38.10 = xor i32 %conv71.38.10, %conv68.38.10
  %conv73.38.10 = trunc i32 %xor72.38.10 to i8
  store i8 %conv73.38.10, i8* %arrayidx70.10, align 1
  %scevgep20.39.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 39
  %6648 = load i8, i8* %scevgep20.39.10, align 1
  %conv68.39.10 = zext i8 %6648 to i32
  %6649 = load i8, i8* %arrayidx70.10, align 1
  %conv71.39.10 = zext i8 %6649 to i32
  %xor72.39.10 = xor i32 %conv71.39.10, %conv68.39.10
  %conv73.39.10 = trunc i32 %xor72.39.10 to i8
  store i8 %conv73.39.10, i8* %arrayidx70.10, align 1
  %scevgep20.40.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 0, i64 40
  %6650 = load i8, i8* %scevgep20.40.10, align 1
  %conv68.40.10 = zext i8 %6650 to i32
  %6651 = load i8, i8* %arrayidx70.10, align 1
  %conv71.40.10 = zext i8 %6651 to i32
  %xor72.40.10 = xor i32 %conv71.40.10, %conv68.40.10
  %conv73.40.10 = trunc i32 %xor72.40.10 to i8
  store i8 %conv73.40.10, i8* %arrayidx70.10, align 1
  %scevgep19.10 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6569, i64 0, i64 1, i64 0
  %6652 = bitcast i8* %scevgep19.10 to [41 x [41 x i8]]*
  %arrayidx51.11 = getelementptr inbounds i8, i8* %a, i64 11
  %6653 = load i8, i8* %arrayidx51.11, align 1
  %arrayidx53.11 = getelementptr inbounds i8, i8* %b, i64 11
  %6654 = load i8, i8* %arrayidx53.11, align 1
  %call54.11 = call zeroext i8 @mult(i8 zeroext %6653, i8 zeroext %6654)
  %arrayidx56.11 = getelementptr inbounds i8, i8* %c, i64 11
  store i8 %call54.11, i8* %arrayidx56.11, align 1
  %arrayidx70.11 = getelementptr inbounds i8, i8* %c, i64 11
  %scevgep20.11154 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 0
  %6655 = load i8, i8* %scevgep20.11154, align 1
  %conv68.11155 = zext i8 %6655 to i32
  %6656 = load i8, i8* %arrayidx70.11, align 1
  %conv71.11156 = zext i8 %6656 to i32
  %xor72.11157 = xor i32 %conv71.11156, %conv68.11155
  %conv73.11158 = trunc i32 %xor72.11157 to i8
  store i8 %conv73.11158, i8* %arrayidx70.11, align 1
  %scevgep20.1.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 1
  %6657 = load i8, i8* %scevgep20.1.11, align 1
  %conv68.1.11 = zext i8 %6657 to i32
  %6658 = load i8, i8* %arrayidx70.11, align 1
  %conv71.1.11 = zext i8 %6658 to i32
  %xor72.1.11 = xor i32 %conv71.1.11, %conv68.1.11
  %conv73.1.11 = trunc i32 %xor72.1.11 to i8
  store i8 %conv73.1.11, i8* %arrayidx70.11, align 1
  %scevgep20.2.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 2
  %6659 = load i8, i8* %scevgep20.2.11, align 1
  %conv68.2.11 = zext i8 %6659 to i32
  %6660 = load i8, i8* %arrayidx70.11, align 1
  %conv71.2.11 = zext i8 %6660 to i32
  %xor72.2.11 = xor i32 %conv71.2.11, %conv68.2.11
  %conv73.2.11 = trunc i32 %xor72.2.11 to i8
  store i8 %conv73.2.11, i8* %arrayidx70.11, align 1
  %scevgep20.3.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 3
  %6661 = load i8, i8* %scevgep20.3.11, align 1
  %conv68.3.11 = zext i8 %6661 to i32
  %6662 = load i8, i8* %arrayidx70.11, align 1
  %conv71.3.11 = zext i8 %6662 to i32
  %xor72.3.11 = xor i32 %conv71.3.11, %conv68.3.11
  %conv73.3.11 = trunc i32 %xor72.3.11 to i8
  store i8 %conv73.3.11, i8* %arrayidx70.11, align 1
  %scevgep20.4.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 4
  %6663 = load i8, i8* %scevgep20.4.11, align 1
  %conv68.4.11 = zext i8 %6663 to i32
  %6664 = load i8, i8* %arrayidx70.11, align 1
  %conv71.4.11 = zext i8 %6664 to i32
  %xor72.4.11 = xor i32 %conv71.4.11, %conv68.4.11
  %conv73.4.11 = trunc i32 %xor72.4.11 to i8
  store i8 %conv73.4.11, i8* %arrayidx70.11, align 1
  %scevgep20.5.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 5
  %6665 = load i8, i8* %scevgep20.5.11, align 1
  %conv68.5.11 = zext i8 %6665 to i32
  %6666 = load i8, i8* %arrayidx70.11, align 1
  %conv71.5.11 = zext i8 %6666 to i32
  %xor72.5.11 = xor i32 %conv71.5.11, %conv68.5.11
  %conv73.5.11 = trunc i32 %xor72.5.11 to i8
  store i8 %conv73.5.11, i8* %arrayidx70.11, align 1
  %scevgep20.6.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 6
  %6667 = load i8, i8* %scevgep20.6.11, align 1
  %conv68.6.11 = zext i8 %6667 to i32
  %6668 = load i8, i8* %arrayidx70.11, align 1
  %conv71.6.11 = zext i8 %6668 to i32
  %xor72.6.11 = xor i32 %conv71.6.11, %conv68.6.11
  %conv73.6.11 = trunc i32 %xor72.6.11 to i8
  store i8 %conv73.6.11, i8* %arrayidx70.11, align 1
  %scevgep20.7.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 7
  %6669 = load i8, i8* %scevgep20.7.11, align 1
  %conv68.7.11 = zext i8 %6669 to i32
  %6670 = load i8, i8* %arrayidx70.11, align 1
  %conv71.7.11 = zext i8 %6670 to i32
  %xor72.7.11 = xor i32 %conv71.7.11, %conv68.7.11
  %conv73.7.11 = trunc i32 %xor72.7.11 to i8
  store i8 %conv73.7.11, i8* %arrayidx70.11, align 1
  %scevgep20.8.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 8
  %6671 = load i8, i8* %scevgep20.8.11, align 1
  %conv68.8.11 = zext i8 %6671 to i32
  %6672 = load i8, i8* %arrayidx70.11, align 1
  %conv71.8.11 = zext i8 %6672 to i32
  %xor72.8.11 = xor i32 %conv71.8.11, %conv68.8.11
  %conv73.8.11 = trunc i32 %xor72.8.11 to i8
  store i8 %conv73.8.11, i8* %arrayidx70.11, align 1
  %scevgep20.9.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 9
  %6673 = load i8, i8* %scevgep20.9.11, align 1
  %conv68.9.11 = zext i8 %6673 to i32
  %6674 = load i8, i8* %arrayidx70.11, align 1
  %conv71.9.11 = zext i8 %6674 to i32
  %xor72.9.11 = xor i32 %conv71.9.11, %conv68.9.11
  %conv73.9.11 = trunc i32 %xor72.9.11 to i8
  store i8 %conv73.9.11, i8* %arrayidx70.11, align 1
  %scevgep20.10.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 10
  %6675 = load i8, i8* %scevgep20.10.11, align 1
  %conv68.10.11 = zext i8 %6675 to i32
  %6676 = load i8, i8* %arrayidx70.11, align 1
  %conv71.10.11 = zext i8 %6676 to i32
  %xor72.10.11 = xor i32 %conv71.10.11, %conv68.10.11
  %conv73.10.11 = trunc i32 %xor72.10.11 to i8
  store i8 %conv73.10.11, i8* %arrayidx70.11, align 1
  %scevgep20.12.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 12
  %6677 = load i8, i8* %scevgep20.12.11, align 1
  %conv68.12.11 = zext i8 %6677 to i32
  %6678 = load i8, i8* %arrayidx70.11, align 1
  %conv71.12.11 = zext i8 %6678 to i32
  %xor72.12.11 = xor i32 %conv71.12.11, %conv68.12.11
  %conv73.12.11 = trunc i32 %xor72.12.11 to i8
  store i8 %conv73.12.11, i8* %arrayidx70.11, align 1
  %scevgep20.13.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 13
  %6679 = load i8, i8* %scevgep20.13.11, align 1
  %conv68.13.11 = zext i8 %6679 to i32
  %6680 = load i8, i8* %arrayidx70.11, align 1
  %conv71.13.11 = zext i8 %6680 to i32
  %xor72.13.11 = xor i32 %conv71.13.11, %conv68.13.11
  %conv73.13.11 = trunc i32 %xor72.13.11 to i8
  store i8 %conv73.13.11, i8* %arrayidx70.11, align 1
  %scevgep20.14.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 14
  %6681 = load i8, i8* %scevgep20.14.11, align 1
  %conv68.14.11 = zext i8 %6681 to i32
  %6682 = load i8, i8* %arrayidx70.11, align 1
  %conv71.14.11 = zext i8 %6682 to i32
  %xor72.14.11 = xor i32 %conv71.14.11, %conv68.14.11
  %conv73.14.11 = trunc i32 %xor72.14.11 to i8
  store i8 %conv73.14.11, i8* %arrayidx70.11, align 1
  %scevgep20.15.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 15
  %6683 = load i8, i8* %scevgep20.15.11, align 1
  %conv68.15.11 = zext i8 %6683 to i32
  %6684 = load i8, i8* %arrayidx70.11, align 1
  %conv71.15.11 = zext i8 %6684 to i32
  %xor72.15.11 = xor i32 %conv71.15.11, %conv68.15.11
  %conv73.15.11 = trunc i32 %xor72.15.11 to i8
  store i8 %conv73.15.11, i8* %arrayidx70.11, align 1
  %scevgep20.16.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 16
  %6685 = load i8, i8* %scevgep20.16.11, align 1
  %conv68.16.11 = zext i8 %6685 to i32
  %6686 = load i8, i8* %arrayidx70.11, align 1
  %conv71.16.11 = zext i8 %6686 to i32
  %xor72.16.11 = xor i32 %conv71.16.11, %conv68.16.11
  %conv73.16.11 = trunc i32 %xor72.16.11 to i8
  store i8 %conv73.16.11, i8* %arrayidx70.11, align 1
  %scevgep20.17.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 17
  %6687 = load i8, i8* %scevgep20.17.11, align 1
  %conv68.17.11 = zext i8 %6687 to i32
  %6688 = load i8, i8* %arrayidx70.11, align 1
  %conv71.17.11 = zext i8 %6688 to i32
  %xor72.17.11 = xor i32 %conv71.17.11, %conv68.17.11
  %conv73.17.11 = trunc i32 %xor72.17.11 to i8
  store i8 %conv73.17.11, i8* %arrayidx70.11, align 1
  %scevgep20.18.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 18
  %6689 = load i8, i8* %scevgep20.18.11, align 1
  %conv68.18.11 = zext i8 %6689 to i32
  %6690 = load i8, i8* %arrayidx70.11, align 1
  %conv71.18.11 = zext i8 %6690 to i32
  %xor72.18.11 = xor i32 %conv71.18.11, %conv68.18.11
  %conv73.18.11 = trunc i32 %xor72.18.11 to i8
  store i8 %conv73.18.11, i8* %arrayidx70.11, align 1
  %scevgep20.19.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 19
  %6691 = load i8, i8* %scevgep20.19.11, align 1
  %conv68.19.11 = zext i8 %6691 to i32
  %6692 = load i8, i8* %arrayidx70.11, align 1
  %conv71.19.11 = zext i8 %6692 to i32
  %xor72.19.11 = xor i32 %conv71.19.11, %conv68.19.11
  %conv73.19.11 = trunc i32 %xor72.19.11 to i8
  store i8 %conv73.19.11, i8* %arrayidx70.11, align 1
  %scevgep20.20.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 20
  %6693 = load i8, i8* %scevgep20.20.11, align 1
  %conv68.20.11 = zext i8 %6693 to i32
  %6694 = load i8, i8* %arrayidx70.11, align 1
  %conv71.20.11 = zext i8 %6694 to i32
  %xor72.20.11 = xor i32 %conv71.20.11, %conv68.20.11
  %conv73.20.11 = trunc i32 %xor72.20.11 to i8
  store i8 %conv73.20.11, i8* %arrayidx70.11, align 1
  %scevgep20.21.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 21
  %6695 = load i8, i8* %scevgep20.21.11, align 1
  %conv68.21.11 = zext i8 %6695 to i32
  %6696 = load i8, i8* %arrayidx70.11, align 1
  %conv71.21.11 = zext i8 %6696 to i32
  %xor72.21.11 = xor i32 %conv71.21.11, %conv68.21.11
  %conv73.21.11 = trunc i32 %xor72.21.11 to i8
  store i8 %conv73.21.11, i8* %arrayidx70.11, align 1
  %scevgep20.22.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 22
  %6697 = load i8, i8* %scevgep20.22.11, align 1
  %conv68.22.11 = zext i8 %6697 to i32
  %6698 = load i8, i8* %arrayidx70.11, align 1
  %conv71.22.11 = zext i8 %6698 to i32
  %xor72.22.11 = xor i32 %conv71.22.11, %conv68.22.11
  %conv73.22.11 = trunc i32 %xor72.22.11 to i8
  store i8 %conv73.22.11, i8* %arrayidx70.11, align 1
  %scevgep20.23.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 23
  %6699 = load i8, i8* %scevgep20.23.11, align 1
  %conv68.23.11 = zext i8 %6699 to i32
  %6700 = load i8, i8* %arrayidx70.11, align 1
  %conv71.23.11 = zext i8 %6700 to i32
  %xor72.23.11 = xor i32 %conv71.23.11, %conv68.23.11
  %conv73.23.11 = trunc i32 %xor72.23.11 to i8
  store i8 %conv73.23.11, i8* %arrayidx70.11, align 1
  %scevgep20.24.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 24
  %6701 = load i8, i8* %scevgep20.24.11, align 1
  %conv68.24.11 = zext i8 %6701 to i32
  %6702 = load i8, i8* %arrayidx70.11, align 1
  %conv71.24.11 = zext i8 %6702 to i32
  %xor72.24.11 = xor i32 %conv71.24.11, %conv68.24.11
  %conv73.24.11 = trunc i32 %xor72.24.11 to i8
  store i8 %conv73.24.11, i8* %arrayidx70.11, align 1
  %scevgep20.25.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 25
  %6703 = load i8, i8* %scevgep20.25.11, align 1
  %conv68.25.11 = zext i8 %6703 to i32
  %6704 = load i8, i8* %arrayidx70.11, align 1
  %conv71.25.11 = zext i8 %6704 to i32
  %xor72.25.11 = xor i32 %conv71.25.11, %conv68.25.11
  %conv73.25.11 = trunc i32 %xor72.25.11 to i8
  store i8 %conv73.25.11, i8* %arrayidx70.11, align 1
  %scevgep20.26.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 26
  %6705 = load i8, i8* %scevgep20.26.11, align 1
  %conv68.26.11 = zext i8 %6705 to i32
  %6706 = load i8, i8* %arrayidx70.11, align 1
  %conv71.26.11 = zext i8 %6706 to i32
  %xor72.26.11 = xor i32 %conv71.26.11, %conv68.26.11
  %conv73.26.11 = trunc i32 %xor72.26.11 to i8
  store i8 %conv73.26.11, i8* %arrayidx70.11, align 1
  %scevgep20.27.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 27
  %6707 = load i8, i8* %scevgep20.27.11, align 1
  %conv68.27.11 = zext i8 %6707 to i32
  %6708 = load i8, i8* %arrayidx70.11, align 1
  %conv71.27.11 = zext i8 %6708 to i32
  %xor72.27.11 = xor i32 %conv71.27.11, %conv68.27.11
  %conv73.27.11 = trunc i32 %xor72.27.11 to i8
  store i8 %conv73.27.11, i8* %arrayidx70.11, align 1
  %scevgep20.28.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 28
  %6709 = load i8, i8* %scevgep20.28.11, align 1
  %conv68.28.11 = zext i8 %6709 to i32
  %6710 = load i8, i8* %arrayidx70.11, align 1
  %conv71.28.11 = zext i8 %6710 to i32
  %xor72.28.11 = xor i32 %conv71.28.11, %conv68.28.11
  %conv73.28.11 = trunc i32 %xor72.28.11 to i8
  store i8 %conv73.28.11, i8* %arrayidx70.11, align 1
  %scevgep20.29.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 29
  %6711 = load i8, i8* %scevgep20.29.11, align 1
  %conv68.29.11 = zext i8 %6711 to i32
  %6712 = load i8, i8* %arrayidx70.11, align 1
  %conv71.29.11 = zext i8 %6712 to i32
  %xor72.29.11 = xor i32 %conv71.29.11, %conv68.29.11
  %conv73.29.11 = trunc i32 %xor72.29.11 to i8
  store i8 %conv73.29.11, i8* %arrayidx70.11, align 1
  %scevgep20.30.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 30
  %6713 = load i8, i8* %scevgep20.30.11, align 1
  %conv68.30.11 = zext i8 %6713 to i32
  %6714 = load i8, i8* %arrayidx70.11, align 1
  %conv71.30.11 = zext i8 %6714 to i32
  %xor72.30.11 = xor i32 %conv71.30.11, %conv68.30.11
  %conv73.30.11 = trunc i32 %xor72.30.11 to i8
  store i8 %conv73.30.11, i8* %arrayidx70.11, align 1
  %scevgep20.31.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 31
  %6715 = load i8, i8* %scevgep20.31.11, align 1
  %conv68.31.11 = zext i8 %6715 to i32
  %6716 = load i8, i8* %arrayidx70.11, align 1
  %conv71.31.11 = zext i8 %6716 to i32
  %xor72.31.11 = xor i32 %conv71.31.11, %conv68.31.11
  %conv73.31.11 = trunc i32 %xor72.31.11 to i8
  store i8 %conv73.31.11, i8* %arrayidx70.11, align 1
  %scevgep20.32.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 32
  %6717 = load i8, i8* %scevgep20.32.11, align 1
  %conv68.32.11 = zext i8 %6717 to i32
  %6718 = load i8, i8* %arrayidx70.11, align 1
  %conv71.32.11 = zext i8 %6718 to i32
  %xor72.32.11 = xor i32 %conv71.32.11, %conv68.32.11
  %conv73.32.11 = trunc i32 %xor72.32.11 to i8
  store i8 %conv73.32.11, i8* %arrayidx70.11, align 1
  %scevgep20.33.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 33
  %6719 = load i8, i8* %scevgep20.33.11, align 1
  %conv68.33.11 = zext i8 %6719 to i32
  %6720 = load i8, i8* %arrayidx70.11, align 1
  %conv71.33.11 = zext i8 %6720 to i32
  %xor72.33.11 = xor i32 %conv71.33.11, %conv68.33.11
  %conv73.33.11 = trunc i32 %xor72.33.11 to i8
  store i8 %conv73.33.11, i8* %arrayidx70.11, align 1
  %scevgep20.34.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 34
  %6721 = load i8, i8* %scevgep20.34.11, align 1
  %conv68.34.11 = zext i8 %6721 to i32
  %6722 = load i8, i8* %arrayidx70.11, align 1
  %conv71.34.11 = zext i8 %6722 to i32
  %xor72.34.11 = xor i32 %conv71.34.11, %conv68.34.11
  %conv73.34.11 = trunc i32 %xor72.34.11 to i8
  store i8 %conv73.34.11, i8* %arrayidx70.11, align 1
  %scevgep20.35.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 35
  %6723 = load i8, i8* %scevgep20.35.11, align 1
  %conv68.35.11 = zext i8 %6723 to i32
  %6724 = load i8, i8* %arrayidx70.11, align 1
  %conv71.35.11 = zext i8 %6724 to i32
  %xor72.35.11 = xor i32 %conv71.35.11, %conv68.35.11
  %conv73.35.11 = trunc i32 %xor72.35.11 to i8
  store i8 %conv73.35.11, i8* %arrayidx70.11, align 1
  %scevgep20.36.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 36
  %6725 = load i8, i8* %scevgep20.36.11, align 1
  %conv68.36.11 = zext i8 %6725 to i32
  %6726 = load i8, i8* %arrayidx70.11, align 1
  %conv71.36.11 = zext i8 %6726 to i32
  %xor72.36.11 = xor i32 %conv71.36.11, %conv68.36.11
  %conv73.36.11 = trunc i32 %xor72.36.11 to i8
  store i8 %conv73.36.11, i8* %arrayidx70.11, align 1
  %scevgep20.37.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 37
  %6727 = load i8, i8* %scevgep20.37.11, align 1
  %conv68.37.11 = zext i8 %6727 to i32
  %6728 = load i8, i8* %arrayidx70.11, align 1
  %conv71.37.11 = zext i8 %6728 to i32
  %xor72.37.11 = xor i32 %conv71.37.11, %conv68.37.11
  %conv73.37.11 = trunc i32 %xor72.37.11 to i8
  store i8 %conv73.37.11, i8* %arrayidx70.11, align 1
  %scevgep20.38.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 38
  %6729 = load i8, i8* %scevgep20.38.11, align 1
  %conv68.38.11 = zext i8 %6729 to i32
  %6730 = load i8, i8* %arrayidx70.11, align 1
  %conv71.38.11 = zext i8 %6730 to i32
  %xor72.38.11 = xor i32 %conv71.38.11, %conv68.38.11
  %conv73.38.11 = trunc i32 %xor72.38.11 to i8
  store i8 %conv73.38.11, i8* %arrayidx70.11, align 1
  %scevgep20.39.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 39
  %6731 = load i8, i8* %scevgep20.39.11, align 1
  %conv68.39.11 = zext i8 %6731 to i32
  %6732 = load i8, i8* %arrayidx70.11, align 1
  %conv71.39.11 = zext i8 %6732 to i32
  %xor72.39.11 = xor i32 %conv71.39.11, %conv68.39.11
  %conv73.39.11 = trunc i32 %xor72.39.11 to i8
  store i8 %conv73.39.11, i8* %arrayidx70.11, align 1
  %scevgep20.40.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 0, i64 40
  %6733 = load i8, i8* %scevgep20.40.11, align 1
  %conv68.40.11 = zext i8 %6733 to i32
  %6734 = load i8, i8* %arrayidx70.11, align 1
  %conv71.40.11 = zext i8 %6734 to i32
  %xor72.40.11 = xor i32 %conv71.40.11, %conv68.40.11
  %conv73.40.11 = trunc i32 %xor72.40.11 to i8
  store i8 %conv73.40.11, i8* %arrayidx70.11, align 1
  %scevgep19.11 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6652, i64 0, i64 1, i64 0
  %6735 = bitcast i8* %scevgep19.11 to [41 x [41 x i8]]*
  %arrayidx51.12 = getelementptr inbounds i8, i8* %a, i64 12
  %6736 = load i8, i8* %arrayidx51.12, align 1
  %arrayidx53.12 = getelementptr inbounds i8, i8* %b, i64 12
  %6737 = load i8, i8* %arrayidx53.12, align 1
  %call54.12 = call zeroext i8 @mult(i8 zeroext %6736, i8 zeroext %6737)
  %arrayidx56.12 = getelementptr inbounds i8, i8* %c, i64 12
  store i8 %call54.12, i8* %arrayidx56.12, align 1
  %arrayidx70.12 = getelementptr inbounds i8, i8* %c, i64 12
  %scevgep20.12164 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 0
  %6738 = load i8, i8* %scevgep20.12164, align 1
  %conv68.12165 = zext i8 %6738 to i32
  %6739 = load i8, i8* %arrayidx70.12, align 1
  %conv71.12166 = zext i8 %6739 to i32
  %xor72.12167 = xor i32 %conv71.12166, %conv68.12165
  %conv73.12168 = trunc i32 %xor72.12167 to i8
  store i8 %conv73.12168, i8* %arrayidx70.12, align 1
  %scevgep20.1.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 1
  %6740 = load i8, i8* %scevgep20.1.12, align 1
  %conv68.1.12 = zext i8 %6740 to i32
  %6741 = load i8, i8* %arrayidx70.12, align 1
  %conv71.1.12 = zext i8 %6741 to i32
  %xor72.1.12 = xor i32 %conv71.1.12, %conv68.1.12
  %conv73.1.12 = trunc i32 %xor72.1.12 to i8
  store i8 %conv73.1.12, i8* %arrayidx70.12, align 1
  %scevgep20.2.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 2
  %6742 = load i8, i8* %scevgep20.2.12, align 1
  %conv68.2.12 = zext i8 %6742 to i32
  %6743 = load i8, i8* %arrayidx70.12, align 1
  %conv71.2.12 = zext i8 %6743 to i32
  %xor72.2.12 = xor i32 %conv71.2.12, %conv68.2.12
  %conv73.2.12 = trunc i32 %xor72.2.12 to i8
  store i8 %conv73.2.12, i8* %arrayidx70.12, align 1
  %scevgep20.3.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 3
  %6744 = load i8, i8* %scevgep20.3.12, align 1
  %conv68.3.12 = zext i8 %6744 to i32
  %6745 = load i8, i8* %arrayidx70.12, align 1
  %conv71.3.12 = zext i8 %6745 to i32
  %xor72.3.12 = xor i32 %conv71.3.12, %conv68.3.12
  %conv73.3.12 = trunc i32 %xor72.3.12 to i8
  store i8 %conv73.3.12, i8* %arrayidx70.12, align 1
  %scevgep20.4.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 4
  %6746 = load i8, i8* %scevgep20.4.12, align 1
  %conv68.4.12 = zext i8 %6746 to i32
  %6747 = load i8, i8* %arrayidx70.12, align 1
  %conv71.4.12 = zext i8 %6747 to i32
  %xor72.4.12 = xor i32 %conv71.4.12, %conv68.4.12
  %conv73.4.12 = trunc i32 %xor72.4.12 to i8
  store i8 %conv73.4.12, i8* %arrayidx70.12, align 1
  %scevgep20.5.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 5
  %6748 = load i8, i8* %scevgep20.5.12, align 1
  %conv68.5.12 = zext i8 %6748 to i32
  %6749 = load i8, i8* %arrayidx70.12, align 1
  %conv71.5.12 = zext i8 %6749 to i32
  %xor72.5.12 = xor i32 %conv71.5.12, %conv68.5.12
  %conv73.5.12 = trunc i32 %xor72.5.12 to i8
  store i8 %conv73.5.12, i8* %arrayidx70.12, align 1
  %scevgep20.6.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 6
  %6750 = load i8, i8* %scevgep20.6.12, align 1
  %conv68.6.12 = zext i8 %6750 to i32
  %6751 = load i8, i8* %arrayidx70.12, align 1
  %conv71.6.12 = zext i8 %6751 to i32
  %xor72.6.12 = xor i32 %conv71.6.12, %conv68.6.12
  %conv73.6.12 = trunc i32 %xor72.6.12 to i8
  store i8 %conv73.6.12, i8* %arrayidx70.12, align 1
  %scevgep20.7.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 7
  %6752 = load i8, i8* %scevgep20.7.12, align 1
  %conv68.7.12 = zext i8 %6752 to i32
  %6753 = load i8, i8* %arrayidx70.12, align 1
  %conv71.7.12 = zext i8 %6753 to i32
  %xor72.7.12 = xor i32 %conv71.7.12, %conv68.7.12
  %conv73.7.12 = trunc i32 %xor72.7.12 to i8
  store i8 %conv73.7.12, i8* %arrayidx70.12, align 1
  %scevgep20.8.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 8
  %6754 = load i8, i8* %scevgep20.8.12, align 1
  %conv68.8.12 = zext i8 %6754 to i32
  %6755 = load i8, i8* %arrayidx70.12, align 1
  %conv71.8.12 = zext i8 %6755 to i32
  %xor72.8.12 = xor i32 %conv71.8.12, %conv68.8.12
  %conv73.8.12 = trunc i32 %xor72.8.12 to i8
  store i8 %conv73.8.12, i8* %arrayidx70.12, align 1
  %scevgep20.9.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 9
  %6756 = load i8, i8* %scevgep20.9.12, align 1
  %conv68.9.12 = zext i8 %6756 to i32
  %6757 = load i8, i8* %arrayidx70.12, align 1
  %conv71.9.12 = zext i8 %6757 to i32
  %xor72.9.12 = xor i32 %conv71.9.12, %conv68.9.12
  %conv73.9.12 = trunc i32 %xor72.9.12 to i8
  store i8 %conv73.9.12, i8* %arrayidx70.12, align 1
  %scevgep20.10.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 10
  %6758 = load i8, i8* %scevgep20.10.12, align 1
  %conv68.10.12 = zext i8 %6758 to i32
  %6759 = load i8, i8* %arrayidx70.12, align 1
  %conv71.10.12 = zext i8 %6759 to i32
  %xor72.10.12 = xor i32 %conv71.10.12, %conv68.10.12
  %conv73.10.12 = trunc i32 %xor72.10.12 to i8
  store i8 %conv73.10.12, i8* %arrayidx70.12, align 1
  %scevgep20.11.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 11
  %6760 = load i8, i8* %scevgep20.11.12, align 1
  %conv68.11.12 = zext i8 %6760 to i32
  %6761 = load i8, i8* %arrayidx70.12, align 1
  %conv71.11.12 = zext i8 %6761 to i32
  %xor72.11.12 = xor i32 %conv71.11.12, %conv68.11.12
  %conv73.11.12 = trunc i32 %xor72.11.12 to i8
  store i8 %conv73.11.12, i8* %arrayidx70.12, align 1
  %scevgep20.13.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 13
  %6762 = load i8, i8* %scevgep20.13.12, align 1
  %conv68.13.12 = zext i8 %6762 to i32
  %6763 = load i8, i8* %arrayidx70.12, align 1
  %conv71.13.12 = zext i8 %6763 to i32
  %xor72.13.12 = xor i32 %conv71.13.12, %conv68.13.12
  %conv73.13.12 = trunc i32 %xor72.13.12 to i8
  store i8 %conv73.13.12, i8* %arrayidx70.12, align 1
  %scevgep20.14.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 14
  %6764 = load i8, i8* %scevgep20.14.12, align 1
  %conv68.14.12 = zext i8 %6764 to i32
  %6765 = load i8, i8* %arrayidx70.12, align 1
  %conv71.14.12 = zext i8 %6765 to i32
  %xor72.14.12 = xor i32 %conv71.14.12, %conv68.14.12
  %conv73.14.12 = trunc i32 %xor72.14.12 to i8
  store i8 %conv73.14.12, i8* %arrayidx70.12, align 1
  %scevgep20.15.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 15
  %6766 = load i8, i8* %scevgep20.15.12, align 1
  %conv68.15.12 = zext i8 %6766 to i32
  %6767 = load i8, i8* %arrayidx70.12, align 1
  %conv71.15.12 = zext i8 %6767 to i32
  %xor72.15.12 = xor i32 %conv71.15.12, %conv68.15.12
  %conv73.15.12 = trunc i32 %xor72.15.12 to i8
  store i8 %conv73.15.12, i8* %arrayidx70.12, align 1
  %scevgep20.16.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 16
  %6768 = load i8, i8* %scevgep20.16.12, align 1
  %conv68.16.12 = zext i8 %6768 to i32
  %6769 = load i8, i8* %arrayidx70.12, align 1
  %conv71.16.12 = zext i8 %6769 to i32
  %xor72.16.12 = xor i32 %conv71.16.12, %conv68.16.12
  %conv73.16.12 = trunc i32 %xor72.16.12 to i8
  store i8 %conv73.16.12, i8* %arrayidx70.12, align 1
  %scevgep20.17.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 17
  %6770 = load i8, i8* %scevgep20.17.12, align 1
  %conv68.17.12 = zext i8 %6770 to i32
  %6771 = load i8, i8* %arrayidx70.12, align 1
  %conv71.17.12 = zext i8 %6771 to i32
  %xor72.17.12 = xor i32 %conv71.17.12, %conv68.17.12
  %conv73.17.12 = trunc i32 %xor72.17.12 to i8
  store i8 %conv73.17.12, i8* %arrayidx70.12, align 1
  %scevgep20.18.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 18
  %6772 = load i8, i8* %scevgep20.18.12, align 1
  %conv68.18.12 = zext i8 %6772 to i32
  %6773 = load i8, i8* %arrayidx70.12, align 1
  %conv71.18.12 = zext i8 %6773 to i32
  %xor72.18.12 = xor i32 %conv71.18.12, %conv68.18.12
  %conv73.18.12 = trunc i32 %xor72.18.12 to i8
  store i8 %conv73.18.12, i8* %arrayidx70.12, align 1
  %scevgep20.19.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 19
  %6774 = load i8, i8* %scevgep20.19.12, align 1
  %conv68.19.12 = zext i8 %6774 to i32
  %6775 = load i8, i8* %arrayidx70.12, align 1
  %conv71.19.12 = zext i8 %6775 to i32
  %xor72.19.12 = xor i32 %conv71.19.12, %conv68.19.12
  %conv73.19.12 = trunc i32 %xor72.19.12 to i8
  store i8 %conv73.19.12, i8* %arrayidx70.12, align 1
  %scevgep20.20.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 20
  %6776 = load i8, i8* %scevgep20.20.12, align 1
  %conv68.20.12 = zext i8 %6776 to i32
  %6777 = load i8, i8* %arrayidx70.12, align 1
  %conv71.20.12 = zext i8 %6777 to i32
  %xor72.20.12 = xor i32 %conv71.20.12, %conv68.20.12
  %conv73.20.12 = trunc i32 %xor72.20.12 to i8
  store i8 %conv73.20.12, i8* %arrayidx70.12, align 1
  %scevgep20.21.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 21
  %6778 = load i8, i8* %scevgep20.21.12, align 1
  %conv68.21.12 = zext i8 %6778 to i32
  %6779 = load i8, i8* %arrayidx70.12, align 1
  %conv71.21.12 = zext i8 %6779 to i32
  %xor72.21.12 = xor i32 %conv71.21.12, %conv68.21.12
  %conv73.21.12 = trunc i32 %xor72.21.12 to i8
  store i8 %conv73.21.12, i8* %arrayidx70.12, align 1
  %scevgep20.22.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 22
  %6780 = load i8, i8* %scevgep20.22.12, align 1
  %conv68.22.12 = zext i8 %6780 to i32
  %6781 = load i8, i8* %arrayidx70.12, align 1
  %conv71.22.12 = zext i8 %6781 to i32
  %xor72.22.12 = xor i32 %conv71.22.12, %conv68.22.12
  %conv73.22.12 = trunc i32 %xor72.22.12 to i8
  store i8 %conv73.22.12, i8* %arrayidx70.12, align 1
  %scevgep20.23.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 23
  %6782 = load i8, i8* %scevgep20.23.12, align 1
  %conv68.23.12 = zext i8 %6782 to i32
  %6783 = load i8, i8* %arrayidx70.12, align 1
  %conv71.23.12 = zext i8 %6783 to i32
  %xor72.23.12 = xor i32 %conv71.23.12, %conv68.23.12
  %conv73.23.12 = trunc i32 %xor72.23.12 to i8
  store i8 %conv73.23.12, i8* %arrayidx70.12, align 1
  %scevgep20.24.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 24
  %6784 = load i8, i8* %scevgep20.24.12, align 1
  %conv68.24.12 = zext i8 %6784 to i32
  %6785 = load i8, i8* %arrayidx70.12, align 1
  %conv71.24.12 = zext i8 %6785 to i32
  %xor72.24.12 = xor i32 %conv71.24.12, %conv68.24.12
  %conv73.24.12 = trunc i32 %xor72.24.12 to i8
  store i8 %conv73.24.12, i8* %arrayidx70.12, align 1
  %scevgep20.25.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 25
  %6786 = load i8, i8* %scevgep20.25.12, align 1
  %conv68.25.12 = zext i8 %6786 to i32
  %6787 = load i8, i8* %arrayidx70.12, align 1
  %conv71.25.12 = zext i8 %6787 to i32
  %xor72.25.12 = xor i32 %conv71.25.12, %conv68.25.12
  %conv73.25.12 = trunc i32 %xor72.25.12 to i8
  store i8 %conv73.25.12, i8* %arrayidx70.12, align 1
  %scevgep20.26.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 26
  %6788 = load i8, i8* %scevgep20.26.12, align 1
  %conv68.26.12 = zext i8 %6788 to i32
  %6789 = load i8, i8* %arrayidx70.12, align 1
  %conv71.26.12 = zext i8 %6789 to i32
  %xor72.26.12 = xor i32 %conv71.26.12, %conv68.26.12
  %conv73.26.12 = trunc i32 %xor72.26.12 to i8
  store i8 %conv73.26.12, i8* %arrayidx70.12, align 1
  %scevgep20.27.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 27
  %6790 = load i8, i8* %scevgep20.27.12, align 1
  %conv68.27.12 = zext i8 %6790 to i32
  %6791 = load i8, i8* %arrayidx70.12, align 1
  %conv71.27.12 = zext i8 %6791 to i32
  %xor72.27.12 = xor i32 %conv71.27.12, %conv68.27.12
  %conv73.27.12 = trunc i32 %xor72.27.12 to i8
  store i8 %conv73.27.12, i8* %arrayidx70.12, align 1
  %scevgep20.28.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 28
  %6792 = load i8, i8* %scevgep20.28.12, align 1
  %conv68.28.12 = zext i8 %6792 to i32
  %6793 = load i8, i8* %arrayidx70.12, align 1
  %conv71.28.12 = zext i8 %6793 to i32
  %xor72.28.12 = xor i32 %conv71.28.12, %conv68.28.12
  %conv73.28.12 = trunc i32 %xor72.28.12 to i8
  store i8 %conv73.28.12, i8* %arrayidx70.12, align 1
  %scevgep20.29.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 29
  %6794 = load i8, i8* %scevgep20.29.12, align 1
  %conv68.29.12 = zext i8 %6794 to i32
  %6795 = load i8, i8* %arrayidx70.12, align 1
  %conv71.29.12 = zext i8 %6795 to i32
  %xor72.29.12 = xor i32 %conv71.29.12, %conv68.29.12
  %conv73.29.12 = trunc i32 %xor72.29.12 to i8
  store i8 %conv73.29.12, i8* %arrayidx70.12, align 1
  %scevgep20.30.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 30
  %6796 = load i8, i8* %scevgep20.30.12, align 1
  %conv68.30.12 = zext i8 %6796 to i32
  %6797 = load i8, i8* %arrayidx70.12, align 1
  %conv71.30.12 = zext i8 %6797 to i32
  %xor72.30.12 = xor i32 %conv71.30.12, %conv68.30.12
  %conv73.30.12 = trunc i32 %xor72.30.12 to i8
  store i8 %conv73.30.12, i8* %arrayidx70.12, align 1
  %scevgep20.31.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 31
  %6798 = load i8, i8* %scevgep20.31.12, align 1
  %conv68.31.12 = zext i8 %6798 to i32
  %6799 = load i8, i8* %arrayidx70.12, align 1
  %conv71.31.12 = zext i8 %6799 to i32
  %xor72.31.12 = xor i32 %conv71.31.12, %conv68.31.12
  %conv73.31.12 = trunc i32 %xor72.31.12 to i8
  store i8 %conv73.31.12, i8* %arrayidx70.12, align 1
  %scevgep20.32.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 32
  %6800 = load i8, i8* %scevgep20.32.12, align 1
  %conv68.32.12 = zext i8 %6800 to i32
  %6801 = load i8, i8* %arrayidx70.12, align 1
  %conv71.32.12 = zext i8 %6801 to i32
  %xor72.32.12 = xor i32 %conv71.32.12, %conv68.32.12
  %conv73.32.12 = trunc i32 %xor72.32.12 to i8
  store i8 %conv73.32.12, i8* %arrayidx70.12, align 1
  %scevgep20.33.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 33
  %6802 = load i8, i8* %scevgep20.33.12, align 1
  %conv68.33.12 = zext i8 %6802 to i32
  %6803 = load i8, i8* %arrayidx70.12, align 1
  %conv71.33.12 = zext i8 %6803 to i32
  %xor72.33.12 = xor i32 %conv71.33.12, %conv68.33.12
  %conv73.33.12 = trunc i32 %xor72.33.12 to i8
  store i8 %conv73.33.12, i8* %arrayidx70.12, align 1
  %scevgep20.34.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 34
  %6804 = load i8, i8* %scevgep20.34.12, align 1
  %conv68.34.12 = zext i8 %6804 to i32
  %6805 = load i8, i8* %arrayidx70.12, align 1
  %conv71.34.12 = zext i8 %6805 to i32
  %xor72.34.12 = xor i32 %conv71.34.12, %conv68.34.12
  %conv73.34.12 = trunc i32 %xor72.34.12 to i8
  store i8 %conv73.34.12, i8* %arrayidx70.12, align 1
  %scevgep20.35.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 35
  %6806 = load i8, i8* %scevgep20.35.12, align 1
  %conv68.35.12 = zext i8 %6806 to i32
  %6807 = load i8, i8* %arrayidx70.12, align 1
  %conv71.35.12 = zext i8 %6807 to i32
  %xor72.35.12 = xor i32 %conv71.35.12, %conv68.35.12
  %conv73.35.12 = trunc i32 %xor72.35.12 to i8
  store i8 %conv73.35.12, i8* %arrayidx70.12, align 1
  %scevgep20.36.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 36
  %6808 = load i8, i8* %scevgep20.36.12, align 1
  %conv68.36.12 = zext i8 %6808 to i32
  %6809 = load i8, i8* %arrayidx70.12, align 1
  %conv71.36.12 = zext i8 %6809 to i32
  %xor72.36.12 = xor i32 %conv71.36.12, %conv68.36.12
  %conv73.36.12 = trunc i32 %xor72.36.12 to i8
  store i8 %conv73.36.12, i8* %arrayidx70.12, align 1
  %scevgep20.37.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 37
  %6810 = load i8, i8* %scevgep20.37.12, align 1
  %conv68.37.12 = zext i8 %6810 to i32
  %6811 = load i8, i8* %arrayidx70.12, align 1
  %conv71.37.12 = zext i8 %6811 to i32
  %xor72.37.12 = xor i32 %conv71.37.12, %conv68.37.12
  %conv73.37.12 = trunc i32 %xor72.37.12 to i8
  store i8 %conv73.37.12, i8* %arrayidx70.12, align 1
  %scevgep20.38.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 38
  %6812 = load i8, i8* %scevgep20.38.12, align 1
  %conv68.38.12 = zext i8 %6812 to i32
  %6813 = load i8, i8* %arrayidx70.12, align 1
  %conv71.38.12 = zext i8 %6813 to i32
  %xor72.38.12 = xor i32 %conv71.38.12, %conv68.38.12
  %conv73.38.12 = trunc i32 %xor72.38.12 to i8
  store i8 %conv73.38.12, i8* %arrayidx70.12, align 1
  %scevgep20.39.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 39
  %6814 = load i8, i8* %scevgep20.39.12, align 1
  %conv68.39.12 = zext i8 %6814 to i32
  %6815 = load i8, i8* %arrayidx70.12, align 1
  %conv71.39.12 = zext i8 %6815 to i32
  %xor72.39.12 = xor i32 %conv71.39.12, %conv68.39.12
  %conv73.39.12 = trunc i32 %xor72.39.12 to i8
  store i8 %conv73.39.12, i8* %arrayidx70.12, align 1
  %scevgep20.40.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 0, i64 40
  %6816 = load i8, i8* %scevgep20.40.12, align 1
  %conv68.40.12 = zext i8 %6816 to i32
  %6817 = load i8, i8* %arrayidx70.12, align 1
  %conv71.40.12 = zext i8 %6817 to i32
  %xor72.40.12 = xor i32 %conv71.40.12, %conv68.40.12
  %conv73.40.12 = trunc i32 %xor72.40.12 to i8
  store i8 %conv73.40.12, i8* %arrayidx70.12, align 1
  %scevgep19.12 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6735, i64 0, i64 1, i64 0
  %6818 = bitcast i8* %scevgep19.12 to [41 x [41 x i8]]*
  %arrayidx51.13 = getelementptr inbounds i8, i8* %a, i64 13
  %6819 = load i8, i8* %arrayidx51.13, align 1
  %arrayidx53.13 = getelementptr inbounds i8, i8* %b, i64 13
  %6820 = load i8, i8* %arrayidx53.13, align 1
  %call54.13 = call zeroext i8 @mult(i8 zeroext %6819, i8 zeroext %6820)
  %arrayidx56.13 = getelementptr inbounds i8, i8* %c, i64 13
  store i8 %call54.13, i8* %arrayidx56.13, align 1
  %arrayidx70.13 = getelementptr inbounds i8, i8* %c, i64 13
  %scevgep20.13174 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 0
  %6821 = load i8, i8* %scevgep20.13174, align 1
  %conv68.13175 = zext i8 %6821 to i32
  %6822 = load i8, i8* %arrayidx70.13, align 1
  %conv71.13176 = zext i8 %6822 to i32
  %xor72.13177 = xor i32 %conv71.13176, %conv68.13175
  %conv73.13178 = trunc i32 %xor72.13177 to i8
  store i8 %conv73.13178, i8* %arrayidx70.13, align 1
  %scevgep20.1.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 1
  %6823 = load i8, i8* %scevgep20.1.13, align 1
  %conv68.1.13 = zext i8 %6823 to i32
  %6824 = load i8, i8* %arrayidx70.13, align 1
  %conv71.1.13 = zext i8 %6824 to i32
  %xor72.1.13 = xor i32 %conv71.1.13, %conv68.1.13
  %conv73.1.13 = trunc i32 %xor72.1.13 to i8
  store i8 %conv73.1.13, i8* %arrayidx70.13, align 1
  %scevgep20.2.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 2
  %6825 = load i8, i8* %scevgep20.2.13, align 1
  %conv68.2.13 = zext i8 %6825 to i32
  %6826 = load i8, i8* %arrayidx70.13, align 1
  %conv71.2.13 = zext i8 %6826 to i32
  %xor72.2.13 = xor i32 %conv71.2.13, %conv68.2.13
  %conv73.2.13 = trunc i32 %xor72.2.13 to i8
  store i8 %conv73.2.13, i8* %arrayidx70.13, align 1
  %scevgep20.3.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 3
  %6827 = load i8, i8* %scevgep20.3.13, align 1
  %conv68.3.13 = zext i8 %6827 to i32
  %6828 = load i8, i8* %arrayidx70.13, align 1
  %conv71.3.13 = zext i8 %6828 to i32
  %xor72.3.13 = xor i32 %conv71.3.13, %conv68.3.13
  %conv73.3.13 = trunc i32 %xor72.3.13 to i8
  store i8 %conv73.3.13, i8* %arrayidx70.13, align 1
  %scevgep20.4.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 4
  %6829 = load i8, i8* %scevgep20.4.13, align 1
  %conv68.4.13 = zext i8 %6829 to i32
  %6830 = load i8, i8* %arrayidx70.13, align 1
  %conv71.4.13 = zext i8 %6830 to i32
  %xor72.4.13 = xor i32 %conv71.4.13, %conv68.4.13
  %conv73.4.13 = trunc i32 %xor72.4.13 to i8
  store i8 %conv73.4.13, i8* %arrayidx70.13, align 1
  %scevgep20.5.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 5
  %6831 = load i8, i8* %scevgep20.5.13, align 1
  %conv68.5.13 = zext i8 %6831 to i32
  %6832 = load i8, i8* %arrayidx70.13, align 1
  %conv71.5.13 = zext i8 %6832 to i32
  %xor72.5.13 = xor i32 %conv71.5.13, %conv68.5.13
  %conv73.5.13 = trunc i32 %xor72.5.13 to i8
  store i8 %conv73.5.13, i8* %arrayidx70.13, align 1
  %scevgep20.6.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 6
  %6833 = load i8, i8* %scevgep20.6.13, align 1
  %conv68.6.13 = zext i8 %6833 to i32
  %6834 = load i8, i8* %arrayidx70.13, align 1
  %conv71.6.13 = zext i8 %6834 to i32
  %xor72.6.13 = xor i32 %conv71.6.13, %conv68.6.13
  %conv73.6.13 = trunc i32 %xor72.6.13 to i8
  store i8 %conv73.6.13, i8* %arrayidx70.13, align 1
  %scevgep20.7.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 7
  %6835 = load i8, i8* %scevgep20.7.13, align 1
  %conv68.7.13 = zext i8 %6835 to i32
  %6836 = load i8, i8* %arrayidx70.13, align 1
  %conv71.7.13 = zext i8 %6836 to i32
  %xor72.7.13 = xor i32 %conv71.7.13, %conv68.7.13
  %conv73.7.13 = trunc i32 %xor72.7.13 to i8
  store i8 %conv73.7.13, i8* %arrayidx70.13, align 1
  %scevgep20.8.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 8
  %6837 = load i8, i8* %scevgep20.8.13, align 1
  %conv68.8.13 = zext i8 %6837 to i32
  %6838 = load i8, i8* %arrayidx70.13, align 1
  %conv71.8.13 = zext i8 %6838 to i32
  %xor72.8.13 = xor i32 %conv71.8.13, %conv68.8.13
  %conv73.8.13 = trunc i32 %xor72.8.13 to i8
  store i8 %conv73.8.13, i8* %arrayidx70.13, align 1
  %scevgep20.9.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 9
  %6839 = load i8, i8* %scevgep20.9.13, align 1
  %conv68.9.13 = zext i8 %6839 to i32
  %6840 = load i8, i8* %arrayidx70.13, align 1
  %conv71.9.13 = zext i8 %6840 to i32
  %xor72.9.13 = xor i32 %conv71.9.13, %conv68.9.13
  %conv73.9.13 = trunc i32 %xor72.9.13 to i8
  store i8 %conv73.9.13, i8* %arrayidx70.13, align 1
  %scevgep20.10.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 10
  %6841 = load i8, i8* %scevgep20.10.13, align 1
  %conv68.10.13 = zext i8 %6841 to i32
  %6842 = load i8, i8* %arrayidx70.13, align 1
  %conv71.10.13 = zext i8 %6842 to i32
  %xor72.10.13 = xor i32 %conv71.10.13, %conv68.10.13
  %conv73.10.13 = trunc i32 %xor72.10.13 to i8
  store i8 %conv73.10.13, i8* %arrayidx70.13, align 1
  %scevgep20.11.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 11
  %6843 = load i8, i8* %scevgep20.11.13, align 1
  %conv68.11.13 = zext i8 %6843 to i32
  %6844 = load i8, i8* %arrayidx70.13, align 1
  %conv71.11.13 = zext i8 %6844 to i32
  %xor72.11.13 = xor i32 %conv71.11.13, %conv68.11.13
  %conv73.11.13 = trunc i32 %xor72.11.13 to i8
  store i8 %conv73.11.13, i8* %arrayidx70.13, align 1
  %scevgep20.12.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 12
  %6845 = load i8, i8* %scevgep20.12.13, align 1
  %conv68.12.13 = zext i8 %6845 to i32
  %6846 = load i8, i8* %arrayidx70.13, align 1
  %conv71.12.13 = zext i8 %6846 to i32
  %xor72.12.13 = xor i32 %conv71.12.13, %conv68.12.13
  %conv73.12.13 = trunc i32 %xor72.12.13 to i8
  store i8 %conv73.12.13, i8* %arrayidx70.13, align 1
  %scevgep20.14.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 14
  %6847 = load i8, i8* %scevgep20.14.13, align 1
  %conv68.14.13 = zext i8 %6847 to i32
  %6848 = load i8, i8* %arrayidx70.13, align 1
  %conv71.14.13 = zext i8 %6848 to i32
  %xor72.14.13 = xor i32 %conv71.14.13, %conv68.14.13
  %conv73.14.13 = trunc i32 %xor72.14.13 to i8
  store i8 %conv73.14.13, i8* %arrayidx70.13, align 1
  %scevgep20.15.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 15
  %6849 = load i8, i8* %scevgep20.15.13, align 1
  %conv68.15.13 = zext i8 %6849 to i32
  %6850 = load i8, i8* %arrayidx70.13, align 1
  %conv71.15.13 = zext i8 %6850 to i32
  %xor72.15.13 = xor i32 %conv71.15.13, %conv68.15.13
  %conv73.15.13 = trunc i32 %xor72.15.13 to i8
  store i8 %conv73.15.13, i8* %arrayidx70.13, align 1
  %scevgep20.16.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 16
  %6851 = load i8, i8* %scevgep20.16.13, align 1
  %conv68.16.13 = zext i8 %6851 to i32
  %6852 = load i8, i8* %arrayidx70.13, align 1
  %conv71.16.13 = zext i8 %6852 to i32
  %xor72.16.13 = xor i32 %conv71.16.13, %conv68.16.13
  %conv73.16.13 = trunc i32 %xor72.16.13 to i8
  store i8 %conv73.16.13, i8* %arrayidx70.13, align 1
  %scevgep20.17.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 17
  %6853 = load i8, i8* %scevgep20.17.13, align 1
  %conv68.17.13 = zext i8 %6853 to i32
  %6854 = load i8, i8* %arrayidx70.13, align 1
  %conv71.17.13 = zext i8 %6854 to i32
  %xor72.17.13 = xor i32 %conv71.17.13, %conv68.17.13
  %conv73.17.13 = trunc i32 %xor72.17.13 to i8
  store i8 %conv73.17.13, i8* %arrayidx70.13, align 1
  %scevgep20.18.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 18
  %6855 = load i8, i8* %scevgep20.18.13, align 1
  %conv68.18.13 = zext i8 %6855 to i32
  %6856 = load i8, i8* %arrayidx70.13, align 1
  %conv71.18.13 = zext i8 %6856 to i32
  %xor72.18.13 = xor i32 %conv71.18.13, %conv68.18.13
  %conv73.18.13 = trunc i32 %xor72.18.13 to i8
  store i8 %conv73.18.13, i8* %arrayidx70.13, align 1
  %scevgep20.19.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 19
  %6857 = load i8, i8* %scevgep20.19.13, align 1
  %conv68.19.13 = zext i8 %6857 to i32
  %6858 = load i8, i8* %arrayidx70.13, align 1
  %conv71.19.13 = zext i8 %6858 to i32
  %xor72.19.13 = xor i32 %conv71.19.13, %conv68.19.13
  %conv73.19.13 = trunc i32 %xor72.19.13 to i8
  store i8 %conv73.19.13, i8* %arrayidx70.13, align 1
  %scevgep20.20.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 20
  %6859 = load i8, i8* %scevgep20.20.13, align 1
  %conv68.20.13 = zext i8 %6859 to i32
  %6860 = load i8, i8* %arrayidx70.13, align 1
  %conv71.20.13 = zext i8 %6860 to i32
  %xor72.20.13 = xor i32 %conv71.20.13, %conv68.20.13
  %conv73.20.13 = trunc i32 %xor72.20.13 to i8
  store i8 %conv73.20.13, i8* %arrayidx70.13, align 1
  %scevgep20.21.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 21
  %6861 = load i8, i8* %scevgep20.21.13, align 1
  %conv68.21.13 = zext i8 %6861 to i32
  %6862 = load i8, i8* %arrayidx70.13, align 1
  %conv71.21.13 = zext i8 %6862 to i32
  %xor72.21.13 = xor i32 %conv71.21.13, %conv68.21.13
  %conv73.21.13 = trunc i32 %xor72.21.13 to i8
  store i8 %conv73.21.13, i8* %arrayidx70.13, align 1
  %scevgep20.22.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 22
  %6863 = load i8, i8* %scevgep20.22.13, align 1
  %conv68.22.13 = zext i8 %6863 to i32
  %6864 = load i8, i8* %arrayidx70.13, align 1
  %conv71.22.13 = zext i8 %6864 to i32
  %xor72.22.13 = xor i32 %conv71.22.13, %conv68.22.13
  %conv73.22.13 = trunc i32 %xor72.22.13 to i8
  store i8 %conv73.22.13, i8* %arrayidx70.13, align 1
  %scevgep20.23.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 23
  %6865 = load i8, i8* %scevgep20.23.13, align 1
  %conv68.23.13 = zext i8 %6865 to i32
  %6866 = load i8, i8* %arrayidx70.13, align 1
  %conv71.23.13 = zext i8 %6866 to i32
  %xor72.23.13 = xor i32 %conv71.23.13, %conv68.23.13
  %conv73.23.13 = trunc i32 %xor72.23.13 to i8
  store i8 %conv73.23.13, i8* %arrayidx70.13, align 1
  %scevgep20.24.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 24
  %6867 = load i8, i8* %scevgep20.24.13, align 1
  %conv68.24.13 = zext i8 %6867 to i32
  %6868 = load i8, i8* %arrayidx70.13, align 1
  %conv71.24.13 = zext i8 %6868 to i32
  %xor72.24.13 = xor i32 %conv71.24.13, %conv68.24.13
  %conv73.24.13 = trunc i32 %xor72.24.13 to i8
  store i8 %conv73.24.13, i8* %arrayidx70.13, align 1
  %scevgep20.25.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 25
  %6869 = load i8, i8* %scevgep20.25.13, align 1
  %conv68.25.13 = zext i8 %6869 to i32
  %6870 = load i8, i8* %arrayidx70.13, align 1
  %conv71.25.13 = zext i8 %6870 to i32
  %xor72.25.13 = xor i32 %conv71.25.13, %conv68.25.13
  %conv73.25.13 = trunc i32 %xor72.25.13 to i8
  store i8 %conv73.25.13, i8* %arrayidx70.13, align 1
  %scevgep20.26.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 26
  %6871 = load i8, i8* %scevgep20.26.13, align 1
  %conv68.26.13 = zext i8 %6871 to i32
  %6872 = load i8, i8* %arrayidx70.13, align 1
  %conv71.26.13 = zext i8 %6872 to i32
  %xor72.26.13 = xor i32 %conv71.26.13, %conv68.26.13
  %conv73.26.13 = trunc i32 %xor72.26.13 to i8
  store i8 %conv73.26.13, i8* %arrayidx70.13, align 1
  %scevgep20.27.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 27
  %6873 = load i8, i8* %scevgep20.27.13, align 1
  %conv68.27.13 = zext i8 %6873 to i32
  %6874 = load i8, i8* %arrayidx70.13, align 1
  %conv71.27.13 = zext i8 %6874 to i32
  %xor72.27.13 = xor i32 %conv71.27.13, %conv68.27.13
  %conv73.27.13 = trunc i32 %xor72.27.13 to i8
  store i8 %conv73.27.13, i8* %arrayidx70.13, align 1
  %scevgep20.28.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 28
  %6875 = load i8, i8* %scevgep20.28.13, align 1
  %conv68.28.13 = zext i8 %6875 to i32
  %6876 = load i8, i8* %arrayidx70.13, align 1
  %conv71.28.13 = zext i8 %6876 to i32
  %xor72.28.13 = xor i32 %conv71.28.13, %conv68.28.13
  %conv73.28.13 = trunc i32 %xor72.28.13 to i8
  store i8 %conv73.28.13, i8* %arrayidx70.13, align 1
  %scevgep20.29.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 29
  %6877 = load i8, i8* %scevgep20.29.13, align 1
  %conv68.29.13 = zext i8 %6877 to i32
  %6878 = load i8, i8* %arrayidx70.13, align 1
  %conv71.29.13 = zext i8 %6878 to i32
  %xor72.29.13 = xor i32 %conv71.29.13, %conv68.29.13
  %conv73.29.13 = trunc i32 %xor72.29.13 to i8
  store i8 %conv73.29.13, i8* %arrayidx70.13, align 1
  %scevgep20.30.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 30
  %6879 = load i8, i8* %scevgep20.30.13, align 1
  %conv68.30.13 = zext i8 %6879 to i32
  %6880 = load i8, i8* %arrayidx70.13, align 1
  %conv71.30.13 = zext i8 %6880 to i32
  %xor72.30.13 = xor i32 %conv71.30.13, %conv68.30.13
  %conv73.30.13 = trunc i32 %xor72.30.13 to i8
  store i8 %conv73.30.13, i8* %arrayidx70.13, align 1
  %scevgep20.31.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 31
  %6881 = load i8, i8* %scevgep20.31.13, align 1
  %conv68.31.13 = zext i8 %6881 to i32
  %6882 = load i8, i8* %arrayidx70.13, align 1
  %conv71.31.13 = zext i8 %6882 to i32
  %xor72.31.13 = xor i32 %conv71.31.13, %conv68.31.13
  %conv73.31.13 = trunc i32 %xor72.31.13 to i8
  store i8 %conv73.31.13, i8* %arrayidx70.13, align 1
  %scevgep20.32.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 32
  %6883 = load i8, i8* %scevgep20.32.13, align 1
  %conv68.32.13 = zext i8 %6883 to i32
  %6884 = load i8, i8* %arrayidx70.13, align 1
  %conv71.32.13 = zext i8 %6884 to i32
  %xor72.32.13 = xor i32 %conv71.32.13, %conv68.32.13
  %conv73.32.13 = trunc i32 %xor72.32.13 to i8
  store i8 %conv73.32.13, i8* %arrayidx70.13, align 1
  %scevgep20.33.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 33
  %6885 = load i8, i8* %scevgep20.33.13, align 1
  %conv68.33.13 = zext i8 %6885 to i32
  %6886 = load i8, i8* %arrayidx70.13, align 1
  %conv71.33.13 = zext i8 %6886 to i32
  %xor72.33.13 = xor i32 %conv71.33.13, %conv68.33.13
  %conv73.33.13 = trunc i32 %xor72.33.13 to i8
  store i8 %conv73.33.13, i8* %arrayidx70.13, align 1
  %scevgep20.34.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 34
  %6887 = load i8, i8* %scevgep20.34.13, align 1
  %conv68.34.13 = zext i8 %6887 to i32
  %6888 = load i8, i8* %arrayidx70.13, align 1
  %conv71.34.13 = zext i8 %6888 to i32
  %xor72.34.13 = xor i32 %conv71.34.13, %conv68.34.13
  %conv73.34.13 = trunc i32 %xor72.34.13 to i8
  store i8 %conv73.34.13, i8* %arrayidx70.13, align 1
  %scevgep20.35.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 35
  %6889 = load i8, i8* %scevgep20.35.13, align 1
  %conv68.35.13 = zext i8 %6889 to i32
  %6890 = load i8, i8* %arrayidx70.13, align 1
  %conv71.35.13 = zext i8 %6890 to i32
  %xor72.35.13 = xor i32 %conv71.35.13, %conv68.35.13
  %conv73.35.13 = trunc i32 %xor72.35.13 to i8
  store i8 %conv73.35.13, i8* %arrayidx70.13, align 1
  %scevgep20.36.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 36
  %6891 = load i8, i8* %scevgep20.36.13, align 1
  %conv68.36.13 = zext i8 %6891 to i32
  %6892 = load i8, i8* %arrayidx70.13, align 1
  %conv71.36.13 = zext i8 %6892 to i32
  %xor72.36.13 = xor i32 %conv71.36.13, %conv68.36.13
  %conv73.36.13 = trunc i32 %xor72.36.13 to i8
  store i8 %conv73.36.13, i8* %arrayidx70.13, align 1
  %scevgep20.37.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 37
  %6893 = load i8, i8* %scevgep20.37.13, align 1
  %conv68.37.13 = zext i8 %6893 to i32
  %6894 = load i8, i8* %arrayidx70.13, align 1
  %conv71.37.13 = zext i8 %6894 to i32
  %xor72.37.13 = xor i32 %conv71.37.13, %conv68.37.13
  %conv73.37.13 = trunc i32 %xor72.37.13 to i8
  store i8 %conv73.37.13, i8* %arrayidx70.13, align 1
  %scevgep20.38.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 38
  %6895 = load i8, i8* %scevgep20.38.13, align 1
  %conv68.38.13 = zext i8 %6895 to i32
  %6896 = load i8, i8* %arrayidx70.13, align 1
  %conv71.38.13 = zext i8 %6896 to i32
  %xor72.38.13 = xor i32 %conv71.38.13, %conv68.38.13
  %conv73.38.13 = trunc i32 %xor72.38.13 to i8
  store i8 %conv73.38.13, i8* %arrayidx70.13, align 1
  %scevgep20.39.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 39
  %6897 = load i8, i8* %scevgep20.39.13, align 1
  %conv68.39.13 = zext i8 %6897 to i32
  %6898 = load i8, i8* %arrayidx70.13, align 1
  %conv71.39.13 = zext i8 %6898 to i32
  %xor72.39.13 = xor i32 %conv71.39.13, %conv68.39.13
  %conv73.39.13 = trunc i32 %xor72.39.13 to i8
  store i8 %conv73.39.13, i8* %arrayidx70.13, align 1
  %scevgep20.40.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 0, i64 40
  %6899 = load i8, i8* %scevgep20.40.13, align 1
  %conv68.40.13 = zext i8 %6899 to i32
  %6900 = load i8, i8* %arrayidx70.13, align 1
  %conv71.40.13 = zext i8 %6900 to i32
  %xor72.40.13 = xor i32 %conv71.40.13, %conv68.40.13
  %conv73.40.13 = trunc i32 %xor72.40.13 to i8
  store i8 %conv73.40.13, i8* %arrayidx70.13, align 1
  %scevgep19.13 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6818, i64 0, i64 1, i64 0
  %6901 = bitcast i8* %scevgep19.13 to [41 x [41 x i8]]*
  %arrayidx51.14 = getelementptr inbounds i8, i8* %a, i64 14
  %6902 = load i8, i8* %arrayidx51.14, align 1
  %arrayidx53.14 = getelementptr inbounds i8, i8* %b, i64 14
  %6903 = load i8, i8* %arrayidx53.14, align 1
  %call54.14 = call zeroext i8 @mult(i8 zeroext %6902, i8 zeroext %6903)
  %arrayidx56.14 = getelementptr inbounds i8, i8* %c, i64 14
  store i8 %call54.14, i8* %arrayidx56.14, align 1
  %arrayidx70.14 = getelementptr inbounds i8, i8* %c, i64 14
  %scevgep20.14184 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 0
  %6904 = load i8, i8* %scevgep20.14184, align 1
  %conv68.14185 = zext i8 %6904 to i32
  %6905 = load i8, i8* %arrayidx70.14, align 1
  %conv71.14186 = zext i8 %6905 to i32
  %xor72.14187 = xor i32 %conv71.14186, %conv68.14185
  %conv73.14188 = trunc i32 %xor72.14187 to i8
  store i8 %conv73.14188, i8* %arrayidx70.14, align 1
  %scevgep20.1.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 1
  %6906 = load i8, i8* %scevgep20.1.14, align 1
  %conv68.1.14 = zext i8 %6906 to i32
  %6907 = load i8, i8* %arrayidx70.14, align 1
  %conv71.1.14 = zext i8 %6907 to i32
  %xor72.1.14 = xor i32 %conv71.1.14, %conv68.1.14
  %conv73.1.14 = trunc i32 %xor72.1.14 to i8
  store i8 %conv73.1.14, i8* %arrayidx70.14, align 1
  %scevgep20.2.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 2
  %6908 = load i8, i8* %scevgep20.2.14, align 1
  %conv68.2.14 = zext i8 %6908 to i32
  %6909 = load i8, i8* %arrayidx70.14, align 1
  %conv71.2.14 = zext i8 %6909 to i32
  %xor72.2.14 = xor i32 %conv71.2.14, %conv68.2.14
  %conv73.2.14 = trunc i32 %xor72.2.14 to i8
  store i8 %conv73.2.14, i8* %arrayidx70.14, align 1
  %scevgep20.3.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 3
  %6910 = load i8, i8* %scevgep20.3.14, align 1
  %conv68.3.14 = zext i8 %6910 to i32
  %6911 = load i8, i8* %arrayidx70.14, align 1
  %conv71.3.14 = zext i8 %6911 to i32
  %xor72.3.14 = xor i32 %conv71.3.14, %conv68.3.14
  %conv73.3.14 = trunc i32 %xor72.3.14 to i8
  store i8 %conv73.3.14, i8* %arrayidx70.14, align 1
  %scevgep20.4.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 4
  %6912 = load i8, i8* %scevgep20.4.14, align 1
  %conv68.4.14 = zext i8 %6912 to i32
  %6913 = load i8, i8* %arrayidx70.14, align 1
  %conv71.4.14 = zext i8 %6913 to i32
  %xor72.4.14 = xor i32 %conv71.4.14, %conv68.4.14
  %conv73.4.14 = trunc i32 %xor72.4.14 to i8
  store i8 %conv73.4.14, i8* %arrayidx70.14, align 1
  %scevgep20.5.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 5
  %6914 = load i8, i8* %scevgep20.5.14, align 1
  %conv68.5.14 = zext i8 %6914 to i32
  %6915 = load i8, i8* %arrayidx70.14, align 1
  %conv71.5.14 = zext i8 %6915 to i32
  %xor72.5.14 = xor i32 %conv71.5.14, %conv68.5.14
  %conv73.5.14 = trunc i32 %xor72.5.14 to i8
  store i8 %conv73.5.14, i8* %arrayidx70.14, align 1
  %scevgep20.6.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 6
  %6916 = load i8, i8* %scevgep20.6.14, align 1
  %conv68.6.14 = zext i8 %6916 to i32
  %6917 = load i8, i8* %arrayidx70.14, align 1
  %conv71.6.14 = zext i8 %6917 to i32
  %xor72.6.14 = xor i32 %conv71.6.14, %conv68.6.14
  %conv73.6.14 = trunc i32 %xor72.6.14 to i8
  store i8 %conv73.6.14, i8* %arrayidx70.14, align 1
  %scevgep20.7.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 7
  %6918 = load i8, i8* %scevgep20.7.14, align 1
  %conv68.7.14 = zext i8 %6918 to i32
  %6919 = load i8, i8* %arrayidx70.14, align 1
  %conv71.7.14 = zext i8 %6919 to i32
  %xor72.7.14 = xor i32 %conv71.7.14, %conv68.7.14
  %conv73.7.14 = trunc i32 %xor72.7.14 to i8
  store i8 %conv73.7.14, i8* %arrayidx70.14, align 1
  %scevgep20.8.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 8
  %6920 = load i8, i8* %scevgep20.8.14, align 1
  %conv68.8.14 = zext i8 %6920 to i32
  %6921 = load i8, i8* %arrayidx70.14, align 1
  %conv71.8.14 = zext i8 %6921 to i32
  %xor72.8.14 = xor i32 %conv71.8.14, %conv68.8.14
  %conv73.8.14 = trunc i32 %xor72.8.14 to i8
  store i8 %conv73.8.14, i8* %arrayidx70.14, align 1
  %scevgep20.9.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 9
  %6922 = load i8, i8* %scevgep20.9.14, align 1
  %conv68.9.14 = zext i8 %6922 to i32
  %6923 = load i8, i8* %arrayidx70.14, align 1
  %conv71.9.14 = zext i8 %6923 to i32
  %xor72.9.14 = xor i32 %conv71.9.14, %conv68.9.14
  %conv73.9.14 = trunc i32 %xor72.9.14 to i8
  store i8 %conv73.9.14, i8* %arrayidx70.14, align 1
  %scevgep20.10.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 10
  %6924 = load i8, i8* %scevgep20.10.14, align 1
  %conv68.10.14 = zext i8 %6924 to i32
  %6925 = load i8, i8* %arrayidx70.14, align 1
  %conv71.10.14 = zext i8 %6925 to i32
  %xor72.10.14 = xor i32 %conv71.10.14, %conv68.10.14
  %conv73.10.14 = trunc i32 %xor72.10.14 to i8
  store i8 %conv73.10.14, i8* %arrayidx70.14, align 1
  %scevgep20.11.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 11
  %6926 = load i8, i8* %scevgep20.11.14, align 1
  %conv68.11.14 = zext i8 %6926 to i32
  %6927 = load i8, i8* %arrayidx70.14, align 1
  %conv71.11.14 = zext i8 %6927 to i32
  %xor72.11.14 = xor i32 %conv71.11.14, %conv68.11.14
  %conv73.11.14 = trunc i32 %xor72.11.14 to i8
  store i8 %conv73.11.14, i8* %arrayidx70.14, align 1
  %scevgep20.12.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 12
  %6928 = load i8, i8* %scevgep20.12.14, align 1
  %conv68.12.14 = zext i8 %6928 to i32
  %6929 = load i8, i8* %arrayidx70.14, align 1
  %conv71.12.14 = zext i8 %6929 to i32
  %xor72.12.14 = xor i32 %conv71.12.14, %conv68.12.14
  %conv73.12.14 = trunc i32 %xor72.12.14 to i8
  store i8 %conv73.12.14, i8* %arrayidx70.14, align 1
  %scevgep20.13.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 13
  %6930 = load i8, i8* %scevgep20.13.14, align 1
  %conv68.13.14 = zext i8 %6930 to i32
  %6931 = load i8, i8* %arrayidx70.14, align 1
  %conv71.13.14 = zext i8 %6931 to i32
  %xor72.13.14 = xor i32 %conv71.13.14, %conv68.13.14
  %conv73.13.14 = trunc i32 %xor72.13.14 to i8
  store i8 %conv73.13.14, i8* %arrayidx70.14, align 1
  %scevgep20.15.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 15
  %6932 = load i8, i8* %scevgep20.15.14, align 1
  %conv68.15.14 = zext i8 %6932 to i32
  %6933 = load i8, i8* %arrayidx70.14, align 1
  %conv71.15.14 = zext i8 %6933 to i32
  %xor72.15.14 = xor i32 %conv71.15.14, %conv68.15.14
  %conv73.15.14 = trunc i32 %xor72.15.14 to i8
  store i8 %conv73.15.14, i8* %arrayidx70.14, align 1
  %scevgep20.16.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 16
  %6934 = load i8, i8* %scevgep20.16.14, align 1
  %conv68.16.14 = zext i8 %6934 to i32
  %6935 = load i8, i8* %arrayidx70.14, align 1
  %conv71.16.14 = zext i8 %6935 to i32
  %xor72.16.14 = xor i32 %conv71.16.14, %conv68.16.14
  %conv73.16.14 = trunc i32 %xor72.16.14 to i8
  store i8 %conv73.16.14, i8* %arrayidx70.14, align 1
  %scevgep20.17.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 17
  %6936 = load i8, i8* %scevgep20.17.14, align 1
  %conv68.17.14 = zext i8 %6936 to i32
  %6937 = load i8, i8* %arrayidx70.14, align 1
  %conv71.17.14 = zext i8 %6937 to i32
  %xor72.17.14 = xor i32 %conv71.17.14, %conv68.17.14
  %conv73.17.14 = trunc i32 %xor72.17.14 to i8
  store i8 %conv73.17.14, i8* %arrayidx70.14, align 1
  %scevgep20.18.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 18
  %6938 = load i8, i8* %scevgep20.18.14, align 1
  %conv68.18.14 = zext i8 %6938 to i32
  %6939 = load i8, i8* %arrayidx70.14, align 1
  %conv71.18.14 = zext i8 %6939 to i32
  %xor72.18.14 = xor i32 %conv71.18.14, %conv68.18.14
  %conv73.18.14 = trunc i32 %xor72.18.14 to i8
  store i8 %conv73.18.14, i8* %arrayidx70.14, align 1
  %scevgep20.19.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 19
  %6940 = load i8, i8* %scevgep20.19.14, align 1
  %conv68.19.14 = zext i8 %6940 to i32
  %6941 = load i8, i8* %arrayidx70.14, align 1
  %conv71.19.14 = zext i8 %6941 to i32
  %xor72.19.14 = xor i32 %conv71.19.14, %conv68.19.14
  %conv73.19.14 = trunc i32 %xor72.19.14 to i8
  store i8 %conv73.19.14, i8* %arrayidx70.14, align 1
  %scevgep20.20.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 20
  %6942 = load i8, i8* %scevgep20.20.14, align 1
  %conv68.20.14 = zext i8 %6942 to i32
  %6943 = load i8, i8* %arrayidx70.14, align 1
  %conv71.20.14 = zext i8 %6943 to i32
  %xor72.20.14 = xor i32 %conv71.20.14, %conv68.20.14
  %conv73.20.14 = trunc i32 %xor72.20.14 to i8
  store i8 %conv73.20.14, i8* %arrayidx70.14, align 1
  %scevgep20.21.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 21
  %6944 = load i8, i8* %scevgep20.21.14, align 1
  %conv68.21.14 = zext i8 %6944 to i32
  %6945 = load i8, i8* %arrayidx70.14, align 1
  %conv71.21.14 = zext i8 %6945 to i32
  %xor72.21.14 = xor i32 %conv71.21.14, %conv68.21.14
  %conv73.21.14 = trunc i32 %xor72.21.14 to i8
  store i8 %conv73.21.14, i8* %arrayidx70.14, align 1
  %scevgep20.22.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 22
  %6946 = load i8, i8* %scevgep20.22.14, align 1
  %conv68.22.14 = zext i8 %6946 to i32
  %6947 = load i8, i8* %arrayidx70.14, align 1
  %conv71.22.14 = zext i8 %6947 to i32
  %xor72.22.14 = xor i32 %conv71.22.14, %conv68.22.14
  %conv73.22.14 = trunc i32 %xor72.22.14 to i8
  store i8 %conv73.22.14, i8* %arrayidx70.14, align 1
  %scevgep20.23.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 23
  %6948 = load i8, i8* %scevgep20.23.14, align 1
  %conv68.23.14 = zext i8 %6948 to i32
  %6949 = load i8, i8* %arrayidx70.14, align 1
  %conv71.23.14 = zext i8 %6949 to i32
  %xor72.23.14 = xor i32 %conv71.23.14, %conv68.23.14
  %conv73.23.14 = trunc i32 %xor72.23.14 to i8
  store i8 %conv73.23.14, i8* %arrayidx70.14, align 1
  %scevgep20.24.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 24
  %6950 = load i8, i8* %scevgep20.24.14, align 1
  %conv68.24.14 = zext i8 %6950 to i32
  %6951 = load i8, i8* %arrayidx70.14, align 1
  %conv71.24.14 = zext i8 %6951 to i32
  %xor72.24.14 = xor i32 %conv71.24.14, %conv68.24.14
  %conv73.24.14 = trunc i32 %xor72.24.14 to i8
  store i8 %conv73.24.14, i8* %arrayidx70.14, align 1
  %scevgep20.25.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 25
  %6952 = load i8, i8* %scevgep20.25.14, align 1
  %conv68.25.14 = zext i8 %6952 to i32
  %6953 = load i8, i8* %arrayidx70.14, align 1
  %conv71.25.14 = zext i8 %6953 to i32
  %xor72.25.14 = xor i32 %conv71.25.14, %conv68.25.14
  %conv73.25.14 = trunc i32 %xor72.25.14 to i8
  store i8 %conv73.25.14, i8* %arrayidx70.14, align 1
  %scevgep20.26.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 26
  %6954 = load i8, i8* %scevgep20.26.14, align 1
  %conv68.26.14 = zext i8 %6954 to i32
  %6955 = load i8, i8* %arrayidx70.14, align 1
  %conv71.26.14 = zext i8 %6955 to i32
  %xor72.26.14 = xor i32 %conv71.26.14, %conv68.26.14
  %conv73.26.14 = trunc i32 %xor72.26.14 to i8
  store i8 %conv73.26.14, i8* %arrayidx70.14, align 1
  %scevgep20.27.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 27
  %6956 = load i8, i8* %scevgep20.27.14, align 1
  %conv68.27.14 = zext i8 %6956 to i32
  %6957 = load i8, i8* %arrayidx70.14, align 1
  %conv71.27.14 = zext i8 %6957 to i32
  %xor72.27.14 = xor i32 %conv71.27.14, %conv68.27.14
  %conv73.27.14 = trunc i32 %xor72.27.14 to i8
  store i8 %conv73.27.14, i8* %arrayidx70.14, align 1
  %scevgep20.28.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 28
  %6958 = load i8, i8* %scevgep20.28.14, align 1
  %conv68.28.14 = zext i8 %6958 to i32
  %6959 = load i8, i8* %arrayidx70.14, align 1
  %conv71.28.14 = zext i8 %6959 to i32
  %xor72.28.14 = xor i32 %conv71.28.14, %conv68.28.14
  %conv73.28.14 = trunc i32 %xor72.28.14 to i8
  store i8 %conv73.28.14, i8* %arrayidx70.14, align 1
  %scevgep20.29.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 29
  %6960 = load i8, i8* %scevgep20.29.14, align 1
  %conv68.29.14 = zext i8 %6960 to i32
  %6961 = load i8, i8* %arrayidx70.14, align 1
  %conv71.29.14 = zext i8 %6961 to i32
  %xor72.29.14 = xor i32 %conv71.29.14, %conv68.29.14
  %conv73.29.14 = trunc i32 %xor72.29.14 to i8
  store i8 %conv73.29.14, i8* %arrayidx70.14, align 1
  %scevgep20.30.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 30
  %6962 = load i8, i8* %scevgep20.30.14, align 1
  %conv68.30.14 = zext i8 %6962 to i32
  %6963 = load i8, i8* %arrayidx70.14, align 1
  %conv71.30.14 = zext i8 %6963 to i32
  %xor72.30.14 = xor i32 %conv71.30.14, %conv68.30.14
  %conv73.30.14 = trunc i32 %xor72.30.14 to i8
  store i8 %conv73.30.14, i8* %arrayidx70.14, align 1
  %scevgep20.31.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 31
  %6964 = load i8, i8* %scevgep20.31.14, align 1
  %conv68.31.14 = zext i8 %6964 to i32
  %6965 = load i8, i8* %arrayidx70.14, align 1
  %conv71.31.14 = zext i8 %6965 to i32
  %xor72.31.14 = xor i32 %conv71.31.14, %conv68.31.14
  %conv73.31.14 = trunc i32 %xor72.31.14 to i8
  store i8 %conv73.31.14, i8* %arrayidx70.14, align 1
  %scevgep20.32.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 32
  %6966 = load i8, i8* %scevgep20.32.14, align 1
  %conv68.32.14 = zext i8 %6966 to i32
  %6967 = load i8, i8* %arrayidx70.14, align 1
  %conv71.32.14 = zext i8 %6967 to i32
  %xor72.32.14 = xor i32 %conv71.32.14, %conv68.32.14
  %conv73.32.14 = trunc i32 %xor72.32.14 to i8
  store i8 %conv73.32.14, i8* %arrayidx70.14, align 1
  %scevgep20.33.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 33
  %6968 = load i8, i8* %scevgep20.33.14, align 1
  %conv68.33.14 = zext i8 %6968 to i32
  %6969 = load i8, i8* %arrayidx70.14, align 1
  %conv71.33.14 = zext i8 %6969 to i32
  %xor72.33.14 = xor i32 %conv71.33.14, %conv68.33.14
  %conv73.33.14 = trunc i32 %xor72.33.14 to i8
  store i8 %conv73.33.14, i8* %arrayidx70.14, align 1
  %scevgep20.34.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 34
  %6970 = load i8, i8* %scevgep20.34.14, align 1
  %conv68.34.14 = zext i8 %6970 to i32
  %6971 = load i8, i8* %arrayidx70.14, align 1
  %conv71.34.14 = zext i8 %6971 to i32
  %xor72.34.14 = xor i32 %conv71.34.14, %conv68.34.14
  %conv73.34.14 = trunc i32 %xor72.34.14 to i8
  store i8 %conv73.34.14, i8* %arrayidx70.14, align 1
  %scevgep20.35.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 35
  %6972 = load i8, i8* %scevgep20.35.14, align 1
  %conv68.35.14 = zext i8 %6972 to i32
  %6973 = load i8, i8* %arrayidx70.14, align 1
  %conv71.35.14 = zext i8 %6973 to i32
  %xor72.35.14 = xor i32 %conv71.35.14, %conv68.35.14
  %conv73.35.14 = trunc i32 %xor72.35.14 to i8
  store i8 %conv73.35.14, i8* %arrayidx70.14, align 1
  %scevgep20.36.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 36
  %6974 = load i8, i8* %scevgep20.36.14, align 1
  %conv68.36.14 = zext i8 %6974 to i32
  %6975 = load i8, i8* %arrayidx70.14, align 1
  %conv71.36.14 = zext i8 %6975 to i32
  %xor72.36.14 = xor i32 %conv71.36.14, %conv68.36.14
  %conv73.36.14 = trunc i32 %xor72.36.14 to i8
  store i8 %conv73.36.14, i8* %arrayidx70.14, align 1
  %scevgep20.37.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 37
  %6976 = load i8, i8* %scevgep20.37.14, align 1
  %conv68.37.14 = zext i8 %6976 to i32
  %6977 = load i8, i8* %arrayidx70.14, align 1
  %conv71.37.14 = zext i8 %6977 to i32
  %xor72.37.14 = xor i32 %conv71.37.14, %conv68.37.14
  %conv73.37.14 = trunc i32 %xor72.37.14 to i8
  store i8 %conv73.37.14, i8* %arrayidx70.14, align 1
  %scevgep20.38.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 38
  %6978 = load i8, i8* %scevgep20.38.14, align 1
  %conv68.38.14 = zext i8 %6978 to i32
  %6979 = load i8, i8* %arrayidx70.14, align 1
  %conv71.38.14 = zext i8 %6979 to i32
  %xor72.38.14 = xor i32 %conv71.38.14, %conv68.38.14
  %conv73.38.14 = trunc i32 %xor72.38.14 to i8
  store i8 %conv73.38.14, i8* %arrayidx70.14, align 1
  %scevgep20.39.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 39
  %6980 = load i8, i8* %scevgep20.39.14, align 1
  %conv68.39.14 = zext i8 %6980 to i32
  %6981 = load i8, i8* %arrayidx70.14, align 1
  %conv71.39.14 = zext i8 %6981 to i32
  %xor72.39.14 = xor i32 %conv71.39.14, %conv68.39.14
  %conv73.39.14 = trunc i32 %xor72.39.14 to i8
  store i8 %conv73.39.14, i8* %arrayidx70.14, align 1
  %scevgep20.40.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 0, i64 40
  %6982 = load i8, i8* %scevgep20.40.14, align 1
  %conv68.40.14 = zext i8 %6982 to i32
  %6983 = load i8, i8* %arrayidx70.14, align 1
  %conv71.40.14 = zext i8 %6983 to i32
  %xor72.40.14 = xor i32 %conv71.40.14, %conv68.40.14
  %conv73.40.14 = trunc i32 %xor72.40.14 to i8
  store i8 %conv73.40.14, i8* %arrayidx70.14, align 1
  %scevgep19.14 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6901, i64 0, i64 1, i64 0
  %6984 = bitcast i8* %scevgep19.14 to [41 x [41 x i8]]*
  %arrayidx51.15 = getelementptr inbounds i8, i8* %a, i64 15
  %6985 = load i8, i8* %arrayidx51.15, align 1
  %arrayidx53.15 = getelementptr inbounds i8, i8* %b, i64 15
  %6986 = load i8, i8* %arrayidx53.15, align 1
  %call54.15 = call zeroext i8 @mult(i8 zeroext %6985, i8 zeroext %6986)
  %arrayidx56.15 = getelementptr inbounds i8, i8* %c, i64 15
  store i8 %call54.15, i8* %arrayidx56.15, align 1
  %arrayidx70.15 = getelementptr inbounds i8, i8* %c, i64 15
  %scevgep20.15194 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 0
  %6987 = load i8, i8* %scevgep20.15194, align 1
  %conv68.15195 = zext i8 %6987 to i32
  %6988 = load i8, i8* %arrayidx70.15, align 1
  %conv71.15196 = zext i8 %6988 to i32
  %xor72.15197 = xor i32 %conv71.15196, %conv68.15195
  %conv73.15198 = trunc i32 %xor72.15197 to i8
  store i8 %conv73.15198, i8* %arrayidx70.15, align 1
  %scevgep20.1.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 1
  %6989 = load i8, i8* %scevgep20.1.15, align 1
  %conv68.1.15 = zext i8 %6989 to i32
  %6990 = load i8, i8* %arrayidx70.15, align 1
  %conv71.1.15 = zext i8 %6990 to i32
  %xor72.1.15 = xor i32 %conv71.1.15, %conv68.1.15
  %conv73.1.15 = trunc i32 %xor72.1.15 to i8
  store i8 %conv73.1.15, i8* %arrayidx70.15, align 1
  %scevgep20.2.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 2
  %6991 = load i8, i8* %scevgep20.2.15, align 1
  %conv68.2.15 = zext i8 %6991 to i32
  %6992 = load i8, i8* %arrayidx70.15, align 1
  %conv71.2.15 = zext i8 %6992 to i32
  %xor72.2.15 = xor i32 %conv71.2.15, %conv68.2.15
  %conv73.2.15 = trunc i32 %xor72.2.15 to i8
  store i8 %conv73.2.15, i8* %arrayidx70.15, align 1
  %scevgep20.3.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 3
  %6993 = load i8, i8* %scevgep20.3.15, align 1
  %conv68.3.15 = zext i8 %6993 to i32
  %6994 = load i8, i8* %arrayidx70.15, align 1
  %conv71.3.15 = zext i8 %6994 to i32
  %xor72.3.15 = xor i32 %conv71.3.15, %conv68.3.15
  %conv73.3.15 = trunc i32 %xor72.3.15 to i8
  store i8 %conv73.3.15, i8* %arrayidx70.15, align 1
  %scevgep20.4.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 4
  %6995 = load i8, i8* %scevgep20.4.15, align 1
  %conv68.4.15 = zext i8 %6995 to i32
  %6996 = load i8, i8* %arrayidx70.15, align 1
  %conv71.4.15 = zext i8 %6996 to i32
  %xor72.4.15 = xor i32 %conv71.4.15, %conv68.4.15
  %conv73.4.15 = trunc i32 %xor72.4.15 to i8
  store i8 %conv73.4.15, i8* %arrayidx70.15, align 1
  %scevgep20.5.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 5
  %6997 = load i8, i8* %scevgep20.5.15, align 1
  %conv68.5.15 = zext i8 %6997 to i32
  %6998 = load i8, i8* %arrayidx70.15, align 1
  %conv71.5.15 = zext i8 %6998 to i32
  %xor72.5.15 = xor i32 %conv71.5.15, %conv68.5.15
  %conv73.5.15 = trunc i32 %xor72.5.15 to i8
  store i8 %conv73.5.15, i8* %arrayidx70.15, align 1
  %scevgep20.6.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 6
  %6999 = load i8, i8* %scevgep20.6.15, align 1
  %conv68.6.15 = zext i8 %6999 to i32
  %7000 = load i8, i8* %arrayidx70.15, align 1
  %conv71.6.15 = zext i8 %7000 to i32
  %xor72.6.15 = xor i32 %conv71.6.15, %conv68.6.15
  %conv73.6.15 = trunc i32 %xor72.6.15 to i8
  store i8 %conv73.6.15, i8* %arrayidx70.15, align 1
  %scevgep20.7.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 7
  %7001 = load i8, i8* %scevgep20.7.15, align 1
  %conv68.7.15 = zext i8 %7001 to i32
  %7002 = load i8, i8* %arrayidx70.15, align 1
  %conv71.7.15 = zext i8 %7002 to i32
  %xor72.7.15 = xor i32 %conv71.7.15, %conv68.7.15
  %conv73.7.15 = trunc i32 %xor72.7.15 to i8
  store i8 %conv73.7.15, i8* %arrayidx70.15, align 1
  %scevgep20.8.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 8
  %7003 = load i8, i8* %scevgep20.8.15, align 1
  %conv68.8.15 = zext i8 %7003 to i32
  %7004 = load i8, i8* %arrayidx70.15, align 1
  %conv71.8.15 = zext i8 %7004 to i32
  %xor72.8.15 = xor i32 %conv71.8.15, %conv68.8.15
  %conv73.8.15 = trunc i32 %xor72.8.15 to i8
  store i8 %conv73.8.15, i8* %arrayidx70.15, align 1
  %scevgep20.9.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 9
  %7005 = load i8, i8* %scevgep20.9.15, align 1
  %conv68.9.15 = zext i8 %7005 to i32
  %7006 = load i8, i8* %arrayidx70.15, align 1
  %conv71.9.15 = zext i8 %7006 to i32
  %xor72.9.15 = xor i32 %conv71.9.15, %conv68.9.15
  %conv73.9.15 = trunc i32 %xor72.9.15 to i8
  store i8 %conv73.9.15, i8* %arrayidx70.15, align 1
  %scevgep20.10.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 10
  %7007 = load i8, i8* %scevgep20.10.15, align 1
  %conv68.10.15 = zext i8 %7007 to i32
  %7008 = load i8, i8* %arrayidx70.15, align 1
  %conv71.10.15 = zext i8 %7008 to i32
  %xor72.10.15 = xor i32 %conv71.10.15, %conv68.10.15
  %conv73.10.15 = trunc i32 %xor72.10.15 to i8
  store i8 %conv73.10.15, i8* %arrayidx70.15, align 1
  %scevgep20.11.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 11
  %7009 = load i8, i8* %scevgep20.11.15, align 1
  %conv68.11.15 = zext i8 %7009 to i32
  %7010 = load i8, i8* %arrayidx70.15, align 1
  %conv71.11.15 = zext i8 %7010 to i32
  %xor72.11.15 = xor i32 %conv71.11.15, %conv68.11.15
  %conv73.11.15 = trunc i32 %xor72.11.15 to i8
  store i8 %conv73.11.15, i8* %arrayidx70.15, align 1
  %scevgep20.12.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 12
  %7011 = load i8, i8* %scevgep20.12.15, align 1
  %conv68.12.15 = zext i8 %7011 to i32
  %7012 = load i8, i8* %arrayidx70.15, align 1
  %conv71.12.15 = zext i8 %7012 to i32
  %xor72.12.15 = xor i32 %conv71.12.15, %conv68.12.15
  %conv73.12.15 = trunc i32 %xor72.12.15 to i8
  store i8 %conv73.12.15, i8* %arrayidx70.15, align 1
  %scevgep20.13.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 13
  %7013 = load i8, i8* %scevgep20.13.15, align 1
  %conv68.13.15 = zext i8 %7013 to i32
  %7014 = load i8, i8* %arrayidx70.15, align 1
  %conv71.13.15 = zext i8 %7014 to i32
  %xor72.13.15 = xor i32 %conv71.13.15, %conv68.13.15
  %conv73.13.15 = trunc i32 %xor72.13.15 to i8
  store i8 %conv73.13.15, i8* %arrayidx70.15, align 1
  %scevgep20.14.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 14
  %7015 = load i8, i8* %scevgep20.14.15, align 1
  %conv68.14.15 = zext i8 %7015 to i32
  %7016 = load i8, i8* %arrayidx70.15, align 1
  %conv71.14.15 = zext i8 %7016 to i32
  %xor72.14.15 = xor i32 %conv71.14.15, %conv68.14.15
  %conv73.14.15 = trunc i32 %xor72.14.15 to i8
  store i8 %conv73.14.15, i8* %arrayidx70.15, align 1
  %scevgep20.16.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 16
  %7017 = load i8, i8* %scevgep20.16.15, align 1
  %conv68.16.15 = zext i8 %7017 to i32
  %7018 = load i8, i8* %arrayidx70.15, align 1
  %conv71.16.15 = zext i8 %7018 to i32
  %xor72.16.15 = xor i32 %conv71.16.15, %conv68.16.15
  %conv73.16.15 = trunc i32 %xor72.16.15 to i8
  store i8 %conv73.16.15, i8* %arrayidx70.15, align 1
  %scevgep20.17.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 17
  %7019 = load i8, i8* %scevgep20.17.15, align 1
  %conv68.17.15 = zext i8 %7019 to i32
  %7020 = load i8, i8* %arrayidx70.15, align 1
  %conv71.17.15 = zext i8 %7020 to i32
  %xor72.17.15 = xor i32 %conv71.17.15, %conv68.17.15
  %conv73.17.15 = trunc i32 %xor72.17.15 to i8
  store i8 %conv73.17.15, i8* %arrayidx70.15, align 1
  %scevgep20.18.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 18
  %7021 = load i8, i8* %scevgep20.18.15, align 1
  %conv68.18.15 = zext i8 %7021 to i32
  %7022 = load i8, i8* %arrayidx70.15, align 1
  %conv71.18.15 = zext i8 %7022 to i32
  %xor72.18.15 = xor i32 %conv71.18.15, %conv68.18.15
  %conv73.18.15 = trunc i32 %xor72.18.15 to i8
  store i8 %conv73.18.15, i8* %arrayidx70.15, align 1
  %scevgep20.19.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 19
  %7023 = load i8, i8* %scevgep20.19.15, align 1
  %conv68.19.15 = zext i8 %7023 to i32
  %7024 = load i8, i8* %arrayidx70.15, align 1
  %conv71.19.15 = zext i8 %7024 to i32
  %xor72.19.15 = xor i32 %conv71.19.15, %conv68.19.15
  %conv73.19.15 = trunc i32 %xor72.19.15 to i8
  store i8 %conv73.19.15, i8* %arrayidx70.15, align 1
  %scevgep20.20.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 20
  %7025 = load i8, i8* %scevgep20.20.15, align 1
  %conv68.20.15 = zext i8 %7025 to i32
  %7026 = load i8, i8* %arrayidx70.15, align 1
  %conv71.20.15 = zext i8 %7026 to i32
  %xor72.20.15 = xor i32 %conv71.20.15, %conv68.20.15
  %conv73.20.15 = trunc i32 %xor72.20.15 to i8
  store i8 %conv73.20.15, i8* %arrayidx70.15, align 1
  %scevgep20.21.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 21
  %7027 = load i8, i8* %scevgep20.21.15, align 1
  %conv68.21.15 = zext i8 %7027 to i32
  %7028 = load i8, i8* %arrayidx70.15, align 1
  %conv71.21.15 = zext i8 %7028 to i32
  %xor72.21.15 = xor i32 %conv71.21.15, %conv68.21.15
  %conv73.21.15 = trunc i32 %xor72.21.15 to i8
  store i8 %conv73.21.15, i8* %arrayidx70.15, align 1
  %scevgep20.22.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 22
  %7029 = load i8, i8* %scevgep20.22.15, align 1
  %conv68.22.15 = zext i8 %7029 to i32
  %7030 = load i8, i8* %arrayidx70.15, align 1
  %conv71.22.15 = zext i8 %7030 to i32
  %xor72.22.15 = xor i32 %conv71.22.15, %conv68.22.15
  %conv73.22.15 = trunc i32 %xor72.22.15 to i8
  store i8 %conv73.22.15, i8* %arrayidx70.15, align 1
  %scevgep20.23.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 23
  %7031 = load i8, i8* %scevgep20.23.15, align 1
  %conv68.23.15 = zext i8 %7031 to i32
  %7032 = load i8, i8* %arrayidx70.15, align 1
  %conv71.23.15 = zext i8 %7032 to i32
  %xor72.23.15 = xor i32 %conv71.23.15, %conv68.23.15
  %conv73.23.15 = trunc i32 %xor72.23.15 to i8
  store i8 %conv73.23.15, i8* %arrayidx70.15, align 1
  %scevgep20.24.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 24
  %7033 = load i8, i8* %scevgep20.24.15, align 1
  %conv68.24.15 = zext i8 %7033 to i32
  %7034 = load i8, i8* %arrayidx70.15, align 1
  %conv71.24.15 = zext i8 %7034 to i32
  %xor72.24.15 = xor i32 %conv71.24.15, %conv68.24.15
  %conv73.24.15 = trunc i32 %xor72.24.15 to i8
  store i8 %conv73.24.15, i8* %arrayidx70.15, align 1
  %scevgep20.25.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 25
  %7035 = load i8, i8* %scevgep20.25.15, align 1
  %conv68.25.15 = zext i8 %7035 to i32
  %7036 = load i8, i8* %arrayidx70.15, align 1
  %conv71.25.15 = zext i8 %7036 to i32
  %xor72.25.15 = xor i32 %conv71.25.15, %conv68.25.15
  %conv73.25.15 = trunc i32 %xor72.25.15 to i8
  store i8 %conv73.25.15, i8* %arrayidx70.15, align 1
  %scevgep20.26.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 26
  %7037 = load i8, i8* %scevgep20.26.15, align 1
  %conv68.26.15 = zext i8 %7037 to i32
  %7038 = load i8, i8* %arrayidx70.15, align 1
  %conv71.26.15 = zext i8 %7038 to i32
  %xor72.26.15 = xor i32 %conv71.26.15, %conv68.26.15
  %conv73.26.15 = trunc i32 %xor72.26.15 to i8
  store i8 %conv73.26.15, i8* %arrayidx70.15, align 1
  %scevgep20.27.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 27
  %7039 = load i8, i8* %scevgep20.27.15, align 1
  %conv68.27.15 = zext i8 %7039 to i32
  %7040 = load i8, i8* %arrayidx70.15, align 1
  %conv71.27.15 = zext i8 %7040 to i32
  %xor72.27.15 = xor i32 %conv71.27.15, %conv68.27.15
  %conv73.27.15 = trunc i32 %xor72.27.15 to i8
  store i8 %conv73.27.15, i8* %arrayidx70.15, align 1
  %scevgep20.28.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 28
  %7041 = load i8, i8* %scevgep20.28.15, align 1
  %conv68.28.15 = zext i8 %7041 to i32
  %7042 = load i8, i8* %arrayidx70.15, align 1
  %conv71.28.15 = zext i8 %7042 to i32
  %xor72.28.15 = xor i32 %conv71.28.15, %conv68.28.15
  %conv73.28.15 = trunc i32 %xor72.28.15 to i8
  store i8 %conv73.28.15, i8* %arrayidx70.15, align 1
  %scevgep20.29.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 29
  %7043 = load i8, i8* %scevgep20.29.15, align 1
  %conv68.29.15 = zext i8 %7043 to i32
  %7044 = load i8, i8* %arrayidx70.15, align 1
  %conv71.29.15 = zext i8 %7044 to i32
  %xor72.29.15 = xor i32 %conv71.29.15, %conv68.29.15
  %conv73.29.15 = trunc i32 %xor72.29.15 to i8
  store i8 %conv73.29.15, i8* %arrayidx70.15, align 1
  %scevgep20.30.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 30
  %7045 = load i8, i8* %scevgep20.30.15, align 1
  %conv68.30.15 = zext i8 %7045 to i32
  %7046 = load i8, i8* %arrayidx70.15, align 1
  %conv71.30.15 = zext i8 %7046 to i32
  %xor72.30.15 = xor i32 %conv71.30.15, %conv68.30.15
  %conv73.30.15 = trunc i32 %xor72.30.15 to i8
  store i8 %conv73.30.15, i8* %arrayidx70.15, align 1
  %scevgep20.31.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 31
  %7047 = load i8, i8* %scevgep20.31.15, align 1
  %conv68.31.15 = zext i8 %7047 to i32
  %7048 = load i8, i8* %arrayidx70.15, align 1
  %conv71.31.15 = zext i8 %7048 to i32
  %xor72.31.15 = xor i32 %conv71.31.15, %conv68.31.15
  %conv73.31.15 = trunc i32 %xor72.31.15 to i8
  store i8 %conv73.31.15, i8* %arrayidx70.15, align 1
  %scevgep20.32.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 32
  %7049 = load i8, i8* %scevgep20.32.15, align 1
  %conv68.32.15 = zext i8 %7049 to i32
  %7050 = load i8, i8* %arrayidx70.15, align 1
  %conv71.32.15 = zext i8 %7050 to i32
  %xor72.32.15 = xor i32 %conv71.32.15, %conv68.32.15
  %conv73.32.15 = trunc i32 %xor72.32.15 to i8
  store i8 %conv73.32.15, i8* %arrayidx70.15, align 1
  %scevgep20.33.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 33
  %7051 = load i8, i8* %scevgep20.33.15, align 1
  %conv68.33.15 = zext i8 %7051 to i32
  %7052 = load i8, i8* %arrayidx70.15, align 1
  %conv71.33.15 = zext i8 %7052 to i32
  %xor72.33.15 = xor i32 %conv71.33.15, %conv68.33.15
  %conv73.33.15 = trunc i32 %xor72.33.15 to i8
  store i8 %conv73.33.15, i8* %arrayidx70.15, align 1
  %scevgep20.34.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 34
  %7053 = load i8, i8* %scevgep20.34.15, align 1
  %conv68.34.15 = zext i8 %7053 to i32
  %7054 = load i8, i8* %arrayidx70.15, align 1
  %conv71.34.15 = zext i8 %7054 to i32
  %xor72.34.15 = xor i32 %conv71.34.15, %conv68.34.15
  %conv73.34.15 = trunc i32 %xor72.34.15 to i8
  store i8 %conv73.34.15, i8* %arrayidx70.15, align 1
  %scevgep20.35.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 35
  %7055 = load i8, i8* %scevgep20.35.15, align 1
  %conv68.35.15 = zext i8 %7055 to i32
  %7056 = load i8, i8* %arrayidx70.15, align 1
  %conv71.35.15 = zext i8 %7056 to i32
  %xor72.35.15 = xor i32 %conv71.35.15, %conv68.35.15
  %conv73.35.15 = trunc i32 %xor72.35.15 to i8
  store i8 %conv73.35.15, i8* %arrayidx70.15, align 1
  %scevgep20.36.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 36
  %7057 = load i8, i8* %scevgep20.36.15, align 1
  %conv68.36.15 = zext i8 %7057 to i32
  %7058 = load i8, i8* %arrayidx70.15, align 1
  %conv71.36.15 = zext i8 %7058 to i32
  %xor72.36.15 = xor i32 %conv71.36.15, %conv68.36.15
  %conv73.36.15 = trunc i32 %xor72.36.15 to i8
  store i8 %conv73.36.15, i8* %arrayidx70.15, align 1
  %scevgep20.37.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 37
  %7059 = load i8, i8* %scevgep20.37.15, align 1
  %conv68.37.15 = zext i8 %7059 to i32
  %7060 = load i8, i8* %arrayidx70.15, align 1
  %conv71.37.15 = zext i8 %7060 to i32
  %xor72.37.15 = xor i32 %conv71.37.15, %conv68.37.15
  %conv73.37.15 = trunc i32 %xor72.37.15 to i8
  store i8 %conv73.37.15, i8* %arrayidx70.15, align 1
  %scevgep20.38.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 38
  %7061 = load i8, i8* %scevgep20.38.15, align 1
  %conv68.38.15 = zext i8 %7061 to i32
  %7062 = load i8, i8* %arrayidx70.15, align 1
  %conv71.38.15 = zext i8 %7062 to i32
  %xor72.38.15 = xor i32 %conv71.38.15, %conv68.38.15
  %conv73.38.15 = trunc i32 %xor72.38.15 to i8
  store i8 %conv73.38.15, i8* %arrayidx70.15, align 1
  %scevgep20.39.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 39
  %7063 = load i8, i8* %scevgep20.39.15, align 1
  %conv68.39.15 = zext i8 %7063 to i32
  %7064 = load i8, i8* %arrayidx70.15, align 1
  %conv71.39.15 = zext i8 %7064 to i32
  %xor72.39.15 = xor i32 %conv71.39.15, %conv68.39.15
  %conv73.39.15 = trunc i32 %xor72.39.15 to i8
  store i8 %conv73.39.15, i8* %arrayidx70.15, align 1
  %scevgep20.40.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 0, i64 40
  %7065 = load i8, i8* %scevgep20.40.15, align 1
  %conv68.40.15 = zext i8 %7065 to i32
  %7066 = load i8, i8* %arrayidx70.15, align 1
  %conv71.40.15 = zext i8 %7066 to i32
  %xor72.40.15 = xor i32 %conv71.40.15, %conv68.40.15
  %conv73.40.15 = trunc i32 %xor72.40.15 to i8
  store i8 %conv73.40.15, i8* %arrayidx70.15, align 1
  %scevgep19.15 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %6984, i64 0, i64 1, i64 0
  %7067 = bitcast i8* %scevgep19.15 to [41 x [41 x i8]]*
  %arrayidx51.16 = getelementptr inbounds i8, i8* %a, i64 16
  %7068 = load i8, i8* %arrayidx51.16, align 1
  %arrayidx53.16 = getelementptr inbounds i8, i8* %b, i64 16
  %7069 = load i8, i8* %arrayidx53.16, align 1
  %call54.16 = call zeroext i8 @mult(i8 zeroext %7068, i8 zeroext %7069)
  %arrayidx56.16 = getelementptr inbounds i8, i8* %c, i64 16
  store i8 %call54.16, i8* %arrayidx56.16, align 1
  %arrayidx70.16 = getelementptr inbounds i8, i8* %c, i64 16
  %scevgep20.16204 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 0
  %7070 = load i8, i8* %scevgep20.16204, align 1
  %conv68.16205 = zext i8 %7070 to i32
  %7071 = load i8, i8* %arrayidx70.16, align 1
  %conv71.16206 = zext i8 %7071 to i32
  %xor72.16207 = xor i32 %conv71.16206, %conv68.16205
  %conv73.16208 = trunc i32 %xor72.16207 to i8
  store i8 %conv73.16208, i8* %arrayidx70.16, align 1
  %scevgep20.1.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 1
  %7072 = load i8, i8* %scevgep20.1.16, align 1
  %conv68.1.16 = zext i8 %7072 to i32
  %7073 = load i8, i8* %arrayidx70.16, align 1
  %conv71.1.16 = zext i8 %7073 to i32
  %xor72.1.16 = xor i32 %conv71.1.16, %conv68.1.16
  %conv73.1.16 = trunc i32 %xor72.1.16 to i8
  store i8 %conv73.1.16, i8* %arrayidx70.16, align 1
  %scevgep20.2.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 2
  %7074 = load i8, i8* %scevgep20.2.16, align 1
  %conv68.2.16 = zext i8 %7074 to i32
  %7075 = load i8, i8* %arrayidx70.16, align 1
  %conv71.2.16 = zext i8 %7075 to i32
  %xor72.2.16 = xor i32 %conv71.2.16, %conv68.2.16
  %conv73.2.16 = trunc i32 %xor72.2.16 to i8
  store i8 %conv73.2.16, i8* %arrayidx70.16, align 1
  %scevgep20.3.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 3
  %7076 = load i8, i8* %scevgep20.3.16, align 1
  %conv68.3.16 = zext i8 %7076 to i32
  %7077 = load i8, i8* %arrayidx70.16, align 1
  %conv71.3.16 = zext i8 %7077 to i32
  %xor72.3.16 = xor i32 %conv71.3.16, %conv68.3.16
  %conv73.3.16 = trunc i32 %xor72.3.16 to i8
  store i8 %conv73.3.16, i8* %arrayidx70.16, align 1
  %scevgep20.4.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 4
  %7078 = load i8, i8* %scevgep20.4.16, align 1
  %conv68.4.16 = zext i8 %7078 to i32
  %7079 = load i8, i8* %arrayidx70.16, align 1
  %conv71.4.16 = zext i8 %7079 to i32
  %xor72.4.16 = xor i32 %conv71.4.16, %conv68.4.16
  %conv73.4.16 = trunc i32 %xor72.4.16 to i8
  store i8 %conv73.4.16, i8* %arrayidx70.16, align 1
  %scevgep20.5.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 5
  %7080 = load i8, i8* %scevgep20.5.16, align 1
  %conv68.5.16 = zext i8 %7080 to i32
  %7081 = load i8, i8* %arrayidx70.16, align 1
  %conv71.5.16 = zext i8 %7081 to i32
  %xor72.5.16 = xor i32 %conv71.5.16, %conv68.5.16
  %conv73.5.16 = trunc i32 %xor72.5.16 to i8
  store i8 %conv73.5.16, i8* %arrayidx70.16, align 1
  %scevgep20.6.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 6
  %7082 = load i8, i8* %scevgep20.6.16, align 1
  %conv68.6.16 = zext i8 %7082 to i32
  %7083 = load i8, i8* %arrayidx70.16, align 1
  %conv71.6.16 = zext i8 %7083 to i32
  %xor72.6.16 = xor i32 %conv71.6.16, %conv68.6.16
  %conv73.6.16 = trunc i32 %xor72.6.16 to i8
  store i8 %conv73.6.16, i8* %arrayidx70.16, align 1
  %scevgep20.7.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 7
  %7084 = load i8, i8* %scevgep20.7.16, align 1
  %conv68.7.16 = zext i8 %7084 to i32
  %7085 = load i8, i8* %arrayidx70.16, align 1
  %conv71.7.16 = zext i8 %7085 to i32
  %xor72.7.16 = xor i32 %conv71.7.16, %conv68.7.16
  %conv73.7.16 = trunc i32 %xor72.7.16 to i8
  store i8 %conv73.7.16, i8* %arrayidx70.16, align 1
  %scevgep20.8.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 8
  %7086 = load i8, i8* %scevgep20.8.16, align 1
  %conv68.8.16 = zext i8 %7086 to i32
  %7087 = load i8, i8* %arrayidx70.16, align 1
  %conv71.8.16 = zext i8 %7087 to i32
  %xor72.8.16 = xor i32 %conv71.8.16, %conv68.8.16
  %conv73.8.16 = trunc i32 %xor72.8.16 to i8
  store i8 %conv73.8.16, i8* %arrayidx70.16, align 1
  %scevgep20.9.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 9
  %7088 = load i8, i8* %scevgep20.9.16, align 1
  %conv68.9.16 = zext i8 %7088 to i32
  %7089 = load i8, i8* %arrayidx70.16, align 1
  %conv71.9.16 = zext i8 %7089 to i32
  %xor72.9.16 = xor i32 %conv71.9.16, %conv68.9.16
  %conv73.9.16 = trunc i32 %xor72.9.16 to i8
  store i8 %conv73.9.16, i8* %arrayidx70.16, align 1
  %scevgep20.10.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 10
  %7090 = load i8, i8* %scevgep20.10.16, align 1
  %conv68.10.16 = zext i8 %7090 to i32
  %7091 = load i8, i8* %arrayidx70.16, align 1
  %conv71.10.16 = zext i8 %7091 to i32
  %xor72.10.16 = xor i32 %conv71.10.16, %conv68.10.16
  %conv73.10.16 = trunc i32 %xor72.10.16 to i8
  store i8 %conv73.10.16, i8* %arrayidx70.16, align 1
  %scevgep20.11.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 11
  %7092 = load i8, i8* %scevgep20.11.16, align 1
  %conv68.11.16 = zext i8 %7092 to i32
  %7093 = load i8, i8* %arrayidx70.16, align 1
  %conv71.11.16 = zext i8 %7093 to i32
  %xor72.11.16 = xor i32 %conv71.11.16, %conv68.11.16
  %conv73.11.16 = trunc i32 %xor72.11.16 to i8
  store i8 %conv73.11.16, i8* %arrayidx70.16, align 1
  %scevgep20.12.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 12
  %7094 = load i8, i8* %scevgep20.12.16, align 1
  %conv68.12.16 = zext i8 %7094 to i32
  %7095 = load i8, i8* %arrayidx70.16, align 1
  %conv71.12.16 = zext i8 %7095 to i32
  %xor72.12.16 = xor i32 %conv71.12.16, %conv68.12.16
  %conv73.12.16 = trunc i32 %xor72.12.16 to i8
  store i8 %conv73.12.16, i8* %arrayidx70.16, align 1
  %scevgep20.13.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 13
  %7096 = load i8, i8* %scevgep20.13.16, align 1
  %conv68.13.16 = zext i8 %7096 to i32
  %7097 = load i8, i8* %arrayidx70.16, align 1
  %conv71.13.16 = zext i8 %7097 to i32
  %xor72.13.16 = xor i32 %conv71.13.16, %conv68.13.16
  %conv73.13.16 = trunc i32 %xor72.13.16 to i8
  store i8 %conv73.13.16, i8* %arrayidx70.16, align 1
  %scevgep20.14.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 14
  %7098 = load i8, i8* %scevgep20.14.16, align 1
  %conv68.14.16 = zext i8 %7098 to i32
  %7099 = load i8, i8* %arrayidx70.16, align 1
  %conv71.14.16 = zext i8 %7099 to i32
  %xor72.14.16 = xor i32 %conv71.14.16, %conv68.14.16
  %conv73.14.16 = trunc i32 %xor72.14.16 to i8
  store i8 %conv73.14.16, i8* %arrayidx70.16, align 1
  %scevgep20.15.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 15
  %7100 = load i8, i8* %scevgep20.15.16, align 1
  %conv68.15.16 = zext i8 %7100 to i32
  %7101 = load i8, i8* %arrayidx70.16, align 1
  %conv71.15.16 = zext i8 %7101 to i32
  %xor72.15.16 = xor i32 %conv71.15.16, %conv68.15.16
  %conv73.15.16 = trunc i32 %xor72.15.16 to i8
  store i8 %conv73.15.16, i8* %arrayidx70.16, align 1
  %scevgep20.17.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 17
  %7102 = load i8, i8* %scevgep20.17.16, align 1
  %conv68.17.16 = zext i8 %7102 to i32
  %7103 = load i8, i8* %arrayidx70.16, align 1
  %conv71.17.16 = zext i8 %7103 to i32
  %xor72.17.16 = xor i32 %conv71.17.16, %conv68.17.16
  %conv73.17.16 = trunc i32 %xor72.17.16 to i8
  store i8 %conv73.17.16, i8* %arrayidx70.16, align 1
  %scevgep20.18.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 18
  %7104 = load i8, i8* %scevgep20.18.16, align 1
  %conv68.18.16 = zext i8 %7104 to i32
  %7105 = load i8, i8* %arrayidx70.16, align 1
  %conv71.18.16 = zext i8 %7105 to i32
  %xor72.18.16 = xor i32 %conv71.18.16, %conv68.18.16
  %conv73.18.16 = trunc i32 %xor72.18.16 to i8
  store i8 %conv73.18.16, i8* %arrayidx70.16, align 1
  %scevgep20.19.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 19
  %7106 = load i8, i8* %scevgep20.19.16, align 1
  %conv68.19.16 = zext i8 %7106 to i32
  %7107 = load i8, i8* %arrayidx70.16, align 1
  %conv71.19.16 = zext i8 %7107 to i32
  %xor72.19.16 = xor i32 %conv71.19.16, %conv68.19.16
  %conv73.19.16 = trunc i32 %xor72.19.16 to i8
  store i8 %conv73.19.16, i8* %arrayidx70.16, align 1
  %scevgep20.20.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 20
  %7108 = load i8, i8* %scevgep20.20.16, align 1
  %conv68.20.16 = zext i8 %7108 to i32
  %7109 = load i8, i8* %arrayidx70.16, align 1
  %conv71.20.16 = zext i8 %7109 to i32
  %xor72.20.16 = xor i32 %conv71.20.16, %conv68.20.16
  %conv73.20.16 = trunc i32 %xor72.20.16 to i8
  store i8 %conv73.20.16, i8* %arrayidx70.16, align 1
  %scevgep20.21.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 21
  %7110 = load i8, i8* %scevgep20.21.16, align 1
  %conv68.21.16 = zext i8 %7110 to i32
  %7111 = load i8, i8* %arrayidx70.16, align 1
  %conv71.21.16 = zext i8 %7111 to i32
  %xor72.21.16 = xor i32 %conv71.21.16, %conv68.21.16
  %conv73.21.16 = trunc i32 %xor72.21.16 to i8
  store i8 %conv73.21.16, i8* %arrayidx70.16, align 1
  %scevgep20.22.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 22
  %7112 = load i8, i8* %scevgep20.22.16, align 1
  %conv68.22.16 = zext i8 %7112 to i32
  %7113 = load i8, i8* %arrayidx70.16, align 1
  %conv71.22.16 = zext i8 %7113 to i32
  %xor72.22.16 = xor i32 %conv71.22.16, %conv68.22.16
  %conv73.22.16 = trunc i32 %xor72.22.16 to i8
  store i8 %conv73.22.16, i8* %arrayidx70.16, align 1
  %scevgep20.23.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 23
  %7114 = load i8, i8* %scevgep20.23.16, align 1
  %conv68.23.16 = zext i8 %7114 to i32
  %7115 = load i8, i8* %arrayidx70.16, align 1
  %conv71.23.16 = zext i8 %7115 to i32
  %xor72.23.16 = xor i32 %conv71.23.16, %conv68.23.16
  %conv73.23.16 = trunc i32 %xor72.23.16 to i8
  store i8 %conv73.23.16, i8* %arrayidx70.16, align 1
  %scevgep20.24.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 24
  %7116 = load i8, i8* %scevgep20.24.16, align 1
  %conv68.24.16 = zext i8 %7116 to i32
  %7117 = load i8, i8* %arrayidx70.16, align 1
  %conv71.24.16 = zext i8 %7117 to i32
  %xor72.24.16 = xor i32 %conv71.24.16, %conv68.24.16
  %conv73.24.16 = trunc i32 %xor72.24.16 to i8
  store i8 %conv73.24.16, i8* %arrayidx70.16, align 1
  %scevgep20.25.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 25
  %7118 = load i8, i8* %scevgep20.25.16, align 1
  %conv68.25.16 = zext i8 %7118 to i32
  %7119 = load i8, i8* %arrayidx70.16, align 1
  %conv71.25.16 = zext i8 %7119 to i32
  %xor72.25.16 = xor i32 %conv71.25.16, %conv68.25.16
  %conv73.25.16 = trunc i32 %xor72.25.16 to i8
  store i8 %conv73.25.16, i8* %arrayidx70.16, align 1
  %scevgep20.26.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 26
  %7120 = load i8, i8* %scevgep20.26.16, align 1
  %conv68.26.16 = zext i8 %7120 to i32
  %7121 = load i8, i8* %arrayidx70.16, align 1
  %conv71.26.16 = zext i8 %7121 to i32
  %xor72.26.16 = xor i32 %conv71.26.16, %conv68.26.16
  %conv73.26.16 = trunc i32 %xor72.26.16 to i8
  store i8 %conv73.26.16, i8* %arrayidx70.16, align 1
  %scevgep20.27.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 27
  %7122 = load i8, i8* %scevgep20.27.16, align 1
  %conv68.27.16 = zext i8 %7122 to i32
  %7123 = load i8, i8* %arrayidx70.16, align 1
  %conv71.27.16 = zext i8 %7123 to i32
  %xor72.27.16 = xor i32 %conv71.27.16, %conv68.27.16
  %conv73.27.16 = trunc i32 %xor72.27.16 to i8
  store i8 %conv73.27.16, i8* %arrayidx70.16, align 1
  %scevgep20.28.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 28
  %7124 = load i8, i8* %scevgep20.28.16, align 1
  %conv68.28.16 = zext i8 %7124 to i32
  %7125 = load i8, i8* %arrayidx70.16, align 1
  %conv71.28.16 = zext i8 %7125 to i32
  %xor72.28.16 = xor i32 %conv71.28.16, %conv68.28.16
  %conv73.28.16 = trunc i32 %xor72.28.16 to i8
  store i8 %conv73.28.16, i8* %arrayidx70.16, align 1
  %scevgep20.29.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 29
  %7126 = load i8, i8* %scevgep20.29.16, align 1
  %conv68.29.16 = zext i8 %7126 to i32
  %7127 = load i8, i8* %arrayidx70.16, align 1
  %conv71.29.16 = zext i8 %7127 to i32
  %xor72.29.16 = xor i32 %conv71.29.16, %conv68.29.16
  %conv73.29.16 = trunc i32 %xor72.29.16 to i8
  store i8 %conv73.29.16, i8* %arrayidx70.16, align 1
  %scevgep20.30.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 30
  %7128 = load i8, i8* %scevgep20.30.16, align 1
  %conv68.30.16 = zext i8 %7128 to i32
  %7129 = load i8, i8* %arrayidx70.16, align 1
  %conv71.30.16 = zext i8 %7129 to i32
  %xor72.30.16 = xor i32 %conv71.30.16, %conv68.30.16
  %conv73.30.16 = trunc i32 %xor72.30.16 to i8
  store i8 %conv73.30.16, i8* %arrayidx70.16, align 1
  %scevgep20.31.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 31
  %7130 = load i8, i8* %scevgep20.31.16, align 1
  %conv68.31.16 = zext i8 %7130 to i32
  %7131 = load i8, i8* %arrayidx70.16, align 1
  %conv71.31.16 = zext i8 %7131 to i32
  %xor72.31.16 = xor i32 %conv71.31.16, %conv68.31.16
  %conv73.31.16 = trunc i32 %xor72.31.16 to i8
  store i8 %conv73.31.16, i8* %arrayidx70.16, align 1
  %scevgep20.32.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 32
  %7132 = load i8, i8* %scevgep20.32.16, align 1
  %conv68.32.16 = zext i8 %7132 to i32
  %7133 = load i8, i8* %arrayidx70.16, align 1
  %conv71.32.16 = zext i8 %7133 to i32
  %xor72.32.16 = xor i32 %conv71.32.16, %conv68.32.16
  %conv73.32.16 = trunc i32 %xor72.32.16 to i8
  store i8 %conv73.32.16, i8* %arrayidx70.16, align 1
  %scevgep20.33.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 33
  %7134 = load i8, i8* %scevgep20.33.16, align 1
  %conv68.33.16 = zext i8 %7134 to i32
  %7135 = load i8, i8* %arrayidx70.16, align 1
  %conv71.33.16 = zext i8 %7135 to i32
  %xor72.33.16 = xor i32 %conv71.33.16, %conv68.33.16
  %conv73.33.16 = trunc i32 %xor72.33.16 to i8
  store i8 %conv73.33.16, i8* %arrayidx70.16, align 1
  %scevgep20.34.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 34
  %7136 = load i8, i8* %scevgep20.34.16, align 1
  %conv68.34.16 = zext i8 %7136 to i32
  %7137 = load i8, i8* %arrayidx70.16, align 1
  %conv71.34.16 = zext i8 %7137 to i32
  %xor72.34.16 = xor i32 %conv71.34.16, %conv68.34.16
  %conv73.34.16 = trunc i32 %xor72.34.16 to i8
  store i8 %conv73.34.16, i8* %arrayidx70.16, align 1
  %scevgep20.35.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 35
  %7138 = load i8, i8* %scevgep20.35.16, align 1
  %conv68.35.16 = zext i8 %7138 to i32
  %7139 = load i8, i8* %arrayidx70.16, align 1
  %conv71.35.16 = zext i8 %7139 to i32
  %xor72.35.16 = xor i32 %conv71.35.16, %conv68.35.16
  %conv73.35.16 = trunc i32 %xor72.35.16 to i8
  store i8 %conv73.35.16, i8* %arrayidx70.16, align 1
  %scevgep20.36.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 36
  %7140 = load i8, i8* %scevgep20.36.16, align 1
  %conv68.36.16 = zext i8 %7140 to i32
  %7141 = load i8, i8* %arrayidx70.16, align 1
  %conv71.36.16 = zext i8 %7141 to i32
  %xor72.36.16 = xor i32 %conv71.36.16, %conv68.36.16
  %conv73.36.16 = trunc i32 %xor72.36.16 to i8
  store i8 %conv73.36.16, i8* %arrayidx70.16, align 1
  %scevgep20.37.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 37
  %7142 = load i8, i8* %scevgep20.37.16, align 1
  %conv68.37.16 = zext i8 %7142 to i32
  %7143 = load i8, i8* %arrayidx70.16, align 1
  %conv71.37.16 = zext i8 %7143 to i32
  %xor72.37.16 = xor i32 %conv71.37.16, %conv68.37.16
  %conv73.37.16 = trunc i32 %xor72.37.16 to i8
  store i8 %conv73.37.16, i8* %arrayidx70.16, align 1
  %scevgep20.38.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 38
  %7144 = load i8, i8* %scevgep20.38.16, align 1
  %conv68.38.16 = zext i8 %7144 to i32
  %7145 = load i8, i8* %arrayidx70.16, align 1
  %conv71.38.16 = zext i8 %7145 to i32
  %xor72.38.16 = xor i32 %conv71.38.16, %conv68.38.16
  %conv73.38.16 = trunc i32 %xor72.38.16 to i8
  store i8 %conv73.38.16, i8* %arrayidx70.16, align 1
  %scevgep20.39.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 39
  %7146 = load i8, i8* %scevgep20.39.16, align 1
  %conv68.39.16 = zext i8 %7146 to i32
  %7147 = load i8, i8* %arrayidx70.16, align 1
  %conv71.39.16 = zext i8 %7147 to i32
  %xor72.39.16 = xor i32 %conv71.39.16, %conv68.39.16
  %conv73.39.16 = trunc i32 %xor72.39.16 to i8
  store i8 %conv73.39.16, i8* %arrayidx70.16, align 1
  %scevgep20.40.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 0, i64 40
  %7148 = load i8, i8* %scevgep20.40.16, align 1
  %conv68.40.16 = zext i8 %7148 to i32
  %7149 = load i8, i8* %arrayidx70.16, align 1
  %conv71.40.16 = zext i8 %7149 to i32
  %xor72.40.16 = xor i32 %conv71.40.16, %conv68.40.16
  %conv73.40.16 = trunc i32 %xor72.40.16 to i8
  store i8 %conv73.40.16, i8* %arrayidx70.16, align 1
  %scevgep19.16 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7067, i64 0, i64 1, i64 0
  %7150 = bitcast i8* %scevgep19.16 to [41 x [41 x i8]]*
  %arrayidx51.17 = getelementptr inbounds i8, i8* %a, i64 17
  %7151 = load i8, i8* %arrayidx51.17, align 1
  %arrayidx53.17 = getelementptr inbounds i8, i8* %b, i64 17
  %7152 = load i8, i8* %arrayidx53.17, align 1
  %call54.17 = call zeroext i8 @mult(i8 zeroext %7151, i8 zeroext %7152)
  %arrayidx56.17 = getelementptr inbounds i8, i8* %c, i64 17
  store i8 %call54.17, i8* %arrayidx56.17, align 1
  %arrayidx70.17 = getelementptr inbounds i8, i8* %c, i64 17
  %scevgep20.17214 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 0
  %7153 = load i8, i8* %scevgep20.17214, align 1
  %conv68.17215 = zext i8 %7153 to i32
  %7154 = load i8, i8* %arrayidx70.17, align 1
  %conv71.17216 = zext i8 %7154 to i32
  %xor72.17217 = xor i32 %conv71.17216, %conv68.17215
  %conv73.17218 = trunc i32 %xor72.17217 to i8
  store i8 %conv73.17218, i8* %arrayidx70.17, align 1
  %scevgep20.1.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 1
  %7155 = load i8, i8* %scevgep20.1.17, align 1
  %conv68.1.17 = zext i8 %7155 to i32
  %7156 = load i8, i8* %arrayidx70.17, align 1
  %conv71.1.17 = zext i8 %7156 to i32
  %xor72.1.17 = xor i32 %conv71.1.17, %conv68.1.17
  %conv73.1.17 = trunc i32 %xor72.1.17 to i8
  store i8 %conv73.1.17, i8* %arrayidx70.17, align 1
  %scevgep20.2.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 2
  %7157 = load i8, i8* %scevgep20.2.17, align 1
  %conv68.2.17 = zext i8 %7157 to i32
  %7158 = load i8, i8* %arrayidx70.17, align 1
  %conv71.2.17 = zext i8 %7158 to i32
  %xor72.2.17 = xor i32 %conv71.2.17, %conv68.2.17
  %conv73.2.17 = trunc i32 %xor72.2.17 to i8
  store i8 %conv73.2.17, i8* %arrayidx70.17, align 1
  %scevgep20.3.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 3
  %7159 = load i8, i8* %scevgep20.3.17, align 1
  %conv68.3.17 = zext i8 %7159 to i32
  %7160 = load i8, i8* %arrayidx70.17, align 1
  %conv71.3.17 = zext i8 %7160 to i32
  %xor72.3.17 = xor i32 %conv71.3.17, %conv68.3.17
  %conv73.3.17 = trunc i32 %xor72.3.17 to i8
  store i8 %conv73.3.17, i8* %arrayidx70.17, align 1
  %scevgep20.4.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 4
  %7161 = load i8, i8* %scevgep20.4.17, align 1
  %conv68.4.17 = zext i8 %7161 to i32
  %7162 = load i8, i8* %arrayidx70.17, align 1
  %conv71.4.17 = zext i8 %7162 to i32
  %xor72.4.17 = xor i32 %conv71.4.17, %conv68.4.17
  %conv73.4.17 = trunc i32 %xor72.4.17 to i8
  store i8 %conv73.4.17, i8* %arrayidx70.17, align 1
  %scevgep20.5.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 5
  %7163 = load i8, i8* %scevgep20.5.17, align 1
  %conv68.5.17 = zext i8 %7163 to i32
  %7164 = load i8, i8* %arrayidx70.17, align 1
  %conv71.5.17 = zext i8 %7164 to i32
  %xor72.5.17 = xor i32 %conv71.5.17, %conv68.5.17
  %conv73.5.17 = trunc i32 %xor72.5.17 to i8
  store i8 %conv73.5.17, i8* %arrayidx70.17, align 1
  %scevgep20.6.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 6
  %7165 = load i8, i8* %scevgep20.6.17, align 1
  %conv68.6.17 = zext i8 %7165 to i32
  %7166 = load i8, i8* %arrayidx70.17, align 1
  %conv71.6.17 = zext i8 %7166 to i32
  %xor72.6.17 = xor i32 %conv71.6.17, %conv68.6.17
  %conv73.6.17 = trunc i32 %xor72.6.17 to i8
  store i8 %conv73.6.17, i8* %arrayidx70.17, align 1
  %scevgep20.7.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 7
  %7167 = load i8, i8* %scevgep20.7.17, align 1
  %conv68.7.17 = zext i8 %7167 to i32
  %7168 = load i8, i8* %arrayidx70.17, align 1
  %conv71.7.17 = zext i8 %7168 to i32
  %xor72.7.17 = xor i32 %conv71.7.17, %conv68.7.17
  %conv73.7.17 = trunc i32 %xor72.7.17 to i8
  store i8 %conv73.7.17, i8* %arrayidx70.17, align 1
  %scevgep20.8.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 8
  %7169 = load i8, i8* %scevgep20.8.17, align 1
  %conv68.8.17 = zext i8 %7169 to i32
  %7170 = load i8, i8* %arrayidx70.17, align 1
  %conv71.8.17 = zext i8 %7170 to i32
  %xor72.8.17 = xor i32 %conv71.8.17, %conv68.8.17
  %conv73.8.17 = trunc i32 %xor72.8.17 to i8
  store i8 %conv73.8.17, i8* %arrayidx70.17, align 1
  %scevgep20.9.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 9
  %7171 = load i8, i8* %scevgep20.9.17, align 1
  %conv68.9.17 = zext i8 %7171 to i32
  %7172 = load i8, i8* %arrayidx70.17, align 1
  %conv71.9.17 = zext i8 %7172 to i32
  %xor72.9.17 = xor i32 %conv71.9.17, %conv68.9.17
  %conv73.9.17 = trunc i32 %xor72.9.17 to i8
  store i8 %conv73.9.17, i8* %arrayidx70.17, align 1
  %scevgep20.10.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 10
  %7173 = load i8, i8* %scevgep20.10.17, align 1
  %conv68.10.17 = zext i8 %7173 to i32
  %7174 = load i8, i8* %arrayidx70.17, align 1
  %conv71.10.17 = zext i8 %7174 to i32
  %xor72.10.17 = xor i32 %conv71.10.17, %conv68.10.17
  %conv73.10.17 = trunc i32 %xor72.10.17 to i8
  store i8 %conv73.10.17, i8* %arrayidx70.17, align 1
  %scevgep20.11.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 11
  %7175 = load i8, i8* %scevgep20.11.17, align 1
  %conv68.11.17 = zext i8 %7175 to i32
  %7176 = load i8, i8* %arrayidx70.17, align 1
  %conv71.11.17 = zext i8 %7176 to i32
  %xor72.11.17 = xor i32 %conv71.11.17, %conv68.11.17
  %conv73.11.17 = trunc i32 %xor72.11.17 to i8
  store i8 %conv73.11.17, i8* %arrayidx70.17, align 1
  %scevgep20.12.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 12
  %7177 = load i8, i8* %scevgep20.12.17, align 1
  %conv68.12.17 = zext i8 %7177 to i32
  %7178 = load i8, i8* %arrayidx70.17, align 1
  %conv71.12.17 = zext i8 %7178 to i32
  %xor72.12.17 = xor i32 %conv71.12.17, %conv68.12.17
  %conv73.12.17 = trunc i32 %xor72.12.17 to i8
  store i8 %conv73.12.17, i8* %arrayidx70.17, align 1
  %scevgep20.13.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 13
  %7179 = load i8, i8* %scevgep20.13.17, align 1
  %conv68.13.17 = zext i8 %7179 to i32
  %7180 = load i8, i8* %arrayidx70.17, align 1
  %conv71.13.17 = zext i8 %7180 to i32
  %xor72.13.17 = xor i32 %conv71.13.17, %conv68.13.17
  %conv73.13.17 = trunc i32 %xor72.13.17 to i8
  store i8 %conv73.13.17, i8* %arrayidx70.17, align 1
  %scevgep20.14.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 14
  %7181 = load i8, i8* %scevgep20.14.17, align 1
  %conv68.14.17 = zext i8 %7181 to i32
  %7182 = load i8, i8* %arrayidx70.17, align 1
  %conv71.14.17 = zext i8 %7182 to i32
  %xor72.14.17 = xor i32 %conv71.14.17, %conv68.14.17
  %conv73.14.17 = trunc i32 %xor72.14.17 to i8
  store i8 %conv73.14.17, i8* %arrayidx70.17, align 1
  %scevgep20.15.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 15
  %7183 = load i8, i8* %scevgep20.15.17, align 1
  %conv68.15.17 = zext i8 %7183 to i32
  %7184 = load i8, i8* %arrayidx70.17, align 1
  %conv71.15.17 = zext i8 %7184 to i32
  %xor72.15.17 = xor i32 %conv71.15.17, %conv68.15.17
  %conv73.15.17 = trunc i32 %xor72.15.17 to i8
  store i8 %conv73.15.17, i8* %arrayidx70.17, align 1
  %scevgep20.16.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 16
  %7185 = load i8, i8* %scevgep20.16.17, align 1
  %conv68.16.17 = zext i8 %7185 to i32
  %7186 = load i8, i8* %arrayidx70.17, align 1
  %conv71.16.17 = zext i8 %7186 to i32
  %xor72.16.17 = xor i32 %conv71.16.17, %conv68.16.17
  %conv73.16.17 = trunc i32 %xor72.16.17 to i8
  store i8 %conv73.16.17, i8* %arrayidx70.17, align 1
  %scevgep20.18.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 18
  %7187 = load i8, i8* %scevgep20.18.17, align 1
  %conv68.18.17 = zext i8 %7187 to i32
  %7188 = load i8, i8* %arrayidx70.17, align 1
  %conv71.18.17 = zext i8 %7188 to i32
  %xor72.18.17 = xor i32 %conv71.18.17, %conv68.18.17
  %conv73.18.17 = trunc i32 %xor72.18.17 to i8
  store i8 %conv73.18.17, i8* %arrayidx70.17, align 1
  %scevgep20.19.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 19
  %7189 = load i8, i8* %scevgep20.19.17, align 1
  %conv68.19.17 = zext i8 %7189 to i32
  %7190 = load i8, i8* %arrayidx70.17, align 1
  %conv71.19.17 = zext i8 %7190 to i32
  %xor72.19.17 = xor i32 %conv71.19.17, %conv68.19.17
  %conv73.19.17 = trunc i32 %xor72.19.17 to i8
  store i8 %conv73.19.17, i8* %arrayidx70.17, align 1
  %scevgep20.20.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 20
  %7191 = load i8, i8* %scevgep20.20.17, align 1
  %conv68.20.17 = zext i8 %7191 to i32
  %7192 = load i8, i8* %arrayidx70.17, align 1
  %conv71.20.17 = zext i8 %7192 to i32
  %xor72.20.17 = xor i32 %conv71.20.17, %conv68.20.17
  %conv73.20.17 = trunc i32 %xor72.20.17 to i8
  store i8 %conv73.20.17, i8* %arrayidx70.17, align 1
  %scevgep20.21.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 21
  %7193 = load i8, i8* %scevgep20.21.17, align 1
  %conv68.21.17 = zext i8 %7193 to i32
  %7194 = load i8, i8* %arrayidx70.17, align 1
  %conv71.21.17 = zext i8 %7194 to i32
  %xor72.21.17 = xor i32 %conv71.21.17, %conv68.21.17
  %conv73.21.17 = trunc i32 %xor72.21.17 to i8
  store i8 %conv73.21.17, i8* %arrayidx70.17, align 1
  %scevgep20.22.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 22
  %7195 = load i8, i8* %scevgep20.22.17, align 1
  %conv68.22.17 = zext i8 %7195 to i32
  %7196 = load i8, i8* %arrayidx70.17, align 1
  %conv71.22.17 = zext i8 %7196 to i32
  %xor72.22.17 = xor i32 %conv71.22.17, %conv68.22.17
  %conv73.22.17 = trunc i32 %xor72.22.17 to i8
  store i8 %conv73.22.17, i8* %arrayidx70.17, align 1
  %scevgep20.23.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 23
  %7197 = load i8, i8* %scevgep20.23.17, align 1
  %conv68.23.17 = zext i8 %7197 to i32
  %7198 = load i8, i8* %arrayidx70.17, align 1
  %conv71.23.17 = zext i8 %7198 to i32
  %xor72.23.17 = xor i32 %conv71.23.17, %conv68.23.17
  %conv73.23.17 = trunc i32 %xor72.23.17 to i8
  store i8 %conv73.23.17, i8* %arrayidx70.17, align 1
  %scevgep20.24.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 24
  %7199 = load i8, i8* %scevgep20.24.17, align 1
  %conv68.24.17 = zext i8 %7199 to i32
  %7200 = load i8, i8* %arrayidx70.17, align 1
  %conv71.24.17 = zext i8 %7200 to i32
  %xor72.24.17 = xor i32 %conv71.24.17, %conv68.24.17
  %conv73.24.17 = trunc i32 %xor72.24.17 to i8
  store i8 %conv73.24.17, i8* %arrayidx70.17, align 1
  %scevgep20.25.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 25
  %7201 = load i8, i8* %scevgep20.25.17, align 1
  %conv68.25.17 = zext i8 %7201 to i32
  %7202 = load i8, i8* %arrayidx70.17, align 1
  %conv71.25.17 = zext i8 %7202 to i32
  %xor72.25.17 = xor i32 %conv71.25.17, %conv68.25.17
  %conv73.25.17 = trunc i32 %xor72.25.17 to i8
  store i8 %conv73.25.17, i8* %arrayidx70.17, align 1
  %scevgep20.26.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 26
  %7203 = load i8, i8* %scevgep20.26.17, align 1
  %conv68.26.17 = zext i8 %7203 to i32
  %7204 = load i8, i8* %arrayidx70.17, align 1
  %conv71.26.17 = zext i8 %7204 to i32
  %xor72.26.17 = xor i32 %conv71.26.17, %conv68.26.17
  %conv73.26.17 = trunc i32 %xor72.26.17 to i8
  store i8 %conv73.26.17, i8* %arrayidx70.17, align 1
  %scevgep20.27.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 27
  %7205 = load i8, i8* %scevgep20.27.17, align 1
  %conv68.27.17 = zext i8 %7205 to i32
  %7206 = load i8, i8* %arrayidx70.17, align 1
  %conv71.27.17 = zext i8 %7206 to i32
  %xor72.27.17 = xor i32 %conv71.27.17, %conv68.27.17
  %conv73.27.17 = trunc i32 %xor72.27.17 to i8
  store i8 %conv73.27.17, i8* %arrayidx70.17, align 1
  %scevgep20.28.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 28
  %7207 = load i8, i8* %scevgep20.28.17, align 1
  %conv68.28.17 = zext i8 %7207 to i32
  %7208 = load i8, i8* %arrayidx70.17, align 1
  %conv71.28.17 = zext i8 %7208 to i32
  %xor72.28.17 = xor i32 %conv71.28.17, %conv68.28.17
  %conv73.28.17 = trunc i32 %xor72.28.17 to i8
  store i8 %conv73.28.17, i8* %arrayidx70.17, align 1
  %scevgep20.29.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 29
  %7209 = load i8, i8* %scevgep20.29.17, align 1
  %conv68.29.17 = zext i8 %7209 to i32
  %7210 = load i8, i8* %arrayidx70.17, align 1
  %conv71.29.17 = zext i8 %7210 to i32
  %xor72.29.17 = xor i32 %conv71.29.17, %conv68.29.17
  %conv73.29.17 = trunc i32 %xor72.29.17 to i8
  store i8 %conv73.29.17, i8* %arrayidx70.17, align 1
  %scevgep20.30.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 30
  %7211 = load i8, i8* %scevgep20.30.17, align 1
  %conv68.30.17 = zext i8 %7211 to i32
  %7212 = load i8, i8* %arrayidx70.17, align 1
  %conv71.30.17 = zext i8 %7212 to i32
  %xor72.30.17 = xor i32 %conv71.30.17, %conv68.30.17
  %conv73.30.17 = trunc i32 %xor72.30.17 to i8
  store i8 %conv73.30.17, i8* %arrayidx70.17, align 1
  %scevgep20.31.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 31
  %7213 = load i8, i8* %scevgep20.31.17, align 1
  %conv68.31.17 = zext i8 %7213 to i32
  %7214 = load i8, i8* %arrayidx70.17, align 1
  %conv71.31.17 = zext i8 %7214 to i32
  %xor72.31.17 = xor i32 %conv71.31.17, %conv68.31.17
  %conv73.31.17 = trunc i32 %xor72.31.17 to i8
  store i8 %conv73.31.17, i8* %arrayidx70.17, align 1
  %scevgep20.32.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 32
  %7215 = load i8, i8* %scevgep20.32.17, align 1
  %conv68.32.17 = zext i8 %7215 to i32
  %7216 = load i8, i8* %arrayidx70.17, align 1
  %conv71.32.17 = zext i8 %7216 to i32
  %xor72.32.17 = xor i32 %conv71.32.17, %conv68.32.17
  %conv73.32.17 = trunc i32 %xor72.32.17 to i8
  store i8 %conv73.32.17, i8* %arrayidx70.17, align 1
  %scevgep20.33.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 33
  %7217 = load i8, i8* %scevgep20.33.17, align 1
  %conv68.33.17 = zext i8 %7217 to i32
  %7218 = load i8, i8* %arrayidx70.17, align 1
  %conv71.33.17 = zext i8 %7218 to i32
  %xor72.33.17 = xor i32 %conv71.33.17, %conv68.33.17
  %conv73.33.17 = trunc i32 %xor72.33.17 to i8
  store i8 %conv73.33.17, i8* %arrayidx70.17, align 1
  %scevgep20.34.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 34
  %7219 = load i8, i8* %scevgep20.34.17, align 1
  %conv68.34.17 = zext i8 %7219 to i32
  %7220 = load i8, i8* %arrayidx70.17, align 1
  %conv71.34.17 = zext i8 %7220 to i32
  %xor72.34.17 = xor i32 %conv71.34.17, %conv68.34.17
  %conv73.34.17 = trunc i32 %xor72.34.17 to i8
  store i8 %conv73.34.17, i8* %arrayidx70.17, align 1
  %scevgep20.35.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 35
  %7221 = load i8, i8* %scevgep20.35.17, align 1
  %conv68.35.17 = zext i8 %7221 to i32
  %7222 = load i8, i8* %arrayidx70.17, align 1
  %conv71.35.17 = zext i8 %7222 to i32
  %xor72.35.17 = xor i32 %conv71.35.17, %conv68.35.17
  %conv73.35.17 = trunc i32 %xor72.35.17 to i8
  store i8 %conv73.35.17, i8* %arrayidx70.17, align 1
  %scevgep20.36.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 36
  %7223 = load i8, i8* %scevgep20.36.17, align 1
  %conv68.36.17 = zext i8 %7223 to i32
  %7224 = load i8, i8* %arrayidx70.17, align 1
  %conv71.36.17 = zext i8 %7224 to i32
  %xor72.36.17 = xor i32 %conv71.36.17, %conv68.36.17
  %conv73.36.17 = trunc i32 %xor72.36.17 to i8
  store i8 %conv73.36.17, i8* %arrayidx70.17, align 1
  %scevgep20.37.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 37
  %7225 = load i8, i8* %scevgep20.37.17, align 1
  %conv68.37.17 = zext i8 %7225 to i32
  %7226 = load i8, i8* %arrayidx70.17, align 1
  %conv71.37.17 = zext i8 %7226 to i32
  %xor72.37.17 = xor i32 %conv71.37.17, %conv68.37.17
  %conv73.37.17 = trunc i32 %xor72.37.17 to i8
  store i8 %conv73.37.17, i8* %arrayidx70.17, align 1
  %scevgep20.38.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 38
  %7227 = load i8, i8* %scevgep20.38.17, align 1
  %conv68.38.17 = zext i8 %7227 to i32
  %7228 = load i8, i8* %arrayidx70.17, align 1
  %conv71.38.17 = zext i8 %7228 to i32
  %xor72.38.17 = xor i32 %conv71.38.17, %conv68.38.17
  %conv73.38.17 = trunc i32 %xor72.38.17 to i8
  store i8 %conv73.38.17, i8* %arrayidx70.17, align 1
  %scevgep20.39.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 39
  %7229 = load i8, i8* %scevgep20.39.17, align 1
  %conv68.39.17 = zext i8 %7229 to i32
  %7230 = load i8, i8* %arrayidx70.17, align 1
  %conv71.39.17 = zext i8 %7230 to i32
  %xor72.39.17 = xor i32 %conv71.39.17, %conv68.39.17
  %conv73.39.17 = trunc i32 %xor72.39.17 to i8
  store i8 %conv73.39.17, i8* %arrayidx70.17, align 1
  %scevgep20.40.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 0, i64 40
  %7231 = load i8, i8* %scevgep20.40.17, align 1
  %conv68.40.17 = zext i8 %7231 to i32
  %7232 = load i8, i8* %arrayidx70.17, align 1
  %conv71.40.17 = zext i8 %7232 to i32
  %xor72.40.17 = xor i32 %conv71.40.17, %conv68.40.17
  %conv73.40.17 = trunc i32 %xor72.40.17 to i8
  store i8 %conv73.40.17, i8* %arrayidx70.17, align 1
  %scevgep19.17 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7150, i64 0, i64 1, i64 0
  %7233 = bitcast i8* %scevgep19.17 to [41 x [41 x i8]]*
  %arrayidx51.18 = getelementptr inbounds i8, i8* %a, i64 18
  %7234 = load i8, i8* %arrayidx51.18, align 1
  %arrayidx53.18 = getelementptr inbounds i8, i8* %b, i64 18
  %7235 = load i8, i8* %arrayidx53.18, align 1
  %call54.18 = call zeroext i8 @mult(i8 zeroext %7234, i8 zeroext %7235)
  %arrayidx56.18 = getelementptr inbounds i8, i8* %c, i64 18
  store i8 %call54.18, i8* %arrayidx56.18, align 1
  %arrayidx70.18 = getelementptr inbounds i8, i8* %c, i64 18
  %scevgep20.18224 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 0
  %7236 = load i8, i8* %scevgep20.18224, align 1
  %conv68.18225 = zext i8 %7236 to i32
  %7237 = load i8, i8* %arrayidx70.18, align 1
  %conv71.18226 = zext i8 %7237 to i32
  %xor72.18227 = xor i32 %conv71.18226, %conv68.18225
  %conv73.18228 = trunc i32 %xor72.18227 to i8
  store i8 %conv73.18228, i8* %arrayidx70.18, align 1
  %scevgep20.1.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 1
  %7238 = load i8, i8* %scevgep20.1.18, align 1
  %conv68.1.18 = zext i8 %7238 to i32
  %7239 = load i8, i8* %arrayidx70.18, align 1
  %conv71.1.18 = zext i8 %7239 to i32
  %xor72.1.18 = xor i32 %conv71.1.18, %conv68.1.18
  %conv73.1.18 = trunc i32 %xor72.1.18 to i8
  store i8 %conv73.1.18, i8* %arrayidx70.18, align 1
  %scevgep20.2.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 2
  %7240 = load i8, i8* %scevgep20.2.18, align 1
  %conv68.2.18 = zext i8 %7240 to i32
  %7241 = load i8, i8* %arrayidx70.18, align 1
  %conv71.2.18 = zext i8 %7241 to i32
  %xor72.2.18 = xor i32 %conv71.2.18, %conv68.2.18
  %conv73.2.18 = trunc i32 %xor72.2.18 to i8
  store i8 %conv73.2.18, i8* %arrayidx70.18, align 1
  %scevgep20.3.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 3
  %7242 = load i8, i8* %scevgep20.3.18, align 1
  %conv68.3.18 = zext i8 %7242 to i32
  %7243 = load i8, i8* %arrayidx70.18, align 1
  %conv71.3.18 = zext i8 %7243 to i32
  %xor72.3.18 = xor i32 %conv71.3.18, %conv68.3.18
  %conv73.3.18 = trunc i32 %xor72.3.18 to i8
  store i8 %conv73.3.18, i8* %arrayidx70.18, align 1
  %scevgep20.4.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 4
  %7244 = load i8, i8* %scevgep20.4.18, align 1
  %conv68.4.18 = zext i8 %7244 to i32
  %7245 = load i8, i8* %arrayidx70.18, align 1
  %conv71.4.18 = zext i8 %7245 to i32
  %xor72.4.18 = xor i32 %conv71.4.18, %conv68.4.18
  %conv73.4.18 = trunc i32 %xor72.4.18 to i8
  store i8 %conv73.4.18, i8* %arrayidx70.18, align 1
  %scevgep20.5.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 5
  %7246 = load i8, i8* %scevgep20.5.18, align 1
  %conv68.5.18 = zext i8 %7246 to i32
  %7247 = load i8, i8* %arrayidx70.18, align 1
  %conv71.5.18 = zext i8 %7247 to i32
  %xor72.5.18 = xor i32 %conv71.5.18, %conv68.5.18
  %conv73.5.18 = trunc i32 %xor72.5.18 to i8
  store i8 %conv73.5.18, i8* %arrayidx70.18, align 1
  %scevgep20.6.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 6
  %7248 = load i8, i8* %scevgep20.6.18, align 1
  %conv68.6.18 = zext i8 %7248 to i32
  %7249 = load i8, i8* %arrayidx70.18, align 1
  %conv71.6.18 = zext i8 %7249 to i32
  %xor72.6.18 = xor i32 %conv71.6.18, %conv68.6.18
  %conv73.6.18 = trunc i32 %xor72.6.18 to i8
  store i8 %conv73.6.18, i8* %arrayidx70.18, align 1
  %scevgep20.7.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 7
  %7250 = load i8, i8* %scevgep20.7.18, align 1
  %conv68.7.18 = zext i8 %7250 to i32
  %7251 = load i8, i8* %arrayidx70.18, align 1
  %conv71.7.18 = zext i8 %7251 to i32
  %xor72.7.18 = xor i32 %conv71.7.18, %conv68.7.18
  %conv73.7.18 = trunc i32 %xor72.7.18 to i8
  store i8 %conv73.7.18, i8* %arrayidx70.18, align 1
  %scevgep20.8.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 8
  %7252 = load i8, i8* %scevgep20.8.18, align 1
  %conv68.8.18 = zext i8 %7252 to i32
  %7253 = load i8, i8* %arrayidx70.18, align 1
  %conv71.8.18 = zext i8 %7253 to i32
  %xor72.8.18 = xor i32 %conv71.8.18, %conv68.8.18
  %conv73.8.18 = trunc i32 %xor72.8.18 to i8
  store i8 %conv73.8.18, i8* %arrayidx70.18, align 1
  %scevgep20.9.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 9
  %7254 = load i8, i8* %scevgep20.9.18, align 1
  %conv68.9.18 = zext i8 %7254 to i32
  %7255 = load i8, i8* %arrayidx70.18, align 1
  %conv71.9.18 = zext i8 %7255 to i32
  %xor72.9.18 = xor i32 %conv71.9.18, %conv68.9.18
  %conv73.9.18 = trunc i32 %xor72.9.18 to i8
  store i8 %conv73.9.18, i8* %arrayidx70.18, align 1
  %scevgep20.10.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 10
  %7256 = load i8, i8* %scevgep20.10.18, align 1
  %conv68.10.18 = zext i8 %7256 to i32
  %7257 = load i8, i8* %arrayidx70.18, align 1
  %conv71.10.18 = zext i8 %7257 to i32
  %xor72.10.18 = xor i32 %conv71.10.18, %conv68.10.18
  %conv73.10.18 = trunc i32 %xor72.10.18 to i8
  store i8 %conv73.10.18, i8* %arrayidx70.18, align 1
  %scevgep20.11.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 11
  %7258 = load i8, i8* %scevgep20.11.18, align 1
  %conv68.11.18 = zext i8 %7258 to i32
  %7259 = load i8, i8* %arrayidx70.18, align 1
  %conv71.11.18 = zext i8 %7259 to i32
  %xor72.11.18 = xor i32 %conv71.11.18, %conv68.11.18
  %conv73.11.18 = trunc i32 %xor72.11.18 to i8
  store i8 %conv73.11.18, i8* %arrayidx70.18, align 1
  %scevgep20.12.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 12
  %7260 = load i8, i8* %scevgep20.12.18, align 1
  %conv68.12.18 = zext i8 %7260 to i32
  %7261 = load i8, i8* %arrayidx70.18, align 1
  %conv71.12.18 = zext i8 %7261 to i32
  %xor72.12.18 = xor i32 %conv71.12.18, %conv68.12.18
  %conv73.12.18 = trunc i32 %xor72.12.18 to i8
  store i8 %conv73.12.18, i8* %arrayidx70.18, align 1
  %scevgep20.13.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 13
  %7262 = load i8, i8* %scevgep20.13.18, align 1
  %conv68.13.18 = zext i8 %7262 to i32
  %7263 = load i8, i8* %arrayidx70.18, align 1
  %conv71.13.18 = zext i8 %7263 to i32
  %xor72.13.18 = xor i32 %conv71.13.18, %conv68.13.18
  %conv73.13.18 = trunc i32 %xor72.13.18 to i8
  store i8 %conv73.13.18, i8* %arrayidx70.18, align 1
  %scevgep20.14.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 14
  %7264 = load i8, i8* %scevgep20.14.18, align 1
  %conv68.14.18 = zext i8 %7264 to i32
  %7265 = load i8, i8* %arrayidx70.18, align 1
  %conv71.14.18 = zext i8 %7265 to i32
  %xor72.14.18 = xor i32 %conv71.14.18, %conv68.14.18
  %conv73.14.18 = trunc i32 %xor72.14.18 to i8
  store i8 %conv73.14.18, i8* %arrayidx70.18, align 1
  %scevgep20.15.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 15
  %7266 = load i8, i8* %scevgep20.15.18, align 1
  %conv68.15.18 = zext i8 %7266 to i32
  %7267 = load i8, i8* %arrayidx70.18, align 1
  %conv71.15.18 = zext i8 %7267 to i32
  %xor72.15.18 = xor i32 %conv71.15.18, %conv68.15.18
  %conv73.15.18 = trunc i32 %xor72.15.18 to i8
  store i8 %conv73.15.18, i8* %arrayidx70.18, align 1
  %scevgep20.16.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 16
  %7268 = load i8, i8* %scevgep20.16.18, align 1
  %conv68.16.18 = zext i8 %7268 to i32
  %7269 = load i8, i8* %arrayidx70.18, align 1
  %conv71.16.18 = zext i8 %7269 to i32
  %xor72.16.18 = xor i32 %conv71.16.18, %conv68.16.18
  %conv73.16.18 = trunc i32 %xor72.16.18 to i8
  store i8 %conv73.16.18, i8* %arrayidx70.18, align 1
  %scevgep20.17.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 17
  %7270 = load i8, i8* %scevgep20.17.18, align 1
  %conv68.17.18 = zext i8 %7270 to i32
  %7271 = load i8, i8* %arrayidx70.18, align 1
  %conv71.17.18 = zext i8 %7271 to i32
  %xor72.17.18 = xor i32 %conv71.17.18, %conv68.17.18
  %conv73.17.18 = trunc i32 %xor72.17.18 to i8
  store i8 %conv73.17.18, i8* %arrayidx70.18, align 1
  %scevgep20.19.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 19
  %7272 = load i8, i8* %scevgep20.19.18, align 1
  %conv68.19.18 = zext i8 %7272 to i32
  %7273 = load i8, i8* %arrayidx70.18, align 1
  %conv71.19.18 = zext i8 %7273 to i32
  %xor72.19.18 = xor i32 %conv71.19.18, %conv68.19.18
  %conv73.19.18 = trunc i32 %xor72.19.18 to i8
  store i8 %conv73.19.18, i8* %arrayidx70.18, align 1
  %scevgep20.20.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 20
  %7274 = load i8, i8* %scevgep20.20.18, align 1
  %conv68.20.18 = zext i8 %7274 to i32
  %7275 = load i8, i8* %arrayidx70.18, align 1
  %conv71.20.18 = zext i8 %7275 to i32
  %xor72.20.18 = xor i32 %conv71.20.18, %conv68.20.18
  %conv73.20.18 = trunc i32 %xor72.20.18 to i8
  store i8 %conv73.20.18, i8* %arrayidx70.18, align 1
  %scevgep20.21.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 21
  %7276 = load i8, i8* %scevgep20.21.18, align 1
  %conv68.21.18 = zext i8 %7276 to i32
  %7277 = load i8, i8* %arrayidx70.18, align 1
  %conv71.21.18 = zext i8 %7277 to i32
  %xor72.21.18 = xor i32 %conv71.21.18, %conv68.21.18
  %conv73.21.18 = trunc i32 %xor72.21.18 to i8
  store i8 %conv73.21.18, i8* %arrayidx70.18, align 1
  %scevgep20.22.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 22
  %7278 = load i8, i8* %scevgep20.22.18, align 1
  %conv68.22.18 = zext i8 %7278 to i32
  %7279 = load i8, i8* %arrayidx70.18, align 1
  %conv71.22.18 = zext i8 %7279 to i32
  %xor72.22.18 = xor i32 %conv71.22.18, %conv68.22.18
  %conv73.22.18 = trunc i32 %xor72.22.18 to i8
  store i8 %conv73.22.18, i8* %arrayidx70.18, align 1
  %scevgep20.23.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 23
  %7280 = load i8, i8* %scevgep20.23.18, align 1
  %conv68.23.18 = zext i8 %7280 to i32
  %7281 = load i8, i8* %arrayidx70.18, align 1
  %conv71.23.18 = zext i8 %7281 to i32
  %xor72.23.18 = xor i32 %conv71.23.18, %conv68.23.18
  %conv73.23.18 = trunc i32 %xor72.23.18 to i8
  store i8 %conv73.23.18, i8* %arrayidx70.18, align 1
  %scevgep20.24.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 24
  %7282 = load i8, i8* %scevgep20.24.18, align 1
  %conv68.24.18 = zext i8 %7282 to i32
  %7283 = load i8, i8* %arrayidx70.18, align 1
  %conv71.24.18 = zext i8 %7283 to i32
  %xor72.24.18 = xor i32 %conv71.24.18, %conv68.24.18
  %conv73.24.18 = trunc i32 %xor72.24.18 to i8
  store i8 %conv73.24.18, i8* %arrayidx70.18, align 1
  %scevgep20.25.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 25
  %7284 = load i8, i8* %scevgep20.25.18, align 1
  %conv68.25.18 = zext i8 %7284 to i32
  %7285 = load i8, i8* %arrayidx70.18, align 1
  %conv71.25.18 = zext i8 %7285 to i32
  %xor72.25.18 = xor i32 %conv71.25.18, %conv68.25.18
  %conv73.25.18 = trunc i32 %xor72.25.18 to i8
  store i8 %conv73.25.18, i8* %arrayidx70.18, align 1
  %scevgep20.26.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 26
  %7286 = load i8, i8* %scevgep20.26.18, align 1
  %conv68.26.18 = zext i8 %7286 to i32
  %7287 = load i8, i8* %arrayidx70.18, align 1
  %conv71.26.18 = zext i8 %7287 to i32
  %xor72.26.18 = xor i32 %conv71.26.18, %conv68.26.18
  %conv73.26.18 = trunc i32 %xor72.26.18 to i8
  store i8 %conv73.26.18, i8* %arrayidx70.18, align 1
  %scevgep20.27.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 27
  %7288 = load i8, i8* %scevgep20.27.18, align 1
  %conv68.27.18 = zext i8 %7288 to i32
  %7289 = load i8, i8* %arrayidx70.18, align 1
  %conv71.27.18 = zext i8 %7289 to i32
  %xor72.27.18 = xor i32 %conv71.27.18, %conv68.27.18
  %conv73.27.18 = trunc i32 %xor72.27.18 to i8
  store i8 %conv73.27.18, i8* %arrayidx70.18, align 1
  %scevgep20.28.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 28
  %7290 = load i8, i8* %scevgep20.28.18, align 1
  %conv68.28.18 = zext i8 %7290 to i32
  %7291 = load i8, i8* %arrayidx70.18, align 1
  %conv71.28.18 = zext i8 %7291 to i32
  %xor72.28.18 = xor i32 %conv71.28.18, %conv68.28.18
  %conv73.28.18 = trunc i32 %xor72.28.18 to i8
  store i8 %conv73.28.18, i8* %arrayidx70.18, align 1
  %scevgep20.29.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 29
  %7292 = load i8, i8* %scevgep20.29.18, align 1
  %conv68.29.18 = zext i8 %7292 to i32
  %7293 = load i8, i8* %arrayidx70.18, align 1
  %conv71.29.18 = zext i8 %7293 to i32
  %xor72.29.18 = xor i32 %conv71.29.18, %conv68.29.18
  %conv73.29.18 = trunc i32 %xor72.29.18 to i8
  store i8 %conv73.29.18, i8* %arrayidx70.18, align 1
  %scevgep20.30.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 30
  %7294 = load i8, i8* %scevgep20.30.18, align 1
  %conv68.30.18 = zext i8 %7294 to i32
  %7295 = load i8, i8* %arrayidx70.18, align 1
  %conv71.30.18 = zext i8 %7295 to i32
  %xor72.30.18 = xor i32 %conv71.30.18, %conv68.30.18
  %conv73.30.18 = trunc i32 %xor72.30.18 to i8
  store i8 %conv73.30.18, i8* %arrayidx70.18, align 1
  %scevgep20.31.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 31
  %7296 = load i8, i8* %scevgep20.31.18, align 1
  %conv68.31.18 = zext i8 %7296 to i32
  %7297 = load i8, i8* %arrayidx70.18, align 1
  %conv71.31.18 = zext i8 %7297 to i32
  %xor72.31.18 = xor i32 %conv71.31.18, %conv68.31.18
  %conv73.31.18 = trunc i32 %xor72.31.18 to i8
  store i8 %conv73.31.18, i8* %arrayidx70.18, align 1
  %scevgep20.32.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 32
  %7298 = load i8, i8* %scevgep20.32.18, align 1
  %conv68.32.18 = zext i8 %7298 to i32
  %7299 = load i8, i8* %arrayidx70.18, align 1
  %conv71.32.18 = zext i8 %7299 to i32
  %xor72.32.18 = xor i32 %conv71.32.18, %conv68.32.18
  %conv73.32.18 = trunc i32 %xor72.32.18 to i8
  store i8 %conv73.32.18, i8* %arrayidx70.18, align 1
  %scevgep20.33.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 33
  %7300 = load i8, i8* %scevgep20.33.18, align 1
  %conv68.33.18 = zext i8 %7300 to i32
  %7301 = load i8, i8* %arrayidx70.18, align 1
  %conv71.33.18 = zext i8 %7301 to i32
  %xor72.33.18 = xor i32 %conv71.33.18, %conv68.33.18
  %conv73.33.18 = trunc i32 %xor72.33.18 to i8
  store i8 %conv73.33.18, i8* %arrayidx70.18, align 1
  %scevgep20.34.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 34
  %7302 = load i8, i8* %scevgep20.34.18, align 1
  %conv68.34.18 = zext i8 %7302 to i32
  %7303 = load i8, i8* %arrayidx70.18, align 1
  %conv71.34.18 = zext i8 %7303 to i32
  %xor72.34.18 = xor i32 %conv71.34.18, %conv68.34.18
  %conv73.34.18 = trunc i32 %xor72.34.18 to i8
  store i8 %conv73.34.18, i8* %arrayidx70.18, align 1
  %scevgep20.35.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 35
  %7304 = load i8, i8* %scevgep20.35.18, align 1
  %conv68.35.18 = zext i8 %7304 to i32
  %7305 = load i8, i8* %arrayidx70.18, align 1
  %conv71.35.18 = zext i8 %7305 to i32
  %xor72.35.18 = xor i32 %conv71.35.18, %conv68.35.18
  %conv73.35.18 = trunc i32 %xor72.35.18 to i8
  store i8 %conv73.35.18, i8* %arrayidx70.18, align 1
  %scevgep20.36.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 36
  %7306 = load i8, i8* %scevgep20.36.18, align 1
  %conv68.36.18 = zext i8 %7306 to i32
  %7307 = load i8, i8* %arrayidx70.18, align 1
  %conv71.36.18 = zext i8 %7307 to i32
  %xor72.36.18 = xor i32 %conv71.36.18, %conv68.36.18
  %conv73.36.18 = trunc i32 %xor72.36.18 to i8
  store i8 %conv73.36.18, i8* %arrayidx70.18, align 1
  %scevgep20.37.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 37
  %7308 = load i8, i8* %scevgep20.37.18, align 1
  %conv68.37.18 = zext i8 %7308 to i32
  %7309 = load i8, i8* %arrayidx70.18, align 1
  %conv71.37.18 = zext i8 %7309 to i32
  %xor72.37.18 = xor i32 %conv71.37.18, %conv68.37.18
  %conv73.37.18 = trunc i32 %xor72.37.18 to i8
  store i8 %conv73.37.18, i8* %arrayidx70.18, align 1
  %scevgep20.38.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 38
  %7310 = load i8, i8* %scevgep20.38.18, align 1
  %conv68.38.18 = zext i8 %7310 to i32
  %7311 = load i8, i8* %arrayidx70.18, align 1
  %conv71.38.18 = zext i8 %7311 to i32
  %xor72.38.18 = xor i32 %conv71.38.18, %conv68.38.18
  %conv73.38.18 = trunc i32 %xor72.38.18 to i8
  store i8 %conv73.38.18, i8* %arrayidx70.18, align 1
  %scevgep20.39.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 39
  %7312 = load i8, i8* %scevgep20.39.18, align 1
  %conv68.39.18 = zext i8 %7312 to i32
  %7313 = load i8, i8* %arrayidx70.18, align 1
  %conv71.39.18 = zext i8 %7313 to i32
  %xor72.39.18 = xor i32 %conv71.39.18, %conv68.39.18
  %conv73.39.18 = trunc i32 %xor72.39.18 to i8
  store i8 %conv73.39.18, i8* %arrayidx70.18, align 1
  %scevgep20.40.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 0, i64 40
  %7314 = load i8, i8* %scevgep20.40.18, align 1
  %conv68.40.18 = zext i8 %7314 to i32
  %7315 = load i8, i8* %arrayidx70.18, align 1
  %conv71.40.18 = zext i8 %7315 to i32
  %xor72.40.18 = xor i32 %conv71.40.18, %conv68.40.18
  %conv73.40.18 = trunc i32 %xor72.40.18 to i8
  store i8 %conv73.40.18, i8* %arrayidx70.18, align 1
  %scevgep19.18 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7233, i64 0, i64 1, i64 0
  %7316 = bitcast i8* %scevgep19.18 to [41 x [41 x i8]]*
  %arrayidx51.19 = getelementptr inbounds i8, i8* %a, i64 19
  %7317 = load i8, i8* %arrayidx51.19, align 1
  %arrayidx53.19 = getelementptr inbounds i8, i8* %b, i64 19
  %7318 = load i8, i8* %arrayidx53.19, align 1
  %call54.19 = call zeroext i8 @mult(i8 zeroext %7317, i8 zeroext %7318)
  %arrayidx56.19 = getelementptr inbounds i8, i8* %c, i64 19
  store i8 %call54.19, i8* %arrayidx56.19, align 1
  %arrayidx70.19 = getelementptr inbounds i8, i8* %c, i64 19
  %scevgep20.19234 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 0
  %7319 = load i8, i8* %scevgep20.19234, align 1
  %conv68.19235 = zext i8 %7319 to i32
  %7320 = load i8, i8* %arrayidx70.19, align 1
  %conv71.19236 = zext i8 %7320 to i32
  %xor72.19237 = xor i32 %conv71.19236, %conv68.19235
  %conv73.19238 = trunc i32 %xor72.19237 to i8
  store i8 %conv73.19238, i8* %arrayidx70.19, align 1
  %scevgep20.1.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 1
  %7321 = load i8, i8* %scevgep20.1.19, align 1
  %conv68.1.19 = zext i8 %7321 to i32
  %7322 = load i8, i8* %arrayidx70.19, align 1
  %conv71.1.19 = zext i8 %7322 to i32
  %xor72.1.19 = xor i32 %conv71.1.19, %conv68.1.19
  %conv73.1.19 = trunc i32 %xor72.1.19 to i8
  store i8 %conv73.1.19, i8* %arrayidx70.19, align 1
  %scevgep20.2.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 2
  %7323 = load i8, i8* %scevgep20.2.19, align 1
  %conv68.2.19 = zext i8 %7323 to i32
  %7324 = load i8, i8* %arrayidx70.19, align 1
  %conv71.2.19 = zext i8 %7324 to i32
  %xor72.2.19 = xor i32 %conv71.2.19, %conv68.2.19
  %conv73.2.19 = trunc i32 %xor72.2.19 to i8
  store i8 %conv73.2.19, i8* %arrayidx70.19, align 1
  %scevgep20.3.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 3
  %7325 = load i8, i8* %scevgep20.3.19, align 1
  %conv68.3.19 = zext i8 %7325 to i32
  %7326 = load i8, i8* %arrayidx70.19, align 1
  %conv71.3.19 = zext i8 %7326 to i32
  %xor72.3.19 = xor i32 %conv71.3.19, %conv68.3.19
  %conv73.3.19 = trunc i32 %xor72.3.19 to i8
  store i8 %conv73.3.19, i8* %arrayidx70.19, align 1
  %scevgep20.4.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 4
  %7327 = load i8, i8* %scevgep20.4.19, align 1
  %conv68.4.19 = zext i8 %7327 to i32
  %7328 = load i8, i8* %arrayidx70.19, align 1
  %conv71.4.19 = zext i8 %7328 to i32
  %xor72.4.19 = xor i32 %conv71.4.19, %conv68.4.19
  %conv73.4.19 = trunc i32 %xor72.4.19 to i8
  store i8 %conv73.4.19, i8* %arrayidx70.19, align 1
  %scevgep20.5.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 5
  %7329 = load i8, i8* %scevgep20.5.19, align 1
  %conv68.5.19 = zext i8 %7329 to i32
  %7330 = load i8, i8* %arrayidx70.19, align 1
  %conv71.5.19 = zext i8 %7330 to i32
  %xor72.5.19 = xor i32 %conv71.5.19, %conv68.5.19
  %conv73.5.19 = trunc i32 %xor72.5.19 to i8
  store i8 %conv73.5.19, i8* %arrayidx70.19, align 1
  %scevgep20.6.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 6
  %7331 = load i8, i8* %scevgep20.6.19, align 1
  %conv68.6.19 = zext i8 %7331 to i32
  %7332 = load i8, i8* %arrayidx70.19, align 1
  %conv71.6.19 = zext i8 %7332 to i32
  %xor72.6.19 = xor i32 %conv71.6.19, %conv68.6.19
  %conv73.6.19 = trunc i32 %xor72.6.19 to i8
  store i8 %conv73.6.19, i8* %arrayidx70.19, align 1
  %scevgep20.7.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 7
  %7333 = load i8, i8* %scevgep20.7.19, align 1
  %conv68.7.19 = zext i8 %7333 to i32
  %7334 = load i8, i8* %arrayidx70.19, align 1
  %conv71.7.19 = zext i8 %7334 to i32
  %xor72.7.19 = xor i32 %conv71.7.19, %conv68.7.19
  %conv73.7.19 = trunc i32 %xor72.7.19 to i8
  store i8 %conv73.7.19, i8* %arrayidx70.19, align 1
  %scevgep20.8.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 8
  %7335 = load i8, i8* %scevgep20.8.19, align 1
  %conv68.8.19 = zext i8 %7335 to i32
  %7336 = load i8, i8* %arrayidx70.19, align 1
  %conv71.8.19 = zext i8 %7336 to i32
  %xor72.8.19 = xor i32 %conv71.8.19, %conv68.8.19
  %conv73.8.19 = trunc i32 %xor72.8.19 to i8
  store i8 %conv73.8.19, i8* %arrayidx70.19, align 1
  %scevgep20.9.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 9
  %7337 = load i8, i8* %scevgep20.9.19, align 1
  %conv68.9.19 = zext i8 %7337 to i32
  %7338 = load i8, i8* %arrayidx70.19, align 1
  %conv71.9.19 = zext i8 %7338 to i32
  %xor72.9.19 = xor i32 %conv71.9.19, %conv68.9.19
  %conv73.9.19 = trunc i32 %xor72.9.19 to i8
  store i8 %conv73.9.19, i8* %arrayidx70.19, align 1
  %scevgep20.10.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 10
  %7339 = load i8, i8* %scevgep20.10.19, align 1
  %conv68.10.19 = zext i8 %7339 to i32
  %7340 = load i8, i8* %arrayidx70.19, align 1
  %conv71.10.19 = zext i8 %7340 to i32
  %xor72.10.19 = xor i32 %conv71.10.19, %conv68.10.19
  %conv73.10.19 = trunc i32 %xor72.10.19 to i8
  store i8 %conv73.10.19, i8* %arrayidx70.19, align 1
  %scevgep20.11.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 11
  %7341 = load i8, i8* %scevgep20.11.19, align 1
  %conv68.11.19 = zext i8 %7341 to i32
  %7342 = load i8, i8* %arrayidx70.19, align 1
  %conv71.11.19 = zext i8 %7342 to i32
  %xor72.11.19 = xor i32 %conv71.11.19, %conv68.11.19
  %conv73.11.19 = trunc i32 %xor72.11.19 to i8
  store i8 %conv73.11.19, i8* %arrayidx70.19, align 1
  %scevgep20.12.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 12
  %7343 = load i8, i8* %scevgep20.12.19, align 1
  %conv68.12.19 = zext i8 %7343 to i32
  %7344 = load i8, i8* %arrayidx70.19, align 1
  %conv71.12.19 = zext i8 %7344 to i32
  %xor72.12.19 = xor i32 %conv71.12.19, %conv68.12.19
  %conv73.12.19 = trunc i32 %xor72.12.19 to i8
  store i8 %conv73.12.19, i8* %arrayidx70.19, align 1
  %scevgep20.13.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 13
  %7345 = load i8, i8* %scevgep20.13.19, align 1
  %conv68.13.19 = zext i8 %7345 to i32
  %7346 = load i8, i8* %arrayidx70.19, align 1
  %conv71.13.19 = zext i8 %7346 to i32
  %xor72.13.19 = xor i32 %conv71.13.19, %conv68.13.19
  %conv73.13.19 = trunc i32 %xor72.13.19 to i8
  store i8 %conv73.13.19, i8* %arrayidx70.19, align 1
  %scevgep20.14.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 14
  %7347 = load i8, i8* %scevgep20.14.19, align 1
  %conv68.14.19 = zext i8 %7347 to i32
  %7348 = load i8, i8* %arrayidx70.19, align 1
  %conv71.14.19 = zext i8 %7348 to i32
  %xor72.14.19 = xor i32 %conv71.14.19, %conv68.14.19
  %conv73.14.19 = trunc i32 %xor72.14.19 to i8
  store i8 %conv73.14.19, i8* %arrayidx70.19, align 1
  %scevgep20.15.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 15
  %7349 = load i8, i8* %scevgep20.15.19, align 1
  %conv68.15.19 = zext i8 %7349 to i32
  %7350 = load i8, i8* %arrayidx70.19, align 1
  %conv71.15.19 = zext i8 %7350 to i32
  %xor72.15.19 = xor i32 %conv71.15.19, %conv68.15.19
  %conv73.15.19 = trunc i32 %xor72.15.19 to i8
  store i8 %conv73.15.19, i8* %arrayidx70.19, align 1
  %scevgep20.16.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 16
  %7351 = load i8, i8* %scevgep20.16.19, align 1
  %conv68.16.19 = zext i8 %7351 to i32
  %7352 = load i8, i8* %arrayidx70.19, align 1
  %conv71.16.19 = zext i8 %7352 to i32
  %xor72.16.19 = xor i32 %conv71.16.19, %conv68.16.19
  %conv73.16.19 = trunc i32 %xor72.16.19 to i8
  store i8 %conv73.16.19, i8* %arrayidx70.19, align 1
  %scevgep20.17.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 17
  %7353 = load i8, i8* %scevgep20.17.19, align 1
  %conv68.17.19 = zext i8 %7353 to i32
  %7354 = load i8, i8* %arrayidx70.19, align 1
  %conv71.17.19 = zext i8 %7354 to i32
  %xor72.17.19 = xor i32 %conv71.17.19, %conv68.17.19
  %conv73.17.19 = trunc i32 %xor72.17.19 to i8
  store i8 %conv73.17.19, i8* %arrayidx70.19, align 1
  %scevgep20.18.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 18
  %7355 = load i8, i8* %scevgep20.18.19, align 1
  %conv68.18.19 = zext i8 %7355 to i32
  %7356 = load i8, i8* %arrayidx70.19, align 1
  %conv71.18.19 = zext i8 %7356 to i32
  %xor72.18.19 = xor i32 %conv71.18.19, %conv68.18.19
  %conv73.18.19 = trunc i32 %xor72.18.19 to i8
  store i8 %conv73.18.19, i8* %arrayidx70.19, align 1
  %scevgep20.20.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 20
  %7357 = load i8, i8* %scevgep20.20.19, align 1
  %conv68.20.19 = zext i8 %7357 to i32
  %7358 = load i8, i8* %arrayidx70.19, align 1
  %conv71.20.19 = zext i8 %7358 to i32
  %xor72.20.19 = xor i32 %conv71.20.19, %conv68.20.19
  %conv73.20.19 = trunc i32 %xor72.20.19 to i8
  store i8 %conv73.20.19, i8* %arrayidx70.19, align 1
  %scevgep20.21.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 21
  %7359 = load i8, i8* %scevgep20.21.19, align 1
  %conv68.21.19 = zext i8 %7359 to i32
  %7360 = load i8, i8* %arrayidx70.19, align 1
  %conv71.21.19 = zext i8 %7360 to i32
  %xor72.21.19 = xor i32 %conv71.21.19, %conv68.21.19
  %conv73.21.19 = trunc i32 %xor72.21.19 to i8
  store i8 %conv73.21.19, i8* %arrayidx70.19, align 1
  %scevgep20.22.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 22
  %7361 = load i8, i8* %scevgep20.22.19, align 1
  %conv68.22.19 = zext i8 %7361 to i32
  %7362 = load i8, i8* %arrayidx70.19, align 1
  %conv71.22.19 = zext i8 %7362 to i32
  %xor72.22.19 = xor i32 %conv71.22.19, %conv68.22.19
  %conv73.22.19 = trunc i32 %xor72.22.19 to i8
  store i8 %conv73.22.19, i8* %arrayidx70.19, align 1
  %scevgep20.23.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 23
  %7363 = load i8, i8* %scevgep20.23.19, align 1
  %conv68.23.19 = zext i8 %7363 to i32
  %7364 = load i8, i8* %arrayidx70.19, align 1
  %conv71.23.19 = zext i8 %7364 to i32
  %xor72.23.19 = xor i32 %conv71.23.19, %conv68.23.19
  %conv73.23.19 = trunc i32 %xor72.23.19 to i8
  store i8 %conv73.23.19, i8* %arrayidx70.19, align 1
  %scevgep20.24.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 24
  %7365 = load i8, i8* %scevgep20.24.19, align 1
  %conv68.24.19 = zext i8 %7365 to i32
  %7366 = load i8, i8* %arrayidx70.19, align 1
  %conv71.24.19 = zext i8 %7366 to i32
  %xor72.24.19 = xor i32 %conv71.24.19, %conv68.24.19
  %conv73.24.19 = trunc i32 %xor72.24.19 to i8
  store i8 %conv73.24.19, i8* %arrayidx70.19, align 1
  %scevgep20.25.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 25
  %7367 = load i8, i8* %scevgep20.25.19, align 1
  %conv68.25.19 = zext i8 %7367 to i32
  %7368 = load i8, i8* %arrayidx70.19, align 1
  %conv71.25.19 = zext i8 %7368 to i32
  %xor72.25.19 = xor i32 %conv71.25.19, %conv68.25.19
  %conv73.25.19 = trunc i32 %xor72.25.19 to i8
  store i8 %conv73.25.19, i8* %arrayidx70.19, align 1
  %scevgep20.26.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 26
  %7369 = load i8, i8* %scevgep20.26.19, align 1
  %conv68.26.19 = zext i8 %7369 to i32
  %7370 = load i8, i8* %arrayidx70.19, align 1
  %conv71.26.19 = zext i8 %7370 to i32
  %xor72.26.19 = xor i32 %conv71.26.19, %conv68.26.19
  %conv73.26.19 = trunc i32 %xor72.26.19 to i8
  store i8 %conv73.26.19, i8* %arrayidx70.19, align 1
  %scevgep20.27.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 27
  %7371 = load i8, i8* %scevgep20.27.19, align 1
  %conv68.27.19 = zext i8 %7371 to i32
  %7372 = load i8, i8* %arrayidx70.19, align 1
  %conv71.27.19 = zext i8 %7372 to i32
  %xor72.27.19 = xor i32 %conv71.27.19, %conv68.27.19
  %conv73.27.19 = trunc i32 %xor72.27.19 to i8
  store i8 %conv73.27.19, i8* %arrayidx70.19, align 1
  %scevgep20.28.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 28
  %7373 = load i8, i8* %scevgep20.28.19, align 1
  %conv68.28.19 = zext i8 %7373 to i32
  %7374 = load i8, i8* %arrayidx70.19, align 1
  %conv71.28.19 = zext i8 %7374 to i32
  %xor72.28.19 = xor i32 %conv71.28.19, %conv68.28.19
  %conv73.28.19 = trunc i32 %xor72.28.19 to i8
  store i8 %conv73.28.19, i8* %arrayidx70.19, align 1
  %scevgep20.29.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 29
  %7375 = load i8, i8* %scevgep20.29.19, align 1
  %conv68.29.19 = zext i8 %7375 to i32
  %7376 = load i8, i8* %arrayidx70.19, align 1
  %conv71.29.19 = zext i8 %7376 to i32
  %xor72.29.19 = xor i32 %conv71.29.19, %conv68.29.19
  %conv73.29.19 = trunc i32 %xor72.29.19 to i8
  store i8 %conv73.29.19, i8* %arrayidx70.19, align 1
  %scevgep20.30.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 30
  %7377 = load i8, i8* %scevgep20.30.19, align 1
  %conv68.30.19 = zext i8 %7377 to i32
  %7378 = load i8, i8* %arrayidx70.19, align 1
  %conv71.30.19 = zext i8 %7378 to i32
  %xor72.30.19 = xor i32 %conv71.30.19, %conv68.30.19
  %conv73.30.19 = trunc i32 %xor72.30.19 to i8
  store i8 %conv73.30.19, i8* %arrayidx70.19, align 1
  %scevgep20.31.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 31
  %7379 = load i8, i8* %scevgep20.31.19, align 1
  %conv68.31.19 = zext i8 %7379 to i32
  %7380 = load i8, i8* %arrayidx70.19, align 1
  %conv71.31.19 = zext i8 %7380 to i32
  %xor72.31.19 = xor i32 %conv71.31.19, %conv68.31.19
  %conv73.31.19 = trunc i32 %xor72.31.19 to i8
  store i8 %conv73.31.19, i8* %arrayidx70.19, align 1
  %scevgep20.32.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 32
  %7381 = load i8, i8* %scevgep20.32.19, align 1
  %conv68.32.19 = zext i8 %7381 to i32
  %7382 = load i8, i8* %arrayidx70.19, align 1
  %conv71.32.19 = zext i8 %7382 to i32
  %xor72.32.19 = xor i32 %conv71.32.19, %conv68.32.19
  %conv73.32.19 = trunc i32 %xor72.32.19 to i8
  store i8 %conv73.32.19, i8* %arrayidx70.19, align 1
  %scevgep20.33.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 33
  %7383 = load i8, i8* %scevgep20.33.19, align 1
  %conv68.33.19 = zext i8 %7383 to i32
  %7384 = load i8, i8* %arrayidx70.19, align 1
  %conv71.33.19 = zext i8 %7384 to i32
  %xor72.33.19 = xor i32 %conv71.33.19, %conv68.33.19
  %conv73.33.19 = trunc i32 %xor72.33.19 to i8
  store i8 %conv73.33.19, i8* %arrayidx70.19, align 1
  %scevgep20.34.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 34
  %7385 = load i8, i8* %scevgep20.34.19, align 1
  %conv68.34.19 = zext i8 %7385 to i32
  %7386 = load i8, i8* %arrayidx70.19, align 1
  %conv71.34.19 = zext i8 %7386 to i32
  %xor72.34.19 = xor i32 %conv71.34.19, %conv68.34.19
  %conv73.34.19 = trunc i32 %xor72.34.19 to i8
  store i8 %conv73.34.19, i8* %arrayidx70.19, align 1
  %scevgep20.35.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 35
  %7387 = load i8, i8* %scevgep20.35.19, align 1
  %conv68.35.19 = zext i8 %7387 to i32
  %7388 = load i8, i8* %arrayidx70.19, align 1
  %conv71.35.19 = zext i8 %7388 to i32
  %xor72.35.19 = xor i32 %conv71.35.19, %conv68.35.19
  %conv73.35.19 = trunc i32 %xor72.35.19 to i8
  store i8 %conv73.35.19, i8* %arrayidx70.19, align 1
  %scevgep20.36.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 36
  %7389 = load i8, i8* %scevgep20.36.19, align 1
  %conv68.36.19 = zext i8 %7389 to i32
  %7390 = load i8, i8* %arrayidx70.19, align 1
  %conv71.36.19 = zext i8 %7390 to i32
  %xor72.36.19 = xor i32 %conv71.36.19, %conv68.36.19
  %conv73.36.19 = trunc i32 %xor72.36.19 to i8
  store i8 %conv73.36.19, i8* %arrayidx70.19, align 1
  %scevgep20.37.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 37
  %7391 = load i8, i8* %scevgep20.37.19, align 1
  %conv68.37.19 = zext i8 %7391 to i32
  %7392 = load i8, i8* %arrayidx70.19, align 1
  %conv71.37.19 = zext i8 %7392 to i32
  %xor72.37.19 = xor i32 %conv71.37.19, %conv68.37.19
  %conv73.37.19 = trunc i32 %xor72.37.19 to i8
  store i8 %conv73.37.19, i8* %arrayidx70.19, align 1
  %scevgep20.38.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 38
  %7393 = load i8, i8* %scevgep20.38.19, align 1
  %conv68.38.19 = zext i8 %7393 to i32
  %7394 = load i8, i8* %arrayidx70.19, align 1
  %conv71.38.19 = zext i8 %7394 to i32
  %xor72.38.19 = xor i32 %conv71.38.19, %conv68.38.19
  %conv73.38.19 = trunc i32 %xor72.38.19 to i8
  store i8 %conv73.38.19, i8* %arrayidx70.19, align 1
  %scevgep20.39.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 39
  %7395 = load i8, i8* %scevgep20.39.19, align 1
  %conv68.39.19 = zext i8 %7395 to i32
  %7396 = load i8, i8* %arrayidx70.19, align 1
  %conv71.39.19 = zext i8 %7396 to i32
  %xor72.39.19 = xor i32 %conv71.39.19, %conv68.39.19
  %conv73.39.19 = trunc i32 %xor72.39.19 to i8
  store i8 %conv73.39.19, i8* %arrayidx70.19, align 1
  %scevgep20.40.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 0, i64 40
  %7397 = load i8, i8* %scevgep20.40.19, align 1
  %conv68.40.19 = zext i8 %7397 to i32
  %7398 = load i8, i8* %arrayidx70.19, align 1
  %conv71.40.19 = zext i8 %7398 to i32
  %xor72.40.19 = xor i32 %conv71.40.19, %conv68.40.19
  %conv73.40.19 = trunc i32 %xor72.40.19 to i8
  store i8 %conv73.40.19, i8* %arrayidx70.19, align 1
  %scevgep19.19 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7316, i64 0, i64 1, i64 0
  %7399 = bitcast i8* %scevgep19.19 to [41 x [41 x i8]]*
  %arrayidx51.20 = getelementptr inbounds i8, i8* %a, i64 20
  %7400 = load i8, i8* %arrayidx51.20, align 1
  %arrayidx53.20 = getelementptr inbounds i8, i8* %b, i64 20
  %7401 = load i8, i8* %arrayidx53.20, align 1
  %call54.20 = call zeroext i8 @mult(i8 zeroext %7400, i8 zeroext %7401)
  %arrayidx56.20 = getelementptr inbounds i8, i8* %c, i64 20
  store i8 %call54.20, i8* %arrayidx56.20, align 1
  %arrayidx70.20 = getelementptr inbounds i8, i8* %c, i64 20
  %scevgep20.20244 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 0
  %7402 = load i8, i8* %scevgep20.20244, align 1
  %conv68.20245 = zext i8 %7402 to i32
  %7403 = load i8, i8* %arrayidx70.20, align 1
  %conv71.20246 = zext i8 %7403 to i32
  %xor72.20247 = xor i32 %conv71.20246, %conv68.20245
  %conv73.20248 = trunc i32 %xor72.20247 to i8
  store i8 %conv73.20248, i8* %arrayidx70.20, align 1
  %scevgep20.1.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 1
  %7404 = load i8, i8* %scevgep20.1.20, align 1
  %conv68.1.20 = zext i8 %7404 to i32
  %7405 = load i8, i8* %arrayidx70.20, align 1
  %conv71.1.20 = zext i8 %7405 to i32
  %xor72.1.20 = xor i32 %conv71.1.20, %conv68.1.20
  %conv73.1.20 = trunc i32 %xor72.1.20 to i8
  store i8 %conv73.1.20, i8* %arrayidx70.20, align 1
  %scevgep20.2.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 2
  %7406 = load i8, i8* %scevgep20.2.20, align 1
  %conv68.2.20 = zext i8 %7406 to i32
  %7407 = load i8, i8* %arrayidx70.20, align 1
  %conv71.2.20 = zext i8 %7407 to i32
  %xor72.2.20 = xor i32 %conv71.2.20, %conv68.2.20
  %conv73.2.20 = trunc i32 %xor72.2.20 to i8
  store i8 %conv73.2.20, i8* %arrayidx70.20, align 1
  %scevgep20.3.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 3
  %7408 = load i8, i8* %scevgep20.3.20, align 1
  %conv68.3.20 = zext i8 %7408 to i32
  %7409 = load i8, i8* %arrayidx70.20, align 1
  %conv71.3.20 = zext i8 %7409 to i32
  %xor72.3.20 = xor i32 %conv71.3.20, %conv68.3.20
  %conv73.3.20 = trunc i32 %xor72.3.20 to i8
  store i8 %conv73.3.20, i8* %arrayidx70.20, align 1
  %scevgep20.4.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 4
  %7410 = load i8, i8* %scevgep20.4.20, align 1
  %conv68.4.20 = zext i8 %7410 to i32
  %7411 = load i8, i8* %arrayidx70.20, align 1
  %conv71.4.20 = zext i8 %7411 to i32
  %xor72.4.20 = xor i32 %conv71.4.20, %conv68.4.20
  %conv73.4.20 = trunc i32 %xor72.4.20 to i8
  store i8 %conv73.4.20, i8* %arrayidx70.20, align 1
  %scevgep20.5.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 5
  %7412 = load i8, i8* %scevgep20.5.20, align 1
  %conv68.5.20 = zext i8 %7412 to i32
  %7413 = load i8, i8* %arrayidx70.20, align 1
  %conv71.5.20 = zext i8 %7413 to i32
  %xor72.5.20 = xor i32 %conv71.5.20, %conv68.5.20
  %conv73.5.20 = trunc i32 %xor72.5.20 to i8
  store i8 %conv73.5.20, i8* %arrayidx70.20, align 1
  %scevgep20.6.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 6
  %7414 = load i8, i8* %scevgep20.6.20, align 1
  %conv68.6.20 = zext i8 %7414 to i32
  %7415 = load i8, i8* %arrayidx70.20, align 1
  %conv71.6.20 = zext i8 %7415 to i32
  %xor72.6.20 = xor i32 %conv71.6.20, %conv68.6.20
  %conv73.6.20 = trunc i32 %xor72.6.20 to i8
  store i8 %conv73.6.20, i8* %arrayidx70.20, align 1
  %scevgep20.7.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 7
  %7416 = load i8, i8* %scevgep20.7.20, align 1
  %conv68.7.20 = zext i8 %7416 to i32
  %7417 = load i8, i8* %arrayidx70.20, align 1
  %conv71.7.20 = zext i8 %7417 to i32
  %xor72.7.20 = xor i32 %conv71.7.20, %conv68.7.20
  %conv73.7.20 = trunc i32 %xor72.7.20 to i8
  store i8 %conv73.7.20, i8* %arrayidx70.20, align 1
  %scevgep20.8.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 8
  %7418 = load i8, i8* %scevgep20.8.20, align 1
  %conv68.8.20 = zext i8 %7418 to i32
  %7419 = load i8, i8* %arrayidx70.20, align 1
  %conv71.8.20 = zext i8 %7419 to i32
  %xor72.8.20 = xor i32 %conv71.8.20, %conv68.8.20
  %conv73.8.20 = trunc i32 %xor72.8.20 to i8
  store i8 %conv73.8.20, i8* %arrayidx70.20, align 1
  %scevgep20.9.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 9
  %7420 = load i8, i8* %scevgep20.9.20, align 1
  %conv68.9.20 = zext i8 %7420 to i32
  %7421 = load i8, i8* %arrayidx70.20, align 1
  %conv71.9.20 = zext i8 %7421 to i32
  %xor72.9.20 = xor i32 %conv71.9.20, %conv68.9.20
  %conv73.9.20 = trunc i32 %xor72.9.20 to i8
  store i8 %conv73.9.20, i8* %arrayidx70.20, align 1
  %scevgep20.10.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 10
  %7422 = load i8, i8* %scevgep20.10.20, align 1
  %conv68.10.20 = zext i8 %7422 to i32
  %7423 = load i8, i8* %arrayidx70.20, align 1
  %conv71.10.20 = zext i8 %7423 to i32
  %xor72.10.20 = xor i32 %conv71.10.20, %conv68.10.20
  %conv73.10.20 = trunc i32 %xor72.10.20 to i8
  store i8 %conv73.10.20, i8* %arrayidx70.20, align 1
  %scevgep20.11.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 11
  %7424 = load i8, i8* %scevgep20.11.20, align 1
  %conv68.11.20 = zext i8 %7424 to i32
  %7425 = load i8, i8* %arrayidx70.20, align 1
  %conv71.11.20 = zext i8 %7425 to i32
  %xor72.11.20 = xor i32 %conv71.11.20, %conv68.11.20
  %conv73.11.20 = trunc i32 %xor72.11.20 to i8
  store i8 %conv73.11.20, i8* %arrayidx70.20, align 1
  %scevgep20.12.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 12
  %7426 = load i8, i8* %scevgep20.12.20, align 1
  %conv68.12.20 = zext i8 %7426 to i32
  %7427 = load i8, i8* %arrayidx70.20, align 1
  %conv71.12.20 = zext i8 %7427 to i32
  %xor72.12.20 = xor i32 %conv71.12.20, %conv68.12.20
  %conv73.12.20 = trunc i32 %xor72.12.20 to i8
  store i8 %conv73.12.20, i8* %arrayidx70.20, align 1
  %scevgep20.13.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 13
  %7428 = load i8, i8* %scevgep20.13.20, align 1
  %conv68.13.20 = zext i8 %7428 to i32
  %7429 = load i8, i8* %arrayidx70.20, align 1
  %conv71.13.20 = zext i8 %7429 to i32
  %xor72.13.20 = xor i32 %conv71.13.20, %conv68.13.20
  %conv73.13.20 = trunc i32 %xor72.13.20 to i8
  store i8 %conv73.13.20, i8* %arrayidx70.20, align 1
  %scevgep20.14.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 14
  %7430 = load i8, i8* %scevgep20.14.20, align 1
  %conv68.14.20 = zext i8 %7430 to i32
  %7431 = load i8, i8* %arrayidx70.20, align 1
  %conv71.14.20 = zext i8 %7431 to i32
  %xor72.14.20 = xor i32 %conv71.14.20, %conv68.14.20
  %conv73.14.20 = trunc i32 %xor72.14.20 to i8
  store i8 %conv73.14.20, i8* %arrayidx70.20, align 1
  %scevgep20.15.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 15
  %7432 = load i8, i8* %scevgep20.15.20, align 1
  %conv68.15.20 = zext i8 %7432 to i32
  %7433 = load i8, i8* %arrayidx70.20, align 1
  %conv71.15.20 = zext i8 %7433 to i32
  %xor72.15.20 = xor i32 %conv71.15.20, %conv68.15.20
  %conv73.15.20 = trunc i32 %xor72.15.20 to i8
  store i8 %conv73.15.20, i8* %arrayidx70.20, align 1
  %scevgep20.16.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 16
  %7434 = load i8, i8* %scevgep20.16.20, align 1
  %conv68.16.20 = zext i8 %7434 to i32
  %7435 = load i8, i8* %arrayidx70.20, align 1
  %conv71.16.20 = zext i8 %7435 to i32
  %xor72.16.20 = xor i32 %conv71.16.20, %conv68.16.20
  %conv73.16.20 = trunc i32 %xor72.16.20 to i8
  store i8 %conv73.16.20, i8* %arrayidx70.20, align 1
  %scevgep20.17.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 17
  %7436 = load i8, i8* %scevgep20.17.20, align 1
  %conv68.17.20 = zext i8 %7436 to i32
  %7437 = load i8, i8* %arrayidx70.20, align 1
  %conv71.17.20 = zext i8 %7437 to i32
  %xor72.17.20 = xor i32 %conv71.17.20, %conv68.17.20
  %conv73.17.20 = trunc i32 %xor72.17.20 to i8
  store i8 %conv73.17.20, i8* %arrayidx70.20, align 1
  %scevgep20.18.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 18
  %7438 = load i8, i8* %scevgep20.18.20, align 1
  %conv68.18.20 = zext i8 %7438 to i32
  %7439 = load i8, i8* %arrayidx70.20, align 1
  %conv71.18.20 = zext i8 %7439 to i32
  %xor72.18.20 = xor i32 %conv71.18.20, %conv68.18.20
  %conv73.18.20 = trunc i32 %xor72.18.20 to i8
  store i8 %conv73.18.20, i8* %arrayidx70.20, align 1
  %scevgep20.19.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 19
  %7440 = load i8, i8* %scevgep20.19.20, align 1
  %conv68.19.20 = zext i8 %7440 to i32
  %7441 = load i8, i8* %arrayidx70.20, align 1
  %conv71.19.20 = zext i8 %7441 to i32
  %xor72.19.20 = xor i32 %conv71.19.20, %conv68.19.20
  %conv73.19.20 = trunc i32 %xor72.19.20 to i8
  store i8 %conv73.19.20, i8* %arrayidx70.20, align 1
  %scevgep20.21.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 21
  %7442 = load i8, i8* %scevgep20.21.20, align 1
  %conv68.21.20 = zext i8 %7442 to i32
  %7443 = load i8, i8* %arrayidx70.20, align 1
  %conv71.21.20 = zext i8 %7443 to i32
  %xor72.21.20 = xor i32 %conv71.21.20, %conv68.21.20
  %conv73.21.20 = trunc i32 %xor72.21.20 to i8
  store i8 %conv73.21.20, i8* %arrayidx70.20, align 1
  %scevgep20.22.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 22
  %7444 = load i8, i8* %scevgep20.22.20, align 1
  %conv68.22.20 = zext i8 %7444 to i32
  %7445 = load i8, i8* %arrayidx70.20, align 1
  %conv71.22.20 = zext i8 %7445 to i32
  %xor72.22.20 = xor i32 %conv71.22.20, %conv68.22.20
  %conv73.22.20 = trunc i32 %xor72.22.20 to i8
  store i8 %conv73.22.20, i8* %arrayidx70.20, align 1
  %scevgep20.23.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 23
  %7446 = load i8, i8* %scevgep20.23.20, align 1
  %conv68.23.20 = zext i8 %7446 to i32
  %7447 = load i8, i8* %arrayidx70.20, align 1
  %conv71.23.20 = zext i8 %7447 to i32
  %xor72.23.20 = xor i32 %conv71.23.20, %conv68.23.20
  %conv73.23.20 = trunc i32 %xor72.23.20 to i8
  store i8 %conv73.23.20, i8* %arrayidx70.20, align 1
  %scevgep20.24.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 24
  %7448 = load i8, i8* %scevgep20.24.20, align 1
  %conv68.24.20 = zext i8 %7448 to i32
  %7449 = load i8, i8* %arrayidx70.20, align 1
  %conv71.24.20 = zext i8 %7449 to i32
  %xor72.24.20 = xor i32 %conv71.24.20, %conv68.24.20
  %conv73.24.20 = trunc i32 %xor72.24.20 to i8
  store i8 %conv73.24.20, i8* %arrayidx70.20, align 1
  %scevgep20.25.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 25
  %7450 = load i8, i8* %scevgep20.25.20, align 1
  %conv68.25.20 = zext i8 %7450 to i32
  %7451 = load i8, i8* %arrayidx70.20, align 1
  %conv71.25.20 = zext i8 %7451 to i32
  %xor72.25.20 = xor i32 %conv71.25.20, %conv68.25.20
  %conv73.25.20 = trunc i32 %xor72.25.20 to i8
  store i8 %conv73.25.20, i8* %arrayidx70.20, align 1
  %scevgep20.26.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 26
  %7452 = load i8, i8* %scevgep20.26.20, align 1
  %conv68.26.20 = zext i8 %7452 to i32
  %7453 = load i8, i8* %arrayidx70.20, align 1
  %conv71.26.20 = zext i8 %7453 to i32
  %xor72.26.20 = xor i32 %conv71.26.20, %conv68.26.20
  %conv73.26.20 = trunc i32 %xor72.26.20 to i8
  store i8 %conv73.26.20, i8* %arrayidx70.20, align 1
  %scevgep20.27.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 27
  %7454 = load i8, i8* %scevgep20.27.20, align 1
  %conv68.27.20 = zext i8 %7454 to i32
  %7455 = load i8, i8* %arrayidx70.20, align 1
  %conv71.27.20 = zext i8 %7455 to i32
  %xor72.27.20 = xor i32 %conv71.27.20, %conv68.27.20
  %conv73.27.20 = trunc i32 %xor72.27.20 to i8
  store i8 %conv73.27.20, i8* %arrayidx70.20, align 1
  %scevgep20.28.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 28
  %7456 = load i8, i8* %scevgep20.28.20, align 1
  %conv68.28.20 = zext i8 %7456 to i32
  %7457 = load i8, i8* %arrayidx70.20, align 1
  %conv71.28.20 = zext i8 %7457 to i32
  %xor72.28.20 = xor i32 %conv71.28.20, %conv68.28.20
  %conv73.28.20 = trunc i32 %xor72.28.20 to i8
  store i8 %conv73.28.20, i8* %arrayidx70.20, align 1
  %scevgep20.29.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 29
  %7458 = load i8, i8* %scevgep20.29.20, align 1
  %conv68.29.20 = zext i8 %7458 to i32
  %7459 = load i8, i8* %arrayidx70.20, align 1
  %conv71.29.20 = zext i8 %7459 to i32
  %xor72.29.20 = xor i32 %conv71.29.20, %conv68.29.20
  %conv73.29.20 = trunc i32 %xor72.29.20 to i8
  store i8 %conv73.29.20, i8* %arrayidx70.20, align 1
  %scevgep20.30.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 30
  %7460 = load i8, i8* %scevgep20.30.20, align 1
  %conv68.30.20 = zext i8 %7460 to i32
  %7461 = load i8, i8* %arrayidx70.20, align 1
  %conv71.30.20 = zext i8 %7461 to i32
  %xor72.30.20 = xor i32 %conv71.30.20, %conv68.30.20
  %conv73.30.20 = trunc i32 %xor72.30.20 to i8
  store i8 %conv73.30.20, i8* %arrayidx70.20, align 1
  %scevgep20.31.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 31
  %7462 = load i8, i8* %scevgep20.31.20, align 1
  %conv68.31.20 = zext i8 %7462 to i32
  %7463 = load i8, i8* %arrayidx70.20, align 1
  %conv71.31.20 = zext i8 %7463 to i32
  %xor72.31.20 = xor i32 %conv71.31.20, %conv68.31.20
  %conv73.31.20 = trunc i32 %xor72.31.20 to i8
  store i8 %conv73.31.20, i8* %arrayidx70.20, align 1
  %scevgep20.32.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 32
  %7464 = load i8, i8* %scevgep20.32.20, align 1
  %conv68.32.20 = zext i8 %7464 to i32
  %7465 = load i8, i8* %arrayidx70.20, align 1
  %conv71.32.20 = zext i8 %7465 to i32
  %xor72.32.20 = xor i32 %conv71.32.20, %conv68.32.20
  %conv73.32.20 = trunc i32 %xor72.32.20 to i8
  store i8 %conv73.32.20, i8* %arrayidx70.20, align 1
  %scevgep20.33.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 33
  %7466 = load i8, i8* %scevgep20.33.20, align 1
  %conv68.33.20 = zext i8 %7466 to i32
  %7467 = load i8, i8* %arrayidx70.20, align 1
  %conv71.33.20 = zext i8 %7467 to i32
  %xor72.33.20 = xor i32 %conv71.33.20, %conv68.33.20
  %conv73.33.20 = trunc i32 %xor72.33.20 to i8
  store i8 %conv73.33.20, i8* %arrayidx70.20, align 1
  %scevgep20.34.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 34
  %7468 = load i8, i8* %scevgep20.34.20, align 1
  %conv68.34.20 = zext i8 %7468 to i32
  %7469 = load i8, i8* %arrayidx70.20, align 1
  %conv71.34.20 = zext i8 %7469 to i32
  %xor72.34.20 = xor i32 %conv71.34.20, %conv68.34.20
  %conv73.34.20 = trunc i32 %xor72.34.20 to i8
  store i8 %conv73.34.20, i8* %arrayidx70.20, align 1
  %scevgep20.35.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 35
  %7470 = load i8, i8* %scevgep20.35.20, align 1
  %conv68.35.20 = zext i8 %7470 to i32
  %7471 = load i8, i8* %arrayidx70.20, align 1
  %conv71.35.20 = zext i8 %7471 to i32
  %xor72.35.20 = xor i32 %conv71.35.20, %conv68.35.20
  %conv73.35.20 = trunc i32 %xor72.35.20 to i8
  store i8 %conv73.35.20, i8* %arrayidx70.20, align 1
  %scevgep20.36.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 36
  %7472 = load i8, i8* %scevgep20.36.20, align 1
  %conv68.36.20 = zext i8 %7472 to i32
  %7473 = load i8, i8* %arrayidx70.20, align 1
  %conv71.36.20 = zext i8 %7473 to i32
  %xor72.36.20 = xor i32 %conv71.36.20, %conv68.36.20
  %conv73.36.20 = trunc i32 %xor72.36.20 to i8
  store i8 %conv73.36.20, i8* %arrayidx70.20, align 1
  %scevgep20.37.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 37
  %7474 = load i8, i8* %scevgep20.37.20, align 1
  %conv68.37.20 = zext i8 %7474 to i32
  %7475 = load i8, i8* %arrayidx70.20, align 1
  %conv71.37.20 = zext i8 %7475 to i32
  %xor72.37.20 = xor i32 %conv71.37.20, %conv68.37.20
  %conv73.37.20 = trunc i32 %xor72.37.20 to i8
  store i8 %conv73.37.20, i8* %arrayidx70.20, align 1
  %scevgep20.38.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 38
  %7476 = load i8, i8* %scevgep20.38.20, align 1
  %conv68.38.20 = zext i8 %7476 to i32
  %7477 = load i8, i8* %arrayidx70.20, align 1
  %conv71.38.20 = zext i8 %7477 to i32
  %xor72.38.20 = xor i32 %conv71.38.20, %conv68.38.20
  %conv73.38.20 = trunc i32 %xor72.38.20 to i8
  store i8 %conv73.38.20, i8* %arrayidx70.20, align 1
  %scevgep20.39.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 39
  %7478 = load i8, i8* %scevgep20.39.20, align 1
  %conv68.39.20 = zext i8 %7478 to i32
  %7479 = load i8, i8* %arrayidx70.20, align 1
  %conv71.39.20 = zext i8 %7479 to i32
  %xor72.39.20 = xor i32 %conv71.39.20, %conv68.39.20
  %conv73.39.20 = trunc i32 %xor72.39.20 to i8
  store i8 %conv73.39.20, i8* %arrayidx70.20, align 1
  %scevgep20.40.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 0, i64 40
  %7480 = load i8, i8* %scevgep20.40.20, align 1
  %conv68.40.20 = zext i8 %7480 to i32
  %7481 = load i8, i8* %arrayidx70.20, align 1
  %conv71.40.20 = zext i8 %7481 to i32
  %xor72.40.20 = xor i32 %conv71.40.20, %conv68.40.20
  %conv73.40.20 = trunc i32 %xor72.40.20 to i8
  store i8 %conv73.40.20, i8* %arrayidx70.20, align 1
  %scevgep19.20 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7399, i64 0, i64 1, i64 0
  %7482 = bitcast i8* %scevgep19.20 to [41 x [41 x i8]]*
  %arrayidx51.21 = getelementptr inbounds i8, i8* %a, i64 21
  %7483 = load i8, i8* %arrayidx51.21, align 1
  %arrayidx53.21 = getelementptr inbounds i8, i8* %b, i64 21
  %7484 = load i8, i8* %arrayidx53.21, align 1
  %call54.21 = call zeroext i8 @mult(i8 zeroext %7483, i8 zeroext %7484)
  %arrayidx56.21 = getelementptr inbounds i8, i8* %c, i64 21
  store i8 %call54.21, i8* %arrayidx56.21, align 1
  %arrayidx70.21 = getelementptr inbounds i8, i8* %c, i64 21
  %scevgep20.21254 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 0
  %7485 = load i8, i8* %scevgep20.21254, align 1
  %conv68.21255 = zext i8 %7485 to i32
  %7486 = load i8, i8* %arrayidx70.21, align 1
  %conv71.21256 = zext i8 %7486 to i32
  %xor72.21257 = xor i32 %conv71.21256, %conv68.21255
  %conv73.21258 = trunc i32 %xor72.21257 to i8
  store i8 %conv73.21258, i8* %arrayidx70.21, align 1
  %scevgep20.1.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 1
  %7487 = load i8, i8* %scevgep20.1.21, align 1
  %conv68.1.21 = zext i8 %7487 to i32
  %7488 = load i8, i8* %arrayidx70.21, align 1
  %conv71.1.21 = zext i8 %7488 to i32
  %xor72.1.21 = xor i32 %conv71.1.21, %conv68.1.21
  %conv73.1.21 = trunc i32 %xor72.1.21 to i8
  store i8 %conv73.1.21, i8* %arrayidx70.21, align 1
  %scevgep20.2.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 2
  %7489 = load i8, i8* %scevgep20.2.21, align 1
  %conv68.2.21 = zext i8 %7489 to i32
  %7490 = load i8, i8* %arrayidx70.21, align 1
  %conv71.2.21 = zext i8 %7490 to i32
  %xor72.2.21 = xor i32 %conv71.2.21, %conv68.2.21
  %conv73.2.21 = trunc i32 %xor72.2.21 to i8
  store i8 %conv73.2.21, i8* %arrayidx70.21, align 1
  %scevgep20.3.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 3
  %7491 = load i8, i8* %scevgep20.3.21, align 1
  %conv68.3.21 = zext i8 %7491 to i32
  %7492 = load i8, i8* %arrayidx70.21, align 1
  %conv71.3.21 = zext i8 %7492 to i32
  %xor72.3.21 = xor i32 %conv71.3.21, %conv68.3.21
  %conv73.3.21 = trunc i32 %xor72.3.21 to i8
  store i8 %conv73.3.21, i8* %arrayidx70.21, align 1
  %scevgep20.4.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 4
  %7493 = load i8, i8* %scevgep20.4.21, align 1
  %conv68.4.21 = zext i8 %7493 to i32
  %7494 = load i8, i8* %arrayidx70.21, align 1
  %conv71.4.21 = zext i8 %7494 to i32
  %xor72.4.21 = xor i32 %conv71.4.21, %conv68.4.21
  %conv73.4.21 = trunc i32 %xor72.4.21 to i8
  store i8 %conv73.4.21, i8* %arrayidx70.21, align 1
  %scevgep20.5.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 5
  %7495 = load i8, i8* %scevgep20.5.21, align 1
  %conv68.5.21 = zext i8 %7495 to i32
  %7496 = load i8, i8* %arrayidx70.21, align 1
  %conv71.5.21 = zext i8 %7496 to i32
  %xor72.5.21 = xor i32 %conv71.5.21, %conv68.5.21
  %conv73.5.21 = trunc i32 %xor72.5.21 to i8
  store i8 %conv73.5.21, i8* %arrayidx70.21, align 1
  %scevgep20.6.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 6
  %7497 = load i8, i8* %scevgep20.6.21, align 1
  %conv68.6.21 = zext i8 %7497 to i32
  %7498 = load i8, i8* %arrayidx70.21, align 1
  %conv71.6.21 = zext i8 %7498 to i32
  %xor72.6.21 = xor i32 %conv71.6.21, %conv68.6.21
  %conv73.6.21 = trunc i32 %xor72.6.21 to i8
  store i8 %conv73.6.21, i8* %arrayidx70.21, align 1
  %scevgep20.7.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 7
  %7499 = load i8, i8* %scevgep20.7.21, align 1
  %conv68.7.21 = zext i8 %7499 to i32
  %7500 = load i8, i8* %arrayidx70.21, align 1
  %conv71.7.21 = zext i8 %7500 to i32
  %xor72.7.21 = xor i32 %conv71.7.21, %conv68.7.21
  %conv73.7.21 = trunc i32 %xor72.7.21 to i8
  store i8 %conv73.7.21, i8* %arrayidx70.21, align 1
  %scevgep20.8.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 8
  %7501 = load i8, i8* %scevgep20.8.21, align 1
  %conv68.8.21 = zext i8 %7501 to i32
  %7502 = load i8, i8* %arrayidx70.21, align 1
  %conv71.8.21 = zext i8 %7502 to i32
  %xor72.8.21 = xor i32 %conv71.8.21, %conv68.8.21
  %conv73.8.21 = trunc i32 %xor72.8.21 to i8
  store i8 %conv73.8.21, i8* %arrayidx70.21, align 1
  %scevgep20.9.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 9
  %7503 = load i8, i8* %scevgep20.9.21, align 1
  %conv68.9.21 = zext i8 %7503 to i32
  %7504 = load i8, i8* %arrayidx70.21, align 1
  %conv71.9.21 = zext i8 %7504 to i32
  %xor72.9.21 = xor i32 %conv71.9.21, %conv68.9.21
  %conv73.9.21 = trunc i32 %xor72.9.21 to i8
  store i8 %conv73.9.21, i8* %arrayidx70.21, align 1
  %scevgep20.10.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 10
  %7505 = load i8, i8* %scevgep20.10.21, align 1
  %conv68.10.21 = zext i8 %7505 to i32
  %7506 = load i8, i8* %arrayidx70.21, align 1
  %conv71.10.21 = zext i8 %7506 to i32
  %xor72.10.21 = xor i32 %conv71.10.21, %conv68.10.21
  %conv73.10.21 = trunc i32 %xor72.10.21 to i8
  store i8 %conv73.10.21, i8* %arrayidx70.21, align 1
  %scevgep20.11.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 11
  %7507 = load i8, i8* %scevgep20.11.21, align 1
  %conv68.11.21 = zext i8 %7507 to i32
  %7508 = load i8, i8* %arrayidx70.21, align 1
  %conv71.11.21 = zext i8 %7508 to i32
  %xor72.11.21 = xor i32 %conv71.11.21, %conv68.11.21
  %conv73.11.21 = trunc i32 %xor72.11.21 to i8
  store i8 %conv73.11.21, i8* %arrayidx70.21, align 1
  %scevgep20.12.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 12
  %7509 = load i8, i8* %scevgep20.12.21, align 1
  %conv68.12.21 = zext i8 %7509 to i32
  %7510 = load i8, i8* %arrayidx70.21, align 1
  %conv71.12.21 = zext i8 %7510 to i32
  %xor72.12.21 = xor i32 %conv71.12.21, %conv68.12.21
  %conv73.12.21 = trunc i32 %xor72.12.21 to i8
  store i8 %conv73.12.21, i8* %arrayidx70.21, align 1
  %scevgep20.13.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 13
  %7511 = load i8, i8* %scevgep20.13.21, align 1
  %conv68.13.21 = zext i8 %7511 to i32
  %7512 = load i8, i8* %arrayidx70.21, align 1
  %conv71.13.21 = zext i8 %7512 to i32
  %xor72.13.21 = xor i32 %conv71.13.21, %conv68.13.21
  %conv73.13.21 = trunc i32 %xor72.13.21 to i8
  store i8 %conv73.13.21, i8* %arrayidx70.21, align 1
  %scevgep20.14.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 14
  %7513 = load i8, i8* %scevgep20.14.21, align 1
  %conv68.14.21 = zext i8 %7513 to i32
  %7514 = load i8, i8* %arrayidx70.21, align 1
  %conv71.14.21 = zext i8 %7514 to i32
  %xor72.14.21 = xor i32 %conv71.14.21, %conv68.14.21
  %conv73.14.21 = trunc i32 %xor72.14.21 to i8
  store i8 %conv73.14.21, i8* %arrayidx70.21, align 1
  %scevgep20.15.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 15
  %7515 = load i8, i8* %scevgep20.15.21, align 1
  %conv68.15.21 = zext i8 %7515 to i32
  %7516 = load i8, i8* %arrayidx70.21, align 1
  %conv71.15.21 = zext i8 %7516 to i32
  %xor72.15.21 = xor i32 %conv71.15.21, %conv68.15.21
  %conv73.15.21 = trunc i32 %xor72.15.21 to i8
  store i8 %conv73.15.21, i8* %arrayidx70.21, align 1
  %scevgep20.16.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 16
  %7517 = load i8, i8* %scevgep20.16.21, align 1
  %conv68.16.21 = zext i8 %7517 to i32
  %7518 = load i8, i8* %arrayidx70.21, align 1
  %conv71.16.21 = zext i8 %7518 to i32
  %xor72.16.21 = xor i32 %conv71.16.21, %conv68.16.21
  %conv73.16.21 = trunc i32 %xor72.16.21 to i8
  store i8 %conv73.16.21, i8* %arrayidx70.21, align 1
  %scevgep20.17.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 17
  %7519 = load i8, i8* %scevgep20.17.21, align 1
  %conv68.17.21 = zext i8 %7519 to i32
  %7520 = load i8, i8* %arrayidx70.21, align 1
  %conv71.17.21 = zext i8 %7520 to i32
  %xor72.17.21 = xor i32 %conv71.17.21, %conv68.17.21
  %conv73.17.21 = trunc i32 %xor72.17.21 to i8
  store i8 %conv73.17.21, i8* %arrayidx70.21, align 1
  %scevgep20.18.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 18
  %7521 = load i8, i8* %scevgep20.18.21, align 1
  %conv68.18.21 = zext i8 %7521 to i32
  %7522 = load i8, i8* %arrayidx70.21, align 1
  %conv71.18.21 = zext i8 %7522 to i32
  %xor72.18.21 = xor i32 %conv71.18.21, %conv68.18.21
  %conv73.18.21 = trunc i32 %xor72.18.21 to i8
  store i8 %conv73.18.21, i8* %arrayidx70.21, align 1
  %scevgep20.19.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 19
  %7523 = load i8, i8* %scevgep20.19.21, align 1
  %conv68.19.21 = zext i8 %7523 to i32
  %7524 = load i8, i8* %arrayidx70.21, align 1
  %conv71.19.21 = zext i8 %7524 to i32
  %xor72.19.21 = xor i32 %conv71.19.21, %conv68.19.21
  %conv73.19.21 = trunc i32 %xor72.19.21 to i8
  store i8 %conv73.19.21, i8* %arrayidx70.21, align 1
  %scevgep20.20.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 20
  %7525 = load i8, i8* %scevgep20.20.21, align 1
  %conv68.20.21 = zext i8 %7525 to i32
  %7526 = load i8, i8* %arrayidx70.21, align 1
  %conv71.20.21 = zext i8 %7526 to i32
  %xor72.20.21 = xor i32 %conv71.20.21, %conv68.20.21
  %conv73.20.21 = trunc i32 %xor72.20.21 to i8
  store i8 %conv73.20.21, i8* %arrayidx70.21, align 1
  %scevgep20.22.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 22
  %7527 = load i8, i8* %scevgep20.22.21, align 1
  %conv68.22.21 = zext i8 %7527 to i32
  %7528 = load i8, i8* %arrayidx70.21, align 1
  %conv71.22.21 = zext i8 %7528 to i32
  %xor72.22.21 = xor i32 %conv71.22.21, %conv68.22.21
  %conv73.22.21 = trunc i32 %xor72.22.21 to i8
  store i8 %conv73.22.21, i8* %arrayidx70.21, align 1
  %scevgep20.23.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 23
  %7529 = load i8, i8* %scevgep20.23.21, align 1
  %conv68.23.21 = zext i8 %7529 to i32
  %7530 = load i8, i8* %arrayidx70.21, align 1
  %conv71.23.21 = zext i8 %7530 to i32
  %xor72.23.21 = xor i32 %conv71.23.21, %conv68.23.21
  %conv73.23.21 = trunc i32 %xor72.23.21 to i8
  store i8 %conv73.23.21, i8* %arrayidx70.21, align 1
  %scevgep20.24.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 24
  %7531 = load i8, i8* %scevgep20.24.21, align 1
  %conv68.24.21 = zext i8 %7531 to i32
  %7532 = load i8, i8* %arrayidx70.21, align 1
  %conv71.24.21 = zext i8 %7532 to i32
  %xor72.24.21 = xor i32 %conv71.24.21, %conv68.24.21
  %conv73.24.21 = trunc i32 %xor72.24.21 to i8
  store i8 %conv73.24.21, i8* %arrayidx70.21, align 1
  %scevgep20.25.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 25
  %7533 = load i8, i8* %scevgep20.25.21, align 1
  %conv68.25.21 = zext i8 %7533 to i32
  %7534 = load i8, i8* %arrayidx70.21, align 1
  %conv71.25.21 = zext i8 %7534 to i32
  %xor72.25.21 = xor i32 %conv71.25.21, %conv68.25.21
  %conv73.25.21 = trunc i32 %xor72.25.21 to i8
  store i8 %conv73.25.21, i8* %arrayidx70.21, align 1
  %scevgep20.26.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 26
  %7535 = load i8, i8* %scevgep20.26.21, align 1
  %conv68.26.21 = zext i8 %7535 to i32
  %7536 = load i8, i8* %arrayidx70.21, align 1
  %conv71.26.21 = zext i8 %7536 to i32
  %xor72.26.21 = xor i32 %conv71.26.21, %conv68.26.21
  %conv73.26.21 = trunc i32 %xor72.26.21 to i8
  store i8 %conv73.26.21, i8* %arrayidx70.21, align 1
  %scevgep20.27.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 27
  %7537 = load i8, i8* %scevgep20.27.21, align 1
  %conv68.27.21 = zext i8 %7537 to i32
  %7538 = load i8, i8* %arrayidx70.21, align 1
  %conv71.27.21 = zext i8 %7538 to i32
  %xor72.27.21 = xor i32 %conv71.27.21, %conv68.27.21
  %conv73.27.21 = trunc i32 %xor72.27.21 to i8
  store i8 %conv73.27.21, i8* %arrayidx70.21, align 1
  %scevgep20.28.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 28
  %7539 = load i8, i8* %scevgep20.28.21, align 1
  %conv68.28.21 = zext i8 %7539 to i32
  %7540 = load i8, i8* %arrayidx70.21, align 1
  %conv71.28.21 = zext i8 %7540 to i32
  %xor72.28.21 = xor i32 %conv71.28.21, %conv68.28.21
  %conv73.28.21 = trunc i32 %xor72.28.21 to i8
  store i8 %conv73.28.21, i8* %arrayidx70.21, align 1
  %scevgep20.29.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 29
  %7541 = load i8, i8* %scevgep20.29.21, align 1
  %conv68.29.21 = zext i8 %7541 to i32
  %7542 = load i8, i8* %arrayidx70.21, align 1
  %conv71.29.21 = zext i8 %7542 to i32
  %xor72.29.21 = xor i32 %conv71.29.21, %conv68.29.21
  %conv73.29.21 = trunc i32 %xor72.29.21 to i8
  store i8 %conv73.29.21, i8* %arrayidx70.21, align 1
  %scevgep20.30.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 30
  %7543 = load i8, i8* %scevgep20.30.21, align 1
  %conv68.30.21 = zext i8 %7543 to i32
  %7544 = load i8, i8* %arrayidx70.21, align 1
  %conv71.30.21 = zext i8 %7544 to i32
  %xor72.30.21 = xor i32 %conv71.30.21, %conv68.30.21
  %conv73.30.21 = trunc i32 %xor72.30.21 to i8
  store i8 %conv73.30.21, i8* %arrayidx70.21, align 1
  %scevgep20.31.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 31
  %7545 = load i8, i8* %scevgep20.31.21, align 1
  %conv68.31.21 = zext i8 %7545 to i32
  %7546 = load i8, i8* %arrayidx70.21, align 1
  %conv71.31.21 = zext i8 %7546 to i32
  %xor72.31.21 = xor i32 %conv71.31.21, %conv68.31.21
  %conv73.31.21 = trunc i32 %xor72.31.21 to i8
  store i8 %conv73.31.21, i8* %arrayidx70.21, align 1
  %scevgep20.32.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 32
  %7547 = load i8, i8* %scevgep20.32.21, align 1
  %conv68.32.21 = zext i8 %7547 to i32
  %7548 = load i8, i8* %arrayidx70.21, align 1
  %conv71.32.21 = zext i8 %7548 to i32
  %xor72.32.21 = xor i32 %conv71.32.21, %conv68.32.21
  %conv73.32.21 = trunc i32 %xor72.32.21 to i8
  store i8 %conv73.32.21, i8* %arrayidx70.21, align 1
  %scevgep20.33.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 33
  %7549 = load i8, i8* %scevgep20.33.21, align 1
  %conv68.33.21 = zext i8 %7549 to i32
  %7550 = load i8, i8* %arrayidx70.21, align 1
  %conv71.33.21 = zext i8 %7550 to i32
  %xor72.33.21 = xor i32 %conv71.33.21, %conv68.33.21
  %conv73.33.21 = trunc i32 %xor72.33.21 to i8
  store i8 %conv73.33.21, i8* %arrayidx70.21, align 1
  %scevgep20.34.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 34
  %7551 = load i8, i8* %scevgep20.34.21, align 1
  %conv68.34.21 = zext i8 %7551 to i32
  %7552 = load i8, i8* %arrayidx70.21, align 1
  %conv71.34.21 = zext i8 %7552 to i32
  %xor72.34.21 = xor i32 %conv71.34.21, %conv68.34.21
  %conv73.34.21 = trunc i32 %xor72.34.21 to i8
  store i8 %conv73.34.21, i8* %arrayidx70.21, align 1
  %scevgep20.35.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 35
  %7553 = load i8, i8* %scevgep20.35.21, align 1
  %conv68.35.21 = zext i8 %7553 to i32
  %7554 = load i8, i8* %arrayidx70.21, align 1
  %conv71.35.21 = zext i8 %7554 to i32
  %xor72.35.21 = xor i32 %conv71.35.21, %conv68.35.21
  %conv73.35.21 = trunc i32 %xor72.35.21 to i8
  store i8 %conv73.35.21, i8* %arrayidx70.21, align 1
  %scevgep20.36.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 36
  %7555 = load i8, i8* %scevgep20.36.21, align 1
  %conv68.36.21 = zext i8 %7555 to i32
  %7556 = load i8, i8* %arrayidx70.21, align 1
  %conv71.36.21 = zext i8 %7556 to i32
  %xor72.36.21 = xor i32 %conv71.36.21, %conv68.36.21
  %conv73.36.21 = trunc i32 %xor72.36.21 to i8
  store i8 %conv73.36.21, i8* %arrayidx70.21, align 1
  %scevgep20.37.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 37
  %7557 = load i8, i8* %scevgep20.37.21, align 1
  %conv68.37.21 = zext i8 %7557 to i32
  %7558 = load i8, i8* %arrayidx70.21, align 1
  %conv71.37.21 = zext i8 %7558 to i32
  %xor72.37.21 = xor i32 %conv71.37.21, %conv68.37.21
  %conv73.37.21 = trunc i32 %xor72.37.21 to i8
  store i8 %conv73.37.21, i8* %arrayidx70.21, align 1
  %scevgep20.38.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 38
  %7559 = load i8, i8* %scevgep20.38.21, align 1
  %conv68.38.21 = zext i8 %7559 to i32
  %7560 = load i8, i8* %arrayidx70.21, align 1
  %conv71.38.21 = zext i8 %7560 to i32
  %xor72.38.21 = xor i32 %conv71.38.21, %conv68.38.21
  %conv73.38.21 = trunc i32 %xor72.38.21 to i8
  store i8 %conv73.38.21, i8* %arrayidx70.21, align 1
  %scevgep20.39.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 39
  %7561 = load i8, i8* %scevgep20.39.21, align 1
  %conv68.39.21 = zext i8 %7561 to i32
  %7562 = load i8, i8* %arrayidx70.21, align 1
  %conv71.39.21 = zext i8 %7562 to i32
  %xor72.39.21 = xor i32 %conv71.39.21, %conv68.39.21
  %conv73.39.21 = trunc i32 %xor72.39.21 to i8
  store i8 %conv73.39.21, i8* %arrayidx70.21, align 1
  %scevgep20.40.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 0, i64 40
  %7563 = load i8, i8* %scevgep20.40.21, align 1
  %conv68.40.21 = zext i8 %7563 to i32
  %7564 = load i8, i8* %arrayidx70.21, align 1
  %conv71.40.21 = zext i8 %7564 to i32
  %xor72.40.21 = xor i32 %conv71.40.21, %conv68.40.21
  %conv73.40.21 = trunc i32 %xor72.40.21 to i8
  store i8 %conv73.40.21, i8* %arrayidx70.21, align 1
  %scevgep19.21 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7482, i64 0, i64 1, i64 0
  %7565 = bitcast i8* %scevgep19.21 to [41 x [41 x i8]]*
  %arrayidx51.22 = getelementptr inbounds i8, i8* %a, i64 22
  %7566 = load i8, i8* %arrayidx51.22, align 1
  %arrayidx53.22 = getelementptr inbounds i8, i8* %b, i64 22
  %7567 = load i8, i8* %arrayidx53.22, align 1
  %call54.22 = call zeroext i8 @mult(i8 zeroext %7566, i8 zeroext %7567)
  %arrayidx56.22 = getelementptr inbounds i8, i8* %c, i64 22
  store i8 %call54.22, i8* %arrayidx56.22, align 1
  %arrayidx70.22 = getelementptr inbounds i8, i8* %c, i64 22
  %scevgep20.22264 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 0
  %7568 = load i8, i8* %scevgep20.22264, align 1
  %conv68.22265 = zext i8 %7568 to i32
  %7569 = load i8, i8* %arrayidx70.22, align 1
  %conv71.22266 = zext i8 %7569 to i32
  %xor72.22267 = xor i32 %conv71.22266, %conv68.22265
  %conv73.22268 = trunc i32 %xor72.22267 to i8
  store i8 %conv73.22268, i8* %arrayidx70.22, align 1
  %scevgep20.1.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 1
  %7570 = load i8, i8* %scevgep20.1.22, align 1
  %conv68.1.22 = zext i8 %7570 to i32
  %7571 = load i8, i8* %arrayidx70.22, align 1
  %conv71.1.22 = zext i8 %7571 to i32
  %xor72.1.22 = xor i32 %conv71.1.22, %conv68.1.22
  %conv73.1.22 = trunc i32 %xor72.1.22 to i8
  store i8 %conv73.1.22, i8* %arrayidx70.22, align 1
  %scevgep20.2.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 2
  %7572 = load i8, i8* %scevgep20.2.22, align 1
  %conv68.2.22 = zext i8 %7572 to i32
  %7573 = load i8, i8* %arrayidx70.22, align 1
  %conv71.2.22 = zext i8 %7573 to i32
  %xor72.2.22 = xor i32 %conv71.2.22, %conv68.2.22
  %conv73.2.22 = trunc i32 %xor72.2.22 to i8
  store i8 %conv73.2.22, i8* %arrayidx70.22, align 1
  %scevgep20.3.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 3
  %7574 = load i8, i8* %scevgep20.3.22, align 1
  %conv68.3.22 = zext i8 %7574 to i32
  %7575 = load i8, i8* %arrayidx70.22, align 1
  %conv71.3.22 = zext i8 %7575 to i32
  %xor72.3.22 = xor i32 %conv71.3.22, %conv68.3.22
  %conv73.3.22 = trunc i32 %xor72.3.22 to i8
  store i8 %conv73.3.22, i8* %arrayidx70.22, align 1
  %scevgep20.4.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 4
  %7576 = load i8, i8* %scevgep20.4.22, align 1
  %conv68.4.22 = zext i8 %7576 to i32
  %7577 = load i8, i8* %arrayidx70.22, align 1
  %conv71.4.22 = zext i8 %7577 to i32
  %xor72.4.22 = xor i32 %conv71.4.22, %conv68.4.22
  %conv73.4.22 = trunc i32 %xor72.4.22 to i8
  store i8 %conv73.4.22, i8* %arrayidx70.22, align 1
  %scevgep20.5.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 5
  %7578 = load i8, i8* %scevgep20.5.22, align 1
  %conv68.5.22 = zext i8 %7578 to i32
  %7579 = load i8, i8* %arrayidx70.22, align 1
  %conv71.5.22 = zext i8 %7579 to i32
  %xor72.5.22 = xor i32 %conv71.5.22, %conv68.5.22
  %conv73.5.22 = trunc i32 %xor72.5.22 to i8
  store i8 %conv73.5.22, i8* %arrayidx70.22, align 1
  %scevgep20.6.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 6
  %7580 = load i8, i8* %scevgep20.6.22, align 1
  %conv68.6.22 = zext i8 %7580 to i32
  %7581 = load i8, i8* %arrayidx70.22, align 1
  %conv71.6.22 = zext i8 %7581 to i32
  %xor72.6.22 = xor i32 %conv71.6.22, %conv68.6.22
  %conv73.6.22 = trunc i32 %xor72.6.22 to i8
  store i8 %conv73.6.22, i8* %arrayidx70.22, align 1
  %scevgep20.7.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 7
  %7582 = load i8, i8* %scevgep20.7.22, align 1
  %conv68.7.22 = zext i8 %7582 to i32
  %7583 = load i8, i8* %arrayidx70.22, align 1
  %conv71.7.22 = zext i8 %7583 to i32
  %xor72.7.22 = xor i32 %conv71.7.22, %conv68.7.22
  %conv73.7.22 = trunc i32 %xor72.7.22 to i8
  store i8 %conv73.7.22, i8* %arrayidx70.22, align 1
  %scevgep20.8.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 8
  %7584 = load i8, i8* %scevgep20.8.22, align 1
  %conv68.8.22 = zext i8 %7584 to i32
  %7585 = load i8, i8* %arrayidx70.22, align 1
  %conv71.8.22 = zext i8 %7585 to i32
  %xor72.8.22 = xor i32 %conv71.8.22, %conv68.8.22
  %conv73.8.22 = trunc i32 %xor72.8.22 to i8
  store i8 %conv73.8.22, i8* %arrayidx70.22, align 1
  %scevgep20.9.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 9
  %7586 = load i8, i8* %scevgep20.9.22, align 1
  %conv68.9.22 = zext i8 %7586 to i32
  %7587 = load i8, i8* %arrayidx70.22, align 1
  %conv71.9.22 = zext i8 %7587 to i32
  %xor72.9.22 = xor i32 %conv71.9.22, %conv68.9.22
  %conv73.9.22 = trunc i32 %xor72.9.22 to i8
  store i8 %conv73.9.22, i8* %arrayidx70.22, align 1
  %scevgep20.10.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 10
  %7588 = load i8, i8* %scevgep20.10.22, align 1
  %conv68.10.22 = zext i8 %7588 to i32
  %7589 = load i8, i8* %arrayidx70.22, align 1
  %conv71.10.22 = zext i8 %7589 to i32
  %xor72.10.22 = xor i32 %conv71.10.22, %conv68.10.22
  %conv73.10.22 = trunc i32 %xor72.10.22 to i8
  store i8 %conv73.10.22, i8* %arrayidx70.22, align 1
  %scevgep20.11.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 11
  %7590 = load i8, i8* %scevgep20.11.22, align 1
  %conv68.11.22 = zext i8 %7590 to i32
  %7591 = load i8, i8* %arrayidx70.22, align 1
  %conv71.11.22 = zext i8 %7591 to i32
  %xor72.11.22 = xor i32 %conv71.11.22, %conv68.11.22
  %conv73.11.22 = trunc i32 %xor72.11.22 to i8
  store i8 %conv73.11.22, i8* %arrayidx70.22, align 1
  %scevgep20.12.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 12
  %7592 = load i8, i8* %scevgep20.12.22, align 1
  %conv68.12.22 = zext i8 %7592 to i32
  %7593 = load i8, i8* %arrayidx70.22, align 1
  %conv71.12.22 = zext i8 %7593 to i32
  %xor72.12.22 = xor i32 %conv71.12.22, %conv68.12.22
  %conv73.12.22 = trunc i32 %xor72.12.22 to i8
  store i8 %conv73.12.22, i8* %arrayidx70.22, align 1
  %scevgep20.13.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 13
  %7594 = load i8, i8* %scevgep20.13.22, align 1
  %conv68.13.22 = zext i8 %7594 to i32
  %7595 = load i8, i8* %arrayidx70.22, align 1
  %conv71.13.22 = zext i8 %7595 to i32
  %xor72.13.22 = xor i32 %conv71.13.22, %conv68.13.22
  %conv73.13.22 = trunc i32 %xor72.13.22 to i8
  store i8 %conv73.13.22, i8* %arrayidx70.22, align 1
  %scevgep20.14.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 14
  %7596 = load i8, i8* %scevgep20.14.22, align 1
  %conv68.14.22 = zext i8 %7596 to i32
  %7597 = load i8, i8* %arrayidx70.22, align 1
  %conv71.14.22 = zext i8 %7597 to i32
  %xor72.14.22 = xor i32 %conv71.14.22, %conv68.14.22
  %conv73.14.22 = trunc i32 %xor72.14.22 to i8
  store i8 %conv73.14.22, i8* %arrayidx70.22, align 1
  %scevgep20.15.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 15
  %7598 = load i8, i8* %scevgep20.15.22, align 1
  %conv68.15.22 = zext i8 %7598 to i32
  %7599 = load i8, i8* %arrayidx70.22, align 1
  %conv71.15.22 = zext i8 %7599 to i32
  %xor72.15.22 = xor i32 %conv71.15.22, %conv68.15.22
  %conv73.15.22 = trunc i32 %xor72.15.22 to i8
  store i8 %conv73.15.22, i8* %arrayidx70.22, align 1
  %scevgep20.16.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 16
  %7600 = load i8, i8* %scevgep20.16.22, align 1
  %conv68.16.22 = zext i8 %7600 to i32
  %7601 = load i8, i8* %arrayidx70.22, align 1
  %conv71.16.22 = zext i8 %7601 to i32
  %xor72.16.22 = xor i32 %conv71.16.22, %conv68.16.22
  %conv73.16.22 = trunc i32 %xor72.16.22 to i8
  store i8 %conv73.16.22, i8* %arrayidx70.22, align 1
  %scevgep20.17.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 17
  %7602 = load i8, i8* %scevgep20.17.22, align 1
  %conv68.17.22 = zext i8 %7602 to i32
  %7603 = load i8, i8* %arrayidx70.22, align 1
  %conv71.17.22 = zext i8 %7603 to i32
  %xor72.17.22 = xor i32 %conv71.17.22, %conv68.17.22
  %conv73.17.22 = trunc i32 %xor72.17.22 to i8
  store i8 %conv73.17.22, i8* %arrayidx70.22, align 1
  %scevgep20.18.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 18
  %7604 = load i8, i8* %scevgep20.18.22, align 1
  %conv68.18.22 = zext i8 %7604 to i32
  %7605 = load i8, i8* %arrayidx70.22, align 1
  %conv71.18.22 = zext i8 %7605 to i32
  %xor72.18.22 = xor i32 %conv71.18.22, %conv68.18.22
  %conv73.18.22 = trunc i32 %xor72.18.22 to i8
  store i8 %conv73.18.22, i8* %arrayidx70.22, align 1
  %scevgep20.19.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 19
  %7606 = load i8, i8* %scevgep20.19.22, align 1
  %conv68.19.22 = zext i8 %7606 to i32
  %7607 = load i8, i8* %arrayidx70.22, align 1
  %conv71.19.22 = zext i8 %7607 to i32
  %xor72.19.22 = xor i32 %conv71.19.22, %conv68.19.22
  %conv73.19.22 = trunc i32 %xor72.19.22 to i8
  store i8 %conv73.19.22, i8* %arrayidx70.22, align 1
  %scevgep20.20.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 20
  %7608 = load i8, i8* %scevgep20.20.22, align 1
  %conv68.20.22 = zext i8 %7608 to i32
  %7609 = load i8, i8* %arrayidx70.22, align 1
  %conv71.20.22 = zext i8 %7609 to i32
  %xor72.20.22 = xor i32 %conv71.20.22, %conv68.20.22
  %conv73.20.22 = trunc i32 %xor72.20.22 to i8
  store i8 %conv73.20.22, i8* %arrayidx70.22, align 1
  %scevgep20.21.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 21
  %7610 = load i8, i8* %scevgep20.21.22, align 1
  %conv68.21.22 = zext i8 %7610 to i32
  %7611 = load i8, i8* %arrayidx70.22, align 1
  %conv71.21.22 = zext i8 %7611 to i32
  %xor72.21.22 = xor i32 %conv71.21.22, %conv68.21.22
  %conv73.21.22 = trunc i32 %xor72.21.22 to i8
  store i8 %conv73.21.22, i8* %arrayidx70.22, align 1
  %scevgep20.23.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 23
  %7612 = load i8, i8* %scevgep20.23.22, align 1
  %conv68.23.22 = zext i8 %7612 to i32
  %7613 = load i8, i8* %arrayidx70.22, align 1
  %conv71.23.22 = zext i8 %7613 to i32
  %xor72.23.22 = xor i32 %conv71.23.22, %conv68.23.22
  %conv73.23.22 = trunc i32 %xor72.23.22 to i8
  store i8 %conv73.23.22, i8* %arrayidx70.22, align 1
  %scevgep20.24.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 24
  %7614 = load i8, i8* %scevgep20.24.22, align 1
  %conv68.24.22 = zext i8 %7614 to i32
  %7615 = load i8, i8* %arrayidx70.22, align 1
  %conv71.24.22 = zext i8 %7615 to i32
  %xor72.24.22 = xor i32 %conv71.24.22, %conv68.24.22
  %conv73.24.22 = trunc i32 %xor72.24.22 to i8
  store i8 %conv73.24.22, i8* %arrayidx70.22, align 1
  %scevgep20.25.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 25
  %7616 = load i8, i8* %scevgep20.25.22, align 1
  %conv68.25.22 = zext i8 %7616 to i32
  %7617 = load i8, i8* %arrayidx70.22, align 1
  %conv71.25.22 = zext i8 %7617 to i32
  %xor72.25.22 = xor i32 %conv71.25.22, %conv68.25.22
  %conv73.25.22 = trunc i32 %xor72.25.22 to i8
  store i8 %conv73.25.22, i8* %arrayidx70.22, align 1
  %scevgep20.26.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 26
  %7618 = load i8, i8* %scevgep20.26.22, align 1
  %conv68.26.22 = zext i8 %7618 to i32
  %7619 = load i8, i8* %arrayidx70.22, align 1
  %conv71.26.22 = zext i8 %7619 to i32
  %xor72.26.22 = xor i32 %conv71.26.22, %conv68.26.22
  %conv73.26.22 = trunc i32 %xor72.26.22 to i8
  store i8 %conv73.26.22, i8* %arrayidx70.22, align 1
  %scevgep20.27.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 27
  %7620 = load i8, i8* %scevgep20.27.22, align 1
  %conv68.27.22 = zext i8 %7620 to i32
  %7621 = load i8, i8* %arrayidx70.22, align 1
  %conv71.27.22 = zext i8 %7621 to i32
  %xor72.27.22 = xor i32 %conv71.27.22, %conv68.27.22
  %conv73.27.22 = trunc i32 %xor72.27.22 to i8
  store i8 %conv73.27.22, i8* %arrayidx70.22, align 1
  %scevgep20.28.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 28
  %7622 = load i8, i8* %scevgep20.28.22, align 1
  %conv68.28.22 = zext i8 %7622 to i32
  %7623 = load i8, i8* %arrayidx70.22, align 1
  %conv71.28.22 = zext i8 %7623 to i32
  %xor72.28.22 = xor i32 %conv71.28.22, %conv68.28.22
  %conv73.28.22 = trunc i32 %xor72.28.22 to i8
  store i8 %conv73.28.22, i8* %arrayidx70.22, align 1
  %scevgep20.29.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 29
  %7624 = load i8, i8* %scevgep20.29.22, align 1
  %conv68.29.22 = zext i8 %7624 to i32
  %7625 = load i8, i8* %arrayidx70.22, align 1
  %conv71.29.22 = zext i8 %7625 to i32
  %xor72.29.22 = xor i32 %conv71.29.22, %conv68.29.22
  %conv73.29.22 = trunc i32 %xor72.29.22 to i8
  store i8 %conv73.29.22, i8* %arrayidx70.22, align 1
  %scevgep20.30.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 30
  %7626 = load i8, i8* %scevgep20.30.22, align 1
  %conv68.30.22 = zext i8 %7626 to i32
  %7627 = load i8, i8* %arrayidx70.22, align 1
  %conv71.30.22 = zext i8 %7627 to i32
  %xor72.30.22 = xor i32 %conv71.30.22, %conv68.30.22
  %conv73.30.22 = trunc i32 %xor72.30.22 to i8
  store i8 %conv73.30.22, i8* %arrayidx70.22, align 1
  %scevgep20.31.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 31
  %7628 = load i8, i8* %scevgep20.31.22, align 1
  %conv68.31.22 = zext i8 %7628 to i32
  %7629 = load i8, i8* %arrayidx70.22, align 1
  %conv71.31.22 = zext i8 %7629 to i32
  %xor72.31.22 = xor i32 %conv71.31.22, %conv68.31.22
  %conv73.31.22 = trunc i32 %xor72.31.22 to i8
  store i8 %conv73.31.22, i8* %arrayidx70.22, align 1
  %scevgep20.32.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 32
  %7630 = load i8, i8* %scevgep20.32.22, align 1
  %conv68.32.22 = zext i8 %7630 to i32
  %7631 = load i8, i8* %arrayidx70.22, align 1
  %conv71.32.22 = zext i8 %7631 to i32
  %xor72.32.22 = xor i32 %conv71.32.22, %conv68.32.22
  %conv73.32.22 = trunc i32 %xor72.32.22 to i8
  store i8 %conv73.32.22, i8* %arrayidx70.22, align 1
  %scevgep20.33.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 33
  %7632 = load i8, i8* %scevgep20.33.22, align 1
  %conv68.33.22 = zext i8 %7632 to i32
  %7633 = load i8, i8* %arrayidx70.22, align 1
  %conv71.33.22 = zext i8 %7633 to i32
  %xor72.33.22 = xor i32 %conv71.33.22, %conv68.33.22
  %conv73.33.22 = trunc i32 %xor72.33.22 to i8
  store i8 %conv73.33.22, i8* %arrayidx70.22, align 1
  %scevgep20.34.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 34
  %7634 = load i8, i8* %scevgep20.34.22, align 1
  %conv68.34.22 = zext i8 %7634 to i32
  %7635 = load i8, i8* %arrayidx70.22, align 1
  %conv71.34.22 = zext i8 %7635 to i32
  %xor72.34.22 = xor i32 %conv71.34.22, %conv68.34.22
  %conv73.34.22 = trunc i32 %xor72.34.22 to i8
  store i8 %conv73.34.22, i8* %arrayidx70.22, align 1
  %scevgep20.35.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 35
  %7636 = load i8, i8* %scevgep20.35.22, align 1
  %conv68.35.22 = zext i8 %7636 to i32
  %7637 = load i8, i8* %arrayidx70.22, align 1
  %conv71.35.22 = zext i8 %7637 to i32
  %xor72.35.22 = xor i32 %conv71.35.22, %conv68.35.22
  %conv73.35.22 = trunc i32 %xor72.35.22 to i8
  store i8 %conv73.35.22, i8* %arrayidx70.22, align 1
  %scevgep20.36.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 36
  %7638 = load i8, i8* %scevgep20.36.22, align 1
  %conv68.36.22 = zext i8 %7638 to i32
  %7639 = load i8, i8* %arrayidx70.22, align 1
  %conv71.36.22 = zext i8 %7639 to i32
  %xor72.36.22 = xor i32 %conv71.36.22, %conv68.36.22
  %conv73.36.22 = trunc i32 %xor72.36.22 to i8
  store i8 %conv73.36.22, i8* %arrayidx70.22, align 1
  %scevgep20.37.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 37
  %7640 = load i8, i8* %scevgep20.37.22, align 1
  %conv68.37.22 = zext i8 %7640 to i32
  %7641 = load i8, i8* %arrayidx70.22, align 1
  %conv71.37.22 = zext i8 %7641 to i32
  %xor72.37.22 = xor i32 %conv71.37.22, %conv68.37.22
  %conv73.37.22 = trunc i32 %xor72.37.22 to i8
  store i8 %conv73.37.22, i8* %arrayidx70.22, align 1
  %scevgep20.38.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 38
  %7642 = load i8, i8* %scevgep20.38.22, align 1
  %conv68.38.22 = zext i8 %7642 to i32
  %7643 = load i8, i8* %arrayidx70.22, align 1
  %conv71.38.22 = zext i8 %7643 to i32
  %xor72.38.22 = xor i32 %conv71.38.22, %conv68.38.22
  %conv73.38.22 = trunc i32 %xor72.38.22 to i8
  store i8 %conv73.38.22, i8* %arrayidx70.22, align 1
  %scevgep20.39.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 39
  %7644 = load i8, i8* %scevgep20.39.22, align 1
  %conv68.39.22 = zext i8 %7644 to i32
  %7645 = load i8, i8* %arrayidx70.22, align 1
  %conv71.39.22 = zext i8 %7645 to i32
  %xor72.39.22 = xor i32 %conv71.39.22, %conv68.39.22
  %conv73.39.22 = trunc i32 %xor72.39.22 to i8
  store i8 %conv73.39.22, i8* %arrayidx70.22, align 1
  %scevgep20.40.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 0, i64 40
  %7646 = load i8, i8* %scevgep20.40.22, align 1
  %conv68.40.22 = zext i8 %7646 to i32
  %7647 = load i8, i8* %arrayidx70.22, align 1
  %conv71.40.22 = zext i8 %7647 to i32
  %xor72.40.22 = xor i32 %conv71.40.22, %conv68.40.22
  %conv73.40.22 = trunc i32 %xor72.40.22 to i8
  store i8 %conv73.40.22, i8* %arrayidx70.22, align 1
  %scevgep19.22 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7565, i64 0, i64 1, i64 0
  %7648 = bitcast i8* %scevgep19.22 to [41 x [41 x i8]]*
  %arrayidx51.23 = getelementptr inbounds i8, i8* %a, i64 23
  %7649 = load i8, i8* %arrayidx51.23, align 1
  %arrayidx53.23 = getelementptr inbounds i8, i8* %b, i64 23
  %7650 = load i8, i8* %arrayidx53.23, align 1
  %call54.23 = call zeroext i8 @mult(i8 zeroext %7649, i8 zeroext %7650)
  %arrayidx56.23 = getelementptr inbounds i8, i8* %c, i64 23
  store i8 %call54.23, i8* %arrayidx56.23, align 1
  %arrayidx70.23 = getelementptr inbounds i8, i8* %c, i64 23
  %scevgep20.23274 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 0
  %7651 = load i8, i8* %scevgep20.23274, align 1
  %conv68.23275 = zext i8 %7651 to i32
  %7652 = load i8, i8* %arrayidx70.23, align 1
  %conv71.23276 = zext i8 %7652 to i32
  %xor72.23277 = xor i32 %conv71.23276, %conv68.23275
  %conv73.23278 = trunc i32 %xor72.23277 to i8
  store i8 %conv73.23278, i8* %arrayidx70.23, align 1
  %scevgep20.1.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 1
  %7653 = load i8, i8* %scevgep20.1.23, align 1
  %conv68.1.23 = zext i8 %7653 to i32
  %7654 = load i8, i8* %arrayidx70.23, align 1
  %conv71.1.23 = zext i8 %7654 to i32
  %xor72.1.23 = xor i32 %conv71.1.23, %conv68.1.23
  %conv73.1.23 = trunc i32 %xor72.1.23 to i8
  store i8 %conv73.1.23, i8* %arrayidx70.23, align 1
  %scevgep20.2.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 2
  %7655 = load i8, i8* %scevgep20.2.23, align 1
  %conv68.2.23 = zext i8 %7655 to i32
  %7656 = load i8, i8* %arrayidx70.23, align 1
  %conv71.2.23 = zext i8 %7656 to i32
  %xor72.2.23 = xor i32 %conv71.2.23, %conv68.2.23
  %conv73.2.23 = trunc i32 %xor72.2.23 to i8
  store i8 %conv73.2.23, i8* %arrayidx70.23, align 1
  %scevgep20.3.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 3
  %7657 = load i8, i8* %scevgep20.3.23, align 1
  %conv68.3.23 = zext i8 %7657 to i32
  %7658 = load i8, i8* %arrayidx70.23, align 1
  %conv71.3.23 = zext i8 %7658 to i32
  %xor72.3.23 = xor i32 %conv71.3.23, %conv68.3.23
  %conv73.3.23 = trunc i32 %xor72.3.23 to i8
  store i8 %conv73.3.23, i8* %arrayidx70.23, align 1
  %scevgep20.4.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 4
  %7659 = load i8, i8* %scevgep20.4.23, align 1
  %conv68.4.23 = zext i8 %7659 to i32
  %7660 = load i8, i8* %arrayidx70.23, align 1
  %conv71.4.23 = zext i8 %7660 to i32
  %xor72.4.23 = xor i32 %conv71.4.23, %conv68.4.23
  %conv73.4.23 = trunc i32 %xor72.4.23 to i8
  store i8 %conv73.4.23, i8* %arrayidx70.23, align 1
  %scevgep20.5.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 5
  %7661 = load i8, i8* %scevgep20.5.23, align 1
  %conv68.5.23 = zext i8 %7661 to i32
  %7662 = load i8, i8* %arrayidx70.23, align 1
  %conv71.5.23 = zext i8 %7662 to i32
  %xor72.5.23 = xor i32 %conv71.5.23, %conv68.5.23
  %conv73.5.23 = trunc i32 %xor72.5.23 to i8
  store i8 %conv73.5.23, i8* %arrayidx70.23, align 1
  %scevgep20.6.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 6
  %7663 = load i8, i8* %scevgep20.6.23, align 1
  %conv68.6.23 = zext i8 %7663 to i32
  %7664 = load i8, i8* %arrayidx70.23, align 1
  %conv71.6.23 = zext i8 %7664 to i32
  %xor72.6.23 = xor i32 %conv71.6.23, %conv68.6.23
  %conv73.6.23 = trunc i32 %xor72.6.23 to i8
  store i8 %conv73.6.23, i8* %arrayidx70.23, align 1
  %scevgep20.7.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 7
  %7665 = load i8, i8* %scevgep20.7.23, align 1
  %conv68.7.23 = zext i8 %7665 to i32
  %7666 = load i8, i8* %arrayidx70.23, align 1
  %conv71.7.23 = zext i8 %7666 to i32
  %xor72.7.23 = xor i32 %conv71.7.23, %conv68.7.23
  %conv73.7.23 = trunc i32 %xor72.7.23 to i8
  store i8 %conv73.7.23, i8* %arrayidx70.23, align 1
  %scevgep20.8.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 8
  %7667 = load i8, i8* %scevgep20.8.23, align 1
  %conv68.8.23 = zext i8 %7667 to i32
  %7668 = load i8, i8* %arrayidx70.23, align 1
  %conv71.8.23 = zext i8 %7668 to i32
  %xor72.8.23 = xor i32 %conv71.8.23, %conv68.8.23
  %conv73.8.23 = trunc i32 %xor72.8.23 to i8
  store i8 %conv73.8.23, i8* %arrayidx70.23, align 1
  %scevgep20.9.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 9
  %7669 = load i8, i8* %scevgep20.9.23, align 1
  %conv68.9.23 = zext i8 %7669 to i32
  %7670 = load i8, i8* %arrayidx70.23, align 1
  %conv71.9.23 = zext i8 %7670 to i32
  %xor72.9.23 = xor i32 %conv71.9.23, %conv68.9.23
  %conv73.9.23 = trunc i32 %xor72.9.23 to i8
  store i8 %conv73.9.23, i8* %arrayidx70.23, align 1
  %scevgep20.10.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 10
  %7671 = load i8, i8* %scevgep20.10.23, align 1
  %conv68.10.23 = zext i8 %7671 to i32
  %7672 = load i8, i8* %arrayidx70.23, align 1
  %conv71.10.23 = zext i8 %7672 to i32
  %xor72.10.23 = xor i32 %conv71.10.23, %conv68.10.23
  %conv73.10.23 = trunc i32 %xor72.10.23 to i8
  store i8 %conv73.10.23, i8* %arrayidx70.23, align 1
  %scevgep20.11.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 11
  %7673 = load i8, i8* %scevgep20.11.23, align 1
  %conv68.11.23 = zext i8 %7673 to i32
  %7674 = load i8, i8* %arrayidx70.23, align 1
  %conv71.11.23 = zext i8 %7674 to i32
  %xor72.11.23 = xor i32 %conv71.11.23, %conv68.11.23
  %conv73.11.23 = trunc i32 %xor72.11.23 to i8
  store i8 %conv73.11.23, i8* %arrayidx70.23, align 1
  %scevgep20.12.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 12
  %7675 = load i8, i8* %scevgep20.12.23, align 1
  %conv68.12.23 = zext i8 %7675 to i32
  %7676 = load i8, i8* %arrayidx70.23, align 1
  %conv71.12.23 = zext i8 %7676 to i32
  %xor72.12.23 = xor i32 %conv71.12.23, %conv68.12.23
  %conv73.12.23 = trunc i32 %xor72.12.23 to i8
  store i8 %conv73.12.23, i8* %arrayidx70.23, align 1
  %scevgep20.13.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 13
  %7677 = load i8, i8* %scevgep20.13.23, align 1
  %conv68.13.23 = zext i8 %7677 to i32
  %7678 = load i8, i8* %arrayidx70.23, align 1
  %conv71.13.23 = zext i8 %7678 to i32
  %xor72.13.23 = xor i32 %conv71.13.23, %conv68.13.23
  %conv73.13.23 = trunc i32 %xor72.13.23 to i8
  store i8 %conv73.13.23, i8* %arrayidx70.23, align 1
  %scevgep20.14.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 14
  %7679 = load i8, i8* %scevgep20.14.23, align 1
  %conv68.14.23 = zext i8 %7679 to i32
  %7680 = load i8, i8* %arrayidx70.23, align 1
  %conv71.14.23 = zext i8 %7680 to i32
  %xor72.14.23 = xor i32 %conv71.14.23, %conv68.14.23
  %conv73.14.23 = trunc i32 %xor72.14.23 to i8
  store i8 %conv73.14.23, i8* %arrayidx70.23, align 1
  %scevgep20.15.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 15
  %7681 = load i8, i8* %scevgep20.15.23, align 1
  %conv68.15.23 = zext i8 %7681 to i32
  %7682 = load i8, i8* %arrayidx70.23, align 1
  %conv71.15.23 = zext i8 %7682 to i32
  %xor72.15.23 = xor i32 %conv71.15.23, %conv68.15.23
  %conv73.15.23 = trunc i32 %xor72.15.23 to i8
  store i8 %conv73.15.23, i8* %arrayidx70.23, align 1
  %scevgep20.16.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 16
  %7683 = load i8, i8* %scevgep20.16.23, align 1
  %conv68.16.23 = zext i8 %7683 to i32
  %7684 = load i8, i8* %arrayidx70.23, align 1
  %conv71.16.23 = zext i8 %7684 to i32
  %xor72.16.23 = xor i32 %conv71.16.23, %conv68.16.23
  %conv73.16.23 = trunc i32 %xor72.16.23 to i8
  store i8 %conv73.16.23, i8* %arrayidx70.23, align 1
  %scevgep20.17.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 17
  %7685 = load i8, i8* %scevgep20.17.23, align 1
  %conv68.17.23 = zext i8 %7685 to i32
  %7686 = load i8, i8* %arrayidx70.23, align 1
  %conv71.17.23 = zext i8 %7686 to i32
  %xor72.17.23 = xor i32 %conv71.17.23, %conv68.17.23
  %conv73.17.23 = trunc i32 %xor72.17.23 to i8
  store i8 %conv73.17.23, i8* %arrayidx70.23, align 1
  %scevgep20.18.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 18
  %7687 = load i8, i8* %scevgep20.18.23, align 1
  %conv68.18.23 = zext i8 %7687 to i32
  %7688 = load i8, i8* %arrayidx70.23, align 1
  %conv71.18.23 = zext i8 %7688 to i32
  %xor72.18.23 = xor i32 %conv71.18.23, %conv68.18.23
  %conv73.18.23 = trunc i32 %xor72.18.23 to i8
  store i8 %conv73.18.23, i8* %arrayidx70.23, align 1
  %scevgep20.19.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 19
  %7689 = load i8, i8* %scevgep20.19.23, align 1
  %conv68.19.23 = zext i8 %7689 to i32
  %7690 = load i8, i8* %arrayidx70.23, align 1
  %conv71.19.23 = zext i8 %7690 to i32
  %xor72.19.23 = xor i32 %conv71.19.23, %conv68.19.23
  %conv73.19.23 = trunc i32 %xor72.19.23 to i8
  store i8 %conv73.19.23, i8* %arrayidx70.23, align 1
  %scevgep20.20.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 20
  %7691 = load i8, i8* %scevgep20.20.23, align 1
  %conv68.20.23 = zext i8 %7691 to i32
  %7692 = load i8, i8* %arrayidx70.23, align 1
  %conv71.20.23 = zext i8 %7692 to i32
  %xor72.20.23 = xor i32 %conv71.20.23, %conv68.20.23
  %conv73.20.23 = trunc i32 %xor72.20.23 to i8
  store i8 %conv73.20.23, i8* %arrayidx70.23, align 1
  %scevgep20.21.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 21
  %7693 = load i8, i8* %scevgep20.21.23, align 1
  %conv68.21.23 = zext i8 %7693 to i32
  %7694 = load i8, i8* %arrayidx70.23, align 1
  %conv71.21.23 = zext i8 %7694 to i32
  %xor72.21.23 = xor i32 %conv71.21.23, %conv68.21.23
  %conv73.21.23 = trunc i32 %xor72.21.23 to i8
  store i8 %conv73.21.23, i8* %arrayidx70.23, align 1
  %scevgep20.22.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 22
  %7695 = load i8, i8* %scevgep20.22.23, align 1
  %conv68.22.23 = zext i8 %7695 to i32
  %7696 = load i8, i8* %arrayidx70.23, align 1
  %conv71.22.23 = zext i8 %7696 to i32
  %xor72.22.23 = xor i32 %conv71.22.23, %conv68.22.23
  %conv73.22.23 = trunc i32 %xor72.22.23 to i8
  store i8 %conv73.22.23, i8* %arrayidx70.23, align 1
  %scevgep20.24.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 24
  %7697 = load i8, i8* %scevgep20.24.23, align 1
  %conv68.24.23 = zext i8 %7697 to i32
  %7698 = load i8, i8* %arrayidx70.23, align 1
  %conv71.24.23 = zext i8 %7698 to i32
  %xor72.24.23 = xor i32 %conv71.24.23, %conv68.24.23
  %conv73.24.23 = trunc i32 %xor72.24.23 to i8
  store i8 %conv73.24.23, i8* %arrayidx70.23, align 1
  %scevgep20.25.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 25
  %7699 = load i8, i8* %scevgep20.25.23, align 1
  %conv68.25.23 = zext i8 %7699 to i32
  %7700 = load i8, i8* %arrayidx70.23, align 1
  %conv71.25.23 = zext i8 %7700 to i32
  %xor72.25.23 = xor i32 %conv71.25.23, %conv68.25.23
  %conv73.25.23 = trunc i32 %xor72.25.23 to i8
  store i8 %conv73.25.23, i8* %arrayidx70.23, align 1
  %scevgep20.26.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 26
  %7701 = load i8, i8* %scevgep20.26.23, align 1
  %conv68.26.23 = zext i8 %7701 to i32
  %7702 = load i8, i8* %arrayidx70.23, align 1
  %conv71.26.23 = zext i8 %7702 to i32
  %xor72.26.23 = xor i32 %conv71.26.23, %conv68.26.23
  %conv73.26.23 = trunc i32 %xor72.26.23 to i8
  store i8 %conv73.26.23, i8* %arrayidx70.23, align 1
  %scevgep20.27.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 27
  %7703 = load i8, i8* %scevgep20.27.23, align 1
  %conv68.27.23 = zext i8 %7703 to i32
  %7704 = load i8, i8* %arrayidx70.23, align 1
  %conv71.27.23 = zext i8 %7704 to i32
  %xor72.27.23 = xor i32 %conv71.27.23, %conv68.27.23
  %conv73.27.23 = trunc i32 %xor72.27.23 to i8
  store i8 %conv73.27.23, i8* %arrayidx70.23, align 1
  %scevgep20.28.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 28
  %7705 = load i8, i8* %scevgep20.28.23, align 1
  %conv68.28.23 = zext i8 %7705 to i32
  %7706 = load i8, i8* %arrayidx70.23, align 1
  %conv71.28.23 = zext i8 %7706 to i32
  %xor72.28.23 = xor i32 %conv71.28.23, %conv68.28.23
  %conv73.28.23 = trunc i32 %xor72.28.23 to i8
  store i8 %conv73.28.23, i8* %arrayidx70.23, align 1
  %scevgep20.29.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 29
  %7707 = load i8, i8* %scevgep20.29.23, align 1
  %conv68.29.23 = zext i8 %7707 to i32
  %7708 = load i8, i8* %arrayidx70.23, align 1
  %conv71.29.23 = zext i8 %7708 to i32
  %xor72.29.23 = xor i32 %conv71.29.23, %conv68.29.23
  %conv73.29.23 = trunc i32 %xor72.29.23 to i8
  store i8 %conv73.29.23, i8* %arrayidx70.23, align 1
  %scevgep20.30.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 30
  %7709 = load i8, i8* %scevgep20.30.23, align 1
  %conv68.30.23 = zext i8 %7709 to i32
  %7710 = load i8, i8* %arrayidx70.23, align 1
  %conv71.30.23 = zext i8 %7710 to i32
  %xor72.30.23 = xor i32 %conv71.30.23, %conv68.30.23
  %conv73.30.23 = trunc i32 %xor72.30.23 to i8
  store i8 %conv73.30.23, i8* %arrayidx70.23, align 1
  %scevgep20.31.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 31
  %7711 = load i8, i8* %scevgep20.31.23, align 1
  %conv68.31.23 = zext i8 %7711 to i32
  %7712 = load i8, i8* %arrayidx70.23, align 1
  %conv71.31.23 = zext i8 %7712 to i32
  %xor72.31.23 = xor i32 %conv71.31.23, %conv68.31.23
  %conv73.31.23 = trunc i32 %xor72.31.23 to i8
  store i8 %conv73.31.23, i8* %arrayidx70.23, align 1
  %scevgep20.32.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 32
  %7713 = load i8, i8* %scevgep20.32.23, align 1
  %conv68.32.23 = zext i8 %7713 to i32
  %7714 = load i8, i8* %arrayidx70.23, align 1
  %conv71.32.23 = zext i8 %7714 to i32
  %xor72.32.23 = xor i32 %conv71.32.23, %conv68.32.23
  %conv73.32.23 = trunc i32 %xor72.32.23 to i8
  store i8 %conv73.32.23, i8* %arrayidx70.23, align 1
  %scevgep20.33.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 33
  %7715 = load i8, i8* %scevgep20.33.23, align 1
  %conv68.33.23 = zext i8 %7715 to i32
  %7716 = load i8, i8* %arrayidx70.23, align 1
  %conv71.33.23 = zext i8 %7716 to i32
  %xor72.33.23 = xor i32 %conv71.33.23, %conv68.33.23
  %conv73.33.23 = trunc i32 %xor72.33.23 to i8
  store i8 %conv73.33.23, i8* %arrayidx70.23, align 1
  %scevgep20.34.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 34
  %7717 = load i8, i8* %scevgep20.34.23, align 1
  %conv68.34.23 = zext i8 %7717 to i32
  %7718 = load i8, i8* %arrayidx70.23, align 1
  %conv71.34.23 = zext i8 %7718 to i32
  %xor72.34.23 = xor i32 %conv71.34.23, %conv68.34.23
  %conv73.34.23 = trunc i32 %xor72.34.23 to i8
  store i8 %conv73.34.23, i8* %arrayidx70.23, align 1
  %scevgep20.35.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 35
  %7719 = load i8, i8* %scevgep20.35.23, align 1
  %conv68.35.23 = zext i8 %7719 to i32
  %7720 = load i8, i8* %arrayidx70.23, align 1
  %conv71.35.23 = zext i8 %7720 to i32
  %xor72.35.23 = xor i32 %conv71.35.23, %conv68.35.23
  %conv73.35.23 = trunc i32 %xor72.35.23 to i8
  store i8 %conv73.35.23, i8* %arrayidx70.23, align 1
  %scevgep20.36.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 36
  %7721 = load i8, i8* %scevgep20.36.23, align 1
  %conv68.36.23 = zext i8 %7721 to i32
  %7722 = load i8, i8* %arrayidx70.23, align 1
  %conv71.36.23 = zext i8 %7722 to i32
  %xor72.36.23 = xor i32 %conv71.36.23, %conv68.36.23
  %conv73.36.23 = trunc i32 %xor72.36.23 to i8
  store i8 %conv73.36.23, i8* %arrayidx70.23, align 1
  %scevgep20.37.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 37
  %7723 = load i8, i8* %scevgep20.37.23, align 1
  %conv68.37.23 = zext i8 %7723 to i32
  %7724 = load i8, i8* %arrayidx70.23, align 1
  %conv71.37.23 = zext i8 %7724 to i32
  %xor72.37.23 = xor i32 %conv71.37.23, %conv68.37.23
  %conv73.37.23 = trunc i32 %xor72.37.23 to i8
  store i8 %conv73.37.23, i8* %arrayidx70.23, align 1
  %scevgep20.38.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 38
  %7725 = load i8, i8* %scevgep20.38.23, align 1
  %conv68.38.23 = zext i8 %7725 to i32
  %7726 = load i8, i8* %arrayidx70.23, align 1
  %conv71.38.23 = zext i8 %7726 to i32
  %xor72.38.23 = xor i32 %conv71.38.23, %conv68.38.23
  %conv73.38.23 = trunc i32 %xor72.38.23 to i8
  store i8 %conv73.38.23, i8* %arrayidx70.23, align 1
  %scevgep20.39.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 39
  %7727 = load i8, i8* %scevgep20.39.23, align 1
  %conv68.39.23 = zext i8 %7727 to i32
  %7728 = load i8, i8* %arrayidx70.23, align 1
  %conv71.39.23 = zext i8 %7728 to i32
  %xor72.39.23 = xor i32 %conv71.39.23, %conv68.39.23
  %conv73.39.23 = trunc i32 %xor72.39.23 to i8
  store i8 %conv73.39.23, i8* %arrayidx70.23, align 1
  %scevgep20.40.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 0, i64 40
  %7729 = load i8, i8* %scevgep20.40.23, align 1
  %conv68.40.23 = zext i8 %7729 to i32
  %7730 = load i8, i8* %arrayidx70.23, align 1
  %conv71.40.23 = zext i8 %7730 to i32
  %xor72.40.23 = xor i32 %conv71.40.23, %conv68.40.23
  %conv73.40.23 = trunc i32 %xor72.40.23 to i8
  store i8 %conv73.40.23, i8* %arrayidx70.23, align 1
  %scevgep19.23 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7648, i64 0, i64 1, i64 0
  %7731 = bitcast i8* %scevgep19.23 to [41 x [41 x i8]]*
  %arrayidx51.24 = getelementptr inbounds i8, i8* %a, i64 24
  %7732 = load i8, i8* %arrayidx51.24, align 1
  %arrayidx53.24 = getelementptr inbounds i8, i8* %b, i64 24
  %7733 = load i8, i8* %arrayidx53.24, align 1
  %call54.24 = call zeroext i8 @mult(i8 zeroext %7732, i8 zeroext %7733)
  %arrayidx56.24 = getelementptr inbounds i8, i8* %c, i64 24
  store i8 %call54.24, i8* %arrayidx56.24, align 1
  %arrayidx70.24 = getelementptr inbounds i8, i8* %c, i64 24
  %scevgep20.24284 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 0
  %7734 = load i8, i8* %scevgep20.24284, align 1
  %conv68.24285 = zext i8 %7734 to i32
  %7735 = load i8, i8* %arrayidx70.24, align 1
  %conv71.24286 = zext i8 %7735 to i32
  %xor72.24287 = xor i32 %conv71.24286, %conv68.24285
  %conv73.24288 = trunc i32 %xor72.24287 to i8
  store i8 %conv73.24288, i8* %arrayidx70.24, align 1
  %scevgep20.1.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 1
  %7736 = load i8, i8* %scevgep20.1.24, align 1
  %conv68.1.24 = zext i8 %7736 to i32
  %7737 = load i8, i8* %arrayidx70.24, align 1
  %conv71.1.24 = zext i8 %7737 to i32
  %xor72.1.24 = xor i32 %conv71.1.24, %conv68.1.24
  %conv73.1.24 = trunc i32 %xor72.1.24 to i8
  store i8 %conv73.1.24, i8* %arrayidx70.24, align 1
  %scevgep20.2.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 2
  %7738 = load i8, i8* %scevgep20.2.24, align 1
  %conv68.2.24 = zext i8 %7738 to i32
  %7739 = load i8, i8* %arrayidx70.24, align 1
  %conv71.2.24 = zext i8 %7739 to i32
  %xor72.2.24 = xor i32 %conv71.2.24, %conv68.2.24
  %conv73.2.24 = trunc i32 %xor72.2.24 to i8
  store i8 %conv73.2.24, i8* %arrayidx70.24, align 1
  %scevgep20.3.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 3
  %7740 = load i8, i8* %scevgep20.3.24, align 1
  %conv68.3.24 = zext i8 %7740 to i32
  %7741 = load i8, i8* %arrayidx70.24, align 1
  %conv71.3.24 = zext i8 %7741 to i32
  %xor72.3.24 = xor i32 %conv71.3.24, %conv68.3.24
  %conv73.3.24 = trunc i32 %xor72.3.24 to i8
  store i8 %conv73.3.24, i8* %arrayidx70.24, align 1
  %scevgep20.4.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 4
  %7742 = load i8, i8* %scevgep20.4.24, align 1
  %conv68.4.24 = zext i8 %7742 to i32
  %7743 = load i8, i8* %arrayidx70.24, align 1
  %conv71.4.24 = zext i8 %7743 to i32
  %xor72.4.24 = xor i32 %conv71.4.24, %conv68.4.24
  %conv73.4.24 = trunc i32 %xor72.4.24 to i8
  store i8 %conv73.4.24, i8* %arrayidx70.24, align 1
  %scevgep20.5.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 5
  %7744 = load i8, i8* %scevgep20.5.24, align 1
  %conv68.5.24 = zext i8 %7744 to i32
  %7745 = load i8, i8* %arrayidx70.24, align 1
  %conv71.5.24 = zext i8 %7745 to i32
  %xor72.5.24 = xor i32 %conv71.5.24, %conv68.5.24
  %conv73.5.24 = trunc i32 %xor72.5.24 to i8
  store i8 %conv73.5.24, i8* %arrayidx70.24, align 1
  %scevgep20.6.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 6
  %7746 = load i8, i8* %scevgep20.6.24, align 1
  %conv68.6.24 = zext i8 %7746 to i32
  %7747 = load i8, i8* %arrayidx70.24, align 1
  %conv71.6.24 = zext i8 %7747 to i32
  %xor72.6.24 = xor i32 %conv71.6.24, %conv68.6.24
  %conv73.6.24 = trunc i32 %xor72.6.24 to i8
  store i8 %conv73.6.24, i8* %arrayidx70.24, align 1
  %scevgep20.7.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 7
  %7748 = load i8, i8* %scevgep20.7.24, align 1
  %conv68.7.24 = zext i8 %7748 to i32
  %7749 = load i8, i8* %arrayidx70.24, align 1
  %conv71.7.24 = zext i8 %7749 to i32
  %xor72.7.24 = xor i32 %conv71.7.24, %conv68.7.24
  %conv73.7.24 = trunc i32 %xor72.7.24 to i8
  store i8 %conv73.7.24, i8* %arrayidx70.24, align 1
  %scevgep20.8.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 8
  %7750 = load i8, i8* %scevgep20.8.24, align 1
  %conv68.8.24 = zext i8 %7750 to i32
  %7751 = load i8, i8* %arrayidx70.24, align 1
  %conv71.8.24 = zext i8 %7751 to i32
  %xor72.8.24 = xor i32 %conv71.8.24, %conv68.8.24
  %conv73.8.24 = trunc i32 %xor72.8.24 to i8
  store i8 %conv73.8.24, i8* %arrayidx70.24, align 1
  %scevgep20.9.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 9
  %7752 = load i8, i8* %scevgep20.9.24, align 1
  %conv68.9.24 = zext i8 %7752 to i32
  %7753 = load i8, i8* %arrayidx70.24, align 1
  %conv71.9.24 = zext i8 %7753 to i32
  %xor72.9.24 = xor i32 %conv71.9.24, %conv68.9.24
  %conv73.9.24 = trunc i32 %xor72.9.24 to i8
  store i8 %conv73.9.24, i8* %arrayidx70.24, align 1
  %scevgep20.10.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 10
  %7754 = load i8, i8* %scevgep20.10.24, align 1
  %conv68.10.24 = zext i8 %7754 to i32
  %7755 = load i8, i8* %arrayidx70.24, align 1
  %conv71.10.24 = zext i8 %7755 to i32
  %xor72.10.24 = xor i32 %conv71.10.24, %conv68.10.24
  %conv73.10.24 = trunc i32 %xor72.10.24 to i8
  store i8 %conv73.10.24, i8* %arrayidx70.24, align 1
  %scevgep20.11.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 11
  %7756 = load i8, i8* %scevgep20.11.24, align 1
  %conv68.11.24 = zext i8 %7756 to i32
  %7757 = load i8, i8* %arrayidx70.24, align 1
  %conv71.11.24 = zext i8 %7757 to i32
  %xor72.11.24 = xor i32 %conv71.11.24, %conv68.11.24
  %conv73.11.24 = trunc i32 %xor72.11.24 to i8
  store i8 %conv73.11.24, i8* %arrayidx70.24, align 1
  %scevgep20.12.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 12
  %7758 = load i8, i8* %scevgep20.12.24, align 1
  %conv68.12.24 = zext i8 %7758 to i32
  %7759 = load i8, i8* %arrayidx70.24, align 1
  %conv71.12.24 = zext i8 %7759 to i32
  %xor72.12.24 = xor i32 %conv71.12.24, %conv68.12.24
  %conv73.12.24 = trunc i32 %xor72.12.24 to i8
  store i8 %conv73.12.24, i8* %arrayidx70.24, align 1
  %scevgep20.13.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 13
  %7760 = load i8, i8* %scevgep20.13.24, align 1
  %conv68.13.24 = zext i8 %7760 to i32
  %7761 = load i8, i8* %arrayidx70.24, align 1
  %conv71.13.24 = zext i8 %7761 to i32
  %xor72.13.24 = xor i32 %conv71.13.24, %conv68.13.24
  %conv73.13.24 = trunc i32 %xor72.13.24 to i8
  store i8 %conv73.13.24, i8* %arrayidx70.24, align 1
  %scevgep20.14.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 14
  %7762 = load i8, i8* %scevgep20.14.24, align 1
  %conv68.14.24 = zext i8 %7762 to i32
  %7763 = load i8, i8* %arrayidx70.24, align 1
  %conv71.14.24 = zext i8 %7763 to i32
  %xor72.14.24 = xor i32 %conv71.14.24, %conv68.14.24
  %conv73.14.24 = trunc i32 %xor72.14.24 to i8
  store i8 %conv73.14.24, i8* %arrayidx70.24, align 1
  %scevgep20.15.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 15
  %7764 = load i8, i8* %scevgep20.15.24, align 1
  %conv68.15.24 = zext i8 %7764 to i32
  %7765 = load i8, i8* %arrayidx70.24, align 1
  %conv71.15.24 = zext i8 %7765 to i32
  %xor72.15.24 = xor i32 %conv71.15.24, %conv68.15.24
  %conv73.15.24 = trunc i32 %xor72.15.24 to i8
  store i8 %conv73.15.24, i8* %arrayidx70.24, align 1
  %scevgep20.16.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 16
  %7766 = load i8, i8* %scevgep20.16.24, align 1
  %conv68.16.24 = zext i8 %7766 to i32
  %7767 = load i8, i8* %arrayidx70.24, align 1
  %conv71.16.24 = zext i8 %7767 to i32
  %xor72.16.24 = xor i32 %conv71.16.24, %conv68.16.24
  %conv73.16.24 = trunc i32 %xor72.16.24 to i8
  store i8 %conv73.16.24, i8* %arrayidx70.24, align 1
  %scevgep20.17.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 17
  %7768 = load i8, i8* %scevgep20.17.24, align 1
  %conv68.17.24 = zext i8 %7768 to i32
  %7769 = load i8, i8* %arrayidx70.24, align 1
  %conv71.17.24 = zext i8 %7769 to i32
  %xor72.17.24 = xor i32 %conv71.17.24, %conv68.17.24
  %conv73.17.24 = trunc i32 %xor72.17.24 to i8
  store i8 %conv73.17.24, i8* %arrayidx70.24, align 1
  %scevgep20.18.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 18
  %7770 = load i8, i8* %scevgep20.18.24, align 1
  %conv68.18.24 = zext i8 %7770 to i32
  %7771 = load i8, i8* %arrayidx70.24, align 1
  %conv71.18.24 = zext i8 %7771 to i32
  %xor72.18.24 = xor i32 %conv71.18.24, %conv68.18.24
  %conv73.18.24 = trunc i32 %xor72.18.24 to i8
  store i8 %conv73.18.24, i8* %arrayidx70.24, align 1
  %scevgep20.19.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 19
  %7772 = load i8, i8* %scevgep20.19.24, align 1
  %conv68.19.24 = zext i8 %7772 to i32
  %7773 = load i8, i8* %arrayidx70.24, align 1
  %conv71.19.24 = zext i8 %7773 to i32
  %xor72.19.24 = xor i32 %conv71.19.24, %conv68.19.24
  %conv73.19.24 = trunc i32 %xor72.19.24 to i8
  store i8 %conv73.19.24, i8* %arrayidx70.24, align 1
  %scevgep20.20.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 20
  %7774 = load i8, i8* %scevgep20.20.24, align 1
  %conv68.20.24 = zext i8 %7774 to i32
  %7775 = load i8, i8* %arrayidx70.24, align 1
  %conv71.20.24 = zext i8 %7775 to i32
  %xor72.20.24 = xor i32 %conv71.20.24, %conv68.20.24
  %conv73.20.24 = trunc i32 %xor72.20.24 to i8
  store i8 %conv73.20.24, i8* %arrayidx70.24, align 1
  %scevgep20.21.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 21
  %7776 = load i8, i8* %scevgep20.21.24, align 1
  %conv68.21.24 = zext i8 %7776 to i32
  %7777 = load i8, i8* %arrayidx70.24, align 1
  %conv71.21.24 = zext i8 %7777 to i32
  %xor72.21.24 = xor i32 %conv71.21.24, %conv68.21.24
  %conv73.21.24 = trunc i32 %xor72.21.24 to i8
  store i8 %conv73.21.24, i8* %arrayidx70.24, align 1
  %scevgep20.22.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 22
  %7778 = load i8, i8* %scevgep20.22.24, align 1
  %conv68.22.24 = zext i8 %7778 to i32
  %7779 = load i8, i8* %arrayidx70.24, align 1
  %conv71.22.24 = zext i8 %7779 to i32
  %xor72.22.24 = xor i32 %conv71.22.24, %conv68.22.24
  %conv73.22.24 = trunc i32 %xor72.22.24 to i8
  store i8 %conv73.22.24, i8* %arrayidx70.24, align 1
  %scevgep20.23.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 23
  %7780 = load i8, i8* %scevgep20.23.24, align 1
  %conv68.23.24 = zext i8 %7780 to i32
  %7781 = load i8, i8* %arrayidx70.24, align 1
  %conv71.23.24 = zext i8 %7781 to i32
  %xor72.23.24 = xor i32 %conv71.23.24, %conv68.23.24
  %conv73.23.24 = trunc i32 %xor72.23.24 to i8
  store i8 %conv73.23.24, i8* %arrayidx70.24, align 1
  %scevgep20.25.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 25
  %7782 = load i8, i8* %scevgep20.25.24, align 1
  %conv68.25.24 = zext i8 %7782 to i32
  %7783 = load i8, i8* %arrayidx70.24, align 1
  %conv71.25.24 = zext i8 %7783 to i32
  %xor72.25.24 = xor i32 %conv71.25.24, %conv68.25.24
  %conv73.25.24 = trunc i32 %xor72.25.24 to i8
  store i8 %conv73.25.24, i8* %arrayidx70.24, align 1
  %scevgep20.26.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 26
  %7784 = load i8, i8* %scevgep20.26.24, align 1
  %conv68.26.24 = zext i8 %7784 to i32
  %7785 = load i8, i8* %arrayidx70.24, align 1
  %conv71.26.24 = zext i8 %7785 to i32
  %xor72.26.24 = xor i32 %conv71.26.24, %conv68.26.24
  %conv73.26.24 = trunc i32 %xor72.26.24 to i8
  store i8 %conv73.26.24, i8* %arrayidx70.24, align 1
  %scevgep20.27.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 27
  %7786 = load i8, i8* %scevgep20.27.24, align 1
  %conv68.27.24 = zext i8 %7786 to i32
  %7787 = load i8, i8* %arrayidx70.24, align 1
  %conv71.27.24 = zext i8 %7787 to i32
  %xor72.27.24 = xor i32 %conv71.27.24, %conv68.27.24
  %conv73.27.24 = trunc i32 %xor72.27.24 to i8
  store i8 %conv73.27.24, i8* %arrayidx70.24, align 1
  %scevgep20.28.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 28
  %7788 = load i8, i8* %scevgep20.28.24, align 1
  %conv68.28.24 = zext i8 %7788 to i32
  %7789 = load i8, i8* %arrayidx70.24, align 1
  %conv71.28.24 = zext i8 %7789 to i32
  %xor72.28.24 = xor i32 %conv71.28.24, %conv68.28.24
  %conv73.28.24 = trunc i32 %xor72.28.24 to i8
  store i8 %conv73.28.24, i8* %arrayidx70.24, align 1
  %scevgep20.29.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 29
  %7790 = load i8, i8* %scevgep20.29.24, align 1
  %conv68.29.24 = zext i8 %7790 to i32
  %7791 = load i8, i8* %arrayidx70.24, align 1
  %conv71.29.24 = zext i8 %7791 to i32
  %xor72.29.24 = xor i32 %conv71.29.24, %conv68.29.24
  %conv73.29.24 = trunc i32 %xor72.29.24 to i8
  store i8 %conv73.29.24, i8* %arrayidx70.24, align 1
  %scevgep20.30.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 30
  %7792 = load i8, i8* %scevgep20.30.24, align 1
  %conv68.30.24 = zext i8 %7792 to i32
  %7793 = load i8, i8* %arrayidx70.24, align 1
  %conv71.30.24 = zext i8 %7793 to i32
  %xor72.30.24 = xor i32 %conv71.30.24, %conv68.30.24
  %conv73.30.24 = trunc i32 %xor72.30.24 to i8
  store i8 %conv73.30.24, i8* %arrayidx70.24, align 1
  %scevgep20.31.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 31
  %7794 = load i8, i8* %scevgep20.31.24, align 1
  %conv68.31.24 = zext i8 %7794 to i32
  %7795 = load i8, i8* %arrayidx70.24, align 1
  %conv71.31.24 = zext i8 %7795 to i32
  %xor72.31.24 = xor i32 %conv71.31.24, %conv68.31.24
  %conv73.31.24 = trunc i32 %xor72.31.24 to i8
  store i8 %conv73.31.24, i8* %arrayidx70.24, align 1
  %scevgep20.32.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 32
  %7796 = load i8, i8* %scevgep20.32.24, align 1
  %conv68.32.24 = zext i8 %7796 to i32
  %7797 = load i8, i8* %arrayidx70.24, align 1
  %conv71.32.24 = zext i8 %7797 to i32
  %xor72.32.24 = xor i32 %conv71.32.24, %conv68.32.24
  %conv73.32.24 = trunc i32 %xor72.32.24 to i8
  store i8 %conv73.32.24, i8* %arrayidx70.24, align 1
  %scevgep20.33.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 33
  %7798 = load i8, i8* %scevgep20.33.24, align 1
  %conv68.33.24 = zext i8 %7798 to i32
  %7799 = load i8, i8* %arrayidx70.24, align 1
  %conv71.33.24 = zext i8 %7799 to i32
  %xor72.33.24 = xor i32 %conv71.33.24, %conv68.33.24
  %conv73.33.24 = trunc i32 %xor72.33.24 to i8
  store i8 %conv73.33.24, i8* %arrayidx70.24, align 1
  %scevgep20.34.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 34
  %7800 = load i8, i8* %scevgep20.34.24, align 1
  %conv68.34.24 = zext i8 %7800 to i32
  %7801 = load i8, i8* %arrayidx70.24, align 1
  %conv71.34.24 = zext i8 %7801 to i32
  %xor72.34.24 = xor i32 %conv71.34.24, %conv68.34.24
  %conv73.34.24 = trunc i32 %xor72.34.24 to i8
  store i8 %conv73.34.24, i8* %arrayidx70.24, align 1
  %scevgep20.35.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 35
  %7802 = load i8, i8* %scevgep20.35.24, align 1
  %conv68.35.24 = zext i8 %7802 to i32
  %7803 = load i8, i8* %arrayidx70.24, align 1
  %conv71.35.24 = zext i8 %7803 to i32
  %xor72.35.24 = xor i32 %conv71.35.24, %conv68.35.24
  %conv73.35.24 = trunc i32 %xor72.35.24 to i8
  store i8 %conv73.35.24, i8* %arrayidx70.24, align 1
  %scevgep20.36.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 36
  %7804 = load i8, i8* %scevgep20.36.24, align 1
  %conv68.36.24 = zext i8 %7804 to i32
  %7805 = load i8, i8* %arrayidx70.24, align 1
  %conv71.36.24 = zext i8 %7805 to i32
  %xor72.36.24 = xor i32 %conv71.36.24, %conv68.36.24
  %conv73.36.24 = trunc i32 %xor72.36.24 to i8
  store i8 %conv73.36.24, i8* %arrayidx70.24, align 1
  %scevgep20.37.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 37
  %7806 = load i8, i8* %scevgep20.37.24, align 1
  %conv68.37.24 = zext i8 %7806 to i32
  %7807 = load i8, i8* %arrayidx70.24, align 1
  %conv71.37.24 = zext i8 %7807 to i32
  %xor72.37.24 = xor i32 %conv71.37.24, %conv68.37.24
  %conv73.37.24 = trunc i32 %xor72.37.24 to i8
  store i8 %conv73.37.24, i8* %arrayidx70.24, align 1
  %scevgep20.38.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 38
  %7808 = load i8, i8* %scevgep20.38.24, align 1
  %conv68.38.24 = zext i8 %7808 to i32
  %7809 = load i8, i8* %arrayidx70.24, align 1
  %conv71.38.24 = zext i8 %7809 to i32
  %xor72.38.24 = xor i32 %conv71.38.24, %conv68.38.24
  %conv73.38.24 = trunc i32 %xor72.38.24 to i8
  store i8 %conv73.38.24, i8* %arrayidx70.24, align 1
  %scevgep20.39.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 39
  %7810 = load i8, i8* %scevgep20.39.24, align 1
  %conv68.39.24 = zext i8 %7810 to i32
  %7811 = load i8, i8* %arrayidx70.24, align 1
  %conv71.39.24 = zext i8 %7811 to i32
  %xor72.39.24 = xor i32 %conv71.39.24, %conv68.39.24
  %conv73.39.24 = trunc i32 %xor72.39.24 to i8
  store i8 %conv73.39.24, i8* %arrayidx70.24, align 1
  %scevgep20.40.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 0, i64 40
  %7812 = load i8, i8* %scevgep20.40.24, align 1
  %conv68.40.24 = zext i8 %7812 to i32
  %7813 = load i8, i8* %arrayidx70.24, align 1
  %conv71.40.24 = zext i8 %7813 to i32
  %xor72.40.24 = xor i32 %conv71.40.24, %conv68.40.24
  %conv73.40.24 = trunc i32 %xor72.40.24 to i8
  store i8 %conv73.40.24, i8* %arrayidx70.24, align 1
  %scevgep19.24 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7731, i64 0, i64 1, i64 0
  %7814 = bitcast i8* %scevgep19.24 to [41 x [41 x i8]]*
  %arrayidx51.25 = getelementptr inbounds i8, i8* %a, i64 25
  %7815 = load i8, i8* %arrayidx51.25, align 1
  %arrayidx53.25 = getelementptr inbounds i8, i8* %b, i64 25
  %7816 = load i8, i8* %arrayidx53.25, align 1
  %call54.25 = call zeroext i8 @mult(i8 zeroext %7815, i8 zeroext %7816)
  %arrayidx56.25 = getelementptr inbounds i8, i8* %c, i64 25
  store i8 %call54.25, i8* %arrayidx56.25, align 1
  %arrayidx70.25 = getelementptr inbounds i8, i8* %c, i64 25
  %scevgep20.25294 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 0
  %7817 = load i8, i8* %scevgep20.25294, align 1
  %conv68.25295 = zext i8 %7817 to i32
  %7818 = load i8, i8* %arrayidx70.25, align 1
  %conv71.25296 = zext i8 %7818 to i32
  %xor72.25297 = xor i32 %conv71.25296, %conv68.25295
  %conv73.25298 = trunc i32 %xor72.25297 to i8
  store i8 %conv73.25298, i8* %arrayidx70.25, align 1
  %scevgep20.1.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 1
  %7819 = load i8, i8* %scevgep20.1.25, align 1
  %conv68.1.25 = zext i8 %7819 to i32
  %7820 = load i8, i8* %arrayidx70.25, align 1
  %conv71.1.25 = zext i8 %7820 to i32
  %xor72.1.25 = xor i32 %conv71.1.25, %conv68.1.25
  %conv73.1.25 = trunc i32 %xor72.1.25 to i8
  store i8 %conv73.1.25, i8* %arrayidx70.25, align 1
  %scevgep20.2.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 2
  %7821 = load i8, i8* %scevgep20.2.25, align 1
  %conv68.2.25 = zext i8 %7821 to i32
  %7822 = load i8, i8* %arrayidx70.25, align 1
  %conv71.2.25 = zext i8 %7822 to i32
  %xor72.2.25 = xor i32 %conv71.2.25, %conv68.2.25
  %conv73.2.25 = trunc i32 %xor72.2.25 to i8
  store i8 %conv73.2.25, i8* %arrayidx70.25, align 1
  %scevgep20.3.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 3
  %7823 = load i8, i8* %scevgep20.3.25, align 1
  %conv68.3.25 = zext i8 %7823 to i32
  %7824 = load i8, i8* %arrayidx70.25, align 1
  %conv71.3.25 = zext i8 %7824 to i32
  %xor72.3.25 = xor i32 %conv71.3.25, %conv68.3.25
  %conv73.3.25 = trunc i32 %xor72.3.25 to i8
  store i8 %conv73.3.25, i8* %arrayidx70.25, align 1
  %scevgep20.4.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 4
  %7825 = load i8, i8* %scevgep20.4.25, align 1
  %conv68.4.25 = zext i8 %7825 to i32
  %7826 = load i8, i8* %arrayidx70.25, align 1
  %conv71.4.25 = zext i8 %7826 to i32
  %xor72.4.25 = xor i32 %conv71.4.25, %conv68.4.25
  %conv73.4.25 = trunc i32 %xor72.4.25 to i8
  store i8 %conv73.4.25, i8* %arrayidx70.25, align 1
  %scevgep20.5.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 5
  %7827 = load i8, i8* %scevgep20.5.25, align 1
  %conv68.5.25 = zext i8 %7827 to i32
  %7828 = load i8, i8* %arrayidx70.25, align 1
  %conv71.5.25 = zext i8 %7828 to i32
  %xor72.5.25 = xor i32 %conv71.5.25, %conv68.5.25
  %conv73.5.25 = trunc i32 %xor72.5.25 to i8
  store i8 %conv73.5.25, i8* %arrayidx70.25, align 1
  %scevgep20.6.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 6
  %7829 = load i8, i8* %scevgep20.6.25, align 1
  %conv68.6.25 = zext i8 %7829 to i32
  %7830 = load i8, i8* %arrayidx70.25, align 1
  %conv71.6.25 = zext i8 %7830 to i32
  %xor72.6.25 = xor i32 %conv71.6.25, %conv68.6.25
  %conv73.6.25 = trunc i32 %xor72.6.25 to i8
  store i8 %conv73.6.25, i8* %arrayidx70.25, align 1
  %scevgep20.7.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 7
  %7831 = load i8, i8* %scevgep20.7.25, align 1
  %conv68.7.25 = zext i8 %7831 to i32
  %7832 = load i8, i8* %arrayidx70.25, align 1
  %conv71.7.25 = zext i8 %7832 to i32
  %xor72.7.25 = xor i32 %conv71.7.25, %conv68.7.25
  %conv73.7.25 = trunc i32 %xor72.7.25 to i8
  store i8 %conv73.7.25, i8* %arrayidx70.25, align 1
  %scevgep20.8.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 8
  %7833 = load i8, i8* %scevgep20.8.25, align 1
  %conv68.8.25 = zext i8 %7833 to i32
  %7834 = load i8, i8* %arrayidx70.25, align 1
  %conv71.8.25 = zext i8 %7834 to i32
  %xor72.8.25 = xor i32 %conv71.8.25, %conv68.8.25
  %conv73.8.25 = trunc i32 %xor72.8.25 to i8
  store i8 %conv73.8.25, i8* %arrayidx70.25, align 1
  %scevgep20.9.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 9
  %7835 = load i8, i8* %scevgep20.9.25, align 1
  %conv68.9.25 = zext i8 %7835 to i32
  %7836 = load i8, i8* %arrayidx70.25, align 1
  %conv71.9.25 = zext i8 %7836 to i32
  %xor72.9.25 = xor i32 %conv71.9.25, %conv68.9.25
  %conv73.9.25 = trunc i32 %xor72.9.25 to i8
  store i8 %conv73.9.25, i8* %arrayidx70.25, align 1
  %scevgep20.10.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 10
  %7837 = load i8, i8* %scevgep20.10.25, align 1
  %conv68.10.25 = zext i8 %7837 to i32
  %7838 = load i8, i8* %arrayidx70.25, align 1
  %conv71.10.25 = zext i8 %7838 to i32
  %xor72.10.25 = xor i32 %conv71.10.25, %conv68.10.25
  %conv73.10.25 = trunc i32 %xor72.10.25 to i8
  store i8 %conv73.10.25, i8* %arrayidx70.25, align 1
  %scevgep20.11.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 11
  %7839 = load i8, i8* %scevgep20.11.25, align 1
  %conv68.11.25 = zext i8 %7839 to i32
  %7840 = load i8, i8* %arrayidx70.25, align 1
  %conv71.11.25 = zext i8 %7840 to i32
  %xor72.11.25 = xor i32 %conv71.11.25, %conv68.11.25
  %conv73.11.25 = trunc i32 %xor72.11.25 to i8
  store i8 %conv73.11.25, i8* %arrayidx70.25, align 1
  %scevgep20.12.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 12
  %7841 = load i8, i8* %scevgep20.12.25, align 1
  %conv68.12.25 = zext i8 %7841 to i32
  %7842 = load i8, i8* %arrayidx70.25, align 1
  %conv71.12.25 = zext i8 %7842 to i32
  %xor72.12.25 = xor i32 %conv71.12.25, %conv68.12.25
  %conv73.12.25 = trunc i32 %xor72.12.25 to i8
  store i8 %conv73.12.25, i8* %arrayidx70.25, align 1
  %scevgep20.13.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 13
  %7843 = load i8, i8* %scevgep20.13.25, align 1
  %conv68.13.25 = zext i8 %7843 to i32
  %7844 = load i8, i8* %arrayidx70.25, align 1
  %conv71.13.25 = zext i8 %7844 to i32
  %xor72.13.25 = xor i32 %conv71.13.25, %conv68.13.25
  %conv73.13.25 = trunc i32 %xor72.13.25 to i8
  store i8 %conv73.13.25, i8* %arrayidx70.25, align 1
  %scevgep20.14.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 14
  %7845 = load i8, i8* %scevgep20.14.25, align 1
  %conv68.14.25 = zext i8 %7845 to i32
  %7846 = load i8, i8* %arrayidx70.25, align 1
  %conv71.14.25 = zext i8 %7846 to i32
  %xor72.14.25 = xor i32 %conv71.14.25, %conv68.14.25
  %conv73.14.25 = trunc i32 %xor72.14.25 to i8
  store i8 %conv73.14.25, i8* %arrayidx70.25, align 1
  %scevgep20.15.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 15
  %7847 = load i8, i8* %scevgep20.15.25, align 1
  %conv68.15.25 = zext i8 %7847 to i32
  %7848 = load i8, i8* %arrayidx70.25, align 1
  %conv71.15.25 = zext i8 %7848 to i32
  %xor72.15.25 = xor i32 %conv71.15.25, %conv68.15.25
  %conv73.15.25 = trunc i32 %xor72.15.25 to i8
  store i8 %conv73.15.25, i8* %arrayidx70.25, align 1
  %scevgep20.16.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 16
  %7849 = load i8, i8* %scevgep20.16.25, align 1
  %conv68.16.25 = zext i8 %7849 to i32
  %7850 = load i8, i8* %arrayidx70.25, align 1
  %conv71.16.25 = zext i8 %7850 to i32
  %xor72.16.25 = xor i32 %conv71.16.25, %conv68.16.25
  %conv73.16.25 = trunc i32 %xor72.16.25 to i8
  store i8 %conv73.16.25, i8* %arrayidx70.25, align 1
  %scevgep20.17.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 17
  %7851 = load i8, i8* %scevgep20.17.25, align 1
  %conv68.17.25 = zext i8 %7851 to i32
  %7852 = load i8, i8* %arrayidx70.25, align 1
  %conv71.17.25 = zext i8 %7852 to i32
  %xor72.17.25 = xor i32 %conv71.17.25, %conv68.17.25
  %conv73.17.25 = trunc i32 %xor72.17.25 to i8
  store i8 %conv73.17.25, i8* %arrayidx70.25, align 1
  %scevgep20.18.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 18
  %7853 = load i8, i8* %scevgep20.18.25, align 1
  %conv68.18.25 = zext i8 %7853 to i32
  %7854 = load i8, i8* %arrayidx70.25, align 1
  %conv71.18.25 = zext i8 %7854 to i32
  %xor72.18.25 = xor i32 %conv71.18.25, %conv68.18.25
  %conv73.18.25 = trunc i32 %xor72.18.25 to i8
  store i8 %conv73.18.25, i8* %arrayidx70.25, align 1
  %scevgep20.19.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 19
  %7855 = load i8, i8* %scevgep20.19.25, align 1
  %conv68.19.25 = zext i8 %7855 to i32
  %7856 = load i8, i8* %arrayidx70.25, align 1
  %conv71.19.25 = zext i8 %7856 to i32
  %xor72.19.25 = xor i32 %conv71.19.25, %conv68.19.25
  %conv73.19.25 = trunc i32 %xor72.19.25 to i8
  store i8 %conv73.19.25, i8* %arrayidx70.25, align 1
  %scevgep20.20.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 20
  %7857 = load i8, i8* %scevgep20.20.25, align 1
  %conv68.20.25 = zext i8 %7857 to i32
  %7858 = load i8, i8* %arrayidx70.25, align 1
  %conv71.20.25 = zext i8 %7858 to i32
  %xor72.20.25 = xor i32 %conv71.20.25, %conv68.20.25
  %conv73.20.25 = trunc i32 %xor72.20.25 to i8
  store i8 %conv73.20.25, i8* %arrayidx70.25, align 1
  %scevgep20.21.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 21
  %7859 = load i8, i8* %scevgep20.21.25, align 1
  %conv68.21.25 = zext i8 %7859 to i32
  %7860 = load i8, i8* %arrayidx70.25, align 1
  %conv71.21.25 = zext i8 %7860 to i32
  %xor72.21.25 = xor i32 %conv71.21.25, %conv68.21.25
  %conv73.21.25 = trunc i32 %xor72.21.25 to i8
  store i8 %conv73.21.25, i8* %arrayidx70.25, align 1
  %scevgep20.22.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 22
  %7861 = load i8, i8* %scevgep20.22.25, align 1
  %conv68.22.25 = zext i8 %7861 to i32
  %7862 = load i8, i8* %arrayidx70.25, align 1
  %conv71.22.25 = zext i8 %7862 to i32
  %xor72.22.25 = xor i32 %conv71.22.25, %conv68.22.25
  %conv73.22.25 = trunc i32 %xor72.22.25 to i8
  store i8 %conv73.22.25, i8* %arrayidx70.25, align 1
  %scevgep20.23.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 23
  %7863 = load i8, i8* %scevgep20.23.25, align 1
  %conv68.23.25 = zext i8 %7863 to i32
  %7864 = load i8, i8* %arrayidx70.25, align 1
  %conv71.23.25 = zext i8 %7864 to i32
  %xor72.23.25 = xor i32 %conv71.23.25, %conv68.23.25
  %conv73.23.25 = trunc i32 %xor72.23.25 to i8
  store i8 %conv73.23.25, i8* %arrayidx70.25, align 1
  %scevgep20.24.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 24
  %7865 = load i8, i8* %scevgep20.24.25, align 1
  %conv68.24.25 = zext i8 %7865 to i32
  %7866 = load i8, i8* %arrayidx70.25, align 1
  %conv71.24.25 = zext i8 %7866 to i32
  %xor72.24.25 = xor i32 %conv71.24.25, %conv68.24.25
  %conv73.24.25 = trunc i32 %xor72.24.25 to i8
  store i8 %conv73.24.25, i8* %arrayidx70.25, align 1
  %scevgep20.26.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 26
  %7867 = load i8, i8* %scevgep20.26.25, align 1
  %conv68.26.25 = zext i8 %7867 to i32
  %7868 = load i8, i8* %arrayidx70.25, align 1
  %conv71.26.25 = zext i8 %7868 to i32
  %xor72.26.25 = xor i32 %conv71.26.25, %conv68.26.25
  %conv73.26.25 = trunc i32 %xor72.26.25 to i8
  store i8 %conv73.26.25, i8* %arrayidx70.25, align 1
  %scevgep20.27.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 27
  %7869 = load i8, i8* %scevgep20.27.25, align 1
  %conv68.27.25 = zext i8 %7869 to i32
  %7870 = load i8, i8* %arrayidx70.25, align 1
  %conv71.27.25 = zext i8 %7870 to i32
  %xor72.27.25 = xor i32 %conv71.27.25, %conv68.27.25
  %conv73.27.25 = trunc i32 %xor72.27.25 to i8
  store i8 %conv73.27.25, i8* %arrayidx70.25, align 1
  %scevgep20.28.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 28
  %7871 = load i8, i8* %scevgep20.28.25, align 1
  %conv68.28.25 = zext i8 %7871 to i32
  %7872 = load i8, i8* %arrayidx70.25, align 1
  %conv71.28.25 = zext i8 %7872 to i32
  %xor72.28.25 = xor i32 %conv71.28.25, %conv68.28.25
  %conv73.28.25 = trunc i32 %xor72.28.25 to i8
  store i8 %conv73.28.25, i8* %arrayidx70.25, align 1
  %scevgep20.29.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 29
  %7873 = load i8, i8* %scevgep20.29.25, align 1
  %conv68.29.25 = zext i8 %7873 to i32
  %7874 = load i8, i8* %arrayidx70.25, align 1
  %conv71.29.25 = zext i8 %7874 to i32
  %xor72.29.25 = xor i32 %conv71.29.25, %conv68.29.25
  %conv73.29.25 = trunc i32 %xor72.29.25 to i8
  store i8 %conv73.29.25, i8* %arrayidx70.25, align 1
  %scevgep20.30.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 30
  %7875 = load i8, i8* %scevgep20.30.25, align 1
  %conv68.30.25 = zext i8 %7875 to i32
  %7876 = load i8, i8* %arrayidx70.25, align 1
  %conv71.30.25 = zext i8 %7876 to i32
  %xor72.30.25 = xor i32 %conv71.30.25, %conv68.30.25
  %conv73.30.25 = trunc i32 %xor72.30.25 to i8
  store i8 %conv73.30.25, i8* %arrayidx70.25, align 1
  %scevgep20.31.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 31
  %7877 = load i8, i8* %scevgep20.31.25, align 1
  %conv68.31.25 = zext i8 %7877 to i32
  %7878 = load i8, i8* %arrayidx70.25, align 1
  %conv71.31.25 = zext i8 %7878 to i32
  %xor72.31.25 = xor i32 %conv71.31.25, %conv68.31.25
  %conv73.31.25 = trunc i32 %xor72.31.25 to i8
  store i8 %conv73.31.25, i8* %arrayidx70.25, align 1
  %scevgep20.32.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 32
  %7879 = load i8, i8* %scevgep20.32.25, align 1
  %conv68.32.25 = zext i8 %7879 to i32
  %7880 = load i8, i8* %arrayidx70.25, align 1
  %conv71.32.25 = zext i8 %7880 to i32
  %xor72.32.25 = xor i32 %conv71.32.25, %conv68.32.25
  %conv73.32.25 = trunc i32 %xor72.32.25 to i8
  store i8 %conv73.32.25, i8* %arrayidx70.25, align 1
  %scevgep20.33.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 33
  %7881 = load i8, i8* %scevgep20.33.25, align 1
  %conv68.33.25 = zext i8 %7881 to i32
  %7882 = load i8, i8* %arrayidx70.25, align 1
  %conv71.33.25 = zext i8 %7882 to i32
  %xor72.33.25 = xor i32 %conv71.33.25, %conv68.33.25
  %conv73.33.25 = trunc i32 %xor72.33.25 to i8
  store i8 %conv73.33.25, i8* %arrayidx70.25, align 1
  %scevgep20.34.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 34
  %7883 = load i8, i8* %scevgep20.34.25, align 1
  %conv68.34.25 = zext i8 %7883 to i32
  %7884 = load i8, i8* %arrayidx70.25, align 1
  %conv71.34.25 = zext i8 %7884 to i32
  %xor72.34.25 = xor i32 %conv71.34.25, %conv68.34.25
  %conv73.34.25 = trunc i32 %xor72.34.25 to i8
  store i8 %conv73.34.25, i8* %arrayidx70.25, align 1
  %scevgep20.35.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 35
  %7885 = load i8, i8* %scevgep20.35.25, align 1
  %conv68.35.25 = zext i8 %7885 to i32
  %7886 = load i8, i8* %arrayidx70.25, align 1
  %conv71.35.25 = zext i8 %7886 to i32
  %xor72.35.25 = xor i32 %conv71.35.25, %conv68.35.25
  %conv73.35.25 = trunc i32 %xor72.35.25 to i8
  store i8 %conv73.35.25, i8* %arrayidx70.25, align 1
  %scevgep20.36.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 36
  %7887 = load i8, i8* %scevgep20.36.25, align 1
  %conv68.36.25 = zext i8 %7887 to i32
  %7888 = load i8, i8* %arrayidx70.25, align 1
  %conv71.36.25 = zext i8 %7888 to i32
  %xor72.36.25 = xor i32 %conv71.36.25, %conv68.36.25
  %conv73.36.25 = trunc i32 %xor72.36.25 to i8
  store i8 %conv73.36.25, i8* %arrayidx70.25, align 1
  %scevgep20.37.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 37
  %7889 = load i8, i8* %scevgep20.37.25, align 1
  %conv68.37.25 = zext i8 %7889 to i32
  %7890 = load i8, i8* %arrayidx70.25, align 1
  %conv71.37.25 = zext i8 %7890 to i32
  %xor72.37.25 = xor i32 %conv71.37.25, %conv68.37.25
  %conv73.37.25 = trunc i32 %xor72.37.25 to i8
  store i8 %conv73.37.25, i8* %arrayidx70.25, align 1
  %scevgep20.38.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 38
  %7891 = load i8, i8* %scevgep20.38.25, align 1
  %conv68.38.25 = zext i8 %7891 to i32
  %7892 = load i8, i8* %arrayidx70.25, align 1
  %conv71.38.25 = zext i8 %7892 to i32
  %xor72.38.25 = xor i32 %conv71.38.25, %conv68.38.25
  %conv73.38.25 = trunc i32 %xor72.38.25 to i8
  store i8 %conv73.38.25, i8* %arrayidx70.25, align 1
  %scevgep20.39.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 39
  %7893 = load i8, i8* %scevgep20.39.25, align 1
  %conv68.39.25 = zext i8 %7893 to i32
  %7894 = load i8, i8* %arrayidx70.25, align 1
  %conv71.39.25 = zext i8 %7894 to i32
  %xor72.39.25 = xor i32 %conv71.39.25, %conv68.39.25
  %conv73.39.25 = trunc i32 %xor72.39.25 to i8
  store i8 %conv73.39.25, i8* %arrayidx70.25, align 1
  %scevgep20.40.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 0, i64 40
  %7895 = load i8, i8* %scevgep20.40.25, align 1
  %conv68.40.25 = zext i8 %7895 to i32
  %7896 = load i8, i8* %arrayidx70.25, align 1
  %conv71.40.25 = zext i8 %7896 to i32
  %xor72.40.25 = xor i32 %conv71.40.25, %conv68.40.25
  %conv73.40.25 = trunc i32 %xor72.40.25 to i8
  store i8 %conv73.40.25, i8* %arrayidx70.25, align 1
  %scevgep19.25 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7814, i64 0, i64 1, i64 0
  %7897 = bitcast i8* %scevgep19.25 to [41 x [41 x i8]]*
  %arrayidx51.26 = getelementptr inbounds i8, i8* %a, i64 26
  %7898 = load i8, i8* %arrayidx51.26, align 1
  %arrayidx53.26 = getelementptr inbounds i8, i8* %b, i64 26
  %7899 = load i8, i8* %arrayidx53.26, align 1
  %call54.26 = call zeroext i8 @mult(i8 zeroext %7898, i8 zeroext %7899)
  %arrayidx56.26 = getelementptr inbounds i8, i8* %c, i64 26
  store i8 %call54.26, i8* %arrayidx56.26, align 1
  %arrayidx70.26 = getelementptr inbounds i8, i8* %c, i64 26
  %scevgep20.26304 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 0
  %7900 = load i8, i8* %scevgep20.26304, align 1
  %conv68.26305 = zext i8 %7900 to i32
  %7901 = load i8, i8* %arrayidx70.26, align 1
  %conv71.26306 = zext i8 %7901 to i32
  %xor72.26307 = xor i32 %conv71.26306, %conv68.26305
  %conv73.26308 = trunc i32 %xor72.26307 to i8
  store i8 %conv73.26308, i8* %arrayidx70.26, align 1
  %scevgep20.1.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 1
  %7902 = load i8, i8* %scevgep20.1.26, align 1
  %conv68.1.26 = zext i8 %7902 to i32
  %7903 = load i8, i8* %arrayidx70.26, align 1
  %conv71.1.26 = zext i8 %7903 to i32
  %xor72.1.26 = xor i32 %conv71.1.26, %conv68.1.26
  %conv73.1.26 = trunc i32 %xor72.1.26 to i8
  store i8 %conv73.1.26, i8* %arrayidx70.26, align 1
  %scevgep20.2.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 2
  %7904 = load i8, i8* %scevgep20.2.26, align 1
  %conv68.2.26 = zext i8 %7904 to i32
  %7905 = load i8, i8* %arrayidx70.26, align 1
  %conv71.2.26 = zext i8 %7905 to i32
  %xor72.2.26 = xor i32 %conv71.2.26, %conv68.2.26
  %conv73.2.26 = trunc i32 %xor72.2.26 to i8
  store i8 %conv73.2.26, i8* %arrayidx70.26, align 1
  %scevgep20.3.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 3
  %7906 = load i8, i8* %scevgep20.3.26, align 1
  %conv68.3.26 = zext i8 %7906 to i32
  %7907 = load i8, i8* %arrayidx70.26, align 1
  %conv71.3.26 = zext i8 %7907 to i32
  %xor72.3.26 = xor i32 %conv71.3.26, %conv68.3.26
  %conv73.3.26 = trunc i32 %xor72.3.26 to i8
  store i8 %conv73.3.26, i8* %arrayidx70.26, align 1
  %scevgep20.4.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 4
  %7908 = load i8, i8* %scevgep20.4.26, align 1
  %conv68.4.26 = zext i8 %7908 to i32
  %7909 = load i8, i8* %arrayidx70.26, align 1
  %conv71.4.26 = zext i8 %7909 to i32
  %xor72.4.26 = xor i32 %conv71.4.26, %conv68.4.26
  %conv73.4.26 = trunc i32 %xor72.4.26 to i8
  store i8 %conv73.4.26, i8* %arrayidx70.26, align 1
  %scevgep20.5.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 5
  %7910 = load i8, i8* %scevgep20.5.26, align 1
  %conv68.5.26 = zext i8 %7910 to i32
  %7911 = load i8, i8* %arrayidx70.26, align 1
  %conv71.5.26 = zext i8 %7911 to i32
  %xor72.5.26 = xor i32 %conv71.5.26, %conv68.5.26
  %conv73.5.26 = trunc i32 %xor72.5.26 to i8
  store i8 %conv73.5.26, i8* %arrayidx70.26, align 1
  %scevgep20.6.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 6
  %7912 = load i8, i8* %scevgep20.6.26, align 1
  %conv68.6.26 = zext i8 %7912 to i32
  %7913 = load i8, i8* %arrayidx70.26, align 1
  %conv71.6.26 = zext i8 %7913 to i32
  %xor72.6.26 = xor i32 %conv71.6.26, %conv68.6.26
  %conv73.6.26 = trunc i32 %xor72.6.26 to i8
  store i8 %conv73.6.26, i8* %arrayidx70.26, align 1
  %scevgep20.7.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 7
  %7914 = load i8, i8* %scevgep20.7.26, align 1
  %conv68.7.26 = zext i8 %7914 to i32
  %7915 = load i8, i8* %arrayidx70.26, align 1
  %conv71.7.26 = zext i8 %7915 to i32
  %xor72.7.26 = xor i32 %conv71.7.26, %conv68.7.26
  %conv73.7.26 = trunc i32 %xor72.7.26 to i8
  store i8 %conv73.7.26, i8* %arrayidx70.26, align 1
  %scevgep20.8.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 8
  %7916 = load i8, i8* %scevgep20.8.26, align 1
  %conv68.8.26 = zext i8 %7916 to i32
  %7917 = load i8, i8* %arrayidx70.26, align 1
  %conv71.8.26 = zext i8 %7917 to i32
  %xor72.8.26 = xor i32 %conv71.8.26, %conv68.8.26
  %conv73.8.26 = trunc i32 %xor72.8.26 to i8
  store i8 %conv73.8.26, i8* %arrayidx70.26, align 1
  %scevgep20.9.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 9
  %7918 = load i8, i8* %scevgep20.9.26, align 1
  %conv68.9.26 = zext i8 %7918 to i32
  %7919 = load i8, i8* %arrayidx70.26, align 1
  %conv71.9.26 = zext i8 %7919 to i32
  %xor72.9.26 = xor i32 %conv71.9.26, %conv68.9.26
  %conv73.9.26 = trunc i32 %xor72.9.26 to i8
  store i8 %conv73.9.26, i8* %arrayidx70.26, align 1
  %scevgep20.10.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 10
  %7920 = load i8, i8* %scevgep20.10.26, align 1
  %conv68.10.26 = zext i8 %7920 to i32
  %7921 = load i8, i8* %arrayidx70.26, align 1
  %conv71.10.26 = zext i8 %7921 to i32
  %xor72.10.26 = xor i32 %conv71.10.26, %conv68.10.26
  %conv73.10.26 = trunc i32 %xor72.10.26 to i8
  store i8 %conv73.10.26, i8* %arrayidx70.26, align 1
  %scevgep20.11.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 11
  %7922 = load i8, i8* %scevgep20.11.26, align 1
  %conv68.11.26 = zext i8 %7922 to i32
  %7923 = load i8, i8* %arrayidx70.26, align 1
  %conv71.11.26 = zext i8 %7923 to i32
  %xor72.11.26 = xor i32 %conv71.11.26, %conv68.11.26
  %conv73.11.26 = trunc i32 %xor72.11.26 to i8
  store i8 %conv73.11.26, i8* %arrayidx70.26, align 1
  %scevgep20.12.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 12
  %7924 = load i8, i8* %scevgep20.12.26, align 1
  %conv68.12.26 = zext i8 %7924 to i32
  %7925 = load i8, i8* %arrayidx70.26, align 1
  %conv71.12.26 = zext i8 %7925 to i32
  %xor72.12.26 = xor i32 %conv71.12.26, %conv68.12.26
  %conv73.12.26 = trunc i32 %xor72.12.26 to i8
  store i8 %conv73.12.26, i8* %arrayidx70.26, align 1
  %scevgep20.13.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 13
  %7926 = load i8, i8* %scevgep20.13.26, align 1
  %conv68.13.26 = zext i8 %7926 to i32
  %7927 = load i8, i8* %arrayidx70.26, align 1
  %conv71.13.26 = zext i8 %7927 to i32
  %xor72.13.26 = xor i32 %conv71.13.26, %conv68.13.26
  %conv73.13.26 = trunc i32 %xor72.13.26 to i8
  store i8 %conv73.13.26, i8* %arrayidx70.26, align 1
  %scevgep20.14.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 14
  %7928 = load i8, i8* %scevgep20.14.26, align 1
  %conv68.14.26 = zext i8 %7928 to i32
  %7929 = load i8, i8* %arrayidx70.26, align 1
  %conv71.14.26 = zext i8 %7929 to i32
  %xor72.14.26 = xor i32 %conv71.14.26, %conv68.14.26
  %conv73.14.26 = trunc i32 %xor72.14.26 to i8
  store i8 %conv73.14.26, i8* %arrayidx70.26, align 1
  %scevgep20.15.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 15
  %7930 = load i8, i8* %scevgep20.15.26, align 1
  %conv68.15.26 = zext i8 %7930 to i32
  %7931 = load i8, i8* %arrayidx70.26, align 1
  %conv71.15.26 = zext i8 %7931 to i32
  %xor72.15.26 = xor i32 %conv71.15.26, %conv68.15.26
  %conv73.15.26 = trunc i32 %xor72.15.26 to i8
  store i8 %conv73.15.26, i8* %arrayidx70.26, align 1
  %scevgep20.16.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 16
  %7932 = load i8, i8* %scevgep20.16.26, align 1
  %conv68.16.26 = zext i8 %7932 to i32
  %7933 = load i8, i8* %arrayidx70.26, align 1
  %conv71.16.26 = zext i8 %7933 to i32
  %xor72.16.26 = xor i32 %conv71.16.26, %conv68.16.26
  %conv73.16.26 = trunc i32 %xor72.16.26 to i8
  store i8 %conv73.16.26, i8* %arrayidx70.26, align 1
  %scevgep20.17.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 17
  %7934 = load i8, i8* %scevgep20.17.26, align 1
  %conv68.17.26 = zext i8 %7934 to i32
  %7935 = load i8, i8* %arrayidx70.26, align 1
  %conv71.17.26 = zext i8 %7935 to i32
  %xor72.17.26 = xor i32 %conv71.17.26, %conv68.17.26
  %conv73.17.26 = trunc i32 %xor72.17.26 to i8
  store i8 %conv73.17.26, i8* %arrayidx70.26, align 1
  %scevgep20.18.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 18
  %7936 = load i8, i8* %scevgep20.18.26, align 1
  %conv68.18.26 = zext i8 %7936 to i32
  %7937 = load i8, i8* %arrayidx70.26, align 1
  %conv71.18.26 = zext i8 %7937 to i32
  %xor72.18.26 = xor i32 %conv71.18.26, %conv68.18.26
  %conv73.18.26 = trunc i32 %xor72.18.26 to i8
  store i8 %conv73.18.26, i8* %arrayidx70.26, align 1
  %scevgep20.19.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 19
  %7938 = load i8, i8* %scevgep20.19.26, align 1
  %conv68.19.26 = zext i8 %7938 to i32
  %7939 = load i8, i8* %arrayidx70.26, align 1
  %conv71.19.26 = zext i8 %7939 to i32
  %xor72.19.26 = xor i32 %conv71.19.26, %conv68.19.26
  %conv73.19.26 = trunc i32 %xor72.19.26 to i8
  store i8 %conv73.19.26, i8* %arrayidx70.26, align 1
  %scevgep20.20.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 20
  %7940 = load i8, i8* %scevgep20.20.26, align 1
  %conv68.20.26 = zext i8 %7940 to i32
  %7941 = load i8, i8* %arrayidx70.26, align 1
  %conv71.20.26 = zext i8 %7941 to i32
  %xor72.20.26 = xor i32 %conv71.20.26, %conv68.20.26
  %conv73.20.26 = trunc i32 %xor72.20.26 to i8
  store i8 %conv73.20.26, i8* %arrayidx70.26, align 1
  %scevgep20.21.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 21
  %7942 = load i8, i8* %scevgep20.21.26, align 1
  %conv68.21.26 = zext i8 %7942 to i32
  %7943 = load i8, i8* %arrayidx70.26, align 1
  %conv71.21.26 = zext i8 %7943 to i32
  %xor72.21.26 = xor i32 %conv71.21.26, %conv68.21.26
  %conv73.21.26 = trunc i32 %xor72.21.26 to i8
  store i8 %conv73.21.26, i8* %arrayidx70.26, align 1
  %scevgep20.22.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 22
  %7944 = load i8, i8* %scevgep20.22.26, align 1
  %conv68.22.26 = zext i8 %7944 to i32
  %7945 = load i8, i8* %arrayidx70.26, align 1
  %conv71.22.26 = zext i8 %7945 to i32
  %xor72.22.26 = xor i32 %conv71.22.26, %conv68.22.26
  %conv73.22.26 = trunc i32 %xor72.22.26 to i8
  store i8 %conv73.22.26, i8* %arrayidx70.26, align 1
  %scevgep20.23.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 23
  %7946 = load i8, i8* %scevgep20.23.26, align 1
  %conv68.23.26 = zext i8 %7946 to i32
  %7947 = load i8, i8* %arrayidx70.26, align 1
  %conv71.23.26 = zext i8 %7947 to i32
  %xor72.23.26 = xor i32 %conv71.23.26, %conv68.23.26
  %conv73.23.26 = trunc i32 %xor72.23.26 to i8
  store i8 %conv73.23.26, i8* %arrayidx70.26, align 1
  %scevgep20.24.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 24
  %7948 = load i8, i8* %scevgep20.24.26, align 1
  %conv68.24.26 = zext i8 %7948 to i32
  %7949 = load i8, i8* %arrayidx70.26, align 1
  %conv71.24.26 = zext i8 %7949 to i32
  %xor72.24.26 = xor i32 %conv71.24.26, %conv68.24.26
  %conv73.24.26 = trunc i32 %xor72.24.26 to i8
  store i8 %conv73.24.26, i8* %arrayidx70.26, align 1
  %scevgep20.25.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 25
  %7950 = load i8, i8* %scevgep20.25.26, align 1
  %conv68.25.26 = zext i8 %7950 to i32
  %7951 = load i8, i8* %arrayidx70.26, align 1
  %conv71.25.26 = zext i8 %7951 to i32
  %xor72.25.26 = xor i32 %conv71.25.26, %conv68.25.26
  %conv73.25.26 = trunc i32 %xor72.25.26 to i8
  store i8 %conv73.25.26, i8* %arrayidx70.26, align 1
  %scevgep20.27.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 27
  %7952 = load i8, i8* %scevgep20.27.26, align 1
  %conv68.27.26 = zext i8 %7952 to i32
  %7953 = load i8, i8* %arrayidx70.26, align 1
  %conv71.27.26 = zext i8 %7953 to i32
  %xor72.27.26 = xor i32 %conv71.27.26, %conv68.27.26
  %conv73.27.26 = trunc i32 %xor72.27.26 to i8
  store i8 %conv73.27.26, i8* %arrayidx70.26, align 1
  %scevgep20.28.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 28
  %7954 = load i8, i8* %scevgep20.28.26, align 1
  %conv68.28.26 = zext i8 %7954 to i32
  %7955 = load i8, i8* %arrayidx70.26, align 1
  %conv71.28.26 = zext i8 %7955 to i32
  %xor72.28.26 = xor i32 %conv71.28.26, %conv68.28.26
  %conv73.28.26 = trunc i32 %xor72.28.26 to i8
  store i8 %conv73.28.26, i8* %arrayidx70.26, align 1
  %scevgep20.29.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 29
  %7956 = load i8, i8* %scevgep20.29.26, align 1
  %conv68.29.26 = zext i8 %7956 to i32
  %7957 = load i8, i8* %arrayidx70.26, align 1
  %conv71.29.26 = zext i8 %7957 to i32
  %xor72.29.26 = xor i32 %conv71.29.26, %conv68.29.26
  %conv73.29.26 = trunc i32 %xor72.29.26 to i8
  store i8 %conv73.29.26, i8* %arrayidx70.26, align 1
  %scevgep20.30.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 30
  %7958 = load i8, i8* %scevgep20.30.26, align 1
  %conv68.30.26 = zext i8 %7958 to i32
  %7959 = load i8, i8* %arrayidx70.26, align 1
  %conv71.30.26 = zext i8 %7959 to i32
  %xor72.30.26 = xor i32 %conv71.30.26, %conv68.30.26
  %conv73.30.26 = trunc i32 %xor72.30.26 to i8
  store i8 %conv73.30.26, i8* %arrayidx70.26, align 1
  %scevgep20.31.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 31
  %7960 = load i8, i8* %scevgep20.31.26, align 1
  %conv68.31.26 = zext i8 %7960 to i32
  %7961 = load i8, i8* %arrayidx70.26, align 1
  %conv71.31.26 = zext i8 %7961 to i32
  %xor72.31.26 = xor i32 %conv71.31.26, %conv68.31.26
  %conv73.31.26 = trunc i32 %xor72.31.26 to i8
  store i8 %conv73.31.26, i8* %arrayidx70.26, align 1
  %scevgep20.32.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 32
  %7962 = load i8, i8* %scevgep20.32.26, align 1
  %conv68.32.26 = zext i8 %7962 to i32
  %7963 = load i8, i8* %arrayidx70.26, align 1
  %conv71.32.26 = zext i8 %7963 to i32
  %xor72.32.26 = xor i32 %conv71.32.26, %conv68.32.26
  %conv73.32.26 = trunc i32 %xor72.32.26 to i8
  store i8 %conv73.32.26, i8* %arrayidx70.26, align 1
  %scevgep20.33.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 33
  %7964 = load i8, i8* %scevgep20.33.26, align 1
  %conv68.33.26 = zext i8 %7964 to i32
  %7965 = load i8, i8* %arrayidx70.26, align 1
  %conv71.33.26 = zext i8 %7965 to i32
  %xor72.33.26 = xor i32 %conv71.33.26, %conv68.33.26
  %conv73.33.26 = trunc i32 %xor72.33.26 to i8
  store i8 %conv73.33.26, i8* %arrayidx70.26, align 1
  %scevgep20.34.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 34
  %7966 = load i8, i8* %scevgep20.34.26, align 1
  %conv68.34.26 = zext i8 %7966 to i32
  %7967 = load i8, i8* %arrayidx70.26, align 1
  %conv71.34.26 = zext i8 %7967 to i32
  %xor72.34.26 = xor i32 %conv71.34.26, %conv68.34.26
  %conv73.34.26 = trunc i32 %xor72.34.26 to i8
  store i8 %conv73.34.26, i8* %arrayidx70.26, align 1
  %scevgep20.35.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 35
  %7968 = load i8, i8* %scevgep20.35.26, align 1
  %conv68.35.26 = zext i8 %7968 to i32
  %7969 = load i8, i8* %arrayidx70.26, align 1
  %conv71.35.26 = zext i8 %7969 to i32
  %xor72.35.26 = xor i32 %conv71.35.26, %conv68.35.26
  %conv73.35.26 = trunc i32 %xor72.35.26 to i8
  store i8 %conv73.35.26, i8* %arrayidx70.26, align 1
  %scevgep20.36.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 36
  %7970 = load i8, i8* %scevgep20.36.26, align 1
  %conv68.36.26 = zext i8 %7970 to i32
  %7971 = load i8, i8* %arrayidx70.26, align 1
  %conv71.36.26 = zext i8 %7971 to i32
  %xor72.36.26 = xor i32 %conv71.36.26, %conv68.36.26
  %conv73.36.26 = trunc i32 %xor72.36.26 to i8
  store i8 %conv73.36.26, i8* %arrayidx70.26, align 1
  %scevgep20.37.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 37
  %7972 = load i8, i8* %scevgep20.37.26, align 1
  %conv68.37.26 = zext i8 %7972 to i32
  %7973 = load i8, i8* %arrayidx70.26, align 1
  %conv71.37.26 = zext i8 %7973 to i32
  %xor72.37.26 = xor i32 %conv71.37.26, %conv68.37.26
  %conv73.37.26 = trunc i32 %xor72.37.26 to i8
  store i8 %conv73.37.26, i8* %arrayidx70.26, align 1
  %scevgep20.38.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 38
  %7974 = load i8, i8* %scevgep20.38.26, align 1
  %conv68.38.26 = zext i8 %7974 to i32
  %7975 = load i8, i8* %arrayidx70.26, align 1
  %conv71.38.26 = zext i8 %7975 to i32
  %xor72.38.26 = xor i32 %conv71.38.26, %conv68.38.26
  %conv73.38.26 = trunc i32 %xor72.38.26 to i8
  store i8 %conv73.38.26, i8* %arrayidx70.26, align 1
  %scevgep20.39.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 39
  %7976 = load i8, i8* %scevgep20.39.26, align 1
  %conv68.39.26 = zext i8 %7976 to i32
  %7977 = load i8, i8* %arrayidx70.26, align 1
  %conv71.39.26 = zext i8 %7977 to i32
  %xor72.39.26 = xor i32 %conv71.39.26, %conv68.39.26
  %conv73.39.26 = trunc i32 %xor72.39.26 to i8
  store i8 %conv73.39.26, i8* %arrayidx70.26, align 1
  %scevgep20.40.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 0, i64 40
  %7978 = load i8, i8* %scevgep20.40.26, align 1
  %conv68.40.26 = zext i8 %7978 to i32
  %7979 = load i8, i8* %arrayidx70.26, align 1
  %conv71.40.26 = zext i8 %7979 to i32
  %xor72.40.26 = xor i32 %conv71.40.26, %conv68.40.26
  %conv73.40.26 = trunc i32 %xor72.40.26 to i8
  store i8 %conv73.40.26, i8* %arrayidx70.26, align 1
  %scevgep19.26 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7897, i64 0, i64 1, i64 0
  %7980 = bitcast i8* %scevgep19.26 to [41 x [41 x i8]]*
  %arrayidx51.27 = getelementptr inbounds i8, i8* %a, i64 27
  %7981 = load i8, i8* %arrayidx51.27, align 1
  %arrayidx53.27 = getelementptr inbounds i8, i8* %b, i64 27
  %7982 = load i8, i8* %arrayidx53.27, align 1
  %call54.27 = call zeroext i8 @mult(i8 zeroext %7981, i8 zeroext %7982)
  %arrayidx56.27 = getelementptr inbounds i8, i8* %c, i64 27
  store i8 %call54.27, i8* %arrayidx56.27, align 1
  %arrayidx70.27 = getelementptr inbounds i8, i8* %c, i64 27
  %scevgep20.27314 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 0
  %7983 = load i8, i8* %scevgep20.27314, align 1
  %conv68.27315 = zext i8 %7983 to i32
  %7984 = load i8, i8* %arrayidx70.27, align 1
  %conv71.27316 = zext i8 %7984 to i32
  %xor72.27317 = xor i32 %conv71.27316, %conv68.27315
  %conv73.27318 = trunc i32 %xor72.27317 to i8
  store i8 %conv73.27318, i8* %arrayidx70.27, align 1
  %scevgep20.1.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 1
  %7985 = load i8, i8* %scevgep20.1.27, align 1
  %conv68.1.27 = zext i8 %7985 to i32
  %7986 = load i8, i8* %arrayidx70.27, align 1
  %conv71.1.27 = zext i8 %7986 to i32
  %xor72.1.27 = xor i32 %conv71.1.27, %conv68.1.27
  %conv73.1.27 = trunc i32 %xor72.1.27 to i8
  store i8 %conv73.1.27, i8* %arrayidx70.27, align 1
  %scevgep20.2.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 2
  %7987 = load i8, i8* %scevgep20.2.27, align 1
  %conv68.2.27 = zext i8 %7987 to i32
  %7988 = load i8, i8* %arrayidx70.27, align 1
  %conv71.2.27 = zext i8 %7988 to i32
  %xor72.2.27 = xor i32 %conv71.2.27, %conv68.2.27
  %conv73.2.27 = trunc i32 %xor72.2.27 to i8
  store i8 %conv73.2.27, i8* %arrayidx70.27, align 1
  %scevgep20.3.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 3
  %7989 = load i8, i8* %scevgep20.3.27, align 1
  %conv68.3.27 = zext i8 %7989 to i32
  %7990 = load i8, i8* %arrayidx70.27, align 1
  %conv71.3.27 = zext i8 %7990 to i32
  %xor72.3.27 = xor i32 %conv71.3.27, %conv68.3.27
  %conv73.3.27 = trunc i32 %xor72.3.27 to i8
  store i8 %conv73.3.27, i8* %arrayidx70.27, align 1
  %scevgep20.4.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 4
  %7991 = load i8, i8* %scevgep20.4.27, align 1
  %conv68.4.27 = zext i8 %7991 to i32
  %7992 = load i8, i8* %arrayidx70.27, align 1
  %conv71.4.27 = zext i8 %7992 to i32
  %xor72.4.27 = xor i32 %conv71.4.27, %conv68.4.27
  %conv73.4.27 = trunc i32 %xor72.4.27 to i8
  store i8 %conv73.4.27, i8* %arrayidx70.27, align 1
  %scevgep20.5.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 5
  %7993 = load i8, i8* %scevgep20.5.27, align 1
  %conv68.5.27 = zext i8 %7993 to i32
  %7994 = load i8, i8* %arrayidx70.27, align 1
  %conv71.5.27 = zext i8 %7994 to i32
  %xor72.5.27 = xor i32 %conv71.5.27, %conv68.5.27
  %conv73.5.27 = trunc i32 %xor72.5.27 to i8
  store i8 %conv73.5.27, i8* %arrayidx70.27, align 1
  %scevgep20.6.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 6
  %7995 = load i8, i8* %scevgep20.6.27, align 1
  %conv68.6.27 = zext i8 %7995 to i32
  %7996 = load i8, i8* %arrayidx70.27, align 1
  %conv71.6.27 = zext i8 %7996 to i32
  %xor72.6.27 = xor i32 %conv71.6.27, %conv68.6.27
  %conv73.6.27 = trunc i32 %xor72.6.27 to i8
  store i8 %conv73.6.27, i8* %arrayidx70.27, align 1
  %scevgep20.7.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 7
  %7997 = load i8, i8* %scevgep20.7.27, align 1
  %conv68.7.27 = zext i8 %7997 to i32
  %7998 = load i8, i8* %arrayidx70.27, align 1
  %conv71.7.27 = zext i8 %7998 to i32
  %xor72.7.27 = xor i32 %conv71.7.27, %conv68.7.27
  %conv73.7.27 = trunc i32 %xor72.7.27 to i8
  store i8 %conv73.7.27, i8* %arrayidx70.27, align 1
  %scevgep20.8.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 8
  %7999 = load i8, i8* %scevgep20.8.27, align 1
  %conv68.8.27 = zext i8 %7999 to i32
  %8000 = load i8, i8* %arrayidx70.27, align 1
  %conv71.8.27 = zext i8 %8000 to i32
  %xor72.8.27 = xor i32 %conv71.8.27, %conv68.8.27
  %conv73.8.27 = trunc i32 %xor72.8.27 to i8
  store i8 %conv73.8.27, i8* %arrayidx70.27, align 1
  %scevgep20.9.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 9
  %8001 = load i8, i8* %scevgep20.9.27, align 1
  %conv68.9.27 = zext i8 %8001 to i32
  %8002 = load i8, i8* %arrayidx70.27, align 1
  %conv71.9.27 = zext i8 %8002 to i32
  %xor72.9.27 = xor i32 %conv71.9.27, %conv68.9.27
  %conv73.9.27 = trunc i32 %xor72.9.27 to i8
  store i8 %conv73.9.27, i8* %arrayidx70.27, align 1
  %scevgep20.10.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 10
  %8003 = load i8, i8* %scevgep20.10.27, align 1
  %conv68.10.27 = zext i8 %8003 to i32
  %8004 = load i8, i8* %arrayidx70.27, align 1
  %conv71.10.27 = zext i8 %8004 to i32
  %xor72.10.27 = xor i32 %conv71.10.27, %conv68.10.27
  %conv73.10.27 = trunc i32 %xor72.10.27 to i8
  store i8 %conv73.10.27, i8* %arrayidx70.27, align 1
  %scevgep20.11.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 11
  %8005 = load i8, i8* %scevgep20.11.27, align 1
  %conv68.11.27 = zext i8 %8005 to i32
  %8006 = load i8, i8* %arrayidx70.27, align 1
  %conv71.11.27 = zext i8 %8006 to i32
  %xor72.11.27 = xor i32 %conv71.11.27, %conv68.11.27
  %conv73.11.27 = trunc i32 %xor72.11.27 to i8
  store i8 %conv73.11.27, i8* %arrayidx70.27, align 1
  %scevgep20.12.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 12
  %8007 = load i8, i8* %scevgep20.12.27, align 1
  %conv68.12.27 = zext i8 %8007 to i32
  %8008 = load i8, i8* %arrayidx70.27, align 1
  %conv71.12.27 = zext i8 %8008 to i32
  %xor72.12.27 = xor i32 %conv71.12.27, %conv68.12.27
  %conv73.12.27 = trunc i32 %xor72.12.27 to i8
  store i8 %conv73.12.27, i8* %arrayidx70.27, align 1
  %scevgep20.13.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 13
  %8009 = load i8, i8* %scevgep20.13.27, align 1
  %conv68.13.27 = zext i8 %8009 to i32
  %8010 = load i8, i8* %arrayidx70.27, align 1
  %conv71.13.27 = zext i8 %8010 to i32
  %xor72.13.27 = xor i32 %conv71.13.27, %conv68.13.27
  %conv73.13.27 = trunc i32 %xor72.13.27 to i8
  store i8 %conv73.13.27, i8* %arrayidx70.27, align 1
  %scevgep20.14.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 14
  %8011 = load i8, i8* %scevgep20.14.27, align 1
  %conv68.14.27 = zext i8 %8011 to i32
  %8012 = load i8, i8* %arrayidx70.27, align 1
  %conv71.14.27 = zext i8 %8012 to i32
  %xor72.14.27 = xor i32 %conv71.14.27, %conv68.14.27
  %conv73.14.27 = trunc i32 %xor72.14.27 to i8
  store i8 %conv73.14.27, i8* %arrayidx70.27, align 1
  %scevgep20.15.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 15
  %8013 = load i8, i8* %scevgep20.15.27, align 1
  %conv68.15.27 = zext i8 %8013 to i32
  %8014 = load i8, i8* %arrayidx70.27, align 1
  %conv71.15.27 = zext i8 %8014 to i32
  %xor72.15.27 = xor i32 %conv71.15.27, %conv68.15.27
  %conv73.15.27 = trunc i32 %xor72.15.27 to i8
  store i8 %conv73.15.27, i8* %arrayidx70.27, align 1
  %scevgep20.16.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 16
  %8015 = load i8, i8* %scevgep20.16.27, align 1
  %conv68.16.27 = zext i8 %8015 to i32
  %8016 = load i8, i8* %arrayidx70.27, align 1
  %conv71.16.27 = zext i8 %8016 to i32
  %xor72.16.27 = xor i32 %conv71.16.27, %conv68.16.27
  %conv73.16.27 = trunc i32 %xor72.16.27 to i8
  store i8 %conv73.16.27, i8* %arrayidx70.27, align 1
  %scevgep20.17.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 17
  %8017 = load i8, i8* %scevgep20.17.27, align 1
  %conv68.17.27 = zext i8 %8017 to i32
  %8018 = load i8, i8* %arrayidx70.27, align 1
  %conv71.17.27 = zext i8 %8018 to i32
  %xor72.17.27 = xor i32 %conv71.17.27, %conv68.17.27
  %conv73.17.27 = trunc i32 %xor72.17.27 to i8
  store i8 %conv73.17.27, i8* %arrayidx70.27, align 1
  %scevgep20.18.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 18
  %8019 = load i8, i8* %scevgep20.18.27, align 1
  %conv68.18.27 = zext i8 %8019 to i32
  %8020 = load i8, i8* %arrayidx70.27, align 1
  %conv71.18.27 = zext i8 %8020 to i32
  %xor72.18.27 = xor i32 %conv71.18.27, %conv68.18.27
  %conv73.18.27 = trunc i32 %xor72.18.27 to i8
  store i8 %conv73.18.27, i8* %arrayidx70.27, align 1
  %scevgep20.19.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 19
  %8021 = load i8, i8* %scevgep20.19.27, align 1
  %conv68.19.27 = zext i8 %8021 to i32
  %8022 = load i8, i8* %arrayidx70.27, align 1
  %conv71.19.27 = zext i8 %8022 to i32
  %xor72.19.27 = xor i32 %conv71.19.27, %conv68.19.27
  %conv73.19.27 = trunc i32 %xor72.19.27 to i8
  store i8 %conv73.19.27, i8* %arrayidx70.27, align 1
  %scevgep20.20.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 20
  %8023 = load i8, i8* %scevgep20.20.27, align 1
  %conv68.20.27 = zext i8 %8023 to i32
  %8024 = load i8, i8* %arrayidx70.27, align 1
  %conv71.20.27 = zext i8 %8024 to i32
  %xor72.20.27 = xor i32 %conv71.20.27, %conv68.20.27
  %conv73.20.27 = trunc i32 %xor72.20.27 to i8
  store i8 %conv73.20.27, i8* %arrayidx70.27, align 1
  %scevgep20.21.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 21
  %8025 = load i8, i8* %scevgep20.21.27, align 1
  %conv68.21.27 = zext i8 %8025 to i32
  %8026 = load i8, i8* %arrayidx70.27, align 1
  %conv71.21.27 = zext i8 %8026 to i32
  %xor72.21.27 = xor i32 %conv71.21.27, %conv68.21.27
  %conv73.21.27 = trunc i32 %xor72.21.27 to i8
  store i8 %conv73.21.27, i8* %arrayidx70.27, align 1
  %scevgep20.22.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 22
  %8027 = load i8, i8* %scevgep20.22.27, align 1
  %conv68.22.27 = zext i8 %8027 to i32
  %8028 = load i8, i8* %arrayidx70.27, align 1
  %conv71.22.27 = zext i8 %8028 to i32
  %xor72.22.27 = xor i32 %conv71.22.27, %conv68.22.27
  %conv73.22.27 = trunc i32 %xor72.22.27 to i8
  store i8 %conv73.22.27, i8* %arrayidx70.27, align 1
  %scevgep20.23.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 23
  %8029 = load i8, i8* %scevgep20.23.27, align 1
  %conv68.23.27 = zext i8 %8029 to i32
  %8030 = load i8, i8* %arrayidx70.27, align 1
  %conv71.23.27 = zext i8 %8030 to i32
  %xor72.23.27 = xor i32 %conv71.23.27, %conv68.23.27
  %conv73.23.27 = trunc i32 %xor72.23.27 to i8
  store i8 %conv73.23.27, i8* %arrayidx70.27, align 1
  %scevgep20.24.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 24
  %8031 = load i8, i8* %scevgep20.24.27, align 1
  %conv68.24.27 = zext i8 %8031 to i32
  %8032 = load i8, i8* %arrayidx70.27, align 1
  %conv71.24.27 = zext i8 %8032 to i32
  %xor72.24.27 = xor i32 %conv71.24.27, %conv68.24.27
  %conv73.24.27 = trunc i32 %xor72.24.27 to i8
  store i8 %conv73.24.27, i8* %arrayidx70.27, align 1
  %scevgep20.25.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 25
  %8033 = load i8, i8* %scevgep20.25.27, align 1
  %conv68.25.27 = zext i8 %8033 to i32
  %8034 = load i8, i8* %arrayidx70.27, align 1
  %conv71.25.27 = zext i8 %8034 to i32
  %xor72.25.27 = xor i32 %conv71.25.27, %conv68.25.27
  %conv73.25.27 = trunc i32 %xor72.25.27 to i8
  store i8 %conv73.25.27, i8* %arrayidx70.27, align 1
  %scevgep20.26.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 26
  %8035 = load i8, i8* %scevgep20.26.27, align 1
  %conv68.26.27 = zext i8 %8035 to i32
  %8036 = load i8, i8* %arrayidx70.27, align 1
  %conv71.26.27 = zext i8 %8036 to i32
  %xor72.26.27 = xor i32 %conv71.26.27, %conv68.26.27
  %conv73.26.27 = trunc i32 %xor72.26.27 to i8
  store i8 %conv73.26.27, i8* %arrayidx70.27, align 1
  %scevgep20.28.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 28
  %8037 = load i8, i8* %scevgep20.28.27, align 1
  %conv68.28.27 = zext i8 %8037 to i32
  %8038 = load i8, i8* %arrayidx70.27, align 1
  %conv71.28.27 = zext i8 %8038 to i32
  %xor72.28.27 = xor i32 %conv71.28.27, %conv68.28.27
  %conv73.28.27 = trunc i32 %xor72.28.27 to i8
  store i8 %conv73.28.27, i8* %arrayidx70.27, align 1
  %scevgep20.29.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 29
  %8039 = load i8, i8* %scevgep20.29.27, align 1
  %conv68.29.27 = zext i8 %8039 to i32
  %8040 = load i8, i8* %arrayidx70.27, align 1
  %conv71.29.27 = zext i8 %8040 to i32
  %xor72.29.27 = xor i32 %conv71.29.27, %conv68.29.27
  %conv73.29.27 = trunc i32 %xor72.29.27 to i8
  store i8 %conv73.29.27, i8* %arrayidx70.27, align 1
  %scevgep20.30.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 30
  %8041 = load i8, i8* %scevgep20.30.27, align 1
  %conv68.30.27 = zext i8 %8041 to i32
  %8042 = load i8, i8* %arrayidx70.27, align 1
  %conv71.30.27 = zext i8 %8042 to i32
  %xor72.30.27 = xor i32 %conv71.30.27, %conv68.30.27
  %conv73.30.27 = trunc i32 %xor72.30.27 to i8
  store i8 %conv73.30.27, i8* %arrayidx70.27, align 1
  %scevgep20.31.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 31
  %8043 = load i8, i8* %scevgep20.31.27, align 1
  %conv68.31.27 = zext i8 %8043 to i32
  %8044 = load i8, i8* %arrayidx70.27, align 1
  %conv71.31.27 = zext i8 %8044 to i32
  %xor72.31.27 = xor i32 %conv71.31.27, %conv68.31.27
  %conv73.31.27 = trunc i32 %xor72.31.27 to i8
  store i8 %conv73.31.27, i8* %arrayidx70.27, align 1
  %scevgep20.32.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 32
  %8045 = load i8, i8* %scevgep20.32.27, align 1
  %conv68.32.27 = zext i8 %8045 to i32
  %8046 = load i8, i8* %arrayidx70.27, align 1
  %conv71.32.27 = zext i8 %8046 to i32
  %xor72.32.27 = xor i32 %conv71.32.27, %conv68.32.27
  %conv73.32.27 = trunc i32 %xor72.32.27 to i8
  store i8 %conv73.32.27, i8* %arrayidx70.27, align 1
  %scevgep20.33.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 33
  %8047 = load i8, i8* %scevgep20.33.27, align 1
  %conv68.33.27 = zext i8 %8047 to i32
  %8048 = load i8, i8* %arrayidx70.27, align 1
  %conv71.33.27 = zext i8 %8048 to i32
  %xor72.33.27 = xor i32 %conv71.33.27, %conv68.33.27
  %conv73.33.27 = trunc i32 %xor72.33.27 to i8
  store i8 %conv73.33.27, i8* %arrayidx70.27, align 1
  %scevgep20.34.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 34
  %8049 = load i8, i8* %scevgep20.34.27, align 1
  %conv68.34.27 = zext i8 %8049 to i32
  %8050 = load i8, i8* %arrayidx70.27, align 1
  %conv71.34.27 = zext i8 %8050 to i32
  %xor72.34.27 = xor i32 %conv71.34.27, %conv68.34.27
  %conv73.34.27 = trunc i32 %xor72.34.27 to i8
  store i8 %conv73.34.27, i8* %arrayidx70.27, align 1
  %scevgep20.35.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 35
  %8051 = load i8, i8* %scevgep20.35.27, align 1
  %conv68.35.27 = zext i8 %8051 to i32
  %8052 = load i8, i8* %arrayidx70.27, align 1
  %conv71.35.27 = zext i8 %8052 to i32
  %xor72.35.27 = xor i32 %conv71.35.27, %conv68.35.27
  %conv73.35.27 = trunc i32 %xor72.35.27 to i8
  store i8 %conv73.35.27, i8* %arrayidx70.27, align 1
  %scevgep20.36.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 36
  %8053 = load i8, i8* %scevgep20.36.27, align 1
  %conv68.36.27 = zext i8 %8053 to i32
  %8054 = load i8, i8* %arrayidx70.27, align 1
  %conv71.36.27 = zext i8 %8054 to i32
  %xor72.36.27 = xor i32 %conv71.36.27, %conv68.36.27
  %conv73.36.27 = trunc i32 %xor72.36.27 to i8
  store i8 %conv73.36.27, i8* %arrayidx70.27, align 1
  %scevgep20.37.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 37
  %8055 = load i8, i8* %scevgep20.37.27, align 1
  %conv68.37.27 = zext i8 %8055 to i32
  %8056 = load i8, i8* %arrayidx70.27, align 1
  %conv71.37.27 = zext i8 %8056 to i32
  %xor72.37.27 = xor i32 %conv71.37.27, %conv68.37.27
  %conv73.37.27 = trunc i32 %xor72.37.27 to i8
  store i8 %conv73.37.27, i8* %arrayidx70.27, align 1
  %scevgep20.38.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 38
  %8057 = load i8, i8* %scevgep20.38.27, align 1
  %conv68.38.27 = zext i8 %8057 to i32
  %8058 = load i8, i8* %arrayidx70.27, align 1
  %conv71.38.27 = zext i8 %8058 to i32
  %xor72.38.27 = xor i32 %conv71.38.27, %conv68.38.27
  %conv73.38.27 = trunc i32 %xor72.38.27 to i8
  store i8 %conv73.38.27, i8* %arrayidx70.27, align 1
  %scevgep20.39.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 39
  %8059 = load i8, i8* %scevgep20.39.27, align 1
  %conv68.39.27 = zext i8 %8059 to i32
  %8060 = load i8, i8* %arrayidx70.27, align 1
  %conv71.39.27 = zext i8 %8060 to i32
  %xor72.39.27 = xor i32 %conv71.39.27, %conv68.39.27
  %conv73.39.27 = trunc i32 %xor72.39.27 to i8
  store i8 %conv73.39.27, i8* %arrayidx70.27, align 1
  %scevgep20.40.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 0, i64 40
  %8061 = load i8, i8* %scevgep20.40.27, align 1
  %conv68.40.27 = zext i8 %8061 to i32
  %8062 = load i8, i8* %arrayidx70.27, align 1
  %conv71.40.27 = zext i8 %8062 to i32
  %xor72.40.27 = xor i32 %conv71.40.27, %conv68.40.27
  %conv73.40.27 = trunc i32 %xor72.40.27 to i8
  store i8 %conv73.40.27, i8* %arrayidx70.27, align 1
  %scevgep19.27 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %7980, i64 0, i64 1, i64 0
  %8063 = bitcast i8* %scevgep19.27 to [41 x [41 x i8]]*
  %arrayidx51.28 = getelementptr inbounds i8, i8* %a, i64 28
  %8064 = load i8, i8* %arrayidx51.28, align 1
  %arrayidx53.28 = getelementptr inbounds i8, i8* %b, i64 28
  %8065 = load i8, i8* %arrayidx53.28, align 1
  %call54.28 = call zeroext i8 @mult(i8 zeroext %8064, i8 zeroext %8065)
  %arrayidx56.28 = getelementptr inbounds i8, i8* %c, i64 28
  store i8 %call54.28, i8* %arrayidx56.28, align 1
  %arrayidx70.28 = getelementptr inbounds i8, i8* %c, i64 28
  %scevgep20.28324 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 0
  %8066 = load i8, i8* %scevgep20.28324, align 1
  %conv68.28325 = zext i8 %8066 to i32
  %8067 = load i8, i8* %arrayidx70.28, align 1
  %conv71.28326 = zext i8 %8067 to i32
  %xor72.28327 = xor i32 %conv71.28326, %conv68.28325
  %conv73.28328 = trunc i32 %xor72.28327 to i8
  store i8 %conv73.28328, i8* %arrayidx70.28, align 1
  %scevgep20.1.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 1
  %8068 = load i8, i8* %scevgep20.1.28, align 1
  %conv68.1.28 = zext i8 %8068 to i32
  %8069 = load i8, i8* %arrayidx70.28, align 1
  %conv71.1.28 = zext i8 %8069 to i32
  %xor72.1.28 = xor i32 %conv71.1.28, %conv68.1.28
  %conv73.1.28 = trunc i32 %xor72.1.28 to i8
  store i8 %conv73.1.28, i8* %arrayidx70.28, align 1
  %scevgep20.2.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 2
  %8070 = load i8, i8* %scevgep20.2.28, align 1
  %conv68.2.28 = zext i8 %8070 to i32
  %8071 = load i8, i8* %arrayidx70.28, align 1
  %conv71.2.28 = zext i8 %8071 to i32
  %xor72.2.28 = xor i32 %conv71.2.28, %conv68.2.28
  %conv73.2.28 = trunc i32 %xor72.2.28 to i8
  store i8 %conv73.2.28, i8* %arrayidx70.28, align 1
  %scevgep20.3.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 3
  %8072 = load i8, i8* %scevgep20.3.28, align 1
  %conv68.3.28 = zext i8 %8072 to i32
  %8073 = load i8, i8* %arrayidx70.28, align 1
  %conv71.3.28 = zext i8 %8073 to i32
  %xor72.3.28 = xor i32 %conv71.3.28, %conv68.3.28
  %conv73.3.28 = trunc i32 %xor72.3.28 to i8
  store i8 %conv73.3.28, i8* %arrayidx70.28, align 1
  %scevgep20.4.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 4
  %8074 = load i8, i8* %scevgep20.4.28, align 1
  %conv68.4.28 = zext i8 %8074 to i32
  %8075 = load i8, i8* %arrayidx70.28, align 1
  %conv71.4.28 = zext i8 %8075 to i32
  %xor72.4.28 = xor i32 %conv71.4.28, %conv68.4.28
  %conv73.4.28 = trunc i32 %xor72.4.28 to i8
  store i8 %conv73.4.28, i8* %arrayidx70.28, align 1
  %scevgep20.5.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 5
  %8076 = load i8, i8* %scevgep20.5.28, align 1
  %conv68.5.28 = zext i8 %8076 to i32
  %8077 = load i8, i8* %arrayidx70.28, align 1
  %conv71.5.28 = zext i8 %8077 to i32
  %xor72.5.28 = xor i32 %conv71.5.28, %conv68.5.28
  %conv73.5.28 = trunc i32 %xor72.5.28 to i8
  store i8 %conv73.5.28, i8* %arrayidx70.28, align 1
  %scevgep20.6.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 6
  %8078 = load i8, i8* %scevgep20.6.28, align 1
  %conv68.6.28 = zext i8 %8078 to i32
  %8079 = load i8, i8* %arrayidx70.28, align 1
  %conv71.6.28 = zext i8 %8079 to i32
  %xor72.6.28 = xor i32 %conv71.6.28, %conv68.6.28
  %conv73.6.28 = trunc i32 %xor72.6.28 to i8
  store i8 %conv73.6.28, i8* %arrayidx70.28, align 1
  %scevgep20.7.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 7
  %8080 = load i8, i8* %scevgep20.7.28, align 1
  %conv68.7.28 = zext i8 %8080 to i32
  %8081 = load i8, i8* %arrayidx70.28, align 1
  %conv71.7.28 = zext i8 %8081 to i32
  %xor72.7.28 = xor i32 %conv71.7.28, %conv68.7.28
  %conv73.7.28 = trunc i32 %xor72.7.28 to i8
  store i8 %conv73.7.28, i8* %arrayidx70.28, align 1
  %scevgep20.8.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 8
  %8082 = load i8, i8* %scevgep20.8.28, align 1
  %conv68.8.28 = zext i8 %8082 to i32
  %8083 = load i8, i8* %arrayidx70.28, align 1
  %conv71.8.28 = zext i8 %8083 to i32
  %xor72.8.28 = xor i32 %conv71.8.28, %conv68.8.28
  %conv73.8.28 = trunc i32 %xor72.8.28 to i8
  store i8 %conv73.8.28, i8* %arrayidx70.28, align 1
  %scevgep20.9.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 9
  %8084 = load i8, i8* %scevgep20.9.28, align 1
  %conv68.9.28 = zext i8 %8084 to i32
  %8085 = load i8, i8* %arrayidx70.28, align 1
  %conv71.9.28 = zext i8 %8085 to i32
  %xor72.9.28 = xor i32 %conv71.9.28, %conv68.9.28
  %conv73.9.28 = trunc i32 %xor72.9.28 to i8
  store i8 %conv73.9.28, i8* %arrayidx70.28, align 1
  %scevgep20.10.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 10
  %8086 = load i8, i8* %scevgep20.10.28, align 1
  %conv68.10.28 = zext i8 %8086 to i32
  %8087 = load i8, i8* %arrayidx70.28, align 1
  %conv71.10.28 = zext i8 %8087 to i32
  %xor72.10.28 = xor i32 %conv71.10.28, %conv68.10.28
  %conv73.10.28 = trunc i32 %xor72.10.28 to i8
  store i8 %conv73.10.28, i8* %arrayidx70.28, align 1
  %scevgep20.11.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 11
  %8088 = load i8, i8* %scevgep20.11.28, align 1
  %conv68.11.28 = zext i8 %8088 to i32
  %8089 = load i8, i8* %arrayidx70.28, align 1
  %conv71.11.28 = zext i8 %8089 to i32
  %xor72.11.28 = xor i32 %conv71.11.28, %conv68.11.28
  %conv73.11.28 = trunc i32 %xor72.11.28 to i8
  store i8 %conv73.11.28, i8* %arrayidx70.28, align 1
  %scevgep20.12.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 12
  %8090 = load i8, i8* %scevgep20.12.28, align 1
  %conv68.12.28 = zext i8 %8090 to i32
  %8091 = load i8, i8* %arrayidx70.28, align 1
  %conv71.12.28 = zext i8 %8091 to i32
  %xor72.12.28 = xor i32 %conv71.12.28, %conv68.12.28
  %conv73.12.28 = trunc i32 %xor72.12.28 to i8
  store i8 %conv73.12.28, i8* %arrayidx70.28, align 1
  %scevgep20.13.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 13
  %8092 = load i8, i8* %scevgep20.13.28, align 1
  %conv68.13.28 = zext i8 %8092 to i32
  %8093 = load i8, i8* %arrayidx70.28, align 1
  %conv71.13.28 = zext i8 %8093 to i32
  %xor72.13.28 = xor i32 %conv71.13.28, %conv68.13.28
  %conv73.13.28 = trunc i32 %xor72.13.28 to i8
  store i8 %conv73.13.28, i8* %arrayidx70.28, align 1
  %scevgep20.14.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 14
  %8094 = load i8, i8* %scevgep20.14.28, align 1
  %conv68.14.28 = zext i8 %8094 to i32
  %8095 = load i8, i8* %arrayidx70.28, align 1
  %conv71.14.28 = zext i8 %8095 to i32
  %xor72.14.28 = xor i32 %conv71.14.28, %conv68.14.28
  %conv73.14.28 = trunc i32 %xor72.14.28 to i8
  store i8 %conv73.14.28, i8* %arrayidx70.28, align 1
  %scevgep20.15.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 15
  %8096 = load i8, i8* %scevgep20.15.28, align 1
  %conv68.15.28 = zext i8 %8096 to i32
  %8097 = load i8, i8* %arrayidx70.28, align 1
  %conv71.15.28 = zext i8 %8097 to i32
  %xor72.15.28 = xor i32 %conv71.15.28, %conv68.15.28
  %conv73.15.28 = trunc i32 %xor72.15.28 to i8
  store i8 %conv73.15.28, i8* %arrayidx70.28, align 1
  %scevgep20.16.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 16
  %8098 = load i8, i8* %scevgep20.16.28, align 1
  %conv68.16.28 = zext i8 %8098 to i32
  %8099 = load i8, i8* %arrayidx70.28, align 1
  %conv71.16.28 = zext i8 %8099 to i32
  %xor72.16.28 = xor i32 %conv71.16.28, %conv68.16.28
  %conv73.16.28 = trunc i32 %xor72.16.28 to i8
  store i8 %conv73.16.28, i8* %arrayidx70.28, align 1
  %scevgep20.17.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 17
  %8100 = load i8, i8* %scevgep20.17.28, align 1
  %conv68.17.28 = zext i8 %8100 to i32
  %8101 = load i8, i8* %arrayidx70.28, align 1
  %conv71.17.28 = zext i8 %8101 to i32
  %xor72.17.28 = xor i32 %conv71.17.28, %conv68.17.28
  %conv73.17.28 = trunc i32 %xor72.17.28 to i8
  store i8 %conv73.17.28, i8* %arrayidx70.28, align 1
  %scevgep20.18.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 18
  %8102 = load i8, i8* %scevgep20.18.28, align 1
  %conv68.18.28 = zext i8 %8102 to i32
  %8103 = load i8, i8* %arrayidx70.28, align 1
  %conv71.18.28 = zext i8 %8103 to i32
  %xor72.18.28 = xor i32 %conv71.18.28, %conv68.18.28
  %conv73.18.28 = trunc i32 %xor72.18.28 to i8
  store i8 %conv73.18.28, i8* %arrayidx70.28, align 1
  %scevgep20.19.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 19
  %8104 = load i8, i8* %scevgep20.19.28, align 1
  %conv68.19.28 = zext i8 %8104 to i32
  %8105 = load i8, i8* %arrayidx70.28, align 1
  %conv71.19.28 = zext i8 %8105 to i32
  %xor72.19.28 = xor i32 %conv71.19.28, %conv68.19.28
  %conv73.19.28 = trunc i32 %xor72.19.28 to i8
  store i8 %conv73.19.28, i8* %arrayidx70.28, align 1
  %scevgep20.20.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 20
  %8106 = load i8, i8* %scevgep20.20.28, align 1
  %conv68.20.28 = zext i8 %8106 to i32
  %8107 = load i8, i8* %arrayidx70.28, align 1
  %conv71.20.28 = zext i8 %8107 to i32
  %xor72.20.28 = xor i32 %conv71.20.28, %conv68.20.28
  %conv73.20.28 = trunc i32 %xor72.20.28 to i8
  store i8 %conv73.20.28, i8* %arrayidx70.28, align 1
  %scevgep20.21.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 21
  %8108 = load i8, i8* %scevgep20.21.28, align 1
  %conv68.21.28 = zext i8 %8108 to i32
  %8109 = load i8, i8* %arrayidx70.28, align 1
  %conv71.21.28 = zext i8 %8109 to i32
  %xor72.21.28 = xor i32 %conv71.21.28, %conv68.21.28
  %conv73.21.28 = trunc i32 %xor72.21.28 to i8
  store i8 %conv73.21.28, i8* %arrayidx70.28, align 1
  %scevgep20.22.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 22
  %8110 = load i8, i8* %scevgep20.22.28, align 1
  %conv68.22.28 = zext i8 %8110 to i32
  %8111 = load i8, i8* %arrayidx70.28, align 1
  %conv71.22.28 = zext i8 %8111 to i32
  %xor72.22.28 = xor i32 %conv71.22.28, %conv68.22.28
  %conv73.22.28 = trunc i32 %xor72.22.28 to i8
  store i8 %conv73.22.28, i8* %arrayidx70.28, align 1
  %scevgep20.23.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 23
  %8112 = load i8, i8* %scevgep20.23.28, align 1
  %conv68.23.28 = zext i8 %8112 to i32
  %8113 = load i8, i8* %arrayidx70.28, align 1
  %conv71.23.28 = zext i8 %8113 to i32
  %xor72.23.28 = xor i32 %conv71.23.28, %conv68.23.28
  %conv73.23.28 = trunc i32 %xor72.23.28 to i8
  store i8 %conv73.23.28, i8* %arrayidx70.28, align 1
  %scevgep20.24.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 24
  %8114 = load i8, i8* %scevgep20.24.28, align 1
  %conv68.24.28 = zext i8 %8114 to i32
  %8115 = load i8, i8* %arrayidx70.28, align 1
  %conv71.24.28 = zext i8 %8115 to i32
  %xor72.24.28 = xor i32 %conv71.24.28, %conv68.24.28
  %conv73.24.28 = trunc i32 %xor72.24.28 to i8
  store i8 %conv73.24.28, i8* %arrayidx70.28, align 1
  %scevgep20.25.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 25
  %8116 = load i8, i8* %scevgep20.25.28, align 1
  %conv68.25.28 = zext i8 %8116 to i32
  %8117 = load i8, i8* %arrayidx70.28, align 1
  %conv71.25.28 = zext i8 %8117 to i32
  %xor72.25.28 = xor i32 %conv71.25.28, %conv68.25.28
  %conv73.25.28 = trunc i32 %xor72.25.28 to i8
  store i8 %conv73.25.28, i8* %arrayidx70.28, align 1
  %scevgep20.26.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 26
  %8118 = load i8, i8* %scevgep20.26.28, align 1
  %conv68.26.28 = zext i8 %8118 to i32
  %8119 = load i8, i8* %arrayidx70.28, align 1
  %conv71.26.28 = zext i8 %8119 to i32
  %xor72.26.28 = xor i32 %conv71.26.28, %conv68.26.28
  %conv73.26.28 = trunc i32 %xor72.26.28 to i8
  store i8 %conv73.26.28, i8* %arrayidx70.28, align 1
  %scevgep20.27.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 27
  %8120 = load i8, i8* %scevgep20.27.28, align 1
  %conv68.27.28 = zext i8 %8120 to i32
  %8121 = load i8, i8* %arrayidx70.28, align 1
  %conv71.27.28 = zext i8 %8121 to i32
  %xor72.27.28 = xor i32 %conv71.27.28, %conv68.27.28
  %conv73.27.28 = trunc i32 %xor72.27.28 to i8
  store i8 %conv73.27.28, i8* %arrayidx70.28, align 1
  %scevgep20.29.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 29
  %8122 = load i8, i8* %scevgep20.29.28, align 1
  %conv68.29.28 = zext i8 %8122 to i32
  %8123 = load i8, i8* %arrayidx70.28, align 1
  %conv71.29.28 = zext i8 %8123 to i32
  %xor72.29.28 = xor i32 %conv71.29.28, %conv68.29.28
  %conv73.29.28 = trunc i32 %xor72.29.28 to i8
  store i8 %conv73.29.28, i8* %arrayidx70.28, align 1
  %scevgep20.30.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 30
  %8124 = load i8, i8* %scevgep20.30.28, align 1
  %conv68.30.28 = zext i8 %8124 to i32
  %8125 = load i8, i8* %arrayidx70.28, align 1
  %conv71.30.28 = zext i8 %8125 to i32
  %xor72.30.28 = xor i32 %conv71.30.28, %conv68.30.28
  %conv73.30.28 = trunc i32 %xor72.30.28 to i8
  store i8 %conv73.30.28, i8* %arrayidx70.28, align 1
  %scevgep20.31.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 31
  %8126 = load i8, i8* %scevgep20.31.28, align 1
  %conv68.31.28 = zext i8 %8126 to i32
  %8127 = load i8, i8* %arrayidx70.28, align 1
  %conv71.31.28 = zext i8 %8127 to i32
  %xor72.31.28 = xor i32 %conv71.31.28, %conv68.31.28
  %conv73.31.28 = trunc i32 %xor72.31.28 to i8
  store i8 %conv73.31.28, i8* %arrayidx70.28, align 1
  %scevgep20.32.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 32
  %8128 = load i8, i8* %scevgep20.32.28, align 1
  %conv68.32.28 = zext i8 %8128 to i32
  %8129 = load i8, i8* %arrayidx70.28, align 1
  %conv71.32.28 = zext i8 %8129 to i32
  %xor72.32.28 = xor i32 %conv71.32.28, %conv68.32.28
  %conv73.32.28 = trunc i32 %xor72.32.28 to i8
  store i8 %conv73.32.28, i8* %arrayidx70.28, align 1
  %scevgep20.33.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 33
  %8130 = load i8, i8* %scevgep20.33.28, align 1
  %conv68.33.28 = zext i8 %8130 to i32
  %8131 = load i8, i8* %arrayidx70.28, align 1
  %conv71.33.28 = zext i8 %8131 to i32
  %xor72.33.28 = xor i32 %conv71.33.28, %conv68.33.28
  %conv73.33.28 = trunc i32 %xor72.33.28 to i8
  store i8 %conv73.33.28, i8* %arrayidx70.28, align 1
  %scevgep20.34.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 34
  %8132 = load i8, i8* %scevgep20.34.28, align 1
  %conv68.34.28 = zext i8 %8132 to i32
  %8133 = load i8, i8* %arrayidx70.28, align 1
  %conv71.34.28 = zext i8 %8133 to i32
  %xor72.34.28 = xor i32 %conv71.34.28, %conv68.34.28
  %conv73.34.28 = trunc i32 %xor72.34.28 to i8
  store i8 %conv73.34.28, i8* %arrayidx70.28, align 1
  %scevgep20.35.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 35
  %8134 = load i8, i8* %scevgep20.35.28, align 1
  %conv68.35.28 = zext i8 %8134 to i32
  %8135 = load i8, i8* %arrayidx70.28, align 1
  %conv71.35.28 = zext i8 %8135 to i32
  %xor72.35.28 = xor i32 %conv71.35.28, %conv68.35.28
  %conv73.35.28 = trunc i32 %xor72.35.28 to i8
  store i8 %conv73.35.28, i8* %arrayidx70.28, align 1
  %scevgep20.36.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 36
  %8136 = load i8, i8* %scevgep20.36.28, align 1
  %conv68.36.28 = zext i8 %8136 to i32
  %8137 = load i8, i8* %arrayidx70.28, align 1
  %conv71.36.28 = zext i8 %8137 to i32
  %xor72.36.28 = xor i32 %conv71.36.28, %conv68.36.28
  %conv73.36.28 = trunc i32 %xor72.36.28 to i8
  store i8 %conv73.36.28, i8* %arrayidx70.28, align 1
  %scevgep20.37.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 37
  %8138 = load i8, i8* %scevgep20.37.28, align 1
  %conv68.37.28 = zext i8 %8138 to i32
  %8139 = load i8, i8* %arrayidx70.28, align 1
  %conv71.37.28 = zext i8 %8139 to i32
  %xor72.37.28 = xor i32 %conv71.37.28, %conv68.37.28
  %conv73.37.28 = trunc i32 %xor72.37.28 to i8
  store i8 %conv73.37.28, i8* %arrayidx70.28, align 1
  %scevgep20.38.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 38
  %8140 = load i8, i8* %scevgep20.38.28, align 1
  %conv68.38.28 = zext i8 %8140 to i32
  %8141 = load i8, i8* %arrayidx70.28, align 1
  %conv71.38.28 = zext i8 %8141 to i32
  %xor72.38.28 = xor i32 %conv71.38.28, %conv68.38.28
  %conv73.38.28 = trunc i32 %xor72.38.28 to i8
  store i8 %conv73.38.28, i8* %arrayidx70.28, align 1
  %scevgep20.39.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 39
  %8142 = load i8, i8* %scevgep20.39.28, align 1
  %conv68.39.28 = zext i8 %8142 to i32
  %8143 = load i8, i8* %arrayidx70.28, align 1
  %conv71.39.28 = zext i8 %8143 to i32
  %xor72.39.28 = xor i32 %conv71.39.28, %conv68.39.28
  %conv73.39.28 = trunc i32 %xor72.39.28 to i8
  store i8 %conv73.39.28, i8* %arrayidx70.28, align 1
  %scevgep20.40.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 0, i64 40
  %8144 = load i8, i8* %scevgep20.40.28, align 1
  %conv68.40.28 = zext i8 %8144 to i32
  %8145 = load i8, i8* %arrayidx70.28, align 1
  %conv71.40.28 = zext i8 %8145 to i32
  %xor72.40.28 = xor i32 %conv71.40.28, %conv68.40.28
  %conv73.40.28 = trunc i32 %xor72.40.28 to i8
  store i8 %conv73.40.28, i8* %arrayidx70.28, align 1
  %scevgep19.28 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8063, i64 0, i64 1, i64 0
  %8146 = bitcast i8* %scevgep19.28 to [41 x [41 x i8]]*
  %arrayidx51.29 = getelementptr inbounds i8, i8* %a, i64 29
  %8147 = load i8, i8* %arrayidx51.29, align 1
  %arrayidx53.29 = getelementptr inbounds i8, i8* %b, i64 29
  %8148 = load i8, i8* %arrayidx53.29, align 1
  %call54.29 = call zeroext i8 @mult(i8 zeroext %8147, i8 zeroext %8148)
  %arrayidx56.29 = getelementptr inbounds i8, i8* %c, i64 29
  store i8 %call54.29, i8* %arrayidx56.29, align 1
  %arrayidx70.29 = getelementptr inbounds i8, i8* %c, i64 29
  %scevgep20.29334 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 0
  %8149 = load i8, i8* %scevgep20.29334, align 1
  %conv68.29335 = zext i8 %8149 to i32
  %8150 = load i8, i8* %arrayidx70.29, align 1
  %conv71.29336 = zext i8 %8150 to i32
  %xor72.29337 = xor i32 %conv71.29336, %conv68.29335
  %conv73.29338 = trunc i32 %xor72.29337 to i8
  store i8 %conv73.29338, i8* %arrayidx70.29, align 1
  %scevgep20.1.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 1
  %8151 = load i8, i8* %scevgep20.1.29, align 1
  %conv68.1.29 = zext i8 %8151 to i32
  %8152 = load i8, i8* %arrayidx70.29, align 1
  %conv71.1.29 = zext i8 %8152 to i32
  %xor72.1.29 = xor i32 %conv71.1.29, %conv68.1.29
  %conv73.1.29 = trunc i32 %xor72.1.29 to i8
  store i8 %conv73.1.29, i8* %arrayidx70.29, align 1
  %scevgep20.2.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 2
  %8153 = load i8, i8* %scevgep20.2.29, align 1
  %conv68.2.29 = zext i8 %8153 to i32
  %8154 = load i8, i8* %arrayidx70.29, align 1
  %conv71.2.29 = zext i8 %8154 to i32
  %xor72.2.29 = xor i32 %conv71.2.29, %conv68.2.29
  %conv73.2.29 = trunc i32 %xor72.2.29 to i8
  store i8 %conv73.2.29, i8* %arrayidx70.29, align 1
  %scevgep20.3.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 3
  %8155 = load i8, i8* %scevgep20.3.29, align 1
  %conv68.3.29 = zext i8 %8155 to i32
  %8156 = load i8, i8* %arrayidx70.29, align 1
  %conv71.3.29 = zext i8 %8156 to i32
  %xor72.3.29 = xor i32 %conv71.3.29, %conv68.3.29
  %conv73.3.29 = trunc i32 %xor72.3.29 to i8
  store i8 %conv73.3.29, i8* %arrayidx70.29, align 1
  %scevgep20.4.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 4
  %8157 = load i8, i8* %scevgep20.4.29, align 1
  %conv68.4.29 = zext i8 %8157 to i32
  %8158 = load i8, i8* %arrayidx70.29, align 1
  %conv71.4.29 = zext i8 %8158 to i32
  %xor72.4.29 = xor i32 %conv71.4.29, %conv68.4.29
  %conv73.4.29 = trunc i32 %xor72.4.29 to i8
  store i8 %conv73.4.29, i8* %arrayidx70.29, align 1
  %scevgep20.5.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 5
  %8159 = load i8, i8* %scevgep20.5.29, align 1
  %conv68.5.29 = zext i8 %8159 to i32
  %8160 = load i8, i8* %arrayidx70.29, align 1
  %conv71.5.29 = zext i8 %8160 to i32
  %xor72.5.29 = xor i32 %conv71.5.29, %conv68.5.29
  %conv73.5.29 = trunc i32 %xor72.5.29 to i8
  store i8 %conv73.5.29, i8* %arrayidx70.29, align 1
  %scevgep20.6.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 6
  %8161 = load i8, i8* %scevgep20.6.29, align 1
  %conv68.6.29 = zext i8 %8161 to i32
  %8162 = load i8, i8* %arrayidx70.29, align 1
  %conv71.6.29 = zext i8 %8162 to i32
  %xor72.6.29 = xor i32 %conv71.6.29, %conv68.6.29
  %conv73.6.29 = trunc i32 %xor72.6.29 to i8
  store i8 %conv73.6.29, i8* %arrayidx70.29, align 1
  %scevgep20.7.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 7
  %8163 = load i8, i8* %scevgep20.7.29, align 1
  %conv68.7.29 = zext i8 %8163 to i32
  %8164 = load i8, i8* %arrayidx70.29, align 1
  %conv71.7.29 = zext i8 %8164 to i32
  %xor72.7.29 = xor i32 %conv71.7.29, %conv68.7.29
  %conv73.7.29 = trunc i32 %xor72.7.29 to i8
  store i8 %conv73.7.29, i8* %arrayidx70.29, align 1
  %scevgep20.8.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 8
  %8165 = load i8, i8* %scevgep20.8.29, align 1
  %conv68.8.29 = zext i8 %8165 to i32
  %8166 = load i8, i8* %arrayidx70.29, align 1
  %conv71.8.29 = zext i8 %8166 to i32
  %xor72.8.29 = xor i32 %conv71.8.29, %conv68.8.29
  %conv73.8.29 = trunc i32 %xor72.8.29 to i8
  store i8 %conv73.8.29, i8* %arrayidx70.29, align 1
  %scevgep20.9.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 9
  %8167 = load i8, i8* %scevgep20.9.29, align 1
  %conv68.9.29 = zext i8 %8167 to i32
  %8168 = load i8, i8* %arrayidx70.29, align 1
  %conv71.9.29 = zext i8 %8168 to i32
  %xor72.9.29 = xor i32 %conv71.9.29, %conv68.9.29
  %conv73.9.29 = trunc i32 %xor72.9.29 to i8
  store i8 %conv73.9.29, i8* %arrayidx70.29, align 1
  %scevgep20.10.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 10
  %8169 = load i8, i8* %scevgep20.10.29, align 1
  %conv68.10.29 = zext i8 %8169 to i32
  %8170 = load i8, i8* %arrayidx70.29, align 1
  %conv71.10.29 = zext i8 %8170 to i32
  %xor72.10.29 = xor i32 %conv71.10.29, %conv68.10.29
  %conv73.10.29 = trunc i32 %xor72.10.29 to i8
  store i8 %conv73.10.29, i8* %arrayidx70.29, align 1
  %scevgep20.11.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 11
  %8171 = load i8, i8* %scevgep20.11.29, align 1
  %conv68.11.29 = zext i8 %8171 to i32
  %8172 = load i8, i8* %arrayidx70.29, align 1
  %conv71.11.29 = zext i8 %8172 to i32
  %xor72.11.29 = xor i32 %conv71.11.29, %conv68.11.29
  %conv73.11.29 = trunc i32 %xor72.11.29 to i8
  store i8 %conv73.11.29, i8* %arrayidx70.29, align 1
  %scevgep20.12.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 12
  %8173 = load i8, i8* %scevgep20.12.29, align 1
  %conv68.12.29 = zext i8 %8173 to i32
  %8174 = load i8, i8* %arrayidx70.29, align 1
  %conv71.12.29 = zext i8 %8174 to i32
  %xor72.12.29 = xor i32 %conv71.12.29, %conv68.12.29
  %conv73.12.29 = trunc i32 %xor72.12.29 to i8
  store i8 %conv73.12.29, i8* %arrayidx70.29, align 1
  %scevgep20.13.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 13
  %8175 = load i8, i8* %scevgep20.13.29, align 1
  %conv68.13.29 = zext i8 %8175 to i32
  %8176 = load i8, i8* %arrayidx70.29, align 1
  %conv71.13.29 = zext i8 %8176 to i32
  %xor72.13.29 = xor i32 %conv71.13.29, %conv68.13.29
  %conv73.13.29 = trunc i32 %xor72.13.29 to i8
  store i8 %conv73.13.29, i8* %arrayidx70.29, align 1
  %scevgep20.14.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 14
  %8177 = load i8, i8* %scevgep20.14.29, align 1
  %conv68.14.29 = zext i8 %8177 to i32
  %8178 = load i8, i8* %arrayidx70.29, align 1
  %conv71.14.29 = zext i8 %8178 to i32
  %xor72.14.29 = xor i32 %conv71.14.29, %conv68.14.29
  %conv73.14.29 = trunc i32 %xor72.14.29 to i8
  store i8 %conv73.14.29, i8* %arrayidx70.29, align 1
  %scevgep20.15.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 15
  %8179 = load i8, i8* %scevgep20.15.29, align 1
  %conv68.15.29 = zext i8 %8179 to i32
  %8180 = load i8, i8* %arrayidx70.29, align 1
  %conv71.15.29 = zext i8 %8180 to i32
  %xor72.15.29 = xor i32 %conv71.15.29, %conv68.15.29
  %conv73.15.29 = trunc i32 %xor72.15.29 to i8
  store i8 %conv73.15.29, i8* %arrayidx70.29, align 1
  %scevgep20.16.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 16
  %8181 = load i8, i8* %scevgep20.16.29, align 1
  %conv68.16.29 = zext i8 %8181 to i32
  %8182 = load i8, i8* %arrayidx70.29, align 1
  %conv71.16.29 = zext i8 %8182 to i32
  %xor72.16.29 = xor i32 %conv71.16.29, %conv68.16.29
  %conv73.16.29 = trunc i32 %xor72.16.29 to i8
  store i8 %conv73.16.29, i8* %arrayidx70.29, align 1
  %scevgep20.17.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 17
  %8183 = load i8, i8* %scevgep20.17.29, align 1
  %conv68.17.29 = zext i8 %8183 to i32
  %8184 = load i8, i8* %arrayidx70.29, align 1
  %conv71.17.29 = zext i8 %8184 to i32
  %xor72.17.29 = xor i32 %conv71.17.29, %conv68.17.29
  %conv73.17.29 = trunc i32 %xor72.17.29 to i8
  store i8 %conv73.17.29, i8* %arrayidx70.29, align 1
  %scevgep20.18.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 18
  %8185 = load i8, i8* %scevgep20.18.29, align 1
  %conv68.18.29 = zext i8 %8185 to i32
  %8186 = load i8, i8* %arrayidx70.29, align 1
  %conv71.18.29 = zext i8 %8186 to i32
  %xor72.18.29 = xor i32 %conv71.18.29, %conv68.18.29
  %conv73.18.29 = trunc i32 %xor72.18.29 to i8
  store i8 %conv73.18.29, i8* %arrayidx70.29, align 1
  %scevgep20.19.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 19
  %8187 = load i8, i8* %scevgep20.19.29, align 1
  %conv68.19.29 = zext i8 %8187 to i32
  %8188 = load i8, i8* %arrayidx70.29, align 1
  %conv71.19.29 = zext i8 %8188 to i32
  %xor72.19.29 = xor i32 %conv71.19.29, %conv68.19.29
  %conv73.19.29 = trunc i32 %xor72.19.29 to i8
  store i8 %conv73.19.29, i8* %arrayidx70.29, align 1
  %scevgep20.20.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 20
  %8189 = load i8, i8* %scevgep20.20.29, align 1
  %conv68.20.29 = zext i8 %8189 to i32
  %8190 = load i8, i8* %arrayidx70.29, align 1
  %conv71.20.29 = zext i8 %8190 to i32
  %xor72.20.29 = xor i32 %conv71.20.29, %conv68.20.29
  %conv73.20.29 = trunc i32 %xor72.20.29 to i8
  store i8 %conv73.20.29, i8* %arrayidx70.29, align 1
  %scevgep20.21.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 21
  %8191 = load i8, i8* %scevgep20.21.29, align 1
  %conv68.21.29 = zext i8 %8191 to i32
  %8192 = load i8, i8* %arrayidx70.29, align 1
  %conv71.21.29 = zext i8 %8192 to i32
  %xor72.21.29 = xor i32 %conv71.21.29, %conv68.21.29
  %conv73.21.29 = trunc i32 %xor72.21.29 to i8
  store i8 %conv73.21.29, i8* %arrayidx70.29, align 1
  %scevgep20.22.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 22
  %8193 = load i8, i8* %scevgep20.22.29, align 1
  %conv68.22.29 = zext i8 %8193 to i32
  %8194 = load i8, i8* %arrayidx70.29, align 1
  %conv71.22.29 = zext i8 %8194 to i32
  %xor72.22.29 = xor i32 %conv71.22.29, %conv68.22.29
  %conv73.22.29 = trunc i32 %xor72.22.29 to i8
  store i8 %conv73.22.29, i8* %arrayidx70.29, align 1
  %scevgep20.23.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 23
  %8195 = load i8, i8* %scevgep20.23.29, align 1
  %conv68.23.29 = zext i8 %8195 to i32
  %8196 = load i8, i8* %arrayidx70.29, align 1
  %conv71.23.29 = zext i8 %8196 to i32
  %xor72.23.29 = xor i32 %conv71.23.29, %conv68.23.29
  %conv73.23.29 = trunc i32 %xor72.23.29 to i8
  store i8 %conv73.23.29, i8* %arrayidx70.29, align 1
  %scevgep20.24.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 24
  %8197 = load i8, i8* %scevgep20.24.29, align 1
  %conv68.24.29 = zext i8 %8197 to i32
  %8198 = load i8, i8* %arrayidx70.29, align 1
  %conv71.24.29 = zext i8 %8198 to i32
  %xor72.24.29 = xor i32 %conv71.24.29, %conv68.24.29
  %conv73.24.29 = trunc i32 %xor72.24.29 to i8
  store i8 %conv73.24.29, i8* %arrayidx70.29, align 1
  %scevgep20.25.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 25
  %8199 = load i8, i8* %scevgep20.25.29, align 1
  %conv68.25.29 = zext i8 %8199 to i32
  %8200 = load i8, i8* %arrayidx70.29, align 1
  %conv71.25.29 = zext i8 %8200 to i32
  %xor72.25.29 = xor i32 %conv71.25.29, %conv68.25.29
  %conv73.25.29 = trunc i32 %xor72.25.29 to i8
  store i8 %conv73.25.29, i8* %arrayidx70.29, align 1
  %scevgep20.26.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 26
  %8201 = load i8, i8* %scevgep20.26.29, align 1
  %conv68.26.29 = zext i8 %8201 to i32
  %8202 = load i8, i8* %arrayidx70.29, align 1
  %conv71.26.29 = zext i8 %8202 to i32
  %xor72.26.29 = xor i32 %conv71.26.29, %conv68.26.29
  %conv73.26.29 = trunc i32 %xor72.26.29 to i8
  store i8 %conv73.26.29, i8* %arrayidx70.29, align 1
  %scevgep20.27.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 27
  %8203 = load i8, i8* %scevgep20.27.29, align 1
  %conv68.27.29 = zext i8 %8203 to i32
  %8204 = load i8, i8* %arrayidx70.29, align 1
  %conv71.27.29 = zext i8 %8204 to i32
  %xor72.27.29 = xor i32 %conv71.27.29, %conv68.27.29
  %conv73.27.29 = trunc i32 %xor72.27.29 to i8
  store i8 %conv73.27.29, i8* %arrayidx70.29, align 1
  %scevgep20.28.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 28
  %8205 = load i8, i8* %scevgep20.28.29, align 1
  %conv68.28.29 = zext i8 %8205 to i32
  %8206 = load i8, i8* %arrayidx70.29, align 1
  %conv71.28.29 = zext i8 %8206 to i32
  %xor72.28.29 = xor i32 %conv71.28.29, %conv68.28.29
  %conv73.28.29 = trunc i32 %xor72.28.29 to i8
  store i8 %conv73.28.29, i8* %arrayidx70.29, align 1
  %scevgep20.30.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 30
  %8207 = load i8, i8* %scevgep20.30.29, align 1
  %conv68.30.29 = zext i8 %8207 to i32
  %8208 = load i8, i8* %arrayidx70.29, align 1
  %conv71.30.29 = zext i8 %8208 to i32
  %xor72.30.29 = xor i32 %conv71.30.29, %conv68.30.29
  %conv73.30.29 = trunc i32 %xor72.30.29 to i8
  store i8 %conv73.30.29, i8* %arrayidx70.29, align 1
  %scevgep20.31.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 31
  %8209 = load i8, i8* %scevgep20.31.29, align 1
  %conv68.31.29 = zext i8 %8209 to i32
  %8210 = load i8, i8* %arrayidx70.29, align 1
  %conv71.31.29 = zext i8 %8210 to i32
  %xor72.31.29 = xor i32 %conv71.31.29, %conv68.31.29
  %conv73.31.29 = trunc i32 %xor72.31.29 to i8
  store i8 %conv73.31.29, i8* %arrayidx70.29, align 1
  %scevgep20.32.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 32
  %8211 = load i8, i8* %scevgep20.32.29, align 1
  %conv68.32.29 = zext i8 %8211 to i32
  %8212 = load i8, i8* %arrayidx70.29, align 1
  %conv71.32.29 = zext i8 %8212 to i32
  %xor72.32.29 = xor i32 %conv71.32.29, %conv68.32.29
  %conv73.32.29 = trunc i32 %xor72.32.29 to i8
  store i8 %conv73.32.29, i8* %arrayidx70.29, align 1
  %scevgep20.33.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 33
  %8213 = load i8, i8* %scevgep20.33.29, align 1
  %conv68.33.29 = zext i8 %8213 to i32
  %8214 = load i8, i8* %arrayidx70.29, align 1
  %conv71.33.29 = zext i8 %8214 to i32
  %xor72.33.29 = xor i32 %conv71.33.29, %conv68.33.29
  %conv73.33.29 = trunc i32 %xor72.33.29 to i8
  store i8 %conv73.33.29, i8* %arrayidx70.29, align 1
  %scevgep20.34.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 34
  %8215 = load i8, i8* %scevgep20.34.29, align 1
  %conv68.34.29 = zext i8 %8215 to i32
  %8216 = load i8, i8* %arrayidx70.29, align 1
  %conv71.34.29 = zext i8 %8216 to i32
  %xor72.34.29 = xor i32 %conv71.34.29, %conv68.34.29
  %conv73.34.29 = trunc i32 %xor72.34.29 to i8
  store i8 %conv73.34.29, i8* %arrayidx70.29, align 1
  %scevgep20.35.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 35
  %8217 = load i8, i8* %scevgep20.35.29, align 1
  %conv68.35.29 = zext i8 %8217 to i32
  %8218 = load i8, i8* %arrayidx70.29, align 1
  %conv71.35.29 = zext i8 %8218 to i32
  %xor72.35.29 = xor i32 %conv71.35.29, %conv68.35.29
  %conv73.35.29 = trunc i32 %xor72.35.29 to i8
  store i8 %conv73.35.29, i8* %arrayidx70.29, align 1
  %scevgep20.36.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 36
  %8219 = load i8, i8* %scevgep20.36.29, align 1
  %conv68.36.29 = zext i8 %8219 to i32
  %8220 = load i8, i8* %arrayidx70.29, align 1
  %conv71.36.29 = zext i8 %8220 to i32
  %xor72.36.29 = xor i32 %conv71.36.29, %conv68.36.29
  %conv73.36.29 = trunc i32 %xor72.36.29 to i8
  store i8 %conv73.36.29, i8* %arrayidx70.29, align 1
  %scevgep20.37.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 37
  %8221 = load i8, i8* %scevgep20.37.29, align 1
  %conv68.37.29 = zext i8 %8221 to i32
  %8222 = load i8, i8* %arrayidx70.29, align 1
  %conv71.37.29 = zext i8 %8222 to i32
  %xor72.37.29 = xor i32 %conv71.37.29, %conv68.37.29
  %conv73.37.29 = trunc i32 %xor72.37.29 to i8
  store i8 %conv73.37.29, i8* %arrayidx70.29, align 1
  %scevgep20.38.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 38
  %8223 = load i8, i8* %scevgep20.38.29, align 1
  %conv68.38.29 = zext i8 %8223 to i32
  %8224 = load i8, i8* %arrayidx70.29, align 1
  %conv71.38.29 = zext i8 %8224 to i32
  %xor72.38.29 = xor i32 %conv71.38.29, %conv68.38.29
  %conv73.38.29 = trunc i32 %xor72.38.29 to i8
  store i8 %conv73.38.29, i8* %arrayidx70.29, align 1
  %scevgep20.39.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 39
  %8225 = load i8, i8* %scevgep20.39.29, align 1
  %conv68.39.29 = zext i8 %8225 to i32
  %8226 = load i8, i8* %arrayidx70.29, align 1
  %conv71.39.29 = zext i8 %8226 to i32
  %xor72.39.29 = xor i32 %conv71.39.29, %conv68.39.29
  %conv73.39.29 = trunc i32 %xor72.39.29 to i8
  store i8 %conv73.39.29, i8* %arrayidx70.29, align 1
  %scevgep20.40.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 0, i64 40
  %8227 = load i8, i8* %scevgep20.40.29, align 1
  %conv68.40.29 = zext i8 %8227 to i32
  %8228 = load i8, i8* %arrayidx70.29, align 1
  %conv71.40.29 = zext i8 %8228 to i32
  %xor72.40.29 = xor i32 %conv71.40.29, %conv68.40.29
  %conv73.40.29 = trunc i32 %xor72.40.29 to i8
  store i8 %conv73.40.29, i8* %arrayidx70.29, align 1
  %scevgep19.29 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8146, i64 0, i64 1, i64 0
  %8229 = bitcast i8* %scevgep19.29 to [41 x [41 x i8]]*
  %arrayidx51.30 = getelementptr inbounds i8, i8* %a, i64 30
  %8230 = load i8, i8* %arrayidx51.30, align 1
  %arrayidx53.30 = getelementptr inbounds i8, i8* %b, i64 30
  %8231 = load i8, i8* %arrayidx53.30, align 1
  %call54.30 = call zeroext i8 @mult(i8 zeroext %8230, i8 zeroext %8231)
  %arrayidx56.30 = getelementptr inbounds i8, i8* %c, i64 30
  store i8 %call54.30, i8* %arrayidx56.30, align 1
  %arrayidx70.30 = getelementptr inbounds i8, i8* %c, i64 30
  %scevgep20.30344 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 0
  %8232 = load i8, i8* %scevgep20.30344, align 1
  %conv68.30345 = zext i8 %8232 to i32
  %8233 = load i8, i8* %arrayidx70.30, align 1
  %conv71.30346 = zext i8 %8233 to i32
  %xor72.30347 = xor i32 %conv71.30346, %conv68.30345
  %conv73.30348 = trunc i32 %xor72.30347 to i8
  store i8 %conv73.30348, i8* %arrayidx70.30, align 1
  %scevgep20.1.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 1
  %8234 = load i8, i8* %scevgep20.1.30, align 1
  %conv68.1.30 = zext i8 %8234 to i32
  %8235 = load i8, i8* %arrayidx70.30, align 1
  %conv71.1.30 = zext i8 %8235 to i32
  %xor72.1.30 = xor i32 %conv71.1.30, %conv68.1.30
  %conv73.1.30 = trunc i32 %xor72.1.30 to i8
  store i8 %conv73.1.30, i8* %arrayidx70.30, align 1
  %scevgep20.2.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 2
  %8236 = load i8, i8* %scevgep20.2.30, align 1
  %conv68.2.30 = zext i8 %8236 to i32
  %8237 = load i8, i8* %arrayidx70.30, align 1
  %conv71.2.30 = zext i8 %8237 to i32
  %xor72.2.30 = xor i32 %conv71.2.30, %conv68.2.30
  %conv73.2.30 = trunc i32 %xor72.2.30 to i8
  store i8 %conv73.2.30, i8* %arrayidx70.30, align 1
  %scevgep20.3.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 3
  %8238 = load i8, i8* %scevgep20.3.30, align 1
  %conv68.3.30 = zext i8 %8238 to i32
  %8239 = load i8, i8* %arrayidx70.30, align 1
  %conv71.3.30 = zext i8 %8239 to i32
  %xor72.3.30 = xor i32 %conv71.3.30, %conv68.3.30
  %conv73.3.30 = trunc i32 %xor72.3.30 to i8
  store i8 %conv73.3.30, i8* %arrayidx70.30, align 1
  %scevgep20.4.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 4
  %8240 = load i8, i8* %scevgep20.4.30, align 1
  %conv68.4.30 = zext i8 %8240 to i32
  %8241 = load i8, i8* %arrayidx70.30, align 1
  %conv71.4.30 = zext i8 %8241 to i32
  %xor72.4.30 = xor i32 %conv71.4.30, %conv68.4.30
  %conv73.4.30 = trunc i32 %xor72.4.30 to i8
  store i8 %conv73.4.30, i8* %arrayidx70.30, align 1
  %scevgep20.5.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 5
  %8242 = load i8, i8* %scevgep20.5.30, align 1
  %conv68.5.30 = zext i8 %8242 to i32
  %8243 = load i8, i8* %arrayidx70.30, align 1
  %conv71.5.30 = zext i8 %8243 to i32
  %xor72.5.30 = xor i32 %conv71.5.30, %conv68.5.30
  %conv73.5.30 = trunc i32 %xor72.5.30 to i8
  store i8 %conv73.5.30, i8* %arrayidx70.30, align 1
  %scevgep20.6.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 6
  %8244 = load i8, i8* %scevgep20.6.30, align 1
  %conv68.6.30 = zext i8 %8244 to i32
  %8245 = load i8, i8* %arrayidx70.30, align 1
  %conv71.6.30 = zext i8 %8245 to i32
  %xor72.6.30 = xor i32 %conv71.6.30, %conv68.6.30
  %conv73.6.30 = trunc i32 %xor72.6.30 to i8
  store i8 %conv73.6.30, i8* %arrayidx70.30, align 1
  %scevgep20.7.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 7
  %8246 = load i8, i8* %scevgep20.7.30, align 1
  %conv68.7.30 = zext i8 %8246 to i32
  %8247 = load i8, i8* %arrayidx70.30, align 1
  %conv71.7.30 = zext i8 %8247 to i32
  %xor72.7.30 = xor i32 %conv71.7.30, %conv68.7.30
  %conv73.7.30 = trunc i32 %xor72.7.30 to i8
  store i8 %conv73.7.30, i8* %arrayidx70.30, align 1
  %scevgep20.8.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 8
  %8248 = load i8, i8* %scevgep20.8.30, align 1
  %conv68.8.30 = zext i8 %8248 to i32
  %8249 = load i8, i8* %arrayidx70.30, align 1
  %conv71.8.30 = zext i8 %8249 to i32
  %xor72.8.30 = xor i32 %conv71.8.30, %conv68.8.30
  %conv73.8.30 = trunc i32 %xor72.8.30 to i8
  store i8 %conv73.8.30, i8* %arrayidx70.30, align 1
  %scevgep20.9.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 9
  %8250 = load i8, i8* %scevgep20.9.30, align 1
  %conv68.9.30 = zext i8 %8250 to i32
  %8251 = load i8, i8* %arrayidx70.30, align 1
  %conv71.9.30 = zext i8 %8251 to i32
  %xor72.9.30 = xor i32 %conv71.9.30, %conv68.9.30
  %conv73.9.30 = trunc i32 %xor72.9.30 to i8
  store i8 %conv73.9.30, i8* %arrayidx70.30, align 1
  %scevgep20.10.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 10
  %8252 = load i8, i8* %scevgep20.10.30, align 1
  %conv68.10.30 = zext i8 %8252 to i32
  %8253 = load i8, i8* %arrayidx70.30, align 1
  %conv71.10.30 = zext i8 %8253 to i32
  %xor72.10.30 = xor i32 %conv71.10.30, %conv68.10.30
  %conv73.10.30 = trunc i32 %xor72.10.30 to i8
  store i8 %conv73.10.30, i8* %arrayidx70.30, align 1
  %scevgep20.11.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 11
  %8254 = load i8, i8* %scevgep20.11.30, align 1
  %conv68.11.30 = zext i8 %8254 to i32
  %8255 = load i8, i8* %arrayidx70.30, align 1
  %conv71.11.30 = zext i8 %8255 to i32
  %xor72.11.30 = xor i32 %conv71.11.30, %conv68.11.30
  %conv73.11.30 = trunc i32 %xor72.11.30 to i8
  store i8 %conv73.11.30, i8* %arrayidx70.30, align 1
  %scevgep20.12.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 12
  %8256 = load i8, i8* %scevgep20.12.30, align 1
  %conv68.12.30 = zext i8 %8256 to i32
  %8257 = load i8, i8* %arrayidx70.30, align 1
  %conv71.12.30 = zext i8 %8257 to i32
  %xor72.12.30 = xor i32 %conv71.12.30, %conv68.12.30
  %conv73.12.30 = trunc i32 %xor72.12.30 to i8
  store i8 %conv73.12.30, i8* %arrayidx70.30, align 1
  %scevgep20.13.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 13
  %8258 = load i8, i8* %scevgep20.13.30, align 1
  %conv68.13.30 = zext i8 %8258 to i32
  %8259 = load i8, i8* %arrayidx70.30, align 1
  %conv71.13.30 = zext i8 %8259 to i32
  %xor72.13.30 = xor i32 %conv71.13.30, %conv68.13.30
  %conv73.13.30 = trunc i32 %xor72.13.30 to i8
  store i8 %conv73.13.30, i8* %arrayidx70.30, align 1
  %scevgep20.14.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 14
  %8260 = load i8, i8* %scevgep20.14.30, align 1
  %conv68.14.30 = zext i8 %8260 to i32
  %8261 = load i8, i8* %arrayidx70.30, align 1
  %conv71.14.30 = zext i8 %8261 to i32
  %xor72.14.30 = xor i32 %conv71.14.30, %conv68.14.30
  %conv73.14.30 = trunc i32 %xor72.14.30 to i8
  store i8 %conv73.14.30, i8* %arrayidx70.30, align 1
  %scevgep20.15.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 15
  %8262 = load i8, i8* %scevgep20.15.30, align 1
  %conv68.15.30 = zext i8 %8262 to i32
  %8263 = load i8, i8* %arrayidx70.30, align 1
  %conv71.15.30 = zext i8 %8263 to i32
  %xor72.15.30 = xor i32 %conv71.15.30, %conv68.15.30
  %conv73.15.30 = trunc i32 %xor72.15.30 to i8
  store i8 %conv73.15.30, i8* %arrayidx70.30, align 1
  %scevgep20.16.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 16
  %8264 = load i8, i8* %scevgep20.16.30, align 1
  %conv68.16.30 = zext i8 %8264 to i32
  %8265 = load i8, i8* %arrayidx70.30, align 1
  %conv71.16.30 = zext i8 %8265 to i32
  %xor72.16.30 = xor i32 %conv71.16.30, %conv68.16.30
  %conv73.16.30 = trunc i32 %xor72.16.30 to i8
  store i8 %conv73.16.30, i8* %arrayidx70.30, align 1
  %scevgep20.17.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 17
  %8266 = load i8, i8* %scevgep20.17.30, align 1
  %conv68.17.30 = zext i8 %8266 to i32
  %8267 = load i8, i8* %arrayidx70.30, align 1
  %conv71.17.30 = zext i8 %8267 to i32
  %xor72.17.30 = xor i32 %conv71.17.30, %conv68.17.30
  %conv73.17.30 = trunc i32 %xor72.17.30 to i8
  store i8 %conv73.17.30, i8* %arrayidx70.30, align 1
  %scevgep20.18.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 18
  %8268 = load i8, i8* %scevgep20.18.30, align 1
  %conv68.18.30 = zext i8 %8268 to i32
  %8269 = load i8, i8* %arrayidx70.30, align 1
  %conv71.18.30 = zext i8 %8269 to i32
  %xor72.18.30 = xor i32 %conv71.18.30, %conv68.18.30
  %conv73.18.30 = trunc i32 %xor72.18.30 to i8
  store i8 %conv73.18.30, i8* %arrayidx70.30, align 1
  %scevgep20.19.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 19
  %8270 = load i8, i8* %scevgep20.19.30, align 1
  %conv68.19.30 = zext i8 %8270 to i32
  %8271 = load i8, i8* %arrayidx70.30, align 1
  %conv71.19.30 = zext i8 %8271 to i32
  %xor72.19.30 = xor i32 %conv71.19.30, %conv68.19.30
  %conv73.19.30 = trunc i32 %xor72.19.30 to i8
  store i8 %conv73.19.30, i8* %arrayidx70.30, align 1
  %scevgep20.20.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 20
  %8272 = load i8, i8* %scevgep20.20.30, align 1
  %conv68.20.30 = zext i8 %8272 to i32
  %8273 = load i8, i8* %arrayidx70.30, align 1
  %conv71.20.30 = zext i8 %8273 to i32
  %xor72.20.30 = xor i32 %conv71.20.30, %conv68.20.30
  %conv73.20.30 = trunc i32 %xor72.20.30 to i8
  store i8 %conv73.20.30, i8* %arrayidx70.30, align 1
  %scevgep20.21.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 21
  %8274 = load i8, i8* %scevgep20.21.30, align 1
  %conv68.21.30 = zext i8 %8274 to i32
  %8275 = load i8, i8* %arrayidx70.30, align 1
  %conv71.21.30 = zext i8 %8275 to i32
  %xor72.21.30 = xor i32 %conv71.21.30, %conv68.21.30
  %conv73.21.30 = trunc i32 %xor72.21.30 to i8
  store i8 %conv73.21.30, i8* %arrayidx70.30, align 1
  %scevgep20.22.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 22
  %8276 = load i8, i8* %scevgep20.22.30, align 1
  %conv68.22.30 = zext i8 %8276 to i32
  %8277 = load i8, i8* %arrayidx70.30, align 1
  %conv71.22.30 = zext i8 %8277 to i32
  %xor72.22.30 = xor i32 %conv71.22.30, %conv68.22.30
  %conv73.22.30 = trunc i32 %xor72.22.30 to i8
  store i8 %conv73.22.30, i8* %arrayidx70.30, align 1
  %scevgep20.23.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 23
  %8278 = load i8, i8* %scevgep20.23.30, align 1
  %conv68.23.30 = zext i8 %8278 to i32
  %8279 = load i8, i8* %arrayidx70.30, align 1
  %conv71.23.30 = zext i8 %8279 to i32
  %xor72.23.30 = xor i32 %conv71.23.30, %conv68.23.30
  %conv73.23.30 = trunc i32 %xor72.23.30 to i8
  store i8 %conv73.23.30, i8* %arrayidx70.30, align 1
  %scevgep20.24.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 24
  %8280 = load i8, i8* %scevgep20.24.30, align 1
  %conv68.24.30 = zext i8 %8280 to i32
  %8281 = load i8, i8* %arrayidx70.30, align 1
  %conv71.24.30 = zext i8 %8281 to i32
  %xor72.24.30 = xor i32 %conv71.24.30, %conv68.24.30
  %conv73.24.30 = trunc i32 %xor72.24.30 to i8
  store i8 %conv73.24.30, i8* %arrayidx70.30, align 1
  %scevgep20.25.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 25
  %8282 = load i8, i8* %scevgep20.25.30, align 1
  %conv68.25.30 = zext i8 %8282 to i32
  %8283 = load i8, i8* %arrayidx70.30, align 1
  %conv71.25.30 = zext i8 %8283 to i32
  %xor72.25.30 = xor i32 %conv71.25.30, %conv68.25.30
  %conv73.25.30 = trunc i32 %xor72.25.30 to i8
  store i8 %conv73.25.30, i8* %arrayidx70.30, align 1
  %scevgep20.26.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 26
  %8284 = load i8, i8* %scevgep20.26.30, align 1
  %conv68.26.30 = zext i8 %8284 to i32
  %8285 = load i8, i8* %arrayidx70.30, align 1
  %conv71.26.30 = zext i8 %8285 to i32
  %xor72.26.30 = xor i32 %conv71.26.30, %conv68.26.30
  %conv73.26.30 = trunc i32 %xor72.26.30 to i8
  store i8 %conv73.26.30, i8* %arrayidx70.30, align 1
  %scevgep20.27.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 27
  %8286 = load i8, i8* %scevgep20.27.30, align 1
  %conv68.27.30 = zext i8 %8286 to i32
  %8287 = load i8, i8* %arrayidx70.30, align 1
  %conv71.27.30 = zext i8 %8287 to i32
  %xor72.27.30 = xor i32 %conv71.27.30, %conv68.27.30
  %conv73.27.30 = trunc i32 %xor72.27.30 to i8
  store i8 %conv73.27.30, i8* %arrayidx70.30, align 1
  %scevgep20.28.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 28
  %8288 = load i8, i8* %scevgep20.28.30, align 1
  %conv68.28.30 = zext i8 %8288 to i32
  %8289 = load i8, i8* %arrayidx70.30, align 1
  %conv71.28.30 = zext i8 %8289 to i32
  %xor72.28.30 = xor i32 %conv71.28.30, %conv68.28.30
  %conv73.28.30 = trunc i32 %xor72.28.30 to i8
  store i8 %conv73.28.30, i8* %arrayidx70.30, align 1
  %scevgep20.29.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 29
  %8290 = load i8, i8* %scevgep20.29.30, align 1
  %conv68.29.30 = zext i8 %8290 to i32
  %8291 = load i8, i8* %arrayidx70.30, align 1
  %conv71.29.30 = zext i8 %8291 to i32
  %xor72.29.30 = xor i32 %conv71.29.30, %conv68.29.30
  %conv73.29.30 = trunc i32 %xor72.29.30 to i8
  store i8 %conv73.29.30, i8* %arrayidx70.30, align 1
  %scevgep20.31.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 31
  %8292 = load i8, i8* %scevgep20.31.30, align 1
  %conv68.31.30 = zext i8 %8292 to i32
  %8293 = load i8, i8* %arrayidx70.30, align 1
  %conv71.31.30 = zext i8 %8293 to i32
  %xor72.31.30 = xor i32 %conv71.31.30, %conv68.31.30
  %conv73.31.30 = trunc i32 %xor72.31.30 to i8
  store i8 %conv73.31.30, i8* %arrayidx70.30, align 1
  %scevgep20.32.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 32
  %8294 = load i8, i8* %scevgep20.32.30, align 1
  %conv68.32.30 = zext i8 %8294 to i32
  %8295 = load i8, i8* %arrayidx70.30, align 1
  %conv71.32.30 = zext i8 %8295 to i32
  %xor72.32.30 = xor i32 %conv71.32.30, %conv68.32.30
  %conv73.32.30 = trunc i32 %xor72.32.30 to i8
  store i8 %conv73.32.30, i8* %arrayidx70.30, align 1
  %scevgep20.33.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 33
  %8296 = load i8, i8* %scevgep20.33.30, align 1
  %conv68.33.30 = zext i8 %8296 to i32
  %8297 = load i8, i8* %arrayidx70.30, align 1
  %conv71.33.30 = zext i8 %8297 to i32
  %xor72.33.30 = xor i32 %conv71.33.30, %conv68.33.30
  %conv73.33.30 = trunc i32 %xor72.33.30 to i8
  store i8 %conv73.33.30, i8* %arrayidx70.30, align 1
  %scevgep20.34.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 34
  %8298 = load i8, i8* %scevgep20.34.30, align 1
  %conv68.34.30 = zext i8 %8298 to i32
  %8299 = load i8, i8* %arrayidx70.30, align 1
  %conv71.34.30 = zext i8 %8299 to i32
  %xor72.34.30 = xor i32 %conv71.34.30, %conv68.34.30
  %conv73.34.30 = trunc i32 %xor72.34.30 to i8
  store i8 %conv73.34.30, i8* %arrayidx70.30, align 1
  %scevgep20.35.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 35
  %8300 = load i8, i8* %scevgep20.35.30, align 1
  %conv68.35.30 = zext i8 %8300 to i32
  %8301 = load i8, i8* %arrayidx70.30, align 1
  %conv71.35.30 = zext i8 %8301 to i32
  %xor72.35.30 = xor i32 %conv71.35.30, %conv68.35.30
  %conv73.35.30 = trunc i32 %xor72.35.30 to i8
  store i8 %conv73.35.30, i8* %arrayidx70.30, align 1
  %scevgep20.36.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 36
  %8302 = load i8, i8* %scevgep20.36.30, align 1
  %conv68.36.30 = zext i8 %8302 to i32
  %8303 = load i8, i8* %arrayidx70.30, align 1
  %conv71.36.30 = zext i8 %8303 to i32
  %xor72.36.30 = xor i32 %conv71.36.30, %conv68.36.30
  %conv73.36.30 = trunc i32 %xor72.36.30 to i8
  store i8 %conv73.36.30, i8* %arrayidx70.30, align 1
  %scevgep20.37.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 37
  %8304 = load i8, i8* %scevgep20.37.30, align 1
  %conv68.37.30 = zext i8 %8304 to i32
  %8305 = load i8, i8* %arrayidx70.30, align 1
  %conv71.37.30 = zext i8 %8305 to i32
  %xor72.37.30 = xor i32 %conv71.37.30, %conv68.37.30
  %conv73.37.30 = trunc i32 %xor72.37.30 to i8
  store i8 %conv73.37.30, i8* %arrayidx70.30, align 1
  %scevgep20.38.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 38
  %8306 = load i8, i8* %scevgep20.38.30, align 1
  %conv68.38.30 = zext i8 %8306 to i32
  %8307 = load i8, i8* %arrayidx70.30, align 1
  %conv71.38.30 = zext i8 %8307 to i32
  %xor72.38.30 = xor i32 %conv71.38.30, %conv68.38.30
  %conv73.38.30 = trunc i32 %xor72.38.30 to i8
  store i8 %conv73.38.30, i8* %arrayidx70.30, align 1
  %scevgep20.39.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 39
  %8308 = load i8, i8* %scevgep20.39.30, align 1
  %conv68.39.30 = zext i8 %8308 to i32
  %8309 = load i8, i8* %arrayidx70.30, align 1
  %conv71.39.30 = zext i8 %8309 to i32
  %xor72.39.30 = xor i32 %conv71.39.30, %conv68.39.30
  %conv73.39.30 = trunc i32 %xor72.39.30 to i8
  store i8 %conv73.39.30, i8* %arrayidx70.30, align 1
  %scevgep20.40.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 0, i64 40
  %8310 = load i8, i8* %scevgep20.40.30, align 1
  %conv68.40.30 = zext i8 %8310 to i32
  %8311 = load i8, i8* %arrayidx70.30, align 1
  %conv71.40.30 = zext i8 %8311 to i32
  %xor72.40.30 = xor i32 %conv71.40.30, %conv68.40.30
  %conv73.40.30 = trunc i32 %xor72.40.30 to i8
  store i8 %conv73.40.30, i8* %arrayidx70.30, align 1
  %scevgep19.30 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8229, i64 0, i64 1, i64 0
  %8312 = bitcast i8* %scevgep19.30 to [41 x [41 x i8]]*
  %arrayidx51.31 = getelementptr inbounds i8, i8* %a, i64 31
  %8313 = load i8, i8* %arrayidx51.31, align 1
  %arrayidx53.31 = getelementptr inbounds i8, i8* %b, i64 31
  %8314 = load i8, i8* %arrayidx53.31, align 1
  %call54.31 = call zeroext i8 @mult(i8 zeroext %8313, i8 zeroext %8314)
  %arrayidx56.31 = getelementptr inbounds i8, i8* %c, i64 31
  store i8 %call54.31, i8* %arrayidx56.31, align 1
  %arrayidx70.31 = getelementptr inbounds i8, i8* %c, i64 31
  %scevgep20.31354 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 0
  %8315 = load i8, i8* %scevgep20.31354, align 1
  %conv68.31355 = zext i8 %8315 to i32
  %8316 = load i8, i8* %arrayidx70.31, align 1
  %conv71.31356 = zext i8 %8316 to i32
  %xor72.31357 = xor i32 %conv71.31356, %conv68.31355
  %conv73.31358 = trunc i32 %xor72.31357 to i8
  store i8 %conv73.31358, i8* %arrayidx70.31, align 1
  %scevgep20.1.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 1
  %8317 = load i8, i8* %scevgep20.1.31, align 1
  %conv68.1.31 = zext i8 %8317 to i32
  %8318 = load i8, i8* %arrayidx70.31, align 1
  %conv71.1.31 = zext i8 %8318 to i32
  %xor72.1.31 = xor i32 %conv71.1.31, %conv68.1.31
  %conv73.1.31 = trunc i32 %xor72.1.31 to i8
  store i8 %conv73.1.31, i8* %arrayidx70.31, align 1
  %scevgep20.2.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 2
  %8319 = load i8, i8* %scevgep20.2.31, align 1
  %conv68.2.31 = zext i8 %8319 to i32
  %8320 = load i8, i8* %arrayidx70.31, align 1
  %conv71.2.31 = zext i8 %8320 to i32
  %xor72.2.31 = xor i32 %conv71.2.31, %conv68.2.31
  %conv73.2.31 = trunc i32 %xor72.2.31 to i8
  store i8 %conv73.2.31, i8* %arrayidx70.31, align 1
  %scevgep20.3.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 3
  %8321 = load i8, i8* %scevgep20.3.31, align 1
  %conv68.3.31 = zext i8 %8321 to i32
  %8322 = load i8, i8* %arrayidx70.31, align 1
  %conv71.3.31 = zext i8 %8322 to i32
  %xor72.3.31 = xor i32 %conv71.3.31, %conv68.3.31
  %conv73.3.31 = trunc i32 %xor72.3.31 to i8
  store i8 %conv73.3.31, i8* %arrayidx70.31, align 1
  %scevgep20.4.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 4
  %8323 = load i8, i8* %scevgep20.4.31, align 1
  %conv68.4.31 = zext i8 %8323 to i32
  %8324 = load i8, i8* %arrayidx70.31, align 1
  %conv71.4.31 = zext i8 %8324 to i32
  %xor72.4.31 = xor i32 %conv71.4.31, %conv68.4.31
  %conv73.4.31 = trunc i32 %xor72.4.31 to i8
  store i8 %conv73.4.31, i8* %arrayidx70.31, align 1
  %scevgep20.5.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 5
  %8325 = load i8, i8* %scevgep20.5.31, align 1
  %conv68.5.31 = zext i8 %8325 to i32
  %8326 = load i8, i8* %arrayidx70.31, align 1
  %conv71.5.31 = zext i8 %8326 to i32
  %xor72.5.31 = xor i32 %conv71.5.31, %conv68.5.31
  %conv73.5.31 = trunc i32 %xor72.5.31 to i8
  store i8 %conv73.5.31, i8* %arrayidx70.31, align 1
  %scevgep20.6.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 6
  %8327 = load i8, i8* %scevgep20.6.31, align 1
  %conv68.6.31 = zext i8 %8327 to i32
  %8328 = load i8, i8* %arrayidx70.31, align 1
  %conv71.6.31 = zext i8 %8328 to i32
  %xor72.6.31 = xor i32 %conv71.6.31, %conv68.6.31
  %conv73.6.31 = trunc i32 %xor72.6.31 to i8
  store i8 %conv73.6.31, i8* %arrayidx70.31, align 1
  %scevgep20.7.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 7
  %8329 = load i8, i8* %scevgep20.7.31, align 1
  %conv68.7.31 = zext i8 %8329 to i32
  %8330 = load i8, i8* %arrayidx70.31, align 1
  %conv71.7.31 = zext i8 %8330 to i32
  %xor72.7.31 = xor i32 %conv71.7.31, %conv68.7.31
  %conv73.7.31 = trunc i32 %xor72.7.31 to i8
  store i8 %conv73.7.31, i8* %arrayidx70.31, align 1
  %scevgep20.8.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 8
  %8331 = load i8, i8* %scevgep20.8.31, align 1
  %conv68.8.31 = zext i8 %8331 to i32
  %8332 = load i8, i8* %arrayidx70.31, align 1
  %conv71.8.31 = zext i8 %8332 to i32
  %xor72.8.31 = xor i32 %conv71.8.31, %conv68.8.31
  %conv73.8.31 = trunc i32 %xor72.8.31 to i8
  store i8 %conv73.8.31, i8* %arrayidx70.31, align 1
  %scevgep20.9.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 9
  %8333 = load i8, i8* %scevgep20.9.31, align 1
  %conv68.9.31 = zext i8 %8333 to i32
  %8334 = load i8, i8* %arrayidx70.31, align 1
  %conv71.9.31 = zext i8 %8334 to i32
  %xor72.9.31 = xor i32 %conv71.9.31, %conv68.9.31
  %conv73.9.31 = trunc i32 %xor72.9.31 to i8
  store i8 %conv73.9.31, i8* %arrayidx70.31, align 1
  %scevgep20.10.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 10
  %8335 = load i8, i8* %scevgep20.10.31, align 1
  %conv68.10.31 = zext i8 %8335 to i32
  %8336 = load i8, i8* %arrayidx70.31, align 1
  %conv71.10.31 = zext i8 %8336 to i32
  %xor72.10.31 = xor i32 %conv71.10.31, %conv68.10.31
  %conv73.10.31 = trunc i32 %xor72.10.31 to i8
  store i8 %conv73.10.31, i8* %arrayidx70.31, align 1
  %scevgep20.11.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 11
  %8337 = load i8, i8* %scevgep20.11.31, align 1
  %conv68.11.31 = zext i8 %8337 to i32
  %8338 = load i8, i8* %arrayidx70.31, align 1
  %conv71.11.31 = zext i8 %8338 to i32
  %xor72.11.31 = xor i32 %conv71.11.31, %conv68.11.31
  %conv73.11.31 = trunc i32 %xor72.11.31 to i8
  store i8 %conv73.11.31, i8* %arrayidx70.31, align 1
  %scevgep20.12.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 12
  %8339 = load i8, i8* %scevgep20.12.31, align 1
  %conv68.12.31 = zext i8 %8339 to i32
  %8340 = load i8, i8* %arrayidx70.31, align 1
  %conv71.12.31 = zext i8 %8340 to i32
  %xor72.12.31 = xor i32 %conv71.12.31, %conv68.12.31
  %conv73.12.31 = trunc i32 %xor72.12.31 to i8
  store i8 %conv73.12.31, i8* %arrayidx70.31, align 1
  %scevgep20.13.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 13
  %8341 = load i8, i8* %scevgep20.13.31, align 1
  %conv68.13.31 = zext i8 %8341 to i32
  %8342 = load i8, i8* %arrayidx70.31, align 1
  %conv71.13.31 = zext i8 %8342 to i32
  %xor72.13.31 = xor i32 %conv71.13.31, %conv68.13.31
  %conv73.13.31 = trunc i32 %xor72.13.31 to i8
  store i8 %conv73.13.31, i8* %arrayidx70.31, align 1
  %scevgep20.14.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 14
  %8343 = load i8, i8* %scevgep20.14.31, align 1
  %conv68.14.31 = zext i8 %8343 to i32
  %8344 = load i8, i8* %arrayidx70.31, align 1
  %conv71.14.31 = zext i8 %8344 to i32
  %xor72.14.31 = xor i32 %conv71.14.31, %conv68.14.31
  %conv73.14.31 = trunc i32 %xor72.14.31 to i8
  store i8 %conv73.14.31, i8* %arrayidx70.31, align 1
  %scevgep20.15.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 15
  %8345 = load i8, i8* %scevgep20.15.31, align 1
  %conv68.15.31 = zext i8 %8345 to i32
  %8346 = load i8, i8* %arrayidx70.31, align 1
  %conv71.15.31 = zext i8 %8346 to i32
  %xor72.15.31 = xor i32 %conv71.15.31, %conv68.15.31
  %conv73.15.31 = trunc i32 %xor72.15.31 to i8
  store i8 %conv73.15.31, i8* %arrayidx70.31, align 1
  %scevgep20.16.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 16
  %8347 = load i8, i8* %scevgep20.16.31, align 1
  %conv68.16.31 = zext i8 %8347 to i32
  %8348 = load i8, i8* %arrayidx70.31, align 1
  %conv71.16.31 = zext i8 %8348 to i32
  %xor72.16.31 = xor i32 %conv71.16.31, %conv68.16.31
  %conv73.16.31 = trunc i32 %xor72.16.31 to i8
  store i8 %conv73.16.31, i8* %arrayidx70.31, align 1
  %scevgep20.17.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 17
  %8349 = load i8, i8* %scevgep20.17.31, align 1
  %conv68.17.31 = zext i8 %8349 to i32
  %8350 = load i8, i8* %arrayidx70.31, align 1
  %conv71.17.31 = zext i8 %8350 to i32
  %xor72.17.31 = xor i32 %conv71.17.31, %conv68.17.31
  %conv73.17.31 = trunc i32 %xor72.17.31 to i8
  store i8 %conv73.17.31, i8* %arrayidx70.31, align 1
  %scevgep20.18.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 18
  %8351 = load i8, i8* %scevgep20.18.31, align 1
  %conv68.18.31 = zext i8 %8351 to i32
  %8352 = load i8, i8* %arrayidx70.31, align 1
  %conv71.18.31 = zext i8 %8352 to i32
  %xor72.18.31 = xor i32 %conv71.18.31, %conv68.18.31
  %conv73.18.31 = trunc i32 %xor72.18.31 to i8
  store i8 %conv73.18.31, i8* %arrayidx70.31, align 1
  %scevgep20.19.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 19
  %8353 = load i8, i8* %scevgep20.19.31, align 1
  %conv68.19.31 = zext i8 %8353 to i32
  %8354 = load i8, i8* %arrayidx70.31, align 1
  %conv71.19.31 = zext i8 %8354 to i32
  %xor72.19.31 = xor i32 %conv71.19.31, %conv68.19.31
  %conv73.19.31 = trunc i32 %xor72.19.31 to i8
  store i8 %conv73.19.31, i8* %arrayidx70.31, align 1
  %scevgep20.20.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 20
  %8355 = load i8, i8* %scevgep20.20.31, align 1
  %conv68.20.31 = zext i8 %8355 to i32
  %8356 = load i8, i8* %arrayidx70.31, align 1
  %conv71.20.31 = zext i8 %8356 to i32
  %xor72.20.31 = xor i32 %conv71.20.31, %conv68.20.31
  %conv73.20.31 = trunc i32 %xor72.20.31 to i8
  store i8 %conv73.20.31, i8* %arrayidx70.31, align 1
  %scevgep20.21.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 21
  %8357 = load i8, i8* %scevgep20.21.31, align 1
  %conv68.21.31 = zext i8 %8357 to i32
  %8358 = load i8, i8* %arrayidx70.31, align 1
  %conv71.21.31 = zext i8 %8358 to i32
  %xor72.21.31 = xor i32 %conv71.21.31, %conv68.21.31
  %conv73.21.31 = trunc i32 %xor72.21.31 to i8
  store i8 %conv73.21.31, i8* %arrayidx70.31, align 1
  %scevgep20.22.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 22
  %8359 = load i8, i8* %scevgep20.22.31, align 1
  %conv68.22.31 = zext i8 %8359 to i32
  %8360 = load i8, i8* %arrayidx70.31, align 1
  %conv71.22.31 = zext i8 %8360 to i32
  %xor72.22.31 = xor i32 %conv71.22.31, %conv68.22.31
  %conv73.22.31 = trunc i32 %xor72.22.31 to i8
  store i8 %conv73.22.31, i8* %arrayidx70.31, align 1
  %scevgep20.23.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 23
  %8361 = load i8, i8* %scevgep20.23.31, align 1
  %conv68.23.31 = zext i8 %8361 to i32
  %8362 = load i8, i8* %arrayidx70.31, align 1
  %conv71.23.31 = zext i8 %8362 to i32
  %xor72.23.31 = xor i32 %conv71.23.31, %conv68.23.31
  %conv73.23.31 = trunc i32 %xor72.23.31 to i8
  store i8 %conv73.23.31, i8* %arrayidx70.31, align 1
  %scevgep20.24.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 24
  %8363 = load i8, i8* %scevgep20.24.31, align 1
  %conv68.24.31 = zext i8 %8363 to i32
  %8364 = load i8, i8* %arrayidx70.31, align 1
  %conv71.24.31 = zext i8 %8364 to i32
  %xor72.24.31 = xor i32 %conv71.24.31, %conv68.24.31
  %conv73.24.31 = trunc i32 %xor72.24.31 to i8
  store i8 %conv73.24.31, i8* %arrayidx70.31, align 1
  %scevgep20.25.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 25
  %8365 = load i8, i8* %scevgep20.25.31, align 1
  %conv68.25.31 = zext i8 %8365 to i32
  %8366 = load i8, i8* %arrayidx70.31, align 1
  %conv71.25.31 = zext i8 %8366 to i32
  %xor72.25.31 = xor i32 %conv71.25.31, %conv68.25.31
  %conv73.25.31 = trunc i32 %xor72.25.31 to i8
  store i8 %conv73.25.31, i8* %arrayidx70.31, align 1
  %scevgep20.26.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 26
  %8367 = load i8, i8* %scevgep20.26.31, align 1
  %conv68.26.31 = zext i8 %8367 to i32
  %8368 = load i8, i8* %arrayidx70.31, align 1
  %conv71.26.31 = zext i8 %8368 to i32
  %xor72.26.31 = xor i32 %conv71.26.31, %conv68.26.31
  %conv73.26.31 = trunc i32 %xor72.26.31 to i8
  store i8 %conv73.26.31, i8* %arrayidx70.31, align 1
  %scevgep20.27.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 27
  %8369 = load i8, i8* %scevgep20.27.31, align 1
  %conv68.27.31 = zext i8 %8369 to i32
  %8370 = load i8, i8* %arrayidx70.31, align 1
  %conv71.27.31 = zext i8 %8370 to i32
  %xor72.27.31 = xor i32 %conv71.27.31, %conv68.27.31
  %conv73.27.31 = trunc i32 %xor72.27.31 to i8
  store i8 %conv73.27.31, i8* %arrayidx70.31, align 1
  %scevgep20.28.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 28
  %8371 = load i8, i8* %scevgep20.28.31, align 1
  %conv68.28.31 = zext i8 %8371 to i32
  %8372 = load i8, i8* %arrayidx70.31, align 1
  %conv71.28.31 = zext i8 %8372 to i32
  %xor72.28.31 = xor i32 %conv71.28.31, %conv68.28.31
  %conv73.28.31 = trunc i32 %xor72.28.31 to i8
  store i8 %conv73.28.31, i8* %arrayidx70.31, align 1
  %scevgep20.29.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 29
  %8373 = load i8, i8* %scevgep20.29.31, align 1
  %conv68.29.31 = zext i8 %8373 to i32
  %8374 = load i8, i8* %arrayidx70.31, align 1
  %conv71.29.31 = zext i8 %8374 to i32
  %xor72.29.31 = xor i32 %conv71.29.31, %conv68.29.31
  %conv73.29.31 = trunc i32 %xor72.29.31 to i8
  store i8 %conv73.29.31, i8* %arrayidx70.31, align 1
  %scevgep20.30.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 30
  %8375 = load i8, i8* %scevgep20.30.31, align 1
  %conv68.30.31 = zext i8 %8375 to i32
  %8376 = load i8, i8* %arrayidx70.31, align 1
  %conv71.30.31 = zext i8 %8376 to i32
  %xor72.30.31 = xor i32 %conv71.30.31, %conv68.30.31
  %conv73.30.31 = trunc i32 %xor72.30.31 to i8
  store i8 %conv73.30.31, i8* %arrayidx70.31, align 1
  %scevgep20.32.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 32
  %8377 = load i8, i8* %scevgep20.32.31, align 1
  %conv68.32.31 = zext i8 %8377 to i32
  %8378 = load i8, i8* %arrayidx70.31, align 1
  %conv71.32.31 = zext i8 %8378 to i32
  %xor72.32.31 = xor i32 %conv71.32.31, %conv68.32.31
  %conv73.32.31 = trunc i32 %xor72.32.31 to i8
  store i8 %conv73.32.31, i8* %arrayidx70.31, align 1
  %scevgep20.33.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 33
  %8379 = load i8, i8* %scevgep20.33.31, align 1
  %conv68.33.31 = zext i8 %8379 to i32
  %8380 = load i8, i8* %arrayidx70.31, align 1
  %conv71.33.31 = zext i8 %8380 to i32
  %xor72.33.31 = xor i32 %conv71.33.31, %conv68.33.31
  %conv73.33.31 = trunc i32 %xor72.33.31 to i8
  store i8 %conv73.33.31, i8* %arrayidx70.31, align 1
  %scevgep20.34.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 34
  %8381 = load i8, i8* %scevgep20.34.31, align 1
  %conv68.34.31 = zext i8 %8381 to i32
  %8382 = load i8, i8* %arrayidx70.31, align 1
  %conv71.34.31 = zext i8 %8382 to i32
  %xor72.34.31 = xor i32 %conv71.34.31, %conv68.34.31
  %conv73.34.31 = trunc i32 %xor72.34.31 to i8
  store i8 %conv73.34.31, i8* %arrayidx70.31, align 1
  %scevgep20.35.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 35
  %8383 = load i8, i8* %scevgep20.35.31, align 1
  %conv68.35.31 = zext i8 %8383 to i32
  %8384 = load i8, i8* %arrayidx70.31, align 1
  %conv71.35.31 = zext i8 %8384 to i32
  %xor72.35.31 = xor i32 %conv71.35.31, %conv68.35.31
  %conv73.35.31 = trunc i32 %xor72.35.31 to i8
  store i8 %conv73.35.31, i8* %arrayidx70.31, align 1
  %scevgep20.36.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 36
  %8385 = load i8, i8* %scevgep20.36.31, align 1
  %conv68.36.31 = zext i8 %8385 to i32
  %8386 = load i8, i8* %arrayidx70.31, align 1
  %conv71.36.31 = zext i8 %8386 to i32
  %xor72.36.31 = xor i32 %conv71.36.31, %conv68.36.31
  %conv73.36.31 = trunc i32 %xor72.36.31 to i8
  store i8 %conv73.36.31, i8* %arrayidx70.31, align 1
  %scevgep20.37.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 37
  %8387 = load i8, i8* %scevgep20.37.31, align 1
  %conv68.37.31 = zext i8 %8387 to i32
  %8388 = load i8, i8* %arrayidx70.31, align 1
  %conv71.37.31 = zext i8 %8388 to i32
  %xor72.37.31 = xor i32 %conv71.37.31, %conv68.37.31
  %conv73.37.31 = trunc i32 %xor72.37.31 to i8
  store i8 %conv73.37.31, i8* %arrayidx70.31, align 1
  %scevgep20.38.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 38
  %8389 = load i8, i8* %scevgep20.38.31, align 1
  %conv68.38.31 = zext i8 %8389 to i32
  %8390 = load i8, i8* %arrayidx70.31, align 1
  %conv71.38.31 = zext i8 %8390 to i32
  %xor72.38.31 = xor i32 %conv71.38.31, %conv68.38.31
  %conv73.38.31 = trunc i32 %xor72.38.31 to i8
  store i8 %conv73.38.31, i8* %arrayidx70.31, align 1
  %scevgep20.39.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 39
  %8391 = load i8, i8* %scevgep20.39.31, align 1
  %conv68.39.31 = zext i8 %8391 to i32
  %8392 = load i8, i8* %arrayidx70.31, align 1
  %conv71.39.31 = zext i8 %8392 to i32
  %xor72.39.31 = xor i32 %conv71.39.31, %conv68.39.31
  %conv73.39.31 = trunc i32 %xor72.39.31 to i8
  store i8 %conv73.39.31, i8* %arrayidx70.31, align 1
  %scevgep20.40.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 0, i64 40
  %8393 = load i8, i8* %scevgep20.40.31, align 1
  %conv68.40.31 = zext i8 %8393 to i32
  %8394 = load i8, i8* %arrayidx70.31, align 1
  %conv71.40.31 = zext i8 %8394 to i32
  %xor72.40.31 = xor i32 %conv71.40.31, %conv68.40.31
  %conv73.40.31 = trunc i32 %xor72.40.31 to i8
  store i8 %conv73.40.31, i8* %arrayidx70.31, align 1
  %scevgep19.31 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8312, i64 0, i64 1, i64 0
  %8395 = bitcast i8* %scevgep19.31 to [41 x [41 x i8]]*
  %arrayidx51.32 = getelementptr inbounds i8, i8* %a, i64 32
  %8396 = load i8, i8* %arrayidx51.32, align 1
  %arrayidx53.32 = getelementptr inbounds i8, i8* %b, i64 32
  %8397 = load i8, i8* %arrayidx53.32, align 1
  %call54.32 = call zeroext i8 @mult(i8 zeroext %8396, i8 zeroext %8397)
  %arrayidx56.32 = getelementptr inbounds i8, i8* %c, i64 32
  store i8 %call54.32, i8* %arrayidx56.32, align 1
  %arrayidx70.32 = getelementptr inbounds i8, i8* %c, i64 32
  %scevgep20.32364 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 0
  %8398 = load i8, i8* %scevgep20.32364, align 1
  %conv68.32365 = zext i8 %8398 to i32
  %8399 = load i8, i8* %arrayidx70.32, align 1
  %conv71.32366 = zext i8 %8399 to i32
  %xor72.32367 = xor i32 %conv71.32366, %conv68.32365
  %conv73.32368 = trunc i32 %xor72.32367 to i8
  store i8 %conv73.32368, i8* %arrayidx70.32, align 1
  %scevgep20.1.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 1
  %8400 = load i8, i8* %scevgep20.1.32, align 1
  %conv68.1.32 = zext i8 %8400 to i32
  %8401 = load i8, i8* %arrayidx70.32, align 1
  %conv71.1.32 = zext i8 %8401 to i32
  %xor72.1.32 = xor i32 %conv71.1.32, %conv68.1.32
  %conv73.1.32 = trunc i32 %xor72.1.32 to i8
  store i8 %conv73.1.32, i8* %arrayidx70.32, align 1
  %scevgep20.2.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 2
  %8402 = load i8, i8* %scevgep20.2.32, align 1
  %conv68.2.32 = zext i8 %8402 to i32
  %8403 = load i8, i8* %arrayidx70.32, align 1
  %conv71.2.32 = zext i8 %8403 to i32
  %xor72.2.32 = xor i32 %conv71.2.32, %conv68.2.32
  %conv73.2.32 = trunc i32 %xor72.2.32 to i8
  store i8 %conv73.2.32, i8* %arrayidx70.32, align 1
  %scevgep20.3.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 3
  %8404 = load i8, i8* %scevgep20.3.32, align 1
  %conv68.3.32 = zext i8 %8404 to i32
  %8405 = load i8, i8* %arrayidx70.32, align 1
  %conv71.3.32 = zext i8 %8405 to i32
  %xor72.3.32 = xor i32 %conv71.3.32, %conv68.3.32
  %conv73.3.32 = trunc i32 %xor72.3.32 to i8
  store i8 %conv73.3.32, i8* %arrayidx70.32, align 1
  %scevgep20.4.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 4
  %8406 = load i8, i8* %scevgep20.4.32, align 1
  %conv68.4.32 = zext i8 %8406 to i32
  %8407 = load i8, i8* %arrayidx70.32, align 1
  %conv71.4.32 = zext i8 %8407 to i32
  %xor72.4.32 = xor i32 %conv71.4.32, %conv68.4.32
  %conv73.4.32 = trunc i32 %xor72.4.32 to i8
  store i8 %conv73.4.32, i8* %arrayidx70.32, align 1
  %scevgep20.5.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 5
  %8408 = load i8, i8* %scevgep20.5.32, align 1
  %conv68.5.32 = zext i8 %8408 to i32
  %8409 = load i8, i8* %arrayidx70.32, align 1
  %conv71.5.32 = zext i8 %8409 to i32
  %xor72.5.32 = xor i32 %conv71.5.32, %conv68.5.32
  %conv73.5.32 = trunc i32 %xor72.5.32 to i8
  store i8 %conv73.5.32, i8* %arrayidx70.32, align 1
  %scevgep20.6.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 6
  %8410 = load i8, i8* %scevgep20.6.32, align 1
  %conv68.6.32 = zext i8 %8410 to i32
  %8411 = load i8, i8* %arrayidx70.32, align 1
  %conv71.6.32 = zext i8 %8411 to i32
  %xor72.6.32 = xor i32 %conv71.6.32, %conv68.6.32
  %conv73.6.32 = trunc i32 %xor72.6.32 to i8
  store i8 %conv73.6.32, i8* %arrayidx70.32, align 1
  %scevgep20.7.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 7
  %8412 = load i8, i8* %scevgep20.7.32, align 1
  %conv68.7.32 = zext i8 %8412 to i32
  %8413 = load i8, i8* %arrayidx70.32, align 1
  %conv71.7.32 = zext i8 %8413 to i32
  %xor72.7.32 = xor i32 %conv71.7.32, %conv68.7.32
  %conv73.7.32 = trunc i32 %xor72.7.32 to i8
  store i8 %conv73.7.32, i8* %arrayidx70.32, align 1
  %scevgep20.8.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 8
  %8414 = load i8, i8* %scevgep20.8.32, align 1
  %conv68.8.32 = zext i8 %8414 to i32
  %8415 = load i8, i8* %arrayidx70.32, align 1
  %conv71.8.32 = zext i8 %8415 to i32
  %xor72.8.32 = xor i32 %conv71.8.32, %conv68.8.32
  %conv73.8.32 = trunc i32 %xor72.8.32 to i8
  store i8 %conv73.8.32, i8* %arrayidx70.32, align 1
  %scevgep20.9.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 9
  %8416 = load i8, i8* %scevgep20.9.32, align 1
  %conv68.9.32 = zext i8 %8416 to i32
  %8417 = load i8, i8* %arrayidx70.32, align 1
  %conv71.9.32 = zext i8 %8417 to i32
  %xor72.9.32 = xor i32 %conv71.9.32, %conv68.9.32
  %conv73.9.32 = trunc i32 %xor72.9.32 to i8
  store i8 %conv73.9.32, i8* %arrayidx70.32, align 1
  %scevgep20.10.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 10
  %8418 = load i8, i8* %scevgep20.10.32, align 1
  %conv68.10.32 = zext i8 %8418 to i32
  %8419 = load i8, i8* %arrayidx70.32, align 1
  %conv71.10.32 = zext i8 %8419 to i32
  %xor72.10.32 = xor i32 %conv71.10.32, %conv68.10.32
  %conv73.10.32 = trunc i32 %xor72.10.32 to i8
  store i8 %conv73.10.32, i8* %arrayidx70.32, align 1
  %scevgep20.11.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 11
  %8420 = load i8, i8* %scevgep20.11.32, align 1
  %conv68.11.32 = zext i8 %8420 to i32
  %8421 = load i8, i8* %arrayidx70.32, align 1
  %conv71.11.32 = zext i8 %8421 to i32
  %xor72.11.32 = xor i32 %conv71.11.32, %conv68.11.32
  %conv73.11.32 = trunc i32 %xor72.11.32 to i8
  store i8 %conv73.11.32, i8* %arrayidx70.32, align 1
  %scevgep20.12.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 12
  %8422 = load i8, i8* %scevgep20.12.32, align 1
  %conv68.12.32 = zext i8 %8422 to i32
  %8423 = load i8, i8* %arrayidx70.32, align 1
  %conv71.12.32 = zext i8 %8423 to i32
  %xor72.12.32 = xor i32 %conv71.12.32, %conv68.12.32
  %conv73.12.32 = trunc i32 %xor72.12.32 to i8
  store i8 %conv73.12.32, i8* %arrayidx70.32, align 1
  %scevgep20.13.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 13
  %8424 = load i8, i8* %scevgep20.13.32, align 1
  %conv68.13.32 = zext i8 %8424 to i32
  %8425 = load i8, i8* %arrayidx70.32, align 1
  %conv71.13.32 = zext i8 %8425 to i32
  %xor72.13.32 = xor i32 %conv71.13.32, %conv68.13.32
  %conv73.13.32 = trunc i32 %xor72.13.32 to i8
  store i8 %conv73.13.32, i8* %arrayidx70.32, align 1
  %scevgep20.14.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 14
  %8426 = load i8, i8* %scevgep20.14.32, align 1
  %conv68.14.32 = zext i8 %8426 to i32
  %8427 = load i8, i8* %arrayidx70.32, align 1
  %conv71.14.32 = zext i8 %8427 to i32
  %xor72.14.32 = xor i32 %conv71.14.32, %conv68.14.32
  %conv73.14.32 = trunc i32 %xor72.14.32 to i8
  store i8 %conv73.14.32, i8* %arrayidx70.32, align 1
  %scevgep20.15.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 15
  %8428 = load i8, i8* %scevgep20.15.32, align 1
  %conv68.15.32 = zext i8 %8428 to i32
  %8429 = load i8, i8* %arrayidx70.32, align 1
  %conv71.15.32 = zext i8 %8429 to i32
  %xor72.15.32 = xor i32 %conv71.15.32, %conv68.15.32
  %conv73.15.32 = trunc i32 %xor72.15.32 to i8
  store i8 %conv73.15.32, i8* %arrayidx70.32, align 1
  %scevgep20.16.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 16
  %8430 = load i8, i8* %scevgep20.16.32, align 1
  %conv68.16.32 = zext i8 %8430 to i32
  %8431 = load i8, i8* %arrayidx70.32, align 1
  %conv71.16.32 = zext i8 %8431 to i32
  %xor72.16.32 = xor i32 %conv71.16.32, %conv68.16.32
  %conv73.16.32 = trunc i32 %xor72.16.32 to i8
  store i8 %conv73.16.32, i8* %arrayidx70.32, align 1
  %scevgep20.17.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 17
  %8432 = load i8, i8* %scevgep20.17.32, align 1
  %conv68.17.32 = zext i8 %8432 to i32
  %8433 = load i8, i8* %arrayidx70.32, align 1
  %conv71.17.32 = zext i8 %8433 to i32
  %xor72.17.32 = xor i32 %conv71.17.32, %conv68.17.32
  %conv73.17.32 = trunc i32 %xor72.17.32 to i8
  store i8 %conv73.17.32, i8* %arrayidx70.32, align 1
  %scevgep20.18.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 18
  %8434 = load i8, i8* %scevgep20.18.32, align 1
  %conv68.18.32 = zext i8 %8434 to i32
  %8435 = load i8, i8* %arrayidx70.32, align 1
  %conv71.18.32 = zext i8 %8435 to i32
  %xor72.18.32 = xor i32 %conv71.18.32, %conv68.18.32
  %conv73.18.32 = trunc i32 %xor72.18.32 to i8
  store i8 %conv73.18.32, i8* %arrayidx70.32, align 1
  %scevgep20.19.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 19
  %8436 = load i8, i8* %scevgep20.19.32, align 1
  %conv68.19.32 = zext i8 %8436 to i32
  %8437 = load i8, i8* %arrayidx70.32, align 1
  %conv71.19.32 = zext i8 %8437 to i32
  %xor72.19.32 = xor i32 %conv71.19.32, %conv68.19.32
  %conv73.19.32 = trunc i32 %xor72.19.32 to i8
  store i8 %conv73.19.32, i8* %arrayidx70.32, align 1
  %scevgep20.20.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 20
  %8438 = load i8, i8* %scevgep20.20.32, align 1
  %conv68.20.32 = zext i8 %8438 to i32
  %8439 = load i8, i8* %arrayidx70.32, align 1
  %conv71.20.32 = zext i8 %8439 to i32
  %xor72.20.32 = xor i32 %conv71.20.32, %conv68.20.32
  %conv73.20.32 = trunc i32 %xor72.20.32 to i8
  store i8 %conv73.20.32, i8* %arrayidx70.32, align 1
  %scevgep20.21.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 21
  %8440 = load i8, i8* %scevgep20.21.32, align 1
  %conv68.21.32 = zext i8 %8440 to i32
  %8441 = load i8, i8* %arrayidx70.32, align 1
  %conv71.21.32 = zext i8 %8441 to i32
  %xor72.21.32 = xor i32 %conv71.21.32, %conv68.21.32
  %conv73.21.32 = trunc i32 %xor72.21.32 to i8
  store i8 %conv73.21.32, i8* %arrayidx70.32, align 1
  %scevgep20.22.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 22
  %8442 = load i8, i8* %scevgep20.22.32, align 1
  %conv68.22.32 = zext i8 %8442 to i32
  %8443 = load i8, i8* %arrayidx70.32, align 1
  %conv71.22.32 = zext i8 %8443 to i32
  %xor72.22.32 = xor i32 %conv71.22.32, %conv68.22.32
  %conv73.22.32 = trunc i32 %xor72.22.32 to i8
  store i8 %conv73.22.32, i8* %arrayidx70.32, align 1
  %scevgep20.23.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 23
  %8444 = load i8, i8* %scevgep20.23.32, align 1
  %conv68.23.32 = zext i8 %8444 to i32
  %8445 = load i8, i8* %arrayidx70.32, align 1
  %conv71.23.32 = zext i8 %8445 to i32
  %xor72.23.32 = xor i32 %conv71.23.32, %conv68.23.32
  %conv73.23.32 = trunc i32 %xor72.23.32 to i8
  store i8 %conv73.23.32, i8* %arrayidx70.32, align 1
  %scevgep20.24.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 24
  %8446 = load i8, i8* %scevgep20.24.32, align 1
  %conv68.24.32 = zext i8 %8446 to i32
  %8447 = load i8, i8* %arrayidx70.32, align 1
  %conv71.24.32 = zext i8 %8447 to i32
  %xor72.24.32 = xor i32 %conv71.24.32, %conv68.24.32
  %conv73.24.32 = trunc i32 %xor72.24.32 to i8
  store i8 %conv73.24.32, i8* %arrayidx70.32, align 1
  %scevgep20.25.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 25
  %8448 = load i8, i8* %scevgep20.25.32, align 1
  %conv68.25.32 = zext i8 %8448 to i32
  %8449 = load i8, i8* %arrayidx70.32, align 1
  %conv71.25.32 = zext i8 %8449 to i32
  %xor72.25.32 = xor i32 %conv71.25.32, %conv68.25.32
  %conv73.25.32 = trunc i32 %xor72.25.32 to i8
  store i8 %conv73.25.32, i8* %arrayidx70.32, align 1
  %scevgep20.26.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 26
  %8450 = load i8, i8* %scevgep20.26.32, align 1
  %conv68.26.32 = zext i8 %8450 to i32
  %8451 = load i8, i8* %arrayidx70.32, align 1
  %conv71.26.32 = zext i8 %8451 to i32
  %xor72.26.32 = xor i32 %conv71.26.32, %conv68.26.32
  %conv73.26.32 = trunc i32 %xor72.26.32 to i8
  store i8 %conv73.26.32, i8* %arrayidx70.32, align 1
  %scevgep20.27.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 27
  %8452 = load i8, i8* %scevgep20.27.32, align 1
  %conv68.27.32 = zext i8 %8452 to i32
  %8453 = load i8, i8* %arrayidx70.32, align 1
  %conv71.27.32 = zext i8 %8453 to i32
  %xor72.27.32 = xor i32 %conv71.27.32, %conv68.27.32
  %conv73.27.32 = trunc i32 %xor72.27.32 to i8
  store i8 %conv73.27.32, i8* %arrayidx70.32, align 1
  %scevgep20.28.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 28
  %8454 = load i8, i8* %scevgep20.28.32, align 1
  %conv68.28.32 = zext i8 %8454 to i32
  %8455 = load i8, i8* %arrayidx70.32, align 1
  %conv71.28.32 = zext i8 %8455 to i32
  %xor72.28.32 = xor i32 %conv71.28.32, %conv68.28.32
  %conv73.28.32 = trunc i32 %xor72.28.32 to i8
  store i8 %conv73.28.32, i8* %arrayidx70.32, align 1
  %scevgep20.29.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 29
  %8456 = load i8, i8* %scevgep20.29.32, align 1
  %conv68.29.32 = zext i8 %8456 to i32
  %8457 = load i8, i8* %arrayidx70.32, align 1
  %conv71.29.32 = zext i8 %8457 to i32
  %xor72.29.32 = xor i32 %conv71.29.32, %conv68.29.32
  %conv73.29.32 = trunc i32 %xor72.29.32 to i8
  store i8 %conv73.29.32, i8* %arrayidx70.32, align 1
  %scevgep20.30.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 30
  %8458 = load i8, i8* %scevgep20.30.32, align 1
  %conv68.30.32 = zext i8 %8458 to i32
  %8459 = load i8, i8* %arrayidx70.32, align 1
  %conv71.30.32 = zext i8 %8459 to i32
  %xor72.30.32 = xor i32 %conv71.30.32, %conv68.30.32
  %conv73.30.32 = trunc i32 %xor72.30.32 to i8
  store i8 %conv73.30.32, i8* %arrayidx70.32, align 1
  %scevgep20.31.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 31
  %8460 = load i8, i8* %scevgep20.31.32, align 1
  %conv68.31.32 = zext i8 %8460 to i32
  %8461 = load i8, i8* %arrayidx70.32, align 1
  %conv71.31.32 = zext i8 %8461 to i32
  %xor72.31.32 = xor i32 %conv71.31.32, %conv68.31.32
  %conv73.31.32 = trunc i32 %xor72.31.32 to i8
  store i8 %conv73.31.32, i8* %arrayidx70.32, align 1
  %scevgep20.33.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 33
  %8462 = load i8, i8* %scevgep20.33.32, align 1
  %conv68.33.32 = zext i8 %8462 to i32
  %8463 = load i8, i8* %arrayidx70.32, align 1
  %conv71.33.32 = zext i8 %8463 to i32
  %xor72.33.32 = xor i32 %conv71.33.32, %conv68.33.32
  %conv73.33.32 = trunc i32 %xor72.33.32 to i8
  store i8 %conv73.33.32, i8* %arrayidx70.32, align 1
  %scevgep20.34.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 34
  %8464 = load i8, i8* %scevgep20.34.32, align 1
  %conv68.34.32 = zext i8 %8464 to i32
  %8465 = load i8, i8* %arrayidx70.32, align 1
  %conv71.34.32 = zext i8 %8465 to i32
  %xor72.34.32 = xor i32 %conv71.34.32, %conv68.34.32
  %conv73.34.32 = trunc i32 %xor72.34.32 to i8
  store i8 %conv73.34.32, i8* %arrayidx70.32, align 1
  %scevgep20.35.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 35
  %8466 = load i8, i8* %scevgep20.35.32, align 1
  %conv68.35.32 = zext i8 %8466 to i32
  %8467 = load i8, i8* %arrayidx70.32, align 1
  %conv71.35.32 = zext i8 %8467 to i32
  %xor72.35.32 = xor i32 %conv71.35.32, %conv68.35.32
  %conv73.35.32 = trunc i32 %xor72.35.32 to i8
  store i8 %conv73.35.32, i8* %arrayidx70.32, align 1
  %scevgep20.36.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 36
  %8468 = load i8, i8* %scevgep20.36.32, align 1
  %conv68.36.32 = zext i8 %8468 to i32
  %8469 = load i8, i8* %arrayidx70.32, align 1
  %conv71.36.32 = zext i8 %8469 to i32
  %xor72.36.32 = xor i32 %conv71.36.32, %conv68.36.32
  %conv73.36.32 = trunc i32 %xor72.36.32 to i8
  store i8 %conv73.36.32, i8* %arrayidx70.32, align 1
  %scevgep20.37.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 37
  %8470 = load i8, i8* %scevgep20.37.32, align 1
  %conv68.37.32 = zext i8 %8470 to i32
  %8471 = load i8, i8* %arrayidx70.32, align 1
  %conv71.37.32 = zext i8 %8471 to i32
  %xor72.37.32 = xor i32 %conv71.37.32, %conv68.37.32
  %conv73.37.32 = trunc i32 %xor72.37.32 to i8
  store i8 %conv73.37.32, i8* %arrayidx70.32, align 1
  %scevgep20.38.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 38
  %8472 = load i8, i8* %scevgep20.38.32, align 1
  %conv68.38.32 = zext i8 %8472 to i32
  %8473 = load i8, i8* %arrayidx70.32, align 1
  %conv71.38.32 = zext i8 %8473 to i32
  %xor72.38.32 = xor i32 %conv71.38.32, %conv68.38.32
  %conv73.38.32 = trunc i32 %xor72.38.32 to i8
  store i8 %conv73.38.32, i8* %arrayidx70.32, align 1
  %scevgep20.39.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 39
  %8474 = load i8, i8* %scevgep20.39.32, align 1
  %conv68.39.32 = zext i8 %8474 to i32
  %8475 = load i8, i8* %arrayidx70.32, align 1
  %conv71.39.32 = zext i8 %8475 to i32
  %xor72.39.32 = xor i32 %conv71.39.32, %conv68.39.32
  %conv73.39.32 = trunc i32 %xor72.39.32 to i8
  store i8 %conv73.39.32, i8* %arrayidx70.32, align 1
  %scevgep20.40.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 0, i64 40
  %8476 = load i8, i8* %scevgep20.40.32, align 1
  %conv68.40.32 = zext i8 %8476 to i32
  %8477 = load i8, i8* %arrayidx70.32, align 1
  %conv71.40.32 = zext i8 %8477 to i32
  %xor72.40.32 = xor i32 %conv71.40.32, %conv68.40.32
  %conv73.40.32 = trunc i32 %xor72.40.32 to i8
  store i8 %conv73.40.32, i8* %arrayidx70.32, align 1
  %scevgep19.32 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8395, i64 0, i64 1, i64 0
  %8478 = bitcast i8* %scevgep19.32 to [41 x [41 x i8]]*
  %arrayidx51.33 = getelementptr inbounds i8, i8* %a, i64 33
  %8479 = load i8, i8* %arrayidx51.33, align 1
  %arrayidx53.33 = getelementptr inbounds i8, i8* %b, i64 33
  %8480 = load i8, i8* %arrayidx53.33, align 1
  %call54.33 = call zeroext i8 @mult(i8 zeroext %8479, i8 zeroext %8480)
  %arrayidx56.33 = getelementptr inbounds i8, i8* %c, i64 33
  store i8 %call54.33, i8* %arrayidx56.33, align 1
  %arrayidx70.33 = getelementptr inbounds i8, i8* %c, i64 33
  %scevgep20.33374 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 0
  %8481 = load i8, i8* %scevgep20.33374, align 1
  %conv68.33375 = zext i8 %8481 to i32
  %8482 = load i8, i8* %arrayidx70.33, align 1
  %conv71.33376 = zext i8 %8482 to i32
  %xor72.33377 = xor i32 %conv71.33376, %conv68.33375
  %conv73.33378 = trunc i32 %xor72.33377 to i8
  store i8 %conv73.33378, i8* %arrayidx70.33, align 1
  %scevgep20.1.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 1
  %8483 = load i8, i8* %scevgep20.1.33, align 1
  %conv68.1.33 = zext i8 %8483 to i32
  %8484 = load i8, i8* %arrayidx70.33, align 1
  %conv71.1.33 = zext i8 %8484 to i32
  %xor72.1.33 = xor i32 %conv71.1.33, %conv68.1.33
  %conv73.1.33 = trunc i32 %xor72.1.33 to i8
  store i8 %conv73.1.33, i8* %arrayidx70.33, align 1
  %scevgep20.2.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 2
  %8485 = load i8, i8* %scevgep20.2.33, align 1
  %conv68.2.33 = zext i8 %8485 to i32
  %8486 = load i8, i8* %arrayidx70.33, align 1
  %conv71.2.33 = zext i8 %8486 to i32
  %xor72.2.33 = xor i32 %conv71.2.33, %conv68.2.33
  %conv73.2.33 = trunc i32 %xor72.2.33 to i8
  store i8 %conv73.2.33, i8* %arrayidx70.33, align 1
  %scevgep20.3.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 3
  %8487 = load i8, i8* %scevgep20.3.33, align 1
  %conv68.3.33 = zext i8 %8487 to i32
  %8488 = load i8, i8* %arrayidx70.33, align 1
  %conv71.3.33 = zext i8 %8488 to i32
  %xor72.3.33 = xor i32 %conv71.3.33, %conv68.3.33
  %conv73.3.33 = trunc i32 %xor72.3.33 to i8
  store i8 %conv73.3.33, i8* %arrayidx70.33, align 1
  %scevgep20.4.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 4
  %8489 = load i8, i8* %scevgep20.4.33, align 1
  %conv68.4.33 = zext i8 %8489 to i32
  %8490 = load i8, i8* %arrayidx70.33, align 1
  %conv71.4.33 = zext i8 %8490 to i32
  %xor72.4.33 = xor i32 %conv71.4.33, %conv68.4.33
  %conv73.4.33 = trunc i32 %xor72.4.33 to i8
  store i8 %conv73.4.33, i8* %arrayidx70.33, align 1
  %scevgep20.5.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 5
  %8491 = load i8, i8* %scevgep20.5.33, align 1
  %conv68.5.33 = zext i8 %8491 to i32
  %8492 = load i8, i8* %arrayidx70.33, align 1
  %conv71.5.33 = zext i8 %8492 to i32
  %xor72.5.33 = xor i32 %conv71.5.33, %conv68.5.33
  %conv73.5.33 = trunc i32 %xor72.5.33 to i8
  store i8 %conv73.5.33, i8* %arrayidx70.33, align 1
  %scevgep20.6.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 6
  %8493 = load i8, i8* %scevgep20.6.33, align 1
  %conv68.6.33 = zext i8 %8493 to i32
  %8494 = load i8, i8* %arrayidx70.33, align 1
  %conv71.6.33 = zext i8 %8494 to i32
  %xor72.6.33 = xor i32 %conv71.6.33, %conv68.6.33
  %conv73.6.33 = trunc i32 %xor72.6.33 to i8
  store i8 %conv73.6.33, i8* %arrayidx70.33, align 1
  %scevgep20.7.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 7
  %8495 = load i8, i8* %scevgep20.7.33, align 1
  %conv68.7.33 = zext i8 %8495 to i32
  %8496 = load i8, i8* %arrayidx70.33, align 1
  %conv71.7.33 = zext i8 %8496 to i32
  %xor72.7.33 = xor i32 %conv71.7.33, %conv68.7.33
  %conv73.7.33 = trunc i32 %xor72.7.33 to i8
  store i8 %conv73.7.33, i8* %arrayidx70.33, align 1
  %scevgep20.8.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 8
  %8497 = load i8, i8* %scevgep20.8.33, align 1
  %conv68.8.33 = zext i8 %8497 to i32
  %8498 = load i8, i8* %arrayidx70.33, align 1
  %conv71.8.33 = zext i8 %8498 to i32
  %xor72.8.33 = xor i32 %conv71.8.33, %conv68.8.33
  %conv73.8.33 = trunc i32 %xor72.8.33 to i8
  store i8 %conv73.8.33, i8* %arrayidx70.33, align 1
  %scevgep20.9.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 9
  %8499 = load i8, i8* %scevgep20.9.33, align 1
  %conv68.9.33 = zext i8 %8499 to i32
  %8500 = load i8, i8* %arrayidx70.33, align 1
  %conv71.9.33 = zext i8 %8500 to i32
  %xor72.9.33 = xor i32 %conv71.9.33, %conv68.9.33
  %conv73.9.33 = trunc i32 %xor72.9.33 to i8
  store i8 %conv73.9.33, i8* %arrayidx70.33, align 1
  %scevgep20.10.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 10
  %8501 = load i8, i8* %scevgep20.10.33, align 1
  %conv68.10.33 = zext i8 %8501 to i32
  %8502 = load i8, i8* %arrayidx70.33, align 1
  %conv71.10.33 = zext i8 %8502 to i32
  %xor72.10.33 = xor i32 %conv71.10.33, %conv68.10.33
  %conv73.10.33 = trunc i32 %xor72.10.33 to i8
  store i8 %conv73.10.33, i8* %arrayidx70.33, align 1
  %scevgep20.11.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 11
  %8503 = load i8, i8* %scevgep20.11.33, align 1
  %conv68.11.33 = zext i8 %8503 to i32
  %8504 = load i8, i8* %arrayidx70.33, align 1
  %conv71.11.33 = zext i8 %8504 to i32
  %xor72.11.33 = xor i32 %conv71.11.33, %conv68.11.33
  %conv73.11.33 = trunc i32 %xor72.11.33 to i8
  store i8 %conv73.11.33, i8* %arrayidx70.33, align 1
  %scevgep20.12.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 12
  %8505 = load i8, i8* %scevgep20.12.33, align 1
  %conv68.12.33 = zext i8 %8505 to i32
  %8506 = load i8, i8* %arrayidx70.33, align 1
  %conv71.12.33 = zext i8 %8506 to i32
  %xor72.12.33 = xor i32 %conv71.12.33, %conv68.12.33
  %conv73.12.33 = trunc i32 %xor72.12.33 to i8
  store i8 %conv73.12.33, i8* %arrayidx70.33, align 1
  %scevgep20.13.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 13
  %8507 = load i8, i8* %scevgep20.13.33, align 1
  %conv68.13.33 = zext i8 %8507 to i32
  %8508 = load i8, i8* %arrayidx70.33, align 1
  %conv71.13.33 = zext i8 %8508 to i32
  %xor72.13.33 = xor i32 %conv71.13.33, %conv68.13.33
  %conv73.13.33 = trunc i32 %xor72.13.33 to i8
  store i8 %conv73.13.33, i8* %arrayidx70.33, align 1
  %scevgep20.14.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 14
  %8509 = load i8, i8* %scevgep20.14.33, align 1
  %conv68.14.33 = zext i8 %8509 to i32
  %8510 = load i8, i8* %arrayidx70.33, align 1
  %conv71.14.33 = zext i8 %8510 to i32
  %xor72.14.33 = xor i32 %conv71.14.33, %conv68.14.33
  %conv73.14.33 = trunc i32 %xor72.14.33 to i8
  store i8 %conv73.14.33, i8* %arrayidx70.33, align 1
  %scevgep20.15.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 15
  %8511 = load i8, i8* %scevgep20.15.33, align 1
  %conv68.15.33 = zext i8 %8511 to i32
  %8512 = load i8, i8* %arrayidx70.33, align 1
  %conv71.15.33 = zext i8 %8512 to i32
  %xor72.15.33 = xor i32 %conv71.15.33, %conv68.15.33
  %conv73.15.33 = trunc i32 %xor72.15.33 to i8
  store i8 %conv73.15.33, i8* %arrayidx70.33, align 1
  %scevgep20.16.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 16
  %8513 = load i8, i8* %scevgep20.16.33, align 1
  %conv68.16.33 = zext i8 %8513 to i32
  %8514 = load i8, i8* %arrayidx70.33, align 1
  %conv71.16.33 = zext i8 %8514 to i32
  %xor72.16.33 = xor i32 %conv71.16.33, %conv68.16.33
  %conv73.16.33 = trunc i32 %xor72.16.33 to i8
  store i8 %conv73.16.33, i8* %arrayidx70.33, align 1
  %scevgep20.17.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 17
  %8515 = load i8, i8* %scevgep20.17.33, align 1
  %conv68.17.33 = zext i8 %8515 to i32
  %8516 = load i8, i8* %arrayidx70.33, align 1
  %conv71.17.33 = zext i8 %8516 to i32
  %xor72.17.33 = xor i32 %conv71.17.33, %conv68.17.33
  %conv73.17.33 = trunc i32 %xor72.17.33 to i8
  store i8 %conv73.17.33, i8* %arrayidx70.33, align 1
  %scevgep20.18.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 18
  %8517 = load i8, i8* %scevgep20.18.33, align 1
  %conv68.18.33 = zext i8 %8517 to i32
  %8518 = load i8, i8* %arrayidx70.33, align 1
  %conv71.18.33 = zext i8 %8518 to i32
  %xor72.18.33 = xor i32 %conv71.18.33, %conv68.18.33
  %conv73.18.33 = trunc i32 %xor72.18.33 to i8
  store i8 %conv73.18.33, i8* %arrayidx70.33, align 1
  %scevgep20.19.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 19
  %8519 = load i8, i8* %scevgep20.19.33, align 1
  %conv68.19.33 = zext i8 %8519 to i32
  %8520 = load i8, i8* %arrayidx70.33, align 1
  %conv71.19.33 = zext i8 %8520 to i32
  %xor72.19.33 = xor i32 %conv71.19.33, %conv68.19.33
  %conv73.19.33 = trunc i32 %xor72.19.33 to i8
  store i8 %conv73.19.33, i8* %arrayidx70.33, align 1
  %scevgep20.20.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 20
  %8521 = load i8, i8* %scevgep20.20.33, align 1
  %conv68.20.33 = zext i8 %8521 to i32
  %8522 = load i8, i8* %arrayidx70.33, align 1
  %conv71.20.33 = zext i8 %8522 to i32
  %xor72.20.33 = xor i32 %conv71.20.33, %conv68.20.33
  %conv73.20.33 = trunc i32 %xor72.20.33 to i8
  store i8 %conv73.20.33, i8* %arrayidx70.33, align 1
  %scevgep20.21.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 21
  %8523 = load i8, i8* %scevgep20.21.33, align 1
  %conv68.21.33 = zext i8 %8523 to i32
  %8524 = load i8, i8* %arrayidx70.33, align 1
  %conv71.21.33 = zext i8 %8524 to i32
  %xor72.21.33 = xor i32 %conv71.21.33, %conv68.21.33
  %conv73.21.33 = trunc i32 %xor72.21.33 to i8
  store i8 %conv73.21.33, i8* %arrayidx70.33, align 1
  %scevgep20.22.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 22
  %8525 = load i8, i8* %scevgep20.22.33, align 1
  %conv68.22.33 = zext i8 %8525 to i32
  %8526 = load i8, i8* %arrayidx70.33, align 1
  %conv71.22.33 = zext i8 %8526 to i32
  %xor72.22.33 = xor i32 %conv71.22.33, %conv68.22.33
  %conv73.22.33 = trunc i32 %xor72.22.33 to i8
  store i8 %conv73.22.33, i8* %arrayidx70.33, align 1
  %scevgep20.23.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 23
  %8527 = load i8, i8* %scevgep20.23.33, align 1
  %conv68.23.33 = zext i8 %8527 to i32
  %8528 = load i8, i8* %arrayidx70.33, align 1
  %conv71.23.33 = zext i8 %8528 to i32
  %xor72.23.33 = xor i32 %conv71.23.33, %conv68.23.33
  %conv73.23.33 = trunc i32 %xor72.23.33 to i8
  store i8 %conv73.23.33, i8* %arrayidx70.33, align 1
  %scevgep20.24.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 24
  %8529 = load i8, i8* %scevgep20.24.33, align 1
  %conv68.24.33 = zext i8 %8529 to i32
  %8530 = load i8, i8* %arrayidx70.33, align 1
  %conv71.24.33 = zext i8 %8530 to i32
  %xor72.24.33 = xor i32 %conv71.24.33, %conv68.24.33
  %conv73.24.33 = trunc i32 %xor72.24.33 to i8
  store i8 %conv73.24.33, i8* %arrayidx70.33, align 1
  %scevgep20.25.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 25
  %8531 = load i8, i8* %scevgep20.25.33, align 1
  %conv68.25.33 = zext i8 %8531 to i32
  %8532 = load i8, i8* %arrayidx70.33, align 1
  %conv71.25.33 = zext i8 %8532 to i32
  %xor72.25.33 = xor i32 %conv71.25.33, %conv68.25.33
  %conv73.25.33 = trunc i32 %xor72.25.33 to i8
  store i8 %conv73.25.33, i8* %arrayidx70.33, align 1
  %scevgep20.26.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 26
  %8533 = load i8, i8* %scevgep20.26.33, align 1
  %conv68.26.33 = zext i8 %8533 to i32
  %8534 = load i8, i8* %arrayidx70.33, align 1
  %conv71.26.33 = zext i8 %8534 to i32
  %xor72.26.33 = xor i32 %conv71.26.33, %conv68.26.33
  %conv73.26.33 = trunc i32 %xor72.26.33 to i8
  store i8 %conv73.26.33, i8* %arrayidx70.33, align 1
  %scevgep20.27.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 27
  %8535 = load i8, i8* %scevgep20.27.33, align 1
  %conv68.27.33 = zext i8 %8535 to i32
  %8536 = load i8, i8* %arrayidx70.33, align 1
  %conv71.27.33 = zext i8 %8536 to i32
  %xor72.27.33 = xor i32 %conv71.27.33, %conv68.27.33
  %conv73.27.33 = trunc i32 %xor72.27.33 to i8
  store i8 %conv73.27.33, i8* %arrayidx70.33, align 1
  %scevgep20.28.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 28
  %8537 = load i8, i8* %scevgep20.28.33, align 1
  %conv68.28.33 = zext i8 %8537 to i32
  %8538 = load i8, i8* %arrayidx70.33, align 1
  %conv71.28.33 = zext i8 %8538 to i32
  %xor72.28.33 = xor i32 %conv71.28.33, %conv68.28.33
  %conv73.28.33 = trunc i32 %xor72.28.33 to i8
  store i8 %conv73.28.33, i8* %arrayidx70.33, align 1
  %scevgep20.29.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 29
  %8539 = load i8, i8* %scevgep20.29.33, align 1
  %conv68.29.33 = zext i8 %8539 to i32
  %8540 = load i8, i8* %arrayidx70.33, align 1
  %conv71.29.33 = zext i8 %8540 to i32
  %xor72.29.33 = xor i32 %conv71.29.33, %conv68.29.33
  %conv73.29.33 = trunc i32 %xor72.29.33 to i8
  store i8 %conv73.29.33, i8* %arrayidx70.33, align 1
  %scevgep20.30.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 30
  %8541 = load i8, i8* %scevgep20.30.33, align 1
  %conv68.30.33 = zext i8 %8541 to i32
  %8542 = load i8, i8* %arrayidx70.33, align 1
  %conv71.30.33 = zext i8 %8542 to i32
  %xor72.30.33 = xor i32 %conv71.30.33, %conv68.30.33
  %conv73.30.33 = trunc i32 %xor72.30.33 to i8
  store i8 %conv73.30.33, i8* %arrayidx70.33, align 1
  %scevgep20.31.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 31
  %8543 = load i8, i8* %scevgep20.31.33, align 1
  %conv68.31.33 = zext i8 %8543 to i32
  %8544 = load i8, i8* %arrayidx70.33, align 1
  %conv71.31.33 = zext i8 %8544 to i32
  %xor72.31.33 = xor i32 %conv71.31.33, %conv68.31.33
  %conv73.31.33 = trunc i32 %xor72.31.33 to i8
  store i8 %conv73.31.33, i8* %arrayidx70.33, align 1
  %scevgep20.32.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 32
  %8545 = load i8, i8* %scevgep20.32.33, align 1
  %conv68.32.33 = zext i8 %8545 to i32
  %8546 = load i8, i8* %arrayidx70.33, align 1
  %conv71.32.33 = zext i8 %8546 to i32
  %xor72.32.33 = xor i32 %conv71.32.33, %conv68.32.33
  %conv73.32.33 = trunc i32 %xor72.32.33 to i8
  store i8 %conv73.32.33, i8* %arrayidx70.33, align 1
  %scevgep20.34.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 34
  %8547 = load i8, i8* %scevgep20.34.33, align 1
  %conv68.34.33 = zext i8 %8547 to i32
  %8548 = load i8, i8* %arrayidx70.33, align 1
  %conv71.34.33 = zext i8 %8548 to i32
  %xor72.34.33 = xor i32 %conv71.34.33, %conv68.34.33
  %conv73.34.33 = trunc i32 %xor72.34.33 to i8
  store i8 %conv73.34.33, i8* %arrayidx70.33, align 1
  %scevgep20.35.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 35
  %8549 = load i8, i8* %scevgep20.35.33, align 1
  %conv68.35.33 = zext i8 %8549 to i32
  %8550 = load i8, i8* %arrayidx70.33, align 1
  %conv71.35.33 = zext i8 %8550 to i32
  %xor72.35.33 = xor i32 %conv71.35.33, %conv68.35.33
  %conv73.35.33 = trunc i32 %xor72.35.33 to i8
  store i8 %conv73.35.33, i8* %arrayidx70.33, align 1
  %scevgep20.36.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 36
  %8551 = load i8, i8* %scevgep20.36.33, align 1
  %conv68.36.33 = zext i8 %8551 to i32
  %8552 = load i8, i8* %arrayidx70.33, align 1
  %conv71.36.33 = zext i8 %8552 to i32
  %xor72.36.33 = xor i32 %conv71.36.33, %conv68.36.33
  %conv73.36.33 = trunc i32 %xor72.36.33 to i8
  store i8 %conv73.36.33, i8* %arrayidx70.33, align 1
  %scevgep20.37.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 37
  %8553 = load i8, i8* %scevgep20.37.33, align 1
  %conv68.37.33 = zext i8 %8553 to i32
  %8554 = load i8, i8* %arrayidx70.33, align 1
  %conv71.37.33 = zext i8 %8554 to i32
  %xor72.37.33 = xor i32 %conv71.37.33, %conv68.37.33
  %conv73.37.33 = trunc i32 %xor72.37.33 to i8
  store i8 %conv73.37.33, i8* %arrayidx70.33, align 1
  %scevgep20.38.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 38
  %8555 = load i8, i8* %scevgep20.38.33, align 1
  %conv68.38.33 = zext i8 %8555 to i32
  %8556 = load i8, i8* %arrayidx70.33, align 1
  %conv71.38.33 = zext i8 %8556 to i32
  %xor72.38.33 = xor i32 %conv71.38.33, %conv68.38.33
  %conv73.38.33 = trunc i32 %xor72.38.33 to i8
  store i8 %conv73.38.33, i8* %arrayidx70.33, align 1
  %scevgep20.39.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 39
  %8557 = load i8, i8* %scevgep20.39.33, align 1
  %conv68.39.33 = zext i8 %8557 to i32
  %8558 = load i8, i8* %arrayidx70.33, align 1
  %conv71.39.33 = zext i8 %8558 to i32
  %xor72.39.33 = xor i32 %conv71.39.33, %conv68.39.33
  %conv73.39.33 = trunc i32 %xor72.39.33 to i8
  store i8 %conv73.39.33, i8* %arrayidx70.33, align 1
  %scevgep20.40.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 0, i64 40
  %8559 = load i8, i8* %scevgep20.40.33, align 1
  %conv68.40.33 = zext i8 %8559 to i32
  %8560 = load i8, i8* %arrayidx70.33, align 1
  %conv71.40.33 = zext i8 %8560 to i32
  %xor72.40.33 = xor i32 %conv71.40.33, %conv68.40.33
  %conv73.40.33 = trunc i32 %xor72.40.33 to i8
  store i8 %conv73.40.33, i8* %arrayidx70.33, align 1
  %scevgep19.33 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8478, i64 0, i64 1, i64 0
  %8561 = bitcast i8* %scevgep19.33 to [41 x [41 x i8]]*
  %arrayidx51.34 = getelementptr inbounds i8, i8* %a, i64 34
  %8562 = load i8, i8* %arrayidx51.34, align 1
  %arrayidx53.34 = getelementptr inbounds i8, i8* %b, i64 34
  %8563 = load i8, i8* %arrayidx53.34, align 1
  %call54.34 = call zeroext i8 @mult(i8 zeroext %8562, i8 zeroext %8563)
  %arrayidx56.34 = getelementptr inbounds i8, i8* %c, i64 34
  store i8 %call54.34, i8* %arrayidx56.34, align 1
  %arrayidx70.34 = getelementptr inbounds i8, i8* %c, i64 34
  %scevgep20.34384 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 0
  %8564 = load i8, i8* %scevgep20.34384, align 1
  %conv68.34385 = zext i8 %8564 to i32
  %8565 = load i8, i8* %arrayidx70.34, align 1
  %conv71.34386 = zext i8 %8565 to i32
  %xor72.34387 = xor i32 %conv71.34386, %conv68.34385
  %conv73.34388 = trunc i32 %xor72.34387 to i8
  store i8 %conv73.34388, i8* %arrayidx70.34, align 1
  %scevgep20.1.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 1
  %8566 = load i8, i8* %scevgep20.1.34, align 1
  %conv68.1.34 = zext i8 %8566 to i32
  %8567 = load i8, i8* %arrayidx70.34, align 1
  %conv71.1.34 = zext i8 %8567 to i32
  %xor72.1.34 = xor i32 %conv71.1.34, %conv68.1.34
  %conv73.1.34 = trunc i32 %xor72.1.34 to i8
  store i8 %conv73.1.34, i8* %arrayidx70.34, align 1
  %scevgep20.2.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 2
  %8568 = load i8, i8* %scevgep20.2.34, align 1
  %conv68.2.34 = zext i8 %8568 to i32
  %8569 = load i8, i8* %arrayidx70.34, align 1
  %conv71.2.34 = zext i8 %8569 to i32
  %xor72.2.34 = xor i32 %conv71.2.34, %conv68.2.34
  %conv73.2.34 = trunc i32 %xor72.2.34 to i8
  store i8 %conv73.2.34, i8* %arrayidx70.34, align 1
  %scevgep20.3.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 3
  %8570 = load i8, i8* %scevgep20.3.34, align 1
  %conv68.3.34 = zext i8 %8570 to i32
  %8571 = load i8, i8* %arrayidx70.34, align 1
  %conv71.3.34 = zext i8 %8571 to i32
  %xor72.3.34 = xor i32 %conv71.3.34, %conv68.3.34
  %conv73.3.34 = trunc i32 %xor72.3.34 to i8
  store i8 %conv73.3.34, i8* %arrayidx70.34, align 1
  %scevgep20.4.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 4
  %8572 = load i8, i8* %scevgep20.4.34, align 1
  %conv68.4.34 = zext i8 %8572 to i32
  %8573 = load i8, i8* %arrayidx70.34, align 1
  %conv71.4.34 = zext i8 %8573 to i32
  %xor72.4.34 = xor i32 %conv71.4.34, %conv68.4.34
  %conv73.4.34 = trunc i32 %xor72.4.34 to i8
  store i8 %conv73.4.34, i8* %arrayidx70.34, align 1
  %scevgep20.5.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 5
  %8574 = load i8, i8* %scevgep20.5.34, align 1
  %conv68.5.34 = zext i8 %8574 to i32
  %8575 = load i8, i8* %arrayidx70.34, align 1
  %conv71.5.34 = zext i8 %8575 to i32
  %xor72.5.34 = xor i32 %conv71.5.34, %conv68.5.34
  %conv73.5.34 = trunc i32 %xor72.5.34 to i8
  store i8 %conv73.5.34, i8* %arrayidx70.34, align 1
  %scevgep20.6.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 6
  %8576 = load i8, i8* %scevgep20.6.34, align 1
  %conv68.6.34 = zext i8 %8576 to i32
  %8577 = load i8, i8* %arrayidx70.34, align 1
  %conv71.6.34 = zext i8 %8577 to i32
  %xor72.6.34 = xor i32 %conv71.6.34, %conv68.6.34
  %conv73.6.34 = trunc i32 %xor72.6.34 to i8
  store i8 %conv73.6.34, i8* %arrayidx70.34, align 1
  %scevgep20.7.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 7
  %8578 = load i8, i8* %scevgep20.7.34, align 1
  %conv68.7.34 = zext i8 %8578 to i32
  %8579 = load i8, i8* %arrayidx70.34, align 1
  %conv71.7.34 = zext i8 %8579 to i32
  %xor72.7.34 = xor i32 %conv71.7.34, %conv68.7.34
  %conv73.7.34 = trunc i32 %xor72.7.34 to i8
  store i8 %conv73.7.34, i8* %arrayidx70.34, align 1
  %scevgep20.8.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 8
  %8580 = load i8, i8* %scevgep20.8.34, align 1
  %conv68.8.34 = zext i8 %8580 to i32
  %8581 = load i8, i8* %arrayidx70.34, align 1
  %conv71.8.34 = zext i8 %8581 to i32
  %xor72.8.34 = xor i32 %conv71.8.34, %conv68.8.34
  %conv73.8.34 = trunc i32 %xor72.8.34 to i8
  store i8 %conv73.8.34, i8* %arrayidx70.34, align 1
  %scevgep20.9.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 9
  %8582 = load i8, i8* %scevgep20.9.34, align 1
  %conv68.9.34 = zext i8 %8582 to i32
  %8583 = load i8, i8* %arrayidx70.34, align 1
  %conv71.9.34 = zext i8 %8583 to i32
  %xor72.9.34 = xor i32 %conv71.9.34, %conv68.9.34
  %conv73.9.34 = trunc i32 %xor72.9.34 to i8
  store i8 %conv73.9.34, i8* %arrayidx70.34, align 1
  %scevgep20.10.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 10
  %8584 = load i8, i8* %scevgep20.10.34, align 1
  %conv68.10.34 = zext i8 %8584 to i32
  %8585 = load i8, i8* %arrayidx70.34, align 1
  %conv71.10.34 = zext i8 %8585 to i32
  %xor72.10.34 = xor i32 %conv71.10.34, %conv68.10.34
  %conv73.10.34 = trunc i32 %xor72.10.34 to i8
  store i8 %conv73.10.34, i8* %arrayidx70.34, align 1
  %scevgep20.11.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 11
  %8586 = load i8, i8* %scevgep20.11.34, align 1
  %conv68.11.34 = zext i8 %8586 to i32
  %8587 = load i8, i8* %arrayidx70.34, align 1
  %conv71.11.34 = zext i8 %8587 to i32
  %xor72.11.34 = xor i32 %conv71.11.34, %conv68.11.34
  %conv73.11.34 = trunc i32 %xor72.11.34 to i8
  store i8 %conv73.11.34, i8* %arrayidx70.34, align 1
  %scevgep20.12.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 12
  %8588 = load i8, i8* %scevgep20.12.34, align 1
  %conv68.12.34 = zext i8 %8588 to i32
  %8589 = load i8, i8* %arrayidx70.34, align 1
  %conv71.12.34 = zext i8 %8589 to i32
  %xor72.12.34 = xor i32 %conv71.12.34, %conv68.12.34
  %conv73.12.34 = trunc i32 %xor72.12.34 to i8
  store i8 %conv73.12.34, i8* %arrayidx70.34, align 1
  %scevgep20.13.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 13
  %8590 = load i8, i8* %scevgep20.13.34, align 1
  %conv68.13.34 = zext i8 %8590 to i32
  %8591 = load i8, i8* %arrayidx70.34, align 1
  %conv71.13.34 = zext i8 %8591 to i32
  %xor72.13.34 = xor i32 %conv71.13.34, %conv68.13.34
  %conv73.13.34 = trunc i32 %xor72.13.34 to i8
  store i8 %conv73.13.34, i8* %arrayidx70.34, align 1
  %scevgep20.14.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 14
  %8592 = load i8, i8* %scevgep20.14.34, align 1
  %conv68.14.34 = zext i8 %8592 to i32
  %8593 = load i8, i8* %arrayidx70.34, align 1
  %conv71.14.34 = zext i8 %8593 to i32
  %xor72.14.34 = xor i32 %conv71.14.34, %conv68.14.34
  %conv73.14.34 = trunc i32 %xor72.14.34 to i8
  store i8 %conv73.14.34, i8* %arrayidx70.34, align 1
  %scevgep20.15.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 15
  %8594 = load i8, i8* %scevgep20.15.34, align 1
  %conv68.15.34 = zext i8 %8594 to i32
  %8595 = load i8, i8* %arrayidx70.34, align 1
  %conv71.15.34 = zext i8 %8595 to i32
  %xor72.15.34 = xor i32 %conv71.15.34, %conv68.15.34
  %conv73.15.34 = trunc i32 %xor72.15.34 to i8
  store i8 %conv73.15.34, i8* %arrayidx70.34, align 1
  %scevgep20.16.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 16
  %8596 = load i8, i8* %scevgep20.16.34, align 1
  %conv68.16.34 = zext i8 %8596 to i32
  %8597 = load i8, i8* %arrayidx70.34, align 1
  %conv71.16.34 = zext i8 %8597 to i32
  %xor72.16.34 = xor i32 %conv71.16.34, %conv68.16.34
  %conv73.16.34 = trunc i32 %xor72.16.34 to i8
  store i8 %conv73.16.34, i8* %arrayidx70.34, align 1
  %scevgep20.17.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 17
  %8598 = load i8, i8* %scevgep20.17.34, align 1
  %conv68.17.34 = zext i8 %8598 to i32
  %8599 = load i8, i8* %arrayidx70.34, align 1
  %conv71.17.34 = zext i8 %8599 to i32
  %xor72.17.34 = xor i32 %conv71.17.34, %conv68.17.34
  %conv73.17.34 = trunc i32 %xor72.17.34 to i8
  store i8 %conv73.17.34, i8* %arrayidx70.34, align 1
  %scevgep20.18.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 18
  %8600 = load i8, i8* %scevgep20.18.34, align 1
  %conv68.18.34 = zext i8 %8600 to i32
  %8601 = load i8, i8* %arrayidx70.34, align 1
  %conv71.18.34 = zext i8 %8601 to i32
  %xor72.18.34 = xor i32 %conv71.18.34, %conv68.18.34
  %conv73.18.34 = trunc i32 %xor72.18.34 to i8
  store i8 %conv73.18.34, i8* %arrayidx70.34, align 1
  %scevgep20.19.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 19
  %8602 = load i8, i8* %scevgep20.19.34, align 1
  %conv68.19.34 = zext i8 %8602 to i32
  %8603 = load i8, i8* %arrayidx70.34, align 1
  %conv71.19.34 = zext i8 %8603 to i32
  %xor72.19.34 = xor i32 %conv71.19.34, %conv68.19.34
  %conv73.19.34 = trunc i32 %xor72.19.34 to i8
  store i8 %conv73.19.34, i8* %arrayidx70.34, align 1
  %scevgep20.20.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 20
  %8604 = load i8, i8* %scevgep20.20.34, align 1
  %conv68.20.34 = zext i8 %8604 to i32
  %8605 = load i8, i8* %arrayidx70.34, align 1
  %conv71.20.34 = zext i8 %8605 to i32
  %xor72.20.34 = xor i32 %conv71.20.34, %conv68.20.34
  %conv73.20.34 = trunc i32 %xor72.20.34 to i8
  store i8 %conv73.20.34, i8* %arrayidx70.34, align 1
  %scevgep20.21.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 21
  %8606 = load i8, i8* %scevgep20.21.34, align 1
  %conv68.21.34 = zext i8 %8606 to i32
  %8607 = load i8, i8* %arrayidx70.34, align 1
  %conv71.21.34 = zext i8 %8607 to i32
  %xor72.21.34 = xor i32 %conv71.21.34, %conv68.21.34
  %conv73.21.34 = trunc i32 %xor72.21.34 to i8
  store i8 %conv73.21.34, i8* %arrayidx70.34, align 1
  %scevgep20.22.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 22
  %8608 = load i8, i8* %scevgep20.22.34, align 1
  %conv68.22.34 = zext i8 %8608 to i32
  %8609 = load i8, i8* %arrayidx70.34, align 1
  %conv71.22.34 = zext i8 %8609 to i32
  %xor72.22.34 = xor i32 %conv71.22.34, %conv68.22.34
  %conv73.22.34 = trunc i32 %xor72.22.34 to i8
  store i8 %conv73.22.34, i8* %arrayidx70.34, align 1
  %scevgep20.23.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 23
  %8610 = load i8, i8* %scevgep20.23.34, align 1
  %conv68.23.34 = zext i8 %8610 to i32
  %8611 = load i8, i8* %arrayidx70.34, align 1
  %conv71.23.34 = zext i8 %8611 to i32
  %xor72.23.34 = xor i32 %conv71.23.34, %conv68.23.34
  %conv73.23.34 = trunc i32 %xor72.23.34 to i8
  store i8 %conv73.23.34, i8* %arrayidx70.34, align 1
  %scevgep20.24.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 24
  %8612 = load i8, i8* %scevgep20.24.34, align 1
  %conv68.24.34 = zext i8 %8612 to i32
  %8613 = load i8, i8* %arrayidx70.34, align 1
  %conv71.24.34 = zext i8 %8613 to i32
  %xor72.24.34 = xor i32 %conv71.24.34, %conv68.24.34
  %conv73.24.34 = trunc i32 %xor72.24.34 to i8
  store i8 %conv73.24.34, i8* %arrayidx70.34, align 1
  %scevgep20.25.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 25
  %8614 = load i8, i8* %scevgep20.25.34, align 1
  %conv68.25.34 = zext i8 %8614 to i32
  %8615 = load i8, i8* %arrayidx70.34, align 1
  %conv71.25.34 = zext i8 %8615 to i32
  %xor72.25.34 = xor i32 %conv71.25.34, %conv68.25.34
  %conv73.25.34 = trunc i32 %xor72.25.34 to i8
  store i8 %conv73.25.34, i8* %arrayidx70.34, align 1
  %scevgep20.26.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 26
  %8616 = load i8, i8* %scevgep20.26.34, align 1
  %conv68.26.34 = zext i8 %8616 to i32
  %8617 = load i8, i8* %arrayidx70.34, align 1
  %conv71.26.34 = zext i8 %8617 to i32
  %xor72.26.34 = xor i32 %conv71.26.34, %conv68.26.34
  %conv73.26.34 = trunc i32 %xor72.26.34 to i8
  store i8 %conv73.26.34, i8* %arrayidx70.34, align 1
  %scevgep20.27.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 27
  %8618 = load i8, i8* %scevgep20.27.34, align 1
  %conv68.27.34 = zext i8 %8618 to i32
  %8619 = load i8, i8* %arrayidx70.34, align 1
  %conv71.27.34 = zext i8 %8619 to i32
  %xor72.27.34 = xor i32 %conv71.27.34, %conv68.27.34
  %conv73.27.34 = trunc i32 %xor72.27.34 to i8
  store i8 %conv73.27.34, i8* %arrayidx70.34, align 1
  %scevgep20.28.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 28
  %8620 = load i8, i8* %scevgep20.28.34, align 1
  %conv68.28.34 = zext i8 %8620 to i32
  %8621 = load i8, i8* %arrayidx70.34, align 1
  %conv71.28.34 = zext i8 %8621 to i32
  %xor72.28.34 = xor i32 %conv71.28.34, %conv68.28.34
  %conv73.28.34 = trunc i32 %xor72.28.34 to i8
  store i8 %conv73.28.34, i8* %arrayidx70.34, align 1
  %scevgep20.29.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 29
  %8622 = load i8, i8* %scevgep20.29.34, align 1
  %conv68.29.34 = zext i8 %8622 to i32
  %8623 = load i8, i8* %arrayidx70.34, align 1
  %conv71.29.34 = zext i8 %8623 to i32
  %xor72.29.34 = xor i32 %conv71.29.34, %conv68.29.34
  %conv73.29.34 = trunc i32 %xor72.29.34 to i8
  store i8 %conv73.29.34, i8* %arrayidx70.34, align 1
  %scevgep20.30.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 30
  %8624 = load i8, i8* %scevgep20.30.34, align 1
  %conv68.30.34 = zext i8 %8624 to i32
  %8625 = load i8, i8* %arrayidx70.34, align 1
  %conv71.30.34 = zext i8 %8625 to i32
  %xor72.30.34 = xor i32 %conv71.30.34, %conv68.30.34
  %conv73.30.34 = trunc i32 %xor72.30.34 to i8
  store i8 %conv73.30.34, i8* %arrayidx70.34, align 1
  %scevgep20.31.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 31
  %8626 = load i8, i8* %scevgep20.31.34, align 1
  %conv68.31.34 = zext i8 %8626 to i32
  %8627 = load i8, i8* %arrayidx70.34, align 1
  %conv71.31.34 = zext i8 %8627 to i32
  %xor72.31.34 = xor i32 %conv71.31.34, %conv68.31.34
  %conv73.31.34 = trunc i32 %xor72.31.34 to i8
  store i8 %conv73.31.34, i8* %arrayidx70.34, align 1
  %scevgep20.32.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 32
  %8628 = load i8, i8* %scevgep20.32.34, align 1
  %conv68.32.34 = zext i8 %8628 to i32
  %8629 = load i8, i8* %arrayidx70.34, align 1
  %conv71.32.34 = zext i8 %8629 to i32
  %xor72.32.34 = xor i32 %conv71.32.34, %conv68.32.34
  %conv73.32.34 = trunc i32 %xor72.32.34 to i8
  store i8 %conv73.32.34, i8* %arrayidx70.34, align 1
  %scevgep20.33.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 33
  %8630 = load i8, i8* %scevgep20.33.34, align 1
  %conv68.33.34 = zext i8 %8630 to i32
  %8631 = load i8, i8* %arrayidx70.34, align 1
  %conv71.33.34 = zext i8 %8631 to i32
  %xor72.33.34 = xor i32 %conv71.33.34, %conv68.33.34
  %conv73.33.34 = trunc i32 %xor72.33.34 to i8
  store i8 %conv73.33.34, i8* %arrayidx70.34, align 1
  %scevgep20.35.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 35
  %8632 = load i8, i8* %scevgep20.35.34, align 1
  %conv68.35.34 = zext i8 %8632 to i32
  %8633 = load i8, i8* %arrayidx70.34, align 1
  %conv71.35.34 = zext i8 %8633 to i32
  %xor72.35.34 = xor i32 %conv71.35.34, %conv68.35.34
  %conv73.35.34 = trunc i32 %xor72.35.34 to i8
  store i8 %conv73.35.34, i8* %arrayidx70.34, align 1
  %scevgep20.36.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 36
  %8634 = load i8, i8* %scevgep20.36.34, align 1
  %conv68.36.34 = zext i8 %8634 to i32
  %8635 = load i8, i8* %arrayidx70.34, align 1
  %conv71.36.34 = zext i8 %8635 to i32
  %xor72.36.34 = xor i32 %conv71.36.34, %conv68.36.34
  %conv73.36.34 = trunc i32 %xor72.36.34 to i8
  store i8 %conv73.36.34, i8* %arrayidx70.34, align 1
  %scevgep20.37.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 37
  %8636 = load i8, i8* %scevgep20.37.34, align 1
  %conv68.37.34 = zext i8 %8636 to i32
  %8637 = load i8, i8* %arrayidx70.34, align 1
  %conv71.37.34 = zext i8 %8637 to i32
  %xor72.37.34 = xor i32 %conv71.37.34, %conv68.37.34
  %conv73.37.34 = trunc i32 %xor72.37.34 to i8
  store i8 %conv73.37.34, i8* %arrayidx70.34, align 1
  %scevgep20.38.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 38
  %8638 = load i8, i8* %scevgep20.38.34, align 1
  %conv68.38.34 = zext i8 %8638 to i32
  %8639 = load i8, i8* %arrayidx70.34, align 1
  %conv71.38.34 = zext i8 %8639 to i32
  %xor72.38.34 = xor i32 %conv71.38.34, %conv68.38.34
  %conv73.38.34 = trunc i32 %xor72.38.34 to i8
  store i8 %conv73.38.34, i8* %arrayidx70.34, align 1
  %scevgep20.39.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 39
  %8640 = load i8, i8* %scevgep20.39.34, align 1
  %conv68.39.34 = zext i8 %8640 to i32
  %8641 = load i8, i8* %arrayidx70.34, align 1
  %conv71.39.34 = zext i8 %8641 to i32
  %xor72.39.34 = xor i32 %conv71.39.34, %conv68.39.34
  %conv73.39.34 = trunc i32 %xor72.39.34 to i8
  store i8 %conv73.39.34, i8* %arrayidx70.34, align 1
  %scevgep20.40.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 0, i64 40
  %8642 = load i8, i8* %scevgep20.40.34, align 1
  %conv68.40.34 = zext i8 %8642 to i32
  %8643 = load i8, i8* %arrayidx70.34, align 1
  %conv71.40.34 = zext i8 %8643 to i32
  %xor72.40.34 = xor i32 %conv71.40.34, %conv68.40.34
  %conv73.40.34 = trunc i32 %xor72.40.34 to i8
  store i8 %conv73.40.34, i8* %arrayidx70.34, align 1
  %scevgep19.34 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8561, i64 0, i64 1, i64 0
  %8644 = bitcast i8* %scevgep19.34 to [41 x [41 x i8]]*
  %arrayidx51.35 = getelementptr inbounds i8, i8* %a, i64 35
  %8645 = load i8, i8* %arrayidx51.35, align 1
  %arrayidx53.35 = getelementptr inbounds i8, i8* %b, i64 35
  %8646 = load i8, i8* %arrayidx53.35, align 1
  %call54.35 = call zeroext i8 @mult(i8 zeroext %8645, i8 zeroext %8646)
  %arrayidx56.35 = getelementptr inbounds i8, i8* %c, i64 35
  store i8 %call54.35, i8* %arrayidx56.35, align 1
  %arrayidx70.35 = getelementptr inbounds i8, i8* %c, i64 35
  %scevgep20.35394 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 0
  %8647 = load i8, i8* %scevgep20.35394, align 1
  %conv68.35395 = zext i8 %8647 to i32
  %8648 = load i8, i8* %arrayidx70.35, align 1
  %conv71.35396 = zext i8 %8648 to i32
  %xor72.35397 = xor i32 %conv71.35396, %conv68.35395
  %conv73.35398 = trunc i32 %xor72.35397 to i8
  store i8 %conv73.35398, i8* %arrayidx70.35, align 1
  %scevgep20.1.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 1
  %8649 = load i8, i8* %scevgep20.1.35, align 1
  %conv68.1.35 = zext i8 %8649 to i32
  %8650 = load i8, i8* %arrayidx70.35, align 1
  %conv71.1.35 = zext i8 %8650 to i32
  %xor72.1.35 = xor i32 %conv71.1.35, %conv68.1.35
  %conv73.1.35 = trunc i32 %xor72.1.35 to i8
  store i8 %conv73.1.35, i8* %arrayidx70.35, align 1
  %scevgep20.2.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 2
  %8651 = load i8, i8* %scevgep20.2.35, align 1
  %conv68.2.35 = zext i8 %8651 to i32
  %8652 = load i8, i8* %arrayidx70.35, align 1
  %conv71.2.35 = zext i8 %8652 to i32
  %xor72.2.35 = xor i32 %conv71.2.35, %conv68.2.35
  %conv73.2.35 = trunc i32 %xor72.2.35 to i8
  store i8 %conv73.2.35, i8* %arrayidx70.35, align 1
  %scevgep20.3.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 3
  %8653 = load i8, i8* %scevgep20.3.35, align 1
  %conv68.3.35 = zext i8 %8653 to i32
  %8654 = load i8, i8* %arrayidx70.35, align 1
  %conv71.3.35 = zext i8 %8654 to i32
  %xor72.3.35 = xor i32 %conv71.3.35, %conv68.3.35
  %conv73.3.35 = trunc i32 %xor72.3.35 to i8
  store i8 %conv73.3.35, i8* %arrayidx70.35, align 1
  %scevgep20.4.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 4
  %8655 = load i8, i8* %scevgep20.4.35, align 1
  %conv68.4.35 = zext i8 %8655 to i32
  %8656 = load i8, i8* %arrayidx70.35, align 1
  %conv71.4.35 = zext i8 %8656 to i32
  %xor72.4.35 = xor i32 %conv71.4.35, %conv68.4.35
  %conv73.4.35 = trunc i32 %xor72.4.35 to i8
  store i8 %conv73.4.35, i8* %arrayidx70.35, align 1
  %scevgep20.5.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 5
  %8657 = load i8, i8* %scevgep20.5.35, align 1
  %conv68.5.35 = zext i8 %8657 to i32
  %8658 = load i8, i8* %arrayidx70.35, align 1
  %conv71.5.35 = zext i8 %8658 to i32
  %xor72.5.35 = xor i32 %conv71.5.35, %conv68.5.35
  %conv73.5.35 = trunc i32 %xor72.5.35 to i8
  store i8 %conv73.5.35, i8* %arrayidx70.35, align 1
  %scevgep20.6.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 6
  %8659 = load i8, i8* %scevgep20.6.35, align 1
  %conv68.6.35 = zext i8 %8659 to i32
  %8660 = load i8, i8* %arrayidx70.35, align 1
  %conv71.6.35 = zext i8 %8660 to i32
  %xor72.6.35 = xor i32 %conv71.6.35, %conv68.6.35
  %conv73.6.35 = trunc i32 %xor72.6.35 to i8
  store i8 %conv73.6.35, i8* %arrayidx70.35, align 1
  %scevgep20.7.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 7
  %8661 = load i8, i8* %scevgep20.7.35, align 1
  %conv68.7.35 = zext i8 %8661 to i32
  %8662 = load i8, i8* %arrayidx70.35, align 1
  %conv71.7.35 = zext i8 %8662 to i32
  %xor72.7.35 = xor i32 %conv71.7.35, %conv68.7.35
  %conv73.7.35 = trunc i32 %xor72.7.35 to i8
  store i8 %conv73.7.35, i8* %arrayidx70.35, align 1
  %scevgep20.8.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 8
  %8663 = load i8, i8* %scevgep20.8.35, align 1
  %conv68.8.35 = zext i8 %8663 to i32
  %8664 = load i8, i8* %arrayidx70.35, align 1
  %conv71.8.35 = zext i8 %8664 to i32
  %xor72.8.35 = xor i32 %conv71.8.35, %conv68.8.35
  %conv73.8.35 = trunc i32 %xor72.8.35 to i8
  store i8 %conv73.8.35, i8* %arrayidx70.35, align 1
  %scevgep20.9.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 9
  %8665 = load i8, i8* %scevgep20.9.35, align 1
  %conv68.9.35 = zext i8 %8665 to i32
  %8666 = load i8, i8* %arrayidx70.35, align 1
  %conv71.9.35 = zext i8 %8666 to i32
  %xor72.9.35 = xor i32 %conv71.9.35, %conv68.9.35
  %conv73.9.35 = trunc i32 %xor72.9.35 to i8
  store i8 %conv73.9.35, i8* %arrayidx70.35, align 1
  %scevgep20.10.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 10
  %8667 = load i8, i8* %scevgep20.10.35, align 1
  %conv68.10.35 = zext i8 %8667 to i32
  %8668 = load i8, i8* %arrayidx70.35, align 1
  %conv71.10.35 = zext i8 %8668 to i32
  %xor72.10.35 = xor i32 %conv71.10.35, %conv68.10.35
  %conv73.10.35 = trunc i32 %xor72.10.35 to i8
  store i8 %conv73.10.35, i8* %arrayidx70.35, align 1
  %scevgep20.11.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 11
  %8669 = load i8, i8* %scevgep20.11.35, align 1
  %conv68.11.35 = zext i8 %8669 to i32
  %8670 = load i8, i8* %arrayidx70.35, align 1
  %conv71.11.35 = zext i8 %8670 to i32
  %xor72.11.35 = xor i32 %conv71.11.35, %conv68.11.35
  %conv73.11.35 = trunc i32 %xor72.11.35 to i8
  store i8 %conv73.11.35, i8* %arrayidx70.35, align 1
  %scevgep20.12.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 12
  %8671 = load i8, i8* %scevgep20.12.35, align 1
  %conv68.12.35 = zext i8 %8671 to i32
  %8672 = load i8, i8* %arrayidx70.35, align 1
  %conv71.12.35 = zext i8 %8672 to i32
  %xor72.12.35 = xor i32 %conv71.12.35, %conv68.12.35
  %conv73.12.35 = trunc i32 %xor72.12.35 to i8
  store i8 %conv73.12.35, i8* %arrayidx70.35, align 1
  %scevgep20.13.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 13
  %8673 = load i8, i8* %scevgep20.13.35, align 1
  %conv68.13.35 = zext i8 %8673 to i32
  %8674 = load i8, i8* %arrayidx70.35, align 1
  %conv71.13.35 = zext i8 %8674 to i32
  %xor72.13.35 = xor i32 %conv71.13.35, %conv68.13.35
  %conv73.13.35 = trunc i32 %xor72.13.35 to i8
  store i8 %conv73.13.35, i8* %arrayidx70.35, align 1
  %scevgep20.14.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 14
  %8675 = load i8, i8* %scevgep20.14.35, align 1
  %conv68.14.35 = zext i8 %8675 to i32
  %8676 = load i8, i8* %arrayidx70.35, align 1
  %conv71.14.35 = zext i8 %8676 to i32
  %xor72.14.35 = xor i32 %conv71.14.35, %conv68.14.35
  %conv73.14.35 = trunc i32 %xor72.14.35 to i8
  store i8 %conv73.14.35, i8* %arrayidx70.35, align 1
  %scevgep20.15.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 15
  %8677 = load i8, i8* %scevgep20.15.35, align 1
  %conv68.15.35 = zext i8 %8677 to i32
  %8678 = load i8, i8* %arrayidx70.35, align 1
  %conv71.15.35 = zext i8 %8678 to i32
  %xor72.15.35 = xor i32 %conv71.15.35, %conv68.15.35
  %conv73.15.35 = trunc i32 %xor72.15.35 to i8
  store i8 %conv73.15.35, i8* %arrayidx70.35, align 1
  %scevgep20.16.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 16
  %8679 = load i8, i8* %scevgep20.16.35, align 1
  %conv68.16.35 = zext i8 %8679 to i32
  %8680 = load i8, i8* %arrayidx70.35, align 1
  %conv71.16.35 = zext i8 %8680 to i32
  %xor72.16.35 = xor i32 %conv71.16.35, %conv68.16.35
  %conv73.16.35 = trunc i32 %xor72.16.35 to i8
  store i8 %conv73.16.35, i8* %arrayidx70.35, align 1
  %scevgep20.17.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 17
  %8681 = load i8, i8* %scevgep20.17.35, align 1
  %conv68.17.35 = zext i8 %8681 to i32
  %8682 = load i8, i8* %arrayidx70.35, align 1
  %conv71.17.35 = zext i8 %8682 to i32
  %xor72.17.35 = xor i32 %conv71.17.35, %conv68.17.35
  %conv73.17.35 = trunc i32 %xor72.17.35 to i8
  store i8 %conv73.17.35, i8* %arrayidx70.35, align 1
  %scevgep20.18.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 18
  %8683 = load i8, i8* %scevgep20.18.35, align 1
  %conv68.18.35 = zext i8 %8683 to i32
  %8684 = load i8, i8* %arrayidx70.35, align 1
  %conv71.18.35 = zext i8 %8684 to i32
  %xor72.18.35 = xor i32 %conv71.18.35, %conv68.18.35
  %conv73.18.35 = trunc i32 %xor72.18.35 to i8
  store i8 %conv73.18.35, i8* %arrayidx70.35, align 1
  %scevgep20.19.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 19
  %8685 = load i8, i8* %scevgep20.19.35, align 1
  %conv68.19.35 = zext i8 %8685 to i32
  %8686 = load i8, i8* %arrayidx70.35, align 1
  %conv71.19.35 = zext i8 %8686 to i32
  %xor72.19.35 = xor i32 %conv71.19.35, %conv68.19.35
  %conv73.19.35 = trunc i32 %xor72.19.35 to i8
  store i8 %conv73.19.35, i8* %arrayidx70.35, align 1
  %scevgep20.20.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 20
  %8687 = load i8, i8* %scevgep20.20.35, align 1
  %conv68.20.35 = zext i8 %8687 to i32
  %8688 = load i8, i8* %arrayidx70.35, align 1
  %conv71.20.35 = zext i8 %8688 to i32
  %xor72.20.35 = xor i32 %conv71.20.35, %conv68.20.35
  %conv73.20.35 = trunc i32 %xor72.20.35 to i8
  store i8 %conv73.20.35, i8* %arrayidx70.35, align 1
  %scevgep20.21.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 21
  %8689 = load i8, i8* %scevgep20.21.35, align 1
  %conv68.21.35 = zext i8 %8689 to i32
  %8690 = load i8, i8* %arrayidx70.35, align 1
  %conv71.21.35 = zext i8 %8690 to i32
  %xor72.21.35 = xor i32 %conv71.21.35, %conv68.21.35
  %conv73.21.35 = trunc i32 %xor72.21.35 to i8
  store i8 %conv73.21.35, i8* %arrayidx70.35, align 1
  %scevgep20.22.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 22
  %8691 = load i8, i8* %scevgep20.22.35, align 1
  %conv68.22.35 = zext i8 %8691 to i32
  %8692 = load i8, i8* %arrayidx70.35, align 1
  %conv71.22.35 = zext i8 %8692 to i32
  %xor72.22.35 = xor i32 %conv71.22.35, %conv68.22.35
  %conv73.22.35 = trunc i32 %xor72.22.35 to i8
  store i8 %conv73.22.35, i8* %arrayidx70.35, align 1
  %scevgep20.23.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 23
  %8693 = load i8, i8* %scevgep20.23.35, align 1
  %conv68.23.35 = zext i8 %8693 to i32
  %8694 = load i8, i8* %arrayidx70.35, align 1
  %conv71.23.35 = zext i8 %8694 to i32
  %xor72.23.35 = xor i32 %conv71.23.35, %conv68.23.35
  %conv73.23.35 = trunc i32 %xor72.23.35 to i8
  store i8 %conv73.23.35, i8* %arrayidx70.35, align 1
  %scevgep20.24.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 24
  %8695 = load i8, i8* %scevgep20.24.35, align 1
  %conv68.24.35 = zext i8 %8695 to i32
  %8696 = load i8, i8* %arrayidx70.35, align 1
  %conv71.24.35 = zext i8 %8696 to i32
  %xor72.24.35 = xor i32 %conv71.24.35, %conv68.24.35
  %conv73.24.35 = trunc i32 %xor72.24.35 to i8
  store i8 %conv73.24.35, i8* %arrayidx70.35, align 1
  %scevgep20.25.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 25
  %8697 = load i8, i8* %scevgep20.25.35, align 1
  %conv68.25.35 = zext i8 %8697 to i32
  %8698 = load i8, i8* %arrayidx70.35, align 1
  %conv71.25.35 = zext i8 %8698 to i32
  %xor72.25.35 = xor i32 %conv71.25.35, %conv68.25.35
  %conv73.25.35 = trunc i32 %xor72.25.35 to i8
  store i8 %conv73.25.35, i8* %arrayidx70.35, align 1
  %scevgep20.26.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 26
  %8699 = load i8, i8* %scevgep20.26.35, align 1
  %conv68.26.35 = zext i8 %8699 to i32
  %8700 = load i8, i8* %arrayidx70.35, align 1
  %conv71.26.35 = zext i8 %8700 to i32
  %xor72.26.35 = xor i32 %conv71.26.35, %conv68.26.35
  %conv73.26.35 = trunc i32 %xor72.26.35 to i8
  store i8 %conv73.26.35, i8* %arrayidx70.35, align 1
  %scevgep20.27.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 27
  %8701 = load i8, i8* %scevgep20.27.35, align 1
  %conv68.27.35 = zext i8 %8701 to i32
  %8702 = load i8, i8* %arrayidx70.35, align 1
  %conv71.27.35 = zext i8 %8702 to i32
  %xor72.27.35 = xor i32 %conv71.27.35, %conv68.27.35
  %conv73.27.35 = trunc i32 %xor72.27.35 to i8
  store i8 %conv73.27.35, i8* %arrayidx70.35, align 1
  %scevgep20.28.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 28
  %8703 = load i8, i8* %scevgep20.28.35, align 1
  %conv68.28.35 = zext i8 %8703 to i32
  %8704 = load i8, i8* %arrayidx70.35, align 1
  %conv71.28.35 = zext i8 %8704 to i32
  %xor72.28.35 = xor i32 %conv71.28.35, %conv68.28.35
  %conv73.28.35 = trunc i32 %xor72.28.35 to i8
  store i8 %conv73.28.35, i8* %arrayidx70.35, align 1
  %scevgep20.29.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 29
  %8705 = load i8, i8* %scevgep20.29.35, align 1
  %conv68.29.35 = zext i8 %8705 to i32
  %8706 = load i8, i8* %arrayidx70.35, align 1
  %conv71.29.35 = zext i8 %8706 to i32
  %xor72.29.35 = xor i32 %conv71.29.35, %conv68.29.35
  %conv73.29.35 = trunc i32 %xor72.29.35 to i8
  store i8 %conv73.29.35, i8* %arrayidx70.35, align 1
  %scevgep20.30.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 30
  %8707 = load i8, i8* %scevgep20.30.35, align 1
  %conv68.30.35 = zext i8 %8707 to i32
  %8708 = load i8, i8* %arrayidx70.35, align 1
  %conv71.30.35 = zext i8 %8708 to i32
  %xor72.30.35 = xor i32 %conv71.30.35, %conv68.30.35
  %conv73.30.35 = trunc i32 %xor72.30.35 to i8
  store i8 %conv73.30.35, i8* %arrayidx70.35, align 1
  %scevgep20.31.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 31
  %8709 = load i8, i8* %scevgep20.31.35, align 1
  %conv68.31.35 = zext i8 %8709 to i32
  %8710 = load i8, i8* %arrayidx70.35, align 1
  %conv71.31.35 = zext i8 %8710 to i32
  %xor72.31.35 = xor i32 %conv71.31.35, %conv68.31.35
  %conv73.31.35 = trunc i32 %xor72.31.35 to i8
  store i8 %conv73.31.35, i8* %arrayidx70.35, align 1
  %scevgep20.32.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 32
  %8711 = load i8, i8* %scevgep20.32.35, align 1
  %conv68.32.35 = zext i8 %8711 to i32
  %8712 = load i8, i8* %arrayidx70.35, align 1
  %conv71.32.35 = zext i8 %8712 to i32
  %xor72.32.35 = xor i32 %conv71.32.35, %conv68.32.35
  %conv73.32.35 = trunc i32 %xor72.32.35 to i8
  store i8 %conv73.32.35, i8* %arrayidx70.35, align 1
  %scevgep20.33.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 33
  %8713 = load i8, i8* %scevgep20.33.35, align 1
  %conv68.33.35 = zext i8 %8713 to i32
  %8714 = load i8, i8* %arrayidx70.35, align 1
  %conv71.33.35 = zext i8 %8714 to i32
  %xor72.33.35 = xor i32 %conv71.33.35, %conv68.33.35
  %conv73.33.35 = trunc i32 %xor72.33.35 to i8
  store i8 %conv73.33.35, i8* %arrayidx70.35, align 1
  %scevgep20.34.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 34
  %8715 = load i8, i8* %scevgep20.34.35, align 1
  %conv68.34.35 = zext i8 %8715 to i32
  %8716 = load i8, i8* %arrayidx70.35, align 1
  %conv71.34.35 = zext i8 %8716 to i32
  %xor72.34.35 = xor i32 %conv71.34.35, %conv68.34.35
  %conv73.34.35 = trunc i32 %xor72.34.35 to i8
  store i8 %conv73.34.35, i8* %arrayidx70.35, align 1
  %scevgep20.36.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 36
  %8717 = load i8, i8* %scevgep20.36.35, align 1
  %conv68.36.35 = zext i8 %8717 to i32
  %8718 = load i8, i8* %arrayidx70.35, align 1
  %conv71.36.35 = zext i8 %8718 to i32
  %xor72.36.35 = xor i32 %conv71.36.35, %conv68.36.35
  %conv73.36.35 = trunc i32 %xor72.36.35 to i8
  store i8 %conv73.36.35, i8* %arrayidx70.35, align 1
  %scevgep20.37.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 37
  %8719 = load i8, i8* %scevgep20.37.35, align 1
  %conv68.37.35 = zext i8 %8719 to i32
  %8720 = load i8, i8* %arrayidx70.35, align 1
  %conv71.37.35 = zext i8 %8720 to i32
  %xor72.37.35 = xor i32 %conv71.37.35, %conv68.37.35
  %conv73.37.35 = trunc i32 %xor72.37.35 to i8
  store i8 %conv73.37.35, i8* %arrayidx70.35, align 1
  %scevgep20.38.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 38
  %8721 = load i8, i8* %scevgep20.38.35, align 1
  %conv68.38.35 = zext i8 %8721 to i32
  %8722 = load i8, i8* %arrayidx70.35, align 1
  %conv71.38.35 = zext i8 %8722 to i32
  %xor72.38.35 = xor i32 %conv71.38.35, %conv68.38.35
  %conv73.38.35 = trunc i32 %xor72.38.35 to i8
  store i8 %conv73.38.35, i8* %arrayidx70.35, align 1
  %scevgep20.39.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 39
  %8723 = load i8, i8* %scevgep20.39.35, align 1
  %conv68.39.35 = zext i8 %8723 to i32
  %8724 = load i8, i8* %arrayidx70.35, align 1
  %conv71.39.35 = zext i8 %8724 to i32
  %xor72.39.35 = xor i32 %conv71.39.35, %conv68.39.35
  %conv73.39.35 = trunc i32 %xor72.39.35 to i8
  store i8 %conv73.39.35, i8* %arrayidx70.35, align 1
  %scevgep20.40.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 0, i64 40
  %8725 = load i8, i8* %scevgep20.40.35, align 1
  %conv68.40.35 = zext i8 %8725 to i32
  %8726 = load i8, i8* %arrayidx70.35, align 1
  %conv71.40.35 = zext i8 %8726 to i32
  %xor72.40.35 = xor i32 %conv71.40.35, %conv68.40.35
  %conv73.40.35 = trunc i32 %xor72.40.35 to i8
  store i8 %conv73.40.35, i8* %arrayidx70.35, align 1
  %scevgep19.35 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8644, i64 0, i64 1, i64 0
  %8727 = bitcast i8* %scevgep19.35 to [41 x [41 x i8]]*
  %arrayidx51.36 = getelementptr inbounds i8, i8* %a, i64 36
  %8728 = load i8, i8* %arrayidx51.36, align 1
  %arrayidx53.36 = getelementptr inbounds i8, i8* %b, i64 36
  %8729 = load i8, i8* %arrayidx53.36, align 1
  %call54.36 = call zeroext i8 @mult(i8 zeroext %8728, i8 zeroext %8729)
  %arrayidx56.36 = getelementptr inbounds i8, i8* %c, i64 36
  store i8 %call54.36, i8* %arrayidx56.36, align 1
  %arrayidx70.36 = getelementptr inbounds i8, i8* %c, i64 36
  %scevgep20.36404 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 0
  %8730 = load i8, i8* %scevgep20.36404, align 1
  %conv68.36405 = zext i8 %8730 to i32
  %8731 = load i8, i8* %arrayidx70.36, align 1
  %conv71.36406 = zext i8 %8731 to i32
  %xor72.36407 = xor i32 %conv71.36406, %conv68.36405
  %conv73.36408 = trunc i32 %xor72.36407 to i8
  store i8 %conv73.36408, i8* %arrayidx70.36, align 1
  %scevgep20.1.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 1
  %8732 = load i8, i8* %scevgep20.1.36, align 1
  %conv68.1.36 = zext i8 %8732 to i32
  %8733 = load i8, i8* %arrayidx70.36, align 1
  %conv71.1.36 = zext i8 %8733 to i32
  %xor72.1.36 = xor i32 %conv71.1.36, %conv68.1.36
  %conv73.1.36 = trunc i32 %xor72.1.36 to i8
  store i8 %conv73.1.36, i8* %arrayidx70.36, align 1
  %scevgep20.2.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 2
  %8734 = load i8, i8* %scevgep20.2.36, align 1
  %conv68.2.36 = zext i8 %8734 to i32
  %8735 = load i8, i8* %arrayidx70.36, align 1
  %conv71.2.36 = zext i8 %8735 to i32
  %xor72.2.36 = xor i32 %conv71.2.36, %conv68.2.36
  %conv73.2.36 = trunc i32 %xor72.2.36 to i8
  store i8 %conv73.2.36, i8* %arrayidx70.36, align 1
  %scevgep20.3.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 3
  %8736 = load i8, i8* %scevgep20.3.36, align 1
  %conv68.3.36 = zext i8 %8736 to i32
  %8737 = load i8, i8* %arrayidx70.36, align 1
  %conv71.3.36 = zext i8 %8737 to i32
  %xor72.3.36 = xor i32 %conv71.3.36, %conv68.3.36
  %conv73.3.36 = trunc i32 %xor72.3.36 to i8
  store i8 %conv73.3.36, i8* %arrayidx70.36, align 1
  %scevgep20.4.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 4
  %8738 = load i8, i8* %scevgep20.4.36, align 1
  %conv68.4.36 = zext i8 %8738 to i32
  %8739 = load i8, i8* %arrayidx70.36, align 1
  %conv71.4.36 = zext i8 %8739 to i32
  %xor72.4.36 = xor i32 %conv71.4.36, %conv68.4.36
  %conv73.4.36 = trunc i32 %xor72.4.36 to i8
  store i8 %conv73.4.36, i8* %arrayidx70.36, align 1
  %scevgep20.5.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 5
  %8740 = load i8, i8* %scevgep20.5.36, align 1
  %conv68.5.36 = zext i8 %8740 to i32
  %8741 = load i8, i8* %arrayidx70.36, align 1
  %conv71.5.36 = zext i8 %8741 to i32
  %xor72.5.36 = xor i32 %conv71.5.36, %conv68.5.36
  %conv73.5.36 = trunc i32 %xor72.5.36 to i8
  store i8 %conv73.5.36, i8* %arrayidx70.36, align 1
  %scevgep20.6.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 6
  %8742 = load i8, i8* %scevgep20.6.36, align 1
  %conv68.6.36 = zext i8 %8742 to i32
  %8743 = load i8, i8* %arrayidx70.36, align 1
  %conv71.6.36 = zext i8 %8743 to i32
  %xor72.6.36 = xor i32 %conv71.6.36, %conv68.6.36
  %conv73.6.36 = trunc i32 %xor72.6.36 to i8
  store i8 %conv73.6.36, i8* %arrayidx70.36, align 1
  %scevgep20.7.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 7
  %8744 = load i8, i8* %scevgep20.7.36, align 1
  %conv68.7.36 = zext i8 %8744 to i32
  %8745 = load i8, i8* %arrayidx70.36, align 1
  %conv71.7.36 = zext i8 %8745 to i32
  %xor72.7.36 = xor i32 %conv71.7.36, %conv68.7.36
  %conv73.7.36 = trunc i32 %xor72.7.36 to i8
  store i8 %conv73.7.36, i8* %arrayidx70.36, align 1
  %scevgep20.8.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 8
  %8746 = load i8, i8* %scevgep20.8.36, align 1
  %conv68.8.36 = zext i8 %8746 to i32
  %8747 = load i8, i8* %arrayidx70.36, align 1
  %conv71.8.36 = zext i8 %8747 to i32
  %xor72.8.36 = xor i32 %conv71.8.36, %conv68.8.36
  %conv73.8.36 = trunc i32 %xor72.8.36 to i8
  store i8 %conv73.8.36, i8* %arrayidx70.36, align 1
  %scevgep20.9.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 9
  %8748 = load i8, i8* %scevgep20.9.36, align 1
  %conv68.9.36 = zext i8 %8748 to i32
  %8749 = load i8, i8* %arrayidx70.36, align 1
  %conv71.9.36 = zext i8 %8749 to i32
  %xor72.9.36 = xor i32 %conv71.9.36, %conv68.9.36
  %conv73.9.36 = trunc i32 %xor72.9.36 to i8
  store i8 %conv73.9.36, i8* %arrayidx70.36, align 1
  %scevgep20.10.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 10
  %8750 = load i8, i8* %scevgep20.10.36, align 1
  %conv68.10.36 = zext i8 %8750 to i32
  %8751 = load i8, i8* %arrayidx70.36, align 1
  %conv71.10.36 = zext i8 %8751 to i32
  %xor72.10.36 = xor i32 %conv71.10.36, %conv68.10.36
  %conv73.10.36 = trunc i32 %xor72.10.36 to i8
  store i8 %conv73.10.36, i8* %arrayidx70.36, align 1
  %scevgep20.11.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 11
  %8752 = load i8, i8* %scevgep20.11.36, align 1
  %conv68.11.36 = zext i8 %8752 to i32
  %8753 = load i8, i8* %arrayidx70.36, align 1
  %conv71.11.36 = zext i8 %8753 to i32
  %xor72.11.36 = xor i32 %conv71.11.36, %conv68.11.36
  %conv73.11.36 = trunc i32 %xor72.11.36 to i8
  store i8 %conv73.11.36, i8* %arrayidx70.36, align 1
  %scevgep20.12.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 12
  %8754 = load i8, i8* %scevgep20.12.36, align 1
  %conv68.12.36 = zext i8 %8754 to i32
  %8755 = load i8, i8* %arrayidx70.36, align 1
  %conv71.12.36 = zext i8 %8755 to i32
  %xor72.12.36 = xor i32 %conv71.12.36, %conv68.12.36
  %conv73.12.36 = trunc i32 %xor72.12.36 to i8
  store i8 %conv73.12.36, i8* %arrayidx70.36, align 1
  %scevgep20.13.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 13
  %8756 = load i8, i8* %scevgep20.13.36, align 1
  %conv68.13.36 = zext i8 %8756 to i32
  %8757 = load i8, i8* %arrayidx70.36, align 1
  %conv71.13.36 = zext i8 %8757 to i32
  %xor72.13.36 = xor i32 %conv71.13.36, %conv68.13.36
  %conv73.13.36 = trunc i32 %xor72.13.36 to i8
  store i8 %conv73.13.36, i8* %arrayidx70.36, align 1
  %scevgep20.14.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 14
  %8758 = load i8, i8* %scevgep20.14.36, align 1
  %conv68.14.36 = zext i8 %8758 to i32
  %8759 = load i8, i8* %arrayidx70.36, align 1
  %conv71.14.36 = zext i8 %8759 to i32
  %xor72.14.36 = xor i32 %conv71.14.36, %conv68.14.36
  %conv73.14.36 = trunc i32 %xor72.14.36 to i8
  store i8 %conv73.14.36, i8* %arrayidx70.36, align 1
  %scevgep20.15.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 15
  %8760 = load i8, i8* %scevgep20.15.36, align 1
  %conv68.15.36 = zext i8 %8760 to i32
  %8761 = load i8, i8* %arrayidx70.36, align 1
  %conv71.15.36 = zext i8 %8761 to i32
  %xor72.15.36 = xor i32 %conv71.15.36, %conv68.15.36
  %conv73.15.36 = trunc i32 %xor72.15.36 to i8
  store i8 %conv73.15.36, i8* %arrayidx70.36, align 1
  %scevgep20.16.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 16
  %8762 = load i8, i8* %scevgep20.16.36, align 1
  %conv68.16.36 = zext i8 %8762 to i32
  %8763 = load i8, i8* %arrayidx70.36, align 1
  %conv71.16.36 = zext i8 %8763 to i32
  %xor72.16.36 = xor i32 %conv71.16.36, %conv68.16.36
  %conv73.16.36 = trunc i32 %xor72.16.36 to i8
  store i8 %conv73.16.36, i8* %arrayidx70.36, align 1
  %scevgep20.17.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 17
  %8764 = load i8, i8* %scevgep20.17.36, align 1
  %conv68.17.36 = zext i8 %8764 to i32
  %8765 = load i8, i8* %arrayidx70.36, align 1
  %conv71.17.36 = zext i8 %8765 to i32
  %xor72.17.36 = xor i32 %conv71.17.36, %conv68.17.36
  %conv73.17.36 = trunc i32 %xor72.17.36 to i8
  store i8 %conv73.17.36, i8* %arrayidx70.36, align 1
  %scevgep20.18.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 18
  %8766 = load i8, i8* %scevgep20.18.36, align 1
  %conv68.18.36 = zext i8 %8766 to i32
  %8767 = load i8, i8* %arrayidx70.36, align 1
  %conv71.18.36 = zext i8 %8767 to i32
  %xor72.18.36 = xor i32 %conv71.18.36, %conv68.18.36
  %conv73.18.36 = trunc i32 %xor72.18.36 to i8
  store i8 %conv73.18.36, i8* %arrayidx70.36, align 1
  %scevgep20.19.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 19
  %8768 = load i8, i8* %scevgep20.19.36, align 1
  %conv68.19.36 = zext i8 %8768 to i32
  %8769 = load i8, i8* %arrayidx70.36, align 1
  %conv71.19.36 = zext i8 %8769 to i32
  %xor72.19.36 = xor i32 %conv71.19.36, %conv68.19.36
  %conv73.19.36 = trunc i32 %xor72.19.36 to i8
  store i8 %conv73.19.36, i8* %arrayidx70.36, align 1
  %scevgep20.20.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 20
  %8770 = load i8, i8* %scevgep20.20.36, align 1
  %conv68.20.36 = zext i8 %8770 to i32
  %8771 = load i8, i8* %arrayidx70.36, align 1
  %conv71.20.36 = zext i8 %8771 to i32
  %xor72.20.36 = xor i32 %conv71.20.36, %conv68.20.36
  %conv73.20.36 = trunc i32 %xor72.20.36 to i8
  store i8 %conv73.20.36, i8* %arrayidx70.36, align 1
  %scevgep20.21.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 21
  %8772 = load i8, i8* %scevgep20.21.36, align 1
  %conv68.21.36 = zext i8 %8772 to i32
  %8773 = load i8, i8* %arrayidx70.36, align 1
  %conv71.21.36 = zext i8 %8773 to i32
  %xor72.21.36 = xor i32 %conv71.21.36, %conv68.21.36
  %conv73.21.36 = trunc i32 %xor72.21.36 to i8
  store i8 %conv73.21.36, i8* %arrayidx70.36, align 1
  %scevgep20.22.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 22
  %8774 = load i8, i8* %scevgep20.22.36, align 1
  %conv68.22.36 = zext i8 %8774 to i32
  %8775 = load i8, i8* %arrayidx70.36, align 1
  %conv71.22.36 = zext i8 %8775 to i32
  %xor72.22.36 = xor i32 %conv71.22.36, %conv68.22.36
  %conv73.22.36 = trunc i32 %xor72.22.36 to i8
  store i8 %conv73.22.36, i8* %arrayidx70.36, align 1
  %scevgep20.23.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 23
  %8776 = load i8, i8* %scevgep20.23.36, align 1
  %conv68.23.36 = zext i8 %8776 to i32
  %8777 = load i8, i8* %arrayidx70.36, align 1
  %conv71.23.36 = zext i8 %8777 to i32
  %xor72.23.36 = xor i32 %conv71.23.36, %conv68.23.36
  %conv73.23.36 = trunc i32 %xor72.23.36 to i8
  store i8 %conv73.23.36, i8* %arrayidx70.36, align 1
  %scevgep20.24.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 24
  %8778 = load i8, i8* %scevgep20.24.36, align 1
  %conv68.24.36 = zext i8 %8778 to i32
  %8779 = load i8, i8* %arrayidx70.36, align 1
  %conv71.24.36 = zext i8 %8779 to i32
  %xor72.24.36 = xor i32 %conv71.24.36, %conv68.24.36
  %conv73.24.36 = trunc i32 %xor72.24.36 to i8
  store i8 %conv73.24.36, i8* %arrayidx70.36, align 1
  %scevgep20.25.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 25
  %8780 = load i8, i8* %scevgep20.25.36, align 1
  %conv68.25.36 = zext i8 %8780 to i32
  %8781 = load i8, i8* %arrayidx70.36, align 1
  %conv71.25.36 = zext i8 %8781 to i32
  %xor72.25.36 = xor i32 %conv71.25.36, %conv68.25.36
  %conv73.25.36 = trunc i32 %xor72.25.36 to i8
  store i8 %conv73.25.36, i8* %arrayidx70.36, align 1
  %scevgep20.26.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 26
  %8782 = load i8, i8* %scevgep20.26.36, align 1
  %conv68.26.36 = zext i8 %8782 to i32
  %8783 = load i8, i8* %arrayidx70.36, align 1
  %conv71.26.36 = zext i8 %8783 to i32
  %xor72.26.36 = xor i32 %conv71.26.36, %conv68.26.36
  %conv73.26.36 = trunc i32 %xor72.26.36 to i8
  store i8 %conv73.26.36, i8* %arrayidx70.36, align 1
  %scevgep20.27.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 27
  %8784 = load i8, i8* %scevgep20.27.36, align 1
  %conv68.27.36 = zext i8 %8784 to i32
  %8785 = load i8, i8* %arrayidx70.36, align 1
  %conv71.27.36 = zext i8 %8785 to i32
  %xor72.27.36 = xor i32 %conv71.27.36, %conv68.27.36
  %conv73.27.36 = trunc i32 %xor72.27.36 to i8
  store i8 %conv73.27.36, i8* %arrayidx70.36, align 1
  %scevgep20.28.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 28
  %8786 = load i8, i8* %scevgep20.28.36, align 1
  %conv68.28.36 = zext i8 %8786 to i32
  %8787 = load i8, i8* %arrayidx70.36, align 1
  %conv71.28.36 = zext i8 %8787 to i32
  %xor72.28.36 = xor i32 %conv71.28.36, %conv68.28.36
  %conv73.28.36 = trunc i32 %xor72.28.36 to i8
  store i8 %conv73.28.36, i8* %arrayidx70.36, align 1
  %scevgep20.29.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 29
  %8788 = load i8, i8* %scevgep20.29.36, align 1
  %conv68.29.36 = zext i8 %8788 to i32
  %8789 = load i8, i8* %arrayidx70.36, align 1
  %conv71.29.36 = zext i8 %8789 to i32
  %xor72.29.36 = xor i32 %conv71.29.36, %conv68.29.36
  %conv73.29.36 = trunc i32 %xor72.29.36 to i8
  store i8 %conv73.29.36, i8* %arrayidx70.36, align 1
  %scevgep20.30.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 30
  %8790 = load i8, i8* %scevgep20.30.36, align 1
  %conv68.30.36 = zext i8 %8790 to i32
  %8791 = load i8, i8* %arrayidx70.36, align 1
  %conv71.30.36 = zext i8 %8791 to i32
  %xor72.30.36 = xor i32 %conv71.30.36, %conv68.30.36
  %conv73.30.36 = trunc i32 %xor72.30.36 to i8
  store i8 %conv73.30.36, i8* %arrayidx70.36, align 1
  %scevgep20.31.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 31
  %8792 = load i8, i8* %scevgep20.31.36, align 1
  %conv68.31.36 = zext i8 %8792 to i32
  %8793 = load i8, i8* %arrayidx70.36, align 1
  %conv71.31.36 = zext i8 %8793 to i32
  %xor72.31.36 = xor i32 %conv71.31.36, %conv68.31.36
  %conv73.31.36 = trunc i32 %xor72.31.36 to i8
  store i8 %conv73.31.36, i8* %arrayidx70.36, align 1
  %scevgep20.32.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 32
  %8794 = load i8, i8* %scevgep20.32.36, align 1
  %conv68.32.36 = zext i8 %8794 to i32
  %8795 = load i8, i8* %arrayidx70.36, align 1
  %conv71.32.36 = zext i8 %8795 to i32
  %xor72.32.36 = xor i32 %conv71.32.36, %conv68.32.36
  %conv73.32.36 = trunc i32 %xor72.32.36 to i8
  store i8 %conv73.32.36, i8* %arrayidx70.36, align 1
  %scevgep20.33.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 33
  %8796 = load i8, i8* %scevgep20.33.36, align 1
  %conv68.33.36 = zext i8 %8796 to i32
  %8797 = load i8, i8* %arrayidx70.36, align 1
  %conv71.33.36 = zext i8 %8797 to i32
  %xor72.33.36 = xor i32 %conv71.33.36, %conv68.33.36
  %conv73.33.36 = trunc i32 %xor72.33.36 to i8
  store i8 %conv73.33.36, i8* %arrayidx70.36, align 1
  %scevgep20.34.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 34
  %8798 = load i8, i8* %scevgep20.34.36, align 1
  %conv68.34.36 = zext i8 %8798 to i32
  %8799 = load i8, i8* %arrayidx70.36, align 1
  %conv71.34.36 = zext i8 %8799 to i32
  %xor72.34.36 = xor i32 %conv71.34.36, %conv68.34.36
  %conv73.34.36 = trunc i32 %xor72.34.36 to i8
  store i8 %conv73.34.36, i8* %arrayidx70.36, align 1
  %scevgep20.35.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 35
  %8800 = load i8, i8* %scevgep20.35.36, align 1
  %conv68.35.36 = zext i8 %8800 to i32
  %8801 = load i8, i8* %arrayidx70.36, align 1
  %conv71.35.36 = zext i8 %8801 to i32
  %xor72.35.36 = xor i32 %conv71.35.36, %conv68.35.36
  %conv73.35.36 = trunc i32 %xor72.35.36 to i8
  store i8 %conv73.35.36, i8* %arrayidx70.36, align 1
  %scevgep20.37.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 37
  %8802 = load i8, i8* %scevgep20.37.36, align 1
  %conv68.37.36 = zext i8 %8802 to i32
  %8803 = load i8, i8* %arrayidx70.36, align 1
  %conv71.37.36 = zext i8 %8803 to i32
  %xor72.37.36 = xor i32 %conv71.37.36, %conv68.37.36
  %conv73.37.36 = trunc i32 %xor72.37.36 to i8
  store i8 %conv73.37.36, i8* %arrayidx70.36, align 1
  %scevgep20.38.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 38
  %8804 = load i8, i8* %scevgep20.38.36, align 1
  %conv68.38.36 = zext i8 %8804 to i32
  %8805 = load i8, i8* %arrayidx70.36, align 1
  %conv71.38.36 = zext i8 %8805 to i32
  %xor72.38.36 = xor i32 %conv71.38.36, %conv68.38.36
  %conv73.38.36 = trunc i32 %xor72.38.36 to i8
  store i8 %conv73.38.36, i8* %arrayidx70.36, align 1
  %scevgep20.39.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 39
  %8806 = load i8, i8* %scevgep20.39.36, align 1
  %conv68.39.36 = zext i8 %8806 to i32
  %8807 = load i8, i8* %arrayidx70.36, align 1
  %conv71.39.36 = zext i8 %8807 to i32
  %xor72.39.36 = xor i32 %conv71.39.36, %conv68.39.36
  %conv73.39.36 = trunc i32 %xor72.39.36 to i8
  store i8 %conv73.39.36, i8* %arrayidx70.36, align 1
  %scevgep20.40.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 0, i64 40
  %8808 = load i8, i8* %scevgep20.40.36, align 1
  %conv68.40.36 = zext i8 %8808 to i32
  %8809 = load i8, i8* %arrayidx70.36, align 1
  %conv71.40.36 = zext i8 %8809 to i32
  %xor72.40.36 = xor i32 %conv71.40.36, %conv68.40.36
  %conv73.40.36 = trunc i32 %xor72.40.36 to i8
  store i8 %conv73.40.36, i8* %arrayidx70.36, align 1
  %scevgep19.36 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8727, i64 0, i64 1, i64 0
  %8810 = bitcast i8* %scevgep19.36 to [41 x [41 x i8]]*
  %arrayidx51.37 = getelementptr inbounds i8, i8* %a, i64 37
  %8811 = load i8, i8* %arrayidx51.37, align 1
  %arrayidx53.37 = getelementptr inbounds i8, i8* %b, i64 37
  %8812 = load i8, i8* %arrayidx53.37, align 1
  %call54.37 = call zeroext i8 @mult(i8 zeroext %8811, i8 zeroext %8812)
  %arrayidx56.37 = getelementptr inbounds i8, i8* %c, i64 37
  store i8 %call54.37, i8* %arrayidx56.37, align 1
  %arrayidx70.37 = getelementptr inbounds i8, i8* %c, i64 37
  %scevgep20.37414 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 0
  %8813 = load i8, i8* %scevgep20.37414, align 1
  %conv68.37415 = zext i8 %8813 to i32
  %8814 = load i8, i8* %arrayidx70.37, align 1
  %conv71.37416 = zext i8 %8814 to i32
  %xor72.37417 = xor i32 %conv71.37416, %conv68.37415
  %conv73.37418 = trunc i32 %xor72.37417 to i8
  store i8 %conv73.37418, i8* %arrayidx70.37, align 1
  %scevgep20.1.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 1
  %8815 = load i8, i8* %scevgep20.1.37, align 1
  %conv68.1.37 = zext i8 %8815 to i32
  %8816 = load i8, i8* %arrayidx70.37, align 1
  %conv71.1.37 = zext i8 %8816 to i32
  %xor72.1.37 = xor i32 %conv71.1.37, %conv68.1.37
  %conv73.1.37 = trunc i32 %xor72.1.37 to i8
  store i8 %conv73.1.37, i8* %arrayidx70.37, align 1
  %scevgep20.2.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 2
  %8817 = load i8, i8* %scevgep20.2.37, align 1
  %conv68.2.37 = zext i8 %8817 to i32
  %8818 = load i8, i8* %arrayidx70.37, align 1
  %conv71.2.37 = zext i8 %8818 to i32
  %xor72.2.37 = xor i32 %conv71.2.37, %conv68.2.37
  %conv73.2.37 = trunc i32 %xor72.2.37 to i8
  store i8 %conv73.2.37, i8* %arrayidx70.37, align 1
  %scevgep20.3.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 3
  %8819 = load i8, i8* %scevgep20.3.37, align 1
  %conv68.3.37 = zext i8 %8819 to i32
  %8820 = load i8, i8* %arrayidx70.37, align 1
  %conv71.3.37 = zext i8 %8820 to i32
  %xor72.3.37 = xor i32 %conv71.3.37, %conv68.3.37
  %conv73.3.37 = trunc i32 %xor72.3.37 to i8
  store i8 %conv73.3.37, i8* %arrayidx70.37, align 1
  %scevgep20.4.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 4
  %8821 = load i8, i8* %scevgep20.4.37, align 1
  %conv68.4.37 = zext i8 %8821 to i32
  %8822 = load i8, i8* %arrayidx70.37, align 1
  %conv71.4.37 = zext i8 %8822 to i32
  %xor72.4.37 = xor i32 %conv71.4.37, %conv68.4.37
  %conv73.4.37 = trunc i32 %xor72.4.37 to i8
  store i8 %conv73.4.37, i8* %arrayidx70.37, align 1
  %scevgep20.5.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 5
  %8823 = load i8, i8* %scevgep20.5.37, align 1
  %conv68.5.37 = zext i8 %8823 to i32
  %8824 = load i8, i8* %arrayidx70.37, align 1
  %conv71.5.37 = zext i8 %8824 to i32
  %xor72.5.37 = xor i32 %conv71.5.37, %conv68.5.37
  %conv73.5.37 = trunc i32 %xor72.5.37 to i8
  store i8 %conv73.5.37, i8* %arrayidx70.37, align 1
  %scevgep20.6.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 6
  %8825 = load i8, i8* %scevgep20.6.37, align 1
  %conv68.6.37 = zext i8 %8825 to i32
  %8826 = load i8, i8* %arrayidx70.37, align 1
  %conv71.6.37 = zext i8 %8826 to i32
  %xor72.6.37 = xor i32 %conv71.6.37, %conv68.6.37
  %conv73.6.37 = trunc i32 %xor72.6.37 to i8
  store i8 %conv73.6.37, i8* %arrayidx70.37, align 1
  %scevgep20.7.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 7
  %8827 = load i8, i8* %scevgep20.7.37, align 1
  %conv68.7.37 = zext i8 %8827 to i32
  %8828 = load i8, i8* %arrayidx70.37, align 1
  %conv71.7.37 = zext i8 %8828 to i32
  %xor72.7.37 = xor i32 %conv71.7.37, %conv68.7.37
  %conv73.7.37 = trunc i32 %xor72.7.37 to i8
  store i8 %conv73.7.37, i8* %arrayidx70.37, align 1
  %scevgep20.8.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 8
  %8829 = load i8, i8* %scevgep20.8.37, align 1
  %conv68.8.37 = zext i8 %8829 to i32
  %8830 = load i8, i8* %arrayidx70.37, align 1
  %conv71.8.37 = zext i8 %8830 to i32
  %xor72.8.37 = xor i32 %conv71.8.37, %conv68.8.37
  %conv73.8.37 = trunc i32 %xor72.8.37 to i8
  store i8 %conv73.8.37, i8* %arrayidx70.37, align 1
  %scevgep20.9.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 9
  %8831 = load i8, i8* %scevgep20.9.37, align 1
  %conv68.9.37 = zext i8 %8831 to i32
  %8832 = load i8, i8* %arrayidx70.37, align 1
  %conv71.9.37 = zext i8 %8832 to i32
  %xor72.9.37 = xor i32 %conv71.9.37, %conv68.9.37
  %conv73.9.37 = trunc i32 %xor72.9.37 to i8
  store i8 %conv73.9.37, i8* %arrayidx70.37, align 1
  %scevgep20.10.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 10
  %8833 = load i8, i8* %scevgep20.10.37, align 1
  %conv68.10.37 = zext i8 %8833 to i32
  %8834 = load i8, i8* %arrayidx70.37, align 1
  %conv71.10.37 = zext i8 %8834 to i32
  %xor72.10.37 = xor i32 %conv71.10.37, %conv68.10.37
  %conv73.10.37 = trunc i32 %xor72.10.37 to i8
  store i8 %conv73.10.37, i8* %arrayidx70.37, align 1
  %scevgep20.11.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 11
  %8835 = load i8, i8* %scevgep20.11.37, align 1
  %conv68.11.37 = zext i8 %8835 to i32
  %8836 = load i8, i8* %arrayidx70.37, align 1
  %conv71.11.37 = zext i8 %8836 to i32
  %xor72.11.37 = xor i32 %conv71.11.37, %conv68.11.37
  %conv73.11.37 = trunc i32 %xor72.11.37 to i8
  store i8 %conv73.11.37, i8* %arrayidx70.37, align 1
  %scevgep20.12.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 12
  %8837 = load i8, i8* %scevgep20.12.37, align 1
  %conv68.12.37 = zext i8 %8837 to i32
  %8838 = load i8, i8* %arrayidx70.37, align 1
  %conv71.12.37 = zext i8 %8838 to i32
  %xor72.12.37 = xor i32 %conv71.12.37, %conv68.12.37
  %conv73.12.37 = trunc i32 %xor72.12.37 to i8
  store i8 %conv73.12.37, i8* %arrayidx70.37, align 1
  %scevgep20.13.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 13
  %8839 = load i8, i8* %scevgep20.13.37, align 1
  %conv68.13.37 = zext i8 %8839 to i32
  %8840 = load i8, i8* %arrayidx70.37, align 1
  %conv71.13.37 = zext i8 %8840 to i32
  %xor72.13.37 = xor i32 %conv71.13.37, %conv68.13.37
  %conv73.13.37 = trunc i32 %xor72.13.37 to i8
  store i8 %conv73.13.37, i8* %arrayidx70.37, align 1
  %scevgep20.14.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 14
  %8841 = load i8, i8* %scevgep20.14.37, align 1
  %conv68.14.37 = zext i8 %8841 to i32
  %8842 = load i8, i8* %arrayidx70.37, align 1
  %conv71.14.37 = zext i8 %8842 to i32
  %xor72.14.37 = xor i32 %conv71.14.37, %conv68.14.37
  %conv73.14.37 = trunc i32 %xor72.14.37 to i8
  store i8 %conv73.14.37, i8* %arrayidx70.37, align 1
  %scevgep20.15.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 15
  %8843 = load i8, i8* %scevgep20.15.37, align 1
  %conv68.15.37 = zext i8 %8843 to i32
  %8844 = load i8, i8* %arrayidx70.37, align 1
  %conv71.15.37 = zext i8 %8844 to i32
  %xor72.15.37 = xor i32 %conv71.15.37, %conv68.15.37
  %conv73.15.37 = trunc i32 %xor72.15.37 to i8
  store i8 %conv73.15.37, i8* %arrayidx70.37, align 1
  %scevgep20.16.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 16
  %8845 = load i8, i8* %scevgep20.16.37, align 1
  %conv68.16.37 = zext i8 %8845 to i32
  %8846 = load i8, i8* %arrayidx70.37, align 1
  %conv71.16.37 = zext i8 %8846 to i32
  %xor72.16.37 = xor i32 %conv71.16.37, %conv68.16.37
  %conv73.16.37 = trunc i32 %xor72.16.37 to i8
  store i8 %conv73.16.37, i8* %arrayidx70.37, align 1
  %scevgep20.17.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 17
  %8847 = load i8, i8* %scevgep20.17.37, align 1
  %conv68.17.37 = zext i8 %8847 to i32
  %8848 = load i8, i8* %arrayidx70.37, align 1
  %conv71.17.37 = zext i8 %8848 to i32
  %xor72.17.37 = xor i32 %conv71.17.37, %conv68.17.37
  %conv73.17.37 = trunc i32 %xor72.17.37 to i8
  store i8 %conv73.17.37, i8* %arrayidx70.37, align 1
  %scevgep20.18.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 18
  %8849 = load i8, i8* %scevgep20.18.37, align 1
  %conv68.18.37 = zext i8 %8849 to i32
  %8850 = load i8, i8* %arrayidx70.37, align 1
  %conv71.18.37 = zext i8 %8850 to i32
  %xor72.18.37 = xor i32 %conv71.18.37, %conv68.18.37
  %conv73.18.37 = trunc i32 %xor72.18.37 to i8
  store i8 %conv73.18.37, i8* %arrayidx70.37, align 1
  %scevgep20.19.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 19
  %8851 = load i8, i8* %scevgep20.19.37, align 1
  %conv68.19.37 = zext i8 %8851 to i32
  %8852 = load i8, i8* %arrayidx70.37, align 1
  %conv71.19.37 = zext i8 %8852 to i32
  %xor72.19.37 = xor i32 %conv71.19.37, %conv68.19.37
  %conv73.19.37 = trunc i32 %xor72.19.37 to i8
  store i8 %conv73.19.37, i8* %arrayidx70.37, align 1
  %scevgep20.20.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 20
  %8853 = load i8, i8* %scevgep20.20.37, align 1
  %conv68.20.37 = zext i8 %8853 to i32
  %8854 = load i8, i8* %arrayidx70.37, align 1
  %conv71.20.37 = zext i8 %8854 to i32
  %xor72.20.37 = xor i32 %conv71.20.37, %conv68.20.37
  %conv73.20.37 = trunc i32 %xor72.20.37 to i8
  store i8 %conv73.20.37, i8* %arrayidx70.37, align 1
  %scevgep20.21.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 21
  %8855 = load i8, i8* %scevgep20.21.37, align 1
  %conv68.21.37 = zext i8 %8855 to i32
  %8856 = load i8, i8* %arrayidx70.37, align 1
  %conv71.21.37 = zext i8 %8856 to i32
  %xor72.21.37 = xor i32 %conv71.21.37, %conv68.21.37
  %conv73.21.37 = trunc i32 %xor72.21.37 to i8
  store i8 %conv73.21.37, i8* %arrayidx70.37, align 1
  %scevgep20.22.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 22
  %8857 = load i8, i8* %scevgep20.22.37, align 1
  %conv68.22.37 = zext i8 %8857 to i32
  %8858 = load i8, i8* %arrayidx70.37, align 1
  %conv71.22.37 = zext i8 %8858 to i32
  %xor72.22.37 = xor i32 %conv71.22.37, %conv68.22.37
  %conv73.22.37 = trunc i32 %xor72.22.37 to i8
  store i8 %conv73.22.37, i8* %arrayidx70.37, align 1
  %scevgep20.23.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 23
  %8859 = load i8, i8* %scevgep20.23.37, align 1
  %conv68.23.37 = zext i8 %8859 to i32
  %8860 = load i8, i8* %arrayidx70.37, align 1
  %conv71.23.37 = zext i8 %8860 to i32
  %xor72.23.37 = xor i32 %conv71.23.37, %conv68.23.37
  %conv73.23.37 = trunc i32 %xor72.23.37 to i8
  store i8 %conv73.23.37, i8* %arrayidx70.37, align 1
  %scevgep20.24.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 24
  %8861 = load i8, i8* %scevgep20.24.37, align 1
  %conv68.24.37 = zext i8 %8861 to i32
  %8862 = load i8, i8* %arrayidx70.37, align 1
  %conv71.24.37 = zext i8 %8862 to i32
  %xor72.24.37 = xor i32 %conv71.24.37, %conv68.24.37
  %conv73.24.37 = trunc i32 %xor72.24.37 to i8
  store i8 %conv73.24.37, i8* %arrayidx70.37, align 1
  %scevgep20.25.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 25
  %8863 = load i8, i8* %scevgep20.25.37, align 1
  %conv68.25.37 = zext i8 %8863 to i32
  %8864 = load i8, i8* %arrayidx70.37, align 1
  %conv71.25.37 = zext i8 %8864 to i32
  %xor72.25.37 = xor i32 %conv71.25.37, %conv68.25.37
  %conv73.25.37 = trunc i32 %xor72.25.37 to i8
  store i8 %conv73.25.37, i8* %arrayidx70.37, align 1
  %scevgep20.26.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 26
  %8865 = load i8, i8* %scevgep20.26.37, align 1
  %conv68.26.37 = zext i8 %8865 to i32
  %8866 = load i8, i8* %arrayidx70.37, align 1
  %conv71.26.37 = zext i8 %8866 to i32
  %xor72.26.37 = xor i32 %conv71.26.37, %conv68.26.37
  %conv73.26.37 = trunc i32 %xor72.26.37 to i8
  store i8 %conv73.26.37, i8* %arrayidx70.37, align 1
  %scevgep20.27.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 27
  %8867 = load i8, i8* %scevgep20.27.37, align 1
  %conv68.27.37 = zext i8 %8867 to i32
  %8868 = load i8, i8* %arrayidx70.37, align 1
  %conv71.27.37 = zext i8 %8868 to i32
  %xor72.27.37 = xor i32 %conv71.27.37, %conv68.27.37
  %conv73.27.37 = trunc i32 %xor72.27.37 to i8
  store i8 %conv73.27.37, i8* %arrayidx70.37, align 1
  %scevgep20.28.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 28
  %8869 = load i8, i8* %scevgep20.28.37, align 1
  %conv68.28.37 = zext i8 %8869 to i32
  %8870 = load i8, i8* %arrayidx70.37, align 1
  %conv71.28.37 = zext i8 %8870 to i32
  %xor72.28.37 = xor i32 %conv71.28.37, %conv68.28.37
  %conv73.28.37 = trunc i32 %xor72.28.37 to i8
  store i8 %conv73.28.37, i8* %arrayidx70.37, align 1
  %scevgep20.29.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 29
  %8871 = load i8, i8* %scevgep20.29.37, align 1
  %conv68.29.37 = zext i8 %8871 to i32
  %8872 = load i8, i8* %arrayidx70.37, align 1
  %conv71.29.37 = zext i8 %8872 to i32
  %xor72.29.37 = xor i32 %conv71.29.37, %conv68.29.37
  %conv73.29.37 = trunc i32 %xor72.29.37 to i8
  store i8 %conv73.29.37, i8* %arrayidx70.37, align 1
  %scevgep20.30.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 30
  %8873 = load i8, i8* %scevgep20.30.37, align 1
  %conv68.30.37 = zext i8 %8873 to i32
  %8874 = load i8, i8* %arrayidx70.37, align 1
  %conv71.30.37 = zext i8 %8874 to i32
  %xor72.30.37 = xor i32 %conv71.30.37, %conv68.30.37
  %conv73.30.37 = trunc i32 %xor72.30.37 to i8
  store i8 %conv73.30.37, i8* %arrayidx70.37, align 1
  %scevgep20.31.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 31
  %8875 = load i8, i8* %scevgep20.31.37, align 1
  %conv68.31.37 = zext i8 %8875 to i32
  %8876 = load i8, i8* %arrayidx70.37, align 1
  %conv71.31.37 = zext i8 %8876 to i32
  %xor72.31.37 = xor i32 %conv71.31.37, %conv68.31.37
  %conv73.31.37 = trunc i32 %xor72.31.37 to i8
  store i8 %conv73.31.37, i8* %arrayidx70.37, align 1
  %scevgep20.32.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 32
  %8877 = load i8, i8* %scevgep20.32.37, align 1
  %conv68.32.37 = zext i8 %8877 to i32
  %8878 = load i8, i8* %arrayidx70.37, align 1
  %conv71.32.37 = zext i8 %8878 to i32
  %xor72.32.37 = xor i32 %conv71.32.37, %conv68.32.37
  %conv73.32.37 = trunc i32 %xor72.32.37 to i8
  store i8 %conv73.32.37, i8* %arrayidx70.37, align 1
  %scevgep20.33.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 33
  %8879 = load i8, i8* %scevgep20.33.37, align 1
  %conv68.33.37 = zext i8 %8879 to i32
  %8880 = load i8, i8* %arrayidx70.37, align 1
  %conv71.33.37 = zext i8 %8880 to i32
  %xor72.33.37 = xor i32 %conv71.33.37, %conv68.33.37
  %conv73.33.37 = trunc i32 %xor72.33.37 to i8
  store i8 %conv73.33.37, i8* %arrayidx70.37, align 1
  %scevgep20.34.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 34
  %8881 = load i8, i8* %scevgep20.34.37, align 1
  %conv68.34.37 = zext i8 %8881 to i32
  %8882 = load i8, i8* %arrayidx70.37, align 1
  %conv71.34.37 = zext i8 %8882 to i32
  %xor72.34.37 = xor i32 %conv71.34.37, %conv68.34.37
  %conv73.34.37 = trunc i32 %xor72.34.37 to i8
  store i8 %conv73.34.37, i8* %arrayidx70.37, align 1
  %scevgep20.35.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 35
  %8883 = load i8, i8* %scevgep20.35.37, align 1
  %conv68.35.37 = zext i8 %8883 to i32
  %8884 = load i8, i8* %arrayidx70.37, align 1
  %conv71.35.37 = zext i8 %8884 to i32
  %xor72.35.37 = xor i32 %conv71.35.37, %conv68.35.37
  %conv73.35.37 = trunc i32 %xor72.35.37 to i8
  store i8 %conv73.35.37, i8* %arrayidx70.37, align 1
  %scevgep20.36.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 36
  %8885 = load i8, i8* %scevgep20.36.37, align 1
  %conv68.36.37 = zext i8 %8885 to i32
  %8886 = load i8, i8* %arrayidx70.37, align 1
  %conv71.36.37 = zext i8 %8886 to i32
  %xor72.36.37 = xor i32 %conv71.36.37, %conv68.36.37
  %conv73.36.37 = trunc i32 %xor72.36.37 to i8
  store i8 %conv73.36.37, i8* %arrayidx70.37, align 1
  %scevgep20.38.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 38
  %8887 = load i8, i8* %scevgep20.38.37, align 1
  %conv68.38.37 = zext i8 %8887 to i32
  %8888 = load i8, i8* %arrayidx70.37, align 1
  %conv71.38.37 = zext i8 %8888 to i32
  %xor72.38.37 = xor i32 %conv71.38.37, %conv68.38.37
  %conv73.38.37 = trunc i32 %xor72.38.37 to i8
  store i8 %conv73.38.37, i8* %arrayidx70.37, align 1
  %scevgep20.39.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 39
  %8889 = load i8, i8* %scevgep20.39.37, align 1
  %conv68.39.37 = zext i8 %8889 to i32
  %8890 = load i8, i8* %arrayidx70.37, align 1
  %conv71.39.37 = zext i8 %8890 to i32
  %xor72.39.37 = xor i32 %conv71.39.37, %conv68.39.37
  %conv73.39.37 = trunc i32 %xor72.39.37 to i8
  store i8 %conv73.39.37, i8* %arrayidx70.37, align 1
  %scevgep20.40.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 0, i64 40
  %8891 = load i8, i8* %scevgep20.40.37, align 1
  %conv68.40.37 = zext i8 %8891 to i32
  %8892 = load i8, i8* %arrayidx70.37, align 1
  %conv71.40.37 = zext i8 %8892 to i32
  %xor72.40.37 = xor i32 %conv71.40.37, %conv68.40.37
  %conv73.40.37 = trunc i32 %xor72.40.37 to i8
  store i8 %conv73.40.37, i8* %arrayidx70.37, align 1
  %scevgep19.37 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8810, i64 0, i64 1, i64 0
  %8893 = bitcast i8* %scevgep19.37 to [41 x [41 x i8]]*
  %arrayidx51.38 = getelementptr inbounds i8, i8* %a, i64 38
  %8894 = load i8, i8* %arrayidx51.38, align 1
  %arrayidx53.38 = getelementptr inbounds i8, i8* %b, i64 38
  %8895 = load i8, i8* %arrayidx53.38, align 1
  %call54.38 = call zeroext i8 @mult(i8 zeroext %8894, i8 zeroext %8895)
  %arrayidx56.38 = getelementptr inbounds i8, i8* %c, i64 38
  store i8 %call54.38, i8* %arrayidx56.38, align 1
  %arrayidx70.38 = getelementptr inbounds i8, i8* %c, i64 38
  %scevgep20.38424 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 0
  %8896 = load i8, i8* %scevgep20.38424, align 1
  %conv68.38425 = zext i8 %8896 to i32
  %8897 = load i8, i8* %arrayidx70.38, align 1
  %conv71.38426 = zext i8 %8897 to i32
  %xor72.38427 = xor i32 %conv71.38426, %conv68.38425
  %conv73.38428 = trunc i32 %xor72.38427 to i8
  store i8 %conv73.38428, i8* %arrayidx70.38, align 1
  %scevgep20.1.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 1
  %8898 = load i8, i8* %scevgep20.1.38, align 1
  %conv68.1.38 = zext i8 %8898 to i32
  %8899 = load i8, i8* %arrayidx70.38, align 1
  %conv71.1.38 = zext i8 %8899 to i32
  %xor72.1.38 = xor i32 %conv71.1.38, %conv68.1.38
  %conv73.1.38 = trunc i32 %xor72.1.38 to i8
  store i8 %conv73.1.38, i8* %arrayidx70.38, align 1
  %scevgep20.2.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 2
  %8900 = load i8, i8* %scevgep20.2.38, align 1
  %conv68.2.38 = zext i8 %8900 to i32
  %8901 = load i8, i8* %arrayidx70.38, align 1
  %conv71.2.38 = zext i8 %8901 to i32
  %xor72.2.38 = xor i32 %conv71.2.38, %conv68.2.38
  %conv73.2.38 = trunc i32 %xor72.2.38 to i8
  store i8 %conv73.2.38, i8* %arrayidx70.38, align 1
  %scevgep20.3.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 3
  %8902 = load i8, i8* %scevgep20.3.38, align 1
  %conv68.3.38 = zext i8 %8902 to i32
  %8903 = load i8, i8* %arrayidx70.38, align 1
  %conv71.3.38 = zext i8 %8903 to i32
  %xor72.3.38 = xor i32 %conv71.3.38, %conv68.3.38
  %conv73.3.38 = trunc i32 %xor72.3.38 to i8
  store i8 %conv73.3.38, i8* %arrayidx70.38, align 1
  %scevgep20.4.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 4
  %8904 = load i8, i8* %scevgep20.4.38, align 1
  %conv68.4.38 = zext i8 %8904 to i32
  %8905 = load i8, i8* %arrayidx70.38, align 1
  %conv71.4.38 = zext i8 %8905 to i32
  %xor72.4.38 = xor i32 %conv71.4.38, %conv68.4.38
  %conv73.4.38 = trunc i32 %xor72.4.38 to i8
  store i8 %conv73.4.38, i8* %arrayidx70.38, align 1
  %scevgep20.5.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 5
  %8906 = load i8, i8* %scevgep20.5.38, align 1
  %conv68.5.38 = zext i8 %8906 to i32
  %8907 = load i8, i8* %arrayidx70.38, align 1
  %conv71.5.38 = zext i8 %8907 to i32
  %xor72.5.38 = xor i32 %conv71.5.38, %conv68.5.38
  %conv73.5.38 = trunc i32 %xor72.5.38 to i8
  store i8 %conv73.5.38, i8* %arrayidx70.38, align 1
  %scevgep20.6.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 6
  %8908 = load i8, i8* %scevgep20.6.38, align 1
  %conv68.6.38 = zext i8 %8908 to i32
  %8909 = load i8, i8* %arrayidx70.38, align 1
  %conv71.6.38 = zext i8 %8909 to i32
  %xor72.6.38 = xor i32 %conv71.6.38, %conv68.6.38
  %conv73.6.38 = trunc i32 %xor72.6.38 to i8
  store i8 %conv73.6.38, i8* %arrayidx70.38, align 1
  %scevgep20.7.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 7
  %8910 = load i8, i8* %scevgep20.7.38, align 1
  %conv68.7.38 = zext i8 %8910 to i32
  %8911 = load i8, i8* %arrayidx70.38, align 1
  %conv71.7.38 = zext i8 %8911 to i32
  %xor72.7.38 = xor i32 %conv71.7.38, %conv68.7.38
  %conv73.7.38 = trunc i32 %xor72.7.38 to i8
  store i8 %conv73.7.38, i8* %arrayidx70.38, align 1
  %scevgep20.8.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 8
  %8912 = load i8, i8* %scevgep20.8.38, align 1
  %conv68.8.38 = zext i8 %8912 to i32
  %8913 = load i8, i8* %arrayidx70.38, align 1
  %conv71.8.38 = zext i8 %8913 to i32
  %xor72.8.38 = xor i32 %conv71.8.38, %conv68.8.38
  %conv73.8.38 = trunc i32 %xor72.8.38 to i8
  store i8 %conv73.8.38, i8* %arrayidx70.38, align 1
  %scevgep20.9.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 9
  %8914 = load i8, i8* %scevgep20.9.38, align 1
  %conv68.9.38 = zext i8 %8914 to i32
  %8915 = load i8, i8* %arrayidx70.38, align 1
  %conv71.9.38 = zext i8 %8915 to i32
  %xor72.9.38 = xor i32 %conv71.9.38, %conv68.9.38
  %conv73.9.38 = trunc i32 %xor72.9.38 to i8
  store i8 %conv73.9.38, i8* %arrayidx70.38, align 1
  %scevgep20.10.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 10
  %8916 = load i8, i8* %scevgep20.10.38, align 1
  %conv68.10.38 = zext i8 %8916 to i32
  %8917 = load i8, i8* %arrayidx70.38, align 1
  %conv71.10.38 = zext i8 %8917 to i32
  %xor72.10.38 = xor i32 %conv71.10.38, %conv68.10.38
  %conv73.10.38 = trunc i32 %xor72.10.38 to i8
  store i8 %conv73.10.38, i8* %arrayidx70.38, align 1
  %scevgep20.11.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 11
  %8918 = load i8, i8* %scevgep20.11.38, align 1
  %conv68.11.38 = zext i8 %8918 to i32
  %8919 = load i8, i8* %arrayidx70.38, align 1
  %conv71.11.38 = zext i8 %8919 to i32
  %xor72.11.38 = xor i32 %conv71.11.38, %conv68.11.38
  %conv73.11.38 = trunc i32 %xor72.11.38 to i8
  store i8 %conv73.11.38, i8* %arrayidx70.38, align 1
  %scevgep20.12.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 12
  %8920 = load i8, i8* %scevgep20.12.38, align 1
  %conv68.12.38 = zext i8 %8920 to i32
  %8921 = load i8, i8* %arrayidx70.38, align 1
  %conv71.12.38 = zext i8 %8921 to i32
  %xor72.12.38 = xor i32 %conv71.12.38, %conv68.12.38
  %conv73.12.38 = trunc i32 %xor72.12.38 to i8
  store i8 %conv73.12.38, i8* %arrayidx70.38, align 1
  %scevgep20.13.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 13
  %8922 = load i8, i8* %scevgep20.13.38, align 1
  %conv68.13.38 = zext i8 %8922 to i32
  %8923 = load i8, i8* %arrayidx70.38, align 1
  %conv71.13.38 = zext i8 %8923 to i32
  %xor72.13.38 = xor i32 %conv71.13.38, %conv68.13.38
  %conv73.13.38 = trunc i32 %xor72.13.38 to i8
  store i8 %conv73.13.38, i8* %arrayidx70.38, align 1
  %scevgep20.14.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 14
  %8924 = load i8, i8* %scevgep20.14.38, align 1
  %conv68.14.38 = zext i8 %8924 to i32
  %8925 = load i8, i8* %arrayidx70.38, align 1
  %conv71.14.38 = zext i8 %8925 to i32
  %xor72.14.38 = xor i32 %conv71.14.38, %conv68.14.38
  %conv73.14.38 = trunc i32 %xor72.14.38 to i8
  store i8 %conv73.14.38, i8* %arrayidx70.38, align 1
  %scevgep20.15.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 15
  %8926 = load i8, i8* %scevgep20.15.38, align 1
  %conv68.15.38 = zext i8 %8926 to i32
  %8927 = load i8, i8* %arrayidx70.38, align 1
  %conv71.15.38 = zext i8 %8927 to i32
  %xor72.15.38 = xor i32 %conv71.15.38, %conv68.15.38
  %conv73.15.38 = trunc i32 %xor72.15.38 to i8
  store i8 %conv73.15.38, i8* %arrayidx70.38, align 1
  %scevgep20.16.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 16
  %8928 = load i8, i8* %scevgep20.16.38, align 1
  %conv68.16.38 = zext i8 %8928 to i32
  %8929 = load i8, i8* %arrayidx70.38, align 1
  %conv71.16.38 = zext i8 %8929 to i32
  %xor72.16.38 = xor i32 %conv71.16.38, %conv68.16.38
  %conv73.16.38 = trunc i32 %xor72.16.38 to i8
  store i8 %conv73.16.38, i8* %arrayidx70.38, align 1
  %scevgep20.17.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 17
  %8930 = load i8, i8* %scevgep20.17.38, align 1
  %conv68.17.38 = zext i8 %8930 to i32
  %8931 = load i8, i8* %arrayidx70.38, align 1
  %conv71.17.38 = zext i8 %8931 to i32
  %xor72.17.38 = xor i32 %conv71.17.38, %conv68.17.38
  %conv73.17.38 = trunc i32 %xor72.17.38 to i8
  store i8 %conv73.17.38, i8* %arrayidx70.38, align 1
  %scevgep20.18.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 18
  %8932 = load i8, i8* %scevgep20.18.38, align 1
  %conv68.18.38 = zext i8 %8932 to i32
  %8933 = load i8, i8* %arrayidx70.38, align 1
  %conv71.18.38 = zext i8 %8933 to i32
  %xor72.18.38 = xor i32 %conv71.18.38, %conv68.18.38
  %conv73.18.38 = trunc i32 %xor72.18.38 to i8
  store i8 %conv73.18.38, i8* %arrayidx70.38, align 1
  %scevgep20.19.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 19
  %8934 = load i8, i8* %scevgep20.19.38, align 1
  %conv68.19.38 = zext i8 %8934 to i32
  %8935 = load i8, i8* %arrayidx70.38, align 1
  %conv71.19.38 = zext i8 %8935 to i32
  %xor72.19.38 = xor i32 %conv71.19.38, %conv68.19.38
  %conv73.19.38 = trunc i32 %xor72.19.38 to i8
  store i8 %conv73.19.38, i8* %arrayidx70.38, align 1
  %scevgep20.20.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 20
  %8936 = load i8, i8* %scevgep20.20.38, align 1
  %conv68.20.38 = zext i8 %8936 to i32
  %8937 = load i8, i8* %arrayidx70.38, align 1
  %conv71.20.38 = zext i8 %8937 to i32
  %xor72.20.38 = xor i32 %conv71.20.38, %conv68.20.38
  %conv73.20.38 = trunc i32 %xor72.20.38 to i8
  store i8 %conv73.20.38, i8* %arrayidx70.38, align 1
  %scevgep20.21.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 21
  %8938 = load i8, i8* %scevgep20.21.38, align 1
  %conv68.21.38 = zext i8 %8938 to i32
  %8939 = load i8, i8* %arrayidx70.38, align 1
  %conv71.21.38 = zext i8 %8939 to i32
  %xor72.21.38 = xor i32 %conv71.21.38, %conv68.21.38
  %conv73.21.38 = trunc i32 %xor72.21.38 to i8
  store i8 %conv73.21.38, i8* %arrayidx70.38, align 1
  %scevgep20.22.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 22
  %8940 = load i8, i8* %scevgep20.22.38, align 1
  %conv68.22.38 = zext i8 %8940 to i32
  %8941 = load i8, i8* %arrayidx70.38, align 1
  %conv71.22.38 = zext i8 %8941 to i32
  %xor72.22.38 = xor i32 %conv71.22.38, %conv68.22.38
  %conv73.22.38 = trunc i32 %xor72.22.38 to i8
  store i8 %conv73.22.38, i8* %arrayidx70.38, align 1
  %scevgep20.23.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 23
  %8942 = load i8, i8* %scevgep20.23.38, align 1
  %conv68.23.38 = zext i8 %8942 to i32
  %8943 = load i8, i8* %arrayidx70.38, align 1
  %conv71.23.38 = zext i8 %8943 to i32
  %xor72.23.38 = xor i32 %conv71.23.38, %conv68.23.38
  %conv73.23.38 = trunc i32 %xor72.23.38 to i8
  store i8 %conv73.23.38, i8* %arrayidx70.38, align 1
  %scevgep20.24.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 24
  %8944 = load i8, i8* %scevgep20.24.38, align 1
  %conv68.24.38 = zext i8 %8944 to i32
  %8945 = load i8, i8* %arrayidx70.38, align 1
  %conv71.24.38 = zext i8 %8945 to i32
  %xor72.24.38 = xor i32 %conv71.24.38, %conv68.24.38
  %conv73.24.38 = trunc i32 %xor72.24.38 to i8
  store i8 %conv73.24.38, i8* %arrayidx70.38, align 1
  %scevgep20.25.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 25
  %8946 = load i8, i8* %scevgep20.25.38, align 1
  %conv68.25.38 = zext i8 %8946 to i32
  %8947 = load i8, i8* %arrayidx70.38, align 1
  %conv71.25.38 = zext i8 %8947 to i32
  %xor72.25.38 = xor i32 %conv71.25.38, %conv68.25.38
  %conv73.25.38 = trunc i32 %xor72.25.38 to i8
  store i8 %conv73.25.38, i8* %arrayidx70.38, align 1
  %scevgep20.26.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 26
  %8948 = load i8, i8* %scevgep20.26.38, align 1
  %conv68.26.38 = zext i8 %8948 to i32
  %8949 = load i8, i8* %arrayidx70.38, align 1
  %conv71.26.38 = zext i8 %8949 to i32
  %xor72.26.38 = xor i32 %conv71.26.38, %conv68.26.38
  %conv73.26.38 = trunc i32 %xor72.26.38 to i8
  store i8 %conv73.26.38, i8* %arrayidx70.38, align 1
  %scevgep20.27.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 27
  %8950 = load i8, i8* %scevgep20.27.38, align 1
  %conv68.27.38 = zext i8 %8950 to i32
  %8951 = load i8, i8* %arrayidx70.38, align 1
  %conv71.27.38 = zext i8 %8951 to i32
  %xor72.27.38 = xor i32 %conv71.27.38, %conv68.27.38
  %conv73.27.38 = trunc i32 %xor72.27.38 to i8
  store i8 %conv73.27.38, i8* %arrayidx70.38, align 1
  %scevgep20.28.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 28
  %8952 = load i8, i8* %scevgep20.28.38, align 1
  %conv68.28.38 = zext i8 %8952 to i32
  %8953 = load i8, i8* %arrayidx70.38, align 1
  %conv71.28.38 = zext i8 %8953 to i32
  %xor72.28.38 = xor i32 %conv71.28.38, %conv68.28.38
  %conv73.28.38 = trunc i32 %xor72.28.38 to i8
  store i8 %conv73.28.38, i8* %arrayidx70.38, align 1
  %scevgep20.29.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 29
  %8954 = load i8, i8* %scevgep20.29.38, align 1
  %conv68.29.38 = zext i8 %8954 to i32
  %8955 = load i8, i8* %arrayidx70.38, align 1
  %conv71.29.38 = zext i8 %8955 to i32
  %xor72.29.38 = xor i32 %conv71.29.38, %conv68.29.38
  %conv73.29.38 = trunc i32 %xor72.29.38 to i8
  store i8 %conv73.29.38, i8* %arrayidx70.38, align 1
  %scevgep20.30.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 30
  %8956 = load i8, i8* %scevgep20.30.38, align 1
  %conv68.30.38 = zext i8 %8956 to i32
  %8957 = load i8, i8* %arrayidx70.38, align 1
  %conv71.30.38 = zext i8 %8957 to i32
  %xor72.30.38 = xor i32 %conv71.30.38, %conv68.30.38
  %conv73.30.38 = trunc i32 %xor72.30.38 to i8
  store i8 %conv73.30.38, i8* %arrayidx70.38, align 1
  %scevgep20.31.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 31
  %8958 = load i8, i8* %scevgep20.31.38, align 1
  %conv68.31.38 = zext i8 %8958 to i32
  %8959 = load i8, i8* %arrayidx70.38, align 1
  %conv71.31.38 = zext i8 %8959 to i32
  %xor72.31.38 = xor i32 %conv71.31.38, %conv68.31.38
  %conv73.31.38 = trunc i32 %xor72.31.38 to i8
  store i8 %conv73.31.38, i8* %arrayidx70.38, align 1
  %scevgep20.32.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 32
  %8960 = load i8, i8* %scevgep20.32.38, align 1
  %conv68.32.38 = zext i8 %8960 to i32
  %8961 = load i8, i8* %arrayidx70.38, align 1
  %conv71.32.38 = zext i8 %8961 to i32
  %xor72.32.38 = xor i32 %conv71.32.38, %conv68.32.38
  %conv73.32.38 = trunc i32 %xor72.32.38 to i8
  store i8 %conv73.32.38, i8* %arrayidx70.38, align 1
  %scevgep20.33.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 33
  %8962 = load i8, i8* %scevgep20.33.38, align 1
  %conv68.33.38 = zext i8 %8962 to i32
  %8963 = load i8, i8* %arrayidx70.38, align 1
  %conv71.33.38 = zext i8 %8963 to i32
  %xor72.33.38 = xor i32 %conv71.33.38, %conv68.33.38
  %conv73.33.38 = trunc i32 %xor72.33.38 to i8
  store i8 %conv73.33.38, i8* %arrayidx70.38, align 1
  %scevgep20.34.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 34
  %8964 = load i8, i8* %scevgep20.34.38, align 1
  %conv68.34.38 = zext i8 %8964 to i32
  %8965 = load i8, i8* %arrayidx70.38, align 1
  %conv71.34.38 = zext i8 %8965 to i32
  %xor72.34.38 = xor i32 %conv71.34.38, %conv68.34.38
  %conv73.34.38 = trunc i32 %xor72.34.38 to i8
  store i8 %conv73.34.38, i8* %arrayidx70.38, align 1
  %scevgep20.35.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 35
  %8966 = load i8, i8* %scevgep20.35.38, align 1
  %conv68.35.38 = zext i8 %8966 to i32
  %8967 = load i8, i8* %arrayidx70.38, align 1
  %conv71.35.38 = zext i8 %8967 to i32
  %xor72.35.38 = xor i32 %conv71.35.38, %conv68.35.38
  %conv73.35.38 = trunc i32 %xor72.35.38 to i8
  store i8 %conv73.35.38, i8* %arrayidx70.38, align 1
  %scevgep20.36.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 36
  %8968 = load i8, i8* %scevgep20.36.38, align 1
  %conv68.36.38 = zext i8 %8968 to i32
  %8969 = load i8, i8* %arrayidx70.38, align 1
  %conv71.36.38 = zext i8 %8969 to i32
  %xor72.36.38 = xor i32 %conv71.36.38, %conv68.36.38
  %conv73.36.38 = trunc i32 %xor72.36.38 to i8
  store i8 %conv73.36.38, i8* %arrayidx70.38, align 1
  %scevgep20.37.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 37
  %8970 = load i8, i8* %scevgep20.37.38, align 1
  %conv68.37.38 = zext i8 %8970 to i32
  %8971 = load i8, i8* %arrayidx70.38, align 1
  %conv71.37.38 = zext i8 %8971 to i32
  %xor72.37.38 = xor i32 %conv71.37.38, %conv68.37.38
  %conv73.37.38 = trunc i32 %xor72.37.38 to i8
  store i8 %conv73.37.38, i8* %arrayidx70.38, align 1
  %scevgep20.39.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 39
  %8972 = load i8, i8* %scevgep20.39.38, align 1
  %conv68.39.38 = zext i8 %8972 to i32
  %8973 = load i8, i8* %arrayidx70.38, align 1
  %conv71.39.38 = zext i8 %8973 to i32
  %xor72.39.38 = xor i32 %conv71.39.38, %conv68.39.38
  %conv73.39.38 = trunc i32 %xor72.39.38 to i8
  store i8 %conv73.39.38, i8* %arrayidx70.38, align 1
  %scevgep20.40.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 0, i64 40
  %8974 = load i8, i8* %scevgep20.40.38, align 1
  %conv68.40.38 = zext i8 %8974 to i32
  %8975 = load i8, i8* %arrayidx70.38, align 1
  %conv71.40.38 = zext i8 %8975 to i32
  %xor72.40.38 = xor i32 %conv71.40.38, %conv68.40.38
  %conv73.40.38 = trunc i32 %xor72.40.38 to i8
  store i8 %conv73.40.38, i8* %arrayidx70.38, align 1
  %scevgep19.38 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8893, i64 0, i64 1, i64 0
  %8976 = bitcast i8* %scevgep19.38 to [41 x [41 x i8]]*
  %arrayidx51.39 = getelementptr inbounds i8, i8* %a, i64 39
  %8977 = load i8, i8* %arrayidx51.39, align 1
  %arrayidx53.39 = getelementptr inbounds i8, i8* %b, i64 39
  %8978 = load i8, i8* %arrayidx53.39, align 1
  %call54.39 = call zeroext i8 @mult(i8 zeroext %8977, i8 zeroext %8978)
  %arrayidx56.39 = getelementptr inbounds i8, i8* %c, i64 39
  store i8 %call54.39, i8* %arrayidx56.39, align 1
  %arrayidx70.39 = getelementptr inbounds i8, i8* %c, i64 39
  %scevgep20.39434 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 0
  %8979 = load i8, i8* %scevgep20.39434, align 1
  %conv68.39435 = zext i8 %8979 to i32
  %8980 = load i8, i8* %arrayidx70.39, align 1
  %conv71.39436 = zext i8 %8980 to i32
  %xor72.39437 = xor i32 %conv71.39436, %conv68.39435
  %conv73.39438 = trunc i32 %xor72.39437 to i8
  store i8 %conv73.39438, i8* %arrayidx70.39, align 1
  %scevgep20.1.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 1
  %8981 = load i8, i8* %scevgep20.1.39, align 1
  %conv68.1.39 = zext i8 %8981 to i32
  %8982 = load i8, i8* %arrayidx70.39, align 1
  %conv71.1.39 = zext i8 %8982 to i32
  %xor72.1.39 = xor i32 %conv71.1.39, %conv68.1.39
  %conv73.1.39 = trunc i32 %xor72.1.39 to i8
  store i8 %conv73.1.39, i8* %arrayidx70.39, align 1
  %scevgep20.2.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 2
  %8983 = load i8, i8* %scevgep20.2.39, align 1
  %conv68.2.39 = zext i8 %8983 to i32
  %8984 = load i8, i8* %arrayidx70.39, align 1
  %conv71.2.39 = zext i8 %8984 to i32
  %xor72.2.39 = xor i32 %conv71.2.39, %conv68.2.39
  %conv73.2.39 = trunc i32 %xor72.2.39 to i8
  store i8 %conv73.2.39, i8* %arrayidx70.39, align 1
  %scevgep20.3.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 3
  %8985 = load i8, i8* %scevgep20.3.39, align 1
  %conv68.3.39 = zext i8 %8985 to i32
  %8986 = load i8, i8* %arrayidx70.39, align 1
  %conv71.3.39 = zext i8 %8986 to i32
  %xor72.3.39 = xor i32 %conv71.3.39, %conv68.3.39
  %conv73.3.39 = trunc i32 %xor72.3.39 to i8
  store i8 %conv73.3.39, i8* %arrayidx70.39, align 1
  %scevgep20.4.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 4
  %8987 = load i8, i8* %scevgep20.4.39, align 1
  %conv68.4.39 = zext i8 %8987 to i32
  %8988 = load i8, i8* %arrayidx70.39, align 1
  %conv71.4.39 = zext i8 %8988 to i32
  %xor72.4.39 = xor i32 %conv71.4.39, %conv68.4.39
  %conv73.4.39 = trunc i32 %xor72.4.39 to i8
  store i8 %conv73.4.39, i8* %arrayidx70.39, align 1
  %scevgep20.5.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 5
  %8989 = load i8, i8* %scevgep20.5.39, align 1
  %conv68.5.39 = zext i8 %8989 to i32
  %8990 = load i8, i8* %arrayidx70.39, align 1
  %conv71.5.39 = zext i8 %8990 to i32
  %xor72.5.39 = xor i32 %conv71.5.39, %conv68.5.39
  %conv73.5.39 = trunc i32 %xor72.5.39 to i8
  store i8 %conv73.5.39, i8* %arrayidx70.39, align 1
  %scevgep20.6.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 6
  %8991 = load i8, i8* %scevgep20.6.39, align 1
  %conv68.6.39 = zext i8 %8991 to i32
  %8992 = load i8, i8* %arrayidx70.39, align 1
  %conv71.6.39 = zext i8 %8992 to i32
  %xor72.6.39 = xor i32 %conv71.6.39, %conv68.6.39
  %conv73.6.39 = trunc i32 %xor72.6.39 to i8
  store i8 %conv73.6.39, i8* %arrayidx70.39, align 1
  %scevgep20.7.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 7
  %8993 = load i8, i8* %scevgep20.7.39, align 1
  %conv68.7.39 = zext i8 %8993 to i32
  %8994 = load i8, i8* %arrayidx70.39, align 1
  %conv71.7.39 = zext i8 %8994 to i32
  %xor72.7.39 = xor i32 %conv71.7.39, %conv68.7.39
  %conv73.7.39 = trunc i32 %xor72.7.39 to i8
  store i8 %conv73.7.39, i8* %arrayidx70.39, align 1
  %scevgep20.8.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 8
  %8995 = load i8, i8* %scevgep20.8.39, align 1
  %conv68.8.39 = zext i8 %8995 to i32
  %8996 = load i8, i8* %arrayidx70.39, align 1
  %conv71.8.39 = zext i8 %8996 to i32
  %xor72.8.39 = xor i32 %conv71.8.39, %conv68.8.39
  %conv73.8.39 = trunc i32 %xor72.8.39 to i8
  store i8 %conv73.8.39, i8* %arrayidx70.39, align 1
  %scevgep20.9.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 9
  %8997 = load i8, i8* %scevgep20.9.39, align 1
  %conv68.9.39 = zext i8 %8997 to i32
  %8998 = load i8, i8* %arrayidx70.39, align 1
  %conv71.9.39 = zext i8 %8998 to i32
  %xor72.9.39 = xor i32 %conv71.9.39, %conv68.9.39
  %conv73.9.39 = trunc i32 %xor72.9.39 to i8
  store i8 %conv73.9.39, i8* %arrayidx70.39, align 1
  %scevgep20.10.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 10
  %8999 = load i8, i8* %scevgep20.10.39, align 1
  %conv68.10.39 = zext i8 %8999 to i32
  %9000 = load i8, i8* %arrayidx70.39, align 1
  %conv71.10.39 = zext i8 %9000 to i32
  %xor72.10.39 = xor i32 %conv71.10.39, %conv68.10.39
  %conv73.10.39 = trunc i32 %xor72.10.39 to i8
  store i8 %conv73.10.39, i8* %arrayidx70.39, align 1
  %scevgep20.11.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 11
  %9001 = load i8, i8* %scevgep20.11.39, align 1
  %conv68.11.39 = zext i8 %9001 to i32
  %9002 = load i8, i8* %arrayidx70.39, align 1
  %conv71.11.39 = zext i8 %9002 to i32
  %xor72.11.39 = xor i32 %conv71.11.39, %conv68.11.39
  %conv73.11.39 = trunc i32 %xor72.11.39 to i8
  store i8 %conv73.11.39, i8* %arrayidx70.39, align 1
  %scevgep20.12.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 12
  %9003 = load i8, i8* %scevgep20.12.39, align 1
  %conv68.12.39 = zext i8 %9003 to i32
  %9004 = load i8, i8* %arrayidx70.39, align 1
  %conv71.12.39 = zext i8 %9004 to i32
  %xor72.12.39 = xor i32 %conv71.12.39, %conv68.12.39
  %conv73.12.39 = trunc i32 %xor72.12.39 to i8
  store i8 %conv73.12.39, i8* %arrayidx70.39, align 1
  %scevgep20.13.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 13
  %9005 = load i8, i8* %scevgep20.13.39, align 1
  %conv68.13.39 = zext i8 %9005 to i32
  %9006 = load i8, i8* %arrayidx70.39, align 1
  %conv71.13.39 = zext i8 %9006 to i32
  %xor72.13.39 = xor i32 %conv71.13.39, %conv68.13.39
  %conv73.13.39 = trunc i32 %xor72.13.39 to i8
  store i8 %conv73.13.39, i8* %arrayidx70.39, align 1
  %scevgep20.14.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 14
  %9007 = load i8, i8* %scevgep20.14.39, align 1
  %conv68.14.39 = zext i8 %9007 to i32
  %9008 = load i8, i8* %arrayidx70.39, align 1
  %conv71.14.39 = zext i8 %9008 to i32
  %xor72.14.39 = xor i32 %conv71.14.39, %conv68.14.39
  %conv73.14.39 = trunc i32 %xor72.14.39 to i8
  store i8 %conv73.14.39, i8* %arrayidx70.39, align 1
  %scevgep20.15.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 15
  %9009 = load i8, i8* %scevgep20.15.39, align 1
  %conv68.15.39 = zext i8 %9009 to i32
  %9010 = load i8, i8* %arrayidx70.39, align 1
  %conv71.15.39 = zext i8 %9010 to i32
  %xor72.15.39 = xor i32 %conv71.15.39, %conv68.15.39
  %conv73.15.39 = trunc i32 %xor72.15.39 to i8
  store i8 %conv73.15.39, i8* %arrayidx70.39, align 1
  %scevgep20.16.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 16
  %9011 = load i8, i8* %scevgep20.16.39, align 1
  %conv68.16.39 = zext i8 %9011 to i32
  %9012 = load i8, i8* %arrayidx70.39, align 1
  %conv71.16.39 = zext i8 %9012 to i32
  %xor72.16.39 = xor i32 %conv71.16.39, %conv68.16.39
  %conv73.16.39 = trunc i32 %xor72.16.39 to i8
  store i8 %conv73.16.39, i8* %arrayidx70.39, align 1
  %scevgep20.17.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 17
  %9013 = load i8, i8* %scevgep20.17.39, align 1
  %conv68.17.39 = zext i8 %9013 to i32
  %9014 = load i8, i8* %arrayidx70.39, align 1
  %conv71.17.39 = zext i8 %9014 to i32
  %xor72.17.39 = xor i32 %conv71.17.39, %conv68.17.39
  %conv73.17.39 = trunc i32 %xor72.17.39 to i8
  store i8 %conv73.17.39, i8* %arrayidx70.39, align 1
  %scevgep20.18.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 18
  %9015 = load i8, i8* %scevgep20.18.39, align 1
  %conv68.18.39 = zext i8 %9015 to i32
  %9016 = load i8, i8* %arrayidx70.39, align 1
  %conv71.18.39 = zext i8 %9016 to i32
  %xor72.18.39 = xor i32 %conv71.18.39, %conv68.18.39
  %conv73.18.39 = trunc i32 %xor72.18.39 to i8
  store i8 %conv73.18.39, i8* %arrayidx70.39, align 1
  %scevgep20.19.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 19
  %9017 = load i8, i8* %scevgep20.19.39, align 1
  %conv68.19.39 = zext i8 %9017 to i32
  %9018 = load i8, i8* %arrayidx70.39, align 1
  %conv71.19.39 = zext i8 %9018 to i32
  %xor72.19.39 = xor i32 %conv71.19.39, %conv68.19.39
  %conv73.19.39 = trunc i32 %xor72.19.39 to i8
  store i8 %conv73.19.39, i8* %arrayidx70.39, align 1
  %scevgep20.20.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 20
  %9019 = load i8, i8* %scevgep20.20.39, align 1
  %conv68.20.39 = zext i8 %9019 to i32
  %9020 = load i8, i8* %arrayidx70.39, align 1
  %conv71.20.39 = zext i8 %9020 to i32
  %xor72.20.39 = xor i32 %conv71.20.39, %conv68.20.39
  %conv73.20.39 = trunc i32 %xor72.20.39 to i8
  store i8 %conv73.20.39, i8* %arrayidx70.39, align 1
  %scevgep20.21.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 21
  %9021 = load i8, i8* %scevgep20.21.39, align 1
  %conv68.21.39 = zext i8 %9021 to i32
  %9022 = load i8, i8* %arrayidx70.39, align 1
  %conv71.21.39 = zext i8 %9022 to i32
  %xor72.21.39 = xor i32 %conv71.21.39, %conv68.21.39
  %conv73.21.39 = trunc i32 %xor72.21.39 to i8
  store i8 %conv73.21.39, i8* %arrayidx70.39, align 1
  %scevgep20.22.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 22
  %9023 = load i8, i8* %scevgep20.22.39, align 1
  %conv68.22.39 = zext i8 %9023 to i32
  %9024 = load i8, i8* %arrayidx70.39, align 1
  %conv71.22.39 = zext i8 %9024 to i32
  %xor72.22.39 = xor i32 %conv71.22.39, %conv68.22.39
  %conv73.22.39 = trunc i32 %xor72.22.39 to i8
  store i8 %conv73.22.39, i8* %arrayidx70.39, align 1
  %scevgep20.23.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 23
  %9025 = load i8, i8* %scevgep20.23.39, align 1
  %conv68.23.39 = zext i8 %9025 to i32
  %9026 = load i8, i8* %arrayidx70.39, align 1
  %conv71.23.39 = zext i8 %9026 to i32
  %xor72.23.39 = xor i32 %conv71.23.39, %conv68.23.39
  %conv73.23.39 = trunc i32 %xor72.23.39 to i8
  store i8 %conv73.23.39, i8* %arrayidx70.39, align 1
  %scevgep20.24.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 24
  %9027 = load i8, i8* %scevgep20.24.39, align 1
  %conv68.24.39 = zext i8 %9027 to i32
  %9028 = load i8, i8* %arrayidx70.39, align 1
  %conv71.24.39 = zext i8 %9028 to i32
  %xor72.24.39 = xor i32 %conv71.24.39, %conv68.24.39
  %conv73.24.39 = trunc i32 %xor72.24.39 to i8
  store i8 %conv73.24.39, i8* %arrayidx70.39, align 1
  %scevgep20.25.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 25
  %9029 = load i8, i8* %scevgep20.25.39, align 1
  %conv68.25.39 = zext i8 %9029 to i32
  %9030 = load i8, i8* %arrayidx70.39, align 1
  %conv71.25.39 = zext i8 %9030 to i32
  %xor72.25.39 = xor i32 %conv71.25.39, %conv68.25.39
  %conv73.25.39 = trunc i32 %xor72.25.39 to i8
  store i8 %conv73.25.39, i8* %arrayidx70.39, align 1
  %scevgep20.26.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 26
  %9031 = load i8, i8* %scevgep20.26.39, align 1
  %conv68.26.39 = zext i8 %9031 to i32
  %9032 = load i8, i8* %arrayidx70.39, align 1
  %conv71.26.39 = zext i8 %9032 to i32
  %xor72.26.39 = xor i32 %conv71.26.39, %conv68.26.39
  %conv73.26.39 = trunc i32 %xor72.26.39 to i8
  store i8 %conv73.26.39, i8* %arrayidx70.39, align 1
  %scevgep20.27.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 27
  %9033 = load i8, i8* %scevgep20.27.39, align 1
  %conv68.27.39 = zext i8 %9033 to i32
  %9034 = load i8, i8* %arrayidx70.39, align 1
  %conv71.27.39 = zext i8 %9034 to i32
  %xor72.27.39 = xor i32 %conv71.27.39, %conv68.27.39
  %conv73.27.39 = trunc i32 %xor72.27.39 to i8
  store i8 %conv73.27.39, i8* %arrayidx70.39, align 1
  %scevgep20.28.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 28
  %9035 = load i8, i8* %scevgep20.28.39, align 1
  %conv68.28.39 = zext i8 %9035 to i32
  %9036 = load i8, i8* %arrayidx70.39, align 1
  %conv71.28.39 = zext i8 %9036 to i32
  %xor72.28.39 = xor i32 %conv71.28.39, %conv68.28.39
  %conv73.28.39 = trunc i32 %xor72.28.39 to i8
  store i8 %conv73.28.39, i8* %arrayidx70.39, align 1
  %scevgep20.29.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 29
  %9037 = load i8, i8* %scevgep20.29.39, align 1
  %conv68.29.39 = zext i8 %9037 to i32
  %9038 = load i8, i8* %arrayidx70.39, align 1
  %conv71.29.39 = zext i8 %9038 to i32
  %xor72.29.39 = xor i32 %conv71.29.39, %conv68.29.39
  %conv73.29.39 = trunc i32 %xor72.29.39 to i8
  store i8 %conv73.29.39, i8* %arrayidx70.39, align 1
  %scevgep20.30.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 30
  %9039 = load i8, i8* %scevgep20.30.39, align 1
  %conv68.30.39 = zext i8 %9039 to i32
  %9040 = load i8, i8* %arrayidx70.39, align 1
  %conv71.30.39 = zext i8 %9040 to i32
  %xor72.30.39 = xor i32 %conv71.30.39, %conv68.30.39
  %conv73.30.39 = trunc i32 %xor72.30.39 to i8
  store i8 %conv73.30.39, i8* %arrayidx70.39, align 1
  %scevgep20.31.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 31
  %9041 = load i8, i8* %scevgep20.31.39, align 1
  %conv68.31.39 = zext i8 %9041 to i32
  %9042 = load i8, i8* %arrayidx70.39, align 1
  %conv71.31.39 = zext i8 %9042 to i32
  %xor72.31.39 = xor i32 %conv71.31.39, %conv68.31.39
  %conv73.31.39 = trunc i32 %xor72.31.39 to i8
  store i8 %conv73.31.39, i8* %arrayidx70.39, align 1
  %scevgep20.32.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 32
  %9043 = load i8, i8* %scevgep20.32.39, align 1
  %conv68.32.39 = zext i8 %9043 to i32
  %9044 = load i8, i8* %arrayidx70.39, align 1
  %conv71.32.39 = zext i8 %9044 to i32
  %xor72.32.39 = xor i32 %conv71.32.39, %conv68.32.39
  %conv73.32.39 = trunc i32 %xor72.32.39 to i8
  store i8 %conv73.32.39, i8* %arrayidx70.39, align 1
  %scevgep20.33.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 33
  %9045 = load i8, i8* %scevgep20.33.39, align 1
  %conv68.33.39 = zext i8 %9045 to i32
  %9046 = load i8, i8* %arrayidx70.39, align 1
  %conv71.33.39 = zext i8 %9046 to i32
  %xor72.33.39 = xor i32 %conv71.33.39, %conv68.33.39
  %conv73.33.39 = trunc i32 %xor72.33.39 to i8
  store i8 %conv73.33.39, i8* %arrayidx70.39, align 1
  %scevgep20.34.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 34
  %9047 = load i8, i8* %scevgep20.34.39, align 1
  %conv68.34.39 = zext i8 %9047 to i32
  %9048 = load i8, i8* %arrayidx70.39, align 1
  %conv71.34.39 = zext i8 %9048 to i32
  %xor72.34.39 = xor i32 %conv71.34.39, %conv68.34.39
  %conv73.34.39 = trunc i32 %xor72.34.39 to i8
  store i8 %conv73.34.39, i8* %arrayidx70.39, align 1
  %scevgep20.35.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 35
  %9049 = load i8, i8* %scevgep20.35.39, align 1
  %conv68.35.39 = zext i8 %9049 to i32
  %9050 = load i8, i8* %arrayidx70.39, align 1
  %conv71.35.39 = zext i8 %9050 to i32
  %xor72.35.39 = xor i32 %conv71.35.39, %conv68.35.39
  %conv73.35.39 = trunc i32 %xor72.35.39 to i8
  store i8 %conv73.35.39, i8* %arrayidx70.39, align 1
  %scevgep20.36.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 36
  %9051 = load i8, i8* %scevgep20.36.39, align 1
  %conv68.36.39 = zext i8 %9051 to i32
  %9052 = load i8, i8* %arrayidx70.39, align 1
  %conv71.36.39 = zext i8 %9052 to i32
  %xor72.36.39 = xor i32 %conv71.36.39, %conv68.36.39
  %conv73.36.39 = trunc i32 %xor72.36.39 to i8
  store i8 %conv73.36.39, i8* %arrayidx70.39, align 1
  %scevgep20.37.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 37
  %9053 = load i8, i8* %scevgep20.37.39, align 1
  %conv68.37.39 = zext i8 %9053 to i32
  %9054 = load i8, i8* %arrayidx70.39, align 1
  %conv71.37.39 = zext i8 %9054 to i32
  %xor72.37.39 = xor i32 %conv71.37.39, %conv68.37.39
  %conv73.37.39 = trunc i32 %xor72.37.39 to i8
  store i8 %conv73.37.39, i8* %arrayidx70.39, align 1
  %scevgep20.38.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 38
  %9055 = load i8, i8* %scevgep20.38.39, align 1
  %conv68.38.39 = zext i8 %9055 to i32
  %9056 = load i8, i8* %arrayidx70.39, align 1
  %conv71.38.39 = zext i8 %9056 to i32
  %xor72.38.39 = xor i32 %conv71.38.39, %conv68.38.39
  %conv73.38.39 = trunc i32 %xor72.38.39 to i8
  store i8 %conv73.38.39, i8* %arrayidx70.39, align 1
  %scevgep20.40.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 0, i64 40
  %9057 = load i8, i8* %scevgep20.40.39, align 1
  %conv68.40.39 = zext i8 %9057 to i32
  %9058 = load i8, i8* %arrayidx70.39, align 1
  %conv71.40.39 = zext i8 %9058 to i32
  %xor72.40.39 = xor i32 %conv71.40.39, %conv68.40.39
  %conv73.40.39 = trunc i32 %xor72.40.39 to i8
  store i8 %conv73.40.39, i8* %arrayidx70.39, align 1
  %scevgep19.39 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %8976, i64 0, i64 1, i64 0
  %9059 = bitcast i8* %scevgep19.39 to [41 x [41 x i8]]*
  %arrayidx51.40 = getelementptr inbounds i8, i8* %a, i64 40
  %9060 = load i8, i8* %arrayidx51.40, align 1
  %arrayidx53.40 = getelementptr inbounds i8, i8* %b, i64 40
  %9061 = load i8, i8* %arrayidx53.40, align 1
  %call54.40 = call zeroext i8 @mult(i8 zeroext %9060, i8 zeroext %9061)
  %arrayidx56.40 = getelementptr inbounds i8, i8* %c, i64 40
  store i8 %call54.40, i8* %arrayidx56.40, align 1
  %arrayidx70.40 = getelementptr inbounds i8, i8* %c, i64 40
  %scevgep20.40444 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 0
  %9062 = load i8, i8* %scevgep20.40444, align 1
  %conv68.40445 = zext i8 %9062 to i32
  %9063 = load i8, i8* %arrayidx70.40, align 1
  %conv71.40446 = zext i8 %9063 to i32
  %xor72.40447 = xor i32 %conv71.40446, %conv68.40445
  %conv73.40448 = trunc i32 %xor72.40447 to i8
  store i8 %conv73.40448, i8* %arrayidx70.40, align 1
  %scevgep20.1.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 1
  %9064 = load i8, i8* %scevgep20.1.40, align 1
  %conv68.1.40 = zext i8 %9064 to i32
  %9065 = load i8, i8* %arrayidx70.40, align 1
  %conv71.1.40 = zext i8 %9065 to i32
  %xor72.1.40 = xor i32 %conv71.1.40, %conv68.1.40
  %conv73.1.40 = trunc i32 %xor72.1.40 to i8
  store i8 %conv73.1.40, i8* %arrayidx70.40, align 1
  %scevgep20.2.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 2
  %9066 = load i8, i8* %scevgep20.2.40, align 1
  %conv68.2.40 = zext i8 %9066 to i32
  %9067 = load i8, i8* %arrayidx70.40, align 1
  %conv71.2.40 = zext i8 %9067 to i32
  %xor72.2.40 = xor i32 %conv71.2.40, %conv68.2.40
  %conv73.2.40 = trunc i32 %xor72.2.40 to i8
  store i8 %conv73.2.40, i8* %arrayidx70.40, align 1
  %scevgep20.3.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 3
  %9068 = load i8, i8* %scevgep20.3.40, align 1
  %conv68.3.40 = zext i8 %9068 to i32
  %9069 = load i8, i8* %arrayidx70.40, align 1
  %conv71.3.40 = zext i8 %9069 to i32
  %xor72.3.40 = xor i32 %conv71.3.40, %conv68.3.40
  %conv73.3.40 = trunc i32 %xor72.3.40 to i8
  store i8 %conv73.3.40, i8* %arrayidx70.40, align 1
  %scevgep20.4.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 4
  %9070 = load i8, i8* %scevgep20.4.40, align 1
  %conv68.4.40 = zext i8 %9070 to i32
  %9071 = load i8, i8* %arrayidx70.40, align 1
  %conv71.4.40 = zext i8 %9071 to i32
  %xor72.4.40 = xor i32 %conv71.4.40, %conv68.4.40
  %conv73.4.40 = trunc i32 %xor72.4.40 to i8
  store i8 %conv73.4.40, i8* %arrayidx70.40, align 1
  %scevgep20.5.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 5
  %9072 = load i8, i8* %scevgep20.5.40, align 1
  %conv68.5.40 = zext i8 %9072 to i32
  %9073 = load i8, i8* %arrayidx70.40, align 1
  %conv71.5.40 = zext i8 %9073 to i32
  %xor72.5.40 = xor i32 %conv71.5.40, %conv68.5.40
  %conv73.5.40 = trunc i32 %xor72.5.40 to i8
  store i8 %conv73.5.40, i8* %arrayidx70.40, align 1
  %scevgep20.6.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 6
  %9074 = load i8, i8* %scevgep20.6.40, align 1
  %conv68.6.40 = zext i8 %9074 to i32
  %9075 = load i8, i8* %arrayidx70.40, align 1
  %conv71.6.40 = zext i8 %9075 to i32
  %xor72.6.40 = xor i32 %conv71.6.40, %conv68.6.40
  %conv73.6.40 = trunc i32 %xor72.6.40 to i8
  store i8 %conv73.6.40, i8* %arrayidx70.40, align 1
  %scevgep20.7.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 7
  %9076 = load i8, i8* %scevgep20.7.40, align 1
  %conv68.7.40 = zext i8 %9076 to i32
  %9077 = load i8, i8* %arrayidx70.40, align 1
  %conv71.7.40 = zext i8 %9077 to i32
  %xor72.7.40 = xor i32 %conv71.7.40, %conv68.7.40
  %conv73.7.40 = trunc i32 %xor72.7.40 to i8
  store i8 %conv73.7.40, i8* %arrayidx70.40, align 1
  %scevgep20.8.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 8
  %9078 = load i8, i8* %scevgep20.8.40, align 1
  %conv68.8.40 = zext i8 %9078 to i32
  %9079 = load i8, i8* %arrayidx70.40, align 1
  %conv71.8.40 = zext i8 %9079 to i32
  %xor72.8.40 = xor i32 %conv71.8.40, %conv68.8.40
  %conv73.8.40 = trunc i32 %xor72.8.40 to i8
  store i8 %conv73.8.40, i8* %arrayidx70.40, align 1
  %scevgep20.9.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 9
  %9080 = load i8, i8* %scevgep20.9.40, align 1
  %conv68.9.40 = zext i8 %9080 to i32
  %9081 = load i8, i8* %arrayidx70.40, align 1
  %conv71.9.40 = zext i8 %9081 to i32
  %xor72.9.40 = xor i32 %conv71.9.40, %conv68.9.40
  %conv73.9.40 = trunc i32 %xor72.9.40 to i8
  store i8 %conv73.9.40, i8* %arrayidx70.40, align 1
  %scevgep20.10.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 10
  %9082 = load i8, i8* %scevgep20.10.40, align 1
  %conv68.10.40 = zext i8 %9082 to i32
  %9083 = load i8, i8* %arrayidx70.40, align 1
  %conv71.10.40 = zext i8 %9083 to i32
  %xor72.10.40 = xor i32 %conv71.10.40, %conv68.10.40
  %conv73.10.40 = trunc i32 %xor72.10.40 to i8
  store i8 %conv73.10.40, i8* %arrayidx70.40, align 1
  %scevgep20.11.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 11
  %9084 = load i8, i8* %scevgep20.11.40, align 1
  %conv68.11.40 = zext i8 %9084 to i32
  %9085 = load i8, i8* %arrayidx70.40, align 1
  %conv71.11.40 = zext i8 %9085 to i32
  %xor72.11.40 = xor i32 %conv71.11.40, %conv68.11.40
  %conv73.11.40 = trunc i32 %xor72.11.40 to i8
  store i8 %conv73.11.40, i8* %arrayidx70.40, align 1
  %scevgep20.12.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 12
  %9086 = load i8, i8* %scevgep20.12.40, align 1
  %conv68.12.40 = zext i8 %9086 to i32
  %9087 = load i8, i8* %arrayidx70.40, align 1
  %conv71.12.40 = zext i8 %9087 to i32
  %xor72.12.40 = xor i32 %conv71.12.40, %conv68.12.40
  %conv73.12.40 = trunc i32 %xor72.12.40 to i8
  store i8 %conv73.12.40, i8* %arrayidx70.40, align 1
  %scevgep20.13.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 13
  %9088 = load i8, i8* %scevgep20.13.40, align 1
  %conv68.13.40 = zext i8 %9088 to i32
  %9089 = load i8, i8* %arrayidx70.40, align 1
  %conv71.13.40 = zext i8 %9089 to i32
  %xor72.13.40 = xor i32 %conv71.13.40, %conv68.13.40
  %conv73.13.40 = trunc i32 %xor72.13.40 to i8
  store i8 %conv73.13.40, i8* %arrayidx70.40, align 1
  %scevgep20.14.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 14
  %9090 = load i8, i8* %scevgep20.14.40, align 1
  %conv68.14.40 = zext i8 %9090 to i32
  %9091 = load i8, i8* %arrayidx70.40, align 1
  %conv71.14.40 = zext i8 %9091 to i32
  %xor72.14.40 = xor i32 %conv71.14.40, %conv68.14.40
  %conv73.14.40 = trunc i32 %xor72.14.40 to i8
  store i8 %conv73.14.40, i8* %arrayidx70.40, align 1
  %scevgep20.15.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 15
  %9092 = load i8, i8* %scevgep20.15.40, align 1
  %conv68.15.40 = zext i8 %9092 to i32
  %9093 = load i8, i8* %arrayidx70.40, align 1
  %conv71.15.40 = zext i8 %9093 to i32
  %xor72.15.40 = xor i32 %conv71.15.40, %conv68.15.40
  %conv73.15.40 = trunc i32 %xor72.15.40 to i8
  store i8 %conv73.15.40, i8* %arrayidx70.40, align 1
  %scevgep20.16.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 16
  %9094 = load i8, i8* %scevgep20.16.40, align 1
  %conv68.16.40 = zext i8 %9094 to i32
  %9095 = load i8, i8* %arrayidx70.40, align 1
  %conv71.16.40 = zext i8 %9095 to i32
  %xor72.16.40 = xor i32 %conv71.16.40, %conv68.16.40
  %conv73.16.40 = trunc i32 %xor72.16.40 to i8
  store i8 %conv73.16.40, i8* %arrayidx70.40, align 1
  %scevgep20.17.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 17
  %9096 = load i8, i8* %scevgep20.17.40, align 1
  %conv68.17.40 = zext i8 %9096 to i32
  %9097 = load i8, i8* %arrayidx70.40, align 1
  %conv71.17.40 = zext i8 %9097 to i32
  %xor72.17.40 = xor i32 %conv71.17.40, %conv68.17.40
  %conv73.17.40 = trunc i32 %xor72.17.40 to i8
  store i8 %conv73.17.40, i8* %arrayidx70.40, align 1
  %scevgep20.18.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 18
  %9098 = load i8, i8* %scevgep20.18.40, align 1
  %conv68.18.40 = zext i8 %9098 to i32
  %9099 = load i8, i8* %arrayidx70.40, align 1
  %conv71.18.40 = zext i8 %9099 to i32
  %xor72.18.40 = xor i32 %conv71.18.40, %conv68.18.40
  %conv73.18.40 = trunc i32 %xor72.18.40 to i8
  store i8 %conv73.18.40, i8* %arrayidx70.40, align 1
  %scevgep20.19.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 19
  %9100 = load i8, i8* %scevgep20.19.40, align 1
  %conv68.19.40 = zext i8 %9100 to i32
  %9101 = load i8, i8* %arrayidx70.40, align 1
  %conv71.19.40 = zext i8 %9101 to i32
  %xor72.19.40 = xor i32 %conv71.19.40, %conv68.19.40
  %conv73.19.40 = trunc i32 %xor72.19.40 to i8
  store i8 %conv73.19.40, i8* %arrayidx70.40, align 1
  %scevgep20.20.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 20
  %9102 = load i8, i8* %scevgep20.20.40, align 1
  %conv68.20.40 = zext i8 %9102 to i32
  %9103 = load i8, i8* %arrayidx70.40, align 1
  %conv71.20.40 = zext i8 %9103 to i32
  %xor72.20.40 = xor i32 %conv71.20.40, %conv68.20.40
  %conv73.20.40 = trunc i32 %xor72.20.40 to i8
  store i8 %conv73.20.40, i8* %arrayidx70.40, align 1
  %scevgep20.21.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 21
  %9104 = load i8, i8* %scevgep20.21.40, align 1
  %conv68.21.40 = zext i8 %9104 to i32
  %9105 = load i8, i8* %arrayidx70.40, align 1
  %conv71.21.40 = zext i8 %9105 to i32
  %xor72.21.40 = xor i32 %conv71.21.40, %conv68.21.40
  %conv73.21.40 = trunc i32 %xor72.21.40 to i8
  store i8 %conv73.21.40, i8* %arrayidx70.40, align 1
  %scevgep20.22.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 22
  %9106 = load i8, i8* %scevgep20.22.40, align 1
  %conv68.22.40 = zext i8 %9106 to i32
  %9107 = load i8, i8* %arrayidx70.40, align 1
  %conv71.22.40 = zext i8 %9107 to i32
  %xor72.22.40 = xor i32 %conv71.22.40, %conv68.22.40
  %conv73.22.40 = trunc i32 %xor72.22.40 to i8
  store i8 %conv73.22.40, i8* %arrayidx70.40, align 1
  %scevgep20.23.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 23
  %9108 = load i8, i8* %scevgep20.23.40, align 1
  %conv68.23.40 = zext i8 %9108 to i32
  %9109 = load i8, i8* %arrayidx70.40, align 1
  %conv71.23.40 = zext i8 %9109 to i32
  %xor72.23.40 = xor i32 %conv71.23.40, %conv68.23.40
  %conv73.23.40 = trunc i32 %xor72.23.40 to i8
  store i8 %conv73.23.40, i8* %arrayidx70.40, align 1
  %scevgep20.24.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 24
  %9110 = load i8, i8* %scevgep20.24.40, align 1
  %conv68.24.40 = zext i8 %9110 to i32
  %9111 = load i8, i8* %arrayidx70.40, align 1
  %conv71.24.40 = zext i8 %9111 to i32
  %xor72.24.40 = xor i32 %conv71.24.40, %conv68.24.40
  %conv73.24.40 = trunc i32 %xor72.24.40 to i8
  store i8 %conv73.24.40, i8* %arrayidx70.40, align 1
  %scevgep20.25.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 25
  %9112 = load i8, i8* %scevgep20.25.40, align 1
  %conv68.25.40 = zext i8 %9112 to i32
  %9113 = load i8, i8* %arrayidx70.40, align 1
  %conv71.25.40 = zext i8 %9113 to i32
  %xor72.25.40 = xor i32 %conv71.25.40, %conv68.25.40
  %conv73.25.40 = trunc i32 %xor72.25.40 to i8
  store i8 %conv73.25.40, i8* %arrayidx70.40, align 1
  %scevgep20.26.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 26
  %9114 = load i8, i8* %scevgep20.26.40, align 1
  %conv68.26.40 = zext i8 %9114 to i32
  %9115 = load i8, i8* %arrayidx70.40, align 1
  %conv71.26.40 = zext i8 %9115 to i32
  %xor72.26.40 = xor i32 %conv71.26.40, %conv68.26.40
  %conv73.26.40 = trunc i32 %xor72.26.40 to i8
  store i8 %conv73.26.40, i8* %arrayidx70.40, align 1
  %scevgep20.27.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 27
  %9116 = load i8, i8* %scevgep20.27.40, align 1
  %conv68.27.40 = zext i8 %9116 to i32
  %9117 = load i8, i8* %arrayidx70.40, align 1
  %conv71.27.40 = zext i8 %9117 to i32
  %xor72.27.40 = xor i32 %conv71.27.40, %conv68.27.40
  %conv73.27.40 = trunc i32 %xor72.27.40 to i8
  store i8 %conv73.27.40, i8* %arrayidx70.40, align 1
  %scevgep20.28.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 28
  %9118 = load i8, i8* %scevgep20.28.40, align 1
  %conv68.28.40 = zext i8 %9118 to i32
  %9119 = load i8, i8* %arrayidx70.40, align 1
  %conv71.28.40 = zext i8 %9119 to i32
  %xor72.28.40 = xor i32 %conv71.28.40, %conv68.28.40
  %conv73.28.40 = trunc i32 %xor72.28.40 to i8
  store i8 %conv73.28.40, i8* %arrayidx70.40, align 1
  %scevgep20.29.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 29
  %9120 = load i8, i8* %scevgep20.29.40, align 1
  %conv68.29.40 = zext i8 %9120 to i32
  %9121 = load i8, i8* %arrayidx70.40, align 1
  %conv71.29.40 = zext i8 %9121 to i32
  %xor72.29.40 = xor i32 %conv71.29.40, %conv68.29.40
  %conv73.29.40 = trunc i32 %xor72.29.40 to i8
  store i8 %conv73.29.40, i8* %arrayidx70.40, align 1
  %scevgep20.30.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 30
  %9122 = load i8, i8* %scevgep20.30.40, align 1
  %conv68.30.40 = zext i8 %9122 to i32
  %9123 = load i8, i8* %arrayidx70.40, align 1
  %conv71.30.40 = zext i8 %9123 to i32
  %xor72.30.40 = xor i32 %conv71.30.40, %conv68.30.40
  %conv73.30.40 = trunc i32 %xor72.30.40 to i8
  store i8 %conv73.30.40, i8* %arrayidx70.40, align 1
  %scevgep20.31.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 31
  %9124 = load i8, i8* %scevgep20.31.40, align 1
  %conv68.31.40 = zext i8 %9124 to i32
  %9125 = load i8, i8* %arrayidx70.40, align 1
  %conv71.31.40 = zext i8 %9125 to i32
  %xor72.31.40 = xor i32 %conv71.31.40, %conv68.31.40
  %conv73.31.40 = trunc i32 %xor72.31.40 to i8
  store i8 %conv73.31.40, i8* %arrayidx70.40, align 1
  %scevgep20.32.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 32
  %9126 = load i8, i8* %scevgep20.32.40, align 1
  %conv68.32.40 = zext i8 %9126 to i32
  %9127 = load i8, i8* %arrayidx70.40, align 1
  %conv71.32.40 = zext i8 %9127 to i32
  %xor72.32.40 = xor i32 %conv71.32.40, %conv68.32.40
  %conv73.32.40 = trunc i32 %xor72.32.40 to i8
  store i8 %conv73.32.40, i8* %arrayidx70.40, align 1
  %scevgep20.33.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 33
  %9128 = load i8, i8* %scevgep20.33.40, align 1
  %conv68.33.40 = zext i8 %9128 to i32
  %9129 = load i8, i8* %arrayidx70.40, align 1
  %conv71.33.40 = zext i8 %9129 to i32
  %xor72.33.40 = xor i32 %conv71.33.40, %conv68.33.40
  %conv73.33.40 = trunc i32 %xor72.33.40 to i8
  store i8 %conv73.33.40, i8* %arrayidx70.40, align 1
  %scevgep20.34.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 34
  %9130 = load i8, i8* %scevgep20.34.40, align 1
  %conv68.34.40 = zext i8 %9130 to i32
  %9131 = load i8, i8* %arrayidx70.40, align 1
  %conv71.34.40 = zext i8 %9131 to i32
  %xor72.34.40 = xor i32 %conv71.34.40, %conv68.34.40
  %conv73.34.40 = trunc i32 %xor72.34.40 to i8
  store i8 %conv73.34.40, i8* %arrayidx70.40, align 1
  %scevgep20.35.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 35
  %9132 = load i8, i8* %scevgep20.35.40, align 1
  %conv68.35.40 = zext i8 %9132 to i32
  %9133 = load i8, i8* %arrayidx70.40, align 1
  %conv71.35.40 = zext i8 %9133 to i32
  %xor72.35.40 = xor i32 %conv71.35.40, %conv68.35.40
  %conv73.35.40 = trunc i32 %xor72.35.40 to i8
  store i8 %conv73.35.40, i8* %arrayidx70.40, align 1
  %scevgep20.36.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 36
  %9134 = load i8, i8* %scevgep20.36.40, align 1
  %conv68.36.40 = zext i8 %9134 to i32
  %9135 = load i8, i8* %arrayidx70.40, align 1
  %conv71.36.40 = zext i8 %9135 to i32
  %xor72.36.40 = xor i32 %conv71.36.40, %conv68.36.40
  %conv73.36.40 = trunc i32 %xor72.36.40 to i8
  store i8 %conv73.36.40, i8* %arrayidx70.40, align 1
  %scevgep20.37.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 37
  %9136 = load i8, i8* %scevgep20.37.40, align 1
  %conv68.37.40 = zext i8 %9136 to i32
  %9137 = load i8, i8* %arrayidx70.40, align 1
  %conv71.37.40 = zext i8 %9137 to i32
  %xor72.37.40 = xor i32 %conv71.37.40, %conv68.37.40
  %conv73.37.40 = trunc i32 %xor72.37.40 to i8
  store i8 %conv73.37.40, i8* %arrayidx70.40, align 1
  %scevgep20.38.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 38
  %9138 = load i8, i8* %scevgep20.38.40, align 1
  %conv68.38.40 = zext i8 %9138 to i32
  %9139 = load i8, i8* %arrayidx70.40, align 1
  %conv71.38.40 = zext i8 %9139 to i32
  %xor72.38.40 = xor i32 %conv71.38.40, %conv68.38.40
  %conv73.38.40 = trunc i32 %xor72.38.40 to i8
  store i8 %conv73.38.40, i8* %arrayidx70.40, align 1
  %scevgep20.39.40 = getelementptr [41 x [41 x i8]], [41 x [41 x i8]]* %9059, i64 0, i64 0, i64 39
  %9140 = load i8, i8* %scevgep20.39.40, align 1
  %conv68.39.40 = zext i8 %9140 to i32
  %9141 = load i8, i8* %arrayidx70.40, align 1
  %conv71.39.40 = zext i8 %9141 to i32
  %xor72.39.40 = xor i32 %conv71.39.40, %conv68.39.40
  %conv73.39.40 = trunc i32 %xor72.39.40 to i8
  store i8 %conv73.39.40, i8* %arrayidx70.40, align 1
  %call80 = call zeroext i8 @mult(i8 zeroext %call, i8 zeroext %call1)
  %conv81 = zext i8 %call80 to i32
  %9142 = load i8, i8* %c, align 1
  %scevgep.1 = getelementptr i8, i8* %c, i64 1
  %9143 = load i8, i8* %scevgep.1, align 1
  %conv.i.i113.1 = zext i8 %9143 to i32
  %conv1.i.i114.1 = zext i8 %9142 to i32
  %xor.i.i115.1 = xor i32 %conv1.i.i114.1, %conv.i.i113.1
  %conv2.i.i116.1 = trunc i32 %xor.i.i115.1 to i8
  %scevgep.2 = getelementptr i8, i8* %c, i64 2
  %9144 = load i8, i8* %scevgep.2, align 1
  %conv.i.i113.2 = zext i8 %9144 to i32
  %conv1.i.i114.2 = zext i8 %conv2.i.i116.1 to i32
  %xor.i.i115.2 = xor i32 %conv1.i.i114.2, %conv.i.i113.2
  %conv2.i.i116.2 = trunc i32 %xor.i.i115.2 to i8
  %scevgep.3 = getelementptr i8, i8* %c, i64 3
  %9145 = load i8, i8* %scevgep.3, align 1
  %conv.i.i113.3 = zext i8 %9145 to i32
  %conv1.i.i114.3 = zext i8 %conv2.i.i116.2 to i32
  %xor.i.i115.3 = xor i32 %conv1.i.i114.3, %conv.i.i113.3
  %conv2.i.i116.3 = trunc i32 %xor.i.i115.3 to i8
  %scevgep.4 = getelementptr i8, i8* %c, i64 4
  %9146 = load i8, i8* %scevgep.4, align 1
  %conv.i.i113.4 = zext i8 %9146 to i32
  %conv1.i.i114.4 = zext i8 %conv2.i.i116.3 to i32
  %xor.i.i115.4 = xor i32 %conv1.i.i114.4, %conv.i.i113.4
  %conv2.i.i116.4 = trunc i32 %xor.i.i115.4 to i8
  %scevgep.5 = getelementptr i8, i8* %c, i64 5
  %9147 = load i8, i8* %scevgep.5, align 1
  %conv.i.i113.5 = zext i8 %9147 to i32
  %conv1.i.i114.5 = zext i8 %conv2.i.i116.4 to i32
  %xor.i.i115.5 = xor i32 %conv1.i.i114.5, %conv.i.i113.5
  %conv2.i.i116.5 = trunc i32 %xor.i.i115.5 to i8
  %scevgep.6 = getelementptr i8, i8* %c, i64 6
  %9148 = load i8, i8* %scevgep.6, align 1
  %conv.i.i113.6 = zext i8 %9148 to i32
  %conv1.i.i114.6 = zext i8 %conv2.i.i116.5 to i32
  %xor.i.i115.6 = xor i32 %conv1.i.i114.6, %conv.i.i113.6
  %conv2.i.i116.6 = trunc i32 %xor.i.i115.6 to i8
  %scevgep.7 = getelementptr i8, i8* %c, i64 7
  %9149 = load i8, i8* %scevgep.7, align 1
  %conv.i.i113.7 = zext i8 %9149 to i32
  %conv1.i.i114.7 = zext i8 %conv2.i.i116.6 to i32
  %xor.i.i115.7 = xor i32 %conv1.i.i114.7, %conv.i.i113.7
  %conv2.i.i116.7 = trunc i32 %xor.i.i115.7 to i8
  %scevgep.8 = getelementptr i8, i8* %c, i64 8
  %9150 = load i8, i8* %scevgep.8, align 1
  %conv.i.i113.8 = zext i8 %9150 to i32
  %conv1.i.i114.8 = zext i8 %conv2.i.i116.7 to i32
  %xor.i.i115.8 = xor i32 %conv1.i.i114.8, %conv.i.i113.8
  %conv2.i.i116.8 = trunc i32 %xor.i.i115.8 to i8
  %scevgep.9 = getelementptr i8, i8* %c, i64 9
  %9151 = load i8, i8* %scevgep.9, align 1
  %conv.i.i113.9 = zext i8 %9151 to i32
  %conv1.i.i114.9 = zext i8 %conv2.i.i116.8 to i32
  %xor.i.i115.9 = xor i32 %conv1.i.i114.9, %conv.i.i113.9
  %conv2.i.i116.9 = trunc i32 %xor.i.i115.9 to i8
  %scevgep.10 = getelementptr i8, i8* %c, i64 10
  %9152 = load i8, i8* %scevgep.10, align 1
  %conv.i.i113.10 = zext i8 %9152 to i32
  %conv1.i.i114.10 = zext i8 %conv2.i.i116.9 to i32
  %xor.i.i115.10 = xor i32 %conv1.i.i114.10, %conv.i.i113.10
  %conv2.i.i116.10 = trunc i32 %xor.i.i115.10 to i8
  %scevgep.11 = getelementptr i8, i8* %c, i64 11
  %9153 = load i8, i8* %scevgep.11, align 1
  %conv.i.i113.11 = zext i8 %9153 to i32
  %conv1.i.i114.11 = zext i8 %conv2.i.i116.10 to i32
  %xor.i.i115.11 = xor i32 %conv1.i.i114.11, %conv.i.i113.11
  %conv2.i.i116.11 = trunc i32 %xor.i.i115.11 to i8
  %scevgep.12 = getelementptr i8, i8* %c, i64 12
  %9154 = load i8, i8* %scevgep.12, align 1
  %conv.i.i113.12 = zext i8 %9154 to i32
  %conv1.i.i114.12 = zext i8 %conv2.i.i116.11 to i32
  %xor.i.i115.12 = xor i32 %conv1.i.i114.12, %conv.i.i113.12
  %conv2.i.i116.12 = trunc i32 %xor.i.i115.12 to i8
  %scevgep.13 = getelementptr i8, i8* %c, i64 13
  %9155 = load i8, i8* %scevgep.13, align 1
  %conv.i.i113.13 = zext i8 %9155 to i32
  %conv1.i.i114.13 = zext i8 %conv2.i.i116.12 to i32
  %xor.i.i115.13 = xor i32 %conv1.i.i114.13, %conv.i.i113.13
  %conv2.i.i116.13 = trunc i32 %xor.i.i115.13 to i8
  %scevgep.14 = getelementptr i8, i8* %c, i64 14
  %9156 = load i8, i8* %scevgep.14, align 1
  %conv.i.i113.14 = zext i8 %9156 to i32
  %conv1.i.i114.14 = zext i8 %conv2.i.i116.13 to i32
  %xor.i.i115.14 = xor i32 %conv1.i.i114.14, %conv.i.i113.14
  %conv2.i.i116.14 = trunc i32 %xor.i.i115.14 to i8
  %scevgep.15 = getelementptr i8, i8* %c, i64 15
  %9157 = load i8, i8* %scevgep.15, align 1
  %conv.i.i113.15 = zext i8 %9157 to i32
  %conv1.i.i114.15 = zext i8 %conv2.i.i116.14 to i32
  %xor.i.i115.15 = xor i32 %conv1.i.i114.15, %conv.i.i113.15
  %conv2.i.i116.15 = trunc i32 %xor.i.i115.15 to i8
  %scevgep.16 = getelementptr i8, i8* %c, i64 16
  %9158 = load i8, i8* %scevgep.16, align 1
  %conv.i.i113.16 = zext i8 %9158 to i32
  %conv1.i.i114.16 = zext i8 %conv2.i.i116.15 to i32
  %xor.i.i115.16 = xor i32 %conv1.i.i114.16, %conv.i.i113.16
  %conv2.i.i116.16 = trunc i32 %xor.i.i115.16 to i8
  %scevgep.17 = getelementptr i8, i8* %c, i64 17
  %9159 = load i8, i8* %scevgep.17, align 1
  %conv.i.i113.17 = zext i8 %9159 to i32
  %conv1.i.i114.17 = zext i8 %conv2.i.i116.16 to i32
  %xor.i.i115.17 = xor i32 %conv1.i.i114.17, %conv.i.i113.17
  %conv2.i.i116.17 = trunc i32 %xor.i.i115.17 to i8
  %scevgep.18 = getelementptr i8, i8* %c, i64 18
  %9160 = load i8, i8* %scevgep.18, align 1
  %conv.i.i113.18 = zext i8 %9160 to i32
  %conv1.i.i114.18 = zext i8 %conv2.i.i116.17 to i32
  %xor.i.i115.18 = xor i32 %conv1.i.i114.18, %conv.i.i113.18
  %conv2.i.i116.18 = trunc i32 %xor.i.i115.18 to i8
  %scevgep.19 = getelementptr i8, i8* %c, i64 19
  %9161 = load i8, i8* %scevgep.19, align 1
  %conv.i.i113.19 = zext i8 %9161 to i32
  %conv1.i.i114.19 = zext i8 %conv2.i.i116.18 to i32
  %xor.i.i115.19 = xor i32 %conv1.i.i114.19, %conv.i.i113.19
  %conv2.i.i116.19 = trunc i32 %xor.i.i115.19 to i8
  %scevgep.20 = getelementptr i8, i8* %c, i64 20
  %9162 = load i8, i8* %scevgep.20, align 1
  %conv.i.i113.20 = zext i8 %9162 to i32
  %conv1.i.i114.20 = zext i8 %conv2.i.i116.19 to i32
  %xor.i.i115.20 = xor i32 %conv1.i.i114.20, %conv.i.i113.20
  %conv2.i.i116.20 = trunc i32 %xor.i.i115.20 to i8
  %scevgep.21 = getelementptr i8, i8* %c, i64 21
  %9163 = load i8, i8* %scevgep.21, align 1
  %conv.i.i113.21 = zext i8 %9163 to i32
  %conv1.i.i114.21 = zext i8 %conv2.i.i116.20 to i32
  %xor.i.i115.21 = xor i32 %conv1.i.i114.21, %conv.i.i113.21
  %conv2.i.i116.21 = trunc i32 %xor.i.i115.21 to i8
  %scevgep.22 = getelementptr i8, i8* %c, i64 22
  %9164 = load i8, i8* %scevgep.22, align 1
  %conv.i.i113.22 = zext i8 %9164 to i32
  %conv1.i.i114.22 = zext i8 %conv2.i.i116.21 to i32
  %xor.i.i115.22 = xor i32 %conv1.i.i114.22, %conv.i.i113.22
  %conv2.i.i116.22 = trunc i32 %xor.i.i115.22 to i8
  %scevgep.23 = getelementptr i8, i8* %c, i64 23
  %9165 = load i8, i8* %scevgep.23, align 1
  %conv.i.i113.23 = zext i8 %9165 to i32
  %conv1.i.i114.23 = zext i8 %conv2.i.i116.22 to i32
  %xor.i.i115.23 = xor i32 %conv1.i.i114.23, %conv.i.i113.23
  %conv2.i.i116.23 = trunc i32 %xor.i.i115.23 to i8
  %scevgep.24 = getelementptr i8, i8* %c, i64 24
  %9166 = load i8, i8* %scevgep.24, align 1
  %conv.i.i113.24 = zext i8 %9166 to i32
  %conv1.i.i114.24 = zext i8 %conv2.i.i116.23 to i32
  %xor.i.i115.24 = xor i32 %conv1.i.i114.24, %conv.i.i113.24
  %conv2.i.i116.24 = trunc i32 %xor.i.i115.24 to i8
  %scevgep.25 = getelementptr i8, i8* %c, i64 25
  %9167 = load i8, i8* %scevgep.25, align 1
  %conv.i.i113.25 = zext i8 %9167 to i32
  %conv1.i.i114.25 = zext i8 %conv2.i.i116.24 to i32
  %xor.i.i115.25 = xor i32 %conv1.i.i114.25, %conv.i.i113.25
  %conv2.i.i116.25 = trunc i32 %xor.i.i115.25 to i8
  %scevgep.26 = getelementptr i8, i8* %c, i64 26
  %9168 = load i8, i8* %scevgep.26, align 1
  %conv.i.i113.26 = zext i8 %9168 to i32
  %conv1.i.i114.26 = zext i8 %conv2.i.i116.25 to i32
  %xor.i.i115.26 = xor i32 %conv1.i.i114.26, %conv.i.i113.26
  %conv2.i.i116.26 = trunc i32 %xor.i.i115.26 to i8
  %scevgep.27 = getelementptr i8, i8* %c, i64 27
  %9169 = load i8, i8* %scevgep.27, align 1
  %conv.i.i113.27 = zext i8 %9169 to i32
  %conv1.i.i114.27 = zext i8 %conv2.i.i116.26 to i32
  %xor.i.i115.27 = xor i32 %conv1.i.i114.27, %conv.i.i113.27
  %conv2.i.i116.27 = trunc i32 %xor.i.i115.27 to i8
  %scevgep.28 = getelementptr i8, i8* %c, i64 28
  %9170 = load i8, i8* %scevgep.28, align 1
  %conv.i.i113.28 = zext i8 %9170 to i32
  %conv1.i.i114.28 = zext i8 %conv2.i.i116.27 to i32
  %xor.i.i115.28 = xor i32 %conv1.i.i114.28, %conv.i.i113.28
  %conv2.i.i116.28 = trunc i32 %xor.i.i115.28 to i8
  %scevgep.29 = getelementptr i8, i8* %c, i64 29
  %9171 = load i8, i8* %scevgep.29, align 1
  %conv.i.i113.29 = zext i8 %9171 to i32
  %conv1.i.i114.29 = zext i8 %conv2.i.i116.28 to i32
  %xor.i.i115.29 = xor i32 %conv1.i.i114.29, %conv.i.i113.29
  %conv2.i.i116.29 = trunc i32 %xor.i.i115.29 to i8
  %scevgep.30 = getelementptr i8, i8* %c, i64 30
  %9172 = load i8, i8* %scevgep.30, align 1
  %conv.i.i113.30 = zext i8 %9172 to i32
  %conv1.i.i114.30 = zext i8 %conv2.i.i116.29 to i32
  %xor.i.i115.30 = xor i32 %conv1.i.i114.30, %conv.i.i113.30
  %conv2.i.i116.30 = trunc i32 %xor.i.i115.30 to i8
  %scevgep.31 = getelementptr i8, i8* %c, i64 31
  %9173 = load i8, i8* %scevgep.31, align 1
  %conv.i.i113.31 = zext i8 %9173 to i32
  %conv1.i.i114.31 = zext i8 %conv2.i.i116.30 to i32
  %xor.i.i115.31 = xor i32 %conv1.i.i114.31, %conv.i.i113.31
  %conv2.i.i116.31 = trunc i32 %xor.i.i115.31 to i8
  %scevgep.32 = getelementptr i8, i8* %c, i64 32
  %9174 = load i8, i8* %scevgep.32, align 1
  %conv.i.i113.32 = zext i8 %9174 to i32
  %conv1.i.i114.32 = zext i8 %conv2.i.i116.31 to i32
  %xor.i.i115.32 = xor i32 %conv1.i.i114.32, %conv.i.i113.32
  %conv2.i.i116.32 = trunc i32 %xor.i.i115.32 to i8
  %scevgep.33 = getelementptr i8, i8* %c, i64 33
  %9175 = load i8, i8* %scevgep.33, align 1
  %conv.i.i113.33 = zext i8 %9175 to i32
  %conv1.i.i114.33 = zext i8 %conv2.i.i116.32 to i32
  %xor.i.i115.33 = xor i32 %conv1.i.i114.33, %conv.i.i113.33
  %conv2.i.i116.33 = trunc i32 %xor.i.i115.33 to i8
  %scevgep.34 = getelementptr i8, i8* %c, i64 34
  %9176 = load i8, i8* %scevgep.34, align 1
  %conv.i.i113.34 = zext i8 %9176 to i32
  %conv1.i.i114.34 = zext i8 %conv2.i.i116.33 to i32
  %xor.i.i115.34 = xor i32 %conv1.i.i114.34, %conv.i.i113.34
  %conv2.i.i116.34 = trunc i32 %xor.i.i115.34 to i8
  %scevgep.35 = getelementptr i8, i8* %c, i64 35
  %9177 = load i8, i8* %scevgep.35, align 1
  %conv.i.i113.35 = zext i8 %9177 to i32
  %conv1.i.i114.35 = zext i8 %conv2.i.i116.34 to i32
  %xor.i.i115.35 = xor i32 %conv1.i.i114.35, %conv.i.i113.35
  %conv2.i.i116.35 = trunc i32 %xor.i.i115.35 to i8
  %scevgep.36 = getelementptr i8, i8* %c, i64 36
  %9178 = load i8, i8* %scevgep.36, align 1
  %conv.i.i113.36 = zext i8 %9178 to i32
  %conv1.i.i114.36 = zext i8 %conv2.i.i116.35 to i32
  %xor.i.i115.36 = xor i32 %conv1.i.i114.36, %conv.i.i113.36
  %conv2.i.i116.36 = trunc i32 %xor.i.i115.36 to i8
  %scevgep.37 = getelementptr i8, i8* %c, i64 37
  %9179 = load i8, i8* %scevgep.37, align 1
  %conv.i.i113.37 = zext i8 %9179 to i32
  %conv1.i.i114.37 = zext i8 %conv2.i.i116.36 to i32
  %xor.i.i115.37 = xor i32 %conv1.i.i114.37, %conv.i.i113.37
  %conv2.i.i116.37 = trunc i32 %xor.i.i115.37 to i8
  %scevgep.38 = getelementptr i8, i8* %c, i64 38
  %9180 = load i8, i8* %scevgep.38, align 1
  %conv.i.i113.38 = zext i8 %9180 to i32
  %conv1.i.i114.38 = zext i8 %conv2.i.i116.37 to i32
  %xor.i.i115.38 = xor i32 %conv1.i.i114.38, %conv.i.i113.38
  %conv2.i.i116.38 = trunc i32 %xor.i.i115.38 to i8
  %scevgep.39 = getelementptr i8, i8* %c, i64 39
  %9181 = load i8, i8* %scevgep.39, align 1
  %conv.i.i113.39 = zext i8 %9181 to i32
  %conv1.i.i114.39 = zext i8 %conv2.i.i116.38 to i32
  %xor.i.i115.39 = xor i32 %conv1.i.i114.39, %conv.i.i113.39
  %conv2.i.i116.39 = trunc i32 %xor.i.i115.39 to i8
  %scevgep.40 = getelementptr i8, i8* %c, i64 40
  %9182 = load i8, i8* %scevgep.40, align 1
  %conv.i.i113.40 = zext i8 %9182 to i32
  %conv1.i.i114.40 = zext i8 %conv2.i.i116.39 to i32
  %xor.i.i115.40 = xor i32 %conv1.i.i114.40, %conv.i.i113.40
  %conv2.i.i116.40 = trunc i32 %xor.i.i115.40 to i8
  %conv83 = zext i8 %conv2.i.i116.40 to i32
  %cmp84 = icmp eq i32 %conv81, %conv83
  call void @assert(i1 zeroext %cmp84)
  ret void
}

declare dso_local zeroext i8 @rand(...) #1

declare dso_local void @assume(i1 zeroext) #1

declare dso_local zeroext i8 @mult(i8 zeroext, i8 zeroext) #1

declare dso_local void @assert(i1 zeroext) #1

; Function Attrs: alwaysinline nounwind uwtable
define dso_local void @refresh_masks(i8* %x) #0 {
entry:
  %call = call zeroext i8 (...) @rand()
  %conv = zext i8 %call to i32
  %0 = load i8, i8* %x, align 1
  %scevgep12.1 = getelementptr i8, i8* %x, i64 1
  %1 = load i8, i8* %scevgep12.1, align 1
  %conv.i.i.1 = zext i8 %1 to i32
  %conv1.i.i.1 = zext i8 %0 to i32
  %xor.i.i.1 = xor i32 %conv1.i.i.1, %conv.i.i.1
  %conv2.i.i.1 = trunc i32 %xor.i.i.1 to i8
  %scevgep12.2 = getelementptr i8, i8* %x, i64 2
  %2 = load i8, i8* %scevgep12.2, align 1
  %conv.i.i.2 = zext i8 %2 to i32
  %conv1.i.i.2 = zext i8 %conv2.i.i.1 to i32
  %xor.i.i.2 = xor i32 %conv1.i.i.2, %conv.i.i.2
  %conv2.i.i.2 = trunc i32 %xor.i.i.2 to i8
  %scevgep12.3 = getelementptr i8, i8* %x, i64 3
  %3 = load i8, i8* %scevgep12.3, align 1
  %conv.i.i.3 = zext i8 %3 to i32
  %conv1.i.i.3 = zext i8 %conv2.i.i.2 to i32
  %xor.i.i.3 = xor i32 %conv1.i.i.3, %conv.i.i.3
  %conv2.i.i.3 = trunc i32 %xor.i.i.3 to i8
  %scevgep12.4 = getelementptr i8, i8* %x, i64 4
  %4 = load i8, i8* %scevgep12.4, align 1
  %conv.i.i.4 = zext i8 %4 to i32
  %conv1.i.i.4 = zext i8 %conv2.i.i.3 to i32
  %xor.i.i.4 = xor i32 %conv1.i.i.4, %conv.i.i.4
  %conv2.i.i.4 = trunc i32 %xor.i.i.4 to i8
  %scevgep12.5 = getelementptr i8, i8* %x, i64 5
  %5 = load i8, i8* %scevgep12.5, align 1
  %conv.i.i.5 = zext i8 %5 to i32
  %conv1.i.i.5 = zext i8 %conv2.i.i.4 to i32
  %xor.i.i.5 = xor i32 %conv1.i.i.5, %conv.i.i.5
  %conv2.i.i.5 = trunc i32 %xor.i.i.5 to i8
  %scevgep12.6 = getelementptr i8, i8* %x, i64 6
  %6 = load i8, i8* %scevgep12.6, align 1
  %conv.i.i.6 = zext i8 %6 to i32
  %conv1.i.i.6 = zext i8 %conv2.i.i.5 to i32
  %xor.i.i.6 = xor i32 %conv1.i.i.6, %conv.i.i.6
  %conv2.i.i.6 = trunc i32 %xor.i.i.6 to i8
  %scevgep12.7 = getelementptr i8, i8* %x, i64 7
  %7 = load i8, i8* %scevgep12.7, align 1
  %conv.i.i.7 = zext i8 %7 to i32
  %conv1.i.i.7 = zext i8 %conv2.i.i.6 to i32
  %xor.i.i.7 = xor i32 %conv1.i.i.7, %conv.i.i.7
  %conv2.i.i.7 = trunc i32 %xor.i.i.7 to i8
  %scevgep12.8 = getelementptr i8, i8* %x, i64 8
  %8 = load i8, i8* %scevgep12.8, align 1
  %conv.i.i.8 = zext i8 %8 to i32
  %conv1.i.i.8 = zext i8 %conv2.i.i.7 to i32
  %xor.i.i.8 = xor i32 %conv1.i.i.8, %conv.i.i.8
  %conv2.i.i.8 = trunc i32 %xor.i.i.8 to i8
  %scevgep12.9 = getelementptr i8, i8* %x, i64 9
  %9 = load i8, i8* %scevgep12.9, align 1
  %conv.i.i.9 = zext i8 %9 to i32
  %conv1.i.i.9 = zext i8 %conv2.i.i.8 to i32
  %xor.i.i.9 = xor i32 %conv1.i.i.9, %conv.i.i.9
  %conv2.i.i.9 = trunc i32 %xor.i.i.9 to i8
  %scevgep12.10 = getelementptr i8, i8* %x, i64 10
  %10 = load i8, i8* %scevgep12.10, align 1
  %conv.i.i.10 = zext i8 %10 to i32
  %conv1.i.i.10 = zext i8 %conv2.i.i.9 to i32
  %xor.i.i.10 = xor i32 %conv1.i.i.10, %conv.i.i.10
  %conv2.i.i.10 = trunc i32 %xor.i.i.10 to i8
  %scevgep12.11 = getelementptr i8, i8* %x, i64 11
  %11 = load i8, i8* %scevgep12.11, align 1
  %conv.i.i.11 = zext i8 %11 to i32
  %conv1.i.i.11 = zext i8 %conv2.i.i.10 to i32
  %xor.i.i.11 = xor i32 %conv1.i.i.11, %conv.i.i.11
  %conv2.i.i.11 = trunc i32 %xor.i.i.11 to i8
  %scevgep12.12 = getelementptr i8, i8* %x, i64 12
  %12 = load i8, i8* %scevgep12.12, align 1
  %conv.i.i.12 = zext i8 %12 to i32
  %conv1.i.i.12 = zext i8 %conv2.i.i.11 to i32
  %xor.i.i.12 = xor i32 %conv1.i.i.12, %conv.i.i.12
  %conv2.i.i.12 = trunc i32 %xor.i.i.12 to i8
  %scevgep12.13 = getelementptr i8, i8* %x, i64 13
  %13 = load i8, i8* %scevgep12.13, align 1
  %conv.i.i.13 = zext i8 %13 to i32
  %conv1.i.i.13 = zext i8 %conv2.i.i.12 to i32
  %xor.i.i.13 = xor i32 %conv1.i.i.13, %conv.i.i.13
  %conv2.i.i.13 = trunc i32 %xor.i.i.13 to i8
  %scevgep12.14 = getelementptr i8, i8* %x, i64 14
  %14 = load i8, i8* %scevgep12.14, align 1
  %conv.i.i.14 = zext i8 %14 to i32
  %conv1.i.i.14 = zext i8 %conv2.i.i.13 to i32
  %xor.i.i.14 = xor i32 %conv1.i.i.14, %conv.i.i.14
  %conv2.i.i.14 = trunc i32 %xor.i.i.14 to i8
  %scevgep12.15 = getelementptr i8, i8* %x, i64 15
  %15 = load i8, i8* %scevgep12.15, align 1
  %conv.i.i.15 = zext i8 %15 to i32
  %conv1.i.i.15 = zext i8 %conv2.i.i.14 to i32
  %xor.i.i.15 = xor i32 %conv1.i.i.15, %conv.i.i.15
  %conv2.i.i.15 = trunc i32 %xor.i.i.15 to i8
  %scevgep12.16 = getelementptr i8, i8* %x, i64 16
  %16 = load i8, i8* %scevgep12.16, align 1
  %conv.i.i.16 = zext i8 %16 to i32
  %conv1.i.i.16 = zext i8 %conv2.i.i.15 to i32
  %xor.i.i.16 = xor i32 %conv1.i.i.16, %conv.i.i.16
  %conv2.i.i.16 = trunc i32 %xor.i.i.16 to i8
  %scevgep12.17 = getelementptr i8, i8* %x, i64 17
  %17 = load i8, i8* %scevgep12.17, align 1
  %conv.i.i.17 = zext i8 %17 to i32
  %conv1.i.i.17 = zext i8 %conv2.i.i.16 to i32
  %xor.i.i.17 = xor i32 %conv1.i.i.17, %conv.i.i.17
  %conv2.i.i.17 = trunc i32 %xor.i.i.17 to i8
  %scevgep12.18 = getelementptr i8, i8* %x, i64 18
  %18 = load i8, i8* %scevgep12.18, align 1
  %conv.i.i.18 = zext i8 %18 to i32
  %conv1.i.i.18 = zext i8 %conv2.i.i.17 to i32
  %xor.i.i.18 = xor i32 %conv1.i.i.18, %conv.i.i.18
  %conv2.i.i.18 = trunc i32 %xor.i.i.18 to i8
  %scevgep12.19 = getelementptr i8, i8* %x, i64 19
  %19 = load i8, i8* %scevgep12.19, align 1
  %conv.i.i.19 = zext i8 %19 to i32
  %conv1.i.i.19 = zext i8 %conv2.i.i.18 to i32
  %xor.i.i.19 = xor i32 %conv1.i.i.19, %conv.i.i.19
  %conv2.i.i.19 = trunc i32 %xor.i.i.19 to i8
  %scevgep12.20 = getelementptr i8, i8* %x, i64 20
  %20 = load i8, i8* %scevgep12.20, align 1
  %conv.i.i.20 = zext i8 %20 to i32
  %conv1.i.i.20 = zext i8 %conv2.i.i.19 to i32
  %xor.i.i.20 = xor i32 %conv1.i.i.20, %conv.i.i.20
  %conv2.i.i.20 = trunc i32 %xor.i.i.20 to i8
  %scevgep12.21 = getelementptr i8, i8* %x, i64 21
  %21 = load i8, i8* %scevgep12.21, align 1
  %conv.i.i.21 = zext i8 %21 to i32
  %conv1.i.i.21 = zext i8 %conv2.i.i.20 to i32
  %xor.i.i.21 = xor i32 %conv1.i.i.21, %conv.i.i.21
  %conv2.i.i.21 = trunc i32 %xor.i.i.21 to i8
  %scevgep12.22 = getelementptr i8, i8* %x, i64 22
  %22 = load i8, i8* %scevgep12.22, align 1
  %conv.i.i.22 = zext i8 %22 to i32
  %conv1.i.i.22 = zext i8 %conv2.i.i.21 to i32
  %xor.i.i.22 = xor i32 %conv1.i.i.22, %conv.i.i.22
  %conv2.i.i.22 = trunc i32 %xor.i.i.22 to i8
  %scevgep12.23 = getelementptr i8, i8* %x, i64 23
  %23 = load i8, i8* %scevgep12.23, align 1
  %conv.i.i.23 = zext i8 %23 to i32
  %conv1.i.i.23 = zext i8 %conv2.i.i.22 to i32
  %xor.i.i.23 = xor i32 %conv1.i.i.23, %conv.i.i.23
  %conv2.i.i.23 = trunc i32 %xor.i.i.23 to i8
  %scevgep12.24 = getelementptr i8, i8* %x, i64 24
  %24 = load i8, i8* %scevgep12.24, align 1
  %conv.i.i.24 = zext i8 %24 to i32
  %conv1.i.i.24 = zext i8 %conv2.i.i.23 to i32
  %xor.i.i.24 = xor i32 %conv1.i.i.24, %conv.i.i.24
  %conv2.i.i.24 = trunc i32 %xor.i.i.24 to i8
  %scevgep12.25 = getelementptr i8, i8* %x, i64 25
  %25 = load i8, i8* %scevgep12.25, align 1
  %conv.i.i.25 = zext i8 %25 to i32
  %conv1.i.i.25 = zext i8 %conv2.i.i.24 to i32
  %xor.i.i.25 = xor i32 %conv1.i.i.25, %conv.i.i.25
  %conv2.i.i.25 = trunc i32 %xor.i.i.25 to i8
  %scevgep12.26 = getelementptr i8, i8* %x, i64 26
  %26 = load i8, i8* %scevgep12.26, align 1
  %conv.i.i.26 = zext i8 %26 to i32
  %conv1.i.i.26 = zext i8 %conv2.i.i.25 to i32
  %xor.i.i.26 = xor i32 %conv1.i.i.26, %conv.i.i.26
  %conv2.i.i.26 = trunc i32 %xor.i.i.26 to i8
  %scevgep12.27 = getelementptr i8, i8* %x, i64 27
  %27 = load i8, i8* %scevgep12.27, align 1
  %conv.i.i.27 = zext i8 %27 to i32
  %conv1.i.i.27 = zext i8 %conv2.i.i.26 to i32
  %xor.i.i.27 = xor i32 %conv1.i.i.27, %conv.i.i.27
  %conv2.i.i.27 = trunc i32 %xor.i.i.27 to i8
  %scevgep12.28 = getelementptr i8, i8* %x, i64 28
  %28 = load i8, i8* %scevgep12.28, align 1
  %conv.i.i.28 = zext i8 %28 to i32
  %conv1.i.i.28 = zext i8 %conv2.i.i.27 to i32
  %xor.i.i.28 = xor i32 %conv1.i.i.28, %conv.i.i.28
  %conv2.i.i.28 = trunc i32 %xor.i.i.28 to i8
  %scevgep12.29 = getelementptr i8, i8* %x, i64 29
  %29 = load i8, i8* %scevgep12.29, align 1
  %conv.i.i.29 = zext i8 %29 to i32
  %conv1.i.i.29 = zext i8 %conv2.i.i.28 to i32
  %xor.i.i.29 = xor i32 %conv1.i.i.29, %conv.i.i.29
  %conv2.i.i.29 = trunc i32 %xor.i.i.29 to i8
  %scevgep12.30 = getelementptr i8, i8* %x, i64 30
  %30 = load i8, i8* %scevgep12.30, align 1
  %conv.i.i.30 = zext i8 %30 to i32
  %conv1.i.i.30 = zext i8 %conv2.i.i.29 to i32
  %xor.i.i.30 = xor i32 %conv1.i.i.30, %conv.i.i.30
  %conv2.i.i.30 = trunc i32 %xor.i.i.30 to i8
  %scevgep12.31 = getelementptr i8, i8* %x, i64 31
  %31 = load i8, i8* %scevgep12.31, align 1
  %conv.i.i.31 = zext i8 %31 to i32
  %conv1.i.i.31 = zext i8 %conv2.i.i.30 to i32
  %xor.i.i.31 = xor i32 %conv1.i.i.31, %conv.i.i.31
  %conv2.i.i.31 = trunc i32 %xor.i.i.31 to i8
  %scevgep12.32 = getelementptr i8, i8* %x, i64 32
  %32 = load i8, i8* %scevgep12.32, align 1
  %conv.i.i.32 = zext i8 %32 to i32
  %conv1.i.i.32 = zext i8 %conv2.i.i.31 to i32
  %xor.i.i.32 = xor i32 %conv1.i.i.32, %conv.i.i.32
  %conv2.i.i.32 = trunc i32 %xor.i.i.32 to i8
  %scevgep12.33 = getelementptr i8, i8* %x, i64 33
  %33 = load i8, i8* %scevgep12.33, align 1
  %conv.i.i.33 = zext i8 %33 to i32
  %conv1.i.i.33 = zext i8 %conv2.i.i.32 to i32
  %xor.i.i.33 = xor i32 %conv1.i.i.33, %conv.i.i.33
  %conv2.i.i.33 = trunc i32 %xor.i.i.33 to i8
  %scevgep12.34 = getelementptr i8, i8* %x, i64 34
  %34 = load i8, i8* %scevgep12.34, align 1
  %conv.i.i.34 = zext i8 %34 to i32
  %conv1.i.i.34 = zext i8 %conv2.i.i.33 to i32
  %xor.i.i.34 = xor i32 %conv1.i.i.34, %conv.i.i.34
  %conv2.i.i.34 = trunc i32 %xor.i.i.34 to i8
  %scevgep12.35 = getelementptr i8, i8* %x, i64 35
  %35 = load i8, i8* %scevgep12.35, align 1
  %conv.i.i.35 = zext i8 %35 to i32
  %conv1.i.i.35 = zext i8 %conv2.i.i.34 to i32
  %xor.i.i.35 = xor i32 %conv1.i.i.35, %conv.i.i.35
  %conv2.i.i.35 = trunc i32 %xor.i.i.35 to i8
  %scevgep12.36 = getelementptr i8, i8* %x, i64 36
  %36 = load i8, i8* %scevgep12.36, align 1
  %conv.i.i.36 = zext i8 %36 to i32
  %conv1.i.i.36 = zext i8 %conv2.i.i.35 to i32
  %xor.i.i.36 = xor i32 %conv1.i.i.36, %conv.i.i.36
  %conv2.i.i.36 = trunc i32 %xor.i.i.36 to i8
  %scevgep12.37 = getelementptr i8, i8* %x, i64 37
  %37 = load i8, i8* %scevgep12.37, align 1
  %conv.i.i.37 = zext i8 %37 to i32
  %conv1.i.i.37 = zext i8 %conv2.i.i.36 to i32
  %xor.i.i.37 = xor i32 %conv1.i.i.37, %conv.i.i.37
  %conv2.i.i.37 = trunc i32 %xor.i.i.37 to i8
  %scevgep12.38 = getelementptr i8, i8* %x, i64 38
  %38 = load i8, i8* %scevgep12.38, align 1
  %conv.i.i.38 = zext i8 %38 to i32
  %conv1.i.i.38 = zext i8 %conv2.i.i.37 to i32
  %xor.i.i.38 = xor i32 %conv1.i.i.38, %conv.i.i.38
  %conv2.i.i.38 = trunc i32 %xor.i.i.38 to i8
  %scevgep12.39 = getelementptr i8, i8* %x, i64 39
  %39 = load i8, i8* %scevgep12.39, align 1
  %conv.i.i.39 = zext i8 %39 to i32
  %conv1.i.i.39 = zext i8 %conv2.i.i.38 to i32
  %xor.i.i.39 = xor i32 %conv1.i.i.39, %conv.i.i.39
  %conv2.i.i.39 = trunc i32 %xor.i.i.39 to i8
  %scevgep12.40 = getelementptr i8, i8* %x, i64 40
  %40 = load i8, i8* %scevgep12.40, align 1
  %conv.i.i.40 = zext i8 %40 to i32
  %conv1.i.i.40 = zext i8 %conv2.i.i.39 to i32
  %xor.i.i.40 = xor i32 %conv1.i.i.40, %conv.i.i.40
  %conv2.i.i.40 = trunc i32 %xor.i.i.40 to i8
  %conv2 = zext i8 %conv2.i.i.40 to i32
  %cmp = icmp eq i32 %conv, %conv2
  call void @assume(i1 zeroext %cmp)
  %call7 = call zeroext i8 (...) @rand()
  %conv8 = zext i8 %call7 to i32
  %41 = load i8, i8* %x, align 1
  %conv9 = zext i8 %41 to i32
  %xor = xor i32 %conv9, %conv8
  %conv10 = trunc i32 %xor to i8
  store i8 %conv10, i8* %x, align 1
  %conv11 = zext i8 %call7 to i32
  %scevgep8 = getelementptr i8, i8* %x, i64 1
  %42 = load i8, i8* %scevgep8, align 1
  %conv13 = zext i8 %42 to i32
  %xor14 = xor i32 %conv13, %conv11
  %conv15 = trunc i32 %xor14 to i8
  store i8 %conv15, i8* %scevgep8, align 1
  %call7.1 = call zeroext i8 (...) @rand()
  %conv8.1 = zext i8 %call7.1 to i32
  %43 = load i8, i8* %x, align 1
  %conv9.1 = zext i8 %43 to i32
  %xor.1 = xor i32 %conv9.1, %conv8.1
  %conv10.1 = trunc i32 %xor.1 to i8
  store i8 %conv10.1, i8* %x, align 1
  %conv11.1 = zext i8 %call7.1 to i32
  %scevgep8.1 = getelementptr i8, i8* %x, i64 2
  %44 = load i8, i8* %scevgep8.1, align 1
  %conv13.1 = zext i8 %44 to i32
  %xor14.1 = xor i32 %conv13.1, %conv11.1
  %conv15.1 = trunc i32 %xor14.1 to i8
  store i8 %conv15.1, i8* %scevgep8.1, align 1
  %call7.2 = call zeroext i8 (...) @rand()
  %conv8.2 = zext i8 %call7.2 to i32
  %45 = load i8, i8* %x, align 1
  %conv9.2 = zext i8 %45 to i32
  %xor.2 = xor i32 %conv9.2, %conv8.2
  %conv10.2 = trunc i32 %xor.2 to i8
  store i8 %conv10.2, i8* %x, align 1
  %conv11.2 = zext i8 %call7.2 to i32
  %scevgep8.2 = getelementptr i8, i8* %x, i64 3
  %46 = load i8, i8* %scevgep8.2, align 1
  %conv13.2 = zext i8 %46 to i32
  %xor14.2 = xor i32 %conv13.2, %conv11.2
  %conv15.2 = trunc i32 %xor14.2 to i8
  store i8 %conv15.2, i8* %scevgep8.2, align 1
  %call7.3 = call zeroext i8 (...) @rand()
  %conv8.3 = zext i8 %call7.3 to i32
  %47 = load i8, i8* %x, align 1
  %conv9.3 = zext i8 %47 to i32
  %xor.3 = xor i32 %conv9.3, %conv8.3
  %conv10.3 = trunc i32 %xor.3 to i8
  store i8 %conv10.3, i8* %x, align 1
  %conv11.3 = zext i8 %call7.3 to i32
  %scevgep8.3 = getelementptr i8, i8* %x, i64 4
  %48 = load i8, i8* %scevgep8.3, align 1
  %conv13.3 = zext i8 %48 to i32
  %xor14.3 = xor i32 %conv13.3, %conv11.3
  %conv15.3 = trunc i32 %xor14.3 to i8
  store i8 %conv15.3, i8* %scevgep8.3, align 1
  %call7.4 = call zeroext i8 (...) @rand()
  %conv8.4 = zext i8 %call7.4 to i32
  %49 = load i8, i8* %x, align 1
  %conv9.4 = zext i8 %49 to i32
  %xor.4 = xor i32 %conv9.4, %conv8.4
  %conv10.4 = trunc i32 %xor.4 to i8
  store i8 %conv10.4, i8* %x, align 1
  %conv11.4 = zext i8 %call7.4 to i32
  %scevgep8.4 = getelementptr i8, i8* %x, i64 5
  %50 = load i8, i8* %scevgep8.4, align 1
  %conv13.4 = zext i8 %50 to i32
  %xor14.4 = xor i32 %conv13.4, %conv11.4
  %conv15.4 = trunc i32 %xor14.4 to i8
  store i8 %conv15.4, i8* %scevgep8.4, align 1
  %call7.5 = call zeroext i8 (...) @rand()
  %conv8.5 = zext i8 %call7.5 to i32
  %51 = load i8, i8* %x, align 1
  %conv9.5 = zext i8 %51 to i32
  %xor.5 = xor i32 %conv9.5, %conv8.5
  %conv10.5 = trunc i32 %xor.5 to i8
  store i8 %conv10.5, i8* %x, align 1
  %conv11.5 = zext i8 %call7.5 to i32
  %scevgep8.5 = getelementptr i8, i8* %x, i64 6
  %52 = load i8, i8* %scevgep8.5, align 1
  %conv13.5 = zext i8 %52 to i32
  %xor14.5 = xor i32 %conv13.5, %conv11.5
  %conv15.5 = trunc i32 %xor14.5 to i8
  store i8 %conv15.5, i8* %scevgep8.5, align 1
  %call7.6 = call zeroext i8 (...) @rand()
  %conv8.6 = zext i8 %call7.6 to i32
  %53 = load i8, i8* %x, align 1
  %conv9.6 = zext i8 %53 to i32
  %xor.6 = xor i32 %conv9.6, %conv8.6
  %conv10.6 = trunc i32 %xor.6 to i8
  store i8 %conv10.6, i8* %x, align 1
  %conv11.6 = zext i8 %call7.6 to i32
  %scevgep8.6 = getelementptr i8, i8* %x, i64 7
  %54 = load i8, i8* %scevgep8.6, align 1
  %conv13.6 = zext i8 %54 to i32
  %xor14.6 = xor i32 %conv13.6, %conv11.6
  %conv15.6 = trunc i32 %xor14.6 to i8
  store i8 %conv15.6, i8* %scevgep8.6, align 1
  %call7.7 = call zeroext i8 (...) @rand()
  %conv8.7 = zext i8 %call7.7 to i32
  %55 = load i8, i8* %x, align 1
  %conv9.7 = zext i8 %55 to i32
  %xor.7 = xor i32 %conv9.7, %conv8.7
  %conv10.7 = trunc i32 %xor.7 to i8
  store i8 %conv10.7, i8* %x, align 1
  %conv11.7 = zext i8 %call7.7 to i32
  %scevgep8.7 = getelementptr i8, i8* %x, i64 8
  %56 = load i8, i8* %scevgep8.7, align 1
  %conv13.7 = zext i8 %56 to i32
  %xor14.7 = xor i32 %conv13.7, %conv11.7
  %conv15.7 = trunc i32 %xor14.7 to i8
  store i8 %conv15.7, i8* %scevgep8.7, align 1
  %call7.8 = call zeroext i8 (...) @rand()
  %conv8.8 = zext i8 %call7.8 to i32
  %57 = load i8, i8* %x, align 1
  %conv9.8 = zext i8 %57 to i32
  %xor.8 = xor i32 %conv9.8, %conv8.8
  %conv10.8 = trunc i32 %xor.8 to i8
  store i8 %conv10.8, i8* %x, align 1
  %conv11.8 = zext i8 %call7.8 to i32
  %scevgep8.8 = getelementptr i8, i8* %x, i64 9
  %58 = load i8, i8* %scevgep8.8, align 1
  %conv13.8 = zext i8 %58 to i32
  %xor14.8 = xor i32 %conv13.8, %conv11.8
  %conv15.8 = trunc i32 %xor14.8 to i8
  store i8 %conv15.8, i8* %scevgep8.8, align 1
  %call7.9 = call zeroext i8 (...) @rand()
  %conv8.9 = zext i8 %call7.9 to i32
  %59 = load i8, i8* %x, align 1
  %conv9.9 = zext i8 %59 to i32
  %xor.9 = xor i32 %conv9.9, %conv8.9
  %conv10.9 = trunc i32 %xor.9 to i8
  store i8 %conv10.9, i8* %x, align 1
  %conv11.9 = zext i8 %call7.9 to i32
  %scevgep8.9 = getelementptr i8, i8* %x, i64 10
  %60 = load i8, i8* %scevgep8.9, align 1
  %conv13.9 = zext i8 %60 to i32
  %xor14.9 = xor i32 %conv13.9, %conv11.9
  %conv15.9 = trunc i32 %xor14.9 to i8
  store i8 %conv15.9, i8* %scevgep8.9, align 1
  %call7.10 = call zeroext i8 (...) @rand()
  %conv8.10 = zext i8 %call7.10 to i32
  %61 = load i8, i8* %x, align 1
  %conv9.10 = zext i8 %61 to i32
  %xor.10 = xor i32 %conv9.10, %conv8.10
  %conv10.10 = trunc i32 %xor.10 to i8
  store i8 %conv10.10, i8* %x, align 1
  %conv11.10 = zext i8 %call7.10 to i32
  %scevgep8.10 = getelementptr i8, i8* %x, i64 11
  %62 = load i8, i8* %scevgep8.10, align 1
  %conv13.10 = zext i8 %62 to i32
  %xor14.10 = xor i32 %conv13.10, %conv11.10
  %conv15.10 = trunc i32 %xor14.10 to i8
  store i8 %conv15.10, i8* %scevgep8.10, align 1
  %call7.11 = call zeroext i8 (...) @rand()
  %conv8.11 = zext i8 %call7.11 to i32
  %63 = load i8, i8* %x, align 1
  %conv9.11 = zext i8 %63 to i32
  %xor.11 = xor i32 %conv9.11, %conv8.11
  %conv10.11 = trunc i32 %xor.11 to i8
  store i8 %conv10.11, i8* %x, align 1
  %conv11.11 = zext i8 %call7.11 to i32
  %scevgep8.11 = getelementptr i8, i8* %x, i64 12
  %64 = load i8, i8* %scevgep8.11, align 1
  %conv13.11 = zext i8 %64 to i32
  %xor14.11 = xor i32 %conv13.11, %conv11.11
  %conv15.11 = trunc i32 %xor14.11 to i8
  store i8 %conv15.11, i8* %scevgep8.11, align 1
  %call7.12 = call zeroext i8 (...) @rand()
  %conv8.12 = zext i8 %call7.12 to i32
  %65 = load i8, i8* %x, align 1
  %conv9.12 = zext i8 %65 to i32
  %xor.12 = xor i32 %conv9.12, %conv8.12
  %conv10.12 = trunc i32 %xor.12 to i8
  store i8 %conv10.12, i8* %x, align 1
  %conv11.12 = zext i8 %call7.12 to i32
  %scevgep8.12 = getelementptr i8, i8* %x, i64 13
  %66 = load i8, i8* %scevgep8.12, align 1
  %conv13.12 = zext i8 %66 to i32
  %xor14.12 = xor i32 %conv13.12, %conv11.12
  %conv15.12 = trunc i32 %xor14.12 to i8
  store i8 %conv15.12, i8* %scevgep8.12, align 1
  %call7.13 = call zeroext i8 (...) @rand()
  %conv8.13 = zext i8 %call7.13 to i32
  %67 = load i8, i8* %x, align 1
  %conv9.13 = zext i8 %67 to i32
  %xor.13 = xor i32 %conv9.13, %conv8.13
  %conv10.13 = trunc i32 %xor.13 to i8
  store i8 %conv10.13, i8* %x, align 1
  %conv11.13 = zext i8 %call7.13 to i32
  %scevgep8.13 = getelementptr i8, i8* %x, i64 14
  %68 = load i8, i8* %scevgep8.13, align 1
  %conv13.13 = zext i8 %68 to i32
  %xor14.13 = xor i32 %conv13.13, %conv11.13
  %conv15.13 = trunc i32 %xor14.13 to i8
  store i8 %conv15.13, i8* %scevgep8.13, align 1
  %call7.14 = call zeroext i8 (...) @rand()
  %conv8.14 = zext i8 %call7.14 to i32
  %69 = load i8, i8* %x, align 1
  %conv9.14 = zext i8 %69 to i32
  %xor.14 = xor i32 %conv9.14, %conv8.14
  %conv10.14 = trunc i32 %xor.14 to i8
  store i8 %conv10.14, i8* %x, align 1
  %conv11.14 = zext i8 %call7.14 to i32
  %scevgep8.14 = getelementptr i8, i8* %x, i64 15
  %70 = load i8, i8* %scevgep8.14, align 1
  %conv13.14 = zext i8 %70 to i32
  %xor14.14 = xor i32 %conv13.14, %conv11.14
  %conv15.14 = trunc i32 %xor14.14 to i8
  store i8 %conv15.14, i8* %scevgep8.14, align 1
  %call7.15 = call zeroext i8 (...) @rand()
  %conv8.15 = zext i8 %call7.15 to i32
  %71 = load i8, i8* %x, align 1
  %conv9.15 = zext i8 %71 to i32
  %xor.15 = xor i32 %conv9.15, %conv8.15
  %conv10.15 = trunc i32 %xor.15 to i8
  store i8 %conv10.15, i8* %x, align 1
  %conv11.15 = zext i8 %call7.15 to i32
  %scevgep8.15 = getelementptr i8, i8* %x, i64 16
  %72 = load i8, i8* %scevgep8.15, align 1
  %conv13.15 = zext i8 %72 to i32
  %xor14.15 = xor i32 %conv13.15, %conv11.15
  %conv15.15 = trunc i32 %xor14.15 to i8
  store i8 %conv15.15, i8* %scevgep8.15, align 1
  %call7.16 = call zeroext i8 (...) @rand()
  %conv8.16 = zext i8 %call7.16 to i32
  %73 = load i8, i8* %x, align 1
  %conv9.16 = zext i8 %73 to i32
  %xor.16 = xor i32 %conv9.16, %conv8.16
  %conv10.16 = trunc i32 %xor.16 to i8
  store i8 %conv10.16, i8* %x, align 1
  %conv11.16 = zext i8 %call7.16 to i32
  %scevgep8.16 = getelementptr i8, i8* %x, i64 17
  %74 = load i8, i8* %scevgep8.16, align 1
  %conv13.16 = zext i8 %74 to i32
  %xor14.16 = xor i32 %conv13.16, %conv11.16
  %conv15.16 = trunc i32 %xor14.16 to i8
  store i8 %conv15.16, i8* %scevgep8.16, align 1
  %call7.17 = call zeroext i8 (...) @rand()
  %conv8.17 = zext i8 %call7.17 to i32
  %75 = load i8, i8* %x, align 1
  %conv9.17 = zext i8 %75 to i32
  %xor.17 = xor i32 %conv9.17, %conv8.17
  %conv10.17 = trunc i32 %xor.17 to i8
  store i8 %conv10.17, i8* %x, align 1
  %conv11.17 = zext i8 %call7.17 to i32
  %scevgep8.17 = getelementptr i8, i8* %x, i64 18
  %76 = load i8, i8* %scevgep8.17, align 1
  %conv13.17 = zext i8 %76 to i32
  %xor14.17 = xor i32 %conv13.17, %conv11.17
  %conv15.17 = trunc i32 %xor14.17 to i8
  store i8 %conv15.17, i8* %scevgep8.17, align 1
  %call7.18 = call zeroext i8 (...) @rand()
  %conv8.18 = zext i8 %call7.18 to i32
  %77 = load i8, i8* %x, align 1
  %conv9.18 = zext i8 %77 to i32
  %xor.18 = xor i32 %conv9.18, %conv8.18
  %conv10.18 = trunc i32 %xor.18 to i8
  store i8 %conv10.18, i8* %x, align 1
  %conv11.18 = zext i8 %call7.18 to i32
  %scevgep8.18 = getelementptr i8, i8* %x, i64 19
  %78 = load i8, i8* %scevgep8.18, align 1
  %conv13.18 = zext i8 %78 to i32
  %xor14.18 = xor i32 %conv13.18, %conv11.18
  %conv15.18 = trunc i32 %xor14.18 to i8
  store i8 %conv15.18, i8* %scevgep8.18, align 1
  %call7.19 = call zeroext i8 (...) @rand()
  %conv8.19 = zext i8 %call7.19 to i32
  %79 = load i8, i8* %x, align 1
  %conv9.19 = zext i8 %79 to i32
  %xor.19 = xor i32 %conv9.19, %conv8.19
  %conv10.19 = trunc i32 %xor.19 to i8
  store i8 %conv10.19, i8* %x, align 1
  %conv11.19 = zext i8 %call7.19 to i32
  %scevgep8.19 = getelementptr i8, i8* %x, i64 20
  %80 = load i8, i8* %scevgep8.19, align 1
  %conv13.19 = zext i8 %80 to i32
  %xor14.19 = xor i32 %conv13.19, %conv11.19
  %conv15.19 = trunc i32 %xor14.19 to i8
  store i8 %conv15.19, i8* %scevgep8.19, align 1
  %call7.20 = call zeroext i8 (...) @rand()
  %conv8.20 = zext i8 %call7.20 to i32
  %81 = load i8, i8* %x, align 1
  %conv9.20 = zext i8 %81 to i32
  %xor.20 = xor i32 %conv9.20, %conv8.20
  %conv10.20 = trunc i32 %xor.20 to i8
  store i8 %conv10.20, i8* %x, align 1
  %conv11.20 = zext i8 %call7.20 to i32
  %scevgep8.20 = getelementptr i8, i8* %x, i64 21
  %82 = load i8, i8* %scevgep8.20, align 1
  %conv13.20 = zext i8 %82 to i32
  %xor14.20 = xor i32 %conv13.20, %conv11.20
  %conv15.20 = trunc i32 %xor14.20 to i8
  store i8 %conv15.20, i8* %scevgep8.20, align 1
  %call7.21 = call zeroext i8 (...) @rand()
  %conv8.21 = zext i8 %call7.21 to i32
  %83 = load i8, i8* %x, align 1
  %conv9.21 = zext i8 %83 to i32
  %xor.21 = xor i32 %conv9.21, %conv8.21
  %conv10.21 = trunc i32 %xor.21 to i8
  store i8 %conv10.21, i8* %x, align 1
  %conv11.21 = zext i8 %call7.21 to i32
  %scevgep8.21 = getelementptr i8, i8* %x, i64 22
  %84 = load i8, i8* %scevgep8.21, align 1
  %conv13.21 = zext i8 %84 to i32
  %xor14.21 = xor i32 %conv13.21, %conv11.21
  %conv15.21 = trunc i32 %xor14.21 to i8
  store i8 %conv15.21, i8* %scevgep8.21, align 1
  %call7.22 = call zeroext i8 (...) @rand()
  %conv8.22 = zext i8 %call7.22 to i32
  %85 = load i8, i8* %x, align 1
  %conv9.22 = zext i8 %85 to i32
  %xor.22 = xor i32 %conv9.22, %conv8.22
  %conv10.22 = trunc i32 %xor.22 to i8
  store i8 %conv10.22, i8* %x, align 1
  %conv11.22 = zext i8 %call7.22 to i32
  %scevgep8.22 = getelementptr i8, i8* %x, i64 23
  %86 = load i8, i8* %scevgep8.22, align 1
  %conv13.22 = zext i8 %86 to i32
  %xor14.22 = xor i32 %conv13.22, %conv11.22
  %conv15.22 = trunc i32 %xor14.22 to i8
  store i8 %conv15.22, i8* %scevgep8.22, align 1
  %call7.23 = call zeroext i8 (...) @rand()
  %conv8.23 = zext i8 %call7.23 to i32
  %87 = load i8, i8* %x, align 1
  %conv9.23 = zext i8 %87 to i32
  %xor.23 = xor i32 %conv9.23, %conv8.23
  %conv10.23 = trunc i32 %xor.23 to i8
  store i8 %conv10.23, i8* %x, align 1
  %conv11.23 = zext i8 %call7.23 to i32
  %scevgep8.23 = getelementptr i8, i8* %x, i64 24
  %88 = load i8, i8* %scevgep8.23, align 1
  %conv13.23 = zext i8 %88 to i32
  %xor14.23 = xor i32 %conv13.23, %conv11.23
  %conv15.23 = trunc i32 %xor14.23 to i8
  store i8 %conv15.23, i8* %scevgep8.23, align 1
  %call7.24 = call zeroext i8 (...) @rand()
  %conv8.24 = zext i8 %call7.24 to i32
  %89 = load i8, i8* %x, align 1
  %conv9.24 = zext i8 %89 to i32
  %xor.24 = xor i32 %conv9.24, %conv8.24
  %conv10.24 = trunc i32 %xor.24 to i8
  store i8 %conv10.24, i8* %x, align 1
  %conv11.24 = zext i8 %call7.24 to i32
  %scevgep8.24 = getelementptr i8, i8* %x, i64 25
  %90 = load i8, i8* %scevgep8.24, align 1
  %conv13.24 = zext i8 %90 to i32
  %xor14.24 = xor i32 %conv13.24, %conv11.24
  %conv15.24 = trunc i32 %xor14.24 to i8
  store i8 %conv15.24, i8* %scevgep8.24, align 1
  %call7.25 = call zeroext i8 (...) @rand()
  %conv8.25 = zext i8 %call7.25 to i32
  %91 = load i8, i8* %x, align 1
  %conv9.25 = zext i8 %91 to i32
  %xor.25 = xor i32 %conv9.25, %conv8.25
  %conv10.25 = trunc i32 %xor.25 to i8
  store i8 %conv10.25, i8* %x, align 1
  %conv11.25 = zext i8 %call7.25 to i32
  %scevgep8.25 = getelementptr i8, i8* %x, i64 26
  %92 = load i8, i8* %scevgep8.25, align 1
  %conv13.25 = zext i8 %92 to i32
  %xor14.25 = xor i32 %conv13.25, %conv11.25
  %conv15.25 = trunc i32 %xor14.25 to i8
  store i8 %conv15.25, i8* %scevgep8.25, align 1
  %call7.26 = call zeroext i8 (...) @rand()
  %conv8.26 = zext i8 %call7.26 to i32
  %93 = load i8, i8* %x, align 1
  %conv9.26 = zext i8 %93 to i32
  %xor.26 = xor i32 %conv9.26, %conv8.26
  %conv10.26 = trunc i32 %xor.26 to i8
  store i8 %conv10.26, i8* %x, align 1
  %conv11.26 = zext i8 %call7.26 to i32
  %scevgep8.26 = getelementptr i8, i8* %x, i64 27
  %94 = load i8, i8* %scevgep8.26, align 1
  %conv13.26 = zext i8 %94 to i32
  %xor14.26 = xor i32 %conv13.26, %conv11.26
  %conv15.26 = trunc i32 %xor14.26 to i8
  store i8 %conv15.26, i8* %scevgep8.26, align 1
  %call7.27 = call zeroext i8 (...) @rand()
  %conv8.27 = zext i8 %call7.27 to i32
  %95 = load i8, i8* %x, align 1
  %conv9.27 = zext i8 %95 to i32
  %xor.27 = xor i32 %conv9.27, %conv8.27
  %conv10.27 = trunc i32 %xor.27 to i8
  store i8 %conv10.27, i8* %x, align 1
  %conv11.27 = zext i8 %call7.27 to i32
  %scevgep8.27 = getelementptr i8, i8* %x, i64 28
  %96 = load i8, i8* %scevgep8.27, align 1
  %conv13.27 = zext i8 %96 to i32
  %xor14.27 = xor i32 %conv13.27, %conv11.27
  %conv15.27 = trunc i32 %xor14.27 to i8
  store i8 %conv15.27, i8* %scevgep8.27, align 1
  %call7.28 = call zeroext i8 (...) @rand()
  %conv8.28 = zext i8 %call7.28 to i32
  %97 = load i8, i8* %x, align 1
  %conv9.28 = zext i8 %97 to i32
  %xor.28 = xor i32 %conv9.28, %conv8.28
  %conv10.28 = trunc i32 %xor.28 to i8
  store i8 %conv10.28, i8* %x, align 1
  %conv11.28 = zext i8 %call7.28 to i32
  %scevgep8.28 = getelementptr i8, i8* %x, i64 29
  %98 = load i8, i8* %scevgep8.28, align 1
  %conv13.28 = zext i8 %98 to i32
  %xor14.28 = xor i32 %conv13.28, %conv11.28
  %conv15.28 = trunc i32 %xor14.28 to i8
  store i8 %conv15.28, i8* %scevgep8.28, align 1
  %call7.29 = call zeroext i8 (...) @rand()
  %conv8.29 = zext i8 %call7.29 to i32
  %99 = load i8, i8* %x, align 1
  %conv9.29 = zext i8 %99 to i32
  %xor.29 = xor i32 %conv9.29, %conv8.29
  %conv10.29 = trunc i32 %xor.29 to i8
  store i8 %conv10.29, i8* %x, align 1
  %conv11.29 = zext i8 %call7.29 to i32
  %scevgep8.29 = getelementptr i8, i8* %x, i64 30
  %100 = load i8, i8* %scevgep8.29, align 1
  %conv13.29 = zext i8 %100 to i32
  %xor14.29 = xor i32 %conv13.29, %conv11.29
  %conv15.29 = trunc i32 %xor14.29 to i8
  store i8 %conv15.29, i8* %scevgep8.29, align 1
  %call7.30 = call zeroext i8 (...) @rand()
  %conv8.30 = zext i8 %call7.30 to i32
  %101 = load i8, i8* %x, align 1
  %conv9.30 = zext i8 %101 to i32
  %xor.30 = xor i32 %conv9.30, %conv8.30
  %conv10.30 = trunc i32 %xor.30 to i8
  store i8 %conv10.30, i8* %x, align 1
  %conv11.30 = zext i8 %call7.30 to i32
  %scevgep8.30 = getelementptr i8, i8* %x, i64 31
  %102 = load i8, i8* %scevgep8.30, align 1
  %conv13.30 = zext i8 %102 to i32
  %xor14.30 = xor i32 %conv13.30, %conv11.30
  %conv15.30 = trunc i32 %xor14.30 to i8
  store i8 %conv15.30, i8* %scevgep8.30, align 1
  %call7.31 = call zeroext i8 (...) @rand()
  %conv8.31 = zext i8 %call7.31 to i32
  %103 = load i8, i8* %x, align 1
  %conv9.31 = zext i8 %103 to i32
  %xor.31 = xor i32 %conv9.31, %conv8.31
  %conv10.31 = trunc i32 %xor.31 to i8
  store i8 %conv10.31, i8* %x, align 1
  %conv11.31 = zext i8 %call7.31 to i32
  %scevgep8.31 = getelementptr i8, i8* %x, i64 32
  %104 = load i8, i8* %scevgep8.31, align 1
  %conv13.31 = zext i8 %104 to i32
  %xor14.31 = xor i32 %conv13.31, %conv11.31
  %conv15.31 = trunc i32 %xor14.31 to i8
  store i8 %conv15.31, i8* %scevgep8.31, align 1
  %call7.32 = call zeroext i8 (...) @rand()
  %conv8.32 = zext i8 %call7.32 to i32
  %105 = load i8, i8* %x, align 1
  %conv9.32 = zext i8 %105 to i32
  %xor.32 = xor i32 %conv9.32, %conv8.32
  %conv10.32 = trunc i32 %xor.32 to i8
  store i8 %conv10.32, i8* %x, align 1
  %conv11.32 = zext i8 %call7.32 to i32
  %scevgep8.32 = getelementptr i8, i8* %x, i64 33
  %106 = load i8, i8* %scevgep8.32, align 1
  %conv13.32 = zext i8 %106 to i32
  %xor14.32 = xor i32 %conv13.32, %conv11.32
  %conv15.32 = trunc i32 %xor14.32 to i8
  store i8 %conv15.32, i8* %scevgep8.32, align 1
  %call7.33 = call zeroext i8 (...) @rand()
  %conv8.33 = zext i8 %call7.33 to i32
  %107 = load i8, i8* %x, align 1
  %conv9.33 = zext i8 %107 to i32
  %xor.33 = xor i32 %conv9.33, %conv8.33
  %conv10.33 = trunc i32 %xor.33 to i8
  store i8 %conv10.33, i8* %x, align 1
  %conv11.33 = zext i8 %call7.33 to i32
  %scevgep8.33 = getelementptr i8, i8* %x, i64 34
  %108 = load i8, i8* %scevgep8.33, align 1
  %conv13.33 = zext i8 %108 to i32
  %xor14.33 = xor i32 %conv13.33, %conv11.33
  %conv15.33 = trunc i32 %xor14.33 to i8
  store i8 %conv15.33, i8* %scevgep8.33, align 1
  %call7.34 = call zeroext i8 (...) @rand()
  %conv8.34 = zext i8 %call7.34 to i32
  %109 = load i8, i8* %x, align 1
  %conv9.34 = zext i8 %109 to i32
  %xor.34 = xor i32 %conv9.34, %conv8.34
  %conv10.34 = trunc i32 %xor.34 to i8
  store i8 %conv10.34, i8* %x, align 1
  %conv11.34 = zext i8 %call7.34 to i32
  %scevgep8.34 = getelementptr i8, i8* %x, i64 35
  %110 = load i8, i8* %scevgep8.34, align 1
  %conv13.34 = zext i8 %110 to i32
  %xor14.34 = xor i32 %conv13.34, %conv11.34
  %conv15.34 = trunc i32 %xor14.34 to i8
  store i8 %conv15.34, i8* %scevgep8.34, align 1
  %call7.35 = call zeroext i8 (...) @rand()
  %conv8.35 = zext i8 %call7.35 to i32
  %111 = load i8, i8* %x, align 1
  %conv9.35 = zext i8 %111 to i32
  %xor.35 = xor i32 %conv9.35, %conv8.35
  %conv10.35 = trunc i32 %xor.35 to i8
  store i8 %conv10.35, i8* %x, align 1
  %conv11.35 = zext i8 %call7.35 to i32
  %scevgep8.35 = getelementptr i8, i8* %x, i64 36
  %112 = load i8, i8* %scevgep8.35, align 1
  %conv13.35 = zext i8 %112 to i32
  %xor14.35 = xor i32 %conv13.35, %conv11.35
  %conv15.35 = trunc i32 %xor14.35 to i8
  store i8 %conv15.35, i8* %scevgep8.35, align 1
  %call7.36 = call zeroext i8 (...) @rand()
  %conv8.36 = zext i8 %call7.36 to i32
  %113 = load i8, i8* %x, align 1
  %conv9.36 = zext i8 %113 to i32
  %xor.36 = xor i32 %conv9.36, %conv8.36
  %conv10.36 = trunc i32 %xor.36 to i8
  store i8 %conv10.36, i8* %x, align 1
  %conv11.36 = zext i8 %call7.36 to i32
  %scevgep8.36 = getelementptr i8, i8* %x, i64 37
  %114 = load i8, i8* %scevgep8.36, align 1
  %conv13.36 = zext i8 %114 to i32
  %xor14.36 = xor i32 %conv13.36, %conv11.36
  %conv15.36 = trunc i32 %xor14.36 to i8
  store i8 %conv15.36, i8* %scevgep8.36, align 1
  %call7.37 = call zeroext i8 (...) @rand()
  %conv8.37 = zext i8 %call7.37 to i32
  %115 = load i8, i8* %x, align 1
  %conv9.37 = zext i8 %115 to i32
  %xor.37 = xor i32 %conv9.37, %conv8.37
  %conv10.37 = trunc i32 %xor.37 to i8
  store i8 %conv10.37, i8* %x, align 1
  %conv11.37 = zext i8 %call7.37 to i32
  %scevgep8.37 = getelementptr i8, i8* %x, i64 38
  %116 = load i8, i8* %scevgep8.37, align 1
  %conv13.37 = zext i8 %116 to i32
  %xor14.37 = xor i32 %conv13.37, %conv11.37
  %conv15.37 = trunc i32 %xor14.37 to i8
  store i8 %conv15.37, i8* %scevgep8.37, align 1
  %call7.38 = call zeroext i8 (...) @rand()
  %conv8.38 = zext i8 %call7.38 to i32
  %117 = load i8, i8* %x, align 1
  %conv9.38 = zext i8 %117 to i32
  %xor.38 = xor i32 %conv9.38, %conv8.38
  %conv10.38 = trunc i32 %xor.38 to i8
  store i8 %conv10.38, i8* %x, align 1
  %conv11.38 = zext i8 %call7.38 to i32
  %scevgep8.38 = getelementptr i8, i8* %x, i64 39
  %118 = load i8, i8* %scevgep8.38, align 1
  %conv13.38 = zext i8 %118 to i32
  %xor14.38 = xor i32 %conv13.38, %conv11.38
  %conv15.38 = trunc i32 %xor14.38 to i8
  store i8 %conv15.38, i8* %scevgep8.38, align 1
  %call7.39 = call zeroext i8 (...) @rand()
  %conv8.39 = zext i8 %call7.39 to i32
  %119 = load i8, i8* %x, align 1
  %conv9.39 = zext i8 %119 to i32
  %xor.39 = xor i32 %conv9.39, %conv8.39
  %conv10.39 = trunc i32 %xor.39 to i8
  store i8 %conv10.39, i8* %x, align 1
  %conv11.39 = zext i8 %call7.39 to i32
  %scevgep8.39 = getelementptr i8, i8* %x, i64 40
  %120 = load i8, i8* %scevgep8.39, align 1
  %conv13.39 = zext i8 %120 to i32
  %xor14.39 = xor i32 %conv13.39, %conv11.39
  %conv15.39 = trunc i32 %xor14.39 to i8
  store i8 %conv15.39, i8* %scevgep8.39, align 1
  %conv16 = zext i8 %call to i32
  %121 = load i8, i8* %x, align 1
  %scevgep.1 = getelementptr i8, i8* %x, i64 1
  %122 = load i8, i8* %scevgep.1, align 1
  %conv.i.i31.1 = zext i8 %122 to i32
  %conv1.i.i32.1 = zext i8 %121 to i32
  %xor.i.i33.1 = xor i32 %conv1.i.i32.1, %conv.i.i31.1
  %conv2.i.i34.1 = trunc i32 %xor.i.i33.1 to i8
  %scevgep.2 = getelementptr i8, i8* %x, i64 2
  %123 = load i8, i8* %scevgep.2, align 1
  %conv.i.i31.2 = zext i8 %123 to i32
  %conv1.i.i32.2 = zext i8 %conv2.i.i34.1 to i32
  %xor.i.i33.2 = xor i32 %conv1.i.i32.2, %conv.i.i31.2
  %conv2.i.i34.2 = trunc i32 %xor.i.i33.2 to i8
  %scevgep.3 = getelementptr i8, i8* %x, i64 3
  %124 = load i8, i8* %scevgep.3, align 1
  %conv.i.i31.3 = zext i8 %124 to i32
  %conv1.i.i32.3 = zext i8 %conv2.i.i34.2 to i32
  %xor.i.i33.3 = xor i32 %conv1.i.i32.3, %conv.i.i31.3
  %conv2.i.i34.3 = trunc i32 %xor.i.i33.3 to i8
  %scevgep.4 = getelementptr i8, i8* %x, i64 4
  %125 = load i8, i8* %scevgep.4, align 1
  %conv.i.i31.4 = zext i8 %125 to i32
  %conv1.i.i32.4 = zext i8 %conv2.i.i34.3 to i32
  %xor.i.i33.4 = xor i32 %conv1.i.i32.4, %conv.i.i31.4
  %conv2.i.i34.4 = trunc i32 %xor.i.i33.4 to i8
  %scevgep.5 = getelementptr i8, i8* %x, i64 5
  %126 = load i8, i8* %scevgep.5, align 1
  %conv.i.i31.5 = zext i8 %126 to i32
  %conv1.i.i32.5 = zext i8 %conv2.i.i34.4 to i32
  %xor.i.i33.5 = xor i32 %conv1.i.i32.5, %conv.i.i31.5
  %conv2.i.i34.5 = trunc i32 %xor.i.i33.5 to i8
  %scevgep.6 = getelementptr i8, i8* %x, i64 6
  %127 = load i8, i8* %scevgep.6, align 1
  %conv.i.i31.6 = zext i8 %127 to i32
  %conv1.i.i32.6 = zext i8 %conv2.i.i34.5 to i32
  %xor.i.i33.6 = xor i32 %conv1.i.i32.6, %conv.i.i31.6
  %conv2.i.i34.6 = trunc i32 %xor.i.i33.6 to i8
  %scevgep.7 = getelementptr i8, i8* %x, i64 7
  %128 = load i8, i8* %scevgep.7, align 1
  %conv.i.i31.7 = zext i8 %128 to i32
  %conv1.i.i32.7 = zext i8 %conv2.i.i34.6 to i32
  %xor.i.i33.7 = xor i32 %conv1.i.i32.7, %conv.i.i31.7
  %conv2.i.i34.7 = trunc i32 %xor.i.i33.7 to i8
  %scevgep.8 = getelementptr i8, i8* %x, i64 8
  %129 = load i8, i8* %scevgep.8, align 1
  %conv.i.i31.8 = zext i8 %129 to i32
  %conv1.i.i32.8 = zext i8 %conv2.i.i34.7 to i32
  %xor.i.i33.8 = xor i32 %conv1.i.i32.8, %conv.i.i31.8
  %conv2.i.i34.8 = trunc i32 %xor.i.i33.8 to i8
  %scevgep.9 = getelementptr i8, i8* %x, i64 9
  %130 = load i8, i8* %scevgep.9, align 1
  %conv.i.i31.9 = zext i8 %130 to i32
  %conv1.i.i32.9 = zext i8 %conv2.i.i34.8 to i32
  %xor.i.i33.9 = xor i32 %conv1.i.i32.9, %conv.i.i31.9
  %conv2.i.i34.9 = trunc i32 %xor.i.i33.9 to i8
  %scevgep.10 = getelementptr i8, i8* %x, i64 10
  %131 = load i8, i8* %scevgep.10, align 1
  %conv.i.i31.10 = zext i8 %131 to i32
  %conv1.i.i32.10 = zext i8 %conv2.i.i34.9 to i32
  %xor.i.i33.10 = xor i32 %conv1.i.i32.10, %conv.i.i31.10
  %conv2.i.i34.10 = trunc i32 %xor.i.i33.10 to i8
  %scevgep.11 = getelementptr i8, i8* %x, i64 11
  %132 = load i8, i8* %scevgep.11, align 1
  %conv.i.i31.11 = zext i8 %132 to i32
  %conv1.i.i32.11 = zext i8 %conv2.i.i34.10 to i32
  %xor.i.i33.11 = xor i32 %conv1.i.i32.11, %conv.i.i31.11
  %conv2.i.i34.11 = trunc i32 %xor.i.i33.11 to i8
  %scevgep.12 = getelementptr i8, i8* %x, i64 12
  %133 = load i8, i8* %scevgep.12, align 1
  %conv.i.i31.12 = zext i8 %133 to i32
  %conv1.i.i32.12 = zext i8 %conv2.i.i34.11 to i32
  %xor.i.i33.12 = xor i32 %conv1.i.i32.12, %conv.i.i31.12
  %conv2.i.i34.12 = trunc i32 %xor.i.i33.12 to i8
  %scevgep.13 = getelementptr i8, i8* %x, i64 13
  %134 = load i8, i8* %scevgep.13, align 1
  %conv.i.i31.13 = zext i8 %134 to i32
  %conv1.i.i32.13 = zext i8 %conv2.i.i34.12 to i32
  %xor.i.i33.13 = xor i32 %conv1.i.i32.13, %conv.i.i31.13
  %conv2.i.i34.13 = trunc i32 %xor.i.i33.13 to i8
  %scevgep.14 = getelementptr i8, i8* %x, i64 14
  %135 = load i8, i8* %scevgep.14, align 1
  %conv.i.i31.14 = zext i8 %135 to i32
  %conv1.i.i32.14 = zext i8 %conv2.i.i34.13 to i32
  %xor.i.i33.14 = xor i32 %conv1.i.i32.14, %conv.i.i31.14
  %conv2.i.i34.14 = trunc i32 %xor.i.i33.14 to i8
  %scevgep.15 = getelementptr i8, i8* %x, i64 15
  %136 = load i8, i8* %scevgep.15, align 1
  %conv.i.i31.15 = zext i8 %136 to i32
  %conv1.i.i32.15 = zext i8 %conv2.i.i34.14 to i32
  %xor.i.i33.15 = xor i32 %conv1.i.i32.15, %conv.i.i31.15
  %conv2.i.i34.15 = trunc i32 %xor.i.i33.15 to i8
  %scevgep.16 = getelementptr i8, i8* %x, i64 16
  %137 = load i8, i8* %scevgep.16, align 1
  %conv.i.i31.16 = zext i8 %137 to i32
  %conv1.i.i32.16 = zext i8 %conv2.i.i34.15 to i32
  %xor.i.i33.16 = xor i32 %conv1.i.i32.16, %conv.i.i31.16
  %conv2.i.i34.16 = trunc i32 %xor.i.i33.16 to i8
  %scevgep.17 = getelementptr i8, i8* %x, i64 17
  %138 = load i8, i8* %scevgep.17, align 1
  %conv.i.i31.17 = zext i8 %138 to i32
  %conv1.i.i32.17 = zext i8 %conv2.i.i34.16 to i32
  %xor.i.i33.17 = xor i32 %conv1.i.i32.17, %conv.i.i31.17
  %conv2.i.i34.17 = trunc i32 %xor.i.i33.17 to i8
  %scevgep.18 = getelementptr i8, i8* %x, i64 18
  %139 = load i8, i8* %scevgep.18, align 1
  %conv.i.i31.18 = zext i8 %139 to i32
  %conv1.i.i32.18 = zext i8 %conv2.i.i34.17 to i32
  %xor.i.i33.18 = xor i32 %conv1.i.i32.18, %conv.i.i31.18
  %conv2.i.i34.18 = trunc i32 %xor.i.i33.18 to i8
  %scevgep.19 = getelementptr i8, i8* %x, i64 19
  %140 = load i8, i8* %scevgep.19, align 1
  %conv.i.i31.19 = zext i8 %140 to i32
  %conv1.i.i32.19 = zext i8 %conv2.i.i34.18 to i32
  %xor.i.i33.19 = xor i32 %conv1.i.i32.19, %conv.i.i31.19
  %conv2.i.i34.19 = trunc i32 %xor.i.i33.19 to i8
  %scevgep.20 = getelementptr i8, i8* %x, i64 20
  %141 = load i8, i8* %scevgep.20, align 1
  %conv.i.i31.20 = zext i8 %141 to i32
  %conv1.i.i32.20 = zext i8 %conv2.i.i34.19 to i32
  %xor.i.i33.20 = xor i32 %conv1.i.i32.20, %conv.i.i31.20
  %conv2.i.i34.20 = trunc i32 %xor.i.i33.20 to i8
  %scevgep.21 = getelementptr i8, i8* %x, i64 21
  %142 = load i8, i8* %scevgep.21, align 1
  %conv.i.i31.21 = zext i8 %142 to i32
  %conv1.i.i32.21 = zext i8 %conv2.i.i34.20 to i32
  %xor.i.i33.21 = xor i32 %conv1.i.i32.21, %conv.i.i31.21
  %conv2.i.i34.21 = trunc i32 %xor.i.i33.21 to i8
  %scevgep.22 = getelementptr i8, i8* %x, i64 22
  %143 = load i8, i8* %scevgep.22, align 1
  %conv.i.i31.22 = zext i8 %143 to i32
  %conv1.i.i32.22 = zext i8 %conv2.i.i34.21 to i32
  %xor.i.i33.22 = xor i32 %conv1.i.i32.22, %conv.i.i31.22
  %conv2.i.i34.22 = trunc i32 %xor.i.i33.22 to i8
  %scevgep.23 = getelementptr i8, i8* %x, i64 23
  %144 = load i8, i8* %scevgep.23, align 1
  %conv.i.i31.23 = zext i8 %144 to i32
  %conv1.i.i32.23 = zext i8 %conv2.i.i34.22 to i32
  %xor.i.i33.23 = xor i32 %conv1.i.i32.23, %conv.i.i31.23
  %conv2.i.i34.23 = trunc i32 %xor.i.i33.23 to i8
  %scevgep.24 = getelementptr i8, i8* %x, i64 24
  %145 = load i8, i8* %scevgep.24, align 1
  %conv.i.i31.24 = zext i8 %145 to i32
  %conv1.i.i32.24 = zext i8 %conv2.i.i34.23 to i32
  %xor.i.i33.24 = xor i32 %conv1.i.i32.24, %conv.i.i31.24
  %conv2.i.i34.24 = trunc i32 %xor.i.i33.24 to i8
  %scevgep.25 = getelementptr i8, i8* %x, i64 25
  %146 = load i8, i8* %scevgep.25, align 1
  %conv.i.i31.25 = zext i8 %146 to i32
  %conv1.i.i32.25 = zext i8 %conv2.i.i34.24 to i32
  %xor.i.i33.25 = xor i32 %conv1.i.i32.25, %conv.i.i31.25
  %conv2.i.i34.25 = trunc i32 %xor.i.i33.25 to i8
  %scevgep.26 = getelementptr i8, i8* %x, i64 26
  %147 = load i8, i8* %scevgep.26, align 1
  %conv.i.i31.26 = zext i8 %147 to i32
  %conv1.i.i32.26 = zext i8 %conv2.i.i34.25 to i32
  %xor.i.i33.26 = xor i32 %conv1.i.i32.26, %conv.i.i31.26
  %conv2.i.i34.26 = trunc i32 %xor.i.i33.26 to i8
  %scevgep.27 = getelementptr i8, i8* %x, i64 27
  %148 = load i8, i8* %scevgep.27, align 1
  %conv.i.i31.27 = zext i8 %148 to i32
  %conv1.i.i32.27 = zext i8 %conv2.i.i34.26 to i32
  %xor.i.i33.27 = xor i32 %conv1.i.i32.27, %conv.i.i31.27
  %conv2.i.i34.27 = trunc i32 %xor.i.i33.27 to i8
  %scevgep.28 = getelementptr i8, i8* %x, i64 28
  %149 = load i8, i8* %scevgep.28, align 1
  %conv.i.i31.28 = zext i8 %149 to i32
  %conv1.i.i32.28 = zext i8 %conv2.i.i34.27 to i32
  %xor.i.i33.28 = xor i32 %conv1.i.i32.28, %conv.i.i31.28
  %conv2.i.i34.28 = trunc i32 %xor.i.i33.28 to i8
  %scevgep.29 = getelementptr i8, i8* %x, i64 29
  %150 = load i8, i8* %scevgep.29, align 1
  %conv.i.i31.29 = zext i8 %150 to i32
  %conv1.i.i32.29 = zext i8 %conv2.i.i34.28 to i32
  %xor.i.i33.29 = xor i32 %conv1.i.i32.29, %conv.i.i31.29
  %conv2.i.i34.29 = trunc i32 %xor.i.i33.29 to i8
  %scevgep.30 = getelementptr i8, i8* %x, i64 30
  %151 = load i8, i8* %scevgep.30, align 1
  %conv.i.i31.30 = zext i8 %151 to i32
  %conv1.i.i32.30 = zext i8 %conv2.i.i34.29 to i32
  %xor.i.i33.30 = xor i32 %conv1.i.i32.30, %conv.i.i31.30
  %conv2.i.i34.30 = trunc i32 %xor.i.i33.30 to i8
  %scevgep.31 = getelementptr i8, i8* %x, i64 31
  %152 = load i8, i8* %scevgep.31, align 1
  %conv.i.i31.31 = zext i8 %152 to i32
  %conv1.i.i32.31 = zext i8 %conv2.i.i34.30 to i32
  %xor.i.i33.31 = xor i32 %conv1.i.i32.31, %conv.i.i31.31
  %conv2.i.i34.31 = trunc i32 %xor.i.i33.31 to i8
  %scevgep.32 = getelementptr i8, i8* %x, i64 32
  %153 = load i8, i8* %scevgep.32, align 1
  %conv.i.i31.32 = zext i8 %153 to i32
  %conv1.i.i32.32 = zext i8 %conv2.i.i34.31 to i32
  %xor.i.i33.32 = xor i32 %conv1.i.i32.32, %conv.i.i31.32
  %conv2.i.i34.32 = trunc i32 %xor.i.i33.32 to i8
  %scevgep.33 = getelementptr i8, i8* %x, i64 33
  %154 = load i8, i8* %scevgep.33, align 1
  %conv.i.i31.33 = zext i8 %154 to i32
  %conv1.i.i32.33 = zext i8 %conv2.i.i34.32 to i32
  %xor.i.i33.33 = xor i32 %conv1.i.i32.33, %conv.i.i31.33
  %conv2.i.i34.33 = trunc i32 %xor.i.i33.33 to i8
  %scevgep.34 = getelementptr i8, i8* %x, i64 34
  %155 = load i8, i8* %scevgep.34, align 1
  %conv.i.i31.34 = zext i8 %155 to i32
  %conv1.i.i32.34 = zext i8 %conv2.i.i34.33 to i32
  %xor.i.i33.34 = xor i32 %conv1.i.i32.34, %conv.i.i31.34
  %conv2.i.i34.34 = trunc i32 %xor.i.i33.34 to i8
  %scevgep.35 = getelementptr i8, i8* %x, i64 35
  %156 = load i8, i8* %scevgep.35, align 1
  %conv.i.i31.35 = zext i8 %156 to i32
  %conv1.i.i32.35 = zext i8 %conv2.i.i34.34 to i32
  %xor.i.i33.35 = xor i32 %conv1.i.i32.35, %conv.i.i31.35
  %conv2.i.i34.35 = trunc i32 %xor.i.i33.35 to i8
  %scevgep.36 = getelementptr i8, i8* %x, i64 36
  %157 = load i8, i8* %scevgep.36, align 1
  %conv.i.i31.36 = zext i8 %157 to i32
  %conv1.i.i32.36 = zext i8 %conv2.i.i34.35 to i32
  %xor.i.i33.36 = xor i32 %conv1.i.i32.36, %conv.i.i31.36
  %conv2.i.i34.36 = trunc i32 %xor.i.i33.36 to i8
  %scevgep.37 = getelementptr i8, i8* %x, i64 37
  %158 = load i8, i8* %scevgep.37, align 1
  %conv.i.i31.37 = zext i8 %158 to i32
  %conv1.i.i32.37 = zext i8 %conv2.i.i34.36 to i32
  %xor.i.i33.37 = xor i32 %conv1.i.i32.37, %conv.i.i31.37
  %conv2.i.i34.37 = trunc i32 %xor.i.i33.37 to i8
  %scevgep.38 = getelementptr i8, i8* %x, i64 38
  %159 = load i8, i8* %scevgep.38, align 1
  %conv.i.i31.38 = zext i8 %159 to i32
  %conv1.i.i32.38 = zext i8 %conv2.i.i34.37 to i32
  %xor.i.i33.38 = xor i32 %conv1.i.i32.38, %conv.i.i31.38
  %conv2.i.i34.38 = trunc i32 %xor.i.i33.38 to i8
  %scevgep.39 = getelementptr i8, i8* %x, i64 39
  %160 = load i8, i8* %scevgep.39, align 1
  %conv.i.i31.39 = zext i8 %160 to i32
  %conv1.i.i32.39 = zext i8 %conv2.i.i34.38 to i32
  %xor.i.i33.39 = xor i32 %conv1.i.i32.39, %conv.i.i31.39
  %conv2.i.i34.39 = trunc i32 %xor.i.i33.39 to i8
  %scevgep.40 = getelementptr i8, i8* %x, i64 40
  %161 = load i8, i8* %scevgep.40, align 1
  %conv.i.i31.40 = zext i8 %161 to i32
  %conv1.i.i32.40 = zext i8 %conv2.i.i34.39 to i32
  %xor.i.i33.40 = xor i32 %conv1.i.i32.40, %conv.i.i31.40
  %conv2.i.i34.40 = trunc i32 %xor.i.i33.40 to i8
  %conv18 = zext i8 %conv2.i.i34.40 to i32
  %cmp19 = icmp eq i32 %conv16, %conv18
  call void @assert(i1 zeroext %cmp19)
  ret void
}

attributes #0 = { alwaysinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 11.1.0 (https://github.com/llvm/llvm-project.git 7e99bddfeaab2713a8bb6ca538da25b66e6efc59)"}
