; ModuleID = '../examples/rivain-ches2010-mult.inline-60.ll'
source_filename = "../examples/rivain-ches2010-mult.c"
target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

@d = dso_local constant i32 60, align 4
@.str = private unnamed_addr constant [7 x i8] c"verify\00", section "llvm.metadata"
@.str.1 = private unnamed_addr constant [35 x i8] c"../examples/rivain-ches2010-mult.c\00", section "llvm.metadata"
@llvm.global.annotations = appending global [2 x { i8*, i8*, i8*, i32 }] [{ i8*, i8*, i8*, i32 } { i8* bitcast (void (i8*, i8*, i8*)* @sec_mult to i8*), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i32 0, i32 0), i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.1, i32 0, i32 0), i32 3 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (i8*)* @refresh_masks to i8*), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str, i32 0, i32 0), i8* getelementptr inbounds ([35 x i8], [35 x i8]* @.str.1, i32 0, i32 0), i32 29 }], section "llvm.metadata"

; Function Attrs: alwaysinline nounwind uwtable
define dso_local void @transform(i8* %from, i8* %to, i8 (i8)* %f) #0 {
entry:
  %0 = load i8, i8* %from, align 1
  %call = call zeroext i8 %f(i8 zeroext %0)
  store i8 %call, i8* %to, align 1
  %scevgep.1 = getelementptr i8, i8* %from, i64 1
  %1 = load i8, i8* %scevgep.1, align 1
  %call.1 = call zeroext i8 %f(i8 zeroext %1)
  %scevgep2.1 = getelementptr i8, i8* %to, i64 1
  store i8 %call.1, i8* %scevgep2.1, align 1
  %scevgep.2 = getelementptr i8, i8* %from, i64 2
  %2 = load i8, i8* %scevgep.2, align 1
  %call.2 = call zeroext i8 %f(i8 zeroext %2)
  %scevgep2.2 = getelementptr i8, i8* %to, i64 2
  store i8 %call.2, i8* %scevgep2.2, align 1
  %scevgep.3 = getelementptr i8, i8* %from, i64 3
  %3 = load i8, i8* %scevgep.3, align 1
  %call.3 = call zeroext i8 %f(i8 zeroext %3)
  %scevgep2.3 = getelementptr i8, i8* %to, i64 3
  store i8 %call.3, i8* %scevgep2.3, align 1
  %scevgep.4 = getelementptr i8, i8* %from, i64 4
  %4 = load i8, i8* %scevgep.4, align 1
  %call.4 = call zeroext i8 %f(i8 zeroext %4)
  %scevgep2.4 = getelementptr i8, i8* %to, i64 4
  store i8 %call.4, i8* %scevgep2.4, align 1
  %scevgep.5 = getelementptr i8, i8* %from, i64 5
  %5 = load i8, i8* %scevgep.5, align 1
  %call.5 = call zeroext i8 %f(i8 zeroext %5)
  %scevgep2.5 = getelementptr i8, i8* %to, i64 5
  store i8 %call.5, i8* %scevgep2.5, align 1
  %scevgep.6 = getelementptr i8, i8* %from, i64 6
  %6 = load i8, i8* %scevgep.6, align 1
  %call.6 = call zeroext i8 %f(i8 zeroext %6)
  %scevgep2.6 = getelementptr i8, i8* %to, i64 6
  store i8 %call.6, i8* %scevgep2.6, align 1
  %scevgep.7 = getelementptr i8, i8* %from, i64 7
  %7 = load i8, i8* %scevgep.7, align 1
  %call.7 = call zeroext i8 %f(i8 zeroext %7)
  %scevgep2.7 = getelementptr i8, i8* %to, i64 7
  store i8 %call.7, i8* %scevgep2.7, align 1
  %scevgep.8 = getelementptr i8, i8* %from, i64 8
  %8 = load i8, i8* %scevgep.8, align 1
  %call.8 = call zeroext i8 %f(i8 zeroext %8)
  %scevgep2.8 = getelementptr i8, i8* %to, i64 8
  store i8 %call.8, i8* %scevgep2.8, align 1
  %scevgep.9 = getelementptr i8, i8* %from, i64 9
  %9 = load i8, i8* %scevgep.9, align 1
  %call.9 = call zeroext i8 %f(i8 zeroext %9)
  %scevgep2.9 = getelementptr i8, i8* %to, i64 9
  store i8 %call.9, i8* %scevgep2.9, align 1
  %scevgep.10 = getelementptr i8, i8* %from, i64 10
  %10 = load i8, i8* %scevgep.10, align 1
  %call.10 = call zeroext i8 %f(i8 zeroext %10)
  %scevgep2.10 = getelementptr i8, i8* %to, i64 10
  store i8 %call.10, i8* %scevgep2.10, align 1
  %scevgep.11 = getelementptr i8, i8* %from, i64 11
  %11 = load i8, i8* %scevgep.11, align 1
  %call.11 = call zeroext i8 %f(i8 zeroext %11)
  %scevgep2.11 = getelementptr i8, i8* %to, i64 11
  store i8 %call.11, i8* %scevgep2.11, align 1
  %scevgep.12 = getelementptr i8, i8* %from, i64 12
  %12 = load i8, i8* %scevgep.12, align 1
  %call.12 = call zeroext i8 %f(i8 zeroext %12)
  %scevgep2.12 = getelementptr i8, i8* %to, i64 12
  store i8 %call.12, i8* %scevgep2.12, align 1
  %scevgep.13 = getelementptr i8, i8* %from, i64 13
  %13 = load i8, i8* %scevgep.13, align 1
  %call.13 = call zeroext i8 %f(i8 zeroext %13)
  %scevgep2.13 = getelementptr i8, i8* %to, i64 13
  store i8 %call.13, i8* %scevgep2.13, align 1
  %scevgep.14 = getelementptr i8, i8* %from, i64 14
  %14 = load i8, i8* %scevgep.14, align 1
  %call.14 = call zeroext i8 %f(i8 zeroext %14)
  %scevgep2.14 = getelementptr i8, i8* %to, i64 14
  store i8 %call.14, i8* %scevgep2.14, align 1
  %scevgep.15 = getelementptr i8, i8* %from, i64 15
  %15 = load i8, i8* %scevgep.15, align 1
  %call.15 = call zeroext i8 %f(i8 zeroext %15)
  %scevgep2.15 = getelementptr i8, i8* %to, i64 15
  store i8 %call.15, i8* %scevgep2.15, align 1
  %scevgep.16 = getelementptr i8, i8* %from, i64 16
  %16 = load i8, i8* %scevgep.16, align 1
  %call.16 = call zeroext i8 %f(i8 zeroext %16)
  %scevgep2.16 = getelementptr i8, i8* %to, i64 16
  store i8 %call.16, i8* %scevgep2.16, align 1
  %scevgep.17 = getelementptr i8, i8* %from, i64 17
  %17 = load i8, i8* %scevgep.17, align 1
  %call.17 = call zeroext i8 %f(i8 zeroext %17)
  %scevgep2.17 = getelementptr i8, i8* %to, i64 17
  store i8 %call.17, i8* %scevgep2.17, align 1
  %scevgep.18 = getelementptr i8, i8* %from, i64 18
  %18 = load i8, i8* %scevgep.18, align 1
  %call.18 = call zeroext i8 %f(i8 zeroext %18)
  %scevgep2.18 = getelementptr i8, i8* %to, i64 18
  store i8 %call.18, i8* %scevgep2.18, align 1
  %scevgep.19 = getelementptr i8, i8* %from, i64 19
  %19 = load i8, i8* %scevgep.19, align 1
  %call.19 = call zeroext i8 %f(i8 zeroext %19)
  %scevgep2.19 = getelementptr i8, i8* %to, i64 19
  store i8 %call.19, i8* %scevgep2.19, align 1
  %scevgep.20 = getelementptr i8, i8* %from, i64 20
  %20 = load i8, i8* %scevgep.20, align 1
  %call.20 = call zeroext i8 %f(i8 zeroext %20)
  %scevgep2.20 = getelementptr i8, i8* %to, i64 20
  store i8 %call.20, i8* %scevgep2.20, align 1
  %scevgep.21 = getelementptr i8, i8* %from, i64 21
  %21 = load i8, i8* %scevgep.21, align 1
  %call.21 = call zeroext i8 %f(i8 zeroext %21)
  %scevgep2.21 = getelementptr i8, i8* %to, i64 21
  store i8 %call.21, i8* %scevgep2.21, align 1
  %scevgep.22 = getelementptr i8, i8* %from, i64 22
  %22 = load i8, i8* %scevgep.22, align 1
  %call.22 = call zeroext i8 %f(i8 zeroext %22)
  %scevgep2.22 = getelementptr i8, i8* %to, i64 22
  store i8 %call.22, i8* %scevgep2.22, align 1
  %scevgep.23 = getelementptr i8, i8* %from, i64 23
  %23 = load i8, i8* %scevgep.23, align 1
  %call.23 = call zeroext i8 %f(i8 zeroext %23)
  %scevgep2.23 = getelementptr i8, i8* %to, i64 23
  store i8 %call.23, i8* %scevgep2.23, align 1
  %scevgep.24 = getelementptr i8, i8* %from, i64 24
  %24 = load i8, i8* %scevgep.24, align 1
  %call.24 = call zeroext i8 %f(i8 zeroext %24)
  %scevgep2.24 = getelementptr i8, i8* %to, i64 24
  store i8 %call.24, i8* %scevgep2.24, align 1
  %scevgep.25 = getelementptr i8, i8* %from, i64 25
  %25 = load i8, i8* %scevgep.25, align 1
  %call.25 = call zeroext i8 %f(i8 zeroext %25)
  %scevgep2.25 = getelementptr i8, i8* %to, i64 25
  store i8 %call.25, i8* %scevgep2.25, align 1
  %scevgep.26 = getelementptr i8, i8* %from, i64 26
  %26 = load i8, i8* %scevgep.26, align 1
  %call.26 = call zeroext i8 %f(i8 zeroext %26)
  %scevgep2.26 = getelementptr i8, i8* %to, i64 26
  store i8 %call.26, i8* %scevgep2.26, align 1
  %scevgep.27 = getelementptr i8, i8* %from, i64 27
  %27 = load i8, i8* %scevgep.27, align 1
  %call.27 = call zeroext i8 %f(i8 zeroext %27)
  %scevgep2.27 = getelementptr i8, i8* %to, i64 27
  store i8 %call.27, i8* %scevgep2.27, align 1
  %scevgep.28 = getelementptr i8, i8* %from, i64 28
  %28 = load i8, i8* %scevgep.28, align 1
  %call.28 = call zeroext i8 %f(i8 zeroext %28)
  %scevgep2.28 = getelementptr i8, i8* %to, i64 28
  store i8 %call.28, i8* %scevgep2.28, align 1
  %scevgep.29 = getelementptr i8, i8* %from, i64 29
  %29 = load i8, i8* %scevgep.29, align 1
  %call.29 = call zeroext i8 %f(i8 zeroext %29)
  %scevgep2.29 = getelementptr i8, i8* %to, i64 29
  store i8 %call.29, i8* %scevgep2.29, align 1
  %scevgep.30 = getelementptr i8, i8* %from, i64 30
  %30 = load i8, i8* %scevgep.30, align 1
  %call.30 = call zeroext i8 %f(i8 zeroext %30)
  %scevgep2.30 = getelementptr i8, i8* %to, i64 30
  store i8 %call.30, i8* %scevgep2.30, align 1
  %scevgep.31 = getelementptr i8, i8* %from, i64 31
  %31 = load i8, i8* %scevgep.31, align 1
  %call.31 = call zeroext i8 %f(i8 zeroext %31)
  %scevgep2.31 = getelementptr i8, i8* %to, i64 31
  store i8 %call.31, i8* %scevgep2.31, align 1
  %scevgep.32 = getelementptr i8, i8* %from, i64 32
  %32 = load i8, i8* %scevgep.32, align 1
  %call.32 = call zeroext i8 %f(i8 zeroext %32)
  %scevgep2.32 = getelementptr i8, i8* %to, i64 32
  store i8 %call.32, i8* %scevgep2.32, align 1
  %scevgep.33 = getelementptr i8, i8* %from, i64 33
  %33 = load i8, i8* %scevgep.33, align 1
  %call.33 = call zeroext i8 %f(i8 zeroext %33)
  %scevgep2.33 = getelementptr i8, i8* %to, i64 33
  store i8 %call.33, i8* %scevgep2.33, align 1
  %scevgep.34 = getelementptr i8, i8* %from, i64 34
  %34 = load i8, i8* %scevgep.34, align 1
  %call.34 = call zeroext i8 %f(i8 zeroext %34)
  %scevgep2.34 = getelementptr i8, i8* %to, i64 34
  store i8 %call.34, i8* %scevgep2.34, align 1
  %scevgep.35 = getelementptr i8, i8* %from, i64 35
  %35 = load i8, i8* %scevgep.35, align 1
  %call.35 = call zeroext i8 %f(i8 zeroext %35)
  %scevgep2.35 = getelementptr i8, i8* %to, i64 35
  store i8 %call.35, i8* %scevgep2.35, align 1
  %scevgep.36 = getelementptr i8, i8* %from, i64 36
  %36 = load i8, i8* %scevgep.36, align 1
  %call.36 = call zeroext i8 %f(i8 zeroext %36)
  %scevgep2.36 = getelementptr i8, i8* %to, i64 36
  store i8 %call.36, i8* %scevgep2.36, align 1
  %scevgep.37 = getelementptr i8, i8* %from, i64 37
  %37 = load i8, i8* %scevgep.37, align 1
  %call.37 = call zeroext i8 %f(i8 zeroext %37)
  %scevgep2.37 = getelementptr i8, i8* %to, i64 37
  store i8 %call.37, i8* %scevgep2.37, align 1
  %scevgep.38 = getelementptr i8, i8* %from, i64 38
  %38 = load i8, i8* %scevgep.38, align 1
  %call.38 = call zeroext i8 %f(i8 zeroext %38)
  %scevgep2.38 = getelementptr i8, i8* %to, i64 38
  store i8 %call.38, i8* %scevgep2.38, align 1
  %scevgep.39 = getelementptr i8, i8* %from, i64 39
  %39 = load i8, i8* %scevgep.39, align 1
  %call.39 = call zeroext i8 %f(i8 zeroext %39)
  %scevgep2.39 = getelementptr i8, i8* %to, i64 39
  store i8 %call.39, i8* %scevgep2.39, align 1
  %scevgep.40 = getelementptr i8, i8* %from, i64 40
  %40 = load i8, i8* %scevgep.40, align 1
  %call.40 = call zeroext i8 %f(i8 zeroext %40)
  %scevgep2.40 = getelementptr i8, i8* %to, i64 40
  store i8 %call.40, i8* %scevgep2.40, align 1
  %scevgep.41 = getelementptr i8, i8* %from, i64 41
  %41 = load i8, i8* %scevgep.41, align 1
  %call.41 = call zeroext i8 %f(i8 zeroext %41)
  %scevgep2.41 = getelementptr i8, i8* %to, i64 41
  store i8 %call.41, i8* %scevgep2.41, align 1
  %scevgep.42 = getelementptr i8, i8* %from, i64 42
  %42 = load i8, i8* %scevgep.42, align 1
  %call.42 = call zeroext i8 %f(i8 zeroext %42)
  %scevgep2.42 = getelementptr i8, i8* %to, i64 42
  store i8 %call.42, i8* %scevgep2.42, align 1
  %scevgep.43 = getelementptr i8, i8* %from, i64 43
  %43 = load i8, i8* %scevgep.43, align 1
  %call.43 = call zeroext i8 %f(i8 zeroext %43)
  %scevgep2.43 = getelementptr i8, i8* %to, i64 43
  store i8 %call.43, i8* %scevgep2.43, align 1
  %scevgep.44 = getelementptr i8, i8* %from, i64 44
  %44 = load i8, i8* %scevgep.44, align 1
  %call.44 = call zeroext i8 %f(i8 zeroext %44)
  %scevgep2.44 = getelementptr i8, i8* %to, i64 44
  store i8 %call.44, i8* %scevgep2.44, align 1
  %scevgep.45 = getelementptr i8, i8* %from, i64 45
  %45 = load i8, i8* %scevgep.45, align 1
  %call.45 = call zeroext i8 %f(i8 zeroext %45)
  %scevgep2.45 = getelementptr i8, i8* %to, i64 45
  store i8 %call.45, i8* %scevgep2.45, align 1
  %scevgep.46 = getelementptr i8, i8* %from, i64 46
  %46 = load i8, i8* %scevgep.46, align 1
  %call.46 = call zeroext i8 %f(i8 zeroext %46)
  %scevgep2.46 = getelementptr i8, i8* %to, i64 46
  store i8 %call.46, i8* %scevgep2.46, align 1
  %scevgep.47 = getelementptr i8, i8* %from, i64 47
  %47 = load i8, i8* %scevgep.47, align 1
  %call.47 = call zeroext i8 %f(i8 zeroext %47)
  %scevgep2.47 = getelementptr i8, i8* %to, i64 47
  store i8 %call.47, i8* %scevgep2.47, align 1
  %scevgep.48 = getelementptr i8, i8* %from, i64 48
  %48 = load i8, i8* %scevgep.48, align 1
  %call.48 = call zeroext i8 %f(i8 zeroext %48)
  %scevgep2.48 = getelementptr i8, i8* %to, i64 48
  store i8 %call.48, i8* %scevgep2.48, align 1
  %scevgep.49 = getelementptr i8, i8* %from, i64 49
  %49 = load i8, i8* %scevgep.49, align 1
  %call.49 = call zeroext i8 %f(i8 zeroext %49)
  %scevgep2.49 = getelementptr i8, i8* %to, i64 49
  store i8 %call.49, i8* %scevgep2.49, align 1
  %scevgep.50 = getelementptr i8, i8* %from, i64 50
  %50 = load i8, i8* %scevgep.50, align 1
  %call.50 = call zeroext i8 %f(i8 zeroext %50)
  %scevgep2.50 = getelementptr i8, i8* %to, i64 50
  store i8 %call.50, i8* %scevgep2.50, align 1
  %scevgep.51 = getelementptr i8, i8* %from, i64 51
  %51 = load i8, i8* %scevgep.51, align 1
  %call.51 = call zeroext i8 %f(i8 zeroext %51)
  %scevgep2.51 = getelementptr i8, i8* %to, i64 51
  store i8 %call.51, i8* %scevgep2.51, align 1
  %scevgep.52 = getelementptr i8, i8* %from, i64 52
  %52 = load i8, i8* %scevgep.52, align 1
  %call.52 = call zeroext i8 %f(i8 zeroext %52)
  %scevgep2.52 = getelementptr i8, i8* %to, i64 52
  store i8 %call.52, i8* %scevgep2.52, align 1
  %scevgep.53 = getelementptr i8, i8* %from, i64 53
  %53 = load i8, i8* %scevgep.53, align 1
  %call.53 = call zeroext i8 %f(i8 zeroext %53)
  %scevgep2.53 = getelementptr i8, i8* %to, i64 53
  store i8 %call.53, i8* %scevgep2.53, align 1
  %scevgep.54 = getelementptr i8, i8* %from, i64 54
  %54 = load i8, i8* %scevgep.54, align 1
  %call.54 = call zeroext i8 %f(i8 zeroext %54)
  %scevgep2.54 = getelementptr i8, i8* %to, i64 54
  store i8 %call.54, i8* %scevgep2.54, align 1
  %scevgep.55 = getelementptr i8, i8* %from, i64 55
  %55 = load i8, i8* %scevgep.55, align 1
  %call.55 = call zeroext i8 %f(i8 zeroext %55)
  %scevgep2.55 = getelementptr i8, i8* %to, i64 55
  store i8 %call.55, i8* %scevgep2.55, align 1
  %scevgep.56 = getelementptr i8, i8* %from, i64 56
  %56 = load i8, i8* %scevgep.56, align 1
  %call.56 = call zeroext i8 %f(i8 zeroext %56)
  %scevgep2.56 = getelementptr i8, i8* %to, i64 56
  store i8 %call.56, i8* %scevgep2.56, align 1
  %scevgep.57 = getelementptr i8, i8* %from, i64 57
  %57 = load i8, i8* %scevgep.57, align 1
  %call.57 = call zeroext i8 %f(i8 zeroext %57)
  %scevgep2.57 = getelementptr i8, i8* %to, i64 57
  store i8 %call.57, i8* %scevgep2.57, align 1
  %scevgep.58 = getelementptr i8, i8* %from, i64 58
  %58 = load i8, i8* %scevgep.58, align 1
  %call.58 = call zeroext i8 %f(i8 zeroext %58)
  %scevgep2.58 = getelementptr i8, i8* %to, i64 58
  store i8 %call.58, i8* %scevgep2.58, align 1
  %scevgep.59 = getelementptr i8, i8* %from, i64 59
  %59 = load i8, i8* %scevgep.59, align 1
  %call.59 = call zeroext i8 %f(i8 zeroext %59)
  %scevgep2.59 = getelementptr i8, i8* %to, i64 59
  store i8 %call.59, i8* %scevgep2.59, align 1
  %scevgep.60 = getelementptr i8, i8* %from, i64 60
  %60 = load i8, i8* %scevgep.60, align 1
  %call.60 = call zeroext i8 %f(i8 zeroext %60)
  %scevgep2.60 = getelementptr i8, i8* %to, i64 60
  store i8 %call.60, i8* %scevgep2.60, align 1
  ret void
}

; Function Attrs: alwaysinline nounwind uwtable
define dso_local zeroext i8 @sigma(i8* %a, i8 (i8)* %f) #0 {
entry:
  %0 = load i8, i8* %a, align 1
  %call = call zeroext i8 %f(i8 zeroext %0)
  %scevgep.1 = getelementptr i8, i8* %a, i64 1
  %1 = load i8, i8* %scevgep.1, align 1
  %call.1 = call zeroext i8 %f(i8 zeroext %1)
  %conv.1 = zext i8 %call.1 to i32
  %conv1.1 = zext i8 %call to i32
  %xor.1 = xor i32 %conv1.1, %conv.1
  %conv2.1 = trunc i32 %xor.1 to i8
  %scevgep.2 = getelementptr i8, i8* %a, i64 2
  %2 = load i8, i8* %scevgep.2, align 1
  %call.2 = call zeroext i8 %f(i8 zeroext %2)
  %conv.2 = zext i8 %call.2 to i32
  %conv1.2 = zext i8 %conv2.1 to i32
  %xor.2 = xor i32 %conv1.2, %conv.2
  %conv2.2 = trunc i32 %xor.2 to i8
  %scevgep.3 = getelementptr i8, i8* %a, i64 3
  %3 = load i8, i8* %scevgep.3, align 1
  %call.3 = call zeroext i8 %f(i8 zeroext %3)
  %conv.3 = zext i8 %call.3 to i32
  %conv1.3 = zext i8 %conv2.2 to i32
  %xor.3 = xor i32 %conv1.3, %conv.3
  %conv2.3 = trunc i32 %xor.3 to i8
  %scevgep.4 = getelementptr i8, i8* %a, i64 4
  %4 = load i8, i8* %scevgep.4, align 1
  %call.4 = call zeroext i8 %f(i8 zeroext %4)
  %conv.4 = zext i8 %call.4 to i32
  %conv1.4 = zext i8 %conv2.3 to i32
  %xor.4 = xor i32 %conv1.4, %conv.4
  %conv2.4 = trunc i32 %xor.4 to i8
  %scevgep.5 = getelementptr i8, i8* %a, i64 5
  %5 = load i8, i8* %scevgep.5, align 1
  %call.5 = call zeroext i8 %f(i8 zeroext %5)
  %conv.5 = zext i8 %call.5 to i32
  %conv1.5 = zext i8 %conv2.4 to i32
  %xor.5 = xor i32 %conv1.5, %conv.5
  %conv2.5 = trunc i32 %xor.5 to i8
  %scevgep.6 = getelementptr i8, i8* %a, i64 6
  %6 = load i8, i8* %scevgep.6, align 1
  %call.6 = call zeroext i8 %f(i8 zeroext %6)
  %conv.6 = zext i8 %call.6 to i32
  %conv1.6 = zext i8 %conv2.5 to i32
  %xor.6 = xor i32 %conv1.6, %conv.6
  %conv2.6 = trunc i32 %xor.6 to i8
  %scevgep.7 = getelementptr i8, i8* %a, i64 7
  %7 = load i8, i8* %scevgep.7, align 1
  %call.7 = call zeroext i8 %f(i8 zeroext %7)
  %conv.7 = zext i8 %call.7 to i32
  %conv1.7 = zext i8 %conv2.6 to i32
  %xor.7 = xor i32 %conv1.7, %conv.7
  %conv2.7 = trunc i32 %xor.7 to i8
  %scevgep.8 = getelementptr i8, i8* %a, i64 8
  %8 = load i8, i8* %scevgep.8, align 1
  %call.8 = call zeroext i8 %f(i8 zeroext %8)
  %conv.8 = zext i8 %call.8 to i32
  %conv1.8 = zext i8 %conv2.7 to i32
  %xor.8 = xor i32 %conv1.8, %conv.8
  %conv2.8 = trunc i32 %xor.8 to i8
  %scevgep.9 = getelementptr i8, i8* %a, i64 9
  %9 = load i8, i8* %scevgep.9, align 1
  %call.9 = call zeroext i8 %f(i8 zeroext %9)
  %conv.9 = zext i8 %call.9 to i32
  %conv1.9 = zext i8 %conv2.8 to i32
  %xor.9 = xor i32 %conv1.9, %conv.9
  %conv2.9 = trunc i32 %xor.9 to i8
  %scevgep.10 = getelementptr i8, i8* %a, i64 10
  %10 = load i8, i8* %scevgep.10, align 1
  %call.10 = call zeroext i8 %f(i8 zeroext %10)
  %conv.10 = zext i8 %call.10 to i32
  %conv1.10 = zext i8 %conv2.9 to i32
  %xor.10 = xor i32 %conv1.10, %conv.10
  %conv2.10 = trunc i32 %xor.10 to i8
  %scevgep.11 = getelementptr i8, i8* %a, i64 11
  %11 = load i8, i8* %scevgep.11, align 1
  %call.11 = call zeroext i8 %f(i8 zeroext %11)
  %conv.11 = zext i8 %call.11 to i32
  %conv1.11 = zext i8 %conv2.10 to i32
  %xor.11 = xor i32 %conv1.11, %conv.11
  %conv2.11 = trunc i32 %xor.11 to i8
  %scevgep.12 = getelementptr i8, i8* %a, i64 12
  %12 = load i8, i8* %scevgep.12, align 1
  %call.12 = call zeroext i8 %f(i8 zeroext %12)
  %conv.12 = zext i8 %call.12 to i32
  %conv1.12 = zext i8 %conv2.11 to i32
  %xor.12 = xor i32 %conv1.12, %conv.12
  %conv2.12 = trunc i32 %xor.12 to i8
  %scevgep.13 = getelementptr i8, i8* %a, i64 13
  %13 = load i8, i8* %scevgep.13, align 1
  %call.13 = call zeroext i8 %f(i8 zeroext %13)
  %conv.13 = zext i8 %call.13 to i32
  %conv1.13 = zext i8 %conv2.12 to i32
  %xor.13 = xor i32 %conv1.13, %conv.13
  %conv2.13 = trunc i32 %xor.13 to i8
  %scevgep.14 = getelementptr i8, i8* %a, i64 14
  %14 = load i8, i8* %scevgep.14, align 1
  %call.14 = call zeroext i8 %f(i8 zeroext %14)
  %conv.14 = zext i8 %call.14 to i32
  %conv1.14 = zext i8 %conv2.13 to i32
  %xor.14 = xor i32 %conv1.14, %conv.14
  %conv2.14 = trunc i32 %xor.14 to i8
  %scevgep.15 = getelementptr i8, i8* %a, i64 15
  %15 = load i8, i8* %scevgep.15, align 1
  %call.15 = call zeroext i8 %f(i8 zeroext %15)
  %conv.15 = zext i8 %call.15 to i32
  %conv1.15 = zext i8 %conv2.14 to i32
  %xor.15 = xor i32 %conv1.15, %conv.15
  %conv2.15 = trunc i32 %xor.15 to i8
  %scevgep.16 = getelementptr i8, i8* %a, i64 16
  %16 = load i8, i8* %scevgep.16, align 1
  %call.16 = call zeroext i8 %f(i8 zeroext %16)
  %conv.16 = zext i8 %call.16 to i32
  %conv1.16 = zext i8 %conv2.15 to i32
  %xor.16 = xor i32 %conv1.16, %conv.16
  %conv2.16 = trunc i32 %xor.16 to i8
  %scevgep.17 = getelementptr i8, i8* %a, i64 17
  %17 = load i8, i8* %scevgep.17, align 1
  %call.17 = call zeroext i8 %f(i8 zeroext %17)
  %conv.17 = zext i8 %call.17 to i32
  %conv1.17 = zext i8 %conv2.16 to i32
  %xor.17 = xor i32 %conv1.17, %conv.17
  %conv2.17 = trunc i32 %xor.17 to i8
  %scevgep.18 = getelementptr i8, i8* %a, i64 18
  %18 = load i8, i8* %scevgep.18, align 1
  %call.18 = call zeroext i8 %f(i8 zeroext %18)
  %conv.18 = zext i8 %call.18 to i32
  %conv1.18 = zext i8 %conv2.17 to i32
  %xor.18 = xor i32 %conv1.18, %conv.18
  %conv2.18 = trunc i32 %xor.18 to i8
  %scevgep.19 = getelementptr i8, i8* %a, i64 19
  %19 = load i8, i8* %scevgep.19, align 1
  %call.19 = call zeroext i8 %f(i8 zeroext %19)
  %conv.19 = zext i8 %call.19 to i32
  %conv1.19 = zext i8 %conv2.18 to i32
  %xor.19 = xor i32 %conv1.19, %conv.19
  %conv2.19 = trunc i32 %xor.19 to i8
  %scevgep.20 = getelementptr i8, i8* %a, i64 20
  %20 = load i8, i8* %scevgep.20, align 1
  %call.20 = call zeroext i8 %f(i8 zeroext %20)
  %conv.20 = zext i8 %call.20 to i32
  %conv1.20 = zext i8 %conv2.19 to i32
  %xor.20 = xor i32 %conv1.20, %conv.20
  %conv2.20 = trunc i32 %xor.20 to i8
  %scevgep.21 = getelementptr i8, i8* %a, i64 21
  %21 = load i8, i8* %scevgep.21, align 1
  %call.21 = call zeroext i8 %f(i8 zeroext %21)
  %conv.21 = zext i8 %call.21 to i32
  %conv1.21 = zext i8 %conv2.20 to i32
  %xor.21 = xor i32 %conv1.21, %conv.21
  %conv2.21 = trunc i32 %xor.21 to i8
  %scevgep.22 = getelementptr i8, i8* %a, i64 22
  %22 = load i8, i8* %scevgep.22, align 1
  %call.22 = call zeroext i8 %f(i8 zeroext %22)
  %conv.22 = zext i8 %call.22 to i32
  %conv1.22 = zext i8 %conv2.21 to i32
  %xor.22 = xor i32 %conv1.22, %conv.22
  %conv2.22 = trunc i32 %xor.22 to i8
  %scevgep.23 = getelementptr i8, i8* %a, i64 23
  %23 = load i8, i8* %scevgep.23, align 1
  %call.23 = call zeroext i8 %f(i8 zeroext %23)
  %conv.23 = zext i8 %call.23 to i32
  %conv1.23 = zext i8 %conv2.22 to i32
  %xor.23 = xor i32 %conv1.23, %conv.23
  %conv2.23 = trunc i32 %xor.23 to i8
  %scevgep.24 = getelementptr i8, i8* %a, i64 24
  %24 = load i8, i8* %scevgep.24, align 1
  %call.24 = call zeroext i8 %f(i8 zeroext %24)
  %conv.24 = zext i8 %call.24 to i32
  %conv1.24 = zext i8 %conv2.23 to i32
  %xor.24 = xor i32 %conv1.24, %conv.24
  %conv2.24 = trunc i32 %xor.24 to i8
  %scevgep.25 = getelementptr i8, i8* %a, i64 25
  %25 = load i8, i8* %scevgep.25, align 1
  %call.25 = call zeroext i8 %f(i8 zeroext %25)
  %conv.25 = zext i8 %call.25 to i32
  %conv1.25 = zext i8 %conv2.24 to i32
  %xor.25 = xor i32 %conv1.25, %conv.25
  %conv2.25 = trunc i32 %xor.25 to i8
  %scevgep.26 = getelementptr i8, i8* %a, i64 26
  %26 = load i8, i8* %scevgep.26, align 1
  %call.26 = call zeroext i8 %f(i8 zeroext %26)
  %conv.26 = zext i8 %call.26 to i32
  %conv1.26 = zext i8 %conv2.25 to i32
  %xor.26 = xor i32 %conv1.26, %conv.26
  %conv2.26 = trunc i32 %xor.26 to i8
  %scevgep.27 = getelementptr i8, i8* %a, i64 27
  %27 = load i8, i8* %scevgep.27, align 1
  %call.27 = call zeroext i8 %f(i8 zeroext %27)
  %conv.27 = zext i8 %call.27 to i32
  %conv1.27 = zext i8 %conv2.26 to i32
  %xor.27 = xor i32 %conv1.27, %conv.27
  %conv2.27 = trunc i32 %xor.27 to i8
  %scevgep.28 = getelementptr i8, i8* %a, i64 28
  %28 = load i8, i8* %scevgep.28, align 1
  %call.28 = call zeroext i8 %f(i8 zeroext %28)
  %conv.28 = zext i8 %call.28 to i32
  %conv1.28 = zext i8 %conv2.27 to i32
  %xor.28 = xor i32 %conv1.28, %conv.28
  %conv2.28 = trunc i32 %xor.28 to i8
  %scevgep.29 = getelementptr i8, i8* %a, i64 29
  %29 = load i8, i8* %scevgep.29, align 1
  %call.29 = call zeroext i8 %f(i8 zeroext %29)
  %conv.29 = zext i8 %call.29 to i32
  %conv1.29 = zext i8 %conv2.28 to i32
  %xor.29 = xor i32 %conv1.29, %conv.29
  %conv2.29 = trunc i32 %xor.29 to i8
  %scevgep.30 = getelementptr i8, i8* %a, i64 30
  %30 = load i8, i8* %scevgep.30, align 1
  %call.30 = call zeroext i8 %f(i8 zeroext %30)
  %conv.30 = zext i8 %call.30 to i32
  %conv1.30 = zext i8 %conv2.29 to i32
  %xor.30 = xor i32 %conv1.30, %conv.30
  %conv2.30 = trunc i32 %xor.30 to i8
  %scevgep.31 = getelementptr i8, i8* %a, i64 31
  %31 = load i8, i8* %scevgep.31, align 1
  %call.31 = call zeroext i8 %f(i8 zeroext %31)
  %conv.31 = zext i8 %call.31 to i32
  %conv1.31 = zext i8 %conv2.30 to i32
  %xor.31 = xor i32 %conv1.31, %conv.31
  %conv2.31 = trunc i32 %xor.31 to i8
  %scevgep.32 = getelementptr i8, i8* %a, i64 32
  %32 = load i8, i8* %scevgep.32, align 1
  %call.32 = call zeroext i8 %f(i8 zeroext %32)
  %conv.32 = zext i8 %call.32 to i32
  %conv1.32 = zext i8 %conv2.31 to i32
  %xor.32 = xor i32 %conv1.32, %conv.32
  %conv2.32 = trunc i32 %xor.32 to i8
  %scevgep.33 = getelementptr i8, i8* %a, i64 33
  %33 = load i8, i8* %scevgep.33, align 1
  %call.33 = call zeroext i8 %f(i8 zeroext %33)
  %conv.33 = zext i8 %call.33 to i32
  %conv1.33 = zext i8 %conv2.32 to i32
  %xor.33 = xor i32 %conv1.33, %conv.33
  %conv2.33 = trunc i32 %xor.33 to i8
  %scevgep.34 = getelementptr i8, i8* %a, i64 34
  %34 = load i8, i8* %scevgep.34, align 1
  %call.34 = call zeroext i8 %f(i8 zeroext %34)
  %conv.34 = zext i8 %call.34 to i32
  %conv1.34 = zext i8 %conv2.33 to i32
  %xor.34 = xor i32 %conv1.34, %conv.34
  %conv2.34 = trunc i32 %xor.34 to i8
  %scevgep.35 = getelementptr i8, i8* %a, i64 35
  %35 = load i8, i8* %scevgep.35, align 1
  %call.35 = call zeroext i8 %f(i8 zeroext %35)
  %conv.35 = zext i8 %call.35 to i32
  %conv1.35 = zext i8 %conv2.34 to i32
  %xor.35 = xor i32 %conv1.35, %conv.35
  %conv2.35 = trunc i32 %xor.35 to i8
  %scevgep.36 = getelementptr i8, i8* %a, i64 36
  %36 = load i8, i8* %scevgep.36, align 1
  %call.36 = call zeroext i8 %f(i8 zeroext %36)
  %conv.36 = zext i8 %call.36 to i32
  %conv1.36 = zext i8 %conv2.35 to i32
  %xor.36 = xor i32 %conv1.36, %conv.36
  %conv2.36 = trunc i32 %xor.36 to i8
  %scevgep.37 = getelementptr i8, i8* %a, i64 37
  %37 = load i8, i8* %scevgep.37, align 1
  %call.37 = call zeroext i8 %f(i8 zeroext %37)
  %conv.37 = zext i8 %call.37 to i32
  %conv1.37 = zext i8 %conv2.36 to i32
  %xor.37 = xor i32 %conv1.37, %conv.37
  %conv2.37 = trunc i32 %xor.37 to i8
  %scevgep.38 = getelementptr i8, i8* %a, i64 38
  %38 = load i8, i8* %scevgep.38, align 1
  %call.38 = call zeroext i8 %f(i8 zeroext %38)
  %conv.38 = zext i8 %call.38 to i32
  %conv1.38 = zext i8 %conv2.37 to i32
  %xor.38 = xor i32 %conv1.38, %conv.38
  %conv2.38 = trunc i32 %xor.38 to i8
  %scevgep.39 = getelementptr i8, i8* %a, i64 39
  %39 = load i8, i8* %scevgep.39, align 1
  %call.39 = call zeroext i8 %f(i8 zeroext %39)
  %conv.39 = zext i8 %call.39 to i32
  %conv1.39 = zext i8 %conv2.38 to i32
  %xor.39 = xor i32 %conv1.39, %conv.39
  %conv2.39 = trunc i32 %xor.39 to i8
  %scevgep.40 = getelementptr i8, i8* %a, i64 40
  %40 = load i8, i8* %scevgep.40, align 1
  %call.40 = call zeroext i8 %f(i8 zeroext %40)
  %conv.40 = zext i8 %call.40 to i32
  %conv1.40 = zext i8 %conv2.39 to i32
  %xor.40 = xor i32 %conv1.40, %conv.40
  %conv2.40 = trunc i32 %xor.40 to i8
  %scevgep.41 = getelementptr i8, i8* %a, i64 41
  %41 = load i8, i8* %scevgep.41, align 1
  %call.41 = call zeroext i8 %f(i8 zeroext %41)
  %conv.41 = zext i8 %call.41 to i32
  %conv1.41 = zext i8 %conv2.40 to i32
  %xor.41 = xor i32 %conv1.41, %conv.41
  %conv2.41 = trunc i32 %xor.41 to i8
  %scevgep.42 = getelementptr i8, i8* %a, i64 42
  %42 = load i8, i8* %scevgep.42, align 1
  %call.42 = call zeroext i8 %f(i8 zeroext %42)
  %conv.42 = zext i8 %call.42 to i32
  %conv1.42 = zext i8 %conv2.41 to i32
  %xor.42 = xor i32 %conv1.42, %conv.42
  %conv2.42 = trunc i32 %xor.42 to i8
  %scevgep.43 = getelementptr i8, i8* %a, i64 43
  %43 = load i8, i8* %scevgep.43, align 1
  %call.43 = call zeroext i8 %f(i8 zeroext %43)
  %conv.43 = zext i8 %call.43 to i32
  %conv1.43 = zext i8 %conv2.42 to i32
  %xor.43 = xor i32 %conv1.43, %conv.43
  %conv2.43 = trunc i32 %xor.43 to i8
  %scevgep.44 = getelementptr i8, i8* %a, i64 44
  %44 = load i8, i8* %scevgep.44, align 1
  %call.44 = call zeroext i8 %f(i8 zeroext %44)
  %conv.44 = zext i8 %call.44 to i32
  %conv1.44 = zext i8 %conv2.43 to i32
  %xor.44 = xor i32 %conv1.44, %conv.44
  %conv2.44 = trunc i32 %xor.44 to i8
  %scevgep.45 = getelementptr i8, i8* %a, i64 45
  %45 = load i8, i8* %scevgep.45, align 1
  %call.45 = call zeroext i8 %f(i8 zeroext %45)
  %conv.45 = zext i8 %call.45 to i32
  %conv1.45 = zext i8 %conv2.44 to i32
  %xor.45 = xor i32 %conv1.45, %conv.45
  %conv2.45 = trunc i32 %xor.45 to i8
  %scevgep.46 = getelementptr i8, i8* %a, i64 46
  %46 = load i8, i8* %scevgep.46, align 1
  %call.46 = call zeroext i8 %f(i8 zeroext %46)
  %conv.46 = zext i8 %call.46 to i32
  %conv1.46 = zext i8 %conv2.45 to i32
  %xor.46 = xor i32 %conv1.46, %conv.46
  %conv2.46 = trunc i32 %xor.46 to i8
  %scevgep.47 = getelementptr i8, i8* %a, i64 47
  %47 = load i8, i8* %scevgep.47, align 1
  %call.47 = call zeroext i8 %f(i8 zeroext %47)
  %conv.47 = zext i8 %call.47 to i32
  %conv1.47 = zext i8 %conv2.46 to i32
  %xor.47 = xor i32 %conv1.47, %conv.47
  %conv2.47 = trunc i32 %xor.47 to i8
  %scevgep.48 = getelementptr i8, i8* %a, i64 48
  %48 = load i8, i8* %scevgep.48, align 1
  %call.48 = call zeroext i8 %f(i8 zeroext %48)
  %conv.48 = zext i8 %call.48 to i32
  %conv1.48 = zext i8 %conv2.47 to i32
  %xor.48 = xor i32 %conv1.48, %conv.48
  %conv2.48 = trunc i32 %xor.48 to i8
  %scevgep.49 = getelementptr i8, i8* %a, i64 49
  %49 = load i8, i8* %scevgep.49, align 1
  %call.49 = call zeroext i8 %f(i8 zeroext %49)
  %conv.49 = zext i8 %call.49 to i32
  %conv1.49 = zext i8 %conv2.48 to i32
  %xor.49 = xor i32 %conv1.49, %conv.49
  %conv2.49 = trunc i32 %xor.49 to i8
  %scevgep.50 = getelementptr i8, i8* %a, i64 50
  %50 = load i8, i8* %scevgep.50, align 1
  %call.50 = call zeroext i8 %f(i8 zeroext %50)
  %conv.50 = zext i8 %call.50 to i32
  %conv1.50 = zext i8 %conv2.49 to i32
  %xor.50 = xor i32 %conv1.50, %conv.50
  %conv2.50 = trunc i32 %xor.50 to i8
  %scevgep.51 = getelementptr i8, i8* %a, i64 51
  %51 = load i8, i8* %scevgep.51, align 1
  %call.51 = call zeroext i8 %f(i8 zeroext %51)
  %conv.51 = zext i8 %call.51 to i32
  %conv1.51 = zext i8 %conv2.50 to i32
  %xor.51 = xor i32 %conv1.51, %conv.51
  %conv2.51 = trunc i32 %xor.51 to i8
  %scevgep.52 = getelementptr i8, i8* %a, i64 52
  %52 = load i8, i8* %scevgep.52, align 1
  %call.52 = call zeroext i8 %f(i8 zeroext %52)
  %conv.52 = zext i8 %call.52 to i32
  %conv1.52 = zext i8 %conv2.51 to i32
  %xor.52 = xor i32 %conv1.52, %conv.52
  %conv2.52 = trunc i32 %xor.52 to i8
  %scevgep.53 = getelementptr i8, i8* %a, i64 53
  %53 = load i8, i8* %scevgep.53, align 1
  %call.53 = call zeroext i8 %f(i8 zeroext %53)
  %conv.53 = zext i8 %call.53 to i32
  %conv1.53 = zext i8 %conv2.52 to i32
  %xor.53 = xor i32 %conv1.53, %conv.53
  %conv2.53 = trunc i32 %xor.53 to i8
  %scevgep.54 = getelementptr i8, i8* %a, i64 54
  %54 = load i8, i8* %scevgep.54, align 1
  %call.54 = call zeroext i8 %f(i8 zeroext %54)
  %conv.54 = zext i8 %call.54 to i32
  %conv1.54 = zext i8 %conv2.53 to i32
  %xor.54 = xor i32 %conv1.54, %conv.54
  %conv2.54 = trunc i32 %xor.54 to i8
  %scevgep.55 = getelementptr i8, i8* %a, i64 55
  %55 = load i8, i8* %scevgep.55, align 1
  %call.55 = call zeroext i8 %f(i8 zeroext %55)
  %conv.55 = zext i8 %call.55 to i32
  %conv1.55 = zext i8 %conv2.54 to i32
  %xor.55 = xor i32 %conv1.55, %conv.55
  %conv2.55 = trunc i32 %xor.55 to i8
  %scevgep.56 = getelementptr i8, i8* %a, i64 56
  %56 = load i8, i8* %scevgep.56, align 1
  %call.56 = call zeroext i8 %f(i8 zeroext %56)
  %conv.56 = zext i8 %call.56 to i32
  %conv1.56 = zext i8 %conv2.55 to i32
  %xor.56 = xor i32 %conv1.56, %conv.56
  %conv2.56 = trunc i32 %xor.56 to i8
  %scevgep.57 = getelementptr i8, i8* %a, i64 57
  %57 = load i8, i8* %scevgep.57, align 1
  %call.57 = call zeroext i8 %f(i8 zeroext %57)
  %conv.57 = zext i8 %call.57 to i32
  %conv1.57 = zext i8 %conv2.56 to i32
  %xor.57 = xor i32 %conv1.57, %conv.57
  %conv2.57 = trunc i32 %xor.57 to i8
  %scevgep.58 = getelementptr i8, i8* %a, i64 58
  %58 = load i8, i8* %scevgep.58, align 1
  %call.58 = call zeroext i8 %f(i8 zeroext %58)
  %conv.58 = zext i8 %call.58 to i32
  %conv1.58 = zext i8 %conv2.57 to i32
  %xor.58 = xor i32 %conv1.58, %conv.58
  %conv2.58 = trunc i32 %xor.58 to i8
  %scevgep.59 = getelementptr i8, i8* %a, i64 59
  %59 = load i8, i8* %scevgep.59, align 1
  %call.59 = call zeroext i8 %f(i8 zeroext %59)
  %conv.59 = zext i8 %call.59 to i32
  %conv1.59 = zext i8 %conv2.58 to i32
  %xor.59 = xor i32 %conv1.59, %conv.59
  %conv2.59 = trunc i32 %xor.59 to i8
  %scevgep.60 = getelementptr i8, i8* %a, i64 60
  %60 = load i8, i8* %scevgep.60, align 1
  %call.60 = call zeroext i8 %f(i8 zeroext %60)
  %conv.60 = zext i8 %call.60 to i32
  %conv1.60 = zext i8 %conv2.59 to i32
  %xor.60 = xor i32 %conv1.60, %conv.60
  %conv2.60 = trunc i32 %xor.60 to i8
  ret i8 %conv2.60
}

; Function Attrs: alwaysinline nounwind uwtable
define dso_local zeroext i8 @id(i8 zeroext %x) #0 {
entry:
  ret i8 %x
}

; Function Attrs: alwaysinline nounwind uwtable
define dso_local zeroext i8 @xors(i8* %a) #0 {
entry:
  %0 = load i8, i8* %a, align 1
  %scevgep.1 = getelementptr i8, i8* %a, i64 1
  %1 = load i8, i8* %scevgep.1, align 1
  %conv.i.1 = zext i8 %1 to i32
  %conv1.i.1 = zext i8 %0 to i32
  %xor.i.1 = xor i32 %conv1.i.1, %conv.i.1
  %conv2.i.1 = trunc i32 %xor.i.1 to i8
  %scevgep.2 = getelementptr i8, i8* %a, i64 2
  %2 = load i8, i8* %scevgep.2, align 1
  %conv.i.2 = zext i8 %2 to i32
  %conv1.i.2 = zext i8 %conv2.i.1 to i32
  %xor.i.2 = xor i32 %conv1.i.2, %conv.i.2
  %conv2.i.2 = trunc i32 %xor.i.2 to i8
  %scevgep.3 = getelementptr i8, i8* %a, i64 3
  %3 = load i8, i8* %scevgep.3, align 1
  %conv.i.3 = zext i8 %3 to i32
  %conv1.i.3 = zext i8 %conv2.i.2 to i32
  %xor.i.3 = xor i32 %conv1.i.3, %conv.i.3
  %conv2.i.3 = trunc i32 %xor.i.3 to i8
  %scevgep.4 = getelementptr i8, i8* %a, i64 4
  %4 = load i8, i8* %scevgep.4, align 1
  %conv.i.4 = zext i8 %4 to i32
  %conv1.i.4 = zext i8 %conv2.i.3 to i32
  %xor.i.4 = xor i32 %conv1.i.4, %conv.i.4
  %conv2.i.4 = trunc i32 %xor.i.4 to i8
  %scevgep.5 = getelementptr i8, i8* %a, i64 5
  %5 = load i8, i8* %scevgep.5, align 1
  %conv.i.5 = zext i8 %5 to i32
  %conv1.i.5 = zext i8 %conv2.i.4 to i32
  %xor.i.5 = xor i32 %conv1.i.5, %conv.i.5
  %conv2.i.5 = trunc i32 %xor.i.5 to i8
  %scevgep.6 = getelementptr i8, i8* %a, i64 6
  %6 = load i8, i8* %scevgep.6, align 1
  %conv.i.6 = zext i8 %6 to i32
  %conv1.i.6 = zext i8 %conv2.i.5 to i32
  %xor.i.6 = xor i32 %conv1.i.6, %conv.i.6
  %conv2.i.6 = trunc i32 %xor.i.6 to i8
  %scevgep.7 = getelementptr i8, i8* %a, i64 7
  %7 = load i8, i8* %scevgep.7, align 1
  %conv.i.7 = zext i8 %7 to i32
  %conv1.i.7 = zext i8 %conv2.i.6 to i32
  %xor.i.7 = xor i32 %conv1.i.7, %conv.i.7
  %conv2.i.7 = trunc i32 %xor.i.7 to i8
  %scevgep.8 = getelementptr i8, i8* %a, i64 8
  %8 = load i8, i8* %scevgep.8, align 1
  %conv.i.8 = zext i8 %8 to i32
  %conv1.i.8 = zext i8 %conv2.i.7 to i32
  %xor.i.8 = xor i32 %conv1.i.8, %conv.i.8
  %conv2.i.8 = trunc i32 %xor.i.8 to i8
  %scevgep.9 = getelementptr i8, i8* %a, i64 9
  %9 = load i8, i8* %scevgep.9, align 1
  %conv.i.9 = zext i8 %9 to i32
  %conv1.i.9 = zext i8 %conv2.i.8 to i32
  %xor.i.9 = xor i32 %conv1.i.9, %conv.i.9
  %conv2.i.9 = trunc i32 %xor.i.9 to i8
  %scevgep.10 = getelementptr i8, i8* %a, i64 10
  %10 = load i8, i8* %scevgep.10, align 1
  %conv.i.10 = zext i8 %10 to i32
  %conv1.i.10 = zext i8 %conv2.i.9 to i32
  %xor.i.10 = xor i32 %conv1.i.10, %conv.i.10
  %conv2.i.10 = trunc i32 %xor.i.10 to i8
  %scevgep.11 = getelementptr i8, i8* %a, i64 11
  %11 = load i8, i8* %scevgep.11, align 1
  %conv.i.11 = zext i8 %11 to i32
  %conv1.i.11 = zext i8 %conv2.i.10 to i32
  %xor.i.11 = xor i32 %conv1.i.11, %conv.i.11
  %conv2.i.11 = trunc i32 %xor.i.11 to i8
  %scevgep.12 = getelementptr i8, i8* %a, i64 12
  %12 = load i8, i8* %scevgep.12, align 1
  %conv.i.12 = zext i8 %12 to i32
  %conv1.i.12 = zext i8 %conv2.i.11 to i32
  %xor.i.12 = xor i32 %conv1.i.12, %conv.i.12
  %conv2.i.12 = trunc i32 %xor.i.12 to i8
  %scevgep.13 = getelementptr i8, i8* %a, i64 13
  %13 = load i8, i8* %scevgep.13, align 1
  %conv.i.13 = zext i8 %13 to i32
  %conv1.i.13 = zext i8 %conv2.i.12 to i32
  %xor.i.13 = xor i32 %conv1.i.13, %conv.i.13
  %conv2.i.13 = trunc i32 %xor.i.13 to i8
  %scevgep.14 = getelementptr i8, i8* %a, i64 14
  %14 = load i8, i8* %scevgep.14, align 1
  %conv.i.14 = zext i8 %14 to i32
  %conv1.i.14 = zext i8 %conv2.i.13 to i32
  %xor.i.14 = xor i32 %conv1.i.14, %conv.i.14
  %conv2.i.14 = trunc i32 %xor.i.14 to i8
  %scevgep.15 = getelementptr i8, i8* %a, i64 15
  %15 = load i8, i8* %scevgep.15, align 1
  %conv.i.15 = zext i8 %15 to i32
  %conv1.i.15 = zext i8 %conv2.i.14 to i32
  %xor.i.15 = xor i32 %conv1.i.15, %conv.i.15
  %conv2.i.15 = trunc i32 %xor.i.15 to i8
  %scevgep.16 = getelementptr i8, i8* %a, i64 16
  %16 = load i8, i8* %scevgep.16, align 1
  %conv.i.16 = zext i8 %16 to i32
  %conv1.i.16 = zext i8 %conv2.i.15 to i32
  %xor.i.16 = xor i32 %conv1.i.16, %conv.i.16
  %conv2.i.16 = trunc i32 %xor.i.16 to i8
  %scevgep.17 = getelementptr i8, i8* %a, i64 17
  %17 = load i8, i8* %scevgep.17, align 1
  %conv.i.17 = zext i8 %17 to i32
  %conv1.i.17 = zext i8 %conv2.i.16 to i32
  %xor.i.17 = xor i32 %conv1.i.17, %conv.i.17
  %conv2.i.17 = trunc i32 %xor.i.17 to i8
  %scevgep.18 = getelementptr i8, i8* %a, i64 18
  %18 = load i8, i8* %scevgep.18, align 1
  %conv.i.18 = zext i8 %18 to i32
  %conv1.i.18 = zext i8 %conv2.i.17 to i32
  %xor.i.18 = xor i32 %conv1.i.18, %conv.i.18
  %conv2.i.18 = trunc i32 %xor.i.18 to i8
  %scevgep.19 = getelementptr i8, i8* %a, i64 19
  %19 = load i8, i8* %scevgep.19, align 1
  %conv.i.19 = zext i8 %19 to i32
  %conv1.i.19 = zext i8 %conv2.i.18 to i32
  %xor.i.19 = xor i32 %conv1.i.19, %conv.i.19
  %conv2.i.19 = trunc i32 %xor.i.19 to i8
  %scevgep.20 = getelementptr i8, i8* %a, i64 20
  %20 = load i8, i8* %scevgep.20, align 1
  %conv.i.20 = zext i8 %20 to i32
  %conv1.i.20 = zext i8 %conv2.i.19 to i32
  %xor.i.20 = xor i32 %conv1.i.20, %conv.i.20
  %conv2.i.20 = trunc i32 %xor.i.20 to i8
  %scevgep.21 = getelementptr i8, i8* %a, i64 21
  %21 = load i8, i8* %scevgep.21, align 1
  %conv.i.21 = zext i8 %21 to i32
  %conv1.i.21 = zext i8 %conv2.i.20 to i32
  %xor.i.21 = xor i32 %conv1.i.21, %conv.i.21
  %conv2.i.21 = trunc i32 %xor.i.21 to i8
  %scevgep.22 = getelementptr i8, i8* %a, i64 22
  %22 = load i8, i8* %scevgep.22, align 1
  %conv.i.22 = zext i8 %22 to i32
  %conv1.i.22 = zext i8 %conv2.i.21 to i32
  %xor.i.22 = xor i32 %conv1.i.22, %conv.i.22
  %conv2.i.22 = trunc i32 %xor.i.22 to i8
  %scevgep.23 = getelementptr i8, i8* %a, i64 23
  %23 = load i8, i8* %scevgep.23, align 1
  %conv.i.23 = zext i8 %23 to i32
  %conv1.i.23 = zext i8 %conv2.i.22 to i32
  %xor.i.23 = xor i32 %conv1.i.23, %conv.i.23
  %conv2.i.23 = trunc i32 %xor.i.23 to i8
  %scevgep.24 = getelementptr i8, i8* %a, i64 24
  %24 = load i8, i8* %scevgep.24, align 1
  %conv.i.24 = zext i8 %24 to i32
  %conv1.i.24 = zext i8 %conv2.i.23 to i32
  %xor.i.24 = xor i32 %conv1.i.24, %conv.i.24
  %conv2.i.24 = trunc i32 %xor.i.24 to i8
  %scevgep.25 = getelementptr i8, i8* %a, i64 25
  %25 = load i8, i8* %scevgep.25, align 1
  %conv.i.25 = zext i8 %25 to i32
  %conv1.i.25 = zext i8 %conv2.i.24 to i32
  %xor.i.25 = xor i32 %conv1.i.25, %conv.i.25
  %conv2.i.25 = trunc i32 %xor.i.25 to i8
  %scevgep.26 = getelementptr i8, i8* %a, i64 26
  %26 = load i8, i8* %scevgep.26, align 1
  %conv.i.26 = zext i8 %26 to i32
  %conv1.i.26 = zext i8 %conv2.i.25 to i32
  %xor.i.26 = xor i32 %conv1.i.26, %conv.i.26
  %conv2.i.26 = trunc i32 %xor.i.26 to i8
  %scevgep.27 = getelementptr i8, i8* %a, i64 27
  %27 = load i8, i8* %scevgep.27, align 1
  %conv.i.27 = zext i8 %27 to i32
  %conv1.i.27 = zext i8 %conv2.i.26 to i32
  %xor.i.27 = xor i32 %conv1.i.27, %conv.i.27
  %conv2.i.27 = trunc i32 %xor.i.27 to i8
  %scevgep.28 = getelementptr i8, i8* %a, i64 28
  %28 = load i8, i8* %scevgep.28, align 1
  %conv.i.28 = zext i8 %28 to i32
  %conv1.i.28 = zext i8 %conv2.i.27 to i32
  %xor.i.28 = xor i32 %conv1.i.28, %conv.i.28
  %conv2.i.28 = trunc i32 %xor.i.28 to i8
  %scevgep.29 = getelementptr i8, i8* %a, i64 29
  %29 = load i8, i8* %scevgep.29, align 1
  %conv.i.29 = zext i8 %29 to i32
  %conv1.i.29 = zext i8 %conv2.i.28 to i32
  %xor.i.29 = xor i32 %conv1.i.29, %conv.i.29
  %conv2.i.29 = trunc i32 %xor.i.29 to i8
  %scevgep.30 = getelementptr i8, i8* %a, i64 30
  %30 = load i8, i8* %scevgep.30, align 1
  %conv.i.30 = zext i8 %30 to i32
  %conv1.i.30 = zext i8 %conv2.i.29 to i32
  %xor.i.30 = xor i32 %conv1.i.30, %conv.i.30
  %conv2.i.30 = trunc i32 %xor.i.30 to i8
  %scevgep.31 = getelementptr i8, i8* %a, i64 31
  %31 = load i8, i8* %scevgep.31, align 1
  %conv.i.31 = zext i8 %31 to i32
  %conv1.i.31 = zext i8 %conv2.i.30 to i32
  %xor.i.31 = xor i32 %conv1.i.31, %conv.i.31
  %conv2.i.31 = trunc i32 %xor.i.31 to i8
  %scevgep.32 = getelementptr i8, i8* %a, i64 32
  %32 = load i8, i8* %scevgep.32, align 1
  %conv.i.32 = zext i8 %32 to i32
  %conv1.i.32 = zext i8 %conv2.i.31 to i32
  %xor.i.32 = xor i32 %conv1.i.32, %conv.i.32
  %conv2.i.32 = trunc i32 %xor.i.32 to i8
  %scevgep.33 = getelementptr i8, i8* %a, i64 33
  %33 = load i8, i8* %scevgep.33, align 1
  %conv.i.33 = zext i8 %33 to i32
  %conv1.i.33 = zext i8 %conv2.i.32 to i32
  %xor.i.33 = xor i32 %conv1.i.33, %conv.i.33
  %conv2.i.33 = trunc i32 %xor.i.33 to i8
  %scevgep.34 = getelementptr i8, i8* %a, i64 34
  %34 = load i8, i8* %scevgep.34, align 1
  %conv.i.34 = zext i8 %34 to i32
  %conv1.i.34 = zext i8 %conv2.i.33 to i32
  %xor.i.34 = xor i32 %conv1.i.34, %conv.i.34
  %conv2.i.34 = trunc i32 %xor.i.34 to i8
  %scevgep.35 = getelementptr i8, i8* %a, i64 35
  %35 = load i8, i8* %scevgep.35, align 1
  %conv.i.35 = zext i8 %35 to i32
  %conv1.i.35 = zext i8 %conv2.i.34 to i32
  %xor.i.35 = xor i32 %conv1.i.35, %conv.i.35
  %conv2.i.35 = trunc i32 %xor.i.35 to i8
  %scevgep.36 = getelementptr i8, i8* %a, i64 36
  %36 = load i8, i8* %scevgep.36, align 1
  %conv.i.36 = zext i8 %36 to i32
  %conv1.i.36 = zext i8 %conv2.i.35 to i32
  %xor.i.36 = xor i32 %conv1.i.36, %conv.i.36
  %conv2.i.36 = trunc i32 %xor.i.36 to i8
  %scevgep.37 = getelementptr i8, i8* %a, i64 37
  %37 = load i8, i8* %scevgep.37, align 1
  %conv.i.37 = zext i8 %37 to i32
  %conv1.i.37 = zext i8 %conv2.i.36 to i32
  %xor.i.37 = xor i32 %conv1.i.37, %conv.i.37
  %conv2.i.37 = trunc i32 %xor.i.37 to i8
  %scevgep.38 = getelementptr i8, i8* %a, i64 38
  %38 = load i8, i8* %scevgep.38, align 1
  %conv.i.38 = zext i8 %38 to i32
  %conv1.i.38 = zext i8 %conv2.i.37 to i32
  %xor.i.38 = xor i32 %conv1.i.38, %conv.i.38
  %conv2.i.38 = trunc i32 %xor.i.38 to i8
  %scevgep.39 = getelementptr i8, i8* %a, i64 39
  %39 = load i8, i8* %scevgep.39, align 1
  %conv.i.39 = zext i8 %39 to i32
  %conv1.i.39 = zext i8 %conv2.i.38 to i32
  %xor.i.39 = xor i32 %conv1.i.39, %conv.i.39
  %conv2.i.39 = trunc i32 %xor.i.39 to i8
  %scevgep.40 = getelementptr i8, i8* %a, i64 40
  %40 = load i8, i8* %scevgep.40, align 1
  %conv.i.40 = zext i8 %40 to i32
  %conv1.i.40 = zext i8 %conv2.i.39 to i32
  %xor.i.40 = xor i32 %conv1.i.40, %conv.i.40
  %conv2.i.40 = trunc i32 %xor.i.40 to i8
  %scevgep.41 = getelementptr i8, i8* %a, i64 41
  %41 = load i8, i8* %scevgep.41, align 1
  %conv.i.41 = zext i8 %41 to i32
  %conv1.i.41 = zext i8 %conv2.i.40 to i32
  %xor.i.41 = xor i32 %conv1.i.41, %conv.i.41
  %conv2.i.41 = trunc i32 %xor.i.41 to i8
  %scevgep.42 = getelementptr i8, i8* %a, i64 42
  %42 = load i8, i8* %scevgep.42, align 1
  %conv.i.42 = zext i8 %42 to i32
  %conv1.i.42 = zext i8 %conv2.i.41 to i32
  %xor.i.42 = xor i32 %conv1.i.42, %conv.i.42
  %conv2.i.42 = trunc i32 %xor.i.42 to i8
  %scevgep.43 = getelementptr i8, i8* %a, i64 43
  %43 = load i8, i8* %scevgep.43, align 1
  %conv.i.43 = zext i8 %43 to i32
  %conv1.i.43 = zext i8 %conv2.i.42 to i32
  %xor.i.43 = xor i32 %conv1.i.43, %conv.i.43
  %conv2.i.43 = trunc i32 %xor.i.43 to i8
  %scevgep.44 = getelementptr i8, i8* %a, i64 44
  %44 = load i8, i8* %scevgep.44, align 1
  %conv.i.44 = zext i8 %44 to i32
  %conv1.i.44 = zext i8 %conv2.i.43 to i32
  %xor.i.44 = xor i32 %conv1.i.44, %conv.i.44
  %conv2.i.44 = trunc i32 %xor.i.44 to i8
  %scevgep.45 = getelementptr i8, i8* %a, i64 45
  %45 = load i8, i8* %scevgep.45, align 1
  %conv.i.45 = zext i8 %45 to i32
  %conv1.i.45 = zext i8 %conv2.i.44 to i32
  %xor.i.45 = xor i32 %conv1.i.45, %conv.i.45
  %conv2.i.45 = trunc i32 %xor.i.45 to i8
  %scevgep.46 = getelementptr i8, i8* %a, i64 46
  %46 = load i8, i8* %scevgep.46, align 1
  %conv.i.46 = zext i8 %46 to i32
  %conv1.i.46 = zext i8 %conv2.i.45 to i32
  %xor.i.46 = xor i32 %conv1.i.46, %conv.i.46
  %conv2.i.46 = trunc i32 %xor.i.46 to i8
  %scevgep.47 = getelementptr i8, i8* %a, i64 47
  %47 = load i8, i8* %scevgep.47, align 1
  %conv.i.47 = zext i8 %47 to i32
  %conv1.i.47 = zext i8 %conv2.i.46 to i32
  %xor.i.47 = xor i32 %conv1.i.47, %conv.i.47
  %conv2.i.47 = trunc i32 %xor.i.47 to i8
  %scevgep.48 = getelementptr i8, i8* %a, i64 48
  %48 = load i8, i8* %scevgep.48, align 1
  %conv.i.48 = zext i8 %48 to i32
  %conv1.i.48 = zext i8 %conv2.i.47 to i32
  %xor.i.48 = xor i32 %conv1.i.48, %conv.i.48
  %conv2.i.48 = trunc i32 %xor.i.48 to i8
  %scevgep.49 = getelementptr i8, i8* %a, i64 49
  %49 = load i8, i8* %scevgep.49, align 1
  %conv.i.49 = zext i8 %49 to i32
  %conv1.i.49 = zext i8 %conv2.i.48 to i32
  %xor.i.49 = xor i32 %conv1.i.49, %conv.i.49
  %conv2.i.49 = trunc i32 %xor.i.49 to i8
  %scevgep.50 = getelementptr i8, i8* %a, i64 50
  %50 = load i8, i8* %scevgep.50, align 1
  %conv.i.50 = zext i8 %50 to i32
  %conv1.i.50 = zext i8 %conv2.i.49 to i32
  %xor.i.50 = xor i32 %conv1.i.50, %conv.i.50
  %conv2.i.50 = trunc i32 %xor.i.50 to i8
  %scevgep.51 = getelementptr i8, i8* %a, i64 51
  %51 = load i8, i8* %scevgep.51, align 1
  %conv.i.51 = zext i8 %51 to i32
  %conv1.i.51 = zext i8 %conv2.i.50 to i32
  %xor.i.51 = xor i32 %conv1.i.51, %conv.i.51
  %conv2.i.51 = trunc i32 %xor.i.51 to i8
  %scevgep.52 = getelementptr i8, i8* %a, i64 52
  %52 = load i8, i8* %scevgep.52, align 1
  %conv.i.52 = zext i8 %52 to i32
  %conv1.i.52 = zext i8 %conv2.i.51 to i32
  %xor.i.52 = xor i32 %conv1.i.52, %conv.i.52
  %conv2.i.52 = trunc i32 %xor.i.52 to i8
  %scevgep.53 = getelementptr i8, i8* %a, i64 53
  %53 = load i8, i8* %scevgep.53, align 1
  %conv.i.53 = zext i8 %53 to i32
  %conv1.i.53 = zext i8 %conv2.i.52 to i32
  %xor.i.53 = xor i32 %conv1.i.53, %conv.i.53
  %conv2.i.53 = trunc i32 %xor.i.53 to i8
  %scevgep.54 = getelementptr i8, i8* %a, i64 54
  %54 = load i8, i8* %scevgep.54, align 1
  %conv.i.54 = zext i8 %54 to i32
  %conv1.i.54 = zext i8 %conv2.i.53 to i32
  %xor.i.54 = xor i32 %conv1.i.54, %conv.i.54
  %conv2.i.54 = trunc i32 %xor.i.54 to i8
  %scevgep.55 = getelementptr i8, i8* %a, i64 55
  %55 = load i8, i8* %scevgep.55, align 1
  %conv.i.55 = zext i8 %55 to i32
  %conv1.i.55 = zext i8 %conv2.i.54 to i32
  %xor.i.55 = xor i32 %conv1.i.55, %conv.i.55
  %conv2.i.55 = trunc i32 %xor.i.55 to i8
  %scevgep.56 = getelementptr i8, i8* %a, i64 56
  %56 = load i8, i8* %scevgep.56, align 1
  %conv.i.56 = zext i8 %56 to i32
  %conv1.i.56 = zext i8 %conv2.i.55 to i32
  %xor.i.56 = xor i32 %conv1.i.56, %conv.i.56
  %conv2.i.56 = trunc i32 %xor.i.56 to i8
  %scevgep.57 = getelementptr i8, i8* %a, i64 57
  %57 = load i8, i8* %scevgep.57, align 1
  %conv.i.57 = zext i8 %57 to i32
  %conv1.i.57 = zext i8 %conv2.i.56 to i32
  %xor.i.57 = xor i32 %conv1.i.57, %conv.i.57
  %conv2.i.57 = trunc i32 %xor.i.57 to i8
  %scevgep.58 = getelementptr i8, i8* %a, i64 58
  %58 = load i8, i8* %scevgep.58, align 1
  %conv.i.58 = zext i8 %58 to i32
  %conv1.i.58 = zext i8 %conv2.i.57 to i32
  %xor.i.58 = xor i32 %conv1.i.58, %conv.i.58
  %conv2.i.58 = trunc i32 %xor.i.58 to i8
  %scevgep.59 = getelementptr i8, i8* %a, i64 59
  %59 = load i8, i8* %scevgep.59, align 1
  %conv.i.59 = zext i8 %59 to i32
  %conv1.i.59 = zext i8 %conv2.i.58 to i32
  %xor.i.59 = xor i32 %conv1.i.59, %conv.i.59
  %conv2.i.59 = trunc i32 %xor.i.59 to i8
  %scevgep.60 = getelementptr i8, i8* %a, i64 60
  %60 = load i8, i8* %scevgep.60, align 1
  %conv.i.60 = zext i8 %60 to i32
  %conv1.i.60 = zext i8 %conv2.i.59 to i32
  %xor.i.60 = xor i32 %conv1.i.60, %conv.i.60
  %conv2.i.60 = trunc i32 %xor.i.60 to i8
  ret i8 %conv2.i.60
}

; Function Attrs: alwaysinline nounwind uwtable
define dso_local void @sec_mult(i8* %a, i8* %b, i8* %c) #0 {
entry:
  %r = alloca [61 x [61 x i8]], align 16
  %call = call zeroext i8 (...) @rand()
  %call1 = call zeroext i8 (...) @rand()
  %conv = zext i8 %call to i32
  %0 = load i8, i8* %a, align 1
  %scevgep50.1 = getelementptr i8, i8* %a, i64 1
  %1 = load i8, i8* %scevgep50.1, align 1
  %conv.i.i.1 = zext i8 %1 to i32
  %conv1.i.i.1 = zext i8 %0 to i32
  %xor.i.i.1 = xor i32 %conv1.i.i.1, %conv.i.i.1
  %conv2.i.i.1 = trunc i32 %xor.i.i.1 to i8
  %scevgep50.2 = getelementptr i8, i8* %a, i64 2
  %2 = load i8, i8* %scevgep50.2, align 1
  %conv.i.i.2 = zext i8 %2 to i32
  %conv1.i.i.2 = zext i8 %conv2.i.i.1 to i32
  %xor.i.i.2 = xor i32 %conv1.i.i.2, %conv.i.i.2
  %conv2.i.i.2 = trunc i32 %xor.i.i.2 to i8
  %scevgep50.3 = getelementptr i8, i8* %a, i64 3
  %3 = load i8, i8* %scevgep50.3, align 1
  %conv.i.i.3 = zext i8 %3 to i32
  %conv1.i.i.3 = zext i8 %conv2.i.i.2 to i32
  %xor.i.i.3 = xor i32 %conv1.i.i.3, %conv.i.i.3
  %conv2.i.i.3 = trunc i32 %xor.i.i.3 to i8
  %scevgep50.4 = getelementptr i8, i8* %a, i64 4
  %4 = load i8, i8* %scevgep50.4, align 1
  %conv.i.i.4 = zext i8 %4 to i32
  %conv1.i.i.4 = zext i8 %conv2.i.i.3 to i32
  %xor.i.i.4 = xor i32 %conv1.i.i.4, %conv.i.i.4
  %conv2.i.i.4 = trunc i32 %xor.i.i.4 to i8
  %scevgep50.5 = getelementptr i8, i8* %a, i64 5
  %5 = load i8, i8* %scevgep50.5, align 1
  %conv.i.i.5 = zext i8 %5 to i32
  %conv1.i.i.5 = zext i8 %conv2.i.i.4 to i32
  %xor.i.i.5 = xor i32 %conv1.i.i.5, %conv.i.i.5
  %conv2.i.i.5 = trunc i32 %xor.i.i.5 to i8
  %scevgep50.6 = getelementptr i8, i8* %a, i64 6
  %6 = load i8, i8* %scevgep50.6, align 1
  %conv.i.i.6 = zext i8 %6 to i32
  %conv1.i.i.6 = zext i8 %conv2.i.i.5 to i32
  %xor.i.i.6 = xor i32 %conv1.i.i.6, %conv.i.i.6
  %conv2.i.i.6 = trunc i32 %xor.i.i.6 to i8
  %scevgep50.7 = getelementptr i8, i8* %a, i64 7
  %7 = load i8, i8* %scevgep50.7, align 1
  %conv.i.i.7 = zext i8 %7 to i32
  %conv1.i.i.7 = zext i8 %conv2.i.i.6 to i32
  %xor.i.i.7 = xor i32 %conv1.i.i.7, %conv.i.i.7
  %conv2.i.i.7 = trunc i32 %xor.i.i.7 to i8
  %scevgep50.8 = getelementptr i8, i8* %a, i64 8
  %8 = load i8, i8* %scevgep50.8, align 1
  %conv.i.i.8 = zext i8 %8 to i32
  %conv1.i.i.8 = zext i8 %conv2.i.i.7 to i32
  %xor.i.i.8 = xor i32 %conv1.i.i.8, %conv.i.i.8
  %conv2.i.i.8 = trunc i32 %xor.i.i.8 to i8
  %scevgep50.9 = getelementptr i8, i8* %a, i64 9
  %9 = load i8, i8* %scevgep50.9, align 1
  %conv.i.i.9 = zext i8 %9 to i32
  %conv1.i.i.9 = zext i8 %conv2.i.i.8 to i32
  %xor.i.i.9 = xor i32 %conv1.i.i.9, %conv.i.i.9
  %conv2.i.i.9 = trunc i32 %xor.i.i.9 to i8
  %scevgep50.10 = getelementptr i8, i8* %a, i64 10
  %10 = load i8, i8* %scevgep50.10, align 1
  %conv.i.i.10 = zext i8 %10 to i32
  %conv1.i.i.10 = zext i8 %conv2.i.i.9 to i32
  %xor.i.i.10 = xor i32 %conv1.i.i.10, %conv.i.i.10
  %conv2.i.i.10 = trunc i32 %xor.i.i.10 to i8
  %scevgep50.11 = getelementptr i8, i8* %a, i64 11
  %11 = load i8, i8* %scevgep50.11, align 1
  %conv.i.i.11 = zext i8 %11 to i32
  %conv1.i.i.11 = zext i8 %conv2.i.i.10 to i32
  %xor.i.i.11 = xor i32 %conv1.i.i.11, %conv.i.i.11
  %conv2.i.i.11 = trunc i32 %xor.i.i.11 to i8
  %scevgep50.12 = getelementptr i8, i8* %a, i64 12
  %12 = load i8, i8* %scevgep50.12, align 1
  %conv.i.i.12 = zext i8 %12 to i32
  %conv1.i.i.12 = zext i8 %conv2.i.i.11 to i32
  %xor.i.i.12 = xor i32 %conv1.i.i.12, %conv.i.i.12
  %conv2.i.i.12 = trunc i32 %xor.i.i.12 to i8
  %scevgep50.13 = getelementptr i8, i8* %a, i64 13
  %13 = load i8, i8* %scevgep50.13, align 1
  %conv.i.i.13 = zext i8 %13 to i32
  %conv1.i.i.13 = zext i8 %conv2.i.i.12 to i32
  %xor.i.i.13 = xor i32 %conv1.i.i.13, %conv.i.i.13
  %conv2.i.i.13 = trunc i32 %xor.i.i.13 to i8
  %scevgep50.14 = getelementptr i8, i8* %a, i64 14
  %14 = load i8, i8* %scevgep50.14, align 1
  %conv.i.i.14 = zext i8 %14 to i32
  %conv1.i.i.14 = zext i8 %conv2.i.i.13 to i32
  %xor.i.i.14 = xor i32 %conv1.i.i.14, %conv.i.i.14
  %conv2.i.i.14 = trunc i32 %xor.i.i.14 to i8
  %scevgep50.15 = getelementptr i8, i8* %a, i64 15
  %15 = load i8, i8* %scevgep50.15, align 1
  %conv.i.i.15 = zext i8 %15 to i32
  %conv1.i.i.15 = zext i8 %conv2.i.i.14 to i32
  %xor.i.i.15 = xor i32 %conv1.i.i.15, %conv.i.i.15
  %conv2.i.i.15 = trunc i32 %xor.i.i.15 to i8
  %scevgep50.16 = getelementptr i8, i8* %a, i64 16
  %16 = load i8, i8* %scevgep50.16, align 1
  %conv.i.i.16 = zext i8 %16 to i32
  %conv1.i.i.16 = zext i8 %conv2.i.i.15 to i32
  %xor.i.i.16 = xor i32 %conv1.i.i.16, %conv.i.i.16
  %conv2.i.i.16 = trunc i32 %xor.i.i.16 to i8
  %scevgep50.17 = getelementptr i8, i8* %a, i64 17
  %17 = load i8, i8* %scevgep50.17, align 1
  %conv.i.i.17 = zext i8 %17 to i32
  %conv1.i.i.17 = zext i8 %conv2.i.i.16 to i32
  %xor.i.i.17 = xor i32 %conv1.i.i.17, %conv.i.i.17
  %conv2.i.i.17 = trunc i32 %xor.i.i.17 to i8
  %scevgep50.18 = getelementptr i8, i8* %a, i64 18
  %18 = load i8, i8* %scevgep50.18, align 1
  %conv.i.i.18 = zext i8 %18 to i32
  %conv1.i.i.18 = zext i8 %conv2.i.i.17 to i32
  %xor.i.i.18 = xor i32 %conv1.i.i.18, %conv.i.i.18
  %conv2.i.i.18 = trunc i32 %xor.i.i.18 to i8
  %scevgep50.19 = getelementptr i8, i8* %a, i64 19
  %19 = load i8, i8* %scevgep50.19, align 1
  %conv.i.i.19 = zext i8 %19 to i32
  %conv1.i.i.19 = zext i8 %conv2.i.i.18 to i32
  %xor.i.i.19 = xor i32 %conv1.i.i.19, %conv.i.i.19
  %conv2.i.i.19 = trunc i32 %xor.i.i.19 to i8
  %scevgep50.20 = getelementptr i8, i8* %a, i64 20
  %20 = load i8, i8* %scevgep50.20, align 1
  %conv.i.i.20 = zext i8 %20 to i32
  %conv1.i.i.20 = zext i8 %conv2.i.i.19 to i32
  %xor.i.i.20 = xor i32 %conv1.i.i.20, %conv.i.i.20
  %conv2.i.i.20 = trunc i32 %xor.i.i.20 to i8
  %scevgep50.21 = getelementptr i8, i8* %a, i64 21
  %21 = load i8, i8* %scevgep50.21, align 1
  %conv.i.i.21 = zext i8 %21 to i32
  %conv1.i.i.21 = zext i8 %conv2.i.i.20 to i32
  %xor.i.i.21 = xor i32 %conv1.i.i.21, %conv.i.i.21
  %conv2.i.i.21 = trunc i32 %xor.i.i.21 to i8
  %scevgep50.22 = getelementptr i8, i8* %a, i64 22
  %22 = load i8, i8* %scevgep50.22, align 1
  %conv.i.i.22 = zext i8 %22 to i32
  %conv1.i.i.22 = zext i8 %conv2.i.i.21 to i32
  %xor.i.i.22 = xor i32 %conv1.i.i.22, %conv.i.i.22
  %conv2.i.i.22 = trunc i32 %xor.i.i.22 to i8
  %scevgep50.23 = getelementptr i8, i8* %a, i64 23
  %23 = load i8, i8* %scevgep50.23, align 1
  %conv.i.i.23 = zext i8 %23 to i32
  %conv1.i.i.23 = zext i8 %conv2.i.i.22 to i32
  %xor.i.i.23 = xor i32 %conv1.i.i.23, %conv.i.i.23
  %conv2.i.i.23 = trunc i32 %xor.i.i.23 to i8
  %scevgep50.24 = getelementptr i8, i8* %a, i64 24
  %24 = load i8, i8* %scevgep50.24, align 1
  %conv.i.i.24 = zext i8 %24 to i32
  %conv1.i.i.24 = zext i8 %conv2.i.i.23 to i32
  %xor.i.i.24 = xor i32 %conv1.i.i.24, %conv.i.i.24
  %conv2.i.i.24 = trunc i32 %xor.i.i.24 to i8
  %scevgep50.25 = getelementptr i8, i8* %a, i64 25
  %25 = load i8, i8* %scevgep50.25, align 1
  %conv.i.i.25 = zext i8 %25 to i32
  %conv1.i.i.25 = zext i8 %conv2.i.i.24 to i32
  %xor.i.i.25 = xor i32 %conv1.i.i.25, %conv.i.i.25
  %conv2.i.i.25 = trunc i32 %xor.i.i.25 to i8
  %scevgep50.26 = getelementptr i8, i8* %a, i64 26
  %26 = load i8, i8* %scevgep50.26, align 1
  %conv.i.i.26 = zext i8 %26 to i32
  %conv1.i.i.26 = zext i8 %conv2.i.i.25 to i32
  %xor.i.i.26 = xor i32 %conv1.i.i.26, %conv.i.i.26
  %conv2.i.i.26 = trunc i32 %xor.i.i.26 to i8
  %scevgep50.27 = getelementptr i8, i8* %a, i64 27
  %27 = load i8, i8* %scevgep50.27, align 1
  %conv.i.i.27 = zext i8 %27 to i32
  %conv1.i.i.27 = zext i8 %conv2.i.i.26 to i32
  %xor.i.i.27 = xor i32 %conv1.i.i.27, %conv.i.i.27
  %conv2.i.i.27 = trunc i32 %xor.i.i.27 to i8
  %scevgep50.28 = getelementptr i8, i8* %a, i64 28
  %28 = load i8, i8* %scevgep50.28, align 1
  %conv.i.i.28 = zext i8 %28 to i32
  %conv1.i.i.28 = zext i8 %conv2.i.i.27 to i32
  %xor.i.i.28 = xor i32 %conv1.i.i.28, %conv.i.i.28
  %conv2.i.i.28 = trunc i32 %xor.i.i.28 to i8
  %scevgep50.29 = getelementptr i8, i8* %a, i64 29
  %29 = load i8, i8* %scevgep50.29, align 1
  %conv.i.i.29 = zext i8 %29 to i32
  %conv1.i.i.29 = zext i8 %conv2.i.i.28 to i32
  %xor.i.i.29 = xor i32 %conv1.i.i.29, %conv.i.i.29
  %conv2.i.i.29 = trunc i32 %xor.i.i.29 to i8
  %scevgep50.30 = getelementptr i8, i8* %a, i64 30
  %30 = load i8, i8* %scevgep50.30, align 1
  %conv.i.i.30 = zext i8 %30 to i32
  %conv1.i.i.30 = zext i8 %conv2.i.i.29 to i32
  %xor.i.i.30 = xor i32 %conv1.i.i.30, %conv.i.i.30
  %conv2.i.i.30 = trunc i32 %xor.i.i.30 to i8
  %scevgep50.31 = getelementptr i8, i8* %a, i64 31
  %31 = load i8, i8* %scevgep50.31, align 1
  %conv.i.i.31 = zext i8 %31 to i32
  %conv1.i.i.31 = zext i8 %conv2.i.i.30 to i32
  %xor.i.i.31 = xor i32 %conv1.i.i.31, %conv.i.i.31
  %conv2.i.i.31 = trunc i32 %xor.i.i.31 to i8
  %scevgep50.32 = getelementptr i8, i8* %a, i64 32
  %32 = load i8, i8* %scevgep50.32, align 1
  %conv.i.i.32 = zext i8 %32 to i32
  %conv1.i.i.32 = zext i8 %conv2.i.i.31 to i32
  %xor.i.i.32 = xor i32 %conv1.i.i.32, %conv.i.i.32
  %conv2.i.i.32 = trunc i32 %xor.i.i.32 to i8
  %scevgep50.33 = getelementptr i8, i8* %a, i64 33
  %33 = load i8, i8* %scevgep50.33, align 1
  %conv.i.i.33 = zext i8 %33 to i32
  %conv1.i.i.33 = zext i8 %conv2.i.i.32 to i32
  %xor.i.i.33 = xor i32 %conv1.i.i.33, %conv.i.i.33
  %conv2.i.i.33 = trunc i32 %xor.i.i.33 to i8
  %scevgep50.34 = getelementptr i8, i8* %a, i64 34
  %34 = load i8, i8* %scevgep50.34, align 1
  %conv.i.i.34 = zext i8 %34 to i32
  %conv1.i.i.34 = zext i8 %conv2.i.i.33 to i32
  %xor.i.i.34 = xor i32 %conv1.i.i.34, %conv.i.i.34
  %conv2.i.i.34 = trunc i32 %xor.i.i.34 to i8
  %scevgep50.35 = getelementptr i8, i8* %a, i64 35
  %35 = load i8, i8* %scevgep50.35, align 1
  %conv.i.i.35 = zext i8 %35 to i32
  %conv1.i.i.35 = zext i8 %conv2.i.i.34 to i32
  %xor.i.i.35 = xor i32 %conv1.i.i.35, %conv.i.i.35
  %conv2.i.i.35 = trunc i32 %xor.i.i.35 to i8
  %scevgep50.36 = getelementptr i8, i8* %a, i64 36
  %36 = load i8, i8* %scevgep50.36, align 1
  %conv.i.i.36 = zext i8 %36 to i32
  %conv1.i.i.36 = zext i8 %conv2.i.i.35 to i32
  %xor.i.i.36 = xor i32 %conv1.i.i.36, %conv.i.i.36
  %conv2.i.i.36 = trunc i32 %xor.i.i.36 to i8
  %scevgep50.37 = getelementptr i8, i8* %a, i64 37
  %37 = load i8, i8* %scevgep50.37, align 1
  %conv.i.i.37 = zext i8 %37 to i32
  %conv1.i.i.37 = zext i8 %conv2.i.i.36 to i32
  %xor.i.i.37 = xor i32 %conv1.i.i.37, %conv.i.i.37
  %conv2.i.i.37 = trunc i32 %xor.i.i.37 to i8
  %scevgep50.38 = getelementptr i8, i8* %a, i64 38
  %38 = load i8, i8* %scevgep50.38, align 1
  %conv.i.i.38 = zext i8 %38 to i32
  %conv1.i.i.38 = zext i8 %conv2.i.i.37 to i32
  %xor.i.i.38 = xor i32 %conv1.i.i.38, %conv.i.i.38
  %conv2.i.i.38 = trunc i32 %xor.i.i.38 to i8
  %scevgep50.39 = getelementptr i8, i8* %a, i64 39
  %39 = load i8, i8* %scevgep50.39, align 1
  %conv.i.i.39 = zext i8 %39 to i32
  %conv1.i.i.39 = zext i8 %conv2.i.i.38 to i32
  %xor.i.i.39 = xor i32 %conv1.i.i.39, %conv.i.i.39
  %conv2.i.i.39 = trunc i32 %xor.i.i.39 to i8
  %scevgep50.40 = getelementptr i8, i8* %a, i64 40
  %40 = load i8, i8* %scevgep50.40, align 1
  %conv.i.i.40 = zext i8 %40 to i32
  %conv1.i.i.40 = zext i8 %conv2.i.i.39 to i32
  %xor.i.i.40 = xor i32 %conv1.i.i.40, %conv.i.i.40
  %conv2.i.i.40 = trunc i32 %xor.i.i.40 to i8
  %scevgep50.41 = getelementptr i8, i8* %a, i64 41
  %41 = load i8, i8* %scevgep50.41, align 1
  %conv.i.i.41 = zext i8 %41 to i32
  %conv1.i.i.41 = zext i8 %conv2.i.i.40 to i32
  %xor.i.i.41 = xor i32 %conv1.i.i.41, %conv.i.i.41
  %conv2.i.i.41 = trunc i32 %xor.i.i.41 to i8
  %scevgep50.42 = getelementptr i8, i8* %a, i64 42
  %42 = load i8, i8* %scevgep50.42, align 1
  %conv.i.i.42 = zext i8 %42 to i32
  %conv1.i.i.42 = zext i8 %conv2.i.i.41 to i32
  %xor.i.i.42 = xor i32 %conv1.i.i.42, %conv.i.i.42
  %conv2.i.i.42 = trunc i32 %xor.i.i.42 to i8
  %scevgep50.43 = getelementptr i8, i8* %a, i64 43
  %43 = load i8, i8* %scevgep50.43, align 1
  %conv.i.i.43 = zext i8 %43 to i32
  %conv1.i.i.43 = zext i8 %conv2.i.i.42 to i32
  %xor.i.i.43 = xor i32 %conv1.i.i.43, %conv.i.i.43
  %conv2.i.i.43 = trunc i32 %xor.i.i.43 to i8
  %scevgep50.44 = getelementptr i8, i8* %a, i64 44
  %44 = load i8, i8* %scevgep50.44, align 1
  %conv.i.i.44 = zext i8 %44 to i32
  %conv1.i.i.44 = zext i8 %conv2.i.i.43 to i32
  %xor.i.i.44 = xor i32 %conv1.i.i.44, %conv.i.i.44
  %conv2.i.i.44 = trunc i32 %xor.i.i.44 to i8
  %scevgep50.45 = getelementptr i8, i8* %a, i64 45
  %45 = load i8, i8* %scevgep50.45, align 1
  %conv.i.i.45 = zext i8 %45 to i32
  %conv1.i.i.45 = zext i8 %conv2.i.i.44 to i32
  %xor.i.i.45 = xor i32 %conv1.i.i.45, %conv.i.i.45
  %conv2.i.i.45 = trunc i32 %xor.i.i.45 to i8
  %scevgep50.46 = getelementptr i8, i8* %a, i64 46
  %46 = load i8, i8* %scevgep50.46, align 1
  %conv.i.i.46 = zext i8 %46 to i32
  %conv1.i.i.46 = zext i8 %conv2.i.i.45 to i32
  %xor.i.i.46 = xor i32 %conv1.i.i.46, %conv.i.i.46
  %conv2.i.i.46 = trunc i32 %xor.i.i.46 to i8
  %scevgep50.47 = getelementptr i8, i8* %a, i64 47
  %47 = load i8, i8* %scevgep50.47, align 1
  %conv.i.i.47 = zext i8 %47 to i32
  %conv1.i.i.47 = zext i8 %conv2.i.i.46 to i32
  %xor.i.i.47 = xor i32 %conv1.i.i.47, %conv.i.i.47
  %conv2.i.i.47 = trunc i32 %xor.i.i.47 to i8
  %scevgep50.48 = getelementptr i8, i8* %a, i64 48
  %48 = load i8, i8* %scevgep50.48, align 1
  %conv.i.i.48 = zext i8 %48 to i32
  %conv1.i.i.48 = zext i8 %conv2.i.i.47 to i32
  %xor.i.i.48 = xor i32 %conv1.i.i.48, %conv.i.i.48
  %conv2.i.i.48 = trunc i32 %xor.i.i.48 to i8
  %scevgep50.49 = getelementptr i8, i8* %a, i64 49
  %49 = load i8, i8* %scevgep50.49, align 1
  %conv.i.i.49 = zext i8 %49 to i32
  %conv1.i.i.49 = zext i8 %conv2.i.i.48 to i32
  %xor.i.i.49 = xor i32 %conv1.i.i.49, %conv.i.i.49
  %conv2.i.i.49 = trunc i32 %xor.i.i.49 to i8
  %scevgep50.50 = getelementptr i8, i8* %a, i64 50
  %50 = load i8, i8* %scevgep50.50, align 1
  %conv.i.i.50 = zext i8 %50 to i32
  %conv1.i.i.50 = zext i8 %conv2.i.i.49 to i32
  %xor.i.i.50 = xor i32 %conv1.i.i.50, %conv.i.i.50
  %conv2.i.i.50 = trunc i32 %xor.i.i.50 to i8
  %scevgep50.51 = getelementptr i8, i8* %a, i64 51
  %51 = load i8, i8* %scevgep50.51, align 1
  %conv.i.i.51 = zext i8 %51 to i32
  %conv1.i.i.51 = zext i8 %conv2.i.i.50 to i32
  %xor.i.i.51 = xor i32 %conv1.i.i.51, %conv.i.i.51
  %conv2.i.i.51 = trunc i32 %xor.i.i.51 to i8
  %scevgep50.52 = getelementptr i8, i8* %a, i64 52
  %52 = load i8, i8* %scevgep50.52, align 1
  %conv.i.i.52 = zext i8 %52 to i32
  %conv1.i.i.52 = zext i8 %conv2.i.i.51 to i32
  %xor.i.i.52 = xor i32 %conv1.i.i.52, %conv.i.i.52
  %conv2.i.i.52 = trunc i32 %xor.i.i.52 to i8
  %scevgep50.53 = getelementptr i8, i8* %a, i64 53
  %53 = load i8, i8* %scevgep50.53, align 1
  %conv.i.i.53 = zext i8 %53 to i32
  %conv1.i.i.53 = zext i8 %conv2.i.i.52 to i32
  %xor.i.i.53 = xor i32 %conv1.i.i.53, %conv.i.i.53
  %conv2.i.i.53 = trunc i32 %xor.i.i.53 to i8
  %scevgep50.54 = getelementptr i8, i8* %a, i64 54
  %54 = load i8, i8* %scevgep50.54, align 1
  %conv.i.i.54 = zext i8 %54 to i32
  %conv1.i.i.54 = zext i8 %conv2.i.i.53 to i32
  %xor.i.i.54 = xor i32 %conv1.i.i.54, %conv.i.i.54
  %conv2.i.i.54 = trunc i32 %xor.i.i.54 to i8
  %scevgep50.55 = getelementptr i8, i8* %a, i64 55
  %55 = load i8, i8* %scevgep50.55, align 1
  %conv.i.i.55 = zext i8 %55 to i32
  %conv1.i.i.55 = zext i8 %conv2.i.i.54 to i32
  %xor.i.i.55 = xor i32 %conv1.i.i.55, %conv.i.i.55
  %conv2.i.i.55 = trunc i32 %xor.i.i.55 to i8
  %scevgep50.56 = getelementptr i8, i8* %a, i64 56
  %56 = load i8, i8* %scevgep50.56, align 1
  %conv.i.i.56 = zext i8 %56 to i32
  %conv1.i.i.56 = zext i8 %conv2.i.i.55 to i32
  %xor.i.i.56 = xor i32 %conv1.i.i.56, %conv.i.i.56
  %conv2.i.i.56 = trunc i32 %xor.i.i.56 to i8
  %scevgep50.57 = getelementptr i8, i8* %a, i64 57
  %57 = load i8, i8* %scevgep50.57, align 1
  %conv.i.i.57 = zext i8 %57 to i32
  %conv1.i.i.57 = zext i8 %conv2.i.i.56 to i32
  %xor.i.i.57 = xor i32 %conv1.i.i.57, %conv.i.i.57
  %conv2.i.i.57 = trunc i32 %xor.i.i.57 to i8
  %scevgep50.58 = getelementptr i8, i8* %a, i64 58
  %58 = load i8, i8* %scevgep50.58, align 1
  %conv.i.i.58 = zext i8 %58 to i32
  %conv1.i.i.58 = zext i8 %conv2.i.i.57 to i32
  %xor.i.i.58 = xor i32 %conv1.i.i.58, %conv.i.i.58
  %conv2.i.i.58 = trunc i32 %xor.i.i.58 to i8
  %scevgep50.59 = getelementptr i8, i8* %a, i64 59
  %59 = load i8, i8* %scevgep50.59, align 1
  %conv.i.i.59 = zext i8 %59 to i32
  %conv1.i.i.59 = zext i8 %conv2.i.i.58 to i32
  %xor.i.i.59 = xor i32 %conv1.i.i.59, %conv.i.i.59
  %conv2.i.i.59 = trunc i32 %xor.i.i.59 to i8
  %scevgep50.60 = getelementptr i8, i8* %a, i64 60
  %60 = load i8, i8* %scevgep50.60, align 1
  %conv.i.i.60 = zext i8 %60 to i32
  %conv1.i.i.60 = zext i8 %conv2.i.i.59 to i32
  %xor.i.i.60 = xor i32 %conv1.i.i.60, %conv.i.i.60
  %conv2.i.i.60 = trunc i32 %xor.i.i.60 to i8
  %conv3 = zext i8 %conv2.i.i.60 to i32
  %cmp = icmp eq i32 %conv, %conv3
  call void @assume(i1 zeroext %cmp)
  %conv5 = zext i8 %call1 to i32
  %61 = load i8, i8* %b, align 1
  %scevgep46.1 = getelementptr i8, i8* %b, i64 1
  %62 = load i8, i8* %scevgep46.1, align 1
  %conv.i.i96.1 = zext i8 %62 to i32
  %conv1.i.i97.1 = zext i8 %61 to i32
  %xor.i.i98.1 = xor i32 %conv1.i.i97.1, %conv.i.i96.1
  %conv2.i.i99.1 = trunc i32 %xor.i.i98.1 to i8
  %scevgep46.2 = getelementptr i8, i8* %b, i64 2
  %63 = load i8, i8* %scevgep46.2, align 1
  %conv.i.i96.2 = zext i8 %63 to i32
  %conv1.i.i97.2 = zext i8 %conv2.i.i99.1 to i32
  %xor.i.i98.2 = xor i32 %conv1.i.i97.2, %conv.i.i96.2
  %conv2.i.i99.2 = trunc i32 %xor.i.i98.2 to i8
  %scevgep46.3 = getelementptr i8, i8* %b, i64 3
  %64 = load i8, i8* %scevgep46.3, align 1
  %conv.i.i96.3 = zext i8 %64 to i32
  %conv1.i.i97.3 = zext i8 %conv2.i.i99.2 to i32
  %xor.i.i98.3 = xor i32 %conv1.i.i97.3, %conv.i.i96.3
  %conv2.i.i99.3 = trunc i32 %xor.i.i98.3 to i8
  %scevgep46.4 = getelementptr i8, i8* %b, i64 4
  %65 = load i8, i8* %scevgep46.4, align 1
  %conv.i.i96.4 = zext i8 %65 to i32
  %conv1.i.i97.4 = zext i8 %conv2.i.i99.3 to i32
  %xor.i.i98.4 = xor i32 %conv1.i.i97.4, %conv.i.i96.4
  %conv2.i.i99.4 = trunc i32 %xor.i.i98.4 to i8
  %scevgep46.5 = getelementptr i8, i8* %b, i64 5
  %66 = load i8, i8* %scevgep46.5, align 1
  %conv.i.i96.5 = zext i8 %66 to i32
  %conv1.i.i97.5 = zext i8 %conv2.i.i99.4 to i32
  %xor.i.i98.5 = xor i32 %conv1.i.i97.5, %conv.i.i96.5
  %conv2.i.i99.5 = trunc i32 %xor.i.i98.5 to i8
  %scevgep46.6 = getelementptr i8, i8* %b, i64 6
  %67 = load i8, i8* %scevgep46.6, align 1
  %conv.i.i96.6 = zext i8 %67 to i32
  %conv1.i.i97.6 = zext i8 %conv2.i.i99.5 to i32
  %xor.i.i98.6 = xor i32 %conv1.i.i97.6, %conv.i.i96.6
  %conv2.i.i99.6 = trunc i32 %xor.i.i98.6 to i8
  %scevgep46.7 = getelementptr i8, i8* %b, i64 7
  %68 = load i8, i8* %scevgep46.7, align 1
  %conv.i.i96.7 = zext i8 %68 to i32
  %conv1.i.i97.7 = zext i8 %conv2.i.i99.6 to i32
  %xor.i.i98.7 = xor i32 %conv1.i.i97.7, %conv.i.i96.7
  %conv2.i.i99.7 = trunc i32 %xor.i.i98.7 to i8
  %scevgep46.8 = getelementptr i8, i8* %b, i64 8
  %69 = load i8, i8* %scevgep46.8, align 1
  %conv.i.i96.8 = zext i8 %69 to i32
  %conv1.i.i97.8 = zext i8 %conv2.i.i99.7 to i32
  %xor.i.i98.8 = xor i32 %conv1.i.i97.8, %conv.i.i96.8
  %conv2.i.i99.8 = trunc i32 %xor.i.i98.8 to i8
  %scevgep46.9 = getelementptr i8, i8* %b, i64 9
  %70 = load i8, i8* %scevgep46.9, align 1
  %conv.i.i96.9 = zext i8 %70 to i32
  %conv1.i.i97.9 = zext i8 %conv2.i.i99.8 to i32
  %xor.i.i98.9 = xor i32 %conv1.i.i97.9, %conv.i.i96.9
  %conv2.i.i99.9 = trunc i32 %xor.i.i98.9 to i8
  %scevgep46.10 = getelementptr i8, i8* %b, i64 10
  %71 = load i8, i8* %scevgep46.10, align 1
  %conv.i.i96.10 = zext i8 %71 to i32
  %conv1.i.i97.10 = zext i8 %conv2.i.i99.9 to i32
  %xor.i.i98.10 = xor i32 %conv1.i.i97.10, %conv.i.i96.10
  %conv2.i.i99.10 = trunc i32 %xor.i.i98.10 to i8
  %scevgep46.11 = getelementptr i8, i8* %b, i64 11
  %72 = load i8, i8* %scevgep46.11, align 1
  %conv.i.i96.11 = zext i8 %72 to i32
  %conv1.i.i97.11 = zext i8 %conv2.i.i99.10 to i32
  %xor.i.i98.11 = xor i32 %conv1.i.i97.11, %conv.i.i96.11
  %conv2.i.i99.11 = trunc i32 %xor.i.i98.11 to i8
  %scevgep46.12 = getelementptr i8, i8* %b, i64 12
  %73 = load i8, i8* %scevgep46.12, align 1
  %conv.i.i96.12 = zext i8 %73 to i32
  %conv1.i.i97.12 = zext i8 %conv2.i.i99.11 to i32
  %xor.i.i98.12 = xor i32 %conv1.i.i97.12, %conv.i.i96.12
  %conv2.i.i99.12 = trunc i32 %xor.i.i98.12 to i8
  %scevgep46.13 = getelementptr i8, i8* %b, i64 13
  %74 = load i8, i8* %scevgep46.13, align 1
  %conv.i.i96.13 = zext i8 %74 to i32
  %conv1.i.i97.13 = zext i8 %conv2.i.i99.12 to i32
  %xor.i.i98.13 = xor i32 %conv1.i.i97.13, %conv.i.i96.13
  %conv2.i.i99.13 = trunc i32 %xor.i.i98.13 to i8
  %scevgep46.14 = getelementptr i8, i8* %b, i64 14
  %75 = load i8, i8* %scevgep46.14, align 1
  %conv.i.i96.14 = zext i8 %75 to i32
  %conv1.i.i97.14 = zext i8 %conv2.i.i99.13 to i32
  %xor.i.i98.14 = xor i32 %conv1.i.i97.14, %conv.i.i96.14
  %conv2.i.i99.14 = trunc i32 %xor.i.i98.14 to i8
  %scevgep46.15 = getelementptr i8, i8* %b, i64 15
  %76 = load i8, i8* %scevgep46.15, align 1
  %conv.i.i96.15 = zext i8 %76 to i32
  %conv1.i.i97.15 = zext i8 %conv2.i.i99.14 to i32
  %xor.i.i98.15 = xor i32 %conv1.i.i97.15, %conv.i.i96.15
  %conv2.i.i99.15 = trunc i32 %xor.i.i98.15 to i8
  %scevgep46.16 = getelementptr i8, i8* %b, i64 16
  %77 = load i8, i8* %scevgep46.16, align 1
  %conv.i.i96.16 = zext i8 %77 to i32
  %conv1.i.i97.16 = zext i8 %conv2.i.i99.15 to i32
  %xor.i.i98.16 = xor i32 %conv1.i.i97.16, %conv.i.i96.16
  %conv2.i.i99.16 = trunc i32 %xor.i.i98.16 to i8
  %scevgep46.17 = getelementptr i8, i8* %b, i64 17
  %78 = load i8, i8* %scevgep46.17, align 1
  %conv.i.i96.17 = zext i8 %78 to i32
  %conv1.i.i97.17 = zext i8 %conv2.i.i99.16 to i32
  %xor.i.i98.17 = xor i32 %conv1.i.i97.17, %conv.i.i96.17
  %conv2.i.i99.17 = trunc i32 %xor.i.i98.17 to i8
  %scevgep46.18 = getelementptr i8, i8* %b, i64 18
  %79 = load i8, i8* %scevgep46.18, align 1
  %conv.i.i96.18 = zext i8 %79 to i32
  %conv1.i.i97.18 = zext i8 %conv2.i.i99.17 to i32
  %xor.i.i98.18 = xor i32 %conv1.i.i97.18, %conv.i.i96.18
  %conv2.i.i99.18 = trunc i32 %xor.i.i98.18 to i8
  %scevgep46.19 = getelementptr i8, i8* %b, i64 19
  %80 = load i8, i8* %scevgep46.19, align 1
  %conv.i.i96.19 = zext i8 %80 to i32
  %conv1.i.i97.19 = zext i8 %conv2.i.i99.18 to i32
  %xor.i.i98.19 = xor i32 %conv1.i.i97.19, %conv.i.i96.19
  %conv2.i.i99.19 = trunc i32 %xor.i.i98.19 to i8
  %scevgep46.20 = getelementptr i8, i8* %b, i64 20
  %81 = load i8, i8* %scevgep46.20, align 1
  %conv.i.i96.20 = zext i8 %81 to i32
  %conv1.i.i97.20 = zext i8 %conv2.i.i99.19 to i32
  %xor.i.i98.20 = xor i32 %conv1.i.i97.20, %conv.i.i96.20
  %conv2.i.i99.20 = trunc i32 %xor.i.i98.20 to i8
  %scevgep46.21 = getelementptr i8, i8* %b, i64 21
  %82 = load i8, i8* %scevgep46.21, align 1
  %conv.i.i96.21 = zext i8 %82 to i32
  %conv1.i.i97.21 = zext i8 %conv2.i.i99.20 to i32
  %xor.i.i98.21 = xor i32 %conv1.i.i97.21, %conv.i.i96.21
  %conv2.i.i99.21 = trunc i32 %xor.i.i98.21 to i8
  %scevgep46.22 = getelementptr i8, i8* %b, i64 22
  %83 = load i8, i8* %scevgep46.22, align 1
  %conv.i.i96.22 = zext i8 %83 to i32
  %conv1.i.i97.22 = zext i8 %conv2.i.i99.21 to i32
  %xor.i.i98.22 = xor i32 %conv1.i.i97.22, %conv.i.i96.22
  %conv2.i.i99.22 = trunc i32 %xor.i.i98.22 to i8
  %scevgep46.23 = getelementptr i8, i8* %b, i64 23
  %84 = load i8, i8* %scevgep46.23, align 1
  %conv.i.i96.23 = zext i8 %84 to i32
  %conv1.i.i97.23 = zext i8 %conv2.i.i99.22 to i32
  %xor.i.i98.23 = xor i32 %conv1.i.i97.23, %conv.i.i96.23
  %conv2.i.i99.23 = trunc i32 %xor.i.i98.23 to i8
  %scevgep46.24 = getelementptr i8, i8* %b, i64 24
  %85 = load i8, i8* %scevgep46.24, align 1
  %conv.i.i96.24 = zext i8 %85 to i32
  %conv1.i.i97.24 = zext i8 %conv2.i.i99.23 to i32
  %xor.i.i98.24 = xor i32 %conv1.i.i97.24, %conv.i.i96.24
  %conv2.i.i99.24 = trunc i32 %xor.i.i98.24 to i8
  %scevgep46.25 = getelementptr i8, i8* %b, i64 25
  %86 = load i8, i8* %scevgep46.25, align 1
  %conv.i.i96.25 = zext i8 %86 to i32
  %conv1.i.i97.25 = zext i8 %conv2.i.i99.24 to i32
  %xor.i.i98.25 = xor i32 %conv1.i.i97.25, %conv.i.i96.25
  %conv2.i.i99.25 = trunc i32 %xor.i.i98.25 to i8
  %scevgep46.26 = getelementptr i8, i8* %b, i64 26
  %87 = load i8, i8* %scevgep46.26, align 1
  %conv.i.i96.26 = zext i8 %87 to i32
  %conv1.i.i97.26 = zext i8 %conv2.i.i99.25 to i32
  %xor.i.i98.26 = xor i32 %conv1.i.i97.26, %conv.i.i96.26
  %conv2.i.i99.26 = trunc i32 %xor.i.i98.26 to i8
  %scevgep46.27 = getelementptr i8, i8* %b, i64 27
  %88 = load i8, i8* %scevgep46.27, align 1
  %conv.i.i96.27 = zext i8 %88 to i32
  %conv1.i.i97.27 = zext i8 %conv2.i.i99.26 to i32
  %xor.i.i98.27 = xor i32 %conv1.i.i97.27, %conv.i.i96.27
  %conv2.i.i99.27 = trunc i32 %xor.i.i98.27 to i8
  %scevgep46.28 = getelementptr i8, i8* %b, i64 28
  %89 = load i8, i8* %scevgep46.28, align 1
  %conv.i.i96.28 = zext i8 %89 to i32
  %conv1.i.i97.28 = zext i8 %conv2.i.i99.27 to i32
  %xor.i.i98.28 = xor i32 %conv1.i.i97.28, %conv.i.i96.28
  %conv2.i.i99.28 = trunc i32 %xor.i.i98.28 to i8
  %scevgep46.29 = getelementptr i8, i8* %b, i64 29
  %90 = load i8, i8* %scevgep46.29, align 1
  %conv.i.i96.29 = zext i8 %90 to i32
  %conv1.i.i97.29 = zext i8 %conv2.i.i99.28 to i32
  %xor.i.i98.29 = xor i32 %conv1.i.i97.29, %conv.i.i96.29
  %conv2.i.i99.29 = trunc i32 %xor.i.i98.29 to i8
  %scevgep46.30 = getelementptr i8, i8* %b, i64 30
  %91 = load i8, i8* %scevgep46.30, align 1
  %conv.i.i96.30 = zext i8 %91 to i32
  %conv1.i.i97.30 = zext i8 %conv2.i.i99.29 to i32
  %xor.i.i98.30 = xor i32 %conv1.i.i97.30, %conv.i.i96.30
  %conv2.i.i99.30 = trunc i32 %xor.i.i98.30 to i8
  %scevgep46.31 = getelementptr i8, i8* %b, i64 31
  %92 = load i8, i8* %scevgep46.31, align 1
  %conv.i.i96.31 = zext i8 %92 to i32
  %conv1.i.i97.31 = zext i8 %conv2.i.i99.30 to i32
  %xor.i.i98.31 = xor i32 %conv1.i.i97.31, %conv.i.i96.31
  %conv2.i.i99.31 = trunc i32 %xor.i.i98.31 to i8
  %scevgep46.32 = getelementptr i8, i8* %b, i64 32
  %93 = load i8, i8* %scevgep46.32, align 1
  %conv.i.i96.32 = zext i8 %93 to i32
  %conv1.i.i97.32 = zext i8 %conv2.i.i99.31 to i32
  %xor.i.i98.32 = xor i32 %conv1.i.i97.32, %conv.i.i96.32
  %conv2.i.i99.32 = trunc i32 %xor.i.i98.32 to i8
  %scevgep46.33 = getelementptr i8, i8* %b, i64 33
  %94 = load i8, i8* %scevgep46.33, align 1
  %conv.i.i96.33 = zext i8 %94 to i32
  %conv1.i.i97.33 = zext i8 %conv2.i.i99.32 to i32
  %xor.i.i98.33 = xor i32 %conv1.i.i97.33, %conv.i.i96.33
  %conv2.i.i99.33 = trunc i32 %xor.i.i98.33 to i8
  %scevgep46.34 = getelementptr i8, i8* %b, i64 34
  %95 = load i8, i8* %scevgep46.34, align 1
  %conv.i.i96.34 = zext i8 %95 to i32
  %conv1.i.i97.34 = zext i8 %conv2.i.i99.33 to i32
  %xor.i.i98.34 = xor i32 %conv1.i.i97.34, %conv.i.i96.34
  %conv2.i.i99.34 = trunc i32 %xor.i.i98.34 to i8
  %scevgep46.35 = getelementptr i8, i8* %b, i64 35
  %96 = load i8, i8* %scevgep46.35, align 1
  %conv.i.i96.35 = zext i8 %96 to i32
  %conv1.i.i97.35 = zext i8 %conv2.i.i99.34 to i32
  %xor.i.i98.35 = xor i32 %conv1.i.i97.35, %conv.i.i96.35
  %conv2.i.i99.35 = trunc i32 %xor.i.i98.35 to i8
  %scevgep46.36 = getelementptr i8, i8* %b, i64 36
  %97 = load i8, i8* %scevgep46.36, align 1
  %conv.i.i96.36 = zext i8 %97 to i32
  %conv1.i.i97.36 = zext i8 %conv2.i.i99.35 to i32
  %xor.i.i98.36 = xor i32 %conv1.i.i97.36, %conv.i.i96.36
  %conv2.i.i99.36 = trunc i32 %xor.i.i98.36 to i8
  %scevgep46.37 = getelementptr i8, i8* %b, i64 37
  %98 = load i8, i8* %scevgep46.37, align 1
  %conv.i.i96.37 = zext i8 %98 to i32
  %conv1.i.i97.37 = zext i8 %conv2.i.i99.36 to i32
  %xor.i.i98.37 = xor i32 %conv1.i.i97.37, %conv.i.i96.37
  %conv2.i.i99.37 = trunc i32 %xor.i.i98.37 to i8
  %scevgep46.38 = getelementptr i8, i8* %b, i64 38
  %99 = load i8, i8* %scevgep46.38, align 1
  %conv.i.i96.38 = zext i8 %99 to i32
  %conv1.i.i97.38 = zext i8 %conv2.i.i99.37 to i32
  %xor.i.i98.38 = xor i32 %conv1.i.i97.38, %conv.i.i96.38
  %conv2.i.i99.38 = trunc i32 %xor.i.i98.38 to i8
  %scevgep46.39 = getelementptr i8, i8* %b, i64 39
  %100 = load i8, i8* %scevgep46.39, align 1
  %conv.i.i96.39 = zext i8 %100 to i32
  %conv1.i.i97.39 = zext i8 %conv2.i.i99.38 to i32
  %xor.i.i98.39 = xor i32 %conv1.i.i97.39, %conv.i.i96.39
  %conv2.i.i99.39 = trunc i32 %xor.i.i98.39 to i8
  %scevgep46.40 = getelementptr i8, i8* %b, i64 40
  %101 = load i8, i8* %scevgep46.40, align 1
  %conv.i.i96.40 = zext i8 %101 to i32
  %conv1.i.i97.40 = zext i8 %conv2.i.i99.39 to i32
  %xor.i.i98.40 = xor i32 %conv1.i.i97.40, %conv.i.i96.40
  %conv2.i.i99.40 = trunc i32 %xor.i.i98.40 to i8
  %scevgep46.41 = getelementptr i8, i8* %b, i64 41
  %102 = load i8, i8* %scevgep46.41, align 1
  %conv.i.i96.41 = zext i8 %102 to i32
  %conv1.i.i97.41 = zext i8 %conv2.i.i99.40 to i32
  %xor.i.i98.41 = xor i32 %conv1.i.i97.41, %conv.i.i96.41
  %conv2.i.i99.41 = trunc i32 %xor.i.i98.41 to i8
  %scevgep46.42 = getelementptr i8, i8* %b, i64 42
  %103 = load i8, i8* %scevgep46.42, align 1
  %conv.i.i96.42 = zext i8 %103 to i32
  %conv1.i.i97.42 = zext i8 %conv2.i.i99.41 to i32
  %xor.i.i98.42 = xor i32 %conv1.i.i97.42, %conv.i.i96.42
  %conv2.i.i99.42 = trunc i32 %xor.i.i98.42 to i8
  %scevgep46.43 = getelementptr i8, i8* %b, i64 43
  %104 = load i8, i8* %scevgep46.43, align 1
  %conv.i.i96.43 = zext i8 %104 to i32
  %conv1.i.i97.43 = zext i8 %conv2.i.i99.42 to i32
  %xor.i.i98.43 = xor i32 %conv1.i.i97.43, %conv.i.i96.43
  %conv2.i.i99.43 = trunc i32 %xor.i.i98.43 to i8
  %scevgep46.44 = getelementptr i8, i8* %b, i64 44
  %105 = load i8, i8* %scevgep46.44, align 1
  %conv.i.i96.44 = zext i8 %105 to i32
  %conv1.i.i97.44 = zext i8 %conv2.i.i99.43 to i32
  %xor.i.i98.44 = xor i32 %conv1.i.i97.44, %conv.i.i96.44
  %conv2.i.i99.44 = trunc i32 %xor.i.i98.44 to i8
  %scevgep46.45 = getelementptr i8, i8* %b, i64 45
  %106 = load i8, i8* %scevgep46.45, align 1
  %conv.i.i96.45 = zext i8 %106 to i32
  %conv1.i.i97.45 = zext i8 %conv2.i.i99.44 to i32
  %xor.i.i98.45 = xor i32 %conv1.i.i97.45, %conv.i.i96.45
  %conv2.i.i99.45 = trunc i32 %xor.i.i98.45 to i8
  %scevgep46.46 = getelementptr i8, i8* %b, i64 46
  %107 = load i8, i8* %scevgep46.46, align 1
  %conv.i.i96.46 = zext i8 %107 to i32
  %conv1.i.i97.46 = zext i8 %conv2.i.i99.45 to i32
  %xor.i.i98.46 = xor i32 %conv1.i.i97.46, %conv.i.i96.46
  %conv2.i.i99.46 = trunc i32 %xor.i.i98.46 to i8
  %scevgep46.47 = getelementptr i8, i8* %b, i64 47
  %108 = load i8, i8* %scevgep46.47, align 1
  %conv.i.i96.47 = zext i8 %108 to i32
  %conv1.i.i97.47 = zext i8 %conv2.i.i99.46 to i32
  %xor.i.i98.47 = xor i32 %conv1.i.i97.47, %conv.i.i96.47
  %conv2.i.i99.47 = trunc i32 %xor.i.i98.47 to i8
  %scevgep46.48 = getelementptr i8, i8* %b, i64 48
  %109 = load i8, i8* %scevgep46.48, align 1
  %conv.i.i96.48 = zext i8 %109 to i32
  %conv1.i.i97.48 = zext i8 %conv2.i.i99.47 to i32
  %xor.i.i98.48 = xor i32 %conv1.i.i97.48, %conv.i.i96.48
  %conv2.i.i99.48 = trunc i32 %xor.i.i98.48 to i8
  %scevgep46.49 = getelementptr i8, i8* %b, i64 49
  %110 = load i8, i8* %scevgep46.49, align 1
  %conv.i.i96.49 = zext i8 %110 to i32
  %conv1.i.i97.49 = zext i8 %conv2.i.i99.48 to i32
  %xor.i.i98.49 = xor i32 %conv1.i.i97.49, %conv.i.i96.49
  %conv2.i.i99.49 = trunc i32 %xor.i.i98.49 to i8
  %scevgep46.50 = getelementptr i8, i8* %b, i64 50
  %111 = load i8, i8* %scevgep46.50, align 1
  %conv.i.i96.50 = zext i8 %111 to i32
  %conv1.i.i97.50 = zext i8 %conv2.i.i99.49 to i32
  %xor.i.i98.50 = xor i32 %conv1.i.i97.50, %conv.i.i96.50
  %conv2.i.i99.50 = trunc i32 %xor.i.i98.50 to i8
  %scevgep46.51 = getelementptr i8, i8* %b, i64 51
  %112 = load i8, i8* %scevgep46.51, align 1
  %conv.i.i96.51 = zext i8 %112 to i32
  %conv1.i.i97.51 = zext i8 %conv2.i.i99.50 to i32
  %xor.i.i98.51 = xor i32 %conv1.i.i97.51, %conv.i.i96.51
  %conv2.i.i99.51 = trunc i32 %xor.i.i98.51 to i8
  %scevgep46.52 = getelementptr i8, i8* %b, i64 52
  %113 = load i8, i8* %scevgep46.52, align 1
  %conv.i.i96.52 = zext i8 %113 to i32
  %conv1.i.i97.52 = zext i8 %conv2.i.i99.51 to i32
  %xor.i.i98.52 = xor i32 %conv1.i.i97.52, %conv.i.i96.52
  %conv2.i.i99.52 = trunc i32 %xor.i.i98.52 to i8
  %scevgep46.53 = getelementptr i8, i8* %b, i64 53
  %114 = load i8, i8* %scevgep46.53, align 1
  %conv.i.i96.53 = zext i8 %114 to i32
  %conv1.i.i97.53 = zext i8 %conv2.i.i99.52 to i32
  %xor.i.i98.53 = xor i32 %conv1.i.i97.53, %conv.i.i96.53
  %conv2.i.i99.53 = trunc i32 %xor.i.i98.53 to i8
  %scevgep46.54 = getelementptr i8, i8* %b, i64 54
  %115 = load i8, i8* %scevgep46.54, align 1
  %conv.i.i96.54 = zext i8 %115 to i32
  %conv1.i.i97.54 = zext i8 %conv2.i.i99.53 to i32
  %xor.i.i98.54 = xor i32 %conv1.i.i97.54, %conv.i.i96.54
  %conv2.i.i99.54 = trunc i32 %xor.i.i98.54 to i8
  %scevgep46.55 = getelementptr i8, i8* %b, i64 55
  %116 = load i8, i8* %scevgep46.55, align 1
  %conv.i.i96.55 = zext i8 %116 to i32
  %conv1.i.i97.55 = zext i8 %conv2.i.i99.54 to i32
  %xor.i.i98.55 = xor i32 %conv1.i.i97.55, %conv.i.i96.55
  %conv2.i.i99.55 = trunc i32 %xor.i.i98.55 to i8
  %scevgep46.56 = getelementptr i8, i8* %b, i64 56
  %117 = load i8, i8* %scevgep46.56, align 1
  %conv.i.i96.56 = zext i8 %117 to i32
  %conv1.i.i97.56 = zext i8 %conv2.i.i99.55 to i32
  %xor.i.i98.56 = xor i32 %conv1.i.i97.56, %conv.i.i96.56
  %conv2.i.i99.56 = trunc i32 %xor.i.i98.56 to i8
  %scevgep46.57 = getelementptr i8, i8* %b, i64 57
  %118 = load i8, i8* %scevgep46.57, align 1
  %conv.i.i96.57 = zext i8 %118 to i32
  %conv1.i.i97.57 = zext i8 %conv2.i.i99.56 to i32
  %xor.i.i98.57 = xor i32 %conv1.i.i97.57, %conv.i.i96.57
  %conv2.i.i99.57 = trunc i32 %xor.i.i98.57 to i8
  %scevgep46.58 = getelementptr i8, i8* %b, i64 58
  %119 = load i8, i8* %scevgep46.58, align 1
  %conv.i.i96.58 = zext i8 %119 to i32
  %conv1.i.i97.58 = zext i8 %conv2.i.i99.57 to i32
  %xor.i.i98.58 = xor i32 %conv1.i.i97.58, %conv.i.i96.58
  %conv2.i.i99.58 = trunc i32 %xor.i.i98.58 to i8
  %scevgep46.59 = getelementptr i8, i8* %b, i64 59
  %120 = load i8, i8* %scevgep46.59, align 1
  %conv.i.i96.59 = zext i8 %120 to i32
  %conv1.i.i97.59 = zext i8 %conv2.i.i99.58 to i32
  %xor.i.i98.59 = xor i32 %conv1.i.i97.59, %conv.i.i96.59
  %conv2.i.i99.59 = trunc i32 %xor.i.i98.59 to i8
  %scevgep46.60 = getelementptr i8, i8* %b, i64 60
  %121 = load i8, i8* %scevgep46.60, align 1
  %conv.i.i96.60 = zext i8 %121 to i32
  %conv1.i.i97.60 = zext i8 %conv2.i.i99.59 to i32
  %xor.i.i98.60 = xor i32 %conv1.i.i97.60, %conv.i.i96.60
  %conv2.i.i99.60 = trunc i32 %xor.i.i98.60 to i8
  %conv7 = zext i8 %conv2.i.i99.60 to i32
  %cmp8 = icmp eq i32 %conv5, %conv7
  call void @assume(i1 zeroext %cmp8)
  %scevgep23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 1
  %scevgep2324 = bitcast i8* %scevgep23 to [61 x [61 x i8]]*
  %scevgep36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 1, i64 0
  %scevgep3637 = bitcast i8* %scevgep36 to [61 x [61 x i8]]*
  %call16 = call zeroext i8 (...) @rand()
  store i8 %call16, i8* %scevgep23, align 1
  %122 = load i8, i8* %scevgep23, align 1
  %conv23 = zext i8 %122 to i32
  %123 = load i8, i8* %a, align 1
  %scevgep34 = getelementptr i8, i8* %b, i64 1
  %124 = load i8, i8* %scevgep34, align 1
  %call28 = call zeroext i8 @mult(i8 zeroext %123, i8 zeroext %124)
  %conv29 = zext i8 %call28 to i32
  %xor = xor i32 %conv23, %conv29
  %scevgep35 = getelementptr i8, i8* %a, i64 1
  %125 = load i8, i8* %scevgep35, align 1
  %126 = load i8, i8* %b, align 1
  %call34 = call zeroext i8 @mult(i8 zeroext %125, i8 zeroext %126)
  %conv35 = zext i8 %call34 to i32
  %xor36 = xor i32 %xor, %conv35
  %conv37 = trunc i32 %xor36 to i8
  store i8 %conv37, i8* %scevgep36, align 1
  %scevgep28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %scevgep2324, i64 0, i64 0, i64 1
  %127 = bitcast i8* %scevgep28 to [61 x [61 x i8]]*
  %scevgep41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %scevgep3637, i64 0, i64 1, i64 0
  %128 = bitcast i8* %scevgep41 to [61 x [61 x i8]]*
  %call16.1652 = call zeroext i8 (...) @rand()
  store i8 %call16.1652, i8* %scevgep28, align 1
  %129 = load i8, i8* %scevgep28, align 1
  %conv23.1653 = zext i8 %129 to i32
  %130 = load i8, i8* %a, align 1
  %scevgep34.1654 = getelementptr i8, i8* %b, i64 2
  %131 = load i8, i8* %scevgep34.1654, align 1
  %call28.1655 = call zeroext i8 @mult(i8 zeroext %130, i8 zeroext %131)
  %conv29.1656 = zext i8 %call28.1655 to i32
  %xor.1657 = xor i32 %conv23.1653, %conv29.1656
  %scevgep35.1658 = getelementptr i8, i8* %a, i64 2
  %132 = load i8, i8* %scevgep35.1658, align 1
  %133 = load i8, i8* %b, align 1
  %call34.1659 = call zeroext i8 @mult(i8 zeroext %132, i8 zeroext %133)
  %conv35.1660 = zext i8 %call34.1659 to i32
  %xor36.1661 = xor i32 %xor.1657, %conv35.1660
  %conv37.1662 = trunc i32 %xor36.1661 to i8
  store i8 %conv37.1662, i8* %scevgep41, align 1
  %scevgep28.1663 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %127, i64 0, i64 0, i64 1
  %134 = bitcast i8* %scevgep28.1663 to [61 x [61 x i8]]*
  %scevgep41.1664 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %128, i64 0, i64 1, i64 0
  %135 = bitcast i8* %scevgep41.1664 to [61 x [61 x i8]]*
  %call16.2666 = call zeroext i8 (...) @rand()
  store i8 %call16.2666, i8* %scevgep28.1663, align 1
  %136 = load i8, i8* %scevgep28.1663, align 1
  %conv23.2667 = zext i8 %136 to i32
  %137 = load i8, i8* %a, align 1
  %scevgep34.2668 = getelementptr i8, i8* %b, i64 3
  %138 = load i8, i8* %scevgep34.2668, align 1
  %call28.2669 = call zeroext i8 @mult(i8 zeroext %137, i8 zeroext %138)
  %conv29.2670 = zext i8 %call28.2669 to i32
  %xor.2671 = xor i32 %conv23.2667, %conv29.2670
  %scevgep35.2672 = getelementptr i8, i8* %a, i64 3
  %139 = load i8, i8* %scevgep35.2672, align 1
  %140 = load i8, i8* %b, align 1
  %call34.2673 = call zeroext i8 @mult(i8 zeroext %139, i8 zeroext %140)
  %conv35.2674 = zext i8 %call34.2673 to i32
  %xor36.2675 = xor i32 %xor.2671, %conv35.2674
  %conv37.2676 = trunc i32 %xor36.2675 to i8
  store i8 %conv37.2676, i8* %scevgep41.1664, align 1
  %scevgep28.2677 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %134, i64 0, i64 0, i64 1
  %141 = bitcast i8* %scevgep28.2677 to [61 x [61 x i8]]*
  %scevgep41.2678 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %135, i64 0, i64 1, i64 0
  %142 = bitcast i8* %scevgep41.2678 to [61 x [61 x i8]]*
  %call16.3680 = call zeroext i8 (...) @rand()
  store i8 %call16.3680, i8* %scevgep28.2677, align 1
  %143 = load i8, i8* %scevgep28.2677, align 1
  %conv23.3681 = zext i8 %143 to i32
  %144 = load i8, i8* %a, align 1
  %scevgep34.3682 = getelementptr i8, i8* %b, i64 4
  %145 = load i8, i8* %scevgep34.3682, align 1
  %call28.3683 = call zeroext i8 @mult(i8 zeroext %144, i8 zeroext %145)
  %conv29.3684 = zext i8 %call28.3683 to i32
  %xor.3685 = xor i32 %conv23.3681, %conv29.3684
  %scevgep35.3686 = getelementptr i8, i8* %a, i64 4
  %146 = load i8, i8* %scevgep35.3686, align 1
  %147 = load i8, i8* %b, align 1
  %call34.3687 = call zeroext i8 @mult(i8 zeroext %146, i8 zeroext %147)
  %conv35.3688 = zext i8 %call34.3687 to i32
  %xor36.3689 = xor i32 %xor.3685, %conv35.3688
  %conv37.3690 = trunc i32 %xor36.3689 to i8
  store i8 %conv37.3690, i8* %scevgep41.2678, align 1
  %scevgep28.3691 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %141, i64 0, i64 0, i64 1
  %148 = bitcast i8* %scevgep28.3691 to [61 x [61 x i8]]*
  %scevgep41.3692 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %142, i64 0, i64 1, i64 0
  %149 = bitcast i8* %scevgep41.3692 to [61 x [61 x i8]]*
  %call16.4694 = call zeroext i8 (...) @rand()
  store i8 %call16.4694, i8* %scevgep28.3691, align 1
  %150 = load i8, i8* %scevgep28.3691, align 1
  %conv23.4695 = zext i8 %150 to i32
  %151 = load i8, i8* %a, align 1
  %scevgep34.4696 = getelementptr i8, i8* %b, i64 5
  %152 = load i8, i8* %scevgep34.4696, align 1
  %call28.4697 = call zeroext i8 @mult(i8 zeroext %151, i8 zeroext %152)
  %conv29.4698 = zext i8 %call28.4697 to i32
  %xor.4699 = xor i32 %conv23.4695, %conv29.4698
  %scevgep35.4700 = getelementptr i8, i8* %a, i64 5
  %153 = load i8, i8* %scevgep35.4700, align 1
  %154 = load i8, i8* %b, align 1
  %call34.4701 = call zeroext i8 @mult(i8 zeroext %153, i8 zeroext %154)
  %conv35.4702 = zext i8 %call34.4701 to i32
  %xor36.4703 = xor i32 %xor.4699, %conv35.4702
  %conv37.4704 = trunc i32 %xor36.4703 to i8
  store i8 %conv37.4704, i8* %scevgep41.3692, align 1
  %scevgep28.4705 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %148, i64 0, i64 0, i64 1
  %155 = bitcast i8* %scevgep28.4705 to [61 x [61 x i8]]*
  %scevgep41.4706 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %149, i64 0, i64 1, i64 0
  %156 = bitcast i8* %scevgep41.4706 to [61 x [61 x i8]]*
  %call16.5708 = call zeroext i8 (...) @rand()
  store i8 %call16.5708, i8* %scevgep28.4705, align 1
  %157 = load i8, i8* %scevgep28.4705, align 1
  %conv23.5709 = zext i8 %157 to i32
  %158 = load i8, i8* %a, align 1
  %scevgep34.5710 = getelementptr i8, i8* %b, i64 6
  %159 = load i8, i8* %scevgep34.5710, align 1
  %call28.5711 = call zeroext i8 @mult(i8 zeroext %158, i8 zeroext %159)
  %conv29.5712 = zext i8 %call28.5711 to i32
  %xor.5713 = xor i32 %conv23.5709, %conv29.5712
  %scevgep35.5714 = getelementptr i8, i8* %a, i64 6
  %160 = load i8, i8* %scevgep35.5714, align 1
  %161 = load i8, i8* %b, align 1
  %call34.5715 = call zeroext i8 @mult(i8 zeroext %160, i8 zeroext %161)
  %conv35.5716 = zext i8 %call34.5715 to i32
  %xor36.5717 = xor i32 %xor.5713, %conv35.5716
  %conv37.5718 = trunc i32 %xor36.5717 to i8
  store i8 %conv37.5718, i8* %scevgep41.4706, align 1
  %scevgep28.5719 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %155, i64 0, i64 0, i64 1
  %162 = bitcast i8* %scevgep28.5719 to [61 x [61 x i8]]*
  %scevgep41.5720 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %156, i64 0, i64 1, i64 0
  %163 = bitcast i8* %scevgep41.5720 to [61 x [61 x i8]]*
  %call16.6722 = call zeroext i8 (...) @rand()
  store i8 %call16.6722, i8* %scevgep28.5719, align 1
  %164 = load i8, i8* %scevgep28.5719, align 1
  %conv23.6723 = zext i8 %164 to i32
  %165 = load i8, i8* %a, align 1
  %scevgep34.6724 = getelementptr i8, i8* %b, i64 7
  %166 = load i8, i8* %scevgep34.6724, align 1
  %call28.6725 = call zeroext i8 @mult(i8 zeroext %165, i8 zeroext %166)
  %conv29.6726 = zext i8 %call28.6725 to i32
  %xor.6727 = xor i32 %conv23.6723, %conv29.6726
  %scevgep35.6728 = getelementptr i8, i8* %a, i64 7
  %167 = load i8, i8* %scevgep35.6728, align 1
  %168 = load i8, i8* %b, align 1
  %call34.6729 = call zeroext i8 @mult(i8 zeroext %167, i8 zeroext %168)
  %conv35.6730 = zext i8 %call34.6729 to i32
  %xor36.6731 = xor i32 %xor.6727, %conv35.6730
  %conv37.6732 = trunc i32 %xor36.6731 to i8
  store i8 %conv37.6732, i8* %scevgep41.5720, align 1
  %scevgep28.6733 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %162, i64 0, i64 0, i64 1
  %169 = bitcast i8* %scevgep28.6733 to [61 x [61 x i8]]*
  %scevgep41.6734 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %163, i64 0, i64 1, i64 0
  %170 = bitcast i8* %scevgep41.6734 to [61 x [61 x i8]]*
  %call16.7736 = call zeroext i8 (...) @rand()
  store i8 %call16.7736, i8* %scevgep28.6733, align 1
  %171 = load i8, i8* %scevgep28.6733, align 1
  %conv23.7737 = zext i8 %171 to i32
  %172 = load i8, i8* %a, align 1
  %scevgep34.7738 = getelementptr i8, i8* %b, i64 8
  %173 = load i8, i8* %scevgep34.7738, align 1
  %call28.7739 = call zeroext i8 @mult(i8 zeroext %172, i8 zeroext %173)
  %conv29.7740 = zext i8 %call28.7739 to i32
  %xor.7741 = xor i32 %conv23.7737, %conv29.7740
  %scevgep35.7742 = getelementptr i8, i8* %a, i64 8
  %174 = load i8, i8* %scevgep35.7742, align 1
  %175 = load i8, i8* %b, align 1
  %call34.7743 = call zeroext i8 @mult(i8 zeroext %174, i8 zeroext %175)
  %conv35.7744 = zext i8 %call34.7743 to i32
  %xor36.7745 = xor i32 %xor.7741, %conv35.7744
  %conv37.7746 = trunc i32 %xor36.7745 to i8
  store i8 %conv37.7746, i8* %scevgep41.6734, align 1
  %scevgep28.7747 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %169, i64 0, i64 0, i64 1
  %176 = bitcast i8* %scevgep28.7747 to [61 x [61 x i8]]*
  %scevgep41.7748 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %170, i64 0, i64 1, i64 0
  %177 = bitcast i8* %scevgep41.7748 to [61 x [61 x i8]]*
  %call16.8750 = call zeroext i8 (...) @rand()
  store i8 %call16.8750, i8* %scevgep28.7747, align 1
  %178 = load i8, i8* %scevgep28.7747, align 1
  %conv23.8751 = zext i8 %178 to i32
  %179 = load i8, i8* %a, align 1
  %scevgep34.8752 = getelementptr i8, i8* %b, i64 9
  %180 = load i8, i8* %scevgep34.8752, align 1
  %call28.8753 = call zeroext i8 @mult(i8 zeroext %179, i8 zeroext %180)
  %conv29.8754 = zext i8 %call28.8753 to i32
  %xor.8755 = xor i32 %conv23.8751, %conv29.8754
  %scevgep35.8756 = getelementptr i8, i8* %a, i64 9
  %181 = load i8, i8* %scevgep35.8756, align 1
  %182 = load i8, i8* %b, align 1
  %call34.8757 = call zeroext i8 @mult(i8 zeroext %181, i8 zeroext %182)
  %conv35.8758 = zext i8 %call34.8757 to i32
  %xor36.8759 = xor i32 %xor.8755, %conv35.8758
  %conv37.8760 = trunc i32 %xor36.8759 to i8
  store i8 %conv37.8760, i8* %scevgep41.7748, align 1
  %scevgep28.8761 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %176, i64 0, i64 0, i64 1
  %183 = bitcast i8* %scevgep28.8761 to [61 x [61 x i8]]*
  %scevgep41.8762 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %177, i64 0, i64 1, i64 0
  %184 = bitcast i8* %scevgep41.8762 to [61 x [61 x i8]]*
  %call16.9764 = call zeroext i8 (...) @rand()
  store i8 %call16.9764, i8* %scevgep28.8761, align 1
  %185 = load i8, i8* %scevgep28.8761, align 1
  %conv23.9765 = zext i8 %185 to i32
  %186 = load i8, i8* %a, align 1
  %scevgep34.9766 = getelementptr i8, i8* %b, i64 10
  %187 = load i8, i8* %scevgep34.9766, align 1
  %call28.9767 = call zeroext i8 @mult(i8 zeroext %186, i8 zeroext %187)
  %conv29.9768 = zext i8 %call28.9767 to i32
  %xor.9769 = xor i32 %conv23.9765, %conv29.9768
  %scevgep35.9770 = getelementptr i8, i8* %a, i64 10
  %188 = load i8, i8* %scevgep35.9770, align 1
  %189 = load i8, i8* %b, align 1
  %call34.9771 = call zeroext i8 @mult(i8 zeroext %188, i8 zeroext %189)
  %conv35.9772 = zext i8 %call34.9771 to i32
  %xor36.9773 = xor i32 %xor.9769, %conv35.9772
  %conv37.9774 = trunc i32 %xor36.9773 to i8
  store i8 %conv37.9774, i8* %scevgep41.8762, align 1
  %scevgep28.9775 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %183, i64 0, i64 0, i64 1
  %190 = bitcast i8* %scevgep28.9775 to [61 x [61 x i8]]*
  %scevgep41.9776 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %184, i64 0, i64 1, i64 0
  %191 = bitcast i8* %scevgep41.9776 to [61 x [61 x i8]]*
  %call16.10778 = call zeroext i8 (...) @rand()
  store i8 %call16.10778, i8* %scevgep28.9775, align 1
  %192 = load i8, i8* %scevgep28.9775, align 1
  %conv23.10779 = zext i8 %192 to i32
  %193 = load i8, i8* %a, align 1
  %scevgep34.10780 = getelementptr i8, i8* %b, i64 11
  %194 = load i8, i8* %scevgep34.10780, align 1
  %call28.10781 = call zeroext i8 @mult(i8 zeroext %193, i8 zeroext %194)
  %conv29.10782 = zext i8 %call28.10781 to i32
  %xor.10783 = xor i32 %conv23.10779, %conv29.10782
  %scevgep35.10784 = getelementptr i8, i8* %a, i64 11
  %195 = load i8, i8* %scevgep35.10784, align 1
  %196 = load i8, i8* %b, align 1
  %call34.10785 = call zeroext i8 @mult(i8 zeroext %195, i8 zeroext %196)
  %conv35.10786 = zext i8 %call34.10785 to i32
  %xor36.10787 = xor i32 %xor.10783, %conv35.10786
  %conv37.10788 = trunc i32 %xor36.10787 to i8
  store i8 %conv37.10788, i8* %scevgep41.9776, align 1
  %scevgep28.10789 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %190, i64 0, i64 0, i64 1
  %197 = bitcast i8* %scevgep28.10789 to [61 x [61 x i8]]*
  %scevgep41.10790 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %191, i64 0, i64 1, i64 0
  %198 = bitcast i8* %scevgep41.10790 to [61 x [61 x i8]]*
  %call16.11792 = call zeroext i8 (...) @rand()
  store i8 %call16.11792, i8* %scevgep28.10789, align 1
  %199 = load i8, i8* %scevgep28.10789, align 1
  %conv23.11793 = zext i8 %199 to i32
  %200 = load i8, i8* %a, align 1
  %scevgep34.11794 = getelementptr i8, i8* %b, i64 12
  %201 = load i8, i8* %scevgep34.11794, align 1
  %call28.11795 = call zeroext i8 @mult(i8 zeroext %200, i8 zeroext %201)
  %conv29.11796 = zext i8 %call28.11795 to i32
  %xor.11797 = xor i32 %conv23.11793, %conv29.11796
  %scevgep35.11798 = getelementptr i8, i8* %a, i64 12
  %202 = load i8, i8* %scevgep35.11798, align 1
  %203 = load i8, i8* %b, align 1
  %call34.11799 = call zeroext i8 @mult(i8 zeroext %202, i8 zeroext %203)
  %conv35.11800 = zext i8 %call34.11799 to i32
  %xor36.11801 = xor i32 %xor.11797, %conv35.11800
  %conv37.11802 = trunc i32 %xor36.11801 to i8
  store i8 %conv37.11802, i8* %scevgep41.10790, align 1
  %scevgep28.11803 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %197, i64 0, i64 0, i64 1
  %204 = bitcast i8* %scevgep28.11803 to [61 x [61 x i8]]*
  %scevgep41.11804 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %198, i64 0, i64 1, i64 0
  %205 = bitcast i8* %scevgep41.11804 to [61 x [61 x i8]]*
  %call16.12806 = call zeroext i8 (...) @rand()
  store i8 %call16.12806, i8* %scevgep28.11803, align 1
  %206 = load i8, i8* %scevgep28.11803, align 1
  %conv23.12807 = zext i8 %206 to i32
  %207 = load i8, i8* %a, align 1
  %scevgep34.12808 = getelementptr i8, i8* %b, i64 13
  %208 = load i8, i8* %scevgep34.12808, align 1
  %call28.12809 = call zeroext i8 @mult(i8 zeroext %207, i8 zeroext %208)
  %conv29.12810 = zext i8 %call28.12809 to i32
  %xor.12811 = xor i32 %conv23.12807, %conv29.12810
  %scevgep35.12812 = getelementptr i8, i8* %a, i64 13
  %209 = load i8, i8* %scevgep35.12812, align 1
  %210 = load i8, i8* %b, align 1
  %call34.12813 = call zeroext i8 @mult(i8 zeroext %209, i8 zeroext %210)
  %conv35.12814 = zext i8 %call34.12813 to i32
  %xor36.12815 = xor i32 %xor.12811, %conv35.12814
  %conv37.12816 = trunc i32 %xor36.12815 to i8
  store i8 %conv37.12816, i8* %scevgep41.11804, align 1
  %scevgep28.12817 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %204, i64 0, i64 0, i64 1
  %211 = bitcast i8* %scevgep28.12817 to [61 x [61 x i8]]*
  %scevgep41.12818 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %205, i64 0, i64 1, i64 0
  %212 = bitcast i8* %scevgep41.12818 to [61 x [61 x i8]]*
  %call16.13820 = call zeroext i8 (...) @rand()
  store i8 %call16.13820, i8* %scevgep28.12817, align 1
  %213 = load i8, i8* %scevgep28.12817, align 1
  %conv23.13821 = zext i8 %213 to i32
  %214 = load i8, i8* %a, align 1
  %scevgep34.13822 = getelementptr i8, i8* %b, i64 14
  %215 = load i8, i8* %scevgep34.13822, align 1
  %call28.13823 = call zeroext i8 @mult(i8 zeroext %214, i8 zeroext %215)
  %conv29.13824 = zext i8 %call28.13823 to i32
  %xor.13825 = xor i32 %conv23.13821, %conv29.13824
  %scevgep35.13826 = getelementptr i8, i8* %a, i64 14
  %216 = load i8, i8* %scevgep35.13826, align 1
  %217 = load i8, i8* %b, align 1
  %call34.13827 = call zeroext i8 @mult(i8 zeroext %216, i8 zeroext %217)
  %conv35.13828 = zext i8 %call34.13827 to i32
  %xor36.13829 = xor i32 %xor.13825, %conv35.13828
  %conv37.13830 = trunc i32 %xor36.13829 to i8
  store i8 %conv37.13830, i8* %scevgep41.12818, align 1
  %scevgep28.13831 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %211, i64 0, i64 0, i64 1
  %218 = bitcast i8* %scevgep28.13831 to [61 x [61 x i8]]*
  %scevgep41.13832 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %212, i64 0, i64 1, i64 0
  %219 = bitcast i8* %scevgep41.13832 to [61 x [61 x i8]]*
  %call16.14834 = call zeroext i8 (...) @rand()
  store i8 %call16.14834, i8* %scevgep28.13831, align 1
  %220 = load i8, i8* %scevgep28.13831, align 1
  %conv23.14835 = zext i8 %220 to i32
  %221 = load i8, i8* %a, align 1
  %scevgep34.14836 = getelementptr i8, i8* %b, i64 15
  %222 = load i8, i8* %scevgep34.14836, align 1
  %call28.14837 = call zeroext i8 @mult(i8 zeroext %221, i8 zeroext %222)
  %conv29.14838 = zext i8 %call28.14837 to i32
  %xor.14839 = xor i32 %conv23.14835, %conv29.14838
  %scevgep35.14840 = getelementptr i8, i8* %a, i64 15
  %223 = load i8, i8* %scevgep35.14840, align 1
  %224 = load i8, i8* %b, align 1
  %call34.14841 = call zeroext i8 @mult(i8 zeroext %223, i8 zeroext %224)
  %conv35.14842 = zext i8 %call34.14841 to i32
  %xor36.14843 = xor i32 %xor.14839, %conv35.14842
  %conv37.14844 = trunc i32 %xor36.14843 to i8
  store i8 %conv37.14844, i8* %scevgep41.13832, align 1
  %scevgep28.14845 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %218, i64 0, i64 0, i64 1
  %225 = bitcast i8* %scevgep28.14845 to [61 x [61 x i8]]*
  %scevgep41.14846 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %219, i64 0, i64 1, i64 0
  %226 = bitcast i8* %scevgep41.14846 to [61 x [61 x i8]]*
  %call16.15848 = call zeroext i8 (...) @rand()
  store i8 %call16.15848, i8* %scevgep28.14845, align 1
  %227 = load i8, i8* %scevgep28.14845, align 1
  %conv23.15849 = zext i8 %227 to i32
  %228 = load i8, i8* %a, align 1
  %scevgep34.15850 = getelementptr i8, i8* %b, i64 16
  %229 = load i8, i8* %scevgep34.15850, align 1
  %call28.15851 = call zeroext i8 @mult(i8 zeroext %228, i8 zeroext %229)
  %conv29.15852 = zext i8 %call28.15851 to i32
  %xor.15853 = xor i32 %conv23.15849, %conv29.15852
  %scevgep35.15854 = getelementptr i8, i8* %a, i64 16
  %230 = load i8, i8* %scevgep35.15854, align 1
  %231 = load i8, i8* %b, align 1
  %call34.15855 = call zeroext i8 @mult(i8 zeroext %230, i8 zeroext %231)
  %conv35.15856 = zext i8 %call34.15855 to i32
  %xor36.15857 = xor i32 %xor.15853, %conv35.15856
  %conv37.15858 = trunc i32 %xor36.15857 to i8
  store i8 %conv37.15858, i8* %scevgep41.14846, align 1
  %scevgep28.15859 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %225, i64 0, i64 0, i64 1
  %232 = bitcast i8* %scevgep28.15859 to [61 x [61 x i8]]*
  %scevgep41.15860 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %226, i64 0, i64 1, i64 0
  %233 = bitcast i8* %scevgep41.15860 to [61 x [61 x i8]]*
  %call16.16862 = call zeroext i8 (...) @rand()
  store i8 %call16.16862, i8* %scevgep28.15859, align 1
  %234 = load i8, i8* %scevgep28.15859, align 1
  %conv23.16863 = zext i8 %234 to i32
  %235 = load i8, i8* %a, align 1
  %scevgep34.16864 = getelementptr i8, i8* %b, i64 17
  %236 = load i8, i8* %scevgep34.16864, align 1
  %call28.16865 = call zeroext i8 @mult(i8 zeroext %235, i8 zeroext %236)
  %conv29.16866 = zext i8 %call28.16865 to i32
  %xor.16867 = xor i32 %conv23.16863, %conv29.16866
  %scevgep35.16868 = getelementptr i8, i8* %a, i64 17
  %237 = load i8, i8* %scevgep35.16868, align 1
  %238 = load i8, i8* %b, align 1
  %call34.16869 = call zeroext i8 @mult(i8 zeroext %237, i8 zeroext %238)
  %conv35.16870 = zext i8 %call34.16869 to i32
  %xor36.16871 = xor i32 %xor.16867, %conv35.16870
  %conv37.16872 = trunc i32 %xor36.16871 to i8
  store i8 %conv37.16872, i8* %scevgep41.15860, align 1
  %scevgep28.16873 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %232, i64 0, i64 0, i64 1
  %239 = bitcast i8* %scevgep28.16873 to [61 x [61 x i8]]*
  %scevgep41.16874 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %233, i64 0, i64 1, i64 0
  %240 = bitcast i8* %scevgep41.16874 to [61 x [61 x i8]]*
  %call16.17876 = call zeroext i8 (...) @rand()
  store i8 %call16.17876, i8* %scevgep28.16873, align 1
  %241 = load i8, i8* %scevgep28.16873, align 1
  %conv23.17877 = zext i8 %241 to i32
  %242 = load i8, i8* %a, align 1
  %scevgep34.17878 = getelementptr i8, i8* %b, i64 18
  %243 = load i8, i8* %scevgep34.17878, align 1
  %call28.17879 = call zeroext i8 @mult(i8 zeroext %242, i8 zeroext %243)
  %conv29.17880 = zext i8 %call28.17879 to i32
  %xor.17881 = xor i32 %conv23.17877, %conv29.17880
  %scevgep35.17882 = getelementptr i8, i8* %a, i64 18
  %244 = load i8, i8* %scevgep35.17882, align 1
  %245 = load i8, i8* %b, align 1
  %call34.17883 = call zeroext i8 @mult(i8 zeroext %244, i8 zeroext %245)
  %conv35.17884 = zext i8 %call34.17883 to i32
  %xor36.17885 = xor i32 %xor.17881, %conv35.17884
  %conv37.17886 = trunc i32 %xor36.17885 to i8
  store i8 %conv37.17886, i8* %scevgep41.16874, align 1
  %scevgep28.17887 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %239, i64 0, i64 0, i64 1
  %246 = bitcast i8* %scevgep28.17887 to [61 x [61 x i8]]*
  %scevgep41.17888 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %240, i64 0, i64 1, i64 0
  %247 = bitcast i8* %scevgep41.17888 to [61 x [61 x i8]]*
  %call16.18890 = call zeroext i8 (...) @rand()
  store i8 %call16.18890, i8* %scevgep28.17887, align 1
  %248 = load i8, i8* %scevgep28.17887, align 1
  %conv23.18891 = zext i8 %248 to i32
  %249 = load i8, i8* %a, align 1
  %scevgep34.18892 = getelementptr i8, i8* %b, i64 19
  %250 = load i8, i8* %scevgep34.18892, align 1
  %call28.18893 = call zeroext i8 @mult(i8 zeroext %249, i8 zeroext %250)
  %conv29.18894 = zext i8 %call28.18893 to i32
  %xor.18895 = xor i32 %conv23.18891, %conv29.18894
  %scevgep35.18896 = getelementptr i8, i8* %a, i64 19
  %251 = load i8, i8* %scevgep35.18896, align 1
  %252 = load i8, i8* %b, align 1
  %call34.18897 = call zeroext i8 @mult(i8 zeroext %251, i8 zeroext %252)
  %conv35.18898 = zext i8 %call34.18897 to i32
  %xor36.18899 = xor i32 %xor.18895, %conv35.18898
  %conv37.18900 = trunc i32 %xor36.18899 to i8
  store i8 %conv37.18900, i8* %scevgep41.17888, align 1
  %scevgep28.18901 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %246, i64 0, i64 0, i64 1
  %253 = bitcast i8* %scevgep28.18901 to [61 x [61 x i8]]*
  %scevgep41.18902 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %247, i64 0, i64 1, i64 0
  %254 = bitcast i8* %scevgep41.18902 to [61 x [61 x i8]]*
  %call16.19904 = call zeroext i8 (...) @rand()
  store i8 %call16.19904, i8* %scevgep28.18901, align 1
  %255 = load i8, i8* %scevgep28.18901, align 1
  %conv23.19905 = zext i8 %255 to i32
  %256 = load i8, i8* %a, align 1
  %scevgep34.19906 = getelementptr i8, i8* %b, i64 20
  %257 = load i8, i8* %scevgep34.19906, align 1
  %call28.19907 = call zeroext i8 @mult(i8 zeroext %256, i8 zeroext %257)
  %conv29.19908 = zext i8 %call28.19907 to i32
  %xor.19909 = xor i32 %conv23.19905, %conv29.19908
  %scevgep35.19910 = getelementptr i8, i8* %a, i64 20
  %258 = load i8, i8* %scevgep35.19910, align 1
  %259 = load i8, i8* %b, align 1
  %call34.19911 = call zeroext i8 @mult(i8 zeroext %258, i8 zeroext %259)
  %conv35.19912 = zext i8 %call34.19911 to i32
  %xor36.19913 = xor i32 %xor.19909, %conv35.19912
  %conv37.19914 = trunc i32 %xor36.19913 to i8
  store i8 %conv37.19914, i8* %scevgep41.18902, align 1
  %scevgep28.19915 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %253, i64 0, i64 0, i64 1
  %260 = bitcast i8* %scevgep28.19915 to [61 x [61 x i8]]*
  %scevgep41.19916 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %254, i64 0, i64 1, i64 0
  %261 = bitcast i8* %scevgep41.19916 to [61 x [61 x i8]]*
  %call16.20918 = call zeroext i8 (...) @rand()
  store i8 %call16.20918, i8* %scevgep28.19915, align 1
  %262 = load i8, i8* %scevgep28.19915, align 1
  %conv23.20919 = zext i8 %262 to i32
  %263 = load i8, i8* %a, align 1
  %scevgep34.20920 = getelementptr i8, i8* %b, i64 21
  %264 = load i8, i8* %scevgep34.20920, align 1
  %call28.20921 = call zeroext i8 @mult(i8 zeroext %263, i8 zeroext %264)
  %conv29.20922 = zext i8 %call28.20921 to i32
  %xor.20923 = xor i32 %conv23.20919, %conv29.20922
  %scevgep35.20924 = getelementptr i8, i8* %a, i64 21
  %265 = load i8, i8* %scevgep35.20924, align 1
  %266 = load i8, i8* %b, align 1
  %call34.20925 = call zeroext i8 @mult(i8 zeroext %265, i8 zeroext %266)
  %conv35.20926 = zext i8 %call34.20925 to i32
  %xor36.20927 = xor i32 %xor.20923, %conv35.20926
  %conv37.20928 = trunc i32 %xor36.20927 to i8
  store i8 %conv37.20928, i8* %scevgep41.19916, align 1
  %scevgep28.20929 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %260, i64 0, i64 0, i64 1
  %267 = bitcast i8* %scevgep28.20929 to [61 x [61 x i8]]*
  %scevgep41.20930 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %261, i64 0, i64 1, i64 0
  %268 = bitcast i8* %scevgep41.20930 to [61 x [61 x i8]]*
  %call16.21932 = call zeroext i8 (...) @rand()
  store i8 %call16.21932, i8* %scevgep28.20929, align 1
  %269 = load i8, i8* %scevgep28.20929, align 1
  %conv23.21933 = zext i8 %269 to i32
  %270 = load i8, i8* %a, align 1
  %scevgep34.21934 = getelementptr i8, i8* %b, i64 22
  %271 = load i8, i8* %scevgep34.21934, align 1
  %call28.21935 = call zeroext i8 @mult(i8 zeroext %270, i8 zeroext %271)
  %conv29.21936 = zext i8 %call28.21935 to i32
  %xor.21937 = xor i32 %conv23.21933, %conv29.21936
  %scevgep35.21938 = getelementptr i8, i8* %a, i64 22
  %272 = load i8, i8* %scevgep35.21938, align 1
  %273 = load i8, i8* %b, align 1
  %call34.21939 = call zeroext i8 @mult(i8 zeroext %272, i8 zeroext %273)
  %conv35.21940 = zext i8 %call34.21939 to i32
  %xor36.21941 = xor i32 %xor.21937, %conv35.21940
  %conv37.21942 = trunc i32 %xor36.21941 to i8
  store i8 %conv37.21942, i8* %scevgep41.20930, align 1
  %scevgep28.21943 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %267, i64 0, i64 0, i64 1
  %274 = bitcast i8* %scevgep28.21943 to [61 x [61 x i8]]*
  %scevgep41.21944 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %268, i64 0, i64 1, i64 0
  %275 = bitcast i8* %scevgep41.21944 to [61 x [61 x i8]]*
  %call16.22946 = call zeroext i8 (...) @rand()
  store i8 %call16.22946, i8* %scevgep28.21943, align 1
  %276 = load i8, i8* %scevgep28.21943, align 1
  %conv23.22947 = zext i8 %276 to i32
  %277 = load i8, i8* %a, align 1
  %scevgep34.22948 = getelementptr i8, i8* %b, i64 23
  %278 = load i8, i8* %scevgep34.22948, align 1
  %call28.22949 = call zeroext i8 @mult(i8 zeroext %277, i8 zeroext %278)
  %conv29.22950 = zext i8 %call28.22949 to i32
  %xor.22951 = xor i32 %conv23.22947, %conv29.22950
  %scevgep35.22952 = getelementptr i8, i8* %a, i64 23
  %279 = load i8, i8* %scevgep35.22952, align 1
  %280 = load i8, i8* %b, align 1
  %call34.22953 = call zeroext i8 @mult(i8 zeroext %279, i8 zeroext %280)
  %conv35.22954 = zext i8 %call34.22953 to i32
  %xor36.22955 = xor i32 %xor.22951, %conv35.22954
  %conv37.22956 = trunc i32 %xor36.22955 to i8
  store i8 %conv37.22956, i8* %scevgep41.21944, align 1
  %scevgep28.22957 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %274, i64 0, i64 0, i64 1
  %281 = bitcast i8* %scevgep28.22957 to [61 x [61 x i8]]*
  %scevgep41.22958 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %275, i64 0, i64 1, i64 0
  %282 = bitcast i8* %scevgep41.22958 to [61 x [61 x i8]]*
  %call16.23960 = call zeroext i8 (...) @rand()
  store i8 %call16.23960, i8* %scevgep28.22957, align 1
  %283 = load i8, i8* %scevgep28.22957, align 1
  %conv23.23961 = zext i8 %283 to i32
  %284 = load i8, i8* %a, align 1
  %scevgep34.23962 = getelementptr i8, i8* %b, i64 24
  %285 = load i8, i8* %scevgep34.23962, align 1
  %call28.23963 = call zeroext i8 @mult(i8 zeroext %284, i8 zeroext %285)
  %conv29.23964 = zext i8 %call28.23963 to i32
  %xor.23965 = xor i32 %conv23.23961, %conv29.23964
  %scevgep35.23966 = getelementptr i8, i8* %a, i64 24
  %286 = load i8, i8* %scevgep35.23966, align 1
  %287 = load i8, i8* %b, align 1
  %call34.23967 = call zeroext i8 @mult(i8 zeroext %286, i8 zeroext %287)
  %conv35.23968 = zext i8 %call34.23967 to i32
  %xor36.23969 = xor i32 %xor.23965, %conv35.23968
  %conv37.23970 = trunc i32 %xor36.23969 to i8
  store i8 %conv37.23970, i8* %scevgep41.22958, align 1
  %scevgep28.23971 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %281, i64 0, i64 0, i64 1
  %288 = bitcast i8* %scevgep28.23971 to [61 x [61 x i8]]*
  %scevgep41.23972 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %282, i64 0, i64 1, i64 0
  %289 = bitcast i8* %scevgep41.23972 to [61 x [61 x i8]]*
  %call16.24974 = call zeroext i8 (...) @rand()
  store i8 %call16.24974, i8* %scevgep28.23971, align 1
  %290 = load i8, i8* %scevgep28.23971, align 1
  %conv23.24975 = zext i8 %290 to i32
  %291 = load i8, i8* %a, align 1
  %scevgep34.24976 = getelementptr i8, i8* %b, i64 25
  %292 = load i8, i8* %scevgep34.24976, align 1
  %call28.24977 = call zeroext i8 @mult(i8 zeroext %291, i8 zeroext %292)
  %conv29.24978 = zext i8 %call28.24977 to i32
  %xor.24979 = xor i32 %conv23.24975, %conv29.24978
  %scevgep35.24980 = getelementptr i8, i8* %a, i64 25
  %293 = load i8, i8* %scevgep35.24980, align 1
  %294 = load i8, i8* %b, align 1
  %call34.24981 = call zeroext i8 @mult(i8 zeroext %293, i8 zeroext %294)
  %conv35.24982 = zext i8 %call34.24981 to i32
  %xor36.24983 = xor i32 %xor.24979, %conv35.24982
  %conv37.24984 = trunc i32 %xor36.24983 to i8
  store i8 %conv37.24984, i8* %scevgep41.23972, align 1
  %scevgep28.24985 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %288, i64 0, i64 0, i64 1
  %295 = bitcast i8* %scevgep28.24985 to [61 x [61 x i8]]*
  %scevgep41.24986 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %289, i64 0, i64 1, i64 0
  %296 = bitcast i8* %scevgep41.24986 to [61 x [61 x i8]]*
  %call16.25988 = call zeroext i8 (...) @rand()
  store i8 %call16.25988, i8* %scevgep28.24985, align 1
  %297 = load i8, i8* %scevgep28.24985, align 1
  %conv23.25989 = zext i8 %297 to i32
  %298 = load i8, i8* %a, align 1
  %scevgep34.25990 = getelementptr i8, i8* %b, i64 26
  %299 = load i8, i8* %scevgep34.25990, align 1
  %call28.25991 = call zeroext i8 @mult(i8 zeroext %298, i8 zeroext %299)
  %conv29.25992 = zext i8 %call28.25991 to i32
  %xor.25993 = xor i32 %conv23.25989, %conv29.25992
  %scevgep35.25994 = getelementptr i8, i8* %a, i64 26
  %300 = load i8, i8* %scevgep35.25994, align 1
  %301 = load i8, i8* %b, align 1
  %call34.25995 = call zeroext i8 @mult(i8 zeroext %300, i8 zeroext %301)
  %conv35.25996 = zext i8 %call34.25995 to i32
  %xor36.25997 = xor i32 %xor.25993, %conv35.25996
  %conv37.25998 = trunc i32 %xor36.25997 to i8
  store i8 %conv37.25998, i8* %scevgep41.24986, align 1
  %scevgep28.25999 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %295, i64 0, i64 0, i64 1
  %302 = bitcast i8* %scevgep28.25999 to [61 x [61 x i8]]*
  %scevgep41.251000 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %296, i64 0, i64 1, i64 0
  %303 = bitcast i8* %scevgep41.251000 to [61 x [61 x i8]]*
  %call16.261002 = call zeroext i8 (...) @rand()
  store i8 %call16.261002, i8* %scevgep28.25999, align 1
  %304 = load i8, i8* %scevgep28.25999, align 1
  %conv23.261003 = zext i8 %304 to i32
  %305 = load i8, i8* %a, align 1
  %scevgep34.261004 = getelementptr i8, i8* %b, i64 27
  %306 = load i8, i8* %scevgep34.261004, align 1
  %call28.261005 = call zeroext i8 @mult(i8 zeroext %305, i8 zeroext %306)
  %conv29.261006 = zext i8 %call28.261005 to i32
  %xor.261007 = xor i32 %conv23.261003, %conv29.261006
  %scevgep35.261008 = getelementptr i8, i8* %a, i64 27
  %307 = load i8, i8* %scevgep35.261008, align 1
  %308 = load i8, i8* %b, align 1
  %call34.261009 = call zeroext i8 @mult(i8 zeroext %307, i8 zeroext %308)
  %conv35.261010 = zext i8 %call34.261009 to i32
  %xor36.261011 = xor i32 %xor.261007, %conv35.261010
  %conv37.261012 = trunc i32 %xor36.261011 to i8
  store i8 %conv37.261012, i8* %scevgep41.251000, align 1
  %scevgep28.261013 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %302, i64 0, i64 0, i64 1
  %309 = bitcast i8* %scevgep28.261013 to [61 x [61 x i8]]*
  %scevgep41.261014 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %303, i64 0, i64 1, i64 0
  %310 = bitcast i8* %scevgep41.261014 to [61 x [61 x i8]]*
  %call16.271016 = call zeroext i8 (...) @rand()
  store i8 %call16.271016, i8* %scevgep28.261013, align 1
  %311 = load i8, i8* %scevgep28.261013, align 1
  %conv23.271017 = zext i8 %311 to i32
  %312 = load i8, i8* %a, align 1
  %scevgep34.271018 = getelementptr i8, i8* %b, i64 28
  %313 = load i8, i8* %scevgep34.271018, align 1
  %call28.271019 = call zeroext i8 @mult(i8 zeroext %312, i8 zeroext %313)
  %conv29.271020 = zext i8 %call28.271019 to i32
  %xor.271021 = xor i32 %conv23.271017, %conv29.271020
  %scevgep35.271022 = getelementptr i8, i8* %a, i64 28
  %314 = load i8, i8* %scevgep35.271022, align 1
  %315 = load i8, i8* %b, align 1
  %call34.271023 = call zeroext i8 @mult(i8 zeroext %314, i8 zeroext %315)
  %conv35.271024 = zext i8 %call34.271023 to i32
  %xor36.271025 = xor i32 %xor.271021, %conv35.271024
  %conv37.271026 = trunc i32 %xor36.271025 to i8
  store i8 %conv37.271026, i8* %scevgep41.261014, align 1
  %scevgep28.271027 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %309, i64 0, i64 0, i64 1
  %316 = bitcast i8* %scevgep28.271027 to [61 x [61 x i8]]*
  %scevgep41.271028 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %310, i64 0, i64 1, i64 0
  %317 = bitcast i8* %scevgep41.271028 to [61 x [61 x i8]]*
  %call16.281030 = call zeroext i8 (...) @rand()
  store i8 %call16.281030, i8* %scevgep28.271027, align 1
  %318 = load i8, i8* %scevgep28.271027, align 1
  %conv23.281031 = zext i8 %318 to i32
  %319 = load i8, i8* %a, align 1
  %scevgep34.281032 = getelementptr i8, i8* %b, i64 29
  %320 = load i8, i8* %scevgep34.281032, align 1
  %call28.281033 = call zeroext i8 @mult(i8 zeroext %319, i8 zeroext %320)
  %conv29.281034 = zext i8 %call28.281033 to i32
  %xor.281035 = xor i32 %conv23.281031, %conv29.281034
  %scevgep35.281036 = getelementptr i8, i8* %a, i64 29
  %321 = load i8, i8* %scevgep35.281036, align 1
  %322 = load i8, i8* %b, align 1
  %call34.281037 = call zeroext i8 @mult(i8 zeroext %321, i8 zeroext %322)
  %conv35.281038 = zext i8 %call34.281037 to i32
  %xor36.281039 = xor i32 %xor.281035, %conv35.281038
  %conv37.281040 = trunc i32 %xor36.281039 to i8
  store i8 %conv37.281040, i8* %scevgep41.271028, align 1
  %scevgep28.281041 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %316, i64 0, i64 0, i64 1
  %323 = bitcast i8* %scevgep28.281041 to [61 x [61 x i8]]*
  %scevgep41.281042 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %317, i64 0, i64 1, i64 0
  %324 = bitcast i8* %scevgep41.281042 to [61 x [61 x i8]]*
  %call16.291044 = call zeroext i8 (...) @rand()
  store i8 %call16.291044, i8* %scevgep28.281041, align 1
  %325 = load i8, i8* %scevgep28.281041, align 1
  %conv23.291045 = zext i8 %325 to i32
  %326 = load i8, i8* %a, align 1
  %scevgep34.291046 = getelementptr i8, i8* %b, i64 30
  %327 = load i8, i8* %scevgep34.291046, align 1
  %call28.291047 = call zeroext i8 @mult(i8 zeroext %326, i8 zeroext %327)
  %conv29.291048 = zext i8 %call28.291047 to i32
  %xor.291049 = xor i32 %conv23.291045, %conv29.291048
  %scevgep35.291050 = getelementptr i8, i8* %a, i64 30
  %328 = load i8, i8* %scevgep35.291050, align 1
  %329 = load i8, i8* %b, align 1
  %call34.291051 = call zeroext i8 @mult(i8 zeroext %328, i8 zeroext %329)
  %conv35.291052 = zext i8 %call34.291051 to i32
  %xor36.291053 = xor i32 %xor.291049, %conv35.291052
  %conv37.291054 = trunc i32 %xor36.291053 to i8
  store i8 %conv37.291054, i8* %scevgep41.281042, align 1
  %scevgep28.291055 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %323, i64 0, i64 0, i64 1
  %330 = bitcast i8* %scevgep28.291055 to [61 x [61 x i8]]*
  %scevgep41.291056 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %324, i64 0, i64 1, i64 0
  %331 = bitcast i8* %scevgep41.291056 to [61 x [61 x i8]]*
  %call16.301058 = call zeroext i8 (...) @rand()
  store i8 %call16.301058, i8* %scevgep28.291055, align 1
  %332 = load i8, i8* %scevgep28.291055, align 1
  %conv23.301059 = zext i8 %332 to i32
  %333 = load i8, i8* %a, align 1
  %scevgep34.301060 = getelementptr i8, i8* %b, i64 31
  %334 = load i8, i8* %scevgep34.301060, align 1
  %call28.301061 = call zeroext i8 @mult(i8 zeroext %333, i8 zeroext %334)
  %conv29.301062 = zext i8 %call28.301061 to i32
  %xor.301063 = xor i32 %conv23.301059, %conv29.301062
  %scevgep35.301064 = getelementptr i8, i8* %a, i64 31
  %335 = load i8, i8* %scevgep35.301064, align 1
  %336 = load i8, i8* %b, align 1
  %call34.301065 = call zeroext i8 @mult(i8 zeroext %335, i8 zeroext %336)
  %conv35.301066 = zext i8 %call34.301065 to i32
  %xor36.301067 = xor i32 %xor.301063, %conv35.301066
  %conv37.301068 = trunc i32 %xor36.301067 to i8
  store i8 %conv37.301068, i8* %scevgep41.291056, align 1
  %scevgep28.301069 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %330, i64 0, i64 0, i64 1
  %337 = bitcast i8* %scevgep28.301069 to [61 x [61 x i8]]*
  %scevgep41.301070 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %331, i64 0, i64 1, i64 0
  %338 = bitcast i8* %scevgep41.301070 to [61 x [61 x i8]]*
  %call16.311072 = call zeroext i8 (...) @rand()
  store i8 %call16.311072, i8* %scevgep28.301069, align 1
  %339 = load i8, i8* %scevgep28.301069, align 1
  %conv23.311073 = zext i8 %339 to i32
  %340 = load i8, i8* %a, align 1
  %scevgep34.311074 = getelementptr i8, i8* %b, i64 32
  %341 = load i8, i8* %scevgep34.311074, align 1
  %call28.311075 = call zeroext i8 @mult(i8 zeroext %340, i8 zeroext %341)
  %conv29.311076 = zext i8 %call28.311075 to i32
  %xor.311077 = xor i32 %conv23.311073, %conv29.311076
  %scevgep35.311078 = getelementptr i8, i8* %a, i64 32
  %342 = load i8, i8* %scevgep35.311078, align 1
  %343 = load i8, i8* %b, align 1
  %call34.311079 = call zeroext i8 @mult(i8 zeroext %342, i8 zeroext %343)
  %conv35.311080 = zext i8 %call34.311079 to i32
  %xor36.311081 = xor i32 %xor.311077, %conv35.311080
  %conv37.311082 = trunc i32 %xor36.311081 to i8
  store i8 %conv37.311082, i8* %scevgep41.301070, align 1
  %scevgep28.311083 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %337, i64 0, i64 0, i64 1
  %344 = bitcast i8* %scevgep28.311083 to [61 x [61 x i8]]*
  %scevgep41.311084 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %338, i64 0, i64 1, i64 0
  %345 = bitcast i8* %scevgep41.311084 to [61 x [61 x i8]]*
  %call16.321086 = call zeroext i8 (...) @rand()
  store i8 %call16.321086, i8* %scevgep28.311083, align 1
  %346 = load i8, i8* %scevgep28.311083, align 1
  %conv23.321087 = zext i8 %346 to i32
  %347 = load i8, i8* %a, align 1
  %scevgep34.321088 = getelementptr i8, i8* %b, i64 33
  %348 = load i8, i8* %scevgep34.321088, align 1
  %call28.321089 = call zeroext i8 @mult(i8 zeroext %347, i8 zeroext %348)
  %conv29.321090 = zext i8 %call28.321089 to i32
  %xor.321091 = xor i32 %conv23.321087, %conv29.321090
  %scevgep35.321092 = getelementptr i8, i8* %a, i64 33
  %349 = load i8, i8* %scevgep35.321092, align 1
  %350 = load i8, i8* %b, align 1
  %call34.321093 = call zeroext i8 @mult(i8 zeroext %349, i8 zeroext %350)
  %conv35.321094 = zext i8 %call34.321093 to i32
  %xor36.321095 = xor i32 %xor.321091, %conv35.321094
  %conv37.321096 = trunc i32 %xor36.321095 to i8
  store i8 %conv37.321096, i8* %scevgep41.311084, align 1
  %scevgep28.321097 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %344, i64 0, i64 0, i64 1
  %351 = bitcast i8* %scevgep28.321097 to [61 x [61 x i8]]*
  %scevgep41.321098 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %345, i64 0, i64 1, i64 0
  %352 = bitcast i8* %scevgep41.321098 to [61 x [61 x i8]]*
  %call16.331100 = call zeroext i8 (...) @rand()
  store i8 %call16.331100, i8* %scevgep28.321097, align 1
  %353 = load i8, i8* %scevgep28.321097, align 1
  %conv23.331101 = zext i8 %353 to i32
  %354 = load i8, i8* %a, align 1
  %scevgep34.331102 = getelementptr i8, i8* %b, i64 34
  %355 = load i8, i8* %scevgep34.331102, align 1
  %call28.331103 = call zeroext i8 @mult(i8 zeroext %354, i8 zeroext %355)
  %conv29.331104 = zext i8 %call28.331103 to i32
  %xor.331105 = xor i32 %conv23.331101, %conv29.331104
  %scevgep35.331106 = getelementptr i8, i8* %a, i64 34
  %356 = load i8, i8* %scevgep35.331106, align 1
  %357 = load i8, i8* %b, align 1
  %call34.331107 = call zeroext i8 @mult(i8 zeroext %356, i8 zeroext %357)
  %conv35.331108 = zext i8 %call34.331107 to i32
  %xor36.331109 = xor i32 %xor.331105, %conv35.331108
  %conv37.331110 = trunc i32 %xor36.331109 to i8
  store i8 %conv37.331110, i8* %scevgep41.321098, align 1
  %scevgep28.331111 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %351, i64 0, i64 0, i64 1
  %358 = bitcast i8* %scevgep28.331111 to [61 x [61 x i8]]*
  %scevgep41.331112 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %352, i64 0, i64 1, i64 0
  %359 = bitcast i8* %scevgep41.331112 to [61 x [61 x i8]]*
  %call16.341114 = call zeroext i8 (...) @rand()
  store i8 %call16.341114, i8* %scevgep28.331111, align 1
  %360 = load i8, i8* %scevgep28.331111, align 1
  %conv23.341115 = zext i8 %360 to i32
  %361 = load i8, i8* %a, align 1
  %scevgep34.341116 = getelementptr i8, i8* %b, i64 35
  %362 = load i8, i8* %scevgep34.341116, align 1
  %call28.341117 = call zeroext i8 @mult(i8 zeroext %361, i8 zeroext %362)
  %conv29.341118 = zext i8 %call28.341117 to i32
  %xor.341119 = xor i32 %conv23.341115, %conv29.341118
  %scevgep35.341120 = getelementptr i8, i8* %a, i64 35
  %363 = load i8, i8* %scevgep35.341120, align 1
  %364 = load i8, i8* %b, align 1
  %call34.341121 = call zeroext i8 @mult(i8 zeroext %363, i8 zeroext %364)
  %conv35.341122 = zext i8 %call34.341121 to i32
  %xor36.341123 = xor i32 %xor.341119, %conv35.341122
  %conv37.341124 = trunc i32 %xor36.341123 to i8
  store i8 %conv37.341124, i8* %scevgep41.331112, align 1
  %scevgep28.341125 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %358, i64 0, i64 0, i64 1
  %365 = bitcast i8* %scevgep28.341125 to [61 x [61 x i8]]*
  %scevgep41.341126 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %359, i64 0, i64 1, i64 0
  %366 = bitcast i8* %scevgep41.341126 to [61 x [61 x i8]]*
  %call16.351128 = call zeroext i8 (...) @rand()
  store i8 %call16.351128, i8* %scevgep28.341125, align 1
  %367 = load i8, i8* %scevgep28.341125, align 1
  %conv23.351129 = zext i8 %367 to i32
  %368 = load i8, i8* %a, align 1
  %scevgep34.351130 = getelementptr i8, i8* %b, i64 36
  %369 = load i8, i8* %scevgep34.351130, align 1
  %call28.351131 = call zeroext i8 @mult(i8 zeroext %368, i8 zeroext %369)
  %conv29.351132 = zext i8 %call28.351131 to i32
  %xor.351133 = xor i32 %conv23.351129, %conv29.351132
  %scevgep35.351134 = getelementptr i8, i8* %a, i64 36
  %370 = load i8, i8* %scevgep35.351134, align 1
  %371 = load i8, i8* %b, align 1
  %call34.351135 = call zeroext i8 @mult(i8 zeroext %370, i8 zeroext %371)
  %conv35.351136 = zext i8 %call34.351135 to i32
  %xor36.351137 = xor i32 %xor.351133, %conv35.351136
  %conv37.351138 = trunc i32 %xor36.351137 to i8
  store i8 %conv37.351138, i8* %scevgep41.341126, align 1
  %scevgep28.351139 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %365, i64 0, i64 0, i64 1
  %372 = bitcast i8* %scevgep28.351139 to [61 x [61 x i8]]*
  %scevgep41.351140 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %366, i64 0, i64 1, i64 0
  %373 = bitcast i8* %scevgep41.351140 to [61 x [61 x i8]]*
  %call16.361142 = call zeroext i8 (...) @rand()
  store i8 %call16.361142, i8* %scevgep28.351139, align 1
  %374 = load i8, i8* %scevgep28.351139, align 1
  %conv23.361143 = zext i8 %374 to i32
  %375 = load i8, i8* %a, align 1
  %scevgep34.361144 = getelementptr i8, i8* %b, i64 37
  %376 = load i8, i8* %scevgep34.361144, align 1
  %call28.361145 = call zeroext i8 @mult(i8 zeroext %375, i8 zeroext %376)
  %conv29.361146 = zext i8 %call28.361145 to i32
  %xor.361147 = xor i32 %conv23.361143, %conv29.361146
  %scevgep35.361148 = getelementptr i8, i8* %a, i64 37
  %377 = load i8, i8* %scevgep35.361148, align 1
  %378 = load i8, i8* %b, align 1
  %call34.361149 = call zeroext i8 @mult(i8 zeroext %377, i8 zeroext %378)
  %conv35.361150 = zext i8 %call34.361149 to i32
  %xor36.361151 = xor i32 %xor.361147, %conv35.361150
  %conv37.361152 = trunc i32 %xor36.361151 to i8
  store i8 %conv37.361152, i8* %scevgep41.351140, align 1
  %scevgep28.361153 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %372, i64 0, i64 0, i64 1
  %379 = bitcast i8* %scevgep28.361153 to [61 x [61 x i8]]*
  %scevgep41.361154 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %373, i64 0, i64 1, i64 0
  %380 = bitcast i8* %scevgep41.361154 to [61 x [61 x i8]]*
  %call16.371156 = call zeroext i8 (...) @rand()
  store i8 %call16.371156, i8* %scevgep28.361153, align 1
  %381 = load i8, i8* %scevgep28.361153, align 1
  %conv23.371157 = zext i8 %381 to i32
  %382 = load i8, i8* %a, align 1
  %scevgep34.371158 = getelementptr i8, i8* %b, i64 38
  %383 = load i8, i8* %scevgep34.371158, align 1
  %call28.371159 = call zeroext i8 @mult(i8 zeroext %382, i8 zeroext %383)
  %conv29.371160 = zext i8 %call28.371159 to i32
  %xor.371161 = xor i32 %conv23.371157, %conv29.371160
  %scevgep35.371162 = getelementptr i8, i8* %a, i64 38
  %384 = load i8, i8* %scevgep35.371162, align 1
  %385 = load i8, i8* %b, align 1
  %call34.371163 = call zeroext i8 @mult(i8 zeroext %384, i8 zeroext %385)
  %conv35.371164 = zext i8 %call34.371163 to i32
  %xor36.371165 = xor i32 %xor.371161, %conv35.371164
  %conv37.371166 = trunc i32 %xor36.371165 to i8
  store i8 %conv37.371166, i8* %scevgep41.361154, align 1
  %scevgep28.371167 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %379, i64 0, i64 0, i64 1
  %386 = bitcast i8* %scevgep28.371167 to [61 x [61 x i8]]*
  %scevgep41.371168 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %380, i64 0, i64 1, i64 0
  %387 = bitcast i8* %scevgep41.371168 to [61 x [61 x i8]]*
  %call16.381170 = call zeroext i8 (...) @rand()
  store i8 %call16.381170, i8* %scevgep28.371167, align 1
  %388 = load i8, i8* %scevgep28.371167, align 1
  %conv23.381171 = zext i8 %388 to i32
  %389 = load i8, i8* %a, align 1
  %scevgep34.381172 = getelementptr i8, i8* %b, i64 39
  %390 = load i8, i8* %scevgep34.381172, align 1
  %call28.381173 = call zeroext i8 @mult(i8 zeroext %389, i8 zeroext %390)
  %conv29.381174 = zext i8 %call28.381173 to i32
  %xor.381175 = xor i32 %conv23.381171, %conv29.381174
  %scevgep35.381176 = getelementptr i8, i8* %a, i64 39
  %391 = load i8, i8* %scevgep35.381176, align 1
  %392 = load i8, i8* %b, align 1
  %call34.381177 = call zeroext i8 @mult(i8 zeroext %391, i8 zeroext %392)
  %conv35.381178 = zext i8 %call34.381177 to i32
  %xor36.381179 = xor i32 %xor.381175, %conv35.381178
  %conv37.381180 = trunc i32 %xor36.381179 to i8
  store i8 %conv37.381180, i8* %scevgep41.371168, align 1
  %scevgep28.381181 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %386, i64 0, i64 0, i64 1
  %393 = bitcast i8* %scevgep28.381181 to [61 x [61 x i8]]*
  %scevgep41.381182 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %387, i64 0, i64 1, i64 0
  %394 = bitcast i8* %scevgep41.381182 to [61 x [61 x i8]]*
  %call16.391184 = call zeroext i8 (...) @rand()
  store i8 %call16.391184, i8* %scevgep28.381181, align 1
  %395 = load i8, i8* %scevgep28.381181, align 1
  %conv23.391185 = zext i8 %395 to i32
  %396 = load i8, i8* %a, align 1
  %scevgep34.391186 = getelementptr i8, i8* %b, i64 40
  %397 = load i8, i8* %scevgep34.391186, align 1
  %call28.391187 = call zeroext i8 @mult(i8 zeroext %396, i8 zeroext %397)
  %conv29.391188 = zext i8 %call28.391187 to i32
  %xor.391189 = xor i32 %conv23.391185, %conv29.391188
  %scevgep35.391190 = getelementptr i8, i8* %a, i64 40
  %398 = load i8, i8* %scevgep35.391190, align 1
  %399 = load i8, i8* %b, align 1
  %call34.391191 = call zeroext i8 @mult(i8 zeroext %398, i8 zeroext %399)
  %conv35.391192 = zext i8 %call34.391191 to i32
  %xor36.391193 = xor i32 %xor.391189, %conv35.391192
  %conv37.391194 = trunc i32 %xor36.391193 to i8
  store i8 %conv37.391194, i8* %scevgep41.381182, align 1
  %scevgep28.391195 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %393, i64 0, i64 0, i64 1
  %400 = bitcast i8* %scevgep28.391195 to [61 x [61 x i8]]*
  %scevgep41.391196 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %394, i64 0, i64 1, i64 0
  %401 = bitcast i8* %scevgep41.391196 to [61 x [61 x i8]]*
  %call16.401198 = call zeroext i8 (...) @rand()
  store i8 %call16.401198, i8* %scevgep28.391195, align 1
  %402 = load i8, i8* %scevgep28.391195, align 1
  %conv23.401199 = zext i8 %402 to i32
  %403 = load i8, i8* %a, align 1
  %scevgep34.401200 = getelementptr i8, i8* %b, i64 41
  %404 = load i8, i8* %scevgep34.401200, align 1
  %call28.401201 = call zeroext i8 @mult(i8 zeroext %403, i8 zeroext %404)
  %conv29.401202 = zext i8 %call28.401201 to i32
  %xor.401203 = xor i32 %conv23.401199, %conv29.401202
  %scevgep35.401204 = getelementptr i8, i8* %a, i64 41
  %405 = load i8, i8* %scevgep35.401204, align 1
  %406 = load i8, i8* %b, align 1
  %call34.401205 = call zeroext i8 @mult(i8 zeroext %405, i8 zeroext %406)
  %conv35.401206 = zext i8 %call34.401205 to i32
  %xor36.401207 = xor i32 %xor.401203, %conv35.401206
  %conv37.401208 = trunc i32 %xor36.401207 to i8
  store i8 %conv37.401208, i8* %scevgep41.391196, align 1
  %scevgep28.401209 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %400, i64 0, i64 0, i64 1
  %407 = bitcast i8* %scevgep28.401209 to [61 x [61 x i8]]*
  %scevgep41.401210 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %401, i64 0, i64 1, i64 0
  %408 = bitcast i8* %scevgep41.401210 to [61 x [61 x i8]]*
  %call16.411212 = call zeroext i8 (...) @rand()
  store i8 %call16.411212, i8* %scevgep28.401209, align 1
  %409 = load i8, i8* %scevgep28.401209, align 1
  %conv23.411213 = zext i8 %409 to i32
  %410 = load i8, i8* %a, align 1
  %scevgep34.411214 = getelementptr i8, i8* %b, i64 42
  %411 = load i8, i8* %scevgep34.411214, align 1
  %call28.411215 = call zeroext i8 @mult(i8 zeroext %410, i8 zeroext %411)
  %conv29.411216 = zext i8 %call28.411215 to i32
  %xor.411217 = xor i32 %conv23.411213, %conv29.411216
  %scevgep35.411218 = getelementptr i8, i8* %a, i64 42
  %412 = load i8, i8* %scevgep35.411218, align 1
  %413 = load i8, i8* %b, align 1
  %call34.411219 = call zeroext i8 @mult(i8 zeroext %412, i8 zeroext %413)
  %conv35.411220 = zext i8 %call34.411219 to i32
  %xor36.411221 = xor i32 %xor.411217, %conv35.411220
  %conv37.411222 = trunc i32 %xor36.411221 to i8
  store i8 %conv37.411222, i8* %scevgep41.401210, align 1
  %scevgep28.411223 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %407, i64 0, i64 0, i64 1
  %414 = bitcast i8* %scevgep28.411223 to [61 x [61 x i8]]*
  %scevgep41.411224 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %408, i64 0, i64 1, i64 0
  %415 = bitcast i8* %scevgep41.411224 to [61 x [61 x i8]]*
  %call16.421226 = call zeroext i8 (...) @rand()
  store i8 %call16.421226, i8* %scevgep28.411223, align 1
  %416 = load i8, i8* %scevgep28.411223, align 1
  %conv23.421227 = zext i8 %416 to i32
  %417 = load i8, i8* %a, align 1
  %scevgep34.421228 = getelementptr i8, i8* %b, i64 43
  %418 = load i8, i8* %scevgep34.421228, align 1
  %call28.421229 = call zeroext i8 @mult(i8 zeroext %417, i8 zeroext %418)
  %conv29.421230 = zext i8 %call28.421229 to i32
  %xor.421231 = xor i32 %conv23.421227, %conv29.421230
  %scevgep35.421232 = getelementptr i8, i8* %a, i64 43
  %419 = load i8, i8* %scevgep35.421232, align 1
  %420 = load i8, i8* %b, align 1
  %call34.421233 = call zeroext i8 @mult(i8 zeroext %419, i8 zeroext %420)
  %conv35.421234 = zext i8 %call34.421233 to i32
  %xor36.421235 = xor i32 %xor.421231, %conv35.421234
  %conv37.421236 = trunc i32 %xor36.421235 to i8
  store i8 %conv37.421236, i8* %scevgep41.411224, align 1
  %scevgep28.421237 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %414, i64 0, i64 0, i64 1
  %421 = bitcast i8* %scevgep28.421237 to [61 x [61 x i8]]*
  %scevgep41.421238 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %415, i64 0, i64 1, i64 0
  %422 = bitcast i8* %scevgep41.421238 to [61 x [61 x i8]]*
  %call16.431240 = call zeroext i8 (...) @rand()
  store i8 %call16.431240, i8* %scevgep28.421237, align 1
  %423 = load i8, i8* %scevgep28.421237, align 1
  %conv23.431241 = zext i8 %423 to i32
  %424 = load i8, i8* %a, align 1
  %scevgep34.431242 = getelementptr i8, i8* %b, i64 44
  %425 = load i8, i8* %scevgep34.431242, align 1
  %call28.431243 = call zeroext i8 @mult(i8 zeroext %424, i8 zeroext %425)
  %conv29.431244 = zext i8 %call28.431243 to i32
  %xor.431245 = xor i32 %conv23.431241, %conv29.431244
  %scevgep35.431246 = getelementptr i8, i8* %a, i64 44
  %426 = load i8, i8* %scevgep35.431246, align 1
  %427 = load i8, i8* %b, align 1
  %call34.431247 = call zeroext i8 @mult(i8 zeroext %426, i8 zeroext %427)
  %conv35.431248 = zext i8 %call34.431247 to i32
  %xor36.431249 = xor i32 %xor.431245, %conv35.431248
  %conv37.431250 = trunc i32 %xor36.431249 to i8
  store i8 %conv37.431250, i8* %scevgep41.421238, align 1
  %scevgep28.431251 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %421, i64 0, i64 0, i64 1
  %428 = bitcast i8* %scevgep28.431251 to [61 x [61 x i8]]*
  %scevgep41.431252 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %422, i64 0, i64 1, i64 0
  %429 = bitcast i8* %scevgep41.431252 to [61 x [61 x i8]]*
  %call16.441254 = call zeroext i8 (...) @rand()
  store i8 %call16.441254, i8* %scevgep28.431251, align 1
  %430 = load i8, i8* %scevgep28.431251, align 1
  %conv23.441255 = zext i8 %430 to i32
  %431 = load i8, i8* %a, align 1
  %scevgep34.441256 = getelementptr i8, i8* %b, i64 45
  %432 = load i8, i8* %scevgep34.441256, align 1
  %call28.441257 = call zeroext i8 @mult(i8 zeroext %431, i8 zeroext %432)
  %conv29.441258 = zext i8 %call28.441257 to i32
  %xor.441259 = xor i32 %conv23.441255, %conv29.441258
  %scevgep35.441260 = getelementptr i8, i8* %a, i64 45
  %433 = load i8, i8* %scevgep35.441260, align 1
  %434 = load i8, i8* %b, align 1
  %call34.441261 = call zeroext i8 @mult(i8 zeroext %433, i8 zeroext %434)
  %conv35.441262 = zext i8 %call34.441261 to i32
  %xor36.441263 = xor i32 %xor.441259, %conv35.441262
  %conv37.441264 = trunc i32 %xor36.441263 to i8
  store i8 %conv37.441264, i8* %scevgep41.431252, align 1
  %scevgep28.441265 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %428, i64 0, i64 0, i64 1
  %435 = bitcast i8* %scevgep28.441265 to [61 x [61 x i8]]*
  %scevgep41.441266 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %429, i64 0, i64 1, i64 0
  %436 = bitcast i8* %scevgep41.441266 to [61 x [61 x i8]]*
  %call16.451268 = call zeroext i8 (...) @rand()
  store i8 %call16.451268, i8* %scevgep28.441265, align 1
  %437 = load i8, i8* %scevgep28.441265, align 1
  %conv23.451269 = zext i8 %437 to i32
  %438 = load i8, i8* %a, align 1
  %scevgep34.451270 = getelementptr i8, i8* %b, i64 46
  %439 = load i8, i8* %scevgep34.451270, align 1
  %call28.451271 = call zeroext i8 @mult(i8 zeroext %438, i8 zeroext %439)
  %conv29.451272 = zext i8 %call28.451271 to i32
  %xor.451273 = xor i32 %conv23.451269, %conv29.451272
  %scevgep35.451274 = getelementptr i8, i8* %a, i64 46
  %440 = load i8, i8* %scevgep35.451274, align 1
  %441 = load i8, i8* %b, align 1
  %call34.451275 = call zeroext i8 @mult(i8 zeroext %440, i8 zeroext %441)
  %conv35.451276 = zext i8 %call34.451275 to i32
  %xor36.451277 = xor i32 %xor.451273, %conv35.451276
  %conv37.451278 = trunc i32 %xor36.451277 to i8
  store i8 %conv37.451278, i8* %scevgep41.441266, align 1
  %scevgep28.451279 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %435, i64 0, i64 0, i64 1
  %442 = bitcast i8* %scevgep28.451279 to [61 x [61 x i8]]*
  %scevgep41.451280 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %436, i64 0, i64 1, i64 0
  %443 = bitcast i8* %scevgep41.451280 to [61 x [61 x i8]]*
  %call16.461282 = call zeroext i8 (...) @rand()
  store i8 %call16.461282, i8* %scevgep28.451279, align 1
  %444 = load i8, i8* %scevgep28.451279, align 1
  %conv23.461283 = zext i8 %444 to i32
  %445 = load i8, i8* %a, align 1
  %scevgep34.461284 = getelementptr i8, i8* %b, i64 47
  %446 = load i8, i8* %scevgep34.461284, align 1
  %call28.461285 = call zeroext i8 @mult(i8 zeroext %445, i8 zeroext %446)
  %conv29.461286 = zext i8 %call28.461285 to i32
  %xor.461287 = xor i32 %conv23.461283, %conv29.461286
  %scevgep35.461288 = getelementptr i8, i8* %a, i64 47
  %447 = load i8, i8* %scevgep35.461288, align 1
  %448 = load i8, i8* %b, align 1
  %call34.461289 = call zeroext i8 @mult(i8 zeroext %447, i8 zeroext %448)
  %conv35.461290 = zext i8 %call34.461289 to i32
  %xor36.461291 = xor i32 %xor.461287, %conv35.461290
  %conv37.461292 = trunc i32 %xor36.461291 to i8
  store i8 %conv37.461292, i8* %scevgep41.451280, align 1
  %scevgep28.461293 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %442, i64 0, i64 0, i64 1
  %449 = bitcast i8* %scevgep28.461293 to [61 x [61 x i8]]*
  %scevgep41.461294 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %443, i64 0, i64 1, i64 0
  %450 = bitcast i8* %scevgep41.461294 to [61 x [61 x i8]]*
  %call16.471296 = call zeroext i8 (...) @rand()
  store i8 %call16.471296, i8* %scevgep28.461293, align 1
  %451 = load i8, i8* %scevgep28.461293, align 1
  %conv23.471297 = zext i8 %451 to i32
  %452 = load i8, i8* %a, align 1
  %scevgep34.471298 = getelementptr i8, i8* %b, i64 48
  %453 = load i8, i8* %scevgep34.471298, align 1
  %call28.471299 = call zeroext i8 @mult(i8 zeroext %452, i8 zeroext %453)
  %conv29.471300 = zext i8 %call28.471299 to i32
  %xor.471301 = xor i32 %conv23.471297, %conv29.471300
  %scevgep35.471302 = getelementptr i8, i8* %a, i64 48
  %454 = load i8, i8* %scevgep35.471302, align 1
  %455 = load i8, i8* %b, align 1
  %call34.471303 = call zeroext i8 @mult(i8 zeroext %454, i8 zeroext %455)
  %conv35.471304 = zext i8 %call34.471303 to i32
  %xor36.471305 = xor i32 %xor.471301, %conv35.471304
  %conv37.471306 = trunc i32 %xor36.471305 to i8
  store i8 %conv37.471306, i8* %scevgep41.461294, align 1
  %scevgep28.471307 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %449, i64 0, i64 0, i64 1
  %456 = bitcast i8* %scevgep28.471307 to [61 x [61 x i8]]*
  %scevgep41.471308 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %450, i64 0, i64 1, i64 0
  %457 = bitcast i8* %scevgep41.471308 to [61 x [61 x i8]]*
  %call16.481310 = call zeroext i8 (...) @rand()
  store i8 %call16.481310, i8* %scevgep28.471307, align 1
  %458 = load i8, i8* %scevgep28.471307, align 1
  %conv23.481311 = zext i8 %458 to i32
  %459 = load i8, i8* %a, align 1
  %scevgep34.481312 = getelementptr i8, i8* %b, i64 49
  %460 = load i8, i8* %scevgep34.481312, align 1
  %call28.481313 = call zeroext i8 @mult(i8 zeroext %459, i8 zeroext %460)
  %conv29.481314 = zext i8 %call28.481313 to i32
  %xor.481315 = xor i32 %conv23.481311, %conv29.481314
  %scevgep35.481316 = getelementptr i8, i8* %a, i64 49
  %461 = load i8, i8* %scevgep35.481316, align 1
  %462 = load i8, i8* %b, align 1
  %call34.481317 = call zeroext i8 @mult(i8 zeroext %461, i8 zeroext %462)
  %conv35.481318 = zext i8 %call34.481317 to i32
  %xor36.481319 = xor i32 %xor.481315, %conv35.481318
  %conv37.481320 = trunc i32 %xor36.481319 to i8
  store i8 %conv37.481320, i8* %scevgep41.471308, align 1
  %scevgep28.481321 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %456, i64 0, i64 0, i64 1
  %463 = bitcast i8* %scevgep28.481321 to [61 x [61 x i8]]*
  %scevgep41.481322 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %457, i64 0, i64 1, i64 0
  %464 = bitcast i8* %scevgep41.481322 to [61 x [61 x i8]]*
  %call16.491324 = call zeroext i8 (...) @rand()
  store i8 %call16.491324, i8* %scevgep28.481321, align 1
  %465 = load i8, i8* %scevgep28.481321, align 1
  %conv23.491325 = zext i8 %465 to i32
  %466 = load i8, i8* %a, align 1
  %scevgep34.491326 = getelementptr i8, i8* %b, i64 50
  %467 = load i8, i8* %scevgep34.491326, align 1
  %call28.491327 = call zeroext i8 @mult(i8 zeroext %466, i8 zeroext %467)
  %conv29.491328 = zext i8 %call28.491327 to i32
  %xor.491329 = xor i32 %conv23.491325, %conv29.491328
  %scevgep35.491330 = getelementptr i8, i8* %a, i64 50
  %468 = load i8, i8* %scevgep35.491330, align 1
  %469 = load i8, i8* %b, align 1
  %call34.491331 = call zeroext i8 @mult(i8 zeroext %468, i8 zeroext %469)
  %conv35.491332 = zext i8 %call34.491331 to i32
  %xor36.491333 = xor i32 %xor.491329, %conv35.491332
  %conv37.491334 = trunc i32 %xor36.491333 to i8
  store i8 %conv37.491334, i8* %scevgep41.481322, align 1
  %scevgep28.491335 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %463, i64 0, i64 0, i64 1
  %470 = bitcast i8* %scevgep28.491335 to [61 x [61 x i8]]*
  %scevgep41.491336 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %464, i64 0, i64 1, i64 0
  %471 = bitcast i8* %scevgep41.491336 to [61 x [61 x i8]]*
  %call16.501338 = call zeroext i8 (...) @rand()
  store i8 %call16.501338, i8* %scevgep28.491335, align 1
  %472 = load i8, i8* %scevgep28.491335, align 1
  %conv23.501339 = zext i8 %472 to i32
  %473 = load i8, i8* %a, align 1
  %scevgep34.501340 = getelementptr i8, i8* %b, i64 51
  %474 = load i8, i8* %scevgep34.501340, align 1
  %call28.501341 = call zeroext i8 @mult(i8 zeroext %473, i8 zeroext %474)
  %conv29.501342 = zext i8 %call28.501341 to i32
  %xor.501343 = xor i32 %conv23.501339, %conv29.501342
  %scevgep35.501344 = getelementptr i8, i8* %a, i64 51
  %475 = load i8, i8* %scevgep35.501344, align 1
  %476 = load i8, i8* %b, align 1
  %call34.501345 = call zeroext i8 @mult(i8 zeroext %475, i8 zeroext %476)
  %conv35.501346 = zext i8 %call34.501345 to i32
  %xor36.501347 = xor i32 %xor.501343, %conv35.501346
  %conv37.501348 = trunc i32 %xor36.501347 to i8
  store i8 %conv37.501348, i8* %scevgep41.491336, align 1
  %scevgep28.501349 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %470, i64 0, i64 0, i64 1
  %477 = bitcast i8* %scevgep28.501349 to [61 x [61 x i8]]*
  %scevgep41.501350 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %471, i64 0, i64 1, i64 0
  %478 = bitcast i8* %scevgep41.501350 to [61 x [61 x i8]]*
  %call16.511352 = call zeroext i8 (...) @rand()
  store i8 %call16.511352, i8* %scevgep28.501349, align 1
  %479 = load i8, i8* %scevgep28.501349, align 1
  %conv23.511353 = zext i8 %479 to i32
  %480 = load i8, i8* %a, align 1
  %scevgep34.511354 = getelementptr i8, i8* %b, i64 52
  %481 = load i8, i8* %scevgep34.511354, align 1
  %call28.511355 = call zeroext i8 @mult(i8 zeroext %480, i8 zeroext %481)
  %conv29.511356 = zext i8 %call28.511355 to i32
  %xor.511357 = xor i32 %conv23.511353, %conv29.511356
  %scevgep35.511358 = getelementptr i8, i8* %a, i64 52
  %482 = load i8, i8* %scevgep35.511358, align 1
  %483 = load i8, i8* %b, align 1
  %call34.511359 = call zeroext i8 @mult(i8 zeroext %482, i8 zeroext %483)
  %conv35.511360 = zext i8 %call34.511359 to i32
  %xor36.511361 = xor i32 %xor.511357, %conv35.511360
  %conv37.511362 = trunc i32 %xor36.511361 to i8
  store i8 %conv37.511362, i8* %scevgep41.501350, align 1
  %scevgep28.511363 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %477, i64 0, i64 0, i64 1
  %484 = bitcast i8* %scevgep28.511363 to [61 x [61 x i8]]*
  %scevgep41.511364 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %478, i64 0, i64 1, i64 0
  %485 = bitcast i8* %scevgep41.511364 to [61 x [61 x i8]]*
  %call16.521366 = call zeroext i8 (...) @rand()
  store i8 %call16.521366, i8* %scevgep28.511363, align 1
  %486 = load i8, i8* %scevgep28.511363, align 1
  %conv23.521367 = zext i8 %486 to i32
  %487 = load i8, i8* %a, align 1
  %scevgep34.521368 = getelementptr i8, i8* %b, i64 53
  %488 = load i8, i8* %scevgep34.521368, align 1
  %call28.521369 = call zeroext i8 @mult(i8 zeroext %487, i8 zeroext %488)
  %conv29.521370 = zext i8 %call28.521369 to i32
  %xor.521371 = xor i32 %conv23.521367, %conv29.521370
  %scevgep35.521372 = getelementptr i8, i8* %a, i64 53
  %489 = load i8, i8* %scevgep35.521372, align 1
  %490 = load i8, i8* %b, align 1
  %call34.521373 = call zeroext i8 @mult(i8 zeroext %489, i8 zeroext %490)
  %conv35.521374 = zext i8 %call34.521373 to i32
  %xor36.521375 = xor i32 %xor.521371, %conv35.521374
  %conv37.521376 = trunc i32 %xor36.521375 to i8
  store i8 %conv37.521376, i8* %scevgep41.511364, align 1
  %scevgep28.521377 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %484, i64 0, i64 0, i64 1
  %491 = bitcast i8* %scevgep28.521377 to [61 x [61 x i8]]*
  %scevgep41.521378 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %485, i64 0, i64 1, i64 0
  %492 = bitcast i8* %scevgep41.521378 to [61 x [61 x i8]]*
  %call16.531380 = call zeroext i8 (...) @rand()
  store i8 %call16.531380, i8* %scevgep28.521377, align 1
  %493 = load i8, i8* %scevgep28.521377, align 1
  %conv23.531381 = zext i8 %493 to i32
  %494 = load i8, i8* %a, align 1
  %scevgep34.531382 = getelementptr i8, i8* %b, i64 54
  %495 = load i8, i8* %scevgep34.531382, align 1
  %call28.531383 = call zeroext i8 @mult(i8 zeroext %494, i8 zeroext %495)
  %conv29.531384 = zext i8 %call28.531383 to i32
  %xor.531385 = xor i32 %conv23.531381, %conv29.531384
  %scevgep35.531386 = getelementptr i8, i8* %a, i64 54
  %496 = load i8, i8* %scevgep35.531386, align 1
  %497 = load i8, i8* %b, align 1
  %call34.531387 = call zeroext i8 @mult(i8 zeroext %496, i8 zeroext %497)
  %conv35.531388 = zext i8 %call34.531387 to i32
  %xor36.531389 = xor i32 %xor.531385, %conv35.531388
  %conv37.531390 = trunc i32 %xor36.531389 to i8
  store i8 %conv37.531390, i8* %scevgep41.521378, align 1
  %scevgep28.531391 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %491, i64 0, i64 0, i64 1
  %498 = bitcast i8* %scevgep28.531391 to [61 x [61 x i8]]*
  %scevgep41.531392 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %492, i64 0, i64 1, i64 0
  %499 = bitcast i8* %scevgep41.531392 to [61 x [61 x i8]]*
  %call16.541394 = call zeroext i8 (...) @rand()
  store i8 %call16.541394, i8* %scevgep28.531391, align 1
  %500 = load i8, i8* %scevgep28.531391, align 1
  %conv23.541395 = zext i8 %500 to i32
  %501 = load i8, i8* %a, align 1
  %scevgep34.541396 = getelementptr i8, i8* %b, i64 55
  %502 = load i8, i8* %scevgep34.541396, align 1
  %call28.541397 = call zeroext i8 @mult(i8 zeroext %501, i8 zeroext %502)
  %conv29.541398 = zext i8 %call28.541397 to i32
  %xor.541399 = xor i32 %conv23.541395, %conv29.541398
  %scevgep35.541400 = getelementptr i8, i8* %a, i64 55
  %503 = load i8, i8* %scevgep35.541400, align 1
  %504 = load i8, i8* %b, align 1
  %call34.541401 = call zeroext i8 @mult(i8 zeroext %503, i8 zeroext %504)
  %conv35.541402 = zext i8 %call34.541401 to i32
  %xor36.541403 = xor i32 %xor.541399, %conv35.541402
  %conv37.541404 = trunc i32 %xor36.541403 to i8
  store i8 %conv37.541404, i8* %scevgep41.531392, align 1
  %scevgep28.541405 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %498, i64 0, i64 0, i64 1
  %505 = bitcast i8* %scevgep28.541405 to [61 x [61 x i8]]*
  %scevgep41.541406 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %499, i64 0, i64 1, i64 0
  %506 = bitcast i8* %scevgep41.541406 to [61 x [61 x i8]]*
  %call16.551408 = call zeroext i8 (...) @rand()
  store i8 %call16.551408, i8* %scevgep28.541405, align 1
  %507 = load i8, i8* %scevgep28.541405, align 1
  %conv23.551409 = zext i8 %507 to i32
  %508 = load i8, i8* %a, align 1
  %scevgep34.551410 = getelementptr i8, i8* %b, i64 56
  %509 = load i8, i8* %scevgep34.551410, align 1
  %call28.551411 = call zeroext i8 @mult(i8 zeroext %508, i8 zeroext %509)
  %conv29.551412 = zext i8 %call28.551411 to i32
  %xor.551413 = xor i32 %conv23.551409, %conv29.551412
  %scevgep35.551414 = getelementptr i8, i8* %a, i64 56
  %510 = load i8, i8* %scevgep35.551414, align 1
  %511 = load i8, i8* %b, align 1
  %call34.551415 = call zeroext i8 @mult(i8 zeroext %510, i8 zeroext %511)
  %conv35.551416 = zext i8 %call34.551415 to i32
  %xor36.551417 = xor i32 %xor.551413, %conv35.551416
  %conv37.551418 = trunc i32 %xor36.551417 to i8
  store i8 %conv37.551418, i8* %scevgep41.541406, align 1
  %scevgep28.551419 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %505, i64 0, i64 0, i64 1
  %512 = bitcast i8* %scevgep28.551419 to [61 x [61 x i8]]*
  %scevgep41.551420 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %506, i64 0, i64 1, i64 0
  %513 = bitcast i8* %scevgep41.551420 to [61 x [61 x i8]]*
  %call16.561422 = call zeroext i8 (...) @rand()
  store i8 %call16.561422, i8* %scevgep28.551419, align 1
  %514 = load i8, i8* %scevgep28.551419, align 1
  %conv23.561423 = zext i8 %514 to i32
  %515 = load i8, i8* %a, align 1
  %scevgep34.561424 = getelementptr i8, i8* %b, i64 57
  %516 = load i8, i8* %scevgep34.561424, align 1
  %call28.561425 = call zeroext i8 @mult(i8 zeroext %515, i8 zeroext %516)
  %conv29.561426 = zext i8 %call28.561425 to i32
  %xor.561427 = xor i32 %conv23.561423, %conv29.561426
  %scevgep35.561428 = getelementptr i8, i8* %a, i64 57
  %517 = load i8, i8* %scevgep35.561428, align 1
  %518 = load i8, i8* %b, align 1
  %call34.561429 = call zeroext i8 @mult(i8 zeroext %517, i8 zeroext %518)
  %conv35.561430 = zext i8 %call34.561429 to i32
  %xor36.561431 = xor i32 %xor.561427, %conv35.561430
  %conv37.561432 = trunc i32 %xor36.561431 to i8
  store i8 %conv37.561432, i8* %scevgep41.551420, align 1
  %scevgep28.561433 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %512, i64 0, i64 0, i64 1
  %519 = bitcast i8* %scevgep28.561433 to [61 x [61 x i8]]*
  %scevgep41.561434 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %513, i64 0, i64 1, i64 0
  %520 = bitcast i8* %scevgep41.561434 to [61 x [61 x i8]]*
  %call16.571436 = call zeroext i8 (...) @rand()
  store i8 %call16.571436, i8* %scevgep28.561433, align 1
  %521 = load i8, i8* %scevgep28.561433, align 1
  %conv23.571437 = zext i8 %521 to i32
  %522 = load i8, i8* %a, align 1
  %scevgep34.571438 = getelementptr i8, i8* %b, i64 58
  %523 = load i8, i8* %scevgep34.571438, align 1
  %call28.571439 = call zeroext i8 @mult(i8 zeroext %522, i8 zeroext %523)
  %conv29.571440 = zext i8 %call28.571439 to i32
  %xor.571441 = xor i32 %conv23.571437, %conv29.571440
  %scevgep35.571442 = getelementptr i8, i8* %a, i64 58
  %524 = load i8, i8* %scevgep35.571442, align 1
  %525 = load i8, i8* %b, align 1
  %call34.571443 = call zeroext i8 @mult(i8 zeroext %524, i8 zeroext %525)
  %conv35.571444 = zext i8 %call34.571443 to i32
  %xor36.571445 = xor i32 %xor.571441, %conv35.571444
  %conv37.571446 = trunc i32 %xor36.571445 to i8
  store i8 %conv37.571446, i8* %scevgep41.561434, align 1
  %scevgep28.571447 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %519, i64 0, i64 0, i64 1
  %526 = bitcast i8* %scevgep28.571447 to [61 x [61 x i8]]*
  %scevgep41.571448 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %520, i64 0, i64 1, i64 0
  %527 = bitcast i8* %scevgep41.571448 to [61 x [61 x i8]]*
  %call16.581450 = call zeroext i8 (...) @rand()
  store i8 %call16.581450, i8* %scevgep28.571447, align 1
  %528 = load i8, i8* %scevgep28.571447, align 1
  %conv23.581451 = zext i8 %528 to i32
  %529 = load i8, i8* %a, align 1
  %scevgep34.581452 = getelementptr i8, i8* %b, i64 59
  %530 = load i8, i8* %scevgep34.581452, align 1
  %call28.581453 = call zeroext i8 @mult(i8 zeroext %529, i8 zeroext %530)
  %conv29.581454 = zext i8 %call28.581453 to i32
  %xor.581455 = xor i32 %conv23.581451, %conv29.581454
  %scevgep35.581456 = getelementptr i8, i8* %a, i64 59
  %531 = load i8, i8* %scevgep35.581456, align 1
  %532 = load i8, i8* %b, align 1
  %call34.581457 = call zeroext i8 @mult(i8 zeroext %531, i8 zeroext %532)
  %conv35.581458 = zext i8 %call34.581457 to i32
  %xor36.581459 = xor i32 %xor.581455, %conv35.581458
  %conv37.581460 = trunc i32 %xor36.581459 to i8
  store i8 %conv37.581460, i8* %scevgep41.571448, align 1
  %scevgep28.581461 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %526, i64 0, i64 0, i64 1
  %scevgep41.581462 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %527, i64 0, i64 1, i64 0
  %call16.591464 = call zeroext i8 (...) @rand()
  store i8 %call16.591464, i8* %scevgep28.581461, align 1
  %533 = load i8, i8* %scevgep28.581461, align 1
  %conv23.591465 = zext i8 %533 to i32
  %534 = load i8, i8* %a, align 1
  %scevgep34.591466 = getelementptr i8, i8* %b, i64 60
  %535 = load i8, i8* %scevgep34.591466, align 1
  %call28.591467 = call zeroext i8 @mult(i8 zeroext %534, i8 zeroext %535)
  %conv29.591468 = zext i8 %call28.591467 to i32
  %xor.591469 = xor i32 %conv23.591465, %conv29.591468
  %scevgep35.591470 = getelementptr i8, i8* %a, i64 60
  %536 = load i8, i8* %scevgep35.591470, align 1
  %537 = load i8, i8* %b, align 1
  %call34.591471 = call zeroext i8 @mult(i8 zeroext %536, i8 zeroext %537)
  %conv35.591472 = zext i8 %call34.591471 to i32
  %xor36.591473 = xor i32 %xor.591469, %conv35.591472
  %conv37.591474 = trunc i32 %xor36.591473 to i8
  store i8 %conv37.591474, i8* %scevgep41.581462, align 1
  %scevgep26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %scevgep2324, i64 0, i64 1, i64 1
  %538 = bitcast i8* %scevgep26 to [61 x [61 x i8]]*
  %scevgep39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %scevgep3637, i64 0, i64 1, i64 1
  %539 = bitcast i8* %scevgep39 to [61 x [61 x i8]]*
  %arrayidx25.1 = getelementptr inbounds i8, i8* %a, i64 1
  %arrayidx33.1 = getelementptr inbounds i8, i8* %b, i64 1
  %call16.1 = call zeroext i8 (...) @rand()
  store i8 %call16.1, i8* %scevgep26, align 1
  %540 = load i8, i8* %scevgep26, align 1
  %conv23.1 = zext i8 %540 to i32
  %541 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1 = getelementptr i8, i8* %b, i64 2
  %542 = load i8, i8* %scevgep34.1, align 1
  %call28.1 = call zeroext i8 @mult(i8 zeroext %541, i8 zeroext %542)
  %conv29.1 = zext i8 %call28.1 to i32
  %xor.1 = xor i32 %conv23.1, %conv29.1
  %scevgep35.1 = getelementptr i8, i8* %a, i64 2
  %543 = load i8, i8* %scevgep35.1, align 1
  %544 = load i8, i8* %arrayidx33.1, align 1
  %call34.1 = call zeroext i8 @mult(i8 zeroext %543, i8 zeroext %544)
  %conv35.1 = zext i8 %call34.1 to i32
  %xor36.1 = xor i32 %xor.1, %conv35.1
  %conv37.1 = trunc i32 %xor36.1 to i8
  store i8 %conv37.1, i8* %scevgep39, align 1
  %scevgep28.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %538, i64 0, i64 0, i64 1
  %545 = bitcast i8* %scevgep28.1 to [61 x [61 x i8]]*
  %scevgep41.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %539, i64 0, i64 1, i64 0
  %546 = bitcast i8* %scevgep41.1 to [61 x [61 x i8]]*
  %call16.1.1 = call zeroext i8 (...) @rand()
  store i8 %call16.1.1, i8* %scevgep28.1, align 1
  %547 = load i8, i8* %scevgep28.1, align 1
  %conv23.1.1 = zext i8 %547 to i32
  %548 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.1 = getelementptr i8, i8* %b, i64 3
  %549 = load i8, i8* %scevgep34.1.1, align 1
  %call28.1.1 = call zeroext i8 @mult(i8 zeroext %548, i8 zeroext %549)
  %conv29.1.1 = zext i8 %call28.1.1 to i32
  %xor.1.1 = xor i32 %conv23.1.1, %conv29.1.1
  %scevgep35.1.1 = getelementptr i8, i8* %a, i64 3
  %550 = load i8, i8* %scevgep35.1.1, align 1
  %551 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.1 = call zeroext i8 @mult(i8 zeroext %550, i8 zeroext %551)
  %conv35.1.1 = zext i8 %call34.1.1 to i32
  %xor36.1.1 = xor i32 %xor.1.1, %conv35.1.1
  %conv37.1.1 = trunc i32 %xor36.1.1 to i8
  store i8 %conv37.1.1, i8* %scevgep41.1, align 1
  %scevgep28.1.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %545, i64 0, i64 0, i64 1
  %552 = bitcast i8* %scevgep28.1.1 to [61 x [61 x i8]]*
  %scevgep41.1.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %546, i64 0, i64 1, i64 0
  %553 = bitcast i8* %scevgep41.1.1 to [61 x [61 x i8]]*
  %call16.1.2 = call zeroext i8 (...) @rand()
  store i8 %call16.1.2, i8* %scevgep28.1.1, align 1
  %554 = load i8, i8* %scevgep28.1.1, align 1
  %conv23.1.2 = zext i8 %554 to i32
  %555 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.2 = getelementptr i8, i8* %b, i64 4
  %556 = load i8, i8* %scevgep34.1.2, align 1
  %call28.1.2 = call zeroext i8 @mult(i8 zeroext %555, i8 zeroext %556)
  %conv29.1.2 = zext i8 %call28.1.2 to i32
  %xor.1.2 = xor i32 %conv23.1.2, %conv29.1.2
  %scevgep35.1.2 = getelementptr i8, i8* %a, i64 4
  %557 = load i8, i8* %scevgep35.1.2, align 1
  %558 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.2 = call zeroext i8 @mult(i8 zeroext %557, i8 zeroext %558)
  %conv35.1.2 = zext i8 %call34.1.2 to i32
  %xor36.1.2 = xor i32 %xor.1.2, %conv35.1.2
  %conv37.1.2 = trunc i32 %xor36.1.2 to i8
  store i8 %conv37.1.2, i8* %scevgep41.1.1, align 1
  %scevgep28.1.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %552, i64 0, i64 0, i64 1
  %559 = bitcast i8* %scevgep28.1.2 to [61 x [61 x i8]]*
  %scevgep41.1.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %553, i64 0, i64 1, i64 0
  %560 = bitcast i8* %scevgep41.1.2 to [61 x [61 x i8]]*
  %call16.1.3 = call zeroext i8 (...) @rand()
  store i8 %call16.1.3, i8* %scevgep28.1.2, align 1
  %561 = load i8, i8* %scevgep28.1.2, align 1
  %conv23.1.3 = zext i8 %561 to i32
  %562 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.3 = getelementptr i8, i8* %b, i64 5
  %563 = load i8, i8* %scevgep34.1.3, align 1
  %call28.1.3 = call zeroext i8 @mult(i8 zeroext %562, i8 zeroext %563)
  %conv29.1.3 = zext i8 %call28.1.3 to i32
  %xor.1.3 = xor i32 %conv23.1.3, %conv29.1.3
  %scevgep35.1.3 = getelementptr i8, i8* %a, i64 5
  %564 = load i8, i8* %scevgep35.1.3, align 1
  %565 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.3 = call zeroext i8 @mult(i8 zeroext %564, i8 zeroext %565)
  %conv35.1.3 = zext i8 %call34.1.3 to i32
  %xor36.1.3 = xor i32 %xor.1.3, %conv35.1.3
  %conv37.1.3 = trunc i32 %xor36.1.3 to i8
  store i8 %conv37.1.3, i8* %scevgep41.1.2, align 1
  %scevgep28.1.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %559, i64 0, i64 0, i64 1
  %566 = bitcast i8* %scevgep28.1.3 to [61 x [61 x i8]]*
  %scevgep41.1.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %560, i64 0, i64 1, i64 0
  %567 = bitcast i8* %scevgep41.1.3 to [61 x [61 x i8]]*
  %call16.1.4 = call zeroext i8 (...) @rand()
  store i8 %call16.1.4, i8* %scevgep28.1.3, align 1
  %568 = load i8, i8* %scevgep28.1.3, align 1
  %conv23.1.4 = zext i8 %568 to i32
  %569 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.4 = getelementptr i8, i8* %b, i64 6
  %570 = load i8, i8* %scevgep34.1.4, align 1
  %call28.1.4 = call zeroext i8 @mult(i8 zeroext %569, i8 zeroext %570)
  %conv29.1.4 = zext i8 %call28.1.4 to i32
  %xor.1.4 = xor i32 %conv23.1.4, %conv29.1.4
  %scevgep35.1.4 = getelementptr i8, i8* %a, i64 6
  %571 = load i8, i8* %scevgep35.1.4, align 1
  %572 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.4 = call zeroext i8 @mult(i8 zeroext %571, i8 zeroext %572)
  %conv35.1.4 = zext i8 %call34.1.4 to i32
  %xor36.1.4 = xor i32 %xor.1.4, %conv35.1.4
  %conv37.1.4 = trunc i32 %xor36.1.4 to i8
  store i8 %conv37.1.4, i8* %scevgep41.1.3, align 1
  %scevgep28.1.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %566, i64 0, i64 0, i64 1
  %573 = bitcast i8* %scevgep28.1.4 to [61 x [61 x i8]]*
  %scevgep41.1.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %567, i64 0, i64 1, i64 0
  %574 = bitcast i8* %scevgep41.1.4 to [61 x [61 x i8]]*
  %call16.1.5 = call zeroext i8 (...) @rand()
  store i8 %call16.1.5, i8* %scevgep28.1.4, align 1
  %575 = load i8, i8* %scevgep28.1.4, align 1
  %conv23.1.5 = zext i8 %575 to i32
  %576 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.5 = getelementptr i8, i8* %b, i64 7
  %577 = load i8, i8* %scevgep34.1.5, align 1
  %call28.1.5 = call zeroext i8 @mult(i8 zeroext %576, i8 zeroext %577)
  %conv29.1.5 = zext i8 %call28.1.5 to i32
  %xor.1.5 = xor i32 %conv23.1.5, %conv29.1.5
  %scevgep35.1.5 = getelementptr i8, i8* %a, i64 7
  %578 = load i8, i8* %scevgep35.1.5, align 1
  %579 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.5 = call zeroext i8 @mult(i8 zeroext %578, i8 zeroext %579)
  %conv35.1.5 = zext i8 %call34.1.5 to i32
  %xor36.1.5 = xor i32 %xor.1.5, %conv35.1.5
  %conv37.1.5 = trunc i32 %xor36.1.5 to i8
  store i8 %conv37.1.5, i8* %scevgep41.1.4, align 1
  %scevgep28.1.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %573, i64 0, i64 0, i64 1
  %580 = bitcast i8* %scevgep28.1.5 to [61 x [61 x i8]]*
  %scevgep41.1.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %574, i64 0, i64 1, i64 0
  %581 = bitcast i8* %scevgep41.1.5 to [61 x [61 x i8]]*
  %call16.1.6 = call zeroext i8 (...) @rand()
  store i8 %call16.1.6, i8* %scevgep28.1.5, align 1
  %582 = load i8, i8* %scevgep28.1.5, align 1
  %conv23.1.6 = zext i8 %582 to i32
  %583 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.6 = getelementptr i8, i8* %b, i64 8
  %584 = load i8, i8* %scevgep34.1.6, align 1
  %call28.1.6 = call zeroext i8 @mult(i8 zeroext %583, i8 zeroext %584)
  %conv29.1.6 = zext i8 %call28.1.6 to i32
  %xor.1.6 = xor i32 %conv23.1.6, %conv29.1.6
  %scevgep35.1.6 = getelementptr i8, i8* %a, i64 8
  %585 = load i8, i8* %scevgep35.1.6, align 1
  %586 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.6 = call zeroext i8 @mult(i8 zeroext %585, i8 zeroext %586)
  %conv35.1.6 = zext i8 %call34.1.6 to i32
  %xor36.1.6 = xor i32 %xor.1.6, %conv35.1.6
  %conv37.1.6 = trunc i32 %xor36.1.6 to i8
  store i8 %conv37.1.6, i8* %scevgep41.1.5, align 1
  %scevgep28.1.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %580, i64 0, i64 0, i64 1
  %587 = bitcast i8* %scevgep28.1.6 to [61 x [61 x i8]]*
  %scevgep41.1.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %581, i64 0, i64 1, i64 0
  %588 = bitcast i8* %scevgep41.1.6 to [61 x [61 x i8]]*
  %call16.1.7 = call zeroext i8 (...) @rand()
  store i8 %call16.1.7, i8* %scevgep28.1.6, align 1
  %589 = load i8, i8* %scevgep28.1.6, align 1
  %conv23.1.7 = zext i8 %589 to i32
  %590 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.7 = getelementptr i8, i8* %b, i64 9
  %591 = load i8, i8* %scevgep34.1.7, align 1
  %call28.1.7 = call zeroext i8 @mult(i8 zeroext %590, i8 zeroext %591)
  %conv29.1.7 = zext i8 %call28.1.7 to i32
  %xor.1.7 = xor i32 %conv23.1.7, %conv29.1.7
  %scevgep35.1.7 = getelementptr i8, i8* %a, i64 9
  %592 = load i8, i8* %scevgep35.1.7, align 1
  %593 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.7 = call zeroext i8 @mult(i8 zeroext %592, i8 zeroext %593)
  %conv35.1.7 = zext i8 %call34.1.7 to i32
  %xor36.1.7 = xor i32 %xor.1.7, %conv35.1.7
  %conv37.1.7 = trunc i32 %xor36.1.7 to i8
  store i8 %conv37.1.7, i8* %scevgep41.1.6, align 1
  %scevgep28.1.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %587, i64 0, i64 0, i64 1
  %594 = bitcast i8* %scevgep28.1.7 to [61 x [61 x i8]]*
  %scevgep41.1.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %588, i64 0, i64 1, i64 0
  %595 = bitcast i8* %scevgep41.1.7 to [61 x [61 x i8]]*
  %call16.1.8 = call zeroext i8 (...) @rand()
  store i8 %call16.1.8, i8* %scevgep28.1.7, align 1
  %596 = load i8, i8* %scevgep28.1.7, align 1
  %conv23.1.8 = zext i8 %596 to i32
  %597 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.8 = getelementptr i8, i8* %b, i64 10
  %598 = load i8, i8* %scevgep34.1.8, align 1
  %call28.1.8 = call zeroext i8 @mult(i8 zeroext %597, i8 zeroext %598)
  %conv29.1.8 = zext i8 %call28.1.8 to i32
  %xor.1.8 = xor i32 %conv23.1.8, %conv29.1.8
  %scevgep35.1.8 = getelementptr i8, i8* %a, i64 10
  %599 = load i8, i8* %scevgep35.1.8, align 1
  %600 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.8 = call zeroext i8 @mult(i8 zeroext %599, i8 zeroext %600)
  %conv35.1.8 = zext i8 %call34.1.8 to i32
  %xor36.1.8 = xor i32 %xor.1.8, %conv35.1.8
  %conv37.1.8 = trunc i32 %xor36.1.8 to i8
  store i8 %conv37.1.8, i8* %scevgep41.1.7, align 1
  %scevgep28.1.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %594, i64 0, i64 0, i64 1
  %601 = bitcast i8* %scevgep28.1.8 to [61 x [61 x i8]]*
  %scevgep41.1.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %595, i64 0, i64 1, i64 0
  %602 = bitcast i8* %scevgep41.1.8 to [61 x [61 x i8]]*
  %call16.1.9 = call zeroext i8 (...) @rand()
  store i8 %call16.1.9, i8* %scevgep28.1.8, align 1
  %603 = load i8, i8* %scevgep28.1.8, align 1
  %conv23.1.9 = zext i8 %603 to i32
  %604 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.9 = getelementptr i8, i8* %b, i64 11
  %605 = load i8, i8* %scevgep34.1.9, align 1
  %call28.1.9 = call zeroext i8 @mult(i8 zeroext %604, i8 zeroext %605)
  %conv29.1.9 = zext i8 %call28.1.9 to i32
  %xor.1.9 = xor i32 %conv23.1.9, %conv29.1.9
  %scevgep35.1.9 = getelementptr i8, i8* %a, i64 11
  %606 = load i8, i8* %scevgep35.1.9, align 1
  %607 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.9 = call zeroext i8 @mult(i8 zeroext %606, i8 zeroext %607)
  %conv35.1.9 = zext i8 %call34.1.9 to i32
  %xor36.1.9 = xor i32 %xor.1.9, %conv35.1.9
  %conv37.1.9 = trunc i32 %xor36.1.9 to i8
  store i8 %conv37.1.9, i8* %scevgep41.1.8, align 1
  %scevgep28.1.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %601, i64 0, i64 0, i64 1
  %608 = bitcast i8* %scevgep28.1.9 to [61 x [61 x i8]]*
  %scevgep41.1.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %602, i64 0, i64 1, i64 0
  %609 = bitcast i8* %scevgep41.1.9 to [61 x [61 x i8]]*
  %call16.1.10 = call zeroext i8 (...) @rand()
  store i8 %call16.1.10, i8* %scevgep28.1.9, align 1
  %610 = load i8, i8* %scevgep28.1.9, align 1
  %conv23.1.10 = zext i8 %610 to i32
  %611 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.10 = getelementptr i8, i8* %b, i64 12
  %612 = load i8, i8* %scevgep34.1.10, align 1
  %call28.1.10 = call zeroext i8 @mult(i8 zeroext %611, i8 zeroext %612)
  %conv29.1.10 = zext i8 %call28.1.10 to i32
  %xor.1.10 = xor i32 %conv23.1.10, %conv29.1.10
  %scevgep35.1.10 = getelementptr i8, i8* %a, i64 12
  %613 = load i8, i8* %scevgep35.1.10, align 1
  %614 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.10 = call zeroext i8 @mult(i8 zeroext %613, i8 zeroext %614)
  %conv35.1.10 = zext i8 %call34.1.10 to i32
  %xor36.1.10 = xor i32 %xor.1.10, %conv35.1.10
  %conv37.1.10 = trunc i32 %xor36.1.10 to i8
  store i8 %conv37.1.10, i8* %scevgep41.1.9, align 1
  %scevgep28.1.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %608, i64 0, i64 0, i64 1
  %615 = bitcast i8* %scevgep28.1.10 to [61 x [61 x i8]]*
  %scevgep41.1.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %609, i64 0, i64 1, i64 0
  %616 = bitcast i8* %scevgep41.1.10 to [61 x [61 x i8]]*
  %call16.1.11 = call zeroext i8 (...) @rand()
  store i8 %call16.1.11, i8* %scevgep28.1.10, align 1
  %617 = load i8, i8* %scevgep28.1.10, align 1
  %conv23.1.11 = zext i8 %617 to i32
  %618 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.11 = getelementptr i8, i8* %b, i64 13
  %619 = load i8, i8* %scevgep34.1.11, align 1
  %call28.1.11 = call zeroext i8 @mult(i8 zeroext %618, i8 zeroext %619)
  %conv29.1.11 = zext i8 %call28.1.11 to i32
  %xor.1.11 = xor i32 %conv23.1.11, %conv29.1.11
  %scevgep35.1.11 = getelementptr i8, i8* %a, i64 13
  %620 = load i8, i8* %scevgep35.1.11, align 1
  %621 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.11 = call zeroext i8 @mult(i8 zeroext %620, i8 zeroext %621)
  %conv35.1.11 = zext i8 %call34.1.11 to i32
  %xor36.1.11 = xor i32 %xor.1.11, %conv35.1.11
  %conv37.1.11 = trunc i32 %xor36.1.11 to i8
  store i8 %conv37.1.11, i8* %scevgep41.1.10, align 1
  %scevgep28.1.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %615, i64 0, i64 0, i64 1
  %622 = bitcast i8* %scevgep28.1.11 to [61 x [61 x i8]]*
  %scevgep41.1.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %616, i64 0, i64 1, i64 0
  %623 = bitcast i8* %scevgep41.1.11 to [61 x [61 x i8]]*
  %call16.1.12 = call zeroext i8 (...) @rand()
  store i8 %call16.1.12, i8* %scevgep28.1.11, align 1
  %624 = load i8, i8* %scevgep28.1.11, align 1
  %conv23.1.12 = zext i8 %624 to i32
  %625 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.12 = getelementptr i8, i8* %b, i64 14
  %626 = load i8, i8* %scevgep34.1.12, align 1
  %call28.1.12 = call zeroext i8 @mult(i8 zeroext %625, i8 zeroext %626)
  %conv29.1.12 = zext i8 %call28.1.12 to i32
  %xor.1.12 = xor i32 %conv23.1.12, %conv29.1.12
  %scevgep35.1.12 = getelementptr i8, i8* %a, i64 14
  %627 = load i8, i8* %scevgep35.1.12, align 1
  %628 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.12 = call zeroext i8 @mult(i8 zeroext %627, i8 zeroext %628)
  %conv35.1.12 = zext i8 %call34.1.12 to i32
  %xor36.1.12 = xor i32 %xor.1.12, %conv35.1.12
  %conv37.1.12 = trunc i32 %xor36.1.12 to i8
  store i8 %conv37.1.12, i8* %scevgep41.1.11, align 1
  %scevgep28.1.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %622, i64 0, i64 0, i64 1
  %629 = bitcast i8* %scevgep28.1.12 to [61 x [61 x i8]]*
  %scevgep41.1.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %623, i64 0, i64 1, i64 0
  %630 = bitcast i8* %scevgep41.1.12 to [61 x [61 x i8]]*
  %call16.1.13 = call zeroext i8 (...) @rand()
  store i8 %call16.1.13, i8* %scevgep28.1.12, align 1
  %631 = load i8, i8* %scevgep28.1.12, align 1
  %conv23.1.13 = zext i8 %631 to i32
  %632 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.13 = getelementptr i8, i8* %b, i64 15
  %633 = load i8, i8* %scevgep34.1.13, align 1
  %call28.1.13 = call zeroext i8 @mult(i8 zeroext %632, i8 zeroext %633)
  %conv29.1.13 = zext i8 %call28.1.13 to i32
  %xor.1.13 = xor i32 %conv23.1.13, %conv29.1.13
  %scevgep35.1.13 = getelementptr i8, i8* %a, i64 15
  %634 = load i8, i8* %scevgep35.1.13, align 1
  %635 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.13 = call zeroext i8 @mult(i8 zeroext %634, i8 zeroext %635)
  %conv35.1.13 = zext i8 %call34.1.13 to i32
  %xor36.1.13 = xor i32 %xor.1.13, %conv35.1.13
  %conv37.1.13 = trunc i32 %xor36.1.13 to i8
  store i8 %conv37.1.13, i8* %scevgep41.1.12, align 1
  %scevgep28.1.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %629, i64 0, i64 0, i64 1
  %636 = bitcast i8* %scevgep28.1.13 to [61 x [61 x i8]]*
  %scevgep41.1.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %630, i64 0, i64 1, i64 0
  %637 = bitcast i8* %scevgep41.1.13 to [61 x [61 x i8]]*
  %call16.1.14 = call zeroext i8 (...) @rand()
  store i8 %call16.1.14, i8* %scevgep28.1.13, align 1
  %638 = load i8, i8* %scevgep28.1.13, align 1
  %conv23.1.14 = zext i8 %638 to i32
  %639 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.14 = getelementptr i8, i8* %b, i64 16
  %640 = load i8, i8* %scevgep34.1.14, align 1
  %call28.1.14 = call zeroext i8 @mult(i8 zeroext %639, i8 zeroext %640)
  %conv29.1.14 = zext i8 %call28.1.14 to i32
  %xor.1.14 = xor i32 %conv23.1.14, %conv29.1.14
  %scevgep35.1.14 = getelementptr i8, i8* %a, i64 16
  %641 = load i8, i8* %scevgep35.1.14, align 1
  %642 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.14 = call zeroext i8 @mult(i8 zeroext %641, i8 zeroext %642)
  %conv35.1.14 = zext i8 %call34.1.14 to i32
  %xor36.1.14 = xor i32 %xor.1.14, %conv35.1.14
  %conv37.1.14 = trunc i32 %xor36.1.14 to i8
  store i8 %conv37.1.14, i8* %scevgep41.1.13, align 1
  %scevgep28.1.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %636, i64 0, i64 0, i64 1
  %643 = bitcast i8* %scevgep28.1.14 to [61 x [61 x i8]]*
  %scevgep41.1.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %637, i64 0, i64 1, i64 0
  %644 = bitcast i8* %scevgep41.1.14 to [61 x [61 x i8]]*
  %call16.1.15 = call zeroext i8 (...) @rand()
  store i8 %call16.1.15, i8* %scevgep28.1.14, align 1
  %645 = load i8, i8* %scevgep28.1.14, align 1
  %conv23.1.15 = zext i8 %645 to i32
  %646 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.15 = getelementptr i8, i8* %b, i64 17
  %647 = load i8, i8* %scevgep34.1.15, align 1
  %call28.1.15 = call zeroext i8 @mult(i8 zeroext %646, i8 zeroext %647)
  %conv29.1.15 = zext i8 %call28.1.15 to i32
  %xor.1.15 = xor i32 %conv23.1.15, %conv29.1.15
  %scevgep35.1.15 = getelementptr i8, i8* %a, i64 17
  %648 = load i8, i8* %scevgep35.1.15, align 1
  %649 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.15 = call zeroext i8 @mult(i8 zeroext %648, i8 zeroext %649)
  %conv35.1.15 = zext i8 %call34.1.15 to i32
  %xor36.1.15 = xor i32 %xor.1.15, %conv35.1.15
  %conv37.1.15 = trunc i32 %xor36.1.15 to i8
  store i8 %conv37.1.15, i8* %scevgep41.1.14, align 1
  %scevgep28.1.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %643, i64 0, i64 0, i64 1
  %650 = bitcast i8* %scevgep28.1.15 to [61 x [61 x i8]]*
  %scevgep41.1.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %644, i64 0, i64 1, i64 0
  %651 = bitcast i8* %scevgep41.1.15 to [61 x [61 x i8]]*
  %call16.1.16 = call zeroext i8 (...) @rand()
  store i8 %call16.1.16, i8* %scevgep28.1.15, align 1
  %652 = load i8, i8* %scevgep28.1.15, align 1
  %conv23.1.16 = zext i8 %652 to i32
  %653 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.16 = getelementptr i8, i8* %b, i64 18
  %654 = load i8, i8* %scevgep34.1.16, align 1
  %call28.1.16 = call zeroext i8 @mult(i8 zeroext %653, i8 zeroext %654)
  %conv29.1.16 = zext i8 %call28.1.16 to i32
  %xor.1.16 = xor i32 %conv23.1.16, %conv29.1.16
  %scevgep35.1.16 = getelementptr i8, i8* %a, i64 18
  %655 = load i8, i8* %scevgep35.1.16, align 1
  %656 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.16 = call zeroext i8 @mult(i8 zeroext %655, i8 zeroext %656)
  %conv35.1.16 = zext i8 %call34.1.16 to i32
  %xor36.1.16 = xor i32 %xor.1.16, %conv35.1.16
  %conv37.1.16 = trunc i32 %xor36.1.16 to i8
  store i8 %conv37.1.16, i8* %scevgep41.1.15, align 1
  %scevgep28.1.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %650, i64 0, i64 0, i64 1
  %657 = bitcast i8* %scevgep28.1.16 to [61 x [61 x i8]]*
  %scevgep41.1.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %651, i64 0, i64 1, i64 0
  %658 = bitcast i8* %scevgep41.1.16 to [61 x [61 x i8]]*
  %call16.1.17 = call zeroext i8 (...) @rand()
  store i8 %call16.1.17, i8* %scevgep28.1.16, align 1
  %659 = load i8, i8* %scevgep28.1.16, align 1
  %conv23.1.17 = zext i8 %659 to i32
  %660 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.17 = getelementptr i8, i8* %b, i64 19
  %661 = load i8, i8* %scevgep34.1.17, align 1
  %call28.1.17 = call zeroext i8 @mult(i8 zeroext %660, i8 zeroext %661)
  %conv29.1.17 = zext i8 %call28.1.17 to i32
  %xor.1.17 = xor i32 %conv23.1.17, %conv29.1.17
  %scevgep35.1.17 = getelementptr i8, i8* %a, i64 19
  %662 = load i8, i8* %scevgep35.1.17, align 1
  %663 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.17 = call zeroext i8 @mult(i8 zeroext %662, i8 zeroext %663)
  %conv35.1.17 = zext i8 %call34.1.17 to i32
  %xor36.1.17 = xor i32 %xor.1.17, %conv35.1.17
  %conv37.1.17 = trunc i32 %xor36.1.17 to i8
  store i8 %conv37.1.17, i8* %scevgep41.1.16, align 1
  %scevgep28.1.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %657, i64 0, i64 0, i64 1
  %664 = bitcast i8* %scevgep28.1.17 to [61 x [61 x i8]]*
  %scevgep41.1.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %658, i64 0, i64 1, i64 0
  %665 = bitcast i8* %scevgep41.1.17 to [61 x [61 x i8]]*
  %call16.1.18 = call zeroext i8 (...) @rand()
  store i8 %call16.1.18, i8* %scevgep28.1.17, align 1
  %666 = load i8, i8* %scevgep28.1.17, align 1
  %conv23.1.18 = zext i8 %666 to i32
  %667 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.18 = getelementptr i8, i8* %b, i64 20
  %668 = load i8, i8* %scevgep34.1.18, align 1
  %call28.1.18 = call zeroext i8 @mult(i8 zeroext %667, i8 zeroext %668)
  %conv29.1.18 = zext i8 %call28.1.18 to i32
  %xor.1.18 = xor i32 %conv23.1.18, %conv29.1.18
  %scevgep35.1.18 = getelementptr i8, i8* %a, i64 20
  %669 = load i8, i8* %scevgep35.1.18, align 1
  %670 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.18 = call zeroext i8 @mult(i8 zeroext %669, i8 zeroext %670)
  %conv35.1.18 = zext i8 %call34.1.18 to i32
  %xor36.1.18 = xor i32 %xor.1.18, %conv35.1.18
  %conv37.1.18 = trunc i32 %xor36.1.18 to i8
  store i8 %conv37.1.18, i8* %scevgep41.1.17, align 1
  %scevgep28.1.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %664, i64 0, i64 0, i64 1
  %671 = bitcast i8* %scevgep28.1.18 to [61 x [61 x i8]]*
  %scevgep41.1.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %665, i64 0, i64 1, i64 0
  %672 = bitcast i8* %scevgep41.1.18 to [61 x [61 x i8]]*
  %call16.1.19 = call zeroext i8 (...) @rand()
  store i8 %call16.1.19, i8* %scevgep28.1.18, align 1
  %673 = load i8, i8* %scevgep28.1.18, align 1
  %conv23.1.19 = zext i8 %673 to i32
  %674 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.19 = getelementptr i8, i8* %b, i64 21
  %675 = load i8, i8* %scevgep34.1.19, align 1
  %call28.1.19 = call zeroext i8 @mult(i8 zeroext %674, i8 zeroext %675)
  %conv29.1.19 = zext i8 %call28.1.19 to i32
  %xor.1.19 = xor i32 %conv23.1.19, %conv29.1.19
  %scevgep35.1.19 = getelementptr i8, i8* %a, i64 21
  %676 = load i8, i8* %scevgep35.1.19, align 1
  %677 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.19 = call zeroext i8 @mult(i8 zeroext %676, i8 zeroext %677)
  %conv35.1.19 = zext i8 %call34.1.19 to i32
  %xor36.1.19 = xor i32 %xor.1.19, %conv35.1.19
  %conv37.1.19 = trunc i32 %xor36.1.19 to i8
  store i8 %conv37.1.19, i8* %scevgep41.1.18, align 1
  %scevgep28.1.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %671, i64 0, i64 0, i64 1
  %678 = bitcast i8* %scevgep28.1.19 to [61 x [61 x i8]]*
  %scevgep41.1.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %672, i64 0, i64 1, i64 0
  %679 = bitcast i8* %scevgep41.1.19 to [61 x [61 x i8]]*
  %call16.1.20 = call zeroext i8 (...) @rand()
  store i8 %call16.1.20, i8* %scevgep28.1.19, align 1
  %680 = load i8, i8* %scevgep28.1.19, align 1
  %conv23.1.20 = zext i8 %680 to i32
  %681 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.20 = getelementptr i8, i8* %b, i64 22
  %682 = load i8, i8* %scevgep34.1.20, align 1
  %call28.1.20 = call zeroext i8 @mult(i8 zeroext %681, i8 zeroext %682)
  %conv29.1.20 = zext i8 %call28.1.20 to i32
  %xor.1.20 = xor i32 %conv23.1.20, %conv29.1.20
  %scevgep35.1.20 = getelementptr i8, i8* %a, i64 22
  %683 = load i8, i8* %scevgep35.1.20, align 1
  %684 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.20 = call zeroext i8 @mult(i8 zeroext %683, i8 zeroext %684)
  %conv35.1.20 = zext i8 %call34.1.20 to i32
  %xor36.1.20 = xor i32 %xor.1.20, %conv35.1.20
  %conv37.1.20 = trunc i32 %xor36.1.20 to i8
  store i8 %conv37.1.20, i8* %scevgep41.1.19, align 1
  %scevgep28.1.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %678, i64 0, i64 0, i64 1
  %685 = bitcast i8* %scevgep28.1.20 to [61 x [61 x i8]]*
  %scevgep41.1.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %679, i64 0, i64 1, i64 0
  %686 = bitcast i8* %scevgep41.1.20 to [61 x [61 x i8]]*
  %call16.1.21 = call zeroext i8 (...) @rand()
  store i8 %call16.1.21, i8* %scevgep28.1.20, align 1
  %687 = load i8, i8* %scevgep28.1.20, align 1
  %conv23.1.21 = zext i8 %687 to i32
  %688 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.21 = getelementptr i8, i8* %b, i64 23
  %689 = load i8, i8* %scevgep34.1.21, align 1
  %call28.1.21 = call zeroext i8 @mult(i8 zeroext %688, i8 zeroext %689)
  %conv29.1.21 = zext i8 %call28.1.21 to i32
  %xor.1.21 = xor i32 %conv23.1.21, %conv29.1.21
  %scevgep35.1.21 = getelementptr i8, i8* %a, i64 23
  %690 = load i8, i8* %scevgep35.1.21, align 1
  %691 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.21 = call zeroext i8 @mult(i8 zeroext %690, i8 zeroext %691)
  %conv35.1.21 = zext i8 %call34.1.21 to i32
  %xor36.1.21 = xor i32 %xor.1.21, %conv35.1.21
  %conv37.1.21 = trunc i32 %xor36.1.21 to i8
  store i8 %conv37.1.21, i8* %scevgep41.1.20, align 1
  %scevgep28.1.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %685, i64 0, i64 0, i64 1
  %692 = bitcast i8* %scevgep28.1.21 to [61 x [61 x i8]]*
  %scevgep41.1.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %686, i64 0, i64 1, i64 0
  %693 = bitcast i8* %scevgep41.1.21 to [61 x [61 x i8]]*
  %call16.1.22 = call zeroext i8 (...) @rand()
  store i8 %call16.1.22, i8* %scevgep28.1.21, align 1
  %694 = load i8, i8* %scevgep28.1.21, align 1
  %conv23.1.22 = zext i8 %694 to i32
  %695 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.22 = getelementptr i8, i8* %b, i64 24
  %696 = load i8, i8* %scevgep34.1.22, align 1
  %call28.1.22 = call zeroext i8 @mult(i8 zeroext %695, i8 zeroext %696)
  %conv29.1.22 = zext i8 %call28.1.22 to i32
  %xor.1.22 = xor i32 %conv23.1.22, %conv29.1.22
  %scevgep35.1.22 = getelementptr i8, i8* %a, i64 24
  %697 = load i8, i8* %scevgep35.1.22, align 1
  %698 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.22 = call zeroext i8 @mult(i8 zeroext %697, i8 zeroext %698)
  %conv35.1.22 = zext i8 %call34.1.22 to i32
  %xor36.1.22 = xor i32 %xor.1.22, %conv35.1.22
  %conv37.1.22 = trunc i32 %xor36.1.22 to i8
  store i8 %conv37.1.22, i8* %scevgep41.1.21, align 1
  %scevgep28.1.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %692, i64 0, i64 0, i64 1
  %699 = bitcast i8* %scevgep28.1.22 to [61 x [61 x i8]]*
  %scevgep41.1.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %693, i64 0, i64 1, i64 0
  %700 = bitcast i8* %scevgep41.1.22 to [61 x [61 x i8]]*
  %call16.1.23 = call zeroext i8 (...) @rand()
  store i8 %call16.1.23, i8* %scevgep28.1.22, align 1
  %701 = load i8, i8* %scevgep28.1.22, align 1
  %conv23.1.23 = zext i8 %701 to i32
  %702 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.23 = getelementptr i8, i8* %b, i64 25
  %703 = load i8, i8* %scevgep34.1.23, align 1
  %call28.1.23 = call zeroext i8 @mult(i8 zeroext %702, i8 zeroext %703)
  %conv29.1.23 = zext i8 %call28.1.23 to i32
  %xor.1.23 = xor i32 %conv23.1.23, %conv29.1.23
  %scevgep35.1.23 = getelementptr i8, i8* %a, i64 25
  %704 = load i8, i8* %scevgep35.1.23, align 1
  %705 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.23 = call zeroext i8 @mult(i8 zeroext %704, i8 zeroext %705)
  %conv35.1.23 = zext i8 %call34.1.23 to i32
  %xor36.1.23 = xor i32 %xor.1.23, %conv35.1.23
  %conv37.1.23 = trunc i32 %xor36.1.23 to i8
  store i8 %conv37.1.23, i8* %scevgep41.1.22, align 1
  %scevgep28.1.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %699, i64 0, i64 0, i64 1
  %706 = bitcast i8* %scevgep28.1.23 to [61 x [61 x i8]]*
  %scevgep41.1.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %700, i64 0, i64 1, i64 0
  %707 = bitcast i8* %scevgep41.1.23 to [61 x [61 x i8]]*
  %call16.1.24 = call zeroext i8 (...) @rand()
  store i8 %call16.1.24, i8* %scevgep28.1.23, align 1
  %708 = load i8, i8* %scevgep28.1.23, align 1
  %conv23.1.24 = zext i8 %708 to i32
  %709 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.24 = getelementptr i8, i8* %b, i64 26
  %710 = load i8, i8* %scevgep34.1.24, align 1
  %call28.1.24 = call zeroext i8 @mult(i8 zeroext %709, i8 zeroext %710)
  %conv29.1.24 = zext i8 %call28.1.24 to i32
  %xor.1.24 = xor i32 %conv23.1.24, %conv29.1.24
  %scevgep35.1.24 = getelementptr i8, i8* %a, i64 26
  %711 = load i8, i8* %scevgep35.1.24, align 1
  %712 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.24 = call zeroext i8 @mult(i8 zeroext %711, i8 zeroext %712)
  %conv35.1.24 = zext i8 %call34.1.24 to i32
  %xor36.1.24 = xor i32 %xor.1.24, %conv35.1.24
  %conv37.1.24 = trunc i32 %xor36.1.24 to i8
  store i8 %conv37.1.24, i8* %scevgep41.1.23, align 1
  %scevgep28.1.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %706, i64 0, i64 0, i64 1
  %713 = bitcast i8* %scevgep28.1.24 to [61 x [61 x i8]]*
  %scevgep41.1.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %707, i64 0, i64 1, i64 0
  %714 = bitcast i8* %scevgep41.1.24 to [61 x [61 x i8]]*
  %call16.1.25 = call zeroext i8 (...) @rand()
  store i8 %call16.1.25, i8* %scevgep28.1.24, align 1
  %715 = load i8, i8* %scevgep28.1.24, align 1
  %conv23.1.25 = zext i8 %715 to i32
  %716 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.25 = getelementptr i8, i8* %b, i64 27
  %717 = load i8, i8* %scevgep34.1.25, align 1
  %call28.1.25 = call zeroext i8 @mult(i8 zeroext %716, i8 zeroext %717)
  %conv29.1.25 = zext i8 %call28.1.25 to i32
  %xor.1.25 = xor i32 %conv23.1.25, %conv29.1.25
  %scevgep35.1.25 = getelementptr i8, i8* %a, i64 27
  %718 = load i8, i8* %scevgep35.1.25, align 1
  %719 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.25 = call zeroext i8 @mult(i8 zeroext %718, i8 zeroext %719)
  %conv35.1.25 = zext i8 %call34.1.25 to i32
  %xor36.1.25 = xor i32 %xor.1.25, %conv35.1.25
  %conv37.1.25 = trunc i32 %xor36.1.25 to i8
  store i8 %conv37.1.25, i8* %scevgep41.1.24, align 1
  %scevgep28.1.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %713, i64 0, i64 0, i64 1
  %720 = bitcast i8* %scevgep28.1.25 to [61 x [61 x i8]]*
  %scevgep41.1.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %714, i64 0, i64 1, i64 0
  %721 = bitcast i8* %scevgep41.1.25 to [61 x [61 x i8]]*
  %call16.1.26 = call zeroext i8 (...) @rand()
  store i8 %call16.1.26, i8* %scevgep28.1.25, align 1
  %722 = load i8, i8* %scevgep28.1.25, align 1
  %conv23.1.26 = zext i8 %722 to i32
  %723 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.26 = getelementptr i8, i8* %b, i64 28
  %724 = load i8, i8* %scevgep34.1.26, align 1
  %call28.1.26 = call zeroext i8 @mult(i8 zeroext %723, i8 zeroext %724)
  %conv29.1.26 = zext i8 %call28.1.26 to i32
  %xor.1.26 = xor i32 %conv23.1.26, %conv29.1.26
  %scevgep35.1.26 = getelementptr i8, i8* %a, i64 28
  %725 = load i8, i8* %scevgep35.1.26, align 1
  %726 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.26 = call zeroext i8 @mult(i8 zeroext %725, i8 zeroext %726)
  %conv35.1.26 = zext i8 %call34.1.26 to i32
  %xor36.1.26 = xor i32 %xor.1.26, %conv35.1.26
  %conv37.1.26 = trunc i32 %xor36.1.26 to i8
  store i8 %conv37.1.26, i8* %scevgep41.1.25, align 1
  %scevgep28.1.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %720, i64 0, i64 0, i64 1
  %727 = bitcast i8* %scevgep28.1.26 to [61 x [61 x i8]]*
  %scevgep41.1.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %721, i64 0, i64 1, i64 0
  %728 = bitcast i8* %scevgep41.1.26 to [61 x [61 x i8]]*
  %call16.1.27 = call zeroext i8 (...) @rand()
  store i8 %call16.1.27, i8* %scevgep28.1.26, align 1
  %729 = load i8, i8* %scevgep28.1.26, align 1
  %conv23.1.27 = zext i8 %729 to i32
  %730 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.27 = getelementptr i8, i8* %b, i64 29
  %731 = load i8, i8* %scevgep34.1.27, align 1
  %call28.1.27 = call zeroext i8 @mult(i8 zeroext %730, i8 zeroext %731)
  %conv29.1.27 = zext i8 %call28.1.27 to i32
  %xor.1.27 = xor i32 %conv23.1.27, %conv29.1.27
  %scevgep35.1.27 = getelementptr i8, i8* %a, i64 29
  %732 = load i8, i8* %scevgep35.1.27, align 1
  %733 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.27 = call zeroext i8 @mult(i8 zeroext %732, i8 zeroext %733)
  %conv35.1.27 = zext i8 %call34.1.27 to i32
  %xor36.1.27 = xor i32 %xor.1.27, %conv35.1.27
  %conv37.1.27 = trunc i32 %xor36.1.27 to i8
  store i8 %conv37.1.27, i8* %scevgep41.1.26, align 1
  %scevgep28.1.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %727, i64 0, i64 0, i64 1
  %734 = bitcast i8* %scevgep28.1.27 to [61 x [61 x i8]]*
  %scevgep41.1.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %728, i64 0, i64 1, i64 0
  %735 = bitcast i8* %scevgep41.1.27 to [61 x [61 x i8]]*
  %call16.1.28 = call zeroext i8 (...) @rand()
  store i8 %call16.1.28, i8* %scevgep28.1.27, align 1
  %736 = load i8, i8* %scevgep28.1.27, align 1
  %conv23.1.28 = zext i8 %736 to i32
  %737 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.28 = getelementptr i8, i8* %b, i64 30
  %738 = load i8, i8* %scevgep34.1.28, align 1
  %call28.1.28 = call zeroext i8 @mult(i8 zeroext %737, i8 zeroext %738)
  %conv29.1.28 = zext i8 %call28.1.28 to i32
  %xor.1.28 = xor i32 %conv23.1.28, %conv29.1.28
  %scevgep35.1.28 = getelementptr i8, i8* %a, i64 30
  %739 = load i8, i8* %scevgep35.1.28, align 1
  %740 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.28 = call zeroext i8 @mult(i8 zeroext %739, i8 zeroext %740)
  %conv35.1.28 = zext i8 %call34.1.28 to i32
  %xor36.1.28 = xor i32 %xor.1.28, %conv35.1.28
  %conv37.1.28 = trunc i32 %xor36.1.28 to i8
  store i8 %conv37.1.28, i8* %scevgep41.1.27, align 1
  %scevgep28.1.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %734, i64 0, i64 0, i64 1
  %741 = bitcast i8* %scevgep28.1.28 to [61 x [61 x i8]]*
  %scevgep41.1.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %735, i64 0, i64 1, i64 0
  %742 = bitcast i8* %scevgep41.1.28 to [61 x [61 x i8]]*
  %call16.1.29 = call zeroext i8 (...) @rand()
  store i8 %call16.1.29, i8* %scevgep28.1.28, align 1
  %743 = load i8, i8* %scevgep28.1.28, align 1
  %conv23.1.29 = zext i8 %743 to i32
  %744 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.29 = getelementptr i8, i8* %b, i64 31
  %745 = load i8, i8* %scevgep34.1.29, align 1
  %call28.1.29 = call zeroext i8 @mult(i8 zeroext %744, i8 zeroext %745)
  %conv29.1.29 = zext i8 %call28.1.29 to i32
  %xor.1.29 = xor i32 %conv23.1.29, %conv29.1.29
  %scevgep35.1.29 = getelementptr i8, i8* %a, i64 31
  %746 = load i8, i8* %scevgep35.1.29, align 1
  %747 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.29 = call zeroext i8 @mult(i8 zeroext %746, i8 zeroext %747)
  %conv35.1.29 = zext i8 %call34.1.29 to i32
  %xor36.1.29 = xor i32 %xor.1.29, %conv35.1.29
  %conv37.1.29 = trunc i32 %xor36.1.29 to i8
  store i8 %conv37.1.29, i8* %scevgep41.1.28, align 1
  %scevgep28.1.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %741, i64 0, i64 0, i64 1
  %748 = bitcast i8* %scevgep28.1.29 to [61 x [61 x i8]]*
  %scevgep41.1.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %742, i64 0, i64 1, i64 0
  %749 = bitcast i8* %scevgep41.1.29 to [61 x [61 x i8]]*
  %call16.1.30 = call zeroext i8 (...) @rand()
  store i8 %call16.1.30, i8* %scevgep28.1.29, align 1
  %750 = load i8, i8* %scevgep28.1.29, align 1
  %conv23.1.30 = zext i8 %750 to i32
  %751 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.30 = getelementptr i8, i8* %b, i64 32
  %752 = load i8, i8* %scevgep34.1.30, align 1
  %call28.1.30 = call zeroext i8 @mult(i8 zeroext %751, i8 zeroext %752)
  %conv29.1.30 = zext i8 %call28.1.30 to i32
  %xor.1.30 = xor i32 %conv23.1.30, %conv29.1.30
  %scevgep35.1.30 = getelementptr i8, i8* %a, i64 32
  %753 = load i8, i8* %scevgep35.1.30, align 1
  %754 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.30 = call zeroext i8 @mult(i8 zeroext %753, i8 zeroext %754)
  %conv35.1.30 = zext i8 %call34.1.30 to i32
  %xor36.1.30 = xor i32 %xor.1.30, %conv35.1.30
  %conv37.1.30 = trunc i32 %xor36.1.30 to i8
  store i8 %conv37.1.30, i8* %scevgep41.1.29, align 1
  %scevgep28.1.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %748, i64 0, i64 0, i64 1
  %755 = bitcast i8* %scevgep28.1.30 to [61 x [61 x i8]]*
  %scevgep41.1.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %749, i64 0, i64 1, i64 0
  %756 = bitcast i8* %scevgep41.1.30 to [61 x [61 x i8]]*
  %call16.1.31 = call zeroext i8 (...) @rand()
  store i8 %call16.1.31, i8* %scevgep28.1.30, align 1
  %757 = load i8, i8* %scevgep28.1.30, align 1
  %conv23.1.31 = zext i8 %757 to i32
  %758 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.31 = getelementptr i8, i8* %b, i64 33
  %759 = load i8, i8* %scevgep34.1.31, align 1
  %call28.1.31 = call zeroext i8 @mult(i8 zeroext %758, i8 zeroext %759)
  %conv29.1.31 = zext i8 %call28.1.31 to i32
  %xor.1.31 = xor i32 %conv23.1.31, %conv29.1.31
  %scevgep35.1.31 = getelementptr i8, i8* %a, i64 33
  %760 = load i8, i8* %scevgep35.1.31, align 1
  %761 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.31 = call zeroext i8 @mult(i8 zeroext %760, i8 zeroext %761)
  %conv35.1.31 = zext i8 %call34.1.31 to i32
  %xor36.1.31 = xor i32 %xor.1.31, %conv35.1.31
  %conv37.1.31 = trunc i32 %xor36.1.31 to i8
  store i8 %conv37.1.31, i8* %scevgep41.1.30, align 1
  %scevgep28.1.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %755, i64 0, i64 0, i64 1
  %762 = bitcast i8* %scevgep28.1.31 to [61 x [61 x i8]]*
  %scevgep41.1.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %756, i64 0, i64 1, i64 0
  %763 = bitcast i8* %scevgep41.1.31 to [61 x [61 x i8]]*
  %call16.1.32 = call zeroext i8 (...) @rand()
  store i8 %call16.1.32, i8* %scevgep28.1.31, align 1
  %764 = load i8, i8* %scevgep28.1.31, align 1
  %conv23.1.32 = zext i8 %764 to i32
  %765 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.32 = getelementptr i8, i8* %b, i64 34
  %766 = load i8, i8* %scevgep34.1.32, align 1
  %call28.1.32 = call zeroext i8 @mult(i8 zeroext %765, i8 zeroext %766)
  %conv29.1.32 = zext i8 %call28.1.32 to i32
  %xor.1.32 = xor i32 %conv23.1.32, %conv29.1.32
  %scevgep35.1.32 = getelementptr i8, i8* %a, i64 34
  %767 = load i8, i8* %scevgep35.1.32, align 1
  %768 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.32 = call zeroext i8 @mult(i8 zeroext %767, i8 zeroext %768)
  %conv35.1.32 = zext i8 %call34.1.32 to i32
  %xor36.1.32 = xor i32 %xor.1.32, %conv35.1.32
  %conv37.1.32 = trunc i32 %xor36.1.32 to i8
  store i8 %conv37.1.32, i8* %scevgep41.1.31, align 1
  %scevgep28.1.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %762, i64 0, i64 0, i64 1
  %769 = bitcast i8* %scevgep28.1.32 to [61 x [61 x i8]]*
  %scevgep41.1.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %763, i64 0, i64 1, i64 0
  %770 = bitcast i8* %scevgep41.1.32 to [61 x [61 x i8]]*
  %call16.1.33 = call zeroext i8 (...) @rand()
  store i8 %call16.1.33, i8* %scevgep28.1.32, align 1
  %771 = load i8, i8* %scevgep28.1.32, align 1
  %conv23.1.33 = zext i8 %771 to i32
  %772 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.33 = getelementptr i8, i8* %b, i64 35
  %773 = load i8, i8* %scevgep34.1.33, align 1
  %call28.1.33 = call zeroext i8 @mult(i8 zeroext %772, i8 zeroext %773)
  %conv29.1.33 = zext i8 %call28.1.33 to i32
  %xor.1.33 = xor i32 %conv23.1.33, %conv29.1.33
  %scevgep35.1.33 = getelementptr i8, i8* %a, i64 35
  %774 = load i8, i8* %scevgep35.1.33, align 1
  %775 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.33 = call zeroext i8 @mult(i8 zeroext %774, i8 zeroext %775)
  %conv35.1.33 = zext i8 %call34.1.33 to i32
  %xor36.1.33 = xor i32 %xor.1.33, %conv35.1.33
  %conv37.1.33 = trunc i32 %xor36.1.33 to i8
  store i8 %conv37.1.33, i8* %scevgep41.1.32, align 1
  %scevgep28.1.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %769, i64 0, i64 0, i64 1
  %776 = bitcast i8* %scevgep28.1.33 to [61 x [61 x i8]]*
  %scevgep41.1.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %770, i64 0, i64 1, i64 0
  %777 = bitcast i8* %scevgep41.1.33 to [61 x [61 x i8]]*
  %call16.1.34 = call zeroext i8 (...) @rand()
  store i8 %call16.1.34, i8* %scevgep28.1.33, align 1
  %778 = load i8, i8* %scevgep28.1.33, align 1
  %conv23.1.34 = zext i8 %778 to i32
  %779 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.34 = getelementptr i8, i8* %b, i64 36
  %780 = load i8, i8* %scevgep34.1.34, align 1
  %call28.1.34 = call zeroext i8 @mult(i8 zeroext %779, i8 zeroext %780)
  %conv29.1.34 = zext i8 %call28.1.34 to i32
  %xor.1.34 = xor i32 %conv23.1.34, %conv29.1.34
  %scevgep35.1.34 = getelementptr i8, i8* %a, i64 36
  %781 = load i8, i8* %scevgep35.1.34, align 1
  %782 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.34 = call zeroext i8 @mult(i8 zeroext %781, i8 zeroext %782)
  %conv35.1.34 = zext i8 %call34.1.34 to i32
  %xor36.1.34 = xor i32 %xor.1.34, %conv35.1.34
  %conv37.1.34 = trunc i32 %xor36.1.34 to i8
  store i8 %conv37.1.34, i8* %scevgep41.1.33, align 1
  %scevgep28.1.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %776, i64 0, i64 0, i64 1
  %783 = bitcast i8* %scevgep28.1.34 to [61 x [61 x i8]]*
  %scevgep41.1.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %777, i64 0, i64 1, i64 0
  %784 = bitcast i8* %scevgep41.1.34 to [61 x [61 x i8]]*
  %call16.1.35 = call zeroext i8 (...) @rand()
  store i8 %call16.1.35, i8* %scevgep28.1.34, align 1
  %785 = load i8, i8* %scevgep28.1.34, align 1
  %conv23.1.35 = zext i8 %785 to i32
  %786 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.35 = getelementptr i8, i8* %b, i64 37
  %787 = load i8, i8* %scevgep34.1.35, align 1
  %call28.1.35 = call zeroext i8 @mult(i8 zeroext %786, i8 zeroext %787)
  %conv29.1.35 = zext i8 %call28.1.35 to i32
  %xor.1.35 = xor i32 %conv23.1.35, %conv29.1.35
  %scevgep35.1.35 = getelementptr i8, i8* %a, i64 37
  %788 = load i8, i8* %scevgep35.1.35, align 1
  %789 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.35 = call zeroext i8 @mult(i8 zeroext %788, i8 zeroext %789)
  %conv35.1.35 = zext i8 %call34.1.35 to i32
  %xor36.1.35 = xor i32 %xor.1.35, %conv35.1.35
  %conv37.1.35 = trunc i32 %xor36.1.35 to i8
  store i8 %conv37.1.35, i8* %scevgep41.1.34, align 1
  %scevgep28.1.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %783, i64 0, i64 0, i64 1
  %790 = bitcast i8* %scevgep28.1.35 to [61 x [61 x i8]]*
  %scevgep41.1.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %784, i64 0, i64 1, i64 0
  %791 = bitcast i8* %scevgep41.1.35 to [61 x [61 x i8]]*
  %call16.1.36 = call zeroext i8 (...) @rand()
  store i8 %call16.1.36, i8* %scevgep28.1.35, align 1
  %792 = load i8, i8* %scevgep28.1.35, align 1
  %conv23.1.36 = zext i8 %792 to i32
  %793 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.36 = getelementptr i8, i8* %b, i64 38
  %794 = load i8, i8* %scevgep34.1.36, align 1
  %call28.1.36 = call zeroext i8 @mult(i8 zeroext %793, i8 zeroext %794)
  %conv29.1.36 = zext i8 %call28.1.36 to i32
  %xor.1.36 = xor i32 %conv23.1.36, %conv29.1.36
  %scevgep35.1.36 = getelementptr i8, i8* %a, i64 38
  %795 = load i8, i8* %scevgep35.1.36, align 1
  %796 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.36 = call zeroext i8 @mult(i8 zeroext %795, i8 zeroext %796)
  %conv35.1.36 = zext i8 %call34.1.36 to i32
  %xor36.1.36 = xor i32 %xor.1.36, %conv35.1.36
  %conv37.1.36 = trunc i32 %xor36.1.36 to i8
  store i8 %conv37.1.36, i8* %scevgep41.1.35, align 1
  %scevgep28.1.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %790, i64 0, i64 0, i64 1
  %797 = bitcast i8* %scevgep28.1.36 to [61 x [61 x i8]]*
  %scevgep41.1.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %791, i64 0, i64 1, i64 0
  %798 = bitcast i8* %scevgep41.1.36 to [61 x [61 x i8]]*
  %call16.1.37 = call zeroext i8 (...) @rand()
  store i8 %call16.1.37, i8* %scevgep28.1.36, align 1
  %799 = load i8, i8* %scevgep28.1.36, align 1
  %conv23.1.37 = zext i8 %799 to i32
  %800 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.37 = getelementptr i8, i8* %b, i64 39
  %801 = load i8, i8* %scevgep34.1.37, align 1
  %call28.1.37 = call zeroext i8 @mult(i8 zeroext %800, i8 zeroext %801)
  %conv29.1.37 = zext i8 %call28.1.37 to i32
  %xor.1.37 = xor i32 %conv23.1.37, %conv29.1.37
  %scevgep35.1.37 = getelementptr i8, i8* %a, i64 39
  %802 = load i8, i8* %scevgep35.1.37, align 1
  %803 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.37 = call zeroext i8 @mult(i8 zeroext %802, i8 zeroext %803)
  %conv35.1.37 = zext i8 %call34.1.37 to i32
  %xor36.1.37 = xor i32 %xor.1.37, %conv35.1.37
  %conv37.1.37 = trunc i32 %xor36.1.37 to i8
  store i8 %conv37.1.37, i8* %scevgep41.1.36, align 1
  %scevgep28.1.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %797, i64 0, i64 0, i64 1
  %804 = bitcast i8* %scevgep28.1.37 to [61 x [61 x i8]]*
  %scevgep41.1.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %798, i64 0, i64 1, i64 0
  %805 = bitcast i8* %scevgep41.1.37 to [61 x [61 x i8]]*
  %call16.1.38 = call zeroext i8 (...) @rand()
  store i8 %call16.1.38, i8* %scevgep28.1.37, align 1
  %806 = load i8, i8* %scevgep28.1.37, align 1
  %conv23.1.38 = zext i8 %806 to i32
  %807 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.38 = getelementptr i8, i8* %b, i64 40
  %808 = load i8, i8* %scevgep34.1.38, align 1
  %call28.1.38 = call zeroext i8 @mult(i8 zeroext %807, i8 zeroext %808)
  %conv29.1.38 = zext i8 %call28.1.38 to i32
  %xor.1.38 = xor i32 %conv23.1.38, %conv29.1.38
  %scevgep35.1.38 = getelementptr i8, i8* %a, i64 40
  %809 = load i8, i8* %scevgep35.1.38, align 1
  %810 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.38 = call zeroext i8 @mult(i8 zeroext %809, i8 zeroext %810)
  %conv35.1.38 = zext i8 %call34.1.38 to i32
  %xor36.1.38 = xor i32 %xor.1.38, %conv35.1.38
  %conv37.1.38 = trunc i32 %xor36.1.38 to i8
  store i8 %conv37.1.38, i8* %scevgep41.1.37, align 1
  %scevgep28.1.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %804, i64 0, i64 0, i64 1
  %811 = bitcast i8* %scevgep28.1.38 to [61 x [61 x i8]]*
  %scevgep41.1.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %805, i64 0, i64 1, i64 0
  %812 = bitcast i8* %scevgep41.1.38 to [61 x [61 x i8]]*
  %call16.1.39 = call zeroext i8 (...) @rand()
  store i8 %call16.1.39, i8* %scevgep28.1.38, align 1
  %813 = load i8, i8* %scevgep28.1.38, align 1
  %conv23.1.39 = zext i8 %813 to i32
  %814 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.39 = getelementptr i8, i8* %b, i64 41
  %815 = load i8, i8* %scevgep34.1.39, align 1
  %call28.1.39 = call zeroext i8 @mult(i8 zeroext %814, i8 zeroext %815)
  %conv29.1.39 = zext i8 %call28.1.39 to i32
  %xor.1.39 = xor i32 %conv23.1.39, %conv29.1.39
  %scevgep35.1.39 = getelementptr i8, i8* %a, i64 41
  %816 = load i8, i8* %scevgep35.1.39, align 1
  %817 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.39 = call zeroext i8 @mult(i8 zeroext %816, i8 zeroext %817)
  %conv35.1.39 = zext i8 %call34.1.39 to i32
  %xor36.1.39 = xor i32 %xor.1.39, %conv35.1.39
  %conv37.1.39 = trunc i32 %xor36.1.39 to i8
  store i8 %conv37.1.39, i8* %scevgep41.1.38, align 1
  %scevgep28.1.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %811, i64 0, i64 0, i64 1
  %818 = bitcast i8* %scevgep28.1.39 to [61 x [61 x i8]]*
  %scevgep41.1.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %812, i64 0, i64 1, i64 0
  %819 = bitcast i8* %scevgep41.1.39 to [61 x [61 x i8]]*
  %call16.1.40 = call zeroext i8 (...) @rand()
  store i8 %call16.1.40, i8* %scevgep28.1.39, align 1
  %820 = load i8, i8* %scevgep28.1.39, align 1
  %conv23.1.40 = zext i8 %820 to i32
  %821 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.40 = getelementptr i8, i8* %b, i64 42
  %822 = load i8, i8* %scevgep34.1.40, align 1
  %call28.1.40 = call zeroext i8 @mult(i8 zeroext %821, i8 zeroext %822)
  %conv29.1.40 = zext i8 %call28.1.40 to i32
  %xor.1.40 = xor i32 %conv23.1.40, %conv29.1.40
  %scevgep35.1.40 = getelementptr i8, i8* %a, i64 42
  %823 = load i8, i8* %scevgep35.1.40, align 1
  %824 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.40 = call zeroext i8 @mult(i8 zeroext %823, i8 zeroext %824)
  %conv35.1.40 = zext i8 %call34.1.40 to i32
  %xor36.1.40 = xor i32 %xor.1.40, %conv35.1.40
  %conv37.1.40 = trunc i32 %xor36.1.40 to i8
  store i8 %conv37.1.40, i8* %scevgep41.1.39, align 1
  %scevgep28.1.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %818, i64 0, i64 0, i64 1
  %825 = bitcast i8* %scevgep28.1.40 to [61 x [61 x i8]]*
  %scevgep41.1.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %819, i64 0, i64 1, i64 0
  %826 = bitcast i8* %scevgep41.1.40 to [61 x [61 x i8]]*
  %call16.1.41 = call zeroext i8 (...) @rand()
  store i8 %call16.1.41, i8* %scevgep28.1.40, align 1
  %827 = load i8, i8* %scevgep28.1.40, align 1
  %conv23.1.41 = zext i8 %827 to i32
  %828 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.41 = getelementptr i8, i8* %b, i64 43
  %829 = load i8, i8* %scevgep34.1.41, align 1
  %call28.1.41 = call zeroext i8 @mult(i8 zeroext %828, i8 zeroext %829)
  %conv29.1.41 = zext i8 %call28.1.41 to i32
  %xor.1.41 = xor i32 %conv23.1.41, %conv29.1.41
  %scevgep35.1.41 = getelementptr i8, i8* %a, i64 43
  %830 = load i8, i8* %scevgep35.1.41, align 1
  %831 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.41 = call zeroext i8 @mult(i8 zeroext %830, i8 zeroext %831)
  %conv35.1.41 = zext i8 %call34.1.41 to i32
  %xor36.1.41 = xor i32 %xor.1.41, %conv35.1.41
  %conv37.1.41 = trunc i32 %xor36.1.41 to i8
  store i8 %conv37.1.41, i8* %scevgep41.1.40, align 1
  %scevgep28.1.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %825, i64 0, i64 0, i64 1
  %832 = bitcast i8* %scevgep28.1.41 to [61 x [61 x i8]]*
  %scevgep41.1.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %826, i64 0, i64 1, i64 0
  %833 = bitcast i8* %scevgep41.1.41 to [61 x [61 x i8]]*
  %call16.1.42 = call zeroext i8 (...) @rand()
  store i8 %call16.1.42, i8* %scevgep28.1.41, align 1
  %834 = load i8, i8* %scevgep28.1.41, align 1
  %conv23.1.42 = zext i8 %834 to i32
  %835 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.42 = getelementptr i8, i8* %b, i64 44
  %836 = load i8, i8* %scevgep34.1.42, align 1
  %call28.1.42 = call zeroext i8 @mult(i8 zeroext %835, i8 zeroext %836)
  %conv29.1.42 = zext i8 %call28.1.42 to i32
  %xor.1.42 = xor i32 %conv23.1.42, %conv29.1.42
  %scevgep35.1.42 = getelementptr i8, i8* %a, i64 44
  %837 = load i8, i8* %scevgep35.1.42, align 1
  %838 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.42 = call zeroext i8 @mult(i8 zeroext %837, i8 zeroext %838)
  %conv35.1.42 = zext i8 %call34.1.42 to i32
  %xor36.1.42 = xor i32 %xor.1.42, %conv35.1.42
  %conv37.1.42 = trunc i32 %xor36.1.42 to i8
  store i8 %conv37.1.42, i8* %scevgep41.1.41, align 1
  %scevgep28.1.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %832, i64 0, i64 0, i64 1
  %839 = bitcast i8* %scevgep28.1.42 to [61 x [61 x i8]]*
  %scevgep41.1.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %833, i64 0, i64 1, i64 0
  %840 = bitcast i8* %scevgep41.1.42 to [61 x [61 x i8]]*
  %call16.1.43 = call zeroext i8 (...) @rand()
  store i8 %call16.1.43, i8* %scevgep28.1.42, align 1
  %841 = load i8, i8* %scevgep28.1.42, align 1
  %conv23.1.43 = zext i8 %841 to i32
  %842 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.43 = getelementptr i8, i8* %b, i64 45
  %843 = load i8, i8* %scevgep34.1.43, align 1
  %call28.1.43 = call zeroext i8 @mult(i8 zeroext %842, i8 zeroext %843)
  %conv29.1.43 = zext i8 %call28.1.43 to i32
  %xor.1.43 = xor i32 %conv23.1.43, %conv29.1.43
  %scevgep35.1.43 = getelementptr i8, i8* %a, i64 45
  %844 = load i8, i8* %scevgep35.1.43, align 1
  %845 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.43 = call zeroext i8 @mult(i8 zeroext %844, i8 zeroext %845)
  %conv35.1.43 = zext i8 %call34.1.43 to i32
  %xor36.1.43 = xor i32 %xor.1.43, %conv35.1.43
  %conv37.1.43 = trunc i32 %xor36.1.43 to i8
  store i8 %conv37.1.43, i8* %scevgep41.1.42, align 1
  %scevgep28.1.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %839, i64 0, i64 0, i64 1
  %846 = bitcast i8* %scevgep28.1.43 to [61 x [61 x i8]]*
  %scevgep41.1.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %840, i64 0, i64 1, i64 0
  %847 = bitcast i8* %scevgep41.1.43 to [61 x [61 x i8]]*
  %call16.1.44 = call zeroext i8 (...) @rand()
  store i8 %call16.1.44, i8* %scevgep28.1.43, align 1
  %848 = load i8, i8* %scevgep28.1.43, align 1
  %conv23.1.44 = zext i8 %848 to i32
  %849 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.44 = getelementptr i8, i8* %b, i64 46
  %850 = load i8, i8* %scevgep34.1.44, align 1
  %call28.1.44 = call zeroext i8 @mult(i8 zeroext %849, i8 zeroext %850)
  %conv29.1.44 = zext i8 %call28.1.44 to i32
  %xor.1.44 = xor i32 %conv23.1.44, %conv29.1.44
  %scevgep35.1.44 = getelementptr i8, i8* %a, i64 46
  %851 = load i8, i8* %scevgep35.1.44, align 1
  %852 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.44 = call zeroext i8 @mult(i8 zeroext %851, i8 zeroext %852)
  %conv35.1.44 = zext i8 %call34.1.44 to i32
  %xor36.1.44 = xor i32 %xor.1.44, %conv35.1.44
  %conv37.1.44 = trunc i32 %xor36.1.44 to i8
  store i8 %conv37.1.44, i8* %scevgep41.1.43, align 1
  %scevgep28.1.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %846, i64 0, i64 0, i64 1
  %853 = bitcast i8* %scevgep28.1.44 to [61 x [61 x i8]]*
  %scevgep41.1.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %847, i64 0, i64 1, i64 0
  %854 = bitcast i8* %scevgep41.1.44 to [61 x [61 x i8]]*
  %call16.1.45 = call zeroext i8 (...) @rand()
  store i8 %call16.1.45, i8* %scevgep28.1.44, align 1
  %855 = load i8, i8* %scevgep28.1.44, align 1
  %conv23.1.45 = zext i8 %855 to i32
  %856 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.45 = getelementptr i8, i8* %b, i64 47
  %857 = load i8, i8* %scevgep34.1.45, align 1
  %call28.1.45 = call zeroext i8 @mult(i8 zeroext %856, i8 zeroext %857)
  %conv29.1.45 = zext i8 %call28.1.45 to i32
  %xor.1.45 = xor i32 %conv23.1.45, %conv29.1.45
  %scevgep35.1.45 = getelementptr i8, i8* %a, i64 47
  %858 = load i8, i8* %scevgep35.1.45, align 1
  %859 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.45 = call zeroext i8 @mult(i8 zeroext %858, i8 zeroext %859)
  %conv35.1.45 = zext i8 %call34.1.45 to i32
  %xor36.1.45 = xor i32 %xor.1.45, %conv35.1.45
  %conv37.1.45 = trunc i32 %xor36.1.45 to i8
  store i8 %conv37.1.45, i8* %scevgep41.1.44, align 1
  %scevgep28.1.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %853, i64 0, i64 0, i64 1
  %860 = bitcast i8* %scevgep28.1.45 to [61 x [61 x i8]]*
  %scevgep41.1.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %854, i64 0, i64 1, i64 0
  %861 = bitcast i8* %scevgep41.1.45 to [61 x [61 x i8]]*
  %call16.1.46 = call zeroext i8 (...) @rand()
  store i8 %call16.1.46, i8* %scevgep28.1.45, align 1
  %862 = load i8, i8* %scevgep28.1.45, align 1
  %conv23.1.46 = zext i8 %862 to i32
  %863 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.46 = getelementptr i8, i8* %b, i64 48
  %864 = load i8, i8* %scevgep34.1.46, align 1
  %call28.1.46 = call zeroext i8 @mult(i8 zeroext %863, i8 zeroext %864)
  %conv29.1.46 = zext i8 %call28.1.46 to i32
  %xor.1.46 = xor i32 %conv23.1.46, %conv29.1.46
  %scevgep35.1.46 = getelementptr i8, i8* %a, i64 48
  %865 = load i8, i8* %scevgep35.1.46, align 1
  %866 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.46 = call zeroext i8 @mult(i8 zeroext %865, i8 zeroext %866)
  %conv35.1.46 = zext i8 %call34.1.46 to i32
  %xor36.1.46 = xor i32 %xor.1.46, %conv35.1.46
  %conv37.1.46 = trunc i32 %xor36.1.46 to i8
  store i8 %conv37.1.46, i8* %scevgep41.1.45, align 1
  %scevgep28.1.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %860, i64 0, i64 0, i64 1
  %867 = bitcast i8* %scevgep28.1.46 to [61 x [61 x i8]]*
  %scevgep41.1.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %861, i64 0, i64 1, i64 0
  %868 = bitcast i8* %scevgep41.1.46 to [61 x [61 x i8]]*
  %call16.1.47 = call zeroext i8 (...) @rand()
  store i8 %call16.1.47, i8* %scevgep28.1.46, align 1
  %869 = load i8, i8* %scevgep28.1.46, align 1
  %conv23.1.47 = zext i8 %869 to i32
  %870 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.47 = getelementptr i8, i8* %b, i64 49
  %871 = load i8, i8* %scevgep34.1.47, align 1
  %call28.1.47 = call zeroext i8 @mult(i8 zeroext %870, i8 zeroext %871)
  %conv29.1.47 = zext i8 %call28.1.47 to i32
  %xor.1.47 = xor i32 %conv23.1.47, %conv29.1.47
  %scevgep35.1.47 = getelementptr i8, i8* %a, i64 49
  %872 = load i8, i8* %scevgep35.1.47, align 1
  %873 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.47 = call zeroext i8 @mult(i8 zeroext %872, i8 zeroext %873)
  %conv35.1.47 = zext i8 %call34.1.47 to i32
  %xor36.1.47 = xor i32 %xor.1.47, %conv35.1.47
  %conv37.1.47 = trunc i32 %xor36.1.47 to i8
  store i8 %conv37.1.47, i8* %scevgep41.1.46, align 1
  %scevgep28.1.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %867, i64 0, i64 0, i64 1
  %874 = bitcast i8* %scevgep28.1.47 to [61 x [61 x i8]]*
  %scevgep41.1.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %868, i64 0, i64 1, i64 0
  %875 = bitcast i8* %scevgep41.1.47 to [61 x [61 x i8]]*
  %call16.1.48 = call zeroext i8 (...) @rand()
  store i8 %call16.1.48, i8* %scevgep28.1.47, align 1
  %876 = load i8, i8* %scevgep28.1.47, align 1
  %conv23.1.48 = zext i8 %876 to i32
  %877 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.48 = getelementptr i8, i8* %b, i64 50
  %878 = load i8, i8* %scevgep34.1.48, align 1
  %call28.1.48 = call zeroext i8 @mult(i8 zeroext %877, i8 zeroext %878)
  %conv29.1.48 = zext i8 %call28.1.48 to i32
  %xor.1.48 = xor i32 %conv23.1.48, %conv29.1.48
  %scevgep35.1.48 = getelementptr i8, i8* %a, i64 50
  %879 = load i8, i8* %scevgep35.1.48, align 1
  %880 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.48 = call zeroext i8 @mult(i8 zeroext %879, i8 zeroext %880)
  %conv35.1.48 = zext i8 %call34.1.48 to i32
  %xor36.1.48 = xor i32 %xor.1.48, %conv35.1.48
  %conv37.1.48 = trunc i32 %xor36.1.48 to i8
  store i8 %conv37.1.48, i8* %scevgep41.1.47, align 1
  %scevgep28.1.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %874, i64 0, i64 0, i64 1
  %881 = bitcast i8* %scevgep28.1.48 to [61 x [61 x i8]]*
  %scevgep41.1.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %875, i64 0, i64 1, i64 0
  %882 = bitcast i8* %scevgep41.1.48 to [61 x [61 x i8]]*
  %call16.1.49 = call zeroext i8 (...) @rand()
  store i8 %call16.1.49, i8* %scevgep28.1.48, align 1
  %883 = load i8, i8* %scevgep28.1.48, align 1
  %conv23.1.49 = zext i8 %883 to i32
  %884 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.49 = getelementptr i8, i8* %b, i64 51
  %885 = load i8, i8* %scevgep34.1.49, align 1
  %call28.1.49 = call zeroext i8 @mult(i8 zeroext %884, i8 zeroext %885)
  %conv29.1.49 = zext i8 %call28.1.49 to i32
  %xor.1.49 = xor i32 %conv23.1.49, %conv29.1.49
  %scevgep35.1.49 = getelementptr i8, i8* %a, i64 51
  %886 = load i8, i8* %scevgep35.1.49, align 1
  %887 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.49 = call zeroext i8 @mult(i8 zeroext %886, i8 zeroext %887)
  %conv35.1.49 = zext i8 %call34.1.49 to i32
  %xor36.1.49 = xor i32 %xor.1.49, %conv35.1.49
  %conv37.1.49 = trunc i32 %xor36.1.49 to i8
  store i8 %conv37.1.49, i8* %scevgep41.1.48, align 1
  %scevgep28.1.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %881, i64 0, i64 0, i64 1
  %888 = bitcast i8* %scevgep28.1.49 to [61 x [61 x i8]]*
  %scevgep41.1.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %882, i64 0, i64 1, i64 0
  %889 = bitcast i8* %scevgep41.1.49 to [61 x [61 x i8]]*
  %call16.1.50 = call zeroext i8 (...) @rand()
  store i8 %call16.1.50, i8* %scevgep28.1.49, align 1
  %890 = load i8, i8* %scevgep28.1.49, align 1
  %conv23.1.50 = zext i8 %890 to i32
  %891 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.50 = getelementptr i8, i8* %b, i64 52
  %892 = load i8, i8* %scevgep34.1.50, align 1
  %call28.1.50 = call zeroext i8 @mult(i8 zeroext %891, i8 zeroext %892)
  %conv29.1.50 = zext i8 %call28.1.50 to i32
  %xor.1.50 = xor i32 %conv23.1.50, %conv29.1.50
  %scevgep35.1.50 = getelementptr i8, i8* %a, i64 52
  %893 = load i8, i8* %scevgep35.1.50, align 1
  %894 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.50 = call zeroext i8 @mult(i8 zeroext %893, i8 zeroext %894)
  %conv35.1.50 = zext i8 %call34.1.50 to i32
  %xor36.1.50 = xor i32 %xor.1.50, %conv35.1.50
  %conv37.1.50 = trunc i32 %xor36.1.50 to i8
  store i8 %conv37.1.50, i8* %scevgep41.1.49, align 1
  %scevgep28.1.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %888, i64 0, i64 0, i64 1
  %895 = bitcast i8* %scevgep28.1.50 to [61 x [61 x i8]]*
  %scevgep41.1.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %889, i64 0, i64 1, i64 0
  %896 = bitcast i8* %scevgep41.1.50 to [61 x [61 x i8]]*
  %call16.1.51 = call zeroext i8 (...) @rand()
  store i8 %call16.1.51, i8* %scevgep28.1.50, align 1
  %897 = load i8, i8* %scevgep28.1.50, align 1
  %conv23.1.51 = zext i8 %897 to i32
  %898 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.51 = getelementptr i8, i8* %b, i64 53
  %899 = load i8, i8* %scevgep34.1.51, align 1
  %call28.1.51 = call zeroext i8 @mult(i8 zeroext %898, i8 zeroext %899)
  %conv29.1.51 = zext i8 %call28.1.51 to i32
  %xor.1.51 = xor i32 %conv23.1.51, %conv29.1.51
  %scevgep35.1.51 = getelementptr i8, i8* %a, i64 53
  %900 = load i8, i8* %scevgep35.1.51, align 1
  %901 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.51 = call zeroext i8 @mult(i8 zeroext %900, i8 zeroext %901)
  %conv35.1.51 = zext i8 %call34.1.51 to i32
  %xor36.1.51 = xor i32 %xor.1.51, %conv35.1.51
  %conv37.1.51 = trunc i32 %xor36.1.51 to i8
  store i8 %conv37.1.51, i8* %scevgep41.1.50, align 1
  %scevgep28.1.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %895, i64 0, i64 0, i64 1
  %902 = bitcast i8* %scevgep28.1.51 to [61 x [61 x i8]]*
  %scevgep41.1.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %896, i64 0, i64 1, i64 0
  %903 = bitcast i8* %scevgep41.1.51 to [61 x [61 x i8]]*
  %call16.1.52 = call zeroext i8 (...) @rand()
  store i8 %call16.1.52, i8* %scevgep28.1.51, align 1
  %904 = load i8, i8* %scevgep28.1.51, align 1
  %conv23.1.52 = zext i8 %904 to i32
  %905 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.52 = getelementptr i8, i8* %b, i64 54
  %906 = load i8, i8* %scevgep34.1.52, align 1
  %call28.1.52 = call zeroext i8 @mult(i8 zeroext %905, i8 zeroext %906)
  %conv29.1.52 = zext i8 %call28.1.52 to i32
  %xor.1.52 = xor i32 %conv23.1.52, %conv29.1.52
  %scevgep35.1.52 = getelementptr i8, i8* %a, i64 54
  %907 = load i8, i8* %scevgep35.1.52, align 1
  %908 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.52 = call zeroext i8 @mult(i8 zeroext %907, i8 zeroext %908)
  %conv35.1.52 = zext i8 %call34.1.52 to i32
  %xor36.1.52 = xor i32 %xor.1.52, %conv35.1.52
  %conv37.1.52 = trunc i32 %xor36.1.52 to i8
  store i8 %conv37.1.52, i8* %scevgep41.1.51, align 1
  %scevgep28.1.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %902, i64 0, i64 0, i64 1
  %909 = bitcast i8* %scevgep28.1.52 to [61 x [61 x i8]]*
  %scevgep41.1.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %903, i64 0, i64 1, i64 0
  %910 = bitcast i8* %scevgep41.1.52 to [61 x [61 x i8]]*
  %call16.1.53 = call zeroext i8 (...) @rand()
  store i8 %call16.1.53, i8* %scevgep28.1.52, align 1
  %911 = load i8, i8* %scevgep28.1.52, align 1
  %conv23.1.53 = zext i8 %911 to i32
  %912 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.53 = getelementptr i8, i8* %b, i64 55
  %913 = load i8, i8* %scevgep34.1.53, align 1
  %call28.1.53 = call zeroext i8 @mult(i8 zeroext %912, i8 zeroext %913)
  %conv29.1.53 = zext i8 %call28.1.53 to i32
  %xor.1.53 = xor i32 %conv23.1.53, %conv29.1.53
  %scevgep35.1.53 = getelementptr i8, i8* %a, i64 55
  %914 = load i8, i8* %scevgep35.1.53, align 1
  %915 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.53 = call zeroext i8 @mult(i8 zeroext %914, i8 zeroext %915)
  %conv35.1.53 = zext i8 %call34.1.53 to i32
  %xor36.1.53 = xor i32 %xor.1.53, %conv35.1.53
  %conv37.1.53 = trunc i32 %xor36.1.53 to i8
  store i8 %conv37.1.53, i8* %scevgep41.1.52, align 1
  %scevgep28.1.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %909, i64 0, i64 0, i64 1
  %916 = bitcast i8* %scevgep28.1.53 to [61 x [61 x i8]]*
  %scevgep41.1.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %910, i64 0, i64 1, i64 0
  %917 = bitcast i8* %scevgep41.1.53 to [61 x [61 x i8]]*
  %call16.1.54 = call zeroext i8 (...) @rand()
  store i8 %call16.1.54, i8* %scevgep28.1.53, align 1
  %918 = load i8, i8* %scevgep28.1.53, align 1
  %conv23.1.54 = zext i8 %918 to i32
  %919 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.54 = getelementptr i8, i8* %b, i64 56
  %920 = load i8, i8* %scevgep34.1.54, align 1
  %call28.1.54 = call zeroext i8 @mult(i8 zeroext %919, i8 zeroext %920)
  %conv29.1.54 = zext i8 %call28.1.54 to i32
  %xor.1.54 = xor i32 %conv23.1.54, %conv29.1.54
  %scevgep35.1.54 = getelementptr i8, i8* %a, i64 56
  %921 = load i8, i8* %scevgep35.1.54, align 1
  %922 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.54 = call zeroext i8 @mult(i8 zeroext %921, i8 zeroext %922)
  %conv35.1.54 = zext i8 %call34.1.54 to i32
  %xor36.1.54 = xor i32 %xor.1.54, %conv35.1.54
  %conv37.1.54 = trunc i32 %xor36.1.54 to i8
  store i8 %conv37.1.54, i8* %scevgep41.1.53, align 1
  %scevgep28.1.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %916, i64 0, i64 0, i64 1
  %923 = bitcast i8* %scevgep28.1.54 to [61 x [61 x i8]]*
  %scevgep41.1.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %917, i64 0, i64 1, i64 0
  %924 = bitcast i8* %scevgep41.1.54 to [61 x [61 x i8]]*
  %call16.1.55 = call zeroext i8 (...) @rand()
  store i8 %call16.1.55, i8* %scevgep28.1.54, align 1
  %925 = load i8, i8* %scevgep28.1.54, align 1
  %conv23.1.55 = zext i8 %925 to i32
  %926 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.55 = getelementptr i8, i8* %b, i64 57
  %927 = load i8, i8* %scevgep34.1.55, align 1
  %call28.1.55 = call zeroext i8 @mult(i8 zeroext %926, i8 zeroext %927)
  %conv29.1.55 = zext i8 %call28.1.55 to i32
  %xor.1.55 = xor i32 %conv23.1.55, %conv29.1.55
  %scevgep35.1.55 = getelementptr i8, i8* %a, i64 57
  %928 = load i8, i8* %scevgep35.1.55, align 1
  %929 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.55 = call zeroext i8 @mult(i8 zeroext %928, i8 zeroext %929)
  %conv35.1.55 = zext i8 %call34.1.55 to i32
  %xor36.1.55 = xor i32 %xor.1.55, %conv35.1.55
  %conv37.1.55 = trunc i32 %xor36.1.55 to i8
  store i8 %conv37.1.55, i8* %scevgep41.1.54, align 1
  %scevgep28.1.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %923, i64 0, i64 0, i64 1
  %930 = bitcast i8* %scevgep28.1.55 to [61 x [61 x i8]]*
  %scevgep41.1.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %924, i64 0, i64 1, i64 0
  %931 = bitcast i8* %scevgep41.1.55 to [61 x [61 x i8]]*
  %call16.1.56 = call zeroext i8 (...) @rand()
  store i8 %call16.1.56, i8* %scevgep28.1.55, align 1
  %932 = load i8, i8* %scevgep28.1.55, align 1
  %conv23.1.56 = zext i8 %932 to i32
  %933 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.56 = getelementptr i8, i8* %b, i64 58
  %934 = load i8, i8* %scevgep34.1.56, align 1
  %call28.1.56 = call zeroext i8 @mult(i8 zeroext %933, i8 zeroext %934)
  %conv29.1.56 = zext i8 %call28.1.56 to i32
  %xor.1.56 = xor i32 %conv23.1.56, %conv29.1.56
  %scevgep35.1.56 = getelementptr i8, i8* %a, i64 58
  %935 = load i8, i8* %scevgep35.1.56, align 1
  %936 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.56 = call zeroext i8 @mult(i8 zeroext %935, i8 zeroext %936)
  %conv35.1.56 = zext i8 %call34.1.56 to i32
  %xor36.1.56 = xor i32 %xor.1.56, %conv35.1.56
  %conv37.1.56 = trunc i32 %xor36.1.56 to i8
  store i8 %conv37.1.56, i8* %scevgep41.1.55, align 1
  %scevgep28.1.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %930, i64 0, i64 0, i64 1
  %937 = bitcast i8* %scevgep28.1.56 to [61 x [61 x i8]]*
  %scevgep41.1.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %931, i64 0, i64 1, i64 0
  %938 = bitcast i8* %scevgep41.1.56 to [61 x [61 x i8]]*
  %call16.1.57 = call zeroext i8 (...) @rand()
  store i8 %call16.1.57, i8* %scevgep28.1.56, align 1
  %939 = load i8, i8* %scevgep28.1.56, align 1
  %conv23.1.57 = zext i8 %939 to i32
  %940 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.57 = getelementptr i8, i8* %b, i64 59
  %941 = load i8, i8* %scevgep34.1.57, align 1
  %call28.1.57 = call zeroext i8 @mult(i8 zeroext %940, i8 zeroext %941)
  %conv29.1.57 = zext i8 %call28.1.57 to i32
  %xor.1.57 = xor i32 %conv23.1.57, %conv29.1.57
  %scevgep35.1.57 = getelementptr i8, i8* %a, i64 59
  %942 = load i8, i8* %scevgep35.1.57, align 1
  %943 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.57 = call zeroext i8 @mult(i8 zeroext %942, i8 zeroext %943)
  %conv35.1.57 = zext i8 %call34.1.57 to i32
  %xor36.1.57 = xor i32 %xor.1.57, %conv35.1.57
  %conv37.1.57 = trunc i32 %xor36.1.57 to i8
  store i8 %conv37.1.57, i8* %scevgep41.1.56, align 1
  %scevgep28.1.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %937, i64 0, i64 0, i64 1
  %scevgep41.1.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %938, i64 0, i64 1, i64 0
  %call16.1.58 = call zeroext i8 (...) @rand()
  store i8 %call16.1.58, i8* %scevgep28.1.57, align 1
  %944 = load i8, i8* %scevgep28.1.57, align 1
  %conv23.1.58 = zext i8 %944 to i32
  %945 = load i8, i8* %arrayidx25.1, align 1
  %scevgep34.1.58 = getelementptr i8, i8* %b, i64 60
  %946 = load i8, i8* %scevgep34.1.58, align 1
  %call28.1.58 = call zeroext i8 @mult(i8 zeroext %945, i8 zeroext %946)
  %conv29.1.58 = zext i8 %call28.1.58 to i32
  %xor.1.58 = xor i32 %conv23.1.58, %conv29.1.58
  %scevgep35.1.58 = getelementptr i8, i8* %a, i64 60
  %947 = load i8, i8* %scevgep35.1.58, align 1
  %948 = load i8, i8* %arrayidx33.1, align 1
  %call34.1.58 = call zeroext i8 @mult(i8 zeroext %947, i8 zeroext %948)
  %conv35.1.58 = zext i8 %call34.1.58 to i32
  %xor36.1.58 = xor i32 %xor.1.58, %conv35.1.58
  %conv37.1.58 = trunc i32 %xor36.1.58 to i8
  store i8 %conv37.1.58, i8* %scevgep41.1.57, align 1
  %scevgep26.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %538, i64 0, i64 1, i64 1
  %949 = bitcast i8* %scevgep26.1 to [61 x [61 x i8]]*
  %scevgep39.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %539, i64 0, i64 1, i64 1
  %950 = bitcast i8* %scevgep39.1 to [61 x [61 x i8]]*
  %arrayidx25.2 = getelementptr inbounds i8, i8* %a, i64 2
  %arrayidx33.2 = getelementptr inbounds i8, i8* %b, i64 2
  %call16.2 = call zeroext i8 (...) @rand()
  store i8 %call16.2, i8* %scevgep26.1, align 1
  %951 = load i8, i8* %scevgep26.1, align 1
  %conv23.2 = zext i8 %951 to i32
  %952 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2 = getelementptr i8, i8* %b, i64 3
  %953 = load i8, i8* %scevgep34.2, align 1
  %call28.2 = call zeroext i8 @mult(i8 zeroext %952, i8 zeroext %953)
  %conv29.2 = zext i8 %call28.2 to i32
  %xor.2 = xor i32 %conv23.2, %conv29.2
  %scevgep35.2 = getelementptr i8, i8* %a, i64 3
  %954 = load i8, i8* %scevgep35.2, align 1
  %955 = load i8, i8* %arrayidx33.2, align 1
  %call34.2 = call zeroext i8 @mult(i8 zeroext %954, i8 zeroext %955)
  %conv35.2 = zext i8 %call34.2 to i32
  %xor36.2 = xor i32 %xor.2, %conv35.2
  %conv37.2 = trunc i32 %xor36.2 to i8
  store i8 %conv37.2, i8* %scevgep39.1, align 1
  %scevgep28.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %949, i64 0, i64 0, i64 1
  %956 = bitcast i8* %scevgep28.2 to [61 x [61 x i8]]*
  %scevgep41.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %950, i64 0, i64 1, i64 0
  %957 = bitcast i8* %scevgep41.2 to [61 x [61 x i8]]*
  %call16.2.1 = call zeroext i8 (...) @rand()
  store i8 %call16.2.1, i8* %scevgep28.2, align 1
  %958 = load i8, i8* %scevgep28.2, align 1
  %conv23.2.1 = zext i8 %958 to i32
  %959 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.1 = getelementptr i8, i8* %b, i64 4
  %960 = load i8, i8* %scevgep34.2.1, align 1
  %call28.2.1 = call zeroext i8 @mult(i8 zeroext %959, i8 zeroext %960)
  %conv29.2.1 = zext i8 %call28.2.1 to i32
  %xor.2.1 = xor i32 %conv23.2.1, %conv29.2.1
  %scevgep35.2.1 = getelementptr i8, i8* %a, i64 4
  %961 = load i8, i8* %scevgep35.2.1, align 1
  %962 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.1 = call zeroext i8 @mult(i8 zeroext %961, i8 zeroext %962)
  %conv35.2.1 = zext i8 %call34.2.1 to i32
  %xor36.2.1 = xor i32 %xor.2.1, %conv35.2.1
  %conv37.2.1 = trunc i32 %xor36.2.1 to i8
  store i8 %conv37.2.1, i8* %scevgep41.2, align 1
  %scevgep28.2.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %956, i64 0, i64 0, i64 1
  %963 = bitcast i8* %scevgep28.2.1 to [61 x [61 x i8]]*
  %scevgep41.2.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %957, i64 0, i64 1, i64 0
  %964 = bitcast i8* %scevgep41.2.1 to [61 x [61 x i8]]*
  %call16.2.2 = call zeroext i8 (...) @rand()
  store i8 %call16.2.2, i8* %scevgep28.2.1, align 1
  %965 = load i8, i8* %scevgep28.2.1, align 1
  %conv23.2.2 = zext i8 %965 to i32
  %966 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.2 = getelementptr i8, i8* %b, i64 5
  %967 = load i8, i8* %scevgep34.2.2, align 1
  %call28.2.2 = call zeroext i8 @mult(i8 zeroext %966, i8 zeroext %967)
  %conv29.2.2 = zext i8 %call28.2.2 to i32
  %xor.2.2 = xor i32 %conv23.2.2, %conv29.2.2
  %scevgep35.2.2 = getelementptr i8, i8* %a, i64 5
  %968 = load i8, i8* %scevgep35.2.2, align 1
  %969 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.2 = call zeroext i8 @mult(i8 zeroext %968, i8 zeroext %969)
  %conv35.2.2 = zext i8 %call34.2.2 to i32
  %xor36.2.2 = xor i32 %xor.2.2, %conv35.2.2
  %conv37.2.2 = trunc i32 %xor36.2.2 to i8
  store i8 %conv37.2.2, i8* %scevgep41.2.1, align 1
  %scevgep28.2.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %963, i64 0, i64 0, i64 1
  %970 = bitcast i8* %scevgep28.2.2 to [61 x [61 x i8]]*
  %scevgep41.2.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %964, i64 0, i64 1, i64 0
  %971 = bitcast i8* %scevgep41.2.2 to [61 x [61 x i8]]*
  %call16.2.3 = call zeroext i8 (...) @rand()
  store i8 %call16.2.3, i8* %scevgep28.2.2, align 1
  %972 = load i8, i8* %scevgep28.2.2, align 1
  %conv23.2.3 = zext i8 %972 to i32
  %973 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.3 = getelementptr i8, i8* %b, i64 6
  %974 = load i8, i8* %scevgep34.2.3, align 1
  %call28.2.3 = call zeroext i8 @mult(i8 zeroext %973, i8 zeroext %974)
  %conv29.2.3 = zext i8 %call28.2.3 to i32
  %xor.2.3 = xor i32 %conv23.2.3, %conv29.2.3
  %scevgep35.2.3 = getelementptr i8, i8* %a, i64 6
  %975 = load i8, i8* %scevgep35.2.3, align 1
  %976 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.3 = call zeroext i8 @mult(i8 zeroext %975, i8 zeroext %976)
  %conv35.2.3 = zext i8 %call34.2.3 to i32
  %xor36.2.3 = xor i32 %xor.2.3, %conv35.2.3
  %conv37.2.3 = trunc i32 %xor36.2.3 to i8
  store i8 %conv37.2.3, i8* %scevgep41.2.2, align 1
  %scevgep28.2.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %970, i64 0, i64 0, i64 1
  %977 = bitcast i8* %scevgep28.2.3 to [61 x [61 x i8]]*
  %scevgep41.2.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %971, i64 0, i64 1, i64 0
  %978 = bitcast i8* %scevgep41.2.3 to [61 x [61 x i8]]*
  %call16.2.4 = call zeroext i8 (...) @rand()
  store i8 %call16.2.4, i8* %scevgep28.2.3, align 1
  %979 = load i8, i8* %scevgep28.2.3, align 1
  %conv23.2.4 = zext i8 %979 to i32
  %980 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.4 = getelementptr i8, i8* %b, i64 7
  %981 = load i8, i8* %scevgep34.2.4, align 1
  %call28.2.4 = call zeroext i8 @mult(i8 zeroext %980, i8 zeroext %981)
  %conv29.2.4 = zext i8 %call28.2.4 to i32
  %xor.2.4 = xor i32 %conv23.2.4, %conv29.2.4
  %scevgep35.2.4 = getelementptr i8, i8* %a, i64 7
  %982 = load i8, i8* %scevgep35.2.4, align 1
  %983 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.4 = call zeroext i8 @mult(i8 zeroext %982, i8 zeroext %983)
  %conv35.2.4 = zext i8 %call34.2.4 to i32
  %xor36.2.4 = xor i32 %xor.2.4, %conv35.2.4
  %conv37.2.4 = trunc i32 %xor36.2.4 to i8
  store i8 %conv37.2.4, i8* %scevgep41.2.3, align 1
  %scevgep28.2.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %977, i64 0, i64 0, i64 1
  %984 = bitcast i8* %scevgep28.2.4 to [61 x [61 x i8]]*
  %scevgep41.2.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %978, i64 0, i64 1, i64 0
  %985 = bitcast i8* %scevgep41.2.4 to [61 x [61 x i8]]*
  %call16.2.5 = call zeroext i8 (...) @rand()
  store i8 %call16.2.5, i8* %scevgep28.2.4, align 1
  %986 = load i8, i8* %scevgep28.2.4, align 1
  %conv23.2.5 = zext i8 %986 to i32
  %987 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.5 = getelementptr i8, i8* %b, i64 8
  %988 = load i8, i8* %scevgep34.2.5, align 1
  %call28.2.5 = call zeroext i8 @mult(i8 zeroext %987, i8 zeroext %988)
  %conv29.2.5 = zext i8 %call28.2.5 to i32
  %xor.2.5 = xor i32 %conv23.2.5, %conv29.2.5
  %scevgep35.2.5 = getelementptr i8, i8* %a, i64 8
  %989 = load i8, i8* %scevgep35.2.5, align 1
  %990 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.5 = call zeroext i8 @mult(i8 zeroext %989, i8 zeroext %990)
  %conv35.2.5 = zext i8 %call34.2.5 to i32
  %xor36.2.5 = xor i32 %xor.2.5, %conv35.2.5
  %conv37.2.5 = trunc i32 %xor36.2.5 to i8
  store i8 %conv37.2.5, i8* %scevgep41.2.4, align 1
  %scevgep28.2.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %984, i64 0, i64 0, i64 1
  %991 = bitcast i8* %scevgep28.2.5 to [61 x [61 x i8]]*
  %scevgep41.2.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %985, i64 0, i64 1, i64 0
  %992 = bitcast i8* %scevgep41.2.5 to [61 x [61 x i8]]*
  %call16.2.6 = call zeroext i8 (...) @rand()
  store i8 %call16.2.6, i8* %scevgep28.2.5, align 1
  %993 = load i8, i8* %scevgep28.2.5, align 1
  %conv23.2.6 = zext i8 %993 to i32
  %994 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.6 = getelementptr i8, i8* %b, i64 9
  %995 = load i8, i8* %scevgep34.2.6, align 1
  %call28.2.6 = call zeroext i8 @mult(i8 zeroext %994, i8 zeroext %995)
  %conv29.2.6 = zext i8 %call28.2.6 to i32
  %xor.2.6 = xor i32 %conv23.2.6, %conv29.2.6
  %scevgep35.2.6 = getelementptr i8, i8* %a, i64 9
  %996 = load i8, i8* %scevgep35.2.6, align 1
  %997 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.6 = call zeroext i8 @mult(i8 zeroext %996, i8 zeroext %997)
  %conv35.2.6 = zext i8 %call34.2.6 to i32
  %xor36.2.6 = xor i32 %xor.2.6, %conv35.2.6
  %conv37.2.6 = trunc i32 %xor36.2.6 to i8
  store i8 %conv37.2.6, i8* %scevgep41.2.5, align 1
  %scevgep28.2.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %991, i64 0, i64 0, i64 1
  %998 = bitcast i8* %scevgep28.2.6 to [61 x [61 x i8]]*
  %scevgep41.2.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %992, i64 0, i64 1, i64 0
  %999 = bitcast i8* %scevgep41.2.6 to [61 x [61 x i8]]*
  %call16.2.7 = call zeroext i8 (...) @rand()
  store i8 %call16.2.7, i8* %scevgep28.2.6, align 1
  %1000 = load i8, i8* %scevgep28.2.6, align 1
  %conv23.2.7 = zext i8 %1000 to i32
  %1001 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.7 = getelementptr i8, i8* %b, i64 10
  %1002 = load i8, i8* %scevgep34.2.7, align 1
  %call28.2.7 = call zeroext i8 @mult(i8 zeroext %1001, i8 zeroext %1002)
  %conv29.2.7 = zext i8 %call28.2.7 to i32
  %xor.2.7 = xor i32 %conv23.2.7, %conv29.2.7
  %scevgep35.2.7 = getelementptr i8, i8* %a, i64 10
  %1003 = load i8, i8* %scevgep35.2.7, align 1
  %1004 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.7 = call zeroext i8 @mult(i8 zeroext %1003, i8 zeroext %1004)
  %conv35.2.7 = zext i8 %call34.2.7 to i32
  %xor36.2.7 = xor i32 %xor.2.7, %conv35.2.7
  %conv37.2.7 = trunc i32 %xor36.2.7 to i8
  store i8 %conv37.2.7, i8* %scevgep41.2.6, align 1
  %scevgep28.2.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %998, i64 0, i64 0, i64 1
  %1005 = bitcast i8* %scevgep28.2.7 to [61 x [61 x i8]]*
  %scevgep41.2.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %999, i64 0, i64 1, i64 0
  %1006 = bitcast i8* %scevgep41.2.7 to [61 x [61 x i8]]*
  %call16.2.8 = call zeroext i8 (...) @rand()
  store i8 %call16.2.8, i8* %scevgep28.2.7, align 1
  %1007 = load i8, i8* %scevgep28.2.7, align 1
  %conv23.2.8 = zext i8 %1007 to i32
  %1008 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.8 = getelementptr i8, i8* %b, i64 11
  %1009 = load i8, i8* %scevgep34.2.8, align 1
  %call28.2.8 = call zeroext i8 @mult(i8 zeroext %1008, i8 zeroext %1009)
  %conv29.2.8 = zext i8 %call28.2.8 to i32
  %xor.2.8 = xor i32 %conv23.2.8, %conv29.2.8
  %scevgep35.2.8 = getelementptr i8, i8* %a, i64 11
  %1010 = load i8, i8* %scevgep35.2.8, align 1
  %1011 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.8 = call zeroext i8 @mult(i8 zeroext %1010, i8 zeroext %1011)
  %conv35.2.8 = zext i8 %call34.2.8 to i32
  %xor36.2.8 = xor i32 %xor.2.8, %conv35.2.8
  %conv37.2.8 = trunc i32 %xor36.2.8 to i8
  store i8 %conv37.2.8, i8* %scevgep41.2.7, align 1
  %scevgep28.2.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1005, i64 0, i64 0, i64 1
  %1012 = bitcast i8* %scevgep28.2.8 to [61 x [61 x i8]]*
  %scevgep41.2.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1006, i64 0, i64 1, i64 0
  %1013 = bitcast i8* %scevgep41.2.8 to [61 x [61 x i8]]*
  %call16.2.9 = call zeroext i8 (...) @rand()
  store i8 %call16.2.9, i8* %scevgep28.2.8, align 1
  %1014 = load i8, i8* %scevgep28.2.8, align 1
  %conv23.2.9 = zext i8 %1014 to i32
  %1015 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.9 = getelementptr i8, i8* %b, i64 12
  %1016 = load i8, i8* %scevgep34.2.9, align 1
  %call28.2.9 = call zeroext i8 @mult(i8 zeroext %1015, i8 zeroext %1016)
  %conv29.2.9 = zext i8 %call28.2.9 to i32
  %xor.2.9 = xor i32 %conv23.2.9, %conv29.2.9
  %scevgep35.2.9 = getelementptr i8, i8* %a, i64 12
  %1017 = load i8, i8* %scevgep35.2.9, align 1
  %1018 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.9 = call zeroext i8 @mult(i8 zeroext %1017, i8 zeroext %1018)
  %conv35.2.9 = zext i8 %call34.2.9 to i32
  %xor36.2.9 = xor i32 %xor.2.9, %conv35.2.9
  %conv37.2.9 = trunc i32 %xor36.2.9 to i8
  store i8 %conv37.2.9, i8* %scevgep41.2.8, align 1
  %scevgep28.2.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1012, i64 0, i64 0, i64 1
  %1019 = bitcast i8* %scevgep28.2.9 to [61 x [61 x i8]]*
  %scevgep41.2.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1013, i64 0, i64 1, i64 0
  %1020 = bitcast i8* %scevgep41.2.9 to [61 x [61 x i8]]*
  %call16.2.10 = call zeroext i8 (...) @rand()
  store i8 %call16.2.10, i8* %scevgep28.2.9, align 1
  %1021 = load i8, i8* %scevgep28.2.9, align 1
  %conv23.2.10 = zext i8 %1021 to i32
  %1022 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.10 = getelementptr i8, i8* %b, i64 13
  %1023 = load i8, i8* %scevgep34.2.10, align 1
  %call28.2.10 = call zeroext i8 @mult(i8 zeroext %1022, i8 zeroext %1023)
  %conv29.2.10 = zext i8 %call28.2.10 to i32
  %xor.2.10 = xor i32 %conv23.2.10, %conv29.2.10
  %scevgep35.2.10 = getelementptr i8, i8* %a, i64 13
  %1024 = load i8, i8* %scevgep35.2.10, align 1
  %1025 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.10 = call zeroext i8 @mult(i8 zeroext %1024, i8 zeroext %1025)
  %conv35.2.10 = zext i8 %call34.2.10 to i32
  %xor36.2.10 = xor i32 %xor.2.10, %conv35.2.10
  %conv37.2.10 = trunc i32 %xor36.2.10 to i8
  store i8 %conv37.2.10, i8* %scevgep41.2.9, align 1
  %scevgep28.2.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1019, i64 0, i64 0, i64 1
  %1026 = bitcast i8* %scevgep28.2.10 to [61 x [61 x i8]]*
  %scevgep41.2.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1020, i64 0, i64 1, i64 0
  %1027 = bitcast i8* %scevgep41.2.10 to [61 x [61 x i8]]*
  %call16.2.11 = call zeroext i8 (...) @rand()
  store i8 %call16.2.11, i8* %scevgep28.2.10, align 1
  %1028 = load i8, i8* %scevgep28.2.10, align 1
  %conv23.2.11 = zext i8 %1028 to i32
  %1029 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.11 = getelementptr i8, i8* %b, i64 14
  %1030 = load i8, i8* %scevgep34.2.11, align 1
  %call28.2.11 = call zeroext i8 @mult(i8 zeroext %1029, i8 zeroext %1030)
  %conv29.2.11 = zext i8 %call28.2.11 to i32
  %xor.2.11 = xor i32 %conv23.2.11, %conv29.2.11
  %scevgep35.2.11 = getelementptr i8, i8* %a, i64 14
  %1031 = load i8, i8* %scevgep35.2.11, align 1
  %1032 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.11 = call zeroext i8 @mult(i8 zeroext %1031, i8 zeroext %1032)
  %conv35.2.11 = zext i8 %call34.2.11 to i32
  %xor36.2.11 = xor i32 %xor.2.11, %conv35.2.11
  %conv37.2.11 = trunc i32 %xor36.2.11 to i8
  store i8 %conv37.2.11, i8* %scevgep41.2.10, align 1
  %scevgep28.2.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1026, i64 0, i64 0, i64 1
  %1033 = bitcast i8* %scevgep28.2.11 to [61 x [61 x i8]]*
  %scevgep41.2.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1027, i64 0, i64 1, i64 0
  %1034 = bitcast i8* %scevgep41.2.11 to [61 x [61 x i8]]*
  %call16.2.12 = call zeroext i8 (...) @rand()
  store i8 %call16.2.12, i8* %scevgep28.2.11, align 1
  %1035 = load i8, i8* %scevgep28.2.11, align 1
  %conv23.2.12 = zext i8 %1035 to i32
  %1036 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.12 = getelementptr i8, i8* %b, i64 15
  %1037 = load i8, i8* %scevgep34.2.12, align 1
  %call28.2.12 = call zeroext i8 @mult(i8 zeroext %1036, i8 zeroext %1037)
  %conv29.2.12 = zext i8 %call28.2.12 to i32
  %xor.2.12 = xor i32 %conv23.2.12, %conv29.2.12
  %scevgep35.2.12 = getelementptr i8, i8* %a, i64 15
  %1038 = load i8, i8* %scevgep35.2.12, align 1
  %1039 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.12 = call zeroext i8 @mult(i8 zeroext %1038, i8 zeroext %1039)
  %conv35.2.12 = zext i8 %call34.2.12 to i32
  %xor36.2.12 = xor i32 %xor.2.12, %conv35.2.12
  %conv37.2.12 = trunc i32 %xor36.2.12 to i8
  store i8 %conv37.2.12, i8* %scevgep41.2.11, align 1
  %scevgep28.2.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1033, i64 0, i64 0, i64 1
  %1040 = bitcast i8* %scevgep28.2.12 to [61 x [61 x i8]]*
  %scevgep41.2.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1034, i64 0, i64 1, i64 0
  %1041 = bitcast i8* %scevgep41.2.12 to [61 x [61 x i8]]*
  %call16.2.13 = call zeroext i8 (...) @rand()
  store i8 %call16.2.13, i8* %scevgep28.2.12, align 1
  %1042 = load i8, i8* %scevgep28.2.12, align 1
  %conv23.2.13 = zext i8 %1042 to i32
  %1043 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.13 = getelementptr i8, i8* %b, i64 16
  %1044 = load i8, i8* %scevgep34.2.13, align 1
  %call28.2.13 = call zeroext i8 @mult(i8 zeroext %1043, i8 zeroext %1044)
  %conv29.2.13 = zext i8 %call28.2.13 to i32
  %xor.2.13 = xor i32 %conv23.2.13, %conv29.2.13
  %scevgep35.2.13 = getelementptr i8, i8* %a, i64 16
  %1045 = load i8, i8* %scevgep35.2.13, align 1
  %1046 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.13 = call zeroext i8 @mult(i8 zeroext %1045, i8 zeroext %1046)
  %conv35.2.13 = zext i8 %call34.2.13 to i32
  %xor36.2.13 = xor i32 %xor.2.13, %conv35.2.13
  %conv37.2.13 = trunc i32 %xor36.2.13 to i8
  store i8 %conv37.2.13, i8* %scevgep41.2.12, align 1
  %scevgep28.2.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1040, i64 0, i64 0, i64 1
  %1047 = bitcast i8* %scevgep28.2.13 to [61 x [61 x i8]]*
  %scevgep41.2.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1041, i64 0, i64 1, i64 0
  %1048 = bitcast i8* %scevgep41.2.13 to [61 x [61 x i8]]*
  %call16.2.14 = call zeroext i8 (...) @rand()
  store i8 %call16.2.14, i8* %scevgep28.2.13, align 1
  %1049 = load i8, i8* %scevgep28.2.13, align 1
  %conv23.2.14 = zext i8 %1049 to i32
  %1050 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.14 = getelementptr i8, i8* %b, i64 17
  %1051 = load i8, i8* %scevgep34.2.14, align 1
  %call28.2.14 = call zeroext i8 @mult(i8 zeroext %1050, i8 zeroext %1051)
  %conv29.2.14 = zext i8 %call28.2.14 to i32
  %xor.2.14 = xor i32 %conv23.2.14, %conv29.2.14
  %scevgep35.2.14 = getelementptr i8, i8* %a, i64 17
  %1052 = load i8, i8* %scevgep35.2.14, align 1
  %1053 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.14 = call zeroext i8 @mult(i8 zeroext %1052, i8 zeroext %1053)
  %conv35.2.14 = zext i8 %call34.2.14 to i32
  %xor36.2.14 = xor i32 %xor.2.14, %conv35.2.14
  %conv37.2.14 = trunc i32 %xor36.2.14 to i8
  store i8 %conv37.2.14, i8* %scevgep41.2.13, align 1
  %scevgep28.2.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1047, i64 0, i64 0, i64 1
  %1054 = bitcast i8* %scevgep28.2.14 to [61 x [61 x i8]]*
  %scevgep41.2.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1048, i64 0, i64 1, i64 0
  %1055 = bitcast i8* %scevgep41.2.14 to [61 x [61 x i8]]*
  %call16.2.15 = call zeroext i8 (...) @rand()
  store i8 %call16.2.15, i8* %scevgep28.2.14, align 1
  %1056 = load i8, i8* %scevgep28.2.14, align 1
  %conv23.2.15 = zext i8 %1056 to i32
  %1057 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.15 = getelementptr i8, i8* %b, i64 18
  %1058 = load i8, i8* %scevgep34.2.15, align 1
  %call28.2.15 = call zeroext i8 @mult(i8 zeroext %1057, i8 zeroext %1058)
  %conv29.2.15 = zext i8 %call28.2.15 to i32
  %xor.2.15 = xor i32 %conv23.2.15, %conv29.2.15
  %scevgep35.2.15 = getelementptr i8, i8* %a, i64 18
  %1059 = load i8, i8* %scevgep35.2.15, align 1
  %1060 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.15 = call zeroext i8 @mult(i8 zeroext %1059, i8 zeroext %1060)
  %conv35.2.15 = zext i8 %call34.2.15 to i32
  %xor36.2.15 = xor i32 %xor.2.15, %conv35.2.15
  %conv37.2.15 = trunc i32 %xor36.2.15 to i8
  store i8 %conv37.2.15, i8* %scevgep41.2.14, align 1
  %scevgep28.2.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1054, i64 0, i64 0, i64 1
  %1061 = bitcast i8* %scevgep28.2.15 to [61 x [61 x i8]]*
  %scevgep41.2.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1055, i64 0, i64 1, i64 0
  %1062 = bitcast i8* %scevgep41.2.15 to [61 x [61 x i8]]*
  %call16.2.16 = call zeroext i8 (...) @rand()
  store i8 %call16.2.16, i8* %scevgep28.2.15, align 1
  %1063 = load i8, i8* %scevgep28.2.15, align 1
  %conv23.2.16 = zext i8 %1063 to i32
  %1064 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.16 = getelementptr i8, i8* %b, i64 19
  %1065 = load i8, i8* %scevgep34.2.16, align 1
  %call28.2.16 = call zeroext i8 @mult(i8 zeroext %1064, i8 zeroext %1065)
  %conv29.2.16 = zext i8 %call28.2.16 to i32
  %xor.2.16 = xor i32 %conv23.2.16, %conv29.2.16
  %scevgep35.2.16 = getelementptr i8, i8* %a, i64 19
  %1066 = load i8, i8* %scevgep35.2.16, align 1
  %1067 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.16 = call zeroext i8 @mult(i8 zeroext %1066, i8 zeroext %1067)
  %conv35.2.16 = zext i8 %call34.2.16 to i32
  %xor36.2.16 = xor i32 %xor.2.16, %conv35.2.16
  %conv37.2.16 = trunc i32 %xor36.2.16 to i8
  store i8 %conv37.2.16, i8* %scevgep41.2.15, align 1
  %scevgep28.2.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1061, i64 0, i64 0, i64 1
  %1068 = bitcast i8* %scevgep28.2.16 to [61 x [61 x i8]]*
  %scevgep41.2.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1062, i64 0, i64 1, i64 0
  %1069 = bitcast i8* %scevgep41.2.16 to [61 x [61 x i8]]*
  %call16.2.17 = call zeroext i8 (...) @rand()
  store i8 %call16.2.17, i8* %scevgep28.2.16, align 1
  %1070 = load i8, i8* %scevgep28.2.16, align 1
  %conv23.2.17 = zext i8 %1070 to i32
  %1071 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.17 = getelementptr i8, i8* %b, i64 20
  %1072 = load i8, i8* %scevgep34.2.17, align 1
  %call28.2.17 = call zeroext i8 @mult(i8 zeroext %1071, i8 zeroext %1072)
  %conv29.2.17 = zext i8 %call28.2.17 to i32
  %xor.2.17 = xor i32 %conv23.2.17, %conv29.2.17
  %scevgep35.2.17 = getelementptr i8, i8* %a, i64 20
  %1073 = load i8, i8* %scevgep35.2.17, align 1
  %1074 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.17 = call zeroext i8 @mult(i8 zeroext %1073, i8 zeroext %1074)
  %conv35.2.17 = zext i8 %call34.2.17 to i32
  %xor36.2.17 = xor i32 %xor.2.17, %conv35.2.17
  %conv37.2.17 = trunc i32 %xor36.2.17 to i8
  store i8 %conv37.2.17, i8* %scevgep41.2.16, align 1
  %scevgep28.2.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1068, i64 0, i64 0, i64 1
  %1075 = bitcast i8* %scevgep28.2.17 to [61 x [61 x i8]]*
  %scevgep41.2.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1069, i64 0, i64 1, i64 0
  %1076 = bitcast i8* %scevgep41.2.17 to [61 x [61 x i8]]*
  %call16.2.18 = call zeroext i8 (...) @rand()
  store i8 %call16.2.18, i8* %scevgep28.2.17, align 1
  %1077 = load i8, i8* %scevgep28.2.17, align 1
  %conv23.2.18 = zext i8 %1077 to i32
  %1078 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.18 = getelementptr i8, i8* %b, i64 21
  %1079 = load i8, i8* %scevgep34.2.18, align 1
  %call28.2.18 = call zeroext i8 @mult(i8 zeroext %1078, i8 zeroext %1079)
  %conv29.2.18 = zext i8 %call28.2.18 to i32
  %xor.2.18 = xor i32 %conv23.2.18, %conv29.2.18
  %scevgep35.2.18 = getelementptr i8, i8* %a, i64 21
  %1080 = load i8, i8* %scevgep35.2.18, align 1
  %1081 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.18 = call zeroext i8 @mult(i8 zeroext %1080, i8 zeroext %1081)
  %conv35.2.18 = zext i8 %call34.2.18 to i32
  %xor36.2.18 = xor i32 %xor.2.18, %conv35.2.18
  %conv37.2.18 = trunc i32 %xor36.2.18 to i8
  store i8 %conv37.2.18, i8* %scevgep41.2.17, align 1
  %scevgep28.2.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1075, i64 0, i64 0, i64 1
  %1082 = bitcast i8* %scevgep28.2.18 to [61 x [61 x i8]]*
  %scevgep41.2.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1076, i64 0, i64 1, i64 0
  %1083 = bitcast i8* %scevgep41.2.18 to [61 x [61 x i8]]*
  %call16.2.19 = call zeroext i8 (...) @rand()
  store i8 %call16.2.19, i8* %scevgep28.2.18, align 1
  %1084 = load i8, i8* %scevgep28.2.18, align 1
  %conv23.2.19 = zext i8 %1084 to i32
  %1085 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.19 = getelementptr i8, i8* %b, i64 22
  %1086 = load i8, i8* %scevgep34.2.19, align 1
  %call28.2.19 = call zeroext i8 @mult(i8 zeroext %1085, i8 zeroext %1086)
  %conv29.2.19 = zext i8 %call28.2.19 to i32
  %xor.2.19 = xor i32 %conv23.2.19, %conv29.2.19
  %scevgep35.2.19 = getelementptr i8, i8* %a, i64 22
  %1087 = load i8, i8* %scevgep35.2.19, align 1
  %1088 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.19 = call zeroext i8 @mult(i8 zeroext %1087, i8 zeroext %1088)
  %conv35.2.19 = zext i8 %call34.2.19 to i32
  %xor36.2.19 = xor i32 %xor.2.19, %conv35.2.19
  %conv37.2.19 = trunc i32 %xor36.2.19 to i8
  store i8 %conv37.2.19, i8* %scevgep41.2.18, align 1
  %scevgep28.2.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1082, i64 0, i64 0, i64 1
  %1089 = bitcast i8* %scevgep28.2.19 to [61 x [61 x i8]]*
  %scevgep41.2.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1083, i64 0, i64 1, i64 0
  %1090 = bitcast i8* %scevgep41.2.19 to [61 x [61 x i8]]*
  %call16.2.20 = call zeroext i8 (...) @rand()
  store i8 %call16.2.20, i8* %scevgep28.2.19, align 1
  %1091 = load i8, i8* %scevgep28.2.19, align 1
  %conv23.2.20 = zext i8 %1091 to i32
  %1092 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.20 = getelementptr i8, i8* %b, i64 23
  %1093 = load i8, i8* %scevgep34.2.20, align 1
  %call28.2.20 = call zeroext i8 @mult(i8 zeroext %1092, i8 zeroext %1093)
  %conv29.2.20 = zext i8 %call28.2.20 to i32
  %xor.2.20 = xor i32 %conv23.2.20, %conv29.2.20
  %scevgep35.2.20 = getelementptr i8, i8* %a, i64 23
  %1094 = load i8, i8* %scevgep35.2.20, align 1
  %1095 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.20 = call zeroext i8 @mult(i8 zeroext %1094, i8 zeroext %1095)
  %conv35.2.20 = zext i8 %call34.2.20 to i32
  %xor36.2.20 = xor i32 %xor.2.20, %conv35.2.20
  %conv37.2.20 = trunc i32 %xor36.2.20 to i8
  store i8 %conv37.2.20, i8* %scevgep41.2.19, align 1
  %scevgep28.2.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1089, i64 0, i64 0, i64 1
  %1096 = bitcast i8* %scevgep28.2.20 to [61 x [61 x i8]]*
  %scevgep41.2.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1090, i64 0, i64 1, i64 0
  %1097 = bitcast i8* %scevgep41.2.20 to [61 x [61 x i8]]*
  %call16.2.21 = call zeroext i8 (...) @rand()
  store i8 %call16.2.21, i8* %scevgep28.2.20, align 1
  %1098 = load i8, i8* %scevgep28.2.20, align 1
  %conv23.2.21 = zext i8 %1098 to i32
  %1099 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.21 = getelementptr i8, i8* %b, i64 24
  %1100 = load i8, i8* %scevgep34.2.21, align 1
  %call28.2.21 = call zeroext i8 @mult(i8 zeroext %1099, i8 zeroext %1100)
  %conv29.2.21 = zext i8 %call28.2.21 to i32
  %xor.2.21 = xor i32 %conv23.2.21, %conv29.2.21
  %scevgep35.2.21 = getelementptr i8, i8* %a, i64 24
  %1101 = load i8, i8* %scevgep35.2.21, align 1
  %1102 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.21 = call zeroext i8 @mult(i8 zeroext %1101, i8 zeroext %1102)
  %conv35.2.21 = zext i8 %call34.2.21 to i32
  %xor36.2.21 = xor i32 %xor.2.21, %conv35.2.21
  %conv37.2.21 = trunc i32 %xor36.2.21 to i8
  store i8 %conv37.2.21, i8* %scevgep41.2.20, align 1
  %scevgep28.2.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1096, i64 0, i64 0, i64 1
  %1103 = bitcast i8* %scevgep28.2.21 to [61 x [61 x i8]]*
  %scevgep41.2.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1097, i64 0, i64 1, i64 0
  %1104 = bitcast i8* %scevgep41.2.21 to [61 x [61 x i8]]*
  %call16.2.22 = call zeroext i8 (...) @rand()
  store i8 %call16.2.22, i8* %scevgep28.2.21, align 1
  %1105 = load i8, i8* %scevgep28.2.21, align 1
  %conv23.2.22 = zext i8 %1105 to i32
  %1106 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.22 = getelementptr i8, i8* %b, i64 25
  %1107 = load i8, i8* %scevgep34.2.22, align 1
  %call28.2.22 = call zeroext i8 @mult(i8 zeroext %1106, i8 zeroext %1107)
  %conv29.2.22 = zext i8 %call28.2.22 to i32
  %xor.2.22 = xor i32 %conv23.2.22, %conv29.2.22
  %scevgep35.2.22 = getelementptr i8, i8* %a, i64 25
  %1108 = load i8, i8* %scevgep35.2.22, align 1
  %1109 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.22 = call zeroext i8 @mult(i8 zeroext %1108, i8 zeroext %1109)
  %conv35.2.22 = zext i8 %call34.2.22 to i32
  %xor36.2.22 = xor i32 %xor.2.22, %conv35.2.22
  %conv37.2.22 = trunc i32 %xor36.2.22 to i8
  store i8 %conv37.2.22, i8* %scevgep41.2.21, align 1
  %scevgep28.2.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1103, i64 0, i64 0, i64 1
  %1110 = bitcast i8* %scevgep28.2.22 to [61 x [61 x i8]]*
  %scevgep41.2.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1104, i64 0, i64 1, i64 0
  %1111 = bitcast i8* %scevgep41.2.22 to [61 x [61 x i8]]*
  %call16.2.23 = call zeroext i8 (...) @rand()
  store i8 %call16.2.23, i8* %scevgep28.2.22, align 1
  %1112 = load i8, i8* %scevgep28.2.22, align 1
  %conv23.2.23 = zext i8 %1112 to i32
  %1113 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.23 = getelementptr i8, i8* %b, i64 26
  %1114 = load i8, i8* %scevgep34.2.23, align 1
  %call28.2.23 = call zeroext i8 @mult(i8 zeroext %1113, i8 zeroext %1114)
  %conv29.2.23 = zext i8 %call28.2.23 to i32
  %xor.2.23 = xor i32 %conv23.2.23, %conv29.2.23
  %scevgep35.2.23 = getelementptr i8, i8* %a, i64 26
  %1115 = load i8, i8* %scevgep35.2.23, align 1
  %1116 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.23 = call zeroext i8 @mult(i8 zeroext %1115, i8 zeroext %1116)
  %conv35.2.23 = zext i8 %call34.2.23 to i32
  %xor36.2.23 = xor i32 %xor.2.23, %conv35.2.23
  %conv37.2.23 = trunc i32 %xor36.2.23 to i8
  store i8 %conv37.2.23, i8* %scevgep41.2.22, align 1
  %scevgep28.2.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1110, i64 0, i64 0, i64 1
  %1117 = bitcast i8* %scevgep28.2.23 to [61 x [61 x i8]]*
  %scevgep41.2.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1111, i64 0, i64 1, i64 0
  %1118 = bitcast i8* %scevgep41.2.23 to [61 x [61 x i8]]*
  %call16.2.24 = call zeroext i8 (...) @rand()
  store i8 %call16.2.24, i8* %scevgep28.2.23, align 1
  %1119 = load i8, i8* %scevgep28.2.23, align 1
  %conv23.2.24 = zext i8 %1119 to i32
  %1120 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.24 = getelementptr i8, i8* %b, i64 27
  %1121 = load i8, i8* %scevgep34.2.24, align 1
  %call28.2.24 = call zeroext i8 @mult(i8 zeroext %1120, i8 zeroext %1121)
  %conv29.2.24 = zext i8 %call28.2.24 to i32
  %xor.2.24 = xor i32 %conv23.2.24, %conv29.2.24
  %scevgep35.2.24 = getelementptr i8, i8* %a, i64 27
  %1122 = load i8, i8* %scevgep35.2.24, align 1
  %1123 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.24 = call zeroext i8 @mult(i8 zeroext %1122, i8 zeroext %1123)
  %conv35.2.24 = zext i8 %call34.2.24 to i32
  %xor36.2.24 = xor i32 %xor.2.24, %conv35.2.24
  %conv37.2.24 = trunc i32 %xor36.2.24 to i8
  store i8 %conv37.2.24, i8* %scevgep41.2.23, align 1
  %scevgep28.2.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1117, i64 0, i64 0, i64 1
  %1124 = bitcast i8* %scevgep28.2.24 to [61 x [61 x i8]]*
  %scevgep41.2.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1118, i64 0, i64 1, i64 0
  %1125 = bitcast i8* %scevgep41.2.24 to [61 x [61 x i8]]*
  %call16.2.25 = call zeroext i8 (...) @rand()
  store i8 %call16.2.25, i8* %scevgep28.2.24, align 1
  %1126 = load i8, i8* %scevgep28.2.24, align 1
  %conv23.2.25 = zext i8 %1126 to i32
  %1127 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.25 = getelementptr i8, i8* %b, i64 28
  %1128 = load i8, i8* %scevgep34.2.25, align 1
  %call28.2.25 = call zeroext i8 @mult(i8 zeroext %1127, i8 zeroext %1128)
  %conv29.2.25 = zext i8 %call28.2.25 to i32
  %xor.2.25 = xor i32 %conv23.2.25, %conv29.2.25
  %scevgep35.2.25 = getelementptr i8, i8* %a, i64 28
  %1129 = load i8, i8* %scevgep35.2.25, align 1
  %1130 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.25 = call zeroext i8 @mult(i8 zeroext %1129, i8 zeroext %1130)
  %conv35.2.25 = zext i8 %call34.2.25 to i32
  %xor36.2.25 = xor i32 %xor.2.25, %conv35.2.25
  %conv37.2.25 = trunc i32 %xor36.2.25 to i8
  store i8 %conv37.2.25, i8* %scevgep41.2.24, align 1
  %scevgep28.2.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1124, i64 0, i64 0, i64 1
  %1131 = bitcast i8* %scevgep28.2.25 to [61 x [61 x i8]]*
  %scevgep41.2.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1125, i64 0, i64 1, i64 0
  %1132 = bitcast i8* %scevgep41.2.25 to [61 x [61 x i8]]*
  %call16.2.26 = call zeroext i8 (...) @rand()
  store i8 %call16.2.26, i8* %scevgep28.2.25, align 1
  %1133 = load i8, i8* %scevgep28.2.25, align 1
  %conv23.2.26 = zext i8 %1133 to i32
  %1134 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.26 = getelementptr i8, i8* %b, i64 29
  %1135 = load i8, i8* %scevgep34.2.26, align 1
  %call28.2.26 = call zeroext i8 @mult(i8 zeroext %1134, i8 zeroext %1135)
  %conv29.2.26 = zext i8 %call28.2.26 to i32
  %xor.2.26 = xor i32 %conv23.2.26, %conv29.2.26
  %scevgep35.2.26 = getelementptr i8, i8* %a, i64 29
  %1136 = load i8, i8* %scevgep35.2.26, align 1
  %1137 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.26 = call zeroext i8 @mult(i8 zeroext %1136, i8 zeroext %1137)
  %conv35.2.26 = zext i8 %call34.2.26 to i32
  %xor36.2.26 = xor i32 %xor.2.26, %conv35.2.26
  %conv37.2.26 = trunc i32 %xor36.2.26 to i8
  store i8 %conv37.2.26, i8* %scevgep41.2.25, align 1
  %scevgep28.2.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1131, i64 0, i64 0, i64 1
  %1138 = bitcast i8* %scevgep28.2.26 to [61 x [61 x i8]]*
  %scevgep41.2.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1132, i64 0, i64 1, i64 0
  %1139 = bitcast i8* %scevgep41.2.26 to [61 x [61 x i8]]*
  %call16.2.27 = call zeroext i8 (...) @rand()
  store i8 %call16.2.27, i8* %scevgep28.2.26, align 1
  %1140 = load i8, i8* %scevgep28.2.26, align 1
  %conv23.2.27 = zext i8 %1140 to i32
  %1141 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.27 = getelementptr i8, i8* %b, i64 30
  %1142 = load i8, i8* %scevgep34.2.27, align 1
  %call28.2.27 = call zeroext i8 @mult(i8 zeroext %1141, i8 zeroext %1142)
  %conv29.2.27 = zext i8 %call28.2.27 to i32
  %xor.2.27 = xor i32 %conv23.2.27, %conv29.2.27
  %scevgep35.2.27 = getelementptr i8, i8* %a, i64 30
  %1143 = load i8, i8* %scevgep35.2.27, align 1
  %1144 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.27 = call zeroext i8 @mult(i8 zeroext %1143, i8 zeroext %1144)
  %conv35.2.27 = zext i8 %call34.2.27 to i32
  %xor36.2.27 = xor i32 %xor.2.27, %conv35.2.27
  %conv37.2.27 = trunc i32 %xor36.2.27 to i8
  store i8 %conv37.2.27, i8* %scevgep41.2.26, align 1
  %scevgep28.2.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1138, i64 0, i64 0, i64 1
  %1145 = bitcast i8* %scevgep28.2.27 to [61 x [61 x i8]]*
  %scevgep41.2.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1139, i64 0, i64 1, i64 0
  %1146 = bitcast i8* %scevgep41.2.27 to [61 x [61 x i8]]*
  %call16.2.28 = call zeroext i8 (...) @rand()
  store i8 %call16.2.28, i8* %scevgep28.2.27, align 1
  %1147 = load i8, i8* %scevgep28.2.27, align 1
  %conv23.2.28 = zext i8 %1147 to i32
  %1148 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.28 = getelementptr i8, i8* %b, i64 31
  %1149 = load i8, i8* %scevgep34.2.28, align 1
  %call28.2.28 = call zeroext i8 @mult(i8 zeroext %1148, i8 zeroext %1149)
  %conv29.2.28 = zext i8 %call28.2.28 to i32
  %xor.2.28 = xor i32 %conv23.2.28, %conv29.2.28
  %scevgep35.2.28 = getelementptr i8, i8* %a, i64 31
  %1150 = load i8, i8* %scevgep35.2.28, align 1
  %1151 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.28 = call zeroext i8 @mult(i8 zeroext %1150, i8 zeroext %1151)
  %conv35.2.28 = zext i8 %call34.2.28 to i32
  %xor36.2.28 = xor i32 %xor.2.28, %conv35.2.28
  %conv37.2.28 = trunc i32 %xor36.2.28 to i8
  store i8 %conv37.2.28, i8* %scevgep41.2.27, align 1
  %scevgep28.2.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1145, i64 0, i64 0, i64 1
  %1152 = bitcast i8* %scevgep28.2.28 to [61 x [61 x i8]]*
  %scevgep41.2.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1146, i64 0, i64 1, i64 0
  %1153 = bitcast i8* %scevgep41.2.28 to [61 x [61 x i8]]*
  %call16.2.29 = call zeroext i8 (...) @rand()
  store i8 %call16.2.29, i8* %scevgep28.2.28, align 1
  %1154 = load i8, i8* %scevgep28.2.28, align 1
  %conv23.2.29 = zext i8 %1154 to i32
  %1155 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.29 = getelementptr i8, i8* %b, i64 32
  %1156 = load i8, i8* %scevgep34.2.29, align 1
  %call28.2.29 = call zeroext i8 @mult(i8 zeroext %1155, i8 zeroext %1156)
  %conv29.2.29 = zext i8 %call28.2.29 to i32
  %xor.2.29 = xor i32 %conv23.2.29, %conv29.2.29
  %scevgep35.2.29 = getelementptr i8, i8* %a, i64 32
  %1157 = load i8, i8* %scevgep35.2.29, align 1
  %1158 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.29 = call zeroext i8 @mult(i8 zeroext %1157, i8 zeroext %1158)
  %conv35.2.29 = zext i8 %call34.2.29 to i32
  %xor36.2.29 = xor i32 %xor.2.29, %conv35.2.29
  %conv37.2.29 = trunc i32 %xor36.2.29 to i8
  store i8 %conv37.2.29, i8* %scevgep41.2.28, align 1
  %scevgep28.2.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1152, i64 0, i64 0, i64 1
  %1159 = bitcast i8* %scevgep28.2.29 to [61 x [61 x i8]]*
  %scevgep41.2.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1153, i64 0, i64 1, i64 0
  %1160 = bitcast i8* %scevgep41.2.29 to [61 x [61 x i8]]*
  %call16.2.30 = call zeroext i8 (...) @rand()
  store i8 %call16.2.30, i8* %scevgep28.2.29, align 1
  %1161 = load i8, i8* %scevgep28.2.29, align 1
  %conv23.2.30 = zext i8 %1161 to i32
  %1162 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.30 = getelementptr i8, i8* %b, i64 33
  %1163 = load i8, i8* %scevgep34.2.30, align 1
  %call28.2.30 = call zeroext i8 @mult(i8 zeroext %1162, i8 zeroext %1163)
  %conv29.2.30 = zext i8 %call28.2.30 to i32
  %xor.2.30 = xor i32 %conv23.2.30, %conv29.2.30
  %scevgep35.2.30 = getelementptr i8, i8* %a, i64 33
  %1164 = load i8, i8* %scevgep35.2.30, align 1
  %1165 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.30 = call zeroext i8 @mult(i8 zeroext %1164, i8 zeroext %1165)
  %conv35.2.30 = zext i8 %call34.2.30 to i32
  %xor36.2.30 = xor i32 %xor.2.30, %conv35.2.30
  %conv37.2.30 = trunc i32 %xor36.2.30 to i8
  store i8 %conv37.2.30, i8* %scevgep41.2.29, align 1
  %scevgep28.2.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1159, i64 0, i64 0, i64 1
  %1166 = bitcast i8* %scevgep28.2.30 to [61 x [61 x i8]]*
  %scevgep41.2.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1160, i64 0, i64 1, i64 0
  %1167 = bitcast i8* %scevgep41.2.30 to [61 x [61 x i8]]*
  %call16.2.31 = call zeroext i8 (...) @rand()
  store i8 %call16.2.31, i8* %scevgep28.2.30, align 1
  %1168 = load i8, i8* %scevgep28.2.30, align 1
  %conv23.2.31 = zext i8 %1168 to i32
  %1169 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.31 = getelementptr i8, i8* %b, i64 34
  %1170 = load i8, i8* %scevgep34.2.31, align 1
  %call28.2.31 = call zeroext i8 @mult(i8 zeroext %1169, i8 zeroext %1170)
  %conv29.2.31 = zext i8 %call28.2.31 to i32
  %xor.2.31 = xor i32 %conv23.2.31, %conv29.2.31
  %scevgep35.2.31 = getelementptr i8, i8* %a, i64 34
  %1171 = load i8, i8* %scevgep35.2.31, align 1
  %1172 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.31 = call zeroext i8 @mult(i8 zeroext %1171, i8 zeroext %1172)
  %conv35.2.31 = zext i8 %call34.2.31 to i32
  %xor36.2.31 = xor i32 %xor.2.31, %conv35.2.31
  %conv37.2.31 = trunc i32 %xor36.2.31 to i8
  store i8 %conv37.2.31, i8* %scevgep41.2.30, align 1
  %scevgep28.2.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1166, i64 0, i64 0, i64 1
  %1173 = bitcast i8* %scevgep28.2.31 to [61 x [61 x i8]]*
  %scevgep41.2.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1167, i64 0, i64 1, i64 0
  %1174 = bitcast i8* %scevgep41.2.31 to [61 x [61 x i8]]*
  %call16.2.32 = call zeroext i8 (...) @rand()
  store i8 %call16.2.32, i8* %scevgep28.2.31, align 1
  %1175 = load i8, i8* %scevgep28.2.31, align 1
  %conv23.2.32 = zext i8 %1175 to i32
  %1176 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.32 = getelementptr i8, i8* %b, i64 35
  %1177 = load i8, i8* %scevgep34.2.32, align 1
  %call28.2.32 = call zeroext i8 @mult(i8 zeroext %1176, i8 zeroext %1177)
  %conv29.2.32 = zext i8 %call28.2.32 to i32
  %xor.2.32 = xor i32 %conv23.2.32, %conv29.2.32
  %scevgep35.2.32 = getelementptr i8, i8* %a, i64 35
  %1178 = load i8, i8* %scevgep35.2.32, align 1
  %1179 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.32 = call zeroext i8 @mult(i8 zeroext %1178, i8 zeroext %1179)
  %conv35.2.32 = zext i8 %call34.2.32 to i32
  %xor36.2.32 = xor i32 %xor.2.32, %conv35.2.32
  %conv37.2.32 = trunc i32 %xor36.2.32 to i8
  store i8 %conv37.2.32, i8* %scevgep41.2.31, align 1
  %scevgep28.2.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1173, i64 0, i64 0, i64 1
  %1180 = bitcast i8* %scevgep28.2.32 to [61 x [61 x i8]]*
  %scevgep41.2.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1174, i64 0, i64 1, i64 0
  %1181 = bitcast i8* %scevgep41.2.32 to [61 x [61 x i8]]*
  %call16.2.33 = call zeroext i8 (...) @rand()
  store i8 %call16.2.33, i8* %scevgep28.2.32, align 1
  %1182 = load i8, i8* %scevgep28.2.32, align 1
  %conv23.2.33 = zext i8 %1182 to i32
  %1183 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.33 = getelementptr i8, i8* %b, i64 36
  %1184 = load i8, i8* %scevgep34.2.33, align 1
  %call28.2.33 = call zeroext i8 @mult(i8 zeroext %1183, i8 zeroext %1184)
  %conv29.2.33 = zext i8 %call28.2.33 to i32
  %xor.2.33 = xor i32 %conv23.2.33, %conv29.2.33
  %scevgep35.2.33 = getelementptr i8, i8* %a, i64 36
  %1185 = load i8, i8* %scevgep35.2.33, align 1
  %1186 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.33 = call zeroext i8 @mult(i8 zeroext %1185, i8 zeroext %1186)
  %conv35.2.33 = zext i8 %call34.2.33 to i32
  %xor36.2.33 = xor i32 %xor.2.33, %conv35.2.33
  %conv37.2.33 = trunc i32 %xor36.2.33 to i8
  store i8 %conv37.2.33, i8* %scevgep41.2.32, align 1
  %scevgep28.2.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1180, i64 0, i64 0, i64 1
  %1187 = bitcast i8* %scevgep28.2.33 to [61 x [61 x i8]]*
  %scevgep41.2.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1181, i64 0, i64 1, i64 0
  %1188 = bitcast i8* %scevgep41.2.33 to [61 x [61 x i8]]*
  %call16.2.34 = call zeroext i8 (...) @rand()
  store i8 %call16.2.34, i8* %scevgep28.2.33, align 1
  %1189 = load i8, i8* %scevgep28.2.33, align 1
  %conv23.2.34 = zext i8 %1189 to i32
  %1190 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.34 = getelementptr i8, i8* %b, i64 37
  %1191 = load i8, i8* %scevgep34.2.34, align 1
  %call28.2.34 = call zeroext i8 @mult(i8 zeroext %1190, i8 zeroext %1191)
  %conv29.2.34 = zext i8 %call28.2.34 to i32
  %xor.2.34 = xor i32 %conv23.2.34, %conv29.2.34
  %scevgep35.2.34 = getelementptr i8, i8* %a, i64 37
  %1192 = load i8, i8* %scevgep35.2.34, align 1
  %1193 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.34 = call zeroext i8 @mult(i8 zeroext %1192, i8 zeroext %1193)
  %conv35.2.34 = zext i8 %call34.2.34 to i32
  %xor36.2.34 = xor i32 %xor.2.34, %conv35.2.34
  %conv37.2.34 = trunc i32 %xor36.2.34 to i8
  store i8 %conv37.2.34, i8* %scevgep41.2.33, align 1
  %scevgep28.2.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1187, i64 0, i64 0, i64 1
  %1194 = bitcast i8* %scevgep28.2.34 to [61 x [61 x i8]]*
  %scevgep41.2.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1188, i64 0, i64 1, i64 0
  %1195 = bitcast i8* %scevgep41.2.34 to [61 x [61 x i8]]*
  %call16.2.35 = call zeroext i8 (...) @rand()
  store i8 %call16.2.35, i8* %scevgep28.2.34, align 1
  %1196 = load i8, i8* %scevgep28.2.34, align 1
  %conv23.2.35 = zext i8 %1196 to i32
  %1197 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.35 = getelementptr i8, i8* %b, i64 38
  %1198 = load i8, i8* %scevgep34.2.35, align 1
  %call28.2.35 = call zeroext i8 @mult(i8 zeroext %1197, i8 zeroext %1198)
  %conv29.2.35 = zext i8 %call28.2.35 to i32
  %xor.2.35 = xor i32 %conv23.2.35, %conv29.2.35
  %scevgep35.2.35 = getelementptr i8, i8* %a, i64 38
  %1199 = load i8, i8* %scevgep35.2.35, align 1
  %1200 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.35 = call zeroext i8 @mult(i8 zeroext %1199, i8 zeroext %1200)
  %conv35.2.35 = zext i8 %call34.2.35 to i32
  %xor36.2.35 = xor i32 %xor.2.35, %conv35.2.35
  %conv37.2.35 = trunc i32 %xor36.2.35 to i8
  store i8 %conv37.2.35, i8* %scevgep41.2.34, align 1
  %scevgep28.2.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1194, i64 0, i64 0, i64 1
  %1201 = bitcast i8* %scevgep28.2.35 to [61 x [61 x i8]]*
  %scevgep41.2.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1195, i64 0, i64 1, i64 0
  %1202 = bitcast i8* %scevgep41.2.35 to [61 x [61 x i8]]*
  %call16.2.36 = call zeroext i8 (...) @rand()
  store i8 %call16.2.36, i8* %scevgep28.2.35, align 1
  %1203 = load i8, i8* %scevgep28.2.35, align 1
  %conv23.2.36 = zext i8 %1203 to i32
  %1204 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.36 = getelementptr i8, i8* %b, i64 39
  %1205 = load i8, i8* %scevgep34.2.36, align 1
  %call28.2.36 = call zeroext i8 @mult(i8 zeroext %1204, i8 zeroext %1205)
  %conv29.2.36 = zext i8 %call28.2.36 to i32
  %xor.2.36 = xor i32 %conv23.2.36, %conv29.2.36
  %scevgep35.2.36 = getelementptr i8, i8* %a, i64 39
  %1206 = load i8, i8* %scevgep35.2.36, align 1
  %1207 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.36 = call zeroext i8 @mult(i8 zeroext %1206, i8 zeroext %1207)
  %conv35.2.36 = zext i8 %call34.2.36 to i32
  %xor36.2.36 = xor i32 %xor.2.36, %conv35.2.36
  %conv37.2.36 = trunc i32 %xor36.2.36 to i8
  store i8 %conv37.2.36, i8* %scevgep41.2.35, align 1
  %scevgep28.2.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1201, i64 0, i64 0, i64 1
  %1208 = bitcast i8* %scevgep28.2.36 to [61 x [61 x i8]]*
  %scevgep41.2.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1202, i64 0, i64 1, i64 0
  %1209 = bitcast i8* %scevgep41.2.36 to [61 x [61 x i8]]*
  %call16.2.37 = call zeroext i8 (...) @rand()
  store i8 %call16.2.37, i8* %scevgep28.2.36, align 1
  %1210 = load i8, i8* %scevgep28.2.36, align 1
  %conv23.2.37 = zext i8 %1210 to i32
  %1211 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.37 = getelementptr i8, i8* %b, i64 40
  %1212 = load i8, i8* %scevgep34.2.37, align 1
  %call28.2.37 = call zeroext i8 @mult(i8 zeroext %1211, i8 zeroext %1212)
  %conv29.2.37 = zext i8 %call28.2.37 to i32
  %xor.2.37 = xor i32 %conv23.2.37, %conv29.2.37
  %scevgep35.2.37 = getelementptr i8, i8* %a, i64 40
  %1213 = load i8, i8* %scevgep35.2.37, align 1
  %1214 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.37 = call zeroext i8 @mult(i8 zeroext %1213, i8 zeroext %1214)
  %conv35.2.37 = zext i8 %call34.2.37 to i32
  %xor36.2.37 = xor i32 %xor.2.37, %conv35.2.37
  %conv37.2.37 = trunc i32 %xor36.2.37 to i8
  store i8 %conv37.2.37, i8* %scevgep41.2.36, align 1
  %scevgep28.2.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1208, i64 0, i64 0, i64 1
  %1215 = bitcast i8* %scevgep28.2.37 to [61 x [61 x i8]]*
  %scevgep41.2.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1209, i64 0, i64 1, i64 0
  %1216 = bitcast i8* %scevgep41.2.37 to [61 x [61 x i8]]*
  %call16.2.38 = call zeroext i8 (...) @rand()
  store i8 %call16.2.38, i8* %scevgep28.2.37, align 1
  %1217 = load i8, i8* %scevgep28.2.37, align 1
  %conv23.2.38 = zext i8 %1217 to i32
  %1218 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.38 = getelementptr i8, i8* %b, i64 41
  %1219 = load i8, i8* %scevgep34.2.38, align 1
  %call28.2.38 = call zeroext i8 @mult(i8 zeroext %1218, i8 zeroext %1219)
  %conv29.2.38 = zext i8 %call28.2.38 to i32
  %xor.2.38 = xor i32 %conv23.2.38, %conv29.2.38
  %scevgep35.2.38 = getelementptr i8, i8* %a, i64 41
  %1220 = load i8, i8* %scevgep35.2.38, align 1
  %1221 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.38 = call zeroext i8 @mult(i8 zeroext %1220, i8 zeroext %1221)
  %conv35.2.38 = zext i8 %call34.2.38 to i32
  %xor36.2.38 = xor i32 %xor.2.38, %conv35.2.38
  %conv37.2.38 = trunc i32 %xor36.2.38 to i8
  store i8 %conv37.2.38, i8* %scevgep41.2.37, align 1
  %scevgep28.2.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1215, i64 0, i64 0, i64 1
  %1222 = bitcast i8* %scevgep28.2.38 to [61 x [61 x i8]]*
  %scevgep41.2.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1216, i64 0, i64 1, i64 0
  %1223 = bitcast i8* %scevgep41.2.38 to [61 x [61 x i8]]*
  %call16.2.39 = call zeroext i8 (...) @rand()
  store i8 %call16.2.39, i8* %scevgep28.2.38, align 1
  %1224 = load i8, i8* %scevgep28.2.38, align 1
  %conv23.2.39 = zext i8 %1224 to i32
  %1225 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.39 = getelementptr i8, i8* %b, i64 42
  %1226 = load i8, i8* %scevgep34.2.39, align 1
  %call28.2.39 = call zeroext i8 @mult(i8 zeroext %1225, i8 zeroext %1226)
  %conv29.2.39 = zext i8 %call28.2.39 to i32
  %xor.2.39 = xor i32 %conv23.2.39, %conv29.2.39
  %scevgep35.2.39 = getelementptr i8, i8* %a, i64 42
  %1227 = load i8, i8* %scevgep35.2.39, align 1
  %1228 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.39 = call zeroext i8 @mult(i8 zeroext %1227, i8 zeroext %1228)
  %conv35.2.39 = zext i8 %call34.2.39 to i32
  %xor36.2.39 = xor i32 %xor.2.39, %conv35.2.39
  %conv37.2.39 = trunc i32 %xor36.2.39 to i8
  store i8 %conv37.2.39, i8* %scevgep41.2.38, align 1
  %scevgep28.2.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1222, i64 0, i64 0, i64 1
  %1229 = bitcast i8* %scevgep28.2.39 to [61 x [61 x i8]]*
  %scevgep41.2.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1223, i64 0, i64 1, i64 0
  %1230 = bitcast i8* %scevgep41.2.39 to [61 x [61 x i8]]*
  %call16.2.40 = call zeroext i8 (...) @rand()
  store i8 %call16.2.40, i8* %scevgep28.2.39, align 1
  %1231 = load i8, i8* %scevgep28.2.39, align 1
  %conv23.2.40 = zext i8 %1231 to i32
  %1232 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.40 = getelementptr i8, i8* %b, i64 43
  %1233 = load i8, i8* %scevgep34.2.40, align 1
  %call28.2.40 = call zeroext i8 @mult(i8 zeroext %1232, i8 zeroext %1233)
  %conv29.2.40 = zext i8 %call28.2.40 to i32
  %xor.2.40 = xor i32 %conv23.2.40, %conv29.2.40
  %scevgep35.2.40 = getelementptr i8, i8* %a, i64 43
  %1234 = load i8, i8* %scevgep35.2.40, align 1
  %1235 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.40 = call zeroext i8 @mult(i8 zeroext %1234, i8 zeroext %1235)
  %conv35.2.40 = zext i8 %call34.2.40 to i32
  %xor36.2.40 = xor i32 %xor.2.40, %conv35.2.40
  %conv37.2.40 = trunc i32 %xor36.2.40 to i8
  store i8 %conv37.2.40, i8* %scevgep41.2.39, align 1
  %scevgep28.2.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1229, i64 0, i64 0, i64 1
  %1236 = bitcast i8* %scevgep28.2.40 to [61 x [61 x i8]]*
  %scevgep41.2.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1230, i64 0, i64 1, i64 0
  %1237 = bitcast i8* %scevgep41.2.40 to [61 x [61 x i8]]*
  %call16.2.41 = call zeroext i8 (...) @rand()
  store i8 %call16.2.41, i8* %scevgep28.2.40, align 1
  %1238 = load i8, i8* %scevgep28.2.40, align 1
  %conv23.2.41 = zext i8 %1238 to i32
  %1239 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.41 = getelementptr i8, i8* %b, i64 44
  %1240 = load i8, i8* %scevgep34.2.41, align 1
  %call28.2.41 = call zeroext i8 @mult(i8 zeroext %1239, i8 zeroext %1240)
  %conv29.2.41 = zext i8 %call28.2.41 to i32
  %xor.2.41 = xor i32 %conv23.2.41, %conv29.2.41
  %scevgep35.2.41 = getelementptr i8, i8* %a, i64 44
  %1241 = load i8, i8* %scevgep35.2.41, align 1
  %1242 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.41 = call zeroext i8 @mult(i8 zeroext %1241, i8 zeroext %1242)
  %conv35.2.41 = zext i8 %call34.2.41 to i32
  %xor36.2.41 = xor i32 %xor.2.41, %conv35.2.41
  %conv37.2.41 = trunc i32 %xor36.2.41 to i8
  store i8 %conv37.2.41, i8* %scevgep41.2.40, align 1
  %scevgep28.2.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1236, i64 0, i64 0, i64 1
  %1243 = bitcast i8* %scevgep28.2.41 to [61 x [61 x i8]]*
  %scevgep41.2.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1237, i64 0, i64 1, i64 0
  %1244 = bitcast i8* %scevgep41.2.41 to [61 x [61 x i8]]*
  %call16.2.42 = call zeroext i8 (...) @rand()
  store i8 %call16.2.42, i8* %scevgep28.2.41, align 1
  %1245 = load i8, i8* %scevgep28.2.41, align 1
  %conv23.2.42 = zext i8 %1245 to i32
  %1246 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.42 = getelementptr i8, i8* %b, i64 45
  %1247 = load i8, i8* %scevgep34.2.42, align 1
  %call28.2.42 = call zeroext i8 @mult(i8 zeroext %1246, i8 zeroext %1247)
  %conv29.2.42 = zext i8 %call28.2.42 to i32
  %xor.2.42 = xor i32 %conv23.2.42, %conv29.2.42
  %scevgep35.2.42 = getelementptr i8, i8* %a, i64 45
  %1248 = load i8, i8* %scevgep35.2.42, align 1
  %1249 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.42 = call zeroext i8 @mult(i8 zeroext %1248, i8 zeroext %1249)
  %conv35.2.42 = zext i8 %call34.2.42 to i32
  %xor36.2.42 = xor i32 %xor.2.42, %conv35.2.42
  %conv37.2.42 = trunc i32 %xor36.2.42 to i8
  store i8 %conv37.2.42, i8* %scevgep41.2.41, align 1
  %scevgep28.2.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1243, i64 0, i64 0, i64 1
  %1250 = bitcast i8* %scevgep28.2.42 to [61 x [61 x i8]]*
  %scevgep41.2.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1244, i64 0, i64 1, i64 0
  %1251 = bitcast i8* %scevgep41.2.42 to [61 x [61 x i8]]*
  %call16.2.43 = call zeroext i8 (...) @rand()
  store i8 %call16.2.43, i8* %scevgep28.2.42, align 1
  %1252 = load i8, i8* %scevgep28.2.42, align 1
  %conv23.2.43 = zext i8 %1252 to i32
  %1253 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.43 = getelementptr i8, i8* %b, i64 46
  %1254 = load i8, i8* %scevgep34.2.43, align 1
  %call28.2.43 = call zeroext i8 @mult(i8 zeroext %1253, i8 zeroext %1254)
  %conv29.2.43 = zext i8 %call28.2.43 to i32
  %xor.2.43 = xor i32 %conv23.2.43, %conv29.2.43
  %scevgep35.2.43 = getelementptr i8, i8* %a, i64 46
  %1255 = load i8, i8* %scevgep35.2.43, align 1
  %1256 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.43 = call zeroext i8 @mult(i8 zeroext %1255, i8 zeroext %1256)
  %conv35.2.43 = zext i8 %call34.2.43 to i32
  %xor36.2.43 = xor i32 %xor.2.43, %conv35.2.43
  %conv37.2.43 = trunc i32 %xor36.2.43 to i8
  store i8 %conv37.2.43, i8* %scevgep41.2.42, align 1
  %scevgep28.2.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1250, i64 0, i64 0, i64 1
  %1257 = bitcast i8* %scevgep28.2.43 to [61 x [61 x i8]]*
  %scevgep41.2.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1251, i64 0, i64 1, i64 0
  %1258 = bitcast i8* %scevgep41.2.43 to [61 x [61 x i8]]*
  %call16.2.44 = call zeroext i8 (...) @rand()
  store i8 %call16.2.44, i8* %scevgep28.2.43, align 1
  %1259 = load i8, i8* %scevgep28.2.43, align 1
  %conv23.2.44 = zext i8 %1259 to i32
  %1260 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.44 = getelementptr i8, i8* %b, i64 47
  %1261 = load i8, i8* %scevgep34.2.44, align 1
  %call28.2.44 = call zeroext i8 @mult(i8 zeroext %1260, i8 zeroext %1261)
  %conv29.2.44 = zext i8 %call28.2.44 to i32
  %xor.2.44 = xor i32 %conv23.2.44, %conv29.2.44
  %scevgep35.2.44 = getelementptr i8, i8* %a, i64 47
  %1262 = load i8, i8* %scevgep35.2.44, align 1
  %1263 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.44 = call zeroext i8 @mult(i8 zeroext %1262, i8 zeroext %1263)
  %conv35.2.44 = zext i8 %call34.2.44 to i32
  %xor36.2.44 = xor i32 %xor.2.44, %conv35.2.44
  %conv37.2.44 = trunc i32 %xor36.2.44 to i8
  store i8 %conv37.2.44, i8* %scevgep41.2.43, align 1
  %scevgep28.2.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1257, i64 0, i64 0, i64 1
  %1264 = bitcast i8* %scevgep28.2.44 to [61 x [61 x i8]]*
  %scevgep41.2.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1258, i64 0, i64 1, i64 0
  %1265 = bitcast i8* %scevgep41.2.44 to [61 x [61 x i8]]*
  %call16.2.45 = call zeroext i8 (...) @rand()
  store i8 %call16.2.45, i8* %scevgep28.2.44, align 1
  %1266 = load i8, i8* %scevgep28.2.44, align 1
  %conv23.2.45 = zext i8 %1266 to i32
  %1267 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.45 = getelementptr i8, i8* %b, i64 48
  %1268 = load i8, i8* %scevgep34.2.45, align 1
  %call28.2.45 = call zeroext i8 @mult(i8 zeroext %1267, i8 zeroext %1268)
  %conv29.2.45 = zext i8 %call28.2.45 to i32
  %xor.2.45 = xor i32 %conv23.2.45, %conv29.2.45
  %scevgep35.2.45 = getelementptr i8, i8* %a, i64 48
  %1269 = load i8, i8* %scevgep35.2.45, align 1
  %1270 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.45 = call zeroext i8 @mult(i8 zeroext %1269, i8 zeroext %1270)
  %conv35.2.45 = zext i8 %call34.2.45 to i32
  %xor36.2.45 = xor i32 %xor.2.45, %conv35.2.45
  %conv37.2.45 = trunc i32 %xor36.2.45 to i8
  store i8 %conv37.2.45, i8* %scevgep41.2.44, align 1
  %scevgep28.2.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1264, i64 0, i64 0, i64 1
  %1271 = bitcast i8* %scevgep28.2.45 to [61 x [61 x i8]]*
  %scevgep41.2.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1265, i64 0, i64 1, i64 0
  %1272 = bitcast i8* %scevgep41.2.45 to [61 x [61 x i8]]*
  %call16.2.46 = call zeroext i8 (...) @rand()
  store i8 %call16.2.46, i8* %scevgep28.2.45, align 1
  %1273 = load i8, i8* %scevgep28.2.45, align 1
  %conv23.2.46 = zext i8 %1273 to i32
  %1274 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.46 = getelementptr i8, i8* %b, i64 49
  %1275 = load i8, i8* %scevgep34.2.46, align 1
  %call28.2.46 = call zeroext i8 @mult(i8 zeroext %1274, i8 zeroext %1275)
  %conv29.2.46 = zext i8 %call28.2.46 to i32
  %xor.2.46 = xor i32 %conv23.2.46, %conv29.2.46
  %scevgep35.2.46 = getelementptr i8, i8* %a, i64 49
  %1276 = load i8, i8* %scevgep35.2.46, align 1
  %1277 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.46 = call zeroext i8 @mult(i8 zeroext %1276, i8 zeroext %1277)
  %conv35.2.46 = zext i8 %call34.2.46 to i32
  %xor36.2.46 = xor i32 %xor.2.46, %conv35.2.46
  %conv37.2.46 = trunc i32 %xor36.2.46 to i8
  store i8 %conv37.2.46, i8* %scevgep41.2.45, align 1
  %scevgep28.2.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1271, i64 0, i64 0, i64 1
  %1278 = bitcast i8* %scevgep28.2.46 to [61 x [61 x i8]]*
  %scevgep41.2.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1272, i64 0, i64 1, i64 0
  %1279 = bitcast i8* %scevgep41.2.46 to [61 x [61 x i8]]*
  %call16.2.47 = call zeroext i8 (...) @rand()
  store i8 %call16.2.47, i8* %scevgep28.2.46, align 1
  %1280 = load i8, i8* %scevgep28.2.46, align 1
  %conv23.2.47 = zext i8 %1280 to i32
  %1281 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.47 = getelementptr i8, i8* %b, i64 50
  %1282 = load i8, i8* %scevgep34.2.47, align 1
  %call28.2.47 = call zeroext i8 @mult(i8 zeroext %1281, i8 zeroext %1282)
  %conv29.2.47 = zext i8 %call28.2.47 to i32
  %xor.2.47 = xor i32 %conv23.2.47, %conv29.2.47
  %scevgep35.2.47 = getelementptr i8, i8* %a, i64 50
  %1283 = load i8, i8* %scevgep35.2.47, align 1
  %1284 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.47 = call zeroext i8 @mult(i8 zeroext %1283, i8 zeroext %1284)
  %conv35.2.47 = zext i8 %call34.2.47 to i32
  %xor36.2.47 = xor i32 %xor.2.47, %conv35.2.47
  %conv37.2.47 = trunc i32 %xor36.2.47 to i8
  store i8 %conv37.2.47, i8* %scevgep41.2.46, align 1
  %scevgep28.2.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1278, i64 0, i64 0, i64 1
  %1285 = bitcast i8* %scevgep28.2.47 to [61 x [61 x i8]]*
  %scevgep41.2.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1279, i64 0, i64 1, i64 0
  %1286 = bitcast i8* %scevgep41.2.47 to [61 x [61 x i8]]*
  %call16.2.48 = call zeroext i8 (...) @rand()
  store i8 %call16.2.48, i8* %scevgep28.2.47, align 1
  %1287 = load i8, i8* %scevgep28.2.47, align 1
  %conv23.2.48 = zext i8 %1287 to i32
  %1288 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.48 = getelementptr i8, i8* %b, i64 51
  %1289 = load i8, i8* %scevgep34.2.48, align 1
  %call28.2.48 = call zeroext i8 @mult(i8 zeroext %1288, i8 zeroext %1289)
  %conv29.2.48 = zext i8 %call28.2.48 to i32
  %xor.2.48 = xor i32 %conv23.2.48, %conv29.2.48
  %scevgep35.2.48 = getelementptr i8, i8* %a, i64 51
  %1290 = load i8, i8* %scevgep35.2.48, align 1
  %1291 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.48 = call zeroext i8 @mult(i8 zeroext %1290, i8 zeroext %1291)
  %conv35.2.48 = zext i8 %call34.2.48 to i32
  %xor36.2.48 = xor i32 %xor.2.48, %conv35.2.48
  %conv37.2.48 = trunc i32 %xor36.2.48 to i8
  store i8 %conv37.2.48, i8* %scevgep41.2.47, align 1
  %scevgep28.2.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1285, i64 0, i64 0, i64 1
  %1292 = bitcast i8* %scevgep28.2.48 to [61 x [61 x i8]]*
  %scevgep41.2.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1286, i64 0, i64 1, i64 0
  %1293 = bitcast i8* %scevgep41.2.48 to [61 x [61 x i8]]*
  %call16.2.49 = call zeroext i8 (...) @rand()
  store i8 %call16.2.49, i8* %scevgep28.2.48, align 1
  %1294 = load i8, i8* %scevgep28.2.48, align 1
  %conv23.2.49 = zext i8 %1294 to i32
  %1295 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.49 = getelementptr i8, i8* %b, i64 52
  %1296 = load i8, i8* %scevgep34.2.49, align 1
  %call28.2.49 = call zeroext i8 @mult(i8 zeroext %1295, i8 zeroext %1296)
  %conv29.2.49 = zext i8 %call28.2.49 to i32
  %xor.2.49 = xor i32 %conv23.2.49, %conv29.2.49
  %scevgep35.2.49 = getelementptr i8, i8* %a, i64 52
  %1297 = load i8, i8* %scevgep35.2.49, align 1
  %1298 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.49 = call zeroext i8 @mult(i8 zeroext %1297, i8 zeroext %1298)
  %conv35.2.49 = zext i8 %call34.2.49 to i32
  %xor36.2.49 = xor i32 %xor.2.49, %conv35.2.49
  %conv37.2.49 = trunc i32 %xor36.2.49 to i8
  store i8 %conv37.2.49, i8* %scevgep41.2.48, align 1
  %scevgep28.2.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1292, i64 0, i64 0, i64 1
  %1299 = bitcast i8* %scevgep28.2.49 to [61 x [61 x i8]]*
  %scevgep41.2.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1293, i64 0, i64 1, i64 0
  %1300 = bitcast i8* %scevgep41.2.49 to [61 x [61 x i8]]*
  %call16.2.50 = call zeroext i8 (...) @rand()
  store i8 %call16.2.50, i8* %scevgep28.2.49, align 1
  %1301 = load i8, i8* %scevgep28.2.49, align 1
  %conv23.2.50 = zext i8 %1301 to i32
  %1302 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.50 = getelementptr i8, i8* %b, i64 53
  %1303 = load i8, i8* %scevgep34.2.50, align 1
  %call28.2.50 = call zeroext i8 @mult(i8 zeroext %1302, i8 zeroext %1303)
  %conv29.2.50 = zext i8 %call28.2.50 to i32
  %xor.2.50 = xor i32 %conv23.2.50, %conv29.2.50
  %scevgep35.2.50 = getelementptr i8, i8* %a, i64 53
  %1304 = load i8, i8* %scevgep35.2.50, align 1
  %1305 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.50 = call zeroext i8 @mult(i8 zeroext %1304, i8 zeroext %1305)
  %conv35.2.50 = zext i8 %call34.2.50 to i32
  %xor36.2.50 = xor i32 %xor.2.50, %conv35.2.50
  %conv37.2.50 = trunc i32 %xor36.2.50 to i8
  store i8 %conv37.2.50, i8* %scevgep41.2.49, align 1
  %scevgep28.2.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1299, i64 0, i64 0, i64 1
  %1306 = bitcast i8* %scevgep28.2.50 to [61 x [61 x i8]]*
  %scevgep41.2.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1300, i64 0, i64 1, i64 0
  %1307 = bitcast i8* %scevgep41.2.50 to [61 x [61 x i8]]*
  %call16.2.51 = call zeroext i8 (...) @rand()
  store i8 %call16.2.51, i8* %scevgep28.2.50, align 1
  %1308 = load i8, i8* %scevgep28.2.50, align 1
  %conv23.2.51 = zext i8 %1308 to i32
  %1309 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.51 = getelementptr i8, i8* %b, i64 54
  %1310 = load i8, i8* %scevgep34.2.51, align 1
  %call28.2.51 = call zeroext i8 @mult(i8 zeroext %1309, i8 zeroext %1310)
  %conv29.2.51 = zext i8 %call28.2.51 to i32
  %xor.2.51 = xor i32 %conv23.2.51, %conv29.2.51
  %scevgep35.2.51 = getelementptr i8, i8* %a, i64 54
  %1311 = load i8, i8* %scevgep35.2.51, align 1
  %1312 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.51 = call zeroext i8 @mult(i8 zeroext %1311, i8 zeroext %1312)
  %conv35.2.51 = zext i8 %call34.2.51 to i32
  %xor36.2.51 = xor i32 %xor.2.51, %conv35.2.51
  %conv37.2.51 = trunc i32 %xor36.2.51 to i8
  store i8 %conv37.2.51, i8* %scevgep41.2.50, align 1
  %scevgep28.2.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1306, i64 0, i64 0, i64 1
  %1313 = bitcast i8* %scevgep28.2.51 to [61 x [61 x i8]]*
  %scevgep41.2.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1307, i64 0, i64 1, i64 0
  %1314 = bitcast i8* %scevgep41.2.51 to [61 x [61 x i8]]*
  %call16.2.52 = call zeroext i8 (...) @rand()
  store i8 %call16.2.52, i8* %scevgep28.2.51, align 1
  %1315 = load i8, i8* %scevgep28.2.51, align 1
  %conv23.2.52 = zext i8 %1315 to i32
  %1316 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.52 = getelementptr i8, i8* %b, i64 55
  %1317 = load i8, i8* %scevgep34.2.52, align 1
  %call28.2.52 = call zeroext i8 @mult(i8 zeroext %1316, i8 zeroext %1317)
  %conv29.2.52 = zext i8 %call28.2.52 to i32
  %xor.2.52 = xor i32 %conv23.2.52, %conv29.2.52
  %scevgep35.2.52 = getelementptr i8, i8* %a, i64 55
  %1318 = load i8, i8* %scevgep35.2.52, align 1
  %1319 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.52 = call zeroext i8 @mult(i8 zeroext %1318, i8 zeroext %1319)
  %conv35.2.52 = zext i8 %call34.2.52 to i32
  %xor36.2.52 = xor i32 %xor.2.52, %conv35.2.52
  %conv37.2.52 = trunc i32 %xor36.2.52 to i8
  store i8 %conv37.2.52, i8* %scevgep41.2.51, align 1
  %scevgep28.2.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1313, i64 0, i64 0, i64 1
  %1320 = bitcast i8* %scevgep28.2.52 to [61 x [61 x i8]]*
  %scevgep41.2.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1314, i64 0, i64 1, i64 0
  %1321 = bitcast i8* %scevgep41.2.52 to [61 x [61 x i8]]*
  %call16.2.53 = call zeroext i8 (...) @rand()
  store i8 %call16.2.53, i8* %scevgep28.2.52, align 1
  %1322 = load i8, i8* %scevgep28.2.52, align 1
  %conv23.2.53 = zext i8 %1322 to i32
  %1323 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.53 = getelementptr i8, i8* %b, i64 56
  %1324 = load i8, i8* %scevgep34.2.53, align 1
  %call28.2.53 = call zeroext i8 @mult(i8 zeroext %1323, i8 zeroext %1324)
  %conv29.2.53 = zext i8 %call28.2.53 to i32
  %xor.2.53 = xor i32 %conv23.2.53, %conv29.2.53
  %scevgep35.2.53 = getelementptr i8, i8* %a, i64 56
  %1325 = load i8, i8* %scevgep35.2.53, align 1
  %1326 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.53 = call zeroext i8 @mult(i8 zeroext %1325, i8 zeroext %1326)
  %conv35.2.53 = zext i8 %call34.2.53 to i32
  %xor36.2.53 = xor i32 %xor.2.53, %conv35.2.53
  %conv37.2.53 = trunc i32 %xor36.2.53 to i8
  store i8 %conv37.2.53, i8* %scevgep41.2.52, align 1
  %scevgep28.2.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1320, i64 0, i64 0, i64 1
  %1327 = bitcast i8* %scevgep28.2.53 to [61 x [61 x i8]]*
  %scevgep41.2.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1321, i64 0, i64 1, i64 0
  %1328 = bitcast i8* %scevgep41.2.53 to [61 x [61 x i8]]*
  %call16.2.54 = call zeroext i8 (...) @rand()
  store i8 %call16.2.54, i8* %scevgep28.2.53, align 1
  %1329 = load i8, i8* %scevgep28.2.53, align 1
  %conv23.2.54 = zext i8 %1329 to i32
  %1330 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.54 = getelementptr i8, i8* %b, i64 57
  %1331 = load i8, i8* %scevgep34.2.54, align 1
  %call28.2.54 = call zeroext i8 @mult(i8 zeroext %1330, i8 zeroext %1331)
  %conv29.2.54 = zext i8 %call28.2.54 to i32
  %xor.2.54 = xor i32 %conv23.2.54, %conv29.2.54
  %scevgep35.2.54 = getelementptr i8, i8* %a, i64 57
  %1332 = load i8, i8* %scevgep35.2.54, align 1
  %1333 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.54 = call zeroext i8 @mult(i8 zeroext %1332, i8 zeroext %1333)
  %conv35.2.54 = zext i8 %call34.2.54 to i32
  %xor36.2.54 = xor i32 %xor.2.54, %conv35.2.54
  %conv37.2.54 = trunc i32 %xor36.2.54 to i8
  store i8 %conv37.2.54, i8* %scevgep41.2.53, align 1
  %scevgep28.2.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1327, i64 0, i64 0, i64 1
  %1334 = bitcast i8* %scevgep28.2.54 to [61 x [61 x i8]]*
  %scevgep41.2.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1328, i64 0, i64 1, i64 0
  %1335 = bitcast i8* %scevgep41.2.54 to [61 x [61 x i8]]*
  %call16.2.55 = call zeroext i8 (...) @rand()
  store i8 %call16.2.55, i8* %scevgep28.2.54, align 1
  %1336 = load i8, i8* %scevgep28.2.54, align 1
  %conv23.2.55 = zext i8 %1336 to i32
  %1337 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.55 = getelementptr i8, i8* %b, i64 58
  %1338 = load i8, i8* %scevgep34.2.55, align 1
  %call28.2.55 = call zeroext i8 @mult(i8 zeroext %1337, i8 zeroext %1338)
  %conv29.2.55 = zext i8 %call28.2.55 to i32
  %xor.2.55 = xor i32 %conv23.2.55, %conv29.2.55
  %scevgep35.2.55 = getelementptr i8, i8* %a, i64 58
  %1339 = load i8, i8* %scevgep35.2.55, align 1
  %1340 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.55 = call zeroext i8 @mult(i8 zeroext %1339, i8 zeroext %1340)
  %conv35.2.55 = zext i8 %call34.2.55 to i32
  %xor36.2.55 = xor i32 %xor.2.55, %conv35.2.55
  %conv37.2.55 = trunc i32 %xor36.2.55 to i8
  store i8 %conv37.2.55, i8* %scevgep41.2.54, align 1
  %scevgep28.2.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1334, i64 0, i64 0, i64 1
  %1341 = bitcast i8* %scevgep28.2.55 to [61 x [61 x i8]]*
  %scevgep41.2.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1335, i64 0, i64 1, i64 0
  %1342 = bitcast i8* %scevgep41.2.55 to [61 x [61 x i8]]*
  %call16.2.56 = call zeroext i8 (...) @rand()
  store i8 %call16.2.56, i8* %scevgep28.2.55, align 1
  %1343 = load i8, i8* %scevgep28.2.55, align 1
  %conv23.2.56 = zext i8 %1343 to i32
  %1344 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.56 = getelementptr i8, i8* %b, i64 59
  %1345 = load i8, i8* %scevgep34.2.56, align 1
  %call28.2.56 = call zeroext i8 @mult(i8 zeroext %1344, i8 zeroext %1345)
  %conv29.2.56 = zext i8 %call28.2.56 to i32
  %xor.2.56 = xor i32 %conv23.2.56, %conv29.2.56
  %scevgep35.2.56 = getelementptr i8, i8* %a, i64 59
  %1346 = load i8, i8* %scevgep35.2.56, align 1
  %1347 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.56 = call zeroext i8 @mult(i8 zeroext %1346, i8 zeroext %1347)
  %conv35.2.56 = zext i8 %call34.2.56 to i32
  %xor36.2.56 = xor i32 %xor.2.56, %conv35.2.56
  %conv37.2.56 = trunc i32 %xor36.2.56 to i8
  store i8 %conv37.2.56, i8* %scevgep41.2.55, align 1
  %scevgep28.2.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1341, i64 0, i64 0, i64 1
  %scevgep41.2.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1342, i64 0, i64 1, i64 0
  %call16.2.57 = call zeroext i8 (...) @rand()
  store i8 %call16.2.57, i8* %scevgep28.2.56, align 1
  %1348 = load i8, i8* %scevgep28.2.56, align 1
  %conv23.2.57 = zext i8 %1348 to i32
  %1349 = load i8, i8* %arrayidx25.2, align 1
  %scevgep34.2.57 = getelementptr i8, i8* %b, i64 60
  %1350 = load i8, i8* %scevgep34.2.57, align 1
  %call28.2.57 = call zeroext i8 @mult(i8 zeroext %1349, i8 zeroext %1350)
  %conv29.2.57 = zext i8 %call28.2.57 to i32
  %xor.2.57 = xor i32 %conv23.2.57, %conv29.2.57
  %scevgep35.2.57 = getelementptr i8, i8* %a, i64 60
  %1351 = load i8, i8* %scevgep35.2.57, align 1
  %1352 = load i8, i8* %arrayidx33.2, align 1
  %call34.2.57 = call zeroext i8 @mult(i8 zeroext %1351, i8 zeroext %1352)
  %conv35.2.57 = zext i8 %call34.2.57 to i32
  %xor36.2.57 = xor i32 %xor.2.57, %conv35.2.57
  %conv37.2.57 = trunc i32 %xor36.2.57 to i8
  store i8 %conv37.2.57, i8* %scevgep41.2.56, align 1
  %scevgep26.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %949, i64 0, i64 1, i64 1
  %1353 = bitcast i8* %scevgep26.2 to [61 x [61 x i8]]*
  %scevgep39.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %950, i64 0, i64 1, i64 1
  %1354 = bitcast i8* %scevgep39.2 to [61 x [61 x i8]]*
  %arrayidx25.3 = getelementptr inbounds i8, i8* %a, i64 3
  %arrayidx33.3 = getelementptr inbounds i8, i8* %b, i64 3
  %call16.3 = call zeroext i8 (...) @rand()
  store i8 %call16.3, i8* %scevgep26.2, align 1
  %1355 = load i8, i8* %scevgep26.2, align 1
  %conv23.3 = zext i8 %1355 to i32
  %1356 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3 = getelementptr i8, i8* %b, i64 4
  %1357 = load i8, i8* %scevgep34.3, align 1
  %call28.3 = call zeroext i8 @mult(i8 zeroext %1356, i8 zeroext %1357)
  %conv29.3 = zext i8 %call28.3 to i32
  %xor.3 = xor i32 %conv23.3, %conv29.3
  %scevgep35.3 = getelementptr i8, i8* %a, i64 4
  %1358 = load i8, i8* %scevgep35.3, align 1
  %1359 = load i8, i8* %arrayidx33.3, align 1
  %call34.3 = call zeroext i8 @mult(i8 zeroext %1358, i8 zeroext %1359)
  %conv35.3 = zext i8 %call34.3 to i32
  %xor36.3 = xor i32 %xor.3, %conv35.3
  %conv37.3 = trunc i32 %xor36.3 to i8
  store i8 %conv37.3, i8* %scevgep39.2, align 1
  %scevgep28.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1353, i64 0, i64 0, i64 1
  %1360 = bitcast i8* %scevgep28.3 to [61 x [61 x i8]]*
  %scevgep41.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1354, i64 0, i64 1, i64 0
  %1361 = bitcast i8* %scevgep41.3 to [61 x [61 x i8]]*
  %call16.3.1 = call zeroext i8 (...) @rand()
  store i8 %call16.3.1, i8* %scevgep28.3, align 1
  %1362 = load i8, i8* %scevgep28.3, align 1
  %conv23.3.1 = zext i8 %1362 to i32
  %1363 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.1 = getelementptr i8, i8* %b, i64 5
  %1364 = load i8, i8* %scevgep34.3.1, align 1
  %call28.3.1 = call zeroext i8 @mult(i8 zeroext %1363, i8 zeroext %1364)
  %conv29.3.1 = zext i8 %call28.3.1 to i32
  %xor.3.1 = xor i32 %conv23.3.1, %conv29.3.1
  %scevgep35.3.1 = getelementptr i8, i8* %a, i64 5
  %1365 = load i8, i8* %scevgep35.3.1, align 1
  %1366 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.1 = call zeroext i8 @mult(i8 zeroext %1365, i8 zeroext %1366)
  %conv35.3.1 = zext i8 %call34.3.1 to i32
  %xor36.3.1 = xor i32 %xor.3.1, %conv35.3.1
  %conv37.3.1 = trunc i32 %xor36.3.1 to i8
  store i8 %conv37.3.1, i8* %scevgep41.3, align 1
  %scevgep28.3.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1360, i64 0, i64 0, i64 1
  %1367 = bitcast i8* %scevgep28.3.1 to [61 x [61 x i8]]*
  %scevgep41.3.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1361, i64 0, i64 1, i64 0
  %1368 = bitcast i8* %scevgep41.3.1 to [61 x [61 x i8]]*
  %call16.3.2 = call zeroext i8 (...) @rand()
  store i8 %call16.3.2, i8* %scevgep28.3.1, align 1
  %1369 = load i8, i8* %scevgep28.3.1, align 1
  %conv23.3.2 = zext i8 %1369 to i32
  %1370 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.2 = getelementptr i8, i8* %b, i64 6
  %1371 = load i8, i8* %scevgep34.3.2, align 1
  %call28.3.2 = call zeroext i8 @mult(i8 zeroext %1370, i8 zeroext %1371)
  %conv29.3.2 = zext i8 %call28.3.2 to i32
  %xor.3.2 = xor i32 %conv23.3.2, %conv29.3.2
  %scevgep35.3.2 = getelementptr i8, i8* %a, i64 6
  %1372 = load i8, i8* %scevgep35.3.2, align 1
  %1373 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.2 = call zeroext i8 @mult(i8 zeroext %1372, i8 zeroext %1373)
  %conv35.3.2 = zext i8 %call34.3.2 to i32
  %xor36.3.2 = xor i32 %xor.3.2, %conv35.3.2
  %conv37.3.2 = trunc i32 %xor36.3.2 to i8
  store i8 %conv37.3.2, i8* %scevgep41.3.1, align 1
  %scevgep28.3.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1367, i64 0, i64 0, i64 1
  %1374 = bitcast i8* %scevgep28.3.2 to [61 x [61 x i8]]*
  %scevgep41.3.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1368, i64 0, i64 1, i64 0
  %1375 = bitcast i8* %scevgep41.3.2 to [61 x [61 x i8]]*
  %call16.3.3 = call zeroext i8 (...) @rand()
  store i8 %call16.3.3, i8* %scevgep28.3.2, align 1
  %1376 = load i8, i8* %scevgep28.3.2, align 1
  %conv23.3.3 = zext i8 %1376 to i32
  %1377 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.3 = getelementptr i8, i8* %b, i64 7
  %1378 = load i8, i8* %scevgep34.3.3, align 1
  %call28.3.3 = call zeroext i8 @mult(i8 zeroext %1377, i8 zeroext %1378)
  %conv29.3.3 = zext i8 %call28.3.3 to i32
  %xor.3.3 = xor i32 %conv23.3.3, %conv29.3.3
  %scevgep35.3.3 = getelementptr i8, i8* %a, i64 7
  %1379 = load i8, i8* %scevgep35.3.3, align 1
  %1380 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.3 = call zeroext i8 @mult(i8 zeroext %1379, i8 zeroext %1380)
  %conv35.3.3 = zext i8 %call34.3.3 to i32
  %xor36.3.3 = xor i32 %xor.3.3, %conv35.3.3
  %conv37.3.3 = trunc i32 %xor36.3.3 to i8
  store i8 %conv37.3.3, i8* %scevgep41.3.2, align 1
  %scevgep28.3.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1374, i64 0, i64 0, i64 1
  %1381 = bitcast i8* %scevgep28.3.3 to [61 x [61 x i8]]*
  %scevgep41.3.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1375, i64 0, i64 1, i64 0
  %1382 = bitcast i8* %scevgep41.3.3 to [61 x [61 x i8]]*
  %call16.3.4 = call zeroext i8 (...) @rand()
  store i8 %call16.3.4, i8* %scevgep28.3.3, align 1
  %1383 = load i8, i8* %scevgep28.3.3, align 1
  %conv23.3.4 = zext i8 %1383 to i32
  %1384 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.4 = getelementptr i8, i8* %b, i64 8
  %1385 = load i8, i8* %scevgep34.3.4, align 1
  %call28.3.4 = call zeroext i8 @mult(i8 zeroext %1384, i8 zeroext %1385)
  %conv29.3.4 = zext i8 %call28.3.4 to i32
  %xor.3.4 = xor i32 %conv23.3.4, %conv29.3.4
  %scevgep35.3.4 = getelementptr i8, i8* %a, i64 8
  %1386 = load i8, i8* %scevgep35.3.4, align 1
  %1387 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.4 = call zeroext i8 @mult(i8 zeroext %1386, i8 zeroext %1387)
  %conv35.3.4 = zext i8 %call34.3.4 to i32
  %xor36.3.4 = xor i32 %xor.3.4, %conv35.3.4
  %conv37.3.4 = trunc i32 %xor36.3.4 to i8
  store i8 %conv37.3.4, i8* %scevgep41.3.3, align 1
  %scevgep28.3.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1381, i64 0, i64 0, i64 1
  %1388 = bitcast i8* %scevgep28.3.4 to [61 x [61 x i8]]*
  %scevgep41.3.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1382, i64 0, i64 1, i64 0
  %1389 = bitcast i8* %scevgep41.3.4 to [61 x [61 x i8]]*
  %call16.3.5 = call zeroext i8 (...) @rand()
  store i8 %call16.3.5, i8* %scevgep28.3.4, align 1
  %1390 = load i8, i8* %scevgep28.3.4, align 1
  %conv23.3.5 = zext i8 %1390 to i32
  %1391 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.5 = getelementptr i8, i8* %b, i64 9
  %1392 = load i8, i8* %scevgep34.3.5, align 1
  %call28.3.5 = call zeroext i8 @mult(i8 zeroext %1391, i8 zeroext %1392)
  %conv29.3.5 = zext i8 %call28.3.5 to i32
  %xor.3.5 = xor i32 %conv23.3.5, %conv29.3.5
  %scevgep35.3.5 = getelementptr i8, i8* %a, i64 9
  %1393 = load i8, i8* %scevgep35.3.5, align 1
  %1394 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.5 = call zeroext i8 @mult(i8 zeroext %1393, i8 zeroext %1394)
  %conv35.3.5 = zext i8 %call34.3.5 to i32
  %xor36.3.5 = xor i32 %xor.3.5, %conv35.3.5
  %conv37.3.5 = trunc i32 %xor36.3.5 to i8
  store i8 %conv37.3.5, i8* %scevgep41.3.4, align 1
  %scevgep28.3.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1388, i64 0, i64 0, i64 1
  %1395 = bitcast i8* %scevgep28.3.5 to [61 x [61 x i8]]*
  %scevgep41.3.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1389, i64 0, i64 1, i64 0
  %1396 = bitcast i8* %scevgep41.3.5 to [61 x [61 x i8]]*
  %call16.3.6 = call zeroext i8 (...) @rand()
  store i8 %call16.3.6, i8* %scevgep28.3.5, align 1
  %1397 = load i8, i8* %scevgep28.3.5, align 1
  %conv23.3.6 = zext i8 %1397 to i32
  %1398 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.6 = getelementptr i8, i8* %b, i64 10
  %1399 = load i8, i8* %scevgep34.3.6, align 1
  %call28.3.6 = call zeroext i8 @mult(i8 zeroext %1398, i8 zeroext %1399)
  %conv29.3.6 = zext i8 %call28.3.6 to i32
  %xor.3.6 = xor i32 %conv23.3.6, %conv29.3.6
  %scevgep35.3.6 = getelementptr i8, i8* %a, i64 10
  %1400 = load i8, i8* %scevgep35.3.6, align 1
  %1401 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.6 = call zeroext i8 @mult(i8 zeroext %1400, i8 zeroext %1401)
  %conv35.3.6 = zext i8 %call34.3.6 to i32
  %xor36.3.6 = xor i32 %xor.3.6, %conv35.3.6
  %conv37.3.6 = trunc i32 %xor36.3.6 to i8
  store i8 %conv37.3.6, i8* %scevgep41.3.5, align 1
  %scevgep28.3.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1395, i64 0, i64 0, i64 1
  %1402 = bitcast i8* %scevgep28.3.6 to [61 x [61 x i8]]*
  %scevgep41.3.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1396, i64 0, i64 1, i64 0
  %1403 = bitcast i8* %scevgep41.3.6 to [61 x [61 x i8]]*
  %call16.3.7 = call zeroext i8 (...) @rand()
  store i8 %call16.3.7, i8* %scevgep28.3.6, align 1
  %1404 = load i8, i8* %scevgep28.3.6, align 1
  %conv23.3.7 = zext i8 %1404 to i32
  %1405 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.7 = getelementptr i8, i8* %b, i64 11
  %1406 = load i8, i8* %scevgep34.3.7, align 1
  %call28.3.7 = call zeroext i8 @mult(i8 zeroext %1405, i8 zeroext %1406)
  %conv29.3.7 = zext i8 %call28.3.7 to i32
  %xor.3.7 = xor i32 %conv23.3.7, %conv29.3.7
  %scevgep35.3.7 = getelementptr i8, i8* %a, i64 11
  %1407 = load i8, i8* %scevgep35.3.7, align 1
  %1408 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.7 = call zeroext i8 @mult(i8 zeroext %1407, i8 zeroext %1408)
  %conv35.3.7 = zext i8 %call34.3.7 to i32
  %xor36.3.7 = xor i32 %xor.3.7, %conv35.3.7
  %conv37.3.7 = trunc i32 %xor36.3.7 to i8
  store i8 %conv37.3.7, i8* %scevgep41.3.6, align 1
  %scevgep28.3.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1402, i64 0, i64 0, i64 1
  %1409 = bitcast i8* %scevgep28.3.7 to [61 x [61 x i8]]*
  %scevgep41.3.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1403, i64 0, i64 1, i64 0
  %1410 = bitcast i8* %scevgep41.3.7 to [61 x [61 x i8]]*
  %call16.3.8 = call zeroext i8 (...) @rand()
  store i8 %call16.3.8, i8* %scevgep28.3.7, align 1
  %1411 = load i8, i8* %scevgep28.3.7, align 1
  %conv23.3.8 = zext i8 %1411 to i32
  %1412 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.8 = getelementptr i8, i8* %b, i64 12
  %1413 = load i8, i8* %scevgep34.3.8, align 1
  %call28.3.8 = call zeroext i8 @mult(i8 zeroext %1412, i8 zeroext %1413)
  %conv29.3.8 = zext i8 %call28.3.8 to i32
  %xor.3.8 = xor i32 %conv23.3.8, %conv29.3.8
  %scevgep35.3.8 = getelementptr i8, i8* %a, i64 12
  %1414 = load i8, i8* %scevgep35.3.8, align 1
  %1415 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.8 = call zeroext i8 @mult(i8 zeroext %1414, i8 zeroext %1415)
  %conv35.3.8 = zext i8 %call34.3.8 to i32
  %xor36.3.8 = xor i32 %xor.3.8, %conv35.3.8
  %conv37.3.8 = trunc i32 %xor36.3.8 to i8
  store i8 %conv37.3.8, i8* %scevgep41.3.7, align 1
  %scevgep28.3.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1409, i64 0, i64 0, i64 1
  %1416 = bitcast i8* %scevgep28.3.8 to [61 x [61 x i8]]*
  %scevgep41.3.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1410, i64 0, i64 1, i64 0
  %1417 = bitcast i8* %scevgep41.3.8 to [61 x [61 x i8]]*
  %call16.3.9 = call zeroext i8 (...) @rand()
  store i8 %call16.3.9, i8* %scevgep28.3.8, align 1
  %1418 = load i8, i8* %scevgep28.3.8, align 1
  %conv23.3.9 = zext i8 %1418 to i32
  %1419 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.9 = getelementptr i8, i8* %b, i64 13
  %1420 = load i8, i8* %scevgep34.3.9, align 1
  %call28.3.9 = call zeroext i8 @mult(i8 zeroext %1419, i8 zeroext %1420)
  %conv29.3.9 = zext i8 %call28.3.9 to i32
  %xor.3.9 = xor i32 %conv23.3.9, %conv29.3.9
  %scevgep35.3.9 = getelementptr i8, i8* %a, i64 13
  %1421 = load i8, i8* %scevgep35.3.9, align 1
  %1422 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.9 = call zeroext i8 @mult(i8 zeroext %1421, i8 zeroext %1422)
  %conv35.3.9 = zext i8 %call34.3.9 to i32
  %xor36.3.9 = xor i32 %xor.3.9, %conv35.3.9
  %conv37.3.9 = trunc i32 %xor36.3.9 to i8
  store i8 %conv37.3.9, i8* %scevgep41.3.8, align 1
  %scevgep28.3.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1416, i64 0, i64 0, i64 1
  %1423 = bitcast i8* %scevgep28.3.9 to [61 x [61 x i8]]*
  %scevgep41.3.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1417, i64 0, i64 1, i64 0
  %1424 = bitcast i8* %scevgep41.3.9 to [61 x [61 x i8]]*
  %call16.3.10 = call zeroext i8 (...) @rand()
  store i8 %call16.3.10, i8* %scevgep28.3.9, align 1
  %1425 = load i8, i8* %scevgep28.3.9, align 1
  %conv23.3.10 = zext i8 %1425 to i32
  %1426 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.10 = getelementptr i8, i8* %b, i64 14
  %1427 = load i8, i8* %scevgep34.3.10, align 1
  %call28.3.10 = call zeroext i8 @mult(i8 zeroext %1426, i8 zeroext %1427)
  %conv29.3.10 = zext i8 %call28.3.10 to i32
  %xor.3.10 = xor i32 %conv23.3.10, %conv29.3.10
  %scevgep35.3.10 = getelementptr i8, i8* %a, i64 14
  %1428 = load i8, i8* %scevgep35.3.10, align 1
  %1429 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.10 = call zeroext i8 @mult(i8 zeroext %1428, i8 zeroext %1429)
  %conv35.3.10 = zext i8 %call34.3.10 to i32
  %xor36.3.10 = xor i32 %xor.3.10, %conv35.3.10
  %conv37.3.10 = trunc i32 %xor36.3.10 to i8
  store i8 %conv37.3.10, i8* %scevgep41.3.9, align 1
  %scevgep28.3.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1423, i64 0, i64 0, i64 1
  %1430 = bitcast i8* %scevgep28.3.10 to [61 x [61 x i8]]*
  %scevgep41.3.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1424, i64 0, i64 1, i64 0
  %1431 = bitcast i8* %scevgep41.3.10 to [61 x [61 x i8]]*
  %call16.3.11 = call zeroext i8 (...) @rand()
  store i8 %call16.3.11, i8* %scevgep28.3.10, align 1
  %1432 = load i8, i8* %scevgep28.3.10, align 1
  %conv23.3.11 = zext i8 %1432 to i32
  %1433 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.11 = getelementptr i8, i8* %b, i64 15
  %1434 = load i8, i8* %scevgep34.3.11, align 1
  %call28.3.11 = call zeroext i8 @mult(i8 zeroext %1433, i8 zeroext %1434)
  %conv29.3.11 = zext i8 %call28.3.11 to i32
  %xor.3.11 = xor i32 %conv23.3.11, %conv29.3.11
  %scevgep35.3.11 = getelementptr i8, i8* %a, i64 15
  %1435 = load i8, i8* %scevgep35.3.11, align 1
  %1436 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.11 = call zeroext i8 @mult(i8 zeroext %1435, i8 zeroext %1436)
  %conv35.3.11 = zext i8 %call34.3.11 to i32
  %xor36.3.11 = xor i32 %xor.3.11, %conv35.3.11
  %conv37.3.11 = trunc i32 %xor36.3.11 to i8
  store i8 %conv37.3.11, i8* %scevgep41.3.10, align 1
  %scevgep28.3.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1430, i64 0, i64 0, i64 1
  %1437 = bitcast i8* %scevgep28.3.11 to [61 x [61 x i8]]*
  %scevgep41.3.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1431, i64 0, i64 1, i64 0
  %1438 = bitcast i8* %scevgep41.3.11 to [61 x [61 x i8]]*
  %call16.3.12 = call zeroext i8 (...) @rand()
  store i8 %call16.3.12, i8* %scevgep28.3.11, align 1
  %1439 = load i8, i8* %scevgep28.3.11, align 1
  %conv23.3.12 = zext i8 %1439 to i32
  %1440 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.12 = getelementptr i8, i8* %b, i64 16
  %1441 = load i8, i8* %scevgep34.3.12, align 1
  %call28.3.12 = call zeroext i8 @mult(i8 zeroext %1440, i8 zeroext %1441)
  %conv29.3.12 = zext i8 %call28.3.12 to i32
  %xor.3.12 = xor i32 %conv23.3.12, %conv29.3.12
  %scevgep35.3.12 = getelementptr i8, i8* %a, i64 16
  %1442 = load i8, i8* %scevgep35.3.12, align 1
  %1443 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.12 = call zeroext i8 @mult(i8 zeroext %1442, i8 zeroext %1443)
  %conv35.3.12 = zext i8 %call34.3.12 to i32
  %xor36.3.12 = xor i32 %xor.3.12, %conv35.3.12
  %conv37.3.12 = trunc i32 %xor36.3.12 to i8
  store i8 %conv37.3.12, i8* %scevgep41.3.11, align 1
  %scevgep28.3.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1437, i64 0, i64 0, i64 1
  %1444 = bitcast i8* %scevgep28.3.12 to [61 x [61 x i8]]*
  %scevgep41.3.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1438, i64 0, i64 1, i64 0
  %1445 = bitcast i8* %scevgep41.3.12 to [61 x [61 x i8]]*
  %call16.3.13 = call zeroext i8 (...) @rand()
  store i8 %call16.3.13, i8* %scevgep28.3.12, align 1
  %1446 = load i8, i8* %scevgep28.3.12, align 1
  %conv23.3.13 = zext i8 %1446 to i32
  %1447 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.13 = getelementptr i8, i8* %b, i64 17
  %1448 = load i8, i8* %scevgep34.3.13, align 1
  %call28.3.13 = call zeroext i8 @mult(i8 zeroext %1447, i8 zeroext %1448)
  %conv29.3.13 = zext i8 %call28.3.13 to i32
  %xor.3.13 = xor i32 %conv23.3.13, %conv29.3.13
  %scevgep35.3.13 = getelementptr i8, i8* %a, i64 17
  %1449 = load i8, i8* %scevgep35.3.13, align 1
  %1450 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.13 = call zeroext i8 @mult(i8 zeroext %1449, i8 zeroext %1450)
  %conv35.3.13 = zext i8 %call34.3.13 to i32
  %xor36.3.13 = xor i32 %xor.3.13, %conv35.3.13
  %conv37.3.13 = trunc i32 %xor36.3.13 to i8
  store i8 %conv37.3.13, i8* %scevgep41.3.12, align 1
  %scevgep28.3.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1444, i64 0, i64 0, i64 1
  %1451 = bitcast i8* %scevgep28.3.13 to [61 x [61 x i8]]*
  %scevgep41.3.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1445, i64 0, i64 1, i64 0
  %1452 = bitcast i8* %scevgep41.3.13 to [61 x [61 x i8]]*
  %call16.3.14 = call zeroext i8 (...) @rand()
  store i8 %call16.3.14, i8* %scevgep28.3.13, align 1
  %1453 = load i8, i8* %scevgep28.3.13, align 1
  %conv23.3.14 = zext i8 %1453 to i32
  %1454 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.14 = getelementptr i8, i8* %b, i64 18
  %1455 = load i8, i8* %scevgep34.3.14, align 1
  %call28.3.14 = call zeroext i8 @mult(i8 zeroext %1454, i8 zeroext %1455)
  %conv29.3.14 = zext i8 %call28.3.14 to i32
  %xor.3.14 = xor i32 %conv23.3.14, %conv29.3.14
  %scevgep35.3.14 = getelementptr i8, i8* %a, i64 18
  %1456 = load i8, i8* %scevgep35.3.14, align 1
  %1457 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.14 = call zeroext i8 @mult(i8 zeroext %1456, i8 zeroext %1457)
  %conv35.3.14 = zext i8 %call34.3.14 to i32
  %xor36.3.14 = xor i32 %xor.3.14, %conv35.3.14
  %conv37.3.14 = trunc i32 %xor36.3.14 to i8
  store i8 %conv37.3.14, i8* %scevgep41.3.13, align 1
  %scevgep28.3.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1451, i64 0, i64 0, i64 1
  %1458 = bitcast i8* %scevgep28.3.14 to [61 x [61 x i8]]*
  %scevgep41.3.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1452, i64 0, i64 1, i64 0
  %1459 = bitcast i8* %scevgep41.3.14 to [61 x [61 x i8]]*
  %call16.3.15 = call zeroext i8 (...) @rand()
  store i8 %call16.3.15, i8* %scevgep28.3.14, align 1
  %1460 = load i8, i8* %scevgep28.3.14, align 1
  %conv23.3.15 = zext i8 %1460 to i32
  %1461 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.15 = getelementptr i8, i8* %b, i64 19
  %1462 = load i8, i8* %scevgep34.3.15, align 1
  %call28.3.15 = call zeroext i8 @mult(i8 zeroext %1461, i8 zeroext %1462)
  %conv29.3.15 = zext i8 %call28.3.15 to i32
  %xor.3.15 = xor i32 %conv23.3.15, %conv29.3.15
  %scevgep35.3.15 = getelementptr i8, i8* %a, i64 19
  %1463 = load i8, i8* %scevgep35.3.15, align 1
  %1464 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.15 = call zeroext i8 @mult(i8 zeroext %1463, i8 zeroext %1464)
  %conv35.3.15 = zext i8 %call34.3.15 to i32
  %xor36.3.15 = xor i32 %xor.3.15, %conv35.3.15
  %conv37.3.15 = trunc i32 %xor36.3.15 to i8
  store i8 %conv37.3.15, i8* %scevgep41.3.14, align 1
  %scevgep28.3.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1458, i64 0, i64 0, i64 1
  %1465 = bitcast i8* %scevgep28.3.15 to [61 x [61 x i8]]*
  %scevgep41.3.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1459, i64 0, i64 1, i64 0
  %1466 = bitcast i8* %scevgep41.3.15 to [61 x [61 x i8]]*
  %call16.3.16 = call zeroext i8 (...) @rand()
  store i8 %call16.3.16, i8* %scevgep28.3.15, align 1
  %1467 = load i8, i8* %scevgep28.3.15, align 1
  %conv23.3.16 = zext i8 %1467 to i32
  %1468 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.16 = getelementptr i8, i8* %b, i64 20
  %1469 = load i8, i8* %scevgep34.3.16, align 1
  %call28.3.16 = call zeroext i8 @mult(i8 zeroext %1468, i8 zeroext %1469)
  %conv29.3.16 = zext i8 %call28.3.16 to i32
  %xor.3.16 = xor i32 %conv23.3.16, %conv29.3.16
  %scevgep35.3.16 = getelementptr i8, i8* %a, i64 20
  %1470 = load i8, i8* %scevgep35.3.16, align 1
  %1471 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.16 = call zeroext i8 @mult(i8 zeroext %1470, i8 zeroext %1471)
  %conv35.3.16 = zext i8 %call34.3.16 to i32
  %xor36.3.16 = xor i32 %xor.3.16, %conv35.3.16
  %conv37.3.16 = trunc i32 %xor36.3.16 to i8
  store i8 %conv37.3.16, i8* %scevgep41.3.15, align 1
  %scevgep28.3.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1465, i64 0, i64 0, i64 1
  %1472 = bitcast i8* %scevgep28.3.16 to [61 x [61 x i8]]*
  %scevgep41.3.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1466, i64 0, i64 1, i64 0
  %1473 = bitcast i8* %scevgep41.3.16 to [61 x [61 x i8]]*
  %call16.3.17 = call zeroext i8 (...) @rand()
  store i8 %call16.3.17, i8* %scevgep28.3.16, align 1
  %1474 = load i8, i8* %scevgep28.3.16, align 1
  %conv23.3.17 = zext i8 %1474 to i32
  %1475 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.17 = getelementptr i8, i8* %b, i64 21
  %1476 = load i8, i8* %scevgep34.3.17, align 1
  %call28.3.17 = call zeroext i8 @mult(i8 zeroext %1475, i8 zeroext %1476)
  %conv29.3.17 = zext i8 %call28.3.17 to i32
  %xor.3.17 = xor i32 %conv23.3.17, %conv29.3.17
  %scevgep35.3.17 = getelementptr i8, i8* %a, i64 21
  %1477 = load i8, i8* %scevgep35.3.17, align 1
  %1478 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.17 = call zeroext i8 @mult(i8 zeroext %1477, i8 zeroext %1478)
  %conv35.3.17 = zext i8 %call34.3.17 to i32
  %xor36.3.17 = xor i32 %xor.3.17, %conv35.3.17
  %conv37.3.17 = trunc i32 %xor36.3.17 to i8
  store i8 %conv37.3.17, i8* %scevgep41.3.16, align 1
  %scevgep28.3.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1472, i64 0, i64 0, i64 1
  %1479 = bitcast i8* %scevgep28.3.17 to [61 x [61 x i8]]*
  %scevgep41.3.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1473, i64 0, i64 1, i64 0
  %1480 = bitcast i8* %scevgep41.3.17 to [61 x [61 x i8]]*
  %call16.3.18 = call zeroext i8 (...) @rand()
  store i8 %call16.3.18, i8* %scevgep28.3.17, align 1
  %1481 = load i8, i8* %scevgep28.3.17, align 1
  %conv23.3.18 = zext i8 %1481 to i32
  %1482 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.18 = getelementptr i8, i8* %b, i64 22
  %1483 = load i8, i8* %scevgep34.3.18, align 1
  %call28.3.18 = call zeroext i8 @mult(i8 zeroext %1482, i8 zeroext %1483)
  %conv29.3.18 = zext i8 %call28.3.18 to i32
  %xor.3.18 = xor i32 %conv23.3.18, %conv29.3.18
  %scevgep35.3.18 = getelementptr i8, i8* %a, i64 22
  %1484 = load i8, i8* %scevgep35.3.18, align 1
  %1485 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.18 = call zeroext i8 @mult(i8 zeroext %1484, i8 zeroext %1485)
  %conv35.3.18 = zext i8 %call34.3.18 to i32
  %xor36.3.18 = xor i32 %xor.3.18, %conv35.3.18
  %conv37.3.18 = trunc i32 %xor36.3.18 to i8
  store i8 %conv37.3.18, i8* %scevgep41.3.17, align 1
  %scevgep28.3.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1479, i64 0, i64 0, i64 1
  %1486 = bitcast i8* %scevgep28.3.18 to [61 x [61 x i8]]*
  %scevgep41.3.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1480, i64 0, i64 1, i64 0
  %1487 = bitcast i8* %scevgep41.3.18 to [61 x [61 x i8]]*
  %call16.3.19 = call zeroext i8 (...) @rand()
  store i8 %call16.3.19, i8* %scevgep28.3.18, align 1
  %1488 = load i8, i8* %scevgep28.3.18, align 1
  %conv23.3.19 = zext i8 %1488 to i32
  %1489 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.19 = getelementptr i8, i8* %b, i64 23
  %1490 = load i8, i8* %scevgep34.3.19, align 1
  %call28.3.19 = call zeroext i8 @mult(i8 zeroext %1489, i8 zeroext %1490)
  %conv29.3.19 = zext i8 %call28.3.19 to i32
  %xor.3.19 = xor i32 %conv23.3.19, %conv29.3.19
  %scevgep35.3.19 = getelementptr i8, i8* %a, i64 23
  %1491 = load i8, i8* %scevgep35.3.19, align 1
  %1492 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.19 = call zeroext i8 @mult(i8 zeroext %1491, i8 zeroext %1492)
  %conv35.3.19 = zext i8 %call34.3.19 to i32
  %xor36.3.19 = xor i32 %xor.3.19, %conv35.3.19
  %conv37.3.19 = trunc i32 %xor36.3.19 to i8
  store i8 %conv37.3.19, i8* %scevgep41.3.18, align 1
  %scevgep28.3.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1486, i64 0, i64 0, i64 1
  %1493 = bitcast i8* %scevgep28.3.19 to [61 x [61 x i8]]*
  %scevgep41.3.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1487, i64 0, i64 1, i64 0
  %1494 = bitcast i8* %scevgep41.3.19 to [61 x [61 x i8]]*
  %call16.3.20 = call zeroext i8 (...) @rand()
  store i8 %call16.3.20, i8* %scevgep28.3.19, align 1
  %1495 = load i8, i8* %scevgep28.3.19, align 1
  %conv23.3.20 = zext i8 %1495 to i32
  %1496 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.20 = getelementptr i8, i8* %b, i64 24
  %1497 = load i8, i8* %scevgep34.3.20, align 1
  %call28.3.20 = call zeroext i8 @mult(i8 zeroext %1496, i8 zeroext %1497)
  %conv29.3.20 = zext i8 %call28.3.20 to i32
  %xor.3.20 = xor i32 %conv23.3.20, %conv29.3.20
  %scevgep35.3.20 = getelementptr i8, i8* %a, i64 24
  %1498 = load i8, i8* %scevgep35.3.20, align 1
  %1499 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.20 = call zeroext i8 @mult(i8 zeroext %1498, i8 zeroext %1499)
  %conv35.3.20 = zext i8 %call34.3.20 to i32
  %xor36.3.20 = xor i32 %xor.3.20, %conv35.3.20
  %conv37.3.20 = trunc i32 %xor36.3.20 to i8
  store i8 %conv37.3.20, i8* %scevgep41.3.19, align 1
  %scevgep28.3.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1493, i64 0, i64 0, i64 1
  %1500 = bitcast i8* %scevgep28.3.20 to [61 x [61 x i8]]*
  %scevgep41.3.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1494, i64 0, i64 1, i64 0
  %1501 = bitcast i8* %scevgep41.3.20 to [61 x [61 x i8]]*
  %call16.3.21 = call zeroext i8 (...) @rand()
  store i8 %call16.3.21, i8* %scevgep28.3.20, align 1
  %1502 = load i8, i8* %scevgep28.3.20, align 1
  %conv23.3.21 = zext i8 %1502 to i32
  %1503 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.21 = getelementptr i8, i8* %b, i64 25
  %1504 = load i8, i8* %scevgep34.3.21, align 1
  %call28.3.21 = call zeroext i8 @mult(i8 zeroext %1503, i8 zeroext %1504)
  %conv29.3.21 = zext i8 %call28.3.21 to i32
  %xor.3.21 = xor i32 %conv23.3.21, %conv29.3.21
  %scevgep35.3.21 = getelementptr i8, i8* %a, i64 25
  %1505 = load i8, i8* %scevgep35.3.21, align 1
  %1506 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.21 = call zeroext i8 @mult(i8 zeroext %1505, i8 zeroext %1506)
  %conv35.3.21 = zext i8 %call34.3.21 to i32
  %xor36.3.21 = xor i32 %xor.3.21, %conv35.3.21
  %conv37.3.21 = trunc i32 %xor36.3.21 to i8
  store i8 %conv37.3.21, i8* %scevgep41.3.20, align 1
  %scevgep28.3.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1500, i64 0, i64 0, i64 1
  %1507 = bitcast i8* %scevgep28.3.21 to [61 x [61 x i8]]*
  %scevgep41.3.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1501, i64 0, i64 1, i64 0
  %1508 = bitcast i8* %scevgep41.3.21 to [61 x [61 x i8]]*
  %call16.3.22 = call zeroext i8 (...) @rand()
  store i8 %call16.3.22, i8* %scevgep28.3.21, align 1
  %1509 = load i8, i8* %scevgep28.3.21, align 1
  %conv23.3.22 = zext i8 %1509 to i32
  %1510 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.22 = getelementptr i8, i8* %b, i64 26
  %1511 = load i8, i8* %scevgep34.3.22, align 1
  %call28.3.22 = call zeroext i8 @mult(i8 zeroext %1510, i8 zeroext %1511)
  %conv29.3.22 = zext i8 %call28.3.22 to i32
  %xor.3.22 = xor i32 %conv23.3.22, %conv29.3.22
  %scevgep35.3.22 = getelementptr i8, i8* %a, i64 26
  %1512 = load i8, i8* %scevgep35.3.22, align 1
  %1513 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.22 = call zeroext i8 @mult(i8 zeroext %1512, i8 zeroext %1513)
  %conv35.3.22 = zext i8 %call34.3.22 to i32
  %xor36.3.22 = xor i32 %xor.3.22, %conv35.3.22
  %conv37.3.22 = trunc i32 %xor36.3.22 to i8
  store i8 %conv37.3.22, i8* %scevgep41.3.21, align 1
  %scevgep28.3.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1507, i64 0, i64 0, i64 1
  %1514 = bitcast i8* %scevgep28.3.22 to [61 x [61 x i8]]*
  %scevgep41.3.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1508, i64 0, i64 1, i64 0
  %1515 = bitcast i8* %scevgep41.3.22 to [61 x [61 x i8]]*
  %call16.3.23 = call zeroext i8 (...) @rand()
  store i8 %call16.3.23, i8* %scevgep28.3.22, align 1
  %1516 = load i8, i8* %scevgep28.3.22, align 1
  %conv23.3.23 = zext i8 %1516 to i32
  %1517 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.23 = getelementptr i8, i8* %b, i64 27
  %1518 = load i8, i8* %scevgep34.3.23, align 1
  %call28.3.23 = call zeroext i8 @mult(i8 zeroext %1517, i8 zeroext %1518)
  %conv29.3.23 = zext i8 %call28.3.23 to i32
  %xor.3.23 = xor i32 %conv23.3.23, %conv29.3.23
  %scevgep35.3.23 = getelementptr i8, i8* %a, i64 27
  %1519 = load i8, i8* %scevgep35.3.23, align 1
  %1520 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.23 = call zeroext i8 @mult(i8 zeroext %1519, i8 zeroext %1520)
  %conv35.3.23 = zext i8 %call34.3.23 to i32
  %xor36.3.23 = xor i32 %xor.3.23, %conv35.3.23
  %conv37.3.23 = trunc i32 %xor36.3.23 to i8
  store i8 %conv37.3.23, i8* %scevgep41.3.22, align 1
  %scevgep28.3.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1514, i64 0, i64 0, i64 1
  %1521 = bitcast i8* %scevgep28.3.23 to [61 x [61 x i8]]*
  %scevgep41.3.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1515, i64 0, i64 1, i64 0
  %1522 = bitcast i8* %scevgep41.3.23 to [61 x [61 x i8]]*
  %call16.3.24 = call zeroext i8 (...) @rand()
  store i8 %call16.3.24, i8* %scevgep28.3.23, align 1
  %1523 = load i8, i8* %scevgep28.3.23, align 1
  %conv23.3.24 = zext i8 %1523 to i32
  %1524 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.24 = getelementptr i8, i8* %b, i64 28
  %1525 = load i8, i8* %scevgep34.3.24, align 1
  %call28.3.24 = call zeroext i8 @mult(i8 zeroext %1524, i8 zeroext %1525)
  %conv29.3.24 = zext i8 %call28.3.24 to i32
  %xor.3.24 = xor i32 %conv23.3.24, %conv29.3.24
  %scevgep35.3.24 = getelementptr i8, i8* %a, i64 28
  %1526 = load i8, i8* %scevgep35.3.24, align 1
  %1527 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.24 = call zeroext i8 @mult(i8 zeroext %1526, i8 zeroext %1527)
  %conv35.3.24 = zext i8 %call34.3.24 to i32
  %xor36.3.24 = xor i32 %xor.3.24, %conv35.3.24
  %conv37.3.24 = trunc i32 %xor36.3.24 to i8
  store i8 %conv37.3.24, i8* %scevgep41.3.23, align 1
  %scevgep28.3.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1521, i64 0, i64 0, i64 1
  %1528 = bitcast i8* %scevgep28.3.24 to [61 x [61 x i8]]*
  %scevgep41.3.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1522, i64 0, i64 1, i64 0
  %1529 = bitcast i8* %scevgep41.3.24 to [61 x [61 x i8]]*
  %call16.3.25 = call zeroext i8 (...) @rand()
  store i8 %call16.3.25, i8* %scevgep28.3.24, align 1
  %1530 = load i8, i8* %scevgep28.3.24, align 1
  %conv23.3.25 = zext i8 %1530 to i32
  %1531 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.25 = getelementptr i8, i8* %b, i64 29
  %1532 = load i8, i8* %scevgep34.3.25, align 1
  %call28.3.25 = call zeroext i8 @mult(i8 zeroext %1531, i8 zeroext %1532)
  %conv29.3.25 = zext i8 %call28.3.25 to i32
  %xor.3.25 = xor i32 %conv23.3.25, %conv29.3.25
  %scevgep35.3.25 = getelementptr i8, i8* %a, i64 29
  %1533 = load i8, i8* %scevgep35.3.25, align 1
  %1534 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.25 = call zeroext i8 @mult(i8 zeroext %1533, i8 zeroext %1534)
  %conv35.3.25 = zext i8 %call34.3.25 to i32
  %xor36.3.25 = xor i32 %xor.3.25, %conv35.3.25
  %conv37.3.25 = trunc i32 %xor36.3.25 to i8
  store i8 %conv37.3.25, i8* %scevgep41.3.24, align 1
  %scevgep28.3.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1528, i64 0, i64 0, i64 1
  %1535 = bitcast i8* %scevgep28.3.25 to [61 x [61 x i8]]*
  %scevgep41.3.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1529, i64 0, i64 1, i64 0
  %1536 = bitcast i8* %scevgep41.3.25 to [61 x [61 x i8]]*
  %call16.3.26 = call zeroext i8 (...) @rand()
  store i8 %call16.3.26, i8* %scevgep28.3.25, align 1
  %1537 = load i8, i8* %scevgep28.3.25, align 1
  %conv23.3.26 = zext i8 %1537 to i32
  %1538 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.26 = getelementptr i8, i8* %b, i64 30
  %1539 = load i8, i8* %scevgep34.3.26, align 1
  %call28.3.26 = call zeroext i8 @mult(i8 zeroext %1538, i8 zeroext %1539)
  %conv29.3.26 = zext i8 %call28.3.26 to i32
  %xor.3.26 = xor i32 %conv23.3.26, %conv29.3.26
  %scevgep35.3.26 = getelementptr i8, i8* %a, i64 30
  %1540 = load i8, i8* %scevgep35.3.26, align 1
  %1541 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.26 = call zeroext i8 @mult(i8 zeroext %1540, i8 zeroext %1541)
  %conv35.3.26 = zext i8 %call34.3.26 to i32
  %xor36.3.26 = xor i32 %xor.3.26, %conv35.3.26
  %conv37.3.26 = trunc i32 %xor36.3.26 to i8
  store i8 %conv37.3.26, i8* %scevgep41.3.25, align 1
  %scevgep28.3.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1535, i64 0, i64 0, i64 1
  %1542 = bitcast i8* %scevgep28.3.26 to [61 x [61 x i8]]*
  %scevgep41.3.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1536, i64 0, i64 1, i64 0
  %1543 = bitcast i8* %scevgep41.3.26 to [61 x [61 x i8]]*
  %call16.3.27 = call zeroext i8 (...) @rand()
  store i8 %call16.3.27, i8* %scevgep28.3.26, align 1
  %1544 = load i8, i8* %scevgep28.3.26, align 1
  %conv23.3.27 = zext i8 %1544 to i32
  %1545 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.27 = getelementptr i8, i8* %b, i64 31
  %1546 = load i8, i8* %scevgep34.3.27, align 1
  %call28.3.27 = call zeroext i8 @mult(i8 zeroext %1545, i8 zeroext %1546)
  %conv29.3.27 = zext i8 %call28.3.27 to i32
  %xor.3.27 = xor i32 %conv23.3.27, %conv29.3.27
  %scevgep35.3.27 = getelementptr i8, i8* %a, i64 31
  %1547 = load i8, i8* %scevgep35.3.27, align 1
  %1548 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.27 = call zeroext i8 @mult(i8 zeroext %1547, i8 zeroext %1548)
  %conv35.3.27 = zext i8 %call34.3.27 to i32
  %xor36.3.27 = xor i32 %xor.3.27, %conv35.3.27
  %conv37.3.27 = trunc i32 %xor36.3.27 to i8
  store i8 %conv37.3.27, i8* %scevgep41.3.26, align 1
  %scevgep28.3.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1542, i64 0, i64 0, i64 1
  %1549 = bitcast i8* %scevgep28.3.27 to [61 x [61 x i8]]*
  %scevgep41.3.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1543, i64 0, i64 1, i64 0
  %1550 = bitcast i8* %scevgep41.3.27 to [61 x [61 x i8]]*
  %call16.3.28 = call zeroext i8 (...) @rand()
  store i8 %call16.3.28, i8* %scevgep28.3.27, align 1
  %1551 = load i8, i8* %scevgep28.3.27, align 1
  %conv23.3.28 = zext i8 %1551 to i32
  %1552 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.28 = getelementptr i8, i8* %b, i64 32
  %1553 = load i8, i8* %scevgep34.3.28, align 1
  %call28.3.28 = call zeroext i8 @mult(i8 zeroext %1552, i8 zeroext %1553)
  %conv29.3.28 = zext i8 %call28.3.28 to i32
  %xor.3.28 = xor i32 %conv23.3.28, %conv29.3.28
  %scevgep35.3.28 = getelementptr i8, i8* %a, i64 32
  %1554 = load i8, i8* %scevgep35.3.28, align 1
  %1555 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.28 = call zeroext i8 @mult(i8 zeroext %1554, i8 zeroext %1555)
  %conv35.3.28 = zext i8 %call34.3.28 to i32
  %xor36.3.28 = xor i32 %xor.3.28, %conv35.3.28
  %conv37.3.28 = trunc i32 %xor36.3.28 to i8
  store i8 %conv37.3.28, i8* %scevgep41.3.27, align 1
  %scevgep28.3.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1549, i64 0, i64 0, i64 1
  %1556 = bitcast i8* %scevgep28.3.28 to [61 x [61 x i8]]*
  %scevgep41.3.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1550, i64 0, i64 1, i64 0
  %1557 = bitcast i8* %scevgep41.3.28 to [61 x [61 x i8]]*
  %call16.3.29 = call zeroext i8 (...) @rand()
  store i8 %call16.3.29, i8* %scevgep28.3.28, align 1
  %1558 = load i8, i8* %scevgep28.3.28, align 1
  %conv23.3.29 = zext i8 %1558 to i32
  %1559 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.29 = getelementptr i8, i8* %b, i64 33
  %1560 = load i8, i8* %scevgep34.3.29, align 1
  %call28.3.29 = call zeroext i8 @mult(i8 zeroext %1559, i8 zeroext %1560)
  %conv29.3.29 = zext i8 %call28.3.29 to i32
  %xor.3.29 = xor i32 %conv23.3.29, %conv29.3.29
  %scevgep35.3.29 = getelementptr i8, i8* %a, i64 33
  %1561 = load i8, i8* %scevgep35.3.29, align 1
  %1562 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.29 = call zeroext i8 @mult(i8 zeroext %1561, i8 zeroext %1562)
  %conv35.3.29 = zext i8 %call34.3.29 to i32
  %xor36.3.29 = xor i32 %xor.3.29, %conv35.3.29
  %conv37.3.29 = trunc i32 %xor36.3.29 to i8
  store i8 %conv37.3.29, i8* %scevgep41.3.28, align 1
  %scevgep28.3.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1556, i64 0, i64 0, i64 1
  %1563 = bitcast i8* %scevgep28.3.29 to [61 x [61 x i8]]*
  %scevgep41.3.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1557, i64 0, i64 1, i64 0
  %1564 = bitcast i8* %scevgep41.3.29 to [61 x [61 x i8]]*
  %call16.3.30 = call zeroext i8 (...) @rand()
  store i8 %call16.3.30, i8* %scevgep28.3.29, align 1
  %1565 = load i8, i8* %scevgep28.3.29, align 1
  %conv23.3.30 = zext i8 %1565 to i32
  %1566 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.30 = getelementptr i8, i8* %b, i64 34
  %1567 = load i8, i8* %scevgep34.3.30, align 1
  %call28.3.30 = call zeroext i8 @mult(i8 zeroext %1566, i8 zeroext %1567)
  %conv29.3.30 = zext i8 %call28.3.30 to i32
  %xor.3.30 = xor i32 %conv23.3.30, %conv29.3.30
  %scevgep35.3.30 = getelementptr i8, i8* %a, i64 34
  %1568 = load i8, i8* %scevgep35.3.30, align 1
  %1569 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.30 = call zeroext i8 @mult(i8 zeroext %1568, i8 zeroext %1569)
  %conv35.3.30 = zext i8 %call34.3.30 to i32
  %xor36.3.30 = xor i32 %xor.3.30, %conv35.3.30
  %conv37.3.30 = trunc i32 %xor36.3.30 to i8
  store i8 %conv37.3.30, i8* %scevgep41.3.29, align 1
  %scevgep28.3.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1563, i64 0, i64 0, i64 1
  %1570 = bitcast i8* %scevgep28.3.30 to [61 x [61 x i8]]*
  %scevgep41.3.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1564, i64 0, i64 1, i64 0
  %1571 = bitcast i8* %scevgep41.3.30 to [61 x [61 x i8]]*
  %call16.3.31 = call zeroext i8 (...) @rand()
  store i8 %call16.3.31, i8* %scevgep28.3.30, align 1
  %1572 = load i8, i8* %scevgep28.3.30, align 1
  %conv23.3.31 = zext i8 %1572 to i32
  %1573 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.31 = getelementptr i8, i8* %b, i64 35
  %1574 = load i8, i8* %scevgep34.3.31, align 1
  %call28.3.31 = call zeroext i8 @mult(i8 zeroext %1573, i8 zeroext %1574)
  %conv29.3.31 = zext i8 %call28.3.31 to i32
  %xor.3.31 = xor i32 %conv23.3.31, %conv29.3.31
  %scevgep35.3.31 = getelementptr i8, i8* %a, i64 35
  %1575 = load i8, i8* %scevgep35.3.31, align 1
  %1576 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.31 = call zeroext i8 @mult(i8 zeroext %1575, i8 zeroext %1576)
  %conv35.3.31 = zext i8 %call34.3.31 to i32
  %xor36.3.31 = xor i32 %xor.3.31, %conv35.3.31
  %conv37.3.31 = trunc i32 %xor36.3.31 to i8
  store i8 %conv37.3.31, i8* %scevgep41.3.30, align 1
  %scevgep28.3.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1570, i64 0, i64 0, i64 1
  %1577 = bitcast i8* %scevgep28.3.31 to [61 x [61 x i8]]*
  %scevgep41.3.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1571, i64 0, i64 1, i64 0
  %1578 = bitcast i8* %scevgep41.3.31 to [61 x [61 x i8]]*
  %call16.3.32 = call zeroext i8 (...) @rand()
  store i8 %call16.3.32, i8* %scevgep28.3.31, align 1
  %1579 = load i8, i8* %scevgep28.3.31, align 1
  %conv23.3.32 = zext i8 %1579 to i32
  %1580 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.32 = getelementptr i8, i8* %b, i64 36
  %1581 = load i8, i8* %scevgep34.3.32, align 1
  %call28.3.32 = call zeroext i8 @mult(i8 zeroext %1580, i8 zeroext %1581)
  %conv29.3.32 = zext i8 %call28.3.32 to i32
  %xor.3.32 = xor i32 %conv23.3.32, %conv29.3.32
  %scevgep35.3.32 = getelementptr i8, i8* %a, i64 36
  %1582 = load i8, i8* %scevgep35.3.32, align 1
  %1583 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.32 = call zeroext i8 @mult(i8 zeroext %1582, i8 zeroext %1583)
  %conv35.3.32 = zext i8 %call34.3.32 to i32
  %xor36.3.32 = xor i32 %xor.3.32, %conv35.3.32
  %conv37.3.32 = trunc i32 %xor36.3.32 to i8
  store i8 %conv37.3.32, i8* %scevgep41.3.31, align 1
  %scevgep28.3.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1577, i64 0, i64 0, i64 1
  %1584 = bitcast i8* %scevgep28.3.32 to [61 x [61 x i8]]*
  %scevgep41.3.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1578, i64 0, i64 1, i64 0
  %1585 = bitcast i8* %scevgep41.3.32 to [61 x [61 x i8]]*
  %call16.3.33 = call zeroext i8 (...) @rand()
  store i8 %call16.3.33, i8* %scevgep28.3.32, align 1
  %1586 = load i8, i8* %scevgep28.3.32, align 1
  %conv23.3.33 = zext i8 %1586 to i32
  %1587 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.33 = getelementptr i8, i8* %b, i64 37
  %1588 = load i8, i8* %scevgep34.3.33, align 1
  %call28.3.33 = call zeroext i8 @mult(i8 zeroext %1587, i8 zeroext %1588)
  %conv29.3.33 = zext i8 %call28.3.33 to i32
  %xor.3.33 = xor i32 %conv23.3.33, %conv29.3.33
  %scevgep35.3.33 = getelementptr i8, i8* %a, i64 37
  %1589 = load i8, i8* %scevgep35.3.33, align 1
  %1590 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.33 = call zeroext i8 @mult(i8 zeroext %1589, i8 zeroext %1590)
  %conv35.3.33 = zext i8 %call34.3.33 to i32
  %xor36.3.33 = xor i32 %xor.3.33, %conv35.3.33
  %conv37.3.33 = trunc i32 %xor36.3.33 to i8
  store i8 %conv37.3.33, i8* %scevgep41.3.32, align 1
  %scevgep28.3.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1584, i64 0, i64 0, i64 1
  %1591 = bitcast i8* %scevgep28.3.33 to [61 x [61 x i8]]*
  %scevgep41.3.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1585, i64 0, i64 1, i64 0
  %1592 = bitcast i8* %scevgep41.3.33 to [61 x [61 x i8]]*
  %call16.3.34 = call zeroext i8 (...) @rand()
  store i8 %call16.3.34, i8* %scevgep28.3.33, align 1
  %1593 = load i8, i8* %scevgep28.3.33, align 1
  %conv23.3.34 = zext i8 %1593 to i32
  %1594 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.34 = getelementptr i8, i8* %b, i64 38
  %1595 = load i8, i8* %scevgep34.3.34, align 1
  %call28.3.34 = call zeroext i8 @mult(i8 zeroext %1594, i8 zeroext %1595)
  %conv29.3.34 = zext i8 %call28.3.34 to i32
  %xor.3.34 = xor i32 %conv23.3.34, %conv29.3.34
  %scevgep35.3.34 = getelementptr i8, i8* %a, i64 38
  %1596 = load i8, i8* %scevgep35.3.34, align 1
  %1597 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.34 = call zeroext i8 @mult(i8 zeroext %1596, i8 zeroext %1597)
  %conv35.3.34 = zext i8 %call34.3.34 to i32
  %xor36.3.34 = xor i32 %xor.3.34, %conv35.3.34
  %conv37.3.34 = trunc i32 %xor36.3.34 to i8
  store i8 %conv37.3.34, i8* %scevgep41.3.33, align 1
  %scevgep28.3.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1591, i64 0, i64 0, i64 1
  %1598 = bitcast i8* %scevgep28.3.34 to [61 x [61 x i8]]*
  %scevgep41.3.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1592, i64 0, i64 1, i64 0
  %1599 = bitcast i8* %scevgep41.3.34 to [61 x [61 x i8]]*
  %call16.3.35 = call zeroext i8 (...) @rand()
  store i8 %call16.3.35, i8* %scevgep28.3.34, align 1
  %1600 = load i8, i8* %scevgep28.3.34, align 1
  %conv23.3.35 = zext i8 %1600 to i32
  %1601 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.35 = getelementptr i8, i8* %b, i64 39
  %1602 = load i8, i8* %scevgep34.3.35, align 1
  %call28.3.35 = call zeroext i8 @mult(i8 zeroext %1601, i8 zeroext %1602)
  %conv29.3.35 = zext i8 %call28.3.35 to i32
  %xor.3.35 = xor i32 %conv23.3.35, %conv29.3.35
  %scevgep35.3.35 = getelementptr i8, i8* %a, i64 39
  %1603 = load i8, i8* %scevgep35.3.35, align 1
  %1604 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.35 = call zeroext i8 @mult(i8 zeroext %1603, i8 zeroext %1604)
  %conv35.3.35 = zext i8 %call34.3.35 to i32
  %xor36.3.35 = xor i32 %xor.3.35, %conv35.3.35
  %conv37.3.35 = trunc i32 %xor36.3.35 to i8
  store i8 %conv37.3.35, i8* %scevgep41.3.34, align 1
  %scevgep28.3.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1598, i64 0, i64 0, i64 1
  %1605 = bitcast i8* %scevgep28.3.35 to [61 x [61 x i8]]*
  %scevgep41.3.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1599, i64 0, i64 1, i64 0
  %1606 = bitcast i8* %scevgep41.3.35 to [61 x [61 x i8]]*
  %call16.3.36 = call zeroext i8 (...) @rand()
  store i8 %call16.3.36, i8* %scevgep28.3.35, align 1
  %1607 = load i8, i8* %scevgep28.3.35, align 1
  %conv23.3.36 = zext i8 %1607 to i32
  %1608 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.36 = getelementptr i8, i8* %b, i64 40
  %1609 = load i8, i8* %scevgep34.3.36, align 1
  %call28.3.36 = call zeroext i8 @mult(i8 zeroext %1608, i8 zeroext %1609)
  %conv29.3.36 = zext i8 %call28.3.36 to i32
  %xor.3.36 = xor i32 %conv23.3.36, %conv29.3.36
  %scevgep35.3.36 = getelementptr i8, i8* %a, i64 40
  %1610 = load i8, i8* %scevgep35.3.36, align 1
  %1611 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.36 = call zeroext i8 @mult(i8 zeroext %1610, i8 zeroext %1611)
  %conv35.3.36 = zext i8 %call34.3.36 to i32
  %xor36.3.36 = xor i32 %xor.3.36, %conv35.3.36
  %conv37.3.36 = trunc i32 %xor36.3.36 to i8
  store i8 %conv37.3.36, i8* %scevgep41.3.35, align 1
  %scevgep28.3.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1605, i64 0, i64 0, i64 1
  %1612 = bitcast i8* %scevgep28.3.36 to [61 x [61 x i8]]*
  %scevgep41.3.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1606, i64 0, i64 1, i64 0
  %1613 = bitcast i8* %scevgep41.3.36 to [61 x [61 x i8]]*
  %call16.3.37 = call zeroext i8 (...) @rand()
  store i8 %call16.3.37, i8* %scevgep28.3.36, align 1
  %1614 = load i8, i8* %scevgep28.3.36, align 1
  %conv23.3.37 = zext i8 %1614 to i32
  %1615 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.37 = getelementptr i8, i8* %b, i64 41
  %1616 = load i8, i8* %scevgep34.3.37, align 1
  %call28.3.37 = call zeroext i8 @mult(i8 zeroext %1615, i8 zeroext %1616)
  %conv29.3.37 = zext i8 %call28.3.37 to i32
  %xor.3.37 = xor i32 %conv23.3.37, %conv29.3.37
  %scevgep35.3.37 = getelementptr i8, i8* %a, i64 41
  %1617 = load i8, i8* %scevgep35.3.37, align 1
  %1618 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.37 = call zeroext i8 @mult(i8 zeroext %1617, i8 zeroext %1618)
  %conv35.3.37 = zext i8 %call34.3.37 to i32
  %xor36.3.37 = xor i32 %xor.3.37, %conv35.3.37
  %conv37.3.37 = trunc i32 %xor36.3.37 to i8
  store i8 %conv37.3.37, i8* %scevgep41.3.36, align 1
  %scevgep28.3.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1612, i64 0, i64 0, i64 1
  %1619 = bitcast i8* %scevgep28.3.37 to [61 x [61 x i8]]*
  %scevgep41.3.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1613, i64 0, i64 1, i64 0
  %1620 = bitcast i8* %scevgep41.3.37 to [61 x [61 x i8]]*
  %call16.3.38 = call zeroext i8 (...) @rand()
  store i8 %call16.3.38, i8* %scevgep28.3.37, align 1
  %1621 = load i8, i8* %scevgep28.3.37, align 1
  %conv23.3.38 = zext i8 %1621 to i32
  %1622 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.38 = getelementptr i8, i8* %b, i64 42
  %1623 = load i8, i8* %scevgep34.3.38, align 1
  %call28.3.38 = call zeroext i8 @mult(i8 zeroext %1622, i8 zeroext %1623)
  %conv29.3.38 = zext i8 %call28.3.38 to i32
  %xor.3.38 = xor i32 %conv23.3.38, %conv29.3.38
  %scevgep35.3.38 = getelementptr i8, i8* %a, i64 42
  %1624 = load i8, i8* %scevgep35.3.38, align 1
  %1625 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.38 = call zeroext i8 @mult(i8 zeroext %1624, i8 zeroext %1625)
  %conv35.3.38 = zext i8 %call34.3.38 to i32
  %xor36.3.38 = xor i32 %xor.3.38, %conv35.3.38
  %conv37.3.38 = trunc i32 %xor36.3.38 to i8
  store i8 %conv37.3.38, i8* %scevgep41.3.37, align 1
  %scevgep28.3.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1619, i64 0, i64 0, i64 1
  %1626 = bitcast i8* %scevgep28.3.38 to [61 x [61 x i8]]*
  %scevgep41.3.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1620, i64 0, i64 1, i64 0
  %1627 = bitcast i8* %scevgep41.3.38 to [61 x [61 x i8]]*
  %call16.3.39 = call zeroext i8 (...) @rand()
  store i8 %call16.3.39, i8* %scevgep28.3.38, align 1
  %1628 = load i8, i8* %scevgep28.3.38, align 1
  %conv23.3.39 = zext i8 %1628 to i32
  %1629 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.39 = getelementptr i8, i8* %b, i64 43
  %1630 = load i8, i8* %scevgep34.3.39, align 1
  %call28.3.39 = call zeroext i8 @mult(i8 zeroext %1629, i8 zeroext %1630)
  %conv29.3.39 = zext i8 %call28.3.39 to i32
  %xor.3.39 = xor i32 %conv23.3.39, %conv29.3.39
  %scevgep35.3.39 = getelementptr i8, i8* %a, i64 43
  %1631 = load i8, i8* %scevgep35.3.39, align 1
  %1632 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.39 = call zeroext i8 @mult(i8 zeroext %1631, i8 zeroext %1632)
  %conv35.3.39 = zext i8 %call34.3.39 to i32
  %xor36.3.39 = xor i32 %xor.3.39, %conv35.3.39
  %conv37.3.39 = trunc i32 %xor36.3.39 to i8
  store i8 %conv37.3.39, i8* %scevgep41.3.38, align 1
  %scevgep28.3.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1626, i64 0, i64 0, i64 1
  %1633 = bitcast i8* %scevgep28.3.39 to [61 x [61 x i8]]*
  %scevgep41.3.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1627, i64 0, i64 1, i64 0
  %1634 = bitcast i8* %scevgep41.3.39 to [61 x [61 x i8]]*
  %call16.3.40 = call zeroext i8 (...) @rand()
  store i8 %call16.3.40, i8* %scevgep28.3.39, align 1
  %1635 = load i8, i8* %scevgep28.3.39, align 1
  %conv23.3.40 = zext i8 %1635 to i32
  %1636 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.40 = getelementptr i8, i8* %b, i64 44
  %1637 = load i8, i8* %scevgep34.3.40, align 1
  %call28.3.40 = call zeroext i8 @mult(i8 zeroext %1636, i8 zeroext %1637)
  %conv29.3.40 = zext i8 %call28.3.40 to i32
  %xor.3.40 = xor i32 %conv23.3.40, %conv29.3.40
  %scevgep35.3.40 = getelementptr i8, i8* %a, i64 44
  %1638 = load i8, i8* %scevgep35.3.40, align 1
  %1639 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.40 = call zeroext i8 @mult(i8 zeroext %1638, i8 zeroext %1639)
  %conv35.3.40 = zext i8 %call34.3.40 to i32
  %xor36.3.40 = xor i32 %xor.3.40, %conv35.3.40
  %conv37.3.40 = trunc i32 %xor36.3.40 to i8
  store i8 %conv37.3.40, i8* %scevgep41.3.39, align 1
  %scevgep28.3.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1633, i64 0, i64 0, i64 1
  %1640 = bitcast i8* %scevgep28.3.40 to [61 x [61 x i8]]*
  %scevgep41.3.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1634, i64 0, i64 1, i64 0
  %1641 = bitcast i8* %scevgep41.3.40 to [61 x [61 x i8]]*
  %call16.3.41 = call zeroext i8 (...) @rand()
  store i8 %call16.3.41, i8* %scevgep28.3.40, align 1
  %1642 = load i8, i8* %scevgep28.3.40, align 1
  %conv23.3.41 = zext i8 %1642 to i32
  %1643 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.41 = getelementptr i8, i8* %b, i64 45
  %1644 = load i8, i8* %scevgep34.3.41, align 1
  %call28.3.41 = call zeroext i8 @mult(i8 zeroext %1643, i8 zeroext %1644)
  %conv29.3.41 = zext i8 %call28.3.41 to i32
  %xor.3.41 = xor i32 %conv23.3.41, %conv29.3.41
  %scevgep35.3.41 = getelementptr i8, i8* %a, i64 45
  %1645 = load i8, i8* %scevgep35.3.41, align 1
  %1646 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.41 = call zeroext i8 @mult(i8 zeroext %1645, i8 zeroext %1646)
  %conv35.3.41 = zext i8 %call34.3.41 to i32
  %xor36.3.41 = xor i32 %xor.3.41, %conv35.3.41
  %conv37.3.41 = trunc i32 %xor36.3.41 to i8
  store i8 %conv37.3.41, i8* %scevgep41.3.40, align 1
  %scevgep28.3.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1640, i64 0, i64 0, i64 1
  %1647 = bitcast i8* %scevgep28.3.41 to [61 x [61 x i8]]*
  %scevgep41.3.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1641, i64 0, i64 1, i64 0
  %1648 = bitcast i8* %scevgep41.3.41 to [61 x [61 x i8]]*
  %call16.3.42 = call zeroext i8 (...) @rand()
  store i8 %call16.3.42, i8* %scevgep28.3.41, align 1
  %1649 = load i8, i8* %scevgep28.3.41, align 1
  %conv23.3.42 = zext i8 %1649 to i32
  %1650 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.42 = getelementptr i8, i8* %b, i64 46
  %1651 = load i8, i8* %scevgep34.3.42, align 1
  %call28.3.42 = call zeroext i8 @mult(i8 zeroext %1650, i8 zeroext %1651)
  %conv29.3.42 = zext i8 %call28.3.42 to i32
  %xor.3.42 = xor i32 %conv23.3.42, %conv29.3.42
  %scevgep35.3.42 = getelementptr i8, i8* %a, i64 46
  %1652 = load i8, i8* %scevgep35.3.42, align 1
  %1653 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.42 = call zeroext i8 @mult(i8 zeroext %1652, i8 zeroext %1653)
  %conv35.3.42 = zext i8 %call34.3.42 to i32
  %xor36.3.42 = xor i32 %xor.3.42, %conv35.3.42
  %conv37.3.42 = trunc i32 %xor36.3.42 to i8
  store i8 %conv37.3.42, i8* %scevgep41.3.41, align 1
  %scevgep28.3.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1647, i64 0, i64 0, i64 1
  %1654 = bitcast i8* %scevgep28.3.42 to [61 x [61 x i8]]*
  %scevgep41.3.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1648, i64 0, i64 1, i64 0
  %1655 = bitcast i8* %scevgep41.3.42 to [61 x [61 x i8]]*
  %call16.3.43 = call zeroext i8 (...) @rand()
  store i8 %call16.3.43, i8* %scevgep28.3.42, align 1
  %1656 = load i8, i8* %scevgep28.3.42, align 1
  %conv23.3.43 = zext i8 %1656 to i32
  %1657 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.43 = getelementptr i8, i8* %b, i64 47
  %1658 = load i8, i8* %scevgep34.3.43, align 1
  %call28.3.43 = call zeroext i8 @mult(i8 zeroext %1657, i8 zeroext %1658)
  %conv29.3.43 = zext i8 %call28.3.43 to i32
  %xor.3.43 = xor i32 %conv23.3.43, %conv29.3.43
  %scevgep35.3.43 = getelementptr i8, i8* %a, i64 47
  %1659 = load i8, i8* %scevgep35.3.43, align 1
  %1660 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.43 = call zeroext i8 @mult(i8 zeroext %1659, i8 zeroext %1660)
  %conv35.3.43 = zext i8 %call34.3.43 to i32
  %xor36.3.43 = xor i32 %xor.3.43, %conv35.3.43
  %conv37.3.43 = trunc i32 %xor36.3.43 to i8
  store i8 %conv37.3.43, i8* %scevgep41.3.42, align 1
  %scevgep28.3.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1654, i64 0, i64 0, i64 1
  %1661 = bitcast i8* %scevgep28.3.43 to [61 x [61 x i8]]*
  %scevgep41.3.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1655, i64 0, i64 1, i64 0
  %1662 = bitcast i8* %scevgep41.3.43 to [61 x [61 x i8]]*
  %call16.3.44 = call zeroext i8 (...) @rand()
  store i8 %call16.3.44, i8* %scevgep28.3.43, align 1
  %1663 = load i8, i8* %scevgep28.3.43, align 1
  %conv23.3.44 = zext i8 %1663 to i32
  %1664 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.44 = getelementptr i8, i8* %b, i64 48
  %1665 = load i8, i8* %scevgep34.3.44, align 1
  %call28.3.44 = call zeroext i8 @mult(i8 zeroext %1664, i8 zeroext %1665)
  %conv29.3.44 = zext i8 %call28.3.44 to i32
  %xor.3.44 = xor i32 %conv23.3.44, %conv29.3.44
  %scevgep35.3.44 = getelementptr i8, i8* %a, i64 48
  %1666 = load i8, i8* %scevgep35.3.44, align 1
  %1667 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.44 = call zeroext i8 @mult(i8 zeroext %1666, i8 zeroext %1667)
  %conv35.3.44 = zext i8 %call34.3.44 to i32
  %xor36.3.44 = xor i32 %xor.3.44, %conv35.3.44
  %conv37.3.44 = trunc i32 %xor36.3.44 to i8
  store i8 %conv37.3.44, i8* %scevgep41.3.43, align 1
  %scevgep28.3.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1661, i64 0, i64 0, i64 1
  %1668 = bitcast i8* %scevgep28.3.44 to [61 x [61 x i8]]*
  %scevgep41.3.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1662, i64 0, i64 1, i64 0
  %1669 = bitcast i8* %scevgep41.3.44 to [61 x [61 x i8]]*
  %call16.3.45 = call zeroext i8 (...) @rand()
  store i8 %call16.3.45, i8* %scevgep28.3.44, align 1
  %1670 = load i8, i8* %scevgep28.3.44, align 1
  %conv23.3.45 = zext i8 %1670 to i32
  %1671 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.45 = getelementptr i8, i8* %b, i64 49
  %1672 = load i8, i8* %scevgep34.3.45, align 1
  %call28.3.45 = call zeroext i8 @mult(i8 zeroext %1671, i8 zeroext %1672)
  %conv29.3.45 = zext i8 %call28.3.45 to i32
  %xor.3.45 = xor i32 %conv23.3.45, %conv29.3.45
  %scevgep35.3.45 = getelementptr i8, i8* %a, i64 49
  %1673 = load i8, i8* %scevgep35.3.45, align 1
  %1674 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.45 = call zeroext i8 @mult(i8 zeroext %1673, i8 zeroext %1674)
  %conv35.3.45 = zext i8 %call34.3.45 to i32
  %xor36.3.45 = xor i32 %xor.3.45, %conv35.3.45
  %conv37.3.45 = trunc i32 %xor36.3.45 to i8
  store i8 %conv37.3.45, i8* %scevgep41.3.44, align 1
  %scevgep28.3.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1668, i64 0, i64 0, i64 1
  %1675 = bitcast i8* %scevgep28.3.45 to [61 x [61 x i8]]*
  %scevgep41.3.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1669, i64 0, i64 1, i64 0
  %1676 = bitcast i8* %scevgep41.3.45 to [61 x [61 x i8]]*
  %call16.3.46 = call zeroext i8 (...) @rand()
  store i8 %call16.3.46, i8* %scevgep28.3.45, align 1
  %1677 = load i8, i8* %scevgep28.3.45, align 1
  %conv23.3.46 = zext i8 %1677 to i32
  %1678 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.46 = getelementptr i8, i8* %b, i64 50
  %1679 = load i8, i8* %scevgep34.3.46, align 1
  %call28.3.46 = call zeroext i8 @mult(i8 zeroext %1678, i8 zeroext %1679)
  %conv29.3.46 = zext i8 %call28.3.46 to i32
  %xor.3.46 = xor i32 %conv23.3.46, %conv29.3.46
  %scevgep35.3.46 = getelementptr i8, i8* %a, i64 50
  %1680 = load i8, i8* %scevgep35.3.46, align 1
  %1681 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.46 = call zeroext i8 @mult(i8 zeroext %1680, i8 zeroext %1681)
  %conv35.3.46 = zext i8 %call34.3.46 to i32
  %xor36.3.46 = xor i32 %xor.3.46, %conv35.3.46
  %conv37.3.46 = trunc i32 %xor36.3.46 to i8
  store i8 %conv37.3.46, i8* %scevgep41.3.45, align 1
  %scevgep28.3.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1675, i64 0, i64 0, i64 1
  %1682 = bitcast i8* %scevgep28.3.46 to [61 x [61 x i8]]*
  %scevgep41.3.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1676, i64 0, i64 1, i64 0
  %1683 = bitcast i8* %scevgep41.3.46 to [61 x [61 x i8]]*
  %call16.3.47 = call zeroext i8 (...) @rand()
  store i8 %call16.3.47, i8* %scevgep28.3.46, align 1
  %1684 = load i8, i8* %scevgep28.3.46, align 1
  %conv23.3.47 = zext i8 %1684 to i32
  %1685 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.47 = getelementptr i8, i8* %b, i64 51
  %1686 = load i8, i8* %scevgep34.3.47, align 1
  %call28.3.47 = call zeroext i8 @mult(i8 zeroext %1685, i8 zeroext %1686)
  %conv29.3.47 = zext i8 %call28.3.47 to i32
  %xor.3.47 = xor i32 %conv23.3.47, %conv29.3.47
  %scevgep35.3.47 = getelementptr i8, i8* %a, i64 51
  %1687 = load i8, i8* %scevgep35.3.47, align 1
  %1688 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.47 = call zeroext i8 @mult(i8 zeroext %1687, i8 zeroext %1688)
  %conv35.3.47 = zext i8 %call34.3.47 to i32
  %xor36.3.47 = xor i32 %xor.3.47, %conv35.3.47
  %conv37.3.47 = trunc i32 %xor36.3.47 to i8
  store i8 %conv37.3.47, i8* %scevgep41.3.46, align 1
  %scevgep28.3.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1682, i64 0, i64 0, i64 1
  %1689 = bitcast i8* %scevgep28.3.47 to [61 x [61 x i8]]*
  %scevgep41.3.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1683, i64 0, i64 1, i64 0
  %1690 = bitcast i8* %scevgep41.3.47 to [61 x [61 x i8]]*
  %call16.3.48 = call zeroext i8 (...) @rand()
  store i8 %call16.3.48, i8* %scevgep28.3.47, align 1
  %1691 = load i8, i8* %scevgep28.3.47, align 1
  %conv23.3.48 = zext i8 %1691 to i32
  %1692 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.48 = getelementptr i8, i8* %b, i64 52
  %1693 = load i8, i8* %scevgep34.3.48, align 1
  %call28.3.48 = call zeroext i8 @mult(i8 zeroext %1692, i8 zeroext %1693)
  %conv29.3.48 = zext i8 %call28.3.48 to i32
  %xor.3.48 = xor i32 %conv23.3.48, %conv29.3.48
  %scevgep35.3.48 = getelementptr i8, i8* %a, i64 52
  %1694 = load i8, i8* %scevgep35.3.48, align 1
  %1695 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.48 = call zeroext i8 @mult(i8 zeroext %1694, i8 zeroext %1695)
  %conv35.3.48 = zext i8 %call34.3.48 to i32
  %xor36.3.48 = xor i32 %xor.3.48, %conv35.3.48
  %conv37.3.48 = trunc i32 %xor36.3.48 to i8
  store i8 %conv37.3.48, i8* %scevgep41.3.47, align 1
  %scevgep28.3.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1689, i64 0, i64 0, i64 1
  %1696 = bitcast i8* %scevgep28.3.48 to [61 x [61 x i8]]*
  %scevgep41.3.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1690, i64 0, i64 1, i64 0
  %1697 = bitcast i8* %scevgep41.3.48 to [61 x [61 x i8]]*
  %call16.3.49 = call zeroext i8 (...) @rand()
  store i8 %call16.3.49, i8* %scevgep28.3.48, align 1
  %1698 = load i8, i8* %scevgep28.3.48, align 1
  %conv23.3.49 = zext i8 %1698 to i32
  %1699 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.49 = getelementptr i8, i8* %b, i64 53
  %1700 = load i8, i8* %scevgep34.3.49, align 1
  %call28.3.49 = call zeroext i8 @mult(i8 zeroext %1699, i8 zeroext %1700)
  %conv29.3.49 = zext i8 %call28.3.49 to i32
  %xor.3.49 = xor i32 %conv23.3.49, %conv29.3.49
  %scevgep35.3.49 = getelementptr i8, i8* %a, i64 53
  %1701 = load i8, i8* %scevgep35.3.49, align 1
  %1702 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.49 = call zeroext i8 @mult(i8 zeroext %1701, i8 zeroext %1702)
  %conv35.3.49 = zext i8 %call34.3.49 to i32
  %xor36.3.49 = xor i32 %xor.3.49, %conv35.3.49
  %conv37.3.49 = trunc i32 %xor36.3.49 to i8
  store i8 %conv37.3.49, i8* %scevgep41.3.48, align 1
  %scevgep28.3.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1696, i64 0, i64 0, i64 1
  %1703 = bitcast i8* %scevgep28.3.49 to [61 x [61 x i8]]*
  %scevgep41.3.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1697, i64 0, i64 1, i64 0
  %1704 = bitcast i8* %scevgep41.3.49 to [61 x [61 x i8]]*
  %call16.3.50 = call zeroext i8 (...) @rand()
  store i8 %call16.3.50, i8* %scevgep28.3.49, align 1
  %1705 = load i8, i8* %scevgep28.3.49, align 1
  %conv23.3.50 = zext i8 %1705 to i32
  %1706 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.50 = getelementptr i8, i8* %b, i64 54
  %1707 = load i8, i8* %scevgep34.3.50, align 1
  %call28.3.50 = call zeroext i8 @mult(i8 zeroext %1706, i8 zeroext %1707)
  %conv29.3.50 = zext i8 %call28.3.50 to i32
  %xor.3.50 = xor i32 %conv23.3.50, %conv29.3.50
  %scevgep35.3.50 = getelementptr i8, i8* %a, i64 54
  %1708 = load i8, i8* %scevgep35.3.50, align 1
  %1709 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.50 = call zeroext i8 @mult(i8 zeroext %1708, i8 zeroext %1709)
  %conv35.3.50 = zext i8 %call34.3.50 to i32
  %xor36.3.50 = xor i32 %xor.3.50, %conv35.3.50
  %conv37.3.50 = trunc i32 %xor36.3.50 to i8
  store i8 %conv37.3.50, i8* %scevgep41.3.49, align 1
  %scevgep28.3.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1703, i64 0, i64 0, i64 1
  %1710 = bitcast i8* %scevgep28.3.50 to [61 x [61 x i8]]*
  %scevgep41.3.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1704, i64 0, i64 1, i64 0
  %1711 = bitcast i8* %scevgep41.3.50 to [61 x [61 x i8]]*
  %call16.3.51 = call zeroext i8 (...) @rand()
  store i8 %call16.3.51, i8* %scevgep28.3.50, align 1
  %1712 = load i8, i8* %scevgep28.3.50, align 1
  %conv23.3.51 = zext i8 %1712 to i32
  %1713 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.51 = getelementptr i8, i8* %b, i64 55
  %1714 = load i8, i8* %scevgep34.3.51, align 1
  %call28.3.51 = call zeroext i8 @mult(i8 zeroext %1713, i8 zeroext %1714)
  %conv29.3.51 = zext i8 %call28.3.51 to i32
  %xor.3.51 = xor i32 %conv23.3.51, %conv29.3.51
  %scevgep35.3.51 = getelementptr i8, i8* %a, i64 55
  %1715 = load i8, i8* %scevgep35.3.51, align 1
  %1716 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.51 = call zeroext i8 @mult(i8 zeroext %1715, i8 zeroext %1716)
  %conv35.3.51 = zext i8 %call34.3.51 to i32
  %xor36.3.51 = xor i32 %xor.3.51, %conv35.3.51
  %conv37.3.51 = trunc i32 %xor36.3.51 to i8
  store i8 %conv37.3.51, i8* %scevgep41.3.50, align 1
  %scevgep28.3.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1710, i64 0, i64 0, i64 1
  %1717 = bitcast i8* %scevgep28.3.51 to [61 x [61 x i8]]*
  %scevgep41.3.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1711, i64 0, i64 1, i64 0
  %1718 = bitcast i8* %scevgep41.3.51 to [61 x [61 x i8]]*
  %call16.3.52 = call zeroext i8 (...) @rand()
  store i8 %call16.3.52, i8* %scevgep28.3.51, align 1
  %1719 = load i8, i8* %scevgep28.3.51, align 1
  %conv23.3.52 = zext i8 %1719 to i32
  %1720 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.52 = getelementptr i8, i8* %b, i64 56
  %1721 = load i8, i8* %scevgep34.3.52, align 1
  %call28.3.52 = call zeroext i8 @mult(i8 zeroext %1720, i8 zeroext %1721)
  %conv29.3.52 = zext i8 %call28.3.52 to i32
  %xor.3.52 = xor i32 %conv23.3.52, %conv29.3.52
  %scevgep35.3.52 = getelementptr i8, i8* %a, i64 56
  %1722 = load i8, i8* %scevgep35.3.52, align 1
  %1723 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.52 = call zeroext i8 @mult(i8 zeroext %1722, i8 zeroext %1723)
  %conv35.3.52 = zext i8 %call34.3.52 to i32
  %xor36.3.52 = xor i32 %xor.3.52, %conv35.3.52
  %conv37.3.52 = trunc i32 %xor36.3.52 to i8
  store i8 %conv37.3.52, i8* %scevgep41.3.51, align 1
  %scevgep28.3.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1717, i64 0, i64 0, i64 1
  %1724 = bitcast i8* %scevgep28.3.52 to [61 x [61 x i8]]*
  %scevgep41.3.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1718, i64 0, i64 1, i64 0
  %1725 = bitcast i8* %scevgep41.3.52 to [61 x [61 x i8]]*
  %call16.3.53 = call zeroext i8 (...) @rand()
  store i8 %call16.3.53, i8* %scevgep28.3.52, align 1
  %1726 = load i8, i8* %scevgep28.3.52, align 1
  %conv23.3.53 = zext i8 %1726 to i32
  %1727 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.53 = getelementptr i8, i8* %b, i64 57
  %1728 = load i8, i8* %scevgep34.3.53, align 1
  %call28.3.53 = call zeroext i8 @mult(i8 zeroext %1727, i8 zeroext %1728)
  %conv29.3.53 = zext i8 %call28.3.53 to i32
  %xor.3.53 = xor i32 %conv23.3.53, %conv29.3.53
  %scevgep35.3.53 = getelementptr i8, i8* %a, i64 57
  %1729 = load i8, i8* %scevgep35.3.53, align 1
  %1730 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.53 = call zeroext i8 @mult(i8 zeroext %1729, i8 zeroext %1730)
  %conv35.3.53 = zext i8 %call34.3.53 to i32
  %xor36.3.53 = xor i32 %xor.3.53, %conv35.3.53
  %conv37.3.53 = trunc i32 %xor36.3.53 to i8
  store i8 %conv37.3.53, i8* %scevgep41.3.52, align 1
  %scevgep28.3.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1724, i64 0, i64 0, i64 1
  %1731 = bitcast i8* %scevgep28.3.53 to [61 x [61 x i8]]*
  %scevgep41.3.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1725, i64 0, i64 1, i64 0
  %1732 = bitcast i8* %scevgep41.3.53 to [61 x [61 x i8]]*
  %call16.3.54 = call zeroext i8 (...) @rand()
  store i8 %call16.3.54, i8* %scevgep28.3.53, align 1
  %1733 = load i8, i8* %scevgep28.3.53, align 1
  %conv23.3.54 = zext i8 %1733 to i32
  %1734 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.54 = getelementptr i8, i8* %b, i64 58
  %1735 = load i8, i8* %scevgep34.3.54, align 1
  %call28.3.54 = call zeroext i8 @mult(i8 zeroext %1734, i8 zeroext %1735)
  %conv29.3.54 = zext i8 %call28.3.54 to i32
  %xor.3.54 = xor i32 %conv23.3.54, %conv29.3.54
  %scevgep35.3.54 = getelementptr i8, i8* %a, i64 58
  %1736 = load i8, i8* %scevgep35.3.54, align 1
  %1737 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.54 = call zeroext i8 @mult(i8 zeroext %1736, i8 zeroext %1737)
  %conv35.3.54 = zext i8 %call34.3.54 to i32
  %xor36.3.54 = xor i32 %xor.3.54, %conv35.3.54
  %conv37.3.54 = trunc i32 %xor36.3.54 to i8
  store i8 %conv37.3.54, i8* %scevgep41.3.53, align 1
  %scevgep28.3.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1731, i64 0, i64 0, i64 1
  %1738 = bitcast i8* %scevgep28.3.54 to [61 x [61 x i8]]*
  %scevgep41.3.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1732, i64 0, i64 1, i64 0
  %1739 = bitcast i8* %scevgep41.3.54 to [61 x [61 x i8]]*
  %call16.3.55 = call zeroext i8 (...) @rand()
  store i8 %call16.3.55, i8* %scevgep28.3.54, align 1
  %1740 = load i8, i8* %scevgep28.3.54, align 1
  %conv23.3.55 = zext i8 %1740 to i32
  %1741 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.55 = getelementptr i8, i8* %b, i64 59
  %1742 = load i8, i8* %scevgep34.3.55, align 1
  %call28.3.55 = call zeroext i8 @mult(i8 zeroext %1741, i8 zeroext %1742)
  %conv29.3.55 = zext i8 %call28.3.55 to i32
  %xor.3.55 = xor i32 %conv23.3.55, %conv29.3.55
  %scevgep35.3.55 = getelementptr i8, i8* %a, i64 59
  %1743 = load i8, i8* %scevgep35.3.55, align 1
  %1744 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.55 = call zeroext i8 @mult(i8 zeroext %1743, i8 zeroext %1744)
  %conv35.3.55 = zext i8 %call34.3.55 to i32
  %xor36.3.55 = xor i32 %xor.3.55, %conv35.3.55
  %conv37.3.55 = trunc i32 %xor36.3.55 to i8
  store i8 %conv37.3.55, i8* %scevgep41.3.54, align 1
  %scevgep28.3.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1738, i64 0, i64 0, i64 1
  %scevgep41.3.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1739, i64 0, i64 1, i64 0
  %call16.3.56 = call zeroext i8 (...) @rand()
  store i8 %call16.3.56, i8* %scevgep28.3.55, align 1
  %1745 = load i8, i8* %scevgep28.3.55, align 1
  %conv23.3.56 = zext i8 %1745 to i32
  %1746 = load i8, i8* %arrayidx25.3, align 1
  %scevgep34.3.56 = getelementptr i8, i8* %b, i64 60
  %1747 = load i8, i8* %scevgep34.3.56, align 1
  %call28.3.56 = call zeroext i8 @mult(i8 zeroext %1746, i8 zeroext %1747)
  %conv29.3.56 = zext i8 %call28.3.56 to i32
  %xor.3.56 = xor i32 %conv23.3.56, %conv29.3.56
  %scevgep35.3.56 = getelementptr i8, i8* %a, i64 60
  %1748 = load i8, i8* %scevgep35.3.56, align 1
  %1749 = load i8, i8* %arrayidx33.3, align 1
  %call34.3.56 = call zeroext i8 @mult(i8 zeroext %1748, i8 zeroext %1749)
  %conv35.3.56 = zext i8 %call34.3.56 to i32
  %xor36.3.56 = xor i32 %xor.3.56, %conv35.3.56
  %conv37.3.56 = trunc i32 %xor36.3.56 to i8
  store i8 %conv37.3.56, i8* %scevgep41.3.55, align 1
  %scevgep26.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1353, i64 0, i64 1, i64 1
  %1750 = bitcast i8* %scevgep26.3 to [61 x [61 x i8]]*
  %scevgep39.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1354, i64 0, i64 1, i64 1
  %1751 = bitcast i8* %scevgep39.3 to [61 x [61 x i8]]*
  %arrayidx25.4 = getelementptr inbounds i8, i8* %a, i64 4
  %arrayidx33.4 = getelementptr inbounds i8, i8* %b, i64 4
  %call16.4 = call zeroext i8 (...) @rand()
  store i8 %call16.4, i8* %scevgep26.3, align 1
  %1752 = load i8, i8* %scevgep26.3, align 1
  %conv23.4 = zext i8 %1752 to i32
  %1753 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4 = getelementptr i8, i8* %b, i64 5
  %1754 = load i8, i8* %scevgep34.4, align 1
  %call28.4 = call zeroext i8 @mult(i8 zeroext %1753, i8 zeroext %1754)
  %conv29.4 = zext i8 %call28.4 to i32
  %xor.4 = xor i32 %conv23.4, %conv29.4
  %scevgep35.4 = getelementptr i8, i8* %a, i64 5
  %1755 = load i8, i8* %scevgep35.4, align 1
  %1756 = load i8, i8* %arrayidx33.4, align 1
  %call34.4 = call zeroext i8 @mult(i8 zeroext %1755, i8 zeroext %1756)
  %conv35.4 = zext i8 %call34.4 to i32
  %xor36.4 = xor i32 %xor.4, %conv35.4
  %conv37.4 = trunc i32 %xor36.4 to i8
  store i8 %conv37.4, i8* %scevgep39.3, align 1
  %scevgep28.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1750, i64 0, i64 0, i64 1
  %1757 = bitcast i8* %scevgep28.4 to [61 x [61 x i8]]*
  %scevgep41.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1751, i64 0, i64 1, i64 0
  %1758 = bitcast i8* %scevgep41.4 to [61 x [61 x i8]]*
  %call16.4.1 = call zeroext i8 (...) @rand()
  store i8 %call16.4.1, i8* %scevgep28.4, align 1
  %1759 = load i8, i8* %scevgep28.4, align 1
  %conv23.4.1 = zext i8 %1759 to i32
  %1760 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.1 = getelementptr i8, i8* %b, i64 6
  %1761 = load i8, i8* %scevgep34.4.1, align 1
  %call28.4.1 = call zeroext i8 @mult(i8 zeroext %1760, i8 zeroext %1761)
  %conv29.4.1 = zext i8 %call28.4.1 to i32
  %xor.4.1 = xor i32 %conv23.4.1, %conv29.4.1
  %scevgep35.4.1 = getelementptr i8, i8* %a, i64 6
  %1762 = load i8, i8* %scevgep35.4.1, align 1
  %1763 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.1 = call zeroext i8 @mult(i8 zeroext %1762, i8 zeroext %1763)
  %conv35.4.1 = zext i8 %call34.4.1 to i32
  %xor36.4.1 = xor i32 %xor.4.1, %conv35.4.1
  %conv37.4.1 = trunc i32 %xor36.4.1 to i8
  store i8 %conv37.4.1, i8* %scevgep41.4, align 1
  %scevgep28.4.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1757, i64 0, i64 0, i64 1
  %1764 = bitcast i8* %scevgep28.4.1 to [61 x [61 x i8]]*
  %scevgep41.4.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1758, i64 0, i64 1, i64 0
  %1765 = bitcast i8* %scevgep41.4.1 to [61 x [61 x i8]]*
  %call16.4.2 = call zeroext i8 (...) @rand()
  store i8 %call16.4.2, i8* %scevgep28.4.1, align 1
  %1766 = load i8, i8* %scevgep28.4.1, align 1
  %conv23.4.2 = zext i8 %1766 to i32
  %1767 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.2 = getelementptr i8, i8* %b, i64 7
  %1768 = load i8, i8* %scevgep34.4.2, align 1
  %call28.4.2 = call zeroext i8 @mult(i8 zeroext %1767, i8 zeroext %1768)
  %conv29.4.2 = zext i8 %call28.4.2 to i32
  %xor.4.2 = xor i32 %conv23.4.2, %conv29.4.2
  %scevgep35.4.2 = getelementptr i8, i8* %a, i64 7
  %1769 = load i8, i8* %scevgep35.4.2, align 1
  %1770 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.2 = call zeroext i8 @mult(i8 zeroext %1769, i8 zeroext %1770)
  %conv35.4.2 = zext i8 %call34.4.2 to i32
  %xor36.4.2 = xor i32 %xor.4.2, %conv35.4.2
  %conv37.4.2 = trunc i32 %xor36.4.2 to i8
  store i8 %conv37.4.2, i8* %scevgep41.4.1, align 1
  %scevgep28.4.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1764, i64 0, i64 0, i64 1
  %1771 = bitcast i8* %scevgep28.4.2 to [61 x [61 x i8]]*
  %scevgep41.4.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1765, i64 0, i64 1, i64 0
  %1772 = bitcast i8* %scevgep41.4.2 to [61 x [61 x i8]]*
  %call16.4.3 = call zeroext i8 (...) @rand()
  store i8 %call16.4.3, i8* %scevgep28.4.2, align 1
  %1773 = load i8, i8* %scevgep28.4.2, align 1
  %conv23.4.3 = zext i8 %1773 to i32
  %1774 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.3 = getelementptr i8, i8* %b, i64 8
  %1775 = load i8, i8* %scevgep34.4.3, align 1
  %call28.4.3 = call zeroext i8 @mult(i8 zeroext %1774, i8 zeroext %1775)
  %conv29.4.3 = zext i8 %call28.4.3 to i32
  %xor.4.3 = xor i32 %conv23.4.3, %conv29.4.3
  %scevgep35.4.3 = getelementptr i8, i8* %a, i64 8
  %1776 = load i8, i8* %scevgep35.4.3, align 1
  %1777 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.3 = call zeroext i8 @mult(i8 zeroext %1776, i8 zeroext %1777)
  %conv35.4.3 = zext i8 %call34.4.3 to i32
  %xor36.4.3 = xor i32 %xor.4.3, %conv35.4.3
  %conv37.4.3 = trunc i32 %xor36.4.3 to i8
  store i8 %conv37.4.3, i8* %scevgep41.4.2, align 1
  %scevgep28.4.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1771, i64 0, i64 0, i64 1
  %1778 = bitcast i8* %scevgep28.4.3 to [61 x [61 x i8]]*
  %scevgep41.4.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1772, i64 0, i64 1, i64 0
  %1779 = bitcast i8* %scevgep41.4.3 to [61 x [61 x i8]]*
  %call16.4.4 = call zeroext i8 (...) @rand()
  store i8 %call16.4.4, i8* %scevgep28.4.3, align 1
  %1780 = load i8, i8* %scevgep28.4.3, align 1
  %conv23.4.4 = zext i8 %1780 to i32
  %1781 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.4 = getelementptr i8, i8* %b, i64 9
  %1782 = load i8, i8* %scevgep34.4.4, align 1
  %call28.4.4 = call zeroext i8 @mult(i8 zeroext %1781, i8 zeroext %1782)
  %conv29.4.4 = zext i8 %call28.4.4 to i32
  %xor.4.4 = xor i32 %conv23.4.4, %conv29.4.4
  %scevgep35.4.4 = getelementptr i8, i8* %a, i64 9
  %1783 = load i8, i8* %scevgep35.4.4, align 1
  %1784 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.4 = call zeroext i8 @mult(i8 zeroext %1783, i8 zeroext %1784)
  %conv35.4.4 = zext i8 %call34.4.4 to i32
  %xor36.4.4 = xor i32 %xor.4.4, %conv35.4.4
  %conv37.4.4 = trunc i32 %xor36.4.4 to i8
  store i8 %conv37.4.4, i8* %scevgep41.4.3, align 1
  %scevgep28.4.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1778, i64 0, i64 0, i64 1
  %1785 = bitcast i8* %scevgep28.4.4 to [61 x [61 x i8]]*
  %scevgep41.4.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1779, i64 0, i64 1, i64 0
  %1786 = bitcast i8* %scevgep41.4.4 to [61 x [61 x i8]]*
  %call16.4.5 = call zeroext i8 (...) @rand()
  store i8 %call16.4.5, i8* %scevgep28.4.4, align 1
  %1787 = load i8, i8* %scevgep28.4.4, align 1
  %conv23.4.5 = zext i8 %1787 to i32
  %1788 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.5 = getelementptr i8, i8* %b, i64 10
  %1789 = load i8, i8* %scevgep34.4.5, align 1
  %call28.4.5 = call zeroext i8 @mult(i8 zeroext %1788, i8 zeroext %1789)
  %conv29.4.5 = zext i8 %call28.4.5 to i32
  %xor.4.5 = xor i32 %conv23.4.5, %conv29.4.5
  %scevgep35.4.5 = getelementptr i8, i8* %a, i64 10
  %1790 = load i8, i8* %scevgep35.4.5, align 1
  %1791 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.5 = call zeroext i8 @mult(i8 zeroext %1790, i8 zeroext %1791)
  %conv35.4.5 = zext i8 %call34.4.5 to i32
  %xor36.4.5 = xor i32 %xor.4.5, %conv35.4.5
  %conv37.4.5 = trunc i32 %xor36.4.5 to i8
  store i8 %conv37.4.5, i8* %scevgep41.4.4, align 1
  %scevgep28.4.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1785, i64 0, i64 0, i64 1
  %1792 = bitcast i8* %scevgep28.4.5 to [61 x [61 x i8]]*
  %scevgep41.4.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1786, i64 0, i64 1, i64 0
  %1793 = bitcast i8* %scevgep41.4.5 to [61 x [61 x i8]]*
  %call16.4.6 = call zeroext i8 (...) @rand()
  store i8 %call16.4.6, i8* %scevgep28.4.5, align 1
  %1794 = load i8, i8* %scevgep28.4.5, align 1
  %conv23.4.6 = zext i8 %1794 to i32
  %1795 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.6 = getelementptr i8, i8* %b, i64 11
  %1796 = load i8, i8* %scevgep34.4.6, align 1
  %call28.4.6 = call zeroext i8 @mult(i8 zeroext %1795, i8 zeroext %1796)
  %conv29.4.6 = zext i8 %call28.4.6 to i32
  %xor.4.6 = xor i32 %conv23.4.6, %conv29.4.6
  %scevgep35.4.6 = getelementptr i8, i8* %a, i64 11
  %1797 = load i8, i8* %scevgep35.4.6, align 1
  %1798 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.6 = call zeroext i8 @mult(i8 zeroext %1797, i8 zeroext %1798)
  %conv35.4.6 = zext i8 %call34.4.6 to i32
  %xor36.4.6 = xor i32 %xor.4.6, %conv35.4.6
  %conv37.4.6 = trunc i32 %xor36.4.6 to i8
  store i8 %conv37.4.6, i8* %scevgep41.4.5, align 1
  %scevgep28.4.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1792, i64 0, i64 0, i64 1
  %1799 = bitcast i8* %scevgep28.4.6 to [61 x [61 x i8]]*
  %scevgep41.4.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1793, i64 0, i64 1, i64 0
  %1800 = bitcast i8* %scevgep41.4.6 to [61 x [61 x i8]]*
  %call16.4.7 = call zeroext i8 (...) @rand()
  store i8 %call16.4.7, i8* %scevgep28.4.6, align 1
  %1801 = load i8, i8* %scevgep28.4.6, align 1
  %conv23.4.7 = zext i8 %1801 to i32
  %1802 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.7 = getelementptr i8, i8* %b, i64 12
  %1803 = load i8, i8* %scevgep34.4.7, align 1
  %call28.4.7 = call zeroext i8 @mult(i8 zeroext %1802, i8 zeroext %1803)
  %conv29.4.7 = zext i8 %call28.4.7 to i32
  %xor.4.7 = xor i32 %conv23.4.7, %conv29.4.7
  %scevgep35.4.7 = getelementptr i8, i8* %a, i64 12
  %1804 = load i8, i8* %scevgep35.4.7, align 1
  %1805 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.7 = call zeroext i8 @mult(i8 zeroext %1804, i8 zeroext %1805)
  %conv35.4.7 = zext i8 %call34.4.7 to i32
  %xor36.4.7 = xor i32 %xor.4.7, %conv35.4.7
  %conv37.4.7 = trunc i32 %xor36.4.7 to i8
  store i8 %conv37.4.7, i8* %scevgep41.4.6, align 1
  %scevgep28.4.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1799, i64 0, i64 0, i64 1
  %1806 = bitcast i8* %scevgep28.4.7 to [61 x [61 x i8]]*
  %scevgep41.4.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1800, i64 0, i64 1, i64 0
  %1807 = bitcast i8* %scevgep41.4.7 to [61 x [61 x i8]]*
  %call16.4.8 = call zeroext i8 (...) @rand()
  store i8 %call16.4.8, i8* %scevgep28.4.7, align 1
  %1808 = load i8, i8* %scevgep28.4.7, align 1
  %conv23.4.8 = zext i8 %1808 to i32
  %1809 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.8 = getelementptr i8, i8* %b, i64 13
  %1810 = load i8, i8* %scevgep34.4.8, align 1
  %call28.4.8 = call zeroext i8 @mult(i8 zeroext %1809, i8 zeroext %1810)
  %conv29.4.8 = zext i8 %call28.4.8 to i32
  %xor.4.8 = xor i32 %conv23.4.8, %conv29.4.8
  %scevgep35.4.8 = getelementptr i8, i8* %a, i64 13
  %1811 = load i8, i8* %scevgep35.4.8, align 1
  %1812 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.8 = call zeroext i8 @mult(i8 zeroext %1811, i8 zeroext %1812)
  %conv35.4.8 = zext i8 %call34.4.8 to i32
  %xor36.4.8 = xor i32 %xor.4.8, %conv35.4.8
  %conv37.4.8 = trunc i32 %xor36.4.8 to i8
  store i8 %conv37.4.8, i8* %scevgep41.4.7, align 1
  %scevgep28.4.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1806, i64 0, i64 0, i64 1
  %1813 = bitcast i8* %scevgep28.4.8 to [61 x [61 x i8]]*
  %scevgep41.4.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1807, i64 0, i64 1, i64 0
  %1814 = bitcast i8* %scevgep41.4.8 to [61 x [61 x i8]]*
  %call16.4.9 = call zeroext i8 (...) @rand()
  store i8 %call16.4.9, i8* %scevgep28.4.8, align 1
  %1815 = load i8, i8* %scevgep28.4.8, align 1
  %conv23.4.9 = zext i8 %1815 to i32
  %1816 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.9 = getelementptr i8, i8* %b, i64 14
  %1817 = load i8, i8* %scevgep34.4.9, align 1
  %call28.4.9 = call zeroext i8 @mult(i8 zeroext %1816, i8 zeroext %1817)
  %conv29.4.9 = zext i8 %call28.4.9 to i32
  %xor.4.9 = xor i32 %conv23.4.9, %conv29.4.9
  %scevgep35.4.9 = getelementptr i8, i8* %a, i64 14
  %1818 = load i8, i8* %scevgep35.4.9, align 1
  %1819 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.9 = call zeroext i8 @mult(i8 zeroext %1818, i8 zeroext %1819)
  %conv35.4.9 = zext i8 %call34.4.9 to i32
  %xor36.4.9 = xor i32 %xor.4.9, %conv35.4.9
  %conv37.4.9 = trunc i32 %xor36.4.9 to i8
  store i8 %conv37.4.9, i8* %scevgep41.4.8, align 1
  %scevgep28.4.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1813, i64 0, i64 0, i64 1
  %1820 = bitcast i8* %scevgep28.4.9 to [61 x [61 x i8]]*
  %scevgep41.4.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1814, i64 0, i64 1, i64 0
  %1821 = bitcast i8* %scevgep41.4.9 to [61 x [61 x i8]]*
  %call16.4.10 = call zeroext i8 (...) @rand()
  store i8 %call16.4.10, i8* %scevgep28.4.9, align 1
  %1822 = load i8, i8* %scevgep28.4.9, align 1
  %conv23.4.10 = zext i8 %1822 to i32
  %1823 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.10 = getelementptr i8, i8* %b, i64 15
  %1824 = load i8, i8* %scevgep34.4.10, align 1
  %call28.4.10 = call zeroext i8 @mult(i8 zeroext %1823, i8 zeroext %1824)
  %conv29.4.10 = zext i8 %call28.4.10 to i32
  %xor.4.10 = xor i32 %conv23.4.10, %conv29.4.10
  %scevgep35.4.10 = getelementptr i8, i8* %a, i64 15
  %1825 = load i8, i8* %scevgep35.4.10, align 1
  %1826 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.10 = call zeroext i8 @mult(i8 zeroext %1825, i8 zeroext %1826)
  %conv35.4.10 = zext i8 %call34.4.10 to i32
  %xor36.4.10 = xor i32 %xor.4.10, %conv35.4.10
  %conv37.4.10 = trunc i32 %xor36.4.10 to i8
  store i8 %conv37.4.10, i8* %scevgep41.4.9, align 1
  %scevgep28.4.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1820, i64 0, i64 0, i64 1
  %1827 = bitcast i8* %scevgep28.4.10 to [61 x [61 x i8]]*
  %scevgep41.4.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1821, i64 0, i64 1, i64 0
  %1828 = bitcast i8* %scevgep41.4.10 to [61 x [61 x i8]]*
  %call16.4.11 = call zeroext i8 (...) @rand()
  store i8 %call16.4.11, i8* %scevgep28.4.10, align 1
  %1829 = load i8, i8* %scevgep28.4.10, align 1
  %conv23.4.11 = zext i8 %1829 to i32
  %1830 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.11 = getelementptr i8, i8* %b, i64 16
  %1831 = load i8, i8* %scevgep34.4.11, align 1
  %call28.4.11 = call zeroext i8 @mult(i8 zeroext %1830, i8 zeroext %1831)
  %conv29.4.11 = zext i8 %call28.4.11 to i32
  %xor.4.11 = xor i32 %conv23.4.11, %conv29.4.11
  %scevgep35.4.11 = getelementptr i8, i8* %a, i64 16
  %1832 = load i8, i8* %scevgep35.4.11, align 1
  %1833 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.11 = call zeroext i8 @mult(i8 zeroext %1832, i8 zeroext %1833)
  %conv35.4.11 = zext i8 %call34.4.11 to i32
  %xor36.4.11 = xor i32 %xor.4.11, %conv35.4.11
  %conv37.4.11 = trunc i32 %xor36.4.11 to i8
  store i8 %conv37.4.11, i8* %scevgep41.4.10, align 1
  %scevgep28.4.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1827, i64 0, i64 0, i64 1
  %1834 = bitcast i8* %scevgep28.4.11 to [61 x [61 x i8]]*
  %scevgep41.4.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1828, i64 0, i64 1, i64 0
  %1835 = bitcast i8* %scevgep41.4.11 to [61 x [61 x i8]]*
  %call16.4.12 = call zeroext i8 (...) @rand()
  store i8 %call16.4.12, i8* %scevgep28.4.11, align 1
  %1836 = load i8, i8* %scevgep28.4.11, align 1
  %conv23.4.12 = zext i8 %1836 to i32
  %1837 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.12 = getelementptr i8, i8* %b, i64 17
  %1838 = load i8, i8* %scevgep34.4.12, align 1
  %call28.4.12 = call zeroext i8 @mult(i8 zeroext %1837, i8 zeroext %1838)
  %conv29.4.12 = zext i8 %call28.4.12 to i32
  %xor.4.12 = xor i32 %conv23.4.12, %conv29.4.12
  %scevgep35.4.12 = getelementptr i8, i8* %a, i64 17
  %1839 = load i8, i8* %scevgep35.4.12, align 1
  %1840 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.12 = call zeroext i8 @mult(i8 zeroext %1839, i8 zeroext %1840)
  %conv35.4.12 = zext i8 %call34.4.12 to i32
  %xor36.4.12 = xor i32 %xor.4.12, %conv35.4.12
  %conv37.4.12 = trunc i32 %xor36.4.12 to i8
  store i8 %conv37.4.12, i8* %scevgep41.4.11, align 1
  %scevgep28.4.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1834, i64 0, i64 0, i64 1
  %1841 = bitcast i8* %scevgep28.4.12 to [61 x [61 x i8]]*
  %scevgep41.4.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1835, i64 0, i64 1, i64 0
  %1842 = bitcast i8* %scevgep41.4.12 to [61 x [61 x i8]]*
  %call16.4.13 = call zeroext i8 (...) @rand()
  store i8 %call16.4.13, i8* %scevgep28.4.12, align 1
  %1843 = load i8, i8* %scevgep28.4.12, align 1
  %conv23.4.13 = zext i8 %1843 to i32
  %1844 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.13 = getelementptr i8, i8* %b, i64 18
  %1845 = load i8, i8* %scevgep34.4.13, align 1
  %call28.4.13 = call zeroext i8 @mult(i8 zeroext %1844, i8 zeroext %1845)
  %conv29.4.13 = zext i8 %call28.4.13 to i32
  %xor.4.13 = xor i32 %conv23.4.13, %conv29.4.13
  %scevgep35.4.13 = getelementptr i8, i8* %a, i64 18
  %1846 = load i8, i8* %scevgep35.4.13, align 1
  %1847 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.13 = call zeroext i8 @mult(i8 zeroext %1846, i8 zeroext %1847)
  %conv35.4.13 = zext i8 %call34.4.13 to i32
  %xor36.4.13 = xor i32 %xor.4.13, %conv35.4.13
  %conv37.4.13 = trunc i32 %xor36.4.13 to i8
  store i8 %conv37.4.13, i8* %scevgep41.4.12, align 1
  %scevgep28.4.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1841, i64 0, i64 0, i64 1
  %1848 = bitcast i8* %scevgep28.4.13 to [61 x [61 x i8]]*
  %scevgep41.4.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1842, i64 0, i64 1, i64 0
  %1849 = bitcast i8* %scevgep41.4.13 to [61 x [61 x i8]]*
  %call16.4.14 = call zeroext i8 (...) @rand()
  store i8 %call16.4.14, i8* %scevgep28.4.13, align 1
  %1850 = load i8, i8* %scevgep28.4.13, align 1
  %conv23.4.14 = zext i8 %1850 to i32
  %1851 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.14 = getelementptr i8, i8* %b, i64 19
  %1852 = load i8, i8* %scevgep34.4.14, align 1
  %call28.4.14 = call zeroext i8 @mult(i8 zeroext %1851, i8 zeroext %1852)
  %conv29.4.14 = zext i8 %call28.4.14 to i32
  %xor.4.14 = xor i32 %conv23.4.14, %conv29.4.14
  %scevgep35.4.14 = getelementptr i8, i8* %a, i64 19
  %1853 = load i8, i8* %scevgep35.4.14, align 1
  %1854 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.14 = call zeroext i8 @mult(i8 zeroext %1853, i8 zeroext %1854)
  %conv35.4.14 = zext i8 %call34.4.14 to i32
  %xor36.4.14 = xor i32 %xor.4.14, %conv35.4.14
  %conv37.4.14 = trunc i32 %xor36.4.14 to i8
  store i8 %conv37.4.14, i8* %scevgep41.4.13, align 1
  %scevgep28.4.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1848, i64 0, i64 0, i64 1
  %1855 = bitcast i8* %scevgep28.4.14 to [61 x [61 x i8]]*
  %scevgep41.4.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1849, i64 0, i64 1, i64 0
  %1856 = bitcast i8* %scevgep41.4.14 to [61 x [61 x i8]]*
  %call16.4.15 = call zeroext i8 (...) @rand()
  store i8 %call16.4.15, i8* %scevgep28.4.14, align 1
  %1857 = load i8, i8* %scevgep28.4.14, align 1
  %conv23.4.15 = zext i8 %1857 to i32
  %1858 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.15 = getelementptr i8, i8* %b, i64 20
  %1859 = load i8, i8* %scevgep34.4.15, align 1
  %call28.4.15 = call zeroext i8 @mult(i8 zeroext %1858, i8 zeroext %1859)
  %conv29.4.15 = zext i8 %call28.4.15 to i32
  %xor.4.15 = xor i32 %conv23.4.15, %conv29.4.15
  %scevgep35.4.15 = getelementptr i8, i8* %a, i64 20
  %1860 = load i8, i8* %scevgep35.4.15, align 1
  %1861 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.15 = call zeroext i8 @mult(i8 zeroext %1860, i8 zeroext %1861)
  %conv35.4.15 = zext i8 %call34.4.15 to i32
  %xor36.4.15 = xor i32 %xor.4.15, %conv35.4.15
  %conv37.4.15 = trunc i32 %xor36.4.15 to i8
  store i8 %conv37.4.15, i8* %scevgep41.4.14, align 1
  %scevgep28.4.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1855, i64 0, i64 0, i64 1
  %1862 = bitcast i8* %scevgep28.4.15 to [61 x [61 x i8]]*
  %scevgep41.4.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1856, i64 0, i64 1, i64 0
  %1863 = bitcast i8* %scevgep41.4.15 to [61 x [61 x i8]]*
  %call16.4.16 = call zeroext i8 (...) @rand()
  store i8 %call16.4.16, i8* %scevgep28.4.15, align 1
  %1864 = load i8, i8* %scevgep28.4.15, align 1
  %conv23.4.16 = zext i8 %1864 to i32
  %1865 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.16 = getelementptr i8, i8* %b, i64 21
  %1866 = load i8, i8* %scevgep34.4.16, align 1
  %call28.4.16 = call zeroext i8 @mult(i8 zeroext %1865, i8 zeroext %1866)
  %conv29.4.16 = zext i8 %call28.4.16 to i32
  %xor.4.16 = xor i32 %conv23.4.16, %conv29.4.16
  %scevgep35.4.16 = getelementptr i8, i8* %a, i64 21
  %1867 = load i8, i8* %scevgep35.4.16, align 1
  %1868 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.16 = call zeroext i8 @mult(i8 zeroext %1867, i8 zeroext %1868)
  %conv35.4.16 = zext i8 %call34.4.16 to i32
  %xor36.4.16 = xor i32 %xor.4.16, %conv35.4.16
  %conv37.4.16 = trunc i32 %xor36.4.16 to i8
  store i8 %conv37.4.16, i8* %scevgep41.4.15, align 1
  %scevgep28.4.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1862, i64 0, i64 0, i64 1
  %1869 = bitcast i8* %scevgep28.4.16 to [61 x [61 x i8]]*
  %scevgep41.4.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1863, i64 0, i64 1, i64 0
  %1870 = bitcast i8* %scevgep41.4.16 to [61 x [61 x i8]]*
  %call16.4.17 = call zeroext i8 (...) @rand()
  store i8 %call16.4.17, i8* %scevgep28.4.16, align 1
  %1871 = load i8, i8* %scevgep28.4.16, align 1
  %conv23.4.17 = zext i8 %1871 to i32
  %1872 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.17 = getelementptr i8, i8* %b, i64 22
  %1873 = load i8, i8* %scevgep34.4.17, align 1
  %call28.4.17 = call zeroext i8 @mult(i8 zeroext %1872, i8 zeroext %1873)
  %conv29.4.17 = zext i8 %call28.4.17 to i32
  %xor.4.17 = xor i32 %conv23.4.17, %conv29.4.17
  %scevgep35.4.17 = getelementptr i8, i8* %a, i64 22
  %1874 = load i8, i8* %scevgep35.4.17, align 1
  %1875 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.17 = call zeroext i8 @mult(i8 zeroext %1874, i8 zeroext %1875)
  %conv35.4.17 = zext i8 %call34.4.17 to i32
  %xor36.4.17 = xor i32 %xor.4.17, %conv35.4.17
  %conv37.4.17 = trunc i32 %xor36.4.17 to i8
  store i8 %conv37.4.17, i8* %scevgep41.4.16, align 1
  %scevgep28.4.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1869, i64 0, i64 0, i64 1
  %1876 = bitcast i8* %scevgep28.4.17 to [61 x [61 x i8]]*
  %scevgep41.4.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1870, i64 0, i64 1, i64 0
  %1877 = bitcast i8* %scevgep41.4.17 to [61 x [61 x i8]]*
  %call16.4.18 = call zeroext i8 (...) @rand()
  store i8 %call16.4.18, i8* %scevgep28.4.17, align 1
  %1878 = load i8, i8* %scevgep28.4.17, align 1
  %conv23.4.18 = zext i8 %1878 to i32
  %1879 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.18 = getelementptr i8, i8* %b, i64 23
  %1880 = load i8, i8* %scevgep34.4.18, align 1
  %call28.4.18 = call zeroext i8 @mult(i8 zeroext %1879, i8 zeroext %1880)
  %conv29.4.18 = zext i8 %call28.4.18 to i32
  %xor.4.18 = xor i32 %conv23.4.18, %conv29.4.18
  %scevgep35.4.18 = getelementptr i8, i8* %a, i64 23
  %1881 = load i8, i8* %scevgep35.4.18, align 1
  %1882 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.18 = call zeroext i8 @mult(i8 zeroext %1881, i8 zeroext %1882)
  %conv35.4.18 = zext i8 %call34.4.18 to i32
  %xor36.4.18 = xor i32 %xor.4.18, %conv35.4.18
  %conv37.4.18 = trunc i32 %xor36.4.18 to i8
  store i8 %conv37.4.18, i8* %scevgep41.4.17, align 1
  %scevgep28.4.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1876, i64 0, i64 0, i64 1
  %1883 = bitcast i8* %scevgep28.4.18 to [61 x [61 x i8]]*
  %scevgep41.4.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1877, i64 0, i64 1, i64 0
  %1884 = bitcast i8* %scevgep41.4.18 to [61 x [61 x i8]]*
  %call16.4.19 = call zeroext i8 (...) @rand()
  store i8 %call16.4.19, i8* %scevgep28.4.18, align 1
  %1885 = load i8, i8* %scevgep28.4.18, align 1
  %conv23.4.19 = zext i8 %1885 to i32
  %1886 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.19 = getelementptr i8, i8* %b, i64 24
  %1887 = load i8, i8* %scevgep34.4.19, align 1
  %call28.4.19 = call zeroext i8 @mult(i8 zeroext %1886, i8 zeroext %1887)
  %conv29.4.19 = zext i8 %call28.4.19 to i32
  %xor.4.19 = xor i32 %conv23.4.19, %conv29.4.19
  %scevgep35.4.19 = getelementptr i8, i8* %a, i64 24
  %1888 = load i8, i8* %scevgep35.4.19, align 1
  %1889 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.19 = call zeroext i8 @mult(i8 zeroext %1888, i8 zeroext %1889)
  %conv35.4.19 = zext i8 %call34.4.19 to i32
  %xor36.4.19 = xor i32 %xor.4.19, %conv35.4.19
  %conv37.4.19 = trunc i32 %xor36.4.19 to i8
  store i8 %conv37.4.19, i8* %scevgep41.4.18, align 1
  %scevgep28.4.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1883, i64 0, i64 0, i64 1
  %1890 = bitcast i8* %scevgep28.4.19 to [61 x [61 x i8]]*
  %scevgep41.4.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1884, i64 0, i64 1, i64 0
  %1891 = bitcast i8* %scevgep41.4.19 to [61 x [61 x i8]]*
  %call16.4.20 = call zeroext i8 (...) @rand()
  store i8 %call16.4.20, i8* %scevgep28.4.19, align 1
  %1892 = load i8, i8* %scevgep28.4.19, align 1
  %conv23.4.20 = zext i8 %1892 to i32
  %1893 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.20 = getelementptr i8, i8* %b, i64 25
  %1894 = load i8, i8* %scevgep34.4.20, align 1
  %call28.4.20 = call zeroext i8 @mult(i8 zeroext %1893, i8 zeroext %1894)
  %conv29.4.20 = zext i8 %call28.4.20 to i32
  %xor.4.20 = xor i32 %conv23.4.20, %conv29.4.20
  %scevgep35.4.20 = getelementptr i8, i8* %a, i64 25
  %1895 = load i8, i8* %scevgep35.4.20, align 1
  %1896 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.20 = call zeroext i8 @mult(i8 zeroext %1895, i8 zeroext %1896)
  %conv35.4.20 = zext i8 %call34.4.20 to i32
  %xor36.4.20 = xor i32 %xor.4.20, %conv35.4.20
  %conv37.4.20 = trunc i32 %xor36.4.20 to i8
  store i8 %conv37.4.20, i8* %scevgep41.4.19, align 1
  %scevgep28.4.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1890, i64 0, i64 0, i64 1
  %1897 = bitcast i8* %scevgep28.4.20 to [61 x [61 x i8]]*
  %scevgep41.4.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1891, i64 0, i64 1, i64 0
  %1898 = bitcast i8* %scevgep41.4.20 to [61 x [61 x i8]]*
  %call16.4.21 = call zeroext i8 (...) @rand()
  store i8 %call16.4.21, i8* %scevgep28.4.20, align 1
  %1899 = load i8, i8* %scevgep28.4.20, align 1
  %conv23.4.21 = zext i8 %1899 to i32
  %1900 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.21 = getelementptr i8, i8* %b, i64 26
  %1901 = load i8, i8* %scevgep34.4.21, align 1
  %call28.4.21 = call zeroext i8 @mult(i8 zeroext %1900, i8 zeroext %1901)
  %conv29.4.21 = zext i8 %call28.4.21 to i32
  %xor.4.21 = xor i32 %conv23.4.21, %conv29.4.21
  %scevgep35.4.21 = getelementptr i8, i8* %a, i64 26
  %1902 = load i8, i8* %scevgep35.4.21, align 1
  %1903 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.21 = call zeroext i8 @mult(i8 zeroext %1902, i8 zeroext %1903)
  %conv35.4.21 = zext i8 %call34.4.21 to i32
  %xor36.4.21 = xor i32 %xor.4.21, %conv35.4.21
  %conv37.4.21 = trunc i32 %xor36.4.21 to i8
  store i8 %conv37.4.21, i8* %scevgep41.4.20, align 1
  %scevgep28.4.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1897, i64 0, i64 0, i64 1
  %1904 = bitcast i8* %scevgep28.4.21 to [61 x [61 x i8]]*
  %scevgep41.4.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1898, i64 0, i64 1, i64 0
  %1905 = bitcast i8* %scevgep41.4.21 to [61 x [61 x i8]]*
  %call16.4.22 = call zeroext i8 (...) @rand()
  store i8 %call16.4.22, i8* %scevgep28.4.21, align 1
  %1906 = load i8, i8* %scevgep28.4.21, align 1
  %conv23.4.22 = zext i8 %1906 to i32
  %1907 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.22 = getelementptr i8, i8* %b, i64 27
  %1908 = load i8, i8* %scevgep34.4.22, align 1
  %call28.4.22 = call zeroext i8 @mult(i8 zeroext %1907, i8 zeroext %1908)
  %conv29.4.22 = zext i8 %call28.4.22 to i32
  %xor.4.22 = xor i32 %conv23.4.22, %conv29.4.22
  %scevgep35.4.22 = getelementptr i8, i8* %a, i64 27
  %1909 = load i8, i8* %scevgep35.4.22, align 1
  %1910 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.22 = call zeroext i8 @mult(i8 zeroext %1909, i8 zeroext %1910)
  %conv35.4.22 = zext i8 %call34.4.22 to i32
  %xor36.4.22 = xor i32 %xor.4.22, %conv35.4.22
  %conv37.4.22 = trunc i32 %xor36.4.22 to i8
  store i8 %conv37.4.22, i8* %scevgep41.4.21, align 1
  %scevgep28.4.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1904, i64 0, i64 0, i64 1
  %1911 = bitcast i8* %scevgep28.4.22 to [61 x [61 x i8]]*
  %scevgep41.4.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1905, i64 0, i64 1, i64 0
  %1912 = bitcast i8* %scevgep41.4.22 to [61 x [61 x i8]]*
  %call16.4.23 = call zeroext i8 (...) @rand()
  store i8 %call16.4.23, i8* %scevgep28.4.22, align 1
  %1913 = load i8, i8* %scevgep28.4.22, align 1
  %conv23.4.23 = zext i8 %1913 to i32
  %1914 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.23 = getelementptr i8, i8* %b, i64 28
  %1915 = load i8, i8* %scevgep34.4.23, align 1
  %call28.4.23 = call zeroext i8 @mult(i8 zeroext %1914, i8 zeroext %1915)
  %conv29.4.23 = zext i8 %call28.4.23 to i32
  %xor.4.23 = xor i32 %conv23.4.23, %conv29.4.23
  %scevgep35.4.23 = getelementptr i8, i8* %a, i64 28
  %1916 = load i8, i8* %scevgep35.4.23, align 1
  %1917 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.23 = call zeroext i8 @mult(i8 zeroext %1916, i8 zeroext %1917)
  %conv35.4.23 = zext i8 %call34.4.23 to i32
  %xor36.4.23 = xor i32 %xor.4.23, %conv35.4.23
  %conv37.4.23 = trunc i32 %xor36.4.23 to i8
  store i8 %conv37.4.23, i8* %scevgep41.4.22, align 1
  %scevgep28.4.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1911, i64 0, i64 0, i64 1
  %1918 = bitcast i8* %scevgep28.4.23 to [61 x [61 x i8]]*
  %scevgep41.4.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1912, i64 0, i64 1, i64 0
  %1919 = bitcast i8* %scevgep41.4.23 to [61 x [61 x i8]]*
  %call16.4.24 = call zeroext i8 (...) @rand()
  store i8 %call16.4.24, i8* %scevgep28.4.23, align 1
  %1920 = load i8, i8* %scevgep28.4.23, align 1
  %conv23.4.24 = zext i8 %1920 to i32
  %1921 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.24 = getelementptr i8, i8* %b, i64 29
  %1922 = load i8, i8* %scevgep34.4.24, align 1
  %call28.4.24 = call zeroext i8 @mult(i8 zeroext %1921, i8 zeroext %1922)
  %conv29.4.24 = zext i8 %call28.4.24 to i32
  %xor.4.24 = xor i32 %conv23.4.24, %conv29.4.24
  %scevgep35.4.24 = getelementptr i8, i8* %a, i64 29
  %1923 = load i8, i8* %scevgep35.4.24, align 1
  %1924 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.24 = call zeroext i8 @mult(i8 zeroext %1923, i8 zeroext %1924)
  %conv35.4.24 = zext i8 %call34.4.24 to i32
  %xor36.4.24 = xor i32 %xor.4.24, %conv35.4.24
  %conv37.4.24 = trunc i32 %xor36.4.24 to i8
  store i8 %conv37.4.24, i8* %scevgep41.4.23, align 1
  %scevgep28.4.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1918, i64 0, i64 0, i64 1
  %1925 = bitcast i8* %scevgep28.4.24 to [61 x [61 x i8]]*
  %scevgep41.4.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1919, i64 0, i64 1, i64 0
  %1926 = bitcast i8* %scevgep41.4.24 to [61 x [61 x i8]]*
  %call16.4.25 = call zeroext i8 (...) @rand()
  store i8 %call16.4.25, i8* %scevgep28.4.24, align 1
  %1927 = load i8, i8* %scevgep28.4.24, align 1
  %conv23.4.25 = zext i8 %1927 to i32
  %1928 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.25 = getelementptr i8, i8* %b, i64 30
  %1929 = load i8, i8* %scevgep34.4.25, align 1
  %call28.4.25 = call zeroext i8 @mult(i8 zeroext %1928, i8 zeroext %1929)
  %conv29.4.25 = zext i8 %call28.4.25 to i32
  %xor.4.25 = xor i32 %conv23.4.25, %conv29.4.25
  %scevgep35.4.25 = getelementptr i8, i8* %a, i64 30
  %1930 = load i8, i8* %scevgep35.4.25, align 1
  %1931 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.25 = call zeroext i8 @mult(i8 zeroext %1930, i8 zeroext %1931)
  %conv35.4.25 = zext i8 %call34.4.25 to i32
  %xor36.4.25 = xor i32 %xor.4.25, %conv35.4.25
  %conv37.4.25 = trunc i32 %xor36.4.25 to i8
  store i8 %conv37.4.25, i8* %scevgep41.4.24, align 1
  %scevgep28.4.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1925, i64 0, i64 0, i64 1
  %1932 = bitcast i8* %scevgep28.4.25 to [61 x [61 x i8]]*
  %scevgep41.4.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1926, i64 0, i64 1, i64 0
  %1933 = bitcast i8* %scevgep41.4.25 to [61 x [61 x i8]]*
  %call16.4.26 = call zeroext i8 (...) @rand()
  store i8 %call16.4.26, i8* %scevgep28.4.25, align 1
  %1934 = load i8, i8* %scevgep28.4.25, align 1
  %conv23.4.26 = zext i8 %1934 to i32
  %1935 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.26 = getelementptr i8, i8* %b, i64 31
  %1936 = load i8, i8* %scevgep34.4.26, align 1
  %call28.4.26 = call zeroext i8 @mult(i8 zeroext %1935, i8 zeroext %1936)
  %conv29.4.26 = zext i8 %call28.4.26 to i32
  %xor.4.26 = xor i32 %conv23.4.26, %conv29.4.26
  %scevgep35.4.26 = getelementptr i8, i8* %a, i64 31
  %1937 = load i8, i8* %scevgep35.4.26, align 1
  %1938 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.26 = call zeroext i8 @mult(i8 zeroext %1937, i8 zeroext %1938)
  %conv35.4.26 = zext i8 %call34.4.26 to i32
  %xor36.4.26 = xor i32 %xor.4.26, %conv35.4.26
  %conv37.4.26 = trunc i32 %xor36.4.26 to i8
  store i8 %conv37.4.26, i8* %scevgep41.4.25, align 1
  %scevgep28.4.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1932, i64 0, i64 0, i64 1
  %1939 = bitcast i8* %scevgep28.4.26 to [61 x [61 x i8]]*
  %scevgep41.4.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1933, i64 0, i64 1, i64 0
  %1940 = bitcast i8* %scevgep41.4.26 to [61 x [61 x i8]]*
  %call16.4.27 = call zeroext i8 (...) @rand()
  store i8 %call16.4.27, i8* %scevgep28.4.26, align 1
  %1941 = load i8, i8* %scevgep28.4.26, align 1
  %conv23.4.27 = zext i8 %1941 to i32
  %1942 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.27 = getelementptr i8, i8* %b, i64 32
  %1943 = load i8, i8* %scevgep34.4.27, align 1
  %call28.4.27 = call zeroext i8 @mult(i8 zeroext %1942, i8 zeroext %1943)
  %conv29.4.27 = zext i8 %call28.4.27 to i32
  %xor.4.27 = xor i32 %conv23.4.27, %conv29.4.27
  %scevgep35.4.27 = getelementptr i8, i8* %a, i64 32
  %1944 = load i8, i8* %scevgep35.4.27, align 1
  %1945 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.27 = call zeroext i8 @mult(i8 zeroext %1944, i8 zeroext %1945)
  %conv35.4.27 = zext i8 %call34.4.27 to i32
  %xor36.4.27 = xor i32 %xor.4.27, %conv35.4.27
  %conv37.4.27 = trunc i32 %xor36.4.27 to i8
  store i8 %conv37.4.27, i8* %scevgep41.4.26, align 1
  %scevgep28.4.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1939, i64 0, i64 0, i64 1
  %1946 = bitcast i8* %scevgep28.4.27 to [61 x [61 x i8]]*
  %scevgep41.4.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1940, i64 0, i64 1, i64 0
  %1947 = bitcast i8* %scevgep41.4.27 to [61 x [61 x i8]]*
  %call16.4.28 = call zeroext i8 (...) @rand()
  store i8 %call16.4.28, i8* %scevgep28.4.27, align 1
  %1948 = load i8, i8* %scevgep28.4.27, align 1
  %conv23.4.28 = zext i8 %1948 to i32
  %1949 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.28 = getelementptr i8, i8* %b, i64 33
  %1950 = load i8, i8* %scevgep34.4.28, align 1
  %call28.4.28 = call zeroext i8 @mult(i8 zeroext %1949, i8 zeroext %1950)
  %conv29.4.28 = zext i8 %call28.4.28 to i32
  %xor.4.28 = xor i32 %conv23.4.28, %conv29.4.28
  %scevgep35.4.28 = getelementptr i8, i8* %a, i64 33
  %1951 = load i8, i8* %scevgep35.4.28, align 1
  %1952 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.28 = call zeroext i8 @mult(i8 zeroext %1951, i8 zeroext %1952)
  %conv35.4.28 = zext i8 %call34.4.28 to i32
  %xor36.4.28 = xor i32 %xor.4.28, %conv35.4.28
  %conv37.4.28 = trunc i32 %xor36.4.28 to i8
  store i8 %conv37.4.28, i8* %scevgep41.4.27, align 1
  %scevgep28.4.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1946, i64 0, i64 0, i64 1
  %1953 = bitcast i8* %scevgep28.4.28 to [61 x [61 x i8]]*
  %scevgep41.4.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1947, i64 0, i64 1, i64 0
  %1954 = bitcast i8* %scevgep41.4.28 to [61 x [61 x i8]]*
  %call16.4.29 = call zeroext i8 (...) @rand()
  store i8 %call16.4.29, i8* %scevgep28.4.28, align 1
  %1955 = load i8, i8* %scevgep28.4.28, align 1
  %conv23.4.29 = zext i8 %1955 to i32
  %1956 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.29 = getelementptr i8, i8* %b, i64 34
  %1957 = load i8, i8* %scevgep34.4.29, align 1
  %call28.4.29 = call zeroext i8 @mult(i8 zeroext %1956, i8 zeroext %1957)
  %conv29.4.29 = zext i8 %call28.4.29 to i32
  %xor.4.29 = xor i32 %conv23.4.29, %conv29.4.29
  %scevgep35.4.29 = getelementptr i8, i8* %a, i64 34
  %1958 = load i8, i8* %scevgep35.4.29, align 1
  %1959 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.29 = call zeroext i8 @mult(i8 zeroext %1958, i8 zeroext %1959)
  %conv35.4.29 = zext i8 %call34.4.29 to i32
  %xor36.4.29 = xor i32 %xor.4.29, %conv35.4.29
  %conv37.4.29 = trunc i32 %xor36.4.29 to i8
  store i8 %conv37.4.29, i8* %scevgep41.4.28, align 1
  %scevgep28.4.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1953, i64 0, i64 0, i64 1
  %1960 = bitcast i8* %scevgep28.4.29 to [61 x [61 x i8]]*
  %scevgep41.4.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1954, i64 0, i64 1, i64 0
  %1961 = bitcast i8* %scevgep41.4.29 to [61 x [61 x i8]]*
  %call16.4.30 = call zeroext i8 (...) @rand()
  store i8 %call16.4.30, i8* %scevgep28.4.29, align 1
  %1962 = load i8, i8* %scevgep28.4.29, align 1
  %conv23.4.30 = zext i8 %1962 to i32
  %1963 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.30 = getelementptr i8, i8* %b, i64 35
  %1964 = load i8, i8* %scevgep34.4.30, align 1
  %call28.4.30 = call zeroext i8 @mult(i8 zeroext %1963, i8 zeroext %1964)
  %conv29.4.30 = zext i8 %call28.4.30 to i32
  %xor.4.30 = xor i32 %conv23.4.30, %conv29.4.30
  %scevgep35.4.30 = getelementptr i8, i8* %a, i64 35
  %1965 = load i8, i8* %scevgep35.4.30, align 1
  %1966 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.30 = call zeroext i8 @mult(i8 zeroext %1965, i8 zeroext %1966)
  %conv35.4.30 = zext i8 %call34.4.30 to i32
  %xor36.4.30 = xor i32 %xor.4.30, %conv35.4.30
  %conv37.4.30 = trunc i32 %xor36.4.30 to i8
  store i8 %conv37.4.30, i8* %scevgep41.4.29, align 1
  %scevgep28.4.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1960, i64 0, i64 0, i64 1
  %1967 = bitcast i8* %scevgep28.4.30 to [61 x [61 x i8]]*
  %scevgep41.4.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1961, i64 0, i64 1, i64 0
  %1968 = bitcast i8* %scevgep41.4.30 to [61 x [61 x i8]]*
  %call16.4.31 = call zeroext i8 (...) @rand()
  store i8 %call16.4.31, i8* %scevgep28.4.30, align 1
  %1969 = load i8, i8* %scevgep28.4.30, align 1
  %conv23.4.31 = zext i8 %1969 to i32
  %1970 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.31 = getelementptr i8, i8* %b, i64 36
  %1971 = load i8, i8* %scevgep34.4.31, align 1
  %call28.4.31 = call zeroext i8 @mult(i8 zeroext %1970, i8 zeroext %1971)
  %conv29.4.31 = zext i8 %call28.4.31 to i32
  %xor.4.31 = xor i32 %conv23.4.31, %conv29.4.31
  %scevgep35.4.31 = getelementptr i8, i8* %a, i64 36
  %1972 = load i8, i8* %scevgep35.4.31, align 1
  %1973 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.31 = call zeroext i8 @mult(i8 zeroext %1972, i8 zeroext %1973)
  %conv35.4.31 = zext i8 %call34.4.31 to i32
  %xor36.4.31 = xor i32 %xor.4.31, %conv35.4.31
  %conv37.4.31 = trunc i32 %xor36.4.31 to i8
  store i8 %conv37.4.31, i8* %scevgep41.4.30, align 1
  %scevgep28.4.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1967, i64 0, i64 0, i64 1
  %1974 = bitcast i8* %scevgep28.4.31 to [61 x [61 x i8]]*
  %scevgep41.4.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1968, i64 0, i64 1, i64 0
  %1975 = bitcast i8* %scevgep41.4.31 to [61 x [61 x i8]]*
  %call16.4.32 = call zeroext i8 (...) @rand()
  store i8 %call16.4.32, i8* %scevgep28.4.31, align 1
  %1976 = load i8, i8* %scevgep28.4.31, align 1
  %conv23.4.32 = zext i8 %1976 to i32
  %1977 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.32 = getelementptr i8, i8* %b, i64 37
  %1978 = load i8, i8* %scevgep34.4.32, align 1
  %call28.4.32 = call zeroext i8 @mult(i8 zeroext %1977, i8 zeroext %1978)
  %conv29.4.32 = zext i8 %call28.4.32 to i32
  %xor.4.32 = xor i32 %conv23.4.32, %conv29.4.32
  %scevgep35.4.32 = getelementptr i8, i8* %a, i64 37
  %1979 = load i8, i8* %scevgep35.4.32, align 1
  %1980 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.32 = call zeroext i8 @mult(i8 zeroext %1979, i8 zeroext %1980)
  %conv35.4.32 = zext i8 %call34.4.32 to i32
  %xor36.4.32 = xor i32 %xor.4.32, %conv35.4.32
  %conv37.4.32 = trunc i32 %xor36.4.32 to i8
  store i8 %conv37.4.32, i8* %scevgep41.4.31, align 1
  %scevgep28.4.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1974, i64 0, i64 0, i64 1
  %1981 = bitcast i8* %scevgep28.4.32 to [61 x [61 x i8]]*
  %scevgep41.4.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1975, i64 0, i64 1, i64 0
  %1982 = bitcast i8* %scevgep41.4.32 to [61 x [61 x i8]]*
  %call16.4.33 = call zeroext i8 (...) @rand()
  store i8 %call16.4.33, i8* %scevgep28.4.32, align 1
  %1983 = load i8, i8* %scevgep28.4.32, align 1
  %conv23.4.33 = zext i8 %1983 to i32
  %1984 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.33 = getelementptr i8, i8* %b, i64 38
  %1985 = load i8, i8* %scevgep34.4.33, align 1
  %call28.4.33 = call zeroext i8 @mult(i8 zeroext %1984, i8 zeroext %1985)
  %conv29.4.33 = zext i8 %call28.4.33 to i32
  %xor.4.33 = xor i32 %conv23.4.33, %conv29.4.33
  %scevgep35.4.33 = getelementptr i8, i8* %a, i64 38
  %1986 = load i8, i8* %scevgep35.4.33, align 1
  %1987 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.33 = call zeroext i8 @mult(i8 zeroext %1986, i8 zeroext %1987)
  %conv35.4.33 = zext i8 %call34.4.33 to i32
  %xor36.4.33 = xor i32 %xor.4.33, %conv35.4.33
  %conv37.4.33 = trunc i32 %xor36.4.33 to i8
  store i8 %conv37.4.33, i8* %scevgep41.4.32, align 1
  %scevgep28.4.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1981, i64 0, i64 0, i64 1
  %1988 = bitcast i8* %scevgep28.4.33 to [61 x [61 x i8]]*
  %scevgep41.4.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1982, i64 0, i64 1, i64 0
  %1989 = bitcast i8* %scevgep41.4.33 to [61 x [61 x i8]]*
  %call16.4.34 = call zeroext i8 (...) @rand()
  store i8 %call16.4.34, i8* %scevgep28.4.33, align 1
  %1990 = load i8, i8* %scevgep28.4.33, align 1
  %conv23.4.34 = zext i8 %1990 to i32
  %1991 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.34 = getelementptr i8, i8* %b, i64 39
  %1992 = load i8, i8* %scevgep34.4.34, align 1
  %call28.4.34 = call zeroext i8 @mult(i8 zeroext %1991, i8 zeroext %1992)
  %conv29.4.34 = zext i8 %call28.4.34 to i32
  %xor.4.34 = xor i32 %conv23.4.34, %conv29.4.34
  %scevgep35.4.34 = getelementptr i8, i8* %a, i64 39
  %1993 = load i8, i8* %scevgep35.4.34, align 1
  %1994 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.34 = call zeroext i8 @mult(i8 zeroext %1993, i8 zeroext %1994)
  %conv35.4.34 = zext i8 %call34.4.34 to i32
  %xor36.4.34 = xor i32 %xor.4.34, %conv35.4.34
  %conv37.4.34 = trunc i32 %xor36.4.34 to i8
  store i8 %conv37.4.34, i8* %scevgep41.4.33, align 1
  %scevgep28.4.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1988, i64 0, i64 0, i64 1
  %1995 = bitcast i8* %scevgep28.4.34 to [61 x [61 x i8]]*
  %scevgep41.4.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1989, i64 0, i64 1, i64 0
  %1996 = bitcast i8* %scevgep41.4.34 to [61 x [61 x i8]]*
  %call16.4.35 = call zeroext i8 (...) @rand()
  store i8 %call16.4.35, i8* %scevgep28.4.34, align 1
  %1997 = load i8, i8* %scevgep28.4.34, align 1
  %conv23.4.35 = zext i8 %1997 to i32
  %1998 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.35 = getelementptr i8, i8* %b, i64 40
  %1999 = load i8, i8* %scevgep34.4.35, align 1
  %call28.4.35 = call zeroext i8 @mult(i8 zeroext %1998, i8 zeroext %1999)
  %conv29.4.35 = zext i8 %call28.4.35 to i32
  %xor.4.35 = xor i32 %conv23.4.35, %conv29.4.35
  %scevgep35.4.35 = getelementptr i8, i8* %a, i64 40
  %2000 = load i8, i8* %scevgep35.4.35, align 1
  %2001 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.35 = call zeroext i8 @mult(i8 zeroext %2000, i8 zeroext %2001)
  %conv35.4.35 = zext i8 %call34.4.35 to i32
  %xor36.4.35 = xor i32 %xor.4.35, %conv35.4.35
  %conv37.4.35 = trunc i32 %xor36.4.35 to i8
  store i8 %conv37.4.35, i8* %scevgep41.4.34, align 1
  %scevgep28.4.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1995, i64 0, i64 0, i64 1
  %2002 = bitcast i8* %scevgep28.4.35 to [61 x [61 x i8]]*
  %scevgep41.4.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1996, i64 0, i64 1, i64 0
  %2003 = bitcast i8* %scevgep41.4.35 to [61 x [61 x i8]]*
  %call16.4.36 = call zeroext i8 (...) @rand()
  store i8 %call16.4.36, i8* %scevgep28.4.35, align 1
  %2004 = load i8, i8* %scevgep28.4.35, align 1
  %conv23.4.36 = zext i8 %2004 to i32
  %2005 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.36 = getelementptr i8, i8* %b, i64 41
  %2006 = load i8, i8* %scevgep34.4.36, align 1
  %call28.4.36 = call zeroext i8 @mult(i8 zeroext %2005, i8 zeroext %2006)
  %conv29.4.36 = zext i8 %call28.4.36 to i32
  %xor.4.36 = xor i32 %conv23.4.36, %conv29.4.36
  %scevgep35.4.36 = getelementptr i8, i8* %a, i64 41
  %2007 = load i8, i8* %scevgep35.4.36, align 1
  %2008 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.36 = call zeroext i8 @mult(i8 zeroext %2007, i8 zeroext %2008)
  %conv35.4.36 = zext i8 %call34.4.36 to i32
  %xor36.4.36 = xor i32 %xor.4.36, %conv35.4.36
  %conv37.4.36 = trunc i32 %xor36.4.36 to i8
  store i8 %conv37.4.36, i8* %scevgep41.4.35, align 1
  %scevgep28.4.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2002, i64 0, i64 0, i64 1
  %2009 = bitcast i8* %scevgep28.4.36 to [61 x [61 x i8]]*
  %scevgep41.4.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2003, i64 0, i64 1, i64 0
  %2010 = bitcast i8* %scevgep41.4.36 to [61 x [61 x i8]]*
  %call16.4.37 = call zeroext i8 (...) @rand()
  store i8 %call16.4.37, i8* %scevgep28.4.36, align 1
  %2011 = load i8, i8* %scevgep28.4.36, align 1
  %conv23.4.37 = zext i8 %2011 to i32
  %2012 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.37 = getelementptr i8, i8* %b, i64 42
  %2013 = load i8, i8* %scevgep34.4.37, align 1
  %call28.4.37 = call zeroext i8 @mult(i8 zeroext %2012, i8 zeroext %2013)
  %conv29.4.37 = zext i8 %call28.4.37 to i32
  %xor.4.37 = xor i32 %conv23.4.37, %conv29.4.37
  %scevgep35.4.37 = getelementptr i8, i8* %a, i64 42
  %2014 = load i8, i8* %scevgep35.4.37, align 1
  %2015 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.37 = call zeroext i8 @mult(i8 zeroext %2014, i8 zeroext %2015)
  %conv35.4.37 = zext i8 %call34.4.37 to i32
  %xor36.4.37 = xor i32 %xor.4.37, %conv35.4.37
  %conv37.4.37 = trunc i32 %xor36.4.37 to i8
  store i8 %conv37.4.37, i8* %scevgep41.4.36, align 1
  %scevgep28.4.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2009, i64 0, i64 0, i64 1
  %2016 = bitcast i8* %scevgep28.4.37 to [61 x [61 x i8]]*
  %scevgep41.4.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2010, i64 0, i64 1, i64 0
  %2017 = bitcast i8* %scevgep41.4.37 to [61 x [61 x i8]]*
  %call16.4.38 = call zeroext i8 (...) @rand()
  store i8 %call16.4.38, i8* %scevgep28.4.37, align 1
  %2018 = load i8, i8* %scevgep28.4.37, align 1
  %conv23.4.38 = zext i8 %2018 to i32
  %2019 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.38 = getelementptr i8, i8* %b, i64 43
  %2020 = load i8, i8* %scevgep34.4.38, align 1
  %call28.4.38 = call zeroext i8 @mult(i8 zeroext %2019, i8 zeroext %2020)
  %conv29.4.38 = zext i8 %call28.4.38 to i32
  %xor.4.38 = xor i32 %conv23.4.38, %conv29.4.38
  %scevgep35.4.38 = getelementptr i8, i8* %a, i64 43
  %2021 = load i8, i8* %scevgep35.4.38, align 1
  %2022 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.38 = call zeroext i8 @mult(i8 zeroext %2021, i8 zeroext %2022)
  %conv35.4.38 = zext i8 %call34.4.38 to i32
  %xor36.4.38 = xor i32 %xor.4.38, %conv35.4.38
  %conv37.4.38 = trunc i32 %xor36.4.38 to i8
  store i8 %conv37.4.38, i8* %scevgep41.4.37, align 1
  %scevgep28.4.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2016, i64 0, i64 0, i64 1
  %2023 = bitcast i8* %scevgep28.4.38 to [61 x [61 x i8]]*
  %scevgep41.4.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2017, i64 0, i64 1, i64 0
  %2024 = bitcast i8* %scevgep41.4.38 to [61 x [61 x i8]]*
  %call16.4.39 = call zeroext i8 (...) @rand()
  store i8 %call16.4.39, i8* %scevgep28.4.38, align 1
  %2025 = load i8, i8* %scevgep28.4.38, align 1
  %conv23.4.39 = zext i8 %2025 to i32
  %2026 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.39 = getelementptr i8, i8* %b, i64 44
  %2027 = load i8, i8* %scevgep34.4.39, align 1
  %call28.4.39 = call zeroext i8 @mult(i8 zeroext %2026, i8 zeroext %2027)
  %conv29.4.39 = zext i8 %call28.4.39 to i32
  %xor.4.39 = xor i32 %conv23.4.39, %conv29.4.39
  %scevgep35.4.39 = getelementptr i8, i8* %a, i64 44
  %2028 = load i8, i8* %scevgep35.4.39, align 1
  %2029 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.39 = call zeroext i8 @mult(i8 zeroext %2028, i8 zeroext %2029)
  %conv35.4.39 = zext i8 %call34.4.39 to i32
  %xor36.4.39 = xor i32 %xor.4.39, %conv35.4.39
  %conv37.4.39 = trunc i32 %xor36.4.39 to i8
  store i8 %conv37.4.39, i8* %scevgep41.4.38, align 1
  %scevgep28.4.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2023, i64 0, i64 0, i64 1
  %2030 = bitcast i8* %scevgep28.4.39 to [61 x [61 x i8]]*
  %scevgep41.4.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2024, i64 0, i64 1, i64 0
  %2031 = bitcast i8* %scevgep41.4.39 to [61 x [61 x i8]]*
  %call16.4.40 = call zeroext i8 (...) @rand()
  store i8 %call16.4.40, i8* %scevgep28.4.39, align 1
  %2032 = load i8, i8* %scevgep28.4.39, align 1
  %conv23.4.40 = zext i8 %2032 to i32
  %2033 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.40 = getelementptr i8, i8* %b, i64 45
  %2034 = load i8, i8* %scevgep34.4.40, align 1
  %call28.4.40 = call zeroext i8 @mult(i8 zeroext %2033, i8 zeroext %2034)
  %conv29.4.40 = zext i8 %call28.4.40 to i32
  %xor.4.40 = xor i32 %conv23.4.40, %conv29.4.40
  %scevgep35.4.40 = getelementptr i8, i8* %a, i64 45
  %2035 = load i8, i8* %scevgep35.4.40, align 1
  %2036 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.40 = call zeroext i8 @mult(i8 zeroext %2035, i8 zeroext %2036)
  %conv35.4.40 = zext i8 %call34.4.40 to i32
  %xor36.4.40 = xor i32 %xor.4.40, %conv35.4.40
  %conv37.4.40 = trunc i32 %xor36.4.40 to i8
  store i8 %conv37.4.40, i8* %scevgep41.4.39, align 1
  %scevgep28.4.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2030, i64 0, i64 0, i64 1
  %2037 = bitcast i8* %scevgep28.4.40 to [61 x [61 x i8]]*
  %scevgep41.4.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2031, i64 0, i64 1, i64 0
  %2038 = bitcast i8* %scevgep41.4.40 to [61 x [61 x i8]]*
  %call16.4.41 = call zeroext i8 (...) @rand()
  store i8 %call16.4.41, i8* %scevgep28.4.40, align 1
  %2039 = load i8, i8* %scevgep28.4.40, align 1
  %conv23.4.41 = zext i8 %2039 to i32
  %2040 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.41 = getelementptr i8, i8* %b, i64 46
  %2041 = load i8, i8* %scevgep34.4.41, align 1
  %call28.4.41 = call zeroext i8 @mult(i8 zeroext %2040, i8 zeroext %2041)
  %conv29.4.41 = zext i8 %call28.4.41 to i32
  %xor.4.41 = xor i32 %conv23.4.41, %conv29.4.41
  %scevgep35.4.41 = getelementptr i8, i8* %a, i64 46
  %2042 = load i8, i8* %scevgep35.4.41, align 1
  %2043 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.41 = call zeroext i8 @mult(i8 zeroext %2042, i8 zeroext %2043)
  %conv35.4.41 = zext i8 %call34.4.41 to i32
  %xor36.4.41 = xor i32 %xor.4.41, %conv35.4.41
  %conv37.4.41 = trunc i32 %xor36.4.41 to i8
  store i8 %conv37.4.41, i8* %scevgep41.4.40, align 1
  %scevgep28.4.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2037, i64 0, i64 0, i64 1
  %2044 = bitcast i8* %scevgep28.4.41 to [61 x [61 x i8]]*
  %scevgep41.4.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2038, i64 0, i64 1, i64 0
  %2045 = bitcast i8* %scevgep41.4.41 to [61 x [61 x i8]]*
  %call16.4.42 = call zeroext i8 (...) @rand()
  store i8 %call16.4.42, i8* %scevgep28.4.41, align 1
  %2046 = load i8, i8* %scevgep28.4.41, align 1
  %conv23.4.42 = zext i8 %2046 to i32
  %2047 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.42 = getelementptr i8, i8* %b, i64 47
  %2048 = load i8, i8* %scevgep34.4.42, align 1
  %call28.4.42 = call zeroext i8 @mult(i8 zeroext %2047, i8 zeroext %2048)
  %conv29.4.42 = zext i8 %call28.4.42 to i32
  %xor.4.42 = xor i32 %conv23.4.42, %conv29.4.42
  %scevgep35.4.42 = getelementptr i8, i8* %a, i64 47
  %2049 = load i8, i8* %scevgep35.4.42, align 1
  %2050 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.42 = call zeroext i8 @mult(i8 zeroext %2049, i8 zeroext %2050)
  %conv35.4.42 = zext i8 %call34.4.42 to i32
  %xor36.4.42 = xor i32 %xor.4.42, %conv35.4.42
  %conv37.4.42 = trunc i32 %xor36.4.42 to i8
  store i8 %conv37.4.42, i8* %scevgep41.4.41, align 1
  %scevgep28.4.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2044, i64 0, i64 0, i64 1
  %2051 = bitcast i8* %scevgep28.4.42 to [61 x [61 x i8]]*
  %scevgep41.4.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2045, i64 0, i64 1, i64 0
  %2052 = bitcast i8* %scevgep41.4.42 to [61 x [61 x i8]]*
  %call16.4.43 = call zeroext i8 (...) @rand()
  store i8 %call16.4.43, i8* %scevgep28.4.42, align 1
  %2053 = load i8, i8* %scevgep28.4.42, align 1
  %conv23.4.43 = zext i8 %2053 to i32
  %2054 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.43 = getelementptr i8, i8* %b, i64 48
  %2055 = load i8, i8* %scevgep34.4.43, align 1
  %call28.4.43 = call zeroext i8 @mult(i8 zeroext %2054, i8 zeroext %2055)
  %conv29.4.43 = zext i8 %call28.4.43 to i32
  %xor.4.43 = xor i32 %conv23.4.43, %conv29.4.43
  %scevgep35.4.43 = getelementptr i8, i8* %a, i64 48
  %2056 = load i8, i8* %scevgep35.4.43, align 1
  %2057 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.43 = call zeroext i8 @mult(i8 zeroext %2056, i8 zeroext %2057)
  %conv35.4.43 = zext i8 %call34.4.43 to i32
  %xor36.4.43 = xor i32 %xor.4.43, %conv35.4.43
  %conv37.4.43 = trunc i32 %xor36.4.43 to i8
  store i8 %conv37.4.43, i8* %scevgep41.4.42, align 1
  %scevgep28.4.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2051, i64 0, i64 0, i64 1
  %2058 = bitcast i8* %scevgep28.4.43 to [61 x [61 x i8]]*
  %scevgep41.4.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2052, i64 0, i64 1, i64 0
  %2059 = bitcast i8* %scevgep41.4.43 to [61 x [61 x i8]]*
  %call16.4.44 = call zeroext i8 (...) @rand()
  store i8 %call16.4.44, i8* %scevgep28.4.43, align 1
  %2060 = load i8, i8* %scevgep28.4.43, align 1
  %conv23.4.44 = zext i8 %2060 to i32
  %2061 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.44 = getelementptr i8, i8* %b, i64 49
  %2062 = load i8, i8* %scevgep34.4.44, align 1
  %call28.4.44 = call zeroext i8 @mult(i8 zeroext %2061, i8 zeroext %2062)
  %conv29.4.44 = zext i8 %call28.4.44 to i32
  %xor.4.44 = xor i32 %conv23.4.44, %conv29.4.44
  %scevgep35.4.44 = getelementptr i8, i8* %a, i64 49
  %2063 = load i8, i8* %scevgep35.4.44, align 1
  %2064 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.44 = call zeroext i8 @mult(i8 zeroext %2063, i8 zeroext %2064)
  %conv35.4.44 = zext i8 %call34.4.44 to i32
  %xor36.4.44 = xor i32 %xor.4.44, %conv35.4.44
  %conv37.4.44 = trunc i32 %xor36.4.44 to i8
  store i8 %conv37.4.44, i8* %scevgep41.4.43, align 1
  %scevgep28.4.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2058, i64 0, i64 0, i64 1
  %2065 = bitcast i8* %scevgep28.4.44 to [61 x [61 x i8]]*
  %scevgep41.4.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2059, i64 0, i64 1, i64 0
  %2066 = bitcast i8* %scevgep41.4.44 to [61 x [61 x i8]]*
  %call16.4.45 = call zeroext i8 (...) @rand()
  store i8 %call16.4.45, i8* %scevgep28.4.44, align 1
  %2067 = load i8, i8* %scevgep28.4.44, align 1
  %conv23.4.45 = zext i8 %2067 to i32
  %2068 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.45 = getelementptr i8, i8* %b, i64 50
  %2069 = load i8, i8* %scevgep34.4.45, align 1
  %call28.4.45 = call zeroext i8 @mult(i8 zeroext %2068, i8 zeroext %2069)
  %conv29.4.45 = zext i8 %call28.4.45 to i32
  %xor.4.45 = xor i32 %conv23.4.45, %conv29.4.45
  %scevgep35.4.45 = getelementptr i8, i8* %a, i64 50
  %2070 = load i8, i8* %scevgep35.4.45, align 1
  %2071 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.45 = call zeroext i8 @mult(i8 zeroext %2070, i8 zeroext %2071)
  %conv35.4.45 = zext i8 %call34.4.45 to i32
  %xor36.4.45 = xor i32 %xor.4.45, %conv35.4.45
  %conv37.4.45 = trunc i32 %xor36.4.45 to i8
  store i8 %conv37.4.45, i8* %scevgep41.4.44, align 1
  %scevgep28.4.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2065, i64 0, i64 0, i64 1
  %2072 = bitcast i8* %scevgep28.4.45 to [61 x [61 x i8]]*
  %scevgep41.4.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2066, i64 0, i64 1, i64 0
  %2073 = bitcast i8* %scevgep41.4.45 to [61 x [61 x i8]]*
  %call16.4.46 = call zeroext i8 (...) @rand()
  store i8 %call16.4.46, i8* %scevgep28.4.45, align 1
  %2074 = load i8, i8* %scevgep28.4.45, align 1
  %conv23.4.46 = zext i8 %2074 to i32
  %2075 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.46 = getelementptr i8, i8* %b, i64 51
  %2076 = load i8, i8* %scevgep34.4.46, align 1
  %call28.4.46 = call zeroext i8 @mult(i8 zeroext %2075, i8 zeroext %2076)
  %conv29.4.46 = zext i8 %call28.4.46 to i32
  %xor.4.46 = xor i32 %conv23.4.46, %conv29.4.46
  %scevgep35.4.46 = getelementptr i8, i8* %a, i64 51
  %2077 = load i8, i8* %scevgep35.4.46, align 1
  %2078 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.46 = call zeroext i8 @mult(i8 zeroext %2077, i8 zeroext %2078)
  %conv35.4.46 = zext i8 %call34.4.46 to i32
  %xor36.4.46 = xor i32 %xor.4.46, %conv35.4.46
  %conv37.4.46 = trunc i32 %xor36.4.46 to i8
  store i8 %conv37.4.46, i8* %scevgep41.4.45, align 1
  %scevgep28.4.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2072, i64 0, i64 0, i64 1
  %2079 = bitcast i8* %scevgep28.4.46 to [61 x [61 x i8]]*
  %scevgep41.4.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2073, i64 0, i64 1, i64 0
  %2080 = bitcast i8* %scevgep41.4.46 to [61 x [61 x i8]]*
  %call16.4.47 = call zeroext i8 (...) @rand()
  store i8 %call16.4.47, i8* %scevgep28.4.46, align 1
  %2081 = load i8, i8* %scevgep28.4.46, align 1
  %conv23.4.47 = zext i8 %2081 to i32
  %2082 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.47 = getelementptr i8, i8* %b, i64 52
  %2083 = load i8, i8* %scevgep34.4.47, align 1
  %call28.4.47 = call zeroext i8 @mult(i8 zeroext %2082, i8 zeroext %2083)
  %conv29.4.47 = zext i8 %call28.4.47 to i32
  %xor.4.47 = xor i32 %conv23.4.47, %conv29.4.47
  %scevgep35.4.47 = getelementptr i8, i8* %a, i64 52
  %2084 = load i8, i8* %scevgep35.4.47, align 1
  %2085 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.47 = call zeroext i8 @mult(i8 zeroext %2084, i8 zeroext %2085)
  %conv35.4.47 = zext i8 %call34.4.47 to i32
  %xor36.4.47 = xor i32 %xor.4.47, %conv35.4.47
  %conv37.4.47 = trunc i32 %xor36.4.47 to i8
  store i8 %conv37.4.47, i8* %scevgep41.4.46, align 1
  %scevgep28.4.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2079, i64 0, i64 0, i64 1
  %2086 = bitcast i8* %scevgep28.4.47 to [61 x [61 x i8]]*
  %scevgep41.4.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2080, i64 0, i64 1, i64 0
  %2087 = bitcast i8* %scevgep41.4.47 to [61 x [61 x i8]]*
  %call16.4.48 = call zeroext i8 (...) @rand()
  store i8 %call16.4.48, i8* %scevgep28.4.47, align 1
  %2088 = load i8, i8* %scevgep28.4.47, align 1
  %conv23.4.48 = zext i8 %2088 to i32
  %2089 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.48 = getelementptr i8, i8* %b, i64 53
  %2090 = load i8, i8* %scevgep34.4.48, align 1
  %call28.4.48 = call zeroext i8 @mult(i8 zeroext %2089, i8 zeroext %2090)
  %conv29.4.48 = zext i8 %call28.4.48 to i32
  %xor.4.48 = xor i32 %conv23.4.48, %conv29.4.48
  %scevgep35.4.48 = getelementptr i8, i8* %a, i64 53
  %2091 = load i8, i8* %scevgep35.4.48, align 1
  %2092 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.48 = call zeroext i8 @mult(i8 zeroext %2091, i8 zeroext %2092)
  %conv35.4.48 = zext i8 %call34.4.48 to i32
  %xor36.4.48 = xor i32 %xor.4.48, %conv35.4.48
  %conv37.4.48 = trunc i32 %xor36.4.48 to i8
  store i8 %conv37.4.48, i8* %scevgep41.4.47, align 1
  %scevgep28.4.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2086, i64 0, i64 0, i64 1
  %2093 = bitcast i8* %scevgep28.4.48 to [61 x [61 x i8]]*
  %scevgep41.4.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2087, i64 0, i64 1, i64 0
  %2094 = bitcast i8* %scevgep41.4.48 to [61 x [61 x i8]]*
  %call16.4.49 = call zeroext i8 (...) @rand()
  store i8 %call16.4.49, i8* %scevgep28.4.48, align 1
  %2095 = load i8, i8* %scevgep28.4.48, align 1
  %conv23.4.49 = zext i8 %2095 to i32
  %2096 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.49 = getelementptr i8, i8* %b, i64 54
  %2097 = load i8, i8* %scevgep34.4.49, align 1
  %call28.4.49 = call zeroext i8 @mult(i8 zeroext %2096, i8 zeroext %2097)
  %conv29.4.49 = zext i8 %call28.4.49 to i32
  %xor.4.49 = xor i32 %conv23.4.49, %conv29.4.49
  %scevgep35.4.49 = getelementptr i8, i8* %a, i64 54
  %2098 = load i8, i8* %scevgep35.4.49, align 1
  %2099 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.49 = call zeroext i8 @mult(i8 zeroext %2098, i8 zeroext %2099)
  %conv35.4.49 = zext i8 %call34.4.49 to i32
  %xor36.4.49 = xor i32 %xor.4.49, %conv35.4.49
  %conv37.4.49 = trunc i32 %xor36.4.49 to i8
  store i8 %conv37.4.49, i8* %scevgep41.4.48, align 1
  %scevgep28.4.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2093, i64 0, i64 0, i64 1
  %2100 = bitcast i8* %scevgep28.4.49 to [61 x [61 x i8]]*
  %scevgep41.4.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2094, i64 0, i64 1, i64 0
  %2101 = bitcast i8* %scevgep41.4.49 to [61 x [61 x i8]]*
  %call16.4.50 = call zeroext i8 (...) @rand()
  store i8 %call16.4.50, i8* %scevgep28.4.49, align 1
  %2102 = load i8, i8* %scevgep28.4.49, align 1
  %conv23.4.50 = zext i8 %2102 to i32
  %2103 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.50 = getelementptr i8, i8* %b, i64 55
  %2104 = load i8, i8* %scevgep34.4.50, align 1
  %call28.4.50 = call zeroext i8 @mult(i8 zeroext %2103, i8 zeroext %2104)
  %conv29.4.50 = zext i8 %call28.4.50 to i32
  %xor.4.50 = xor i32 %conv23.4.50, %conv29.4.50
  %scevgep35.4.50 = getelementptr i8, i8* %a, i64 55
  %2105 = load i8, i8* %scevgep35.4.50, align 1
  %2106 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.50 = call zeroext i8 @mult(i8 zeroext %2105, i8 zeroext %2106)
  %conv35.4.50 = zext i8 %call34.4.50 to i32
  %xor36.4.50 = xor i32 %xor.4.50, %conv35.4.50
  %conv37.4.50 = trunc i32 %xor36.4.50 to i8
  store i8 %conv37.4.50, i8* %scevgep41.4.49, align 1
  %scevgep28.4.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2100, i64 0, i64 0, i64 1
  %2107 = bitcast i8* %scevgep28.4.50 to [61 x [61 x i8]]*
  %scevgep41.4.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2101, i64 0, i64 1, i64 0
  %2108 = bitcast i8* %scevgep41.4.50 to [61 x [61 x i8]]*
  %call16.4.51 = call zeroext i8 (...) @rand()
  store i8 %call16.4.51, i8* %scevgep28.4.50, align 1
  %2109 = load i8, i8* %scevgep28.4.50, align 1
  %conv23.4.51 = zext i8 %2109 to i32
  %2110 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.51 = getelementptr i8, i8* %b, i64 56
  %2111 = load i8, i8* %scevgep34.4.51, align 1
  %call28.4.51 = call zeroext i8 @mult(i8 zeroext %2110, i8 zeroext %2111)
  %conv29.4.51 = zext i8 %call28.4.51 to i32
  %xor.4.51 = xor i32 %conv23.4.51, %conv29.4.51
  %scevgep35.4.51 = getelementptr i8, i8* %a, i64 56
  %2112 = load i8, i8* %scevgep35.4.51, align 1
  %2113 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.51 = call zeroext i8 @mult(i8 zeroext %2112, i8 zeroext %2113)
  %conv35.4.51 = zext i8 %call34.4.51 to i32
  %xor36.4.51 = xor i32 %xor.4.51, %conv35.4.51
  %conv37.4.51 = trunc i32 %xor36.4.51 to i8
  store i8 %conv37.4.51, i8* %scevgep41.4.50, align 1
  %scevgep28.4.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2107, i64 0, i64 0, i64 1
  %2114 = bitcast i8* %scevgep28.4.51 to [61 x [61 x i8]]*
  %scevgep41.4.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2108, i64 0, i64 1, i64 0
  %2115 = bitcast i8* %scevgep41.4.51 to [61 x [61 x i8]]*
  %call16.4.52 = call zeroext i8 (...) @rand()
  store i8 %call16.4.52, i8* %scevgep28.4.51, align 1
  %2116 = load i8, i8* %scevgep28.4.51, align 1
  %conv23.4.52 = zext i8 %2116 to i32
  %2117 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.52 = getelementptr i8, i8* %b, i64 57
  %2118 = load i8, i8* %scevgep34.4.52, align 1
  %call28.4.52 = call zeroext i8 @mult(i8 zeroext %2117, i8 zeroext %2118)
  %conv29.4.52 = zext i8 %call28.4.52 to i32
  %xor.4.52 = xor i32 %conv23.4.52, %conv29.4.52
  %scevgep35.4.52 = getelementptr i8, i8* %a, i64 57
  %2119 = load i8, i8* %scevgep35.4.52, align 1
  %2120 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.52 = call zeroext i8 @mult(i8 zeroext %2119, i8 zeroext %2120)
  %conv35.4.52 = zext i8 %call34.4.52 to i32
  %xor36.4.52 = xor i32 %xor.4.52, %conv35.4.52
  %conv37.4.52 = trunc i32 %xor36.4.52 to i8
  store i8 %conv37.4.52, i8* %scevgep41.4.51, align 1
  %scevgep28.4.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2114, i64 0, i64 0, i64 1
  %2121 = bitcast i8* %scevgep28.4.52 to [61 x [61 x i8]]*
  %scevgep41.4.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2115, i64 0, i64 1, i64 0
  %2122 = bitcast i8* %scevgep41.4.52 to [61 x [61 x i8]]*
  %call16.4.53 = call zeroext i8 (...) @rand()
  store i8 %call16.4.53, i8* %scevgep28.4.52, align 1
  %2123 = load i8, i8* %scevgep28.4.52, align 1
  %conv23.4.53 = zext i8 %2123 to i32
  %2124 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.53 = getelementptr i8, i8* %b, i64 58
  %2125 = load i8, i8* %scevgep34.4.53, align 1
  %call28.4.53 = call zeroext i8 @mult(i8 zeroext %2124, i8 zeroext %2125)
  %conv29.4.53 = zext i8 %call28.4.53 to i32
  %xor.4.53 = xor i32 %conv23.4.53, %conv29.4.53
  %scevgep35.4.53 = getelementptr i8, i8* %a, i64 58
  %2126 = load i8, i8* %scevgep35.4.53, align 1
  %2127 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.53 = call zeroext i8 @mult(i8 zeroext %2126, i8 zeroext %2127)
  %conv35.4.53 = zext i8 %call34.4.53 to i32
  %xor36.4.53 = xor i32 %xor.4.53, %conv35.4.53
  %conv37.4.53 = trunc i32 %xor36.4.53 to i8
  store i8 %conv37.4.53, i8* %scevgep41.4.52, align 1
  %scevgep28.4.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2121, i64 0, i64 0, i64 1
  %2128 = bitcast i8* %scevgep28.4.53 to [61 x [61 x i8]]*
  %scevgep41.4.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2122, i64 0, i64 1, i64 0
  %2129 = bitcast i8* %scevgep41.4.53 to [61 x [61 x i8]]*
  %call16.4.54 = call zeroext i8 (...) @rand()
  store i8 %call16.4.54, i8* %scevgep28.4.53, align 1
  %2130 = load i8, i8* %scevgep28.4.53, align 1
  %conv23.4.54 = zext i8 %2130 to i32
  %2131 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.54 = getelementptr i8, i8* %b, i64 59
  %2132 = load i8, i8* %scevgep34.4.54, align 1
  %call28.4.54 = call zeroext i8 @mult(i8 zeroext %2131, i8 zeroext %2132)
  %conv29.4.54 = zext i8 %call28.4.54 to i32
  %xor.4.54 = xor i32 %conv23.4.54, %conv29.4.54
  %scevgep35.4.54 = getelementptr i8, i8* %a, i64 59
  %2133 = load i8, i8* %scevgep35.4.54, align 1
  %2134 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.54 = call zeroext i8 @mult(i8 zeroext %2133, i8 zeroext %2134)
  %conv35.4.54 = zext i8 %call34.4.54 to i32
  %xor36.4.54 = xor i32 %xor.4.54, %conv35.4.54
  %conv37.4.54 = trunc i32 %xor36.4.54 to i8
  store i8 %conv37.4.54, i8* %scevgep41.4.53, align 1
  %scevgep28.4.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2128, i64 0, i64 0, i64 1
  %scevgep41.4.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2129, i64 0, i64 1, i64 0
  %call16.4.55 = call zeroext i8 (...) @rand()
  store i8 %call16.4.55, i8* %scevgep28.4.54, align 1
  %2135 = load i8, i8* %scevgep28.4.54, align 1
  %conv23.4.55 = zext i8 %2135 to i32
  %2136 = load i8, i8* %arrayidx25.4, align 1
  %scevgep34.4.55 = getelementptr i8, i8* %b, i64 60
  %2137 = load i8, i8* %scevgep34.4.55, align 1
  %call28.4.55 = call zeroext i8 @mult(i8 zeroext %2136, i8 zeroext %2137)
  %conv29.4.55 = zext i8 %call28.4.55 to i32
  %xor.4.55 = xor i32 %conv23.4.55, %conv29.4.55
  %scevgep35.4.55 = getelementptr i8, i8* %a, i64 60
  %2138 = load i8, i8* %scevgep35.4.55, align 1
  %2139 = load i8, i8* %arrayidx33.4, align 1
  %call34.4.55 = call zeroext i8 @mult(i8 zeroext %2138, i8 zeroext %2139)
  %conv35.4.55 = zext i8 %call34.4.55 to i32
  %xor36.4.55 = xor i32 %xor.4.55, %conv35.4.55
  %conv37.4.55 = trunc i32 %xor36.4.55 to i8
  store i8 %conv37.4.55, i8* %scevgep41.4.54, align 1
  %scevgep26.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1750, i64 0, i64 1, i64 1
  %2140 = bitcast i8* %scevgep26.4 to [61 x [61 x i8]]*
  %scevgep39.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %1751, i64 0, i64 1, i64 1
  %2141 = bitcast i8* %scevgep39.4 to [61 x [61 x i8]]*
  %arrayidx25.5 = getelementptr inbounds i8, i8* %a, i64 5
  %arrayidx33.5 = getelementptr inbounds i8, i8* %b, i64 5
  %call16.5 = call zeroext i8 (...) @rand()
  store i8 %call16.5, i8* %scevgep26.4, align 1
  %2142 = load i8, i8* %scevgep26.4, align 1
  %conv23.5 = zext i8 %2142 to i32
  %2143 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5 = getelementptr i8, i8* %b, i64 6
  %2144 = load i8, i8* %scevgep34.5, align 1
  %call28.5 = call zeroext i8 @mult(i8 zeroext %2143, i8 zeroext %2144)
  %conv29.5 = zext i8 %call28.5 to i32
  %xor.5 = xor i32 %conv23.5, %conv29.5
  %scevgep35.5 = getelementptr i8, i8* %a, i64 6
  %2145 = load i8, i8* %scevgep35.5, align 1
  %2146 = load i8, i8* %arrayidx33.5, align 1
  %call34.5 = call zeroext i8 @mult(i8 zeroext %2145, i8 zeroext %2146)
  %conv35.5 = zext i8 %call34.5 to i32
  %xor36.5 = xor i32 %xor.5, %conv35.5
  %conv37.5 = trunc i32 %xor36.5 to i8
  store i8 %conv37.5, i8* %scevgep39.4, align 1
  %scevgep28.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2140, i64 0, i64 0, i64 1
  %2147 = bitcast i8* %scevgep28.5 to [61 x [61 x i8]]*
  %scevgep41.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2141, i64 0, i64 1, i64 0
  %2148 = bitcast i8* %scevgep41.5 to [61 x [61 x i8]]*
  %call16.5.1 = call zeroext i8 (...) @rand()
  store i8 %call16.5.1, i8* %scevgep28.5, align 1
  %2149 = load i8, i8* %scevgep28.5, align 1
  %conv23.5.1 = zext i8 %2149 to i32
  %2150 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.1 = getelementptr i8, i8* %b, i64 7
  %2151 = load i8, i8* %scevgep34.5.1, align 1
  %call28.5.1 = call zeroext i8 @mult(i8 zeroext %2150, i8 zeroext %2151)
  %conv29.5.1 = zext i8 %call28.5.1 to i32
  %xor.5.1 = xor i32 %conv23.5.1, %conv29.5.1
  %scevgep35.5.1 = getelementptr i8, i8* %a, i64 7
  %2152 = load i8, i8* %scevgep35.5.1, align 1
  %2153 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.1 = call zeroext i8 @mult(i8 zeroext %2152, i8 zeroext %2153)
  %conv35.5.1 = zext i8 %call34.5.1 to i32
  %xor36.5.1 = xor i32 %xor.5.1, %conv35.5.1
  %conv37.5.1 = trunc i32 %xor36.5.1 to i8
  store i8 %conv37.5.1, i8* %scevgep41.5, align 1
  %scevgep28.5.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2147, i64 0, i64 0, i64 1
  %2154 = bitcast i8* %scevgep28.5.1 to [61 x [61 x i8]]*
  %scevgep41.5.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2148, i64 0, i64 1, i64 0
  %2155 = bitcast i8* %scevgep41.5.1 to [61 x [61 x i8]]*
  %call16.5.2 = call zeroext i8 (...) @rand()
  store i8 %call16.5.2, i8* %scevgep28.5.1, align 1
  %2156 = load i8, i8* %scevgep28.5.1, align 1
  %conv23.5.2 = zext i8 %2156 to i32
  %2157 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.2 = getelementptr i8, i8* %b, i64 8
  %2158 = load i8, i8* %scevgep34.5.2, align 1
  %call28.5.2 = call zeroext i8 @mult(i8 zeroext %2157, i8 zeroext %2158)
  %conv29.5.2 = zext i8 %call28.5.2 to i32
  %xor.5.2 = xor i32 %conv23.5.2, %conv29.5.2
  %scevgep35.5.2 = getelementptr i8, i8* %a, i64 8
  %2159 = load i8, i8* %scevgep35.5.2, align 1
  %2160 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.2 = call zeroext i8 @mult(i8 zeroext %2159, i8 zeroext %2160)
  %conv35.5.2 = zext i8 %call34.5.2 to i32
  %xor36.5.2 = xor i32 %xor.5.2, %conv35.5.2
  %conv37.5.2 = trunc i32 %xor36.5.2 to i8
  store i8 %conv37.5.2, i8* %scevgep41.5.1, align 1
  %scevgep28.5.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2154, i64 0, i64 0, i64 1
  %2161 = bitcast i8* %scevgep28.5.2 to [61 x [61 x i8]]*
  %scevgep41.5.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2155, i64 0, i64 1, i64 0
  %2162 = bitcast i8* %scevgep41.5.2 to [61 x [61 x i8]]*
  %call16.5.3 = call zeroext i8 (...) @rand()
  store i8 %call16.5.3, i8* %scevgep28.5.2, align 1
  %2163 = load i8, i8* %scevgep28.5.2, align 1
  %conv23.5.3 = zext i8 %2163 to i32
  %2164 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.3 = getelementptr i8, i8* %b, i64 9
  %2165 = load i8, i8* %scevgep34.5.3, align 1
  %call28.5.3 = call zeroext i8 @mult(i8 zeroext %2164, i8 zeroext %2165)
  %conv29.5.3 = zext i8 %call28.5.3 to i32
  %xor.5.3 = xor i32 %conv23.5.3, %conv29.5.3
  %scevgep35.5.3 = getelementptr i8, i8* %a, i64 9
  %2166 = load i8, i8* %scevgep35.5.3, align 1
  %2167 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.3 = call zeroext i8 @mult(i8 zeroext %2166, i8 zeroext %2167)
  %conv35.5.3 = zext i8 %call34.5.3 to i32
  %xor36.5.3 = xor i32 %xor.5.3, %conv35.5.3
  %conv37.5.3 = trunc i32 %xor36.5.3 to i8
  store i8 %conv37.5.3, i8* %scevgep41.5.2, align 1
  %scevgep28.5.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2161, i64 0, i64 0, i64 1
  %2168 = bitcast i8* %scevgep28.5.3 to [61 x [61 x i8]]*
  %scevgep41.5.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2162, i64 0, i64 1, i64 0
  %2169 = bitcast i8* %scevgep41.5.3 to [61 x [61 x i8]]*
  %call16.5.4 = call zeroext i8 (...) @rand()
  store i8 %call16.5.4, i8* %scevgep28.5.3, align 1
  %2170 = load i8, i8* %scevgep28.5.3, align 1
  %conv23.5.4 = zext i8 %2170 to i32
  %2171 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.4 = getelementptr i8, i8* %b, i64 10
  %2172 = load i8, i8* %scevgep34.5.4, align 1
  %call28.5.4 = call zeroext i8 @mult(i8 zeroext %2171, i8 zeroext %2172)
  %conv29.5.4 = zext i8 %call28.5.4 to i32
  %xor.5.4 = xor i32 %conv23.5.4, %conv29.5.4
  %scevgep35.5.4 = getelementptr i8, i8* %a, i64 10
  %2173 = load i8, i8* %scevgep35.5.4, align 1
  %2174 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.4 = call zeroext i8 @mult(i8 zeroext %2173, i8 zeroext %2174)
  %conv35.5.4 = zext i8 %call34.5.4 to i32
  %xor36.5.4 = xor i32 %xor.5.4, %conv35.5.4
  %conv37.5.4 = trunc i32 %xor36.5.4 to i8
  store i8 %conv37.5.4, i8* %scevgep41.5.3, align 1
  %scevgep28.5.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2168, i64 0, i64 0, i64 1
  %2175 = bitcast i8* %scevgep28.5.4 to [61 x [61 x i8]]*
  %scevgep41.5.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2169, i64 0, i64 1, i64 0
  %2176 = bitcast i8* %scevgep41.5.4 to [61 x [61 x i8]]*
  %call16.5.5 = call zeroext i8 (...) @rand()
  store i8 %call16.5.5, i8* %scevgep28.5.4, align 1
  %2177 = load i8, i8* %scevgep28.5.4, align 1
  %conv23.5.5 = zext i8 %2177 to i32
  %2178 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.5 = getelementptr i8, i8* %b, i64 11
  %2179 = load i8, i8* %scevgep34.5.5, align 1
  %call28.5.5 = call zeroext i8 @mult(i8 zeroext %2178, i8 zeroext %2179)
  %conv29.5.5 = zext i8 %call28.5.5 to i32
  %xor.5.5 = xor i32 %conv23.5.5, %conv29.5.5
  %scevgep35.5.5 = getelementptr i8, i8* %a, i64 11
  %2180 = load i8, i8* %scevgep35.5.5, align 1
  %2181 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.5 = call zeroext i8 @mult(i8 zeroext %2180, i8 zeroext %2181)
  %conv35.5.5 = zext i8 %call34.5.5 to i32
  %xor36.5.5 = xor i32 %xor.5.5, %conv35.5.5
  %conv37.5.5 = trunc i32 %xor36.5.5 to i8
  store i8 %conv37.5.5, i8* %scevgep41.5.4, align 1
  %scevgep28.5.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2175, i64 0, i64 0, i64 1
  %2182 = bitcast i8* %scevgep28.5.5 to [61 x [61 x i8]]*
  %scevgep41.5.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2176, i64 0, i64 1, i64 0
  %2183 = bitcast i8* %scevgep41.5.5 to [61 x [61 x i8]]*
  %call16.5.6 = call zeroext i8 (...) @rand()
  store i8 %call16.5.6, i8* %scevgep28.5.5, align 1
  %2184 = load i8, i8* %scevgep28.5.5, align 1
  %conv23.5.6 = zext i8 %2184 to i32
  %2185 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.6 = getelementptr i8, i8* %b, i64 12
  %2186 = load i8, i8* %scevgep34.5.6, align 1
  %call28.5.6 = call zeroext i8 @mult(i8 zeroext %2185, i8 zeroext %2186)
  %conv29.5.6 = zext i8 %call28.5.6 to i32
  %xor.5.6 = xor i32 %conv23.5.6, %conv29.5.6
  %scevgep35.5.6 = getelementptr i8, i8* %a, i64 12
  %2187 = load i8, i8* %scevgep35.5.6, align 1
  %2188 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.6 = call zeroext i8 @mult(i8 zeroext %2187, i8 zeroext %2188)
  %conv35.5.6 = zext i8 %call34.5.6 to i32
  %xor36.5.6 = xor i32 %xor.5.6, %conv35.5.6
  %conv37.5.6 = trunc i32 %xor36.5.6 to i8
  store i8 %conv37.5.6, i8* %scevgep41.5.5, align 1
  %scevgep28.5.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2182, i64 0, i64 0, i64 1
  %2189 = bitcast i8* %scevgep28.5.6 to [61 x [61 x i8]]*
  %scevgep41.5.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2183, i64 0, i64 1, i64 0
  %2190 = bitcast i8* %scevgep41.5.6 to [61 x [61 x i8]]*
  %call16.5.7 = call zeroext i8 (...) @rand()
  store i8 %call16.5.7, i8* %scevgep28.5.6, align 1
  %2191 = load i8, i8* %scevgep28.5.6, align 1
  %conv23.5.7 = zext i8 %2191 to i32
  %2192 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.7 = getelementptr i8, i8* %b, i64 13
  %2193 = load i8, i8* %scevgep34.5.7, align 1
  %call28.5.7 = call zeroext i8 @mult(i8 zeroext %2192, i8 zeroext %2193)
  %conv29.5.7 = zext i8 %call28.5.7 to i32
  %xor.5.7 = xor i32 %conv23.5.7, %conv29.5.7
  %scevgep35.5.7 = getelementptr i8, i8* %a, i64 13
  %2194 = load i8, i8* %scevgep35.5.7, align 1
  %2195 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.7 = call zeroext i8 @mult(i8 zeroext %2194, i8 zeroext %2195)
  %conv35.5.7 = zext i8 %call34.5.7 to i32
  %xor36.5.7 = xor i32 %xor.5.7, %conv35.5.7
  %conv37.5.7 = trunc i32 %xor36.5.7 to i8
  store i8 %conv37.5.7, i8* %scevgep41.5.6, align 1
  %scevgep28.5.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2189, i64 0, i64 0, i64 1
  %2196 = bitcast i8* %scevgep28.5.7 to [61 x [61 x i8]]*
  %scevgep41.5.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2190, i64 0, i64 1, i64 0
  %2197 = bitcast i8* %scevgep41.5.7 to [61 x [61 x i8]]*
  %call16.5.8 = call zeroext i8 (...) @rand()
  store i8 %call16.5.8, i8* %scevgep28.5.7, align 1
  %2198 = load i8, i8* %scevgep28.5.7, align 1
  %conv23.5.8 = zext i8 %2198 to i32
  %2199 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.8 = getelementptr i8, i8* %b, i64 14
  %2200 = load i8, i8* %scevgep34.5.8, align 1
  %call28.5.8 = call zeroext i8 @mult(i8 zeroext %2199, i8 zeroext %2200)
  %conv29.5.8 = zext i8 %call28.5.8 to i32
  %xor.5.8 = xor i32 %conv23.5.8, %conv29.5.8
  %scevgep35.5.8 = getelementptr i8, i8* %a, i64 14
  %2201 = load i8, i8* %scevgep35.5.8, align 1
  %2202 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.8 = call zeroext i8 @mult(i8 zeroext %2201, i8 zeroext %2202)
  %conv35.5.8 = zext i8 %call34.5.8 to i32
  %xor36.5.8 = xor i32 %xor.5.8, %conv35.5.8
  %conv37.5.8 = trunc i32 %xor36.5.8 to i8
  store i8 %conv37.5.8, i8* %scevgep41.5.7, align 1
  %scevgep28.5.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2196, i64 0, i64 0, i64 1
  %2203 = bitcast i8* %scevgep28.5.8 to [61 x [61 x i8]]*
  %scevgep41.5.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2197, i64 0, i64 1, i64 0
  %2204 = bitcast i8* %scevgep41.5.8 to [61 x [61 x i8]]*
  %call16.5.9 = call zeroext i8 (...) @rand()
  store i8 %call16.5.9, i8* %scevgep28.5.8, align 1
  %2205 = load i8, i8* %scevgep28.5.8, align 1
  %conv23.5.9 = zext i8 %2205 to i32
  %2206 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.9 = getelementptr i8, i8* %b, i64 15
  %2207 = load i8, i8* %scevgep34.5.9, align 1
  %call28.5.9 = call zeroext i8 @mult(i8 zeroext %2206, i8 zeroext %2207)
  %conv29.5.9 = zext i8 %call28.5.9 to i32
  %xor.5.9 = xor i32 %conv23.5.9, %conv29.5.9
  %scevgep35.5.9 = getelementptr i8, i8* %a, i64 15
  %2208 = load i8, i8* %scevgep35.5.9, align 1
  %2209 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.9 = call zeroext i8 @mult(i8 zeroext %2208, i8 zeroext %2209)
  %conv35.5.9 = zext i8 %call34.5.9 to i32
  %xor36.5.9 = xor i32 %xor.5.9, %conv35.5.9
  %conv37.5.9 = trunc i32 %xor36.5.9 to i8
  store i8 %conv37.5.9, i8* %scevgep41.5.8, align 1
  %scevgep28.5.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2203, i64 0, i64 0, i64 1
  %2210 = bitcast i8* %scevgep28.5.9 to [61 x [61 x i8]]*
  %scevgep41.5.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2204, i64 0, i64 1, i64 0
  %2211 = bitcast i8* %scevgep41.5.9 to [61 x [61 x i8]]*
  %call16.5.10 = call zeroext i8 (...) @rand()
  store i8 %call16.5.10, i8* %scevgep28.5.9, align 1
  %2212 = load i8, i8* %scevgep28.5.9, align 1
  %conv23.5.10 = zext i8 %2212 to i32
  %2213 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.10 = getelementptr i8, i8* %b, i64 16
  %2214 = load i8, i8* %scevgep34.5.10, align 1
  %call28.5.10 = call zeroext i8 @mult(i8 zeroext %2213, i8 zeroext %2214)
  %conv29.5.10 = zext i8 %call28.5.10 to i32
  %xor.5.10 = xor i32 %conv23.5.10, %conv29.5.10
  %scevgep35.5.10 = getelementptr i8, i8* %a, i64 16
  %2215 = load i8, i8* %scevgep35.5.10, align 1
  %2216 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.10 = call zeroext i8 @mult(i8 zeroext %2215, i8 zeroext %2216)
  %conv35.5.10 = zext i8 %call34.5.10 to i32
  %xor36.5.10 = xor i32 %xor.5.10, %conv35.5.10
  %conv37.5.10 = trunc i32 %xor36.5.10 to i8
  store i8 %conv37.5.10, i8* %scevgep41.5.9, align 1
  %scevgep28.5.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2210, i64 0, i64 0, i64 1
  %2217 = bitcast i8* %scevgep28.5.10 to [61 x [61 x i8]]*
  %scevgep41.5.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2211, i64 0, i64 1, i64 0
  %2218 = bitcast i8* %scevgep41.5.10 to [61 x [61 x i8]]*
  %call16.5.11 = call zeroext i8 (...) @rand()
  store i8 %call16.5.11, i8* %scevgep28.5.10, align 1
  %2219 = load i8, i8* %scevgep28.5.10, align 1
  %conv23.5.11 = zext i8 %2219 to i32
  %2220 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.11 = getelementptr i8, i8* %b, i64 17
  %2221 = load i8, i8* %scevgep34.5.11, align 1
  %call28.5.11 = call zeroext i8 @mult(i8 zeroext %2220, i8 zeroext %2221)
  %conv29.5.11 = zext i8 %call28.5.11 to i32
  %xor.5.11 = xor i32 %conv23.5.11, %conv29.5.11
  %scevgep35.5.11 = getelementptr i8, i8* %a, i64 17
  %2222 = load i8, i8* %scevgep35.5.11, align 1
  %2223 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.11 = call zeroext i8 @mult(i8 zeroext %2222, i8 zeroext %2223)
  %conv35.5.11 = zext i8 %call34.5.11 to i32
  %xor36.5.11 = xor i32 %xor.5.11, %conv35.5.11
  %conv37.5.11 = trunc i32 %xor36.5.11 to i8
  store i8 %conv37.5.11, i8* %scevgep41.5.10, align 1
  %scevgep28.5.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2217, i64 0, i64 0, i64 1
  %2224 = bitcast i8* %scevgep28.5.11 to [61 x [61 x i8]]*
  %scevgep41.5.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2218, i64 0, i64 1, i64 0
  %2225 = bitcast i8* %scevgep41.5.11 to [61 x [61 x i8]]*
  %call16.5.12 = call zeroext i8 (...) @rand()
  store i8 %call16.5.12, i8* %scevgep28.5.11, align 1
  %2226 = load i8, i8* %scevgep28.5.11, align 1
  %conv23.5.12 = zext i8 %2226 to i32
  %2227 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.12 = getelementptr i8, i8* %b, i64 18
  %2228 = load i8, i8* %scevgep34.5.12, align 1
  %call28.5.12 = call zeroext i8 @mult(i8 zeroext %2227, i8 zeroext %2228)
  %conv29.5.12 = zext i8 %call28.5.12 to i32
  %xor.5.12 = xor i32 %conv23.5.12, %conv29.5.12
  %scevgep35.5.12 = getelementptr i8, i8* %a, i64 18
  %2229 = load i8, i8* %scevgep35.5.12, align 1
  %2230 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.12 = call zeroext i8 @mult(i8 zeroext %2229, i8 zeroext %2230)
  %conv35.5.12 = zext i8 %call34.5.12 to i32
  %xor36.5.12 = xor i32 %xor.5.12, %conv35.5.12
  %conv37.5.12 = trunc i32 %xor36.5.12 to i8
  store i8 %conv37.5.12, i8* %scevgep41.5.11, align 1
  %scevgep28.5.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2224, i64 0, i64 0, i64 1
  %2231 = bitcast i8* %scevgep28.5.12 to [61 x [61 x i8]]*
  %scevgep41.5.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2225, i64 0, i64 1, i64 0
  %2232 = bitcast i8* %scevgep41.5.12 to [61 x [61 x i8]]*
  %call16.5.13 = call zeroext i8 (...) @rand()
  store i8 %call16.5.13, i8* %scevgep28.5.12, align 1
  %2233 = load i8, i8* %scevgep28.5.12, align 1
  %conv23.5.13 = zext i8 %2233 to i32
  %2234 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.13 = getelementptr i8, i8* %b, i64 19
  %2235 = load i8, i8* %scevgep34.5.13, align 1
  %call28.5.13 = call zeroext i8 @mult(i8 zeroext %2234, i8 zeroext %2235)
  %conv29.5.13 = zext i8 %call28.5.13 to i32
  %xor.5.13 = xor i32 %conv23.5.13, %conv29.5.13
  %scevgep35.5.13 = getelementptr i8, i8* %a, i64 19
  %2236 = load i8, i8* %scevgep35.5.13, align 1
  %2237 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.13 = call zeroext i8 @mult(i8 zeroext %2236, i8 zeroext %2237)
  %conv35.5.13 = zext i8 %call34.5.13 to i32
  %xor36.5.13 = xor i32 %xor.5.13, %conv35.5.13
  %conv37.5.13 = trunc i32 %xor36.5.13 to i8
  store i8 %conv37.5.13, i8* %scevgep41.5.12, align 1
  %scevgep28.5.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2231, i64 0, i64 0, i64 1
  %2238 = bitcast i8* %scevgep28.5.13 to [61 x [61 x i8]]*
  %scevgep41.5.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2232, i64 0, i64 1, i64 0
  %2239 = bitcast i8* %scevgep41.5.13 to [61 x [61 x i8]]*
  %call16.5.14 = call zeroext i8 (...) @rand()
  store i8 %call16.5.14, i8* %scevgep28.5.13, align 1
  %2240 = load i8, i8* %scevgep28.5.13, align 1
  %conv23.5.14 = zext i8 %2240 to i32
  %2241 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.14 = getelementptr i8, i8* %b, i64 20
  %2242 = load i8, i8* %scevgep34.5.14, align 1
  %call28.5.14 = call zeroext i8 @mult(i8 zeroext %2241, i8 zeroext %2242)
  %conv29.5.14 = zext i8 %call28.5.14 to i32
  %xor.5.14 = xor i32 %conv23.5.14, %conv29.5.14
  %scevgep35.5.14 = getelementptr i8, i8* %a, i64 20
  %2243 = load i8, i8* %scevgep35.5.14, align 1
  %2244 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.14 = call zeroext i8 @mult(i8 zeroext %2243, i8 zeroext %2244)
  %conv35.5.14 = zext i8 %call34.5.14 to i32
  %xor36.5.14 = xor i32 %xor.5.14, %conv35.5.14
  %conv37.5.14 = trunc i32 %xor36.5.14 to i8
  store i8 %conv37.5.14, i8* %scevgep41.5.13, align 1
  %scevgep28.5.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2238, i64 0, i64 0, i64 1
  %2245 = bitcast i8* %scevgep28.5.14 to [61 x [61 x i8]]*
  %scevgep41.5.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2239, i64 0, i64 1, i64 0
  %2246 = bitcast i8* %scevgep41.5.14 to [61 x [61 x i8]]*
  %call16.5.15 = call zeroext i8 (...) @rand()
  store i8 %call16.5.15, i8* %scevgep28.5.14, align 1
  %2247 = load i8, i8* %scevgep28.5.14, align 1
  %conv23.5.15 = zext i8 %2247 to i32
  %2248 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.15 = getelementptr i8, i8* %b, i64 21
  %2249 = load i8, i8* %scevgep34.5.15, align 1
  %call28.5.15 = call zeroext i8 @mult(i8 zeroext %2248, i8 zeroext %2249)
  %conv29.5.15 = zext i8 %call28.5.15 to i32
  %xor.5.15 = xor i32 %conv23.5.15, %conv29.5.15
  %scevgep35.5.15 = getelementptr i8, i8* %a, i64 21
  %2250 = load i8, i8* %scevgep35.5.15, align 1
  %2251 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.15 = call zeroext i8 @mult(i8 zeroext %2250, i8 zeroext %2251)
  %conv35.5.15 = zext i8 %call34.5.15 to i32
  %xor36.5.15 = xor i32 %xor.5.15, %conv35.5.15
  %conv37.5.15 = trunc i32 %xor36.5.15 to i8
  store i8 %conv37.5.15, i8* %scevgep41.5.14, align 1
  %scevgep28.5.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2245, i64 0, i64 0, i64 1
  %2252 = bitcast i8* %scevgep28.5.15 to [61 x [61 x i8]]*
  %scevgep41.5.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2246, i64 0, i64 1, i64 0
  %2253 = bitcast i8* %scevgep41.5.15 to [61 x [61 x i8]]*
  %call16.5.16 = call zeroext i8 (...) @rand()
  store i8 %call16.5.16, i8* %scevgep28.5.15, align 1
  %2254 = load i8, i8* %scevgep28.5.15, align 1
  %conv23.5.16 = zext i8 %2254 to i32
  %2255 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.16 = getelementptr i8, i8* %b, i64 22
  %2256 = load i8, i8* %scevgep34.5.16, align 1
  %call28.5.16 = call zeroext i8 @mult(i8 zeroext %2255, i8 zeroext %2256)
  %conv29.5.16 = zext i8 %call28.5.16 to i32
  %xor.5.16 = xor i32 %conv23.5.16, %conv29.5.16
  %scevgep35.5.16 = getelementptr i8, i8* %a, i64 22
  %2257 = load i8, i8* %scevgep35.5.16, align 1
  %2258 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.16 = call zeroext i8 @mult(i8 zeroext %2257, i8 zeroext %2258)
  %conv35.5.16 = zext i8 %call34.5.16 to i32
  %xor36.5.16 = xor i32 %xor.5.16, %conv35.5.16
  %conv37.5.16 = trunc i32 %xor36.5.16 to i8
  store i8 %conv37.5.16, i8* %scevgep41.5.15, align 1
  %scevgep28.5.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2252, i64 0, i64 0, i64 1
  %2259 = bitcast i8* %scevgep28.5.16 to [61 x [61 x i8]]*
  %scevgep41.5.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2253, i64 0, i64 1, i64 0
  %2260 = bitcast i8* %scevgep41.5.16 to [61 x [61 x i8]]*
  %call16.5.17 = call zeroext i8 (...) @rand()
  store i8 %call16.5.17, i8* %scevgep28.5.16, align 1
  %2261 = load i8, i8* %scevgep28.5.16, align 1
  %conv23.5.17 = zext i8 %2261 to i32
  %2262 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.17 = getelementptr i8, i8* %b, i64 23
  %2263 = load i8, i8* %scevgep34.5.17, align 1
  %call28.5.17 = call zeroext i8 @mult(i8 zeroext %2262, i8 zeroext %2263)
  %conv29.5.17 = zext i8 %call28.5.17 to i32
  %xor.5.17 = xor i32 %conv23.5.17, %conv29.5.17
  %scevgep35.5.17 = getelementptr i8, i8* %a, i64 23
  %2264 = load i8, i8* %scevgep35.5.17, align 1
  %2265 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.17 = call zeroext i8 @mult(i8 zeroext %2264, i8 zeroext %2265)
  %conv35.5.17 = zext i8 %call34.5.17 to i32
  %xor36.5.17 = xor i32 %xor.5.17, %conv35.5.17
  %conv37.5.17 = trunc i32 %xor36.5.17 to i8
  store i8 %conv37.5.17, i8* %scevgep41.5.16, align 1
  %scevgep28.5.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2259, i64 0, i64 0, i64 1
  %2266 = bitcast i8* %scevgep28.5.17 to [61 x [61 x i8]]*
  %scevgep41.5.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2260, i64 0, i64 1, i64 0
  %2267 = bitcast i8* %scevgep41.5.17 to [61 x [61 x i8]]*
  %call16.5.18 = call zeroext i8 (...) @rand()
  store i8 %call16.5.18, i8* %scevgep28.5.17, align 1
  %2268 = load i8, i8* %scevgep28.5.17, align 1
  %conv23.5.18 = zext i8 %2268 to i32
  %2269 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.18 = getelementptr i8, i8* %b, i64 24
  %2270 = load i8, i8* %scevgep34.5.18, align 1
  %call28.5.18 = call zeroext i8 @mult(i8 zeroext %2269, i8 zeroext %2270)
  %conv29.5.18 = zext i8 %call28.5.18 to i32
  %xor.5.18 = xor i32 %conv23.5.18, %conv29.5.18
  %scevgep35.5.18 = getelementptr i8, i8* %a, i64 24
  %2271 = load i8, i8* %scevgep35.5.18, align 1
  %2272 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.18 = call zeroext i8 @mult(i8 zeroext %2271, i8 zeroext %2272)
  %conv35.5.18 = zext i8 %call34.5.18 to i32
  %xor36.5.18 = xor i32 %xor.5.18, %conv35.5.18
  %conv37.5.18 = trunc i32 %xor36.5.18 to i8
  store i8 %conv37.5.18, i8* %scevgep41.5.17, align 1
  %scevgep28.5.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2266, i64 0, i64 0, i64 1
  %2273 = bitcast i8* %scevgep28.5.18 to [61 x [61 x i8]]*
  %scevgep41.5.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2267, i64 0, i64 1, i64 0
  %2274 = bitcast i8* %scevgep41.5.18 to [61 x [61 x i8]]*
  %call16.5.19 = call zeroext i8 (...) @rand()
  store i8 %call16.5.19, i8* %scevgep28.5.18, align 1
  %2275 = load i8, i8* %scevgep28.5.18, align 1
  %conv23.5.19 = zext i8 %2275 to i32
  %2276 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.19 = getelementptr i8, i8* %b, i64 25
  %2277 = load i8, i8* %scevgep34.5.19, align 1
  %call28.5.19 = call zeroext i8 @mult(i8 zeroext %2276, i8 zeroext %2277)
  %conv29.5.19 = zext i8 %call28.5.19 to i32
  %xor.5.19 = xor i32 %conv23.5.19, %conv29.5.19
  %scevgep35.5.19 = getelementptr i8, i8* %a, i64 25
  %2278 = load i8, i8* %scevgep35.5.19, align 1
  %2279 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.19 = call zeroext i8 @mult(i8 zeroext %2278, i8 zeroext %2279)
  %conv35.5.19 = zext i8 %call34.5.19 to i32
  %xor36.5.19 = xor i32 %xor.5.19, %conv35.5.19
  %conv37.5.19 = trunc i32 %xor36.5.19 to i8
  store i8 %conv37.5.19, i8* %scevgep41.5.18, align 1
  %scevgep28.5.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2273, i64 0, i64 0, i64 1
  %2280 = bitcast i8* %scevgep28.5.19 to [61 x [61 x i8]]*
  %scevgep41.5.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2274, i64 0, i64 1, i64 0
  %2281 = bitcast i8* %scevgep41.5.19 to [61 x [61 x i8]]*
  %call16.5.20 = call zeroext i8 (...) @rand()
  store i8 %call16.5.20, i8* %scevgep28.5.19, align 1
  %2282 = load i8, i8* %scevgep28.5.19, align 1
  %conv23.5.20 = zext i8 %2282 to i32
  %2283 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.20 = getelementptr i8, i8* %b, i64 26
  %2284 = load i8, i8* %scevgep34.5.20, align 1
  %call28.5.20 = call zeroext i8 @mult(i8 zeroext %2283, i8 zeroext %2284)
  %conv29.5.20 = zext i8 %call28.5.20 to i32
  %xor.5.20 = xor i32 %conv23.5.20, %conv29.5.20
  %scevgep35.5.20 = getelementptr i8, i8* %a, i64 26
  %2285 = load i8, i8* %scevgep35.5.20, align 1
  %2286 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.20 = call zeroext i8 @mult(i8 zeroext %2285, i8 zeroext %2286)
  %conv35.5.20 = zext i8 %call34.5.20 to i32
  %xor36.5.20 = xor i32 %xor.5.20, %conv35.5.20
  %conv37.5.20 = trunc i32 %xor36.5.20 to i8
  store i8 %conv37.5.20, i8* %scevgep41.5.19, align 1
  %scevgep28.5.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2280, i64 0, i64 0, i64 1
  %2287 = bitcast i8* %scevgep28.5.20 to [61 x [61 x i8]]*
  %scevgep41.5.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2281, i64 0, i64 1, i64 0
  %2288 = bitcast i8* %scevgep41.5.20 to [61 x [61 x i8]]*
  %call16.5.21 = call zeroext i8 (...) @rand()
  store i8 %call16.5.21, i8* %scevgep28.5.20, align 1
  %2289 = load i8, i8* %scevgep28.5.20, align 1
  %conv23.5.21 = zext i8 %2289 to i32
  %2290 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.21 = getelementptr i8, i8* %b, i64 27
  %2291 = load i8, i8* %scevgep34.5.21, align 1
  %call28.5.21 = call zeroext i8 @mult(i8 zeroext %2290, i8 zeroext %2291)
  %conv29.5.21 = zext i8 %call28.5.21 to i32
  %xor.5.21 = xor i32 %conv23.5.21, %conv29.5.21
  %scevgep35.5.21 = getelementptr i8, i8* %a, i64 27
  %2292 = load i8, i8* %scevgep35.5.21, align 1
  %2293 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.21 = call zeroext i8 @mult(i8 zeroext %2292, i8 zeroext %2293)
  %conv35.5.21 = zext i8 %call34.5.21 to i32
  %xor36.5.21 = xor i32 %xor.5.21, %conv35.5.21
  %conv37.5.21 = trunc i32 %xor36.5.21 to i8
  store i8 %conv37.5.21, i8* %scevgep41.5.20, align 1
  %scevgep28.5.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2287, i64 0, i64 0, i64 1
  %2294 = bitcast i8* %scevgep28.5.21 to [61 x [61 x i8]]*
  %scevgep41.5.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2288, i64 0, i64 1, i64 0
  %2295 = bitcast i8* %scevgep41.5.21 to [61 x [61 x i8]]*
  %call16.5.22 = call zeroext i8 (...) @rand()
  store i8 %call16.5.22, i8* %scevgep28.5.21, align 1
  %2296 = load i8, i8* %scevgep28.5.21, align 1
  %conv23.5.22 = zext i8 %2296 to i32
  %2297 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.22 = getelementptr i8, i8* %b, i64 28
  %2298 = load i8, i8* %scevgep34.5.22, align 1
  %call28.5.22 = call zeroext i8 @mult(i8 zeroext %2297, i8 zeroext %2298)
  %conv29.5.22 = zext i8 %call28.5.22 to i32
  %xor.5.22 = xor i32 %conv23.5.22, %conv29.5.22
  %scevgep35.5.22 = getelementptr i8, i8* %a, i64 28
  %2299 = load i8, i8* %scevgep35.5.22, align 1
  %2300 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.22 = call zeroext i8 @mult(i8 zeroext %2299, i8 zeroext %2300)
  %conv35.5.22 = zext i8 %call34.5.22 to i32
  %xor36.5.22 = xor i32 %xor.5.22, %conv35.5.22
  %conv37.5.22 = trunc i32 %xor36.5.22 to i8
  store i8 %conv37.5.22, i8* %scevgep41.5.21, align 1
  %scevgep28.5.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2294, i64 0, i64 0, i64 1
  %2301 = bitcast i8* %scevgep28.5.22 to [61 x [61 x i8]]*
  %scevgep41.5.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2295, i64 0, i64 1, i64 0
  %2302 = bitcast i8* %scevgep41.5.22 to [61 x [61 x i8]]*
  %call16.5.23 = call zeroext i8 (...) @rand()
  store i8 %call16.5.23, i8* %scevgep28.5.22, align 1
  %2303 = load i8, i8* %scevgep28.5.22, align 1
  %conv23.5.23 = zext i8 %2303 to i32
  %2304 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.23 = getelementptr i8, i8* %b, i64 29
  %2305 = load i8, i8* %scevgep34.5.23, align 1
  %call28.5.23 = call zeroext i8 @mult(i8 zeroext %2304, i8 zeroext %2305)
  %conv29.5.23 = zext i8 %call28.5.23 to i32
  %xor.5.23 = xor i32 %conv23.5.23, %conv29.5.23
  %scevgep35.5.23 = getelementptr i8, i8* %a, i64 29
  %2306 = load i8, i8* %scevgep35.5.23, align 1
  %2307 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.23 = call zeroext i8 @mult(i8 zeroext %2306, i8 zeroext %2307)
  %conv35.5.23 = zext i8 %call34.5.23 to i32
  %xor36.5.23 = xor i32 %xor.5.23, %conv35.5.23
  %conv37.5.23 = trunc i32 %xor36.5.23 to i8
  store i8 %conv37.5.23, i8* %scevgep41.5.22, align 1
  %scevgep28.5.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2301, i64 0, i64 0, i64 1
  %2308 = bitcast i8* %scevgep28.5.23 to [61 x [61 x i8]]*
  %scevgep41.5.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2302, i64 0, i64 1, i64 0
  %2309 = bitcast i8* %scevgep41.5.23 to [61 x [61 x i8]]*
  %call16.5.24 = call zeroext i8 (...) @rand()
  store i8 %call16.5.24, i8* %scevgep28.5.23, align 1
  %2310 = load i8, i8* %scevgep28.5.23, align 1
  %conv23.5.24 = zext i8 %2310 to i32
  %2311 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.24 = getelementptr i8, i8* %b, i64 30
  %2312 = load i8, i8* %scevgep34.5.24, align 1
  %call28.5.24 = call zeroext i8 @mult(i8 zeroext %2311, i8 zeroext %2312)
  %conv29.5.24 = zext i8 %call28.5.24 to i32
  %xor.5.24 = xor i32 %conv23.5.24, %conv29.5.24
  %scevgep35.5.24 = getelementptr i8, i8* %a, i64 30
  %2313 = load i8, i8* %scevgep35.5.24, align 1
  %2314 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.24 = call zeroext i8 @mult(i8 zeroext %2313, i8 zeroext %2314)
  %conv35.5.24 = zext i8 %call34.5.24 to i32
  %xor36.5.24 = xor i32 %xor.5.24, %conv35.5.24
  %conv37.5.24 = trunc i32 %xor36.5.24 to i8
  store i8 %conv37.5.24, i8* %scevgep41.5.23, align 1
  %scevgep28.5.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2308, i64 0, i64 0, i64 1
  %2315 = bitcast i8* %scevgep28.5.24 to [61 x [61 x i8]]*
  %scevgep41.5.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2309, i64 0, i64 1, i64 0
  %2316 = bitcast i8* %scevgep41.5.24 to [61 x [61 x i8]]*
  %call16.5.25 = call zeroext i8 (...) @rand()
  store i8 %call16.5.25, i8* %scevgep28.5.24, align 1
  %2317 = load i8, i8* %scevgep28.5.24, align 1
  %conv23.5.25 = zext i8 %2317 to i32
  %2318 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.25 = getelementptr i8, i8* %b, i64 31
  %2319 = load i8, i8* %scevgep34.5.25, align 1
  %call28.5.25 = call zeroext i8 @mult(i8 zeroext %2318, i8 zeroext %2319)
  %conv29.5.25 = zext i8 %call28.5.25 to i32
  %xor.5.25 = xor i32 %conv23.5.25, %conv29.5.25
  %scevgep35.5.25 = getelementptr i8, i8* %a, i64 31
  %2320 = load i8, i8* %scevgep35.5.25, align 1
  %2321 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.25 = call zeroext i8 @mult(i8 zeroext %2320, i8 zeroext %2321)
  %conv35.5.25 = zext i8 %call34.5.25 to i32
  %xor36.5.25 = xor i32 %xor.5.25, %conv35.5.25
  %conv37.5.25 = trunc i32 %xor36.5.25 to i8
  store i8 %conv37.5.25, i8* %scevgep41.5.24, align 1
  %scevgep28.5.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2315, i64 0, i64 0, i64 1
  %2322 = bitcast i8* %scevgep28.5.25 to [61 x [61 x i8]]*
  %scevgep41.5.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2316, i64 0, i64 1, i64 0
  %2323 = bitcast i8* %scevgep41.5.25 to [61 x [61 x i8]]*
  %call16.5.26 = call zeroext i8 (...) @rand()
  store i8 %call16.5.26, i8* %scevgep28.5.25, align 1
  %2324 = load i8, i8* %scevgep28.5.25, align 1
  %conv23.5.26 = zext i8 %2324 to i32
  %2325 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.26 = getelementptr i8, i8* %b, i64 32
  %2326 = load i8, i8* %scevgep34.5.26, align 1
  %call28.5.26 = call zeroext i8 @mult(i8 zeroext %2325, i8 zeroext %2326)
  %conv29.5.26 = zext i8 %call28.5.26 to i32
  %xor.5.26 = xor i32 %conv23.5.26, %conv29.5.26
  %scevgep35.5.26 = getelementptr i8, i8* %a, i64 32
  %2327 = load i8, i8* %scevgep35.5.26, align 1
  %2328 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.26 = call zeroext i8 @mult(i8 zeroext %2327, i8 zeroext %2328)
  %conv35.5.26 = zext i8 %call34.5.26 to i32
  %xor36.5.26 = xor i32 %xor.5.26, %conv35.5.26
  %conv37.5.26 = trunc i32 %xor36.5.26 to i8
  store i8 %conv37.5.26, i8* %scevgep41.5.25, align 1
  %scevgep28.5.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2322, i64 0, i64 0, i64 1
  %2329 = bitcast i8* %scevgep28.5.26 to [61 x [61 x i8]]*
  %scevgep41.5.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2323, i64 0, i64 1, i64 0
  %2330 = bitcast i8* %scevgep41.5.26 to [61 x [61 x i8]]*
  %call16.5.27 = call zeroext i8 (...) @rand()
  store i8 %call16.5.27, i8* %scevgep28.5.26, align 1
  %2331 = load i8, i8* %scevgep28.5.26, align 1
  %conv23.5.27 = zext i8 %2331 to i32
  %2332 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.27 = getelementptr i8, i8* %b, i64 33
  %2333 = load i8, i8* %scevgep34.5.27, align 1
  %call28.5.27 = call zeroext i8 @mult(i8 zeroext %2332, i8 zeroext %2333)
  %conv29.5.27 = zext i8 %call28.5.27 to i32
  %xor.5.27 = xor i32 %conv23.5.27, %conv29.5.27
  %scevgep35.5.27 = getelementptr i8, i8* %a, i64 33
  %2334 = load i8, i8* %scevgep35.5.27, align 1
  %2335 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.27 = call zeroext i8 @mult(i8 zeroext %2334, i8 zeroext %2335)
  %conv35.5.27 = zext i8 %call34.5.27 to i32
  %xor36.5.27 = xor i32 %xor.5.27, %conv35.5.27
  %conv37.5.27 = trunc i32 %xor36.5.27 to i8
  store i8 %conv37.5.27, i8* %scevgep41.5.26, align 1
  %scevgep28.5.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2329, i64 0, i64 0, i64 1
  %2336 = bitcast i8* %scevgep28.5.27 to [61 x [61 x i8]]*
  %scevgep41.5.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2330, i64 0, i64 1, i64 0
  %2337 = bitcast i8* %scevgep41.5.27 to [61 x [61 x i8]]*
  %call16.5.28 = call zeroext i8 (...) @rand()
  store i8 %call16.5.28, i8* %scevgep28.5.27, align 1
  %2338 = load i8, i8* %scevgep28.5.27, align 1
  %conv23.5.28 = zext i8 %2338 to i32
  %2339 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.28 = getelementptr i8, i8* %b, i64 34
  %2340 = load i8, i8* %scevgep34.5.28, align 1
  %call28.5.28 = call zeroext i8 @mult(i8 zeroext %2339, i8 zeroext %2340)
  %conv29.5.28 = zext i8 %call28.5.28 to i32
  %xor.5.28 = xor i32 %conv23.5.28, %conv29.5.28
  %scevgep35.5.28 = getelementptr i8, i8* %a, i64 34
  %2341 = load i8, i8* %scevgep35.5.28, align 1
  %2342 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.28 = call zeroext i8 @mult(i8 zeroext %2341, i8 zeroext %2342)
  %conv35.5.28 = zext i8 %call34.5.28 to i32
  %xor36.5.28 = xor i32 %xor.5.28, %conv35.5.28
  %conv37.5.28 = trunc i32 %xor36.5.28 to i8
  store i8 %conv37.5.28, i8* %scevgep41.5.27, align 1
  %scevgep28.5.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2336, i64 0, i64 0, i64 1
  %2343 = bitcast i8* %scevgep28.5.28 to [61 x [61 x i8]]*
  %scevgep41.5.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2337, i64 0, i64 1, i64 0
  %2344 = bitcast i8* %scevgep41.5.28 to [61 x [61 x i8]]*
  %call16.5.29 = call zeroext i8 (...) @rand()
  store i8 %call16.5.29, i8* %scevgep28.5.28, align 1
  %2345 = load i8, i8* %scevgep28.5.28, align 1
  %conv23.5.29 = zext i8 %2345 to i32
  %2346 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.29 = getelementptr i8, i8* %b, i64 35
  %2347 = load i8, i8* %scevgep34.5.29, align 1
  %call28.5.29 = call zeroext i8 @mult(i8 zeroext %2346, i8 zeroext %2347)
  %conv29.5.29 = zext i8 %call28.5.29 to i32
  %xor.5.29 = xor i32 %conv23.5.29, %conv29.5.29
  %scevgep35.5.29 = getelementptr i8, i8* %a, i64 35
  %2348 = load i8, i8* %scevgep35.5.29, align 1
  %2349 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.29 = call zeroext i8 @mult(i8 zeroext %2348, i8 zeroext %2349)
  %conv35.5.29 = zext i8 %call34.5.29 to i32
  %xor36.5.29 = xor i32 %xor.5.29, %conv35.5.29
  %conv37.5.29 = trunc i32 %xor36.5.29 to i8
  store i8 %conv37.5.29, i8* %scevgep41.5.28, align 1
  %scevgep28.5.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2343, i64 0, i64 0, i64 1
  %2350 = bitcast i8* %scevgep28.5.29 to [61 x [61 x i8]]*
  %scevgep41.5.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2344, i64 0, i64 1, i64 0
  %2351 = bitcast i8* %scevgep41.5.29 to [61 x [61 x i8]]*
  %call16.5.30 = call zeroext i8 (...) @rand()
  store i8 %call16.5.30, i8* %scevgep28.5.29, align 1
  %2352 = load i8, i8* %scevgep28.5.29, align 1
  %conv23.5.30 = zext i8 %2352 to i32
  %2353 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.30 = getelementptr i8, i8* %b, i64 36
  %2354 = load i8, i8* %scevgep34.5.30, align 1
  %call28.5.30 = call zeroext i8 @mult(i8 zeroext %2353, i8 zeroext %2354)
  %conv29.5.30 = zext i8 %call28.5.30 to i32
  %xor.5.30 = xor i32 %conv23.5.30, %conv29.5.30
  %scevgep35.5.30 = getelementptr i8, i8* %a, i64 36
  %2355 = load i8, i8* %scevgep35.5.30, align 1
  %2356 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.30 = call zeroext i8 @mult(i8 zeroext %2355, i8 zeroext %2356)
  %conv35.5.30 = zext i8 %call34.5.30 to i32
  %xor36.5.30 = xor i32 %xor.5.30, %conv35.5.30
  %conv37.5.30 = trunc i32 %xor36.5.30 to i8
  store i8 %conv37.5.30, i8* %scevgep41.5.29, align 1
  %scevgep28.5.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2350, i64 0, i64 0, i64 1
  %2357 = bitcast i8* %scevgep28.5.30 to [61 x [61 x i8]]*
  %scevgep41.5.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2351, i64 0, i64 1, i64 0
  %2358 = bitcast i8* %scevgep41.5.30 to [61 x [61 x i8]]*
  %call16.5.31 = call zeroext i8 (...) @rand()
  store i8 %call16.5.31, i8* %scevgep28.5.30, align 1
  %2359 = load i8, i8* %scevgep28.5.30, align 1
  %conv23.5.31 = zext i8 %2359 to i32
  %2360 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.31 = getelementptr i8, i8* %b, i64 37
  %2361 = load i8, i8* %scevgep34.5.31, align 1
  %call28.5.31 = call zeroext i8 @mult(i8 zeroext %2360, i8 zeroext %2361)
  %conv29.5.31 = zext i8 %call28.5.31 to i32
  %xor.5.31 = xor i32 %conv23.5.31, %conv29.5.31
  %scevgep35.5.31 = getelementptr i8, i8* %a, i64 37
  %2362 = load i8, i8* %scevgep35.5.31, align 1
  %2363 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.31 = call zeroext i8 @mult(i8 zeroext %2362, i8 zeroext %2363)
  %conv35.5.31 = zext i8 %call34.5.31 to i32
  %xor36.5.31 = xor i32 %xor.5.31, %conv35.5.31
  %conv37.5.31 = trunc i32 %xor36.5.31 to i8
  store i8 %conv37.5.31, i8* %scevgep41.5.30, align 1
  %scevgep28.5.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2357, i64 0, i64 0, i64 1
  %2364 = bitcast i8* %scevgep28.5.31 to [61 x [61 x i8]]*
  %scevgep41.5.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2358, i64 0, i64 1, i64 0
  %2365 = bitcast i8* %scevgep41.5.31 to [61 x [61 x i8]]*
  %call16.5.32 = call zeroext i8 (...) @rand()
  store i8 %call16.5.32, i8* %scevgep28.5.31, align 1
  %2366 = load i8, i8* %scevgep28.5.31, align 1
  %conv23.5.32 = zext i8 %2366 to i32
  %2367 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.32 = getelementptr i8, i8* %b, i64 38
  %2368 = load i8, i8* %scevgep34.5.32, align 1
  %call28.5.32 = call zeroext i8 @mult(i8 zeroext %2367, i8 zeroext %2368)
  %conv29.5.32 = zext i8 %call28.5.32 to i32
  %xor.5.32 = xor i32 %conv23.5.32, %conv29.5.32
  %scevgep35.5.32 = getelementptr i8, i8* %a, i64 38
  %2369 = load i8, i8* %scevgep35.5.32, align 1
  %2370 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.32 = call zeroext i8 @mult(i8 zeroext %2369, i8 zeroext %2370)
  %conv35.5.32 = zext i8 %call34.5.32 to i32
  %xor36.5.32 = xor i32 %xor.5.32, %conv35.5.32
  %conv37.5.32 = trunc i32 %xor36.5.32 to i8
  store i8 %conv37.5.32, i8* %scevgep41.5.31, align 1
  %scevgep28.5.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2364, i64 0, i64 0, i64 1
  %2371 = bitcast i8* %scevgep28.5.32 to [61 x [61 x i8]]*
  %scevgep41.5.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2365, i64 0, i64 1, i64 0
  %2372 = bitcast i8* %scevgep41.5.32 to [61 x [61 x i8]]*
  %call16.5.33 = call zeroext i8 (...) @rand()
  store i8 %call16.5.33, i8* %scevgep28.5.32, align 1
  %2373 = load i8, i8* %scevgep28.5.32, align 1
  %conv23.5.33 = zext i8 %2373 to i32
  %2374 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.33 = getelementptr i8, i8* %b, i64 39
  %2375 = load i8, i8* %scevgep34.5.33, align 1
  %call28.5.33 = call zeroext i8 @mult(i8 zeroext %2374, i8 zeroext %2375)
  %conv29.5.33 = zext i8 %call28.5.33 to i32
  %xor.5.33 = xor i32 %conv23.5.33, %conv29.5.33
  %scevgep35.5.33 = getelementptr i8, i8* %a, i64 39
  %2376 = load i8, i8* %scevgep35.5.33, align 1
  %2377 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.33 = call zeroext i8 @mult(i8 zeroext %2376, i8 zeroext %2377)
  %conv35.5.33 = zext i8 %call34.5.33 to i32
  %xor36.5.33 = xor i32 %xor.5.33, %conv35.5.33
  %conv37.5.33 = trunc i32 %xor36.5.33 to i8
  store i8 %conv37.5.33, i8* %scevgep41.5.32, align 1
  %scevgep28.5.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2371, i64 0, i64 0, i64 1
  %2378 = bitcast i8* %scevgep28.5.33 to [61 x [61 x i8]]*
  %scevgep41.5.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2372, i64 0, i64 1, i64 0
  %2379 = bitcast i8* %scevgep41.5.33 to [61 x [61 x i8]]*
  %call16.5.34 = call zeroext i8 (...) @rand()
  store i8 %call16.5.34, i8* %scevgep28.5.33, align 1
  %2380 = load i8, i8* %scevgep28.5.33, align 1
  %conv23.5.34 = zext i8 %2380 to i32
  %2381 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.34 = getelementptr i8, i8* %b, i64 40
  %2382 = load i8, i8* %scevgep34.5.34, align 1
  %call28.5.34 = call zeroext i8 @mult(i8 zeroext %2381, i8 zeroext %2382)
  %conv29.5.34 = zext i8 %call28.5.34 to i32
  %xor.5.34 = xor i32 %conv23.5.34, %conv29.5.34
  %scevgep35.5.34 = getelementptr i8, i8* %a, i64 40
  %2383 = load i8, i8* %scevgep35.5.34, align 1
  %2384 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.34 = call zeroext i8 @mult(i8 zeroext %2383, i8 zeroext %2384)
  %conv35.5.34 = zext i8 %call34.5.34 to i32
  %xor36.5.34 = xor i32 %xor.5.34, %conv35.5.34
  %conv37.5.34 = trunc i32 %xor36.5.34 to i8
  store i8 %conv37.5.34, i8* %scevgep41.5.33, align 1
  %scevgep28.5.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2378, i64 0, i64 0, i64 1
  %2385 = bitcast i8* %scevgep28.5.34 to [61 x [61 x i8]]*
  %scevgep41.5.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2379, i64 0, i64 1, i64 0
  %2386 = bitcast i8* %scevgep41.5.34 to [61 x [61 x i8]]*
  %call16.5.35 = call zeroext i8 (...) @rand()
  store i8 %call16.5.35, i8* %scevgep28.5.34, align 1
  %2387 = load i8, i8* %scevgep28.5.34, align 1
  %conv23.5.35 = zext i8 %2387 to i32
  %2388 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.35 = getelementptr i8, i8* %b, i64 41
  %2389 = load i8, i8* %scevgep34.5.35, align 1
  %call28.5.35 = call zeroext i8 @mult(i8 zeroext %2388, i8 zeroext %2389)
  %conv29.5.35 = zext i8 %call28.5.35 to i32
  %xor.5.35 = xor i32 %conv23.5.35, %conv29.5.35
  %scevgep35.5.35 = getelementptr i8, i8* %a, i64 41
  %2390 = load i8, i8* %scevgep35.5.35, align 1
  %2391 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.35 = call zeroext i8 @mult(i8 zeroext %2390, i8 zeroext %2391)
  %conv35.5.35 = zext i8 %call34.5.35 to i32
  %xor36.5.35 = xor i32 %xor.5.35, %conv35.5.35
  %conv37.5.35 = trunc i32 %xor36.5.35 to i8
  store i8 %conv37.5.35, i8* %scevgep41.5.34, align 1
  %scevgep28.5.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2385, i64 0, i64 0, i64 1
  %2392 = bitcast i8* %scevgep28.5.35 to [61 x [61 x i8]]*
  %scevgep41.5.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2386, i64 0, i64 1, i64 0
  %2393 = bitcast i8* %scevgep41.5.35 to [61 x [61 x i8]]*
  %call16.5.36 = call zeroext i8 (...) @rand()
  store i8 %call16.5.36, i8* %scevgep28.5.35, align 1
  %2394 = load i8, i8* %scevgep28.5.35, align 1
  %conv23.5.36 = zext i8 %2394 to i32
  %2395 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.36 = getelementptr i8, i8* %b, i64 42
  %2396 = load i8, i8* %scevgep34.5.36, align 1
  %call28.5.36 = call zeroext i8 @mult(i8 zeroext %2395, i8 zeroext %2396)
  %conv29.5.36 = zext i8 %call28.5.36 to i32
  %xor.5.36 = xor i32 %conv23.5.36, %conv29.5.36
  %scevgep35.5.36 = getelementptr i8, i8* %a, i64 42
  %2397 = load i8, i8* %scevgep35.5.36, align 1
  %2398 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.36 = call zeroext i8 @mult(i8 zeroext %2397, i8 zeroext %2398)
  %conv35.5.36 = zext i8 %call34.5.36 to i32
  %xor36.5.36 = xor i32 %xor.5.36, %conv35.5.36
  %conv37.5.36 = trunc i32 %xor36.5.36 to i8
  store i8 %conv37.5.36, i8* %scevgep41.5.35, align 1
  %scevgep28.5.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2392, i64 0, i64 0, i64 1
  %2399 = bitcast i8* %scevgep28.5.36 to [61 x [61 x i8]]*
  %scevgep41.5.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2393, i64 0, i64 1, i64 0
  %2400 = bitcast i8* %scevgep41.5.36 to [61 x [61 x i8]]*
  %call16.5.37 = call zeroext i8 (...) @rand()
  store i8 %call16.5.37, i8* %scevgep28.5.36, align 1
  %2401 = load i8, i8* %scevgep28.5.36, align 1
  %conv23.5.37 = zext i8 %2401 to i32
  %2402 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.37 = getelementptr i8, i8* %b, i64 43
  %2403 = load i8, i8* %scevgep34.5.37, align 1
  %call28.5.37 = call zeroext i8 @mult(i8 zeroext %2402, i8 zeroext %2403)
  %conv29.5.37 = zext i8 %call28.5.37 to i32
  %xor.5.37 = xor i32 %conv23.5.37, %conv29.5.37
  %scevgep35.5.37 = getelementptr i8, i8* %a, i64 43
  %2404 = load i8, i8* %scevgep35.5.37, align 1
  %2405 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.37 = call zeroext i8 @mult(i8 zeroext %2404, i8 zeroext %2405)
  %conv35.5.37 = zext i8 %call34.5.37 to i32
  %xor36.5.37 = xor i32 %xor.5.37, %conv35.5.37
  %conv37.5.37 = trunc i32 %xor36.5.37 to i8
  store i8 %conv37.5.37, i8* %scevgep41.5.36, align 1
  %scevgep28.5.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2399, i64 0, i64 0, i64 1
  %2406 = bitcast i8* %scevgep28.5.37 to [61 x [61 x i8]]*
  %scevgep41.5.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2400, i64 0, i64 1, i64 0
  %2407 = bitcast i8* %scevgep41.5.37 to [61 x [61 x i8]]*
  %call16.5.38 = call zeroext i8 (...) @rand()
  store i8 %call16.5.38, i8* %scevgep28.5.37, align 1
  %2408 = load i8, i8* %scevgep28.5.37, align 1
  %conv23.5.38 = zext i8 %2408 to i32
  %2409 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.38 = getelementptr i8, i8* %b, i64 44
  %2410 = load i8, i8* %scevgep34.5.38, align 1
  %call28.5.38 = call zeroext i8 @mult(i8 zeroext %2409, i8 zeroext %2410)
  %conv29.5.38 = zext i8 %call28.5.38 to i32
  %xor.5.38 = xor i32 %conv23.5.38, %conv29.5.38
  %scevgep35.5.38 = getelementptr i8, i8* %a, i64 44
  %2411 = load i8, i8* %scevgep35.5.38, align 1
  %2412 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.38 = call zeroext i8 @mult(i8 zeroext %2411, i8 zeroext %2412)
  %conv35.5.38 = zext i8 %call34.5.38 to i32
  %xor36.5.38 = xor i32 %xor.5.38, %conv35.5.38
  %conv37.5.38 = trunc i32 %xor36.5.38 to i8
  store i8 %conv37.5.38, i8* %scevgep41.5.37, align 1
  %scevgep28.5.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2406, i64 0, i64 0, i64 1
  %2413 = bitcast i8* %scevgep28.5.38 to [61 x [61 x i8]]*
  %scevgep41.5.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2407, i64 0, i64 1, i64 0
  %2414 = bitcast i8* %scevgep41.5.38 to [61 x [61 x i8]]*
  %call16.5.39 = call zeroext i8 (...) @rand()
  store i8 %call16.5.39, i8* %scevgep28.5.38, align 1
  %2415 = load i8, i8* %scevgep28.5.38, align 1
  %conv23.5.39 = zext i8 %2415 to i32
  %2416 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.39 = getelementptr i8, i8* %b, i64 45
  %2417 = load i8, i8* %scevgep34.5.39, align 1
  %call28.5.39 = call zeroext i8 @mult(i8 zeroext %2416, i8 zeroext %2417)
  %conv29.5.39 = zext i8 %call28.5.39 to i32
  %xor.5.39 = xor i32 %conv23.5.39, %conv29.5.39
  %scevgep35.5.39 = getelementptr i8, i8* %a, i64 45
  %2418 = load i8, i8* %scevgep35.5.39, align 1
  %2419 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.39 = call zeroext i8 @mult(i8 zeroext %2418, i8 zeroext %2419)
  %conv35.5.39 = zext i8 %call34.5.39 to i32
  %xor36.5.39 = xor i32 %xor.5.39, %conv35.5.39
  %conv37.5.39 = trunc i32 %xor36.5.39 to i8
  store i8 %conv37.5.39, i8* %scevgep41.5.38, align 1
  %scevgep28.5.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2413, i64 0, i64 0, i64 1
  %2420 = bitcast i8* %scevgep28.5.39 to [61 x [61 x i8]]*
  %scevgep41.5.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2414, i64 0, i64 1, i64 0
  %2421 = bitcast i8* %scevgep41.5.39 to [61 x [61 x i8]]*
  %call16.5.40 = call zeroext i8 (...) @rand()
  store i8 %call16.5.40, i8* %scevgep28.5.39, align 1
  %2422 = load i8, i8* %scevgep28.5.39, align 1
  %conv23.5.40 = zext i8 %2422 to i32
  %2423 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.40 = getelementptr i8, i8* %b, i64 46
  %2424 = load i8, i8* %scevgep34.5.40, align 1
  %call28.5.40 = call zeroext i8 @mult(i8 zeroext %2423, i8 zeroext %2424)
  %conv29.5.40 = zext i8 %call28.5.40 to i32
  %xor.5.40 = xor i32 %conv23.5.40, %conv29.5.40
  %scevgep35.5.40 = getelementptr i8, i8* %a, i64 46
  %2425 = load i8, i8* %scevgep35.5.40, align 1
  %2426 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.40 = call zeroext i8 @mult(i8 zeroext %2425, i8 zeroext %2426)
  %conv35.5.40 = zext i8 %call34.5.40 to i32
  %xor36.5.40 = xor i32 %xor.5.40, %conv35.5.40
  %conv37.5.40 = trunc i32 %xor36.5.40 to i8
  store i8 %conv37.5.40, i8* %scevgep41.5.39, align 1
  %scevgep28.5.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2420, i64 0, i64 0, i64 1
  %2427 = bitcast i8* %scevgep28.5.40 to [61 x [61 x i8]]*
  %scevgep41.5.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2421, i64 0, i64 1, i64 0
  %2428 = bitcast i8* %scevgep41.5.40 to [61 x [61 x i8]]*
  %call16.5.41 = call zeroext i8 (...) @rand()
  store i8 %call16.5.41, i8* %scevgep28.5.40, align 1
  %2429 = load i8, i8* %scevgep28.5.40, align 1
  %conv23.5.41 = zext i8 %2429 to i32
  %2430 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.41 = getelementptr i8, i8* %b, i64 47
  %2431 = load i8, i8* %scevgep34.5.41, align 1
  %call28.5.41 = call zeroext i8 @mult(i8 zeroext %2430, i8 zeroext %2431)
  %conv29.5.41 = zext i8 %call28.5.41 to i32
  %xor.5.41 = xor i32 %conv23.5.41, %conv29.5.41
  %scevgep35.5.41 = getelementptr i8, i8* %a, i64 47
  %2432 = load i8, i8* %scevgep35.5.41, align 1
  %2433 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.41 = call zeroext i8 @mult(i8 zeroext %2432, i8 zeroext %2433)
  %conv35.5.41 = zext i8 %call34.5.41 to i32
  %xor36.5.41 = xor i32 %xor.5.41, %conv35.5.41
  %conv37.5.41 = trunc i32 %xor36.5.41 to i8
  store i8 %conv37.5.41, i8* %scevgep41.5.40, align 1
  %scevgep28.5.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2427, i64 0, i64 0, i64 1
  %2434 = bitcast i8* %scevgep28.5.41 to [61 x [61 x i8]]*
  %scevgep41.5.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2428, i64 0, i64 1, i64 0
  %2435 = bitcast i8* %scevgep41.5.41 to [61 x [61 x i8]]*
  %call16.5.42 = call zeroext i8 (...) @rand()
  store i8 %call16.5.42, i8* %scevgep28.5.41, align 1
  %2436 = load i8, i8* %scevgep28.5.41, align 1
  %conv23.5.42 = zext i8 %2436 to i32
  %2437 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.42 = getelementptr i8, i8* %b, i64 48
  %2438 = load i8, i8* %scevgep34.5.42, align 1
  %call28.5.42 = call zeroext i8 @mult(i8 zeroext %2437, i8 zeroext %2438)
  %conv29.5.42 = zext i8 %call28.5.42 to i32
  %xor.5.42 = xor i32 %conv23.5.42, %conv29.5.42
  %scevgep35.5.42 = getelementptr i8, i8* %a, i64 48
  %2439 = load i8, i8* %scevgep35.5.42, align 1
  %2440 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.42 = call zeroext i8 @mult(i8 zeroext %2439, i8 zeroext %2440)
  %conv35.5.42 = zext i8 %call34.5.42 to i32
  %xor36.5.42 = xor i32 %xor.5.42, %conv35.5.42
  %conv37.5.42 = trunc i32 %xor36.5.42 to i8
  store i8 %conv37.5.42, i8* %scevgep41.5.41, align 1
  %scevgep28.5.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2434, i64 0, i64 0, i64 1
  %2441 = bitcast i8* %scevgep28.5.42 to [61 x [61 x i8]]*
  %scevgep41.5.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2435, i64 0, i64 1, i64 0
  %2442 = bitcast i8* %scevgep41.5.42 to [61 x [61 x i8]]*
  %call16.5.43 = call zeroext i8 (...) @rand()
  store i8 %call16.5.43, i8* %scevgep28.5.42, align 1
  %2443 = load i8, i8* %scevgep28.5.42, align 1
  %conv23.5.43 = zext i8 %2443 to i32
  %2444 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.43 = getelementptr i8, i8* %b, i64 49
  %2445 = load i8, i8* %scevgep34.5.43, align 1
  %call28.5.43 = call zeroext i8 @mult(i8 zeroext %2444, i8 zeroext %2445)
  %conv29.5.43 = zext i8 %call28.5.43 to i32
  %xor.5.43 = xor i32 %conv23.5.43, %conv29.5.43
  %scevgep35.5.43 = getelementptr i8, i8* %a, i64 49
  %2446 = load i8, i8* %scevgep35.5.43, align 1
  %2447 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.43 = call zeroext i8 @mult(i8 zeroext %2446, i8 zeroext %2447)
  %conv35.5.43 = zext i8 %call34.5.43 to i32
  %xor36.5.43 = xor i32 %xor.5.43, %conv35.5.43
  %conv37.5.43 = trunc i32 %xor36.5.43 to i8
  store i8 %conv37.5.43, i8* %scevgep41.5.42, align 1
  %scevgep28.5.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2441, i64 0, i64 0, i64 1
  %2448 = bitcast i8* %scevgep28.5.43 to [61 x [61 x i8]]*
  %scevgep41.5.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2442, i64 0, i64 1, i64 0
  %2449 = bitcast i8* %scevgep41.5.43 to [61 x [61 x i8]]*
  %call16.5.44 = call zeroext i8 (...) @rand()
  store i8 %call16.5.44, i8* %scevgep28.5.43, align 1
  %2450 = load i8, i8* %scevgep28.5.43, align 1
  %conv23.5.44 = zext i8 %2450 to i32
  %2451 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.44 = getelementptr i8, i8* %b, i64 50
  %2452 = load i8, i8* %scevgep34.5.44, align 1
  %call28.5.44 = call zeroext i8 @mult(i8 zeroext %2451, i8 zeroext %2452)
  %conv29.5.44 = zext i8 %call28.5.44 to i32
  %xor.5.44 = xor i32 %conv23.5.44, %conv29.5.44
  %scevgep35.5.44 = getelementptr i8, i8* %a, i64 50
  %2453 = load i8, i8* %scevgep35.5.44, align 1
  %2454 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.44 = call zeroext i8 @mult(i8 zeroext %2453, i8 zeroext %2454)
  %conv35.5.44 = zext i8 %call34.5.44 to i32
  %xor36.5.44 = xor i32 %xor.5.44, %conv35.5.44
  %conv37.5.44 = trunc i32 %xor36.5.44 to i8
  store i8 %conv37.5.44, i8* %scevgep41.5.43, align 1
  %scevgep28.5.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2448, i64 0, i64 0, i64 1
  %2455 = bitcast i8* %scevgep28.5.44 to [61 x [61 x i8]]*
  %scevgep41.5.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2449, i64 0, i64 1, i64 0
  %2456 = bitcast i8* %scevgep41.5.44 to [61 x [61 x i8]]*
  %call16.5.45 = call zeroext i8 (...) @rand()
  store i8 %call16.5.45, i8* %scevgep28.5.44, align 1
  %2457 = load i8, i8* %scevgep28.5.44, align 1
  %conv23.5.45 = zext i8 %2457 to i32
  %2458 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.45 = getelementptr i8, i8* %b, i64 51
  %2459 = load i8, i8* %scevgep34.5.45, align 1
  %call28.5.45 = call zeroext i8 @mult(i8 zeroext %2458, i8 zeroext %2459)
  %conv29.5.45 = zext i8 %call28.5.45 to i32
  %xor.5.45 = xor i32 %conv23.5.45, %conv29.5.45
  %scevgep35.5.45 = getelementptr i8, i8* %a, i64 51
  %2460 = load i8, i8* %scevgep35.5.45, align 1
  %2461 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.45 = call zeroext i8 @mult(i8 zeroext %2460, i8 zeroext %2461)
  %conv35.5.45 = zext i8 %call34.5.45 to i32
  %xor36.5.45 = xor i32 %xor.5.45, %conv35.5.45
  %conv37.5.45 = trunc i32 %xor36.5.45 to i8
  store i8 %conv37.5.45, i8* %scevgep41.5.44, align 1
  %scevgep28.5.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2455, i64 0, i64 0, i64 1
  %2462 = bitcast i8* %scevgep28.5.45 to [61 x [61 x i8]]*
  %scevgep41.5.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2456, i64 0, i64 1, i64 0
  %2463 = bitcast i8* %scevgep41.5.45 to [61 x [61 x i8]]*
  %call16.5.46 = call zeroext i8 (...) @rand()
  store i8 %call16.5.46, i8* %scevgep28.5.45, align 1
  %2464 = load i8, i8* %scevgep28.5.45, align 1
  %conv23.5.46 = zext i8 %2464 to i32
  %2465 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.46 = getelementptr i8, i8* %b, i64 52
  %2466 = load i8, i8* %scevgep34.5.46, align 1
  %call28.5.46 = call zeroext i8 @mult(i8 zeroext %2465, i8 zeroext %2466)
  %conv29.5.46 = zext i8 %call28.5.46 to i32
  %xor.5.46 = xor i32 %conv23.5.46, %conv29.5.46
  %scevgep35.5.46 = getelementptr i8, i8* %a, i64 52
  %2467 = load i8, i8* %scevgep35.5.46, align 1
  %2468 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.46 = call zeroext i8 @mult(i8 zeroext %2467, i8 zeroext %2468)
  %conv35.5.46 = zext i8 %call34.5.46 to i32
  %xor36.5.46 = xor i32 %xor.5.46, %conv35.5.46
  %conv37.5.46 = trunc i32 %xor36.5.46 to i8
  store i8 %conv37.5.46, i8* %scevgep41.5.45, align 1
  %scevgep28.5.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2462, i64 0, i64 0, i64 1
  %2469 = bitcast i8* %scevgep28.5.46 to [61 x [61 x i8]]*
  %scevgep41.5.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2463, i64 0, i64 1, i64 0
  %2470 = bitcast i8* %scevgep41.5.46 to [61 x [61 x i8]]*
  %call16.5.47 = call zeroext i8 (...) @rand()
  store i8 %call16.5.47, i8* %scevgep28.5.46, align 1
  %2471 = load i8, i8* %scevgep28.5.46, align 1
  %conv23.5.47 = zext i8 %2471 to i32
  %2472 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.47 = getelementptr i8, i8* %b, i64 53
  %2473 = load i8, i8* %scevgep34.5.47, align 1
  %call28.5.47 = call zeroext i8 @mult(i8 zeroext %2472, i8 zeroext %2473)
  %conv29.5.47 = zext i8 %call28.5.47 to i32
  %xor.5.47 = xor i32 %conv23.5.47, %conv29.5.47
  %scevgep35.5.47 = getelementptr i8, i8* %a, i64 53
  %2474 = load i8, i8* %scevgep35.5.47, align 1
  %2475 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.47 = call zeroext i8 @mult(i8 zeroext %2474, i8 zeroext %2475)
  %conv35.5.47 = zext i8 %call34.5.47 to i32
  %xor36.5.47 = xor i32 %xor.5.47, %conv35.5.47
  %conv37.5.47 = trunc i32 %xor36.5.47 to i8
  store i8 %conv37.5.47, i8* %scevgep41.5.46, align 1
  %scevgep28.5.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2469, i64 0, i64 0, i64 1
  %2476 = bitcast i8* %scevgep28.5.47 to [61 x [61 x i8]]*
  %scevgep41.5.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2470, i64 0, i64 1, i64 0
  %2477 = bitcast i8* %scevgep41.5.47 to [61 x [61 x i8]]*
  %call16.5.48 = call zeroext i8 (...) @rand()
  store i8 %call16.5.48, i8* %scevgep28.5.47, align 1
  %2478 = load i8, i8* %scevgep28.5.47, align 1
  %conv23.5.48 = zext i8 %2478 to i32
  %2479 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.48 = getelementptr i8, i8* %b, i64 54
  %2480 = load i8, i8* %scevgep34.5.48, align 1
  %call28.5.48 = call zeroext i8 @mult(i8 zeroext %2479, i8 zeroext %2480)
  %conv29.5.48 = zext i8 %call28.5.48 to i32
  %xor.5.48 = xor i32 %conv23.5.48, %conv29.5.48
  %scevgep35.5.48 = getelementptr i8, i8* %a, i64 54
  %2481 = load i8, i8* %scevgep35.5.48, align 1
  %2482 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.48 = call zeroext i8 @mult(i8 zeroext %2481, i8 zeroext %2482)
  %conv35.5.48 = zext i8 %call34.5.48 to i32
  %xor36.5.48 = xor i32 %xor.5.48, %conv35.5.48
  %conv37.5.48 = trunc i32 %xor36.5.48 to i8
  store i8 %conv37.5.48, i8* %scevgep41.5.47, align 1
  %scevgep28.5.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2476, i64 0, i64 0, i64 1
  %2483 = bitcast i8* %scevgep28.5.48 to [61 x [61 x i8]]*
  %scevgep41.5.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2477, i64 0, i64 1, i64 0
  %2484 = bitcast i8* %scevgep41.5.48 to [61 x [61 x i8]]*
  %call16.5.49 = call zeroext i8 (...) @rand()
  store i8 %call16.5.49, i8* %scevgep28.5.48, align 1
  %2485 = load i8, i8* %scevgep28.5.48, align 1
  %conv23.5.49 = zext i8 %2485 to i32
  %2486 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.49 = getelementptr i8, i8* %b, i64 55
  %2487 = load i8, i8* %scevgep34.5.49, align 1
  %call28.5.49 = call zeroext i8 @mult(i8 zeroext %2486, i8 zeroext %2487)
  %conv29.5.49 = zext i8 %call28.5.49 to i32
  %xor.5.49 = xor i32 %conv23.5.49, %conv29.5.49
  %scevgep35.5.49 = getelementptr i8, i8* %a, i64 55
  %2488 = load i8, i8* %scevgep35.5.49, align 1
  %2489 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.49 = call zeroext i8 @mult(i8 zeroext %2488, i8 zeroext %2489)
  %conv35.5.49 = zext i8 %call34.5.49 to i32
  %xor36.5.49 = xor i32 %xor.5.49, %conv35.5.49
  %conv37.5.49 = trunc i32 %xor36.5.49 to i8
  store i8 %conv37.5.49, i8* %scevgep41.5.48, align 1
  %scevgep28.5.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2483, i64 0, i64 0, i64 1
  %2490 = bitcast i8* %scevgep28.5.49 to [61 x [61 x i8]]*
  %scevgep41.5.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2484, i64 0, i64 1, i64 0
  %2491 = bitcast i8* %scevgep41.5.49 to [61 x [61 x i8]]*
  %call16.5.50 = call zeroext i8 (...) @rand()
  store i8 %call16.5.50, i8* %scevgep28.5.49, align 1
  %2492 = load i8, i8* %scevgep28.5.49, align 1
  %conv23.5.50 = zext i8 %2492 to i32
  %2493 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.50 = getelementptr i8, i8* %b, i64 56
  %2494 = load i8, i8* %scevgep34.5.50, align 1
  %call28.5.50 = call zeroext i8 @mult(i8 zeroext %2493, i8 zeroext %2494)
  %conv29.5.50 = zext i8 %call28.5.50 to i32
  %xor.5.50 = xor i32 %conv23.5.50, %conv29.5.50
  %scevgep35.5.50 = getelementptr i8, i8* %a, i64 56
  %2495 = load i8, i8* %scevgep35.5.50, align 1
  %2496 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.50 = call zeroext i8 @mult(i8 zeroext %2495, i8 zeroext %2496)
  %conv35.5.50 = zext i8 %call34.5.50 to i32
  %xor36.5.50 = xor i32 %xor.5.50, %conv35.5.50
  %conv37.5.50 = trunc i32 %xor36.5.50 to i8
  store i8 %conv37.5.50, i8* %scevgep41.5.49, align 1
  %scevgep28.5.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2490, i64 0, i64 0, i64 1
  %2497 = bitcast i8* %scevgep28.5.50 to [61 x [61 x i8]]*
  %scevgep41.5.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2491, i64 0, i64 1, i64 0
  %2498 = bitcast i8* %scevgep41.5.50 to [61 x [61 x i8]]*
  %call16.5.51 = call zeroext i8 (...) @rand()
  store i8 %call16.5.51, i8* %scevgep28.5.50, align 1
  %2499 = load i8, i8* %scevgep28.5.50, align 1
  %conv23.5.51 = zext i8 %2499 to i32
  %2500 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.51 = getelementptr i8, i8* %b, i64 57
  %2501 = load i8, i8* %scevgep34.5.51, align 1
  %call28.5.51 = call zeroext i8 @mult(i8 zeroext %2500, i8 zeroext %2501)
  %conv29.5.51 = zext i8 %call28.5.51 to i32
  %xor.5.51 = xor i32 %conv23.5.51, %conv29.5.51
  %scevgep35.5.51 = getelementptr i8, i8* %a, i64 57
  %2502 = load i8, i8* %scevgep35.5.51, align 1
  %2503 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.51 = call zeroext i8 @mult(i8 zeroext %2502, i8 zeroext %2503)
  %conv35.5.51 = zext i8 %call34.5.51 to i32
  %xor36.5.51 = xor i32 %xor.5.51, %conv35.5.51
  %conv37.5.51 = trunc i32 %xor36.5.51 to i8
  store i8 %conv37.5.51, i8* %scevgep41.5.50, align 1
  %scevgep28.5.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2497, i64 0, i64 0, i64 1
  %2504 = bitcast i8* %scevgep28.5.51 to [61 x [61 x i8]]*
  %scevgep41.5.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2498, i64 0, i64 1, i64 0
  %2505 = bitcast i8* %scevgep41.5.51 to [61 x [61 x i8]]*
  %call16.5.52 = call zeroext i8 (...) @rand()
  store i8 %call16.5.52, i8* %scevgep28.5.51, align 1
  %2506 = load i8, i8* %scevgep28.5.51, align 1
  %conv23.5.52 = zext i8 %2506 to i32
  %2507 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.52 = getelementptr i8, i8* %b, i64 58
  %2508 = load i8, i8* %scevgep34.5.52, align 1
  %call28.5.52 = call zeroext i8 @mult(i8 zeroext %2507, i8 zeroext %2508)
  %conv29.5.52 = zext i8 %call28.5.52 to i32
  %xor.5.52 = xor i32 %conv23.5.52, %conv29.5.52
  %scevgep35.5.52 = getelementptr i8, i8* %a, i64 58
  %2509 = load i8, i8* %scevgep35.5.52, align 1
  %2510 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.52 = call zeroext i8 @mult(i8 zeroext %2509, i8 zeroext %2510)
  %conv35.5.52 = zext i8 %call34.5.52 to i32
  %xor36.5.52 = xor i32 %xor.5.52, %conv35.5.52
  %conv37.5.52 = trunc i32 %xor36.5.52 to i8
  store i8 %conv37.5.52, i8* %scevgep41.5.51, align 1
  %scevgep28.5.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2504, i64 0, i64 0, i64 1
  %2511 = bitcast i8* %scevgep28.5.52 to [61 x [61 x i8]]*
  %scevgep41.5.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2505, i64 0, i64 1, i64 0
  %2512 = bitcast i8* %scevgep41.5.52 to [61 x [61 x i8]]*
  %call16.5.53 = call zeroext i8 (...) @rand()
  store i8 %call16.5.53, i8* %scevgep28.5.52, align 1
  %2513 = load i8, i8* %scevgep28.5.52, align 1
  %conv23.5.53 = zext i8 %2513 to i32
  %2514 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.53 = getelementptr i8, i8* %b, i64 59
  %2515 = load i8, i8* %scevgep34.5.53, align 1
  %call28.5.53 = call zeroext i8 @mult(i8 zeroext %2514, i8 zeroext %2515)
  %conv29.5.53 = zext i8 %call28.5.53 to i32
  %xor.5.53 = xor i32 %conv23.5.53, %conv29.5.53
  %scevgep35.5.53 = getelementptr i8, i8* %a, i64 59
  %2516 = load i8, i8* %scevgep35.5.53, align 1
  %2517 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.53 = call zeroext i8 @mult(i8 zeroext %2516, i8 zeroext %2517)
  %conv35.5.53 = zext i8 %call34.5.53 to i32
  %xor36.5.53 = xor i32 %xor.5.53, %conv35.5.53
  %conv37.5.53 = trunc i32 %xor36.5.53 to i8
  store i8 %conv37.5.53, i8* %scevgep41.5.52, align 1
  %scevgep28.5.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2511, i64 0, i64 0, i64 1
  %scevgep41.5.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2512, i64 0, i64 1, i64 0
  %call16.5.54 = call zeroext i8 (...) @rand()
  store i8 %call16.5.54, i8* %scevgep28.5.53, align 1
  %2518 = load i8, i8* %scevgep28.5.53, align 1
  %conv23.5.54 = zext i8 %2518 to i32
  %2519 = load i8, i8* %arrayidx25.5, align 1
  %scevgep34.5.54 = getelementptr i8, i8* %b, i64 60
  %2520 = load i8, i8* %scevgep34.5.54, align 1
  %call28.5.54 = call zeroext i8 @mult(i8 zeroext %2519, i8 zeroext %2520)
  %conv29.5.54 = zext i8 %call28.5.54 to i32
  %xor.5.54 = xor i32 %conv23.5.54, %conv29.5.54
  %scevgep35.5.54 = getelementptr i8, i8* %a, i64 60
  %2521 = load i8, i8* %scevgep35.5.54, align 1
  %2522 = load i8, i8* %arrayidx33.5, align 1
  %call34.5.54 = call zeroext i8 @mult(i8 zeroext %2521, i8 zeroext %2522)
  %conv35.5.54 = zext i8 %call34.5.54 to i32
  %xor36.5.54 = xor i32 %xor.5.54, %conv35.5.54
  %conv37.5.54 = trunc i32 %xor36.5.54 to i8
  store i8 %conv37.5.54, i8* %scevgep41.5.53, align 1
  %scevgep26.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2140, i64 0, i64 1, i64 1
  %2523 = bitcast i8* %scevgep26.5 to [61 x [61 x i8]]*
  %scevgep39.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2141, i64 0, i64 1, i64 1
  %2524 = bitcast i8* %scevgep39.5 to [61 x [61 x i8]]*
  %arrayidx25.6 = getelementptr inbounds i8, i8* %a, i64 6
  %arrayidx33.6 = getelementptr inbounds i8, i8* %b, i64 6
  %call16.6 = call zeroext i8 (...) @rand()
  store i8 %call16.6, i8* %scevgep26.5, align 1
  %2525 = load i8, i8* %scevgep26.5, align 1
  %conv23.6 = zext i8 %2525 to i32
  %2526 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6 = getelementptr i8, i8* %b, i64 7
  %2527 = load i8, i8* %scevgep34.6, align 1
  %call28.6 = call zeroext i8 @mult(i8 zeroext %2526, i8 zeroext %2527)
  %conv29.6 = zext i8 %call28.6 to i32
  %xor.6 = xor i32 %conv23.6, %conv29.6
  %scevgep35.6 = getelementptr i8, i8* %a, i64 7
  %2528 = load i8, i8* %scevgep35.6, align 1
  %2529 = load i8, i8* %arrayidx33.6, align 1
  %call34.6 = call zeroext i8 @mult(i8 zeroext %2528, i8 zeroext %2529)
  %conv35.6 = zext i8 %call34.6 to i32
  %xor36.6 = xor i32 %xor.6, %conv35.6
  %conv37.6 = trunc i32 %xor36.6 to i8
  store i8 %conv37.6, i8* %scevgep39.5, align 1
  %scevgep28.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2523, i64 0, i64 0, i64 1
  %2530 = bitcast i8* %scevgep28.6 to [61 x [61 x i8]]*
  %scevgep41.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2524, i64 0, i64 1, i64 0
  %2531 = bitcast i8* %scevgep41.6 to [61 x [61 x i8]]*
  %call16.6.1 = call zeroext i8 (...) @rand()
  store i8 %call16.6.1, i8* %scevgep28.6, align 1
  %2532 = load i8, i8* %scevgep28.6, align 1
  %conv23.6.1 = zext i8 %2532 to i32
  %2533 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.1 = getelementptr i8, i8* %b, i64 8
  %2534 = load i8, i8* %scevgep34.6.1, align 1
  %call28.6.1 = call zeroext i8 @mult(i8 zeroext %2533, i8 zeroext %2534)
  %conv29.6.1 = zext i8 %call28.6.1 to i32
  %xor.6.1 = xor i32 %conv23.6.1, %conv29.6.1
  %scevgep35.6.1 = getelementptr i8, i8* %a, i64 8
  %2535 = load i8, i8* %scevgep35.6.1, align 1
  %2536 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.1 = call zeroext i8 @mult(i8 zeroext %2535, i8 zeroext %2536)
  %conv35.6.1 = zext i8 %call34.6.1 to i32
  %xor36.6.1 = xor i32 %xor.6.1, %conv35.6.1
  %conv37.6.1 = trunc i32 %xor36.6.1 to i8
  store i8 %conv37.6.1, i8* %scevgep41.6, align 1
  %scevgep28.6.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2530, i64 0, i64 0, i64 1
  %2537 = bitcast i8* %scevgep28.6.1 to [61 x [61 x i8]]*
  %scevgep41.6.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2531, i64 0, i64 1, i64 0
  %2538 = bitcast i8* %scevgep41.6.1 to [61 x [61 x i8]]*
  %call16.6.2 = call zeroext i8 (...) @rand()
  store i8 %call16.6.2, i8* %scevgep28.6.1, align 1
  %2539 = load i8, i8* %scevgep28.6.1, align 1
  %conv23.6.2 = zext i8 %2539 to i32
  %2540 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.2 = getelementptr i8, i8* %b, i64 9
  %2541 = load i8, i8* %scevgep34.6.2, align 1
  %call28.6.2 = call zeroext i8 @mult(i8 zeroext %2540, i8 zeroext %2541)
  %conv29.6.2 = zext i8 %call28.6.2 to i32
  %xor.6.2 = xor i32 %conv23.6.2, %conv29.6.2
  %scevgep35.6.2 = getelementptr i8, i8* %a, i64 9
  %2542 = load i8, i8* %scevgep35.6.2, align 1
  %2543 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.2 = call zeroext i8 @mult(i8 zeroext %2542, i8 zeroext %2543)
  %conv35.6.2 = zext i8 %call34.6.2 to i32
  %xor36.6.2 = xor i32 %xor.6.2, %conv35.6.2
  %conv37.6.2 = trunc i32 %xor36.6.2 to i8
  store i8 %conv37.6.2, i8* %scevgep41.6.1, align 1
  %scevgep28.6.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2537, i64 0, i64 0, i64 1
  %2544 = bitcast i8* %scevgep28.6.2 to [61 x [61 x i8]]*
  %scevgep41.6.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2538, i64 0, i64 1, i64 0
  %2545 = bitcast i8* %scevgep41.6.2 to [61 x [61 x i8]]*
  %call16.6.3 = call zeroext i8 (...) @rand()
  store i8 %call16.6.3, i8* %scevgep28.6.2, align 1
  %2546 = load i8, i8* %scevgep28.6.2, align 1
  %conv23.6.3 = zext i8 %2546 to i32
  %2547 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.3 = getelementptr i8, i8* %b, i64 10
  %2548 = load i8, i8* %scevgep34.6.3, align 1
  %call28.6.3 = call zeroext i8 @mult(i8 zeroext %2547, i8 zeroext %2548)
  %conv29.6.3 = zext i8 %call28.6.3 to i32
  %xor.6.3 = xor i32 %conv23.6.3, %conv29.6.3
  %scevgep35.6.3 = getelementptr i8, i8* %a, i64 10
  %2549 = load i8, i8* %scevgep35.6.3, align 1
  %2550 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.3 = call zeroext i8 @mult(i8 zeroext %2549, i8 zeroext %2550)
  %conv35.6.3 = zext i8 %call34.6.3 to i32
  %xor36.6.3 = xor i32 %xor.6.3, %conv35.6.3
  %conv37.6.3 = trunc i32 %xor36.6.3 to i8
  store i8 %conv37.6.3, i8* %scevgep41.6.2, align 1
  %scevgep28.6.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2544, i64 0, i64 0, i64 1
  %2551 = bitcast i8* %scevgep28.6.3 to [61 x [61 x i8]]*
  %scevgep41.6.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2545, i64 0, i64 1, i64 0
  %2552 = bitcast i8* %scevgep41.6.3 to [61 x [61 x i8]]*
  %call16.6.4 = call zeroext i8 (...) @rand()
  store i8 %call16.6.4, i8* %scevgep28.6.3, align 1
  %2553 = load i8, i8* %scevgep28.6.3, align 1
  %conv23.6.4 = zext i8 %2553 to i32
  %2554 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.4 = getelementptr i8, i8* %b, i64 11
  %2555 = load i8, i8* %scevgep34.6.4, align 1
  %call28.6.4 = call zeroext i8 @mult(i8 zeroext %2554, i8 zeroext %2555)
  %conv29.6.4 = zext i8 %call28.6.4 to i32
  %xor.6.4 = xor i32 %conv23.6.4, %conv29.6.4
  %scevgep35.6.4 = getelementptr i8, i8* %a, i64 11
  %2556 = load i8, i8* %scevgep35.6.4, align 1
  %2557 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.4 = call zeroext i8 @mult(i8 zeroext %2556, i8 zeroext %2557)
  %conv35.6.4 = zext i8 %call34.6.4 to i32
  %xor36.6.4 = xor i32 %xor.6.4, %conv35.6.4
  %conv37.6.4 = trunc i32 %xor36.6.4 to i8
  store i8 %conv37.6.4, i8* %scevgep41.6.3, align 1
  %scevgep28.6.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2551, i64 0, i64 0, i64 1
  %2558 = bitcast i8* %scevgep28.6.4 to [61 x [61 x i8]]*
  %scevgep41.6.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2552, i64 0, i64 1, i64 0
  %2559 = bitcast i8* %scevgep41.6.4 to [61 x [61 x i8]]*
  %call16.6.5 = call zeroext i8 (...) @rand()
  store i8 %call16.6.5, i8* %scevgep28.6.4, align 1
  %2560 = load i8, i8* %scevgep28.6.4, align 1
  %conv23.6.5 = zext i8 %2560 to i32
  %2561 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.5 = getelementptr i8, i8* %b, i64 12
  %2562 = load i8, i8* %scevgep34.6.5, align 1
  %call28.6.5 = call zeroext i8 @mult(i8 zeroext %2561, i8 zeroext %2562)
  %conv29.6.5 = zext i8 %call28.6.5 to i32
  %xor.6.5 = xor i32 %conv23.6.5, %conv29.6.5
  %scevgep35.6.5 = getelementptr i8, i8* %a, i64 12
  %2563 = load i8, i8* %scevgep35.6.5, align 1
  %2564 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.5 = call zeroext i8 @mult(i8 zeroext %2563, i8 zeroext %2564)
  %conv35.6.5 = zext i8 %call34.6.5 to i32
  %xor36.6.5 = xor i32 %xor.6.5, %conv35.6.5
  %conv37.6.5 = trunc i32 %xor36.6.5 to i8
  store i8 %conv37.6.5, i8* %scevgep41.6.4, align 1
  %scevgep28.6.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2558, i64 0, i64 0, i64 1
  %2565 = bitcast i8* %scevgep28.6.5 to [61 x [61 x i8]]*
  %scevgep41.6.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2559, i64 0, i64 1, i64 0
  %2566 = bitcast i8* %scevgep41.6.5 to [61 x [61 x i8]]*
  %call16.6.6 = call zeroext i8 (...) @rand()
  store i8 %call16.6.6, i8* %scevgep28.6.5, align 1
  %2567 = load i8, i8* %scevgep28.6.5, align 1
  %conv23.6.6 = zext i8 %2567 to i32
  %2568 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.6 = getelementptr i8, i8* %b, i64 13
  %2569 = load i8, i8* %scevgep34.6.6, align 1
  %call28.6.6 = call zeroext i8 @mult(i8 zeroext %2568, i8 zeroext %2569)
  %conv29.6.6 = zext i8 %call28.6.6 to i32
  %xor.6.6 = xor i32 %conv23.6.6, %conv29.6.6
  %scevgep35.6.6 = getelementptr i8, i8* %a, i64 13
  %2570 = load i8, i8* %scevgep35.6.6, align 1
  %2571 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.6 = call zeroext i8 @mult(i8 zeroext %2570, i8 zeroext %2571)
  %conv35.6.6 = zext i8 %call34.6.6 to i32
  %xor36.6.6 = xor i32 %xor.6.6, %conv35.6.6
  %conv37.6.6 = trunc i32 %xor36.6.6 to i8
  store i8 %conv37.6.6, i8* %scevgep41.6.5, align 1
  %scevgep28.6.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2565, i64 0, i64 0, i64 1
  %2572 = bitcast i8* %scevgep28.6.6 to [61 x [61 x i8]]*
  %scevgep41.6.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2566, i64 0, i64 1, i64 0
  %2573 = bitcast i8* %scevgep41.6.6 to [61 x [61 x i8]]*
  %call16.6.7 = call zeroext i8 (...) @rand()
  store i8 %call16.6.7, i8* %scevgep28.6.6, align 1
  %2574 = load i8, i8* %scevgep28.6.6, align 1
  %conv23.6.7 = zext i8 %2574 to i32
  %2575 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.7 = getelementptr i8, i8* %b, i64 14
  %2576 = load i8, i8* %scevgep34.6.7, align 1
  %call28.6.7 = call zeroext i8 @mult(i8 zeroext %2575, i8 zeroext %2576)
  %conv29.6.7 = zext i8 %call28.6.7 to i32
  %xor.6.7 = xor i32 %conv23.6.7, %conv29.6.7
  %scevgep35.6.7 = getelementptr i8, i8* %a, i64 14
  %2577 = load i8, i8* %scevgep35.6.7, align 1
  %2578 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.7 = call zeroext i8 @mult(i8 zeroext %2577, i8 zeroext %2578)
  %conv35.6.7 = zext i8 %call34.6.7 to i32
  %xor36.6.7 = xor i32 %xor.6.7, %conv35.6.7
  %conv37.6.7 = trunc i32 %xor36.6.7 to i8
  store i8 %conv37.6.7, i8* %scevgep41.6.6, align 1
  %scevgep28.6.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2572, i64 0, i64 0, i64 1
  %2579 = bitcast i8* %scevgep28.6.7 to [61 x [61 x i8]]*
  %scevgep41.6.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2573, i64 0, i64 1, i64 0
  %2580 = bitcast i8* %scevgep41.6.7 to [61 x [61 x i8]]*
  %call16.6.8 = call zeroext i8 (...) @rand()
  store i8 %call16.6.8, i8* %scevgep28.6.7, align 1
  %2581 = load i8, i8* %scevgep28.6.7, align 1
  %conv23.6.8 = zext i8 %2581 to i32
  %2582 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.8 = getelementptr i8, i8* %b, i64 15
  %2583 = load i8, i8* %scevgep34.6.8, align 1
  %call28.6.8 = call zeroext i8 @mult(i8 zeroext %2582, i8 zeroext %2583)
  %conv29.6.8 = zext i8 %call28.6.8 to i32
  %xor.6.8 = xor i32 %conv23.6.8, %conv29.6.8
  %scevgep35.6.8 = getelementptr i8, i8* %a, i64 15
  %2584 = load i8, i8* %scevgep35.6.8, align 1
  %2585 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.8 = call zeroext i8 @mult(i8 zeroext %2584, i8 zeroext %2585)
  %conv35.6.8 = zext i8 %call34.6.8 to i32
  %xor36.6.8 = xor i32 %xor.6.8, %conv35.6.8
  %conv37.6.8 = trunc i32 %xor36.6.8 to i8
  store i8 %conv37.6.8, i8* %scevgep41.6.7, align 1
  %scevgep28.6.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2579, i64 0, i64 0, i64 1
  %2586 = bitcast i8* %scevgep28.6.8 to [61 x [61 x i8]]*
  %scevgep41.6.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2580, i64 0, i64 1, i64 0
  %2587 = bitcast i8* %scevgep41.6.8 to [61 x [61 x i8]]*
  %call16.6.9 = call zeroext i8 (...) @rand()
  store i8 %call16.6.9, i8* %scevgep28.6.8, align 1
  %2588 = load i8, i8* %scevgep28.6.8, align 1
  %conv23.6.9 = zext i8 %2588 to i32
  %2589 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.9 = getelementptr i8, i8* %b, i64 16
  %2590 = load i8, i8* %scevgep34.6.9, align 1
  %call28.6.9 = call zeroext i8 @mult(i8 zeroext %2589, i8 zeroext %2590)
  %conv29.6.9 = zext i8 %call28.6.9 to i32
  %xor.6.9 = xor i32 %conv23.6.9, %conv29.6.9
  %scevgep35.6.9 = getelementptr i8, i8* %a, i64 16
  %2591 = load i8, i8* %scevgep35.6.9, align 1
  %2592 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.9 = call zeroext i8 @mult(i8 zeroext %2591, i8 zeroext %2592)
  %conv35.6.9 = zext i8 %call34.6.9 to i32
  %xor36.6.9 = xor i32 %xor.6.9, %conv35.6.9
  %conv37.6.9 = trunc i32 %xor36.6.9 to i8
  store i8 %conv37.6.9, i8* %scevgep41.6.8, align 1
  %scevgep28.6.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2586, i64 0, i64 0, i64 1
  %2593 = bitcast i8* %scevgep28.6.9 to [61 x [61 x i8]]*
  %scevgep41.6.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2587, i64 0, i64 1, i64 0
  %2594 = bitcast i8* %scevgep41.6.9 to [61 x [61 x i8]]*
  %call16.6.10 = call zeroext i8 (...) @rand()
  store i8 %call16.6.10, i8* %scevgep28.6.9, align 1
  %2595 = load i8, i8* %scevgep28.6.9, align 1
  %conv23.6.10 = zext i8 %2595 to i32
  %2596 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.10 = getelementptr i8, i8* %b, i64 17
  %2597 = load i8, i8* %scevgep34.6.10, align 1
  %call28.6.10 = call zeroext i8 @mult(i8 zeroext %2596, i8 zeroext %2597)
  %conv29.6.10 = zext i8 %call28.6.10 to i32
  %xor.6.10 = xor i32 %conv23.6.10, %conv29.6.10
  %scevgep35.6.10 = getelementptr i8, i8* %a, i64 17
  %2598 = load i8, i8* %scevgep35.6.10, align 1
  %2599 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.10 = call zeroext i8 @mult(i8 zeroext %2598, i8 zeroext %2599)
  %conv35.6.10 = zext i8 %call34.6.10 to i32
  %xor36.6.10 = xor i32 %xor.6.10, %conv35.6.10
  %conv37.6.10 = trunc i32 %xor36.6.10 to i8
  store i8 %conv37.6.10, i8* %scevgep41.6.9, align 1
  %scevgep28.6.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2593, i64 0, i64 0, i64 1
  %2600 = bitcast i8* %scevgep28.6.10 to [61 x [61 x i8]]*
  %scevgep41.6.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2594, i64 0, i64 1, i64 0
  %2601 = bitcast i8* %scevgep41.6.10 to [61 x [61 x i8]]*
  %call16.6.11 = call zeroext i8 (...) @rand()
  store i8 %call16.6.11, i8* %scevgep28.6.10, align 1
  %2602 = load i8, i8* %scevgep28.6.10, align 1
  %conv23.6.11 = zext i8 %2602 to i32
  %2603 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.11 = getelementptr i8, i8* %b, i64 18
  %2604 = load i8, i8* %scevgep34.6.11, align 1
  %call28.6.11 = call zeroext i8 @mult(i8 zeroext %2603, i8 zeroext %2604)
  %conv29.6.11 = zext i8 %call28.6.11 to i32
  %xor.6.11 = xor i32 %conv23.6.11, %conv29.6.11
  %scevgep35.6.11 = getelementptr i8, i8* %a, i64 18
  %2605 = load i8, i8* %scevgep35.6.11, align 1
  %2606 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.11 = call zeroext i8 @mult(i8 zeroext %2605, i8 zeroext %2606)
  %conv35.6.11 = zext i8 %call34.6.11 to i32
  %xor36.6.11 = xor i32 %xor.6.11, %conv35.6.11
  %conv37.6.11 = trunc i32 %xor36.6.11 to i8
  store i8 %conv37.6.11, i8* %scevgep41.6.10, align 1
  %scevgep28.6.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2600, i64 0, i64 0, i64 1
  %2607 = bitcast i8* %scevgep28.6.11 to [61 x [61 x i8]]*
  %scevgep41.6.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2601, i64 0, i64 1, i64 0
  %2608 = bitcast i8* %scevgep41.6.11 to [61 x [61 x i8]]*
  %call16.6.12 = call zeroext i8 (...) @rand()
  store i8 %call16.6.12, i8* %scevgep28.6.11, align 1
  %2609 = load i8, i8* %scevgep28.6.11, align 1
  %conv23.6.12 = zext i8 %2609 to i32
  %2610 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.12 = getelementptr i8, i8* %b, i64 19
  %2611 = load i8, i8* %scevgep34.6.12, align 1
  %call28.6.12 = call zeroext i8 @mult(i8 zeroext %2610, i8 zeroext %2611)
  %conv29.6.12 = zext i8 %call28.6.12 to i32
  %xor.6.12 = xor i32 %conv23.6.12, %conv29.6.12
  %scevgep35.6.12 = getelementptr i8, i8* %a, i64 19
  %2612 = load i8, i8* %scevgep35.6.12, align 1
  %2613 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.12 = call zeroext i8 @mult(i8 zeroext %2612, i8 zeroext %2613)
  %conv35.6.12 = zext i8 %call34.6.12 to i32
  %xor36.6.12 = xor i32 %xor.6.12, %conv35.6.12
  %conv37.6.12 = trunc i32 %xor36.6.12 to i8
  store i8 %conv37.6.12, i8* %scevgep41.6.11, align 1
  %scevgep28.6.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2607, i64 0, i64 0, i64 1
  %2614 = bitcast i8* %scevgep28.6.12 to [61 x [61 x i8]]*
  %scevgep41.6.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2608, i64 0, i64 1, i64 0
  %2615 = bitcast i8* %scevgep41.6.12 to [61 x [61 x i8]]*
  %call16.6.13 = call zeroext i8 (...) @rand()
  store i8 %call16.6.13, i8* %scevgep28.6.12, align 1
  %2616 = load i8, i8* %scevgep28.6.12, align 1
  %conv23.6.13 = zext i8 %2616 to i32
  %2617 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.13 = getelementptr i8, i8* %b, i64 20
  %2618 = load i8, i8* %scevgep34.6.13, align 1
  %call28.6.13 = call zeroext i8 @mult(i8 zeroext %2617, i8 zeroext %2618)
  %conv29.6.13 = zext i8 %call28.6.13 to i32
  %xor.6.13 = xor i32 %conv23.6.13, %conv29.6.13
  %scevgep35.6.13 = getelementptr i8, i8* %a, i64 20
  %2619 = load i8, i8* %scevgep35.6.13, align 1
  %2620 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.13 = call zeroext i8 @mult(i8 zeroext %2619, i8 zeroext %2620)
  %conv35.6.13 = zext i8 %call34.6.13 to i32
  %xor36.6.13 = xor i32 %xor.6.13, %conv35.6.13
  %conv37.6.13 = trunc i32 %xor36.6.13 to i8
  store i8 %conv37.6.13, i8* %scevgep41.6.12, align 1
  %scevgep28.6.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2614, i64 0, i64 0, i64 1
  %2621 = bitcast i8* %scevgep28.6.13 to [61 x [61 x i8]]*
  %scevgep41.6.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2615, i64 0, i64 1, i64 0
  %2622 = bitcast i8* %scevgep41.6.13 to [61 x [61 x i8]]*
  %call16.6.14 = call zeroext i8 (...) @rand()
  store i8 %call16.6.14, i8* %scevgep28.6.13, align 1
  %2623 = load i8, i8* %scevgep28.6.13, align 1
  %conv23.6.14 = zext i8 %2623 to i32
  %2624 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.14 = getelementptr i8, i8* %b, i64 21
  %2625 = load i8, i8* %scevgep34.6.14, align 1
  %call28.6.14 = call zeroext i8 @mult(i8 zeroext %2624, i8 zeroext %2625)
  %conv29.6.14 = zext i8 %call28.6.14 to i32
  %xor.6.14 = xor i32 %conv23.6.14, %conv29.6.14
  %scevgep35.6.14 = getelementptr i8, i8* %a, i64 21
  %2626 = load i8, i8* %scevgep35.6.14, align 1
  %2627 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.14 = call zeroext i8 @mult(i8 zeroext %2626, i8 zeroext %2627)
  %conv35.6.14 = zext i8 %call34.6.14 to i32
  %xor36.6.14 = xor i32 %xor.6.14, %conv35.6.14
  %conv37.6.14 = trunc i32 %xor36.6.14 to i8
  store i8 %conv37.6.14, i8* %scevgep41.6.13, align 1
  %scevgep28.6.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2621, i64 0, i64 0, i64 1
  %2628 = bitcast i8* %scevgep28.6.14 to [61 x [61 x i8]]*
  %scevgep41.6.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2622, i64 0, i64 1, i64 0
  %2629 = bitcast i8* %scevgep41.6.14 to [61 x [61 x i8]]*
  %call16.6.15 = call zeroext i8 (...) @rand()
  store i8 %call16.6.15, i8* %scevgep28.6.14, align 1
  %2630 = load i8, i8* %scevgep28.6.14, align 1
  %conv23.6.15 = zext i8 %2630 to i32
  %2631 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.15 = getelementptr i8, i8* %b, i64 22
  %2632 = load i8, i8* %scevgep34.6.15, align 1
  %call28.6.15 = call zeroext i8 @mult(i8 zeroext %2631, i8 zeroext %2632)
  %conv29.6.15 = zext i8 %call28.6.15 to i32
  %xor.6.15 = xor i32 %conv23.6.15, %conv29.6.15
  %scevgep35.6.15 = getelementptr i8, i8* %a, i64 22
  %2633 = load i8, i8* %scevgep35.6.15, align 1
  %2634 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.15 = call zeroext i8 @mult(i8 zeroext %2633, i8 zeroext %2634)
  %conv35.6.15 = zext i8 %call34.6.15 to i32
  %xor36.6.15 = xor i32 %xor.6.15, %conv35.6.15
  %conv37.6.15 = trunc i32 %xor36.6.15 to i8
  store i8 %conv37.6.15, i8* %scevgep41.6.14, align 1
  %scevgep28.6.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2628, i64 0, i64 0, i64 1
  %2635 = bitcast i8* %scevgep28.6.15 to [61 x [61 x i8]]*
  %scevgep41.6.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2629, i64 0, i64 1, i64 0
  %2636 = bitcast i8* %scevgep41.6.15 to [61 x [61 x i8]]*
  %call16.6.16 = call zeroext i8 (...) @rand()
  store i8 %call16.6.16, i8* %scevgep28.6.15, align 1
  %2637 = load i8, i8* %scevgep28.6.15, align 1
  %conv23.6.16 = zext i8 %2637 to i32
  %2638 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.16 = getelementptr i8, i8* %b, i64 23
  %2639 = load i8, i8* %scevgep34.6.16, align 1
  %call28.6.16 = call zeroext i8 @mult(i8 zeroext %2638, i8 zeroext %2639)
  %conv29.6.16 = zext i8 %call28.6.16 to i32
  %xor.6.16 = xor i32 %conv23.6.16, %conv29.6.16
  %scevgep35.6.16 = getelementptr i8, i8* %a, i64 23
  %2640 = load i8, i8* %scevgep35.6.16, align 1
  %2641 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.16 = call zeroext i8 @mult(i8 zeroext %2640, i8 zeroext %2641)
  %conv35.6.16 = zext i8 %call34.6.16 to i32
  %xor36.6.16 = xor i32 %xor.6.16, %conv35.6.16
  %conv37.6.16 = trunc i32 %xor36.6.16 to i8
  store i8 %conv37.6.16, i8* %scevgep41.6.15, align 1
  %scevgep28.6.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2635, i64 0, i64 0, i64 1
  %2642 = bitcast i8* %scevgep28.6.16 to [61 x [61 x i8]]*
  %scevgep41.6.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2636, i64 0, i64 1, i64 0
  %2643 = bitcast i8* %scevgep41.6.16 to [61 x [61 x i8]]*
  %call16.6.17 = call zeroext i8 (...) @rand()
  store i8 %call16.6.17, i8* %scevgep28.6.16, align 1
  %2644 = load i8, i8* %scevgep28.6.16, align 1
  %conv23.6.17 = zext i8 %2644 to i32
  %2645 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.17 = getelementptr i8, i8* %b, i64 24
  %2646 = load i8, i8* %scevgep34.6.17, align 1
  %call28.6.17 = call zeroext i8 @mult(i8 zeroext %2645, i8 zeroext %2646)
  %conv29.6.17 = zext i8 %call28.6.17 to i32
  %xor.6.17 = xor i32 %conv23.6.17, %conv29.6.17
  %scevgep35.6.17 = getelementptr i8, i8* %a, i64 24
  %2647 = load i8, i8* %scevgep35.6.17, align 1
  %2648 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.17 = call zeroext i8 @mult(i8 zeroext %2647, i8 zeroext %2648)
  %conv35.6.17 = zext i8 %call34.6.17 to i32
  %xor36.6.17 = xor i32 %xor.6.17, %conv35.6.17
  %conv37.6.17 = trunc i32 %xor36.6.17 to i8
  store i8 %conv37.6.17, i8* %scevgep41.6.16, align 1
  %scevgep28.6.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2642, i64 0, i64 0, i64 1
  %2649 = bitcast i8* %scevgep28.6.17 to [61 x [61 x i8]]*
  %scevgep41.6.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2643, i64 0, i64 1, i64 0
  %2650 = bitcast i8* %scevgep41.6.17 to [61 x [61 x i8]]*
  %call16.6.18 = call zeroext i8 (...) @rand()
  store i8 %call16.6.18, i8* %scevgep28.6.17, align 1
  %2651 = load i8, i8* %scevgep28.6.17, align 1
  %conv23.6.18 = zext i8 %2651 to i32
  %2652 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.18 = getelementptr i8, i8* %b, i64 25
  %2653 = load i8, i8* %scevgep34.6.18, align 1
  %call28.6.18 = call zeroext i8 @mult(i8 zeroext %2652, i8 zeroext %2653)
  %conv29.6.18 = zext i8 %call28.6.18 to i32
  %xor.6.18 = xor i32 %conv23.6.18, %conv29.6.18
  %scevgep35.6.18 = getelementptr i8, i8* %a, i64 25
  %2654 = load i8, i8* %scevgep35.6.18, align 1
  %2655 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.18 = call zeroext i8 @mult(i8 zeroext %2654, i8 zeroext %2655)
  %conv35.6.18 = zext i8 %call34.6.18 to i32
  %xor36.6.18 = xor i32 %xor.6.18, %conv35.6.18
  %conv37.6.18 = trunc i32 %xor36.6.18 to i8
  store i8 %conv37.6.18, i8* %scevgep41.6.17, align 1
  %scevgep28.6.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2649, i64 0, i64 0, i64 1
  %2656 = bitcast i8* %scevgep28.6.18 to [61 x [61 x i8]]*
  %scevgep41.6.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2650, i64 0, i64 1, i64 0
  %2657 = bitcast i8* %scevgep41.6.18 to [61 x [61 x i8]]*
  %call16.6.19 = call zeroext i8 (...) @rand()
  store i8 %call16.6.19, i8* %scevgep28.6.18, align 1
  %2658 = load i8, i8* %scevgep28.6.18, align 1
  %conv23.6.19 = zext i8 %2658 to i32
  %2659 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.19 = getelementptr i8, i8* %b, i64 26
  %2660 = load i8, i8* %scevgep34.6.19, align 1
  %call28.6.19 = call zeroext i8 @mult(i8 zeroext %2659, i8 zeroext %2660)
  %conv29.6.19 = zext i8 %call28.6.19 to i32
  %xor.6.19 = xor i32 %conv23.6.19, %conv29.6.19
  %scevgep35.6.19 = getelementptr i8, i8* %a, i64 26
  %2661 = load i8, i8* %scevgep35.6.19, align 1
  %2662 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.19 = call zeroext i8 @mult(i8 zeroext %2661, i8 zeroext %2662)
  %conv35.6.19 = zext i8 %call34.6.19 to i32
  %xor36.6.19 = xor i32 %xor.6.19, %conv35.6.19
  %conv37.6.19 = trunc i32 %xor36.6.19 to i8
  store i8 %conv37.6.19, i8* %scevgep41.6.18, align 1
  %scevgep28.6.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2656, i64 0, i64 0, i64 1
  %2663 = bitcast i8* %scevgep28.6.19 to [61 x [61 x i8]]*
  %scevgep41.6.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2657, i64 0, i64 1, i64 0
  %2664 = bitcast i8* %scevgep41.6.19 to [61 x [61 x i8]]*
  %call16.6.20 = call zeroext i8 (...) @rand()
  store i8 %call16.6.20, i8* %scevgep28.6.19, align 1
  %2665 = load i8, i8* %scevgep28.6.19, align 1
  %conv23.6.20 = zext i8 %2665 to i32
  %2666 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.20 = getelementptr i8, i8* %b, i64 27
  %2667 = load i8, i8* %scevgep34.6.20, align 1
  %call28.6.20 = call zeroext i8 @mult(i8 zeroext %2666, i8 zeroext %2667)
  %conv29.6.20 = zext i8 %call28.6.20 to i32
  %xor.6.20 = xor i32 %conv23.6.20, %conv29.6.20
  %scevgep35.6.20 = getelementptr i8, i8* %a, i64 27
  %2668 = load i8, i8* %scevgep35.6.20, align 1
  %2669 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.20 = call zeroext i8 @mult(i8 zeroext %2668, i8 zeroext %2669)
  %conv35.6.20 = zext i8 %call34.6.20 to i32
  %xor36.6.20 = xor i32 %xor.6.20, %conv35.6.20
  %conv37.6.20 = trunc i32 %xor36.6.20 to i8
  store i8 %conv37.6.20, i8* %scevgep41.6.19, align 1
  %scevgep28.6.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2663, i64 0, i64 0, i64 1
  %2670 = bitcast i8* %scevgep28.6.20 to [61 x [61 x i8]]*
  %scevgep41.6.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2664, i64 0, i64 1, i64 0
  %2671 = bitcast i8* %scevgep41.6.20 to [61 x [61 x i8]]*
  %call16.6.21 = call zeroext i8 (...) @rand()
  store i8 %call16.6.21, i8* %scevgep28.6.20, align 1
  %2672 = load i8, i8* %scevgep28.6.20, align 1
  %conv23.6.21 = zext i8 %2672 to i32
  %2673 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.21 = getelementptr i8, i8* %b, i64 28
  %2674 = load i8, i8* %scevgep34.6.21, align 1
  %call28.6.21 = call zeroext i8 @mult(i8 zeroext %2673, i8 zeroext %2674)
  %conv29.6.21 = zext i8 %call28.6.21 to i32
  %xor.6.21 = xor i32 %conv23.6.21, %conv29.6.21
  %scevgep35.6.21 = getelementptr i8, i8* %a, i64 28
  %2675 = load i8, i8* %scevgep35.6.21, align 1
  %2676 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.21 = call zeroext i8 @mult(i8 zeroext %2675, i8 zeroext %2676)
  %conv35.6.21 = zext i8 %call34.6.21 to i32
  %xor36.6.21 = xor i32 %xor.6.21, %conv35.6.21
  %conv37.6.21 = trunc i32 %xor36.6.21 to i8
  store i8 %conv37.6.21, i8* %scevgep41.6.20, align 1
  %scevgep28.6.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2670, i64 0, i64 0, i64 1
  %2677 = bitcast i8* %scevgep28.6.21 to [61 x [61 x i8]]*
  %scevgep41.6.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2671, i64 0, i64 1, i64 0
  %2678 = bitcast i8* %scevgep41.6.21 to [61 x [61 x i8]]*
  %call16.6.22 = call zeroext i8 (...) @rand()
  store i8 %call16.6.22, i8* %scevgep28.6.21, align 1
  %2679 = load i8, i8* %scevgep28.6.21, align 1
  %conv23.6.22 = zext i8 %2679 to i32
  %2680 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.22 = getelementptr i8, i8* %b, i64 29
  %2681 = load i8, i8* %scevgep34.6.22, align 1
  %call28.6.22 = call zeroext i8 @mult(i8 zeroext %2680, i8 zeroext %2681)
  %conv29.6.22 = zext i8 %call28.6.22 to i32
  %xor.6.22 = xor i32 %conv23.6.22, %conv29.6.22
  %scevgep35.6.22 = getelementptr i8, i8* %a, i64 29
  %2682 = load i8, i8* %scevgep35.6.22, align 1
  %2683 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.22 = call zeroext i8 @mult(i8 zeroext %2682, i8 zeroext %2683)
  %conv35.6.22 = zext i8 %call34.6.22 to i32
  %xor36.6.22 = xor i32 %xor.6.22, %conv35.6.22
  %conv37.6.22 = trunc i32 %xor36.6.22 to i8
  store i8 %conv37.6.22, i8* %scevgep41.6.21, align 1
  %scevgep28.6.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2677, i64 0, i64 0, i64 1
  %2684 = bitcast i8* %scevgep28.6.22 to [61 x [61 x i8]]*
  %scevgep41.6.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2678, i64 0, i64 1, i64 0
  %2685 = bitcast i8* %scevgep41.6.22 to [61 x [61 x i8]]*
  %call16.6.23 = call zeroext i8 (...) @rand()
  store i8 %call16.6.23, i8* %scevgep28.6.22, align 1
  %2686 = load i8, i8* %scevgep28.6.22, align 1
  %conv23.6.23 = zext i8 %2686 to i32
  %2687 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.23 = getelementptr i8, i8* %b, i64 30
  %2688 = load i8, i8* %scevgep34.6.23, align 1
  %call28.6.23 = call zeroext i8 @mult(i8 zeroext %2687, i8 zeroext %2688)
  %conv29.6.23 = zext i8 %call28.6.23 to i32
  %xor.6.23 = xor i32 %conv23.6.23, %conv29.6.23
  %scevgep35.6.23 = getelementptr i8, i8* %a, i64 30
  %2689 = load i8, i8* %scevgep35.6.23, align 1
  %2690 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.23 = call zeroext i8 @mult(i8 zeroext %2689, i8 zeroext %2690)
  %conv35.6.23 = zext i8 %call34.6.23 to i32
  %xor36.6.23 = xor i32 %xor.6.23, %conv35.6.23
  %conv37.6.23 = trunc i32 %xor36.6.23 to i8
  store i8 %conv37.6.23, i8* %scevgep41.6.22, align 1
  %scevgep28.6.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2684, i64 0, i64 0, i64 1
  %2691 = bitcast i8* %scevgep28.6.23 to [61 x [61 x i8]]*
  %scevgep41.6.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2685, i64 0, i64 1, i64 0
  %2692 = bitcast i8* %scevgep41.6.23 to [61 x [61 x i8]]*
  %call16.6.24 = call zeroext i8 (...) @rand()
  store i8 %call16.6.24, i8* %scevgep28.6.23, align 1
  %2693 = load i8, i8* %scevgep28.6.23, align 1
  %conv23.6.24 = zext i8 %2693 to i32
  %2694 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.24 = getelementptr i8, i8* %b, i64 31
  %2695 = load i8, i8* %scevgep34.6.24, align 1
  %call28.6.24 = call zeroext i8 @mult(i8 zeroext %2694, i8 zeroext %2695)
  %conv29.6.24 = zext i8 %call28.6.24 to i32
  %xor.6.24 = xor i32 %conv23.6.24, %conv29.6.24
  %scevgep35.6.24 = getelementptr i8, i8* %a, i64 31
  %2696 = load i8, i8* %scevgep35.6.24, align 1
  %2697 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.24 = call zeroext i8 @mult(i8 zeroext %2696, i8 zeroext %2697)
  %conv35.6.24 = zext i8 %call34.6.24 to i32
  %xor36.6.24 = xor i32 %xor.6.24, %conv35.6.24
  %conv37.6.24 = trunc i32 %xor36.6.24 to i8
  store i8 %conv37.6.24, i8* %scevgep41.6.23, align 1
  %scevgep28.6.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2691, i64 0, i64 0, i64 1
  %2698 = bitcast i8* %scevgep28.6.24 to [61 x [61 x i8]]*
  %scevgep41.6.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2692, i64 0, i64 1, i64 0
  %2699 = bitcast i8* %scevgep41.6.24 to [61 x [61 x i8]]*
  %call16.6.25 = call zeroext i8 (...) @rand()
  store i8 %call16.6.25, i8* %scevgep28.6.24, align 1
  %2700 = load i8, i8* %scevgep28.6.24, align 1
  %conv23.6.25 = zext i8 %2700 to i32
  %2701 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.25 = getelementptr i8, i8* %b, i64 32
  %2702 = load i8, i8* %scevgep34.6.25, align 1
  %call28.6.25 = call zeroext i8 @mult(i8 zeroext %2701, i8 zeroext %2702)
  %conv29.6.25 = zext i8 %call28.6.25 to i32
  %xor.6.25 = xor i32 %conv23.6.25, %conv29.6.25
  %scevgep35.6.25 = getelementptr i8, i8* %a, i64 32
  %2703 = load i8, i8* %scevgep35.6.25, align 1
  %2704 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.25 = call zeroext i8 @mult(i8 zeroext %2703, i8 zeroext %2704)
  %conv35.6.25 = zext i8 %call34.6.25 to i32
  %xor36.6.25 = xor i32 %xor.6.25, %conv35.6.25
  %conv37.6.25 = trunc i32 %xor36.6.25 to i8
  store i8 %conv37.6.25, i8* %scevgep41.6.24, align 1
  %scevgep28.6.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2698, i64 0, i64 0, i64 1
  %2705 = bitcast i8* %scevgep28.6.25 to [61 x [61 x i8]]*
  %scevgep41.6.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2699, i64 0, i64 1, i64 0
  %2706 = bitcast i8* %scevgep41.6.25 to [61 x [61 x i8]]*
  %call16.6.26 = call zeroext i8 (...) @rand()
  store i8 %call16.6.26, i8* %scevgep28.6.25, align 1
  %2707 = load i8, i8* %scevgep28.6.25, align 1
  %conv23.6.26 = zext i8 %2707 to i32
  %2708 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.26 = getelementptr i8, i8* %b, i64 33
  %2709 = load i8, i8* %scevgep34.6.26, align 1
  %call28.6.26 = call zeroext i8 @mult(i8 zeroext %2708, i8 zeroext %2709)
  %conv29.6.26 = zext i8 %call28.6.26 to i32
  %xor.6.26 = xor i32 %conv23.6.26, %conv29.6.26
  %scevgep35.6.26 = getelementptr i8, i8* %a, i64 33
  %2710 = load i8, i8* %scevgep35.6.26, align 1
  %2711 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.26 = call zeroext i8 @mult(i8 zeroext %2710, i8 zeroext %2711)
  %conv35.6.26 = zext i8 %call34.6.26 to i32
  %xor36.6.26 = xor i32 %xor.6.26, %conv35.6.26
  %conv37.6.26 = trunc i32 %xor36.6.26 to i8
  store i8 %conv37.6.26, i8* %scevgep41.6.25, align 1
  %scevgep28.6.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2705, i64 0, i64 0, i64 1
  %2712 = bitcast i8* %scevgep28.6.26 to [61 x [61 x i8]]*
  %scevgep41.6.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2706, i64 0, i64 1, i64 0
  %2713 = bitcast i8* %scevgep41.6.26 to [61 x [61 x i8]]*
  %call16.6.27 = call zeroext i8 (...) @rand()
  store i8 %call16.6.27, i8* %scevgep28.6.26, align 1
  %2714 = load i8, i8* %scevgep28.6.26, align 1
  %conv23.6.27 = zext i8 %2714 to i32
  %2715 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.27 = getelementptr i8, i8* %b, i64 34
  %2716 = load i8, i8* %scevgep34.6.27, align 1
  %call28.6.27 = call zeroext i8 @mult(i8 zeroext %2715, i8 zeroext %2716)
  %conv29.6.27 = zext i8 %call28.6.27 to i32
  %xor.6.27 = xor i32 %conv23.6.27, %conv29.6.27
  %scevgep35.6.27 = getelementptr i8, i8* %a, i64 34
  %2717 = load i8, i8* %scevgep35.6.27, align 1
  %2718 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.27 = call zeroext i8 @mult(i8 zeroext %2717, i8 zeroext %2718)
  %conv35.6.27 = zext i8 %call34.6.27 to i32
  %xor36.6.27 = xor i32 %xor.6.27, %conv35.6.27
  %conv37.6.27 = trunc i32 %xor36.6.27 to i8
  store i8 %conv37.6.27, i8* %scevgep41.6.26, align 1
  %scevgep28.6.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2712, i64 0, i64 0, i64 1
  %2719 = bitcast i8* %scevgep28.6.27 to [61 x [61 x i8]]*
  %scevgep41.6.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2713, i64 0, i64 1, i64 0
  %2720 = bitcast i8* %scevgep41.6.27 to [61 x [61 x i8]]*
  %call16.6.28 = call zeroext i8 (...) @rand()
  store i8 %call16.6.28, i8* %scevgep28.6.27, align 1
  %2721 = load i8, i8* %scevgep28.6.27, align 1
  %conv23.6.28 = zext i8 %2721 to i32
  %2722 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.28 = getelementptr i8, i8* %b, i64 35
  %2723 = load i8, i8* %scevgep34.6.28, align 1
  %call28.6.28 = call zeroext i8 @mult(i8 zeroext %2722, i8 zeroext %2723)
  %conv29.6.28 = zext i8 %call28.6.28 to i32
  %xor.6.28 = xor i32 %conv23.6.28, %conv29.6.28
  %scevgep35.6.28 = getelementptr i8, i8* %a, i64 35
  %2724 = load i8, i8* %scevgep35.6.28, align 1
  %2725 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.28 = call zeroext i8 @mult(i8 zeroext %2724, i8 zeroext %2725)
  %conv35.6.28 = zext i8 %call34.6.28 to i32
  %xor36.6.28 = xor i32 %xor.6.28, %conv35.6.28
  %conv37.6.28 = trunc i32 %xor36.6.28 to i8
  store i8 %conv37.6.28, i8* %scevgep41.6.27, align 1
  %scevgep28.6.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2719, i64 0, i64 0, i64 1
  %2726 = bitcast i8* %scevgep28.6.28 to [61 x [61 x i8]]*
  %scevgep41.6.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2720, i64 0, i64 1, i64 0
  %2727 = bitcast i8* %scevgep41.6.28 to [61 x [61 x i8]]*
  %call16.6.29 = call zeroext i8 (...) @rand()
  store i8 %call16.6.29, i8* %scevgep28.6.28, align 1
  %2728 = load i8, i8* %scevgep28.6.28, align 1
  %conv23.6.29 = zext i8 %2728 to i32
  %2729 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.29 = getelementptr i8, i8* %b, i64 36
  %2730 = load i8, i8* %scevgep34.6.29, align 1
  %call28.6.29 = call zeroext i8 @mult(i8 zeroext %2729, i8 zeroext %2730)
  %conv29.6.29 = zext i8 %call28.6.29 to i32
  %xor.6.29 = xor i32 %conv23.6.29, %conv29.6.29
  %scevgep35.6.29 = getelementptr i8, i8* %a, i64 36
  %2731 = load i8, i8* %scevgep35.6.29, align 1
  %2732 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.29 = call zeroext i8 @mult(i8 zeroext %2731, i8 zeroext %2732)
  %conv35.6.29 = zext i8 %call34.6.29 to i32
  %xor36.6.29 = xor i32 %xor.6.29, %conv35.6.29
  %conv37.6.29 = trunc i32 %xor36.6.29 to i8
  store i8 %conv37.6.29, i8* %scevgep41.6.28, align 1
  %scevgep28.6.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2726, i64 0, i64 0, i64 1
  %2733 = bitcast i8* %scevgep28.6.29 to [61 x [61 x i8]]*
  %scevgep41.6.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2727, i64 0, i64 1, i64 0
  %2734 = bitcast i8* %scevgep41.6.29 to [61 x [61 x i8]]*
  %call16.6.30 = call zeroext i8 (...) @rand()
  store i8 %call16.6.30, i8* %scevgep28.6.29, align 1
  %2735 = load i8, i8* %scevgep28.6.29, align 1
  %conv23.6.30 = zext i8 %2735 to i32
  %2736 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.30 = getelementptr i8, i8* %b, i64 37
  %2737 = load i8, i8* %scevgep34.6.30, align 1
  %call28.6.30 = call zeroext i8 @mult(i8 zeroext %2736, i8 zeroext %2737)
  %conv29.6.30 = zext i8 %call28.6.30 to i32
  %xor.6.30 = xor i32 %conv23.6.30, %conv29.6.30
  %scevgep35.6.30 = getelementptr i8, i8* %a, i64 37
  %2738 = load i8, i8* %scevgep35.6.30, align 1
  %2739 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.30 = call zeroext i8 @mult(i8 zeroext %2738, i8 zeroext %2739)
  %conv35.6.30 = zext i8 %call34.6.30 to i32
  %xor36.6.30 = xor i32 %xor.6.30, %conv35.6.30
  %conv37.6.30 = trunc i32 %xor36.6.30 to i8
  store i8 %conv37.6.30, i8* %scevgep41.6.29, align 1
  %scevgep28.6.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2733, i64 0, i64 0, i64 1
  %2740 = bitcast i8* %scevgep28.6.30 to [61 x [61 x i8]]*
  %scevgep41.6.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2734, i64 0, i64 1, i64 0
  %2741 = bitcast i8* %scevgep41.6.30 to [61 x [61 x i8]]*
  %call16.6.31 = call zeroext i8 (...) @rand()
  store i8 %call16.6.31, i8* %scevgep28.6.30, align 1
  %2742 = load i8, i8* %scevgep28.6.30, align 1
  %conv23.6.31 = zext i8 %2742 to i32
  %2743 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.31 = getelementptr i8, i8* %b, i64 38
  %2744 = load i8, i8* %scevgep34.6.31, align 1
  %call28.6.31 = call zeroext i8 @mult(i8 zeroext %2743, i8 zeroext %2744)
  %conv29.6.31 = zext i8 %call28.6.31 to i32
  %xor.6.31 = xor i32 %conv23.6.31, %conv29.6.31
  %scevgep35.6.31 = getelementptr i8, i8* %a, i64 38
  %2745 = load i8, i8* %scevgep35.6.31, align 1
  %2746 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.31 = call zeroext i8 @mult(i8 zeroext %2745, i8 zeroext %2746)
  %conv35.6.31 = zext i8 %call34.6.31 to i32
  %xor36.6.31 = xor i32 %xor.6.31, %conv35.6.31
  %conv37.6.31 = trunc i32 %xor36.6.31 to i8
  store i8 %conv37.6.31, i8* %scevgep41.6.30, align 1
  %scevgep28.6.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2740, i64 0, i64 0, i64 1
  %2747 = bitcast i8* %scevgep28.6.31 to [61 x [61 x i8]]*
  %scevgep41.6.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2741, i64 0, i64 1, i64 0
  %2748 = bitcast i8* %scevgep41.6.31 to [61 x [61 x i8]]*
  %call16.6.32 = call zeroext i8 (...) @rand()
  store i8 %call16.6.32, i8* %scevgep28.6.31, align 1
  %2749 = load i8, i8* %scevgep28.6.31, align 1
  %conv23.6.32 = zext i8 %2749 to i32
  %2750 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.32 = getelementptr i8, i8* %b, i64 39
  %2751 = load i8, i8* %scevgep34.6.32, align 1
  %call28.6.32 = call zeroext i8 @mult(i8 zeroext %2750, i8 zeroext %2751)
  %conv29.6.32 = zext i8 %call28.6.32 to i32
  %xor.6.32 = xor i32 %conv23.6.32, %conv29.6.32
  %scevgep35.6.32 = getelementptr i8, i8* %a, i64 39
  %2752 = load i8, i8* %scevgep35.6.32, align 1
  %2753 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.32 = call zeroext i8 @mult(i8 zeroext %2752, i8 zeroext %2753)
  %conv35.6.32 = zext i8 %call34.6.32 to i32
  %xor36.6.32 = xor i32 %xor.6.32, %conv35.6.32
  %conv37.6.32 = trunc i32 %xor36.6.32 to i8
  store i8 %conv37.6.32, i8* %scevgep41.6.31, align 1
  %scevgep28.6.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2747, i64 0, i64 0, i64 1
  %2754 = bitcast i8* %scevgep28.6.32 to [61 x [61 x i8]]*
  %scevgep41.6.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2748, i64 0, i64 1, i64 0
  %2755 = bitcast i8* %scevgep41.6.32 to [61 x [61 x i8]]*
  %call16.6.33 = call zeroext i8 (...) @rand()
  store i8 %call16.6.33, i8* %scevgep28.6.32, align 1
  %2756 = load i8, i8* %scevgep28.6.32, align 1
  %conv23.6.33 = zext i8 %2756 to i32
  %2757 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.33 = getelementptr i8, i8* %b, i64 40
  %2758 = load i8, i8* %scevgep34.6.33, align 1
  %call28.6.33 = call zeroext i8 @mult(i8 zeroext %2757, i8 zeroext %2758)
  %conv29.6.33 = zext i8 %call28.6.33 to i32
  %xor.6.33 = xor i32 %conv23.6.33, %conv29.6.33
  %scevgep35.6.33 = getelementptr i8, i8* %a, i64 40
  %2759 = load i8, i8* %scevgep35.6.33, align 1
  %2760 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.33 = call zeroext i8 @mult(i8 zeroext %2759, i8 zeroext %2760)
  %conv35.6.33 = zext i8 %call34.6.33 to i32
  %xor36.6.33 = xor i32 %xor.6.33, %conv35.6.33
  %conv37.6.33 = trunc i32 %xor36.6.33 to i8
  store i8 %conv37.6.33, i8* %scevgep41.6.32, align 1
  %scevgep28.6.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2754, i64 0, i64 0, i64 1
  %2761 = bitcast i8* %scevgep28.6.33 to [61 x [61 x i8]]*
  %scevgep41.6.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2755, i64 0, i64 1, i64 0
  %2762 = bitcast i8* %scevgep41.6.33 to [61 x [61 x i8]]*
  %call16.6.34 = call zeroext i8 (...) @rand()
  store i8 %call16.6.34, i8* %scevgep28.6.33, align 1
  %2763 = load i8, i8* %scevgep28.6.33, align 1
  %conv23.6.34 = zext i8 %2763 to i32
  %2764 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.34 = getelementptr i8, i8* %b, i64 41
  %2765 = load i8, i8* %scevgep34.6.34, align 1
  %call28.6.34 = call zeroext i8 @mult(i8 zeroext %2764, i8 zeroext %2765)
  %conv29.6.34 = zext i8 %call28.6.34 to i32
  %xor.6.34 = xor i32 %conv23.6.34, %conv29.6.34
  %scevgep35.6.34 = getelementptr i8, i8* %a, i64 41
  %2766 = load i8, i8* %scevgep35.6.34, align 1
  %2767 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.34 = call zeroext i8 @mult(i8 zeroext %2766, i8 zeroext %2767)
  %conv35.6.34 = zext i8 %call34.6.34 to i32
  %xor36.6.34 = xor i32 %xor.6.34, %conv35.6.34
  %conv37.6.34 = trunc i32 %xor36.6.34 to i8
  store i8 %conv37.6.34, i8* %scevgep41.6.33, align 1
  %scevgep28.6.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2761, i64 0, i64 0, i64 1
  %2768 = bitcast i8* %scevgep28.6.34 to [61 x [61 x i8]]*
  %scevgep41.6.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2762, i64 0, i64 1, i64 0
  %2769 = bitcast i8* %scevgep41.6.34 to [61 x [61 x i8]]*
  %call16.6.35 = call zeroext i8 (...) @rand()
  store i8 %call16.6.35, i8* %scevgep28.6.34, align 1
  %2770 = load i8, i8* %scevgep28.6.34, align 1
  %conv23.6.35 = zext i8 %2770 to i32
  %2771 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.35 = getelementptr i8, i8* %b, i64 42
  %2772 = load i8, i8* %scevgep34.6.35, align 1
  %call28.6.35 = call zeroext i8 @mult(i8 zeroext %2771, i8 zeroext %2772)
  %conv29.6.35 = zext i8 %call28.6.35 to i32
  %xor.6.35 = xor i32 %conv23.6.35, %conv29.6.35
  %scevgep35.6.35 = getelementptr i8, i8* %a, i64 42
  %2773 = load i8, i8* %scevgep35.6.35, align 1
  %2774 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.35 = call zeroext i8 @mult(i8 zeroext %2773, i8 zeroext %2774)
  %conv35.6.35 = zext i8 %call34.6.35 to i32
  %xor36.6.35 = xor i32 %xor.6.35, %conv35.6.35
  %conv37.6.35 = trunc i32 %xor36.6.35 to i8
  store i8 %conv37.6.35, i8* %scevgep41.6.34, align 1
  %scevgep28.6.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2768, i64 0, i64 0, i64 1
  %2775 = bitcast i8* %scevgep28.6.35 to [61 x [61 x i8]]*
  %scevgep41.6.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2769, i64 0, i64 1, i64 0
  %2776 = bitcast i8* %scevgep41.6.35 to [61 x [61 x i8]]*
  %call16.6.36 = call zeroext i8 (...) @rand()
  store i8 %call16.6.36, i8* %scevgep28.6.35, align 1
  %2777 = load i8, i8* %scevgep28.6.35, align 1
  %conv23.6.36 = zext i8 %2777 to i32
  %2778 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.36 = getelementptr i8, i8* %b, i64 43
  %2779 = load i8, i8* %scevgep34.6.36, align 1
  %call28.6.36 = call zeroext i8 @mult(i8 zeroext %2778, i8 zeroext %2779)
  %conv29.6.36 = zext i8 %call28.6.36 to i32
  %xor.6.36 = xor i32 %conv23.6.36, %conv29.6.36
  %scevgep35.6.36 = getelementptr i8, i8* %a, i64 43
  %2780 = load i8, i8* %scevgep35.6.36, align 1
  %2781 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.36 = call zeroext i8 @mult(i8 zeroext %2780, i8 zeroext %2781)
  %conv35.6.36 = zext i8 %call34.6.36 to i32
  %xor36.6.36 = xor i32 %xor.6.36, %conv35.6.36
  %conv37.6.36 = trunc i32 %xor36.6.36 to i8
  store i8 %conv37.6.36, i8* %scevgep41.6.35, align 1
  %scevgep28.6.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2775, i64 0, i64 0, i64 1
  %2782 = bitcast i8* %scevgep28.6.36 to [61 x [61 x i8]]*
  %scevgep41.6.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2776, i64 0, i64 1, i64 0
  %2783 = bitcast i8* %scevgep41.6.36 to [61 x [61 x i8]]*
  %call16.6.37 = call zeroext i8 (...) @rand()
  store i8 %call16.6.37, i8* %scevgep28.6.36, align 1
  %2784 = load i8, i8* %scevgep28.6.36, align 1
  %conv23.6.37 = zext i8 %2784 to i32
  %2785 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.37 = getelementptr i8, i8* %b, i64 44
  %2786 = load i8, i8* %scevgep34.6.37, align 1
  %call28.6.37 = call zeroext i8 @mult(i8 zeroext %2785, i8 zeroext %2786)
  %conv29.6.37 = zext i8 %call28.6.37 to i32
  %xor.6.37 = xor i32 %conv23.6.37, %conv29.6.37
  %scevgep35.6.37 = getelementptr i8, i8* %a, i64 44
  %2787 = load i8, i8* %scevgep35.6.37, align 1
  %2788 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.37 = call zeroext i8 @mult(i8 zeroext %2787, i8 zeroext %2788)
  %conv35.6.37 = zext i8 %call34.6.37 to i32
  %xor36.6.37 = xor i32 %xor.6.37, %conv35.6.37
  %conv37.6.37 = trunc i32 %xor36.6.37 to i8
  store i8 %conv37.6.37, i8* %scevgep41.6.36, align 1
  %scevgep28.6.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2782, i64 0, i64 0, i64 1
  %2789 = bitcast i8* %scevgep28.6.37 to [61 x [61 x i8]]*
  %scevgep41.6.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2783, i64 0, i64 1, i64 0
  %2790 = bitcast i8* %scevgep41.6.37 to [61 x [61 x i8]]*
  %call16.6.38 = call zeroext i8 (...) @rand()
  store i8 %call16.6.38, i8* %scevgep28.6.37, align 1
  %2791 = load i8, i8* %scevgep28.6.37, align 1
  %conv23.6.38 = zext i8 %2791 to i32
  %2792 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.38 = getelementptr i8, i8* %b, i64 45
  %2793 = load i8, i8* %scevgep34.6.38, align 1
  %call28.6.38 = call zeroext i8 @mult(i8 zeroext %2792, i8 zeroext %2793)
  %conv29.6.38 = zext i8 %call28.6.38 to i32
  %xor.6.38 = xor i32 %conv23.6.38, %conv29.6.38
  %scevgep35.6.38 = getelementptr i8, i8* %a, i64 45
  %2794 = load i8, i8* %scevgep35.6.38, align 1
  %2795 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.38 = call zeroext i8 @mult(i8 zeroext %2794, i8 zeroext %2795)
  %conv35.6.38 = zext i8 %call34.6.38 to i32
  %xor36.6.38 = xor i32 %xor.6.38, %conv35.6.38
  %conv37.6.38 = trunc i32 %xor36.6.38 to i8
  store i8 %conv37.6.38, i8* %scevgep41.6.37, align 1
  %scevgep28.6.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2789, i64 0, i64 0, i64 1
  %2796 = bitcast i8* %scevgep28.6.38 to [61 x [61 x i8]]*
  %scevgep41.6.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2790, i64 0, i64 1, i64 0
  %2797 = bitcast i8* %scevgep41.6.38 to [61 x [61 x i8]]*
  %call16.6.39 = call zeroext i8 (...) @rand()
  store i8 %call16.6.39, i8* %scevgep28.6.38, align 1
  %2798 = load i8, i8* %scevgep28.6.38, align 1
  %conv23.6.39 = zext i8 %2798 to i32
  %2799 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.39 = getelementptr i8, i8* %b, i64 46
  %2800 = load i8, i8* %scevgep34.6.39, align 1
  %call28.6.39 = call zeroext i8 @mult(i8 zeroext %2799, i8 zeroext %2800)
  %conv29.6.39 = zext i8 %call28.6.39 to i32
  %xor.6.39 = xor i32 %conv23.6.39, %conv29.6.39
  %scevgep35.6.39 = getelementptr i8, i8* %a, i64 46
  %2801 = load i8, i8* %scevgep35.6.39, align 1
  %2802 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.39 = call zeroext i8 @mult(i8 zeroext %2801, i8 zeroext %2802)
  %conv35.6.39 = zext i8 %call34.6.39 to i32
  %xor36.6.39 = xor i32 %xor.6.39, %conv35.6.39
  %conv37.6.39 = trunc i32 %xor36.6.39 to i8
  store i8 %conv37.6.39, i8* %scevgep41.6.38, align 1
  %scevgep28.6.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2796, i64 0, i64 0, i64 1
  %2803 = bitcast i8* %scevgep28.6.39 to [61 x [61 x i8]]*
  %scevgep41.6.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2797, i64 0, i64 1, i64 0
  %2804 = bitcast i8* %scevgep41.6.39 to [61 x [61 x i8]]*
  %call16.6.40 = call zeroext i8 (...) @rand()
  store i8 %call16.6.40, i8* %scevgep28.6.39, align 1
  %2805 = load i8, i8* %scevgep28.6.39, align 1
  %conv23.6.40 = zext i8 %2805 to i32
  %2806 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.40 = getelementptr i8, i8* %b, i64 47
  %2807 = load i8, i8* %scevgep34.6.40, align 1
  %call28.6.40 = call zeroext i8 @mult(i8 zeroext %2806, i8 zeroext %2807)
  %conv29.6.40 = zext i8 %call28.6.40 to i32
  %xor.6.40 = xor i32 %conv23.6.40, %conv29.6.40
  %scevgep35.6.40 = getelementptr i8, i8* %a, i64 47
  %2808 = load i8, i8* %scevgep35.6.40, align 1
  %2809 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.40 = call zeroext i8 @mult(i8 zeroext %2808, i8 zeroext %2809)
  %conv35.6.40 = zext i8 %call34.6.40 to i32
  %xor36.6.40 = xor i32 %xor.6.40, %conv35.6.40
  %conv37.6.40 = trunc i32 %xor36.6.40 to i8
  store i8 %conv37.6.40, i8* %scevgep41.6.39, align 1
  %scevgep28.6.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2803, i64 0, i64 0, i64 1
  %2810 = bitcast i8* %scevgep28.6.40 to [61 x [61 x i8]]*
  %scevgep41.6.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2804, i64 0, i64 1, i64 0
  %2811 = bitcast i8* %scevgep41.6.40 to [61 x [61 x i8]]*
  %call16.6.41 = call zeroext i8 (...) @rand()
  store i8 %call16.6.41, i8* %scevgep28.6.40, align 1
  %2812 = load i8, i8* %scevgep28.6.40, align 1
  %conv23.6.41 = zext i8 %2812 to i32
  %2813 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.41 = getelementptr i8, i8* %b, i64 48
  %2814 = load i8, i8* %scevgep34.6.41, align 1
  %call28.6.41 = call zeroext i8 @mult(i8 zeroext %2813, i8 zeroext %2814)
  %conv29.6.41 = zext i8 %call28.6.41 to i32
  %xor.6.41 = xor i32 %conv23.6.41, %conv29.6.41
  %scevgep35.6.41 = getelementptr i8, i8* %a, i64 48
  %2815 = load i8, i8* %scevgep35.6.41, align 1
  %2816 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.41 = call zeroext i8 @mult(i8 zeroext %2815, i8 zeroext %2816)
  %conv35.6.41 = zext i8 %call34.6.41 to i32
  %xor36.6.41 = xor i32 %xor.6.41, %conv35.6.41
  %conv37.6.41 = trunc i32 %xor36.6.41 to i8
  store i8 %conv37.6.41, i8* %scevgep41.6.40, align 1
  %scevgep28.6.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2810, i64 0, i64 0, i64 1
  %2817 = bitcast i8* %scevgep28.6.41 to [61 x [61 x i8]]*
  %scevgep41.6.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2811, i64 0, i64 1, i64 0
  %2818 = bitcast i8* %scevgep41.6.41 to [61 x [61 x i8]]*
  %call16.6.42 = call zeroext i8 (...) @rand()
  store i8 %call16.6.42, i8* %scevgep28.6.41, align 1
  %2819 = load i8, i8* %scevgep28.6.41, align 1
  %conv23.6.42 = zext i8 %2819 to i32
  %2820 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.42 = getelementptr i8, i8* %b, i64 49
  %2821 = load i8, i8* %scevgep34.6.42, align 1
  %call28.6.42 = call zeroext i8 @mult(i8 zeroext %2820, i8 zeroext %2821)
  %conv29.6.42 = zext i8 %call28.6.42 to i32
  %xor.6.42 = xor i32 %conv23.6.42, %conv29.6.42
  %scevgep35.6.42 = getelementptr i8, i8* %a, i64 49
  %2822 = load i8, i8* %scevgep35.6.42, align 1
  %2823 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.42 = call zeroext i8 @mult(i8 zeroext %2822, i8 zeroext %2823)
  %conv35.6.42 = zext i8 %call34.6.42 to i32
  %xor36.6.42 = xor i32 %xor.6.42, %conv35.6.42
  %conv37.6.42 = trunc i32 %xor36.6.42 to i8
  store i8 %conv37.6.42, i8* %scevgep41.6.41, align 1
  %scevgep28.6.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2817, i64 0, i64 0, i64 1
  %2824 = bitcast i8* %scevgep28.6.42 to [61 x [61 x i8]]*
  %scevgep41.6.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2818, i64 0, i64 1, i64 0
  %2825 = bitcast i8* %scevgep41.6.42 to [61 x [61 x i8]]*
  %call16.6.43 = call zeroext i8 (...) @rand()
  store i8 %call16.6.43, i8* %scevgep28.6.42, align 1
  %2826 = load i8, i8* %scevgep28.6.42, align 1
  %conv23.6.43 = zext i8 %2826 to i32
  %2827 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.43 = getelementptr i8, i8* %b, i64 50
  %2828 = load i8, i8* %scevgep34.6.43, align 1
  %call28.6.43 = call zeroext i8 @mult(i8 zeroext %2827, i8 zeroext %2828)
  %conv29.6.43 = zext i8 %call28.6.43 to i32
  %xor.6.43 = xor i32 %conv23.6.43, %conv29.6.43
  %scevgep35.6.43 = getelementptr i8, i8* %a, i64 50
  %2829 = load i8, i8* %scevgep35.6.43, align 1
  %2830 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.43 = call zeroext i8 @mult(i8 zeroext %2829, i8 zeroext %2830)
  %conv35.6.43 = zext i8 %call34.6.43 to i32
  %xor36.6.43 = xor i32 %xor.6.43, %conv35.6.43
  %conv37.6.43 = trunc i32 %xor36.6.43 to i8
  store i8 %conv37.6.43, i8* %scevgep41.6.42, align 1
  %scevgep28.6.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2824, i64 0, i64 0, i64 1
  %2831 = bitcast i8* %scevgep28.6.43 to [61 x [61 x i8]]*
  %scevgep41.6.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2825, i64 0, i64 1, i64 0
  %2832 = bitcast i8* %scevgep41.6.43 to [61 x [61 x i8]]*
  %call16.6.44 = call zeroext i8 (...) @rand()
  store i8 %call16.6.44, i8* %scevgep28.6.43, align 1
  %2833 = load i8, i8* %scevgep28.6.43, align 1
  %conv23.6.44 = zext i8 %2833 to i32
  %2834 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.44 = getelementptr i8, i8* %b, i64 51
  %2835 = load i8, i8* %scevgep34.6.44, align 1
  %call28.6.44 = call zeroext i8 @mult(i8 zeroext %2834, i8 zeroext %2835)
  %conv29.6.44 = zext i8 %call28.6.44 to i32
  %xor.6.44 = xor i32 %conv23.6.44, %conv29.6.44
  %scevgep35.6.44 = getelementptr i8, i8* %a, i64 51
  %2836 = load i8, i8* %scevgep35.6.44, align 1
  %2837 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.44 = call zeroext i8 @mult(i8 zeroext %2836, i8 zeroext %2837)
  %conv35.6.44 = zext i8 %call34.6.44 to i32
  %xor36.6.44 = xor i32 %xor.6.44, %conv35.6.44
  %conv37.6.44 = trunc i32 %xor36.6.44 to i8
  store i8 %conv37.6.44, i8* %scevgep41.6.43, align 1
  %scevgep28.6.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2831, i64 0, i64 0, i64 1
  %2838 = bitcast i8* %scevgep28.6.44 to [61 x [61 x i8]]*
  %scevgep41.6.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2832, i64 0, i64 1, i64 0
  %2839 = bitcast i8* %scevgep41.6.44 to [61 x [61 x i8]]*
  %call16.6.45 = call zeroext i8 (...) @rand()
  store i8 %call16.6.45, i8* %scevgep28.6.44, align 1
  %2840 = load i8, i8* %scevgep28.6.44, align 1
  %conv23.6.45 = zext i8 %2840 to i32
  %2841 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.45 = getelementptr i8, i8* %b, i64 52
  %2842 = load i8, i8* %scevgep34.6.45, align 1
  %call28.6.45 = call zeroext i8 @mult(i8 zeroext %2841, i8 zeroext %2842)
  %conv29.6.45 = zext i8 %call28.6.45 to i32
  %xor.6.45 = xor i32 %conv23.6.45, %conv29.6.45
  %scevgep35.6.45 = getelementptr i8, i8* %a, i64 52
  %2843 = load i8, i8* %scevgep35.6.45, align 1
  %2844 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.45 = call zeroext i8 @mult(i8 zeroext %2843, i8 zeroext %2844)
  %conv35.6.45 = zext i8 %call34.6.45 to i32
  %xor36.6.45 = xor i32 %xor.6.45, %conv35.6.45
  %conv37.6.45 = trunc i32 %xor36.6.45 to i8
  store i8 %conv37.6.45, i8* %scevgep41.6.44, align 1
  %scevgep28.6.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2838, i64 0, i64 0, i64 1
  %2845 = bitcast i8* %scevgep28.6.45 to [61 x [61 x i8]]*
  %scevgep41.6.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2839, i64 0, i64 1, i64 0
  %2846 = bitcast i8* %scevgep41.6.45 to [61 x [61 x i8]]*
  %call16.6.46 = call zeroext i8 (...) @rand()
  store i8 %call16.6.46, i8* %scevgep28.6.45, align 1
  %2847 = load i8, i8* %scevgep28.6.45, align 1
  %conv23.6.46 = zext i8 %2847 to i32
  %2848 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.46 = getelementptr i8, i8* %b, i64 53
  %2849 = load i8, i8* %scevgep34.6.46, align 1
  %call28.6.46 = call zeroext i8 @mult(i8 zeroext %2848, i8 zeroext %2849)
  %conv29.6.46 = zext i8 %call28.6.46 to i32
  %xor.6.46 = xor i32 %conv23.6.46, %conv29.6.46
  %scevgep35.6.46 = getelementptr i8, i8* %a, i64 53
  %2850 = load i8, i8* %scevgep35.6.46, align 1
  %2851 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.46 = call zeroext i8 @mult(i8 zeroext %2850, i8 zeroext %2851)
  %conv35.6.46 = zext i8 %call34.6.46 to i32
  %xor36.6.46 = xor i32 %xor.6.46, %conv35.6.46
  %conv37.6.46 = trunc i32 %xor36.6.46 to i8
  store i8 %conv37.6.46, i8* %scevgep41.6.45, align 1
  %scevgep28.6.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2845, i64 0, i64 0, i64 1
  %2852 = bitcast i8* %scevgep28.6.46 to [61 x [61 x i8]]*
  %scevgep41.6.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2846, i64 0, i64 1, i64 0
  %2853 = bitcast i8* %scevgep41.6.46 to [61 x [61 x i8]]*
  %call16.6.47 = call zeroext i8 (...) @rand()
  store i8 %call16.6.47, i8* %scevgep28.6.46, align 1
  %2854 = load i8, i8* %scevgep28.6.46, align 1
  %conv23.6.47 = zext i8 %2854 to i32
  %2855 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.47 = getelementptr i8, i8* %b, i64 54
  %2856 = load i8, i8* %scevgep34.6.47, align 1
  %call28.6.47 = call zeroext i8 @mult(i8 zeroext %2855, i8 zeroext %2856)
  %conv29.6.47 = zext i8 %call28.6.47 to i32
  %xor.6.47 = xor i32 %conv23.6.47, %conv29.6.47
  %scevgep35.6.47 = getelementptr i8, i8* %a, i64 54
  %2857 = load i8, i8* %scevgep35.6.47, align 1
  %2858 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.47 = call zeroext i8 @mult(i8 zeroext %2857, i8 zeroext %2858)
  %conv35.6.47 = zext i8 %call34.6.47 to i32
  %xor36.6.47 = xor i32 %xor.6.47, %conv35.6.47
  %conv37.6.47 = trunc i32 %xor36.6.47 to i8
  store i8 %conv37.6.47, i8* %scevgep41.6.46, align 1
  %scevgep28.6.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2852, i64 0, i64 0, i64 1
  %2859 = bitcast i8* %scevgep28.6.47 to [61 x [61 x i8]]*
  %scevgep41.6.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2853, i64 0, i64 1, i64 0
  %2860 = bitcast i8* %scevgep41.6.47 to [61 x [61 x i8]]*
  %call16.6.48 = call zeroext i8 (...) @rand()
  store i8 %call16.6.48, i8* %scevgep28.6.47, align 1
  %2861 = load i8, i8* %scevgep28.6.47, align 1
  %conv23.6.48 = zext i8 %2861 to i32
  %2862 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.48 = getelementptr i8, i8* %b, i64 55
  %2863 = load i8, i8* %scevgep34.6.48, align 1
  %call28.6.48 = call zeroext i8 @mult(i8 zeroext %2862, i8 zeroext %2863)
  %conv29.6.48 = zext i8 %call28.6.48 to i32
  %xor.6.48 = xor i32 %conv23.6.48, %conv29.6.48
  %scevgep35.6.48 = getelementptr i8, i8* %a, i64 55
  %2864 = load i8, i8* %scevgep35.6.48, align 1
  %2865 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.48 = call zeroext i8 @mult(i8 zeroext %2864, i8 zeroext %2865)
  %conv35.6.48 = zext i8 %call34.6.48 to i32
  %xor36.6.48 = xor i32 %xor.6.48, %conv35.6.48
  %conv37.6.48 = trunc i32 %xor36.6.48 to i8
  store i8 %conv37.6.48, i8* %scevgep41.6.47, align 1
  %scevgep28.6.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2859, i64 0, i64 0, i64 1
  %2866 = bitcast i8* %scevgep28.6.48 to [61 x [61 x i8]]*
  %scevgep41.6.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2860, i64 0, i64 1, i64 0
  %2867 = bitcast i8* %scevgep41.6.48 to [61 x [61 x i8]]*
  %call16.6.49 = call zeroext i8 (...) @rand()
  store i8 %call16.6.49, i8* %scevgep28.6.48, align 1
  %2868 = load i8, i8* %scevgep28.6.48, align 1
  %conv23.6.49 = zext i8 %2868 to i32
  %2869 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.49 = getelementptr i8, i8* %b, i64 56
  %2870 = load i8, i8* %scevgep34.6.49, align 1
  %call28.6.49 = call zeroext i8 @mult(i8 zeroext %2869, i8 zeroext %2870)
  %conv29.6.49 = zext i8 %call28.6.49 to i32
  %xor.6.49 = xor i32 %conv23.6.49, %conv29.6.49
  %scevgep35.6.49 = getelementptr i8, i8* %a, i64 56
  %2871 = load i8, i8* %scevgep35.6.49, align 1
  %2872 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.49 = call zeroext i8 @mult(i8 zeroext %2871, i8 zeroext %2872)
  %conv35.6.49 = zext i8 %call34.6.49 to i32
  %xor36.6.49 = xor i32 %xor.6.49, %conv35.6.49
  %conv37.6.49 = trunc i32 %xor36.6.49 to i8
  store i8 %conv37.6.49, i8* %scevgep41.6.48, align 1
  %scevgep28.6.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2866, i64 0, i64 0, i64 1
  %2873 = bitcast i8* %scevgep28.6.49 to [61 x [61 x i8]]*
  %scevgep41.6.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2867, i64 0, i64 1, i64 0
  %2874 = bitcast i8* %scevgep41.6.49 to [61 x [61 x i8]]*
  %call16.6.50 = call zeroext i8 (...) @rand()
  store i8 %call16.6.50, i8* %scevgep28.6.49, align 1
  %2875 = load i8, i8* %scevgep28.6.49, align 1
  %conv23.6.50 = zext i8 %2875 to i32
  %2876 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.50 = getelementptr i8, i8* %b, i64 57
  %2877 = load i8, i8* %scevgep34.6.50, align 1
  %call28.6.50 = call zeroext i8 @mult(i8 zeroext %2876, i8 zeroext %2877)
  %conv29.6.50 = zext i8 %call28.6.50 to i32
  %xor.6.50 = xor i32 %conv23.6.50, %conv29.6.50
  %scevgep35.6.50 = getelementptr i8, i8* %a, i64 57
  %2878 = load i8, i8* %scevgep35.6.50, align 1
  %2879 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.50 = call zeroext i8 @mult(i8 zeroext %2878, i8 zeroext %2879)
  %conv35.6.50 = zext i8 %call34.6.50 to i32
  %xor36.6.50 = xor i32 %xor.6.50, %conv35.6.50
  %conv37.6.50 = trunc i32 %xor36.6.50 to i8
  store i8 %conv37.6.50, i8* %scevgep41.6.49, align 1
  %scevgep28.6.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2873, i64 0, i64 0, i64 1
  %2880 = bitcast i8* %scevgep28.6.50 to [61 x [61 x i8]]*
  %scevgep41.6.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2874, i64 0, i64 1, i64 0
  %2881 = bitcast i8* %scevgep41.6.50 to [61 x [61 x i8]]*
  %call16.6.51 = call zeroext i8 (...) @rand()
  store i8 %call16.6.51, i8* %scevgep28.6.50, align 1
  %2882 = load i8, i8* %scevgep28.6.50, align 1
  %conv23.6.51 = zext i8 %2882 to i32
  %2883 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.51 = getelementptr i8, i8* %b, i64 58
  %2884 = load i8, i8* %scevgep34.6.51, align 1
  %call28.6.51 = call zeroext i8 @mult(i8 zeroext %2883, i8 zeroext %2884)
  %conv29.6.51 = zext i8 %call28.6.51 to i32
  %xor.6.51 = xor i32 %conv23.6.51, %conv29.6.51
  %scevgep35.6.51 = getelementptr i8, i8* %a, i64 58
  %2885 = load i8, i8* %scevgep35.6.51, align 1
  %2886 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.51 = call zeroext i8 @mult(i8 zeroext %2885, i8 zeroext %2886)
  %conv35.6.51 = zext i8 %call34.6.51 to i32
  %xor36.6.51 = xor i32 %xor.6.51, %conv35.6.51
  %conv37.6.51 = trunc i32 %xor36.6.51 to i8
  store i8 %conv37.6.51, i8* %scevgep41.6.50, align 1
  %scevgep28.6.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2880, i64 0, i64 0, i64 1
  %2887 = bitcast i8* %scevgep28.6.51 to [61 x [61 x i8]]*
  %scevgep41.6.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2881, i64 0, i64 1, i64 0
  %2888 = bitcast i8* %scevgep41.6.51 to [61 x [61 x i8]]*
  %call16.6.52 = call zeroext i8 (...) @rand()
  store i8 %call16.6.52, i8* %scevgep28.6.51, align 1
  %2889 = load i8, i8* %scevgep28.6.51, align 1
  %conv23.6.52 = zext i8 %2889 to i32
  %2890 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.52 = getelementptr i8, i8* %b, i64 59
  %2891 = load i8, i8* %scevgep34.6.52, align 1
  %call28.6.52 = call zeroext i8 @mult(i8 zeroext %2890, i8 zeroext %2891)
  %conv29.6.52 = zext i8 %call28.6.52 to i32
  %xor.6.52 = xor i32 %conv23.6.52, %conv29.6.52
  %scevgep35.6.52 = getelementptr i8, i8* %a, i64 59
  %2892 = load i8, i8* %scevgep35.6.52, align 1
  %2893 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.52 = call zeroext i8 @mult(i8 zeroext %2892, i8 zeroext %2893)
  %conv35.6.52 = zext i8 %call34.6.52 to i32
  %xor36.6.52 = xor i32 %xor.6.52, %conv35.6.52
  %conv37.6.52 = trunc i32 %xor36.6.52 to i8
  store i8 %conv37.6.52, i8* %scevgep41.6.51, align 1
  %scevgep28.6.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2887, i64 0, i64 0, i64 1
  %scevgep41.6.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2888, i64 0, i64 1, i64 0
  %call16.6.53 = call zeroext i8 (...) @rand()
  store i8 %call16.6.53, i8* %scevgep28.6.52, align 1
  %2894 = load i8, i8* %scevgep28.6.52, align 1
  %conv23.6.53 = zext i8 %2894 to i32
  %2895 = load i8, i8* %arrayidx25.6, align 1
  %scevgep34.6.53 = getelementptr i8, i8* %b, i64 60
  %2896 = load i8, i8* %scevgep34.6.53, align 1
  %call28.6.53 = call zeroext i8 @mult(i8 zeroext %2895, i8 zeroext %2896)
  %conv29.6.53 = zext i8 %call28.6.53 to i32
  %xor.6.53 = xor i32 %conv23.6.53, %conv29.6.53
  %scevgep35.6.53 = getelementptr i8, i8* %a, i64 60
  %2897 = load i8, i8* %scevgep35.6.53, align 1
  %2898 = load i8, i8* %arrayidx33.6, align 1
  %call34.6.53 = call zeroext i8 @mult(i8 zeroext %2897, i8 zeroext %2898)
  %conv35.6.53 = zext i8 %call34.6.53 to i32
  %xor36.6.53 = xor i32 %xor.6.53, %conv35.6.53
  %conv37.6.53 = trunc i32 %xor36.6.53 to i8
  store i8 %conv37.6.53, i8* %scevgep41.6.52, align 1
  %scevgep26.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2523, i64 0, i64 1, i64 1
  %2899 = bitcast i8* %scevgep26.6 to [61 x [61 x i8]]*
  %scevgep39.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2524, i64 0, i64 1, i64 1
  %2900 = bitcast i8* %scevgep39.6 to [61 x [61 x i8]]*
  %arrayidx25.7 = getelementptr inbounds i8, i8* %a, i64 7
  %arrayidx33.7 = getelementptr inbounds i8, i8* %b, i64 7
  %call16.7 = call zeroext i8 (...) @rand()
  store i8 %call16.7, i8* %scevgep26.6, align 1
  %2901 = load i8, i8* %scevgep26.6, align 1
  %conv23.7 = zext i8 %2901 to i32
  %2902 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7 = getelementptr i8, i8* %b, i64 8
  %2903 = load i8, i8* %scevgep34.7, align 1
  %call28.7 = call zeroext i8 @mult(i8 zeroext %2902, i8 zeroext %2903)
  %conv29.7 = zext i8 %call28.7 to i32
  %xor.7 = xor i32 %conv23.7, %conv29.7
  %scevgep35.7 = getelementptr i8, i8* %a, i64 8
  %2904 = load i8, i8* %scevgep35.7, align 1
  %2905 = load i8, i8* %arrayidx33.7, align 1
  %call34.7 = call zeroext i8 @mult(i8 zeroext %2904, i8 zeroext %2905)
  %conv35.7 = zext i8 %call34.7 to i32
  %xor36.7 = xor i32 %xor.7, %conv35.7
  %conv37.7 = trunc i32 %xor36.7 to i8
  store i8 %conv37.7, i8* %scevgep39.6, align 1
  %scevgep28.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2899, i64 0, i64 0, i64 1
  %2906 = bitcast i8* %scevgep28.7 to [61 x [61 x i8]]*
  %scevgep41.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2900, i64 0, i64 1, i64 0
  %2907 = bitcast i8* %scevgep41.7 to [61 x [61 x i8]]*
  %call16.7.1 = call zeroext i8 (...) @rand()
  store i8 %call16.7.1, i8* %scevgep28.7, align 1
  %2908 = load i8, i8* %scevgep28.7, align 1
  %conv23.7.1 = zext i8 %2908 to i32
  %2909 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.1 = getelementptr i8, i8* %b, i64 9
  %2910 = load i8, i8* %scevgep34.7.1, align 1
  %call28.7.1 = call zeroext i8 @mult(i8 zeroext %2909, i8 zeroext %2910)
  %conv29.7.1 = zext i8 %call28.7.1 to i32
  %xor.7.1 = xor i32 %conv23.7.1, %conv29.7.1
  %scevgep35.7.1 = getelementptr i8, i8* %a, i64 9
  %2911 = load i8, i8* %scevgep35.7.1, align 1
  %2912 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.1 = call zeroext i8 @mult(i8 zeroext %2911, i8 zeroext %2912)
  %conv35.7.1 = zext i8 %call34.7.1 to i32
  %xor36.7.1 = xor i32 %xor.7.1, %conv35.7.1
  %conv37.7.1 = trunc i32 %xor36.7.1 to i8
  store i8 %conv37.7.1, i8* %scevgep41.7, align 1
  %scevgep28.7.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2906, i64 0, i64 0, i64 1
  %2913 = bitcast i8* %scevgep28.7.1 to [61 x [61 x i8]]*
  %scevgep41.7.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2907, i64 0, i64 1, i64 0
  %2914 = bitcast i8* %scevgep41.7.1 to [61 x [61 x i8]]*
  %call16.7.2 = call zeroext i8 (...) @rand()
  store i8 %call16.7.2, i8* %scevgep28.7.1, align 1
  %2915 = load i8, i8* %scevgep28.7.1, align 1
  %conv23.7.2 = zext i8 %2915 to i32
  %2916 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.2 = getelementptr i8, i8* %b, i64 10
  %2917 = load i8, i8* %scevgep34.7.2, align 1
  %call28.7.2 = call zeroext i8 @mult(i8 zeroext %2916, i8 zeroext %2917)
  %conv29.7.2 = zext i8 %call28.7.2 to i32
  %xor.7.2 = xor i32 %conv23.7.2, %conv29.7.2
  %scevgep35.7.2 = getelementptr i8, i8* %a, i64 10
  %2918 = load i8, i8* %scevgep35.7.2, align 1
  %2919 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.2 = call zeroext i8 @mult(i8 zeroext %2918, i8 zeroext %2919)
  %conv35.7.2 = zext i8 %call34.7.2 to i32
  %xor36.7.2 = xor i32 %xor.7.2, %conv35.7.2
  %conv37.7.2 = trunc i32 %xor36.7.2 to i8
  store i8 %conv37.7.2, i8* %scevgep41.7.1, align 1
  %scevgep28.7.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2913, i64 0, i64 0, i64 1
  %2920 = bitcast i8* %scevgep28.7.2 to [61 x [61 x i8]]*
  %scevgep41.7.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2914, i64 0, i64 1, i64 0
  %2921 = bitcast i8* %scevgep41.7.2 to [61 x [61 x i8]]*
  %call16.7.3 = call zeroext i8 (...) @rand()
  store i8 %call16.7.3, i8* %scevgep28.7.2, align 1
  %2922 = load i8, i8* %scevgep28.7.2, align 1
  %conv23.7.3 = zext i8 %2922 to i32
  %2923 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.3 = getelementptr i8, i8* %b, i64 11
  %2924 = load i8, i8* %scevgep34.7.3, align 1
  %call28.7.3 = call zeroext i8 @mult(i8 zeroext %2923, i8 zeroext %2924)
  %conv29.7.3 = zext i8 %call28.7.3 to i32
  %xor.7.3 = xor i32 %conv23.7.3, %conv29.7.3
  %scevgep35.7.3 = getelementptr i8, i8* %a, i64 11
  %2925 = load i8, i8* %scevgep35.7.3, align 1
  %2926 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.3 = call zeroext i8 @mult(i8 zeroext %2925, i8 zeroext %2926)
  %conv35.7.3 = zext i8 %call34.7.3 to i32
  %xor36.7.3 = xor i32 %xor.7.3, %conv35.7.3
  %conv37.7.3 = trunc i32 %xor36.7.3 to i8
  store i8 %conv37.7.3, i8* %scevgep41.7.2, align 1
  %scevgep28.7.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2920, i64 0, i64 0, i64 1
  %2927 = bitcast i8* %scevgep28.7.3 to [61 x [61 x i8]]*
  %scevgep41.7.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2921, i64 0, i64 1, i64 0
  %2928 = bitcast i8* %scevgep41.7.3 to [61 x [61 x i8]]*
  %call16.7.4 = call zeroext i8 (...) @rand()
  store i8 %call16.7.4, i8* %scevgep28.7.3, align 1
  %2929 = load i8, i8* %scevgep28.7.3, align 1
  %conv23.7.4 = zext i8 %2929 to i32
  %2930 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.4 = getelementptr i8, i8* %b, i64 12
  %2931 = load i8, i8* %scevgep34.7.4, align 1
  %call28.7.4 = call zeroext i8 @mult(i8 zeroext %2930, i8 zeroext %2931)
  %conv29.7.4 = zext i8 %call28.7.4 to i32
  %xor.7.4 = xor i32 %conv23.7.4, %conv29.7.4
  %scevgep35.7.4 = getelementptr i8, i8* %a, i64 12
  %2932 = load i8, i8* %scevgep35.7.4, align 1
  %2933 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.4 = call zeroext i8 @mult(i8 zeroext %2932, i8 zeroext %2933)
  %conv35.7.4 = zext i8 %call34.7.4 to i32
  %xor36.7.4 = xor i32 %xor.7.4, %conv35.7.4
  %conv37.7.4 = trunc i32 %xor36.7.4 to i8
  store i8 %conv37.7.4, i8* %scevgep41.7.3, align 1
  %scevgep28.7.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2927, i64 0, i64 0, i64 1
  %2934 = bitcast i8* %scevgep28.7.4 to [61 x [61 x i8]]*
  %scevgep41.7.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2928, i64 0, i64 1, i64 0
  %2935 = bitcast i8* %scevgep41.7.4 to [61 x [61 x i8]]*
  %call16.7.5 = call zeroext i8 (...) @rand()
  store i8 %call16.7.5, i8* %scevgep28.7.4, align 1
  %2936 = load i8, i8* %scevgep28.7.4, align 1
  %conv23.7.5 = zext i8 %2936 to i32
  %2937 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.5 = getelementptr i8, i8* %b, i64 13
  %2938 = load i8, i8* %scevgep34.7.5, align 1
  %call28.7.5 = call zeroext i8 @mult(i8 zeroext %2937, i8 zeroext %2938)
  %conv29.7.5 = zext i8 %call28.7.5 to i32
  %xor.7.5 = xor i32 %conv23.7.5, %conv29.7.5
  %scevgep35.7.5 = getelementptr i8, i8* %a, i64 13
  %2939 = load i8, i8* %scevgep35.7.5, align 1
  %2940 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.5 = call zeroext i8 @mult(i8 zeroext %2939, i8 zeroext %2940)
  %conv35.7.5 = zext i8 %call34.7.5 to i32
  %xor36.7.5 = xor i32 %xor.7.5, %conv35.7.5
  %conv37.7.5 = trunc i32 %xor36.7.5 to i8
  store i8 %conv37.7.5, i8* %scevgep41.7.4, align 1
  %scevgep28.7.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2934, i64 0, i64 0, i64 1
  %2941 = bitcast i8* %scevgep28.7.5 to [61 x [61 x i8]]*
  %scevgep41.7.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2935, i64 0, i64 1, i64 0
  %2942 = bitcast i8* %scevgep41.7.5 to [61 x [61 x i8]]*
  %call16.7.6 = call zeroext i8 (...) @rand()
  store i8 %call16.7.6, i8* %scevgep28.7.5, align 1
  %2943 = load i8, i8* %scevgep28.7.5, align 1
  %conv23.7.6 = zext i8 %2943 to i32
  %2944 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.6 = getelementptr i8, i8* %b, i64 14
  %2945 = load i8, i8* %scevgep34.7.6, align 1
  %call28.7.6 = call zeroext i8 @mult(i8 zeroext %2944, i8 zeroext %2945)
  %conv29.7.6 = zext i8 %call28.7.6 to i32
  %xor.7.6 = xor i32 %conv23.7.6, %conv29.7.6
  %scevgep35.7.6 = getelementptr i8, i8* %a, i64 14
  %2946 = load i8, i8* %scevgep35.7.6, align 1
  %2947 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.6 = call zeroext i8 @mult(i8 zeroext %2946, i8 zeroext %2947)
  %conv35.7.6 = zext i8 %call34.7.6 to i32
  %xor36.7.6 = xor i32 %xor.7.6, %conv35.7.6
  %conv37.7.6 = trunc i32 %xor36.7.6 to i8
  store i8 %conv37.7.6, i8* %scevgep41.7.5, align 1
  %scevgep28.7.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2941, i64 0, i64 0, i64 1
  %2948 = bitcast i8* %scevgep28.7.6 to [61 x [61 x i8]]*
  %scevgep41.7.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2942, i64 0, i64 1, i64 0
  %2949 = bitcast i8* %scevgep41.7.6 to [61 x [61 x i8]]*
  %call16.7.7 = call zeroext i8 (...) @rand()
  store i8 %call16.7.7, i8* %scevgep28.7.6, align 1
  %2950 = load i8, i8* %scevgep28.7.6, align 1
  %conv23.7.7 = zext i8 %2950 to i32
  %2951 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.7 = getelementptr i8, i8* %b, i64 15
  %2952 = load i8, i8* %scevgep34.7.7, align 1
  %call28.7.7 = call zeroext i8 @mult(i8 zeroext %2951, i8 zeroext %2952)
  %conv29.7.7 = zext i8 %call28.7.7 to i32
  %xor.7.7 = xor i32 %conv23.7.7, %conv29.7.7
  %scevgep35.7.7 = getelementptr i8, i8* %a, i64 15
  %2953 = load i8, i8* %scevgep35.7.7, align 1
  %2954 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.7 = call zeroext i8 @mult(i8 zeroext %2953, i8 zeroext %2954)
  %conv35.7.7 = zext i8 %call34.7.7 to i32
  %xor36.7.7 = xor i32 %xor.7.7, %conv35.7.7
  %conv37.7.7 = trunc i32 %xor36.7.7 to i8
  store i8 %conv37.7.7, i8* %scevgep41.7.6, align 1
  %scevgep28.7.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2948, i64 0, i64 0, i64 1
  %2955 = bitcast i8* %scevgep28.7.7 to [61 x [61 x i8]]*
  %scevgep41.7.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2949, i64 0, i64 1, i64 0
  %2956 = bitcast i8* %scevgep41.7.7 to [61 x [61 x i8]]*
  %call16.7.8 = call zeroext i8 (...) @rand()
  store i8 %call16.7.8, i8* %scevgep28.7.7, align 1
  %2957 = load i8, i8* %scevgep28.7.7, align 1
  %conv23.7.8 = zext i8 %2957 to i32
  %2958 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.8 = getelementptr i8, i8* %b, i64 16
  %2959 = load i8, i8* %scevgep34.7.8, align 1
  %call28.7.8 = call zeroext i8 @mult(i8 zeroext %2958, i8 zeroext %2959)
  %conv29.7.8 = zext i8 %call28.7.8 to i32
  %xor.7.8 = xor i32 %conv23.7.8, %conv29.7.8
  %scevgep35.7.8 = getelementptr i8, i8* %a, i64 16
  %2960 = load i8, i8* %scevgep35.7.8, align 1
  %2961 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.8 = call zeroext i8 @mult(i8 zeroext %2960, i8 zeroext %2961)
  %conv35.7.8 = zext i8 %call34.7.8 to i32
  %xor36.7.8 = xor i32 %xor.7.8, %conv35.7.8
  %conv37.7.8 = trunc i32 %xor36.7.8 to i8
  store i8 %conv37.7.8, i8* %scevgep41.7.7, align 1
  %scevgep28.7.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2955, i64 0, i64 0, i64 1
  %2962 = bitcast i8* %scevgep28.7.8 to [61 x [61 x i8]]*
  %scevgep41.7.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2956, i64 0, i64 1, i64 0
  %2963 = bitcast i8* %scevgep41.7.8 to [61 x [61 x i8]]*
  %call16.7.9 = call zeroext i8 (...) @rand()
  store i8 %call16.7.9, i8* %scevgep28.7.8, align 1
  %2964 = load i8, i8* %scevgep28.7.8, align 1
  %conv23.7.9 = zext i8 %2964 to i32
  %2965 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.9 = getelementptr i8, i8* %b, i64 17
  %2966 = load i8, i8* %scevgep34.7.9, align 1
  %call28.7.9 = call zeroext i8 @mult(i8 zeroext %2965, i8 zeroext %2966)
  %conv29.7.9 = zext i8 %call28.7.9 to i32
  %xor.7.9 = xor i32 %conv23.7.9, %conv29.7.9
  %scevgep35.7.9 = getelementptr i8, i8* %a, i64 17
  %2967 = load i8, i8* %scevgep35.7.9, align 1
  %2968 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.9 = call zeroext i8 @mult(i8 zeroext %2967, i8 zeroext %2968)
  %conv35.7.9 = zext i8 %call34.7.9 to i32
  %xor36.7.9 = xor i32 %xor.7.9, %conv35.7.9
  %conv37.7.9 = trunc i32 %xor36.7.9 to i8
  store i8 %conv37.7.9, i8* %scevgep41.7.8, align 1
  %scevgep28.7.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2962, i64 0, i64 0, i64 1
  %2969 = bitcast i8* %scevgep28.7.9 to [61 x [61 x i8]]*
  %scevgep41.7.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2963, i64 0, i64 1, i64 0
  %2970 = bitcast i8* %scevgep41.7.9 to [61 x [61 x i8]]*
  %call16.7.10 = call zeroext i8 (...) @rand()
  store i8 %call16.7.10, i8* %scevgep28.7.9, align 1
  %2971 = load i8, i8* %scevgep28.7.9, align 1
  %conv23.7.10 = zext i8 %2971 to i32
  %2972 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.10 = getelementptr i8, i8* %b, i64 18
  %2973 = load i8, i8* %scevgep34.7.10, align 1
  %call28.7.10 = call zeroext i8 @mult(i8 zeroext %2972, i8 zeroext %2973)
  %conv29.7.10 = zext i8 %call28.7.10 to i32
  %xor.7.10 = xor i32 %conv23.7.10, %conv29.7.10
  %scevgep35.7.10 = getelementptr i8, i8* %a, i64 18
  %2974 = load i8, i8* %scevgep35.7.10, align 1
  %2975 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.10 = call zeroext i8 @mult(i8 zeroext %2974, i8 zeroext %2975)
  %conv35.7.10 = zext i8 %call34.7.10 to i32
  %xor36.7.10 = xor i32 %xor.7.10, %conv35.7.10
  %conv37.7.10 = trunc i32 %xor36.7.10 to i8
  store i8 %conv37.7.10, i8* %scevgep41.7.9, align 1
  %scevgep28.7.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2969, i64 0, i64 0, i64 1
  %2976 = bitcast i8* %scevgep28.7.10 to [61 x [61 x i8]]*
  %scevgep41.7.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2970, i64 0, i64 1, i64 0
  %2977 = bitcast i8* %scevgep41.7.10 to [61 x [61 x i8]]*
  %call16.7.11 = call zeroext i8 (...) @rand()
  store i8 %call16.7.11, i8* %scevgep28.7.10, align 1
  %2978 = load i8, i8* %scevgep28.7.10, align 1
  %conv23.7.11 = zext i8 %2978 to i32
  %2979 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.11 = getelementptr i8, i8* %b, i64 19
  %2980 = load i8, i8* %scevgep34.7.11, align 1
  %call28.7.11 = call zeroext i8 @mult(i8 zeroext %2979, i8 zeroext %2980)
  %conv29.7.11 = zext i8 %call28.7.11 to i32
  %xor.7.11 = xor i32 %conv23.7.11, %conv29.7.11
  %scevgep35.7.11 = getelementptr i8, i8* %a, i64 19
  %2981 = load i8, i8* %scevgep35.7.11, align 1
  %2982 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.11 = call zeroext i8 @mult(i8 zeroext %2981, i8 zeroext %2982)
  %conv35.7.11 = zext i8 %call34.7.11 to i32
  %xor36.7.11 = xor i32 %xor.7.11, %conv35.7.11
  %conv37.7.11 = trunc i32 %xor36.7.11 to i8
  store i8 %conv37.7.11, i8* %scevgep41.7.10, align 1
  %scevgep28.7.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2976, i64 0, i64 0, i64 1
  %2983 = bitcast i8* %scevgep28.7.11 to [61 x [61 x i8]]*
  %scevgep41.7.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2977, i64 0, i64 1, i64 0
  %2984 = bitcast i8* %scevgep41.7.11 to [61 x [61 x i8]]*
  %call16.7.12 = call zeroext i8 (...) @rand()
  store i8 %call16.7.12, i8* %scevgep28.7.11, align 1
  %2985 = load i8, i8* %scevgep28.7.11, align 1
  %conv23.7.12 = zext i8 %2985 to i32
  %2986 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.12 = getelementptr i8, i8* %b, i64 20
  %2987 = load i8, i8* %scevgep34.7.12, align 1
  %call28.7.12 = call zeroext i8 @mult(i8 zeroext %2986, i8 zeroext %2987)
  %conv29.7.12 = zext i8 %call28.7.12 to i32
  %xor.7.12 = xor i32 %conv23.7.12, %conv29.7.12
  %scevgep35.7.12 = getelementptr i8, i8* %a, i64 20
  %2988 = load i8, i8* %scevgep35.7.12, align 1
  %2989 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.12 = call zeroext i8 @mult(i8 zeroext %2988, i8 zeroext %2989)
  %conv35.7.12 = zext i8 %call34.7.12 to i32
  %xor36.7.12 = xor i32 %xor.7.12, %conv35.7.12
  %conv37.7.12 = trunc i32 %xor36.7.12 to i8
  store i8 %conv37.7.12, i8* %scevgep41.7.11, align 1
  %scevgep28.7.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2983, i64 0, i64 0, i64 1
  %2990 = bitcast i8* %scevgep28.7.12 to [61 x [61 x i8]]*
  %scevgep41.7.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2984, i64 0, i64 1, i64 0
  %2991 = bitcast i8* %scevgep41.7.12 to [61 x [61 x i8]]*
  %call16.7.13 = call zeroext i8 (...) @rand()
  store i8 %call16.7.13, i8* %scevgep28.7.12, align 1
  %2992 = load i8, i8* %scevgep28.7.12, align 1
  %conv23.7.13 = zext i8 %2992 to i32
  %2993 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.13 = getelementptr i8, i8* %b, i64 21
  %2994 = load i8, i8* %scevgep34.7.13, align 1
  %call28.7.13 = call zeroext i8 @mult(i8 zeroext %2993, i8 zeroext %2994)
  %conv29.7.13 = zext i8 %call28.7.13 to i32
  %xor.7.13 = xor i32 %conv23.7.13, %conv29.7.13
  %scevgep35.7.13 = getelementptr i8, i8* %a, i64 21
  %2995 = load i8, i8* %scevgep35.7.13, align 1
  %2996 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.13 = call zeroext i8 @mult(i8 zeroext %2995, i8 zeroext %2996)
  %conv35.7.13 = zext i8 %call34.7.13 to i32
  %xor36.7.13 = xor i32 %xor.7.13, %conv35.7.13
  %conv37.7.13 = trunc i32 %xor36.7.13 to i8
  store i8 %conv37.7.13, i8* %scevgep41.7.12, align 1
  %scevgep28.7.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2990, i64 0, i64 0, i64 1
  %2997 = bitcast i8* %scevgep28.7.13 to [61 x [61 x i8]]*
  %scevgep41.7.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2991, i64 0, i64 1, i64 0
  %2998 = bitcast i8* %scevgep41.7.13 to [61 x [61 x i8]]*
  %call16.7.14 = call zeroext i8 (...) @rand()
  store i8 %call16.7.14, i8* %scevgep28.7.13, align 1
  %2999 = load i8, i8* %scevgep28.7.13, align 1
  %conv23.7.14 = zext i8 %2999 to i32
  %3000 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.14 = getelementptr i8, i8* %b, i64 22
  %3001 = load i8, i8* %scevgep34.7.14, align 1
  %call28.7.14 = call zeroext i8 @mult(i8 zeroext %3000, i8 zeroext %3001)
  %conv29.7.14 = zext i8 %call28.7.14 to i32
  %xor.7.14 = xor i32 %conv23.7.14, %conv29.7.14
  %scevgep35.7.14 = getelementptr i8, i8* %a, i64 22
  %3002 = load i8, i8* %scevgep35.7.14, align 1
  %3003 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.14 = call zeroext i8 @mult(i8 zeroext %3002, i8 zeroext %3003)
  %conv35.7.14 = zext i8 %call34.7.14 to i32
  %xor36.7.14 = xor i32 %xor.7.14, %conv35.7.14
  %conv37.7.14 = trunc i32 %xor36.7.14 to i8
  store i8 %conv37.7.14, i8* %scevgep41.7.13, align 1
  %scevgep28.7.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2997, i64 0, i64 0, i64 1
  %3004 = bitcast i8* %scevgep28.7.14 to [61 x [61 x i8]]*
  %scevgep41.7.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2998, i64 0, i64 1, i64 0
  %3005 = bitcast i8* %scevgep41.7.14 to [61 x [61 x i8]]*
  %call16.7.15 = call zeroext i8 (...) @rand()
  store i8 %call16.7.15, i8* %scevgep28.7.14, align 1
  %3006 = load i8, i8* %scevgep28.7.14, align 1
  %conv23.7.15 = zext i8 %3006 to i32
  %3007 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.15 = getelementptr i8, i8* %b, i64 23
  %3008 = load i8, i8* %scevgep34.7.15, align 1
  %call28.7.15 = call zeroext i8 @mult(i8 zeroext %3007, i8 zeroext %3008)
  %conv29.7.15 = zext i8 %call28.7.15 to i32
  %xor.7.15 = xor i32 %conv23.7.15, %conv29.7.15
  %scevgep35.7.15 = getelementptr i8, i8* %a, i64 23
  %3009 = load i8, i8* %scevgep35.7.15, align 1
  %3010 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.15 = call zeroext i8 @mult(i8 zeroext %3009, i8 zeroext %3010)
  %conv35.7.15 = zext i8 %call34.7.15 to i32
  %xor36.7.15 = xor i32 %xor.7.15, %conv35.7.15
  %conv37.7.15 = trunc i32 %xor36.7.15 to i8
  store i8 %conv37.7.15, i8* %scevgep41.7.14, align 1
  %scevgep28.7.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3004, i64 0, i64 0, i64 1
  %3011 = bitcast i8* %scevgep28.7.15 to [61 x [61 x i8]]*
  %scevgep41.7.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3005, i64 0, i64 1, i64 0
  %3012 = bitcast i8* %scevgep41.7.15 to [61 x [61 x i8]]*
  %call16.7.16 = call zeroext i8 (...) @rand()
  store i8 %call16.7.16, i8* %scevgep28.7.15, align 1
  %3013 = load i8, i8* %scevgep28.7.15, align 1
  %conv23.7.16 = zext i8 %3013 to i32
  %3014 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.16 = getelementptr i8, i8* %b, i64 24
  %3015 = load i8, i8* %scevgep34.7.16, align 1
  %call28.7.16 = call zeroext i8 @mult(i8 zeroext %3014, i8 zeroext %3015)
  %conv29.7.16 = zext i8 %call28.7.16 to i32
  %xor.7.16 = xor i32 %conv23.7.16, %conv29.7.16
  %scevgep35.7.16 = getelementptr i8, i8* %a, i64 24
  %3016 = load i8, i8* %scevgep35.7.16, align 1
  %3017 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.16 = call zeroext i8 @mult(i8 zeroext %3016, i8 zeroext %3017)
  %conv35.7.16 = zext i8 %call34.7.16 to i32
  %xor36.7.16 = xor i32 %xor.7.16, %conv35.7.16
  %conv37.7.16 = trunc i32 %xor36.7.16 to i8
  store i8 %conv37.7.16, i8* %scevgep41.7.15, align 1
  %scevgep28.7.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3011, i64 0, i64 0, i64 1
  %3018 = bitcast i8* %scevgep28.7.16 to [61 x [61 x i8]]*
  %scevgep41.7.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3012, i64 0, i64 1, i64 0
  %3019 = bitcast i8* %scevgep41.7.16 to [61 x [61 x i8]]*
  %call16.7.17 = call zeroext i8 (...) @rand()
  store i8 %call16.7.17, i8* %scevgep28.7.16, align 1
  %3020 = load i8, i8* %scevgep28.7.16, align 1
  %conv23.7.17 = zext i8 %3020 to i32
  %3021 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.17 = getelementptr i8, i8* %b, i64 25
  %3022 = load i8, i8* %scevgep34.7.17, align 1
  %call28.7.17 = call zeroext i8 @mult(i8 zeroext %3021, i8 zeroext %3022)
  %conv29.7.17 = zext i8 %call28.7.17 to i32
  %xor.7.17 = xor i32 %conv23.7.17, %conv29.7.17
  %scevgep35.7.17 = getelementptr i8, i8* %a, i64 25
  %3023 = load i8, i8* %scevgep35.7.17, align 1
  %3024 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.17 = call zeroext i8 @mult(i8 zeroext %3023, i8 zeroext %3024)
  %conv35.7.17 = zext i8 %call34.7.17 to i32
  %xor36.7.17 = xor i32 %xor.7.17, %conv35.7.17
  %conv37.7.17 = trunc i32 %xor36.7.17 to i8
  store i8 %conv37.7.17, i8* %scevgep41.7.16, align 1
  %scevgep28.7.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3018, i64 0, i64 0, i64 1
  %3025 = bitcast i8* %scevgep28.7.17 to [61 x [61 x i8]]*
  %scevgep41.7.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3019, i64 0, i64 1, i64 0
  %3026 = bitcast i8* %scevgep41.7.17 to [61 x [61 x i8]]*
  %call16.7.18 = call zeroext i8 (...) @rand()
  store i8 %call16.7.18, i8* %scevgep28.7.17, align 1
  %3027 = load i8, i8* %scevgep28.7.17, align 1
  %conv23.7.18 = zext i8 %3027 to i32
  %3028 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.18 = getelementptr i8, i8* %b, i64 26
  %3029 = load i8, i8* %scevgep34.7.18, align 1
  %call28.7.18 = call zeroext i8 @mult(i8 zeroext %3028, i8 zeroext %3029)
  %conv29.7.18 = zext i8 %call28.7.18 to i32
  %xor.7.18 = xor i32 %conv23.7.18, %conv29.7.18
  %scevgep35.7.18 = getelementptr i8, i8* %a, i64 26
  %3030 = load i8, i8* %scevgep35.7.18, align 1
  %3031 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.18 = call zeroext i8 @mult(i8 zeroext %3030, i8 zeroext %3031)
  %conv35.7.18 = zext i8 %call34.7.18 to i32
  %xor36.7.18 = xor i32 %xor.7.18, %conv35.7.18
  %conv37.7.18 = trunc i32 %xor36.7.18 to i8
  store i8 %conv37.7.18, i8* %scevgep41.7.17, align 1
  %scevgep28.7.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3025, i64 0, i64 0, i64 1
  %3032 = bitcast i8* %scevgep28.7.18 to [61 x [61 x i8]]*
  %scevgep41.7.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3026, i64 0, i64 1, i64 0
  %3033 = bitcast i8* %scevgep41.7.18 to [61 x [61 x i8]]*
  %call16.7.19 = call zeroext i8 (...) @rand()
  store i8 %call16.7.19, i8* %scevgep28.7.18, align 1
  %3034 = load i8, i8* %scevgep28.7.18, align 1
  %conv23.7.19 = zext i8 %3034 to i32
  %3035 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.19 = getelementptr i8, i8* %b, i64 27
  %3036 = load i8, i8* %scevgep34.7.19, align 1
  %call28.7.19 = call zeroext i8 @mult(i8 zeroext %3035, i8 zeroext %3036)
  %conv29.7.19 = zext i8 %call28.7.19 to i32
  %xor.7.19 = xor i32 %conv23.7.19, %conv29.7.19
  %scevgep35.7.19 = getelementptr i8, i8* %a, i64 27
  %3037 = load i8, i8* %scevgep35.7.19, align 1
  %3038 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.19 = call zeroext i8 @mult(i8 zeroext %3037, i8 zeroext %3038)
  %conv35.7.19 = zext i8 %call34.7.19 to i32
  %xor36.7.19 = xor i32 %xor.7.19, %conv35.7.19
  %conv37.7.19 = trunc i32 %xor36.7.19 to i8
  store i8 %conv37.7.19, i8* %scevgep41.7.18, align 1
  %scevgep28.7.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3032, i64 0, i64 0, i64 1
  %3039 = bitcast i8* %scevgep28.7.19 to [61 x [61 x i8]]*
  %scevgep41.7.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3033, i64 0, i64 1, i64 0
  %3040 = bitcast i8* %scevgep41.7.19 to [61 x [61 x i8]]*
  %call16.7.20 = call zeroext i8 (...) @rand()
  store i8 %call16.7.20, i8* %scevgep28.7.19, align 1
  %3041 = load i8, i8* %scevgep28.7.19, align 1
  %conv23.7.20 = zext i8 %3041 to i32
  %3042 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.20 = getelementptr i8, i8* %b, i64 28
  %3043 = load i8, i8* %scevgep34.7.20, align 1
  %call28.7.20 = call zeroext i8 @mult(i8 zeroext %3042, i8 zeroext %3043)
  %conv29.7.20 = zext i8 %call28.7.20 to i32
  %xor.7.20 = xor i32 %conv23.7.20, %conv29.7.20
  %scevgep35.7.20 = getelementptr i8, i8* %a, i64 28
  %3044 = load i8, i8* %scevgep35.7.20, align 1
  %3045 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.20 = call zeroext i8 @mult(i8 zeroext %3044, i8 zeroext %3045)
  %conv35.7.20 = zext i8 %call34.7.20 to i32
  %xor36.7.20 = xor i32 %xor.7.20, %conv35.7.20
  %conv37.7.20 = trunc i32 %xor36.7.20 to i8
  store i8 %conv37.7.20, i8* %scevgep41.7.19, align 1
  %scevgep28.7.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3039, i64 0, i64 0, i64 1
  %3046 = bitcast i8* %scevgep28.7.20 to [61 x [61 x i8]]*
  %scevgep41.7.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3040, i64 0, i64 1, i64 0
  %3047 = bitcast i8* %scevgep41.7.20 to [61 x [61 x i8]]*
  %call16.7.21 = call zeroext i8 (...) @rand()
  store i8 %call16.7.21, i8* %scevgep28.7.20, align 1
  %3048 = load i8, i8* %scevgep28.7.20, align 1
  %conv23.7.21 = zext i8 %3048 to i32
  %3049 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.21 = getelementptr i8, i8* %b, i64 29
  %3050 = load i8, i8* %scevgep34.7.21, align 1
  %call28.7.21 = call zeroext i8 @mult(i8 zeroext %3049, i8 zeroext %3050)
  %conv29.7.21 = zext i8 %call28.7.21 to i32
  %xor.7.21 = xor i32 %conv23.7.21, %conv29.7.21
  %scevgep35.7.21 = getelementptr i8, i8* %a, i64 29
  %3051 = load i8, i8* %scevgep35.7.21, align 1
  %3052 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.21 = call zeroext i8 @mult(i8 zeroext %3051, i8 zeroext %3052)
  %conv35.7.21 = zext i8 %call34.7.21 to i32
  %xor36.7.21 = xor i32 %xor.7.21, %conv35.7.21
  %conv37.7.21 = trunc i32 %xor36.7.21 to i8
  store i8 %conv37.7.21, i8* %scevgep41.7.20, align 1
  %scevgep28.7.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3046, i64 0, i64 0, i64 1
  %3053 = bitcast i8* %scevgep28.7.21 to [61 x [61 x i8]]*
  %scevgep41.7.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3047, i64 0, i64 1, i64 0
  %3054 = bitcast i8* %scevgep41.7.21 to [61 x [61 x i8]]*
  %call16.7.22 = call zeroext i8 (...) @rand()
  store i8 %call16.7.22, i8* %scevgep28.7.21, align 1
  %3055 = load i8, i8* %scevgep28.7.21, align 1
  %conv23.7.22 = zext i8 %3055 to i32
  %3056 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.22 = getelementptr i8, i8* %b, i64 30
  %3057 = load i8, i8* %scevgep34.7.22, align 1
  %call28.7.22 = call zeroext i8 @mult(i8 zeroext %3056, i8 zeroext %3057)
  %conv29.7.22 = zext i8 %call28.7.22 to i32
  %xor.7.22 = xor i32 %conv23.7.22, %conv29.7.22
  %scevgep35.7.22 = getelementptr i8, i8* %a, i64 30
  %3058 = load i8, i8* %scevgep35.7.22, align 1
  %3059 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.22 = call zeroext i8 @mult(i8 zeroext %3058, i8 zeroext %3059)
  %conv35.7.22 = zext i8 %call34.7.22 to i32
  %xor36.7.22 = xor i32 %xor.7.22, %conv35.7.22
  %conv37.7.22 = trunc i32 %xor36.7.22 to i8
  store i8 %conv37.7.22, i8* %scevgep41.7.21, align 1
  %scevgep28.7.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3053, i64 0, i64 0, i64 1
  %3060 = bitcast i8* %scevgep28.7.22 to [61 x [61 x i8]]*
  %scevgep41.7.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3054, i64 0, i64 1, i64 0
  %3061 = bitcast i8* %scevgep41.7.22 to [61 x [61 x i8]]*
  %call16.7.23 = call zeroext i8 (...) @rand()
  store i8 %call16.7.23, i8* %scevgep28.7.22, align 1
  %3062 = load i8, i8* %scevgep28.7.22, align 1
  %conv23.7.23 = zext i8 %3062 to i32
  %3063 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.23 = getelementptr i8, i8* %b, i64 31
  %3064 = load i8, i8* %scevgep34.7.23, align 1
  %call28.7.23 = call zeroext i8 @mult(i8 zeroext %3063, i8 zeroext %3064)
  %conv29.7.23 = zext i8 %call28.7.23 to i32
  %xor.7.23 = xor i32 %conv23.7.23, %conv29.7.23
  %scevgep35.7.23 = getelementptr i8, i8* %a, i64 31
  %3065 = load i8, i8* %scevgep35.7.23, align 1
  %3066 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.23 = call zeroext i8 @mult(i8 zeroext %3065, i8 zeroext %3066)
  %conv35.7.23 = zext i8 %call34.7.23 to i32
  %xor36.7.23 = xor i32 %xor.7.23, %conv35.7.23
  %conv37.7.23 = trunc i32 %xor36.7.23 to i8
  store i8 %conv37.7.23, i8* %scevgep41.7.22, align 1
  %scevgep28.7.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3060, i64 0, i64 0, i64 1
  %3067 = bitcast i8* %scevgep28.7.23 to [61 x [61 x i8]]*
  %scevgep41.7.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3061, i64 0, i64 1, i64 0
  %3068 = bitcast i8* %scevgep41.7.23 to [61 x [61 x i8]]*
  %call16.7.24 = call zeroext i8 (...) @rand()
  store i8 %call16.7.24, i8* %scevgep28.7.23, align 1
  %3069 = load i8, i8* %scevgep28.7.23, align 1
  %conv23.7.24 = zext i8 %3069 to i32
  %3070 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.24 = getelementptr i8, i8* %b, i64 32
  %3071 = load i8, i8* %scevgep34.7.24, align 1
  %call28.7.24 = call zeroext i8 @mult(i8 zeroext %3070, i8 zeroext %3071)
  %conv29.7.24 = zext i8 %call28.7.24 to i32
  %xor.7.24 = xor i32 %conv23.7.24, %conv29.7.24
  %scevgep35.7.24 = getelementptr i8, i8* %a, i64 32
  %3072 = load i8, i8* %scevgep35.7.24, align 1
  %3073 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.24 = call zeroext i8 @mult(i8 zeroext %3072, i8 zeroext %3073)
  %conv35.7.24 = zext i8 %call34.7.24 to i32
  %xor36.7.24 = xor i32 %xor.7.24, %conv35.7.24
  %conv37.7.24 = trunc i32 %xor36.7.24 to i8
  store i8 %conv37.7.24, i8* %scevgep41.7.23, align 1
  %scevgep28.7.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3067, i64 0, i64 0, i64 1
  %3074 = bitcast i8* %scevgep28.7.24 to [61 x [61 x i8]]*
  %scevgep41.7.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3068, i64 0, i64 1, i64 0
  %3075 = bitcast i8* %scevgep41.7.24 to [61 x [61 x i8]]*
  %call16.7.25 = call zeroext i8 (...) @rand()
  store i8 %call16.7.25, i8* %scevgep28.7.24, align 1
  %3076 = load i8, i8* %scevgep28.7.24, align 1
  %conv23.7.25 = zext i8 %3076 to i32
  %3077 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.25 = getelementptr i8, i8* %b, i64 33
  %3078 = load i8, i8* %scevgep34.7.25, align 1
  %call28.7.25 = call zeroext i8 @mult(i8 zeroext %3077, i8 zeroext %3078)
  %conv29.7.25 = zext i8 %call28.7.25 to i32
  %xor.7.25 = xor i32 %conv23.7.25, %conv29.7.25
  %scevgep35.7.25 = getelementptr i8, i8* %a, i64 33
  %3079 = load i8, i8* %scevgep35.7.25, align 1
  %3080 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.25 = call zeroext i8 @mult(i8 zeroext %3079, i8 zeroext %3080)
  %conv35.7.25 = zext i8 %call34.7.25 to i32
  %xor36.7.25 = xor i32 %xor.7.25, %conv35.7.25
  %conv37.7.25 = trunc i32 %xor36.7.25 to i8
  store i8 %conv37.7.25, i8* %scevgep41.7.24, align 1
  %scevgep28.7.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3074, i64 0, i64 0, i64 1
  %3081 = bitcast i8* %scevgep28.7.25 to [61 x [61 x i8]]*
  %scevgep41.7.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3075, i64 0, i64 1, i64 0
  %3082 = bitcast i8* %scevgep41.7.25 to [61 x [61 x i8]]*
  %call16.7.26 = call zeroext i8 (...) @rand()
  store i8 %call16.7.26, i8* %scevgep28.7.25, align 1
  %3083 = load i8, i8* %scevgep28.7.25, align 1
  %conv23.7.26 = zext i8 %3083 to i32
  %3084 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.26 = getelementptr i8, i8* %b, i64 34
  %3085 = load i8, i8* %scevgep34.7.26, align 1
  %call28.7.26 = call zeroext i8 @mult(i8 zeroext %3084, i8 zeroext %3085)
  %conv29.7.26 = zext i8 %call28.7.26 to i32
  %xor.7.26 = xor i32 %conv23.7.26, %conv29.7.26
  %scevgep35.7.26 = getelementptr i8, i8* %a, i64 34
  %3086 = load i8, i8* %scevgep35.7.26, align 1
  %3087 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.26 = call zeroext i8 @mult(i8 zeroext %3086, i8 zeroext %3087)
  %conv35.7.26 = zext i8 %call34.7.26 to i32
  %xor36.7.26 = xor i32 %xor.7.26, %conv35.7.26
  %conv37.7.26 = trunc i32 %xor36.7.26 to i8
  store i8 %conv37.7.26, i8* %scevgep41.7.25, align 1
  %scevgep28.7.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3081, i64 0, i64 0, i64 1
  %3088 = bitcast i8* %scevgep28.7.26 to [61 x [61 x i8]]*
  %scevgep41.7.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3082, i64 0, i64 1, i64 0
  %3089 = bitcast i8* %scevgep41.7.26 to [61 x [61 x i8]]*
  %call16.7.27 = call zeroext i8 (...) @rand()
  store i8 %call16.7.27, i8* %scevgep28.7.26, align 1
  %3090 = load i8, i8* %scevgep28.7.26, align 1
  %conv23.7.27 = zext i8 %3090 to i32
  %3091 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.27 = getelementptr i8, i8* %b, i64 35
  %3092 = load i8, i8* %scevgep34.7.27, align 1
  %call28.7.27 = call zeroext i8 @mult(i8 zeroext %3091, i8 zeroext %3092)
  %conv29.7.27 = zext i8 %call28.7.27 to i32
  %xor.7.27 = xor i32 %conv23.7.27, %conv29.7.27
  %scevgep35.7.27 = getelementptr i8, i8* %a, i64 35
  %3093 = load i8, i8* %scevgep35.7.27, align 1
  %3094 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.27 = call zeroext i8 @mult(i8 zeroext %3093, i8 zeroext %3094)
  %conv35.7.27 = zext i8 %call34.7.27 to i32
  %xor36.7.27 = xor i32 %xor.7.27, %conv35.7.27
  %conv37.7.27 = trunc i32 %xor36.7.27 to i8
  store i8 %conv37.7.27, i8* %scevgep41.7.26, align 1
  %scevgep28.7.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3088, i64 0, i64 0, i64 1
  %3095 = bitcast i8* %scevgep28.7.27 to [61 x [61 x i8]]*
  %scevgep41.7.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3089, i64 0, i64 1, i64 0
  %3096 = bitcast i8* %scevgep41.7.27 to [61 x [61 x i8]]*
  %call16.7.28 = call zeroext i8 (...) @rand()
  store i8 %call16.7.28, i8* %scevgep28.7.27, align 1
  %3097 = load i8, i8* %scevgep28.7.27, align 1
  %conv23.7.28 = zext i8 %3097 to i32
  %3098 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.28 = getelementptr i8, i8* %b, i64 36
  %3099 = load i8, i8* %scevgep34.7.28, align 1
  %call28.7.28 = call zeroext i8 @mult(i8 zeroext %3098, i8 zeroext %3099)
  %conv29.7.28 = zext i8 %call28.7.28 to i32
  %xor.7.28 = xor i32 %conv23.7.28, %conv29.7.28
  %scevgep35.7.28 = getelementptr i8, i8* %a, i64 36
  %3100 = load i8, i8* %scevgep35.7.28, align 1
  %3101 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.28 = call zeroext i8 @mult(i8 zeroext %3100, i8 zeroext %3101)
  %conv35.7.28 = zext i8 %call34.7.28 to i32
  %xor36.7.28 = xor i32 %xor.7.28, %conv35.7.28
  %conv37.7.28 = trunc i32 %xor36.7.28 to i8
  store i8 %conv37.7.28, i8* %scevgep41.7.27, align 1
  %scevgep28.7.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3095, i64 0, i64 0, i64 1
  %3102 = bitcast i8* %scevgep28.7.28 to [61 x [61 x i8]]*
  %scevgep41.7.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3096, i64 0, i64 1, i64 0
  %3103 = bitcast i8* %scevgep41.7.28 to [61 x [61 x i8]]*
  %call16.7.29 = call zeroext i8 (...) @rand()
  store i8 %call16.7.29, i8* %scevgep28.7.28, align 1
  %3104 = load i8, i8* %scevgep28.7.28, align 1
  %conv23.7.29 = zext i8 %3104 to i32
  %3105 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.29 = getelementptr i8, i8* %b, i64 37
  %3106 = load i8, i8* %scevgep34.7.29, align 1
  %call28.7.29 = call zeroext i8 @mult(i8 zeroext %3105, i8 zeroext %3106)
  %conv29.7.29 = zext i8 %call28.7.29 to i32
  %xor.7.29 = xor i32 %conv23.7.29, %conv29.7.29
  %scevgep35.7.29 = getelementptr i8, i8* %a, i64 37
  %3107 = load i8, i8* %scevgep35.7.29, align 1
  %3108 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.29 = call zeroext i8 @mult(i8 zeroext %3107, i8 zeroext %3108)
  %conv35.7.29 = zext i8 %call34.7.29 to i32
  %xor36.7.29 = xor i32 %xor.7.29, %conv35.7.29
  %conv37.7.29 = trunc i32 %xor36.7.29 to i8
  store i8 %conv37.7.29, i8* %scevgep41.7.28, align 1
  %scevgep28.7.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3102, i64 0, i64 0, i64 1
  %3109 = bitcast i8* %scevgep28.7.29 to [61 x [61 x i8]]*
  %scevgep41.7.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3103, i64 0, i64 1, i64 0
  %3110 = bitcast i8* %scevgep41.7.29 to [61 x [61 x i8]]*
  %call16.7.30 = call zeroext i8 (...) @rand()
  store i8 %call16.7.30, i8* %scevgep28.7.29, align 1
  %3111 = load i8, i8* %scevgep28.7.29, align 1
  %conv23.7.30 = zext i8 %3111 to i32
  %3112 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.30 = getelementptr i8, i8* %b, i64 38
  %3113 = load i8, i8* %scevgep34.7.30, align 1
  %call28.7.30 = call zeroext i8 @mult(i8 zeroext %3112, i8 zeroext %3113)
  %conv29.7.30 = zext i8 %call28.7.30 to i32
  %xor.7.30 = xor i32 %conv23.7.30, %conv29.7.30
  %scevgep35.7.30 = getelementptr i8, i8* %a, i64 38
  %3114 = load i8, i8* %scevgep35.7.30, align 1
  %3115 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.30 = call zeroext i8 @mult(i8 zeroext %3114, i8 zeroext %3115)
  %conv35.7.30 = zext i8 %call34.7.30 to i32
  %xor36.7.30 = xor i32 %xor.7.30, %conv35.7.30
  %conv37.7.30 = trunc i32 %xor36.7.30 to i8
  store i8 %conv37.7.30, i8* %scevgep41.7.29, align 1
  %scevgep28.7.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3109, i64 0, i64 0, i64 1
  %3116 = bitcast i8* %scevgep28.7.30 to [61 x [61 x i8]]*
  %scevgep41.7.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3110, i64 0, i64 1, i64 0
  %3117 = bitcast i8* %scevgep41.7.30 to [61 x [61 x i8]]*
  %call16.7.31 = call zeroext i8 (...) @rand()
  store i8 %call16.7.31, i8* %scevgep28.7.30, align 1
  %3118 = load i8, i8* %scevgep28.7.30, align 1
  %conv23.7.31 = zext i8 %3118 to i32
  %3119 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.31 = getelementptr i8, i8* %b, i64 39
  %3120 = load i8, i8* %scevgep34.7.31, align 1
  %call28.7.31 = call zeroext i8 @mult(i8 zeroext %3119, i8 zeroext %3120)
  %conv29.7.31 = zext i8 %call28.7.31 to i32
  %xor.7.31 = xor i32 %conv23.7.31, %conv29.7.31
  %scevgep35.7.31 = getelementptr i8, i8* %a, i64 39
  %3121 = load i8, i8* %scevgep35.7.31, align 1
  %3122 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.31 = call zeroext i8 @mult(i8 zeroext %3121, i8 zeroext %3122)
  %conv35.7.31 = zext i8 %call34.7.31 to i32
  %xor36.7.31 = xor i32 %xor.7.31, %conv35.7.31
  %conv37.7.31 = trunc i32 %xor36.7.31 to i8
  store i8 %conv37.7.31, i8* %scevgep41.7.30, align 1
  %scevgep28.7.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3116, i64 0, i64 0, i64 1
  %3123 = bitcast i8* %scevgep28.7.31 to [61 x [61 x i8]]*
  %scevgep41.7.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3117, i64 0, i64 1, i64 0
  %3124 = bitcast i8* %scevgep41.7.31 to [61 x [61 x i8]]*
  %call16.7.32 = call zeroext i8 (...) @rand()
  store i8 %call16.7.32, i8* %scevgep28.7.31, align 1
  %3125 = load i8, i8* %scevgep28.7.31, align 1
  %conv23.7.32 = zext i8 %3125 to i32
  %3126 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.32 = getelementptr i8, i8* %b, i64 40
  %3127 = load i8, i8* %scevgep34.7.32, align 1
  %call28.7.32 = call zeroext i8 @mult(i8 zeroext %3126, i8 zeroext %3127)
  %conv29.7.32 = zext i8 %call28.7.32 to i32
  %xor.7.32 = xor i32 %conv23.7.32, %conv29.7.32
  %scevgep35.7.32 = getelementptr i8, i8* %a, i64 40
  %3128 = load i8, i8* %scevgep35.7.32, align 1
  %3129 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.32 = call zeroext i8 @mult(i8 zeroext %3128, i8 zeroext %3129)
  %conv35.7.32 = zext i8 %call34.7.32 to i32
  %xor36.7.32 = xor i32 %xor.7.32, %conv35.7.32
  %conv37.7.32 = trunc i32 %xor36.7.32 to i8
  store i8 %conv37.7.32, i8* %scevgep41.7.31, align 1
  %scevgep28.7.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3123, i64 0, i64 0, i64 1
  %3130 = bitcast i8* %scevgep28.7.32 to [61 x [61 x i8]]*
  %scevgep41.7.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3124, i64 0, i64 1, i64 0
  %3131 = bitcast i8* %scevgep41.7.32 to [61 x [61 x i8]]*
  %call16.7.33 = call zeroext i8 (...) @rand()
  store i8 %call16.7.33, i8* %scevgep28.7.32, align 1
  %3132 = load i8, i8* %scevgep28.7.32, align 1
  %conv23.7.33 = zext i8 %3132 to i32
  %3133 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.33 = getelementptr i8, i8* %b, i64 41
  %3134 = load i8, i8* %scevgep34.7.33, align 1
  %call28.7.33 = call zeroext i8 @mult(i8 zeroext %3133, i8 zeroext %3134)
  %conv29.7.33 = zext i8 %call28.7.33 to i32
  %xor.7.33 = xor i32 %conv23.7.33, %conv29.7.33
  %scevgep35.7.33 = getelementptr i8, i8* %a, i64 41
  %3135 = load i8, i8* %scevgep35.7.33, align 1
  %3136 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.33 = call zeroext i8 @mult(i8 zeroext %3135, i8 zeroext %3136)
  %conv35.7.33 = zext i8 %call34.7.33 to i32
  %xor36.7.33 = xor i32 %xor.7.33, %conv35.7.33
  %conv37.7.33 = trunc i32 %xor36.7.33 to i8
  store i8 %conv37.7.33, i8* %scevgep41.7.32, align 1
  %scevgep28.7.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3130, i64 0, i64 0, i64 1
  %3137 = bitcast i8* %scevgep28.7.33 to [61 x [61 x i8]]*
  %scevgep41.7.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3131, i64 0, i64 1, i64 0
  %3138 = bitcast i8* %scevgep41.7.33 to [61 x [61 x i8]]*
  %call16.7.34 = call zeroext i8 (...) @rand()
  store i8 %call16.7.34, i8* %scevgep28.7.33, align 1
  %3139 = load i8, i8* %scevgep28.7.33, align 1
  %conv23.7.34 = zext i8 %3139 to i32
  %3140 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.34 = getelementptr i8, i8* %b, i64 42
  %3141 = load i8, i8* %scevgep34.7.34, align 1
  %call28.7.34 = call zeroext i8 @mult(i8 zeroext %3140, i8 zeroext %3141)
  %conv29.7.34 = zext i8 %call28.7.34 to i32
  %xor.7.34 = xor i32 %conv23.7.34, %conv29.7.34
  %scevgep35.7.34 = getelementptr i8, i8* %a, i64 42
  %3142 = load i8, i8* %scevgep35.7.34, align 1
  %3143 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.34 = call zeroext i8 @mult(i8 zeroext %3142, i8 zeroext %3143)
  %conv35.7.34 = zext i8 %call34.7.34 to i32
  %xor36.7.34 = xor i32 %xor.7.34, %conv35.7.34
  %conv37.7.34 = trunc i32 %xor36.7.34 to i8
  store i8 %conv37.7.34, i8* %scevgep41.7.33, align 1
  %scevgep28.7.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3137, i64 0, i64 0, i64 1
  %3144 = bitcast i8* %scevgep28.7.34 to [61 x [61 x i8]]*
  %scevgep41.7.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3138, i64 0, i64 1, i64 0
  %3145 = bitcast i8* %scevgep41.7.34 to [61 x [61 x i8]]*
  %call16.7.35 = call zeroext i8 (...) @rand()
  store i8 %call16.7.35, i8* %scevgep28.7.34, align 1
  %3146 = load i8, i8* %scevgep28.7.34, align 1
  %conv23.7.35 = zext i8 %3146 to i32
  %3147 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.35 = getelementptr i8, i8* %b, i64 43
  %3148 = load i8, i8* %scevgep34.7.35, align 1
  %call28.7.35 = call zeroext i8 @mult(i8 zeroext %3147, i8 zeroext %3148)
  %conv29.7.35 = zext i8 %call28.7.35 to i32
  %xor.7.35 = xor i32 %conv23.7.35, %conv29.7.35
  %scevgep35.7.35 = getelementptr i8, i8* %a, i64 43
  %3149 = load i8, i8* %scevgep35.7.35, align 1
  %3150 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.35 = call zeroext i8 @mult(i8 zeroext %3149, i8 zeroext %3150)
  %conv35.7.35 = zext i8 %call34.7.35 to i32
  %xor36.7.35 = xor i32 %xor.7.35, %conv35.7.35
  %conv37.7.35 = trunc i32 %xor36.7.35 to i8
  store i8 %conv37.7.35, i8* %scevgep41.7.34, align 1
  %scevgep28.7.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3144, i64 0, i64 0, i64 1
  %3151 = bitcast i8* %scevgep28.7.35 to [61 x [61 x i8]]*
  %scevgep41.7.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3145, i64 0, i64 1, i64 0
  %3152 = bitcast i8* %scevgep41.7.35 to [61 x [61 x i8]]*
  %call16.7.36 = call zeroext i8 (...) @rand()
  store i8 %call16.7.36, i8* %scevgep28.7.35, align 1
  %3153 = load i8, i8* %scevgep28.7.35, align 1
  %conv23.7.36 = zext i8 %3153 to i32
  %3154 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.36 = getelementptr i8, i8* %b, i64 44
  %3155 = load i8, i8* %scevgep34.7.36, align 1
  %call28.7.36 = call zeroext i8 @mult(i8 zeroext %3154, i8 zeroext %3155)
  %conv29.7.36 = zext i8 %call28.7.36 to i32
  %xor.7.36 = xor i32 %conv23.7.36, %conv29.7.36
  %scevgep35.7.36 = getelementptr i8, i8* %a, i64 44
  %3156 = load i8, i8* %scevgep35.7.36, align 1
  %3157 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.36 = call zeroext i8 @mult(i8 zeroext %3156, i8 zeroext %3157)
  %conv35.7.36 = zext i8 %call34.7.36 to i32
  %xor36.7.36 = xor i32 %xor.7.36, %conv35.7.36
  %conv37.7.36 = trunc i32 %xor36.7.36 to i8
  store i8 %conv37.7.36, i8* %scevgep41.7.35, align 1
  %scevgep28.7.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3151, i64 0, i64 0, i64 1
  %3158 = bitcast i8* %scevgep28.7.36 to [61 x [61 x i8]]*
  %scevgep41.7.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3152, i64 0, i64 1, i64 0
  %3159 = bitcast i8* %scevgep41.7.36 to [61 x [61 x i8]]*
  %call16.7.37 = call zeroext i8 (...) @rand()
  store i8 %call16.7.37, i8* %scevgep28.7.36, align 1
  %3160 = load i8, i8* %scevgep28.7.36, align 1
  %conv23.7.37 = zext i8 %3160 to i32
  %3161 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.37 = getelementptr i8, i8* %b, i64 45
  %3162 = load i8, i8* %scevgep34.7.37, align 1
  %call28.7.37 = call zeroext i8 @mult(i8 zeroext %3161, i8 zeroext %3162)
  %conv29.7.37 = zext i8 %call28.7.37 to i32
  %xor.7.37 = xor i32 %conv23.7.37, %conv29.7.37
  %scevgep35.7.37 = getelementptr i8, i8* %a, i64 45
  %3163 = load i8, i8* %scevgep35.7.37, align 1
  %3164 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.37 = call zeroext i8 @mult(i8 zeroext %3163, i8 zeroext %3164)
  %conv35.7.37 = zext i8 %call34.7.37 to i32
  %xor36.7.37 = xor i32 %xor.7.37, %conv35.7.37
  %conv37.7.37 = trunc i32 %xor36.7.37 to i8
  store i8 %conv37.7.37, i8* %scevgep41.7.36, align 1
  %scevgep28.7.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3158, i64 0, i64 0, i64 1
  %3165 = bitcast i8* %scevgep28.7.37 to [61 x [61 x i8]]*
  %scevgep41.7.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3159, i64 0, i64 1, i64 0
  %3166 = bitcast i8* %scevgep41.7.37 to [61 x [61 x i8]]*
  %call16.7.38 = call zeroext i8 (...) @rand()
  store i8 %call16.7.38, i8* %scevgep28.7.37, align 1
  %3167 = load i8, i8* %scevgep28.7.37, align 1
  %conv23.7.38 = zext i8 %3167 to i32
  %3168 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.38 = getelementptr i8, i8* %b, i64 46
  %3169 = load i8, i8* %scevgep34.7.38, align 1
  %call28.7.38 = call zeroext i8 @mult(i8 zeroext %3168, i8 zeroext %3169)
  %conv29.7.38 = zext i8 %call28.7.38 to i32
  %xor.7.38 = xor i32 %conv23.7.38, %conv29.7.38
  %scevgep35.7.38 = getelementptr i8, i8* %a, i64 46
  %3170 = load i8, i8* %scevgep35.7.38, align 1
  %3171 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.38 = call zeroext i8 @mult(i8 zeroext %3170, i8 zeroext %3171)
  %conv35.7.38 = zext i8 %call34.7.38 to i32
  %xor36.7.38 = xor i32 %xor.7.38, %conv35.7.38
  %conv37.7.38 = trunc i32 %xor36.7.38 to i8
  store i8 %conv37.7.38, i8* %scevgep41.7.37, align 1
  %scevgep28.7.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3165, i64 0, i64 0, i64 1
  %3172 = bitcast i8* %scevgep28.7.38 to [61 x [61 x i8]]*
  %scevgep41.7.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3166, i64 0, i64 1, i64 0
  %3173 = bitcast i8* %scevgep41.7.38 to [61 x [61 x i8]]*
  %call16.7.39 = call zeroext i8 (...) @rand()
  store i8 %call16.7.39, i8* %scevgep28.7.38, align 1
  %3174 = load i8, i8* %scevgep28.7.38, align 1
  %conv23.7.39 = zext i8 %3174 to i32
  %3175 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.39 = getelementptr i8, i8* %b, i64 47
  %3176 = load i8, i8* %scevgep34.7.39, align 1
  %call28.7.39 = call zeroext i8 @mult(i8 zeroext %3175, i8 zeroext %3176)
  %conv29.7.39 = zext i8 %call28.7.39 to i32
  %xor.7.39 = xor i32 %conv23.7.39, %conv29.7.39
  %scevgep35.7.39 = getelementptr i8, i8* %a, i64 47
  %3177 = load i8, i8* %scevgep35.7.39, align 1
  %3178 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.39 = call zeroext i8 @mult(i8 zeroext %3177, i8 zeroext %3178)
  %conv35.7.39 = zext i8 %call34.7.39 to i32
  %xor36.7.39 = xor i32 %xor.7.39, %conv35.7.39
  %conv37.7.39 = trunc i32 %xor36.7.39 to i8
  store i8 %conv37.7.39, i8* %scevgep41.7.38, align 1
  %scevgep28.7.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3172, i64 0, i64 0, i64 1
  %3179 = bitcast i8* %scevgep28.7.39 to [61 x [61 x i8]]*
  %scevgep41.7.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3173, i64 0, i64 1, i64 0
  %3180 = bitcast i8* %scevgep41.7.39 to [61 x [61 x i8]]*
  %call16.7.40 = call zeroext i8 (...) @rand()
  store i8 %call16.7.40, i8* %scevgep28.7.39, align 1
  %3181 = load i8, i8* %scevgep28.7.39, align 1
  %conv23.7.40 = zext i8 %3181 to i32
  %3182 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.40 = getelementptr i8, i8* %b, i64 48
  %3183 = load i8, i8* %scevgep34.7.40, align 1
  %call28.7.40 = call zeroext i8 @mult(i8 zeroext %3182, i8 zeroext %3183)
  %conv29.7.40 = zext i8 %call28.7.40 to i32
  %xor.7.40 = xor i32 %conv23.7.40, %conv29.7.40
  %scevgep35.7.40 = getelementptr i8, i8* %a, i64 48
  %3184 = load i8, i8* %scevgep35.7.40, align 1
  %3185 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.40 = call zeroext i8 @mult(i8 zeroext %3184, i8 zeroext %3185)
  %conv35.7.40 = zext i8 %call34.7.40 to i32
  %xor36.7.40 = xor i32 %xor.7.40, %conv35.7.40
  %conv37.7.40 = trunc i32 %xor36.7.40 to i8
  store i8 %conv37.7.40, i8* %scevgep41.7.39, align 1
  %scevgep28.7.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3179, i64 0, i64 0, i64 1
  %3186 = bitcast i8* %scevgep28.7.40 to [61 x [61 x i8]]*
  %scevgep41.7.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3180, i64 0, i64 1, i64 0
  %3187 = bitcast i8* %scevgep41.7.40 to [61 x [61 x i8]]*
  %call16.7.41 = call zeroext i8 (...) @rand()
  store i8 %call16.7.41, i8* %scevgep28.7.40, align 1
  %3188 = load i8, i8* %scevgep28.7.40, align 1
  %conv23.7.41 = zext i8 %3188 to i32
  %3189 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.41 = getelementptr i8, i8* %b, i64 49
  %3190 = load i8, i8* %scevgep34.7.41, align 1
  %call28.7.41 = call zeroext i8 @mult(i8 zeroext %3189, i8 zeroext %3190)
  %conv29.7.41 = zext i8 %call28.7.41 to i32
  %xor.7.41 = xor i32 %conv23.7.41, %conv29.7.41
  %scevgep35.7.41 = getelementptr i8, i8* %a, i64 49
  %3191 = load i8, i8* %scevgep35.7.41, align 1
  %3192 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.41 = call zeroext i8 @mult(i8 zeroext %3191, i8 zeroext %3192)
  %conv35.7.41 = zext i8 %call34.7.41 to i32
  %xor36.7.41 = xor i32 %xor.7.41, %conv35.7.41
  %conv37.7.41 = trunc i32 %xor36.7.41 to i8
  store i8 %conv37.7.41, i8* %scevgep41.7.40, align 1
  %scevgep28.7.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3186, i64 0, i64 0, i64 1
  %3193 = bitcast i8* %scevgep28.7.41 to [61 x [61 x i8]]*
  %scevgep41.7.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3187, i64 0, i64 1, i64 0
  %3194 = bitcast i8* %scevgep41.7.41 to [61 x [61 x i8]]*
  %call16.7.42 = call zeroext i8 (...) @rand()
  store i8 %call16.7.42, i8* %scevgep28.7.41, align 1
  %3195 = load i8, i8* %scevgep28.7.41, align 1
  %conv23.7.42 = zext i8 %3195 to i32
  %3196 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.42 = getelementptr i8, i8* %b, i64 50
  %3197 = load i8, i8* %scevgep34.7.42, align 1
  %call28.7.42 = call zeroext i8 @mult(i8 zeroext %3196, i8 zeroext %3197)
  %conv29.7.42 = zext i8 %call28.7.42 to i32
  %xor.7.42 = xor i32 %conv23.7.42, %conv29.7.42
  %scevgep35.7.42 = getelementptr i8, i8* %a, i64 50
  %3198 = load i8, i8* %scevgep35.7.42, align 1
  %3199 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.42 = call zeroext i8 @mult(i8 zeroext %3198, i8 zeroext %3199)
  %conv35.7.42 = zext i8 %call34.7.42 to i32
  %xor36.7.42 = xor i32 %xor.7.42, %conv35.7.42
  %conv37.7.42 = trunc i32 %xor36.7.42 to i8
  store i8 %conv37.7.42, i8* %scevgep41.7.41, align 1
  %scevgep28.7.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3193, i64 0, i64 0, i64 1
  %3200 = bitcast i8* %scevgep28.7.42 to [61 x [61 x i8]]*
  %scevgep41.7.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3194, i64 0, i64 1, i64 0
  %3201 = bitcast i8* %scevgep41.7.42 to [61 x [61 x i8]]*
  %call16.7.43 = call zeroext i8 (...) @rand()
  store i8 %call16.7.43, i8* %scevgep28.7.42, align 1
  %3202 = load i8, i8* %scevgep28.7.42, align 1
  %conv23.7.43 = zext i8 %3202 to i32
  %3203 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.43 = getelementptr i8, i8* %b, i64 51
  %3204 = load i8, i8* %scevgep34.7.43, align 1
  %call28.7.43 = call zeroext i8 @mult(i8 zeroext %3203, i8 zeroext %3204)
  %conv29.7.43 = zext i8 %call28.7.43 to i32
  %xor.7.43 = xor i32 %conv23.7.43, %conv29.7.43
  %scevgep35.7.43 = getelementptr i8, i8* %a, i64 51
  %3205 = load i8, i8* %scevgep35.7.43, align 1
  %3206 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.43 = call zeroext i8 @mult(i8 zeroext %3205, i8 zeroext %3206)
  %conv35.7.43 = zext i8 %call34.7.43 to i32
  %xor36.7.43 = xor i32 %xor.7.43, %conv35.7.43
  %conv37.7.43 = trunc i32 %xor36.7.43 to i8
  store i8 %conv37.7.43, i8* %scevgep41.7.42, align 1
  %scevgep28.7.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3200, i64 0, i64 0, i64 1
  %3207 = bitcast i8* %scevgep28.7.43 to [61 x [61 x i8]]*
  %scevgep41.7.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3201, i64 0, i64 1, i64 0
  %3208 = bitcast i8* %scevgep41.7.43 to [61 x [61 x i8]]*
  %call16.7.44 = call zeroext i8 (...) @rand()
  store i8 %call16.7.44, i8* %scevgep28.7.43, align 1
  %3209 = load i8, i8* %scevgep28.7.43, align 1
  %conv23.7.44 = zext i8 %3209 to i32
  %3210 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.44 = getelementptr i8, i8* %b, i64 52
  %3211 = load i8, i8* %scevgep34.7.44, align 1
  %call28.7.44 = call zeroext i8 @mult(i8 zeroext %3210, i8 zeroext %3211)
  %conv29.7.44 = zext i8 %call28.7.44 to i32
  %xor.7.44 = xor i32 %conv23.7.44, %conv29.7.44
  %scevgep35.7.44 = getelementptr i8, i8* %a, i64 52
  %3212 = load i8, i8* %scevgep35.7.44, align 1
  %3213 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.44 = call zeroext i8 @mult(i8 zeroext %3212, i8 zeroext %3213)
  %conv35.7.44 = zext i8 %call34.7.44 to i32
  %xor36.7.44 = xor i32 %xor.7.44, %conv35.7.44
  %conv37.7.44 = trunc i32 %xor36.7.44 to i8
  store i8 %conv37.7.44, i8* %scevgep41.7.43, align 1
  %scevgep28.7.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3207, i64 0, i64 0, i64 1
  %3214 = bitcast i8* %scevgep28.7.44 to [61 x [61 x i8]]*
  %scevgep41.7.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3208, i64 0, i64 1, i64 0
  %3215 = bitcast i8* %scevgep41.7.44 to [61 x [61 x i8]]*
  %call16.7.45 = call zeroext i8 (...) @rand()
  store i8 %call16.7.45, i8* %scevgep28.7.44, align 1
  %3216 = load i8, i8* %scevgep28.7.44, align 1
  %conv23.7.45 = zext i8 %3216 to i32
  %3217 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.45 = getelementptr i8, i8* %b, i64 53
  %3218 = load i8, i8* %scevgep34.7.45, align 1
  %call28.7.45 = call zeroext i8 @mult(i8 zeroext %3217, i8 zeroext %3218)
  %conv29.7.45 = zext i8 %call28.7.45 to i32
  %xor.7.45 = xor i32 %conv23.7.45, %conv29.7.45
  %scevgep35.7.45 = getelementptr i8, i8* %a, i64 53
  %3219 = load i8, i8* %scevgep35.7.45, align 1
  %3220 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.45 = call zeroext i8 @mult(i8 zeroext %3219, i8 zeroext %3220)
  %conv35.7.45 = zext i8 %call34.7.45 to i32
  %xor36.7.45 = xor i32 %xor.7.45, %conv35.7.45
  %conv37.7.45 = trunc i32 %xor36.7.45 to i8
  store i8 %conv37.7.45, i8* %scevgep41.7.44, align 1
  %scevgep28.7.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3214, i64 0, i64 0, i64 1
  %3221 = bitcast i8* %scevgep28.7.45 to [61 x [61 x i8]]*
  %scevgep41.7.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3215, i64 0, i64 1, i64 0
  %3222 = bitcast i8* %scevgep41.7.45 to [61 x [61 x i8]]*
  %call16.7.46 = call zeroext i8 (...) @rand()
  store i8 %call16.7.46, i8* %scevgep28.7.45, align 1
  %3223 = load i8, i8* %scevgep28.7.45, align 1
  %conv23.7.46 = zext i8 %3223 to i32
  %3224 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.46 = getelementptr i8, i8* %b, i64 54
  %3225 = load i8, i8* %scevgep34.7.46, align 1
  %call28.7.46 = call zeroext i8 @mult(i8 zeroext %3224, i8 zeroext %3225)
  %conv29.7.46 = zext i8 %call28.7.46 to i32
  %xor.7.46 = xor i32 %conv23.7.46, %conv29.7.46
  %scevgep35.7.46 = getelementptr i8, i8* %a, i64 54
  %3226 = load i8, i8* %scevgep35.7.46, align 1
  %3227 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.46 = call zeroext i8 @mult(i8 zeroext %3226, i8 zeroext %3227)
  %conv35.7.46 = zext i8 %call34.7.46 to i32
  %xor36.7.46 = xor i32 %xor.7.46, %conv35.7.46
  %conv37.7.46 = trunc i32 %xor36.7.46 to i8
  store i8 %conv37.7.46, i8* %scevgep41.7.45, align 1
  %scevgep28.7.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3221, i64 0, i64 0, i64 1
  %3228 = bitcast i8* %scevgep28.7.46 to [61 x [61 x i8]]*
  %scevgep41.7.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3222, i64 0, i64 1, i64 0
  %3229 = bitcast i8* %scevgep41.7.46 to [61 x [61 x i8]]*
  %call16.7.47 = call zeroext i8 (...) @rand()
  store i8 %call16.7.47, i8* %scevgep28.7.46, align 1
  %3230 = load i8, i8* %scevgep28.7.46, align 1
  %conv23.7.47 = zext i8 %3230 to i32
  %3231 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.47 = getelementptr i8, i8* %b, i64 55
  %3232 = load i8, i8* %scevgep34.7.47, align 1
  %call28.7.47 = call zeroext i8 @mult(i8 zeroext %3231, i8 zeroext %3232)
  %conv29.7.47 = zext i8 %call28.7.47 to i32
  %xor.7.47 = xor i32 %conv23.7.47, %conv29.7.47
  %scevgep35.7.47 = getelementptr i8, i8* %a, i64 55
  %3233 = load i8, i8* %scevgep35.7.47, align 1
  %3234 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.47 = call zeroext i8 @mult(i8 zeroext %3233, i8 zeroext %3234)
  %conv35.7.47 = zext i8 %call34.7.47 to i32
  %xor36.7.47 = xor i32 %xor.7.47, %conv35.7.47
  %conv37.7.47 = trunc i32 %xor36.7.47 to i8
  store i8 %conv37.7.47, i8* %scevgep41.7.46, align 1
  %scevgep28.7.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3228, i64 0, i64 0, i64 1
  %3235 = bitcast i8* %scevgep28.7.47 to [61 x [61 x i8]]*
  %scevgep41.7.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3229, i64 0, i64 1, i64 0
  %3236 = bitcast i8* %scevgep41.7.47 to [61 x [61 x i8]]*
  %call16.7.48 = call zeroext i8 (...) @rand()
  store i8 %call16.7.48, i8* %scevgep28.7.47, align 1
  %3237 = load i8, i8* %scevgep28.7.47, align 1
  %conv23.7.48 = zext i8 %3237 to i32
  %3238 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.48 = getelementptr i8, i8* %b, i64 56
  %3239 = load i8, i8* %scevgep34.7.48, align 1
  %call28.7.48 = call zeroext i8 @mult(i8 zeroext %3238, i8 zeroext %3239)
  %conv29.7.48 = zext i8 %call28.7.48 to i32
  %xor.7.48 = xor i32 %conv23.7.48, %conv29.7.48
  %scevgep35.7.48 = getelementptr i8, i8* %a, i64 56
  %3240 = load i8, i8* %scevgep35.7.48, align 1
  %3241 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.48 = call zeroext i8 @mult(i8 zeroext %3240, i8 zeroext %3241)
  %conv35.7.48 = zext i8 %call34.7.48 to i32
  %xor36.7.48 = xor i32 %xor.7.48, %conv35.7.48
  %conv37.7.48 = trunc i32 %xor36.7.48 to i8
  store i8 %conv37.7.48, i8* %scevgep41.7.47, align 1
  %scevgep28.7.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3235, i64 0, i64 0, i64 1
  %3242 = bitcast i8* %scevgep28.7.48 to [61 x [61 x i8]]*
  %scevgep41.7.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3236, i64 0, i64 1, i64 0
  %3243 = bitcast i8* %scevgep41.7.48 to [61 x [61 x i8]]*
  %call16.7.49 = call zeroext i8 (...) @rand()
  store i8 %call16.7.49, i8* %scevgep28.7.48, align 1
  %3244 = load i8, i8* %scevgep28.7.48, align 1
  %conv23.7.49 = zext i8 %3244 to i32
  %3245 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.49 = getelementptr i8, i8* %b, i64 57
  %3246 = load i8, i8* %scevgep34.7.49, align 1
  %call28.7.49 = call zeroext i8 @mult(i8 zeroext %3245, i8 zeroext %3246)
  %conv29.7.49 = zext i8 %call28.7.49 to i32
  %xor.7.49 = xor i32 %conv23.7.49, %conv29.7.49
  %scevgep35.7.49 = getelementptr i8, i8* %a, i64 57
  %3247 = load i8, i8* %scevgep35.7.49, align 1
  %3248 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.49 = call zeroext i8 @mult(i8 zeroext %3247, i8 zeroext %3248)
  %conv35.7.49 = zext i8 %call34.7.49 to i32
  %xor36.7.49 = xor i32 %xor.7.49, %conv35.7.49
  %conv37.7.49 = trunc i32 %xor36.7.49 to i8
  store i8 %conv37.7.49, i8* %scevgep41.7.48, align 1
  %scevgep28.7.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3242, i64 0, i64 0, i64 1
  %3249 = bitcast i8* %scevgep28.7.49 to [61 x [61 x i8]]*
  %scevgep41.7.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3243, i64 0, i64 1, i64 0
  %3250 = bitcast i8* %scevgep41.7.49 to [61 x [61 x i8]]*
  %call16.7.50 = call zeroext i8 (...) @rand()
  store i8 %call16.7.50, i8* %scevgep28.7.49, align 1
  %3251 = load i8, i8* %scevgep28.7.49, align 1
  %conv23.7.50 = zext i8 %3251 to i32
  %3252 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.50 = getelementptr i8, i8* %b, i64 58
  %3253 = load i8, i8* %scevgep34.7.50, align 1
  %call28.7.50 = call zeroext i8 @mult(i8 zeroext %3252, i8 zeroext %3253)
  %conv29.7.50 = zext i8 %call28.7.50 to i32
  %xor.7.50 = xor i32 %conv23.7.50, %conv29.7.50
  %scevgep35.7.50 = getelementptr i8, i8* %a, i64 58
  %3254 = load i8, i8* %scevgep35.7.50, align 1
  %3255 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.50 = call zeroext i8 @mult(i8 zeroext %3254, i8 zeroext %3255)
  %conv35.7.50 = zext i8 %call34.7.50 to i32
  %xor36.7.50 = xor i32 %xor.7.50, %conv35.7.50
  %conv37.7.50 = trunc i32 %xor36.7.50 to i8
  store i8 %conv37.7.50, i8* %scevgep41.7.49, align 1
  %scevgep28.7.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3249, i64 0, i64 0, i64 1
  %3256 = bitcast i8* %scevgep28.7.50 to [61 x [61 x i8]]*
  %scevgep41.7.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3250, i64 0, i64 1, i64 0
  %3257 = bitcast i8* %scevgep41.7.50 to [61 x [61 x i8]]*
  %call16.7.51 = call zeroext i8 (...) @rand()
  store i8 %call16.7.51, i8* %scevgep28.7.50, align 1
  %3258 = load i8, i8* %scevgep28.7.50, align 1
  %conv23.7.51 = zext i8 %3258 to i32
  %3259 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.51 = getelementptr i8, i8* %b, i64 59
  %3260 = load i8, i8* %scevgep34.7.51, align 1
  %call28.7.51 = call zeroext i8 @mult(i8 zeroext %3259, i8 zeroext %3260)
  %conv29.7.51 = zext i8 %call28.7.51 to i32
  %xor.7.51 = xor i32 %conv23.7.51, %conv29.7.51
  %scevgep35.7.51 = getelementptr i8, i8* %a, i64 59
  %3261 = load i8, i8* %scevgep35.7.51, align 1
  %3262 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.51 = call zeroext i8 @mult(i8 zeroext %3261, i8 zeroext %3262)
  %conv35.7.51 = zext i8 %call34.7.51 to i32
  %xor36.7.51 = xor i32 %xor.7.51, %conv35.7.51
  %conv37.7.51 = trunc i32 %xor36.7.51 to i8
  store i8 %conv37.7.51, i8* %scevgep41.7.50, align 1
  %scevgep28.7.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3256, i64 0, i64 0, i64 1
  %scevgep41.7.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3257, i64 0, i64 1, i64 0
  %call16.7.52 = call zeroext i8 (...) @rand()
  store i8 %call16.7.52, i8* %scevgep28.7.51, align 1
  %3263 = load i8, i8* %scevgep28.7.51, align 1
  %conv23.7.52 = zext i8 %3263 to i32
  %3264 = load i8, i8* %arrayidx25.7, align 1
  %scevgep34.7.52 = getelementptr i8, i8* %b, i64 60
  %3265 = load i8, i8* %scevgep34.7.52, align 1
  %call28.7.52 = call zeroext i8 @mult(i8 zeroext %3264, i8 zeroext %3265)
  %conv29.7.52 = zext i8 %call28.7.52 to i32
  %xor.7.52 = xor i32 %conv23.7.52, %conv29.7.52
  %scevgep35.7.52 = getelementptr i8, i8* %a, i64 60
  %3266 = load i8, i8* %scevgep35.7.52, align 1
  %3267 = load i8, i8* %arrayidx33.7, align 1
  %call34.7.52 = call zeroext i8 @mult(i8 zeroext %3266, i8 zeroext %3267)
  %conv35.7.52 = zext i8 %call34.7.52 to i32
  %xor36.7.52 = xor i32 %xor.7.52, %conv35.7.52
  %conv37.7.52 = trunc i32 %xor36.7.52 to i8
  store i8 %conv37.7.52, i8* %scevgep41.7.51, align 1
  %scevgep26.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2899, i64 0, i64 1, i64 1
  %3268 = bitcast i8* %scevgep26.7 to [61 x [61 x i8]]*
  %scevgep39.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %2900, i64 0, i64 1, i64 1
  %3269 = bitcast i8* %scevgep39.7 to [61 x [61 x i8]]*
  %arrayidx25.8 = getelementptr inbounds i8, i8* %a, i64 8
  %arrayidx33.8 = getelementptr inbounds i8, i8* %b, i64 8
  %call16.8 = call zeroext i8 (...) @rand()
  store i8 %call16.8, i8* %scevgep26.7, align 1
  %3270 = load i8, i8* %scevgep26.7, align 1
  %conv23.8 = zext i8 %3270 to i32
  %3271 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8 = getelementptr i8, i8* %b, i64 9
  %3272 = load i8, i8* %scevgep34.8, align 1
  %call28.8 = call zeroext i8 @mult(i8 zeroext %3271, i8 zeroext %3272)
  %conv29.8 = zext i8 %call28.8 to i32
  %xor.8 = xor i32 %conv23.8, %conv29.8
  %scevgep35.8 = getelementptr i8, i8* %a, i64 9
  %3273 = load i8, i8* %scevgep35.8, align 1
  %3274 = load i8, i8* %arrayidx33.8, align 1
  %call34.8 = call zeroext i8 @mult(i8 zeroext %3273, i8 zeroext %3274)
  %conv35.8 = zext i8 %call34.8 to i32
  %xor36.8 = xor i32 %xor.8, %conv35.8
  %conv37.8 = trunc i32 %xor36.8 to i8
  store i8 %conv37.8, i8* %scevgep39.7, align 1
  %scevgep28.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3268, i64 0, i64 0, i64 1
  %3275 = bitcast i8* %scevgep28.8 to [61 x [61 x i8]]*
  %scevgep41.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3269, i64 0, i64 1, i64 0
  %3276 = bitcast i8* %scevgep41.8 to [61 x [61 x i8]]*
  %call16.8.1 = call zeroext i8 (...) @rand()
  store i8 %call16.8.1, i8* %scevgep28.8, align 1
  %3277 = load i8, i8* %scevgep28.8, align 1
  %conv23.8.1 = zext i8 %3277 to i32
  %3278 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.1 = getelementptr i8, i8* %b, i64 10
  %3279 = load i8, i8* %scevgep34.8.1, align 1
  %call28.8.1 = call zeroext i8 @mult(i8 zeroext %3278, i8 zeroext %3279)
  %conv29.8.1 = zext i8 %call28.8.1 to i32
  %xor.8.1 = xor i32 %conv23.8.1, %conv29.8.1
  %scevgep35.8.1 = getelementptr i8, i8* %a, i64 10
  %3280 = load i8, i8* %scevgep35.8.1, align 1
  %3281 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.1 = call zeroext i8 @mult(i8 zeroext %3280, i8 zeroext %3281)
  %conv35.8.1 = zext i8 %call34.8.1 to i32
  %xor36.8.1 = xor i32 %xor.8.1, %conv35.8.1
  %conv37.8.1 = trunc i32 %xor36.8.1 to i8
  store i8 %conv37.8.1, i8* %scevgep41.8, align 1
  %scevgep28.8.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3275, i64 0, i64 0, i64 1
  %3282 = bitcast i8* %scevgep28.8.1 to [61 x [61 x i8]]*
  %scevgep41.8.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3276, i64 0, i64 1, i64 0
  %3283 = bitcast i8* %scevgep41.8.1 to [61 x [61 x i8]]*
  %call16.8.2 = call zeroext i8 (...) @rand()
  store i8 %call16.8.2, i8* %scevgep28.8.1, align 1
  %3284 = load i8, i8* %scevgep28.8.1, align 1
  %conv23.8.2 = zext i8 %3284 to i32
  %3285 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.2 = getelementptr i8, i8* %b, i64 11
  %3286 = load i8, i8* %scevgep34.8.2, align 1
  %call28.8.2 = call zeroext i8 @mult(i8 zeroext %3285, i8 zeroext %3286)
  %conv29.8.2 = zext i8 %call28.8.2 to i32
  %xor.8.2 = xor i32 %conv23.8.2, %conv29.8.2
  %scevgep35.8.2 = getelementptr i8, i8* %a, i64 11
  %3287 = load i8, i8* %scevgep35.8.2, align 1
  %3288 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.2 = call zeroext i8 @mult(i8 zeroext %3287, i8 zeroext %3288)
  %conv35.8.2 = zext i8 %call34.8.2 to i32
  %xor36.8.2 = xor i32 %xor.8.2, %conv35.8.2
  %conv37.8.2 = trunc i32 %xor36.8.2 to i8
  store i8 %conv37.8.2, i8* %scevgep41.8.1, align 1
  %scevgep28.8.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3282, i64 0, i64 0, i64 1
  %3289 = bitcast i8* %scevgep28.8.2 to [61 x [61 x i8]]*
  %scevgep41.8.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3283, i64 0, i64 1, i64 0
  %3290 = bitcast i8* %scevgep41.8.2 to [61 x [61 x i8]]*
  %call16.8.3 = call zeroext i8 (...) @rand()
  store i8 %call16.8.3, i8* %scevgep28.8.2, align 1
  %3291 = load i8, i8* %scevgep28.8.2, align 1
  %conv23.8.3 = zext i8 %3291 to i32
  %3292 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.3 = getelementptr i8, i8* %b, i64 12
  %3293 = load i8, i8* %scevgep34.8.3, align 1
  %call28.8.3 = call zeroext i8 @mult(i8 zeroext %3292, i8 zeroext %3293)
  %conv29.8.3 = zext i8 %call28.8.3 to i32
  %xor.8.3 = xor i32 %conv23.8.3, %conv29.8.3
  %scevgep35.8.3 = getelementptr i8, i8* %a, i64 12
  %3294 = load i8, i8* %scevgep35.8.3, align 1
  %3295 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.3 = call zeroext i8 @mult(i8 zeroext %3294, i8 zeroext %3295)
  %conv35.8.3 = zext i8 %call34.8.3 to i32
  %xor36.8.3 = xor i32 %xor.8.3, %conv35.8.3
  %conv37.8.3 = trunc i32 %xor36.8.3 to i8
  store i8 %conv37.8.3, i8* %scevgep41.8.2, align 1
  %scevgep28.8.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3289, i64 0, i64 0, i64 1
  %3296 = bitcast i8* %scevgep28.8.3 to [61 x [61 x i8]]*
  %scevgep41.8.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3290, i64 0, i64 1, i64 0
  %3297 = bitcast i8* %scevgep41.8.3 to [61 x [61 x i8]]*
  %call16.8.4 = call zeroext i8 (...) @rand()
  store i8 %call16.8.4, i8* %scevgep28.8.3, align 1
  %3298 = load i8, i8* %scevgep28.8.3, align 1
  %conv23.8.4 = zext i8 %3298 to i32
  %3299 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.4 = getelementptr i8, i8* %b, i64 13
  %3300 = load i8, i8* %scevgep34.8.4, align 1
  %call28.8.4 = call zeroext i8 @mult(i8 zeroext %3299, i8 zeroext %3300)
  %conv29.8.4 = zext i8 %call28.8.4 to i32
  %xor.8.4 = xor i32 %conv23.8.4, %conv29.8.4
  %scevgep35.8.4 = getelementptr i8, i8* %a, i64 13
  %3301 = load i8, i8* %scevgep35.8.4, align 1
  %3302 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.4 = call zeroext i8 @mult(i8 zeroext %3301, i8 zeroext %3302)
  %conv35.8.4 = zext i8 %call34.8.4 to i32
  %xor36.8.4 = xor i32 %xor.8.4, %conv35.8.4
  %conv37.8.4 = trunc i32 %xor36.8.4 to i8
  store i8 %conv37.8.4, i8* %scevgep41.8.3, align 1
  %scevgep28.8.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3296, i64 0, i64 0, i64 1
  %3303 = bitcast i8* %scevgep28.8.4 to [61 x [61 x i8]]*
  %scevgep41.8.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3297, i64 0, i64 1, i64 0
  %3304 = bitcast i8* %scevgep41.8.4 to [61 x [61 x i8]]*
  %call16.8.5 = call zeroext i8 (...) @rand()
  store i8 %call16.8.5, i8* %scevgep28.8.4, align 1
  %3305 = load i8, i8* %scevgep28.8.4, align 1
  %conv23.8.5 = zext i8 %3305 to i32
  %3306 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.5 = getelementptr i8, i8* %b, i64 14
  %3307 = load i8, i8* %scevgep34.8.5, align 1
  %call28.8.5 = call zeroext i8 @mult(i8 zeroext %3306, i8 zeroext %3307)
  %conv29.8.5 = zext i8 %call28.8.5 to i32
  %xor.8.5 = xor i32 %conv23.8.5, %conv29.8.5
  %scevgep35.8.5 = getelementptr i8, i8* %a, i64 14
  %3308 = load i8, i8* %scevgep35.8.5, align 1
  %3309 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.5 = call zeroext i8 @mult(i8 zeroext %3308, i8 zeroext %3309)
  %conv35.8.5 = zext i8 %call34.8.5 to i32
  %xor36.8.5 = xor i32 %xor.8.5, %conv35.8.5
  %conv37.8.5 = trunc i32 %xor36.8.5 to i8
  store i8 %conv37.8.5, i8* %scevgep41.8.4, align 1
  %scevgep28.8.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3303, i64 0, i64 0, i64 1
  %3310 = bitcast i8* %scevgep28.8.5 to [61 x [61 x i8]]*
  %scevgep41.8.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3304, i64 0, i64 1, i64 0
  %3311 = bitcast i8* %scevgep41.8.5 to [61 x [61 x i8]]*
  %call16.8.6 = call zeroext i8 (...) @rand()
  store i8 %call16.8.6, i8* %scevgep28.8.5, align 1
  %3312 = load i8, i8* %scevgep28.8.5, align 1
  %conv23.8.6 = zext i8 %3312 to i32
  %3313 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.6 = getelementptr i8, i8* %b, i64 15
  %3314 = load i8, i8* %scevgep34.8.6, align 1
  %call28.8.6 = call zeroext i8 @mult(i8 zeroext %3313, i8 zeroext %3314)
  %conv29.8.6 = zext i8 %call28.8.6 to i32
  %xor.8.6 = xor i32 %conv23.8.6, %conv29.8.6
  %scevgep35.8.6 = getelementptr i8, i8* %a, i64 15
  %3315 = load i8, i8* %scevgep35.8.6, align 1
  %3316 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.6 = call zeroext i8 @mult(i8 zeroext %3315, i8 zeroext %3316)
  %conv35.8.6 = zext i8 %call34.8.6 to i32
  %xor36.8.6 = xor i32 %xor.8.6, %conv35.8.6
  %conv37.8.6 = trunc i32 %xor36.8.6 to i8
  store i8 %conv37.8.6, i8* %scevgep41.8.5, align 1
  %scevgep28.8.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3310, i64 0, i64 0, i64 1
  %3317 = bitcast i8* %scevgep28.8.6 to [61 x [61 x i8]]*
  %scevgep41.8.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3311, i64 0, i64 1, i64 0
  %3318 = bitcast i8* %scevgep41.8.6 to [61 x [61 x i8]]*
  %call16.8.7 = call zeroext i8 (...) @rand()
  store i8 %call16.8.7, i8* %scevgep28.8.6, align 1
  %3319 = load i8, i8* %scevgep28.8.6, align 1
  %conv23.8.7 = zext i8 %3319 to i32
  %3320 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.7 = getelementptr i8, i8* %b, i64 16
  %3321 = load i8, i8* %scevgep34.8.7, align 1
  %call28.8.7 = call zeroext i8 @mult(i8 zeroext %3320, i8 zeroext %3321)
  %conv29.8.7 = zext i8 %call28.8.7 to i32
  %xor.8.7 = xor i32 %conv23.8.7, %conv29.8.7
  %scevgep35.8.7 = getelementptr i8, i8* %a, i64 16
  %3322 = load i8, i8* %scevgep35.8.7, align 1
  %3323 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.7 = call zeroext i8 @mult(i8 zeroext %3322, i8 zeroext %3323)
  %conv35.8.7 = zext i8 %call34.8.7 to i32
  %xor36.8.7 = xor i32 %xor.8.7, %conv35.8.7
  %conv37.8.7 = trunc i32 %xor36.8.7 to i8
  store i8 %conv37.8.7, i8* %scevgep41.8.6, align 1
  %scevgep28.8.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3317, i64 0, i64 0, i64 1
  %3324 = bitcast i8* %scevgep28.8.7 to [61 x [61 x i8]]*
  %scevgep41.8.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3318, i64 0, i64 1, i64 0
  %3325 = bitcast i8* %scevgep41.8.7 to [61 x [61 x i8]]*
  %call16.8.8 = call zeroext i8 (...) @rand()
  store i8 %call16.8.8, i8* %scevgep28.8.7, align 1
  %3326 = load i8, i8* %scevgep28.8.7, align 1
  %conv23.8.8 = zext i8 %3326 to i32
  %3327 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.8 = getelementptr i8, i8* %b, i64 17
  %3328 = load i8, i8* %scevgep34.8.8, align 1
  %call28.8.8 = call zeroext i8 @mult(i8 zeroext %3327, i8 zeroext %3328)
  %conv29.8.8 = zext i8 %call28.8.8 to i32
  %xor.8.8 = xor i32 %conv23.8.8, %conv29.8.8
  %scevgep35.8.8 = getelementptr i8, i8* %a, i64 17
  %3329 = load i8, i8* %scevgep35.8.8, align 1
  %3330 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.8 = call zeroext i8 @mult(i8 zeroext %3329, i8 zeroext %3330)
  %conv35.8.8 = zext i8 %call34.8.8 to i32
  %xor36.8.8 = xor i32 %xor.8.8, %conv35.8.8
  %conv37.8.8 = trunc i32 %xor36.8.8 to i8
  store i8 %conv37.8.8, i8* %scevgep41.8.7, align 1
  %scevgep28.8.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3324, i64 0, i64 0, i64 1
  %3331 = bitcast i8* %scevgep28.8.8 to [61 x [61 x i8]]*
  %scevgep41.8.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3325, i64 0, i64 1, i64 0
  %3332 = bitcast i8* %scevgep41.8.8 to [61 x [61 x i8]]*
  %call16.8.9 = call zeroext i8 (...) @rand()
  store i8 %call16.8.9, i8* %scevgep28.8.8, align 1
  %3333 = load i8, i8* %scevgep28.8.8, align 1
  %conv23.8.9 = zext i8 %3333 to i32
  %3334 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.9 = getelementptr i8, i8* %b, i64 18
  %3335 = load i8, i8* %scevgep34.8.9, align 1
  %call28.8.9 = call zeroext i8 @mult(i8 zeroext %3334, i8 zeroext %3335)
  %conv29.8.9 = zext i8 %call28.8.9 to i32
  %xor.8.9 = xor i32 %conv23.8.9, %conv29.8.9
  %scevgep35.8.9 = getelementptr i8, i8* %a, i64 18
  %3336 = load i8, i8* %scevgep35.8.9, align 1
  %3337 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.9 = call zeroext i8 @mult(i8 zeroext %3336, i8 zeroext %3337)
  %conv35.8.9 = zext i8 %call34.8.9 to i32
  %xor36.8.9 = xor i32 %xor.8.9, %conv35.8.9
  %conv37.8.9 = trunc i32 %xor36.8.9 to i8
  store i8 %conv37.8.9, i8* %scevgep41.8.8, align 1
  %scevgep28.8.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3331, i64 0, i64 0, i64 1
  %3338 = bitcast i8* %scevgep28.8.9 to [61 x [61 x i8]]*
  %scevgep41.8.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3332, i64 0, i64 1, i64 0
  %3339 = bitcast i8* %scevgep41.8.9 to [61 x [61 x i8]]*
  %call16.8.10 = call zeroext i8 (...) @rand()
  store i8 %call16.8.10, i8* %scevgep28.8.9, align 1
  %3340 = load i8, i8* %scevgep28.8.9, align 1
  %conv23.8.10 = zext i8 %3340 to i32
  %3341 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.10 = getelementptr i8, i8* %b, i64 19
  %3342 = load i8, i8* %scevgep34.8.10, align 1
  %call28.8.10 = call zeroext i8 @mult(i8 zeroext %3341, i8 zeroext %3342)
  %conv29.8.10 = zext i8 %call28.8.10 to i32
  %xor.8.10 = xor i32 %conv23.8.10, %conv29.8.10
  %scevgep35.8.10 = getelementptr i8, i8* %a, i64 19
  %3343 = load i8, i8* %scevgep35.8.10, align 1
  %3344 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.10 = call zeroext i8 @mult(i8 zeroext %3343, i8 zeroext %3344)
  %conv35.8.10 = zext i8 %call34.8.10 to i32
  %xor36.8.10 = xor i32 %xor.8.10, %conv35.8.10
  %conv37.8.10 = trunc i32 %xor36.8.10 to i8
  store i8 %conv37.8.10, i8* %scevgep41.8.9, align 1
  %scevgep28.8.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3338, i64 0, i64 0, i64 1
  %3345 = bitcast i8* %scevgep28.8.10 to [61 x [61 x i8]]*
  %scevgep41.8.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3339, i64 0, i64 1, i64 0
  %3346 = bitcast i8* %scevgep41.8.10 to [61 x [61 x i8]]*
  %call16.8.11 = call zeroext i8 (...) @rand()
  store i8 %call16.8.11, i8* %scevgep28.8.10, align 1
  %3347 = load i8, i8* %scevgep28.8.10, align 1
  %conv23.8.11 = zext i8 %3347 to i32
  %3348 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.11 = getelementptr i8, i8* %b, i64 20
  %3349 = load i8, i8* %scevgep34.8.11, align 1
  %call28.8.11 = call zeroext i8 @mult(i8 zeroext %3348, i8 zeroext %3349)
  %conv29.8.11 = zext i8 %call28.8.11 to i32
  %xor.8.11 = xor i32 %conv23.8.11, %conv29.8.11
  %scevgep35.8.11 = getelementptr i8, i8* %a, i64 20
  %3350 = load i8, i8* %scevgep35.8.11, align 1
  %3351 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.11 = call zeroext i8 @mult(i8 zeroext %3350, i8 zeroext %3351)
  %conv35.8.11 = zext i8 %call34.8.11 to i32
  %xor36.8.11 = xor i32 %xor.8.11, %conv35.8.11
  %conv37.8.11 = trunc i32 %xor36.8.11 to i8
  store i8 %conv37.8.11, i8* %scevgep41.8.10, align 1
  %scevgep28.8.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3345, i64 0, i64 0, i64 1
  %3352 = bitcast i8* %scevgep28.8.11 to [61 x [61 x i8]]*
  %scevgep41.8.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3346, i64 0, i64 1, i64 0
  %3353 = bitcast i8* %scevgep41.8.11 to [61 x [61 x i8]]*
  %call16.8.12 = call zeroext i8 (...) @rand()
  store i8 %call16.8.12, i8* %scevgep28.8.11, align 1
  %3354 = load i8, i8* %scevgep28.8.11, align 1
  %conv23.8.12 = zext i8 %3354 to i32
  %3355 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.12 = getelementptr i8, i8* %b, i64 21
  %3356 = load i8, i8* %scevgep34.8.12, align 1
  %call28.8.12 = call zeroext i8 @mult(i8 zeroext %3355, i8 zeroext %3356)
  %conv29.8.12 = zext i8 %call28.8.12 to i32
  %xor.8.12 = xor i32 %conv23.8.12, %conv29.8.12
  %scevgep35.8.12 = getelementptr i8, i8* %a, i64 21
  %3357 = load i8, i8* %scevgep35.8.12, align 1
  %3358 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.12 = call zeroext i8 @mult(i8 zeroext %3357, i8 zeroext %3358)
  %conv35.8.12 = zext i8 %call34.8.12 to i32
  %xor36.8.12 = xor i32 %xor.8.12, %conv35.8.12
  %conv37.8.12 = trunc i32 %xor36.8.12 to i8
  store i8 %conv37.8.12, i8* %scevgep41.8.11, align 1
  %scevgep28.8.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3352, i64 0, i64 0, i64 1
  %3359 = bitcast i8* %scevgep28.8.12 to [61 x [61 x i8]]*
  %scevgep41.8.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3353, i64 0, i64 1, i64 0
  %3360 = bitcast i8* %scevgep41.8.12 to [61 x [61 x i8]]*
  %call16.8.13 = call zeroext i8 (...) @rand()
  store i8 %call16.8.13, i8* %scevgep28.8.12, align 1
  %3361 = load i8, i8* %scevgep28.8.12, align 1
  %conv23.8.13 = zext i8 %3361 to i32
  %3362 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.13 = getelementptr i8, i8* %b, i64 22
  %3363 = load i8, i8* %scevgep34.8.13, align 1
  %call28.8.13 = call zeroext i8 @mult(i8 zeroext %3362, i8 zeroext %3363)
  %conv29.8.13 = zext i8 %call28.8.13 to i32
  %xor.8.13 = xor i32 %conv23.8.13, %conv29.8.13
  %scevgep35.8.13 = getelementptr i8, i8* %a, i64 22
  %3364 = load i8, i8* %scevgep35.8.13, align 1
  %3365 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.13 = call zeroext i8 @mult(i8 zeroext %3364, i8 zeroext %3365)
  %conv35.8.13 = zext i8 %call34.8.13 to i32
  %xor36.8.13 = xor i32 %xor.8.13, %conv35.8.13
  %conv37.8.13 = trunc i32 %xor36.8.13 to i8
  store i8 %conv37.8.13, i8* %scevgep41.8.12, align 1
  %scevgep28.8.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3359, i64 0, i64 0, i64 1
  %3366 = bitcast i8* %scevgep28.8.13 to [61 x [61 x i8]]*
  %scevgep41.8.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3360, i64 0, i64 1, i64 0
  %3367 = bitcast i8* %scevgep41.8.13 to [61 x [61 x i8]]*
  %call16.8.14 = call zeroext i8 (...) @rand()
  store i8 %call16.8.14, i8* %scevgep28.8.13, align 1
  %3368 = load i8, i8* %scevgep28.8.13, align 1
  %conv23.8.14 = zext i8 %3368 to i32
  %3369 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.14 = getelementptr i8, i8* %b, i64 23
  %3370 = load i8, i8* %scevgep34.8.14, align 1
  %call28.8.14 = call zeroext i8 @mult(i8 zeroext %3369, i8 zeroext %3370)
  %conv29.8.14 = zext i8 %call28.8.14 to i32
  %xor.8.14 = xor i32 %conv23.8.14, %conv29.8.14
  %scevgep35.8.14 = getelementptr i8, i8* %a, i64 23
  %3371 = load i8, i8* %scevgep35.8.14, align 1
  %3372 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.14 = call zeroext i8 @mult(i8 zeroext %3371, i8 zeroext %3372)
  %conv35.8.14 = zext i8 %call34.8.14 to i32
  %xor36.8.14 = xor i32 %xor.8.14, %conv35.8.14
  %conv37.8.14 = trunc i32 %xor36.8.14 to i8
  store i8 %conv37.8.14, i8* %scevgep41.8.13, align 1
  %scevgep28.8.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3366, i64 0, i64 0, i64 1
  %3373 = bitcast i8* %scevgep28.8.14 to [61 x [61 x i8]]*
  %scevgep41.8.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3367, i64 0, i64 1, i64 0
  %3374 = bitcast i8* %scevgep41.8.14 to [61 x [61 x i8]]*
  %call16.8.15 = call zeroext i8 (...) @rand()
  store i8 %call16.8.15, i8* %scevgep28.8.14, align 1
  %3375 = load i8, i8* %scevgep28.8.14, align 1
  %conv23.8.15 = zext i8 %3375 to i32
  %3376 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.15 = getelementptr i8, i8* %b, i64 24
  %3377 = load i8, i8* %scevgep34.8.15, align 1
  %call28.8.15 = call zeroext i8 @mult(i8 zeroext %3376, i8 zeroext %3377)
  %conv29.8.15 = zext i8 %call28.8.15 to i32
  %xor.8.15 = xor i32 %conv23.8.15, %conv29.8.15
  %scevgep35.8.15 = getelementptr i8, i8* %a, i64 24
  %3378 = load i8, i8* %scevgep35.8.15, align 1
  %3379 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.15 = call zeroext i8 @mult(i8 zeroext %3378, i8 zeroext %3379)
  %conv35.8.15 = zext i8 %call34.8.15 to i32
  %xor36.8.15 = xor i32 %xor.8.15, %conv35.8.15
  %conv37.8.15 = trunc i32 %xor36.8.15 to i8
  store i8 %conv37.8.15, i8* %scevgep41.8.14, align 1
  %scevgep28.8.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3373, i64 0, i64 0, i64 1
  %3380 = bitcast i8* %scevgep28.8.15 to [61 x [61 x i8]]*
  %scevgep41.8.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3374, i64 0, i64 1, i64 0
  %3381 = bitcast i8* %scevgep41.8.15 to [61 x [61 x i8]]*
  %call16.8.16 = call zeroext i8 (...) @rand()
  store i8 %call16.8.16, i8* %scevgep28.8.15, align 1
  %3382 = load i8, i8* %scevgep28.8.15, align 1
  %conv23.8.16 = zext i8 %3382 to i32
  %3383 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.16 = getelementptr i8, i8* %b, i64 25
  %3384 = load i8, i8* %scevgep34.8.16, align 1
  %call28.8.16 = call zeroext i8 @mult(i8 zeroext %3383, i8 zeroext %3384)
  %conv29.8.16 = zext i8 %call28.8.16 to i32
  %xor.8.16 = xor i32 %conv23.8.16, %conv29.8.16
  %scevgep35.8.16 = getelementptr i8, i8* %a, i64 25
  %3385 = load i8, i8* %scevgep35.8.16, align 1
  %3386 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.16 = call zeroext i8 @mult(i8 zeroext %3385, i8 zeroext %3386)
  %conv35.8.16 = zext i8 %call34.8.16 to i32
  %xor36.8.16 = xor i32 %xor.8.16, %conv35.8.16
  %conv37.8.16 = trunc i32 %xor36.8.16 to i8
  store i8 %conv37.8.16, i8* %scevgep41.8.15, align 1
  %scevgep28.8.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3380, i64 0, i64 0, i64 1
  %3387 = bitcast i8* %scevgep28.8.16 to [61 x [61 x i8]]*
  %scevgep41.8.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3381, i64 0, i64 1, i64 0
  %3388 = bitcast i8* %scevgep41.8.16 to [61 x [61 x i8]]*
  %call16.8.17 = call zeroext i8 (...) @rand()
  store i8 %call16.8.17, i8* %scevgep28.8.16, align 1
  %3389 = load i8, i8* %scevgep28.8.16, align 1
  %conv23.8.17 = zext i8 %3389 to i32
  %3390 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.17 = getelementptr i8, i8* %b, i64 26
  %3391 = load i8, i8* %scevgep34.8.17, align 1
  %call28.8.17 = call zeroext i8 @mult(i8 zeroext %3390, i8 zeroext %3391)
  %conv29.8.17 = zext i8 %call28.8.17 to i32
  %xor.8.17 = xor i32 %conv23.8.17, %conv29.8.17
  %scevgep35.8.17 = getelementptr i8, i8* %a, i64 26
  %3392 = load i8, i8* %scevgep35.8.17, align 1
  %3393 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.17 = call zeroext i8 @mult(i8 zeroext %3392, i8 zeroext %3393)
  %conv35.8.17 = zext i8 %call34.8.17 to i32
  %xor36.8.17 = xor i32 %xor.8.17, %conv35.8.17
  %conv37.8.17 = trunc i32 %xor36.8.17 to i8
  store i8 %conv37.8.17, i8* %scevgep41.8.16, align 1
  %scevgep28.8.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3387, i64 0, i64 0, i64 1
  %3394 = bitcast i8* %scevgep28.8.17 to [61 x [61 x i8]]*
  %scevgep41.8.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3388, i64 0, i64 1, i64 0
  %3395 = bitcast i8* %scevgep41.8.17 to [61 x [61 x i8]]*
  %call16.8.18 = call zeroext i8 (...) @rand()
  store i8 %call16.8.18, i8* %scevgep28.8.17, align 1
  %3396 = load i8, i8* %scevgep28.8.17, align 1
  %conv23.8.18 = zext i8 %3396 to i32
  %3397 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.18 = getelementptr i8, i8* %b, i64 27
  %3398 = load i8, i8* %scevgep34.8.18, align 1
  %call28.8.18 = call zeroext i8 @mult(i8 zeroext %3397, i8 zeroext %3398)
  %conv29.8.18 = zext i8 %call28.8.18 to i32
  %xor.8.18 = xor i32 %conv23.8.18, %conv29.8.18
  %scevgep35.8.18 = getelementptr i8, i8* %a, i64 27
  %3399 = load i8, i8* %scevgep35.8.18, align 1
  %3400 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.18 = call zeroext i8 @mult(i8 zeroext %3399, i8 zeroext %3400)
  %conv35.8.18 = zext i8 %call34.8.18 to i32
  %xor36.8.18 = xor i32 %xor.8.18, %conv35.8.18
  %conv37.8.18 = trunc i32 %xor36.8.18 to i8
  store i8 %conv37.8.18, i8* %scevgep41.8.17, align 1
  %scevgep28.8.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3394, i64 0, i64 0, i64 1
  %3401 = bitcast i8* %scevgep28.8.18 to [61 x [61 x i8]]*
  %scevgep41.8.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3395, i64 0, i64 1, i64 0
  %3402 = bitcast i8* %scevgep41.8.18 to [61 x [61 x i8]]*
  %call16.8.19 = call zeroext i8 (...) @rand()
  store i8 %call16.8.19, i8* %scevgep28.8.18, align 1
  %3403 = load i8, i8* %scevgep28.8.18, align 1
  %conv23.8.19 = zext i8 %3403 to i32
  %3404 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.19 = getelementptr i8, i8* %b, i64 28
  %3405 = load i8, i8* %scevgep34.8.19, align 1
  %call28.8.19 = call zeroext i8 @mult(i8 zeroext %3404, i8 zeroext %3405)
  %conv29.8.19 = zext i8 %call28.8.19 to i32
  %xor.8.19 = xor i32 %conv23.8.19, %conv29.8.19
  %scevgep35.8.19 = getelementptr i8, i8* %a, i64 28
  %3406 = load i8, i8* %scevgep35.8.19, align 1
  %3407 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.19 = call zeroext i8 @mult(i8 zeroext %3406, i8 zeroext %3407)
  %conv35.8.19 = zext i8 %call34.8.19 to i32
  %xor36.8.19 = xor i32 %xor.8.19, %conv35.8.19
  %conv37.8.19 = trunc i32 %xor36.8.19 to i8
  store i8 %conv37.8.19, i8* %scevgep41.8.18, align 1
  %scevgep28.8.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3401, i64 0, i64 0, i64 1
  %3408 = bitcast i8* %scevgep28.8.19 to [61 x [61 x i8]]*
  %scevgep41.8.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3402, i64 0, i64 1, i64 0
  %3409 = bitcast i8* %scevgep41.8.19 to [61 x [61 x i8]]*
  %call16.8.20 = call zeroext i8 (...) @rand()
  store i8 %call16.8.20, i8* %scevgep28.8.19, align 1
  %3410 = load i8, i8* %scevgep28.8.19, align 1
  %conv23.8.20 = zext i8 %3410 to i32
  %3411 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.20 = getelementptr i8, i8* %b, i64 29
  %3412 = load i8, i8* %scevgep34.8.20, align 1
  %call28.8.20 = call zeroext i8 @mult(i8 zeroext %3411, i8 zeroext %3412)
  %conv29.8.20 = zext i8 %call28.8.20 to i32
  %xor.8.20 = xor i32 %conv23.8.20, %conv29.8.20
  %scevgep35.8.20 = getelementptr i8, i8* %a, i64 29
  %3413 = load i8, i8* %scevgep35.8.20, align 1
  %3414 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.20 = call zeroext i8 @mult(i8 zeroext %3413, i8 zeroext %3414)
  %conv35.8.20 = zext i8 %call34.8.20 to i32
  %xor36.8.20 = xor i32 %xor.8.20, %conv35.8.20
  %conv37.8.20 = trunc i32 %xor36.8.20 to i8
  store i8 %conv37.8.20, i8* %scevgep41.8.19, align 1
  %scevgep28.8.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3408, i64 0, i64 0, i64 1
  %3415 = bitcast i8* %scevgep28.8.20 to [61 x [61 x i8]]*
  %scevgep41.8.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3409, i64 0, i64 1, i64 0
  %3416 = bitcast i8* %scevgep41.8.20 to [61 x [61 x i8]]*
  %call16.8.21 = call zeroext i8 (...) @rand()
  store i8 %call16.8.21, i8* %scevgep28.8.20, align 1
  %3417 = load i8, i8* %scevgep28.8.20, align 1
  %conv23.8.21 = zext i8 %3417 to i32
  %3418 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.21 = getelementptr i8, i8* %b, i64 30
  %3419 = load i8, i8* %scevgep34.8.21, align 1
  %call28.8.21 = call zeroext i8 @mult(i8 zeroext %3418, i8 zeroext %3419)
  %conv29.8.21 = zext i8 %call28.8.21 to i32
  %xor.8.21 = xor i32 %conv23.8.21, %conv29.8.21
  %scevgep35.8.21 = getelementptr i8, i8* %a, i64 30
  %3420 = load i8, i8* %scevgep35.8.21, align 1
  %3421 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.21 = call zeroext i8 @mult(i8 zeroext %3420, i8 zeroext %3421)
  %conv35.8.21 = zext i8 %call34.8.21 to i32
  %xor36.8.21 = xor i32 %xor.8.21, %conv35.8.21
  %conv37.8.21 = trunc i32 %xor36.8.21 to i8
  store i8 %conv37.8.21, i8* %scevgep41.8.20, align 1
  %scevgep28.8.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3415, i64 0, i64 0, i64 1
  %3422 = bitcast i8* %scevgep28.8.21 to [61 x [61 x i8]]*
  %scevgep41.8.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3416, i64 0, i64 1, i64 0
  %3423 = bitcast i8* %scevgep41.8.21 to [61 x [61 x i8]]*
  %call16.8.22 = call zeroext i8 (...) @rand()
  store i8 %call16.8.22, i8* %scevgep28.8.21, align 1
  %3424 = load i8, i8* %scevgep28.8.21, align 1
  %conv23.8.22 = zext i8 %3424 to i32
  %3425 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.22 = getelementptr i8, i8* %b, i64 31
  %3426 = load i8, i8* %scevgep34.8.22, align 1
  %call28.8.22 = call zeroext i8 @mult(i8 zeroext %3425, i8 zeroext %3426)
  %conv29.8.22 = zext i8 %call28.8.22 to i32
  %xor.8.22 = xor i32 %conv23.8.22, %conv29.8.22
  %scevgep35.8.22 = getelementptr i8, i8* %a, i64 31
  %3427 = load i8, i8* %scevgep35.8.22, align 1
  %3428 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.22 = call zeroext i8 @mult(i8 zeroext %3427, i8 zeroext %3428)
  %conv35.8.22 = zext i8 %call34.8.22 to i32
  %xor36.8.22 = xor i32 %xor.8.22, %conv35.8.22
  %conv37.8.22 = trunc i32 %xor36.8.22 to i8
  store i8 %conv37.8.22, i8* %scevgep41.8.21, align 1
  %scevgep28.8.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3422, i64 0, i64 0, i64 1
  %3429 = bitcast i8* %scevgep28.8.22 to [61 x [61 x i8]]*
  %scevgep41.8.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3423, i64 0, i64 1, i64 0
  %3430 = bitcast i8* %scevgep41.8.22 to [61 x [61 x i8]]*
  %call16.8.23 = call zeroext i8 (...) @rand()
  store i8 %call16.8.23, i8* %scevgep28.8.22, align 1
  %3431 = load i8, i8* %scevgep28.8.22, align 1
  %conv23.8.23 = zext i8 %3431 to i32
  %3432 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.23 = getelementptr i8, i8* %b, i64 32
  %3433 = load i8, i8* %scevgep34.8.23, align 1
  %call28.8.23 = call zeroext i8 @mult(i8 zeroext %3432, i8 zeroext %3433)
  %conv29.8.23 = zext i8 %call28.8.23 to i32
  %xor.8.23 = xor i32 %conv23.8.23, %conv29.8.23
  %scevgep35.8.23 = getelementptr i8, i8* %a, i64 32
  %3434 = load i8, i8* %scevgep35.8.23, align 1
  %3435 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.23 = call zeroext i8 @mult(i8 zeroext %3434, i8 zeroext %3435)
  %conv35.8.23 = zext i8 %call34.8.23 to i32
  %xor36.8.23 = xor i32 %xor.8.23, %conv35.8.23
  %conv37.8.23 = trunc i32 %xor36.8.23 to i8
  store i8 %conv37.8.23, i8* %scevgep41.8.22, align 1
  %scevgep28.8.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3429, i64 0, i64 0, i64 1
  %3436 = bitcast i8* %scevgep28.8.23 to [61 x [61 x i8]]*
  %scevgep41.8.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3430, i64 0, i64 1, i64 0
  %3437 = bitcast i8* %scevgep41.8.23 to [61 x [61 x i8]]*
  %call16.8.24 = call zeroext i8 (...) @rand()
  store i8 %call16.8.24, i8* %scevgep28.8.23, align 1
  %3438 = load i8, i8* %scevgep28.8.23, align 1
  %conv23.8.24 = zext i8 %3438 to i32
  %3439 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.24 = getelementptr i8, i8* %b, i64 33
  %3440 = load i8, i8* %scevgep34.8.24, align 1
  %call28.8.24 = call zeroext i8 @mult(i8 zeroext %3439, i8 zeroext %3440)
  %conv29.8.24 = zext i8 %call28.8.24 to i32
  %xor.8.24 = xor i32 %conv23.8.24, %conv29.8.24
  %scevgep35.8.24 = getelementptr i8, i8* %a, i64 33
  %3441 = load i8, i8* %scevgep35.8.24, align 1
  %3442 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.24 = call zeroext i8 @mult(i8 zeroext %3441, i8 zeroext %3442)
  %conv35.8.24 = zext i8 %call34.8.24 to i32
  %xor36.8.24 = xor i32 %xor.8.24, %conv35.8.24
  %conv37.8.24 = trunc i32 %xor36.8.24 to i8
  store i8 %conv37.8.24, i8* %scevgep41.8.23, align 1
  %scevgep28.8.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3436, i64 0, i64 0, i64 1
  %3443 = bitcast i8* %scevgep28.8.24 to [61 x [61 x i8]]*
  %scevgep41.8.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3437, i64 0, i64 1, i64 0
  %3444 = bitcast i8* %scevgep41.8.24 to [61 x [61 x i8]]*
  %call16.8.25 = call zeroext i8 (...) @rand()
  store i8 %call16.8.25, i8* %scevgep28.8.24, align 1
  %3445 = load i8, i8* %scevgep28.8.24, align 1
  %conv23.8.25 = zext i8 %3445 to i32
  %3446 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.25 = getelementptr i8, i8* %b, i64 34
  %3447 = load i8, i8* %scevgep34.8.25, align 1
  %call28.8.25 = call zeroext i8 @mult(i8 zeroext %3446, i8 zeroext %3447)
  %conv29.8.25 = zext i8 %call28.8.25 to i32
  %xor.8.25 = xor i32 %conv23.8.25, %conv29.8.25
  %scevgep35.8.25 = getelementptr i8, i8* %a, i64 34
  %3448 = load i8, i8* %scevgep35.8.25, align 1
  %3449 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.25 = call zeroext i8 @mult(i8 zeroext %3448, i8 zeroext %3449)
  %conv35.8.25 = zext i8 %call34.8.25 to i32
  %xor36.8.25 = xor i32 %xor.8.25, %conv35.8.25
  %conv37.8.25 = trunc i32 %xor36.8.25 to i8
  store i8 %conv37.8.25, i8* %scevgep41.8.24, align 1
  %scevgep28.8.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3443, i64 0, i64 0, i64 1
  %3450 = bitcast i8* %scevgep28.8.25 to [61 x [61 x i8]]*
  %scevgep41.8.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3444, i64 0, i64 1, i64 0
  %3451 = bitcast i8* %scevgep41.8.25 to [61 x [61 x i8]]*
  %call16.8.26 = call zeroext i8 (...) @rand()
  store i8 %call16.8.26, i8* %scevgep28.8.25, align 1
  %3452 = load i8, i8* %scevgep28.8.25, align 1
  %conv23.8.26 = zext i8 %3452 to i32
  %3453 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.26 = getelementptr i8, i8* %b, i64 35
  %3454 = load i8, i8* %scevgep34.8.26, align 1
  %call28.8.26 = call zeroext i8 @mult(i8 zeroext %3453, i8 zeroext %3454)
  %conv29.8.26 = zext i8 %call28.8.26 to i32
  %xor.8.26 = xor i32 %conv23.8.26, %conv29.8.26
  %scevgep35.8.26 = getelementptr i8, i8* %a, i64 35
  %3455 = load i8, i8* %scevgep35.8.26, align 1
  %3456 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.26 = call zeroext i8 @mult(i8 zeroext %3455, i8 zeroext %3456)
  %conv35.8.26 = zext i8 %call34.8.26 to i32
  %xor36.8.26 = xor i32 %xor.8.26, %conv35.8.26
  %conv37.8.26 = trunc i32 %xor36.8.26 to i8
  store i8 %conv37.8.26, i8* %scevgep41.8.25, align 1
  %scevgep28.8.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3450, i64 0, i64 0, i64 1
  %3457 = bitcast i8* %scevgep28.8.26 to [61 x [61 x i8]]*
  %scevgep41.8.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3451, i64 0, i64 1, i64 0
  %3458 = bitcast i8* %scevgep41.8.26 to [61 x [61 x i8]]*
  %call16.8.27 = call zeroext i8 (...) @rand()
  store i8 %call16.8.27, i8* %scevgep28.8.26, align 1
  %3459 = load i8, i8* %scevgep28.8.26, align 1
  %conv23.8.27 = zext i8 %3459 to i32
  %3460 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.27 = getelementptr i8, i8* %b, i64 36
  %3461 = load i8, i8* %scevgep34.8.27, align 1
  %call28.8.27 = call zeroext i8 @mult(i8 zeroext %3460, i8 zeroext %3461)
  %conv29.8.27 = zext i8 %call28.8.27 to i32
  %xor.8.27 = xor i32 %conv23.8.27, %conv29.8.27
  %scevgep35.8.27 = getelementptr i8, i8* %a, i64 36
  %3462 = load i8, i8* %scevgep35.8.27, align 1
  %3463 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.27 = call zeroext i8 @mult(i8 zeroext %3462, i8 zeroext %3463)
  %conv35.8.27 = zext i8 %call34.8.27 to i32
  %xor36.8.27 = xor i32 %xor.8.27, %conv35.8.27
  %conv37.8.27 = trunc i32 %xor36.8.27 to i8
  store i8 %conv37.8.27, i8* %scevgep41.8.26, align 1
  %scevgep28.8.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3457, i64 0, i64 0, i64 1
  %3464 = bitcast i8* %scevgep28.8.27 to [61 x [61 x i8]]*
  %scevgep41.8.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3458, i64 0, i64 1, i64 0
  %3465 = bitcast i8* %scevgep41.8.27 to [61 x [61 x i8]]*
  %call16.8.28 = call zeroext i8 (...) @rand()
  store i8 %call16.8.28, i8* %scevgep28.8.27, align 1
  %3466 = load i8, i8* %scevgep28.8.27, align 1
  %conv23.8.28 = zext i8 %3466 to i32
  %3467 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.28 = getelementptr i8, i8* %b, i64 37
  %3468 = load i8, i8* %scevgep34.8.28, align 1
  %call28.8.28 = call zeroext i8 @mult(i8 zeroext %3467, i8 zeroext %3468)
  %conv29.8.28 = zext i8 %call28.8.28 to i32
  %xor.8.28 = xor i32 %conv23.8.28, %conv29.8.28
  %scevgep35.8.28 = getelementptr i8, i8* %a, i64 37
  %3469 = load i8, i8* %scevgep35.8.28, align 1
  %3470 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.28 = call zeroext i8 @mult(i8 zeroext %3469, i8 zeroext %3470)
  %conv35.8.28 = zext i8 %call34.8.28 to i32
  %xor36.8.28 = xor i32 %xor.8.28, %conv35.8.28
  %conv37.8.28 = trunc i32 %xor36.8.28 to i8
  store i8 %conv37.8.28, i8* %scevgep41.8.27, align 1
  %scevgep28.8.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3464, i64 0, i64 0, i64 1
  %3471 = bitcast i8* %scevgep28.8.28 to [61 x [61 x i8]]*
  %scevgep41.8.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3465, i64 0, i64 1, i64 0
  %3472 = bitcast i8* %scevgep41.8.28 to [61 x [61 x i8]]*
  %call16.8.29 = call zeroext i8 (...) @rand()
  store i8 %call16.8.29, i8* %scevgep28.8.28, align 1
  %3473 = load i8, i8* %scevgep28.8.28, align 1
  %conv23.8.29 = zext i8 %3473 to i32
  %3474 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.29 = getelementptr i8, i8* %b, i64 38
  %3475 = load i8, i8* %scevgep34.8.29, align 1
  %call28.8.29 = call zeroext i8 @mult(i8 zeroext %3474, i8 zeroext %3475)
  %conv29.8.29 = zext i8 %call28.8.29 to i32
  %xor.8.29 = xor i32 %conv23.8.29, %conv29.8.29
  %scevgep35.8.29 = getelementptr i8, i8* %a, i64 38
  %3476 = load i8, i8* %scevgep35.8.29, align 1
  %3477 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.29 = call zeroext i8 @mult(i8 zeroext %3476, i8 zeroext %3477)
  %conv35.8.29 = zext i8 %call34.8.29 to i32
  %xor36.8.29 = xor i32 %xor.8.29, %conv35.8.29
  %conv37.8.29 = trunc i32 %xor36.8.29 to i8
  store i8 %conv37.8.29, i8* %scevgep41.8.28, align 1
  %scevgep28.8.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3471, i64 0, i64 0, i64 1
  %3478 = bitcast i8* %scevgep28.8.29 to [61 x [61 x i8]]*
  %scevgep41.8.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3472, i64 0, i64 1, i64 0
  %3479 = bitcast i8* %scevgep41.8.29 to [61 x [61 x i8]]*
  %call16.8.30 = call zeroext i8 (...) @rand()
  store i8 %call16.8.30, i8* %scevgep28.8.29, align 1
  %3480 = load i8, i8* %scevgep28.8.29, align 1
  %conv23.8.30 = zext i8 %3480 to i32
  %3481 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.30 = getelementptr i8, i8* %b, i64 39
  %3482 = load i8, i8* %scevgep34.8.30, align 1
  %call28.8.30 = call zeroext i8 @mult(i8 zeroext %3481, i8 zeroext %3482)
  %conv29.8.30 = zext i8 %call28.8.30 to i32
  %xor.8.30 = xor i32 %conv23.8.30, %conv29.8.30
  %scevgep35.8.30 = getelementptr i8, i8* %a, i64 39
  %3483 = load i8, i8* %scevgep35.8.30, align 1
  %3484 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.30 = call zeroext i8 @mult(i8 zeroext %3483, i8 zeroext %3484)
  %conv35.8.30 = zext i8 %call34.8.30 to i32
  %xor36.8.30 = xor i32 %xor.8.30, %conv35.8.30
  %conv37.8.30 = trunc i32 %xor36.8.30 to i8
  store i8 %conv37.8.30, i8* %scevgep41.8.29, align 1
  %scevgep28.8.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3478, i64 0, i64 0, i64 1
  %3485 = bitcast i8* %scevgep28.8.30 to [61 x [61 x i8]]*
  %scevgep41.8.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3479, i64 0, i64 1, i64 0
  %3486 = bitcast i8* %scevgep41.8.30 to [61 x [61 x i8]]*
  %call16.8.31 = call zeroext i8 (...) @rand()
  store i8 %call16.8.31, i8* %scevgep28.8.30, align 1
  %3487 = load i8, i8* %scevgep28.8.30, align 1
  %conv23.8.31 = zext i8 %3487 to i32
  %3488 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.31 = getelementptr i8, i8* %b, i64 40
  %3489 = load i8, i8* %scevgep34.8.31, align 1
  %call28.8.31 = call zeroext i8 @mult(i8 zeroext %3488, i8 zeroext %3489)
  %conv29.8.31 = zext i8 %call28.8.31 to i32
  %xor.8.31 = xor i32 %conv23.8.31, %conv29.8.31
  %scevgep35.8.31 = getelementptr i8, i8* %a, i64 40
  %3490 = load i8, i8* %scevgep35.8.31, align 1
  %3491 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.31 = call zeroext i8 @mult(i8 zeroext %3490, i8 zeroext %3491)
  %conv35.8.31 = zext i8 %call34.8.31 to i32
  %xor36.8.31 = xor i32 %xor.8.31, %conv35.8.31
  %conv37.8.31 = trunc i32 %xor36.8.31 to i8
  store i8 %conv37.8.31, i8* %scevgep41.8.30, align 1
  %scevgep28.8.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3485, i64 0, i64 0, i64 1
  %3492 = bitcast i8* %scevgep28.8.31 to [61 x [61 x i8]]*
  %scevgep41.8.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3486, i64 0, i64 1, i64 0
  %3493 = bitcast i8* %scevgep41.8.31 to [61 x [61 x i8]]*
  %call16.8.32 = call zeroext i8 (...) @rand()
  store i8 %call16.8.32, i8* %scevgep28.8.31, align 1
  %3494 = load i8, i8* %scevgep28.8.31, align 1
  %conv23.8.32 = zext i8 %3494 to i32
  %3495 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.32 = getelementptr i8, i8* %b, i64 41
  %3496 = load i8, i8* %scevgep34.8.32, align 1
  %call28.8.32 = call zeroext i8 @mult(i8 zeroext %3495, i8 zeroext %3496)
  %conv29.8.32 = zext i8 %call28.8.32 to i32
  %xor.8.32 = xor i32 %conv23.8.32, %conv29.8.32
  %scevgep35.8.32 = getelementptr i8, i8* %a, i64 41
  %3497 = load i8, i8* %scevgep35.8.32, align 1
  %3498 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.32 = call zeroext i8 @mult(i8 zeroext %3497, i8 zeroext %3498)
  %conv35.8.32 = zext i8 %call34.8.32 to i32
  %xor36.8.32 = xor i32 %xor.8.32, %conv35.8.32
  %conv37.8.32 = trunc i32 %xor36.8.32 to i8
  store i8 %conv37.8.32, i8* %scevgep41.8.31, align 1
  %scevgep28.8.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3492, i64 0, i64 0, i64 1
  %3499 = bitcast i8* %scevgep28.8.32 to [61 x [61 x i8]]*
  %scevgep41.8.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3493, i64 0, i64 1, i64 0
  %3500 = bitcast i8* %scevgep41.8.32 to [61 x [61 x i8]]*
  %call16.8.33 = call zeroext i8 (...) @rand()
  store i8 %call16.8.33, i8* %scevgep28.8.32, align 1
  %3501 = load i8, i8* %scevgep28.8.32, align 1
  %conv23.8.33 = zext i8 %3501 to i32
  %3502 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.33 = getelementptr i8, i8* %b, i64 42
  %3503 = load i8, i8* %scevgep34.8.33, align 1
  %call28.8.33 = call zeroext i8 @mult(i8 zeroext %3502, i8 zeroext %3503)
  %conv29.8.33 = zext i8 %call28.8.33 to i32
  %xor.8.33 = xor i32 %conv23.8.33, %conv29.8.33
  %scevgep35.8.33 = getelementptr i8, i8* %a, i64 42
  %3504 = load i8, i8* %scevgep35.8.33, align 1
  %3505 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.33 = call zeroext i8 @mult(i8 zeroext %3504, i8 zeroext %3505)
  %conv35.8.33 = zext i8 %call34.8.33 to i32
  %xor36.8.33 = xor i32 %xor.8.33, %conv35.8.33
  %conv37.8.33 = trunc i32 %xor36.8.33 to i8
  store i8 %conv37.8.33, i8* %scevgep41.8.32, align 1
  %scevgep28.8.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3499, i64 0, i64 0, i64 1
  %3506 = bitcast i8* %scevgep28.8.33 to [61 x [61 x i8]]*
  %scevgep41.8.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3500, i64 0, i64 1, i64 0
  %3507 = bitcast i8* %scevgep41.8.33 to [61 x [61 x i8]]*
  %call16.8.34 = call zeroext i8 (...) @rand()
  store i8 %call16.8.34, i8* %scevgep28.8.33, align 1
  %3508 = load i8, i8* %scevgep28.8.33, align 1
  %conv23.8.34 = zext i8 %3508 to i32
  %3509 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.34 = getelementptr i8, i8* %b, i64 43
  %3510 = load i8, i8* %scevgep34.8.34, align 1
  %call28.8.34 = call zeroext i8 @mult(i8 zeroext %3509, i8 zeroext %3510)
  %conv29.8.34 = zext i8 %call28.8.34 to i32
  %xor.8.34 = xor i32 %conv23.8.34, %conv29.8.34
  %scevgep35.8.34 = getelementptr i8, i8* %a, i64 43
  %3511 = load i8, i8* %scevgep35.8.34, align 1
  %3512 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.34 = call zeroext i8 @mult(i8 zeroext %3511, i8 zeroext %3512)
  %conv35.8.34 = zext i8 %call34.8.34 to i32
  %xor36.8.34 = xor i32 %xor.8.34, %conv35.8.34
  %conv37.8.34 = trunc i32 %xor36.8.34 to i8
  store i8 %conv37.8.34, i8* %scevgep41.8.33, align 1
  %scevgep28.8.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3506, i64 0, i64 0, i64 1
  %3513 = bitcast i8* %scevgep28.8.34 to [61 x [61 x i8]]*
  %scevgep41.8.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3507, i64 0, i64 1, i64 0
  %3514 = bitcast i8* %scevgep41.8.34 to [61 x [61 x i8]]*
  %call16.8.35 = call zeroext i8 (...) @rand()
  store i8 %call16.8.35, i8* %scevgep28.8.34, align 1
  %3515 = load i8, i8* %scevgep28.8.34, align 1
  %conv23.8.35 = zext i8 %3515 to i32
  %3516 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.35 = getelementptr i8, i8* %b, i64 44
  %3517 = load i8, i8* %scevgep34.8.35, align 1
  %call28.8.35 = call zeroext i8 @mult(i8 zeroext %3516, i8 zeroext %3517)
  %conv29.8.35 = zext i8 %call28.8.35 to i32
  %xor.8.35 = xor i32 %conv23.8.35, %conv29.8.35
  %scevgep35.8.35 = getelementptr i8, i8* %a, i64 44
  %3518 = load i8, i8* %scevgep35.8.35, align 1
  %3519 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.35 = call zeroext i8 @mult(i8 zeroext %3518, i8 zeroext %3519)
  %conv35.8.35 = zext i8 %call34.8.35 to i32
  %xor36.8.35 = xor i32 %xor.8.35, %conv35.8.35
  %conv37.8.35 = trunc i32 %xor36.8.35 to i8
  store i8 %conv37.8.35, i8* %scevgep41.8.34, align 1
  %scevgep28.8.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3513, i64 0, i64 0, i64 1
  %3520 = bitcast i8* %scevgep28.8.35 to [61 x [61 x i8]]*
  %scevgep41.8.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3514, i64 0, i64 1, i64 0
  %3521 = bitcast i8* %scevgep41.8.35 to [61 x [61 x i8]]*
  %call16.8.36 = call zeroext i8 (...) @rand()
  store i8 %call16.8.36, i8* %scevgep28.8.35, align 1
  %3522 = load i8, i8* %scevgep28.8.35, align 1
  %conv23.8.36 = zext i8 %3522 to i32
  %3523 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.36 = getelementptr i8, i8* %b, i64 45
  %3524 = load i8, i8* %scevgep34.8.36, align 1
  %call28.8.36 = call zeroext i8 @mult(i8 zeroext %3523, i8 zeroext %3524)
  %conv29.8.36 = zext i8 %call28.8.36 to i32
  %xor.8.36 = xor i32 %conv23.8.36, %conv29.8.36
  %scevgep35.8.36 = getelementptr i8, i8* %a, i64 45
  %3525 = load i8, i8* %scevgep35.8.36, align 1
  %3526 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.36 = call zeroext i8 @mult(i8 zeroext %3525, i8 zeroext %3526)
  %conv35.8.36 = zext i8 %call34.8.36 to i32
  %xor36.8.36 = xor i32 %xor.8.36, %conv35.8.36
  %conv37.8.36 = trunc i32 %xor36.8.36 to i8
  store i8 %conv37.8.36, i8* %scevgep41.8.35, align 1
  %scevgep28.8.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3520, i64 0, i64 0, i64 1
  %3527 = bitcast i8* %scevgep28.8.36 to [61 x [61 x i8]]*
  %scevgep41.8.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3521, i64 0, i64 1, i64 0
  %3528 = bitcast i8* %scevgep41.8.36 to [61 x [61 x i8]]*
  %call16.8.37 = call zeroext i8 (...) @rand()
  store i8 %call16.8.37, i8* %scevgep28.8.36, align 1
  %3529 = load i8, i8* %scevgep28.8.36, align 1
  %conv23.8.37 = zext i8 %3529 to i32
  %3530 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.37 = getelementptr i8, i8* %b, i64 46
  %3531 = load i8, i8* %scevgep34.8.37, align 1
  %call28.8.37 = call zeroext i8 @mult(i8 zeroext %3530, i8 zeroext %3531)
  %conv29.8.37 = zext i8 %call28.8.37 to i32
  %xor.8.37 = xor i32 %conv23.8.37, %conv29.8.37
  %scevgep35.8.37 = getelementptr i8, i8* %a, i64 46
  %3532 = load i8, i8* %scevgep35.8.37, align 1
  %3533 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.37 = call zeroext i8 @mult(i8 zeroext %3532, i8 zeroext %3533)
  %conv35.8.37 = zext i8 %call34.8.37 to i32
  %xor36.8.37 = xor i32 %xor.8.37, %conv35.8.37
  %conv37.8.37 = trunc i32 %xor36.8.37 to i8
  store i8 %conv37.8.37, i8* %scevgep41.8.36, align 1
  %scevgep28.8.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3527, i64 0, i64 0, i64 1
  %3534 = bitcast i8* %scevgep28.8.37 to [61 x [61 x i8]]*
  %scevgep41.8.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3528, i64 0, i64 1, i64 0
  %3535 = bitcast i8* %scevgep41.8.37 to [61 x [61 x i8]]*
  %call16.8.38 = call zeroext i8 (...) @rand()
  store i8 %call16.8.38, i8* %scevgep28.8.37, align 1
  %3536 = load i8, i8* %scevgep28.8.37, align 1
  %conv23.8.38 = zext i8 %3536 to i32
  %3537 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.38 = getelementptr i8, i8* %b, i64 47
  %3538 = load i8, i8* %scevgep34.8.38, align 1
  %call28.8.38 = call zeroext i8 @mult(i8 zeroext %3537, i8 zeroext %3538)
  %conv29.8.38 = zext i8 %call28.8.38 to i32
  %xor.8.38 = xor i32 %conv23.8.38, %conv29.8.38
  %scevgep35.8.38 = getelementptr i8, i8* %a, i64 47
  %3539 = load i8, i8* %scevgep35.8.38, align 1
  %3540 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.38 = call zeroext i8 @mult(i8 zeroext %3539, i8 zeroext %3540)
  %conv35.8.38 = zext i8 %call34.8.38 to i32
  %xor36.8.38 = xor i32 %xor.8.38, %conv35.8.38
  %conv37.8.38 = trunc i32 %xor36.8.38 to i8
  store i8 %conv37.8.38, i8* %scevgep41.8.37, align 1
  %scevgep28.8.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3534, i64 0, i64 0, i64 1
  %3541 = bitcast i8* %scevgep28.8.38 to [61 x [61 x i8]]*
  %scevgep41.8.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3535, i64 0, i64 1, i64 0
  %3542 = bitcast i8* %scevgep41.8.38 to [61 x [61 x i8]]*
  %call16.8.39 = call zeroext i8 (...) @rand()
  store i8 %call16.8.39, i8* %scevgep28.8.38, align 1
  %3543 = load i8, i8* %scevgep28.8.38, align 1
  %conv23.8.39 = zext i8 %3543 to i32
  %3544 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.39 = getelementptr i8, i8* %b, i64 48
  %3545 = load i8, i8* %scevgep34.8.39, align 1
  %call28.8.39 = call zeroext i8 @mult(i8 zeroext %3544, i8 zeroext %3545)
  %conv29.8.39 = zext i8 %call28.8.39 to i32
  %xor.8.39 = xor i32 %conv23.8.39, %conv29.8.39
  %scevgep35.8.39 = getelementptr i8, i8* %a, i64 48
  %3546 = load i8, i8* %scevgep35.8.39, align 1
  %3547 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.39 = call zeroext i8 @mult(i8 zeroext %3546, i8 zeroext %3547)
  %conv35.8.39 = zext i8 %call34.8.39 to i32
  %xor36.8.39 = xor i32 %xor.8.39, %conv35.8.39
  %conv37.8.39 = trunc i32 %xor36.8.39 to i8
  store i8 %conv37.8.39, i8* %scevgep41.8.38, align 1
  %scevgep28.8.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3541, i64 0, i64 0, i64 1
  %3548 = bitcast i8* %scevgep28.8.39 to [61 x [61 x i8]]*
  %scevgep41.8.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3542, i64 0, i64 1, i64 0
  %3549 = bitcast i8* %scevgep41.8.39 to [61 x [61 x i8]]*
  %call16.8.40 = call zeroext i8 (...) @rand()
  store i8 %call16.8.40, i8* %scevgep28.8.39, align 1
  %3550 = load i8, i8* %scevgep28.8.39, align 1
  %conv23.8.40 = zext i8 %3550 to i32
  %3551 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.40 = getelementptr i8, i8* %b, i64 49
  %3552 = load i8, i8* %scevgep34.8.40, align 1
  %call28.8.40 = call zeroext i8 @mult(i8 zeroext %3551, i8 zeroext %3552)
  %conv29.8.40 = zext i8 %call28.8.40 to i32
  %xor.8.40 = xor i32 %conv23.8.40, %conv29.8.40
  %scevgep35.8.40 = getelementptr i8, i8* %a, i64 49
  %3553 = load i8, i8* %scevgep35.8.40, align 1
  %3554 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.40 = call zeroext i8 @mult(i8 zeroext %3553, i8 zeroext %3554)
  %conv35.8.40 = zext i8 %call34.8.40 to i32
  %xor36.8.40 = xor i32 %xor.8.40, %conv35.8.40
  %conv37.8.40 = trunc i32 %xor36.8.40 to i8
  store i8 %conv37.8.40, i8* %scevgep41.8.39, align 1
  %scevgep28.8.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3548, i64 0, i64 0, i64 1
  %3555 = bitcast i8* %scevgep28.8.40 to [61 x [61 x i8]]*
  %scevgep41.8.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3549, i64 0, i64 1, i64 0
  %3556 = bitcast i8* %scevgep41.8.40 to [61 x [61 x i8]]*
  %call16.8.41 = call zeroext i8 (...) @rand()
  store i8 %call16.8.41, i8* %scevgep28.8.40, align 1
  %3557 = load i8, i8* %scevgep28.8.40, align 1
  %conv23.8.41 = zext i8 %3557 to i32
  %3558 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.41 = getelementptr i8, i8* %b, i64 50
  %3559 = load i8, i8* %scevgep34.8.41, align 1
  %call28.8.41 = call zeroext i8 @mult(i8 zeroext %3558, i8 zeroext %3559)
  %conv29.8.41 = zext i8 %call28.8.41 to i32
  %xor.8.41 = xor i32 %conv23.8.41, %conv29.8.41
  %scevgep35.8.41 = getelementptr i8, i8* %a, i64 50
  %3560 = load i8, i8* %scevgep35.8.41, align 1
  %3561 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.41 = call zeroext i8 @mult(i8 zeroext %3560, i8 zeroext %3561)
  %conv35.8.41 = zext i8 %call34.8.41 to i32
  %xor36.8.41 = xor i32 %xor.8.41, %conv35.8.41
  %conv37.8.41 = trunc i32 %xor36.8.41 to i8
  store i8 %conv37.8.41, i8* %scevgep41.8.40, align 1
  %scevgep28.8.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3555, i64 0, i64 0, i64 1
  %3562 = bitcast i8* %scevgep28.8.41 to [61 x [61 x i8]]*
  %scevgep41.8.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3556, i64 0, i64 1, i64 0
  %3563 = bitcast i8* %scevgep41.8.41 to [61 x [61 x i8]]*
  %call16.8.42 = call zeroext i8 (...) @rand()
  store i8 %call16.8.42, i8* %scevgep28.8.41, align 1
  %3564 = load i8, i8* %scevgep28.8.41, align 1
  %conv23.8.42 = zext i8 %3564 to i32
  %3565 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.42 = getelementptr i8, i8* %b, i64 51
  %3566 = load i8, i8* %scevgep34.8.42, align 1
  %call28.8.42 = call zeroext i8 @mult(i8 zeroext %3565, i8 zeroext %3566)
  %conv29.8.42 = zext i8 %call28.8.42 to i32
  %xor.8.42 = xor i32 %conv23.8.42, %conv29.8.42
  %scevgep35.8.42 = getelementptr i8, i8* %a, i64 51
  %3567 = load i8, i8* %scevgep35.8.42, align 1
  %3568 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.42 = call zeroext i8 @mult(i8 zeroext %3567, i8 zeroext %3568)
  %conv35.8.42 = zext i8 %call34.8.42 to i32
  %xor36.8.42 = xor i32 %xor.8.42, %conv35.8.42
  %conv37.8.42 = trunc i32 %xor36.8.42 to i8
  store i8 %conv37.8.42, i8* %scevgep41.8.41, align 1
  %scevgep28.8.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3562, i64 0, i64 0, i64 1
  %3569 = bitcast i8* %scevgep28.8.42 to [61 x [61 x i8]]*
  %scevgep41.8.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3563, i64 0, i64 1, i64 0
  %3570 = bitcast i8* %scevgep41.8.42 to [61 x [61 x i8]]*
  %call16.8.43 = call zeroext i8 (...) @rand()
  store i8 %call16.8.43, i8* %scevgep28.8.42, align 1
  %3571 = load i8, i8* %scevgep28.8.42, align 1
  %conv23.8.43 = zext i8 %3571 to i32
  %3572 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.43 = getelementptr i8, i8* %b, i64 52
  %3573 = load i8, i8* %scevgep34.8.43, align 1
  %call28.8.43 = call zeroext i8 @mult(i8 zeroext %3572, i8 zeroext %3573)
  %conv29.8.43 = zext i8 %call28.8.43 to i32
  %xor.8.43 = xor i32 %conv23.8.43, %conv29.8.43
  %scevgep35.8.43 = getelementptr i8, i8* %a, i64 52
  %3574 = load i8, i8* %scevgep35.8.43, align 1
  %3575 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.43 = call zeroext i8 @mult(i8 zeroext %3574, i8 zeroext %3575)
  %conv35.8.43 = zext i8 %call34.8.43 to i32
  %xor36.8.43 = xor i32 %xor.8.43, %conv35.8.43
  %conv37.8.43 = trunc i32 %xor36.8.43 to i8
  store i8 %conv37.8.43, i8* %scevgep41.8.42, align 1
  %scevgep28.8.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3569, i64 0, i64 0, i64 1
  %3576 = bitcast i8* %scevgep28.8.43 to [61 x [61 x i8]]*
  %scevgep41.8.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3570, i64 0, i64 1, i64 0
  %3577 = bitcast i8* %scevgep41.8.43 to [61 x [61 x i8]]*
  %call16.8.44 = call zeroext i8 (...) @rand()
  store i8 %call16.8.44, i8* %scevgep28.8.43, align 1
  %3578 = load i8, i8* %scevgep28.8.43, align 1
  %conv23.8.44 = zext i8 %3578 to i32
  %3579 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.44 = getelementptr i8, i8* %b, i64 53
  %3580 = load i8, i8* %scevgep34.8.44, align 1
  %call28.8.44 = call zeroext i8 @mult(i8 zeroext %3579, i8 zeroext %3580)
  %conv29.8.44 = zext i8 %call28.8.44 to i32
  %xor.8.44 = xor i32 %conv23.8.44, %conv29.8.44
  %scevgep35.8.44 = getelementptr i8, i8* %a, i64 53
  %3581 = load i8, i8* %scevgep35.8.44, align 1
  %3582 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.44 = call zeroext i8 @mult(i8 zeroext %3581, i8 zeroext %3582)
  %conv35.8.44 = zext i8 %call34.8.44 to i32
  %xor36.8.44 = xor i32 %xor.8.44, %conv35.8.44
  %conv37.8.44 = trunc i32 %xor36.8.44 to i8
  store i8 %conv37.8.44, i8* %scevgep41.8.43, align 1
  %scevgep28.8.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3576, i64 0, i64 0, i64 1
  %3583 = bitcast i8* %scevgep28.8.44 to [61 x [61 x i8]]*
  %scevgep41.8.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3577, i64 0, i64 1, i64 0
  %3584 = bitcast i8* %scevgep41.8.44 to [61 x [61 x i8]]*
  %call16.8.45 = call zeroext i8 (...) @rand()
  store i8 %call16.8.45, i8* %scevgep28.8.44, align 1
  %3585 = load i8, i8* %scevgep28.8.44, align 1
  %conv23.8.45 = zext i8 %3585 to i32
  %3586 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.45 = getelementptr i8, i8* %b, i64 54
  %3587 = load i8, i8* %scevgep34.8.45, align 1
  %call28.8.45 = call zeroext i8 @mult(i8 zeroext %3586, i8 zeroext %3587)
  %conv29.8.45 = zext i8 %call28.8.45 to i32
  %xor.8.45 = xor i32 %conv23.8.45, %conv29.8.45
  %scevgep35.8.45 = getelementptr i8, i8* %a, i64 54
  %3588 = load i8, i8* %scevgep35.8.45, align 1
  %3589 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.45 = call zeroext i8 @mult(i8 zeroext %3588, i8 zeroext %3589)
  %conv35.8.45 = zext i8 %call34.8.45 to i32
  %xor36.8.45 = xor i32 %xor.8.45, %conv35.8.45
  %conv37.8.45 = trunc i32 %xor36.8.45 to i8
  store i8 %conv37.8.45, i8* %scevgep41.8.44, align 1
  %scevgep28.8.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3583, i64 0, i64 0, i64 1
  %3590 = bitcast i8* %scevgep28.8.45 to [61 x [61 x i8]]*
  %scevgep41.8.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3584, i64 0, i64 1, i64 0
  %3591 = bitcast i8* %scevgep41.8.45 to [61 x [61 x i8]]*
  %call16.8.46 = call zeroext i8 (...) @rand()
  store i8 %call16.8.46, i8* %scevgep28.8.45, align 1
  %3592 = load i8, i8* %scevgep28.8.45, align 1
  %conv23.8.46 = zext i8 %3592 to i32
  %3593 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.46 = getelementptr i8, i8* %b, i64 55
  %3594 = load i8, i8* %scevgep34.8.46, align 1
  %call28.8.46 = call zeroext i8 @mult(i8 zeroext %3593, i8 zeroext %3594)
  %conv29.8.46 = zext i8 %call28.8.46 to i32
  %xor.8.46 = xor i32 %conv23.8.46, %conv29.8.46
  %scevgep35.8.46 = getelementptr i8, i8* %a, i64 55
  %3595 = load i8, i8* %scevgep35.8.46, align 1
  %3596 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.46 = call zeroext i8 @mult(i8 zeroext %3595, i8 zeroext %3596)
  %conv35.8.46 = zext i8 %call34.8.46 to i32
  %xor36.8.46 = xor i32 %xor.8.46, %conv35.8.46
  %conv37.8.46 = trunc i32 %xor36.8.46 to i8
  store i8 %conv37.8.46, i8* %scevgep41.8.45, align 1
  %scevgep28.8.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3590, i64 0, i64 0, i64 1
  %3597 = bitcast i8* %scevgep28.8.46 to [61 x [61 x i8]]*
  %scevgep41.8.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3591, i64 0, i64 1, i64 0
  %3598 = bitcast i8* %scevgep41.8.46 to [61 x [61 x i8]]*
  %call16.8.47 = call zeroext i8 (...) @rand()
  store i8 %call16.8.47, i8* %scevgep28.8.46, align 1
  %3599 = load i8, i8* %scevgep28.8.46, align 1
  %conv23.8.47 = zext i8 %3599 to i32
  %3600 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.47 = getelementptr i8, i8* %b, i64 56
  %3601 = load i8, i8* %scevgep34.8.47, align 1
  %call28.8.47 = call zeroext i8 @mult(i8 zeroext %3600, i8 zeroext %3601)
  %conv29.8.47 = zext i8 %call28.8.47 to i32
  %xor.8.47 = xor i32 %conv23.8.47, %conv29.8.47
  %scevgep35.8.47 = getelementptr i8, i8* %a, i64 56
  %3602 = load i8, i8* %scevgep35.8.47, align 1
  %3603 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.47 = call zeroext i8 @mult(i8 zeroext %3602, i8 zeroext %3603)
  %conv35.8.47 = zext i8 %call34.8.47 to i32
  %xor36.8.47 = xor i32 %xor.8.47, %conv35.8.47
  %conv37.8.47 = trunc i32 %xor36.8.47 to i8
  store i8 %conv37.8.47, i8* %scevgep41.8.46, align 1
  %scevgep28.8.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3597, i64 0, i64 0, i64 1
  %3604 = bitcast i8* %scevgep28.8.47 to [61 x [61 x i8]]*
  %scevgep41.8.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3598, i64 0, i64 1, i64 0
  %3605 = bitcast i8* %scevgep41.8.47 to [61 x [61 x i8]]*
  %call16.8.48 = call zeroext i8 (...) @rand()
  store i8 %call16.8.48, i8* %scevgep28.8.47, align 1
  %3606 = load i8, i8* %scevgep28.8.47, align 1
  %conv23.8.48 = zext i8 %3606 to i32
  %3607 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.48 = getelementptr i8, i8* %b, i64 57
  %3608 = load i8, i8* %scevgep34.8.48, align 1
  %call28.8.48 = call zeroext i8 @mult(i8 zeroext %3607, i8 zeroext %3608)
  %conv29.8.48 = zext i8 %call28.8.48 to i32
  %xor.8.48 = xor i32 %conv23.8.48, %conv29.8.48
  %scevgep35.8.48 = getelementptr i8, i8* %a, i64 57
  %3609 = load i8, i8* %scevgep35.8.48, align 1
  %3610 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.48 = call zeroext i8 @mult(i8 zeroext %3609, i8 zeroext %3610)
  %conv35.8.48 = zext i8 %call34.8.48 to i32
  %xor36.8.48 = xor i32 %xor.8.48, %conv35.8.48
  %conv37.8.48 = trunc i32 %xor36.8.48 to i8
  store i8 %conv37.8.48, i8* %scevgep41.8.47, align 1
  %scevgep28.8.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3604, i64 0, i64 0, i64 1
  %3611 = bitcast i8* %scevgep28.8.48 to [61 x [61 x i8]]*
  %scevgep41.8.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3605, i64 0, i64 1, i64 0
  %3612 = bitcast i8* %scevgep41.8.48 to [61 x [61 x i8]]*
  %call16.8.49 = call zeroext i8 (...) @rand()
  store i8 %call16.8.49, i8* %scevgep28.8.48, align 1
  %3613 = load i8, i8* %scevgep28.8.48, align 1
  %conv23.8.49 = zext i8 %3613 to i32
  %3614 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.49 = getelementptr i8, i8* %b, i64 58
  %3615 = load i8, i8* %scevgep34.8.49, align 1
  %call28.8.49 = call zeroext i8 @mult(i8 zeroext %3614, i8 zeroext %3615)
  %conv29.8.49 = zext i8 %call28.8.49 to i32
  %xor.8.49 = xor i32 %conv23.8.49, %conv29.8.49
  %scevgep35.8.49 = getelementptr i8, i8* %a, i64 58
  %3616 = load i8, i8* %scevgep35.8.49, align 1
  %3617 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.49 = call zeroext i8 @mult(i8 zeroext %3616, i8 zeroext %3617)
  %conv35.8.49 = zext i8 %call34.8.49 to i32
  %xor36.8.49 = xor i32 %xor.8.49, %conv35.8.49
  %conv37.8.49 = trunc i32 %xor36.8.49 to i8
  store i8 %conv37.8.49, i8* %scevgep41.8.48, align 1
  %scevgep28.8.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3611, i64 0, i64 0, i64 1
  %3618 = bitcast i8* %scevgep28.8.49 to [61 x [61 x i8]]*
  %scevgep41.8.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3612, i64 0, i64 1, i64 0
  %3619 = bitcast i8* %scevgep41.8.49 to [61 x [61 x i8]]*
  %call16.8.50 = call zeroext i8 (...) @rand()
  store i8 %call16.8.50, i8* %scevgep28.8.49, align 1
  %3620 = load i8, i8* %scevgep28.8.49, align 1
  %conv23.8.50 = zext i8 %3620 to i32
  %3621 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.50 = getelementptr i8, i8* %b, i64 59
  %3622 = load i8, i8* %scevgep34.8.50, align 1
  %call28.8.50 = call zeroext i8 @mult(i8 zeroext %3621, i8 zeroext %3622)
  %conv29.8.50 = zext i8 %call28.8.50 to i32
  %xor.8.50 = xor i32 %conv23.8.50, %conv29.8.50
  %scevgep35.8.50 = getelementptr i8, i8* %a, i64 59
  %3623 = load i8, i8* %scevgep35.8.50, align 1
  %3624 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.50 = call zeroext i8 @mult(i8 zeroext %3623, i8 zeroext %3624)
  %conv35.8.50 = zext i8 %call34.8.50 to i32
  %xor36.8.50 = xor i32 %xor.8.50, %conv35.8.50
  %conv37.8.50 = trunc i32 %xor36.8.50 to i8
  store i8 %conv37.8.50, i8* %scevgep41.8.49, align 1
  %scevgep28.8.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3618, i64 0, i64 0, i64 1
  %scevgep41.8.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3619, i64 0, i64 1, i64 0
  %call16.8.51 = call zeroext i8 (...) @rand()
  store i8 %call16.8.51, i8* %scevgep28.8.50, align 1
  %3625 = load i8, i8* %scevgep28.8.50, align 1
  %conv23.8.51 = zext i8 %3625 to i32
  %3626 = load i8, i8* %arrayidx25.8, align 1
  %scevgep34.8.51 = getelementptr i8, i8* %b, i64 60
  %3627 = load i8, i8* %scevgep34.8.51, align 1
  %call28.8.51 = call zeroext i8 @mult(i8 zeroext %3626, i8 zeroext %3627)
  %conv29.8.51 = zext i8 %call28.8.51 to i32
  %xor.8.51 = xor i32 %conv23.8.51, %conv29.8.51
  %scevgep35.8.51 = getelementptr i8, i8* %a, i64 60
  %3628 = load i8, i8* %scevgep35.8.51, align 1
  %3629 = load i8, i8* %arrayidx33.8, align 1
  %call34.8.51 = call zeroext i8 @mult(i8 zeroext %3628, i8 zeroext %3629)
  %conv35.8.51 = zext i8 %call34.8.51 to i32
  %xor36.8.51 = xor i32 %xor.8.51, %conv35.8.51
  %conv37.8.51 = trunc i32 %xor36.8.51 to i8
  store i8 %conv37.8.51, i8* %scevgep41.8.50, align 1
  %scevgep26.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3268, i64 0, i64 1, i64 1
  %3630 = bitcast i8* %scevgep26.8 to [61 x [61 x i8]]*
  %scevgep39.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3269, i64 0, i64 1, i64 1
  %3631 = bitcast i8* %scevgep39.8 to [61 x [61 x i8]]*
  %arrayidx25.9 = getelementptr inbounds i8, i8* %a, i64 9
  %arrayidx33.9 = getelementptr inbounds i8, i8* %b, i64 9
  %call16.9 = call zeroext i8 (...) @rand()
  store i8 %call16.9, i8* %scevgep26.8, align 1
  %3632 = load i8, i8* %scevgep26.8, align 1
  %conv23.9 = zext i8 %3632 to i32
  %3633 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9 = getelementptr i8, i8* %b, i64 10
  %3634 = load i8, i8* %scevgep34.9, align 1
  %call28.9 = call zeroext i8 @mult(i8 zeroext %3633, i8 zeroext %3634)
  %conv29.9 = zext i8 %call28.9 to i32
  %xor.9 = xor i32 %conv23.9, %conv29.9
  %scevgep35.9 = getelementptr i8, i8* %a, i64 10
  %3635 = load i8, i8* %scevgep35.9, align 1
  %3636 = load i8, i8* %arrayidx33.9, align 1
  %call34.9 = call zeroext i8 @mult(i8 zeroext %3635, i8 zeroext %3636)
  %conv35.9 = zext i8 %call34.9 to i32
  %xor36.9 = xor i32 %xor.9, %conv35.9
  %conv37.9 = trunc i32 %xor36.9 to i8
  store i8 %conv37.9, i8* %scevgep39.8, align 1
  %scevgep28.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3630, i64 0, i64 0, i64 1
  %3637 = bitcast i8* %scevgep28.9 to [61 x [61 x i8]]*
  %scevgep41.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3631, i64 0, i64 1, i64 0
  %3638 = bitcast i8* %scevgep41.9 to [61 x [61 x i8]]*
  %call16.9.1 = call zeroext i8 (...) @rand()
  store i8 %call16.9.1, i8* %scevgep28.9, align 1
  %3639 = load i8, i8* %scevgep28.9, align 1
  %conv23.9.1 = zext i8 %3639 to i32
  %3640 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.1 = getelementptr i8, i8* %b, i64 11
  %3641 = load i8, i8* %scevgep34.9.1, align 1
  %call28.9.1 = call zeroext i8 @mult(i8 zeroext %3640, i8 zeroext %3641)
  %conv29.9.1 = zext i8 %call28.9.1 to i32
  %xor.9.1 = xor i32 %conv23.9.1, %conv29.9.1
  %scevgep35.9.1 = getelementptr i8, i8* %a, i64 11
  %3642 = load i8, i8* %scevgep35.9.1, align 1
  %3643 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.1 = call zeroext i8 @mult(i8 zeroext %3642, i8 zeroext %3643)
  %conv35.9.1 = zext i8 %call34.9.1 to i32
  %xor36.9.1 = xor i32 %xor.9.1, %conv35.9.1
  %conv37.9.1 = trunc i32 %xor36.9.1 to i8
  store i8 %conv37.9.1, i8* %scevgep41.9, align 1
  %scevgep28.9.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3637, i64 0, i64 0, i64 1
  %3644 = bitcast i8* %scevgep28.9.1 to [61 x [61 x i8]]*
  %scevgep41.9.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3638, i64 0, i64 1, i64 0
  %3645 = bitcast i8* %scevgep41.9.1 to [61 x [61 x i8]]*
  %call16.9.2 = call zeroext i8 (...) @rand()
  store i8 %call16.9.2, i8* %scevgep28.9.1, align 1
  %3646 = load i8, i8* %scevgep28.9.1, align 1
  %conv23.9.2 = zext i8 %3646 to i32
  %3647 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.2 = getelementptr i8, i8* %b, i64 12
  %3648 = load i8, i8* %scevgep34.9.2, align 1
  %call28.9.2 = call zeroext i8 @mult(i8 zeroext %3647, i8 zeroext %3648)
  %conv29.9.2 = zext i8 %call28.9.2 to i32
  %xor.9.2 = xor i32 %conv23.9.2, %conv29.9.2
  %scevgep35.9.2 = getelementptr i8, i8* %a, i64 12
  %3649 = load i8, i8* %scevgep35.9.2, align 1
  %3650 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.2 = call zeroext i8 @mult(i8 zeroext %3649, i8 zeroext %3650)
  %conv35.9.2 = zext i8 %call34.9.2 to i32
  %xor36.9.2 = xor i32 %xor.9.2, %conv35.9.2
  %conv37.9.2 = trunc i32 %xor36.9.2 to i8
  store i8 %conv37.9.2, i8* %scevgep41.9.1, align 1
  %scevgep28.9.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3644, i64 0, i64 0, i64 1
  %3651 = bitcast i8* %scevgep28.9.2 to [61 x [61 x i8]]*
  %scevgep41.9.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3645, i64 0, i64 1, i64 0
  %3652 = bitcast i8* %scevgep41.9.2 to [61 x [61 x i8]]*
  %call16.9.3 = call zeroext i8 (...) @rand()
  store i8 %call16.9.3, i8* %scevgep28.9.2, align 1
  %3653 = load i8, i8* %scevgep28.9.2, align 1
  %conv23.9.3 = zext i8 %3653 to i32
  %3654 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.3 = getelementptr i8, i8* %b, i64 13
  %3655 = load i8, i8* %scevgep34.9.3, align 1
  %call28.9.3 = call zeroext i8 @mult(i8 zeroext %3654, i8 zeroext %3655)
  %conv29.9.3 = zext i8 %call28.9.3 to i32
  %xor.9.3 = xor i32 %conv23.9.3, %conv29.9.3
  %scevgep35.9.3 = getelementptr i8, i8* %a, i64 13
  %3656 = load i8, i8* %scevgep35.9.3, align 1
  %3657 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.3 = call zeroext i8 @mult(i8 zeroext %3656, i8 zeroext %3657)
  %conv35.9.3 = zext i8 %call34.9.3 to i32
  %xor36.9.3 = xor i32 %xor.9.3, %conv35.9.3
  %conv37.9.3 = trunc i32 %xor36.9.3 to i8
  store i8 %conv37.9.3, i8* %scevgep41.9.2, align 1
  %scevgep28.9.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3651, i64 0, i64 0, i64 1
  %3658 = bitcast i8* %scevgep28.9.3 to [61 x [61 x i8]]*
  %scevgep41.9.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3652, i64 0, i64 1, i64 0
  %3659 = bitcast i8* %scevgep41.9.3 to [61 x [61 x i8]]*
  %call16.9.4 = call zeroext i8 (...) @rand()
  store i8 %call16.9.4, i8* %scevgep28.9.3, align 1
  %3660 = load i8, i8* %scevgep28.9.3, align 1
  %conv23.9.4 = zext i8 %3660 to i32
  %3661 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.4 = getelementptr i8, i8* %b, i64 14
  %3662 = load i8, i8* %scevgep34.9.4, align 1
  %call28.9.4 = call zeroext i8 @mult(i8 zeroext %3661, i8 zeroext %3662)
  %conv29.9.4 = zext i8 %call28.9.4 to i32
  %xor.9.4 = xor i32 %conv23.9.4, %conv29.9.4
  %scevgep35.9.4 = getelementptr i8, i8* %a, i64 14
  %3663 = load i8, i8* %scevgep35.9.4, align 1
  %3664 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.4 = call zeroext i8 @mult(i8 zeroext %3663, i8 zeroext %3664)
  %conv35.9.4 = zext i8 %call34.9.4 to i32
  %xor36.9.4 = xor i32 %xor.9.4, %conv35.9.4
  %conv37.9.4 = trunc i32 %xor36.9.4 to i8
  store i8 %conv37.9.4, i8* %scevgep41.9.3, align 1
  %scevgep28.9.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3658, i64 0, i64 0, i64 1
  %3665 = bitcast i8* %scevgep28.9.4 to [61 x [61 x i8]]*
  %scevgep41.9.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3659, i64 0, i64 1, i64 0
  %3666 = bitcast i8* %scevgep41.9.4 to [61 x [61 x i8]]*
  %call16.9.5 = call zeroext i8 (...) @rand()
  store i8 %call16.9.5, i8* %scevgep28.9.4, align 1
  %3667 = load i8, i8* %scevgep28.9.4, align 1
  %conv23.9.5 = zext i8 %3667 to i32
  %3668 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.5 = getelementptr i8, i8* %b, i64 15
  %3669 = load i8, i8* %scevgep34.9.5, align 1
  %call28.9.5 = call zeroext i8 @mult(i8 zeroext %3668, i8 zeroext %3669)
  %conv29.9.5 = zext i8 %call28.9.5 to i32
  %xor.9.5 = xor i32 %conv23.9.5, %conv29.9.5
  %scevgep35.9.5 = getelementptr i8, i8* %a, i64 15
  %3670 = load i8, i8* %scevgep35.9.5, align 1
  %3671 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.5 = call zeroext i8 @mult(i8 zeroext %3670, i8 zeroext %3671)
  %conv35.9.5 = zext i8 %call34.9.5 to i32
  %xor36.9.5 = xor i32 %xor.9.5, %conv35.9.5
  %conv37.9.5 = trunc i32 %xor36.9.5 to i8
  store i8 %conv37.9.5, i8* %scevgep41.9.4, align 1
  %scevgep28.9.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3665, i64 0, i64 0, i64 1
  %3672 = bitcast i8* %scevgep28.9.5 to [61 x [61 x i8]]*
  %scevgep41.9.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3666, i64 0, i64 1, i64 0
  %3673 = bitcast i8* %scevgep41.9.5 to [61 x [61 x i8]]*
  %call16.9.6 = call zeroext i8 (...) @rand()
  store i8 %call16.9.6, i8* %scevgep28.9.5, align 1
  %3674 = load i8, i8* %scevgep28.9.5, align 1
  %conv23.9.6 = zext i8 %3674 to i32
  %3675 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.6 = getelementptr i8, i8* %b, i64 16
  %3676 = load i8, i8* %scevgep34.9.6, align 1
  %call28.9.6 = call zeroext i8 @mult(i8 zeroext %3675, i8 zeroext %3676)
  %conv29.9.6 = zext i8 %call28.9.6 to i32
  %xor.9.6 = xor i32 %conv23.9.6, %conv29.9.6
  %scevgep35.9.6 = getelementptr i8, i8* %a, i64 16
  %3677 = load i8, i8* %scevgep35.9.6, align 1
  %3678 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.6 = call zeroext i8 @mult(i8 zeroext %3677, i8 zeroext %3678)
  %conv35.9.6 = zext i8 %call34.9.6 to i32
  %xor36.9.6 = xor i32 %xor.9.6, %conv35.9.6
  %conv37.9.6 = trunc i32 %xor36.9.6 to i8
  store i8 %conv37.9.6, i8* %scevgep41.9.5, align 1
  %scevgep28.9.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3672, i64 0, i64 0, i64 1
  %3679 = bitcast i8* %scevgep28.9.6 to [61 x [61 x i8]]*
  %scevgep41.9.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3673, i64 0, i64 1, i64 0
  %3680 = bitcast i8* %scevgep41.9.6 to [61 x [61 x i8]]*
  %call16.9.7 = call zeroext i8 (...) @rand()
  store i8 %call16.9.7, i8* %scevgep28.9.6, align 1
  %3681 = load i8, i8* %scevgep28.9.6, align 1
  %conv23.9.7 = zext i8 %3681 to i32
  %3682 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.7 = getelementptr i8, i8* %b, i64 17
  %3683 = load i8, i8* %scevgep34.9.7, align 1
  %call28.9.7 = call zeroext i8 @mult(i8 zeroext %3682, i8 zeroext %3683)
  %conv29.9.7 = zext i8 %call28.9.7 to i32
  %xor.9.7 = xor i32 %conv23.9.7, %conv29.9.7
  %scevgep35.9.7 = getelementptr i8, i8* %a, i64 17
  %3684 = load i8, i8* %scevgep35.9.7, align 1
  %3685 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.7 = call zeroext i8 @mult(i8 zeroext %3684, i8 zeroext %3685)
  %conv35.9.7 = zext i8 %call34.9.7 to i32
  %xor36.9.7 = xor i32 %xor.9.7, %conv35.9.7
  %conv37.9.7 = trunc i32 %xor36.9.7 to i8
  store i8 %conv37.9.7, i8* %scevgep41.9.6, align 1
  %scevgep28.9.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3679, i64 0, i64 0, i64 1
  %3686 = bitcast i8* %scevgep28.9.7 to [61 x [61 x i8]]*
  %scevgep41.9.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3680, i64 0, i64 1, i64 0
  %3687 = bitcast i8* %scevgep41.9.7 to [61 x [61 x i8]]*
  %call16.9.8 = call zeroext i8 (...) @rand()
  store i8 %call16.9.8, i8* %scevgep28.9.7, align 1
  %3688 = load i8, i8* %scevgep28.9.7, align 1
  %conv23.9.8 = zext i8 %3688 to i32
  %3689 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.8 = getelementptr i8, i8* %b, i64 18
  %3690 = load i8, i8* %scevgep34.9.8, align 1
  %call28.9.8 = call zeroext i8 @mult(i8 zeroext %3689, i8 zeroext %3690)
  %conv29.9.8 = zext i8 %call28.9.8 to i32
  %xor.9.8 = xor i32 %conv23.9.8, %conv29.9.8
  %scevgep35.9.8 = getelementptr i8, i8* %a, i64 18
  %3691 = load i8, i8* %scevgep35.9.8, align 1
  %3692 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.8 = call zeroext i8 @mult(i8 zeroext %3691, i8 zeroext %3692)
  %conv35.9.8 = zext i8 %call34.9.8 to i32
  %xor36.9.8 = xor i32 %xor.9.8, %conv35.9.8
  %conv37.9.8 = trunc i32 %xor36.9.8 to i8
  store i8 %conv37.9.8, i8* %scevgep41.9.7, align 1
  %scevgep28.9.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3686, i64 0, i64 0, i64 1
  %3693 = bitcast i8* %scevgep28.9.8 to [61 x [61 x i8]]*
  %scevgep41.9.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3687, i64 0, i64 1, i64 0
  %3694 = bitcast i8* %scevgep41.9.8 to [61 x [61 x i8]]*
  %call16.9.9 = call zeroext i8 (...) @rand()
  store i8 %call16.9.9, i8* %scevgep28.9.8, align 1
  %3695 = load i8, i8* %scevgep28.9.8, align 1
  %conv23.9.9 = zext i8 %3695 to i32
  %3696 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.9 = getelementptr i8, i8* %b, i64 19
  %3697 = load i8, i8* %scevgep34.9.9, align 1
  %call28.9.9 = call zeroext i8 @mult(i8 zeroext %3696, i8 zeroext %3697)
  %conv29.9.9 = zext i8 %call28.9.9 to i32
  %xor.9.9 = xor i32 %conv23.9.9, %conv29.9.9
  %scevgep35.9.9 = getelementptr i8, i8* %a, i64 19
  %3698 = load i8, i8* %scevgep35.9.9, align 1
  %3699 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.9 = call zeroext i8 @mult(i8 zeroext %3698, i8 zeroext %3699)
  %conv35.9.9 = zext i8 %call34.9.9 to i32
  %xor36.9.9 = xor i32 %xor.9.9, %conv35.9.9
  %conv37.9.9 = trunc i32 %xor36.9.9 to i8
  store i8 %conv37.9.9, i8* %scevgep41.9.8, align 1
  %scevgep28.9.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3693, i64 0, i64 0, i64 1
  %3700 = bitcast i8* %scevgep28.9.9 to [61 x [61 x i8]]*
  %scevgep41.9.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3694, i64 0, i64 1, i64 0
  %3701 = bitcast i8* %scevgep41.9.9 to [61 x [61 x i8]]*
  %call16.9.10 = call zeroext i8 (...) @rand()
  store i8 %call16.9.10, i8* %scevgep28.9.9, align 1
  %3702 = load i8, i8* %scevgep28.9.9, align 1
  %conv23.9.10 = zext i8 %3702 to i32
  %3703 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.10 = getelementptr i8, i8* %b, i64 20
  %3704 = load i8, i8* %scevgep34.9.10, align 1
  %call28.9.10 = call zeroext i8 @mult(i8 zeroext %3703, i8 zeroext %3704)
  %conv29.9.10 = zext i8 %call28.9.10 to i32
  %xor.9.10 = xor i32 %conv23.9.10, %conv29.9.10
  %scevgep35.9.10 = getelementptr i8, i8* %a, i64 20
  %3705 = load i8, i8* %scevgep35.9.10, align 1
  %3706 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.10 = call zeroext i8 @mult(i8 zeroext %3705, i8 zeroext %3706)
  %conv35.9.10 = zext i8 %call34.9.10 to i32
  %xor36.9.10 = xor i32 %xor.9.10, %conv35.9.10
  %conv37.9.10 = trunc i32 %xor36.9.10 to i8
  store i8 %conv37.9.10, i8* %scevgep41.9.9, align 1
  %scevgep28.9.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3700, i64 0, i64 0, i64 1
  %3707 = bitcast i8* %scevgep28.9.10 to [61 x [61 x i8]]*
  %scevgep41.9.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3701, i64 0, i64 1, i64 0
  %3708 = bitcast i8* %scevgep41.9.10 to [61 x [61 x i8]]*
  %call16.9.11 = call zeroext i8 (...) @rand()
  store i8 %call16.9.11, i8* %scevgep28.9.10, align 1
  %3709 = load i8, i8* %scevgep28.9.10, align 1
  %conv23.9.11 = zext i8 %3709 to i32
  %3710 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.11 = getelementptr i8, i8* %b, i64 21
  %3711 = load i8, i8* %scevgep34.9.11, align 1
  %call28.9.11 = call zeroext i8 @mult(i8 zeroext %3710, i8 zeroext %3711)
  %conv29.9.11 = zext i8 %call28.9.11 to i32
  %xor.9.11 = xor i32 %conv23.9.11, %conv29.9.11
  %scevgep35.9.11 = getelementptr i8, i8* %a, i64 21
  %3712 = load i8, i8* %scevgep35.9.11, align 1
  %3713 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.11 = call zeroext i8 @mult(i8 zeroext %3712, i8 zeroext %3713)
  %conv35.9.11 = zext i8 %call34.9.11 to i32
  %xor36.9.11 = xor i32 %xor.9.11, %conv35.9.11
  %conv37.9.11 = trunc i32 %xor36.9.11 to i8
  store i8 %conv37.9.11, i8* %scevgep41.9.10, align 1
  %scevgep28.9.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3707, i64 0, i64 0, i64 1
  %3714 = bitcast i8* %scevgep28.9.11 to [61 x [61 x i8]]*
  %scevgep41.9.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3708, i64 0, i64 1, i64 0
  %3715 = bitcast i8* %scevgep41.9.11 to [61 x [61 x i8]]*
  %call16.9.12 = call zeroext i8 (...) @rand()
  store i8 %call16.9.12, i8* %scevgep28.9.11, align 1
  %3716 = load i8, i8* %scevgep28.9.11, align 1
  %conv23.9.12 = zext i8 %3716 to i32
  %3717 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.12 = getelementptr i8, i8* %b, i64 22
  %3718 = load i8, i8* %scevgep34.9.12, align 1
  %call28.9.12 = call zeroext i8 @mult(i8 zeroext %3717, i8 zeroext %3718)
  %conv29.9.12 = zext i8 %call28.9.12 to i32
  %xor.9.12 = xor i32 %conv23.9.12, %conv29.9.12
  %scevgep35.9.12 = getelementptr i8, i8* %a, i64 22
  %3719 = load i8, i8* %scevgep35.9.12, align 1
  %3720 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.12 = call zeroext i8 @mult(i8 zeroext %3719, i8 zeroext %3720)
  %conv35.9.12 = zext i8 %call34.9.12 to i32
  %xor36.9.12 = xor i32 %xor.9.12, %conv35.9.12
  %conv37.9.12 = trunc i32 %xor36.9.12 to i8
  store i8 %conv37.9.12, i8* %scevgep41.9.11, align 1
  %scevgep28.9.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3714, i64 0, i64 0, i64 1
  %3721 = bitcast i8* %scevgep28.9.12 to [61 x [61 x i8]]*
  %scevgep41.9.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3715, i64 0, i64 1, i64 0
  %3722 = bitcast i8* %scevgep41.9.12 to [61 x [61 x i8]]*
  %call16.9.13 = call zeroext i8 (...) @rand()
  store i8 %call16.9.13, i8* %scevgep28.9.12, align 1
  %3723 = load i8, i8* %scevgep28.9.12, align 1
  %conv23.9.13 = zext i8 %3723 to i32
  %3724 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.13 = getelementptr i8, i8* %b, i64 23
  %3725 = load i8, i8* %scevgep34.9.13, align 1
  %call28.9.13 = call zeroext i8 @mult(i8 zeroext %3724, i8 zeroext %3725)
  %conv29.9.13 = zext i8 %call28.9.13 to i32
  %xor.9.13 = xor i32 %conv23.9.13, %conv29.9.13
  %scevgep35.9.13 = getelementptr i8, i8* %a, i64 23
  %3726 = load i8, i8* %scevgep35.9.13, align 1
  %3727 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.13 = call zeroext i8 @mult(i8 zeroext %3726, i8 zeroext %3727)
  %conv35.9.13 = zext i8 %call34.9.13 to i32
  %xor36.9.13 = xor i32 %xor.9.13, %conv35.9.13
  %conv37.9.13 = trunc i32 %xor36.9.13 to i8
  store i8 %conv37.9.13, i8* %scevgep41.9.12, align 1
  %scevgep28.9.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3721, i64 0, i64 0, i64 1
  %3728 = bitcast i8* %scevgep28.9.13 to [61 x [61 x i8]]*
  %scevgep41.9.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3722, i64 0, i64 1, i64 0
  %3729 = bitcast i8* %scevgep41.9.13 to [61 x [61 x i8]]*
  %call16.9.14 = call zeroext i8 (...) @rand()
  store i8 %call16.9.14, i8* %scevgep28.9.13, align 1
  %3730 = load i8, i8* %scevgep28.9.13, align 1
  %conv23.9.14 = zext i8 %3730 to i32
  %3731 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.14 = getelementptr i8, i8* %b, i64 24
  %3732 = load i8, i8* %scevgep34.9.14, align 1
  %call28.9.14 = call zeroext i8 @mult(i8 zeroext %3731, i8 zeroext %3732)
  %conv29.9.14 = zext i8 %call28.9.14 to i32
  %xor.9.14 = xor i32 %conv23.9.14, %conv29.9.14
  %scevgep35.9.14 = getelementptr i8, i8* %a, i64 24
  %3733 = load i8, i8* %scevgep35.9.14, align 1
  %3734 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.14 = call zeroext i8 @mult(i8 zeroext %3733, i8 zeroext %3734)
  %conv35.9.14 = zext i8 %call34.9.14 to i32
  %xor36.9.14 = xor i32 %xor.9.14, %conv35.9.14
  %conv37.9.14 = trunc i32 %xor36.9.14 to i8
  store i8 %conv37.9.14, i8* %scevgep41.9.13, align 1
  %scevgep28.9.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3728, i64 0, i64 0, i64 1
  %3735 = bitcast i8* %scevgep28.9.14 to [61 x [61 x i8]]*
  %scevgep41.9.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3729, i64 0, i64 1, i64 0
  %3736 = bitcast i8* %scevgep41.9.14 to [61 x [61 x i8]]*
  %call16.9.15 = call zeroext i8 (...) @rand()
  store i8 %call16.9.15, i8* %scevgep28.9.14, align 1
  %3737 = load i8, i8* %scevgep28.9.14, align 1
  %conv23.9.15 = zext i8 %3737 to i32
  %3738 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.15 = getelementptr i8, i8* %b, i64 25
  %3739 = load i8, i8* %scevgep34.9.15, align 1
  %call28.9.15 = call zeroext i8 @mult(i8 zeroext %3738, i8 zeroext %3739)
  %conv29.9.15 = zext i8 %call28.9.15 to i32
  %xor.9.15 = xor i32 %conv23.9.15, %conv29.9.15
  %scevgep35.9.15 = getelementptr i8, i8* %a, i64 25
  %3740 = load i8, i8* %scevgep35.9.15, align 1
  %3741 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.15 = call zeroext i8 @mult(i8 zeroext %3740, i8 zeroext %3741)
  %conv35.9.15 = zext i8 %call34.9.15 to i32
  %xor36.9.15 = xor i32 %xor.9.15, %conv35.9.15
  %conv37.9.15 = trunc i32 %xor36.9.15 to i8
  store i8 %conv37.9.15, i8* %scevgep41.9.14, align 1
  %scevgep28.9.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3735, i64 0, i64 0, i64 1
  %3742 = bitcast i8* %scevgep28.9.15 to [61 x [61 x i8]]*
  %scevgep41.9.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3736, i64 0, i64 1, i64 0
  %3743 = bitcast i8* %scevgep41.9.15 to [61 x [61 x i8]]*
  %call16.9.16 = call zeroext i8 (...) @rand()
  store i8 %call16.9.16, i8* %scevgep28.9.15, align 1
  %3744 = load i8, i8* %scevgep28.9.15, align 1
  %conv23.9.16 = zext i8 %3744 to i32
  %3745 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.16 = getelementptr i8, i8* %b, i64 26
  %3746 = load i8, i8* %scevgep34.9.16, align 1
  %call28.9.16 = call zeroext i8 @mult(i8 zeroext %3745, i8 zeroext %3746)
  %conv29.9.16 = zext i8 %call28.9.16 to i32
  %xor.9.16 = xor i32 %conv23.9.16, %conv29.9.16
  %scevgep35.9.16 = getelementptr i8, i8* %a, i64 26
  %3747 = load i8, i8* %scevgep35.9.16, align 1
  %3748 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.16 = call zeroext i8 @mult(i8 zeroext %3747, i8 zeroext %3748)
  %conv35.9.16 = zext i8 %call34.9.16 to i32
  %xor36.9.16 = xor i32 %xor.9.16, %conv35.9.16
  %conv37.9.16 = trunc i32 %xor36.9.16 to i8
  store i8 %conv37.9.16, i8* %scevgep41.9.15, align 1
  %scevgep28.9.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3742, i64 0, i64 0, i64 1
  %3749 = bitcast i8* %scevgep28.9.16 to [61 x [61 x i8]]*
  %scevgep41.9.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3743, i64 0, i64 1, i64 0
  %3750 = bitcast i8* %scevgep41.9.16 to [61 x [61 x i8]]*
  %call16.9.17 = call zeroext i8 (...) @rand()
  store i8 %call16.9.17, i8* %scevgep28.9.16, align 1
  %3751 = load i8, i8* %scevgep28.9.16, align 1
  %conv23.9.17 = zext i8 %3751 to i32
  %3752 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.17 = getelementptr i8, i8* %b, i64 27
  %3753 = load i8, i8* %scevgep34.9.17, align 1
  %call28.9.17 = call zeroext i8 @mult(i8 zeroext %3752, i8 zeroext %3753)
  %conv29.9.17 = zext i8 %call28.9.17 to i32
  %xor.9.17 = xor i32 %conv23.9.17, %conv29.9.17
  %scevgep35.9.17 = getelementptr i8, i8* %a, i64 27
  %3754 = load i8, i8* %scevgep35.9.17, align 1
  %3755 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.17 = call zeroext i8 @mult(i8 zeroext %3754, i8 zeroext %3755)
  %conv35.9.17 = zext i8 %call34.9.17 to i32
  %xor36.9.17 = xor i32 %xor.9.17, %conv35.9.17
  %conv37.9.17 = trunc i32 %xor36.9.17 to i8
  store i8 %conv37.9.17, i8* %scevgep41.9.16, align 1
  %scevgep28.9.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3749, i64 0, i64 0, i64 1
  %3756 = bitcast i8* %scevgep28.9.17 to [61 x [61 x i8]]*
  %scevgep41.9.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3750, i64 0, i64 1, i64 0
  %3757 = bitcast i8* %scevgep41.9.17 to [61 x [61 x i8]]*
  %call16.9.18 = call zeroext i8 (...) @rand()
  store i8 %call16.9.18, i8* %scevgep28.9.17, align 1
  %3758 = load i8, i8* %scevgep28.9.17, align 1
  %conv23.9.18 = zext i8 %3758 to i32
  %3759 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.18 = getelementptr i8, i8* %b, i64 28
  %3760 = load i8, i8* %scevgep34.9.18, align 1
  %call28.9.18 = call zeroext i8 @mult(i8 zeroext %3759, i8 zeroext %3760)
  %conv29.9.18 = zext i8 %call28.9.18 to i32
  %xor.9.18 = xor i32 %conv23.9.18, %conv29.9.18
  %scevgep35.9.18 = getelementptr i8, i8* %a, i64 28
  %3761 = load i8, i8* %scevgep35.9.18, align 1
  %3762 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.18 = call zeroext i8 @mult(i8 zeroext %3761, i8 zeroext %3762)
  %conv35.9.18 = zext i8 %call34.9.18 to i32
  %xor36.9.18 = xor i32 %xor.9.18, %conv35.9.18
  %conv37.9.18 = trunc i32 %xor36.9.18 to i8
  store i8 %conv37.9.18, i8* %scevgep41.9.17, align 1
  %scevgep28.9.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3756, i64 0, i64 0, i64 1
  %3763 = bitcast i8* %scevgep28.9.18 to [61 x [61 x i8]]*
  %scevgep41.9.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3757, i64 0, i64 1, i64 0
  %3764 = bitcast i8* %scevgep41.9.18 to [61 x [61 x i8]]*
  %call16.9.19 = call zeroext i8 (...) @rand()
  store i8 %call16.9.19, i8* %scevgep28.9.18, align 1
  %3765 = load i8, i8* %scevgep28.9.18, align 1
  %conv23.9.19 = zext i8 %3765 to i32
  %3766 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.19 = getelementptr i8, i8* %b, i64 29
  %3767 = load i8, i8* %scevgep34.9.19, align 1
  %call28.9.19 = call zeroext i8 @mult(i8 zeroext %3766, i8 zeroext %3767)
  %conv29.9.19 = zext i8 %call28.9.19 to i32
  %xor.9.19 = xor i32 %conv23.9.19, %conv29.9.19
  %scevgep35.9.19 = getelementptr i8, i8* %a, i64 29
  %3768 = load i8, i8* %scevgep35.9.19, align 1
  %3769 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.19 = call zeroext i8 @mult(i8 zeroext %3768, i8 zeroext %3769)
  %conv35.9.19 = zext i8 %call34.9.19 to i32
  %xor36.9.19 = xor i32 %xor.9.19, %conv35.9.19
  %conv37.9.19 = trunc i32 %xor36.9.19 to i8
  store i8 %conv37.9.19, i8* %scevgep41.9.18, align 1
  %scevgep28.9.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3763, i64 0, i64 0, i64 1
  %3770 = bitcast i8* %scevgep28.9.19 to [61 x [61 x i8]]*
  %scevgep41.9.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3764, i64 0, i64 1, i64 0
  %3771 = bitcast i8* %scevgep41.9.19 to [61 x [61 x i8]]*
  %call16.9.20 = call zeroext i8 (...) @rand()
  store i8 %call16.9.20, i8* %scevgep28.9.19, align 1
  %3772 = load i8, i8* %scevgep28.9.19, align 1
  %conv23.9.20 = zext i8 %3772 to i32
  %3773 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.20 = getelementptr i8, i8* %b, i64 30
  %3774 = load i8, i8* %scevgep34.9.20, align 1
  %call28.9.20 = call zeroext i8 @mult(i8 zeroext %3773, i8 zeroext %3774)
  %conv29.9.20 = zext i8 %call28.9.20 to i32
  %xor.9.20 = xor i32 %conv23.9.20, %conv29.9.20
  %scevgep35.9.20 = getelementptr i8, i8* %a, i64 30
  %3775 = load i8, i8* %scevgep35.9.20, align 1
  %3776 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.20 = call zeroext i8 @mult(i8 zeroext %3775, i8 zeroext %3776)
  %conv35.9.20 = zext i8 %call34.9.20 to i32
  %xor36.9.20 = xor i32 %xor.9.20, %conv35.9.20
  %conv37.9.20 = trunc i32 %xor36.9.20 to i8
  store i8 %conv37.9.20, i8* %scevgep41.9.19, align 1
  %scevgep28.9.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3770, i64 0, i64 0, i64 1
  %3777 = bitcast i8* %scevgep28.9.20 to [61 x [61 x i8]]*
  %scevgep41.9.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3771, i64 0, i64 1, i64 0
  %3778 = bitcast i8* %scevgep41.9.20 to [61 x [61 x i8]]*
  %call16.9.21 = call zeroext i8 (...) @rand()
  store i8 %call16.9.21, i8* %scevgep28.9.20, align 1
  %3779 = load i8, i8* %scevgep28.9.20, align 1
  %conv23.9.21 = zext i8 %3779 to i32
  %3780 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.21 = getelementptr i8, i8* %b, i64 31
  %3781 = load i8, i8* %scevgep34.9.21, align 1
  %call28.9.21 = call zeroext i8 @mult(i8 zeroext %3780, i8 zeroext %3781)
  %conv29.9.21 = zext i8 %call28.9.21 to i32
  %xor.9.21 = xor i32 %conv23.9.21, %conv29.9.21
  %scevgep35.9.21 = getelementptr i8, i8* %a, i64 31
  %3782 = load i8, i8* %scevgep35.9.21, align 1
  %3783 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.21 = call zeroext i8 @mult(i8 zeroext %3782, i8 zeroext %3783)
  %conv35.9.21 = zext i8 %call34.9.21 to i32
  %xor36.9.21 = xor i32 %xor.9.21, %conv35.9.21
  %conv37.9.21 = trunc i32 %xor36.9.21 to i8
  store i8 %conv37.9.21, i8* %scevgep41.9.20, align 1
  %scevgep28.9.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3777, i64 0, i64 0, i64 1
  %3784 = bitcast i8* %scevgep28.9.21 to [61 x [61 x i8]]*
  %scevgep41.9.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3778, i64 0, i64 1, i64 0
  %3785 = bitcast i8* %scevgep41.9.21 to [61 x [61 x i8]]*
  %call16.9.22 = call zeroext i8 (...) @rand()
  store i8 %call16.9.22, i8* %scevgep28.9.21, align 1
  %3786 = load i8, i8* %scevgep28.9.21, align 1
  %conv23.9.22 = zext i8 %3786 to i32
  %3787 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.22 = getelementptr i8, i8* %b, i64 32
  %3788 = load i8, i8* %scevgep34.9.22, align 1
  %call28.9.22 = call zeroext i8 @mult(i8 zeroext %3787, i8 zeroext %3788)
  %conv29.9.22 = zext i8 %call28.9.22 to i32
  %xor.9.22 = xor i32 %conv23.9.22, %conv29.9.22
  %scevgep35.9.22 = getelementptr i8, i8* %a, i64 32
  %3789 = load i8, i8* %scevgep35.9.22, align 1
  %3790 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.22 = call zeroext i8 @mult(i8 zeroext %3789, i8 zeroext %3790)
  %conv35.9.22 = zext i8 %call34.9.22 to i32
  %xor36.9.22 = xor i32 %xor.9.22, %conv35.9.22
  %conv37.9.22 = trunc i32 %xor36.9.22 to i8
  store i8 %conv37.9.22, i8* %scevgep41.9.21, align 1
  %scevgep28.9.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3784, i64 0, i64 0, i64 1
  %3791 = bitcast i8* %scevgep28.9.22 to [61 x [61 x i8]]*
  %scevgep41.9.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3785, i64 0, i64 1, i64 0
  %3792 = bitcast i8* %scevgep41.9.22 to [61 x [61 x i8]]*
  %call16.9.23 = call zeroext i8 (...) @rand()
  store i8 %call16.9.23, i8* %scevgep28.9.22, align 1
  %3793 = load i8, i8* %scevgep28.9.22, align 1
  %conv23.9.23 = zext i8 %3793 to i32
  %3794 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.23 = getelementptr i8, i8* %b, i64 33
  %3795 = load i8, i8* %scevgep34.9.23, align 1
  %call28.9.23 = call zeroext i8 @mult(i8 zeroext %3794, i8 zeroext %3795)
  %conv29.9.23 = zext i8 %call28.9.23 to i32
  %xor.9.23 = xor i32 %conv23.9.23, %conv29.9.23
  %scevgep35.9.23 = getelementptr i8, i8* %a, i64 33
  %3796 = load i8, i8* %scevgep35.9.23, align 1
  %3797 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.23 = call zeroext i8 @mult(i8 zeroext %3796, i8 zeroext %3797)
  %conv35.9.23 = zext i8 %call34.9.23 to i32
  %xor36.9.23 = xor i32 %xor.9.23, %conv35.9.23
  %conv37.9.23 = trunc i32 %xor36.9.23 to i8
  store i8 %conv37.9.23, i8* %scevgep41.9.22, align 1
  %scevgep28.9.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3791, i64 0, i64 0, i64 1
  %3798 = bitcast i8* %scevgep28.9.23 to [61 x [61 x i8]]*
  %scevgep41.9.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3792, i64 0, i64 1, i64 0
  %3799 = bitcast i8* %scevgep41.9.23 to [61 x [61 x i8]]*
  %call16.9.24 = call zeroext i8 (...) @rand()
  store i8 %call16.9.24, i8* %scevgep28.9.23, align 1
  %3800 = load i8, i8* %scevgep28.9.23, align 1
  %conv23.9.24 = zext i8 %3800 to i32
  %3801 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.24 = getelementptr i8, i8* %b, i64 34
  %3802 = load i8, i8* %scevgep34.9.24, align 1
  %call28.9.24 = call zeroext i8 @mult(i8 zeroext %3801, i8 zeroext %3802)
  %conv29.9.24 = zext i8 %call28.9.24 to i32
  %xor.9.24 = xor i32 %conv23.9.24, %conv29.9.24
  %scevgep35.9.24 = getelementptr i8, i8* %a, i64 34
  %3803 = load i8, i8* %scevgep35.9.24, align 1
  %3804 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.24 = call zeroext i8 @mult(i8 zeroext %3803, i8 zeroext %3804)
  %conv35.9.24 = zext i8 %call34.9.24 to i32
  %xor36.9.24 = xor i32 %xor.9.24, %conv35.9.24
  %conv37.9.24 = trunc i32 %xor36.9.24 to i8
  store i8 %conv37.9.24, i8* %scevgep41.9.23, align 1
  %scevgep28.9.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3798, i64 0, i64 0, i64 1
  %3805 = bitcast i8* %scevgep28.9.24 to [61 x [61 x i8]]*
  %scevgep41.9.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3799, i64 0, i64 1, i64 0
  %3806 = bitcast i8* %scevgep41.9.24 to [61 x [61 x i8]]*
  %call16.9.25 = call zeroext i8 (...) @rand()
  store i8 %call16.9.25, i8* %scevgep28.9.24, align 1
  %3807 = load i8, i8* %scevgep28.9.24, align 1
  %conv23.9.25 = zext i8 %3807 to i32
  %3808 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.25 = getelementptr i8, i8* %b, i64 35
  %3809 = load i8, i8* %scevgep34.9.25, align 1
  %call28.9.25 = call zeroext i8 @mult(i8 zeroext %3808, i8 zeroext %3809)
  %conv29.9.25 = zext i8 %call28.9.25 to i32
  %xor.9.25 = xor i32 %conv23.9.25, %conv29.9.25
  %scevgep35.9.25 = getelementptr i8, i8* %a, i64 35
  %3810 = load i8, i8* %scevgep35.9.25, align 1
  %3811 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.25 = call zeroext i8 @mult(i8 zeroext %3810, i8 zeroext %3811)
  %conv35.9.25 = zext i8 %call34.9.25 to i32
  %xor36.9.25 = xor i32 %xor.9.25, %conv35.9.25
  %conv37.9.25 = trunc i32 %xor36.9.25 to i8
  store i8 %conv37.9.25, i8* %scevgep41.9.24, align 1
  %scevgep28.9.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3805, i64 0, i64 0, i64 1
  %3812 = bitcast i8* %scevgep28.9.25 to [61 x [61 x i8]]*
  %scevgep41.9.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3806, i64 0, i64 1, i64 0
  %3813 = bitcast i8* %scevgep41.9.25 to [61 x [61 x i8]]*
  %call16.9.26 = call zeroext i8 (...) @rand()
  store i8 %call16.9.26, i8* %scevgep28.9.25, align 1
  %3814 = load i8, i8* %scevgep28.9.25, align 1
  %conv23.9.26 = zext i8 %3814 to i32
  %3815 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.26 = getelementptr i8, i8* %b, i64 36
  %3816 = load i8, i8* %scevgep34.9.26, align 1
  %call28.9.26 = call zeroext i8 @mult(i8 zeroext %3815, i8 zeroext %3816)
  %conv29.9.26 = zext i8 %call28.9.26 to i32
  %xor.9.26 = xor i32 %conv23.9.26, %conv29.9.26
  %scevgep35.9.26 = getelementptr i8, i8* %a, i64 36
  %3817 = load i8, i8* %scevgep35.9.26, align 1
  %3818 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.26 = call zeroext i8 @mult(i8 zeroext %3817, i8 zeroext %3818)
  %conv35.9.26 = zext i8 %call34.9.26 to i32
  %xor36.9.26 = xor i32 %xor.9.26, %conv35.9.26
  %conv37.9.26 = trunc i32 %xor36.9.26 to i8
  store i8 %conv37.9.26, i8* %scevgep41.9.25, align 1
  %scevgep28.9.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3812, i64 0, i64 0, i64 1
  %3819 = bitcast i8* %scevgep28.9.26 to [61 x [61 x i8]]*
  %scevgep41.9.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3813, i64 0, i64 1, i64 0
  %3820 = bitcast i8* %scevgep41.9.26 to [61 x [61 x i8]]*
  %call16.9.27 = call zeroext i8 (...) @rand()
  store i8 %call16.9.27, i8* %scevgep28.9.26, align 1
  %3821 = load i8, i8* %scevgep28.9.26, align 1
  %conv23.9.27 = zext i8 %3821 to i32
  %3822 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.27 = getelementptr i8, i8* %b, i64 37
  %3823 = load i8, i8* %scevgep34.9.27, align 1
  %call28.9.27 = call zeroext i8 @mult(i8 zeroext %3822, i8 zeroext %3823)
  %conv29.9.27 = zext i8 %call28.9.27 to i32
  %xor.9.27 = xor i32 %conv23.9.27, %conv29.9.27
  %scevgep35.9.27 = getelementptr i8, i8* %a, i64 37
  %3824 = load i8, i8* %scevgep35.9.27, align 1
  %3825 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.27 = call zeroext i8 @mult(i8 zeroext %3824, i8 zeroext %3825)
  %conv35.9.27 = zext i8 %call34.9.27 to i32
  %xor36.9.27 = xor i32 %xor.9.27, %conv35.9.27
  %conv37.9.27 = trunc i32 %xor36.9.27 to i8
  store i8 %conv37.9.27, i8* %scevgep41.9.26, align 1
  %scevgep28.9.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3819, i64 0, i64 0, i64 1
  %3826 = bitcast i8* %scevgep28.9.27 to [61 x [61 x i8]]*
  %scevgep41.9.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3820, i64 0, i64 1, i64 0
  %3827 = bitcast i8* %scevgep41.9.27 to [61 x [61 x i8]]*
  %call16.9.28 = call zeroext i8 (...) @rand()
  store i8 %call16.9.28, i8* %scevgep28.9.27, align 1
  %3828 = load i8, i8* %scevgep28.9.27, align 1
  %conv23.9.28 = zext i8 %3828 to i32
  %3829 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.28 = getelementptr i8, i8* %b, i64 38
  %3830 = load i8, i8* %scevgep34.9.28, align 1
  %call28.9.28 = call zeroext i8 @mult(i8 zeroext %3829, i8 zeroext %3830)
  %conv29.9.28 = zext i8 %call28.9.28 to i32
  %xor.9.28 = xor i32 %conv23.9.28, %conv29.9.28
  %scevgep35.9.28 = getelementptr i8, i8* %a, i64 38
  %3831 = load i8, i8* %scevgep35.9.28, align 1
  %3832 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.28 = call zeroext i8 @mult(i8 zeroext %3831, i8 zeroext %3832)
  %conv35.9.28 = zext i8 %call34.9.28 to i32
  %xor36.9.28 = xor i32 %xor.9.28, %conv35.9.28
  %conv37.9.28 = trunc i32 %xor36.9.28 to i8
  store i8 %conv37.9.28, i8* %scevgep41.9.27, align 1
  %scevgep28.9.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3826, i64 0, i64 0, i64 1
  %3833 = bitcast i8* %scevgep28.9.28 to [61 x [61 x i8]]*
  %scevgep41.9.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3827, i64 0, i64 1, i64 0
  %3834 = bitcast i8* %scevgep41.9.28 to [61 x [61 x i8]]*
  %call16.9.29 = call zeroext i8 (...) @rand()
  store i8 %call16.9.29, i8* %scevgep28.9.28, align 1
  %3835 = load i8, i8* %scevgep28.9.28, align 1
  %conv23.9.29 = zext i8 %3835 to i32
  %3836 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.29 = getelementptr i8, i8* %b, i64 39
  %3837 = load i8, i8* %scevgep34.9.29, align 1
  %call28.9.29 = call zeroext i8 @mult(i8 zeroext %3836, i8 zeroext %3837)
  %conv29.9.29 = zext i8 %call28.9.29 to i32
  %xor.9.29 = xor i32 %conv23.9.29, %conv29.9.29
  %scevgep35.9.29 = getelementptr i8, i8* %a, i64 39
  %3838 = load i8, i8* %scevgep35.9.29, align 1
  %3839 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.29 = call zeroext i8 @mult(i8 zeroext %3838, i8 zeroext %3839)
  %conv35.9.29 = zext i8 %call34.9.29 to i32
  %xor36.9.29 = xor i32 %xor.9.29, %conv35.9.29
  %conv37.9.29 = trunc i32 %xor36.9.29 to i8
  store i8 %conv37.9.29, i8* %scevgep41.9.28, align 1
  %scevgep28.9.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3833, i64 0, i64 0, i64 1
  %3840 = bitcast i8* %scevgep28.9.29 to [61 x [61 x i8]]*
  %scevgep41.9.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3834, i64 0, i64 1, i64 0
  %3841 = bitcast i8* %scevgep41.9.29 to [61 x [61 x i8]]*
  %call16.9.30 = call zeroext i8 (...) @rand()
  store i8 %call16.9.30, i8* %scevgep28.9.29, align 1
  %3842 = load i8, i8* %scevgep28.9.29, align 1
  %conv23.9.30 = zext i8 %3842 to i32
  %3843 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.30 = getelementptr i8, i8* %b, i64 40
  %3844 = load i8, i8* %scevgep34.9.30, align 1
  %call28.9.30 = call zeroext i8 @mult(i8 zeroext %3843, i8 zeroext %3844)
  %conv29.9.30 = zext i8 %call28.9.30 to i32
  %xor.9.30 = xor i32 %conv23.9.30, %conv29.9.30
  %scevgep35.9.30 = getelementptr i8, i8* %a, i64 40
  %3845 = load i8, i8* %scevgep35.9.30, align 1
  %3846 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.30 = call zeroext i8 @mult(i8 zeroext %3845, i8 zeroext %3846)
  %conv35.9.30 = zext i8 %call34.9.30 to i32
  %xor36.9.30 = xor i32 %xor.9.30, %conv35.9.30
  %conv37.9.30 = trunc i32 %xor36.9.30 to i8
  store i8 %conv37.9.30, i8* %scevgep41.9.29, align 1
  %scevgep28.9.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3840, i64 0, i64 0, i64 1
  %3847 = bitcast i8* %scevgep28.9.30 to [61 x [61 x i8]]*
  %scevgep41.9.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3841, i64 0, i64 1, i64 0
  %3848 = bitcast i8* %scevgep41.9.30 to [61 x [61 x i8]]*
  %call16.9.31 = call zeroext i8 (...) @rand()
  store i8 %call16.9.31, i8* %scevgep28.9.30, align 1
  %3849 = load i8, i8* %scevgep28.9.30, align 1
  %conv23.9.31 = zext i8 %3849 to i32
  %3850 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.31 = getelementptr i8, i8* %b, i64 41
  %3851 = load i8, i8* %scevgep34.9.31, align 1
  %call28.9.31 = call zeroext i8 @mult(i8 zeroext %3850, i8 zeroext %3851)
  %conv29.9.31 = zext i8 %call28.9.31 to i32
  %xor.9.31 = xor i32 %conv23.9.31, %conv29.9.31
  %scevgep35.9.31 = getelementptr i8, i8* %a, i64 41
  %3852 = load i8, i8* %scevgep35.9.31, align 1
  %3853 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.31 = call zeroext i8 @mult(i8 zeroext %3852, i8 zeroext %3853)
  %conv35.9.31 = zext i8 %call34.9.31 to i32
  %xor36.9.31 = xor i32 %xor.9.31, %conv35.9.31
  %conv37.9.31 = trunc i32 %xor36.9.31 to i8
  store i8 %conv37.9.31, i8* %scevgep41.9.30, align 1
  %scevgep28.9.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3847, i64 0, i64 0, i64 1
  %3854 = bitcast i8* %scevgep28.9.31 to [61 x [61 x i8]]*
  %scevgep41.9.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3848, i64 0, i64 1, i64 0
  %3855 = bitcast i8* %scevgep41.9.31 to [61 x [61 x i8]]*
  %call16.9.32 = call zeroext i8 (...) @rand()
  store i8 %call16.9.32, i8* %scevgep28.9.31, align 1
  %3856 = load i8, i8* %scevgep28.9.31, align 1
  %conv23.9.32 = zext i8 %3856 to i32
  %3857 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.32 = getelementptr i8, i8* %b, i64 42
  %3858 = load i8, i8* %scevgep34.9.32, align 1
  %call28.9.32 = call zeroext i8 @mult(i8 zeroext %3857, i8 zeroext %3858)
  %conv29.9.32 = zext i8 %call28.9.32 to i32
  %xor.9.32 = xor i32 %conv23.9.32, %conv29.9.32
  %scevgep35.9.32 = getelementptr i8, i8* %a, i64 42
  %3859 = load i8, i8* %scevgep35.9.32, align 1
  %3860 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.32 = call zeroext i8 @mult(i8 zeroext %3859, i8 zeroext %3860)
  %conv35.9.32 = zext i8 %call34.9.32 to i32
  %xor36.9.32 = xor i32 %xor.9.32, %conv35.9.32
  %conv37.9.32 = trunc i32 %xor36.9.32 to i8
  store i8 %conv37.9.32, i8* %scevgep41.9.31, align 1
  %scevgep28.9.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3854, i64 0, i64 0, i64 1
  %3861 = bitcast i8* %scevgep28.9.32 to [61 x [61 x i8]]*
  %scevgep41.9.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3855, i64 0, i64 1, i64 0
  %3862 = bitcast i8* %scevgep41.9.32 to [61 x [61 x i8]]*
  %call16.9.33 = call zeroext i8 (...) @rand()
  store i8 %call16.9.33, i8* %scevgep28.9.32, align 1
  %3863 = load i8, i8* %scevgep28.9.32, align 1
  %conv23.9.33 = zext i8 %3863 to i32
  %3864 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.33 = getelementptr i8, i8* %b, i64 43
  %3865 = load i8, i8* %scevgep34.9.33, align 1
  %call28.9.33 = call zeroext i8 @mult(i8 zeroext %3864, i8 zeroext %3865)
  %conv29.9.33 = zext i8 %call28.9.33 to i32
  %xor.9.33 = xor i32 %conv23.9.33, %conv29.9.33
  %scevgep35.9.33 = getelementptr i8, i8* %a, i64 43
  %3866 = load i8, i8* %scevgep35.9.33, align 1
  %3867 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.33 = call zeroext i8 @mult(i8 zeroext %3866, i8 zeroext %3867)
  %conv35.9.33 = zext i8 %call34.9.33 to i32
  %xor36.9.33 = xor i32 %xor.9.33, %conv35.9.33
  %conv37.9.33 = trunc i32 %xor36.9.33 to i8
  store i8 %conv37.9.33, i8* %scevgep41.9.32, align 1
  %scevgep28.9.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3861, i64 0, i64 0, i64 1
  %3868 = bitcast i8* %scevgep28.9.33 to [61 x [61 x i8]]*
  %scevgep41.9.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3862, i64 0, i64 1, i64 0
  %3869 = bitcast i8* %scevgep41.9.33 to [61 x [61 x i8]]*
  %call16.9.34 = call zeroext i8 (...) @rand()
  store i8 %call16.9.34, i8* %scevgep28.9.33, align 1
  %3870 = load i8, i8* %scevgep28.9.33, align 1
  %conv23.9.34 = zext i8 %3870 to i32
  %3871 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.34 = getelementptr i8, i8* %b, i64 44
  %3872 = load i8, i8* %scevgep34.9.34, align 1
  %call28.9.34 = call zeroext i8 @mult(i8 zeroext %3871, i8 zeroext %3872)
  %conv29.9.34 = zext i8 %call28.9.34 to i32
  %xor.9.34 = xor i32 %conv23.9.34, %conv29.9.34
  %scevgep35.9.34 = getelementptr i8, i8* %a, i64 44
  %3873 = load i8, i8* %scevgep35.9.34, align 1
  %3874 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.34 = call zeroext i8 @mult(i8 zeroext %3873, i8 zeroext %3874)
  %conv35.9.34 = zext i8 %call34.9.34 to i32
  %xor36.9.34 = xor i32 %xor.9.34, %conv35.9.34
  %conv37.9.34 = trunc i32 %xor36.9.34 to i8
  store i8 %conv37.9.34, i8* %scevgep41.9.33, align 1
  %scevgep28.9.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3868, i64 0, i64 0, i64 1
  %3875 = bitcast i8* %scevgep28.9.34 to [61 x [61 x i8]]*
  %scevgep41.9.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3869, i64 0, i64 1, i64 0
  %3876 = bitcast i8* %scevgep41.9.34 to [61 x [61 x i8]]*
  %call16.9.35 = call zeroext i8 (...) @rand()
  store i8 %call16.9.35, i8* %scevgep28.9.34, align 1
  %3877 = load i8, i8* %scevgep28.9.34, align 1
  %conv23.9.35 = zext i8 %3877 to i32
  %3878 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.35 = getelementptr i8, i8* %b, i64 45
  %3879 = load i8, i8* %scevgep34.9.35, align 1
  %call28.9.35 = call zeroext i8 @mult(i8 zeroext %3878, i8 zeroext %3879)
  %conv29.9.35 = zext i8 %call28.9.35 to i32
  %xor.9.35 = xor i32 %conv23.9.35, %conv29.9.35
  %scevgep35.9.35 = getelementptr i8, i8* %a, i64 45
  %3880 = load i8, i8* %scevgep35.9.35, align 1
  %3881 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.35 = call zeroext i8 @mult(i8 zeroext %3880, i8 zeroext %3881)
  %conv35.9.35 = zext i8 %call34.9.35 to i32
  %xor36.9.35 = xor i32 %xor.9.35, %conv35.9.35
  %conv37.9.35 = trunc i32 %xor36.9.35 to i8
  store i8 %conv37.9.35, i8* %scevgep41.9.34, align 1
  %scevgep28.9.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3875, i64 0, i64 0, i64 1
  %3882 = bitcast i8* %scevgep28.9.35 to [61 x [61 x i8]]*
  %scevgep41.9.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3876, i64 0, i64 1, i64 0
  %3883 = bitcast i8* %scevgep41.9.35 to [61 x [61 x i8]]*
  %call16.9.36 = call zeroext i8 (...) @rand()
  store i8 %call16.9.36, i8* %scevgep28.9.35, align 1
  %3884 = load i8, i8* %scevgep28.9.35, align 1
  %conv23.9.36 = zext i8 %3884 to i32
  %3885 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.36 = getelementptr i8, i8* %b, i64 46
  %3886 = load i8, i8* %scevgep34.9.36, align 1
  %call28.9.36 = call zeroext i8 @mult(i8 zeroext %3885, i8 zeroext %3886)
  %conv29.9.36 = zext i8 %call28.9.36 to i32
  %xor.9.36 = xor i32 %conv23.9.36, %conv29.9.36
  %scevgep35.9.36 = getelementptr i8, i8* %a, i64 46
  %3887 = load i8, i8* %scevgep35.9.36, align 1
  %3888 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.36 = call zeroext i8 @mult(i8 zeroext %3887, i8 zeroext %3888)
  %conv35.9.36 = zext i8 %call34.9.36 to i32
  %xor36.9.36 = xor i32 %xor.9.36, %conv35.9.36
  %conv37.9.36 = trunc i32 %xor36.9.36 to i8
  store i8 %conv37.9.36, i8* %scevgep41.9.35, align 1
  %scevgep28.9.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3882, i64 0, i64 0, i64 1
  %3889 = bitcast i8* %scevgep28.9.36 to [61 x [61 x i8]]*
  %scevgep41.9.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3883, i64 0, i64 1, i64 0
  %3890 = bitcast i8* %scevgep41.9.36 to [61 x [61 x i8]]*
  %call16.9.37 = call zeroext i8 (...) @rand()
  store i8 %call16.9.37, i8* %scevgep28.9.36, align 1
  %3891 = load i8, i8* %scevgep28.9.36, align 1
  %conv23.9.37 = zext i8 %3891 to i32
  %3892 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.37 = getelementptr i8, i8* %b, i64 47
  %3893 = load i8, i8* %scevgep34.9.37, align 1
  %call28.9.37 = call zeroext i8 @mult(i8 zeroext %3892, i8 zeroext %3893)
  %conv29.9.37 = zext i8 %call28.9.37 to i32
  %xor.9.37 = xor i32 %conv23.9.37, %conv29.9.37
  %scevgep35.9.37 = getelementptr i8, i8* %a, i64 47
  %3894 = load i8, i8* %scevgep35.9.37, align 1
  %3895 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.37 = call zeroext i8 @mult(i8 zeroext %3894, i8 zeroext %3895)
  %conv35.9.37 = zext i8 %call34.9.37 to i32
  %xor36.9.37 = xor i32 %xor.9.37, %conv35.9.37
  %conv37.9.37 = trunc i32 %xor36.9.37 to i8
  store i8 %conv37.9.37, i8* %scevgep41.9.36, align 1
  %scevgep28.9.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3889, i64 0, i64 0, i64 1
  %3896 = bitcast i8* %scevgep28.9.37 to [61 x [61 x i8]]*
  %scevgep41.9.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3890, i64 0, i64 1, i64 0
  %3897 = bitcast i8* %scevgep41.9.37 to [61 x [61 x i8]]*
  %call16.9.38 = call zeroext i8 (...) @rand()
  store i8 %call16.9.38, i8* %scevgep28.9.37, align 1
  %3898 = load i8, i8* %scevgep28.9.37, align 1
  %conv23.9.38 = zext i8 %3898 to i32
  %3899 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.38 = getelementptr i8, i8* %b, i64 48
  %3900 = load i8, i8* %scevgep34.9.38, align 1
  %call28.9.38 = call zeroext i8 @mult(i8 zeroext %3899, i8 zeroext %3900)
  %conv29.9.38 = zext i8 %call28.9.38 to i32
  %xor.9.38 = xor i32 %conv23.9.38, %conv29.9.38
  %scevgep35.9.38 = getelementptr i8, i8* %a, i64 48
  %3901 = load i8, i8* %scevgep35.9.38, align 1
  %3902 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.38 = call zeroext i8 @mult(i8 zeroext %3901, i8 zeroext %3902)
  %conv35.9.38 = zext i8 %call34.9.38 to i32
  %xor36.9.38 = xor i32 %xor.9.38, %conv35.9.38
  %conv37.9.38 = trunc i32 %xor36.9.38 to i8
  store i8 %conv37.9.38, i8* %scevgep41.9.37, align 1
  %scevgep28.9.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3896, i64 0, i64 0, i64 1
  %3903 = bitcast i8* %scevgep28.9.38 to [61 x [61 x i8]]*
  %scevgep41.9.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3897, i64 0, i64 1, i64 0
  %3904 = bitcast i8* %scevgep41.9.38 to [61 x [61 x i8]]*
  %call16.9.39 = call zeroext i8 (...) @rand()
  store i8 %call16.9.39, i8* %scevgep28.9.38, align 1
  %3905 = load i8, i8* %scevgep28.9.38, align 1
  %conv23.9.39 = zext i8 %3905 to i32
  %3906 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.39 = getelementptr i8, i8* %b, i64 49
  %3907 = load i8, i8* %scevgep34.9.39, align 1
  %call28.9.39 = call zeroext i8 @mult(i8 zeroext %3906, i8 zeroext %3907)
  %conv29.9.39 = zext i8 %call28.9.39 to i32
  %xor.9.39 = xor i32 %conv23.9.39, %conv29.9.39
  %scevgep35.9.39 = getelementptr i8, i8* %a, i64 49
  %3908 = load i8, i8* %scevgep35.9.39, align 1
  %3909 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.39 = call zeroext i8 @mult(i8 zeroext %3908, i8 zeroext %3909)
  %conv35.9.39 = zext i8 %call34.9.39 to i32
  %xor36.9.39 = xor i32 %xor.9.39, %conv35.9.39
  %conv37.9.39 = trunc i32 %xor36.9.39 to i8
  store i8 %conv37.9.39, i8* %scevgep41.9.38, align 1
  %scevgep28.9.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3903, i64 0, i64 0, i64 1
  %3910 = bitcast i8* %scevgep28.9.39 to [61 x [61 x i8]]*
  %scevgep41.9.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3904, i64 0, i64 1, i64 0
  %3911 = bitcast i8* %scevgep41.9.39 to [61 x [61 x i8]]*
  %call16.9.40 = call zeroext i8 (...) @rand()
  store i8 %call16.9.40, i8* %scevgep28.9.39, align 1
  %3912 = load i8, i8* %scevgep28.9.39, align 1
  %conv23.9.40 = zext i8 %3912 to i32
  %3913 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.40 = getelementptr i8, i8* %b, i64 50
  %3914 = load i8, i8* %scevgep34.9.40, align 1
  %call28.9.40 = call zeroext i8 @mult(i8 zeroext %3913, i8 zeroext %3914)
  %conv29.9.40 = zext i8 %call28.9.40 to i32
  %xor.9.40 = xor i32 %conv23.9.40, %conv29.9.40
  %scevgep35.9.40 = getelementptr i8, i8* %a, i64 50
  %3915 = load i8, i8* %scevgep35.9.40, align 1
  %3916 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.40 = call zeroext i8 @mult(i8 zeroext %3915, i8 zeroext %3916)
  %conv35.9.40 = zext i8 %call34.9.40 to i32
  %xor36.9.40 = xor i32 %xor.9.40, %conv35.9.40
  %conv37.9.40 = trunc i32 %xor36.9.40 to i8
  store i8 %conv37.9.40, i8* %scevgep41.9.39, align 1
  %scevgep28.9.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3910, i64 0, i64 0, i64 1
  %3917 = bitcast i8* %scevgep28.9.40 to [61 x [61 x i8]]*
  %scevgep41.9.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3911, i64 0, i64 1, i64 0
  %3918 = bitcast i8* %scevgep41.9.40 to [61 x [61 x i8]]*
  %call16.9.41 = call zeroext i8 (...) @rand()
  store i8 %call16.9.41, i8* %scevgep28.9.40, align 1
  %3919 = load i8, i8* %scevgep28.9.40, align 1
  %conv23.9.41 = zext i8 %3919 to i32
  %3920 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.41 = getelementptr i8, i8* %b, i64 51
  %3921 = load i8, i8* %scevgep34.9.41, align 1
  %call28.9.41 = call zeroext i8 @mult(i8 zeroext %3920, i8 zeroext %3921)
  %conv29.9.41 = zext i8 %call28.9.41 to i32
  %xor.9.41 = xor i32 %conv23.9.41, %conv29.9.41
  %scevgep35.9.41 = getelementptr i8, i8* %a, i64 51
  %3922 = load i8, i8* %scevgep35.9.41, align 1
  %3923 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.41 = call zeroext i8 @mult(i8 zeroext %3922, i8 zeroext %3923)
  %conv35.9.41 = zext i8 %call34.9.41 to i32
  %xor36.9.41 = xor i32 %xor.9.41, %conv35.9.41
  %conv37.9.41 = trunc i32 %xor36.9.41 to i8
  store i8 %conv37.9.41, i8* %scevgep41.9.40, align 1
  %scevgep28.9.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3917, i64 0, i64 0, i64 1
  %3924 = bitcast i8* %scevgep28.9.41 to [61 x [61 x i8]]*
  %scevgep41.9.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3918, i64 0, i64 1, i64 0
  %3925 = bitcast i8* %scevgep41.9.41 to [61 x [61 x i8]]*
  %call16.9.42 = call zeroext i8 (...) @rand()
  store i8 %call16.9.42, i8* %scevgep28.9.41, align 1
  %3926 = load i8, i8* %scevgep28.9.41, align 1
  %conv23.9.42 = zext i8 %3926 to i32
  %3927 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.42 = getelementptr i8, i8* %b, i64 52
  %3928 = load i8, i8* %scevgep34.9.42, align 1
  %call28.9.42 = call zeroext i8 @mult(i8 zeroext %3927, i8 zeroext %3928)
  %conv29.9.42 = zext i8 %call28.9.42 to i32
  %xor.9.42 = xor i32 %conv23.9.42, %conv29.9.42
  %scevgep35.9.42 = getelementptr i8, i8* %a, i64 52
  %3929 = load i8, i8* %scevgep35.9.42, align 1
  %3930 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.42 = call zeroext i8 @mult(i8 zeroext %3929, i8 zeroext %3930)
  %conv35.9.42 = zext i8 %call34.9.42 to i32
  %xor36.9.42 = xor i32 %xor.9.42, %conv35.9.42
  %conv37.9.42 = trunc i32 %xor36.9.42 to i8
  store i8 %conv37.9.42, i8* %scevgep41.9.41, align 1
  %scevgep28.9.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3924, i64 0, i64 0, i64 1
  %3931 = bitcast i8* %scevgep28.9.42 to [61 x [61 x i8]]*
  %scevgep41.9.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3925, i64 0, i64 1, i64 0
  %3932 = bitcast i8* %scevgep41.9.42 to [61 x [61 x i8]]*
  %call16.9.43 = call zeroext i8 (...) @rand()
  store i8 %call16.9.43, i8* %scevgep28.9.42, align 1
  %3933 = load i8, i8* %scevgep28.9.42, align 1
  %conv23.9.43 = zext i8 %3933 to i32
  %3934 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.43 = getelementptr i8, i8* %b, i64 53
  %3935 = load i8, i8* %scevgep34.9.43, align 1
  %call28.9.43 = call zeroext i8 @mult(i8 zeroext %3934, i8 zeroext %3935)
  %conv29.9.43 = zext i8 %call28.9.43 to i32
  %xor.9.43 = xor i32 %conv23.9.43, %conv29.9.43
  %scevgep35.9.43 = getelementptr i8, i8* %a, i64 53
  %3936 = load i8, i8* %scevgep35.9.43, align 1
  %3937 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.43 = call zeroext i8 @mult(i8 zeroext %3936, i8 zeroext %3937)
  %conv35.9.43 = zext i8 %call34.9.43 to i32
  %xor36.9.43 = xor i32 %xor.9.43, %conv35.9.43
  %conv37.9.43 = trunc i32 %xor36.9.43 to i8
  store i8 %conv37.9.43, i8* %scevgep41.9.42, align 1
  %scevgep28.9.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3931, i64 0, i64 0, i64 1
  %3938 = bitcast i8* %scevgep28.9.43 to [61 x [61 x i8]]*
  %scevgep41.9.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3932, i64 0, i64 1, i64 0
  %3939 = bitcast i8* %scevgep41.9.43 to [61 x [61 x i8]]*
  %call16.9.44 = call zeroext i8 (...) @rand()
  store i8 %call16.9.44, i8* %scevgep28.9.43, align 1
  %3940 = load i8, i8* %scevgep28.9.43, align 1
  %conv23.9.44 = zext i8 %3940 to i32
  %3941 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.44 = getelementptr i8, i8* %b, i64 54
  %3942 = load i8, i8* %scevgep34.9.44, align 1
  %call28.9.44 = call zeroext i8 @mult(i8 zeroext %3941, i8 zeroext %3942)
  %conv29.9.44 = zext i8 %call28.9.44 to i32
  %xor.9.44 = xor i32 %conv23.9.44, %conv29.9.44
  %scevgep35.9.44 = getelementptr i8, i8* %a, i64 54
  %3943 = load i8, i8* %scevgep35.9.44, align 1
  %3944 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.44 = call zeroext i8 @mult(i8 zeroext %3943, i8 zeroext %3944)
  %conv35.9.44 = zext i8 %call34.9.44 to i32
  %xor36.9.44 = xor i32 %xor.9.44, %conv35.9.44
  %conv37.9.44 = trunc i32 %xor36.9.44 to i8
  store i8 %conv37.9.44, i8* %scevgep41.9.43, align 1
  %scevgep28.9.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3938, i64 0, i64 0, i64 1
  %3945 = bitcast i8* %scevgep28.9.44 to [61 x [61 x i8]]*
  %scevgep41.9.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3939, i64 0, i64 1, i64 0
  %3946 = bitcast i8* %scevgep41.9.44 to [61 x [61 x i8]]*
  %call16.9.45 = call zeroext i8 (...) @rand()
  store i8 %call16.9.45, i8* %scevgep28.9.44, align 1
  %3947 = load i8, i8* %scevgep28.9.44, align 1
  %conv23.9.45 = zext i8 %3947 to i32
  %3948 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.45 = getelementptr i8, i8* %b, i64 55
  %3949 = load i8, i8* %scevgep34.9.45, align 1
  %call28.9.45 = call zeroext i8 @mult(i8 zeroext %3948, i8 zeroext %3949)
  %conv29.9.45 = zext i8 %call28.9.45 to i32
  %xor.9.45 = xor i32 %conv23.9.45, %conv29.9.45
  %scevgep35.9.45 = getelementptr i8, i8* %a, i64 55
  %3950 = load i8, i8* %scevgep35.9.45, align 1
  %3951 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.45 = call zeroext i8 @mult(i8 zeroext %3950, i8 zeroext %3951)
  %conv35.9.45 = zext i8 %call34.9.45 to i32
  %xor36.9.45 = xor i32 %xor.9.45, %conv35.9.45
  %conv37.9.45 = trunc i32 %xor36.9.45 to i8
  store i8 %conv37.9.45, i8* %scevgep41.9.44, align 1
  %scevgep28.9.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3945, i64 0, i64 0, i64 1
  %3952 = bitcast i8* %scevgep28.9.45 to [61 x [61 x i8]]*
  %scevgep41.9.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3946, i64 0, i64 1, i64 0
  %3953 = bitcast i8* %scevgep41.9.45 to [61 x [61 x i8]]*
  %call16.9.46 = call zeroext i8 (...) @rand()
  store i8 %call16.9.46, i8* %scevgep28.9.45, align 1
  %3954 = load i8, i8* %scevgep28.9.45, align 1
  %conv23.9.46 = zext i8 %3954 to i32
  %3955 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.46 = getelementptr i8, i8* %b, i64 56
  %3956 = load i8, i8* %scevgep34.9.46, align 1
  %call28.9.46 = call zeroext i8 @mult(i8 zeroext %3955, i8 zeroext %3956)
  %conv29.9.46 = zext i8 %call28.9.46 to i32
  %xor.9.46 = xor i32 %conv23.9.46, %conv29.9.46
  %scevgep35.9.46 = getelementptr i8, i8* %a, i64 56
  %3957 = load i8, i8* %scevgep35.9.46, align 1
  %3958 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.46 = call zeroext i8 @mult(i8 zeroext %3957, i8 zeroext %3958)
  %conv35.9.46 = zext i8 %call34.9.46 to i32
  %xor36.9.46 = xor i32 %xor.9.46, %conv35.9.46
  %conv37.9.46 = trunc i32 %xor36.9.46 to i8
  store i8 %conv37.9.46, i8* %scevgep41.9.45, align 1
  %scevgep28.9.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3952, i64 0, i64 0, i64 1
  %3959 = bitcast i8* %scevgep28.9.46 to [61 x [61 x i8]]*
  %scevgep41.9.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3953, i64 0, i64 1, i64 0
  %3960 = bitcast i8* %scevgep41.9.46 to [61 x [61 x i8]]*
  %call16.9.47 = call zeroext i8 (...) @rand()
  store i8 %call16.9.47, i8* %scevgep28.9.46, align 1
  %3961 = load i8, i8* %scevgep28.9.46, align 1
  %conv23.9.47 = zext i8 %3961 to i32
  %3962 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.47 = getelementptr i8, i8* %b, i64 57
  %3963 = load i8, i8* %scevgep34.9.47, align 1
  %call28.9.47 = call zeroext i8 @mult(i8 zeroext %3962, i8 zeroext %3963)
  %conv29.9.47 = zext i8 %call28.9.47 to i32
  %xor.9.47 = xor i32 %conv23.9.47, %conv29.9.47
  %scevgep35.9.47 = getelementptr i8, i8* %a, i64 57
  %3964 = load i8, i8* %scevgep35.9.47, align 1
  %3965 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.47 = call zeroext i8 @mult(i8 zeroext %3964, i8 zeroext %3965)
  %conv35.9.47 = zext i8 %call34.9.47 to i32
  %xor36.9.47 = xor i32 %xor.9.47, %conv35.9.47
  %conv37.9.47 = trunc i32 %xor36.9.47 to i8
  store i8 %conv37.9.47, i8* %scevgep41.9.46, align 1
  %scevgep28.9.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3959, i64 0, i64 0, i64 1
  %3966 = bitcast i8* %scevgep28.9.47 to [61 x [61 x i8]]*
  %scevgep41.9.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3960, i64 0, i64 1, i64 0
  %3967 = bitcast i8* %scevgep41.9.47 to [61 x [61 x i8]]*
  %call16.9.48 = call zeroext i8 (...) @rand()
  store i8 %call16.9.48, i8* %scevgep28.9.47, align 1
  %3968 = load i8, i8* %scevgep28.9.47, align 1
  %conv23.9.48 = zext i8 %3968 to i32
  %3969 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.48 = getelementptr i8, i8* %b, i64 58
  %3970 = load i8, i8* %scevgep34.9.48, align 1
  %call28.9.48 = call zeroext i8 @mult(i8 zeroext %3969, i8 zeroext %3970)
  %conv29.9.48 = zext i8 %call28.9.48 to i32
  %xor.9.48 = xor i32 %conv23.9.48, %conv29.9.48
  %scevgep35.9.48 = getelementptr i8, i8* %a, i64 58
  %3971 = load i8, i8* %scevgep35.9.48, align 1
  %3972 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.48 = call zeroext i8 @mult(i8 zeroext %3971, i8 zeroext %3972)
  %conv35.9.48 = zext i8 %call34.9.48 to i32
  %xor36.9.48 = xor i32 %xor.9.48, %conv35.9.48
  %conv37.9.48 = trunc i32 %xor36.9.48 to i8
  store i8 %conv37.9.48, i8* %scevgep41.9.47, align 1
  %scevgep28.9.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3966, i64 0, i64 0, i64 1
  %3973 = bitcast i8* %scevgep28.9.48 to [61 x [61 x i8]]*
  %scevgep41.9.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3967, i64 0, i64 1, i64 0
  %3974 = bitcast i8* %scevgep41.9.48 to [61 x [61 x i8]]*
  %call16.9.49 = call zeroext i8 (...) @rand()
  store i8 %call16.9.49, i8* %scevgep28.9.48, align 1
  %3975 = load i8, i8* %scevgep28.9.48, align 1
  %conv23.9.49 = zext i8 %3975 to i32
  %3976 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.49 = getelementptr i8, i8* %b, i64 59
  %3977 = load i8, i8* %scevgep34.9.49, align 1
  %call28.9.49 = call zeroext i8 @mult(i8 zeroext %3976, i8 zeroext %3977)
  %conv29.9.49 = zext i8 %call28.9.49 to i32
  %xor.9.49 = xor i32 %conv23.9.49, %conv29.9.49
  %scevgep35.9.49 = getelementptr i8, i8* %a, i64 59
  %3978 = load i8, i8* %scevgep35.9.49, align 1
  %3979 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.49 = call zeroext i8 @mult(i8 zeroext %3978, i8 zeroext %3979)
  %conv35.9.49 = zext i8 %call34.9.49 to i32
  %xor36.9.49 = xor i32 %xor.9.49, %conv35.9.49
  %conv37.9.49 = trunc i32 %xor36.9.49 to i8
  store i8 %conv37.9.49, i8* %scevgep41.9.48, align 1
  %scevgep28.9.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3973, i64 0, i64 0, i64 1
  %scevgep41.9.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3974, i64 0, i64 1, i64 0
  %call16.9.50 = call zeroext i8 (...) @rand()
  store i8 %call16.9.50, i8* %scevgep28.9.49, align 1
  %3980 = load i8, i8* %scevgep28.9.49, align 1
  %conv23.9.50 = zext i8 %3980 to i32
  %3981 = load i8, i8* %arrayidx25.9, align 1
  %scevgep34.9.50 = getelementptr i8, i8* %b, i64 60
  %3982 = load i8, i8* %scevgep34.9.50, align 1
  %call28.9.50 = call zeroext i8 @mult(i8 zeroext %3981, i8 zeroext %3982)
  %conv29.9.50 = zext i8 %call28.9.50 to i32
  %xor.9.50 = xor i32 %conv23.9.50, %conv29.9.50
  %scevgep35.9.50 = getelementptr i8, i8* %a, i64 60
  %3983 = load i8, i8* %scevgep35.9.50, align 1
  %3984 = load i8, i8* %arrayidx33.9, align 1
  %call34.9.50 = call zeroext i8 @mult(i8 zeroext %3983, i8 zeroext %3984)
  %conv35.9.50 = zext i8 %call34.9.50 to i32
  %xor36.9.50 = xor i32 %xor.9.50, %conv35.9.50
  %conv37.9.50 = trunc i32 %xor36.9.50 to i8
  store i8 %conv37.9.50, i8* %scevgep41.9.49, align 1
  %scevgep26.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3630, i64 0, i64 1, i64 1
  %3985 = bitcast i8* %scevgep26.9 to [61 x [61 x i8]]*
  %scevgep39.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3631, i64 0, i64 1, i64 1
  %3986 = bitcast i8* %scevgep39.9 to [61 x [61 x i8]]*
  %arrayidx25.10 = getelementptr inbounds i8, i8* %a, i64 10
  %arrayidx33.10 = getelementptr inbounds i8, i8* %b, i64 10
  %call16.10 = call zeroext i8 (...) @rand()
  store i8 %call16.10, i8* %scevgep26.9, align 1
  %3987 = load i8, i8* %scevgep26.9, align 1
  %conv23.10 = zext i8 %3987 to i32
  %3988 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10 = getelementptr i8, i8* %b, i64 11
  %3989 = load i8, i8* %scevgep34.10, align 1
  %call28.10 = call zeroext i8 @mult(i8 zeroext %3988, i8 zeroext %3989)
  %conv29.10 = zext i8 %call28.10 to i32
  %xor.10 = xor i32 %conv23.10, %conv29.10
  %scevgep35.10 = getelementptr i8, i8* %a, i64 11
  %3990 = load i8, i8* %scevgep35.10, align 1
  %3991 = load i8, i8* %arrayidx33.10, align 1
  %call34.10 = call zeroext i8 @mult(i8 zeroext %3990, i8 zeroext %3991)
  %conv35.10 = zext i8 %call34.10 to i32
  %xor36.10 = xor i32 %xor.10, %conv35.10
  %conv37.10 = trunc i32 %xor36.10 to i8
  store i8 %conv37.10, i8* %scevgep39.9, align 1
  %scevgep28.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3985, i64 0, i64 0, i64 1
  %3992 = bitcast i8* %scevgep28.10 to [61 x [61 x i8]]*
  %scevgep41.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3986, i64 0, i64 1, i64 0
  %3993 = bitcast i8* %scevgep41.10 to [61 x [61 x i8]]*
  %call16.10.1 = call zeroext i8 (...) @rand()
  store i8 %call16.10.1, i8* %scevgep28.10, align 1
  %3994 = load i8, i8* %scevgep28.10, align 1
  %conv23.10.1 = zext i8 %3994 to i32
  %3995 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.1 = getelementptr i8, i8* %b, i64 12
  %3996 = load i8, i8* %scevgep34.10.1, align 1
  %call28.10.1 = call zeroext i8 @mult(i8 zeroext %3995, i8 zeroext %3996)
  %conv29.10.1 = zext i8 %call28.10.1 to i32
  %xor.10.1 = xor i32 %conv23.10.1, %conv29.10.1
  %scevgep35.10.1 = getelementptr i8, i8* %a, i64 12
  %3997 = load i8, i8* %scevgep35.10.1, align 1
  %3998 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.1 = call zeroext i8 @mult(i8 zeroext %3997, i8 zeroext %3998)
  %conv35.10.1 = zext i8 %call34.10.1 to i32
  %xor36.10.1 = xor i32 %xor.10.1, %conv35.10.1
  %conv37.10.1 = trunc i32 %xor36.10.1 to i8
  store i8 %conv37.10.1, i8* %scevgep41.10, align 1
  %scevgep28.10.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3992, i64 0, i64 0, i64 1
  %3999 = bitcast i8* %scevgep28.10.1 to [61 x [61 x i8]]*
  %scevgep41.10.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3993, i64 0, i64 1, i64 0
  %4000 = bitcast i8* %scevgep41.10.1 to [61 x [61 x i8]]*
  %call16.10.2 = call zeroext i8 (...) @rand()
  store i8 %call16.10.2, i8* %scevgep28.10.1, align 1
  %4001 = load i8, i8* %scevgep28.10.1, align 1
  %conv23.10.2 = zext i8 %4001 to i32
  %4002 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.2 = getelementptr i8, i8* %b, i64 13
  %4003 = load i8, i8* %scevgep34.10.2, align 1
  %call28.10.2 = call zeroext i8 @mult(i8 zeroext %4002, i8 zeroext %4003)
  %conv29.10.2 = zext i8 %call28.10.2 to i32
  %xor.10.2 = xor i32 %conv23.10.2, %conv29.10.2
  %scevgep35.10.2 = getelementptr i8, i8* %a, i64 13
  %4004 = load i8, i8* %scevgep35.10.2, align 1
  %4005 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.2 = call zeroext i8 @mult(i8 zeroext %4004, i8 zeroext %4005)
  %conv35.10.2 = zext i8 %call34.10.2 to i32
  %xor36.10.2 = xor i32 %xor.10.2, %conv35.10.2
  %conv37.10.2 = trunc i32 %xor36.10.2 to i8
  store i8 %conv37.10.2, i8* %scevgep41.10.1, align 1
  %scevgep28.10.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3999, i64 0, i64 0, i64 1
  %4006 = bitcast i8* %scevgep28.10.2 to [61 x [61 x i8]]*
  %scevgep41.10.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4000, i64 0, i64 1, i64 0
  %4007 = bitcast i8* %scevgep41.10.2 to [61 x [61 x i8]]*
  %call16.10.3 = call zeroext i8 (...) @rand()
  store i8 %call16.10.3, i8* %scevgep28.10.2, align 1
  %4008 = load i8, i8* %scevgep28.10.2, align 1
  %conv23.10.3 = zext i8 %4008 to i32
  %4009 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.3 = getelementptr i8, i8* %b, i64 14
  %4010 = load i8, i8* %scevgep34.10.3, align 1
  %call28.10.3 = call zeroext i8 @mult(i8 zeroext %4009, i8 zeroext %4010)
  %conv29.10.3 = zext i8 %call28.10.3 to i32
  %xor.10.3 = xor i32 %conv23.10.3, %conv29.10.3
  %scevgep35.10.3 = getelementptr i8, i8* %a, i64 14
  %4011 = load i8, i8* %scevgep35.10.3, align 1
  %4012 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.3 = call zeroext i8 @mult(i8 zeroext %4011, i8 zeroext %4012)
  %conv35.10.3 = zext i8 %call34.10.3 to i32
  %xor36.10.3 = xor i32 %xor.10.3, %conv35.10.3
  %conv37.10.3 = trunc i32 %xor36.10.3 to i8
  store i8 %conv37.10.3, i8* %scevgep41.10.2, align 1
  %scevgep28.10.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4006, i64 0, i64 0, i64 1
  %4013 = bitcast i8* %scevgep28.10.3 to [61 x [61 x i8]]*
  %scevgep41.10.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4007, i64 0, i64 1, i64 0
  %4014 = bitcast i8* %scevgep41.10.3 to [61 x [61 x i8]]*
  %call16.10.4 = call zeroext i8 (...) @rand()
  store i8 %call16.10.4, i8* %scevgep28.10.3, align 1
  %4015 = load i8, i8* %scevgep28.10.3, align 1
  %conv23.10.4 = zext i8 %4015 to i32
  %4016 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.4 = getelementptr i8, i8* %b, i64 15
  %4017 = load i8, i8* %scevgep34.10.4, align 1
  %call28.10.4 = call zeroext i8 @mult(i8 zeroext %4016, i8 zeroext %4017)
  %conv29.10.4 = zext i8 %call28.10.4 to i32
  %xor.10.4 = xor i32 %conv23.10.4, %conv29.10.4
  %scevgep35.10.4 = getelementptr i8, i8* %a, i64 15
  %4018 = load i8, i8* %scevgep35.10.4, align 1
  %4019 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.4 = call zeroext i8 @mult(i8 zeroext %4018, i8 zeroext %4019)
  %conv35.10.4 = zext i8 %call34.10.4 to i32
  %xor36.10.4 = xor i32 %xor.10.4, %conv35.10.4
  %conv37.10.4 = trunc i32 %xor36.10.4 to i8
  store i8 %conv37.10.4, i8* %scevgep41.10.3, align 1
  %scevgep28.10.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4013, i64 0, i64 0, i64 1
  %4020 = bitcast i8* %scevgep28.10.4 to [61 x [61 x i8]]*
  %scevgep41.10.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4014, i64 0, i64 1, i64 0
  %4021 = bitcast i8* %scevgep41.10.4 to [61 x [61 x i8]]*
  %call16.10.5 = call zeroext i8 (...) @rand()
  store i8 %call16.10.5, i8* %scevgep28.10.4, align 1
  %4022 = load i8, i8* %scevgep28.10.4, align 1
  %conv23.10.5 = zext i8 %4022 to i32
  %4023 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.5 = getelementptr i8, i8* %b, i64 16
  %4024 = load i8, i8* %scevgep34.10.5, align 1
  %call28.10.5 = call zeroext i8 @mult(i8 zeroext %4023, i8 zeroext %4024)
  %conv29.10.5 = zext i8 %call28.10.5 to i32
  %xor.10.5 = xor i32 %conv23.10.5, %conv29.10.5
  %scevgep35.10.5 = getelementptr i8, i8* %a, i64 16
  %4025 = load i8, i8* %scevgep35.10.5, align 1
  %4026 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.5 = call zeroext i8 @mult(i8 zeroext %4025, i8 zeroext %4026)
  %conv35.10.5 = zext i8 %call34.10.5 to i32
  %xor36.10.5 = xor i32 %xor.10.5, %conv35.10.5
  %conv37.10.5 = trunc i32 %xor36.10.5 to i8
  store i8 %conv37.10.5, i8* %scevgep41.10.4, align 1
  %scevgep28.10.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4020, i64 0, i64 0, i64 1
  %4027 = bitcast i8* %scevgep28.10.5 to [61 x [61 x i8]]*
  %scevgep41.10.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4021, i64 0, i64 1, i64 0
  %4028 = bitcast i8* %scevgep41.10.5 to [61 x [61 x i8]]*
  %call16.10.6 = call zeroext i8 (...) @rand()
  store i8 %call16.10.6, i8* %scevgep28.10.5, align 1
  %4029 = load i8, i8* %scevgep28.10.5, align 1
  %conv23.10.6 = zext i8 %4029 to i32
  %4030 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.6 = getelementptr i8, i8* %b, i64 17
  %4031 = load i8, i8* %scevgep34.10.6, align 1
  %call28.10.6 = call zeroext i8 @mult(i8 zeroext %4030, i8 zeroext %4031)
  %conv29.10.6 = zext i8 %call28.10.6 to i32
  %xor.10.6 = xor i32 %conv23.10.6, %conv29.10.6
  %scevgep35.10.6 = getelementptr i8, i8* %a, i64 17
  %4032 = load i8, i8* %scevgep35.10.6, align 1
  %4033 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.6 = call zeroext i8 @mult(i8 zeroext %4032, i8 zeroext %4033)
  %conv35.10.6 = zext i8 %call34.10.6 to i32
  %xor36.10.6 = xor i32 %xor.10.6, %conv35.10.6
  %conv37.10.6 = trunc i32 %xor36.10.6 to i8
  store i8 %conv37.10.6, i8* %scevgep41.10.5, align 1
  %scevgep28.10.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4027, i64 0, i64 0, i64 1
  %4034 = bitcast i8* %scevgep28.10.6 to [61 x [61 x i8]]*
  %scevgep41.10.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4028, i64 0, i64 1, i64 0
  %4035 = bitcast i8* %scevgep41.10.6 to [61 x [61 x i8]]*
  %call16.10.7 = call zeroext i8 (...) @rand()
  store i8 %call16.10.7, i8* %scevgep28.10.6, align 1
  %4036 = load i8, i8* %scevgep28.10.6, align 1
  %conv23.10.7 = zext i8 %4036 to i32
  %4037 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.7 = getelementptr i8, i8* %b, i64 18
  %4038 = load i8, i8* %scevgep34.10.7, align 1
  %call28.10.7 = call zeroext i8 @mult(i8 zeroext %4037, i8 zeroext %4038)
  %conv29.10.7 = zext i8 %call28.10.7 to i32
  %xor.10.7 = xor i32 %conv23.10.7, %conv29.10.7
  %scevgep35.10.7 = getelementptr i8, i8* %a, i64 18
  %4039 = load i8, i8* %scevgep35.10.7, align 1
  %4040 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.7 = call zeroext i8 @mult(i8 zeroext %4039, i8 zeroext %4040)
  %conv35.10.7 = zext i8 %call34.10.7 to i32
  %xor36.10.7 = xor i32 %xor.10.7, %conv35.10.7
  %conv37.10.7 = trunc i32 %xor36.10.7 to i8
  store i8 %conv37.10.7, i8* %scevgep41.10.6, align 1
  %scevgep28.10.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4034, i64 0, i64 0, i64 1
  %4041 = bitcast i8* %scevgep28.10.7 to [61 x [61 x i8]]*
  %scevgep41.10.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4035, i64 0, i64 1, i64 0
  %4042 = bitcast i8* %scevgep41.10.7 to [61 x [61 x i8]]*
  %call16.10.8 = call zeroext i8 (...) @rand()
  store i8 %call16.10.8, i8* %scevgep28.10.7, align 1
  %4043 = load i8, i8* %scevgep28.10.7, align 1
  %conv23.10.8 = zext i8 %4043 to i32
  %4044 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.8 = getelementptr i8, i8* %b, i64 19
  %4045 = load i8, i8* %scevgep34.10.8, align 1
  %call28.10.8 = call zeroext i8 @mult(i8 zeroext %4044, i8 zeroext %4045)
  %conv29.10.8 = zext i8 %call28.10.8 to i32
  %xor.10.8 = xor i32 %conv23.10.8, %conv29.10.8
  %scevgep35.10.8 = getelementptr i8, i8* %a, i64 19
  %4046 = load i8, i8* %scevgep35.10.8, align 1
  %4047 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.8 = call zeroext i8 @mult(i8 zeroext %4046, i8 zeroext %4047)
  %conv35.10.8 = zext i8 %call34.10.8 to i32
  %xor36.10.8 = xor i32 %xor.10.8, %conv35.10.8
  %conv37.10.8 = trunc i32 %xor36.10.8 to i8
  store i8 %conv37.10.8, i8* %scevgep41.10.7, align 1
  %scevgep28.10.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4041, i64 0, i64 0, i64 1
  %4048 = bitcast i8* %scevgep28.10.8 to [61 x [61 x i8]]*
  %scevgep41.10.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4042, i64 0, i64 1, i64 0
  %4049 = bitcast i8* %scevgep41.10.8 to [61 x [61 x i8]]*
  %call16.10.9 = call zeroext i8 (...) @rand()
  store i8 %call16.10.9, i8* %scevgep28.10.8, align 1
  %4050 = load i8, i8* %scevgep28.10.8, align 1
  %conv23.10.9 = zext i8 %4050 to i32
  %4051 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.9 = getelementptr i8, i8* %b, i64 20
  %4052 = load i8, i8* %scevgep34.10.9, align 1
  %call28.10.9 = call zeroext i8 @mult(i8 zeroext %4051, i8 zeroext %4052)
  %conv29.10.9 = zext i8 %call28.10.9 to i32
  %xor.10.9 = xor i32 %conv23.10.9, %conv29.10.9
  %scevgep35.10.9 = getelementptr i8, i8* %a, i64 20
  %4053 = load i8, i8* %scevgep35.10.9, align 1
  %4054 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.9 = call zeroext i8 @mult(i8 zeroext %4053, i8 zeroext %4054)
  %conv35.10.9 = zext i8 %call34.10.9 to i32
  %xor36.10.9 = xor i32 %xor.10.9, %conv35.10.9
  %conv37.10.9 = trunc i32 %xor36.10.9 to i8
  store i8 %conv37.10.9, i8* %scevgep41.10.8, align 1
  %scevgep28.10.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4048, i64 0, i64 0, i64 1
  %4055 = bitcast i8* %scevgep28.10.9 to [61 x [61 x i8]]*
  %scevgep41.10.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4049, i64 0, i64 1, i64 0
  %4056 = bitcast i8* %scevgep41.10.9 to [61 x [61 x i8]]*
  %call16.10.10 = call zeroext i8 (...) @rand()
  store i8 %call16.10.10, i8* %scevgep28.10.9, align 1
  %4057 = load i8, i8* %scevgep28.10.9, align 1
  %conv23.10.10 = zext i8 %4057 to i32
  %4058 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.10 = getelementptr i8, i8* %b, i64 21
  %4059 = load i8, i8* %scevgep34.10.10, align 1
  %call28.10.10 = call zeroext i8 @mult(i8 zeroext %4058, i8 zeroext %4059)
  %conv29.10.10 = zext i8 %call28.10.10 to i32
  %xor.10.10 = xor i32 %conv23.10.10, %conv29.10.10
  %scevgep35.10.10 = getelementptr i8, i8* %a, i64 21
  %4060 = load i8, i8* %scevgep35.10.10, align 1
  %4061 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.10 = call zeroext i8 @mult(i8 zeroext %4060, i8 zeroext %4061)
  %conv35.10.10 = zext i8 %call34.10.10 to i32
  %xor36.10.10 = xor i32 %xor.10.10, %conv35.10.10
  %conv37.10.10 = trunc i32 %xor36.10.10 to i8
  store i8 %conv37.10.10, i8* %scevgep41.10.9, align 1
  %scevgep28.10.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4055, i64 0, i64 0, i64 1
  %4062 = bitcast i8* %scevgep28.10.10 to [61 x [61 x i8]]*
  %scevgep41.10.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4056, i64 0, i64 1, i64 0
  %4063 = bitcast i8* %scevgep41.10.10 to [61 x [61 x i8]]*
  %call16.10.11 = call zeroext i8 (...) @rand()
  store i8 %call16.10.11, i8* %scevgep28.10.10, align 1
  %4064 = load i8, i8* %scevgep28.10.10, align 1
  %conv23.10.11 = zext i8 %4064 to i32
  %4065 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.11 = getelementptr i8, i8* %b, i64 22
  %4066 = load i8, i8* %scevgep34.10.11, align 1
  %call28.10.11 = call zeroext i8 @mult(i8 zeroext %4065, i8 zeroext %4066)
  %conv29.10.11 = zext i8 %call28.10.11 to i32
  %xor.10.11 = xor i32 %conv23.10.11, %conv29.10.11
  %scevgep35.10.11 = getelementptr i8, i8* %a, i64 22
  %4067 = load i8, i8* %scevgep35.10.11, align 1
  %4068 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.11 = call zeroext i8 @mult(i8 zeroext %4067, i8 zeroext %4068)
  %conv35.10.11 = zext i8 %call34.10.11 to i32
  %xor36.10.11 = xor i32 %xor.10.11, %conv35.10.11
  %conv37.10.11 = trunc i32 %xor36.10.11 to i8
  store i8 %conv37.10.11, i8* %scevgep41.10.10, align 1
  %scevgep28.10.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4062, i64 0, i64 0, i64 1
  %4069 = bitcast i8* %scevgep28.10.11 to [61 x [61 x i8]]*
  %scevgep41.10.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4063, i64 0, i64 1, i64 0
  %4070 = bitcast i8* %scevgep41.10.11 to [61 x [61 x i8]]*
  %call16.10.12 = call zeroext i8 (...) @rand()
  store i8 %call16.10.12, i8* %scevgep28.10.11, align 1
  %4071 = load i8, i8* %scevgep28.10.11, align 1
  %conv23.10.12 = zext i8 %4071 to i32
  %4072 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.12 = getelementptr i8, i8* %b, i64 23
  %4073 = load i8, i8* %scevgep34.10.12, align 1
  %call28.10.12 = call zeroext i8 @mult(i8 zeroext %4072, i8 zeroext %4073)
  %conv29.10.12 = zext i8 %call28.10.12 to i32
  %xor.10.12 = xor i32 %conv23.10.12, %conv29.10.12
  %scevgep35.10.12 = getelementptr i8, i8* %a, i64 23
  %4074 = load i8, i8* %scevgep35.10.12, align 1
  %4075 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.12 = call zeroext i8 @mult(i8 zeroext %4074, i8 zeroext %4075)
  %conv35.10.12 = zext i8 %call34.10.12 to i32
  %xor36.10.12 = xor i32 %xor.10.12, %conv35.10.12
  %conv37.10.12 = trunc i32 %xor36.10.12 to i8
  store i8 %conv37.10.12, i8* %scevgep41.10.11, align 1
  %scevgep28.10.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4069, i64 0, i64 0, i64 1
  %4076 = bitcast i8* %scevgep28.10.12 to [61 x [61 x i8]]*
  %scevgep41.10.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4070, i64 0, i64 1, i64 0
  %4077 = bitcast i8* %scevgep41.10.12 to [61 x [61 x i8]]*
  %call16.10.13 = call zeroext i8 (...) @rand()
  store i8 %call16.10.13, i8* %scevgep28.10.12, align 1
  %4078 = load i8, i8* %scevgep28.10.12, align 1
  %conv23.10.13 = zext i8 %4078 to i32
  %4079 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.13 = getelementptr i8, i8* %b, i64 24
  %4080 = load i8, i8* %scevgep34.10.13, align 1
  %call28.10.13 = call zeroext i8 @mult(i8 zeroext %4079, i8 zeroext %4080)
  %conv29.10.13 = zext i8 %call28.10.13 to i32
  %xor.10.13 = xor i32 %conv23.10.13, %conv29.10.13
  %scevgep35.10.13 = getelementptr i8, i8* %a, i64 24
  %4081 = load i8, i8* %scevgep35.10.13, align 1
  %4082 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.13 = call zeroext i8 @mult(i8 zeroext %4081, i8 zeroext %4082)
  %conv35.10.13 = zext i8 %call34.10.13 to i32
  %xor36.10.13 = xor i32 %xor.10.13, %conv35.10.13
  %conv37.10.13 = trunc i32 %xor36.10.13 to i8
  store i8 %conv37.10.13, i8* %scevgep41.10.12, align 1
  %scevgep28.10.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4076, i64 0, i64 0, i64 1
  %4083 = bitcast i8* %scevgep28.10.13 to [61 x [61 x i8]]*
  %scevgep41.10.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4077, i64 0, i64 1, i64 0
  %4084 = bitcast i8* %scevgep41.10.13 to [61 x [61 x i8]]*
  %call16.10.14 = call zeroext i8 (...) @rand()
  store i8 %call16.10.14, i8* %scevgep28.10.13, align 1
  %4085 = load i8, i8* %scevgep28.10.13, align 1
  %conv23.10.14 = zext i8 %4085 to i32
  %4086 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.14 = getelementptr i8, i8* %b, i64 25
  %4087 = load i8, i8* %scevgep34.10.14, align 1
  %call28.10.14 = call zeroext i8 @mult(i8 zeroext %4086, i8 zeroext %4087)
  %conv29.10.14 = zext i8 %call28.10.14 to i32
  %xor.10.14 = xor i32 %conv23.10.14, %conv29.10.14
  %scevgep35.10.14 = getelementptr i8, i8* %a, i64 25
  %4088 = load i8, i8* %scevgep35.10.14, align 1
  %4089 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.14 = call zeroext i8 @mult(i8 zeroext %4088, i8 zeroext %4089)
  %conv35.10.14 = zext i8 %call34.10.14 to i32
  %xor36.10.14 = xor i32 %xor.10.14, %conv35.10.14
  %conv37.10.14 = trunc i32 %xor36.10.14 to i8
  store i8 %conv37.10.14, i8* %scevgep41.10.13, align 1
  %scevgep28.10.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4083, i64 0, i64 0, i64 1
  %4090 = bitcast i8* %scevgep28.10.14 to [61 x [61 x i8]]*
  %scevgep41.10.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4084, i64 0, i64 1, i64 0
  %4091 = bitcast i8* %scevgep41.10.14 to [61 x [61 x i8]]*
  %call16.10.15 = call zeroext i8 (...) @rand()
  store i8 %call16.10.15, i8* %scevgep28.10.14, align 1
  %4092 = load i8, i8* %scevgep28.10.14, align 1
  %conv23.10.15 = zext i8 %4092 to i32
  %4093 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.15 = getelementptr i8, i8* %b, i64 26
  %4094 = load i8, i8* %scevgep34.10.15, align 1
  %call28.10.15 = call zeroext i8 @mult(i8 zeroext %4093, i8 zeroext %4094)
  %conv29.10.15 = zext i8 %call28.10.15 to i32
  %xor.10.15 = xor i32 %conv23.10.15, %conv29.10.15
  %scevgep35.10.15 = getelementptr i8, i8* %a, i64 26
  %4095 = load i8, i8* %scevgep35.10.15, align 1
  %4096 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.15 = call zeroext i8 @mult(i8 zeroext %4095, i8 zeroext %4096)
  %conv35.10.15 = zext i8 %call34.10.15 to i32
  %xor36.10.15 = xor i32 %xor.10.15, %conv35.10.15
  %conv37.10.15 = trunc i32 %xor36.10.15 to i8
  store i8 %conv37.10.15, i8* %scevgep41.10.14, align 1
  %scevgep28.10.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4090, i64 0, i64 0, i64 1
  %4097 = bitcast i8* %scevgep28.10.15 to [61 x [61 x i8]]*
  %scevgep41.10.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4091, i64 0, i64 1, i64 0
  %4098 = bitcast i8* %scevgep41.10.15 to [61 x [61 x i8]]*
  %call16.10.16 = call zeroext i8 (...) @rand()
  store i8 %call16.10.16, i8* %scevgep28.10.15, align 1
  %4099 = load i8, i8* %scevgep28.10.15, align 1
  %conv23.10.16 = zext i8 %4099 to i32
  %4100 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.16 = getelementptr i8, i8* %b, i64 27
  %4101 = load i8, i8* %scevgep34.10.16, align 1
  %call28.10.16 = call zeroext i8 @mult(i8 zeroext %4100, i8 zeroext %4101)
  %conv29.10.16 = zext i8 %call28.10.16 to i32
  %xor.10.16 = xor i32 %conv23.10.16, %conv29.10.16
  %scevgep35.10.16 = getelementptr i8, i8* %a, i64 27
  %4102 = load i8, i8* %scevgep35.10.16, align 1
  %4103 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.16 = call zeroext i8 @mult(i8 zeroext %4102, i8 zeroext %4103)
  %conv35.10.16 = zext i8 %call34.10.16 to i32
  %xor36.10.16 = xor i32 %xor.10.16, %conv35.10.16
  %conv37.10.16 = trunc i32 %xor36.10.16 to i8
  store i8 %conv37.10.16, i8* %scevgep41.10.15, align 1
  %scevgep28.10.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4097, i64 0, i64 0, i64 1
  %4104 = bitcast i8* %scevgep28.10.16 to [61 x [61 x i8]]*
  %scevgep41.10.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4098, i64 0, i64 1, i64 0
  %4105 = bitcast i8* %scevgep41.10.16 to [61 x [61 x i8]]*
  %call16.10.17 = call zeroext i8 (...) @rand()
  store i8 %call16.10.17, i8* %scevgep28.10.16, align 1
  %4106 = load i8, i8* %scevgep28.10.16, align 1
  %conv23.10.17 = zext i8 %4106 to i32
  %4107 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.17 = getelementptr i8, i8* %b, i64 28
  %4108 = load i8, i8* %scevgep34.10.17, align 1
  %call28.10.17 = call zeroext i8 @mult(i8 zeroext %4107, i8 zeroext %4108)
  %conv29.10.17 = zext i8 %call28.10.17 to i32
  %xor.10.17 = xor i32 %conv23.10.17, %conv29.10.17
  %scevgep35.10.17 = getelementptr i8, i8* %a, i64 28
  %4109 = load i8, i8* %scevgep35.10.17, align 1
  %4110 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.17 = call zeroext i8 @mult(i8 zeroext %4109, i8 zeroext %4110)
  %conv35.10.17 = zext i8 %call34.10.17 to i32
  %xor36.10.17 = xor i32 %xor.10.17, %conv35.10.17
  %conv37.10.17 = trunc i32 %xor36.10.17 to i8
  store i8 %conv37.10.17, i8* %scevgep41.10.16, align 1
  %scevgep28.10.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4104, i64 0, i64 0, i64 1
  %4111 = bitcast i8* %scevgep28.10.17 to [61 x [61 x i8]]*
  %scevgep41.10.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4105, i64 0, i64 1, i64 0
  %4112 = bitcast i8* %scevgep41.10.17 to [61 x [61 x i8]]*
  %call16.10.18 = call zeroext i8 (...) @rand()
  store i8 %call16.10.18, i8* %scevgep28.10.17, align 1
  %4113 = load i8, i8* %scevgep28.10.17, align 1
  %conv23.10.18 = zext i8 %4113 to i32
  %4114 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.18 = getelementptr i8, i8* %b, i64 29
  %4115 = load i8, i8* %scevgep34.10.18, align 1
  %call28.10.18 = call zeroext i8 @mult(i8 zeroext %4114, i8 zeroext %4115)
  %conv29.10.18 = zext i8 %call28.10.18 to i32
  %xor.10.18 = xor i32 %conv23.10.18, %conv29.10.18
  %scevgep35.10.18 = getelementptr i8, i8* %a, i64 29
  %4116 = load i8, i8* %scevgep35.10.18, align 1
  %4117 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.18 = call zeroext i8 @mult(i8 zeroext %4116, i8 zeroext %4117)
  %conv35.10.18 = zext i8 %call34.10.18 to i32
  %xor36.10.18 = xor i32 %xor.10.18, %conv35.10.18
  %conv37.10.18 = trunc i32 %xor36.10.18 to i8
  store i8 %conv37.10.18, i8* %scevgep41.10.17, align 1
  %scevgep28.10.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4111, i64 0, i64 0, i64 1
  %4118 = bitcast i8* %scevgep28.10.18 to [61 x [61 x i8]]*
  %scevgep41.10.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4112, i64 0, i64 1, i64 0
  %4119 = bitcast i8* %scevgep41.10.18 to [61 x [61 x i8]]*
  %call16.10.19 = call zeroext i8 (...) @rand()
  store i8 %call16.10.19, i8* %scevgep28.10.18, align 1
  %4120 = load i8, i8* %scevgep28.10.18, align 1
  %conv23.10.19 = zext i8 %4120 to i32
  %4121 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.19 = getelementptr i8, i8* %b, i64 30
  %4122 = load i8, i8* %scevgep34.10.19, align 1
  %call28.10.19 = call zeroext i8 @mult(i8 zeroext %4121, i8 zeroext %4122)
  %conv29.10.19 = zext i8 %call28.10.19 to i32
  %xor.10.19 = xor i32 %conv23.10.19, %conv29.10.19
  %scevgep35.10.19 = getelementptr i8, i8* %a, i64 30
  %4123 = load i8, i8* %scevgep35.10.19, align 1
  %4124 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.19 = call zeroext i8 @mult(i8 zeroext %4123, i8 zeroext %4124)
  %conv35.10.19 = zext i8 %call34.10.19 to i32
  %xor36.10.19 = xor i32 %xor.10.19, %conv35.10.19
  %conv37.10.19 = trunc i32 %xor36.10.19 to i8
  store i8 %conv37.10.19, i8* %scevgep41.10.18, align 1
  %scevgep28.10.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4118, i64 0, i64 0, i64 1
  %4125 = bitcast i8* %scevgep28.10.19 to [61 x [61 x i8]]*
  %scevgep41.10.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4119, i64 0, i64 1, i64 0
  %4126 = bitcast i8* %scevgep41.10.19 to [61 x [61 x i8]]*
  %call16.10.20 = call zeroext i8 (...) @rand()
  store i8 %call16.10.20, i8* %scevgep28.10.19, align 1
  %4127 = load i8, i8* %scevgep28.10.19, align 1
  %conv23.10.20 = zext i8 %4127 to i32
  %4128 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.20 = getelementptr i8, i8* %b, i64 31
  %4129 = load i8, i8* %scevgep34.10.20, align 1
  %call28.10.20 = call zeroext i8 @mult(i8 zeroext %4128, i8 zeroext %4129)
  %conv29.10.20 = zext i8 %call28.10.20 to i32
  %xor.10.20 = xor i32 %conv23.10.20, %conv29.10.20
  %scevgep35.10.20 = getelementptr i8, i8* %a, i64 31
  %4130 = load i8, i8* %scevgep35.10.20, align 1
  %4131 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.20 = call zeroext i8 @mult(i8 zeroext %4130, i8 zeroext %4131)
  %conv35.10.20 = zext i8 %call34.10.20 to i32
  %xor36.10.20 = xor i32 %xor.10.20, %conv35.10.20
  %conv37.10.20 = trunc i32 %xor36.10.20 to i8
  store i8 %conv37.10.20, i8* %scevgep41.10.19, align 1
  %scevgep28.10.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4125, i64 0, i64 0, i64 1
  %4132 = bitcast i8* %scevgep28.10.20 to [61 x [61 x i8]]*
  %scevgep41.10.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4126, i64 0, i64 1, i64 0
  %4133 = bitcast i8* %scevgep41.10.20 to [61 x [61 x i8]]*
  %call16.10.21 = call zeroext i8 (...) @rand()
  store i8 %call16.10.21, i8* %scevgep28.10.20, align 1
  %4134 = load i8, i8* %scevgep28.10.20, align 1
  %conv23.10.21 = zext i8 %4134 to i32
  %4135 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.21 = getelementptr i8, i8* %b, i64 32
  %4136 = load i8, i8* %scevgep34.10.21, align 1
  %call28.10.21 = call zeroext i8 @mult(i8 zeroext %4135, i8 zeroext %4136)
  %conv29.10.21 = zext i8 %call28.10.21 to i32
  %xor.10.21 = xor i32 %conv23.10.21, %conv29.10.21
  %scevgep35.10.21 = getelementptr i8, i8* %a, i64 32
  %4137 = load i8, i8* %scevgep35.10.21, align 1
  %4138 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.21 = call zeroext i8 @mult(i8 zeroext %4137, i8 zeroext %4138)
  %conv35.10.21 = zext i8 %call34.10.21 to i32
  %xor36.10.21 = xor i32 %xor.10.21, %conv35.10.21
  %conv37.10.21 = trunc i32 %xor36.10.21 to i8
  store i8 %conv37.10.21, i8* %scevgep41.10.20, align 1
  %scevgep28.10.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4132, i64 0, i64 0, i64 1
  %4139 = bitcast i8* %scevgep28.10.21 to [61 x [61 x i8]]*
  %scevgep41.10.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4133, i64 0, i64 1, i64 0
  %4140 = bitcast i8* %scevgep41.10.21 to [61 x [61 x i8]]*
  %call16.10.22 = call zeroext i8 (...) @rand()
  store i8 %call16.10.22, i8* %scevgep28.10.21, align 1
  %4141 = load i8, i8* %scevgep28.10.21, align 1
  %conv23.10.22 = zext i8 %4141 to i32
  %4142 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.22 = getelementptr i8, i8* %b, i64 33
  %4143 = load i8, i8* %scevgep34.10.22, align 1
  %call28.10.22 = call zeroext i8 @mult(i8 zeroext %4142, i8 zeroext %4143)
  %conv29.10.22 = zext i8 %call28.10.22 to i32
  %xor.10.22 = xor i32 %conv23.10.22, %conv29.10.22
  %scevgep35.10.22 = getelementptr i8, i8* %a, i64 33
  %4144 = load i8, i8* %scevgep35.10.22, align 1
  %4145 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.22 = call zeroext i8 @mult(i8 zeroext %4144, i8 zeroext %4145)
  %conv35.10.22 = zext i8 %call34.10.22 to i32
  %xor36.10.22 = xor i32 %xor.10.22, %conv35.10.22
  %conv37.10.22 = trunc i32 %xor36.10.22 to i8
  store i8 %conv37.10.22, i8* %scevgep41.10.21, align 1
  %scevgep28.10.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4139, i64 0, i64 0, i64 1
  %4146 = bitcast i8* %scevgep28.10.22 to [61 x [61 x i8]]*
  %scevgep41.10.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4140, i64 0, i64 1, i64 0
  %4147 = bitcast i8* %scevgep41.10.22 to [61 x [61 x i8]]*
  %call16.10.23 = call zeroext i8 (...) @rand()
  store i8 %call16.10.23, i8* %scevgep28.10.22, align 1
  %4148 = load i8, i8* %scevgep28.10.22, align 1
  %conv23.10.23 = zext i8 %4148 to i32
  %4149 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.23 = getelementptr i8, i8* %b, i64 34
  %4150 = load i8, i8* %scevgep34.10.23, align 1
  %call28.10.23 = call zeroext i8 @mult(i8 zeroext %4149, i8 zeroext %4150)
  %conv29.10.23 = zext i8 %call28.10.23 to i32
  %xor.10.23 = xor i32 %conv23.10.23, %conv29.10.23
  %scevgep35.10.23 = getelementptr i8, i8* %a, i64 34
  %4151 = load i8, i8* %scevgep35.10.23, align 1
  %4152 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.23 = call zeroext i8 @mult(i8 zeroext %4151, i8 zeroext %4152)
  %conv35.10.23 = zext i8 %call34.10.23 to i32
  %xor36.10.23 = xor i32 %xor.10.23, %conv35.10.23
  %conv37.10.23 = trunc i32 %xor36.10.23 to i8
  store i8 %conv37.10.23, i8* %scevgep41.10.22, align 1
  %scevgep28.10.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4146, i64 0, i64 0, i64 1
  %4153 = bitcast i8* %scevgep28.10.23 to [61 x [61 x i8]]*
  %scevgep41.10.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4147, i64 0, i64 1, i64 0
  %4154 = bitcast i8* %scevgep41.10.23 to [61 x [61 x i8]]*
  %call16.10.24 = call zeroext i8 (...) @rand()
  store i8 %call16.10.24, i8* %scevgep28.10.23, align 1
  %4155 = load i8, i8* %scevgep28.10.23, align 1
  %conv23.10.24 = zext i8 %4155 to i32
  %4156 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.24 = getelementptr i8, i8* %b, i64 35
  %4157 = load i8, i8* %scevgep34.10.24, align 1
  %call28.10.24 = call zeroext i8 @mult(i8 zeroext %4156, i8 zeroext %4157)
  %conv29.10.24 = zext i8 %call28.10.24 to i32
  %xor.10.24 = xor i32 %conv23.10.24, %conv29.10.24
  %scevgep35.10.24 = getelementptr i8, i8* %a, i64 35
  %4158 = load i8, i8* %scevgep35.10.24, align 1
  %4159 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.24 = call zeroext i8 @mult(i8 zeroext %4158, i8 zeroext %4159)
  %conv35.10.24 = zext i8 %call34.10.24 to i32
  %xor36.10.24 = xor i32 %xor.10.24, %conv35.10.24
  %conv37.10.24 = trunc i32 %xor36.10.24 to i8
  store i8 %conv37.10.24, i8* %scevgep41.10.23, align 1
  %scevgep28.10.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4153, i64 0, i64 0, i64 1
  %4160 = bitcast i8* %scevgep28.10.24 to [61 x [61 x i8]]*
  %scevgep41.10.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4154, i64 0, i64 1, i64 0
  %4161 = bitcast i8* %scevgep41.10.24 to [61 x [61 x i8]]*
  %call16.10.25 = call zeroext i8 (...) @rand()
  store i8 %call16.10.25, i8* %scevgep28.10.24, align 1
  %4162 = load i8, i8* %scevgep28.10.24, align 1
  %conv23.10.25 = zext i8 %4162 to i32
  %4163 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.25 = getelementptr i8, i8* %b, i64 36
  %4164 = load i8, i8* %scevgep34.10.25, align 1
  %call28.10.25 = call zeroext i8 @mult(i8 zeroext %4163, i8 zeroext %4164)
  %conv29.10.25 = zext i8 %call28.10.25 to i32
  %xor.10.25 = xor i32 %conv23.10.25, %conv29.10.25
  %scevgep35.10.25 = getelementptr i8, i8* %a, i64 36
  %4165 = load i8, i8* %scevgep35.10.25, align 1
  %4166 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.25 = call zeroext i8 @mult(i8 zeroext %4165, i8 zeroext %4166)
  %conv35.10.25 = zext i8 %call34.10.25 to i32
  %xor36.10.25 = xor i32 %xor.10.25, %conv35.10.25
  %conv37.10.25 = trunc i32 %xor36.10.25 to i8
  store i8 %conv37.10.25, i8* %scevgep41.10.24, align 1
  %scevgep28.10.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4160, i64 0, i64 0, i64 1
  %4167 = bitcast i8* %scevgep28.10.25 to [61 x [61 x i8]]*
  %scevgep41.10.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4161, i64 0, i64 1, i64 0
  %4168 = bitcast i8* %scevgep41.10.25 to [61 x [61 x i8]]*
  %call16.10.26 = call zeroext i8 (...) @rand()
  store i8 %call16.10.26, i8* %scevgep28.10.25, align 1
  %4169 = load i8, i8* %scevgep28.10.25, align 1
  %conv23.10.26 = zext i8 %4169 to i32
  %4170 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.26 = getelementptr i8, i8* %b, i64 37
  %4171 = load i8, i8* %scevgep34.10.26, align 1
  %call28.10.26 = call zeroext i8 @mult(i8 zeroext %4170, i8 zeroext %4171)
  %conv29.10.26 = zext i8 %call28.10.26 to i32
  %xor.10.26 = xor i32 %conv23.10.26, %conv29.10.26
  %scevgep35.10.26 = getelementptr i8, i8* %a, i64 37
  %4172 = load i8, i8* %scevgep35.10.26, align 1
  %4173 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.26 = call zeroext i8 @mult(i8 zeroext %4172, i8 zeroext %4173)
  %conv35.10.26 = zext i8 %call34.10.26 to i32
  %xor36.10.26 = xor i32 %xor.10.26, %conv35.10.26
  %conv37.10.26 = trunc i32 %xor36.10.26 to i8
  store i8 %conv37.10.26, i8* %scevgep41.10.25, align 1
  %scevgep28.10.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4167, i64 0, i64 0, i64 1
  %4174 = bitcast i8* %scevgep28.10.26 to [61 x [61 x i8]]*
  %scevgep41.10.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4168, i64 0, i64 1, i64 0
  %4175 = bitcast i8* %scevgep41.10.26 to [61 x [61 x i8]]*
  %call16.10.27 = call zeroext i8 (...) @rand()
  store i8 %call16.10.27, i8* %scevgep28.10.26, align 1
  %4176 = load i8, i8* %scevgep28.10.26, align 1
  %conv23.10.27 = zext i8 %4176 to i32
  %4177 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.27 = getelementptr i8, i8* %b, i64 38
  %4178 = load i8, i8* %scevgep34.10.27, align 1
  %call28.10.27 = call zeroext i8 @mult(i8 zeroext %4177, i8 zeroext %4178)
  %conv29.10.27 = zext i8 %call28.10.27 to i32
  %xor.10.27 = xor i32 %conv23.10.27, %conv29.10.27
  %scevgep35.10.27 = getelementptr i8, i8* %a, i64 38
  %4179 = load i8, i8* %scevgep35.10.27, align 1
  %4180 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.27 = call zeroext i8 @mult(i8 zeroext %4179, i8 zeroext %4180)
  %conv35.10.27 = zext i8 %call34.10.27 to i32
  %xor36.10.27 = xor i32 %xor.10.27, %conv35.10.27
  %conv37.10.27 = trunc i32 %xor36.10.27 to i8
  store i8 %conv37.10.27, i8* %scevgep41.10.26, align 1
  %scevgep28.10.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4174, i64 0, i64 0, i64 1
  %4181 = bitcast i8* %scevgep28.10.27 to [61 x [61 x i8]]*
  %scevgep41.10.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4175, i64 0, i64 1, i64 0
  %4182 = bitcast i8* %scevgep41.10.27 to [61 x [61 x i8]]*
  %call16.10.28 = call zeroext i8 (...) @rand()
  store i8 %call16.10.28, i8* %scevgep28.10.27, align 1
  %4183 = load i8, i8* %scevgep28.10.27, align 1
  %conv23.10.28 = zext i8 %4183 to i32
  %4184 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.28 = getelementptr i8, i8* %b, i64 39
  %4185 = load i8, i8* %scevgep34.10.28, align 1
  %call28.10.28 = call zeroext i8 @mult(i8 zeroext %4184, i8 zeroext %4185)
  %conv29.10.28 = zext i8 %call28.10.28 to i32
  %xor.10.28 = xor i32 %conv23.10.28, %conv29.10.28
  %scevgep35.10.28 = getelementptr i8, i8* %a, i64 39
  %4186 = load i8, i8* %scevgep35.10.28, align 1
  %4187 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.28 = call zeroext i8 @mult(i8 zeroext %4186, i8 zeroext %4187)
  %conv35.10.28 = zext i8 %call34.10.28 to i32
  %xor36.10.28 = xor i32 %xor.10.28, %conv35.10.28
  %conv37.10.28 = trunc i32 %xor36.10.28 to i8
  store i8 %conv37.10.28, i8* %scevgep41.10.27, align 1
  %scevgep28.10.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4181, i64 0, i64 0, i64 1
  %4188 = bitcast i8* %scevgep28.10.28 to [61 x [61 x i8]]*
  %scevgep41.10.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4182, i64 0, i64 1, i64 0
  %4189 = bitcast i8* %scevgep41.10.28 to [61 x [61 x i8]]*
  %call16.10.29 = call zeroext i8 (...) @rand()
  store i8 %call16.10.29, i8* %scevgep28.10.28, align 1
  %4190 = load i8, i8* %scevgep28.10.28, align 1
  %conv23.10.29 = zext i8 %4190 to i32
  %4191 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.29 = getelementptr i8, i8* %b, i64 40
  %4192 = load i8, i8* %scevgep34.10.29, align 1
  %call28.10.29 = call zeroext i8 @mult(i8 zeroext %4191, i8 zeroext %4192)
  %conv29.10.29 = zext i8 %call28.10.29 to i32
  %xor.10.29 = xor i32 %conv23.10.29, %conv29.10.29
  %scevgep35.10.29 = getelementptr i8, i8* %a, i64 40
  %4193 = load i8, i8* %scevgep35.10.29, align 1
  %4194 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.29 = call zeroext i8 @mult(i8 zeroext %4193, i8 zeroext %4194)
  %conv35.10.29 = zext i8 %call34.10.29 to i32
  %xor36.10.29 = xor i32 %xor.10.29, %conv35.10.29
  %conv37.10.29 = trunc i32 %xor36.10.29 to i8
  store i8 %conv37.10.29, i8* %scevgep41.10.28, align 1
  %scevgep28.10.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4188, i64 0, i64 0, i64 1
  %4195 = bitcast i8* %scevgep28.10.29 to [61 x [61 x i8]]*
  %scevgep41.10.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4189, i64 0, i64 1, i64 0
  %4196 = bitcast i8* %scevgep41.10.29 to [61 x [61 x i8]]*
  %call16.10.30 = call zeroext i8 (...) @rand()
  store i8 %call16.10.30, i8* %scevgep28.10.29, align 1
  %4197 = load i8, i8* %scevgep28.10.29, align 1
  %conv23.10.30 = zext i8 %4197 to i32
  %4198 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.30 = getelementptr i8, i8* %b, i64 41
  %4199 = load i8, i8* %scevgep34.10.30, align 1
  %call28.10.30 = call zeroext i8 @mult(i8 zeroext %4198, i8 zeroext %4199)
  %conv29.10.30 = zext i8 %call28.10.30 to i32
  %xor.10.30 = xor i32 %conv23.10.30, %conv29.10.30
  %scevgep35.10.30 = getelementptr i8, i8* %a, i64 41
  %4200 = load i8, i8* %scevgep35.10.30, align 1
  %4201 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.30 = call zeroext i8 @mult(i8 zeroext %4200, i8 zeroext %4201)
  %conv35.10.30 = zext i8 %call34.10.30 to i32
  %xor36.10.30 = xor i32 %xor.10.30, %conv35.10.30
  %conv37.10.30 = trunc i32 %xor36.10.30 to i8
  store i8 %conv37.10.30, i8* %scevgep41.10.29, align 1
  %scevgep28.10.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4195, i64 0, i64 0, i64 1
  %4202 = bitcast i8* %scevgep28.10.30 to [61 x [61 x i8]]*
  %scevgep41.10.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4196, i64 0, i64 1, i64 0
  %4203 = bitcast i8* %scevgep41.10.30 to [61 x [61 x i8]]*
  %call16.10.31 = call zeroext i8 (...) @rand()
  store i8 %call16.10.31, i8* %scevgep28.10.30, align 1
  %4204 = load i8, i8* %scevgep28.10.30, align 1
  %conv23.10.31 = zext i8 %4204 to i32
  %4205 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.31 = getelementptr i8, i8* %b, i64 42
  %4206 = load i8, i8* %scevgep34.10.31, align 1
  %call28.10.31 = call zeroext i8 @mult(i8 zeroext %4205, i8 zeroext %4206)
  %conv29.10.31 = zext i8 %call28.10.31 to i32
  %xor.10.31 = xor i32 %conv23.10.31, %conv29.10.31
  %scevgep35.10.31 = getelementptr i8, i8* %a, i64 42
  %4207 = load i8, i8* %scevgep35.10.31, align 1
  %4208 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.31 = call zeroext i8 @mult(i8 zeroext %4207, i8 zeroext %4208)
  %conv35.10.31 = zext i8 %call34.10.31 to i32
  %xor36.10.31 = xor i32 %xor.10.31, %conv35.10.31
  %conv37.10.31 = trunc i32 %xor36.10.31 to i8
  store i8 %conv37.10.31, i8* %scevgep41.10.30, align 1
  %scevgep28.10.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4202, i64 0, i64 0, i64 1
  %4209 = bitcast i8* %scevgep28.10.31 to [61 x [61 x i8]]*
  %scevgep41.10.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4203, i64 0, i64 1, i64 0
  %4210 = bitcast i8* %scevgep41.10.31 to [61 x [61 x i8]]*
  %call16.10.32 = call zeroext i8 (...) @rand()
  store i8 %call16.10.32, i8* %scevgep28.10.31, align 1
  %4211 = load i8, i8* %scevgep28.10.31, align 1
  %conv23.10.32 = zext i8 %4211 to i32
  %4212 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.32 = getelementptr i8, i8* %b, i64 43
  %4213 = load i8, i8* %scevgep34.10.32, align 1
  %call28.10.32 = call zeroext i8 @mult(i8 zeroext %4212, i8 zeroext %4213)
  %conv29.10.32 = zext i8 %call28.10.32 to i32
  %xor.10.32 = xor i32 %conv23.10.32, %conv29.10.32
  %scevgep35.10.32 = getelementptr i8, i8* %a, i64 43
  %4214 = load i8, i8* %scevgep35.10.32, align 1
  %4215 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.32 = call zeroext i8 @mult(i8 zeroext %4214, i8 zeroext %4215)
  %conv35.10.32 = zext i8 %call34.10.32 to i32
  %xor36.10.32 = xor i32 %xor.10.32, %conv35.10.32
  %conv37.10.32 = trunc i32 %xor36.10.32 to i8
  store i8 %conv37.10.32, i8* %scevgep41.10.31, align 1
  %scevgep28.10.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4209, i64 0, i64 0, i64 1
  %4216 = bitcast i8* %scevgep28.10.32 to [61 x [61 x i8]]*
  %scevgep41.10.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4210, i64 0, i64 1, i64 0
  %4217 = bitcast i8* %scevgep41.10.32 to [61 x [61 x i8]]*
  %call16.10.33 = call zeroext i8 (...) @rand()
  store i8 %call16.10.33, i8* %scevgep28.10.32, align 1
  %4218 = load i8, i8* %scevgep28.10.32, align 1
  %conv23.10.33 = zext i8 %4218 to i32
  %4219 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.33 = getelementptr i8, i8* %b, i64 44
  %4220 = load i8, i8* %scevgep34.10.33, align 1
  %call28.10.33 = call zeroext i8 @mult(i8 zeroext %4219, i8 zeroext %4220)
  %conv29.10.33 = zext i8 %call28.10.33 to i32
  %xor.10.33 = xor i32 %conv23.10.33, %conv29.10.33
  %scevgep35.10.33 = getelementptr i8, i8* %a, i64 44
  %4221 = load i8, i8* %scevgep35.10.33, align 1
  %4222 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.33 = call zeroext i8 @mult(i8 zeroext %4221, i8 zeroext %4222)
  %conv35.10.33 = zext i8 %call34.10.33 to i32
  %xor36.10.33 = xor i32 %xor.10.33, %conv35.10.33
  %conv37.10.33 = trunc i32 %xor36.10.33 to i8
  store i8 %conv37.10.33, i8* %scevgep41.10.32, align 1
  %scevgep28.10.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4216, i64 0, i64 0, i64 1
  %4223 = bitcast i8* %scevgep28.10.33 to [61 x [61 x i8]]*
  %scevgep41.10.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4217, i64 0, i64 1, i64 0
  %4224 = bitcast i8* %scevgep41.10.33 to [61 x [61 x i8]]*
  %call16.10.34 = call zeroext i8 (...) @rand()
  store i8 %call16.10.34, i8* %scevgep28.10.33, align 1
  %4225 = load i8, i8* %scevgep28.10.33, align 1
  %conv23.10.34 = zext i8 %4225 to i32
  %4226 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.34 = getelementptr i8, i8* %b, i64 45
  %4227 = load i8, i8* %scevgep34.10.34, align 1
  %call28.10.34 = call zeroext i8 @mult(i8 zeroext %4226, i8 zeroext %4227)
  %conv29.10.34 = zext i8 %call28.10.34 to i32
  %xor.10.34 = xor i32 %conv23.10.34, %conv29.10.34
  %scevgep35.10.34 = getelementptr i8, i8* %a, i64 45
  %4228 = load i8, i8* %scevgep35.10.34, align 1
  %4229 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.34 = call zeroext i8 @mult(i8 zeroext %4228, i8 zeroext %4229)
  %conv35.10.34 = zext i8 %call34.10.34 to i32
  %xor36.10.34 = xor i32 %xor.10.34, %conv35.10.34
  %conv37.10.34 = trunc i32 %xor36.10.34 to i8
  store i8 %conv37.10.34, i8* %scevgep41.10.33, align 1
  %scevgep28.10.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4223, i64 0, i64 0, i64 1
  %4230 = bitcast i8* %scevgep28.10.34 to [61 x [61 x i8]]*
  %scevgep41.10.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4224, i64 0, i64 1, i64 0
  %4231 = bitcast i8* %scevgep41.10.34 to [61 x [61 x i8]]*
  %call16.10.35 = call zeroext i8 (...) @rand()
  store i8 %call16.10.35, i8* %scevgep28.10.34, align 1
  %4232 = load i8, i8* %scevgep28.10.34, align 1
  %conv23.10.35 = zext i8 %4232 to i32
  %4233 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.35 = getelementptr i8, i8* %b, i64 46
  %4234 = load i8, i8* %scevgep34.10.35, align 1
  %call28.10.35 = call zeroext i8 @mult(i8 zeroext %4233, i8 zeroext %4234)
  %conv29.10.35 = zext i8 %call28.10.35 to i32
  %xor.10.35 = xor i32 %conv23.10.35, %conv29.10.35
  %scevgep35.10.35 = getelementptr i8, i8* %a, i64 46
  %4235 = load i8, i8* %scevgep35.10.35, align 1
  %4236 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.35 = call zeroext i8 @mult(i8 zeroext %4235, i8 zeroext %4236)
  %conv35.10.35 = zext i8 %call34.10.35 to i32
  %xor36.10.35 = xor i32 %xor.10.35, %conv35.10.35
  %conv37.10.35 = trunc i32 %xor36.10.35 to i8
  store i8 %conv37.10.35, i8* %scevgep41.10.34, align 1
  %scevgep28.10.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4230, i64 0, i64 0, i64 1
  %4237 = bitcast i8* %scevgep28.10.35 to [61 x [61 x i8]]*
  %scevgep41.10.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4231, i64 0, i64 1, i64 0
  %4238 = bitcast i8* %scevgep41.10.35 to [61 x [61 x i8]]*
  %call16.10.36 = call zeroext i8 (...) @rand()
  store i8 %call16.10.36, i8* %scevgep28.10.35, align 1
  %4239 = load i8, i8* %scevgep28.10.35, align 1
  %conv23.10.36 = zext i8 %4239 to i32
  %4240 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.36 = getelementptr i8, i8* %b, i64 47
  %4241 = load i8, i8* %scevgep34.10.36, align 1
  %call28.10.36 = call zeroext i8 @mult(i8 zeroext %4240, i8 zeroext %4241)
  %conv29.10.36 = zext i8 %call28.10.36 to i32
  %xor.10.36 = xor i32 %conv23.10.36, %conv29.10.36
  %scevgep35.10.36 = getelementptr i8, i8* %a, i64 47
  %4242 = load i8, i8* %scevgep35.10.36, align 1
  %4243 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.36 = call zeroext i8 @mult(i8 zeroext %4242, i8 zeroext %4243)
  %conv35.10.36 = zext i8 %call34.10.36 to i32
  %xor36.10.36 = xor i32 %xor.10.36, %conv35.10.36
  %conv37.10.36 = trunc i32 %xor36.10.36 to i8
  store i8 %conv37.10.36, i8* %scevgep41.10.35, align 1
  %scevgep28.10.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4237, i64 0, i64 0, i64 1
  %4244 = bitcast i8* %scevgep28.10.36 to [61 x [61 x i8]]*
  %scevgep41.10.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4238, i64 0, i64 1, i64 0
  %4245 = bitcast i8* %scevgep41.10.36 to [61 x [61 x i8]]*
  %call16.10.37 = call zeroext i8 (...) @rand()
  store i8 %call16.10.37, i8* %scevgep28.10.36, align 1
  %4246 = load i8, i8* %scevgep28.10.36, align 1
  %conv23.10.37 = zext i8 %4246 to i32
  %4247 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.37 = getelementptr i8, i8* %b, i64 48
  %4248 = load i8, i8* %scevgep34.10.37, align 1
  %call28.10.37 = call zeroext i8 @mult(i8 zeroext %4247, i8 zeroext %4248)
  %conv29.10.37 = zext i8 %call28.10.37 to i32
  %xor.10.37 = xor i32 %conv23.10.37, %conv29.10.37
  %scevgep35.10.37 = getelementptr i8, i8* %a, i64 48
  %4249 = load i8, i8* %scevgep35.10.37, align 1
  %4250 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.37 = call zeroext i8 @mult(i8 zeroext %4249, i8 zeroext %4250)
  %conv35.10.37 = zext i8 %call34.10.37 to i32
  %xor36.10.37 = xor i32 %xor.10.37, %conv35.10.37
  %conv37.10.37 = trunc i32 %xor36.10.37 to i8
  store i8 %conv37.10.37, i8* %scevgep41.10.36, align 1
  %scevgep28.10.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4244, i64 0, i64 0, i64 1
  %4251 = bitcast i8* %scevgep28.10.37 to [61 x [61 x i8]]*
  %scevgep41.10.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4245, i64 0, i64 1, i64 0
  %4252 = bitcast i8* %scevgep41.10.37 to [61 x [61 x i8]]*
  %call16.10.38 = call zeroext i8 (...) @rand()
  store i8 %call16.10.38, i8* %scevgep28.10.37, align 1
  %4253 = load i8, i8* %scevgep28.10.37, align 1
  %conv23.10.38 = zext i8 %4253 to i32
  %4254 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.38 = getelementptr i8, i8* %b, i64 49
  %4255 = load i8, i8* %scevgep34.10.38, align 1
  %call28.10.38 = call zeroext i8 @mult(i8 zeroext %4254, i8 zeroext %4255)
  %conv29.10.38 = zext i8 %call28.10.38 to i32
  %xor.10.38 = xor i32 %conv23.10.38, %conv29.10.38
  %scevgep35.10.38 = getelementptr i8, i8* %a, i64 49
  %4256 = load i8, i8* %scevgep35.10.38, align 1
  %4257 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.38 = call zeroext i8 @mult(i8 zeroext %4256, i8 zeroext %4257)
  %conv35.10.38 = zext i8 %call34.10.38 to i32
  %xor36.10.38 = xor i32 %xor.10.38, %conv35.10.38
  %conv37.10.38 = trunc i32 %xor36.10.38 to i8
  store i8 %conv37.10.38, i8* %scevgep41.10.37, align 1
  %scevgep28.10.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4251, i64 0, i64 0, i64 1
  %4258 = bitcast i8* %scevgep28.10.38 to [61 x [61 x i8]]*
  %scevgep41.10.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4252, i64 0, i64 1, i64 0
  %4259 = bitcast i8* %scevgep41.10.38 to [61 x [61 x i8]]*
  %call16.10.39 = call zeroext i8 (...) @rand()
  store i8 %call16.10.39, i8* %scevgep28.10.38, align 1
  %4260 = load i8, i8* %scevgep28.10.38, align 1
  %conv23.10.39 = zext i8 %4260 to i32
  %4261 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.39 = getelementptr i8, i8* %b, i64 50
  %4262 = load i8, i8* %scevgep34.10.39, align 1
  %call28.10.39 = call zeroext i8 @mult(i8 zeroext %4261, i8 zeroext %4262)
  %conv29.10.39 = zext i8 %call28.10.39 to i32
  %xor.10.39 = xor i32 %conv23.10.39, %conv29.10.39
  %scevgep35.10.39 = getelementptr i8, i8* %a, i64 50
  %4263 = load i8, i8* %scevgep35.10.39, align 1
  %4264 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.39 = call zeroext i8 @mult(i8 zeroext %4263, i8 zeroext %4264)
  %conv35.10.39 = zext i8 %call34.10.39 to i32
  %xor36.10.39 = xor i32 %xor.10.39, %conv35.10.39
  %conv37.10.39 = trunc i32 %xor36.10.39 to i8
  store i8 %conv37.10.39, i8* %scevgep41.10.38, align 1
  %scevgep28.10.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4258, i64 0, i64 0, i64 1
  %4265 = bitcast i8* %scevgep28.10.39 to [61 x [61 x i8]]*
  %scevgep41.10.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4259, i64 0, i64 1, i64 0
  %4266 = bitcast i8* %scevgep41.10.39 to [61 x [61 x i8]]*
  %call16.10.40 = call zeroext i8 (...) @rand()
  store i8 %call16.10.40, i8* %scevgep28.10.39, align 1
  %4267 = load i8, i8* %scevgep28.10.39, align 1
  %conv23.10.40 = zext i8 %4267 to i32
  %4268 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.40 = getelementptr i8, i8* %b, i64 51
  %4269 = load i8, i8* %scevgep34.10.40, align 1
  %call28.10.40 = call zeroext i8 @mult(i8 zeroext %4268, i8 zeroext %4269)
  %conv29.10.40 = zext i8 %call28.10.40 to i32
  %xor.10.40 = xor i32 %conv23.10.40, %conv29.10.40
  %scevgep35.10.40 = getelementptr i8, i8* %a, i64 51
  %4270 = load i8, i8* %scevgep35.10.40, align 1
  %4271 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.40 = call zeroext i8 @mult(i8 zeroext %4270, i8 zeroext %4271)
  %conv35.10.40 = zext i8 %call34.10.40 to i32
  %xor36.10.40 = xor i32 %xor.10.40, %conv35.10.40
  %conv37.10.40 = trunc i32 %xor36.10.40 to i8
  store i8 %conv37.10.40, i8* %scevgep41.10.39, align 1
  %scevgep28.10.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4265, i64 0, i64 0, i64 1
  %4272 = bitcast i8* %scevgep28.10.40 to [61 x [61 x i8]]*
  %scevgep41.10.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4266, i64 0, i64 1, i64 0
  %4273 = bitcast i8* %scevgep41.10.40 to [61 x [61 x i8]]*
  %call16.10.41 = call zeroext i8 (...) @rand()
  store i8 %call16.10.41, i8* %scevgep28.10.40, align 1
  %4274 = load i8, i8* %scevgep28.10.40, align 1
  %conv23.10.41 = zext i8 %4274 to i32
  %4275 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.41 = getelementptr i8, i8* %b, i64 52
  %4276 = load i8, i8* %scevgep34.10.41, align 1
  %call28.10.41 = call zeroext i8 @mult(i8 zeroext %4275, i8 zeroext %4276)
  %conv29.10.41 = zext i8 %call28.10.41 to i32
  %xor.10.41 = xor i32 %conv23.10.41, %conv29.10.41
  %scevgep35.10.41 = getelementptr i8, i8* %a, i64 52
  %4277 = load i8, i8* %scevgep35.10.41, align 1
  %4278 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.41 = call zeroext i8 @mult(i8 zeroext %4277, i8 zeroext %4278)
  %conv35.10.41 = zext i8 %call34.10.41 to i32
  %xor36.10.41 = xor i32 %xor.10.41, %conv35.10.41
  %conv37.10.41 = trunc i32 %xor36.10.41 to i8
  store i8 %conv37.10.41, i8* %scevgep41.10.40, align 1
  %scevgep28.10.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4272, i64 0, i64 0, i64 1
  %4279 = bitcast i8* %scevgep28.10.41 to [61 x [61 x i8]]*
  %scevgep41.10.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4273, i64 0, i64 1, i64 0
  %4280 = bitcast i8* %scevgep41.10.41 to [61 x [61 x i8]]*
  %call16.10.42 = call zeroext i8 (...) @rand()
  store i8 %call16.10.42, i8* %scevgep28.10.41, align 1
  %4281 = load i8, i8* %scevgep28.10.41, align 1
  %conv23.10.42 = zext i8 %4281 to i32
  %4282 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.42 = getelementptr i8, i8* %b, i64 53
  %4283 = load i8, i8* %scevgep34.10.42, align 1
  %call28.10.42 = call zeroext i8 @mult(i8 zeroext %4282, i8 zeroext %4283)
  %conv29.10.42 = zext i8 %call28.10.42 to i32
  %xor.10.42 = xor i32 %conv23.10.42, %conv29.10.42
  %scevgep35.10.42 = getelementptr i8, i8* %a, i64 53
  %4284 = load i8, i8* %scevgep35.10.42, align 1
  %4285 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.42 = call zeroext i8 @mult(i8 zeroext %4284, i8 zeroext %4285)
  %conv35.10.42 = zext i8 %call34.10.42 to i32
  %xor36.10.42 = xor i32 %xor.10.42, %conv35.10.42
  %conv37.10.42 = trunc i32 %xor36.10.42 to i8
  store i8 %conv37.10.42, i8* %scevgep41.10.41, align 1
  %scevgep28.10.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4279, i64 0, i64 0, i64 1
  %4286 = bitcast i8* %scevgep28.10.42 to [61 x [61 x i8]]*
  %scevgep41.10.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4280, i64 0, i64 1, i64 0
  %4287 = bitcast i8* %scevgep41.10.42 to [61 x [61 x i8]]*
  %call16.10.43 = call zeroext i8 (...) @rand()
  store i8 %call16.10.43, i8* %scevgep28.10.42, align 1
  %4288 = load i8, i8* %scevgep28.10.42, align 1
  %conv23.10.43 = zext i8 %4288 to i32
  %4289 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.43 = getelementptr i8, i8* %b, i64 54
  %4290 = load i8, i8* %scevgep34.10.43, align 1
  %call28.10.43 = call zeroext i8 @mult(i8 zeroext %4289, i8 zeroext %4290)
  %conv29.10.43 = zext i8 %call28.10.43 to i32
  %xor.10.43 = xor i32 %conv23.10.43, %conv29.10.43
  %scevgep35.10.43 = getelementptr i8, i8* %a, i64 54
  %4291 = load i8, i8* %scevgep35.10.43, align 1
  %4292 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.43 = call zeroext i8 @mult(i8 zeroext %4291, i8 zeroext %4292)
  %conv35.10.43 = zext i8 %call34.10.43 to i32
  %xor36.10.43 = xor i32 %xor.10.43, %conv35.10.43
  %conv37.10.43 = trunc i32 %xor36.10.43 to i8
  store i8 %conv37.10.43, i8* %scevgep41.10.42, align 1
  %scevgep28.10.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4286, i64 0, i64 0, i64 1
  %4293 = bitcast i8* %scevgep28.10.43 to [61 x [61 x i8]]*
  %scevgep41.10.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4287, i64 0, i64 1, i64 0
  %4294 = bitcast i8* %scevgep41.10.43 to [61 x [61 x i8]]*
  %call16.10.44 = call zeroext i8 (...) @rand()
  store i8 %call16.10.44, i8* %scevgep28.10.43, align 1
  %4295 = load i8, i8* %scevgep28.10.43, align 1
  %conv23.10.44 = zext i8 %4295 to i32
  %4296 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.44 = getelementptr i8, i8* %b, i64 55
  %4297 = load i8, i8* %scevgep34.10.44, align 1
  %call28.10.44 = call zeroext i8 @mult(i8 zeroext %4296, i8 zeroext %4297)
  %conv29.10.44 = zext i8 %call28.10.44 to i32
  %xor.10.44 = xor i32 %conv23.10.44, %conv29.10.44
  %scevgep35.10.44 = getelementptr i8, i8* %a, i64 55
  %4298 = load i8, i8* %scevgep35.10.44, align 1
  %4299 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.44 = call zeroext i8 @mult(i8 zeroext %4298, i8 zeroext %4299)
  %conv35.10.44 = zext i8 %call34.10.44 to i32
  %xor36.10.44 = xor i32 %xor.10.44, %conv35.10.44
  %conv37.10.44 = trunc i32 %xor36.10.44 to i8
  store i8 %conv37.10.44, i8* %scevgep41.10.43, align 1
  %scevgep28.10.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4293, i64 0, i64 0, i64 1
  %4300 = bitcast i8* %scevgep28.10.44 to [61 x [61 x i8]]*
  %scevgep41.10.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4294, i64 0, i64 1, i64 0
  %4301 = bitcast i8* %scevgep41.10.44 to [61 x [61 x i8]]*
  %call16.10.45 = call zeroext i8 (...) @rand()
  store i8 %call16.10.45, i8* %scevgep28.10.44, align 1
  %4302 = load i8, i8* %scevgep28.10.44, align 1
  %conv23.10.45 = zext i8 %4302 to i32
  %4303 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.45 = getelementptr i8, i8* %b, i64 56
  %4304 = load i8, i8* %scevgep34.10.45, align 1
  %call28.10.45 = call zeroext i8 @mult(i8 zeroext %4303, i8 zeroext %4304)
  %conv29.10.45 = zext i8 %call28.10.45 to i32
  %xor.10.45 = xor i32 %conv23.10.45, %conv29.10.45
  %scevgep35.10.45 = getelementptr i8, i8* %a, i64 56
  %4305 = load i8, i8* %scevgep35.10.45, align 1
  %4306 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.45 = call zeroext i8 @mult(i8 zeroext %4305, i8 zeroext %4306)
  %conv35.10.45 = zext i8 %call34.10.45 to i32
  %xor36.10.45 = xor i32 %xor.10.45, %conv35.10.45
  %conv37.10.45 = trunc i32 %xor36.10.45 to i8
  store i8 %conv37.10.45, i8* %scevgep41.10.44, align 1
  %scevgep28.10.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4300, i64 0, i64 0, i64 1
  %4307 = bitcast i8* %scevgep28.10.45 to [61 x [61 x i8]]*
  %scevgep41.10.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4301, i64 0, i64 1, i64 0
  %4308 = bitcast i8* %scevgep41.10.45 to [61 x [61 x i8]]*
  %call16.10.46 = call zeroext i8 (...) @rand()
  store i8 %call16.10.46, i8* %scevgep28.10.45, align 1
  %4309 = load i8, i8* %scevgep28.10.45, align 1
  %conv23.10.46 = zext i8 %4309 to i32
  %4310 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.46 = getelementptr i8, i8* %b, i64 57
  %4311 = load i8, i8* %scevgep34.10.46, align 1
  %call28.10.46 = call zeroext i8 @mult(i8 zeroext %4310, i8 zeroext %4311)
  %conv29.10.46 = zext i8 %call28.10.46 to i32
  %xor.10.46 = xor i32 %conv23.10.46, %conv29.10.46
  %scevgep35.10.46 = getelementptr i8, i8* %a, i64 57
  %4312 = load i8, i8* %scevgep35.10.46, align 1
  %4313 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.46 = call zeroext i8 @mult(i8 zeroext %4312, i8 zeroext %4313)
  %conv35.10.46 = zext i8 %call34.10.46 to i32
  %xor36.10.46 = xor i32 %xor.10.46, %conv35.10.46
  %conv37.10.46 = trunc i32 %xor36.10.46 to i8
  store i8 %conv37.10.46, i8* %scevgep41.10.45, align 1
  %scevgep28.10.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4307, i64 0, i64 0, i64 1
  %4314 = bitcast i8* %scevgep28.10.46 to [61 x [61 x i8]]*
  %scevgep41.10.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4308, i64 0, i64 1, i64 0
  %4315 = bitcast i8* %scevgep41.10.46 to [61 x [61 x i8]]*
  %call16.10.47 = call zeroext i8 (...) @rand()
  store i8 %call16.10.47, i8* %scevgep28.10.46, align 1
  %4316 = load i8, i8* %scevgep28.10.46, align 1
  %conv23.10.47 = zext i8 %4316 to i32
  %4317 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.47 = getelementptr i8, i8* %b, i64 58
  %4318 = load i8, i8* %scevgep34.10.47, align 1
  %call28.10.47 = call zeroext i8 @mult(i8 zeroext %4317, i8 zeroext %4318)
  %conv29.10.47 = zext i8 %call28.10.47 to i32
  %xor.10.47 = xor i32 %conv23.10.47, %conv29.10.47
  %scevgep35.10.47 = getelementptr i8, i8* %a, i64 58
  %4319 = load i8, i8* %scevgep35.10.47, align 1
  %4320 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.47 = call zeroext i8 @mult(i8 zeroext %4319, i8 zeroext %4320)
  %conv35.10.47 = zext i8 %call34.10.47 to i32
  %xor36.10.47 = xor i32 %xor.10.47, %conv35.10.47
  %conv37.10.47 = trunc i32 %xor36.10.47 to i8
  store i8 %conv37.10.47, i8* %scevgep41.10.46, align 1
  %scevgep28.10.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4314, i64 0, i64 0, i64 1
  %4321 = bitcast i8* %scevgep28.10.47 to [61 x [61 x i8]]*
  %scevgep41.10.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4315, i64 0, i64 1, i64 0
  %4322 = bitcast i8* %scevgep41.10.47 to [61 x [61 x i8]]*
  %call16.10.48 = call zeroext i8 (...) @rand()
  store i8 %call16.10.48, i8* %scevgep28.10.47, align 1
  %4323 = load i8, i8* %scevgep28.10.47, align 1
  %conv23.10.48 = zext i8 %4323 to i32
  %4324 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.48 = getelementptr i8, i8* %b, i64 59
  %4325 = load i8, i8* %scevgep34.10.48, align 1
  %call28.10.48 = call zeroext i8 @mult(i8 zeroext %4324, i8 zeroext %4325)
  %conv29.10.48 = zext i8 %call28.10.48 to i32
  %xor.10.48 = xor i32 %conv23.10.48, %conv29.10.48
  %scevgep35.10.48 = getelementptr i8, i8* %a, i64 59
  %4326 = load i8, i8* %scevgep35.10.48, align 1
  %4327 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.48 = call zeroext i8 @mult(i8 zeroext %4326, i8 zeroext %4327)
  %conv35.10.48 = zext i8 %call34.10.48 to i32
  %xor36.10.48 = xor i32 %xor.10.48, %conv35.10.48
  %conv37.10.48 = trunc i32 %xor36.10.48 to i8
  store i8 %conv37.10.48, i8* %scevgep41.10.47, align 1
  %scevgep28.10.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4321, i64 0, i64 0, i64 1
  %scevgep41.10.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4322, i64 0, i64 1, i64 0
  %call16.10.49 = call zeroext i8 (...) @rand()
  store i8 %call16.10.49, i8* %scevgep28.10.48, align 1
  %4328 = load i8, i8* %scevgep28.10.48, align 1
  %conv23.10.49 = zext i8 %4328 to i32
  %4329 = load i8, i8* %arrayidx25.10, align 1
  %scevgep34.10.49 = getelementptr i8, i8* %b, i64 60
  %4330 = load i8, i8* %scevgep34.10.49, align 1
  %call28.10.49 = call zeroext i8 @mult(i8 zeroext %4329, i8 zeroext %4330)
  %conv29.10.49 = zext i8 %call28.10.49 to i32
  %xor.10.49 = xor i32 %conv23.10.49, %conv29.10.49
  %scevgep35.10.49 = getelementptr i8, i8* %a, i64 60
  %4331 = load i8, i8* %scevgep35.10.49, align 1
  %4332 = load i8, i8* %arrayidx33.10, align 1
  %call34.10.49 = call zeroext i8 @mult(i8 zeroext %4331, i8 zeroext %4332)
  %conv35.10.49 = zext i8 %call34.10.49 to i32
  %xor36.10.49 = xor i32 %xor.10.49, %conv35.10.49
  %conv37.10.49 = trunc i32 %xor36.10.49 to i8
  store i8 %conv37.10.49, i8* %scevgep41.10.48, align 1
  %scevgep26.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3985, i64 0, i64 1, i64 1
  %4333 = bitcast i8* %scevgep26.10 to [61 x [61 x i8]]*
  %scevgep39.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %3986, i64 0, i64 1, i64 1
  %4334 = bitcast i8* %scevgep39.10 to [61 x [61 x i8]]*
  %arrayidx25.11 = getelementptr inbounds i8, i8* %a, i64 11
  %arrayidx33.11 = getelementptr inbounds i8, i8* %b, i64 11
  %call16.11 = call zeroext i8 (...) @rand()
  store i8 %call16.11, i8* %scevgep26.10, align 1
  %4335 = load i8, i8* %scevgep26.10, align 1
  %conv23.11 = zext i8 %4335 to i32
  %4336 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11 = getelementptr i8, i8* %b, i64 12
  %4337 = load i8, i8* %scevgep34.11, align 1
  %call28.11 = call zeroext i8 @mult(i8 zeroext %4336, i8 zeroext %4337)
  %conv29.11 = zext i8 %call28.11 to i32
  %xor.11 = xor i32 %conv23.11, %conv29.11
  %scevgep35.11 = getelementptr i8, i8* %a, i64 12
  %4338 = load i8, i8* %scevgep35.11, align 1
  %4339 = load i8, i8* %arrayidx33.11, align 1
  %call34.11 = call zeroext i8 @mult(i8 zeroext %4338, i8 zeroext %4339)
  %conv35.11 = zext i8 %call34.11 to i32
  %xor36.11 = xor i32 %xor.11, %conv35.11
  %conv37.11 = trunc i32 %xor36.11 to i8
  store i8 %conv37.11, i8* %scevgep39.10, align 1
  %scevgep28.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4333, i64 0, i64 0, i64 1
  %4340 = bitcast i8* %scevgep28.11 to [61 x [61 x i8]]*
  %scevgep41.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4334, i64 0, i64 1, i64 0
  %4341 = bitcast i8* %scevgep41.11 to [61 x [61 x i8]]*
  %call16.11.1 = call zeroext i8 (...) @rand()
  store i8 %call16.11.1, i8* %scevgep28.11, align 1
  %4342 = load i8, i8* %scevgep28.11, align 1
  %conv23.11.1 = zext i8 %4342 to i32
  %4343 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.1 = getelementptr i8, i8* %b, i64 13
  %4344 = load i8, i8* %scevgep34.11.1, align 1
  %call28.11.1 = call zeroext i8 @mult(i8 zeroext %4343, i8 zeroext %4344)
  %conv29.11.1 = zext i8 %call28.11.1 to i32
  %xor.11.1 = xor i32 %conv23.11.1, %conv29.11.1
  %scevgep35.11.1 = getelementptr i8, i8* %a, i64 13
  %4345 = load i8, i8* %scevgep35.11.1, align 1
  %4346 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.1 = call zeroext i8 @mult(i8 zeroext %4345, i8 zeroext %4346)
  %conv35.11.1 = zext i8 %call34.11.1 to i32
  %xor36.11.1 = xor i32 %xor.11.1, %conv35.11.1
  %conv37.11.1 = trunc i32 %xor36.11.1 to i8
  store i8 %conv37.11.1, i8* %scevgep41.11, align 1
  %scevgep28.11.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4340, i64 0, i64 0, i64 1
  %4347 = bitcast i8* %scevgep28.11.1 to [61 x [61 x i8]]*
  %scevgep41.11.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4341, i64 0, i64 1, i64 0
  %4348 = bitcast i8* %scevgep41.11.1 to [61 x [61 x i8]]*
  %call16.11.2 = call zeroext i8 (...) @rand()
  store i8 %call16.11.2, i8* %scevgep28.11.1, align 1
  %4349 = load i8, i8* %scevgep28.11.1, align 1
  %conv23.11.2 = zext i8 %4349 to i32
  %4350 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.2 = getelementptr i8, i8* %b, i64 14
  %4351 = load i8, i8* %scevgep34.11.2, align 1
  %call28.11.2 = call zeroext i8 @mult(i8 zeroext %4350, i8 zeroext %4351)
  %conv29.11.2 = zext i8 %call28.11.2 to i32
  %xor.11.2 = xor i32 %conv23.11.2, %conv29.11.2
  %scevgep35.11.2 = getelementptr i8, i8* %a, i64 14
  %4352 = load i8, i8* %scevgep35.11.2, align 1
  %4353 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.2 = call zeroext i8 @mult(i8 zeroext %4352, i8 zeroext %4353)
  %conv35.11.2 = zext i8 %call34.11.2 to i32
  %xor36.11.2 = xor i32 %xor.11.2, %conv35.11.2
  %conv37.11.2 = trunc i32 %xor36.11.2 to i8
  store i8 %conv37.11.2, i8* %scevgep41.11.1, align 1
  %scevgep28.11.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4347, i64 0, i64 0, i64 1
  %4354 = bitcast i8* %scevgep28.11.2 to [61 x [61 x i8]]*
  %scevgep41.11.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4348, i64 0, i64 1, i64 0
  %4355 = bitcast i8* %scevgep41.11.2 to [61 x [61 x i8]]*
  %call16.11.3 = call zeroext i8 (...) @rand()
  store i8 %call16.11.3, i8* %scevgep28.11.2, align 1
  %4356 = load i8, i8* %scevgep28.11.2, align 1
  %conv23.11.3 = zext i8 %4356 to i32
  %4357 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.3 = getelementptr i8, i8* %b, i64 15
  %4358 = load i8, i8* %scevgep34.11.3, align 1
  %call28.11.3 = call zeroext i8 @mult(i8 zeroext %4357, i8 zeroext %4358)
  %conv29.11.3 = zext i8 %call28.11.3 to i32
  %xor.11.3 = xor i32 %conv23.11.3, %conv29.11.3
  %scevgep35.11.3 = getelementptr i8, i8* %a, i64 15
  %4359 = load i8, i8* %scevgep35.11.3, align 1
  %4360 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.3 = call zeroext i8 @mult(i8 zeroext %4359, i8 zeroext %4360)
  %conv35.11.3 = zext i8 %call34.11.3 to i32
  %xor36.11.3 = xor i32 %xor.11.3, %conv35.11.3
  %conv37.11.3 = trunc i32 %xor36.11.3 to i8
  store i8 %conv37.11.3, i8* %scevgep41.11.2, align 1
  %scevgep28.11.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4354, i64 0, i64 0, i64 1
  %4361 = bitcast i8* %scevgep28.11.3 to [61 x [61 x i8]]*
  %scevgep41.11.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4355, i64 0, i64 1, i64 0
  %4362 = bitcast i8* %scevgep41.11.3 to [61 x [61 x i8]]*
  %call16.11.4 = call zeroext i8 (...) @rand()
  store i8 %call16.11.4, i8* %scevgep28.11.3, align 1
  %4363 = load i8, i8* %scevgep28.11.3, align 1
  %conv23.11.4 = zext i8 %4363 to i32
  %4364 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.4 = getelementptr i8, i8* %b, i64 16
  %4365 = load i8, i8* %scevgep34.11.4, align 1
  %call28.11.4 = call zeroext i8 @mult(i8 zeroext %4364, i8 zeroext %4365)
  %conv29.11.4 = zext i8 %call28.11.4 to i32
  %xor.11.4 = xor i32 %conv23.11.4, %conv29.11.4
  %scevgep35.11.4 = getelementptr i8, i8* %a, i64 16
  %4366 = load i8, i8* %scevgep35.11.4, align 1
  %4367 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.4 = call zeroext i8 @mult(i8 zeroext %4366, i8 zeroext %4367)
  %conv35.11.4 = zext i8 %call34.11.4 to i32
  %xor36.11.4 = xor i32 %xor.11.4, %conv35.11.4
  %conv37.11.4 = trunc i32 %xor36.11.4 to i8
  store i8 %conv37.11.4, i8* %scevgep41.11.3, align 1
  %scevgep28.11.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4361, i64 0, i64 0, i64 1
  %4368 = bitcast i8* %scevgep28.11.4 to [61 x [61 x i8]]*
  %scevgep41.11.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4362, i64 0, i64 1, i64 0
  %4369 = bitcast i8* %scevgep41.11.4 to [61 x [61 x i8]]*
  %call16.11.5 = call zeroext i8 (...) @rand()
  store i8 %call16.11.5, i8* %scevgep28.11.4, align 1
  %4370 = load i8, i8* %scevgep28.11.4, align 1
  %conv23.11.5 = zext i8 %4370 to i32
  %4371 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.5 = getelementptr i8, i8* %b, i64 17
  %4372 = load i8, i8* %scevgep34.11.5, align 1
  %call28.11.5 = call zeroext i8 @mult(i8 zeroext %4371, i8 zeroext %4372)
  %conv29.11.5 = zext i8 %call28.11.5 to i32
  %xor.11.5 = xor i32 %conv23.11.5, %conv29.11.5
  %scevgep35.11.5 = getelementptr i8, i8* %a, i64 17
  %4373 = load i8, i8* %scevgep35.11.5, align 1
  %4374 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.5 = call zeroext i8 @mult(i8 zeroext %4373, i8 zeroext %4374)
  %conv35.11.5 = zext i8 %call34.11.5 to i32
  %xor36.11.5 = xor i32 %xor.11.5, %conv35.11.5
  %conv37.11.5 = trunc i32 %xor36.11.5 to i8
  store i8 %conv37.11.5, i8* %scevgep41.11.4, align 1
  %scevgep28.11.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4368, i64 0, i64 0, i64 1
  %4375 = bitcast i8* %scevgep28.11.5 to [61 x [61 x i8]]*
  %scevgep41.11.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4369, i64 0, i64 1, i64 0
  %4376 = bitcast i8* %scevgep41.11.5 to [61 x [61 x i8]]*
  %call16.11.6 = call zeroext i8 (...) @rand()
  store i8 %call16.11.6, i8* %scevgep28.11.5, align 1
  %4377 = load i8, i8* %scevgep28.11.5, align 1
  %conv23.11.6 = zext i8 %4377 to i32
  %4378 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.6 = getelementptr i8, i8* %b, i64 18
  %4379 = load i8, i8* %scevgep34.11.6, align 1
  %call28.11.6 = call zeroext i8 @mult(i8 zeroext %4378, i8 zeroext %4379)
  %conv29.11.6 = zext i8 %call28.11.6 to i32
  %xor.11.6 = xor i32 %conv23.11.6, %conv29.11.6
  %scevgep35.11.6 = getelementptr i8, i8* %a, i64 18
  %4380 = load i8, i8* %scevgep35.11.6, align 1
  %4381 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.6 = call zeroext i8 @mult(i8 zeroext %4380, i8 zeroext %4381)
  %conv35.11.6 = zext i8 %call34.11.6 to i32
  %xor36.11.6 = xor i32 %xor.11.6, %conv35.11.6
  %conv37.11.6 = trunc i32 %xor36.11.6 to i8
  store i8 %conv37.11.6, i8* %scevgep41.11.5, align 1
  %scevgep28.11.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4375, i64 0, i64 0, i64 1
  %4382 = bitcast i8* %scevgep28.11.6 to [61 x [61 x i8]]*
  %scevgep41.11.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4376, i64 0, i64 1, i64 0
  %4383 = bitcast i8* %scevgep41.11.6 to [61 x [61 x i8]]*
  %call16.11.7 = call zeroext i8 (...) @rand()
  store i8 %call16.11.7, i8* %scevgep28.11.6, align 1
  %4384 = load i8, i8* %scevgep28.11.6, align 1
  %conv23.11.7 = zext i8 %4384 to i32
  %4385 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.7 = getelementptr i8, i8* %b, i64 19
  %4386 = load i8, i8* %scevgep34.11.7, align 1
  %call28.11.7 = call zeroext i8 @mult(i8 zeroext %4385, i8 zeroext %4386)
  %conv29.11.7 = zext i8 %call28.11.7 to i32
  %xor.11.7 = xor i32 %conv23.11.7, %conv29.11.7
  %scevgep35.11.7 = getelementptr i8, i8* %a, i64 19
  %4387 = load i8, i8* %scevgep35.11.7, align 1
  %4388 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.7 = call zeroext i8 @mult(i8 zeroext %4387, i8 zeroext %4388)
  %conv35.11.7 = zext i8 %call34.11.7 to i32
  %xor36.11.7 = xor i32 %xor.11.7, %conv35.11.7
  %conv37.11.7 = trunc i32 %xor36.11.7 to i8
  store i8 %conv37.11.7, i8* %scevgep41.11.6, align 1
  %scevgep28.11.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4382, i64 0, i64 0, i64 1
  %4389 = bitcast i8* %scevgep28.11.7 to [61 x [61 x i8]]*
  %scevgep41.11.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4383, i64 0, i64 1, i64 0
  %4390 = bitcast i8* %scevgep41.11.7 to [61 x [61 x i8]]*
  %call16.11.8 = call zeroext i8 (...) @rand()
  store i8 %call16.11.8, i8* %scevgep28.11.7, align 1
  %4391 = load i8, i8* %scevgep28.11.7, align 1
  %conv23.11.8 = zext i8 %4391 to i32
  %4392 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.8 = getelementptr i8, i8* %b, i64 20
  %4393 = load i8, i8* %scevgep34.11.8, align 1
  %call28.11.8 = call zeroext i8 @mult(i8 zeroext %4392, i8 zeroext %4393)
  %conv29.11.8 = zext i8 %call28.11.8 to i32
  %xor.11.8 = xor i32 %conv23.11.8, %conv29.11.8
  %scevgep35.11.8 = getelementptr i8, i8* %a, i64 20
  %4394 = load i8, i8* %scevgep35.11.8, align 1
  %4395 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.8 = call zeroext i8 @mult(i8 zeroext %4394, i8 zeroext %4395)
  %conv35.11.8 = zext i8 %call34.11.8 to i32
  %xor36.11.8 = xor i32 %xor.11.8, %conv35.11.8
  %conv37.11.8 = trunc i32 %xor36.11.8 to i8
  store i8 %conv37.11.8, i8* %scevgep41.11.7, align 1
  %scevgep28.11.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4389, i64 0, i64 0, i64 1
  %4396 = bitcast i8* %scevgep28.11.8 to [61 x [61 x i8]]*
  %scevgep41.11.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4390, i64 0, i64 1, i64 0
  %4397 = bitcast i8* %scevgep41.11.8 to [61 x [61 x i8]]*
  %call16.11.9 = call zeroext i8 (...) @rand()
  store i8 %call16.11.9, i8* %scevgep28.11.8, align 1
  %4398 = load i8, i8* %scevgep28.11.8, align 1
  %conv23.11.9 = zext i8 %4398 to i32
  %4399 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.9 = getelementptr i8, i8* %b, i64 21
  %4400 = load i8, i8* %scevgep34.11.9, align 1
  %call28.11.9 = call zeroext i8 @mult(i8 zeroext %4399, i8 zeroext %4400)
  %conv29.11.9 = zext i8 %call28.11.9 to i32
  %xor.11.9 = xor i32 %conv23.11.9, %conv29.11.9
  %scevgep35.11.9 = getelementptr i8, i8* %a, i64 21
  %4401 = load i8, i8* %scevgep35.11.9, align 1
  %4402 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.9 = call zeroext i8 @mult(i8 zeroext %4401, i8 zeroext %4402)
  %conv35.11.9 = zext i8 %call34.11.9 to i32
  %xor36.11.9 = xor i32 %xor.11.9, %conv35.11.9
  %conv37.11.9 = trunc i32 %xor36.11.9 to i8
  store i8 %conv37.11.9, i8* %scevgep41.11.8, align 1
  %scevgep28.11.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4396, i64 0, i64 0, i64 1
  %4403 = bitcast i8* %scevgep28.11.9 to [61 x [61 x i8]]*
  %scevgep41.11.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4397, i64 0, i64 1, i64 0
  %4404 = bitcast i8* %scevgep41.11.9 to [61 x [61 x i8]]*
  %call16.11.10 = call zeroext i8 (...) @rand()
  store i8 %call16.11.10, i8* %scevgep28.11.9, align 1
  %4405 = load i8, i8* %scevgep28.11.9, align 1
  %conv23.11.10 = zext i8 %4405 to i32
  %4406 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.10 = getelementptr i8, i8* %b, i64 22
  %4407 = load i8, i8* %scevgep34.11.10, align 1
  %call28.11.10 = call zeroext i8 @mult(i8 zeroext %4406, i8 zeroext %4407)
  %conv29.11.10 = zext i8 %call28.11.10 to i32
  %xor.11.10 = xor i32 %conv23.11.10, %conv29.11.10
  %scevgep35.11.10 = getelementptr i8, i8* %a, i64 22
  %4408 = load i8, i8* %scevgep35.11.10, align 1
  %4409 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.10 = call zeroext i8 @mult(i8 zeroext %4408, i8 zeroext %4409)
  %conv35.11.10 = zext i8 %call34.11.10 to i32
  %xor36.11.10 = xor i32 %xor.11.10, %conv35.11.10
  %conv37.11.10 = trunc i32 %xor36.11.10 to i8
  store i8 %conv37.11.10, i8* %scevgep41.11.9, align 1
  %scevgep28.11.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4403, i64 0, i64 0, i64 1
  %4410 = bitcast i8* %scevgep28.11.10 to [61 x [61 x i8]]*
  %scevgep41.11.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4404, i64 0, i64 1, i64 0
  %4411 = bitcast i8* %scevgep41.11.10 to [61 x [61 x i8]]*
  %call16.11.11 = call zeroext i8 (...) @rand()
  store i8 %call16.11.11, i8* %scevgep28.11.10, align 1
  %4412 = load i8, i8* %scevgep28.11.10, align 1
  %conv23.11.11 = zext i8 %4412 to i32
  %4413 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.11 = getelementptr i8, i8* %b, i64 23
  %4414 = load i8, i8* %scevgep34.11.11, align 1
  %call28.11.11 = call zeroext i8 @mult(i8 zeroext %4413, i8 zeroext %4414)
  %conv29.11.11 = zext i8 %call28.11.11 to i32
  %xor.11.11 = xor i32 %conv23.11.11, %conv29.11.11
  %scevgep35.11.11 = getelementptr i8, i8* %a, i64 23
  %4415 = load i8, i8* %scevgep35.11.11, align 1
  %4416 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.11 = call zeroext i8 @mult(i8 zeroext %4415, i8 zeroext %4416)
  %conv35.11.11 = zext i8 %call34.11.11 to i32
  %xor36.11.11 = xor i32 %xor.11.11, %conv35.11.11
  %conv37.11.11 = trunc i32 %xor36.11.11 to i8
  store i8 %conv37.11.11, i8* %scevgep41.11.10, align 1
  %scevgep28.11.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4410, i64 0, i64 0, i64 1
  %4417 = bitcast i8* %scevgep28.11.11 to [61 x [61 x i8]]*
  %scevgep41.11.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4411, i64 0, i64 1, i64 0
  %4418 = bitcast i8* %scevgep41.11.11 to [61 x [61 x i8]]*
  %call16.11.12 = call zeroext i8 (...) @rand()
  store i8 %call16.11.12, i8* %scevgep28.11.11, align 1
  %4419 = load i8, i8* %scevgep28.11.11, align 1
  %conv23.11.12 = zext i8 %4419 to i32
  %4420 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.12 = getelementptr i8, i8* %b, i64 24
  %4421 = load i8, i8* %scevgep34.11.12, align 1
  %call28.11.12 = call zeroext i8 @mult(i8 zeroext %4420, i8 zeroext %4421)
  %conv29.11.12 = zext i8 %call28.11.12 to i32
  %xor.11.12 = xor i32 %conv23.11.12, %conv29.11.12
  %scevgep35.11.12 = getelementptr i8, i8* %a, i64 24
  %4422 = load i8, i8* %scevgep35.11.12, align 1
  %4423 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.12 = call zeroext i8 @mult(i8 zeroext %4422, i8 zeroext %4423)
  %conv35.11.12 = zext i8 %call34.11.12 to i32
  %xor36.11.12 = xor i32 %xor.11.12, %conv35.11.12
  %conv37.11.12 = trunc i32 %xor36.11.12 to i8
  store i8 %conv37.11.12, i8* %scevgep41.11.11, align 1
  %scevgep28.11.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4417, i64 0, i64 0, i64 1
  %4424 = bitcast i8* %scevgep28.11.12 to [61 x [61 x i8]]*
  %scevgep41.11.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4418, i64 0, i64 1, i64 0
  %4425 = bitcast i8* %scevgep41.11.12 to [61 x [61 x i8]]*
  %call16.11.13 = call zeroext i8 (...) @rand()
  store i8 %call16.11.13, i8* %scevgep28.11.12, align 1
  %4426 = load i8, i8* %scevgep28.11.12, align 1
  %conv23.11.13 = zext i8 %4426 to i32
  %4427 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.13 = getelementptr i8, i8* %b, i64 25
  %4428 = load i8, i8* %scevgep34.11.13, align 1
  %call28.11.13 = call zeroext i8 @mult(i8 zeroext %4427, i8 zeroext %4428)
  %conv29.11.13 = zext i8 %call28.11.13 to i32
  %xor.11.13 = xor i32 %conv23.11.13, %conv29.11.13
  %scevgep35.11.13 = getelementptr i8, i8* %a, i64 25
  %4429 = load i8, i8* %scevgep35.11.13, align 1
  %4430 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.13 = call zeroext i8 @mult(i8 zeroext %4429, i8 zeroext %4430)
  %conv35.11.13 = zext i8 %call34.11.13 to i32
  %xor36.11.13 = xor i32 %xor.11.13, %conv35.11.13
  %conv37.11.13 = trunc i32 %xor36.11.13 to i8
  store i8 %conv37.11.13, i8* %scevgep41.11.12, align 1
  %scevgep28.11.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4424, i64 0, i64 0, i64 1
  %4431 = bitcast i8* %scevgep28.11.13 to [61 x [61 x i8]]*
  %scevgep41.11.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4425, i64 0, i64 1, i64 0
  %4432 = bitcast i8* %scevgep41.11.13 to [61 x [61 x i8]]*
  %call16.11.14 = call zeroext i8 (...) @rand()
  store i8 %call16.11.14, i8* %scevgep28.11.13, align 1
  %4433 = load i8, i8* %scevgep28.11.13, align 1
  %conv23.11.14 = zext i8 %4433 to i32
  %4434 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.14 = getelementptr i8, i8* %b, i64 26
  %4435 = load i8, i8* %scevgep34.11.14, align 1
  %call28.11.14 = call zeroext i8 @mult(i8 zeroext %4434, i8 zeroext %4435)
  %conv29.11.14 = zext i8 %call28.11.14 to i32
  %xor.11.14 = xor i32 %conv23.11.14, %conv29.11.14
  %scevgep35.11.14 = getelementptr i8, i8* %a, i64 26
  %4436 = load i8, i8* %scevgep35.11.14, align 1
  %4437 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.14 = call zeroext i8 @mult(i8 zeroext %4436, i8 zeroext %4437)
  %conv35.11.14 = zext i8 %call34.11.14 to i32
  %xor36.11.14 = xor i32 %xor.11.14, %conv35.11.14
  %conv37.11.14 = trunc i32 %xor36.11.14 to i8
  store i8 %conv37.11.14, i8* %scevgep41.11.13, align 1
  %scevgep28.11.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4431, i64 0, i64 0, i64 1
  %4438 = bitcast i8* %scevgep28.11.14 to [61 x [61 x i8]]*
  %scevgep41.11.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4432, i64 0, i64 1, i64 0
  %4439 = bitcast i8* %scevgep41.11.14 to [61 x [61 x i8]]*
  %call16.11.15 = call zeroext i8 (...) @rand()
  store i8 %call16.11.15, i8* %scevgep28.11.14, align 1
  %4440 = load i8, i8* %scevgep28.11.14, align 1
  %conv23.11.15 = zext i8 %4440 to i32
  %4441 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.15 = getelementptr i8, i8* %b, i64 27
  %4442 = load i8, i8* %scevgep34.11.15, align 1
  %call28.11.15 = call zeroext i8 @mult(i8 zeroext %4441, i8 zeroext %4442)
  %conv29.11.15 = zext i8 %call28.11.15 to i32
  %xor.11.15 = xor i32 %conv23.11.15, %conv29.11.15
  %scevgep35.11.15 = getelementptr i8, i8* %a, i64 27
  %4443 = load i8, i8* %scevgep35.11.15, align 1
  %4444 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.15 = call zeroext i8 @mult(i8 zeroext %4443, i8 zeroext %4444)
  %conv35.11.15 = zext i8 %call34.11.15 to i32
  %xor36.11.15 = xor i32 %xor.11.15, %conv35.11.15
  %conv37.11.15 = trunc i32 %xor36.11.15 to i8
  store i8 %conv37.11.15, i8* %scevgep41.11.14, align 1
  %scevgep28.11.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4438, i64 0, i64 0, i64 1
  %4445 = bitcast i8* %scevgep28.11.15 to [61 x [61 x i8]]*
  %scevgep41.11.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4439, i64 0, i64 1, i64 0
  %4446 = bitcast i8* %scevgep41.11.15 to [61 x [61 x i8]]*
  %call16.11.16 = call zeroext i8 (...) @rand()
  store i8 %call16.11.16, i8* %scevgep28.11.15, align 1
  %4447 = load i8, i8* %scevgep28.11.15, align 1
  %conv23.11.16 = zext i8 %4447 to i32
  %4448 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.16 = getelementptr i8, i8* %b, i64 28
  %4449 = load i8, i8* %scevgep34.11.16, align 1
  %call28.11.16 = call zeroext i8 @mult(i8 zeroext %4448, i8 zeroext %4449)
  %conv29.11.16 = zext i8 %call28.11.16 to i32
  %xor.11.16 = xor i32 %conv23.11.16, %conv29.11.16
  %scevgep35.11.16 = getelementptr i8, i8* %a, i64 28
  %4450 = load i8, i8* %scevgep35.11.16, align 1
  %4451 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.16 = call zeroext i8 @mult(i8 zeroext %4450, i8 zeroext %4451)
  %conv35.11.16 = zext i8 %call34.11.16 to i32
  %xor36.11.16 = xor i32 %xor.11.16, %conv35.11.16
  %conv37.11.16 = trunc i32 %xor36.11.16 to i8
  store i8 %conv37.11.16, i8* %scevgep41.11.15, align 1
  %scevgep28.11.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4445, i64 0, i64 0, i64 1
  %4452 = bitcast i8* %scevgep28.11.16 to [61 x [61 x i8]]*
  %scevgep41.11.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4446, i64 0, i64 1, i64 0
  %4453 = bitcast i8* %scevgep41.11.16 to [61 x [61 x i8]]*
  %call16.11.17 = call zeroext i8 (...) @rand()
  store i8 %call16.11.17, i8* %scevgep28.11.16, align 1
  %4454 = load i8, i8* %scevgep28.11.16, align 1
  %conv23.11.17 = zext i8 %4454 to i32
  %4455 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.17 = getelementptr i8, i8* %b, i64 29
  %4456 = load i8, i8* %scevgep34.11.17, align 1
  %call28.11.17 = call zeroext i8 @mult(i8 zeroext %4455, i8 zeroext %4456)
  %conv29.11.17 = zext i8 %call28.11.17 to i32
  %xor.11.17 = xor i32 %conv23.11.17, %conv29.11.17
  %scevgep35.11.17 = getelementptr i8, i8* %a, i64 29
  %4457 = load i8, i8* %scevgep35.11.17, align 1
  %4458 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.17 = call zeroext i8 @mult(i8 zeroext %4457, i8 zeroext %4458)
  %conv35.11.17 = zext i8 %call34.11.17 to i32
  %xor36.11.17 = xor i32 %xor.11.17, %conv35.11.17
  %conv37.11.17 = trunc i32 %xor36.11.17 to i8
  store i8 %conv37.11.17, i8* %scevgep41.11.16, align 1
  %scevgep28.11.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4452, i64 0, i64 0, i64 1
  %4459 = bitcast i8* %scevgep28.11.17 to [61 x [61 x i8]]*
  %scevgep41.11.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4453, i64 0, i64 1, i64 0
  %4460 = bitcast i8* %scevgep41.11.17 to [61 x [61 x i8]]*
  %call16.11.18 = call zeroext i8 (...) @rand()
  store i8 %call16.11.18, i8* %scevgep28.11.17, align 1
  %4461 = load i8, i8* %scevgep28.11.17, align 1
  %conv23.11.18 = zext i8 %4461 to i32
  %4462 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.18 = getelementptr i8, i8* %b, i64 30
  %4463 = load i8, i8* %scevgep34.11.18, align 1
  %call28.11.18 = call zeroext i8 @mult(i8 zeroext %4462, i8 zeroext %4463)
  %conv29.11.18 = zext i8 %call28.11.18 to i32
  %xor.11.18 = xor i32 %conv23.11.18, %conv29.11.18
  %scevgep35.11.18 = getelementptr i8, i8* %a, i64 30
  %4464 = load i8, i8* %scevgep35.11.18, align 1
  %4465 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.18 = call zeroext i8 @mult(i8 zeroext %4464, i8 zeroext %4465)
  %conv35.11.18 = zext i8 %call34.11.18 to i32
  %xor36.11.18 = xor i32 %xor.11.18, %conv35.11.18
  %conv37.11.18 = trunc i32 %xor36.11.18 to i8
  store i8 %conv37.11.18, i8* %scevgep41.11.17, align 1
  %scevgep28.11.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4459, i64 0, i64 0, i64 1
  %4466 = bitcast i8* %scevgep28.11.18 to [61 x [61 x i8]]*
  %scevgep41.11.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4460, i64 0, i64 1, i64 0
  %4467 = bitcast i8* %scevgep41.11.18 to [61 x [61 x i8]]*
  %call16.11.19 = call zeroext i8 (...) @rand()
  store i8 %call16.11.19, i8* %scevgep28.11.18, align 1
  %4468 = load i8, i8* %scevgep28.11.18, align 1
  %conv23.11.19 = zext i8 %4468 to i32
  %4469 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.19 = getelementptr i8, i8* %b, i64 31
  %4470 = load i8, i8* %scevgep34.11.19, align 1
  %call28.11.19 = call zeroext i8 @mult(i8 zeroext %4469, i8 zeroext %4470)
  %conv29.11.19 = zext i8 %call28.11.19 to i32
  %xor.11.19 = xor i32 %conv23.11.19, %conv29.11.19
  %scevgep35.11.19 = getelementptr i8, i8* %a, i64 31
  %4471 = load i8, i8* %scevgep35.11.19, align 1
  %4472 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.19 = call zeroext i8 @mult(i8 zeroext %4471, i8 zeroext %4472)
  %conv35.11.19 = zext i8 %call34.11.19 to i32
  %xor36.11.19 = xor i32 %xor.11.19, %conv35.11.19
  %conv37.11.19 = trunc i32 %xor36.11.19 to i8
  store i8 %conv37.11.19, i8* %scevgep41.11.18, align 1
  %scevgep28.11.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4466, i64 0, i64 0, i64 1
  %4473 = bitcast i8* %scevgep28.11.19 to [61 x [61 x i8]]*
  %scevgep41.11.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4467, i64 0, i64 1, i64 0
  %4474 = bitcast i8* %scevgep41.11.19 to [61 x [61 x i8]]*
  %call16.11.20 = call zeroext i8 (...) @rand()
  store i8 %call16.11.20, i8* %scevgep28.11.19, align 1
  %4475 = load i8, i8* %scevgep28.11.19, align 1
  %conv23.11.20 = zext i8 %4475 to i32
  %4476 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.20 = getelementptr i8, i8* %b, i64 32
  %4477 = load i8, i8* %scevgep34.11.20, align 1
  %call28.11.20 = call zeroext i8 @mult(i8 zeroext %4476, i8 zeroext %4477)
  %conv29.11.20 = zext i8 %call28.11.20 to i32
  %xor.11.20 = xor i32 %conv23.11.20, %conv29.11.20
  %scevgep35.11.20 = getelementptr i8, i8* %a, i64 32
  %4478 = load i8, i8* %scevgep35.11.20, align 1
  %4479 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.20 = call zeroext i8 @mult(i8 zeroext %4478, i8 zeroext %4479)
  %conv35.11.20 = zext i8 %call34.11.20 to i32
  %xor36.11.20 = xor i32 %xor.11.20, %conv35.11.20
  %conv37.11.20 = trunc i32 %xor36.11.20 to i8
  store i8 %conv37.11.20, i8* %scevgep41.11.19, align 1
  %scevgep28.11.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4473, i64 0, i64 0, i64 1
  %4480 = bitcast i8* %scevgep28.11.20 to [61 x [61 x i8]]*
  %scevgep41.11.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4474, i64 0, i64 1, i64 0
  %4481 = bitcast i8* %scevgep41.11.20 to [61 x [61 x i8]]*
  %call16.11.21 = call zeroext i8 (...) @rand()
  store i8 %call16.11.21, i8* %scevgep28.11.20, align 1
  %4482 = load i8, i8* %scevgep28.11.20, align 1
  %conv23.11.21 = zext i8 %4482 to i32
  %4483 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.21 = getelementptr i8, i8* %b, i64 33
  %4484 = load i8, i8* %scevgep34.11.21, align 1
  %call28.11.21 = call zeroext i8 @mult(i8 zeroext %4483, i8 zeroext %4484)
  %conv29.11.21 = zext i8 %call28.11.21 to i32
  %xor.11.21 = xor i32 %conv23.11.21, %conv29.11.21
  %scevgep35.11.21 = getelementptr i8, i8* %a, i64 33
  %4485 = load i8, i8* %scevgep35.11.21, align 1
  %4486 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.21 = call zeroext i8 @mult(i8 zeroext %4485, i8 zeroext %4486)
  %conv35.11.21 = zext i8 %call34.11.21 to i32
  %xor36.11.21 = xor i32 %xor.11.21, %conv35.11.21
  %conv37.11.21 = trunc i32 %xor36.11.21 to i8
  store i8 %conv37.11.21, i8* %scevgep41.11.20, align 1
  %scevgep28.11.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4480, i64 0, i64 0, i64 1
  %4487 = bitcast i8* %scevgep28.11.21 to [61 x [61 x i8]]*
  %scevgep41.11.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4481, i64 0, i64 1, i64 0
  %4488 = bitcast i8* %scevgep41.11.21 to [61 x [61 x i8]]*
  %call16.11.22 = call zeroext i8 (...) @rand()
  store i8 %call16.11.22, i8* %scevgep28.11.21, align 1
  %4489 = load i8, i8* %scevgep28.11.21, align 1
  %conv23.11.22 = zext i8 %4489 to i32
  %4490 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.22 = getelementptr i8, i8* %b, i64 34
  %4491 = load i8, i8* %scevgep34.11.22, align 1
  %call28.11.22 = call zeroext i8 @mult(i8 zeroext %4490, i8 zeroext %4491)
  %conv29.11.22 = zext i8 %call28.11.22 to i32
  %xor.11.22 = xor i32 %conv23.11.22, %conv29.11.22
  %scevgep35.11.22 = getelementptr i8, i8* %a, i64 34
  %4492 = load i8, i8* %scevgep35.11.22, align 1
  %4493 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.22 = call zeroext i8 @mult(i8 zeroext %4492, i8 zeroext %4493)
  %conv35.11.22 = zext i8 %call34.11.22 to i32
  %xor36.11.22 = xor i32 %xor.11.22, %conv35.11.22
  %conv37.11.22 = trunc i32 %xor36.11.22 to i8
  store i8 %conv37.11.22, i8* %scevgep41.11.21, align 1
  %scevgep28.11.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4487, i64 0, i64 0, i64 1
  %4494 = bitcast i8* %scevgep28.11.22 to [61 x [61 x i8]]*
  %scevgep41.11.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4488, i64 0, i64 1, i64 0
  %4495 = bitcast i8* %scevgep41.11.22 to [61 x [61 x i8]]*
  %call16.11.23 = call zeroext i8 (...) @rand()
  store i8 %call16.11.23, i8* %scevgep28.11.22, align 1
  %4496 = load i8, i8* %scevgep28.11.22, align 1
  %conv23.11.23 = zext i8 %4496 to i32
  %4497 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.23 = getelementptr i8, i8* %b, i64 35
  %4498 = load i8, i8* %scevgep34.11.23, align 1
  %call28.11.23 = call zeroext i8 @mult(i8 zeroext %4497, i8 zeroext %4498)
  %conv29.11.23 = zext i8 %call28.11.23 to i32
  %xor.11.23 = xor i32 %conv23.11.23, %conv29.11.23
  %scevgep35.11.23 = getelementptr i8, i8* %a, i64 35
  %4499 = load i8, i8* %scevgep35.11.23, align 1
  %4500 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.23 = call zeroext i8 @mult(i8 zeroext %4499, i8 zeroext %4500)
  %conv35.11.23 = zext i8 %call34.11.23 to i32
  %xor36.11.23 = xor i32 %xor.11.23, %conv35.11.23
  %conv37.11.23 = trunc i32 %xor36.11.23 to i8
  store i8 %conv37.11.23, i8* %scevgep41.11.22, align 1
  %scevgep28.11.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4494, i64 0, i64 0, i64 1
  %4501 = bitcast i8* %scevgep28.11.23 to [61 x [61 x i8]]*
  %scevgep41.11.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4495, i64 0, i64 1, i64 0
  %4502 = bitcast i8* %scevgep41.11.23 to [61 x [61 x i8]]*
  %call16.11.24 = call zeroext i8 (...) @rand()
  store i8 %call16.11.24, i8* %scevgep28.11.23, align 1
  %4503 = load i8, i8* %scevgep28.11.23, align 1
  %conv23.11.24 = zext i8 %4503 to i32
  %4504 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.24 = getelementptr i8, i8* %b, i64 36
  %4505 = load i8, i8* %scevgep34.11.24, align 1
  %call28.11.24 = call zeroext i8 @mult(i8 zeroext %4504, i8 zeroext %4505)
  %conv29.11.24 = zext i8 %call28.11.24 to i32
  %xor.11.24 = xor i32 %conv23.11.24, %conv29.11.24
  %scevgep35.11.24 = getelementptr i8, i8* %a, i64 36
  %4506 = load i8, i8* %scevgep35.11.24, align 1
  %4507 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.24 = call zeroext i8 @mult(i8 zeroext %4506, i8 zeroext %4507)
  %conv35.11.24 = zext i8 %call34.11.24 to i32
  %xor36.11.24 = xor i32 %xor.11.24, %conv35.11.24
  %conv37.11.24 = trunc i32 %xor36.11.24 to i8
  store i8 %conv37.11.24, i8* %scevgep41.11.23, align 1
  %scevgep28.11.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4501, i64 0, i64 0, i64 1
  %4508 = bitcast i8* %scevgep28.11.24 to [61 x [61 x i8]]*
  %scevgep41.11.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4502, i64 0, i64 1, i64 0
  %4509 = bitcast i8* %scevgep41.11.24 to [61 x [61 x i8]]*
  %call16.11.25 = call zeroext i8 (...) @rand()
  store i8 %call16.11.25, i8* %scevgep28.11.24, align 1
  %4510 = load i8, i8* %scevgep28.11.24, align 1
  %conv23.11.25 = zext i8 %4510 to i32
  %4511 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.25 = getelementptr i8, i8* %b, i64 37
  %4512 = load i8, i8* %scevgep34.11.25, align 1
  %call28.11.25 = call zeroext i8 @mult(i8 zeroext %4511, i8 zeroext %4512)
  %conv29.11.25 = zext i8 %call28.11.25 to i32
  %xor.11.25 = xor i32 %conv23.11.25, %conv29.11.25
  %scevgep35.11.25 = getelementptr i8, i8* %a, i64 37
  %4513 = load i8, i8* %scevgep35.11.25, align 1
  %4514 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.25 = call zeroext i8 @mult(i8 zeroext %4513, i8 zeroext %4514)
  %conv35.11.25 = zext i8 %call34.11.25 to i32
  %xor36.11.25 = xor i32 %xor.11.25, %conv35.11.25
  %conv37.11.25 = trunc i32 %xor36.11.25 to i8
  store i8 %conv37.11.25, i8* %scevgep41.11.24, align 1
  %scevgep28.11.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4508, i64 0, i64 0, i64 1
  %4515 = bitcast i8* %scevgep28.11.25 to [61 x [61 x i8]]*
  %scevgep41.11.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4509, i64 0, i64 1, i64 0
  %4516 = bitcast i8* %scevgep41.11.25 to [61 x [61 x i8]]*
  %call16.11.26 = call zeroext i8 (...) @rand()
  store i8 %call16.11.26, i8* %scevgep28.11.25, align 1
  %4517 = load i8, i8* %scevgep28.11.25, align 1
  %conv23.11.26 = zext i8 %4517 to i32
  %4518 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.26 = getelementptr i8, i8* %b, i64 38
  %4519 = load i8, i8* %scevgep34.11.26, align 1
  %call28.11.26 = call zeroext i8 @mult(i8 zeroext %4518, i8 zeroext %4519)
  %conv29.11.26 = zext i8 %call28.11.26 to i32
  %xor.11.26 = xor i32 %conv23.11.26, %conv29.11.26
  %scevgep35.11.26 = getelementptr i8, i8* %a, i64 38
  %4520 = load i8, i8* %scevgep35.11.26, align 1
  %4521 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.26 = call zeroext i8 @mult(i8 zeroext %4520, i8 zeroext %4521)
  %conv35.11.26 = zext i8 %call34.11.26 to i32
  %xor36.11.26 = xor i32 %xor.11.26, %conv35.11.26
  %conv37.11.26 = trunc i32 %xor36.11.26 to i8
  store i8 %conv37.11.26, i8* %scevgep41.11.25, align 1
  %scevgep28.11.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4515, i64 0, i64 0, i64 1
  %4522 = bitcast i8* %scevgep28.11.26 to [61 x [61 x i8]]*
  %scevgep41.11.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4516, i64 0, i64 1, i64 0
  %4523 = bitcast i8* %scevgep41.11.26 to [61 x [61 x i8]]*
  %call16.11.27 = call zeroext i8 (...) @rand()
  store i8 %call16.11.27, i8* %scevgep28.11.26, align 1
  %4524 = load i8, i8* %scevgep28.11.26, align 1
  %conv23.11.27 = zext i8 %4524 to i32
  %4525 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.27 = getelementptr i8, i8* %b, i64 39
  %4526 = load i8, i8* %scevgep34.11.27, align 1
  %call28.11.27 = call zeroext i8 @mult(i8 zeroext %4525, i8 zeroext %4526)
  %conv29.11.27 = zext i8 %call28.11.27 to i32
  %xor.11.27 = xor i32 %conv23.11.27, %conv29.11.27
  %scevgep35.11.27 = getelementptr i8, i8* %a, i64 39
  %4527 = load i8, i8* %scevgep35.11.27, align 1
  %4528 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.27 = call zeroext i8 @mult(i8 zeroext %4527, i8 zeroext %4528)
  %conv35.11.27 = zext i8 %call34.11.27 to i32
  %xor36.11.27 = xor i32 %xor.11.27, %conv35.11.27
  %conv37.11.27 = trunc i32 %xor36.11.27 to i8
  store i8 %conv37.11.27, i8* %scevgep41.11.26, align 1
  %scevgep28.11.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4522, i64 0, i64 0, i64 1
  %4529 = bitcast i8* %scevgep28.11.27 to [61 x [61 x i8]]*
  %scevgep41.11.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4523, i64 0, i64 1, i64 0
  %4530 = bitcast i8* %scevgep41.11.27 to [61 x [61 x i8]]*
  %call16.11.28 = call zeroext i8 (...) @rand()
  store i8 %call16.11.28, i8* %scevgep28.11.27, align 1
  %4531 = load i8, i8* %scevgep28.11.27, align 1
  %conv23.11.28 = zext i8 %4531 to i32
  %4532 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.28 = getelementptr i8, i8* %b, i64 40
  %4533 = load i8, i8* %scevgep34.11.28, align 1
  %call28.11.28 = call zeroext i8 @mult(i8 zeroext %4532, i8 zeroext %4533)
  %conv29.11.28 = zext i8 %call28.11.28 to i32
  %xor.11.28 = xor i32 %conv23.11.28, %conv29.11.28
  %scevgep35.11.28 = getelementptr i8, i8* %a, i64 40
  %4534 = load i8, i8* %scevgep35.11.28, align 1
  %4535 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.28 = call zeroext i8 @mult(i8 zeroext %4534, i8 zeroext %4535)
  %conv35.11.28 = zext i8 %call34.11.28 to i32
  %xor36.11.28 = xor i32 %xor.11.28, %conv35.11.28
  %conv37.11.28 = trunc i32 %xor36.11.28 to i8
  store i8 %conv37.11.28, i8* %scevgep41.11.27, align 1
  %scevgep28.11.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4529, i64 0, i64 0, i64 1
  %4536 = bitcast i8* %scevgep28.11.28 to [61 x [61 x i8]]*
  %scevgep41.11.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4530, i64 0, i64 1, i64 0
  %4537 = bitcast i8* %scevgep41.11.28 to [61 x [61 x i8]]*
  %call16.11.29 = call zeroext i8 (...) @rand()
  store i8 %call16.11.29, i8* %scevgep28.11.28, align 1
  %4538 = load i8, i8* %scevgep28.11.28, align 1
  %conv23.11.29 = zext i8 %4538 to i32
  %4539 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.29 = getelementptr i8, i8* %b, i64 41
  %4540 = load i8, i8* %scevgep34.11.29, align 1
  %call28.11.29 = call zeroext i8 @mult(i8 zeroext %4539, i8 zeroext %4540)
  %conv29.11.29 = zext i8 %call28.11.29 to i32
  %xor.11.29 = xor i32 %conv23.11.29, %conv29.11.29
  %scevgep35.11.29 = getelementptr i8, i8* %a, i64 41
  %4541 = load i8, i8* %scevgep35.11.29, align 1
  %4542 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.29 = call zeroext i8 @mult(i8 zeroext %4541, i8 zeroext %4542)
  %conv35.11.29 = zext i8 %call34.11.29 to i32
  %xor36.11.29 = xor i32 %xor.11.29, %conv35.11.29
  %conv37.11.29 = trunc i32 %xor36.11.29 to i8
  store i8 %conv37.11.29, i8* %scevgep41.11.28, align 1
  %scevgep28.11.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4536, i64 0, i64 0, i64 1
  %4543 = bitcast i8* %scevgep28.11.29 to [61 x [61 x i8]]*
  %scevgep41.11.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4537, i64 0, i64 1, i64 0
  %4544 = bitcast i8* %scevgep41.11.29 to [61 x [61 x i8]]*
  %call16.11.30 = call zeroext i8 (...) @rand()
  store i8 %call16.11.30, i8* %scevgep28.11.29, align 1
  %4545 = load i8, i8* %scevgep28.11.29, align 1
  %conv23.11.30 = zext i8 %4545 to i32
  %4546 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.30 = getelementptr i8, i8* %b, i64 42
  %4547 = load i8, i8* %scevgep34.11.30, align 1
  %call28.11.30 = call zeroext i8 @mult(i8 zeroext %4546, i8 zeroext %4547)
  %conv29.11.30 = zext i8 %call28.11.30 to i32
  %xor.11.30 = xor i32 %conv23.11.30, %conv29.11.30
  %scevgep35.11.30 = getelementptr i8, i8* %a, i64 42
  %4548 = load i8, i8* %scevgep35.11.30, align 1
  %4549 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.30 = call zeroext i8 @mult(i8 zeroext %4548, i8 zeroext %4549)
  %conv35.11.30 = zext i8 %call34.11.30 to i32
  %xor36.11.30 = xor i32 %xor.11.30, %conv35.11.30
  %conv37.11.30 = trunc i32 %xor36.11.30 to i8
  store i8 %conv37.11.30, i8* %scevgep41.11.29, align 1
  %scevgep28.11.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4543, i64 0, i64 0, i64 1
  %4550 = bitcast i8* %scevgep28.11.30 to [61 x [61 x i8]]*
  %scevgep41.11.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4544, i64 0, i64 1, i64 0
  %4551 = bitcast i8* %scevgep41.11.30 to [61 x [61 x i8]]*
  %call16.11.31 = call zeroext i8 (...) @rand()
  store i8 %call16.11.31, i8* %scevgep28.11.30, align 1
  %4552 = load i8, i8* %scevgep28.11.30, align 1
  %conv23.11.31 = zext i8 %4552 to i32
  %4553 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.31 = getelementptr i8, i8* %b, i64 43
  %4554 = load i8, i8* %scevgep34.11.31, align 1
  %call28.11.31 = call zeroext i8 @mult(i8 zeroext %4553, i8 zeroext %4554)
  %conv29.11.31 = zext i8 %call28.11.31 to i32
  %xor.11.31 = xor i32 %conv23.11.31, %conv29.11.31
  %scevgep35.11.31 = getelementptr i8, i8* %a, i64 43
  %4555 = load i8, i8* %scevgep35.11.31, align 1
  %4556 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.31 = call zeroext i8 @mult(i8 zeroext %4555, i8 zeroext %4556)
  %conv35.11.31 = zext i8 %call34.11.31 to i32
  %xor36.11.31 = xor i32 %xor.11.31, %conv35.11.31
  %conv37.11.31 = trunc i32 %xor36.11.31 to i8
  store i8 %conv37.11.31, i8* %scevgep41.11.30, align 1
  %scevgep28.11.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4550, i64 0, i64 0, i64 1
  %4557 = bitcast i8* %scevgep28.11.31 to [61 x [61 x i8]]*
  %scevgep41.11.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4551, i64 0, i64 1, i64 0
  %4558 = bitcast i8* %scevgep41.11.31 to [61 x [61 x i8]]*
  %call16.11.32 = call zeroext i8 (...) @rand()
  store i8 %call16.11.32, i8* %scevgep28.11.31, align 1
  %4559 = load i8, i8* %scevgep28.11.31, align 1
  %conv23.11.32 = zext i8 %4559 to i32
  %4560 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.32 = getelementptr i8, i8* %b, i64 44
  %4561 = load i8, i8* %scevgep34.11.32, align 1
  %call28.11.32 = call zeroext i8 @mult(i8 zeroext %4560, i8 zeroext %4561)
  %conv29.11.32 = zext i8 %call28.11.32 to i32
  %xor.11.32 = xor i32 %conv23.11.32, %conv29.11.32
  %scevgep35.11.32 = getelementptr i8, i8* %a, i64 44
  %4562 = load i8, i8* %scevgep35.11.32, align 1
  %4563 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.32 = call zeroext i8 @mult(i8 zeroext %4562, i8 zeroext %4563)
  %conv35.11.32 = zext i8 %call34.11.32 to i32
  %xor36.11.32 = xor i32 %xor.11.32, %conv35.11.32
  %conv37.11.32 = trunc i32 %xor36.11.32 to i8
  store i8 %conv37.11.32, i8* %scevgep41.11.31, align 1
  %scevgep28.11.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4557, i64 0, i64 0, i64 1
  %4564 = bitcast i8* %scevgep28.11.32 to [61 x [61 x i8]]*
  %scevgep41.11.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4558, i64 0, i64 1, i64 0
  %4565 = bitcast i8* %scevgep41.11.32 to [61 x [61 x i8]]*
  %call16.11.33 = call zeroext i8 (...) @rand()
  store i8 %call16.11.33, i8* %scevgep28.11.32, align 1
  %4566 = load i8, i8* %scevgep28.11.32, align 1
  %conv23.11.33 = zext i8 %4566 to i32
  %4567 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.33 = getelementptr i8, i8* %b, i64 45
  %4568 = load i8, i8* %scevgep34.11.33, align 1
  %call28.11.33 = call zeroext i8 @mult(i8 zeroext %4567, i8 zeroext %4568)
  %conv29.11.33 = zext i8 %call28.11.33 to i32
  %xor.11.33 = xor i32 %conv23.11.33, %conv29.11.33
  %scevgep35.11.33 = getelementptr i8, i8* %a, i64 45
  %4569 = load i8, i8* %scevgep35.11.33, align 1
  %4570 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.33 = call zeroext i8 @mult(i8 zeroext %4569, i8 zeroext %4570)
  %conv35.11.33 = zext i8 %call34.11.33 to i32
  %xor36.11.33 = xor i32 %xor.11.33, %conv35.11.33
  %conv37.11.33 = trunc i32 %xor36.11.33 to i8
  store i8 %conv37.11.33, i8* %scevgep41.11.32, align 1
  %scevgep28.11.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4564, i64 0, i64 0, i64 1
  %4571 = bitcast i8* %scevgep28.11.33 to [61 x [61 x i8]]*
  %scevgep41.11.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4565, i64 0, i64 1, i64 0
  %4572 = bitcast i8* %scevgep41.11.33 to [61 x [61 x i8]]*
  %call16.11.34 = call zeroext i8 (...) @rand()
  store i8 %call16.11.34, i8* %scevgep28.11.33, align 1
  %4573 = load i8, i8* %scevgep28.11.33, align 1
  %conv23.11.34 = zext i8 %4573 to i32
  %4574 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.34 = getelementptr i8, i8* %b, i64 46
  %4575 = load i8, i8* %scevgep34.11.34, align 1
  %call28.11.34 = call zeroext i8 @mult(i8 zeroext %4574, i8 zeroext %4575)
  %conv29.11.34 = zext i8 %call28.11.34 to i32
  %xor.11.34 = xor i32 %conv23.11.34, %conv29.11.34
  %scevgep35.11.34 = getelementptr i8, i8* %a, i64 46
  %4576 = load i8, i8* %scevgep35.11.34, align 1
  %4577 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.34 = call zeroext i8 @mult(i8 zeroext %4576, i8 zeroext %4577)
  %conv35.11.34 = zext i8 %call34.11.34 to i32
  %xor36.11.34 = xor i32 %xor.11.34, %conv35.11.34
  %conv37.11.34 = trunc i32 %xor36.11.34 to i8
  store i8 %conv37.11.34, i8* %scevgep41.11.33, align 1
  %scevgep28.11.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4571, i64 0, i64 0, i64 1
  %4578 = bitcast i8* %scevgep28.11.34 to [61 x [61 x i8]]*
  %scevgep41.11.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4572, i64 0, i64 1, i64 0
  %4579 = bitcast i8* %scevgep41.11.34 to [61 x [61 x i8]]*
  %call16.11.35 = call zeroext i8 (...) @rand()
  store i8 %call16.11.35, i8* %scevgep28.11.34, align 1
  %4580 = load i8, i8* %scevgep28.11.34, align 1
  %conv23.11.35 = zext i8 %4580 to i32
  %4581 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.35 = getelementptr i8, i8* %b, i64 47
  %4582 = load i8, i8* %scevgep34.11.35, align 1
  %call28.11.35 = call zeroext i8 @mult(i8 zeroext %4581, i8 zeroext %4582)
  %conv29.11.35 = zext i8 %call28.11.35 to i32
  %xor.11.35 = xor i32 %conv23.11.35, %conv29.11.35
  %scevgep35.11.35 = getelementptr i8, i8* %a, i64 47
  %4583 = load i8, i8* %scevgep35.11.35, align 1
  %4584 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.35 = call zeroext i8 @mult(i8 zeroext %4583, i8 zeroext %4584)
  %conv35.11.35 = zext i8 %call34.11.35 to i32
  %xor36.11.35 = xor i32 %xor.11.35, %conv35.11.35
  %conv37.11.35 = trunc i32 %xor36.11.35 to i8
  store i8 %conv37.11.35, i8* %scevgep41.11.34, align 1
  %scevgep28.11.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4578, i64 0, i64 0, i64 1
  %4585 = bitcast i8* %scevgep28.11.35 to [61 x [61 x i8]]*
  %scevgep41.11.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4579, i64 0, i64 1, i64 0
  %4586 = bitcast i8* %scevgep41.11.35 to [61 x [61 x i8]]*
  %call16.11.36 = call zeroext i8 (...) @rand()
  store i8 %call16.11.36, i8* %scevgep28.11.35, align 1
  %4587 = load i8, i8* %scevgep28.11.35, align 1
  %conv23.11.36 = zext i8 %4587 to i32
  %4588 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.36 = getelementptr i8, i8* %b, i64 48
  %4589 = load i8, i8* %scevgep34.11.36, align 1
  %call28.11.36 = call zeroext i8 @mult(i8 zeroext %4588, i8 zeroext %4589)
  %conv29.11.36 = zext i8 %call28.11.36 to i32
  %xor.11.36 = xor i32 %conv23.11.36, %conv29.11.36
  %scevgep35.11.36 = getelementptr i8, i8* %a, i64 48
  %4590 = load i8, i8* %scevgep35.11.36, align 1
  %4591 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.36 = call zeroext i8 @mult(i8 zeroext %4590, i8 zeroext %4591)
  %conv35.11.36 = zext i8 %call34.11.36 to i32
  %xor36.11.36 = xor i32 %xor.11.36, %conv35.11.36
  %conv37.11.36 = trunc i32 %xor36.11.36 to i8
  store i8 %conv37.11.36, i8* %scevgep41.11.35, align 1
  %scevgep28.11.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4585, i64 0, i64 0, i64 1
  %4592 = bitcast i8* %scevgep28.11.36 to [61 x [61 x i8]]*
  %scevgep41.11.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4586, i64 0, i64 1, i64 0
  %4593 = bitcast i8* %scevgep41.11.36 to [61 x [61 x i8]]*
  %call16.11.37 = call zeroext i8 (...) @rand()
  store i8 %call16.11.37, i8* %scevgep28.11.36, align 1
  %4594 = load i8, i8* %scevgep28.11.36, align 1
  %conv23.11.37 = zext i8 %4594 to i32
  %4595 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.37 = getelementptr i8, i8* %b, i64 49
  %4596 = load i8, i8* %scevgep34.11.37, align 1
  %call28.11.37 = call zeroext i8 @mult(i8 zeroext %4595, i8 zeroext %4596)
  %conv29.11.37 = zext i8 %call28.11.37 to i32
  %xor.11.37 = xor i32 %conv23.11.37, %conv29.11.37
  %scevgep35.11.37 = getelementptr i8, i8* %a, i64 49
  %4597 = load i8, i8* %scevgep35.11.37, align 1
  %4598 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.37 = call zeroext i8 @mult(i8 zeroext %4597, i8 zeroext %4598)
  %conv35.11.37 = zext i8 %call34.11.37 to i32
  %xor36.11.37 = xor i32 %xor.11.37, %conv35.11.37
  %conv37.11.37 = trunc i32 %xor36.11.37 to i8
  store i8 %conv37.11.37, i8* %scevgep41.11.36, align 1
  %scevgep28.11.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4592, i64 0, i64 0, i64 1
  %4599 = bitcast i8* %scevgep28.11.37 to [61 x [61 x i8]]*
  %scevgep41.11.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4593, i64 0, i64 1, i64 0
  %4600 = bitcast i8* %scevgep41.11.37 to [61 x [61 x i8]]*
  %call16.11.38 = call zeroext i8 (...) @rand()
  store i8 %call16.11.38, i8* %scevgep28.11.37, align 1
  %4601 = load i8, i8* %scevgep28.11.37, align 1
  %conv23.11.38 = zext i8 %4601 to i32
  %4602 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.38 = getelementptr i8, i8* %b, i64 50
  %4603 = load i8, i8* %scevgep34.11.38, align 1
  %call28.11.38 = call zeroext i8 @mult(i8 zeroext %4602, i8 zeroext %4603)
  %conv29.11.38 = zext i8 %call28.11.38 to i32
  %xor.11.38 = xor i32 %conv23.11.38, %conv29.11.38
  %scevgep35.11.38 = getelementptr i8, i8* %a, i64 50
  %4604 = load i8, i8* %scevgep35.11.38, align 1
  %4605 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.38 = call zeroext i8 @mult(i8 zeroext %4604, i8 zeroext %4605)
  %conv35.11.38 = zext i8 %call34.11.38 to i32
  %xor36.11.38 = xor i32 %xor.11.38, %conv35.11.38
  %conv37.11.38 = trunc i32 %xor36.11.38 to i8
  store i8 %conv37.11.38, i8* %scevgep41.11.37, align 1
  %scevgep28.11.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4599, i64 0, i64 0, i64 1
  %4606 = bitcast i8* %scevgep28.11.38 to [61 x [61 x i8]]*
  %scevgep41.11.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4600, i64 0, i64 1, i64 0
  %4607 = bitcast i8* %scevgep41.11.38 to [61 x [61 x i8]]*
  %call16.11.39 = call zeroext i8 (...) @rand()
  store i8 %call16.11.39, i8* %scevgep28.11.38, align 1
  %4608 = load i8, i8* %scevgep28.11.38, align 1
  %conv23.11.39 = zext i8 %4608 to i32
  %4609 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.39 = getelementptr i8, i8* %b, i64 51
  %4610 = load i8, i8* %scevgep34.11.39, align 1
  %call28.11.39 = call zeroext i8 @mult(i8 zeroext %4609, i8 zeroext %4610)
  %conv29.11.39 = zext i8 %call28.11.39 to i32
  %xor.11.39 = xor i32 %conv23.11.39, %conv29.11.39
  %scevgep35.11.39 = getelementptr i8, i8* %a, i64 51
  %4611 = load i8, i8* %scevgep35.11.39, align 1
  %4612 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.39 = call zeroext i8 @mult(i8 zeroext %4611, i8 zeroext %4612)
  %conv35.11.39 = zext i8 %call34.11.39 to i32
  %xor36.11.39 = xor i32 %xor.11.39, %conv35.11.39
  %conv37.11.39 = trunc i32 %xor36.11.39 to i8
  store i8 %conv37.11.39, i8* %scevgep41.11.38, align 1
  %scevgep28.11.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4606, i64 0, i64 0, i64 1
  %4613 = bitcast i8* %scevgep28.11.39 to [61 x [61 x i8]]*
  %scevgep41.11.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4607, i64 0, i64 1, i64 0
  %4614 = bitcast i8* %scevgep41.11.39 to [61 x [61 x i8]]*
  %call16.11.40 = call zeroext i8 (...) @rand()
  store i8 %call16.11.40, i8* %scevgep28.11.39, align 1
  %4615 = load i8, i8* %scevgep28.11.39, align 1
  %conv23.11.40 = zext i8 %4615 to i32
  %4616 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.40 = getelementptr i8, i8* %b, i64 52
  %4617 = load i8, i8* %scevgep34.11.40, align 1
  %call28.11.40 = call zeroext i8 @mult(i8 zeroext %4616, i8 zeroext %4617)
  %conv29.11.40 = zext i8 %call28.11.40 to i32
  %xor.11.40 = xor i32 %conv23.11.40, %conv29.11.40
  %scevgep35.11.40 = getelementptr i8, i8* %a, i64 52
  %4618 = load i8, i8* %scevgep35.11.40, align 1
  %4619 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.40 = call zeroext i8 @mult(i8 zeroext %4618, i8 zeroext %4619)
  %conv35.11.40 = zext i8 %call34.11.40 to i32
  %xor36.11.40 = xor i32 %xor.11.40, %conv35.11.40
  %conv37.11.40 = trunc i32 %xor36.11.40 to i8
  store i8 %conv37.11.40, i8* %scevgep41.11.39, align 1
  %scevgep28.11.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4613, i64 0, i64 0, i64 1
  %4620 = bitcast i8* %scevgep28.11.40 to [61 x [61 x i8]]*
  %scevgep41.11.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4614, i64 0, i64 1, i64 0
  %4621 = bitcast i8* %scevgep41.11.40 to [61 x [61 x i8]]*
  %call16.11.41 = call zeroext i8 (...) @rand()
  store i8 %call16.11.41, i8* %scevgep28.11.40, align 1
  %4622 = load i8, i8* %scevgep28.11.40, align 1
  %conv23.11.41 = zext i8 %4622 to i32
  %4623 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.41 = getelementptr i8, i8* %b, i64 53
  %4624 = load i8, i8* %scevgep34.11.41, align 1
  %call28.11.41 = call zeroext i8 @mult(i8 zeroext %4623, i8 zeroext %4624)
  %conv29.11.41 = zext i8 %call28.11.41 to i32
  %xor.11.41 = xor i32 %conv23.11.41, %conv29.11.41
  %scevgep35.11.41 = getelementptr i8, i8* %a, i64 53
  %4625 = load i8, i8* %scevgep35.11.41, align 1
  %4626 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.41 = call zeroext i8 @mult(i8 zeroext %4625, i8 zeroext %4626)
  %conv35.11.41 = zext i8 %call34.11.41 to i32
  %xor36.11.41 = xor i32 %xor.11.41, %conv35.11.41
  %conv37.11.41 = trunc i32 %xor36.11.41 to i8
  store i8 %conv37.11.41, i8* %scevgep41.11.40, align 1
  %scevgep28.11.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4620, i64 0, i64 0, i64 1
  %4627 = bitcast i8* %scevgep28.11.41 to [61 x [61 x i8]]*
  %scevgep41.11.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4621, i64 0, i64 1, i64 0
  %4628 = bitcast i8* %scevgep41.11.41 to [61 x [61 x i8]]*
  %call16.11.42 = call zeroext i8 (...) @rand()
  store i8 %call16.11.42, i8* %scevgep28.11.41, align 1
  %4629 = load i8, i8* %scevgep28.11.41, align 1
  %conv23.11.42 = zext i8 %4629 to i32
  %4630 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.42 = getelementptr i8, i8* %b, i64 54
  %4631 = load i8, i8* %scevgep34.11.42, align 1
  %call28.11.42 = call zeroext i8 @mult(i8 zeroext %4630, i8 zeroext %4631)
  %conv29.11.42 = zext i8 %call28.11.42 to i32
  %xor.11.42 = xor i32 %conv23.11.42, %conv29.11.42
  %scevgep35.11.42 = getelementptr i8, i8* %a, i64 54
  %4632 = load i8, i8* %scevgep35.11.42, align 1
  %4633 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.42 = call zeroext i8 @mult(i8 zeroext %4632, i8 zeroext %4633)
  %conv35.11.42 = zext i8 %call34.11.42 to i32
  %xor36.11.42 = xor i32 %xor.11.42, %conv35.11.42
  %conv37.11.42 = trunc i32 %xor36.11.42 to i8
  store i8 %conv37.11.42, i8* %scevgep41.11.41, align 1
  %scevgep28.11.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4627, i64 0, i64 0, i64 1
  %4634 = bitcast i8* %scevgep28.11.42 to [61 x [61 x i8]]*
  %scevgep41.11.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4628, i64 0, i64 1, i64 0
  %4635 = bitcast i8* %scevgep41.11.42 to [61 x [61 x i8]]*
  %call16.11.43 = call zeroext i8 (...) @rand()
  store i8 %call16.11.43, i8* %scevgep28.11.42, align 1
  %4636 = load i8, i8* %scevgep28.11.42, align 1
  %conv23.11.43 = zext i8 %4636 to i32
  %4637 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.43 = getelementptr i8, i8* %b, i64 55
  %4638 = load i8, i8* %scevgep34.11.43, align 1
  %call28.11.43 = call zeroext i8 @mult(i8 zeroext %4637, i8 zeroext %4638)
  %conv29.11.43 = zext i8 %call28.11.43 to i32
  %xor.11.43 = xor i32 %conv23.11.43, %conv29.11.43
  %scevgep35.11.43 = getelementptr i8, i8* %a, i64 55
  %4639 = load i8, i8* %scevgep35.11.43, align 1
  %4640 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.43 = call zeroext i8 @mult(i8 zeroext %4639, i8 zeroext %4640)
  %conv35.11.43 = zext i8 %call34.11.43 to i32
  %xor36.11.43 = xor i32 %xor.11.43, %conv35.11.43
  %conv37.11.43 = trunc i32 %xor36.11.43 to i8
  store i8 %conv37.11.43, i8* %scevgep41.11.42, align 1
  %scevgep28.11.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4634, i64 0, i64 0, i64 1
  %4641 = bitcast i8* %scevgep28.11.43 to [61 x [61 x i8]]*
  %scevgep41.11.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4635, i64 0, i64 1, i64 0
  %4642 = bitcast i8* %scevgep41.11.43 to [61 x [61 x i8]]*
  %call16.11.44 = call zeroext i8 (...) @rand()
  store i8 %call16.11.44, i8* %scevgep28.11.43, align 1
  %4643 = load i8, i8* %scevgep28.11.43, align 1
  %conv23.11.44 = zext i8 %4643 to i32
  %4644 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.44 = getelementptr i8, i8* %b, i64 56
  %4645 = load i8, i8* %scevgep34.11.44, align 1
  %call28.11.44 = call zeroext i8 @mult(i8 zeroext %4644, i8 zeroext %4645)
  %conv29.11.44 = zext i8 %call28.11.44 to i32
  %xor.11.44 = xor i32 %conv23.11.44, %conv29.11.44
  %scevgep35.11.44 = getelementptr i8, i8* %a, i64 56
  %4646 = load i8, i8* %scevgep35.11.44, align 1
  %4647 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.44 = call zeroext i8 @mult(i8 zeroext %4646, i8 zeroext %4647)
  %conv35.11.44 = zext i8 %call34.11.44 to i32
  %xor36.11.44 = xor i32 %xor.11.44, %conv35.11.44
  %conv37.11.44 = trunc i32 %xor36.11.44 to i8
  store i8 %conv37.11.44, i8* %scevgep41.11.43, align 1
  %scevgep28.11.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4641, i64 0, i64 0, i64 1
  %4648 = bitcast i8* %scevgep28.11.44 to [61 x [61 x i8]]*
  %scevgep41.11.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4642, i64 0, i64 1, i64 0
  %4649 = bitcast i8* %scevgep41.11.44 to [61 x [61 x i8]]*
  %call16.11.45 = call zeroext i8 (...) @rand()
  store i8 %call16.11.45, i8* %scevgep28.11.44, align 1
  %4650 = load i8, i8* %scevgep28.11.44, align 1
  %conv23.11.45 = zext i8 %4650 to i32
  %4651 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.45 = getelementptr i8, i8* %b, i64 57
  %4652 = load i8, i8* %scevgep34.11.45, align 1
  %call28.11.45 = call zeroext i8 @mult(i8 zeroext %4651, i8 zeroext %4652)
  %conv29.11.45 = zext i8 %call28.11.45 to i32
  %xor.11.45 = xor i32 %conv23.11.45, %conv29.11.45
  %scevgep35.11.45 = getelementptr i8, i8* %a, i64 57
  %4653 = load i8, i8* %scevgep35.11.45, align 1
  %4654 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.45 = call zeroext i8 @mult(i8 zeroext %4653, i8 zeroext %4654)
  %conv35.11.45 = zext i8 %call34.11.45 to i32
  %xor36.11.45 = xor i32 %xor.11.45, %conv35.11.45
  %conv37.11.45 = trunc i32 %xor36.11.45 to i8
  store i8 %conv37.11.45, i8* %scevgep41.11.44, align 1
  %scevgep28.11.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4648, i64 0, i64 0, i64 1
  %4655 = bitcast i8* %scevgep28.11.45 to [61 x [61 x i8]]*
  %scevgep41.11.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4649, i64 0, i64 1, i64 0
  %4656 = bitcast i8* %scevgep41.11.45 to [61 x [61 x i8]]*
  %call16.11.46 = call zeroext i8 (...) @rand()
  store i8 %call16.11.46, i8* %scevgep28.11.45, align 1
  %4657 = load i8, i8* %scevgep28.11.45, align 1
  %conv23.11.46 = zext i8 %4657 to i32
  %4658 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.46 = getelementptr i8, i8* %b, i64 58
  %4659 = load i8, i8* %scevgep34.11.46, align 1
  %call28.11.46 = call zeroext i8 @mult(i8 zeroext %4658, i8 zeroext %4659)
  %conv29.11.46 = zext i8 %call28.11.46 to i32
  %xor.11.46 = xor i32 %conv23.11.46, %conv29.11.46
  %scevgep35.11.46 = getelementptr i8, i8* %a, i64 58
  %4660 = load i8, i8* %scevgep35.11.46, align 1
  %4661 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.46 = call zeroext i8 @mult(i8 zeroext %4660, i8 zeroext %4661)
  %conv35.11.46 = zext i8 %call34.11.46 to i32
  %xor36.11.46 = xor i32 %xor.11.46, %conv35.11.46
  %conv37.11.46 = trunc i32 %xor36.11.46 to i8
  store i8 %conv37.11.46, i8* %scevgep41.11.45, align 1
  %scevgep28.11.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4655, i64 0, i64 0, i64 1
  %4662 = bitcast i8* %scevgep28.11.46 to [61 x [61 x i8]]*
  %scevgep41.11.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4656, i64 0, i64 1, i64 0
  %4663 = bitcast i8* %scevgep41.11.46 to [61 x [61 x i8]]*
  %call16.11.47 = call zeroext i8 (...) @rand()
  store i8 %call16.11.47, i8* %scevgep28.11.46, align 1
  %4664 = load i8, i8* %scevgep28.11.46, align 1
  %conv23.11.47 = zext i8 %4664 to i32
  %4665 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.47 = getelementptr i8, i8* %b, i64 59
  %4666 = load i8, i8* %scevgep34.11.47, align 1
  %call28.11.47 = call zeroext i8 @mult(i8 zeroext %4665, i8 zeroext %4666)
  %conv29.11.47 = zext i8 %call28.11.47 to i32
  %xor.11.47 = xor i32 %conv23.11.47, %conv29.11.47
  %scevgep35.11.47 = getelementptr i8, i8* %a, i64 59
  %4667 = load i8, i8* %scevgep35.11.47, align 1
  %4668 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.47 = call zeroext i8 @mult(i8 zeroext %4667, i8 zeroext %4668)
  %conv35.11.47 = zext i8 %call34.11.47 to i32
  %xor36.11.47 = xor i32 %xor.11.47, %conv35.11.47
  %conv37.11.47 = trunc i32 %xor36.11.47 to i8
  store i8 %conv37.11.47, i8* %scevgep41.11.46, align 1
  %scevgep28.11.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4662, i64 0, i64 0, i64 1
  %scevgep41.11.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4663, i64 0, i64 1, i64 0
  %call16.11.48 = call zeroext i8 (...) @rand()
  store i8 %call16.11.48, i8* %scevgep28.11.47, align 1
  %4669 = load i8, i8* %scevgep28.11.47, align 1
  %conv23.11.48 = zext i8 %4669 to i32
  %4670 = load i8, i8* %arrayidx25.11, align 1
  %scevgep34.11.48 = getelementptr i8, i8* %b, i64 60
  %4671 = load i8, i8* %scevgep34.11.48, align 1
  %call28.11.48 = call zeroext i8 @mult(i8 zeroext %4670, i8 zeroext %4671)
  %conv29.11.48 = zext i8 %call28.11.48 to i32
  %xor.11.48 = xor i32 %conv23.11.48, %conv29.11.48
  %scevgep35.11.48 = getelementptr i8, i8* %a, i64 60
  %4672 = load i8, i8* %scevgep35.11.48, align 1
  %4673 = load i8, i8* %arrayidx33.11, align 1
  %call34.11.48 = call zeroext i8 @mult(i8 zeroext %4672, i8 zeroext %4673)
  %conv35.11.48 = zext i8 %call34.11.48 to i32
  %xor36.11.48 = xor i32 %xor.11.48, %conv35.11.48
  %conv37.11.48 = trunc i32 %xor36.11.48 to i8
  store i8 %conv37.11.48, i8* %scevgep41.11.47, align 1
  %scevgep26.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4333, i64 0, i64 1, i64 1
  %4674 = bitcast i8* %scevgep26.11 to [61 x [61 x i8]]*
  %scevgep39.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4334, i64 0, i64 1, i64 1
  %4675 = bitcast i8* %scevgep39.11 to [61 x [61 x i8]]*
  %arrayidx25.12 = getelementptr inbounds i8, i8* %a, i64 12
  %arrayidx33.12 = getelementptr inbounds i8, i8* %b, i64 12
  %call16.12 = call zeroext i8 (...) @rand()
  store i8 %call16.12, i8* %scevgep26.11, align 1
  %4676 = load i8, i8* %scevgep26.11, align 1
  %conv23.12 = zext i8 %4676 to i32
  %4677 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12 = getelementptr i8, i8* %b, i64 13
  %4678 = load i8, i8* %scevgep34.12, align 1
  %call28.12 = call zeroext i8 @mult(i8 zeroext %4677, i8 zeroext %4678)
  %conv29.12 = zext i8 %call28.12 to i32
  %xor.12 = xor i32 %conv23.12, %conv29.12
  %scevgep35.12 = getelementptr i8, i8* %a, i64 13
  %4679 = load i8, i8* %scevgep35.12, align 1
  %4680 = load i8, i8* %arrayidx33.12, align 1
  %call34.12 = call zeroext i8 @mult(i8 zeroext %4679, i8 zeroext %4680)
  %conv35.12 = zext i8 %call34.12 to i32
  %xor36.12 = xor i32 %xor.12, %conv35.12
  %conv37.12 = trunc i32 %xor36.12 to i8
  store i8 %conv37.12, i8* %scevgep39.11, align 1
  %scevgep28.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4674, i64 0, i64 0, i64 1
  %4681 = bitcast i8* %scevgep28.12 to [61 x [61 x i8]]*
  %scevgep41.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4675, i64 0, i64 1, i64 0
  %4682 = bitcast i8* %scevgep41.12 to [61 x [61 x i8]]*
  %call16.12.1 = call zeroext i8 (...) @rand()
  store i8 %call16.12.1, i8* %scevgep28.12, align 1
  %4683 = load i8, i8* %scevgep28.12, align 1
  %conv23.12.1 = zext i8 %4683 to i32
  %4684 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.1 = getelementptr i8, i8* %b, i64 14
  %4685 = load i8, i8* %scevgep34.12.1, align 1
  %call28.12.1 = call zeroext i8 @mult(i8 zeroext %4684, i8 zeroext %4685)
  %conv29.12.1 = zext i8 %call28.12.1 to i32
  %xor.12.1 = xor i32 %conv23.12.1, %conv29.12.1
  %scevgep35.12.1 = getelementptr i8, i8* %a, i64 14
  %4686 = load i8, i8* %scevgep35.12.1, align 1
  %4687 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.1 = call zeroext i8 @mult(i8 zeroext %4686, i8 zeroext %4687)
  %conv35.12.1 = zext i8 %call34.12.1 to i32
  %xor36.12.1 = xor i32 %xor.12.1, %conv35.12.1
  %conv37.12.1 = trunc i32 %xor36.12.1 to i8
  store i8 %conv37.12.1, i8* %scevgep41.12, align 1
  %scevgep28.12.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4681, i64 0, i64 0, i64 1
  %4688 = bitcast i8* %scevgep28.12.1 to [61 x [61 x i8]]*
  %scevgep41.12.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4682, i64 0, i64 1, i64 0
  %4689 = bitcast i8* %scevgep41.12.1 to [61 x [61 x i8]]*
  %call16.12.2 = call zeroext i8 (...) @rand()
  store i8 %call16.12.2, i8* %scevgep28.12.1, align 1
  %4690 = load i8, i8* %scevgep28.12.1, align 1
  %conv23.12.2 = zext i8 %4690 to i32
  %4691 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.2 = getelementptr i8, i8* %b, i64 15
  %4692 = load i8, i8* %scevgep34.12.2, align 1
  %call28.12.2 = call zeroext i8 @mult(i8 zeroext %4691, i8 zeroext %4692)
  %conv29.12.2 = zext i8 %call28.12.2 to i32
  %xor.12.2 = xor i32 %conv23.12.2, %conv29.12.2
  %scevgep35.12.2 = getelementptr i8, i8* %a, i64 15
  %4693 = load i8, i8* %scevgep35.12.2, align 1
  %4694 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.2 = call zeroext i8 @mult(i8 zeroext %4693, i8 zeroext %4694)
  %conv35.12.2 = zext i8 %call34.12.2 to i32
  %xor36.12.2 = xor i32 %xor.12.2, %conv35.12.2
  %conv37.12.2 = trunc i32 %xor36.12.2 to i8
  store i8 %conv37.12.2, i8* %scevgep41.12.1, align 1
  %scevgep28.12.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4688, i64 0, i64 0, i64 1
  %4695 = bitcast i8* %scevgep28.12.2 to [61 x [61 x i8]]*
  %scevgep41.12.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4689, i64 0, i64 1, i64 0
  %4696 = bitcast i8* %scevgep41.12.2 to [61 x [61 x i8]]*
  %call16.12.3 = call zeroext i8 (...) @rand()
  store i8 %call16.12.3, i8* %scevgep28.12.2, align 1
  %4697 = load i8, i8* %scevgep28.12.2, align 1
  %conv23.12.3 = zext i8 %4697 to i32
  %4698 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.3 = getelementptr i8, i8* %b, i64 16
  %4699 = load i8, i8* %scevgep34.12.3, align 1
  %call28.12.3 = call zeroext i8 @mult(i8 zeroext %4698, i8 zeroext %4699)
  %conv29.12.3 = zext i8 %call28.12.3 to i32
  %xor.12.3 = xor i32 %conv23.12.3, %conv29.12.3
  %scevgep35.12.3 = getelementptr i8, i8* %a, i64 16
  %4700 = load i8, i8* %scevgep35.12.3, align 1
  %4701 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.3 = call zeroext i8 @mult(i8 zeroext %4700, i8 zeroext %4701)
  %conv35.12.3 = zext i8 %call34.12.3 to i32
  %xor36.12.3 = xor i32 %xor.12.3, %conv35.12.3
  %conv37.12.3 = trunc i32 %xor36.12.3 to i8
  store i8 %conv37.12.3, i8* %scevgep41.12.2, align 1
  %scevgep28.12.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4695, i64 0, i64 0, i64 1
  %4702 = bitcast i8* %scevgep28.12.3 to [61 x [61 x i8]]*
  %scevgep41.12.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4696, i64 0, i64 1, i64 0
  %4703 = bitcast i8* %scevgep41.12.3 to [61 x [61 x i8]]*
  %call16.12.4 = call zeroext i8 (...) @rand()
  store i8 %call16.12.4, i8* %scevgep28.12.3, align 1
  %4704 = load i8, i8* %scevgep28.12.3, align 1
  %conv23.12.4 = zext i8 %4704 to i32
  %4705 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.4 = getelementptr i8, i8* %b, i64 17
  %4706 = load i8, i8* %scevgep34.12.4, align 1
  %call28.12.4 = call zeroext i8 @mult(i8 zeroext %4705, i8 zeroext %4706)
  %conv29.12.4 = zext i8 %call28.12.4 to i32
  %xor.12.4 = xor i32 %conv23.12.4, %conv29.12.4
  %scevgep35.12.4 = getelementptr i8, i8* %a, i64 17
  %4707 = load i8, i8* %scevgep35.12.4, align 1
  %4708 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.4 = call zeroext i8 @mult(i8 zeroext %4707, i8 zeroext %4708)
  %conv35.12.4 = zext i8 %call34.12.4 to i32
  %xor36.12.4 = xor i32 %xor.12.4, %conv35.12.4
  %conv37.12.4 = trunc i32 %xor36.12.4 to i8
  store i8 %conv37.12.4, i8* %scevgep41.12.3, align 1
  %scevgep28.12.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4702, i64 0, i64 0, i64 1
  %4709 = bitcast i8* %scevgep28.12.4 to [61 x [61 x i8]]*
  %scevgep41.12.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4703, i64 0, i64 1, i64 0
  %4710 = bitcast i8* %scevgep41.12.4 to [61 x [61 x i8]]*
  %call16.12.5 = call zeroext i8 (...) @rand()
  store i8 %call16.12.5, i8* %scevgep28.12.4, align 1
  %4711 = load i8, i8* %scevgep28.12.4, align 1
  %conv23.12.5 = zext i8 %4711 to i32
  %4712 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.5 = getelementptr i8, i8* %b, i64 18
  %4713 = load i8, i8* %scevgep34.12.5, align 1
  %call28.12.5 = call zeroext i8 @mult(i8 zeroext %4712, i8 zeroext %4713)
  %conv29.12.5 = zext i8 %call28.12.5 to i32
  %xor.12.5 = xor i32 %conv23.12.5, %conv29.12.5
  %scevgep35.12.5 = getelementptr i8, i8* %a, i64 18
  %4714 = load i8, i8* %scevgep35.12.5, align 1
  %4715 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.5 = call zeroext i8 @mult(i8 zeroext %4714, i8 zeroext %4715)
  %conv35.12.5 = zext i8 %call34.12.5 to i32
  %xor36.12.5 = xor i32 %xor.12.5, %conv35.12.5
  %conv37.12.5 = trunc i32 %xor36.12.5 to i8
  store i8 %conv37.12.5, i8* %scevgep41.12.4, align 1
  %scevgep28.12.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4709, i64 0, i64 0, i64 1
  %4716 = bitcast i8* %scevgep28.12.5 to [61 x [61 x i8]]*
  %scevgep41.12.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4710, i64 0, i64 1, i64 0
  %4717 = bitcast i8* %scevgep41.12.5 to [61 x [61 x i8]]*
  %call16.12.6 = call zeroext i8 (...) @rand()
  store i8 %call16.12.6, i8* %scevgep28.12.5, align 1
  %4718 = load i8, i8* %scevgep28.12.5, align 1
  %conv23.12.6 = zext i8 %4718 to i32
  %4719 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.6 = getelementptr i8, i8* %b, i64 19
  %4720 = load i8, i8* %scevgep34.12.6, align 1
  %call28.12.6 = call zeroext i8 @mult(i8 zeroext %4719, i8 zeroext %4720)
  %conv29.12.6 = zext i8 %call28.12.6 to i32
  %xor.12.6 = xor i32 %conv23.12.6, %conv29.12.6
  %scevgep35.12.6 = getelementptr i8, i8* %a, i64 19
  %4721 = load i8, i8* %scevgep35.12.6, align 1
  %4722 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.6 = call zeroext i8 @mult(i8 zeroext %4721, i8 zeroext %4722)
  %conv35.12.6 = zext i8 %call34.12.6 to i32
  %xor36.12.6 = xor i32 %xor.12.6, %conv35.12.6
  %conv37.12.6 = trunc i32 %xor36.12.6 to i8
  store i8 %conv37.12.6, i8* %scevgep41.12.5, align 1
  %scevgep28.12.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4716, i64 0, i64 0, i64 1
  %4723 = bitcast i8* %scevgep28.12.6 to [61 x [61 x i8]]*
  %scevgep41.12.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4717, i64 0, i64 1, i64 0
  %4724 = bitcast i8* %scevgep41.12.6 to [61 x [61 x i8]]*
  %call16.12.7 = call zeroext i8 (...) @rand()
  store i8 %call16.12.7, i8* %scevgep28.12.6, align 1
  %4725 = load i8, i8* %scevgep28.12.6, align 1
  %conv23.12.7 = zext i8 %4725 to i32
  %4726 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.7 = getelementptr i8, i8* %b, i64 20
  %4727 = load i8, i8* %scevgep34.12.7, align 1
  %call28.12.7 = call zeroext i8 @mult(i8 zeroext %4726, i8 zeroext %4727)
  %conv29.12.7 = zext i8 %call28.12.7 to i32
  %xor.12.7 = xor i32 %conv23.12.7, %conv29.12.7
  %scevgep35.12.7 = getelementptr i8, i8* %a, i64 20
  %4728 = load i8, i8* %scevgep35.12.7, align 1
  %4729 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.7 = call zeroext i8 @mult(i8 zeroext %4728, i8 zeroext %4729)
  %conv35.12.7 = zext i8 %call34.12.7 to i32
  %xor36.12.7 = xor i32 %xor.12.7, %conv35.12.7
  %conv37.12.7 = trunc i32 %xor36.12.7 to i8
  store i8 %conv37.12.7, i8* %scevgep41.12.6, align 1
  %scevgep28.12.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4723, i64 0, i64 0, i64 1
  %4730 = bitcast i8* %scevgep28.12.7 to [61 x [61 x i8]]*
  %scevgep41.12.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4724, i64 0, i64 1, i64 0
  %4731 = bitcast i8* %scevgep41.12.7 to [61 x [61 x i8]]*
  %call16.12.8 = call zeroext i8 (...) @rand()
  store i8 %call16.12.8, i8* %scevgep28.12.7, align 1
  %4732 = load i8, i8* %scevgep28.12.7, align 1
  %conv23.12.8 = zext i8 %4732 to i32
  %4733 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.8 = getelementptr i8, i8* %b, i64 21
  %4734 = load i8, i8* %scevgep34.12.8, align 1
  %call28.12.8 = call zeroext i8 @mult(i8 zeroext %4733, i8 zeroext %4734)
  %conv29.12.8 = zext i8 %call28.12.8 to i32
  %xor.12.8 = xor i32 %conv23.12.8, %conv29.12.8
  %scevgep35.12.8 = getelementptr i8, i8* %a, i64 21
  %4735 = load i8, i8* %scevgep35.12.8, align 1
  %4736 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.8 = call zeroext i8 @mult(i8 zeroext %4735, i8 zeroext %4736)
  %conv35.12.8 = zext i8 %call34.12.8 to i32
  %xor36.12.8 = xor i32 %xor.12.8, %conv35.12.8
  %conv37.12.8 = trunc i32 %xor36.12.8 to i8
  store i8 %conv37.12.8, i8* %scevgep41.12.7, align 1
  %scevgep28.12.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4730, i64 0, i64 0, i64 1
  %4737 = bitcast i8* %scevgep28.12.8 to [61 x [61 x i8]]*
  %scevgep41.12.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4731, i64 0, i64 1, i64 0
  %4738 = bitcast i8* %scevgep41.12.8 to [61 x [61 x i8]]*
  %call16.12.9 = call zeroext i8 (...) @rand()
  store i8 %call16.12.9, i8* %scevgep28.12.8, align 1
  %4739 = load i8, i8* %scevgep28.12.8, align 1
  %conv23.12.9 = zext i8 %4739 to i32
  %4740 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.9 = getelementptr i8, i8* %b, i64 22
  %4741 = load i8, i8* %scevgep34.12.9, align 1
  %call28.12.9 = call zeroext i8 @mult(i8 zeroext %4740, i8 zeroext %4741)
  %conv29.12.9 = zext i8 %call28.12.9 to i32
  %xor.12.9 = xor i32 %conv23.12.9, %conv29.12.9
  %scevgep35.12.9 = getelementptr i8, i8* %a, i64 22
  %4742 = load i8, i8* %scevgep35.12.9, align 1
  %4743 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.9 = call zeroext i8 @mult(i8 zeroext %4742, i8 zeroext %4743)
  %conv35.12.9 = zext i8 %call34.12.9 to i32
  %xor36.12.9 = xor i32 %xor.12.9, %conv35.12.9
  %conv37.12.9 = trunc i32 %xor36.12.9 to i8
  store i8 %conv37.12.9, i8* %scevgep41.12.8, align 1
  %scevgep28.12.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4737, i64 0, i64 0, i64 1
  %4744 = bitcast i8* %scevgep28.12.9 to [61 x [61 x i8]]*
  %scevgep41.12.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4738, i64 0, i64 1, i64 0
  %4745 = bitcast i8* %scevgep41.12.9 to [61 x [61 x i8]]*
  %call16.12.10 = call zeroext i8 (...) @rand()
  store i8 %call16.12.10, i8* %scevgep28.12.9, align 1
  %4746 = load i8, i8* %scevgep28.12.9, align 1
  %conv23.12.10 = zext i8 %4746 to i32
  %4747 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.10 = getelementptr i8, i8* %b, i64 23
  %4748 = load i8, i8* %scevgep34.12.10, align 1
  %call28.12.10 = call zeroext i8 @mult(i8 zeroext %4747, i8 zeroext %4748)
  %conv29.12.10 = zext i8 %call28.12.10 to i32
  %xor.12.10 = xor i32 %conv23.12.10, %conv29.12.10
  %scevgep35.12.10 = getelementptr i8, i8* %a, i64 23
  %4749 = load i8, i8* %scevgep35.12.10, align 1
  %4750 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.10 = call zeroext i8 @mult(i8 zeroext %4749, i8 zeroext %4750)
  %conv35.12.10 = zext i8 %call34.12.10 to i32
  %xor36.12.10 = xor i32 %xor.12.10, %conv35.12.10
  %conv37.12.10 = trunc i32 %xor36.12.10 to i8
  store i8 %conv37.12.10, i8* %scevgep41.12.9, align 1
  %scevgep28.12.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4744, i64 0, i64 0, i64 1
  %4751 = bitcast i8* %scevgep28.12.10 to [61 x [61 x i8]]*
  %scevgep41.12.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4745, i64 0, i64 1, i64 0
  %4752 = bitcast i8* %scevgep41.12.10 to [61 x [61 x i8]]*
  %call16.12.11 = call zeroext i8 (...) @rand()
  store i8 %call16.12.11, i8* %scevgep28.12.10, align 1
  %4753 = load i8, i8* %scevgep28.12.10, align 1
  %conv23.12.11 = zext i8 %4753 to i32
  %4754 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.11 = getelementptr i8, i8* %b, i64 24
  %4755 = load i8, i8* %scevgep34.12.11, align 1
  %call28.12.11 = call zeroext i8 @mult(i8 zeroext %4754, i8 zeroext %4755)
  %conv29.12.11 = zext i8 %call28.12.11 to i32
  %xor.12.11 = xor i32 %conv23.12.11, %conv29.12.11
  %scevgep35.12.11 = getelementptr i8, i8* %a, i64 24
  %4756 = load i8, i8* %scevgep35.12.11, align 1
  %4757 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.11 = call zeroext i8 @mult(i8 zeroext %4756, i8 zeroext %4757)
  %conv35.12.11 = zext i8 %call34.12.11 to i32
  %xor36.12.11 = xor i32 %xor.12.11, %conv35.12.11
  %conv37.12.11 = trunc i32 %xor36.12.11 to i8
  store i8 %conv37.12.11, i8* %scevgep41.12.10, align 1
  %scevgep28.12.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4751, i64 0, i64 0, i64 1
  %4758 = bitcast i8* %scevgep28.12.11 to [61 x [61 x i8]]*
  %scevgep41.12.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4752, i64 0, i64 1, i64 0
  %4759 = bitcast i8* %scevgep41.12.11 to [61 x [61 x i8]]*
  %call16.12.12 = call zeroext i8 (...) @rand()
  store i8 %call16.12.12, i8* %scevgep28.12.11, align 1
  %4760 = load i8, i8* %scevgep28.12.11, align 1
  %conv23.12.12 = zext i8 %4760 to i32
  %4761 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.12 = getelementptr i8, i8* %b, i64 25
  %4762 = load i8, i8* %scevgep34.12.12, align 1
  %call28.12.12 = call zeroext i8 @mult(i8 zeroext %4761, i8 zeroext %4762)
  %conv29.12.12 = zext i8 %call28.12.12 to i32
  %xor.12.12 = xor i32 %conv23.12.12, %conv29.12.12
  %scevgep35.12.12 = getelementptr i8, i8* %a, i64 25
  %4763 = load i8, i8* %scevgep35.12.12, align 1
  %4764 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.12 = call zeroext i8 @mult(i8 zeroext %4763, i8 zeroext %4764)
  %conv35.12.12 = zext i8 %call34.12.12 to i32
  %xor36.12.12 = xor i32 %xor.12.12, %conv35.12.12
  %conv37.12.12 = trunc i32 %xor36.12.12 to i8
  store i8 %conv37.12.12, i8* %scevgep41.12.11, align 1
  %scevgep28.12.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4758, i64 0, i64 0, i64 1
  %4765 = bitcast i8* %scevgep28.12.12 to [61 x [61 x i8]]*
  %scevgep41.12.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4759, i64 0, i64 1, i64 0
  %4766 = bitcast i8* %scevgep41.12.12 to [61 x [61 x i8]]*
  %call16.12.13 = call zeroext i8 (...) @rand()
  store i8 %call16.12.13, i8* %scevgep28.12.12, align 1
  %4767 = load i8, i8* %scevgep28.12.12, align 1
  %conv23.12.13 = zext i8 %4767 to i32
  %4768 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.13 = getelementptr i8, i8* %b, i64 26
  %4769 = load i8, i8* %scevgep34.12.13, align 1
  %call28.12.13 = call zeroext i8 @mult(i8 zeroext %4768, i8 zeroext %4769)
  %conv29.12.13 = zext i8 %call28.12.13 to i32
  %xor.12.13 = xor i32 %conv23.12.13, %conv29.12.13
  %scevgep35.12.13 = getelementptr i8, i8* %a, i64 26
  %4770 = load i8, i8* %scevgep35.12.13, align 1
  %4771 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.13 = call zeroext i8 @mult(i8 zeroext %4770, i8 zeroext %4771)
  %conv35.12.13 = zext i8 %call34.12.13 to i32
  %xor36.12.13 = xor i32 %xor.12.13, %conv35.12.13
  %conv37.12.13 = trunc i32 %xor36.12.13 to i8
  store i8 %conv37.12.13, i8* %scevgep41.12.12, align 1
  %scevgep28.12.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4765, i64 0, i64 0, i64 1
  %4772 = bitcast i8* %scevgep28.12.13 to [61 x [61 x i8]]*
  %scevgep41.12.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4766, i64 0, i64 1, i64 0
  %4773 = bitcast i8* %scevgep41.12.13 to [61 x [61 x i8]]*
  %call16.12.14 = call zeroext i8 (...) @rand()
  store i8 %call16.12.14, i8* %scevgep28.12.13, align 1
  %4774 = load i8, i8* %scevgep28.12.13, align 1
  %conv23.12.14 = zext i8 %4774 to i32
  %4775 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.14 = getelementptr i8, i8* %b, i64 27
  %4776 = load i8, i8* %scevgep34.12.14, align 1
  %call28.12.14 = call zeroext i8 @mult(i8 zeroext %4775, i8 zeroext %4776)
  %conv29.12.14 = zext i8 %call28.12.14 to i32
  %xor.12.14 = xor i32 %conv23.12.14, %conv29.12.14
  %scevgep35.12.14 = getelementptr i8, i8* %a, i64 27
  %4777 = load i8, i8* %scevgep35.12.14, align 1
  %4778 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.14 = call zeroext i8 @mult(i8 zeroext %4777, i8 zeroext %4778)
  %conv35.12.14 = zext i8 %call34.12.14 to i32
  %xor36.12.14 = xor i32 %xor.12.14, %conv35.12.14
  %conv37.12.14 = trunc i32 %xor36.12.14 to i8
  store i8 %conv37.12.14, i8* %scevgep41.12.13, align 1
  %scevgep28.12.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4772, i64 0, i64 0, i64 1
  %4779 = bitcast i8* %scevgep28.12.14 to [61 x [61 x i8]]*
  %scevgep41.12.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4773, i64 0, i64 1, i64 0
  %4780 = bitcast i8* %scevgep41.12.14 to [61 x [61 x i8]]*
  %call16.12.15 = call zeroext i8 (...) @rand()
  store i8 %call16.12.15, i8* %scevgep28.12.14, align 1
  %4781 = load i8, i8* %scevgep28.12.14, align 1
  %conv23.12.15 = zext i8 %4781 to i32
  %4782 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.15 = getelementptr i8, i8* %b, i64 28
  %4783 = load i8, i8* %scevgep34.12.15, align 1
  %call28.12.15 = call zeroext i8 @mult(i8 zeroext %4782, i8 zeroext %4783)
  %conv29.12.15 = zext i8 %call28.12.15 to i32
  %xor.12.15 = xor i32 %conv23.12.15, %conv29.12.15
  %scevgep35.12.15 = getelementptr i8, i8* %a, i64 28
  %4784 = load i8, i8* %scevgep35.12.15, align 1
  %4785 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.15 = call zeroext i8 @mult(i8 zeroext %4784, i8 zeroext %4785)
  %conv35.12.15 = zext i8 %call34.12.15 to i32
  %xor36.12.15 = xor i32 %xor.12.15, %conv35.12.15
  %conv37.12.15 = trunc i32 %xor36.12.15 to i8
  store i8 %conv37.12.15, i8* %scevgep41.12.14, align 1
  %scevgep28.12.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4779, i64 0, i64 0, i64 1
  %4786 = bitcast i8* %scevgep28.12.15 to [61 x [61 x i8]]*
  %scevgep41.12.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4780, i64 0, i64 1, i64 0
  %4787 = bitcast i8* %scevgep41.12.15 to [61 x [61 x i8]]*
  %call16.12.16 = call zeroext i8 (...) @rand()
  store i8 %call16.12.16, i8* %scevgep28.12.15, align 1
  %4788 = load i8, i8* %scevgep28.12.15, align 1
  %conv23.12.16 = zext i8 %4788 to i32
  %4789 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.16 = getelementptr i8, i8* %b, i64 29
  %4790 = load i8, i8* %scevgep34.12.16, align 1
  %call28.12.16 = call zeroext i8 @mult(i8 zeroext %4789, i8 zeroext %4790)
  %conv29.12.16 = zext i8 %call28.12.16 to i32
  %xor.12.16 = xor i32 %conv23.12.16, %conv29.12.16
  %scevgep35.12.16 = getelementptr i8, i8* %a, i64 29
  %4791 = load i8, i8* %scevgep35.12.16, align 1
  %4792 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.16 = call zeroext i8 @mult(i8 zeroext %4791, i8 zeroext %4792)
  %conv35.12.16 = zext i8 %call34.12.16 to i32
  %xor36.12.16 = xor i32 %xor.12.16, %conv35.12.16
  %conv37.12.16 = trunc i32 %xor36.12.16 to i8
  store i8 %conv37.12.16, i8* %scevgep41.12.15, align 1
  %scevgep28.12.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4786, i64 0, i64 0, i64 1
  %4793 = bitcast i8* %scevgep28.12.16 to [61 x [61 x i8]]*
  %scevgep41.12.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4787, i64 0, i64 1, i64 0
  %4794 = bitcast i8* %scevgep41.12.16 to [61 x [61 x i8]]*
  %call16.12.17 = call zeroext i8 (...) @rand()
  store i8 %call16.12.17, i8* %scevgep28.12.16, align 1
  %4795 = load i8, i8* %scevgep28.12.16, align 1
  %conv23.12.17 = zext i8 %4795 to i32
  %4796 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.17 = getelementptr i8, i8* %b, i64 30
  %4797 = load i8, i8* %scevgep34.12.17, align 1
  %call28.12.17 = call zeroext i8 @mult(i8 zeroext %4796, i8 zeroext %4797)
  %conv29.12.17 = zext i8 %call28.12.17 to i32
  %xor.12.17 = xor i32 %conv23.12.17, %conv29.12.17
  %scevgep35.12.17 = getelementptr i8, i8* %a, i64 30
  %4798 = load i8, i8* %scevgep35.12.17, align 1
  %4799 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.17 = call zeroext i8 @mult(i8 zeroext %4798, i8 zeroext %4799)
  %conv35.12.17 = zext i8 %call34.12.17 to i32
  %xor36.12.17 = xor i32 %xor.12.17, %conv35.12.17
  %conv37.12.17 = trunc i32 %xor36.12.17 to i8
  store i8 %conv37.12.17, i8* %scevgep41.12.16, align 1
  %scevgep28.12.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4793, i64 0, i64 0, i64 1
  %4800 = bitcast i8* %scevgep28.12.17 to [61 x [61 x i8]]*
  %scevgep41.12.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4794, i64 0, i64 1, i64 0
  %4801 = bitcast i8* %scevgep41.12.17 to [61 x [61 x i8]]*
  %call16.12.18 = call zeroext i8 (...) @rand()
  store i8 %call16.12.18, i8* %scevgep28.12.17, align 1
  %4802 = load i8, i8* %scevgep28.12.17, align 1
  %conv23.12.18 = zext i8 %4802 to i32
  %4803 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.18 = getelementptr i8, i8* %b, i64 31
  %4804 = load i8, i8* %scevgep34.12.18, align 1
  %call28.12.18 = call zeroext i8 @mult(i8 zeroext %4803, i8 zeroext %4804)
  %conv29.12.18 = zext i8 %call28.12.18 to i32
  %xor.12.18 = xor i32 %conv23.12.18, %conv29.12.18
  %scevgep35.12.18 = getelementptr i8, i8* %a, i64 31
  %4805 = load i8, i8* %scevgep35.12.18, align 1
  %4806 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.18 = call zeroext i8 @mult(i8 zeroext %4805, i8 zeroext %4806)
  %conv35.12.18 = zext i8 %call34.12.18 to i32
  %xor36.12.18 = xor i32 %xor.12.18, %conv35.12.18
  %conv37.12.18 = trunc i32 %xor36.12.18 to i8
  store i8 %conv37.12.18, i8* %scevgep41.12.17, align 1
  %scevgep28.12.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4800, i64 0, i64 0, i64 1
  %4807 = bitcast i8* %scevgep28.12.18 to [61 x [61 x i8]]*
  %scevgep41.12.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4801, i64 0, i64 1, i64 0
  %4808 = bitcast i8* %scevgep41.12.18 to [61 x [61 x i8]]*
  %call16.12.19 = call zeroext i8 (...) @rand()
  store i8 %call16.12.19, i8* %scevgep28.12.18, align 1
  %4809 = load i8, i8* %scevgep28.12.18, align 1
  %conv23.12.19 = zext i8 %4809 to i32
  %4810 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.19 = getelementptr i8, i8* %b, i64 32
  %4811 = load i8, i8* %scevgep34.12.19, align 1
  %call28.12.19 = call zeroext i8 @mult(i8 zeroext %4810, i8 zeroext %4811)
  %conv29.12.19 = zext i8 %call28.12.19 to i32
  %xor.12.19 = xor i32 %conv23.12.19, %conv29.12.19
  %scevgep35.12.19 = getelementptr i8, i8* %a, i64 32
  %4812 = load i8, i8* %scevgep35.12.19, align 1
  %4813 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.19 = call zeroext i8 @mult(i8 zeroext %4812, i8 zeroext %4813)
  %conv35.12.19 = zext i8 %call34.12.19 to i32
  %xor36.12.19 = xor i32 %xor.12.19, %conv35.12.19
  %conv37.12.19 = trunc i32 %xor36.12.19 to i8
  store i8 %conv37.12.19, i8* %scevgep41.12.18, align 1
  %scevgep28.12.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4807, i64 0, i64 0, i64 1
  %4814 = bitcast i8* %scevgep28.12.19 to [61 x [61 x i8]]*
  %scevgep41.12.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4808, i64 0, i64 1, i64 0
  %4815 = bitcast i8* %scevgep41.12.19 to [61 x [61 x i8]]*
  %call16.12.20 = call zeroext i8 (...) @rand()
  store i8 %call16.12.20, i8* %scevgep28.12.19, align 1
  %4816 = load i8, i8* %scevgep28.12.19, align 1
  %conv23.12.20 = zext i8 %4816 to i32
  %4817 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.20 = getelementptr i8, i8* %b, i64 33
  %4818 = load i8, i8* %scevgep34.12.20, align 1
  %call28.12.20 = call zeroext i8 @mult(i8 zeroext %4817, i8 zeroext %4818)
  %conv29.12.20 = zext i8 %call28.12.20 to i32
  %xor.12.20 = xor i32 %conv23.12.20, %conv29.12.20
  %scevgep35.12.20 = getelementptr i8, i8* %a, i64 33
  %4819 = load i8, i8* %scevgep35.12.20, align 1
  %4820 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.20 = call zeroext i8 @mult(i8 zeroext %4819, i8 zeroext %4820)
  %conv35.12.20 = zext i8 %call34.12.20 to i32
  %xor36.12.20 = xor i32 %xor.12.20, %conv35.12.20
  %conv37.12.20 = trunc i32 %xor36.12.20 to i8
  store i8 %conv37.12.20, i8* %scevgep41.12.19, align 1
  %scevgep28.12.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4814, i64 0, i64 0, i64 1
  %4821 = bitcast i8* %scevgep28.12.20 to [61 x [61 x i8]]*
  %scevgep41.12.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4815, i64 0, i64 1, i64 0
  %4822 = bitcast i8* %scevgep41.12.20 to [61 x [61 x i8]]*
  %call16.12.21 = call zeroext i8 (...) @rand()
  store i8 %call16.12.21, i8* %scevgep28.12.20, align 1
  %4823 = load i8, i8* %scevgep28.12.20, align 1
  %conv23.12.21 = zext i8 %4823 to i32
  %4824 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.21 = getelementptr i8, i8* %b, i64 34
  %4825 = load i8, i8* %scevgep34.12.21, align 1
  %call28.12.21 = call zeroext i8 @mult(i8 zeroext %4824, i8 zeroext %4825)
  %conv29.12.21 = zext i8 %call28.12.21 to i32
  %xor.12.21 = xor i32 %conv23.12.21, %conv29.12.21
  %scevgep35.12.21 = getelementptr i8, i8* %a, i64 34
  %4826 = load i8, i8* %scevgep35.12.21, align 1
  %4827 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.21 = call zeroext i8 @mult(i8 zeroext %4826, i8 zeroext %4827)
  %conv35.12.21 = zext i8 %call34.12.21 to i32
  %xor36.12.21 = xor i32 %xor.12.21, %conv35.12.21
  %conv37.12.21 = trunc i32 %xor36.12.21 to i8
  store i8 %conv37.12.21, i8* %scevgep41.12.20, align 1
  %scevgep28.12.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4821, i64 0, i64 0, i64 1
  %4828 = bitcast i8* %scevgep28.12.21 to [61 x [61 x i8]]*
  %scevgep41.12.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4822, i64 0, i64 1, i64 0
  %4829 = bitcast i8* %scevgep41.12.21 to [61 x [61 x i8]]*
  %call16.12.22 = call zeroext i8 (...) @rand()
  store i8 %call16.12.22, i8* %scevgep28.12.21, align 1
  %4830 = load i8, i8* %scevgep28.12.21, align 1
  %conv23.12.22 = zext i8 %4830 to i32
  %4831 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.22 = getelementptr i8, i8* %b, i64 35
  %4832 = load i8, i8* %scevgep34.12.22, align 1
  %call28.12.22 = call zeroext i8 @mult(i8 zeroext %4831, i8 zeroext %4832)
  %conv29.12.22 = zext i8 %call28.12.22 to i32
  %xor.12.22 = xor i32 %conv23.12.22, %conv29.12.22
  %scevgep35.12.22 = getelementptr i8, i8* %a, i64 35
  %4833 = load i8, i8* %scevgep35.12.22, align 1
  %4834 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.22 = call zeroext i8 @mult(i8 zeroext %4833, i8 zeroext %4834)
  %conv35.12.22 = zext i8 %call34.12.22 to i32
  %xor36.12.22 = xor i32 %xor.12.22, %conv35.12.22
  %conv37.12.22 = trunc i32 %xor36.12.22 to i8
  store i8 %conv37.12.22, i8* %scevgep41.12.21, align 1
  %scevgep28.12.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4828, i64 0, i64 0, i64 1
  %4835 = bitcast i8* %scevgep28.12.22 to [61 x [61 x i8]]*
  %scevgep41.12.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4829, i64 0, i64 1, i64 0
  %4836 = bitcast i8* %scevgep41.12.22 to [61 x [61 x i8]]*
  %call16.12.23 = call zeroext i8 (...) @rand()
  store i8 %call16.12.23, i8* %scevgep28.12.22, align 1
  %4837 = load i8, i8* %scevgep28.12.22, align 1
  %conv23.12.23 = zext i8 %4837 to i32
  %4838 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.23 = getelementptr i8, i8* %b, i64 36
  %4839 = load i8, i8* %scevgep34.12.23, align 1
  %call28.12.23 = call zeroext i8 @mult(i8 zeroext %4838, i8 zeroext %4839)
  %conv29.12.23 = zext i8 %call28.12.23 to i32
  %xor.12.23 = xor i32 %conv23.12.23, %conv29.12.23
  %scevgep35.12.23 = getelementptr i8, i8* %a, i64 36
  %4840 = load i8, i8* %scevgep35.12.23, align 1
  %4841 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.23 = call zeroext i8 @mult(i8 zeroext %4840, i8 zeroext %4841)
  %conv35.12.23 = zext i8 %call34.12.23 to i32
  %xor36.12.23 = xor i32 %xor.12.23, %conv35.12.23
  %conv37.12.23 = trunc i32 %xor36.12.23 to i8
  store i8 %conv37.12.23, i8* %scevgep41.12.22, align 1
  %scevgep28.12.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4835, i64 0, i64 0, i64 1
  %4842 = bitcast i8* %scevgep28.12.23 to [61 x [61 x i8]]*
  %scevgep41.12.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4836, i64 0, i64 1, i64 0
  %4843 = bitcast i8* %scevgep41.12.23 to [61 x [61 x i8]]*
  %call16.12.24 = call zeroext i8 (...) @rand()
  store i8 %call16.12.24, i8* %scevgep28.12.23, align 1
  %4844 = load i8, i8* %scevgep28.12.23, align 1
  %conv23.12.24 = zext i8 %4844 to i32
  %4845 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.24 = getelementptr i8, i8* %b, i64 37
  %4846 = load i8, i8* %scevgep34.12.24, align 1
  %call28.12.24 = call zeroext i8 @mult(i8 zeroext %4845, i8 zeroext %4846)
  %conv29.12.24 = zext i8 %call28.12.24 to i32
  %xor.12.24 = xor i32 %conv23.12.24, %conv29.12.24
  %scevgep35.12.24 = getelementptr i8, i8* %a, i64 37
  %4847 = load i8, i8* %scevgep35.12.24, align 1
  %4848 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.24 = call zeroext i8 @mult(i8 zeroext %4847, i8 zeroext %4848)
  %conv35.12.24 = zext i8 %call34.12.24 to i32
  %xor36.12.24 = xor i32 %xor.12.24, %conv35.12.24
  %conv37.12.24 = trunc i32 %xor36.12.24 to i8
  store i8 %conv37.12.24, i8* %scevgep41.12.23, align 1
  %scevgep28.12.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4842, i64 0, i64 0, i64 1
  %4849 = bitcast i8* %scevgep28.12.24 to [61 x [61 x i8]]*
  %scevgep41.12.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4843, i64 0, i64 1, i64 0
  %4850 = bitcast i8* %scevgep41.12.24 to [61 x [61 x i8]]*
  %call16.12.25 = call zeroext i8 (...) @rand()
  store i8 %call16.12.25, i8* %scevgep28.12.24, align 1
  %4851 = load i8, i8* %scevgep28.12.24, align 1
  %conv23.12.25 = zext i8 %4851 to i32
  %4852 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.25 = getelementptr i8, i8* %b, i64 38
  %4853 = load i8, i8* %scevgep34.12.25, align 1
  %call28.12.25 = call zeroext i8 @mult(i8 zeroext %4852, i8 zeroext %4853)
  %conv29.12.25 = zext i8 %call28.12.25 to i32
  %xor.12.25 = xor i32 %conv23.12.25, %conv29.12.25
  %scevgep35.12.25 = getelementptr i8, i8* %a, i64 38
  %4854 = load i8, i8* %scevgep35.12.25, align 1
  %4855 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.25 = call zeroext i8 @mult(i8 zeroext %4854, i8 zeroext %4855)
  %conv35.12.25 = zext i8 %call34.12.25 to i32
  %xor36.12.25 = xor i32 %xor.12.25, %conv35.12.25
  %conv37.12.25 = trunc i32 %xor36.12.25 to i8
  store i8 %conv37.12.25, i8* %scevgep41.12.24, align 1
  %scevgep28.12.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4849, i64 0, i64 0, i64 1
  %4856 = bitcast i8* %scevgep28.12.25 to [61 x [61 x i8]]*
  %scevgep41.12.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4850, i64 0, i64 1, i64 0
  %4857 = bitcast i8* %scevgep41.12.25 to [61 x [61 x i8]]*
  %call16.12.26 = call zeroext i8 (...) @rand()
  store i8 %call16.12.26, i8* %scevgep28.12.25, align 1
  %4858 = load i8, i8* %scevgep28.12.25, align 1
  %conv23.12.26 = zext i8 %4858 to i32
  %4859 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.26 = getelementptr i8, i8* %b, i64 39
  %4860 = load i8, i8* %scevgep34.12.26, align 1
  %call28.12.26 = call zeroext i8 @mult(i8 zeroext %4859, i8 zeroext %4860)
  %conv29.12.26 = zext i8 %call28.12.26 to i32
  %xor.12.26 = xor i32 %conv23.12.26, %conv29.12.26
  %scevgep35.12.26 = getelementptr i8, i8* %a, i64 39
  %4861 = load i8, i8* %scevgep35.12.26, align 1
  %4862 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.26 = call zeroext i8 @mult(i8 zeroext %4861, i8 zeroext %4862)
  %conv35.12.26 = zext i8 %call34.12.26 to i32
  %xor36.12.26 = xor i32 %xor.12.26, %conv35.12.26
  %conv37.12.26 = trunc i32 %xor36.12.26 to i8
  store i8 %conv37.12.26, i8* %scevgep41.12.25, align 1
  %scevgep28.12.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4856, i64 0, i64 0, i64 1
  %4863 = bitcast i8* %scevgep28.12.26 to [61 x [61 x i8]]*
  %scevgep41.12.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4857, i64 0, i64 1, i64 0
  %4864 = bitcast i8* %scevgep41.12.26 to [61 x [61 x i8]]*
  %call16.12.27 = call zeroext i8 (...) @rand()
  store i8 %call16.12.27, i8* %scevgep28.12.26, align 1
  %4865 = load i8, i8* %scevgep28.12.26, align 1
  %conv23.12.27 = zext i8 %4865 to i32
  %4866 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.27 = getelementptr i8, i8* %b, i64 40
  %4867 = load i8, i8* %scevgep34.12.27, align 1
  %call28.12.27 = call zeroext i8 @mult(i8 zeroext %4866, i8 zeroext %4867)
  %conv29.12.27 = zext i8 %call28.12.27 to i32
  %xor.12.27 = xor i32 %conv23.12.27, %conv29.12.27
  %scevgep35.12.27 = getelementptr i8, i8* %a, i64 40
  %4868 = load i8, i8* %scevgep35.12.27, align 1
  %4869 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.27 = call zeroext i8 @mult(i8 zeroext %4868, i8 zeroext %4869)
  %conv35.12.27 = zext i8 %call34.12.27 to i32
  %xor36.12.27 = xor i32 %xor.12.27, %conv35.12.27
  %conv37.12.27 = trunc i32 %xor36.12.27 to i8
  store i8 %conv37.12.27, i8* %scevgep41.12.26, align 1
  %scevgep28.12.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4863, i64 0, i64 0, i64 1
  %4870 = bitcast i8* %scevgep28.12.27 to [61 x [61 x i8]]*
  %scevgep41.12.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4864, i64 0, i64 1, i64 0
  %4871 = bitcast i8* %scevgep41.12.27 to [61 x [61 x i8]]*
  %call16.12.28 = call zeroext i8 (...) @rand()
  store i8 %call16.12.28, i8* %scevgep28.12.27, align 1
  %4872 = load i8, i8* %scevgep28.12.27, align 1
  %conv23.12.28 = zext i8 %4872 to i32
  %4873 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.28 = getelementptr i8, i8* %b, i64 41
  %4874 = load i8, i8* %scevgep34.12.28, align 1
  %call28.12.28 = call zeroext i8 @mult(i8 zeroext %4873, i8 zeroext %4874)
  %conv29.12.28 = zext i8 %call28.12.28 to i32
  %xor.12.28 = xor i32 %conv23.12.28, %conv29.12.28
  %scevgep35.12.28 = getelementptr i8, i8* %a, i64 41
  %4875 = load i8, i8* %scevgep35.12.28, align 1
  %4876 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.28 = call zeroext i8 @mult(i8 zeroext %4875, i8 zeroext %4876)
  %conv35.12.28 = zext i8 %call34.12.28 to i32
  %xor36.12.28 = xor i32 %xor.12.28, %conv35.12.28
  %conv37.12.28 = trunc i32 %xor36.12.28 to i8
  store i8 %conv37.12.28, i8* %scevgep41.12.27, align 1
  %scevgep28.12.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4870, i64 0, i64 0, i64 1
  %4877 = bitcast i8* %scevgep28.12.28 to [61 x [61 x i8]]*
  %scevgep41.12.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4871, i64 0, i64 1, i64 0
  %4878 = bitcast i8* %scevgep41.12.28 to [61 x [61 x i8]]*
  %call16.12.29 = call zeroext i8 (...) @rand()
  store i8 %call16.12.29, i8* %scevgep28.12.28, align 1
  %4879 = load i8, i8* %scevgep28.12.28, align 1
  %conv23.12.29 = zext i8 %4879 to i32
  %4880 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.29 = getelementptr i8, i8* %b, i64 42
  %4881 = load i8, i8* %scevgep34.12.29, align 1
  %call28.12.29 = call zeroext i8 @mult(i8 zeroext %4880, i8 zeroext %4881)
  %conv29.12.29 = zext i8 %call28.12.29 to i32
  %xor.12.29 = xor i32 %conv23.12.29, %conv29.12.29
  %scevgep35.12.29 = getelementptr i8, i8* %a, i64 42
  %4882 = load i8, i8* %scevgep35.12.29, align 1
  %4883 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.29 = call zeroext i8 @mult(i8 zeroext %4882, i8 zeroext %4883)
  %conv35.12.29 = zext i8 %call34.12.29 to i32
  %xor36.12.29 = xor i32 %xor.12.29, %conv35.12.29
  %conv37.12.29 = trunc i32 %xor36.12.29 to i8
  store i8 %conv37.12.29, i8* %scevgep41.12.28, align 1
  %scevgep28.12.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4877, i64 0, i64 0, i64 1
  %4884 = bitcast i8* %scevgep28.12.29 to [61 x [61 x i8]]*
  %scevgep41.12.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4878, i64 0, i64 1, i64 0
  %4885 = bitcast i8* %scevgep41.12.29 to [61 x [61 x i8]]*
  %call16.12.30 = call zeroext i8 (...) @rand()
  store i8 %call16.12.30, i8* %scevgep28.12.29, align 1
  %4886 = load i8, i8* %scevgep28.12.29, align 1
  %conv23.12.30 = zext i8 %4886 to i32
  %4887 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.30 = getelementptr i8, i8* %b, i64 43
  %4888 = load i8, i8* %scevgep34.12.30, align 1
  %call28.12.30 = call zeroext i8 @mult(i8 zeroext %4887, i8 zeroext %4888)
  %conv29.12.30 = zext i8 %call28.12.30 to i32
  %xor.12.30 = xor i32 %conv23.12.30, %conv29.12.30
  %scevgep35.12.30 = getelementptr i8, i8* %a, i64 43
  %4889 = load i8, i8* %scevgep35.12.30, align 1
  %4890 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.30 = call zeroext i8 @mult(i8 zeroext %4889, i8 zeroext %4890)
  %conv35.12.30 = zext i8 %call34.12.30 to i32
  %xor36.12.30 = xor i32 %xor.12.30, %conv35.12.30
  %conv37.12.30 = trunc i32 %xor36.12.30 to i8
  store i8 %conv37.12.30, i8* %scevgep41.12.29, align 1
  %scevgep28.12.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4884, i64 0, i64 0, i64 1
  %4891 = bitcast i8* %scevgep28.12.30 to [61 x [61 x i8]]*
  %scevgep41.12.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4885, i64 0, i64 1, i64 0
  %4892 = bitcast i8* %scevgep41.12.30 to [61 x [61 x i8]]*
  %call16.12.31 = call zeroext i8 (...) @rand()
  store i8 %call16.12.31, i8* %scevgep28.12.30, align 1
  %4893 = load i8, i8* %scevgep28.12.30, align 1
  %conv23.12.31 = zext i8 %4893 to i32
  %4894 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.31 = getelementptr i8, i8* %b, i64 44
  %4895 = load i8, i8* %scevgep34.12.31, align 1
  %call28.12.31 = call zeroext i8 @mult(i8 zeroext %4894, i8 zeroext %4895)
  %conv29.12.31 = zext i8 %call28.12.31 to i32
  %xor.12.31 = xor i32 %conv23.12.31, %conv29.12.31
  %scevgep35.12.31 = getelementptr i8, i8* %a, i64 44
  %4896 = load i8, i8* %scevgep35.12.31, align 1
  %4897 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.31 = call zeroext i8 @mult(i8 zeroext %4896, i8 zeroext %4897)
  %conv35.12.31 = zext i8 %call34.12.31 to i32
  %xor36.12.31 = xor i32 %xor.12.31, %conv35.12.31
  %conv37.12.31 = trunc i32 %xor36.12.31 to i8
  store i8 %conv37.12.31, i8* %scevgep41.12.30, align 1
  %scevgep28.12.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4891, i64 0, i64 0, i64 1
  %4898 = bitcast i8* %scevgep28.12.31 to [61 x [61 x i8]]*
  %scevgep41.12.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4892, i64 0, i64 1, i64 0
  %4899 = bitcast i8* %scevgep41.12.31 to [61 x [61 x i8]]*
  %call16.12.32 = call zeroext i8 (...) @rand()
  store i8 %call16.12.32, i8* %scevgep28.12.31, align 1
  %4900 = load i8, i8* %scevgep28.12.31, align 1
  %conv23.12.32 = zext i8 %4900 to i32
  %4901 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.32 = getelementptr i8, i8* %b, i64 45
  %4902 = load i8, i8* %scevgep34.12.32, align 1
  %call28.12.32 = call zeroext i8 @mult(i8 zeroext %4901, i8 zeroext %4902)
  %conv29.12.32 = zext i8 %call28.12.32 to i32
  %xor.12.32 = xor i32 %conv23.12.32, %conv29.12.32
  %scevgep35.12.32 = getelementptr i8, i8* %a, i64 45
  %4903 = load i8, i8* %scevgep35.12.32, align 1
  %4904 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.32 = call zeroext i8 @mult(i8 zeroext %4903, i8 zeroext %4904)
  %conv35.12.32 = zext i8 %call34.12.32 to i32
  %xor36.12.32 = xor i32 %xor.12.32, %conv35.12.32
  %conv37.12.32 = trunc i32 %xor36.12.32 to i8
  store i8 %conv37.12.32, i8* %scevgep41.12.31, align 1
  %scevgep28.12.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4898, i64 0, i64 0, i64 1
  %4905 = bitcast i8* %scevgep28.12.32 to [61 x [61 x i8]]*
  %scevgep41.12.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4899, i64 0, i64 1, i64 0
  %4906 = bitcast i8* %scevgep41.12.32 to [61 x [61 x i8]]*
  %call16.12.33 = call zeroext i8 (...) @rand()
  store i8 %call16.12.33, i8* %scevgep28.12.32, align 1
  %4907 = load i8, i8* %scevgep28.12.32, align 1
  %conv23.12.33 = zext i8 %4907 to i32
  %4908 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.33 = getelementptr i8, i8* %b, i64 46
  %4909 = load i8, i8* %scevgep34.12.33, align 1
  %call28.12.33 = call zeroext i8 @mult(i8 zeroext %4908, i8 zeroext %4909)
  %conv29.12.33 = zext i8 %call28.12.33 to i32
  %xor.12.33 = xor i32 %conv23.12.33, %conv29.12.33
  %scevgep35.12.33 = getelementptr i8, i8* %a, i64 46
  %4910 = load i8, i8* %scevgep35.12.33, align 1
  %4911 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.33 = call zeroext i8 @mult(i8 zeroext %4910, i8 zeroext %4911)
  %conv35.12.33 = zext i8 %call34.12.33 to i32
  %xor36.12.33 = xor i32 %xor.12.33, %conv35.12.33
  %conv37.12.33 = trunc i32 %xor36.12.33 to i8
  store i8 %conv37.12.33, i8* %scevgep41.12.32, align 1
  %scevgep28.12.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4905, i64 0, i64 0, i64 1
  %4912 = bitcast i8* %scevgep28.12.33 to [61 x [61 x i8]]*
  %scevgep41.12.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4906, i64 0, i64 1, i64 0
  %4913 = bitcast i8* %scevgep41.12.33 to [61 x [61 x i8]]*
  %call16.12.34 = call zeroext i8 (...) @rand()
  store i8 %call16.12.34, i8* %scevgep28.12.33, align 1
  %4914 = load i8, i8* %scevgep28.12.33, align 1
  %conv23.12.34 = zext i8 %4914 to i32
  %4915 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.34 = getelementptr i8, i8* %b, i64 47
  %4916 = load i8, i8* %scevgep34.12.34, align 1
  %call28.12.34 = call zeroext i8 @mult(i8 zeroext %4915, i8 zeroext %4916)
  %conv29.12.34 = zext i8 %call28.12.34 to i32
  %xor.12.34 = xor i32 %conv23.12.34, %conv29.12.34
  %scevgep35.12.34 = getelementptr i8, i8* %a, i64 47
  %4917 = load i8, i8* %scevgep35.12.34, align 1
  %4918 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.34 = call zeroext i8 @mult(i8 zeroext %4917, i8 zeroext %4918)
  %conv35.12.34 = zext i8 %call34.12.34 to i32
  %xor36.12.34 = xor i32 %xor.12.34, %conv35.12.34
  %conv37.12.34 = trunc i32 %xor36.12.34 to i8
  store i8 %conv37.12.34, i8* %scevgep41.12.33, align 1
  %scevgep28.12.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4912, i64 0, i64 0, i64 1
  %4919 = bitcast i8* %scevgep28.12.34 to [61 x [61 x i8]]*
  %scevgep41.12.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4913, i64 0, i64 1, i64 0
  %4920 = bitcast i8* %scevgep41.12.34 to [61 x [61 x i8]]*
  %call16.12.35 = call zeroext i8 (...) @rand()
  store i8 %call16.12.35, i8* %scevgep28.12.34, align 1
  %4921 = load i8, i8* %scevgep28.12.34, align 1
  %conv23.12.35 = zext i8 %4921 to i32
  %4922 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.35 = getelementptr i8, i8* %b, i64 48
  %4923 = load i8, i8* %scevgep34.12.35, align 1
  %call28.12.35 = call zeroext i8 @mult(i8 zeroext %4922, i8 zeroext %4923)
  %conv29.12.35 = zext i8 %call28.12.35 to i32
  %xor.12.35 = xor i32 %conv23.12.35, %conv29.12.35
  %scevgep35.12.35 = getelementptr i8, i8* %a, i64 48
  %4924 = load i8, i8* %scevgep35.12.35, align 1
  %4925 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.35 = call zeroext i8 @mult(i8 zeroext %4924, i8 zeroext %4925)
  %conv35.12.35 = zext i8 %call34.12.35 to i32
  %xor36.12.35 = xor i32 %xor.12.35, %conv35.12.35
  %conv37.12.35 = trunc i32 %xor36.12.35 to i8
  store i8 %conv37.12.35, i8* %scevgep41.12.34, align 1
  %scevgep28.12.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4919, i64 0, i64 0, i64 1
  %4926 = bitcast i8* %scevgep28.12.35 to [61 x [61 x i8]]*
  %scevgep41.12.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4920, i64 0, i64 1, i64 0
  %4927 = bitcast i8* %scevgep41.12.35 to [61 x [61 x i8]]*
  %call16.12.36 = call zeroext i8 (...) @rand()
  store i8 %call16.12.36, i8* %scevgep28.12.35, align 1
  %4928 = load i8, i8* %scevgep28.12.35, align 1
  %conv23.12.36 = zext i8 %4928 to i32
  %4929 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.36 = getelementptr i8, i8* %b, i64 49
  %4930 = load i8, i8* %scevgep34.12.36, align 1
  %call28.12.36 = call zeroext i8 @mult(i8 zeroext %4929, i8 zeroext %4930)
  %conv29.12.36 = zext i8 %call28.12.36 to i32
  %xor.12.36 = xor i32 %conv23.12.36, %conv29.12.36
  %scevgep35.12.36 = getelementptr i8, i8* %a, i64 49
  %4931 = load i8, i8* %scevgep35.12.36, align 1
  %4932 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.36 = call zeroext i8 @mult(i8 zeroext %4931, i8 zeroext %4932)
  %conv35.12.36 = zext i8 %call34.12.36 to i32
  %xor36.12.36 = xor i32 %xor.12.36, %conv35.12.36
  %conv37.12.36 = trunc i32 %xor36.12.36 to i8
  store i8 %conv37.12.36, i8* %scevgep41.12.35, align 1
  %scevgep28.12.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4926, i64 0, i64 0, i64 1
  %4933 = bitcast i8* %scevgep28.12.36 to [61 x [61 x i8]]*
  %scevgep41.12.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4927, i64 0, i64 1, i64 0
  %4934 = bitcast i8* %scevgep41.12.36 to [61 x [61 x i8]]*
  %call16.12.37 = call zeroext i8 (...) @rand()
  store i8 %call16.12.37, i8* %scevgep28.12.36, align 1
  %4935 = load i8, i8* %scevgep28.12.36, align 1
  %conv23.12.37 = zext i8 %4935 to i32
  %4936 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.37 = getelementptr i8, i8* %b, i64 50
  %4937 = load i8, i8* %scevgep34.12.37, align 1
  %call28.12.37 = call zeroext i8 @mult(i8 zeroext %4936, i8 zeroext %4937)
  %conv29.12.37 = zext i8 %call28.12.37 to i32
  %xor.12.37 = xor i32 %conv23.12.37, %conv29.12.37
  %scevgep35.12.37 = getelementptr i8, i8* %a, i64 50
  %4938 = load i8, i8* %scevgep35.12.37, align 1
  %4939 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.37 = call zeroext i8 @mult(i8 zeroext %4938, i8 zeroext %4939)
  %conv35.12.37 = zext i8 %call34.12.37 to i32
  %xor36.12.37 = xor i32 %xor.12.37, %conv35.12.37
  %conv37.12.37 = trunc i32 %xor36.12.37 to i8
  store i8 %conv37.12.37, i8* %scevgep41.12.36, align 1
  %scevgep28.12.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4933, i64 0, i64 0, i64 1
  %4940 = bitcast i8* %scevgep28.12.37 to [61 x [61 x i8]]*
  %scevgep41.12.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4934, i64 0, i64 1, i64 0
  %4941 = bitcast i8* %scevgep41.12.37 to [61 x [61 x i8]]*
  %call16.12.38 = call zeroext i8 (...) @rand()
  store i8 %call16.12.38, i8* %scevgep28.12.37, align 1
  %4942 = load i8, i8* %scevgep28.12.37, align 1
  %conv23.12.38 = zext i8 %4942 to i32
  %4943 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.38 = getelementptr i8, i8* %b, i64 51
  %4944 = load i8, i8* %scevgep34.12.38, align 1
  %call28.12.38 = call zeroext i8 @mult(i8 zeroext %4943, i8 zeroext %4944)
  %conv29.12.38 = zext i8 %call28.12.38 to i32
  %xor.12.38 = xor i32 %conv23.12.38, %conv29.12.38
  %scevgep35.12.38 = getelementptr i8, i8* %a, i64 51
  %4945 = load i8, i8* %scevgep35.12.38, align 1
  %4946 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.38 = call zeroext i8 @mult(i8 zeroext %4945, i8 zeroext %4946)
  %conv35.12.38 = zext i8 %call34.12.38 to i32
  %xor36.12.38 = xor i32 %xor.12.38, %conv35.12.38
  %conv37.12.38 = trunc i32 %xor36.12.38 to i8
  store i8 %conv37.12.38, i8* %scevgep41.12.37, align 1
  %scevgep28.12.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4940, i64 0, i64 0, i64 1
  %4947 = bitcast i8* %scevgep28.12.38 to [61 x [61 x i8]]*
  %scevgep41.12.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4941, i64 0, i64 1, i64 0
  %4948 = bitcast i8* %scevgep41.12.38 to [61 x [61 x i8]]*
  %call16.12.39 = call zeroext i8 (...) @rand()
  store i8 %call16.12.39, i8* %scevgep28.12.38, align 1
  %4949 = load i8, i8* %scevgep28.12.38, align 1
  %conv23.12.39 = zext i8 %4949 to i32
  %4950 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.39 = getelementptr i8, i8* %b, i64 52
  %4951 = load i8, i8* %scevgep34.12.39, align 1
  %call28.12.39 = call zeroext i8 @mult(i8 zeroext %4950, i8 zeroext %4951)
  %conv29.12.39 = zext i8 %call28.12.39 to i32
  %xor.12.39 = xor i32 %conv23.12.39, %conv29.12.39
  %scevgep35.12.39 = getelementptr i8, i8* %a, i64 52
  %4952 = load i8, i8* %scevgep35.12.39, align 1
  %4953 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.39 = call zeroext i8 @mult(i8 zeroext %4952, i8 zeroext %4953)
  %conv35.12.39 = zext i8 %call34.12.39 to i32
  %xor36.12.39 = xor i32 %xor.12.39, %conv35.12.39
  %conv37.12.39 = trunc i32 %xor36.12.39 to i8
  store i8 %conv37.12.39, i8* %scevgep41.12.38, align 1
  %scevgep28.12.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4947, i64 0, i64 0, i64 1
  %4954 = bitcast i8* %scevgep28.12.39 to [61 x [61 x i8]]*
  %scevgep41.12.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4948, i64 0, i64 1, i64 0
  %4955 = bitcast i8* %scevgep41.12.39 to [61 x [61 x i8]]*
  %call16.12.40 = call zeroext i8 (...) @rand()
  store i8 %call16.12.40, i8* %scevgep28.12.39, align 1
  %4956 = load i8, i8* %scevgep28.12.39, align 1
  %conv23.12.40 = zext i8 %4956 to i32
  %4957 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.40 = getelementptr i8, i8* %b, i64 53
  %4958 = load i8, i8* %scevgep34.12.40, align 1
  %call28.12.40 = call zeroext i8 @mult(i8 zeroext %4957, i8 zeroext %4958)
  %conv29.12.40 = zext i8 %call28.12.40 to i32
  %xor.12.40 = xor i32 %conv23.12.40, %conv29.12.40
  %scevgep35.12.40 = getelementptr i8, i8* %a, i64 53
  %4959 = load i8, i8* %scevgep35.12.40, align 1
  %4960 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.40 = call zeroext i8 @mult(i8 zeroext %4959, i8 zeroext %4960)
  %conv35.12.40 = zext i8 %call34.12.40 to i32
  %xor36.12.40 = xor i32 %xor.12.40, %conv35.12.40
  %conv37.12.40 = trunc i32 %xor36.12.40 to i8
  store i8 %conv37.12.40, i8* %scevgep41.12.39, align 1
  %scevgep28.12.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4954, i64 0, i64 0, i64 1
  %4961 = bitcast i8* %scevgep28.12.40 to [61 x [61 x i8]]*
  %scevgep41.12.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4955, i64 0, i64 1, i64 0
  %4962 = bitcast i8* %scevgep41.12.40 to [61 x [61 x i8]]*
  %call16.12.41 = call zeroext i8 (...) @rand()
  store i8 %call16.12.41, i8* %scevgep28.12.40, align 1
  %4963 = load i8, i8* %scevgep28.12.40, align 1
  %conv23.12.41 = zext i8 %4963 to i32
  %4964 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.41 = getelementptr i8, i8* %b, i64 54
  %4965 = load i8, i8* %scevgep34.12.41, align 1
  %call28.12.41 = call zeroext i8 @mult(i8 zeroext %4964, i8 zeroext %4965)
  %conv29.12.41 = zext i8 %call28.12.41 to i32
  %xor.12.41 = xor i32 %conv23.12.41, %conv29.12.41
  %scevgep35.12.41 = getelementptr i8, i8* %a, i64 54
  %4966 = load i8, i8* %scevgep35.12.41, align 1
  %4967 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.41 = call zeroext i8 @mult(i8 zeroext %4966, i8 zeroext %4967)
  %conv35.12.41 = zext i8 %call34.12.41 to i32
  %xor36.12.41 = xor i32 %xor.12.41, %conv35.12.41
  %conv37.12.41 = trunc i32 %xor36.12.41 to i8
  store i8 %conv37.12.41, i8* %scevgep41.12.40, align 1
  %scevgep28.12.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4961, i64 0, i64 0, i64 1
  %4968 = bitcast i8* %scevgep28.12.41 to [61 x [61 x i8]]*
  %scevgep41.12.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4962, i64 0, i64 1, i64 0
  %4969 = bitcast i8* %scevgep41.12.41 to [61 x [61 x i8]]*
  %call16.12.42 = call zeroext i8 (...) @rand()
  store i8 %call16.12.42, i8* %scevgep28.12.41, align 1
  %4970 = load i8, i8* %scevgep28.12.41, align 1
  %conv23.12.42 = zext i8 %4970 to i32
  %4971 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.42 = getelementptr i8, i8* %b, i64 55
  %4972 = load i8, i8* %scevgep34.12.42, align 1
  %call28.12.42 = call zeroext i8 @mult(i8 zeroext %4971, i8 zeroext %4972)
  %conv29.12.42 = zext i8 %call28.12.42 to i32
  %xor.12.42 = xor i32 %conv23.12.42, %conv29.12.42
  %scevgep35.12.42 = getelementptr i8, i8* %a, i64 55
  %4973 = load i8, i8* %scevgep35.12.42, align 1
  %4974 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.42 = call zeroext i8 @mult(i8 zeroext %4973, i8 zeroext %4974)
  %conv35.12.42 = zext i8 %call34.12.42 to i32
  %xor36.12.42 = xor i32 %xor.12.42, %conv35.12.42
  %conv37.12.42 = trunc i32 %xor36.12.42 to i8
  store i8 %conv37.12.42, i8* %scevgep41.12.41, align 1
  %scevgep28.12.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4968, i64 0, i64 0, i64 1
  %4975 = bitcast i8* %scevgep28.12.42 to [61 x [61 x i8]]*
  %scevgep41.12.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4969, i64 0, i64 1, i64 0
  %4976 = bitcast i8* %scevgep41.12.42 to [61 x [61 x i8]]*
  %call16.12.43 = call zeroext i8 (...) @rand()
  store i8 %call16.12.43, i8* %scevgep28.12.42, align 1
  %4977 = load i8, i8* %scevgep28.12.42, align 1
  %conv23.12.43 = zext i8 %4977 to i32
  %4978 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.43 = getelementptr i8, i8* %b, i64 56
  %4979 = load i8, i8* %scevgep34.12.43, align 1
  %call28.12.43 = call zeroext i8 @mult(i8 zeroext %4978, i8 zeroext %4979)
  %conv29.12.43 = zext i8 %call28.12.43 to i32
  %xor.12.43 = xor i32 %conv23.12.43, %conv29.12.43
  %scevgep35.12.43 = getelementptr i8, i8* %a, i64 56
  %4980 = load i8, i8* %scevgep35.12.43, align 1
  %4981 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.43 = call zeroext i8 @mult(i8 zeroext %4980, i8 zeroext %4981)
  %conv35.12.43 = zext i8 %call34.12.43 to i32
  %xor36.12.43 = xor i32 %xor.12.43, %conv35.12.43
  %conv37.12.43 = trunc i32 %xor36.12.43 to i8
  store i8 %conv37.12.43, i8* %scevgep41.12.42, align 1
  %scevgep28.12.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4975, i64 0, i64 0, i64 1
  %4982 = bitcast i8* %scevgep28.12.43 to [61 x [61 x i8]]*
  %scevgep41.12.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4976, i64 0, i64 1, i64 0
  %4983 = bitcast i8* %scevgep41.12.43 to [61 x [61 x i8]]*
  %call16.12.44 = call zeroext i8 (...) @rand()
  store i8 %call16.12.44, i8* %scevgep28.12.43, align 1
  %4984 = load i8, i8* %scevgep28.12.43, align 1
  %conv23.12.44 = zext i8 %4984 to i32
  %4985 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.44 = getelementptr i8, i8* %b, i64 57
  %4986 = load i8, i8* %scevgep34.12.44, align 1
  %call28.12.44 = call zeroext i8 @mult(i8 zeroext %4985, i8 zeroext %4986)
  %conv29.12.44 = zext i8 %call28.12.44 to i32
  %xor.12.44 = xor i32 %conv23.12.44, %conv29.12.44
  %scevgep35.12.44 = getelementptr i8, i8* %a, i64 57
  %4987 = load i8, i8* %scevgep35.12.44, align 1
  %4988 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.44 = call zeroext i8 @mult(i8 zeroext %4987, i8 zeroext %4988)
  %conv35.12.44 = zext i8 %call34.12.44 to i32
  %xor36.12.44 = xor i32 %xor.12.44, %conv35.12.44
  %conv37.12.44 = trunc i32 %xor36.12.44 to i8
  store i8 %conv37.12.44, i8* %scevgep41.12.43, align 1
  %scevgep28.12.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4982, i64 0, i64 0, i64 1
  %4989 = bitcast i8* %scevgep28.12.44 to [61 x [61 x i8]]*
  %scevgep41.12.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4983, i64 0, i64 1, i64 0
  %4990 = bitcast i8* %scevgep41.12.44 to [61 x [61 x i8]]*
  %call16.12.45 = call zeroext i8 (...) @rand()
  store i8 %call16.12.45, i8* %scevgep28.12.44, align 1
  %4991 = load i8, i8* %scevgep28.12.44, align 1
  %conv23.12.45 = zext i8 %4991 to i32
  %4992 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.45 = getelementptr i8, i8* %b, i64 58
  %4993 = load i8, i8* %scevgep34.12.45, align 1
  %call28.12.45 = call zeroext i8 @mult(i8 zeroext %4992, i8 zeroext %4993)
  %conv29.12.45 = zext i8 %call28.12.45 to i32
  %xor.12.45 = xor i32 %conv23.12.45, %conv29.12.45
  %scevgep35.12.45 = getelementptr i8, i8* %a, i64 58
  %4994 = load i8, i8* %scevgep35.12.45, align 1
  %4995 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.45 = call zeroext i8 @mult(i8 zeroext %4994, i8 zeroext %4995)
  %conv35.12.45 = zext i8 %call34.12.45 to i32
  %xor36.12.45 = xor i32 %xor.12.45, %conv35.12.45
  %conv37.12.45 = trunc i32 %xor36.12.45 to i8
  store i8 %conv37.12.45, i8* %scevgep41.12.44, align 1
  %scevgep28.12.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4989, i64 0, i64 0, i64 1
  %4996 = bitcast i8* %scevgep28.12.45 to [61 x [61 x i8]]*
  %scevgep41.12.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4990, i64 0, i64 1, i64 0
  %4997 = bitcast i8* %scevgep41.12.45 to [61 x [61 x i8]]*
  %call16.12.46 = call zeroext i8 (...) @rand()
  store i8 %call16.12.46, i8* %scevgep28.12.45, align 1
  %4998 = load i8, i8* %scevgep28.12.45, align 1
  %conv23.12.46 = zext i8 %4998 to i32
  %4999 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.46 = getelementptr i8, i8* %b, i64 59
  %5000 = load i8, i8* %scevgep34.12.46, align 1
  %call28.12.46 = call zeroext i8 @mult(i8 zeroext %4999, i8 zeroext %5000)
  %conv29.12.46 = zext i8 %call28.12.46 to i32
  %xor.12.46 = xor i32 %conv23.12.46, %conv29.12.46
  %scevgep35.12.46 = getelementptr i8, i8* %a, i64 59
  %5001 = load i8, i8* %scevgep35.12.46, align 1
  %5002 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.46 = call zeroext i8 @mult(i8 zeroext %5001, i8 zeroext %5002)
  %conv35.12.46 = zext i8 %call34.12.46 to i32
  %xor36.12.46 = xor i32 %xor.12.46, %conv35.12.46
  %conv37.12.46 = trunc i32 %xor36.12.46 to i8
  store i8 %conv37.12.46, i8* %scevgep41.12.45, align 1
  %scevgep28.12.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4996, i64 0, i64 0, i64 1
  %scevgep41.12.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4997, i64 0, i64 1, i64 0
  %call16.12.47 = call zeroext i8 (...) @rand()
  store i8 %call16.12.47, i8* %scevgep28.12.46, align 1
  %5003 = load i8, i8* %scevgep28.12.46, align 1
  %conv23.12.47 = zext i8 %5003 to i32
  %5004 = load i8, i8* %arrayidx25.12, align 1
  %scevgep34.12.47 = getelementptr i8, i8* %b, i64 60
  %5005 = load i8, i8* %scevgep34.12.47, align 1
  %call28.12.47 = call zeroext i8 @mult(i8 zeroext %5004, i8 zeroext %5005)
  %conv29.12.47 = zext i8 %call28.12.47 to i32
  %xor.12.47 = xor i32 %conv23.12.47, %conv29.12.47
  %scevgep35.12.47 = getelementptr i8, i8* %a, i64 60
  %5006 = load i8, i8* %scevgep35.12.47, align 1
  %5007 = load i8, i8* %arrayidx33.12, align 1
  %call34.12.47 = call zeroext i8 @mult(i8 zeroext %5006, i8 zeroext %5007)
  %conv35.12.47 = zext i8 %call34.12.47 to i32
  %xor36.12.47 = xor i32 %xor.12.47, %conv35.12.47
  %conv37.12.47 = trunc i32 %xor36.12.47 to i8
  store i8 %conv37.12.47, i8* %scevgep41.12.46, align 1
  %scevgep26.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4674, i64 0, i64 1, i64 1
  %5008 = bitcast i8* %scevgep26.12 to [61 x [61 x i8]]*
  %scevgep39.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %4675, i64 0, i64 1, i64 1
  %5009 = bitcast i8* %scevgep39.12 to [61 x [61 x i8]]*
  %arrayidx25.13 = getelementptr inbounds i8, i8* %a, i64 13
  %arrayidx33.13 = getelementptr inbounds i8, i8* %b, i64 13
  %call16.13 = call zeroext i8 (...) @rand()
  store i8 %call16.13, i8* %scevgep26.12, align 1
  %5010 = load i8, i8* %scevgep26.12, align 1
  %conv23.13 = zext i8 %5010 to i32
  %5011 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13 = getelementptr i8, i8* %b, i64 14
  %5012 = load i8, i8* %scevgep34.13, align 1
  %call28.13 = call zeroext i8 @mult(i8 zeroext %5011, i8 zeroext %5012)
  %conv29.13 = zext i8 %call28.13 to i32
  %xor.13 = xor i32 %conv23.13, %conv29.13
  %scevgep35.13 = getelementptr i8, i8* %a, i64 14
  %5013 = load i8, i8* %scevgep35.13, align 1
  %5014 = load i8, i8* %arrayidx33.13, align 1
  %call34.13 = call zeroext i8 @mult(i8 zeroext %5013, i8 zeroext %5014)
  %conv35.13 = zext i8 %call34.13 to i32
  %xor36.13 = xor i32 %xor.13, %conv35.13
  %conv37.13 = trunc i32 %xor36.13 to i8
  store i8 %conv37.13, i8* %scevgep39.12, align 1
  %scevgep28.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5008, i64 0, i64 0, i64 1
  %5015 = bitcast i8* %scevgep28.13 to [61 x [61 x i8]]*
  %scevgep41.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5009, i64 0, i64 1, i64 0
  %5016 = bitcast i8* %scevgep41.13 to [61 x [61 x i8]]*
  %call16.13.1 = call zeroext i8 (...) @rand()
  store i8 %call16.13.1, i8* %scevgep28.13, align 1
  %5017 = load i8, i8* %scevgep28.13, align 1
  %conv23.13.1 = zext i8 %5017 to i32
  %5018 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.1 = getelementptr i8, i8* %b, i64 15
  %5019 = load i8, i8* %scevgep34.13.1, align 1
  %call28.13.1 = call zeroext i8 @mult(i8 zeroext %5018, i8 zeroext %5019)
  %conv29.13.1 = zext i8 %call28.13.1 to i32
  %xor.13.1 = xor i32 %conv23.13.1, %conv29.13.1
  %scevgep35.13.1 = getelementptr i8, i8* %a, i64 15
  %5020 = load i8, i8* %scevgep35.13.1, align 1
  %5021 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.1 = call zeroext i8 @mult(i8 zeroext %5020, i8 zeroext %5021)
  %conv35.13.1 = zext i8 %call34.13.1 to i32
  %xor36.13.1 = xor i32 %xor.13.1, %conv35.13.1
  %conv37.13.1 = trunc i32 %xor36.13.1 to i8
  store i8 %conv37.13.1, i8* %scevgep41.13, align 1
  %scevgep28.13.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5015, i64 0, i64 0, i64 1
  %5022 = bitcast i8* %scevgep28.13.1 to [61 x [61 x i8]]*
  %scevgep41.13.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5016, i64 0, i64 1, i64 0
  %5023 = bitcast i8* %scevgep41.13.1 to [61 x [61 x i8]]*
  %call16.13.2 = call zeroext i8 (...) @rand()
  store i8 %call16.13.2, i8* %scevgep28.13.1, align 1
  %5024 = load i8, i8* %scevgep28.13.1, align 1
  %conv23.13.2 = zext i8 %5024 to i32
  %5025 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.2 = getelementptr i8, i8* %b, i64 16
  %5026 = load i8, i8* %scevgep34.13.2, align 1
  %call28.13.2 = call zeroext i8 @mult(i8 zeroext %5025, i8 zeroext %5026)
  %conv29.13.2 = zext i8 %call28.13.2 to i32
  %xor.13.2 = xor i32 %conv23.13.2, %conv29.13.2
  %scevgep35.13.2 = getelementptr i8, i8* %a, i64 16
  %5027 = load i8, i8* %scevgep35.13.2, align 1
  %5028 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.2 = call zeroext i8 @mult(i8 zeroext %5027, i8 zeroext %5028)
  %conv35.13.2 = zext i8 %call34.13.2 to i32
  %xor36.13.2 = xor i32 %xor.13.2, %conv35.13.2
  %conv37.13.2 = trunc i32 %xor36.13.2 to i8
  store i8 %conv37.13.2, i8* %scevgep41.13.1, align 1
  %scevgep28.13.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5022, i64 0, i64 0, i64 1
  %5029 = bitcast i8* %scevgep28.13.2 to [61 x [61 x i8]]*
  %scevgep41.13.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5023, i64 0, i64 1, i64 0
  %5030 = bitcast i8* %scevgep41.13.2 to [61 x [61 x i8]]*
  %call16.13.3 = call zeroext i8 (...) @rand()
  store i8 %call16.13.3, i8* %scevgep28.13.2, align 1
  %5031 = load i8, i8* %scevgep28.13.2, align 1
  %conv23.13.3 = zext i8 %5031 to i32
  %5032 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.3 = getelementptr i8, i8* %b, i64 17
  %5033 = load i8, i8* %scevgep34.13.3, align 1
  %call28.13.3 = call zeroext i8 @mult(i8 zeroext %5032, i8 zeroext %5033)
  %conv29.13.3 = zext i8 %call28.13.3 to i32
  %xor.13.3 = xor i32 %conv23.13.3, %conv29.13.3
  %scevgep35.13.3 = getelementptr i8, i8* %a, i64 17
  %5034 = load i8, i8* %scevgep35.13.3, align 1
  %5035 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.3 = call zeroext i8 @mult(i8 zeroext %5034, i8 zeroext %5035)
  %conv35.13.3 = zext i8 %call34.13.3 to i32
  %xor36.13.3 = xor i32 %xor.13.3, %conv35.13.3
  %conv37.13.3 = trunc i32 %xor36.13.3 to i8
  store i8 %conv37.13.3, i8* %scevgep41.13.2, align 1
  %scevgep28.13.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5029, i64 0, i64 0, i64 1
  %5036 = bitcast i8* %scevgep28.13.3 to [61 x [61 x i8]]*
  %scevgep41.13.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5030, i64 0, i64 1, i64 0
  %5037 = bitcast i8* %scevgep41.13.3 to [61 x [61 x i8]]*
  %call16.13.4 = call zeroext i8 (...) @rand()
  store i8 %call16.13.4, i8* %scevgep28.13.3, align 1
  %5038 = load i8, i8* %scevgep28.13.3, align 1
  %conv23.13.4 = zext i8 %5038 to i32
  %5039 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.4 = getelementptr i8, i8* %b, i64 18
  %5040 = load i8, i8* %scevgep34.13.4, align 1
  %call28.13.4 = call zeroext i8 @mult(i8 zeroext %5039, i8 zeroext %5040)
  %conv29.13.4 = zext i8 %call28.13.4 to i32
  %xor.13.4 = xor i32 %conv23.13.4, %conv29.13.4
  %scevgep35.13.4 = getelementptr i8, i8* %a, i64 18
  %5041 = load i8, i8* %scevgep35.13.4, align 1
  %5042 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.4 = call zeroext i8 @mult(i8 zeroext %5041, i8 zeroext %5042)
  %conv35.13.4 = zext i8 %call34.13.4 to i32
  %xor36.13.4 = xor i32 %xor.13.4, %conv35.13.4
  %conv37.13.4 = trunc i32 %xor36.13.4 to i8
  store i8 %conv37.13.4, i8* %scevgep41.13.3, align 1
  %scevgep28.13.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5036, i64 0, i64 0, i64 1
  %5043 = bitcast i8* %scevgep28.13.4 to [61 x [61 x i8]]*
  %scevgep41.13.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5037, i64 0, i64 1, i64 0
  %5044 = bitcast i8* %scevgep41.13.4 to [61 x [61 x i8]]*
  %call16.13.5 = call zeroext i8 (...) @rand()
  store i8 %call16.13.5, i8* %scevgep28.13.4, align 1
  %5045 = load i8, i8* %scevgep28.13.4, align 1
  %conv23.13.5 = zext i8 %5045 to i32
  %5046 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.5 = getelementptr i8, i8* %b, i64 19
  %5047 = load i8, i8* %scevgep34.13.5, align 1
  %call28.13.5 = call zeroext i8 @mult(i8 zeroext %5046, i8 zeroext %5047)
  %conv29.13.5 = zext i8 %call28.13.5 to i32
  %xor.13.5 = xor i32 %conv23.13.5, %conv29.13.5
  %scevgep35.13.5 = getelementptr i8, i8* %a, i64 19
  %5048 = load i8, i8* %scevgep35.13.5, align 1
  %5049 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.5 = call zeroext i8 @mult(i8 zeroext %5048, i8 zeroext %5049)
  %conv35.13.5 = zext i8 %call34.13.5 to i32
  %xor36.13.5 = xor i32 %xor.13.5, %conv35.13.5
  %conv37.13.5 = trunc i32 %xor36.13.5 to i8
  store i8 %conv37.13.5, i8* %scevgep41.13.4, align 1
  %scevgep28.13.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5043, i64 0, i64 0, i64 1
  %5050 = bitcast i8* %scevgep28.13.5 to [61 x [61 x i8]]*
  %scevgep41.13.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5044, i64 0, i64 1, i64 0
  %5051 = bitcast i8* %scevgep41.13.5 to [61 x [61 x i8]]*
  %call16.13.6 = call zeroext i8 (...) @rand()
  store i8 %call16.13.6, i8* %scevgep28.13.5, align 1
  %5052 = load i8, i8* %scevgep28.13.5, align 1
  %conv23.13.6 = zext i8 %5052 to i32
  %5053 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.6 = getelementptr i8, i8* %b, i64 20
  %5054 = load i8, i8* %scevgep34.13.6, align 1
  %call28.13.6 = call zeroext i8 @mult(i8 zeroext %5053, i8 zeroext %5054)
  %conv29.13.6 = zext i8 %call28.13.6 to i32
  %xor.13.6 = xor i32 %conv23.13.6, %conv29.13.6
  %scevgep35.13.6 = getelementptr i8, i8* %a, i64 20
  %5055 = load i8, i8* %scevgep35.13.6, align 1
  %5056 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.6 = call zeroext i8 @mult(i8 zeroext %5055, i8 zeroext %5056)
  %conv35.13.6 = zext i8 %call34.13.6 to i32
  %xor36.13.6 = xor i32 %xor.13.6, %conv35.13.6
  %conv37.13.6 = trunc i32 %xor36.13.6 to i8
  store i8 %conv37.13.6, i8* %scevgep41.13.5, align 1
  %scevgep28.13.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5050, i64 0, i64 0, i64 1
  %5057 = bitcast i8* %scevgep28.13.6 to [61 x [61 x i8]]*
  %scevgep41.13.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5051, i64 0, i64 1, i64 0
  %5058 = bitcast i8* %scevgep41.13.6 to [61 x [61 x i8]]*
  %call16.13.7 = call zeroext i8 (...) @rand()
  store i8 %call16.13.7, i8* %scevgep28.13.6, align 1
  %5059 = load i8, i8* %scevgep28.13.6, align 1
  %conv23.13.7 = zext i8 %5059 to i32
  %5060 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.7 = getelementptr i8, i8* %b, i64 21
  %5061 = load i8, i8* %scevgep34.13.7, align 1
  %call28.13.7 = call zeroext i8 @mult(i8 zeroext %5060, i8 zeroext %5061)
  %conv29.13.7 = zext i8 %call28.13.7 to i32
  %xor.13.7 = xor i32 %conv23.13.7, %conv29.13.7
  %scevgep35.13.7 = getelementptr i8, i8* %a, i64 21
  %5062 = load i8, i8* %scevgep35.13.7, align 1
  %5063 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.7 = call zeroext i8 @mult(i8 zeroext %5062, i8 zeroext %5063)
  %conv35.13.7 = zext i8 %call34.13.7 to i32
  %xor36.13.7 = xor i32 %xor.13.7, %conv35.13.7
  %conv37.13.7 = trunc i32 %xor36.13.7 to i8
  store i8 %conv37.13.7, i8* %scevgep41.13.6, align 1
  %scevgep28.13.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5057, i64 0, i64 0, i64 1
  %5064 = bitcast i8* %scevgep28.13.7 to [61 x [61 x i8]]*
  %scevgep41.13.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5058, i64 0, i64 1, i64 0
  %5065 = bitcast i8* %scevgep41.13.7 to [61 x [61 x i8]]*
  %call16.13.8 = call zeroext i8 (...) @rand()
  store i8 %call16.13.8, i8* %scevgep28.13.7, align 1
  %5066 = load i8, i8* %scevgep28.13.7, align 1
  %conv23.13.8 = zext i8 %5066 to i32
  %5067 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.8 = getelementptr i8, i8* %b, i64 22
  %5068 = load i8, i8* %scevgep34.13.8, align 1
  %call28.13.8 = call zeroext i8 @mult(i8 zeroext %5067, i8 zeroext %5068)
  %conv29.13.8 = zext i8 %call28.13.8 to i32
  %xor.13.8 = xor i32 %conv23.13.8, %conv29.13.8
  %scevgep35.13.8 = getelementptr i8, i8* %a, i64 22
  %5069 = load i8, i8* %scevgep35.13.8, align 1
  %5070 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.8 = call zeroext i8 @mult(i8 zeroext %5069, i8 zeroext %5070)
  %conv35.13.8 = zext i8 %call34.13.8 to i32
  %xor36.13.8 = xor i32 %xor.13.8, %conv35.13.8
  %conv37.13.8 = trunc i32 %xor36.13.8 to i8
  store i8 %conv37.13.8, i8* %scevgep41.13.7, align 1
  %scevgep28.13.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5064, i64 0, i64 0, i64 1
  %5071 = bitcast i8* %scevgep28.13.8 to [61 x [61 x i8]]*
  %scevgep41.13.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5065, i64 0, i64 1, i64 0
  %5072 = bitcast i8* %scevgep41.13.8 to [61 x [61 x i8]]*
  %call16.13.9 = call zeroext i8 (...) @rand()
  store i8 %call16.13.9, i8* %scevgep28.13.8, align 1
  %5073 = load i8, i8* %scevgep28.13.8, align 1
  %conv23.13.9 = zext i8 %5073 to i32
  %5074 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.9 = getelementptr i8, i8* %b, i64 23
  %5075 = load i8, i8* %scevgep34.13.9, align 1
  %call28.13.9 = call zeroext i8 @mult(i8 zeroext %5074, i8 zeroext %5075)
  %conv29.13.9 = zext i8 %call28.13.9 to i32
  %xor.13.9 = xor i32 %conv23.13.9, %conv29.13.9
  %scevgep35.13.9 = getelementptr i8, i8* %a, i64 23
  %5076 = load i8, i8* %scevgep35.13.9, align 1
  %5077 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.9 = call zeroext i8 @mult(i8 zeroext %5076, i8 zeroext %5077)
  %conv35.13.9 = zext i8 %call34.13.9 to i32
  %xor36.13.9 = xor i32 %xor.13.9, %conv35.13.9
  %conv37.13.9 = trunc i32 %xor36.13.9 to i8
  store i8 %conv37.13.9, i8* %scevgep41.13.8, align 1
  %scevgep28.13.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5071, i64 0, i64 0, i64 1
  %5078 = bitcast i8* %scevgep28.13.9 to [61 x [61 x i8]]*
  %scevgep41.13.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5072, i64 0, i64 1, i64 0
  %5079 = bitcast i8* %scevgep41.13.9 to [61 x [61 x i8]]*
  %call16.13.10 = call zeroext i8 (...) @rand()
  store i8 %call16.13.10, i8* %scevgep28.13.9, align 1
  %5080 = load i8, i8* %scevgep28.13.9, align 1
  %conv23.13.10 = zext i8 %5080 to i32
  %5081 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.10 = getelementptr i8, i8* %b, i64 24
  %5082 = load i8, i8* %scevgep34.13.10, align 1
  %call28.13.10 = call zeroext i8 @mult(i8 zeroext %5081, i8 zeroext %5082)
  %conv29.13.10 = zext i8 %call28.13.10 to i32
  %xor.13.10 = xor i32 %conv23.13.10, %conv29.13.10
  %scevgep35.13.10 = getelementptr i8, i8* %a, i64 24
  %5083 = load i8, i8* %scevgep35.13.10, align 1
  %5084 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.10 = call zeroext i8 @mult(i8 zeroext %5083, i8 zeroext %5084)
  %conv35.13.10 = zext i8 %call34.13.10 to i32
  %xor36.13.10 = xor i32 %xor.13.10, %conv35.13.10
  %conv37.13.10 = trunc i32 %xor36.13.10 to i8
  store i8 %conv37.13.10, i8* %scevgep41.13.9, align 1
  %scevgep28.13.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5078, i64 0, i64 0, i64 1
  %5085 = bitcast i8* %scevgep28.13.10 to [61 x [61 x i8]]*
  %scevgep41.13.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5079, i64 0, i64 1, i64 0
  %5086 = bitcast i8* %scevgep41.13.10 to [61 x [61 x i8]]*
  %call16.13.11 = call zeroext i8 (...) @rand()
  store i8 %call16.13.11, i8* %scevgep28.13.10, align 1
  %5087 = load i8, i8* %scevgep28.13.10, align 1
  %conv23.13.11 = zext i8 %5087 to i32
  %5088 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.11 = getelementptr i8, i8* %b, i64 25
  %5089 = load i8, i8* %scevgep34.13.11, align 1
  %call28.13.11 = call zeroext i8 @mult(i8 zeroext %5088, i8 zeroext %5089)
  %conv29.13.11 = zext i8 %call28.13.11 to i32
  %xor.13.11 = xor i32 %conv23.13.11, %conv29.13.11
  %scevgep35.13.11 = getelementptr i8, i8* %a, i64 25
  %5090 = load i8, i8* %scevgep35.13.11, align 1
  %5091 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.11 = call zeroext i8 @mult(i8 zeroext %5090, i8 zeroext %5091)
  %conv35.13.11 = zext i8 %call34.13.11 to i32
  %xor36.13.11 = xor i32 %xor.13.11, %conv35.13.11
  %conv37.13.11 = trunc i32 %xor36.13.11 to i8
  store i8 %conv37.13.11, i8* %scevgep41.13.10, align 1
  %scevgep28.13.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5085, i64 0, i64 0, i64 1
  %5092 = bitcast i8* %scevgep28.13.11 to [61 x [61 x i8]]*
  %scevgep41.13.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5086, i64 0, i64 1, i64 0
  %5093 = bitcast i8* %scevgep41.13.11 to [61 x [61 x i8]]*
  %call16.13.12 = call zeroext i8 (...) @rand()
  store i8 %call16.13.12, i8* %scevgep28.13.11, align 1
  %5094 = load i8, i8* %scevgep28.13.11, align 1
  %conv23.13.12 = zext i8 %5094 to i32
  %5095 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.12 = getelementptr i8, i8* %b, i64 26
  %5096 = load i8, i8* %scevgep34.13.12, align 1
  %call28.13.12 = call zeroext i8 @mult(i8 zeroext %5095, i8 zeroext %5096)
  %conv29.13.12 = zext i8 %call28.13.12 to i32
  %xor.13.12 = xor i32 %conv23.13.12, %conv29.13.12
  %scevgep35.13.12 = getelementptr i8, i8* %a, i64 26
  %5097 = load i8, i8* %scevgep35.13.12, align 1
  %5098 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.12 = call zeroext i8 @mult(i8 zeroext %5097, i8 zeroext %5098)
  %conv35.13.12 = zext i8 %call34.13.12 to i32
  %xor36.13.12 = xor i32 %xor.13.12, %conv35.13.12
  %conv37.13.12 = trunc i32 %xor36.13.12 to i8
  store i8 %conv37.13.12, i8* %scevgep41.13.11, align 1
  %scevgep28.13.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5092, i64 0, i64 0, i64 1
  %5099 = bitcast i8* %scevgep28.13.12 to [61 x [61 x i8]]*
  %scevgep41.13.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5093, i64 0, i64 1, i64 0
  %5100 = bitcast i8* %scevgep41.13.12 to [61 x [61 x i8]]*
  %call16.13.13 = call zeroext i8 (...) @rand()
  store i8 %call16.13.13, i8* %scevgep28.13.12, align 1
  %5101 = load i8, i8* %scevgep28.13.12, align 1
  %conv23.13.13 = zext i8 %5101 to i32
  %5102 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.13 = getelementptr i8, i8* %b, i64 27
  %5103 = load i8, i8* %scevgep34.13.13, align 1
  %call28.13.13 = call zeroext i8 @mult(i8 zeroext %5102, i8 zeroext %5103)
  %conv29.13.13 = zext i8 %call28.13.13 to i32
  %xor.13.13 = xor i32 %conv23.13.13, %conv29.13.13
  %scevgep35.13.13 = getelementptr i8, i8* %a, i64 27
  %5104 = load i8, i8* %scevgep35.13.13, align 1
  %5105 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.13 = call zeroext i8 @mult(i8 zeroext %5104, i8 zeroext %5105)
  %conv35.13.13 = zext i8 %call34.13.13 to i32
  %xor36.13.13 = xor i32 %xor.13.13, %conv35.13.13
  %conv37.13.13 = trunc i32 %xor36.13.13 to i8
  store i8 %conv37.13.13, i8* %scevgep41.13.12, align 1
  %scevgep28.13.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5099, i64 0, i64 0, i64 1
  %5106 = bitcast i8* %scevgep28.13.13 to [61 x [61 x i8]]*
  %scevgep41.13.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5100, i64 0, i64 1, i64 0
  %5107 = bitcast i8* %scevgep41.13.13 to [61 x [61 x i8]]*
  %call16.13.14 = call zeroext i8 (...) @rand()
  store i8 %call16.13.14, i8* %scevgep28.13.13, align 1
  %5108 = load i8, i8* %scevgep28.13.13, align 1
  %conv23.13.14 = zext i8 %5108 to i32
  %5109 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.14 = getelementptr i8, i8* %b, i64 28
  %5110 = load i8, i8* %scevgep34.13.14, align 1
  %call28.13.14 = call zeroext i8 @mult(i8 zeroext %5109, i8 zeroext %5110)
  %conv29.13.14 = zext i8 %call28.13.14 to i32
  %xor.13.14 = xor i32 %conv23.13.14, %conv29.13.14
  %scevgep35.13.14 = getelementptr i8, i8* %a, i64 28
  %5111 = load i8, i8* %scevgep35.13.14, align 1
  %5112 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.14 = call zeroext i8 @mult(i8 zeroext %5111, i8 zeroext %5112)
  %conv35.13.14 = zext i8 %call34.13.14 to i32
  %xor36.13.14 = xor i32 %xor.13.14, %conv35.13.14
  %conv37.13.14 = trunc i32 %xor36.13.14 to i8
  store i8 %conv37.13.14, i8* %scevgep41.13.13, align 1
  %scevgep28.13.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5106, i64 0, i64 0, i64 1
  %5113 = bitcast i8* %scevgep28.13.14 to [61 x [61 x i8]]*
  %scevgep41.13.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5107, i64 0, i64 1, i64 0
  %5114 = bitcast i8* %scevgep41.13.14 to [61 x [61 x i8]]*
  %call16.13.15 = call zeroext i8 (...) @rand()
  store i8 %call16.13.15, i8* %scevgep28.13.14, align 1
  %5115 = load i8, i8* %scevgep28.13.14, align 1
  %conv23.13.15 = zext i8 %5115 to i32
  %5116 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.15 = getelementptr i8, i8* %b, i64 29
  %5117 = load i8, i8* %scevgep34.13.15, align 1
  %call28.13.15 = call zeroext i8 @mult(i8 zeroext %5116, i8 zeroext %5117)
  %conv29.13.15 = zext i8 %call28.13.15 to i32
  %xor.13.15 = xor i32 %conv23.13.15, %conv29.13.15
  %scevgep35.13.15 = getelementptr i8, i8* %a, i64 29
  %5118 = load i8, i8* %scevgep35.13.15, align 1
  %5119 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.15 = call zeroext i8 @mult(i8 zeroext %5118, i8 zeroext %5119)
  %conv35.13.15 = zext i8 %call34.13.15 to i32
  %xor36.13.15 = xor i32 %xor.13.15, %conv35.13.15
  %conv37.13.15 = trunc i32 %xor36.13.15 to i8
  store i8 %conv37.13.15, i8* %scevgep41.13.14, align 1
  %scevgep28.13.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5113, i64 0, i64 0, i64 1
  %5120 = bitcast i8* %scevgep28.13.15 to [61 x [61 x i8]]*
  %scevgep41.13.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5114, i64 0, i64 1, i64 0
  %5121 = bitcast i8* %scevgep41.13.15 to [61 x [61 x i8]]*
  %call16.13.16 = call zeroext i8 (...) @rand()
  store i8 %call16.13.16, i8* %scevgep28.13.15, align 1
  %5122 = load i8, i8* %scevgep28.13.15, align 1
  %conv23.13.16 = zext i8 %5122 to i32
  %5123 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.16 = getelementptr i8, i8* %b, i64 30
  %5124 = load i8, i8* %scevgep34.13.16, align 1
  %call28.13.16 = call zeroext i8 @mult(i8 zeroext %5123, i8 zeroext %5124)
  %conv29.13.16 = zext i8 %call28.13.16 to i32
  %xor.13.16 = xor i32 %conv23.13.16, %conv29.13.16
  %scevgep35.13.16 = getelementptr i8, i8* %a, i64 30
  %5125 = load i8, i8* %scevgep35.13.16, align 1
  %5126 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.16 = call zeroext i8 @mult(i8 zeroext %5125, i8 zeroext %5126)
  %conv35.13.16 = zext i8 %call34.13.16 to i32
  %xor36.13.16 = xor i32 %xor.13.16, %conv35.13.16
  %conv37.13.16 = trunc i32 %xor36.13.16 to i8
  store i8 %conv37.13.16, i8* %scevgep41.13.15, align 1
  %scevgep28.13.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5120, i64 0, i64 0, i64 1
  %5127 = bitcast i8* %scevgep28.13.16 to [61 x [61 x i8]]*
  %scevgep41.13.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5121, i64 0, i64 1, i64 0
  %5128 = bitcast i8* %scevgep41.13.16 to [61 x [61 x i8]]*
  %call16.13.17 = call zeroext i8 (...) @rand()
  store i8 %call16.13.17, i8* %scevgep28.13.16, align 1
  %5129 = load i8, i8* %scevgep28.13.16, align 1
  %conv23.13.17 = zext i8 %5129 to i32
  %5130 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.17 = getelementptr i8, i8* %b, i64 31
  %5131 = load i8, i8* %scevgep34.13.17, align 1
  %call28.13.17 = call zeroext i8 @mult(i8 zeroext %5130, i8 zeroext %5131)
  %conv29.13.17 = zext i8 %call28.13.17 to i32
  %xor.13.17 = xor i32 %conv23.13.17, %conv29.13.17
  %scevgep35.13.17 = getelementptr i8, i8* %a, i64 31
  %5132 = load i8, i8* %scevgep35.13.17, align 1
  %5133 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.17 = call zeroext i8 @mult(i8 zeroext %5132, i8 zeroext %5133)
  %conv35.13.17 = zext i8 %call34.13.17 to i32
  %xor36.13.17 = xor i32 %xor.13.17, %conv35.13.17
  %conv37.13.17 = trunc i32 %xor36.13.17 to i8
  store i8 %conv37.13.17, i8* %scevgep41.13.16, align 1
  %scevgep28.13.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5127, i64 0, i64 0, i64 1
  %5134 = bitcast i8* %scevgep28.13.17 to [61 x [61 x i8]]*
  %scevgep41.13.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5128, i64 0, i64 1, i64 0
  %5135 = bitcast i8* %scevgep41.13.17 to [61 x [61 x i8]]*
  %call16.13.18 = call zeroext i8 (...) @rand()
  store i8 %call16.13.18, i8* %scevgep28.13.17, align 1
  %5136 = load i8, i8* %scevgep28.13.17, align 1
  %conv23.13.18 = zext i8 %5136 to i32
  %5137 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.18 = getelementptr i8, i8* %b, i64 32
  %5138 = load i8, i8* %scevgep34.13.18, align 1
  %call28.13.18 = call zeroext i8 @mult(i8 zeroext %5137, i8 zeroext %5138)
  %conv29.13.18 = zext i8 %call28.13.18 to i32
  %xor.13.18 = xor i32 %conv23.13.18, %conv29.13.18
  %scevgep35.13.18 = getelementptr i8, i8* %a, i64 32
  %5139 = load i8, i8* %scevgep35.13.18, align 1
  %5140 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.18 = call zeroext i8 @mult(i8 zeroext %5139, i8 zeroext %5140)
  %conv35.13.18 = zext i8 %call34.13.18 to i32
  %xor36.13.18 = xor i32 %xor.13.18, %conv35.13.18
  %conv37.13.18 = trunc i32 %xor36.13.18 to i8
  store i8 %conv37.13.18, i8* %scevgep41.13.17, align 1
  %scevgep28.13.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5134, i64 0, i64 0, i64 1
  %5141 = bitcast i8* %scevgep28.13.18 to [61 x [61 x i8]]*
  %scevgep41.13.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5135, i64 0, i64 1, i64 0
  %5142 = bitcast i8* %scevgep41.13.18 to [61 x [61 x i8]]*
  %call16.13.19 = call zeroext i8 (...) @rand()
  store i8 %call16.13.19, i8* %scevgep28.13.18, align 1
  %5143 = load i8, i8* %scevgep28.13.18, align 1
  %conv23.13.19 = zext i8 %5143 to i32
  %5144 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.19 = getelementptr i8, i8* %b, i64 33
  %5145 = load i8, i8* %scevgep34.13.19, align 1
  %call28.13.19 = call zeroext i8 @mult(i8 zeroext %5144, i8 zeroext %5145)
  %conv29.13.19 = zext i8 %call28.13.19 to i32
  %xor.13.19 = xor i32 %conv23.13.19, %conv29.13.19
  %scevgep35.13.19 = getelementptr i8, i8* %a, i64 33
  %5146 = load i8, i8* %scevgep35.13.19, align 1
  %5147 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.19 = call zeroext i8 @mult(i8 zeroext %5146, i8 zeroext %5147)
  %conv35.13.19 = zext i8 %call34.13.19 to i32
  %xor36.13.19 = xor i32 %xor.13.19, %conv35.13.19
  %conv37.13.19 = trunc i32 %xor36.13.19 to i8
  store i8 %conv37.13.19, i8* %scevgep41.13.18, align 1
  %scevgep28.13.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5141, i64 0, i64 0, i64 1
  %5148 = bitcast i8* %scevgep28.13.19 to [61 x [61 x i8]]*
  %scevgep41.13.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5142, i64 0, i64 1, i64 0
  %5149 = bitcast i8* %scevgep41.13.19 to [61 x [61 x i8]]*
  %call16.13.20 = call zeroext i8 (...) @rand()
  store i8 %call16.13.20, i8* %scevgep28.13.19, align 1
  %5150 = load i8, i8* %scevgep28.13.19, align 1
  %conv23.13.20 = zext i8 %5150 to i32
  %5151 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.20 = getelementptr i8, i8* %b, i64 34
  %5152 = load i8, i8* %scevgep34.13.20, align 1
  %call28.13.20 = call zeroext i8 @mult(i8 zeroext %5151, i8 zeroext %5152)
  %conv29.13.20 = zext i8 %call28.13.20 to i32
  %xor.13.20 = xor i32 %conv23.13.20, %conv29.13.20
  %scevgep35.13.20 = getelementptr i8, i8* %a, i64 34
  %5153 = load i8, i8* %scevgep35.13.20, align 1
  %5154 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.20 = call zeroext i8 @mult(i8 zeroext %5153, i8 zeroext %5154)
  %conv35.13.20 = zext i8 %call34.13.20 to i32
  %xor36.13.20 = xor i32 %xor.13.20, %conv35.13.20
  %conv37.13.20 = trunc i32 %xor36.13.20 to i8
  store i8 %conv37.13.20, i8* %scevgep41.13.19, align 1
  %scevgep28.13.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5148, i64 0, i64 0, i64 1
  %5155 = bitcast i8* %scevgep28.13.20 to [61 x [61 x i8]]*
  %scevgep41.13.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5149, i64 0, i64 1, i64 0
  %5156 = bitcast i8* %scevgep41.13.20 to [61 x [61 x i8]]*
  %call16.13.21 = call zeroext i8 (...) @rand()
  store i8 %call16.13.21, i8* %scevgep28.13.20, align 1
  %5157 = load i8, i8* %scevgep28.13.20, align 1
  %conv23.13.21 = zext i8 %5157 to i32
  %5158 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.21 = getelementptr i8, i8* %b, i64 35
  %5159 = load i8, i8* %scevgep34.13.21, align 1
  %call28.13.21 = call zeroext i8 @mult(i8 zeroext %5158, i8 zeroext %5159)
  %conv29.13.21 = zext i8 %call28.13.21 to i32
  %xor.13.21 = xor i32 %conv23.13.21, %conv29.13.21
  %scevgep35.13.21 = getelementptr i8, i8* %a, i64 35
  %5160 = load i8, i8* %scevgep35.13.21, align 1
  %5161 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.21 = call zeroext i8 @mult(i8 zeroext %5160, i8 zeroext %5161)
  %conv35.13.21 = zext i8 %call34.13.21 to i32
  %xor36.13.21 = xor i32 %xor.13.21, %conv35.13.21
  %conv37.13.21 = trunc i32 %xor36.13.21 to i8
  store i8 %conv37.13.21, i8* %scevgep41.13.20, align 1
  %scevgep28.13.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5155, i64 0, i64 0, i64 1
  %5162 = bitcast i8* %scevgep28.13.21 to [61 x [61 x i8]]*
  %scevgep41.13.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5156, i64 0, i64 1, i64 0
  %5163 = bitcast i8* %scevgep41.13.21 to [61 x [61 x i8]]*
  %call16.13.22 = call zeroext i8 (...) @rand()
  store i8 %call16.13.22, i8* %scevgep28.13.21, align 1
  %5164 = load i8, i8* %scevgep28.13.21, align 1
  %conv23.13.22 = zext i8 %5164 to i32
  %5165 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.22 = getelementptr i8, i8* %b, i64 36
  %5166 = load i8, i8* %scevgep34.13.22, align 1
  %call28.13.22 = call zeroext i8 @mult(i8 zeroext %5165, i8 zeroext %5166)
  %conv29.13.22 = zext i8 %call28.13.22 to i32
  %xor.13.22 = xor i32 %conv23.13.22, %conv29.13.22
  %scevgep35.13.22 = getelementptr i8, i8* %a, i64 36
  %5167 = load i8, i8* %scevgep35.13.22, align 1
  %5168 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.22 = call zeroext i8 @mult(i8 zeroext %5167, i8 zeroext %5168)
  %conv35.13.22 = zext i8 %call34.13.22 to i32
  %xor36.13.22 = xor i32 %xor.13.22, %conv35.13.22
  %conv37.13.22 = trunc i32 %xor36.13.22 to i8
  store i8 %conv37.13.22, i8* %scevgep41.13.21, align 1
  %scevgep28.13.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5162, i64 0, i64 0, i64 1
  %5169 = bitcast i8* %scevgep28.13.22 to [61 x [61 x i8]]*
  %scevgep41.13.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5163, i64 0, i64 1, i64 0
  %5170 = bitcast i8* %scevgep41.13.22 to [61 x [61 x i8]]*
  %call16.13.23 = call zeroext i8 (...) @rand()
  store i8 %call16.13.23, i8* %scevgep28.13.22, align 1
  %5171 = load i8, i8* %scevgep28.13.22, align 1
  %conv23.13.23 = zext i8 %5171 to i32
  %5172 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.23 = getelementptr i8, i8* %b, i64 37
  %5173 = load i8, i8* %scevgep34.13.23, align 1
  %call28.13.23 = call zeroext i8 @mult(i8 zeroext %5172, i8 zeroext %5173)
  %conv29.13.23 = zext i8 %call28.13.23 to i32
  %xor.13.23 = xor i32 %conv23.13.23, %conv29.13.23
  %scevgep35.13.23 = getelementptr i8, i8* %a, i64 37
  %5174 = load i8, i8* %scevgep35.13.23, align 1
  %5175 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.23 = call zeroext i8 @mult(i8 zeroext %5174, i8 zeroext %5175)
  %conv35.13.23 = zext i8 %call34.13.23 to i32
  %xor36.13.23 = xor i32 %xor.13.23, %conv35.13.23
  %conv37.13.23 = trunc i32 %xor36.13.23 to i8
  store i8 %conv37.13.23, i8* %scevgep41.13.22, align 1
  %scevgep28.13.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5169, i64 0, i64 0, i64 1
  %5176 = bitcast i8* %scevgep28.13.23 to [61 x [61 x i8]]*
  %scevgep41.13.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5170, i64 0, i64 1, i64 0
  %5177 = bitcast i8* %scevgep41.13.23 to [61 x [61 x i8]]*
  %call16.13.24 = call zeroext i8 (...) @rand()
  store i8 %call16.13.24, i8* %scevgep28.13.23, align 1
  %5178 = load i8, i8* %scevgep28.13.23, align 1
  %conv23.13.24 = zext i8 %5178 to i32
  %5179 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.24 = getelementptr i8, i8* %b, i64 38
  %5180 = load i8, i8* %scevgep34.13.24, align 1
  %call28.13.24 = call zeroext i8 @mult(i8 zeroext %5179, i8 zeroext %5180)
  %conv29.13.24 = zext i8 %call28.13.24 to i32
  %xor.13.24 = xor i32 %conv23.13.24, %conv29.13.24
  %scevgep35.13.24 = getelementptr i8, i8* %a, i64 38
  %5181 = load i8, i8* %scevgep35.13.24, align 1
  %5182 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.24 = call zeroext i8 @mult(i8 zeroext %5181, i8 zeroext %5182)
  %conv35.13.24 = zext i8 %call34.13.24 to i32
  %xor36.13.24 = xor i32 %xor.13.24, %conv35.13.24
  %conv37.13.24 = trunc i32 %xor36.13.24 to i8
  store i8 %conv37.13.24, i8* %scevgep41.13.23, align 1
  %scevgep28.13.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5176, i64 0, i64 0, i64 1
  %5183 = bitcast i8* %scevgep28.13.24 to [61 x [61 x i8]]*
  %scevgep41.13.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5177, i64 0, i64 1, i64 0
  %5184 = bitcast i8* %scevgep41.13.24 to [61 x [61 x i8]]*
  %call16.13.25 = call zeroext i8 (...) @rand()
  store i8 %call16.13.25, i8* %scevgep28.13.24, align 1
  %5185 = load i8, i8* %scevgep28.13.24, align 1
  %conv23.13.25 = zext i8 %5185 to i32
  %5186 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.25 = getelementptr i8, i8* %b, i64 39
  %5187 = load i8, i8* %scevgep34.13.25, align 1
  %call28.13.25 = call zeroext i8 @mult(i8 zeroext %5186, i8 zeroext %5187)
  %conv29.13.25 = zext i8 %call28.13.25 to i32
  %xor.13.25 = xor i32 %conv23.13.25, %conv29.13.25
  %scevgep35.13.25 = getelementptr i8, i8* %a, i64 39
  %5188 = load i8, i8* %scevgep35.13.25, align 1
  %5189 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.25 = call zeroext i8 @mult(i8 zeroext %5188, i8 zeroext %5189)
  %conv35.13.25 = zext i8 %call34.13.25 to i32
  %xor36.13.25 = xor i32 %xor.13.25, %conv35.13.25
  %conv37.13.25 = trunc i32 %xor36.13.25 to i8
  store i8 %conv37.13.25, i8* %scevgep41.13.24, align 1
  %scevgep28.13.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5183, i64 0, i64 0, i64 1
  %5190 = bitcast i8* %scevgep28.13.25 to [61 x [61 x i8]]*
  %scevgep41.13.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5184, i64 0, i64 1, i64 0
  %5191 = bitcast i8* %scevgep41.13.25 to [61 x [61 x i8]]*
  %call16.13.26 = call zeroext i8 (...) @rand()
  store i8 %call16.13.26, i8* %scevgep28.13.25, align 1
  %5192 = load i8, i8* %scevgep28.13.25, align 1
  %conv23.13.26 = zext i8 %5192 to i32
  %5193 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.26 = getelementptr i8, i8* %b, i64 40
  %5194 = load i8, i8* %scevgep34.13.26, align 1
  %call28.13.26 = call zeroext i8 @mult(i8 zeroext %5193, i8 zeroext %5194)
  %conv29.13.26 = zext i8 %call28.13.26 to i32
  %xor.13.26 = xor i32 %conv23.13.26, %conv29.13.26
  %scevgep35.13.26 = getelementptr i8, i8* %a, i64 40
  %5195 = load i8, i8* %scevgep35.13.26, align 1
  %5196 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.26 = call zeroext i8 @mult(i8 zeroext %5195, i8 zeroext %5196)
  %conv35.13.26 = zext i8 %call34.13.26 to i32
  %xor36.13.26 = xor i32 %xor.13.26, %conv35.13.26
  %conv37.13.26 = trunc i32 %xor36.13.26 to i8
  store i8 %conv37.13.26, i8* %scevgep41.13.25, align 1
  %scevgep28.13.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5190, i64 0, i64 0, i64 1
  %5197 = bitcast i8* %scevgep28.13.26 to [61 x [61 x i8]]*
  %scevgep41.13.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5191, i64 0, i64 1, i64 0
  %5198 = bitcast i8* %scevgep41.13.26 to [61 x [61 x i8]]*
  %call16.13.27 = call zeroext i8 (...) @rand()
  store i8 %call16.13.27, i8* %scevgep28.13.26, align 1
  %5199 = load i8, i8* %scevgep28.13.26, align 1
  %conv23.13.27 = zext i8 %5199 to i32
  %5200 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.27 = getelementptr i8, i8* %b, i64 41
  %5201 = load i8, i8* %scevgep34.13.27, align 1
  %call28.13.27 = call zeroext i8 @mult(i8 zeroext %5200, i8 zeroext %5201)
  %conv29.13.27 = zext i8 %call28.13.27 to i32
  %xor.13.27 = xor i32 %conv23.13.27, %conv29.13.27
  %scevgep35.13.27 = getelementptr i8, i8* %a, i64 41
  %5202 = load i8, i8* %scevgep35.13.27, align 1
  %5203 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.27 = call zeroext i8 @mult(i8 zeroext %5202, i8 zeroext %5203)
  %conv35.13.27 = zext i8 %call34.13.27 to i32
  %xor36.13.27 = xor i32 %xor.13.27, %conv35.13.27
  %conv37.13.27 = trunc i32 %xor36.13.27 to i8
  store i8 %conv37.13.27, i8* %scevgep41.13.26, align 1
  %scevgep28.13.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5197, i64 0, i64 0, i64 1
  %5204 = bitcast i8* %scevgep28.13.27 to [61 x [61 x i8]]*
  %scevgep41.13.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5198, i64 0, i64 1, i64 0
  %5205 = bitcast i8* %scevgep41.13.27 to [61 x [61 x i8]]*
  %call16.13.28 = call zeroext i8 (...) @rand()
  store i8 %call16.13.28, i8* %scevgep28.13.27, align 1
  %5206 = load i8, i8* %scevgep28.13.27, align 1
  %conv23.13.28 = zext i8 %5206 to i32
  %5207 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.28 = getelementptr i8, i8* %b, i64 42
  %5208 = load i8, i8* %scevgep34.13.28, align 1
  %call28.13.28 = call zeroext i8 @mult(i8 zeroext %5207, i8 zeroext %5208)
  %conv29.13.28 = zext i8 %call28.13.28 to i32
  %xor.13.28 = xor i32 %conv23.13.28, %conv29.13.28
  %scevgep35.13.28 = getelementptr i8, i8* %a, i64 42
  %5209 = load i8, i8* %scevgep35.13.28, align 1
  %5210 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.28 = call zeroext i8 @mult(i8 zeroext %5209, i8 zeroext %5210)
  %conv35.13.28 = zext i8 %call34.13.28 to i32
  %xor36.13.28 = xor i32 %xor.13.28, %conv35.13.28
  %conv37.13.28 = trunc i32 %xor36.13.28 to i8
  store i8 %conv37.13.28, i8* %scevgep41.13.27, align 1
  %scevgep28.13.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5204, i64 0, i64 0, i64 1
  %5211 = bitcast i8* %scevgep28.13.28 to [61 x [61 x i8]]*
  %scevgep41.13.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5205, i64 0, i64 1, i64 0
  %5212 = bitcast i8* %scevgep41.13.28 to [61 x [61 x i8]]*
  %call16.13.29 = call zeroext i8 (...) @rand()
  store i8 %call16.13.29, i8* %scevgep28.13.28, align 1
  %5213 = load i8, i8* %scevgep28.13.28, align 1
  %conv23.13.29 = zext i8 %5213 to i32
  %5214 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.29 = getelementptr i8, i8* %b, i64 43
  %5215 = load i8, i8* %scevgep34.13.29, align 1
  %call28.13.29 = call zeroext i8 @mult(i8 zeroext %5214, i8 zeroext %5215)
  %conv29.13.29 = zext i8 %call28.13.29 to i32
  %xor.13.29 = xor i32 %conv23.13.29, %conv29.13.29
  %scevgep35.13.29 = getelementptr i8, i8* %a, i64 43
  %5216 = load i8, i8* %scevgep35.13.29, align 1
  %5217 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.29 = call zeroext i8 @mult(i8 zeroext %5216, i8 zeroext %5217)
  %conv35.13.29 = zext i8 %call34.13.29 to i32
  %xor36.13.29 = xor i32 %xor.13.29, %conv35.13.29
  %conv37.13.29 = trunc i32 %xor36.13.29 to i8
  store i8 %conv37.13.29, i8* %scevgep41.13.28, align 1
  %scevgep28.13.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5211, i64 0, i64 0, i64 1
  %5218 = bitcast i8* %scevgep28.13.29 to [61 x [61 x i8]]*
  %scevgep41.13.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5212, i64 0, i64 1, i64 0
  %5219 = bitcast i8* %scevgep41.13.29 to [61 x [61 x i8]]*
  %call16.13.30 = call zeroext i8 (...) @rand()
  store i8 %call16.13.30, i8* %scevgep28.13.29, align 1
  %5220 = load i8, i8* %scevgep28.13.29, align 1
  %conv23.13.30 = zext i8 %5220 to i32
  %5221 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.30 = getelementptr i8, i8* %b, i64 44
  %5222 = load i8, i8* %scevgep34.13.30, align 1
  %call28.13.30 = call zeroext i8 @mult(i8 zeroext %5221, i8 zeroext %5222)
  %conv29.13.30 = zext i8 %call28.13.30 to i32
  %xor.13.30 = xor i32 %conv23.13.30, %conv29.13.30
  %scevgep35.13.30 = getelementptr i8, i8* %a, i64 44
  %5223 = load i8, i8* %scevgep35.13.30, align 1
  %5224 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.30 = call zeroext i8 @mult(i8 zeroext %5223, i8 zeroext %5224)
  %conv35.13.30 = zext i8 %call34.13.30 to i32
  %xor36.13.30 = xor i32 %xor.13.30, %conv35.13.30
  %conv37.13.30 = trunc i32 %xor36.13.30 to i8
  store i8 %conv37.13.30, i8* %scevgep41.13.29, align 1
  %scevgep28.13.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5218, i64 0, i64 0, i64 1
  %5225 = bitcast i8* %scevgep28.13.30 to [61 x [61 x i8]]*
  %scevgep41.13.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5219, i64 0, i64 1, i64 0
  %5226 = bitcast i8* %scevgep41.13.30 to [61 x [61 x i8]]*
  %call16.13.31 = call zeroext i8 (...) @rand()
  store i8 %call16.13.31, i8* %scevgep28.13.30, align 1
  %5227 = load i8, i8* %scevgep28.13.30, align 1
  %conv23.13.31 = zext i8 %5227 to i32
  %5228 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.31 = getelementptr i8, i8* %b, i64 45
  %5229 = load i8, i8* %scevgep34.13.31, align 1
  %call28.13.31 = call zeroext i8 @mult(i8 zeroext %5228, i8 zeroext %5229)
  %conv29.13.31 = zext i8 %call28.13.31 to i32
  %xor.13.31 = xor i32 %conv23.13.31, %conv29.13.31
  %scevgep35.13.31 = getelementptr i8, i8* %a, i64 45
  %5230 = load i8, i8* %scevgep35.13.31, align 1
  %5231 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.31 = call zeroext i8 @mult(i8 zeroext %5230, i8 zeroext %5231)
  %conv35.13.31 = zext i8 %call34.13.31 to i32
  %xor36.13.31 = xor i32 %xor.13.31, %conv35.13.31
  %conv37.13.31 = trunc i32 %xor36.13.31 to i8
  store i8 %conv37.13.31, i8* %scevgep41.13.30, align 1
  %scevgep28.13.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5225, i64 0, i64 0, i64 1
  %5232 = bitcast i8* %scevgep28.13.31 to [61 x [61 x i8]]*
  %scevgep41.13.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5226, i64 0, i64 1, i64 0
  %5233 = bitcast i8* %scevgep41.13.31 to [61 x [61 x i8]]*
  %call16.13.32 = call zeroext i8 (...) @rand()
  store i8 %call16.13.32, i8* %scevgep28.13.31, align 1
  %5234 = load i8, i8* %scevgep28.13.31, align 1
  %conv23.13.32 = zext i8 %5234 to i32
  %5235 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.32 = getelementptr i8, i8* %b, i64 46
  %5236 = load i8, i8* %scevgep34.13.32, align 1
  %call28.13.32 = call zeroext i8 @mult(i8 zeroext %5235, i8 zeroext %5236)
  %conv29.13.32 = zext i8 %call28.13.32 to i32
  %xor.13.32 = xor i32 %conv23.13.32, %conv29.13.32
  %scevgep35.13.32 = getelementptr i8, i8* %a, i64 46
  %5237 = load i8, i8* %scevgep35.13.32, align 1
  %5238 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.32 = call zeroext i8 @mult(i8 zeroext %5237, i8 zeroext %5238)
  %conv35.13.32 = zext i8 %call34.13.32 to i32
  %xor36.13.32 = xor i32 %xor.13.32, %conv35.13.32
  %conv37.13.32 = trunc i32 %xor36.13.32 to i8
  store i8 %conv37.13.32, i8* %scevgep41.13.31, align 1
  %scevgep28.13.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5232, i64 0, i64 0, i64 1
  %5239 = bitcast i8* %scevgep28.13.32 to [61 x [61 x i8]]*
  %scevgep41.13.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5233, i64 0, i64 1, i64 0
  %5240 = bitcast i8* %scevgep41.13.32 to [61 x [61 x i8]]*
  %call16.13.33 = call zeroext i8 (...) @rand()
  store i8 %call16.13.33, i8* %scevgep28.13.32, align 1
  %5241 = load i8, i8* %scevgep28.13.32, align 1
  %conv23.13.33 = zext i8 %5241 to i32
  %5242 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.33 = getelementptr i8, i8* %b, i64 47
  %5243 = load i8, i8* %scevgep34.13.33, align 1
  %call28.13.33 = call zeroext i8 @mult(i8 zeroext %5242, i8 zeroext %5243)
  %conv29.13.33 = zext i8 %call28.13.33 to i32
  %xor.13.33 = xor i32 %conv23.13.33, %conv29.13.33
  %scevgep35.13.33 = getelementptr i8, i8* %a, i64 47
  %5244 = load i8, i8* %scevgep35.13.33, align 1
  %5245 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.33 = call zeroext i8 @mult(i8 zeroext %5244, i8 zeroext %5245)
  %conv35.13.33 = zext i8 %call34.13.33 to i32
  %xor36.13.33 = xor i32 %xor.13.33, %conv35.13.33
  %conv37.13.33 = trunc i32 %xor36.13.33 to i8
  store i8 %conv37.13.33, i8* %scevgep41.13.32, align 1
  %scevgep28.13.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5239, i64 0, i64 0, i64 1
  %5246 = bitcast i8* %scevgep28.13.33 to [61 x [61 x i8]]*
  %scevgep41.13.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5240, i64 0, i64 1, i64 0
  %5247 = bitcast i8* %scevgep41.13.33 to [61 x [61 x i8]]*
  %call16.13.34 = call zeroext i8 (...) @rand()
  store i8 %call16.13.34, i8* %scevgep28.13.33, align 1
  %5248 = load i8, i8* %scevgep28.13.33, align 1
  %conv23.13.34 = zext i8 %5248 to i32
  %5249 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.34 = getelementptr i8, i8* %b, i64 48
  %5250 = load i8, i8* %scevgep34.13.34, align 1
  %call28.13.34 = call zeroext i8 @mult(i8 zeroext %5249, i8 zeroext %5250)
  %conv29.13.34 = zext i8 %call28.13.34 to i32
  %xor.13.34 = xor i32 %conv23.13.34, %conv29.13.34
  %scevgep35.13.34 = getelementptr i8, i8* %a, i64 48
  %5251 = load i8, i8* %scevgep35.13.34, align 1
  %5252 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.34 = call zeroext i8 @mult(i8 zeroext %5251, i8 zeroext %5252)
  %conv35.13.34 = zext i8 %call34.13.34 to i32
  %xor36.13.34 = xor i32 %xor.13.34, %conv35.13.34
  %conv37.13.34 = trunc i32 %xor36.13.34 to i8
  store i8 %conv37.13.34, i8* %scevgep41.13.33, align 1
  %scevgep28.13.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5246, i64 0, i64 0, i64 1
  %5253 = bitcast i8* %scevgep28.13.34 to [61 x [61 x i8]]*
  %scevgep41.13.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5247, i64 0, i64 1, i64 0
  %5254 = bitcast i8* %scevgep41.13.34 to [61 x [61 x i8]]*
  %call16.13.35 = call zeroext i8 (...) @rand()
  store i8 %call16.13.35, i8* %scevgep28.13.34, align 1
  %5255 = load i8, i8* %scevgep28.13.34, align 1
  %conv23.13.35 = zext i8 %5255 to i32
  %5256 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.35 = getelementptr i8, i8* %b, i64 49
  %5257 = load i8, i8* %scevgep34.13.35, align 1
  %call28.13.35 = call zeroext i8 @mult(i8 zeroext %5256, i8 zeroext %5257)
  %conv29.13.35 = zext i8 %call28.13.35 to i32
  %xor.13.35 = xor i32 %conv23.13.35, %conv29.13.35
  %scevgep35.13.35 = getelementptr i8, i8* %a, i64 49
  %5258 = load i8, i8* %scevgep35.13.35, align 1
  %5259 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.35 = call zeroext i8 @mult(i8 zeroext %5258, i8 zeroext %5259)
  %conv35.13.35 = zext i8 %call34.13.35 to i32
  %xor36.13.35 = xor i32 %xor.13.35, %conv35.13.35
  %conv37.13.35 = trunc i32 %xor36.13.35 to i8
  store i8 %conv37.13.35, i8* %scevgep41.13.34, align 1
  %scevgep28.13.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5253, i64 0, i64 0, i64 1
  %5260 = bitcast i8* %scevgep28.13.35 to [61 x [61 x i8]]*
  %scevgep41.13.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5254, i64 0, i64 1, i64 0
  %5261 = bitcast i8* %scevgep41.13.35 to [61 x [61 x i8]]*
  %call16.13.36 = call zeroext i8 (...) @rand()
  store i8 %call16.13.36, i8* %scevgep28.13.35, align 1
  %5262 = load i8, i8* %scevgep28.13.35, align 1
  %conv23.13.36 = zext i8 %5262 to i32
  %5263 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.36 = getelementptr i8, i8* %b, i64 50
  %5264 = load i8, i8* %scevgep34.13.36, align 1
  %call28.13.36 = call zeroext i8 @mult(i8 zeroext %5263, i8 zeroext %5264)
  %conv29.13.36 = zext i8 %call28.13.36 to i32
  %xor.13.36 = xor i32 %conv23.13.36, %conv29.13.36
  %scevgep35.13.36 = getelementptr i8, i8* %a, i64 50
  %5265 = load i8, i8* %scevgep35.13.36, align 1
  %5266 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.36 = call zeroext i8 @mult(i8 zeroext %5265, i8 zeroext %5266)
  %conv35.13.36 = zext i8 %call34.13.36 to i32
  %xor36.13.36 = xor i32 %xor.13.36, %conv35.13.36
  %conv37.13.36 = trunc i32 %xor36.13.36 to i8
  store i8 %conv37.13.36, i8* %scevgep41.13.35, align 1
  %scevgep28.13.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5260, i64 0, i64 0, i64 1
  %5267 = bitcast i8* %scevgep28.13.36 to [61 x [61 x i8]]*
  %scevgep41.13.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5261, i64 0, i64 1, i64 0
  %5268 = bitcast i8* %scevgep41.13.36 to [61 x [61 x i8]]*
  %call16.13.37 = call zeroext i8 (...) @rand()
  store i8 %call16.13.37, i8* %scevgep28.13.36, align 1
  %5269 = load i8, i8* %scevgep28.13.36, align 1
  %conv23.13.37 = zext i8 %5269 to i32
  %5270 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.37 = getelementptr i8, i8* %b, i64 51
  %5271 = load i8, i8* %scevgep34.13.37, align 1
  %call28.13.37 = call zeroext i8 @mult(i8 zeroext %5270, i8 zeroext %5271)
  %conv29.13.37 = zext i8 %call28.13.37 to i32
  %xor.13.37 = xor i32 %conv23.13.37, %conv29.13.37
  %scevgep35.13.37 = getelementptr i8, i8* %a, i64 51
  %5272 = load i8, i8* %scevgep35.13.37, align 1
  %5273 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.37 = call zeroext i8 @mult(i8 zeroext %5272, i8 zeroext %5273)
  %conv35.13.37 = zext i8 %call34.13.37 to i32
  %xor36.13.37 = xor i32 %xor.13.37, %conv35.13.37
  %conv37.13.37 = trunc i32 %xor36.13.37 to i8
  store i8 %conv37.13.37, i8* %scevgep41.13.36, align 1
  %scevgep28.13.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5267, i64 0, i64 0, i64 1
  %5274 = bitcast i8* %scevgep28.13.37 to [61 x [61 x i8]]*
  %scevgep41.13.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5268, i64 0, i64 1, i64 0
  %5275 = bitcast i8* %scevgep41.13.37 to [61 x [61 x i8]]*
  %call16.13.38 = call zeroext i8 (...) @rand()
  store i8 %call16.13.38, i8* %scevgep28.13.37, align 1
  %5276 = load i8, i8* %scevgep28.13.37, align 1
  %conv23.13.38 = zext i8 %5276 to i32
  %5277 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.38 = getelementptr i8, i8* %b, i64 52
  %5278 = load i8, i8* %scevgep34.13.38, align 1
  %call28.13.38 = call zeroext i8 @mult(i8 zeroext %5277, i8 zeroext %5278)
  %conv29.13.38 = zext i8 %call28.13.38 to i32
  %xor.13.38 = xor i32 %conv23.13.38, %conv29.13.38
  %scevgep35.13.38 = getelementptr i8, i8* %a, i64 52
  %5279 = load i8, i8* %scevgep35.13.38, align 1
  %5280 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.38 = call zeroext i8 @mult(i8 zeroext %5279, i8 zeroext %5280)
  %conv35.13.38 = zext i8 %call34.13.38 to i32
  %xor36.13.38 = xor i32 %xor.13.38, %conv35.13.38
  %conv37.13.38 = trunc i32 %xor36.13.38 to i8
  store i8 %conv37.13.38, i8* %scevgep41.13.37, align 1
  %scevgep28.13.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5274, i64 0, i64 0, i64 1
  %5281 = bitcast i8* %scevgep28.13.38 to [61 x [61 x i8]]*
  %scevgep41.13.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5275, i64 0, i64 1, i64 0
  %5282 = bitcast i8* %scevgep41.13.38 to [61 x [61 x i8]]*
  %call16.13.39 = call zeroext i8 (...) @rand()
  store i8 %call16.13.39, i8* %scevgep28.13.38, align 1
  %5283 = load i8, i8* %scevgep28.13.38, align 1
  %conv23.13.39 = zext i8 %5283 to i32
  %5284 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.39 = getelementptr i8, i8* %b, i64 53
  %5285 = load i8, i8* %scevgep34.13.39, align 1
  %call28.13.39 = call zeroext i8 @mult(i8 zeroext %5284, i8 zeroext %5285)
  %conv29.13.39 = zext i8 %call28.13.39 to i32
  %xor.13.39 = xor i32 %conv23.13.39, %conv29.13.39
  %scevgep35.13.39 = getelementptr i8, i8* %a, i64 53
  %5286 = load i8, i8* %scevgep35.13.39, align 1
  %5287 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.39 = call zeroext i8 @mult(i8 zeroext %5286, i8 zeroext %5287)
  %conv35.13.39 = zext i8 %call34.13.39 to i32
  %xor36.13.39 = xor i32 %xor.13.39, %conv35.13.39
  %conv37.13.39 = trunc i32 %xor36.13.39 to i8
  store i8 %conv37.13.39, i8* %scevgep41.13.38, align 1
  %scevgep28.13.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5281, i64 0, i64 0, i64 1
  %5288 = bitcast i8* %scevgep28.13.39 to [61 x [61 x i8]]*
  %scevgep41.13.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5282, i64 0, i64 1, i64 0
  %5289 = bitcast i8* %scevgep41.13.39 to [61 x [61 x i8]]*
  %call16.13.40 = call zeroext i8 (...) @rand()
  store i8 %call16.13.40, i8* %scevgep28.13.39, align 1
  %5290 = load i8, i8* %scevgep28.13.39, align 1
  %conv23.13.40 = zext i8 %5290 to i32
  %5291 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.40 = getelementptr i8, i8* %b, i64 54
  %5292 = load i8, i8* %scevgep34.13.40, align 1
  %call28.13.40 = call zeroext i8 @mult(i8 zeroext %5291, i8 zeroext %5292)
  %conv29.13.40 = zext i8 %call28.13.40 to i32
  %xor.13.40 = xor i32 %conv23.13.40, %conv29.13.40
  %scevgep35.13.40 = getelementptr i8, i8* %a, i64 54
  %5293 = load i8, i8* %scevgep35.13.40, align 1
  %5294 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.40 = call zeroext i8 @mult(i8 zeroext %5293, i8 zeroext %5294)
  %conv35.13.40 = zext i8 %call34.13.40 to i32
  %xor36.13.40 = xor i32 %xor.13.40, %conv35.13.40
  %conv37.13.40 = trunc i32 %xor36.13.40 to i8
  store i8 %conv37.13.40, i8* %scevgep41.13.39, align 1
  %scevgep28.13.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5288, i64 0, i64 0, i64 1
  %5295 = bitcast i8* %scevgep28.13.40 to [61 x [61 x i8]]*
  %scevgep41.13.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5289, i64 0, i64 1, i64 0
  %5296 = bitcast i8* %scevgep41.13.40 to [61 x [61 x i8]]*
  %call16.13.41 = call zeroext i8 (...) @rand()
  store i8 %call16.13.41, i8* %scevgep28.13.40, align 1
  %5297 = load i8, i8* %scevgep28.13.40, align 1
  %conv23.13.41 = zext i8 %5297 to i32
  %5298 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.41 = getelementptr i8, i8* %b, i64 55
  %5299 = load i8, i8* %scevgep34.13.41, align 1
  %call28.13.41 = call zeroext i8 @mult(i8 zeroext %5298, i8 zeroext %5299)
  %conv29.13.41 = zext i8 %call28.13.41 to i32
  %xor.13.41 = xor i32 %conv23.13.41, %conv29.13.41
  %scevgep35.13.41 = getelementptr i8, i8* %a, i64 55
  %5300 = load i8, i8* %scevgep35.13.41, align 1
  %5301 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.41 = call zeroext i8 @mult(i8 zeroext %5300, i8 zeroext %5301)
  %conv35.13.41 = zext i8 %call34.13.41 to i32
  %xor36.13.41 = xor i32 %xor.13.41, %conv35.13.41
  %conv37.13.41 = trunc i32 %xor36.13.41 to i8
  store i8 %conv37.13.41, i8* %scevgep41.13.40, align 1
  %scevgep28.13.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5295, i64 0, i64 0, i64 1
  %5302 = bitcast i8* %scevgep28.13.41 to [61 x [61 x i8]]*
  %scevgep41.13.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5296, i64 0, i64 1, i64 0
  %5303 = bitcast i8* %scevgep41.13.41 to [61 x [61 x i8]]*
  %call16.13.42 = call zeroext i8 (...) @rand()
  store i8 %call16.13.42, i8* %scevgep28.13.41, align 1
  %5304 = load i8, i8* %scevgep28.13.41, align 1
  %conv23.13.42 = zext i8 %5304 to i32
  %5305 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.42 = getelementptr i8, i8* %b, i64 56
  %5306 = load i8, i8* %scevgep34.13.42, align 1
  %call28.13.42 = call zeroext i8 @mult(i8 zeroext %5305, i8 zeroext %5306)
  %conv29.13.42 = zext i8 %call28.13.42 to i32
  %xor.13.42 = xor i32 %conv23.13.42, %conv29.13.42
  %scevgep35.13.42 = getelementptr i8, i8* %a, i64 56
  %5307 = load i8, i8* %scevgep35.13.42, align 1
  %5308 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.42 = call zeroext i8 @mult(i8 zeroext %5307, i8 zeroext %5308)
  %conv35.13.42 = zext i8 %call34.13.42 to i32
  %xor36.13.42 = xor i32 %xor.13.42, %conv35.13.42
  %conv37.13.42 = trunc i32 %xor36.13.42 to i8
  store i8 %conv37.13.42, i8* %scevgep41.13.41, align 1
  %scevgep28.13.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5302, i64 0, i64 0, i64 1
  %5309 = bitcast i8* %scevgep28.13.42 to [61 x [61 x i8]]*
  %scevgep41.13.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5303, i64 0, i64 1, i64 0
  %5310 = bitcast i8* %scevgep41.13.42 to [61 x [61 x i8]]*
  %call16.13.43 = call zeroext i8 (...) @rand()
  store i8 %call16.13.43, i8* %scevgep28.13.42, align 1
  %5311 = load i8, i8* %scevgep28.13.42, align 1
  %conv23.13.43 = zext i8 %5311 to i32
  %5312 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.43 = getelementptr i8, i8* %b, i64 57
  %5313 = load i8, i8* %scevgep34.13.43, align 1
  %call28.13.43 = call zeroext i8 @mult(i8 zeroext %5312, i8 zeroext %5313)
  %conv29.13.43 = zext i8 %call28.13.43 to i32
  %xor.13.43 = xor i32 %conv23.13.43, %conv29.13.43
  %scevgep35.13.43 = getelementptr i8, i8* %a, i64 57
  %5314 = load i8, i8* %scevgep35.13.43, align 1
  %5315 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.43 = call zeroext i8 @mult(i8 zeroext %5314, i8 zeroext %5315)
  %conv35.13.43 = zext i8 %call34.13.43 to i32
  %xor36.13.43 = xor i32 %xor.13.43, %conv35.13.43
  %conv37.13.43 = trunc i32 %xor36.13.43 to i8
  store i8 %conv37.13.43, i8* %scevgep41.13.42, align 1
  %scevgep28.13.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5309, i64 0, i64 0, i64 1
  %5316 = bitcast i8* %scevgep28.13.43 to [61 x [61 x i8]]*
  %scevgep41.13.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5310, i64 0, i64 1, i64 0
  %5317 = bitcast i8* %scevgep41.13.43 to [61 x [61 x i8]]*
  %call16.13.44 = call zeroext i8 (...) @rand()
  store i8 %call16.13.44, i8* %scevgep28.13.43, align 1
  %5318 = load i8, i8* %scevgep28.13.43, align 1
  %conv23.13.44 = zext i8 %5318 to i32
  %5319 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.44 = getelementptr i8, i8* %b, i64 58
  %5320 = load i8, i8* %scevgep34.13.44, align 1
  %call28.13.44 = call zeroext i8 @mult(i8 zeroext %5319, i8 zeroext %5320)
  %conv29.13.44 = zext i8 %call28.13.44 to i32
  %xor.13.44 = xor i32 %conv23.13.44, %conv29.13.44
  %scevgep35.13.44 = getelementptr i8, i8* %a, i64 58
  %5321 = load i8, i8* %scevgep35.13.44, align 1
  %5322 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.44 = call zeroext i8 @mult(i8 zeroext %5321, i8 zeroext %5322)
  %conv35.13.44 = zext i8 %call34.13.44 to i32
  %xor36.13.44 = xor i32 %xor.13.44, %conv35.13.44
  %conv37.13.44 = trunc i32 %xor36.13.44 to i8
  store i8 %conv37.13.44, i8* %scevgep41.13.43, align 1
  %scevgep28.13.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5316, i64 0, i64 0, i64 1
  %5323 = bitcast i8* %scevgep28.13.44 to [61 x [61 x i8]]*
  %scevgep41.13.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5317, i64 0, i64 1, i64 0
  %5324 = bitcast i8* %scevgep41.13.44 to [61 x [61 x i8]]*
  %call16.13.45 = call zeroext i8 (...) @rand()
  store i8 %call16.13.45, i8* %scevgep28.13.44, align 1
  %5325 = load i8, i8* %scevgep28.13.44, align 1
  %conv23.13.45 = zext i8 %5325 to i32
  %5326 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.45 = getelementptr i8, i8* %b, i64 59
  %5327 = load i8, i8* %scevgep34.13.45, align 1
  %call28.13.45 = call zeroext i8 @mult(i8 zeroext %5326, i8 zeroext %5327)
  %conv29.13.45 = zext i8 %call28.13.45 to i32
  %xor.13.45 = xor i32 %conv23.13.45, %conv29.13.45
  %scevgep35.13.45 = getelementptr i8, i8* %a, i64 59
  %5328 = load i8, i8* %scevgep35.13.45, align 1
  %5329 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.45 = call zeroext i8 @mult(i8 zeroext %5328, i8 zeroext %5329)
  %conv35.13.45 = zext i8 %call34.13.45 to i32
  %xor36.13.45 = xor i32 %xor.13.45, %conv35.13.45
  %conv37.13.45 = trunc i32 %xor36.13.45 to i8
  store i8 %conv37.13.45, i8* %scevgep41.13.44, align 1
  %scevgep28.13.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5323, i64 0, i64 0, i64 1
  %scevgep41.13.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5324, i64 0, i64 1, i64 0
  %call16.13.46 = call zeroext i8 (...) @rand()
  store i8 %call16.13.46, i8* %scevgep28.13.45, align 1
  %5330 = load i8, i8* %scevgep28.13.45, align 1
  %conv23.13.46 = zext i8 %5330 to i32
  %5331 = load i8, i8* %arrayidx25.13, align 1
  %scevgep34.13.46 = getelementptr i8, i8* %b, i64 60
  %5332 = load i8, i8* %scevgep34.13.46, align 1
  %call28.13.46 = call zeroext i8 @mult(i8 zeroext %5331, i8 zeroext %5332)
  %conv29.13.46 = zext i8 %call28.13.46 to i32
  %xor.13.46 = xor i32 %conv23.13.46, %conv29.13.46
  %scevgep35.13.46 = getelementptr i8, i8* %a, i64 60
  %5333 = load i8, i8* %scevgep35.13.46, align 1
  %5334 = load i8, i8* %arrayidx33.13, align 1
  %call34.13.46 = call zeroext i8 @mult(i8 zeroext %5333, i8 zeroext %5334)
  %conv35.13.46 = zext i8 %call34.13.46 to i32
  %xor36.13.46 = xor i32 %xor.13.46, %conv35.13.46
  %conv37.13.46 = trunc i32 %xor36.13.46 to i8
  store i8 %conv37.13.46, i8* %scevgep41.13.45, align 1
  %scevgep26.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5008, i64 0, i64 1, i64 1
  %5335 = bitcast i8* %scevgep26.13 to [61 x [61 x i8]]*
  %scevgep39.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5009, i64 0, i64 1, i64 1
  %5336 = bitcast i8* %scevgep39.13 to [61 x [61 x i8]]*
  %arrayidx25.14 = getelementptr inbounds i8, i8* %a, i64 14
  %arrayidx33.14 = getelementptr inbounds i8, i8* %b, i64 14
  %call16.14 = call zeroext i8 (...) @rand()
  store i8 %call16.14, i8* %scevgep26.13, align 1
  %5337 = load i8, i8* %scevgep26.13, align 1
  %conv23.14 = zext i8 %5337 to i32
  %5338 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14 = getelementptr i8, i8* %b, i64 15
  %5339 = load i8, i8* %scevgep34.14, align 1
  %call28.14 = call zeroext i8 @mult(i8 zeroext %5338, i8 zeroext %5339)
  %conv29.14 = zext i8 %call28.14 to i32
  %xor.14 = xor i32 %conv23.14, %conv29.14
  %scevgep35.14 = getelementptr i8, i8* %a, i64 15
  %5340 = load i8, i8* %scevgep35.14, align 1
  %5341 = load i8, i8* %arrayidx33.14, align 1
  %call34.14 = call zeroext i8 @mult(i8 zeroext %5340, i8 zeroext %5341)
  %conv35.14 = zext i8 %call34.14 to i32
  %xor36.14 = xor i32 %xor.14, %conv35.14
  %conv37.14 = trunc i32 %xor36.14 to i8
  store i8 %conv37.14, i8* %scevgep39.13, align 1
  %scevgep28.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5335, i64 0, i64 0, i64 1
  %5342 = bitcast i8* %scevgep28.14 to [61 x [61 x i8]]*
  %scevgep41.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5336, i64 0, i64 1, i64 0
  %5343 = bitcast i8* %scevgep41.14 to [61 x [61 x i8]]*
  %call16.14.1 = call zeroext i8 (...) @rand()
  store i8 %call16.14.1, i8* %scevgep28.14, align 1
  %5344 = load i8, i8* %scevgep28.14, align 1
  %conv23.14.1 = zext i8 %5344 to i32
  %5345 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.1 = getelementptr i8, i8* %b, i64 16
  %5346 = load i8, i8* %scevgep34.14.1, align 1
  %call28.14.1 = call zeroext i8 @mult(i8 zeroext %5345, i8 zeroext %5346)
  %conv29.14.1 = zext i8 %call28.14.1 to i32
  %xor.14.1 = xor i32 %conv23.14.1, %conv29.14.1
  %scevgep35.14.1 = getelementptr i8, i8* %a, i64 16
  %5347 = load i8, i8* %scevgep35.14.1, align 1
  %5348 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.1 = call zeroext i8 @mult(i8 zeroext %5347, i8 zeroext %5348)
  %conv35.14.1 = zext i8 %call34.14.1 to i32
  %xor36.14.1 = xor i32 %xor.14.1, %conv35.14.1
  %conv37.14.1 = trunc i32 %xor36.14.1 to i8
  store i8 %conv37.14.1, i8* %scevgep41.14, align 1
  %scevgep28.14.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5342, i64 0, i64 0, i64 1
  %5349 = bitcast i8* %scevgep28.14.1 to [61 x [61 x i8]]*
  %scevgep41.14.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5343, i64 0, i64 1, i64 0
  %5350 = bitcast i8* %scevgep41.14.1 to [61 x [61 x i8]]*
  %call16.14.2 = call zeroext i8 (...) @rand()
  store i8 %call16.14.2, i8* %scevgep28.14.1, align 1
  %5351 = load i8, i8* %scevgep28.14.1, align 1
  %conv23.14.2 = zext i8 %5351 to i32
  %5352 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.2 = getelementptr i8, i8* %b, i64 17
  %5353 = load i8, i8* %scevgep34.14.2, align 1
  %call28.14.2 = call zeroext i8 @mult(i8 zeroext %5352, i8 zeroext %5353)
  %conv29.14.2 = zext i8 %call28.14.2 to i32
  %xor.14.2 = xor i32 %conv23.14.2, %conv29.14.2
  %scevgep35.14.2 = getelementptr i8, i8* %a, i64 17
  %5354 = load i8, i8* %scevgep35.14.2, align 1
  %5355 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.2 = call zeroext i8 @mult(i8 zeroext %5354, i8 zeroext %5355)
  %conv35.14.2 = zext i8 %call34.14.2 to i32
  %xor36.14.2 = xor i32 %xor.14.2, %conv35.14.2
  %conv37.14.2 = trunc i32 %xor36.14.2 to i8
  store i8 %conv37.14.2, i8* %scevgep41.14.1, align 1
  %scevgep28.14.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5349, i64 0, i64 0, i64 1
  %5356 = bitcast i8* %scevgep28.14.2 to [61 x [61 x i8]]*
  %scevgep41.14.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5350, i64 0, i64 1, i64 0
  %5357 = bitcast i8* %scevgep41.14.2 to [61 x [61 x i8]]*
  %call16.14.3 = call zeroext i8 (...) @rand()
  store i8 %call16.14.3, i8* %scevgep28.14.2, align 1
  %5358 = load i8, i8* %scevgep28.14.2, align 1
  %conv23.14.3 = zext i8 %5358 to i32
  %5359 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.3 = getelementptr i8, i8* %b, i64 18
  %5360 = load i8, i8* %scevgep34.14.3, align 1
  %call28.14.3 = call zeroext i8 @mult(i8 zeroext %5359, i8 zeroext %5360)
  %conv29.14.3 = zext i8 %call28.14.3 to i32
  %xor.14.3 = xor i32 %conv23.14.3, %conv29.14.3
  %scevgep35.14.3 = getelementptr i8, i8* %a, i64 18
  %5361 = load i8, i8* %scevgep35.14.3, align 1
  %5362 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.3 = call zeroext i8 @mult(i8 zeroext %5361, i8 zeroext %5362)
  %conv35.14.3 = zext i8 %call34.14.3 to i32
  %xor36.14.3 = xor i32 %xor.14.3, %conv35.14.3
  %conv37.14.3 = trunc i32 %xor36.14.3 to i8
  store i8 %conv37.14.3, i8* %scevgep41.14.2, align 1
  %scevgep28.14.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5356, i64 0, i64 0, i64 1
  %5363 = bitcast i8* %scevgep28.14.3 to [61 x [61 x i8]]*
  %scevgep41.14.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5357, i64 0, i64 1, i64 0
  %5364 = bitcast i8* %scevgep41.14.3 to [61 x [61 x i8]]*
  %call16.14.4 = call zeroext i8 (...) @rand()
  store i8 %call16.14.4, i8* %scevgep28.14.3, align 1
  %5365 = load i8, i8* %scevgep28.14.3, align 1
  %conv23.14.4 = zext i8 %5365 to i32
  %5366 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.4 = getelementptr i8, i8* %b, i64 19
  %5367 = load i8, i8* %scevgep34.14.4, align 1
  %call28.14.4 = call zeroext i8 @mult(i8 zeroext %5366, i8 zeroext %5367)
  %conv29.14.4 = zext i8 %call28.14.4 to i32
  %xor.14.4 = xor i32 %conv23.14.4, %conv29.14.4
  %scevgep35.14.4 = getelementptr i8, i8* %a, i64 19
  %5368 = load i8, i8* %scevgep35.14.4, align 1
  %5369 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.4 = call zeroext i8 @mult(i8 zeroext %5368, i8 zeroext %5369)
  %conv35.14.4 = zext i8 %call34.14.4 to i32
  %xor36.14.4 = xor i32 %xor.14.4, %conv35.14.4
  %conv37.14.4 = trunc i32 %xor36.14.4 to i8
  store i8 %conv37.14.4, i8* %scevgep41.14.3, align 1
  %scevgep28.14.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5363, i64 0, i64 0, i64 1
  %5370 = bitcast i8* %scevgep28.14.4 to [61 x [61 x i8]]*
  %scevgep41.14.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5364, i64 0, i64 1, i64 0
  %5371 = bitcast i8* %scevgep41.14.4 to [61 x [61 x i8]]*
  %call16.14.5 = call zeroext i8 (...) @rand()
  store i8 %call16.14.5, i8* %scevgep28.14.4, align 1
  %5372 = load i8, i8* %scevgep28.14.4, align 1
  %conv23.14.5 = zext i8 %5372 to i32
  %5373 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.5 = getelementptr i8, i8* %b, i64 20
  %5374 = load i8, i8* %scevgep34.14.5, align 1
  %call28.14.5 = call zeroext i8 @mult(i8 zeroext %5373, i8 zeroext %5374)
  %conv29.14.5 = zext i8 %call28.14.5 to i32
  %xor.14.5 = xor i32 %conv23.14.5, %conv29.14.5
  %scevgep35.14.5 = getelementptr i8, i8* %a, i64 20
  %5375 = load i8, i8* %scevgep35.14.5, align 1
  %5376 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.5 = call zeroext i8 @mult(i8 zeroext %5375, i8 zeroext %5376)
  %conv35.14.5 = zext i8 %call34.14.5 to i32
  %xor36.14.5 = xor i32 %xor.14.5, %conv35.14.5
  %conv37.14.5 = trunc i32 %xor36.14.5 to i8
  store i8 %conv37.14.5, i8* %scevgep41.14.4, align 1
  %scevgep28.14.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5370, i64 0, i64 0, i64 1
  %5377 = bitcast i8* %scevgep28.14.5 to [61 x [61 x i8]]*
  %scevgep41.14.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5371, i64 0, i64 1, i64 0
  %5378 = bitcast i8* %scevgep41.14.5 to [61 x [61 x i8]]*
  %call16.14.6 = call zeroext i8 (...) @rand()
  store i8 %call16.14.6, i8* %scevgep28.14.5, align 1
  %5379 = load i8, i8* %scevgep28.14.5, align 1
  %conv23.14.6 = zext i8 %5379 to i32
  %5380 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.6 = getelementptr i8, i8* %b, i64 21
  %5381 = load i8, i8* %scevgep34.14.6, align 1
  %call28.14.6 = call zeroext i8 @mult(i8 zeroext %5380, i8 zeroext %5381)
  %conv29.14.6 = zext i8 %call28.14.6 to i32
  %xor.14.6 = xor i32 %conv23.14.6, %conv29.14.6
  %scevgep35.14.6 = getelementptr i8, i8* %a, i64 21
  %5382 = load i8, i8* %scevgep35.14.6, align 1
  %5383 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.6 = call zeroext i8 @mult(i8 zeroext %5382, i8 zeroext %5383)
  %conv35.14.6 = zext i8 %call34.14.6 to i32
  %xor36.14.6 = xor i32 %xor.14.6, %conv35.14.6
  %conv37.14.6 = trunc i32 %xor36.14.6 to i8
  store i8 %conv37.14.6, i8* %scevgep41.14.5, align 1
  %scevgep28.14.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5377, i64 0, i64 0, i64 1
  %5384 = bitcast i8* %scevgep28.14.6 to [61 x [61 x i8]]*
  %scevgep41.14.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5378, i64 0, i64 1, i64 0
  %5385 = bitcast i8* %scevgep41.14.6 to [61 x [61 x i8]]*
  %call16.14.7 = call zeroext i8 (...) @rand()
  store i8 %call16.14.7, i8* %scevgep28.14.6, align 1
  %5386 = load i8, i8* %scevgep28.14.6, align 1
  %conv23.14.7 = zext i8 %5386 to i32
  %5387 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.7 = getelementptr i8, i8* %b, i64 22
  %5388 = load i8, i8* %scevgep34.14.7, align 1
  %call28.14.7 = call zeroext i8 @mult(i8 zeroext %5387, i8 zeroext %5388)
  %conv29.14.7 = zext i8 %call28.14.7 to i32
  %xor.14.7 = xor i32 %conv23.14.7, %conv29.14.7
  %scevgep35.14.7 = getelementptr i8, i8* %a, i64 22
  %5389 = load i8, i8* %scevgep35.14.7, align 1
  %5390 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.7 = call zeroext i8 @mult(i8 zeroext %5389, i8 zeroext %5390)
  %conv35.14.7 = zext i8 %call34.14.7 to i32
  %xor36.14.7 = xor i32 %xor.14.7, %conv35.14.7
  %conv37.14.7 = trunc i32 %xor36.14.7 to i8
  store i8 %conv37.14.7, i8* %scevgep41.14.6, align 1
  %scevgep28.14.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5384, i64 0, i64 0, i64 1
  %5391 = bitcast i8* %scevgep28.14.7 to [61 x [61 x i8]]*
  %scevgep41.14.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5385, i64 0, i64 1, i64 0
  %5392 = bitcast i8* %scevgep41.14.7 to [61 x [61 x i8]]*
  %call16.14.8 = call zeroext i8 (...) @rand()
  store i8 %call16.14.8, i8* %scevgep28.14.7, align 1
  %5393 = load i8, i8* %scevgep28.14.7, align 1
  %conv23.14.8 = zext i8 %5393 to i32
  %5394 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.8 = getelementptr i8, i8* %b, i64 23
  %5395 = load i8, i8* %scevgep34.14.8, align 1
  %call28.14.8 = call zeroext i8 @mult(i8 zeroext %5394, i8 zeroext %5395)
  %conv29.14.8 = zext i8 %call28.14.8 to i32
  %xor.14.8 = xor i32 %conv23.14.8, %conv29.14.8
  %scevgep35.14.8 = getelementptr i8, i8* %a, i64 23
  %5396 = load i8, i8* %scevgep35.14.8, align 1
  %5397 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.8 = call zeroext i8 @mult(i8 zeroext %5396, i8 zeroext %5397)
  %conv35.14.8 = zext i8 %call34.14.8 to i32
  %xor36.14.8 = xor i32 %xor.14.8, %conv35.14.8
  %conv37.14.8 = trunc i32 %xor36.14.8 to i8
  store i8 %conv37.14.8, i8* %scevgep41.14.7, align 1
  %scevgep28.14.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5391, i64 0, i64 0, i64 1
  %5398 = bitcast i8* %scevgep28.14.8 to [61 x [61 x i8]]*
  %scevgep41.14.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5392, i64 0, i64 1, i64 0
  %5399 = bitcast i8* %scevgep41.14.8 to [61 x [61 x i8]]*
  %call16.14.9 = call zeroext i8 (...) @rand()
  store i8 %call16.14.9, i8* %scevgep28.14.8, align 1
  %5400 = load i8, i8* %scevgep28.14.8, align 1
  %conv23.14.9 = zext i8 %5400 to i32
  %5401 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.9 = getelementptr i8, i8* %b, i64 24
  %5402 = load i8, i8* %scevgep34.14.9, align 1
  %call28.14.9 = call zeroext i8 @mult(i8 zeroext %5401, i8 zeroext %5402)
  %conv29.14.9 = zext i8 %call28.14.9 to i32
  %xor.14.9 = xor i32 %conv23.14.9, %conv29.14.9
  %scevgep35.14.9 = getelementptr i8, i8* %a, i64 24
  %5403 = load i8, i8* %scevgep35.14.9, align 1
  %5404 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.9 = call zeroext i8 @mult(i8 zeroext %5403, i8 zeroext %5404)
  %conv35.14.9 = zext i8 %call34.14.9 to i32
  %xor36.14.9 = xor i32 %xor.14.9, %conv35.14.9
  %conv37.14.9 = trunc i32 %xor36.14.9 to i8
  store i8 %conv37.14.9, i8* %scevgep41.14.8, align 1
  %scevgep28.14.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5398, i64 0, i64 0, i64 1
  %5405 = bitcast i8* %scevgep28.14.9 to [61 x [61 x i8]]*
  %scevgep41.14.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5399, i64 0, i64 1, i64 0
  %5406 = bitcast i8* %scevgep41.14.9 to [61 x [61 x i8]]*
  %call16.14.10 = call zeroext i8 (...) @rand()
  store i8 %call16.14.10, i8* %scevgep28.14.9, align 1
  %5407 = load i8, i8* %scevgep28.14.9, align 1
  %conv23.14.10 = zext i8 %5407 to i32
  %5408 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.10 = getelementptr i8, i8* %b, i64 25
  %5409 = load i8, i8* %scevgep34.14.10, align 1
  %call28.14.10 = call zeroext i8 @mult(i8 zeroext %5408, i8 zeroext %5409)
  %conv29.14.10 = zext i8 %call28.14.10 to i32
  %xor.14.10 = xor i32 %conv23.14.10, %conv29.14.10
  %scevgep35.14.10 = getelementptr i8, i8* %a, i64 25
  %5410 = load i8, i8* %scevgep35.14.10, align 1
  %5411 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.10 = call zeroext i8 @mult(i8 zeroext %5410, i8 zeroext %5411)
  %conv35.14.10 = zext i8 %call34.14.10 to i32
  %xor36.14.10 = xor i32 %xor.14.10, %conv35.14.10
  %conv37.14.10 = trunc i32 %xor36.14.10 to i8
  store i8 %conv37.14.10, i8* %scevgep41.14.9, align 1
  %scevgep28.14.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5405, i64 0, i64 0, i64 1
  %5412 = bitcast i8* %scevgep28.14.10 to [61 x [61 x i8]]*
  %scevgep41.14.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5406, i64 0, i64 1, i64 0
  %5413 = bitcast i8* %scevgep41.14.10 to [61 x [61 x i8]]*
  %call16.14.11 = call zeroext i8 (...) @rand()
  store i8 %call16.14.11, i8* %scevgep28.14.10, align 1
  %5414 = load i8, i8* %scevgep28.14.10, align 1
  %conv23.14.11 = zext i8 %5414 to i32
  %5415 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.11 = getelementptr i8, i8* %b, i64 26
  %5416 = load i8, i8* %scevgep34.14.11, align 1
  %call28.14.11 = call zeroext i8 @mult(i8 zeroext %5415, i8 zeroext %5416)
  %conv29.14.11 = zext i8 %call28.14.11 to i32
  %xor.14.11 = xor i32 %conv23.14.11, %conv29.14.11
  %scevgep35.14.11 = getelementptr i8, i8* %a, i64 26
  %5417 = load i8, i8* %scevgep35.14.11, align 1
  %5418 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.11 = call zeroext i8 @mult(i8 zeroext %5417, i8 zeroext %5418)
  %conv35.14.11 = zext i8 %call34.14.11 to i32
  %xor36.14.11 = xor i32 %xor.14.11, %conv35.14.11
  %conv37.14.11 = trunc i32 %xor36.14.11 to i8
  store i8 %conv37.14.11, i8* %scevgep41.14.10, align 1
  %scevgep28.14.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5412, i64 0, i64 0, i64 1
  %5419 = bitcast i8* %scevgep28.14.11 to [61 x [61 x i8]]*
  %scevgep41.14.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5413, i64 0, i64 1, i64 0
  %5420 = bitcast i8* %scevgep41.14.11 to [61 x [61 x i8]]*
  %call16.14.12 = call zeroext i8 (...) @rand()
  store i8 %call16.14.12, i8* %scevgep28.14.11, align 1
  %5421 = load i8, i8* %scevgep28.14.11, align 1
  %conv23.14.12 = zext i8 %5421 to i32
  %5422 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.12 = getelementptr i8, i8* %b, i64 27
  %5423 = load i8, i8* %scevgep34.14.12, align 1
  %call28.14.12 = call zeroext i8 @mult(i8 zeroext %5422, i8 zeroext %5423)
  %conv29.14.12 = zext i8 %call28.14.12 to i32
  %xor.14.12 = xor i32 %conv23.14.12, %conv29.14.12
  %scevgep35.14.12 = getelementptr i8, i8* %a, i64 27
  %5424 = load i8, i8* %scevgep35.14.12, align 1
  %5425 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.12 = call zeroext i8 @mult(i8 zeroext %5424, i8 zeroext %5425)
  %conv35.14.12 = zext i8 %call34.14.12 to i32
  %xor36.14.12 = xor i32 %xor.14.12, %conv35.14.12
  %conv37.14.12 = trunc i32 %xor36.14.12 to i8
  store i8 %conv37.14.12, i8* %scevgep41.14.11, align 1
  %scevgep28.14.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5419, i64 0, i64 0, i64 1
  %5426 = bitcast i8* %scevgep28.14.12 to [61 x [61 x i8]]*
  %scevgep41.14.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5420, i64 0, i64 1, i64 0
  %5427 = bitcast i8* %scevgep41.14.12 to [61 x [61 x i8]]*
  %call16.14.13 = call zeroext i8 (...) @rand()
  store i8 %call16.14.13, i8* %scevgep28.14.12, align 1
  %5428 = load i8, i8* %scevgep28.14.12, align 1
  %conv23.14.13 = zext i8 %5428 to i32
  %5429 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.13 = getelementptr i8, i8* %b, i64 28
  %5430 = load i8, i8* %scevgep34.14.13, align 1
  %call28.14.13 = call zeroext i8 @mult(i8 zeroext %5429, i8 zeroext %5430)
  %conv29.14.13 = zext i8 %call28.14.13 to i32
  %xor.14.13 = xor i32 %conv23.14.13, %conv29.14.13
  %scevgep35.14.13 = getelementptr i8, i8* %a, i64 28
  %5431 = load i8, i8* %scevgep35.14.13, align 1
  %5432 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.13 = call zeroext i8 @mult(i8 zeroext %5431, i8 zeroext %5432)
  %conv35.14.13 = zext i8 %call34.14.13 to i32
  %xor36.14.13 = xor i32 %xor.14.13, %conv35.14.13
  %conv37.14.13 = trunc i32 %xor36.14.13 to i8
  store i8 %conv37.14.13, i8* %scevgep41.14.12, align 1
  %scevgep28.14.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5426, i64 0, i64 0, i64 1
  %5433 = bitcast i8* %scevgep28.14.13 to [61 x [61 x i8]]*
  %scevgep41.14.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5427, i64 0, i64 1, i64 0
  %5434 = bitcast i8* %scevgep41.14.13 to [61 x [61 x i8]]*
  %call16.14.14 = call zeroext i8 (...) @rand()
  store i8 %call16.14.14, i8* %scevgep28.14.13, align 1
  %5435 = load i8, i8* %scevgep28.14.13, align 1
  %conv23.14.14 = zext i8 %5435 to i32
  %5436 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.14 = getelementptr i8, i8* %b, i64 29
  %5437 = load i8, i8* %scevgep34.14.14, align 1
  %call28.14.14 = call zeroext i8 @mult(i8 zeroext %5436, i8 zeroext %5437)
  %conv29.14.14 = zext i8 %call28.14.14 to i32
  %xor.14.14 = xor i32 %conv23.14.14, %conv29.14.14
  %scevgep35.14.14 = getelementptr i8, i8* %a, i64 29
  %5438 = load i8, i8* %scevgep35.14.14, align 1
  %5439 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.14 = call zeroext i8 @mult(i8 zeroext %5438, i8 zeroext %5439)
  %conv35.14.14 = zext i8 %call34.14.14 to i32
  %xor36.14.14 = xor i32 %xor.14.14, %conv35.14.14
  %conv37.14.14 = trunc i32 %xor36.14.14 to i8
  store i8 %conv37.14.14, i8* %scevgep41.14.13, align 1
  %scevgep28.14.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5433, i64 0, i64 0, i64 1
  %5440 = bitcast i8* %scevgep28.14.14 to [61 x [61 x i8]]*
  %scevgep41.14.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5434, i64 0, i64 1, i64 0
  %5441 = bitcast i8* %scevgep41.14.14 to [61 x [61 x i8]]*
  %call16.14.15 = call zeroext i8 (...) @rand()
  store i8 %call16.14.15, i8* %scevgep28.14.14, align 1
  %5442 = load i8, i8* %scevgep28.14.14, align 1
  %conv23.14.15 = zext i8 %5442 to i32
  %5443 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.15 = getelementptr i8, i8* %b, i64 30
  %5444 = load i8, i8* %scevgep34.14.15, align 1
  %call28.14.15 = call zeroext i8 @mult(i8 zeroext %5443, i8 zeroext %5444)
  %conv29.14.15 = zext i8 %call28.14.15 to i32
  %xor.14.15 = xor i32 %conv23.14.15, %conv29.14.15
  %scevgep35.14.15 = getelementptr i8, i8* %a, i64 30
  %5445 = load i8, i8* %scevgep35.14.15, align 1
  %5446 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.15 = call zeroext i8 @mult(i8 zeroext %5445, i8 zeroext %5446)
  %conv35.14.15 = zext i8 %call34.14.15 to i32
  %xor36.14.15 = xor i32 %xor.14.15, %conv35.14.15
  %conv37.14.15 = trunc i32 %xor36.14.15 to i8
  store i8 %conv37.14.15, i8* %scevgep41.14.14, align 1
  %scevgep28.14.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5440, i64 0, i64 0, i64 1
  %5447 = bitcast i8* %scevgep28.14.15 to [61 x [61 x i8]]*
  %scevgep41.14.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5441, i64 0, i64 1, i64 0
  %5448 = bitcast i8* %scevgep41.14.15 to [61 x [61 x i8]]*
  %call16.14.16 = call zeroext i8 (...) @rand()
  store i8 %call16.14.16, i8* %scevgep28.14.15, align 1
  %5449 = load i8, i8* %scevgep28.14.15, align 1
  %conv23.14.16 = zext i8 %5449 to i32
  %5450 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.16 = getelementptr i8, i8* %b, i64 31
  %5451 = load i8, i8* %scevgep34.14.16, align 1
  %call28.14.16 = call zeroext i8 @mult(i8 zeroext %5450, i8 zeroext %5451)
  %conv29.14.16 = zext i8 %call28.14.16 to i32
  %xor.14.16 = xor i32 %conv23.14.16, %conv29.14.16
  %scevgep35.14.16 = getelementptr i8, i8* %a, i64 31
  %5452 = load i8, i8* %scevgep35.14.16, align 1
  %5453 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.16 = call zeroext i8 @mult(i8 zeroext %5452, i8 zeroext %5453)
  %conv35.14.16 = zext i8 %call34.14.16 to i32
  %xor36.14.16 = xor i32 %xor.14.16, %conv35.14.16
  %conv37.14.16 = trunc i32 %xor36.14.16 to i8
  store i8 %conv37.14.16, i8* %scevgep41.14.15, align 1
  %scevgep28.14.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5447, i64 0, i64 0, i64 1
  %5454 = bitcast i8* %scevgep28.14.16 to [61 x [61 x i8]]*
  %scevgep41.14.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5448, i64 0, i64 1, i64 0
  %5455 = bitcast i8* %scevgep41.14.16 to [61 x [61 x i8]]*
  %call16.14.17 = call zeroext i8 (...) @rand()
  store i8 %call16.14.17, i8* %scevgep28.14.16, align 1
  %5456 = load i8, i8* %scevgep28.14.16, align 1
  %conv23.14.17 = zext i8 %5456 to i32
  %5457 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.17 = getelementptr i8, i8* %b, i64 32
  %5458 = load i8, i8* %scevgep34.14.17, align 1
  %call28.14.17 = call zeroext i8 @mult(i8 zeroext %5457, i8 zeroext %5458)
  %conv29.14.17 = zext i8 %call28.14.17 to i32
  %xor.14.17 = xor i32 %conv23.14.17, %conv29.14.17
  %scevgep35.14.17 = getelementptr i8, i8* %a, i64 32
  %5459 = load i8, i8* %scevgep35.14.17, align 1
  %5460 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.17 = call zeroext i8 @mult(i8 zeroext %5459, i8 zeroext %5460)
  %conv35.14.17 = zext i8 %call34.14.17 to i32
  %xor36.14.17 = xor i32 %xor.14.17, %conv35.14.17
  %conv37.14.17 = trunc i32 %xor36.14.17 to i8
  store i8 %conv37.14.17, i8* %scevgep41.14.16, align 1
  %scevgep28.14.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5454, i64 0, i64 0, i64 1
  %5461 = bitcast i8* %scevgep28.14.17 to [61 x [61 x i8]]*
  %scevgep41.14.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5455, i64 0, i64 1, i64 0
  %5462 = bitcast i8* %scevgep41.14.17 to [61 x [61 x i8]]*
  %call16.14.18 = call zeroext i8 (...) @rand()
  store i8 %call16.14.18, i8* %scevgep28.14.17, align 1
  %5463 = load i8, i8* %scevgep28.14.17, align 1
  %conv23.14.18 = zext i8 %5463 to i32
  %5464 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.18 = getelementptr i8, i8* %b, i64 33
  %5465 = load i8, i8* %scevgep34.14.18, align 1
  %call28.14.18 = call zeroext i8 @mult(i8 zeroext %5464, i8 zeroext %5465)
  %conv29.14.18 = zext i8 %call28.14.18 to i32
  %xor.14.18 = xor i32 %conv23.14.18, %conv29.14.18
  %scevgep35.14.18 = getelementptr i8, i8* %a, i64 33
  %5466 = load i8, i8* %scevgep35.14.18, align 1
  %5467 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.18 = call zeroext i8 @mult(i8 zeroext %5466, i8 zeroext %5467)
  %conv35.14.18 = zext i8 %call34.14.18 to i32
  %xor36.14.18 = xor i32 %xor.14.18, %conv35.14.18
  %conv37.14.18 = trunc i32 %xor36.14.18 to i8
  store i8 %conv37.14.18, i8* %scevgep41.14.17, align 1
  %scevgep28.14.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5461, i64 0, i64 0, i64 1
  %5468 = bitcast i8* %scevgep28.14.18 to [61 x [61 x i8]]*
  %scevgep41.14.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5462, i64 0, i64 1, i64 0
  %5469 = bitcast i8* %scevgep41.14.18 to [61 x [61 x i8]]*
  %call16.14.19 = call zeroext i8 (...) @rand()
  store i8 %call16.14.19, i8* %scevgep28.14.18, align 1
  %5470 = load i8, i8* %scevgep28.14.18, align 1
  %conv23.14.19 = zext i8 %5470 to i32
  %5471 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.19 = getelementptr i8, i8* %b, i64 34
  %5472 = load i8, i8* %scevgep34.14.19, align 1
  %call28.14.19 = call zeroext i8 @mult(i8 zeroext %5471, i8 zeroext %5472)
  %conv29.14.19 = zext i8 %call28.14.19 to i32
  %xor.14.19 = xor i32 %conv23.14.19, %conv29.14.19
  %scevgep35.14.19 = getelementptr i8, i8* %a, i64 34
  %5473 = load i8, i8* %scevgep35.14.19, align 1
  %5474 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.19 = call zeroext i8 @mult(i8 zeroext %5473, i8 zeroext %5474)
  %conv35.14.19 = zext i8 %call34.14.19 to i32
  %xor36.14.19 = xor i32 %xor.14.19, %conv35.14.19
  %conv37.14.19 = trunc i32 %xor36.14.19 to i8
  store i8 %conv37.14.19, i8* %scevgep41.14.18, align 1
  %scevgep28.14.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5468, i64 0, i64 0, i64 1
  %5475 = bitcast i8* %scevgep28.14.19 to [61 x [61 x i8]]*
  %scevgep41.14.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5469, i64 0, i64 1, i64 0
  %5476 = bitcast i8* %scevgep41.14.19 to [61 x [61 x i8]]*
  %call16.14.20 = call zeroext i8 (...) @rand()
  store i8 %call16.14.20, i8* %scevgep28.14.19, align 1
  %5477 = load i8, i8* %scevgep28.14.19, align 1
  %conv23.14.20 = zext i8 %5477 to i32
  %5478 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.20 = getelementptr i8, i8* %b, i64 35
  %5479 = load i8, i8* %scevgep34.14.20, align 1
  %call28.14.20 = call zeroext i8 @mult(i8 zeroext %5478, i8 zeroext %5479)
  %conv29.14.20 = zext i8 %call28.14.20 to i32
  %xor.14.20 = xor i32 %conv23.14.20, %conv29.14.20
  %scevgep35.14.20 = getelementptr i8, i8* %a, i64 35
  %5480 = load i8, i8* %scevgep35.14.20, align 1
  %5481 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.20 = call zeroext i8 @mult(i8 zeroext %5480, i8 zeroext %5481)
  %conv35.14.20 = zext i8 %call34.14.20 to i32
  %xor36.14.20 = xor i32 %xor.14.20, %conv35.14.20
  %conv37.14.20 = trunc i32 %xor36.14.20 to i8
  store i8 %conv37.14.20, i8* %scevgep41.14.19, align 1
  %scevgep28.14.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5475, i64 0, i64 0, i64 1
  %5482 = bitcast i8* %scevgep28.14.20 to [61 x [61 x i8]]*
  %scevgep41.14.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5476, i64 0, i64 1, i64 0
  %5483 = bitcast i8* %scevgep41.14.20 to [61 x [61 x i8]]*
  %call16.14.21 = call zeroext i8 (...) @rand()
  store i8 %call16.14.21, i8* %scevgep28.14.20, align 1
  %5484 = load i8, i8* %scevgep28.14.20, align 1
  %conv23.14.21 = zext i8 %5484 to i32
  %5485 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.21 = getelementptr i8, i8* %b, i64 36
  %5486 = load i8, i8* %scevgep34.14.21, align 1
  %call28.14.21 = call zeroext i8 @mult(i8 zeroext %5485, i8 zeroext %5486)
  %conv29.14.21 = zext i8 %call28.14.21 to i32
  %xor.14.21 = xor i32 %conv23.14.21, %conv29.14.21
  %scevgep35.14.21 = getelementptr i8, i8* %a, i64 36
  %5487 = load i8, i8* %scevgep35.14.21, align 1
  %5488 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.21 = call zeroext i8 @mult(i8 zeroext %5487, i8 zeroext %5488)
  %conv35.14.21 = zext i8 %call34.14.21 to i32
  %xor36.14.21 = xor i32 %xor.14.21, %conv35.14.21
  %conv37.14.21 = trunc i32 %xor36.14.21 to i8
  store i8 %conv37.14.21, i8* %scevgep41.14.20, align 1
  %scevgep28.14.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5482, i64 0, i64 0, i64 1
  %5489 = bitcast i8* %scevgep28.14.21 to [61 x [61 x i8]]*
  %scevgep41.14.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5483, i64 0, i64 1, i64 0
  %5490 = bitcast i8* %scevgep41.14.21 to [61 x [61 x i8]]*
  %call16.14.22 = call zeroext i8 (...) @rand()
  store i8 %call16.14.22, i8* %scevgep28.14.21, align 1
  %5491 = load i8, i8* %scevgep28.14.21, align 1
  %conv23.14.22 = zext i8 %5491 to i32
  %5492 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.22 = getelementptr i8, i8* %b, i64 37
  %5493 = load i8, i8* %scevgep34.14.22, align 1
  %call28.14.22 = call zeroext i8 @mult(i8 zeroext %5492, i8 zeroext %5493)
  %conv29.14.22 = zext i8 %call28.14.22 to i32
  %xor.14.22 = xor i32 %conv23.14.22, %conv29.14.22
  %scevgep35.14.22 = getelementptr i8, i8* %a, i64 37
  %5494 = load i8, i8* %scevgep35.14.22, align 1
  %5495 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.22 = call zeroext i8 @mult(i8 zeroext %5494, i8 zeroext %5495)
  %conv35.14.22 = zext i8 %call34.14.22 to i32
  %xor36.14.22 = xor i32 %xor.14.22, %conv35.14.22
  %conv37.14.22 = trunc i32 %xor36.14.22 to i8
  store i8 %conv37.14.22, i8* %scevgep41.14.21, align 1
  %scevgep28.14.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5489, i64 0, i64 0, i64 1
  %5496 = bitcast i8* %scevgep28.14.22 to [61 x [61 x i8]]*
  %scevgep41.14.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5490, i64 0, i64 1, i64 0
  %5497 = bitcast i8* %scevgep41.14.22 to [61 x [61 x i8]]*
  %call16.14.23 = call zeroext i8 (...) @rand()
  store i8 %call16.14.23, i8* %scevgep28.14.22, align 1
  %5498 = load i8, i8* %scevgep28.14.22, align 1
  %conv23.14.23 = zext i8 %5498 to i32
  %5499 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.23 = getelementptr i8, i8* %b, i64 38
  %5500 = load i8, i8* %scevgep34.14.23, align 1
  %call28.14.23 = call zeroext i8 @mult(i8 zeroext %5499, i8 zeroext %5500)
  %conv29.14.23 = zext i8 %call28.14.23 to i32
  %xor.14.23 = xor i32 %conv23.14.23, %conv29.14.23
  %scevgep35.14.23 = getelementptr i8, i8* %a, i64 38
  %5501 = load i8, i8* %scevgep35.14.23, align 1
  %5502 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.23 = call zeroext i8 @mult(i8 zeroext %5501, i8 zeroext %5502)
  %conv35.14.23 = zext i8 %call34.14.23 to i32
  %xor36.14.23 = xor i32 %xor.14.23, %conv35.14.23
  %conv37.14.23 = trunc i32 %xor36.14.23 to i8
  store i8 %conv37.14.23, i8* %scevgep41.14.22, align 1
  %scevgep28.14.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5496, i64 0, i64 0, i64 1
  %5503 = bitcast i8* %scevgep28.14.23 to [61 x [61 x i8]]*
  %scevgep41.14.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5497, i64 0, i64 1, i64 0
  %5504 = bitcast i8* %scevgep41.14.23 to [61 x [61 x i8]]*
  %call16.14.24 = call zeroext i8 (...) @rand()
  store i8 %call16.14.24, i8* %scevgep28.14.23, align 1
  %5505 = load i8, i8* %scevgep28.14.23, align 1
  %conv23.14.24 = zext i8 %5505 to i32
  %5506 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.24 = getelementptr i8, i8* %b, i64 39
  %5507 = load i8, i8* %scevgep34.14.24, align 1
  %call28.14.24 = call zeroext i8 @mult(i8 zeroext %5506, i8 zeroext %5507)
  %conv29.14.24 = zext i8 %call28.14.24 to i32
  %xor.14.24 = xor i32 %conv23.14.24, %conv29.14.24
  %scevgep35.14.24 = getelementptr i8, i8* %a, i64 39
  %5508 = load i8, i8* %scevgep35.14.24, align 1
  %5509 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.24 = call zeroext i8 @mult(i8 zeroext %5508, i8 zeroext %5509)
  %conv35.14.24 = zext i8 %call34.14.24 to i32
  %xor36.14.24 = xor i32 %xor.14.24, %conv35.14.24
  %conv37.14.24 = trunc i32 %xor36.14.24 to i8
  store i8 %conv37.14.24, i8* %scevgep41.14.23, align 1
  %scevgep28.14.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5503, i64 0, i64 0, i64 1
  %5510 = bitcast i8* %scevgep28.14.24 to [61 x [61 x i8]]*
  %scevgep41.14.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5504, i64 0, i64 1, i64 0
  %5511 = bitcast i8* %scevgep41.14.24 to [61 x [61 x i8]]*
  %call16.14.25 = call zeroext i8 (...) @rand()
  store i8 %call16.14.25, i8* %scevgep28.14.24, align 1
  %5512 = load i8, i8* %scevgep28.14.24, align 1
  %conv23.14.25 = zext i8 %5512 to i32
  %5513 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.25 = getelementptr i8, i8* %b, i64 40
  %5514 = load i8, i8* %scevgep34.14.25, align 1
  %call28.14.25 = call zeroext i8 @mult(i8 zeroext %5513, i8 zeroext %5514)
  %conv29.14.25 = zext i8 %call28.14.25 to i32
  %xor.14.25 = xor i32 %conv23.14.25, %conv29.14.25
  %scevgep35.14.25 = getelementptr i8, i8* %a, i64 40
  %5515 = load i8, i8* %scevgep35.14.25, align 1
  %5516 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.25 = call zeroext i8 @mult(i8 zeroext %5515, i8 zeroext %5516)
  %conv35.14.25 = zext i8 %call34.14.25 to i32
  %xor36.14.25 = xor i32 %xor.14.25, %conv35.14.25
  %conv37.14.25 = trunc i32 %xor36.14.25 to i8
  store i8 %conv37.14.25, i8* %scevgep41.14.24, align 1
  %scevgep28.14.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5510, i64 0, i64 0, i64 1
  %5517 = bitcast i8* %scevgep28.14.25 to [61 x [61 x i8]]*
  %scevgep41.14.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5511, i64 0, i64 1, i64 0
  %5518 = bitcast i8* %scevgep41.14.25 to [61 x [61 x i8]]*
  %call16.14.26 = call zeroext i8 (...) @rand()
  store i8 %call16.14.26, i8* %scevgep28.14.25, align 1
  %5519 = load i8, i8* %scevgep28.14.25, align 1
  %conv23.14.26 = zext i8 %5519 to i32
  %5520 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.26 = getelementptr i8, i8* %b, i64 41
  %5521 = load i8, i8* %scevgep34.14.26, align 1
  %call28.14.26 = call zeroext i8 @mult(i8 zeroext %5520, i8 zeroext %5521)
  %conv29.14.26 = zext i8 %call28.14.26 to i32
  %xor.14.26 = xor i32 %conv23.14.26, %conv29.14.26
  %scevgep35.14.26 = getelementptr i8, i8* %a, i64 41
  %5522 = load i8, i8* %scevgep35.14.26, align 1
  %5523 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.26 = call zeroext i8 @mult(i8 zeroext %5522, i8 zeroext %5523)
  %conv35.14.26 = zext i8 %call34.14.26 to i32
  %xor36.14.26 = xor i32 %xor.14.26, %conv35.14.26
  %conv37.14.26 = trunc i32 %xor36.14.26 to i8
  store i8 %conv37.14.26, i8* %scevgep41.14.25, align 1
  %scevgep28.14.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5517, i64 0, i64 0, i64 1
  %5524 = bitcast i8* %scevgep28.14.26 to [61 x [61 x i8]]*
  %scevgep41.14.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5518, i64 0, i64 1, i64 0
  %5525 = bitcast i8* %scevgep41.14.26 to [61 x [61 x i8]]*
  %call16.14.27 = call zeroext i8 (...) @rand()
  store i8 %call16.14.27, i8* %scevgep28.14.26, align 1
  %5526 = load i8, i8* %scevgep28.14.26, align 1
  %conv23.14.27 = zext i8 %5526 to i32
  %5527 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.27 = getelementptr i8, i8* %b, i64 42
  %5528 = load i8, i8* %scevgep34.14.27, align 1
  %call28.14.27 = call zeroext i8 @mult(i8 zeroext %5527, i8 zeroext %5528)
  %conv29.14.27 = zext i8 %call28.14.27 to i32
  %xor.14.27 = xor i32 %conv23.14.27, %conv29.14.27
  %scevgep35.14.27 = getelementptr i8, i8* %a, i64 42
  %5529 = load i8, i8* %scevgep35.14.27, align 1
  %5530 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.27 = call zeroext i8 @mult(i8 zeroext %5529, i8 zeroext %5530)
  %conv35.14.27 = zext i8 %call34.14.27 to i32
  %xor36.14.27 = xor i32 %xor.14.27, %conv35.14.27
  %conv37.14.27 = trunc i32 %xor36.14.27 to i8
  store i8 %conv37.14.27, i8* %scevgep41.14.26, align 1
  %scevgep28.14.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5524, i64 0, i64 0, i64 1
  %5531 = bitcast i8* %scevgep28.14.27 to [61 x [61 x i8]]*
  %scevgep41.14.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5525, i64 0, i64 1, i64 0
  %5532 = bitcast i8* %scevgep41.14.27 to [61 x [61 x i8]]*
  %call16.14.28 = call zeroext i8 (...) @rand()
  store i8 %call16.14.28, i8* %scevgep28.14.27, align 1
  %5533 = load i8, i8* %scevgep28.14.27, align 1
  %conv23.14.28 = zext i8 %5533 to i32
  %5534 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.28 = getelementptr i8, i8* %b, i64 43
  %5535 = load i8, i8* %scevgep34.14.28, align 1
  %call28.14.28 = call zeroext i8 @mult(i8 zeroext %5534, i8 zeroext %5535)
  %conv29.14.28 = zext i8 %call28.14.28 to i32
  %xor.14.28 = xor i32 %conv23.14.28, %conv29.14.28
  %scevgep35.14.28 = getelementptr i8, i8* %a, i64 43
  %5536 = load i8, i8* %scevgep35.14.28, align 1
  %5537 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.28 = call zeroext i8 @mult(i8 zeroext %5536, i8 zeroext %5537)
  %conv35.14.28 = zext i8 %call34.14.28 to i32
  %xor36.14.28 = xor i32 %xor.14.28, %conv35.14.28
  %conv37.14.28 = trunc i32 %xor36.14.28 to i8
  store i8 %conv37.14.28, i8* %scevgep41.14.27, align 1
  %scevgep28.14.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5531, i64 0, i64 0, i64 1
  %5538 = bitcast i8* %scevgep28.14.28 to [61 x [61 x i8]]*
  %scevgep41.14.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5532, i64 0, i64 1, i64 0
  %5539 = bitcast i8* %scevgep41.14.28 to [61 x [61 x i8]]*
  %call16.14.29 = call zeroext i8 (...) @rand()
  store i8 %call16.14.29, i8* %scevgep28.14.28, align 1
  %5540 = load i8, i8* %scevgep28.14.28, align 1
  %conv23.14.29 = zext i8 %5540 to i32
  %5541 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.29 = getelementptr i8, i8* %b, i64 44
  %5542 = load i8, i8* %scevgep34.14.29, align 1
  %call28.14.29 = call zeroext i8 @mult(i8 zeroext %5541, i8 zeroext %5542)
  %conv29.14.29 = zext i8 %call28.14.29 to i32
  %xor.14.29 = xor i32 %conv23.14.29, %conv29.14.29
  %scevgep35.14.29 = getelementptr i8, i8* %a, i64 44
  %5543 = load i8, i8* %scevgep35.14.29, align 1
  %5544 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.29 = call zeroext i8 @mult(i8 zeroext %5543, i8 zeroext %5544)
  %conv35.14.29 = zext i8 %call34.14.29 to i32
  %xor36.14.29 = xor i32 %xor.14.29, %conv35.14.29
  %conv37.14.29 = trunc i32 %xor36.14.29 to i8
  store i8 %conv37.14.29, i8* %scevgep41.14.28, align 1
  %scevgep28.14.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5538, i64 0, i64 0, i64 1
  %5545 = bitcast i8* %scevgep28.14.29 to [61 x [61 x i8]]*
  %scevgep41.14.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5539, i64 0, i64 1, i64 0
  %5546 = bitcast i8* %scevgep41.14.29 to [61 x [61 x i8]]*
  %call16.14.30 = call zeroext i8 (...) @rand()
  store i8 %call16.14.30, i8* %scevgep28.14.29, align 1
  %5547 = load i8, i8* %scevgep28.14.29, align 1
  %conv23.14.30 = zext i8 %5547 to i32
  %5548 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.30 = getelementptr i8, i8* %b, i64 45
  %5549 = load i8, i8* %scevgep34.14.30, align 1
  %call28.14.30 = call zeroext i8 @mult(i8 zeroext %5548, i8 zeroext %5549)
  %conv29.14.30 = zext i8 %call28.14.30 to i32
  %xor.14.30 = xor i32 %conv23.14.30, %conv29.14.30
  %scevgep35.14.30 = getelementptr i8, i8* %a, i64 45
  %5550 = load i8, i8* %scevgep35.14.30, align 1
  %5551 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.30 = call zeroext i8 @mult(i8 zeroext %5550, i8 zeroext %5551)
  %conv35.14.30 = zext i8 %call34.14.30 to i32
  %xor36.14.30 = xor i32 %xor.14.30, %conv35.14.30
  %conv37.14.30 = trunc i32 %xor36.14.30 to i8
  store i8 %conv37.14.30, i8* %scevgep41.14.29, align 1
  %scevgep28.14.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5545, i64 0, i64 0, i64 1
  %5552 = bitcast i8* %scevgep28.14.30 to [61 x [61 x i8]]*
  %scevgep41.14.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5546, i64 0, i64 1, i64 0
  %5553 = bitcast i8* %scevgep41.14.30 to [61 x [61 x i8]]*
  %call16.14.31 = call zeroext i8 (...) @rand()
  store i8 %call16.14.31, i8* %scevgep28.14.30, align 1
  %5554 = load i8, i8* %scevgep28.14.30, align 1
  %conv23.14.31 = zext i8 %5554 to i32
  %5555 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.31 = getelementptr i8, i8* %b, i64 46
  %5556 = load i8, i8* %scevgep34.14.31, align 1
  %call28.14.31 = call zeroext i8 @mult(i8 zeroext %5555, i8 zeroext %5556)
  %conv29.14.31 = zext i8 %call28.14.31 to i32
  %xor.14.31 = xor i32 %conv23.14.31, %conv29.14.31
  %scevgep35.14.31 = getelementptr i8, i8* %a, i64 46
  %5557 = load i8, i8* %scevgep35.14.31, align 1
  %5558 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.31 = call zeroext i8 @mult(i8 zeroext %5557, i8 zeroext %5558)
  %conv35.14.31 = zext i8 %call34.14.31 to i32
  %xor36.14.31 = xor i32 %xor.14.31, %conv35.14.31
  %conv37.14.31 = trunc i32 %xor36.14.31 to i8
  store i8 %conv37.14.31, i8* %scevgep41.14.30, align 1
  %scevgep28.14.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5552, i64 0, i64 0, i64 1
  %5559 = bitcast i8* %scevgep28.14.31 to [61 x [61 x i8]]*
  %scevgep41.14.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5553, i64 0, i64 1, i64 0
  %5560 = bitcast i8* %scevgep41.14.31 to [61 x [61 x i8]]*
  %call16.14.32 = call zeroext i8 (...) @rand()
  store i8 %call16.14.32, i8* %scevgep28.14.31, align 1
  %5561 = load i8, i8* %scevgep28.14.31, align 1
  %conv23.14.32 = zext i8 %5561 to i32
  %5562 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.32 = getelementptr i8, i8* %b, i64 47
  %5563 = load i8, i8* %scevgep34.14.32, align 1
  %call28.14.32 = call zeroext i8 @mult(i8 zeroext %5562, i8 zeroext %5563)
  %conv29.14.32 = zext i8 %call28.14.32 to i32
  %xor.14.32 = xor i32 %conv23.14.32, %conv29.14.32
  %scevgep35.14.32 = getelementptr i8, i8* %a, i64 47
  %5564 = load i8, i8* %scevgep35.14.32, align 1
  %5565 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.32 = call zeroext i8 @mult(i8 zeroext %5564, i8 zeroext %5565)
  %conv35.14.32 = zext i8 %call34.14.32 to i32
  %xor36.14.32 = xor i32 %xor.14.32, %conv35.14.32
  %conv37.14.32 = trunc i32 %xor36.14.32 to i8
  store i8 %conv37.14.32, i8* %scevgep41.14.31, align 1
  %scevgep28.14.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5559, i64 0, i64 0, i64 1
  %5566 = bitcast i8* %scevgep28.14.32 to [61 x [61 x i8]]*
  %scevgep41.14.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5560, i64 0, i64 1, i64 0
  %5567 = bitcast i8* %scevgep41.14.32 to [61 x [61 x i8]]*
  %call16.14.33 = call zeroext i8 (...) @rand()
  store i8 %call16.14.33, i8* %scevgep28.14.32, align 1
  %5568 = load i8, i8* %scevgep28.14.32, align 1
  %conv23.14.33 = zext i8 %5568 to i32
  %5569 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.33 = getelementptr i8, i8* %b, i64 48
  %5570 = load i8, i8* %scevgep34.14.33, align 1
  %call28.14.33 = call zeroext i8 @mult(i8 zeroext %5569, i8 zeroext %5570)
  %conv29.14.33 = zext i8 %call28.14.33 to i32
  %xor.14.33 = xor i32 %conv23.14.33, %conv29.14.33
  %scevgep35.14.33 = getelementptr i8, i8* %a, i64 48
  %5571 = load i8, i8* %scevgep35.14.33, align 1
  %5572 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.33 = call zeroext i8 @mult(i8 zeroext %5571, i8 zeroext %5572)
  %conv35.14.33 = zext i8 %call34.14.33 to i32
  %xor36.14.33 = xor i32 %xor.14.33, %conv35.14.33
  %conv37.14.33 = trunc i32 %xor36.14.33 to i8
  store i8 %conv37.14.33, i8* %scevgep41.14.32, align 1
  %scevgep28.14.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5566, i64 0, i64 0, i64 1
  %5573 = bitcast i8* %scevgep28.14.33 to [61 x [61 x i8]]*
  %scevgep41.14.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5567, i64 0, i64 1, i64 0
  %5574 = bitcast i8* %scevgep41.14.33 to [61 x [61 x i8]]*
  %call16.14.34 = call zeroext i8 (...) @rand()
  store i8 %call16.14.34, i8* %scevgep28.14.33, align 1
  %5575 = load i8, i8* %scevgep28.14.33, align 1
  %conv23.14.34 = zext i8 %5575 to i32
  %5576 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.34 = getelementptr i8, i8* %b, i64 49
  %5577 = load i8, i8* %scevgep34.14.34, align 1
  %call28.14.34 = call zeroext i8 @mult(i8 zeroext %5576, i8 zeroext %5577)
  %conv29.14.34 = zext i8 %call28.14.34 to i32
  %xor.14.34 = xor i32 %conv23.14.34, %conv29.14.34
  %scevgep35.14.34 = getelementptr i8, i8* %a, i64 49
  %5578 = load i8, i8* %scevgep35.14.34, align 1
  %5579 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.34 = call zeroext i8 @mult(i8 zeroext %5578, i8 zeroext %5579)
  %conv35.14.34 = zext i8 %call34.14.34 to i32
  %xor36.14.34 = xor i32 %xor.14.34, %conv35.14.34
  %conv37.14.34 = trunc i32 %xor36.14.34 to i8
  store i8 %conv37.14.34, i8* %scevgep41.14.33, align 1
  %scevgep28.14.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5573, i64 0, i64 0, i64 1
  %5580 = bitcast i8* %scevgep28.14.34 to [61 x [61 x i8]]*
  %scevgep41.14.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5574, i64 0, i64 1, i64 0
  %5581 = bitcast i8* %scevgep41.14.34 to [61 x [61 x i8]]*
  %call16.14.35 = call zeroext i8 (...) @rand()
  store i8 %call16.14.35, i8* %scevgep28.14.34, align 1
  %5582 = load i8, i8* %scevgep28.14.34, align 1
  %conv23.14.35 = zext i8 %5582 to i32
  %5583 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.35 = getelementptr i8, i8* %b, i64 50
  %5584 = load i8, i8* %scevgep34.14.35, align 1
  %call28.14.35 = call zeroext i8 @mult(i8 zeroext %5583, i8 zeroext %5584)
  %conv29.14.35 = zext i8 %call28.14.35 to i32
  %xor.14.35 = xor i32 %conv23.14.35, %conv29.14.35
  %scevgep35.14.35 = getelementptr i8, i8* %a, i64 50
  %5585 = load i8, i8* %scevgep35.14.35, align 1
  %5586 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.35 = call zeroext i8 @mult(i8 zeroext %5585, i8 zeroext %5586)
  %conv35.14.35 = zext i8 %call34.14.35 to i32
  %xor36.14.35 = xor i32 %xor.14.35, %conv35.14.35
  %conv37.14.35 = trunc i32 %xor36.14.35 to i8
  store i8 %conv37.14.35, i8* %scevgep41.14.34, align 1
  %scevgep28.14.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5580, i64 0, i64 0, i64 1
  %5587 = bitcast i8* %scevgep28.14.35 to [61 x [61 x i8]]*
  %scevgep41.14.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5581, i64 0, i64 1, i64 0
  %5588 = bitcast i8* %scevgep41.14.35 to [61 x [61 x i8]]*
  %call16.14.36 = call zeroext i8 (...) @rand()
  store i8 %call16.14.36, i8* %scevgep28.14.35, align 1
  %5589 = load i8, i8* %scevgep28.14.35, align 1
  %conv23.14.36 = zext i8 %5589 to i32
  %5590 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.36 = getelementptr i8, i8* %b, i64 51
  %5591 = load i8, i8* %scevgep34.14.36, align 1
  %call28.14.36 = call zeroext i8 @mult(i8 zeroext %5590, i8 zeroext %5591)
  %conv29.14.36 = zext i8 %call28.14.36 to i32
  %xor.14.36 = xor i32 %conv23.14.36, %conv29.14.36
  %scevgep35.14.36 = getelementptr i8, i8* %a, i64 51
  %5592 = load i8, i8* %scevgep35.14.36, align 1
  %5593 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.36 = call zeroext i8 @mult(i8 zeroext %5592, i8 zeroext %5593)
  %conv35.14.36 = zext i8 %call34.14.36 to i32
  %xor36.14.36 = xor i32 %xor.14.36, %conv35.14.36
  %conv37.14.36 = trunc i32 %xor36.14.36 to i8
  store i8 %conv37.14.36, i8* %scevgep41.14.35, align 1
  %scevgep28.14.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5587, i64 0, i64 0, i64 1
  %5594 = bitcast i8* %scevgep28.14.36 to [61 x [61 x i8]]*
  %scevgep41.14.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5588, i64 0, i64 1, i64 0
  %5595 = bitcast i8* %scevgep41.14.36 to [61 x [61 x i8]]*
  %call16.14.37 = call zeroext i8 (...) @rand()
  store i8 %call16.14.37, i8* %scevgep28.14.36, align 1
  %5596 = load i8, i8* %scevgep28.14.36, align 1
  %conv23.14.37 = zext i8 %5596 to i32
  %5597 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.37 = getelementptr i8, i8* %b, i64 52
  %5598 = load i8, i8* %scevgep34.14.37, align 1
  %call28.14.37 = call zeroext i8 @mult(i8 zeroext %5597, i8 zeroext %5598)
  %conv29.14.37 = zext i8 %call28.14.37 to i32
  %xor.14.37 = xor i32 %conv23.14.37, %conv29.14.37
  %scevgep35.14.37 = getelementptr i8, i8* %a, i64 52
  %5599 = load i8, i8* %scevgep35.14.37, align 1
  %5600 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.37 = call zeroext i8 @mult(i8 zeroext %5599, i8 zeroext %5600)
  %conv35.14.37 = zext i8 %call34.14.37 to i32
  %xor36.14.37 = xor i32 %xor.14.37, %conv35.14.37
  %conv37.14.37 = trunc i32 %xor36.14.37 to i8
  store i8 %conv37.14.37, i8* %scevgep41.14.36, align 1
  %scevgep28.14.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5594, i64 0, i64 0, i64 1
  %5601 = bitcast i8* %scevgep28.14.37 to [61 x [61 x i8]]*
  %scevgep41.14.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5595, i64 0, i64 1, i64 0
  %5602 = bitcast i8* %scevgep41.14.37 to [61 x [61 x i8]]*
  %call16.14.38 = call zeroext i8 (...) @rand()
  store i8 %call16.14.38, i8* %scevgep28.14.37, align 1
  %5603 = load i8, i8* %scevgep28.14.37, align 1
  %conv23.14.38 = zext i8 %5603 to i32
  %5604 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.38 = getelementptr i8, i8* %b, i64 53
  %5605 = load i8, i8* %scevgep34.14.38, align 1
  %call28.14.38 = call zeroext i8 @mult(i8 zeroext %5604, i8 zeroext %5605)
  %conv29.14.38 = zext i8 %call28.14.38 to i32
  %xor.14.38 = xor i32 %conv23.14.38, %conv29.14.38
  %scevgep35.14.38 = getelementptr i8, i8* %a, i64 53
  %5606 = load i8, i8* %scevgep35.14.38, align 1
  %5607 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.38 = call zeroext i8 @mult(i8 zeroext %5606, i8 zeroext %5607)
  %conv35.14.38 = zext i8 %call34.14.38 to i32
  %xor36.14.38 = xor i32 %xor.14.38, %conv35.14.38
  %conv37.14.38 = trunc i32 %xor36.14.38 to i8
  store i8 %conv37.14.38, i8* %scevgep41.14.37, align 1
  %scevgep28.14.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5601, i64 0, i64 0, i64 1
  %5608 = bitcast i8* %scevgep28.14.38 to [61 x [61 x i8]]*
  %scevgep41.14.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5602, i64 0, i64 1, i64 0
  %5609 = bitcast i8* %scevgep41.14.38 to [61 x [61 x i8]]*
  %call16.14.39 = call zeroext i8 (...) @rand()
  store i8 %call16.14.39, i8* %scevgep28.14.38, align 1
  %5610 = load i8, i8* %scevgep28.14.38, align 1
  %conv23.14.39 = zext i8 %5610 to i32
  %5611 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.39 = getelementptr i8, i8* %b, i64 54
  %5612 = load i8, i8* %scevgep34.14.39, align 1
  %call28.14.39 = call zeroext i8 @mult(i8 zeroext %5611, i8 zeroext %5612)
  %conv29.14.39 = zext i8 %call28.14.39 to i32
  %xor.14.39 = xor i32 %conv23.14.39, %conv29.14.39
  %scevgep35.14.39 = getelementptr i8, i8* %a, i64 54
  %5613 = load i8, i8* %scevgep35.14.39, align 1
  %5614 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.39 = call zeroext i8 @mult(i8 zeroext %5613, i8 zeroext %5614)
  %conv35.14.39 = zext i8 %call34.14.39 to i32
  %xor36.14.39 = xor i32 %xor.14.39, %conv35.14.39
  %conv37.14.39 = trunc i32 %xor36.14.39 to i8
  store i8 %conv37.14.39, i8* %scevgep41.14.38, align 1
  %scevgep28.14.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5608, i64 0, i64 0, i64 1
  %5615 = bitcast i8* %scevgep28.14.39 to [61 x [61 x i8]]*
  %scevgep41.14.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5609, i64 0, i64 1, i64 0
  %5616 = bitcast i8* %scevgep41.14.39 to [61 x [61 x i8]]*
  %call16.14.40 = call zeroext i8 (...) @rand()
  store i8 %call16.14.40, i8* %scevgep28.14.39, align 1
  %5617 = load i8, i8* %scevgep28.14.39, align 1
  %conv23.14.40 = zext i8 %5617 to i32
  %5618 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.40 = getelementptr i8, i8* %b, i64 55
  %5619 = load i8, i8* %scevgep34.14.40, align 1
  %call28.14.40 = call zeroext i8 @mult(i8 zeroext %5618, i8 zeroext %5619)
  %conv29.14.40 = zext i8 %call28.14.40 to i32
  %xor.14.40 = xor i32 %conv23.14.40, %conv29.14.40
  %scevgep35.14.40 = getelementptr i8, i8* %a, i64 55
  %5620 = load i8, i8* %scevgep35.14.40, align 1
  %5621 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.40 = call zeroext i8 @mult(i8 zeroext %5620, i8 zeroext %5621)
  %conv35.14.40 = zext i8 %call34.14.40 to i32
  %xor36.14.40 = xor i32 %xor.14.40, %conv35.14.40
  %conv37.14.40 = trunc i32 %xor36.14.40 to i8
  store i8 %conv37.14.40, i8* %scevgep41.14.39, align 1
  %scevgep28.14.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5615, i64 0, i64 0, i64 1
  %5622 = bitcast i8* %scevgep28.14.40 to [61 x [61 x i8]]*
  %scevgep41.14.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5616, i64 0, i64 1, i64 0
  %5623 = bitcast i8* %scevgep41.14.40 to [61 x [61 x i8]]*
  %call16.14.41 = call zeroext i8 (...) @rand()
  store i8 %call16.14.41, i8* %scevgep28.14.40, align 1
  %5624 = load i8, i8* %scevgep28.14.40, align 1
  %conv23.14.41 = zext i8 %5624 to i32
  %5625 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.41 = getelementptr i8, i8* %b, i64 56
  %5626 = load i8, i8* %scevgep34.14.41, align 1
  %call28.14.41 = call zeroext i8 @mult(i8 zeroext %5625, i8 zeroext %5626)
  %conv29.14.41 = zext i8 %call28.14.41 to i32
  %xor.14.41 = xor i32 %conv23.14.41, %conv29.14.41
  %scevgep35.14.41 = getelementptr i8, i8* %a, i64 56
  %5627 = load i8, i8* %scevgep35.14.41, align 1
  %5628 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.41 = call zeroext i8 @mult(i8 zeroext %5627, i8 zeroext %5628)
  %conv35.14.41 = zext i8 %call34.14.41 to i32
  %xor36.14.41 = xor i32 %xor.14.41, %conv35.14.41
  %conv37.14.41 = trunc i32 %xor36.14.41 to i8
  store i8 %conv37.14.41, i8* %scevgep41.14.40, align 1
  %scevgep28.14.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5622, i64 0, i64 0, i64 1
  %5629 = bitcast i8* %scevgep28.14.41 to [61 x [61 x i8]]*
  %scevgep41.14.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5623, i64 0, i64 1, i64 0
  %5630 = bitcast i8* %scevgep41.14.41 to [61 x [61 x i8]]*
  %call16.14.42 = call zeroext i8 (...) @rand()
  store i8 %call16.14.42, i8* %scevgep28.14.41, align 1
  %5631 = load i8, i8* %scevgep28.14.41, align 1
  %conv23.14.42 = zext i8 %5631 to i32
  %5632 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.42 = getelementptr i8, i8* %b, i64 57
  %5633 = load i8, i8* %scevgep34.14.42, align 1
  %call28.14.42 = call zeroext i8 @mult(i8 zeroext %5632, i8 zeroext %5633)
  %conv29.14.42 = zext i8 %call28.14.42 to i32
  %xor.14.42 = xor i32 %conv23.14.42, %conv29.14.42
  %scevgep35.14.42 = getelementptr i8, i8* %a, i64 57
  %5634 = load i8, i8* %scevgep35.14.42, align 1
  %5635 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.42 = call zeroext i8 @mult(i8 zeroext %5634, i8 zeroext %5635)
  %conv35.14.42 = zext i8 %call34.14.42 to i32
  %xor36.14.42 = xor i32 %xor.14.42, %conv35.14.42
  %conv37.14.42 = trunc i32 %xor36.14.42 to i8
  store i8 %conv37.14.42, i8* %scevgep41.14.41, align 1
  %scevgep28.14.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5629, i64 0, i64 0, i64 1
  %5636 = bitcast i8* %scevgep28.14.42 to [61 x [61 x i8]]*
  %scevgep41.14.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5630, i64 0, i64 1, i64 0
  %5637 = bitcast i8* %scevgep41.14.42 to [61 x [61 x i8]]*
  %call16.14.43 = call zeroext i8 (...) @rand()
  store i8 %call16.14.43, i8* %scevgep28.14.42, align 1
  %5638 = load i8, i8* %scevgep28.14.42, align 1
  %conv23.14.43 = zext i8 %5638 to i32
  %5639 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.43 = getelementptr i8, i8* %b, i64 58
  %5640 = load i8, i8* %scevgep34.14.43, align 1
  %call28.14.43 = call zeroext i8 @mult(i8 zeroext %5639, i8 zeroext %5640)
  %conv29.14.43 = zext i8 %call28.14.43 to i32
  %xor.14.43 = xor i32 %conv23.14.43, %conv29.14.43
  %scevgep35.14.43 = getelementptr i8, i8* %a, i64 58
  %5641 = load i8, i8* %scevgep35.14.43, align 1
  %5642 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.43 = call zeroext i8 @mult(i8 zeroext %5641, i8 zeroext %5642)
  %conv35.14.43 = zext i8 %call34.14.43 to i32
  %xor36.14.43 = xor i32 %xor.14.43, %conv35.14.43
  %conv37.14.43 = trunc i32 %xor36.14.43 to i8
  store i8 %conv37.14.43, i8* %scevgep41.14.42, align 1
  %scevgep28.14.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5636, i64 0, i64 0, i64 1
  %5643 = bitcast i8* %scevgep28.14.43 to [61 x [61 x i8]]*
  %scevgep41.14.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5637, i64 0, i64 1, i64 0
  %5644 = bitcast i8* %scevgep41.14.43 to [61 x [61 x i8]]*
  %call16.14.44 = call zeroext i8 (...) @rand()
  store i8 %call16.14.44, i8* %scevgep28.14.43, align 1
  %5645 = load i8, i8* %scevgep28.14.43, align 1
  %conv23.14.44 = zext i8 %5645 to i32
  %5646 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.44 = getelementptr i8, i8* %b, i64 59
  %5647 = load i8, i8* %scevgep34.14.44, align 1
  %call28.14.44 = call zeroext i8 @mult(i8 zeroext %5646, i8 zeroext %5647)
  %conv29.14.44 = zext i8 %call28.14.44 to i32
  %xor.14.44 = xor i32 %conv23.14.44, %conv29.14.44
  %scevgep35.14.44 = getelementptr i8, i8* %a, i64 59
  %5648 = load i8, i8* %scevgep35.14.44, align 1
  %5649 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.44 = call zeroext i8 @mult(i8 zeroext %5648, i8 zeroext %5649)
  %conv35.14.44 = zext i8 %call34.14.44 to i32
  %xor36.14.44 = xor i32 %xor.14.44, %conv35.14.44
  %conv37.14.44 = trunc i32 %xor36.14.44 to i8
  store i8 %conv37.14.44, i8* %scevgep41.14.43, align 1
  %scevgep28.14.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5643, i64 0, i64 0, i64 1
  %scevgep41.14.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5644, i64 0, i64 1, i64 0
  %call16.14.45 = call zeroext i8 (...) @rand()
  store i8 %call16.14.45, i8* %scevgep28.14.44, align 1
  %5650 = load i8, i8* %scevgep28.14.44, align 1
  %conv23.14.45 = zext i8 %5650 to i32
  %5651 = load i8, i8* %arrayidx25.14, align 1
  %scevgep34.14.45 = getelementptr i8, i8* %b, i64 60
  %5652 = load i8, i8* %scevgep34.14.45, align 1
  %call28.14.45 = call zeroext i8 @mult(i8 zeroext %5651, i8 zeroext %5652)
  %conv29.14.45 = zext i8 %call28.14.45 to i32
  %xor.14.45 = xor i32 %conv23.14.45, %conv29.14.45
  %scevgep35.14.45 = getelementptr i8, i8* %a, i64 60
  %5653 = load i8, i8* %scevgep35.14.45, align 1
  %5654 = load i8, i8* %arrayidx33.14, align 1
  %call34.14.45 = call zeroext i8 @mult(i8 zeroext %5653, i8 zeroext %5654)
  %conv35.14.45 = zext i8 %call34.14.45 to i32
  %xor36.14.45 = xor i32 %xor.14.45, %conv35.14.45
  %conv37.14.45 = trunc i32 %xor36.14.45 to i8
  store i8 %conv37.14.45, i8* %scevgep41.14.44, align 1
  %scevgep26.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5335, i64 0, i64 1, i64 1
  %5655 = bitcast i8* %scevgep26.14 to [61 x [61 x i8]]*
  %scevgep39.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5336, i64 0, i64 1, i64 1
  %5656 = bitcast i8* %scevgep39.14 to [61 x [61 x i8]]*
  %arrayidx25.15 = getelementptr inbounds i8, i8* %a, i64 15
  %arrayidx33.15 = getelementptr inbounds i8, i8* %b, i64 15
  %call16.15 = call zeroext i8 (...) @rand()
  store i8 %call16.15, i8* %scevgep26.14, align 1
  %5657 = load i8, i8* %scevgep26.14, align 1
  %conv23.15 = zext i8 %5657 to i32
  %5658 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15 = getelementptr i8, i8* %b, i64 16
  %5659 = load i8, i8* %scevgep34.15, align 1
  %call28.15 = call zeroext i8 @mult(i8 zeroext %5658, i8 zeroext %5659)
  %conv29.15 = zext i8 %call28.15 to i32
  %xor.15 = xor i32 %conv23.15, %conv29.15
  %scevgep35.15 = getelementptr i8, i8* %a, i64 16
  %5660 = load i8, i8* %scevgep35.15, align 1
  %5661 = load i8, i8* %arrayidx33.15, align 1
  %call34.15 = call zeroext i8 @mult(i8 zeroext %5660, i8 zeroext %5661)
  %conv35.15 = zext i8 %call34.15 to i32
  %xor36.15 = xor i32 %xor.15, %conv35.15
  %conv37.15 = trunc i32 %xor36.15 to i8
  store i8 %conv37.15, i8* %scevgep39.14, align 1
  %scevgep28.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5655, i64 0, i64 0, i64 1
  %5662 = bitcast i8* %scevgep28.15 to [61 x [61 x i8]]*
  %scevgep41.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5656, i64 0, i64 1, i64 0
  %5663 = bitcast i8* %scevgep41.15 to [61 x [61 x i8]]*
  %call16.15.1 = call zeroext i8 (...) @rand()
  store i8 %call16.15.1, i8* %scevgep28.15, align 1
  %5664 = load i8, i8* %scevgep28.15, align 1
  %conv23.15.1 = zext i8 %5664 to i32
  %5665 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.1 = getelementptr i8, i8* %b, i64 17
  %5666 = load i8, i8* %scevgep34.15.1, align 1
  %call28.15.1 = call zeroext i8 @mult(i8 zeroext %5665, i8 zeroext %5666)
  %conv29.15.1 = zext i8 %call28.15.1 to i32
  %xor.15.1 = xor i32 %conv23.15.1, %conv29.15.1
  %scevgep35.15.1 = getelementptr i8, i8* %a, i64 17
  %5667 = load i8, i8* %scevgep35.15.1, align 1
  %5668 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.1 = call zeroext i8 @mult(i8 zeroext %5667, i8 zeroext %5668)
  %conv35.15.1 = zext i8 %call34.15.1 to i32
  %xor36.15.1 = xor i32 %xor.15.1, %conv35.15.1
  %conv37.15.1 = trunc i32 %xor36.15.1 to i8
  store i8 %conv37.15.1, i8* %scevgep41.15, align 1
  %scevgep28.15.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5662, i64 0, i64 0, i64 1
  %5669 = bitcast i8* %scevgep28.15.1 to [61 x [61 x i8]]*
  %scevgep41.15.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5663, i64 0, i64 1, i64 0
  %5670 = bitcast i8* %scevgep41.15.1 to [61 x [61 x i8]]*
  %call16.15.2 = call zeroext i8 (...) @rand()
  store i8 %call16.15.2, i8* %scevgep28.15.1, align 1
  %5671 = load i8, i8* %scevgep28.15.1, align 1
  %conv23.15.2 = zext i8 %5671 to i32
  %5672 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.2 = getelementptr i8, i8* %b, i64 18
  %5673 = load i8, i8* %scevgep34.15.2, align 1
  %call28.15.2 = call zeroext i8 @mult(i8 zeroext %5672, i8 zeroext %5673)
  %conv29.15.2 = zext i8 %call28.15.2 to i32
  %xor.15.2 = xor i32 %conv23.15.2, %conv29.15.2
  %scevgep35.15.2 = getelementptr i8, i8* %a, i64 18
  %5674 = load i8, i8* %scevgep35.15.2, align 1
  %5675 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.2 = call zeroext i8 @mult(i8 zeroext %5674, i8 zeroext %5675)
  %conv35.15.2 = zext i8 %call34.15.2 to i32
  %xor36.15.2 = xor i32 %xor.15.2, %conv35.15.2
  %conv37.15.2 = trunc i32 %xor36.15.2 to i8
  store i8 %conv37.15.2, i8* %scevgep41.15.1, align 1
  %scevgep28.15.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5669, i64 0, i64 0, i64 1
  %5676 = bitcast i8* %scevgep28.15.2 to [61 x [61 x i8]]*
  %scevgep41.15.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5670, i64 0, i64 1, i64 0
  %5677 = bitcast i8* %scevgep41.15.2 to [61 x [61 x i8]]*
  %call16.15.3 = call zeroext i8 (...) @rand()
  store i8 %call16.15.3, i8* %scevgep28.15.2, align 1
  %5678 = load i8, i8* %scevgep28.15.2, align 1
  %conv23.15.3 = zext i8 %5678 to i32
  %5679 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.3 = getelementptr i8, i8* %b, i64 19
  %5680 = load i8, i8* %scevgep34.15.3, align 1
  %call28.15.3 = call zeroext i8 @mult(i8 zeroext %5679, i8 zeroext %5680)
  %conv29.15.3 = zext i8 %call28.15.3 to i32
  %xor.15.3 = xor i32 %conv23.15.3, %conv29.15.3
  %scevgep35.15.3 = getelementptr i8, i8* %a, i64 19
  %5681 = load i8, i8* %scevgep35.15.3, align 1
  %5682 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.3 = call zeroext i8 @mult(i8 zeroext %5681, i8 zeroext %5682)
  %conv35.15.3 = zext i8 %call34.15.3 to i32
  %xor36.15.3 = xor i32 %xor.15.3, %conv35.15.3
  %conv37.15.3 = trunc i32 %xor36.15.3 to i8
  store i8 %conv37.15.3, i8* %scevgep41.15.2, align 1
  %scevgep28.15.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5676, i64 0, i64 0, i64 1
  %5683 = bitcast i8* %scevgep28.15.3 to [61 x [61 x i8]]*
  %scevgep41.15.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5677, i64 0, i64 1, i64 0
  %5684 = bitcast i8* %scevgep41.15.3 to [61 x [61 x i8]]*
  %call16.15.4 = call zeroext i8 (...) @rand()
  store i8 %call16.15.4, i8* %scevgep28.15.3, align 1
  %5685 = load i8, i8* %scevgep28.15.3, align 1
  %conv23.15.4 = zext i8 %5685 to i32
  %5686 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.4 = getelementptr i8, i8* %b, i64 20
  %5687 = load i8, i8* %scevgep34.15.4, align 1
  %call28.15.4 = call zeroext i8 @mult(i8 zeroext %5686, i8 zeroext %5687)
  %conv29.15.4 = zext i8 %call28.15.4 to i32
  %xor.15.4 = xor i32 %conv23.15.4, %conv29.15.4
  %scevgep35.15.4 = getelementptr i8, i8* %a, i64 20
  %5688 = load i8, i8* %scevgep35.15.4, align 1
  %5689 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.4 = call zeroext i8 @mult(i8 zeroext %5688, i8 zeroext %5689)
  %conv35.15.4 = zext i8 %call34.15.4 to i32
  %xor36.15.4 = xor i32 %xor.15.4, %conv35.15.4
  %conv37.15.4 = trunc i32 %xor36.15.4 to i8
  store i8 %conv37.15.4, i8* %scevgep41.15.3, align 1
  %scevgep28.15.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5683, i64 0, i64 0, i64 1
  %5690 = bitcast i8* %scevgep28.15.4 to [61 x [61 x i8]]*
  %scevgep41.15.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5684, i64 0, i64 1, i64 0
  %5691 = bitcast i8* %scevgep41.15.4 to [61 x [61 x i8]]*
  %call16.15.5 = call zeroext i8 (...) @rand()
  store i8 %call16.15.5, i8* %scevgep28.15.4, align 1
  %5692 = load i8, i8* %scevgep28.15.4, align 1
  %conv23.15.5 = zext i8 %5692 to i32
  %5693 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.5 = getelementptr i8, i8* %b, i64 21
  %5694 = load i8, i8* %scevgep34.15.5, align 1
  %call28.15.5 = call zeroext i8 @mult(i8 zeroext %5693, i8 zeroext %5694)
  %conv29.15.5 = zext i8 %call28.15.5 to i32
  %xor.15.5 = xor i32 %conv23.15.5, %conv29.15.5
  %scevgep35.15.5 = getelementptr i8, i8* %a, i64 21
  %5695 = load i8, i8* %scevgep35.15.5, align 1
  %5696 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.5 = call zeroext i8 @mult(i8 zeroext %5695, i8 zeroext %5696)
  %conv35.15.5 = zext i8 %call34.15.5 to i32
  %xor36.15.5 = xor i32 %xor.15.5, %conv35.15.5
  %conv37.15.5 = trunc i32 %xor36.15.5 to i8
  store i8 %conv37.15.5, i8* %scevgep41.15.4, align 1
  %scevgep28.15.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5690, i64 0, i64 0, i64 1
  %5697 = bitcast i8* %scevgep28.15.5 to [61 x [61 x i8]]*
  %scevgep41.15.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5691, i64 0, i64 1, i64 0
  %5698 = bitcast i8* %scevgep41.15.5 to [61 x [61 x i8]]*
  %call16.15.6 = call zeroext i8 (...) @rand()
  store i8 %call16.15.6, i8* %scevgep28.15.5, align 1
  %5699 = load i8, i8* %scevgep28.15.5, align 1
  %conv23.15.6 = zext i8 %5699 to i32
  %5700 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.6 = getelementptr i8, i8* %b, i64 22
  %5701 = load i8, i8* %scevgep34.15.6, align 1
  %call28.15.6 = call zeroext i8 @mult(i8 zeroext %5700, i8 zeroext %5701)
  %conv29.15.6 = zext i8 %call28.15.6 to i32
  %xor.15.6 = xor i32 %conv23.15.6, %conv29.15.6
  %scevgep35.15.6 = getelementptr i8, i8* %a, i64 22
  %5702 = load i8, i8* %scevgep35.15.6, align 1
  %5703 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.6 = call zeroext i8 @mult(i8 zeroext %5702, i8 zeroext %5703)
  %conv35.15.6 = zext i8 %call34.15.6 to i32
  %xor36.15.6 = xor i32 %xor.15.6, %conv35.15.6
  %conv37.15.6 = trunc i32 %xor36.15.6 to i8
  store i8 %conv37.15.6, i8* %scevgep41.15.5, align 1
  %scevgep28.15.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5697, i64 0, i64 0, i64 1
  %5704 = bitcast i8* %scevgep28.15.6 to [61 x [61 x i8]]*
  %scevgep41.15.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5698, i64 0, i64 1, i64 0
  %5705 = bitcast i8* %scevgep41.15.6 to [61 x [61 x i8]]*
  %call16.15.7 = call zeroext i8 (...) @rand()
  store i8 %call16.15.7, i8* %scevgep28.15.6, align 1
  %5706 = load i8, i8* %scevgep28.15.6, align 1
  %conv23.15.7 = zext i8 %5706 to i32
  %5707 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.7 = getelementptr i8, i8* %b, i64 23
  %5708 = load i8, i8* %scevgep34.15.7, align 1
  %call28.15.7 = call zeroext i8 @mult(i8 zeroext %5707, i8 zeroext %5708)
  %conv29.15.7 = zext i8 %call28.15.7 to i32
  %xor.15.7 = xor i32 %conv23.15.7, %conv29.15.7
  %scevgep35.15.7 = getelementptr i8, i8* %a, i64 23
  %5709 = load i8, i8* %scevgep35.15.7, align 1
  %5710 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.7 = call zeroext i8 @mult(i8 zeroext %5709, i8 zeroext %5710)
  %conv35.15.7 = zext i8 %call34.15.7 to i32
  %xor36.15.7 = xor i32 %xor.15.7, %conv35.15.7
  %conv37.15.7 = trunc i32 %xor36.15.7 to i8
  store i8 %conv37.15.7, i8* %scevgep41.15.6, align 1
  %scevgep28.15.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5704, i64 0, i64 0, i64 1
  %5711 = bitcast i8* %scevgep28.15.7 to [61 x [61 x i8]]*
  %scevgep41.15.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5705, i64 0, i64 1, i64 0
  %5712 = bitcast i8* %scevgep41.15.7 to [61 x [61 x i8]]*
  %call16.15.8 = call zeroext i8 (...) @rand()
  store i8 %call16.15.8, i8* %scevgep28.15.7, align 1
  %5713 = load i8, i8* %scevgep28.15.7, align 1
  %conv23.15.8 = zext i8 %5713 to i32
  %5714 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.8 = getelementptr i8, i8* %b, i64 24
  %5715 = load i8, i8* %scevgep34.15.8, align 1
  %call28.15.8 = call zeroext i8 @mult(i8 zeroext %5714, i8 zeroext %5715)
  %conv29.15.8 = zext i8 %call28.15.8 to i32
  %xor.15.8 = xor i32 %conv23.15.8, %conv29.15.8
  %scevgep35.15.8 = getelementptr i8, i8* %a, i64 24
  %5716 = load i8, i8* %scevgep35.15.8, align 1
  %5717 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.8 = call zeroext i8 @mult(i8 zeroext %5716, i8 zeroext %5717)
  %conv35.15.8 = zext i8 %call34.15.8 to i32
  %xor36.15.8 = xor i32 %xor.15.8, %conv35.15.8
  %conv37.15.8 = trunc i32 %xor36.15.8 to i8
  store i8 %conv37.15.8, i8* %scevgep41.15.7, align 1
  %scevgep28.15.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5711, i64 0, i64 0, i64 1
  %5718 = bitcast i8* %scevgep28.15.8 to [61 x [61 x i8]]*
  %scevgep41.15.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5712, i64 0, i64 1, i64 0
  %5719 = bitcast i8* %scevgep41.15.8 to [61 x [61 x i8]]*
  %call16.15.9 = call zeroext i8 (...) @rand()
  store i8 %call16.15.9, i8* %scevgep28.15.8, align 1
  %5720 = load i8, i8* %scevgep28.15.8, align 1
  %conv23.15.9 = zext i8 %5720 to i32
  %5721 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.9 = getelementptr i8, i8* %b, i64 25
  %5722 = load i8, i8* %scevgep34.15.9, align 1
  %call28.15.9 = call zeroext i8 @mult(i8 zeroext %5721, i8 zeroext %5722)
  %conv29.15.9 = zext i8 %call28.15.9 to i32
  %xor.15.9 = xor i32 %conv23.15.9, %conv29.15.9
  %scevgep35.15.9 = getelementptr i8, i8* %a, i64 25
  %5723 = load i8, i8* %scevgep35.15.9, align 1
  %5724 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.9 = call zeroext i8 @mult(i8 zeroext %5723, i8 zeroext %5724)
  %conv35.15.9 = zext i8 %call34.15.9 to i32
  %xor36.15.9 = xor i32 %xor.15.9, %conv35.15.9
  %conv37.15.9 = trunc i32 %xor36.15.9 to i8
  store i8 %conv37.15.9, i8* %scevgep41.15.8, align 1
  %scevgep28.15.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5718, i64 0, i64 0, i64 1
  %5725 = bitcast i8* %scevgep28.15.9 to [61 x [61 x i8]]*
  %scevgep41.15.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5719, i64 0, i64 1, i64 0
  %5726 = bitcast i8* %scevgep41.15.9 to [61 x [61 x i8]]*
  %call16.15.10 = call zeroext i8 (...) @rand()
  store i8 %call16.15.10, i8* %scevgep28.15.9, align 1
  %5727 = load i8, i8* %scevgep28.15.9, align 1
  %conv23.15.10 = zext i8 %5727 to i32
  %5728 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.10 = getelementptr i8, i8* %b, i64 26
  %5729 = load i8, i8* %scevgep34.15.10, align 1
  %call28.15.10 = call zeroext i8 @mult(i8 zeroext %5728, i8 zeroext %5729)
  %conv29.15.10 = zext i8 %call28.15.10 to i32
  %xor.15.10 = xor i32 %conv23.15.10, %conv29.15.10
  %scevgep35.15.10 = getelementptr i8, i8* %a, i64 26
  %5730 = load i8, i8* %scevgep35.15.10, align 1
  %5731 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.10 = call zeroext i8 @mult(i8 zeroext %5730, i8 zeroext %5731)
  %conv35.15.10 = zext i8 %call34.15.10 to i32
  %xor36.15.10 = xor i32 %xor.15.10, %conv35.15.10
  %conv37.15.10 = trunc i32 %xor36.15.10 to i8
  store i8 %conv37.15.10, i8* %scevgep41.15.9, align 1
  %scevgep28.15.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5725, i64 0, i64 0, i64 1
  %5732 = bitcast i8* %scevgep28.15.10 to [61 x [61 x i8]]*
  %scevgep41.15.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5726, i64 0, i64 1, i64 0
  %5733 = bitcast i8* %scevgep41.15.10 to [61 x [61 x i8]]*
  %call16.15.11 = call zeroext i8 (...) @rand()
  store i8 %call16.15.11, i8* %scevgep28.15.10, align 1
  %5734 = load i8, i8* %scevgep28.15.10, align 1
  %conv23.15.11 = zext i8 %5734 to i32
  %5735 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.11 = getelementptr i8, i8* %b, i64 27
  %5736 = load i8, i8* %scevgep34.15.11, align 1
  %call28.15.11 = call zeroext i8 @mult(i8 zeroext %5735, i8 zeroext %5736)
  %conv29.15.11 = zext i8 %call28.15.11 to i32
  %xor.15.11 = xor i32 %conv23.15.11, %conv29.15.11
  %scevgep35.15.11 = getelementptr i8, i8* %a, i64 27
  %5737 = load i8, i8* %scevgep35.15.11, align 1
  %5738 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.11 = call zeroext i8 @mult(i8 zeroext %5737, i8 zeroext %5738)
  %conv35.15.11 = zext i8 %call34.15.11 to i32
  %xor36.15.11 = xor i32 %xor.15.11, %conv35.15.11
  %conv37.15.11 = trunc i32 %xor36.15.11 to i8
  store i8 %conv37.15.11, i8* %scevgep41.15.10, align 1
  %scevgep28.15.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5732, i64 0, i64 0, i64 1
  %5739 = bitcast i8* %scevgep28.15.11 to [61 x [61 x i8]]*
  %scevgep41.15.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5733, i64 0, i64 1, i64 0
  %5740 = bitcast i8* %scevgep41.15.11 to [61 x [61 x i8]]*
  %call16.15.12 = call zeroext i8 (...) @rand()
  store i8 %call16.15.12, i8* %scevgep28.15.11, align 1
  %5741 = load i8, i8* %scevgep28.15.11, align 1
  %conv23.15.12 = zext i8 %5741 to i32
  %5742 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.12 = getelementptr i8, i8* %b, i64 28
  %5743 = load i8, i8* %scevgep34.15.12, align 1
  %call28.15.12 = call zeroext i8 @mult(i8 zeroext %5742, i8 zeroext %5743)
  %conv29.15.12 = zext i8 %call28.15.12 to i32
  %xor.15.12 = xor i32 %conv23.15.12, %conv29.15.12
  %scevgep35.15.12 = getelementptr i8, i8* %a, i64 28
  %5744 = load i8, i8* %scevgep35.15.12, align 1
  %5745 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.12 = call zeroext i8 @mult(i8 zeroext %5744, i8 zeroext %5745)
  %conv35.15.12 = zext i8 %call34.15.12 to i32
  %xor36.15.12 = xor i32 %xor.15.12, %conv35.15.12
  %conv37.15.12 = trunc i32 %xor36.15.12 to i8
  store i8 %conv37.15.12, i8* %scevgep41.15.11, align 1
  %scevgep28.15.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5739, i64 0, i64 0, i64 1
  %5746 = bitcast i8* %scevgep28.15.12 to [61 x [61 x i8]]*
  %scevgep41.15.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5740, i64 0, i64 1, i64 0
  %5747 = bitcast i8* %scevgep41.15.12 to [61 x [61 x i8]]*
  %call16.15.13 = call zeroext i8 (...) @rand()
  store i8 %call16.15.13, i8* %scevgep28.15.12, align 1
  %5748 = load i8, i8* %scevgep28.15.12, align 1
  %conv23.15.13 = zext i8 %5748 to i32
  %5749 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.13 = getelementptr i8, i8* %b, i64 29
  %5750 = load i8, i8* %scevgep34.15.13, align 1
  %call28.15.13 = call zeroext i8 @mult(i8 zeroext %5749, i8 zeroext %5750)
  %conv29.15.13 = zext i8 %call28.15.13 to i32
  %xor.15.13 = xor i32 %conv23.15.13, %conv29.15.13
  %scevgep35.15.13 = getelementptr i8, i8* %a, i64 29
  %5751 = load i8, i8* %scevgep35.15.13, align 1
  %5752 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.13 = call zeroext i8 @mult(i8 zeroext %5751, i8 zeroext %5752)
  %conv35.15.13 = zext i8 %call34.15.13 to i32
  %xor36.15.13 = xor i32 %xor.15.13, %conv35.15.13
  %conv37.15.13 = trunc i32 %xor36.15.13 to i8
  store i8 %conv37.15.13, i8* %scevgep41.15.12, align 1
  %scevgep28.15.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5746, i64 0, i64 0, i64 1
  %5753 = bitcast i8* %scevgep28.15.13 to [61 x [61 x i8]]*
  %scevgep41.15.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5747, i64 0, i64 1, i64 0
  %5754 = bitcast i8* %scevgep41.15.13 to [61 x [61 x i8]]*
  %call16.15.14 = call zeroext i8 (...) @rand()
  store i8 %call16.15.14, i8* %scevgep28.15.13, align 1
  %5755 = load i8, i8* %scevgep28.15.13, align 1
  %conv23.15.14 = zext i8 %5755 to i32
  %5756 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.14 = getelementptr i8, i8* %b, i64 30
  %5757 = load i8, i8* %scevgep34.15.14, align 1
  %call28.15.14 = call zeroext i8 @mult(i8 zeroext %5756, i8 zeroext %5757)
  %conv29.15.14 = zext i8 %call28.15.14 to i32
  %xor.15.14 = xor i32 %conv23.15.14, %conv29.15.14
  %scevgep35.15.14 = getelementptr i8, i8* %a, i64 30
  %5758 = load i8, i8* %scevgep35.15.14, align 1
  %5759 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.14 = call zeroext i8 @mult(i8 zeroext %5758, i8 zeroext %5759)
  %conv35.15.14 = zext i8 %call34.15.14 to i32
  %xor36.15.14 = xor i32 %xor.15.14, %conv35.15.14
  %conv37.15.14 = trunc i32 %xor36.15.14 to i8
  store i8 %conv37.15.14, i8* %scevgep41.15.13, align 1
  %scevgep28.15.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5753, i64 0, i64 0, i64 1
  %5760 = bitcast i8* %scevgep28.15.14 to [61 x [61 x i8]]*
  %scevgep41.15.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5754, i64 0, i64 1, i64 0
  %5761 = bitcast i8* %scevgep41.15.14 to [61 x [61 x i8]]*
  %call16.15.15 = call zeroext i8 (...) @rand()
  store i8 %call16.15.15, i8* %scevgep28.15.14, align 1
  %5762 = load i8, i8* %scevgep28.15.14, align 1
  %conv23.15.15 = zext i8 %5762 to i32
  %5763 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.15 = getelementptr i8, i8* %b, i64 31
  %5764 = load i8, i8* %scevgep34.15.15, align 1
  %call28.15.15 = call zeroext i8 @mult(i8 zeroext %5763, i8 zeroext %5764)
  %conv29.15.15 = zext i8 %call28.15.15 to i32
  %xor.15.15 = xor i32 %conv23.15.15, %conv29.15.15
  %scevgep35.15.15 = getelementptr i8, i8* %a, i64 31
  %5765 = load i8, i8* %scevgep35.15.15, align 1
  %5766 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.15 = call zeroext i8 @mult(i8 zeroext %5765, i8 zeroext %5766)
  %conv35.15.15 = zext i8 %call34.15.15 to i32
  %xor36.15.15 = xor i32 %xor.15.15, %conv35.15.15
  %conv37.15.15 = trunc i32 %xor36.15.15 to i8
  store i8 %conv37.15.15, i8* %scevgep41.15.14, align 1
  %scevgep28.15.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5760, i64 0, i64 0, i64 1
  %5767 = bitcast i8* %scevgep28.15.15 to [61 x [61 x i8]]*
  %scevgep41.15.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5761, i64 0, i64 1, i64 0
  %5768 = bitcast i8* %scevgep41.15.15 to [61 x [61 x i8]]*
  %call16.15.16 = call zeroext i8 (...) @rand()
  store i8 %call16.15.16, i8* %scevgep28.15.15, align 1
  %5769 = load i8, i8* %scevgep28.15.15, align 1
  %conv23.15.16 = zext i8 %5769 to i32
  %5770 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.16 = getelementptr i8, i8* %b, i64 32
  %5771 = load i8, i8* %scevgep34.15.16, align 1
  %call28.15.16 = call zeroext i8 @mult(i8 zeroext %5770, i8 zeroext %5771)
  %conv29.15.16 = zext i8 %call28.15.16 to i32
  %xor.15.16 = xor i32 %conv23.15.16, %conv29.15.16
  %scevgep35.15.16 = getelementptr i8, i8* %a, i64 32
  %5772 = load i8, i8* %scevgep35.15.16, align 1
  %5773 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.16 = call zeroext i8 @mult(i8 zeroext %5772, i8 zeroext %5773)
  %conv35.15.16 = zext i8 %call34.15.16 to i32
  %xor36.15.16 = xor i32 %xor.15.16, %conv35.15.16
  %conv37.15.16 = trunc i32 %xor36.15.16 to i8
  store i8 %conv37.15.16, i8* %scevgep41.15.15, align 1
  %scevgep28.15.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5767, i64 0, i64 0, i64 1
  %5774 = bitcast i8* %scevgep28.15.16 to [61 x [61 x i8]]*
  %scevgep41.15.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5768, i64 0, i64 1, i64 0
  %5775 = bitcast i8* %scevgep41.15.16 to [61 x [61 x i8]]*
  %call16.15.17 = call zeroext i8 (...) @rand()
  store i8 %call16.15.17, i8* %scevgep28.15.16, align 1
  %5776 = load i8, i8* %scevgep28.15.16, align 1
  %conv23.15.17 = zext i8 %5776 to i32
  %5777 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.17 = getelementptr i8, i8* %b, i64 33
  %5778 = load i8, i8* %scevgep34.15.17, align 1
  %call28.15.17 = call zeroext i8 @mult(i8 zeroext %5777, i8 zeroext %5778)
  %conv29.15.17 = zext i8 %call28.15.17 to i32
  %xor.15.17 = xor i32 %conv23.15.17, %conv29.15.17
  %scevgep35.15.17 = getelementptr i8, i8* %a, i64 33
  %5779 = load i8, i8* %scevgep35.15.17, align 1
  %5780 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.17 = call zeroext i8 @mult(i8 zeroext %5779, i8 zeroext %5780)
  %conv35.15.17 = zext i8 %call34.15.17 to i32
  %xor36.15.17 = xor i32 %xor.15.17, %conv35.15.17
  %conv37.15.17 = trunc i32 %xor36.15.17 to i8
  store i8 %conv37.15.17, i8* %scevgep41.15.16, align 1
  %scevgep28.15.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5774, i64 0, i64 0, i64 1
  %5781 = bitcast i8* %scevgep28.15.17 to [61 x [61 x i8]]*
  %scevgep41.15.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5775, i64 0, i64 1, i64 0
  %5782 = bitcast i8* %scevgep41.15.17 to [61 x [61 x i8]]*
  %call16.15.18 = call zeroext i8 (...) @rand()
  store i8 %call16.15.18, i8* %scevgep28.15.17, align 1
  %5783 = load i8, i8* %scevgep28.15.17, align 1
  %conv23.15.18 = zext i8 %5783 to i32
  %5784 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.18 = getelementptr i8, i8* %b, i64 34
  %5785 = load i8, i8* %scevgep34.15.18, align 1
  %call28.15.18 = call zeroext i8 @mult(i8 zeroext %5784, i8 zeroext %5785)
  %conv29.15.18 = zext i8 %call28.15.18 to i32
  %xor.15.18 = xor i32 %conv23.15.18, %conv29.15.18
  %scevgep35.15.18 = getelementptr i8, i8* %a, i64 34
  %5786 = load i8, i8* %scevgep35.15.18, align 1
  %5787 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.18 = call zeroext i8 @mult(i8 zeroext %5786, i8 zeroext %5787)
  %conv35.15.18 = zext i8 %call34.15.18 to i32
  %xor36.15.18 = xor i32 %xor.15.18, %conv35.15.18
  %conv37.15.18 = trunc i32 %xor36.15.18 to i8
  store i8 %conv37.15.18, i8* %scevgep41.15.17, align 1
  %scevgep28.15.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5781, i64 0, i64 0, i64 1
  %5788 = bitcast i8* %scevgep28.15.18 to [61 x [61 x i8]]*
  %scevgep41.15.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5782, i64 0, i64 1, i64 0
  %5789 = bitcast i8* %scevgep41.15.18 to [61 x [61 x i8]]*
  %call16.15.19 = call zeroext i8 (...) @rand()
  store i8 %call16.15.19, i8* %scevgep28.15.18, align 1
  %5790 = load i8, i8* %scevgep28.15.18, align 1
  %conv23.15.19 = zext i8 %5790 to i32
  %5791 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.19 = getelementptr i8, i8* %b, i64 35
  %5792 = load i8, i8* %scevgep34.15.19, align 1
  %call28.15.19 = call zeroext i8 @mult(i8 zeroext %5791, i8 zeroext %5792)
  %conv29.15.19 = zext i8 %call28.15.19 to i32
  %xor.15.19 = xor i32 %conv23.15.19, %conv29.15.19
  %scevgep35.15.19 = getelementptr i8, i8* %a, i64 35
  %5793 = load i8, i8* %scevgep35.15.19, align 1
  %5794 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.19 = call zeroext i8 @mult(i8 zeroext %5793, i8 zeroext %5794)
  %conv35.15.19 = zext i8 %call34.15.19 to i32
  %xor36.15.19 = xor i32 %xor.15.19, %conv35.15.19
  %conv37.15.19 = trunc i32 %xor36.15.19 to i8
  store i8 %conv37.15.19, i8* %scevgep41.15.18, align 1
  %scevgep28.15.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5788, i64 0, i64 0, i64 1
  %5795 = bitcast i8* %scevgep28.15.19 to [61 x [61 x i8]]*
  %scevgep41.15.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5789, i64 0, i64 1, i64 0
  %5796 = bitcast i8* %scevgep41.15.19 to [61 x [61 x i8]]*
  %call16.15.20 = call zeroext i8 (...) @rand()
  store i8 %call16.15.20, i8* %scevgep28.15.19, align 1
  %5797 = load i8, i8* %scevgep28.15.19, align 1
  %conv23.15.20 = zext i8 %5797 to i32
  %5798 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.20 = getelementptr i8, i8* %b, i64 36
  %5799 = load i8, i8* %scevgep34.15.20, align 1
  %call28.15.20 = call zeroext i8 @mult(i8 zeroext %5798, i8 zeroext %5799)
  %conv29.15.20 = zext i8 %call28.15.20 to i32
  %xor.15.20 = xor i32 %conv23.15.20, %conv29.15.20
  %scevgep35.15.20 = getelementptr i8, i8* %a, i64 36
  %5800 = load i8, i8* %scevgep35.15.20, align 1
  %5801 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.20 = call zeroext i8 @mult(i8 zeroext %5800, i8 zeroext %5801)
  %conv35.15.20 = zext i8 %call34.15.20 to i32
  %xor36.15.20 = xor i32 %xor.15.20, %conv35.15.20
  %conv37.15.20 = trunc i32 %xor36.15.20 to i8
  store i8 %conv37.15.20, i8* %scevgep41.15.19, align 1
  %scevgep28.15.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5795, i64 0, i64 0, i64 1
  %5802 = bitcast i8* %scevgep28.15.20 to [61 x [61 x i8]]*
  %scevgep41.15.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5796, i64 0, i64 1, i64 0
  %5803 = bitcast i8* %scevgep41.15.20 to [61 x [61 x i8]]*
  %call16.15.21 = call zeroext i8 (...) @rand()
  store i8 %call16.15.21, i8* %scevgep28.15.20, align 1
  %5804 = load i8, i8* %scevgep28.15.20, align 1
  %conv23.15.21 = zext i8 %5804 to i32
  %5805 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.21 = getelementptr i8, i8* %b, i64 37
  %5806 = load i8, i8* %scevgep34.15.21, align 1
  %call28.15.21 = call zeroext i8 @mult(i8 zeroext %5805, i8 zeroext %5806)
  %conv29.15.21 = zext i8 %call28.15.21 to i32
  %xor.15.21 = xor i32 %conv23.15.21, %conv29.15.21
  %scevgep35.15.21 = getelementptr i8, i8* %a, i64 37
  %5807 = load i8, i8* %scevgep35.15.21, align 1
  %5808 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.21 = call zeroext i8 @mult(i8 zeroext %5807, i8 zeroext %5808)
  %conv35.15.21 = zext i8 %call34.15.21 to i32
  %xor36.15.21 = xor i32 %xor.15.21, %conv35.15.21
  %conv37.15.21 = trunc i32 %xor36.15.21 to i8
  store i8 %conv37.15.21, i8* %scevgep41.15.20, align 1
  %scevgep28.15.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5802, i64 0, i64 0, i64 1
  %5809 = bitcast i8* %scevgep28.15.21 to [61 x [61 x i8]]*
  %scevgep41.15.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5803, i64 0, i64 1, i64 0
  %5810 = bitcast i8* %scevgep41.15.21 to [61 x [61 x i8]]*
  %call16.15.22 = call zeroext i8 (...) @rand()
  store i8 %call16.15.22, i8* %scevgep28.15.21, align 1
  %5811 = load i8, i8* %scevgep28.15.21, align 1
  %conv23.15.22 = zext i8 %5811 to i32
  %5812 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.22 = getelementptr i8, i8* %b, i64 38
  %5813 = load i8, i8* %scevgep34.15.22, align 1
  %call28.15.22 = call zeroext i8 @mult(i8 zeroext %5812, i8 zeroext %5813)
  %conv29.15.22 = zext i8 %call28.15.22 to i32
  %xor.15.22 = xor i32 %conv23.15.22, %conv29.15.22
  %scevgep35.15.22 = getelementptr i8, i8* %a, i64 38
  %5814 = load i8, i8* %scevgep35.15.22, align 1
  %5815 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.22 = call zeroext i8 @mult(i8 zeroext %5814, i8 zeroext %5815)
  %conv35.15.22 = zext i8 %call34.15.22 to i32
  %xor36.15.22 = xor i32 %xor.15.22, %conv35.15.22
  %conv37.15.22 = trunc i32 %xor36.15.22 to i8
  store i8 %conv37.15.22, i8* %scevgep41.15.21, align 1
  %scevgep28.15.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5809, i64 0, i64 0, i64 1
  %5816 = bitcast i8* %scevgep28.15.22 to [61 x [61 x i8]]*
  %scevgep41.15.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5810, i64 0, i64 1, i64 0
  %5817 = bitcast i8* %scevgep41.15.22 to [61 x [61 x i8]]*
  %call16.15.23 = call zeroext i8 (...) @rand()
  store i8 %call16.15.23, i8* %scevgep28.15.22, align 1
  %5818 = load i8, i8* %scevgep28.15.22, align 1
  %conv23.15.23 = zext i8 %5818 to i32
  %5819 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.23 = getelementptr i8, i8* %b, i64 39
  %5820 = load i8, i8* %scevgep34.15.23, align 1
  %call28.15.23 = call zeroext i8 @mult(i8 zeroext %5819, i8 zeroext %5820)
  %conv29.15.23 = zext i8 %call28.15.23 to i32
  %xor.15.23 = xor i32 %conv23.15.23, %conv29.15.23
  %scevgep35.15.23 = getelementptr i8, i8* %a, i64 39
  %5821 = load i8, i8* %scevgep35.15.23, align 1
  %5822 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.23 = call zeroext i8 @mult(i8 zeroext %5821, i8 zeroext %5822)
  %conv35.15.23 = zext i8 %call34.15.23 to i32
  %xor36.15.23 = xor i32 %xor.15.23, %conv35.15.23
  %conv37.15.23 = trunc i32 %xor36.15.23 to i8
  store i8 %conv37.15.23, i8* %scevgep41.15.22, align 1
  %scevgep28.15.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5816, i64 0, i64 0, i64 1
  %5823 = bitcast i8* %scevgep28.15.23 to [61 x [61 x i8]]*
  %scevgep41.15.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5817, i64 0, i64 1, i64 0
  %5824 = bitcast i8* %scevgep41.15.23 to [61 x [61 x i8]]*
  %call16.15.24 = call zeroext i8 (...) @rand()
  store i8 %call16.15.24, i8* %scevgep28.15.23, align 1
  %5825 = load i8, i8* %scevgep28.15.23, align 1
  %conv23.15.24 = zext i8 %5825 to i32
  %5826 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.24 = getelementptr i8, i8* %b, i64 40
  %5827 = load i8, i8* %scevgep34.15.24, align 1
  %call28.15.24 = call zeroext i8 @mult(i8 zeroext %5826, i8 zeroext %5827)
  %conv29.15.24 = zext i8 %call28.15.24 to i32
  %xor.15.24 = xor i32 %conv23.15.24, %conv29.15.24
  %scevgep35.15.24 = getelementptr i8, i8* %a, i64 40
  %5828 = load i8, i8* %scevgep35.15.24, align 1
  %5829 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.24 = call zeroext i8 @mult(i8 zeroext %5828, i8 zeroext %5829)
  %conv35.15.24 = zext i8 %call34.15.24 to i32
  %xor36.15.24 = xor i32 %xor.15.24, %conv35.15.24
  %conv37.15.24 = trunc i32 %xor36.15.24 to i8
  store i8 %conv37.15.24, i8* %scevgep41.15.23, align 1
  %scevgep28.15.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5823, i64 0, i64 0, i64 1
  %5830 = bitcast i8* %scevgep28.15.24 to [61 x [61 x i8]]*
  %scevgep41.15.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5824, i64 0, i64 1, i64 0
  %5831 = bitcast i8* %scevgep41.15.24 to [61 x [61 x i8]]*
  %call16.15.25 = call zeroext i8 (...) @rand()
  store i8 %call16.15.25, i8* %scevgep28.15.24, align 1
  %5832 = load i8, i8* %scevgep28.15.24, align 1
  %conv23.15.25 = zext i8 %5832 to i32
  %5833 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.25 = getelementptr i8, i8* %b, i64 41
  %5834 = load i8, i8* %scevgep34.15.25, align 1
  %call28.15.25 = call zeroext i8 @mult(i8 zeroext %5833, i8 zeroext %5834)
  %conv29.15.25 = zext i8 %call28.15.25 to i32
  %xor.15.25 = xor i32 %conv23.15.25, %conv29.15.25
  %scevgep35.15.25 = getelementptr i8, i8* %a, i64 41
  %5835 = load i8, i8* %scevgep35.15.25, align 1
  %5836 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.25 = call zeroext i8 @mult(i8 zeroext %5835, i8 zeroext %5836)
  %conv35.15.25 = zext i8 %call34.15.25 to i32
  %xor36.15.25 = xor i32 %xor.15.25, %conv35.15.25
  %conv37.15.25 = trunc i32 %xor36.15.25 to i8
  store i8 %conv37.15.25, i8* %scevgep41.15.24, align 1
  %scevgep28.15.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5830, i64 0, i64 0, i64 1
  %5837 = bitcast i8* %scevgep28.15.25 to [61 x [61 x i8]]*
  %scevgep41.15.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5831, i64 0, i64 1, i64 0
  %5838 = bitcast i8* %scevgep41.15.25 to [61 x [61 x i8]]*
  %call16.15.26 = call zeroext i8 (...) @rand()
  store i8 %call16.15.26, i8* %scevgep28.15.25, align 1
  %5839 = load i8, i8* %scevgep28.15.25, align 1
  %conv23.15.26 = zext i8 %5839 to i32
  %5840 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.26 = getelementptr i8, i8* %b, i64 42
  %5841 = load i8, i8* %scevgep34.15.26, align 1
  %call28.15.26 = call zeroext i8 @mult(i8 zeroext %5840, i8 zeroext %5841)
  %conv29.15.26 = zext i8 %call28.15.26 to i32
  %xor.15.26 = xor i32 %conv23.15.26, %conv29.15.26
  %scevgep35.15.26 = getelementptr i8, i8* %a, i64 42
  %5842 = load i8, i8* %scevgep35.15.26, align 1
  %5843 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.26 = call zeroext i8 @mult(i8 zeroext %5842, i8 zeroext %5843)
  %conv35.15.26 = zext i8 %call34.15.26 to i32
  %xor36.15.26 = xor i32 %xor.15.26, %conv35.15.26
  %conv37.15.26 = trunc i32 %xor36.15.26 to i8
  store i8 %conv37.15.26, i8* %scevgep41.15.25, align 1
  %scevgep28.15.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5837, i64 0, i64 0, i64 1
  %5844 = bitcast i8* %scevgep28.15.26 to [61 x [61 x i8]]*
  %scevgep41.15.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5838, i64 0, i64 1, i64 0
  %5845 = bitcast i8* %scevgep41.15.26 to [61 x [61 x i8]]*
  %call16.15.27 = call zeroext i8 (...) @rand()
  store i8 %call16.15.27, i8* %scevgep28.15.26, align 1
  %5846 = load i8, i8* %scevgep28.15.26, align 1
  %conv23.15.27 = zext i8 %5846 to i32
  %5847 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.27 = getelementptr i8, i8* %b, i64 43
  %5848 = load i8, i8* %scevgep34.15.27, align 1
  %call28.15.27 = call zeroext i8 @mult(i8 zeroext %5847, i8 zeroext %5848)
  %conv29.15.27 = zext i8 %call28.15.27 to i32
  %xor.15.27 = xor i32 %conv23.15.27, %conv29.15.27
  %scevgep35.15.27 = getelementptr i8, i8* %a, i64 43
  %5849 = load i8, i8* %scevgep35.15.27, align 1
  %5850 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.27 = call zeroext i8 @mult(i8 zeroext %5849, i8 zeroext %5850)
  %conv35.15.27 = zext i8 %call34.15.27 to i32
  %xor36.15.27 = xor i32 %xor.15.27, %conv35.15.27
  %conv37.15.27 = trunc i32 %xor36.15.27 to i8
  store i8 %conv37.15.27, i8* %scevgep41.15.26, align 1
  %scevgep28.15.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5844, i64 0, i64 0, i64 1
  %5851 = bitcast i8* %scevgep28.15.27 to [61 x [61 x i8]]*
  %scevgep41.15.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5845, i64 0, i64 1, i64 0
  %5852 = bitcast i8* %scevgep41.15.27 to [61 x [61 x i8]]*
  %call16.15.28 = call zeroext i8 (...) @rand()
  store i8 %call16.15.28, i8* %scevgep28.15.27, align 1
  %5853 = load i8, i8* %scevgep28.15.27, align 1
  %conv23.15.28 = zext i8 %5853 to i32
  %5854 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.28 = getelementptr i8, i8* %b, i64 44
  %5855 = load i8, i8* %scevgep34.15.28, align 1
  %call28.15.28 = call zeroext i8 @mult(i8 zeroext %5854, i8 zeroext %5855)
  %conv29.15.28 = zext i8 %call28.15.28 to i32
  %xor.15.28 = xor i32 %conv23.15.28, %conv29.15.28
  %scevgep35.15.28 = getelementptr i8, i8* %a, i64 44
  %5856 = load i8, i8* %scevgep35.15.28, align 1
  %5857 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.28 = call zeroext i8 @mult(i8 zeroext %5856, i8 zeroext %5857)
  %conv35.15.28 = zext i8 %call34.15.28 to i32
  %xor36.15.28 = xor i32 %xor.15.28, %conv35.15.28
  %conv37.15.28 = trunc i32 %xor36.15.28 to i8
  store i8 %conv37.15.28, i8* %scevgep41.15.27, align 1
  %scevgep28.15.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5851, i64 0, i64 0, i64 1
  %5858 = bitcast i8* %scevgep28.15.28 to [61 x [61 x i8]]*
  %scevgep41.15.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5852, i64 0, i64 1, i64 0
  %5859 = bitcast i8* %scevgep41.15.28 to [61 x [61 x i8]]*
  %call16.15.29 = call zeroext i8 (...) @rand()
  store i8 %call16.15.29, i8* %scevgep28.15.28, align 1
  %5860 = load i8, i8* %scevgep28.15.28, align 1
  %conv23.15.29 = zext i8 %5860 to i32
  %5861 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.29 = getelementptr i8, i8* %b, i64 45
  %5862 = load i8, i8* %scevgep34.15.29, align 1
  %call28.15.29 = call zeroext i8 @mult(i8 zeroext %5861, i8 zeroext %5862)
  %conv29.15.29 = zext i8 %call28.15.29 to i32
  %xor.15.29 = xor i32 %conv23.15.29, %conv29.15.29
  %scevgep35.15.29 = getelementptr i8, i8* %a, i64 45
  %5863 = load i8, i8* %scevgep35.15.29, align 1
  %5864 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.29 = call zeroext i8 @mult(i8 zeroext %5863, i8 zeroext %5864)
  %conv35.15.29 = zext i8 %call34.15.29 to i32
  %xor36.15.29 = xor i32 %xor.15.29, %conv35.15.29
  %conv37.15.29 = trunc i32 %xor36.15.29 to i8
  store i8 %conv37.15.29, i8* %scevgep41.15.28, align 1
  %scevgep28.15.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5858, i64 0, i64 0, i64 1
  %5865 = bitcast i8* %scevgep28.15.29 to [61 x [61 x i8]]*
  %scevgep41.15.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5859, i64 0, i64 1, i64 0
  %5866 = bitcast i8* %scevgep41.15.29 to [61 x [61 x i8]]*
  %call16.15.30 = call zeroext i8 (...) @rand()
  store i8 %call16.15.30, i8* %scevgep28.15.29, align 1
  %5867 = load i8, i8* %scevgep28.15.29, align 1
  %conv23.15.30 = zext i8 %5867 to i32
  %5868 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.30 = getelementptr i8, i8* %b, i64 46
  %5869 = load i8, i8* %scevgep34.15.30, align 1
  %call28.15.30 = call zeroext i8 @mult(i8 zeroext %5868, i8 zeroext %5869)
  %conv29.15.30 = zext i8 %call28.15.30 to i32
  %xor.15.30 = xor i32 %conv23.15.30, %conv29.15.30
  %scevgep35.15.30 = getelementptr i8, i8* %a, i64 46
  %5870 = load i8, i8* %scevgep35.15.30, align 1
  %5871 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.30 = call zeroext i8 @mult(i8 zeroext %5870, i8 zeroext %5871)
  %conv35.15.30 = zext i8 %call34.15.30 to i32
  %xor36.15.30 = xor i32 %xor.15.30, %conv35.15.30
  %conv37.15.30 = trunc i32 %xor36.15.30 to i8
  store i8 %conv37.15.30, i8* %scevgep41.15.29, align 1
  %scevgep28.15.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5865, i64 0, i64 0, i64 1
  %5872 = bitcast i8* %scevgep28.15.30 to [61 x [61 x i8]]*
  %scevgep41.15.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5866, i64 0, i64 1, i64 0
  %5873 = bitcast i8* %scevgep41.15.30 to [61 x [61 x i8]]*
  %call16.15.31 = call zeroext i8 (...) @rand()
  store i8 %call16.15.31, i8* %scevgep28.15.30, align 1
  %5874 = load i8, i8* %scevgep28.15.30, align 1
  %conv23.15.31 = zext i8 %5874 to i32
  %5875 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.31 = getelementptr i8, i8* %b, i64 47
  %5876 = load i8, i8* %scevgep34.15.31, align 1
  %call28.15.31 = call zeroext i8 @mult(i8 zeroext %5875, i8 zeroext %5876)
  %conv29.15.31 = zext i8 %call28.15.31 to i32
  %xor.15.31 = xor i32 %conv23.15.31, %conv29.15.31
  %scevgep35.15.31 = getelementptr i8, i8* %a, i64 47
  %5877 = load i8, i8* %scevgep35.15.31, align 1
  %5878 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.31 = call zeroext i8 @mult(i8 zeroext %5877, i8 zeroext %5878)
  %conv35.15.31 = zext i8 %call34.15.31 to i32
  %xor36.15.31 = xor i32 %xor.15.31, %conv35.15.31
  %conv37.15.31 = trunc i32 %xor36.15.31 to i8
  store i8 %conv37.15.31, i8* %scevgep41.15.30, align 1
  %scevgep28.15.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5872, i64 0, i64 0, i64 1
  %5879 = bitcast i8* %scevgep28.15.31 to [61 x [61 x i8]]*
  %scevgep41.15.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5873, i64 0, i64 1, i64 0
  %5880 = bitcast i8* %scevgep41.15.31 to [61 x [61 x i8]]*
  %call16.15.32 = call zeroext i8 (...) @rand()
  store i8 %call16.15.32, i8* %scevgep28.15.31, align 1
  %5881 = load i8, i8* %scevgep28.15.31, align 1
  %conv23.15.32 = zext i8 %5881 to i32
  %5882 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.32 = getelementptr i8, i8* %b, i64 48
  %5883 = load i8, i8* %scevgep34.15.32, align 1
  %call28.15.32 = call zeroext i8 @mult(i8 zeroext %5882, i8 zeroext %5883)
  %conv29.15.32 = zext i8 %call28.15.32 to i32
  %xor.15.32 = xor i32 %conv23.15.32, %conv29.15.32
  %scevgep35.15.32 = getelementptr i8, i8* %a, i64 48
  %5884 = load i8, i8* %scevgep35.15.32, align 1
  %5885 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.32 = call zeroext i8 @mult(i8 zeroext %5884, i8 zeroext %5885)
  %conv35.15.32 = zext i8 %call34.15.32 to i32
  %xor36.15.32 = xor i32 %xor.15.32, %conv35.15.32
  %conv37.15.32 = trunc i32 %xor36.15.32 to i8
  store i8 %conv37.15.32, i8* %scevgep41.15.31, align 1
  %scevgep28.15.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5879, i64 0, i64 0, i64 1
  %5886 = bitcast i8* %scevgep28.15.32 to [61 x [61 x i8]]*
  %scevgep41.15.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5880, i64 0, i64 1, i64 0
  %5887 = bitcast i8* %scevgep41.15.32 to [61 x [61 x i8]]*
  %call16.15.33 = call zeroext i8 (...) @rand()
  store i8 %call16.15.33, i8* %scevgep28.15.32, align 1
  %5888 = load i8, i8* %scevgep28.15.32, align 1
  %conv23.15.33 = zext i8 %5888 to i32
  %5889 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.33 = getelementptr i8, i8* %b, i64 49
  %5890 = load i8, i8* %scevgep34.15.33, align 1
  %call28.15.33 = call zeroext i8 @mult(i8 zeroext %5889, i8 zeroext %5890)
  %conv29.15.33 = zext i8 %call28.15.33 to i32
  %xor.15.33 = xor i32 %conv23.15.33, %conv29.15.33
  %scevgep35.15.33 = getelementptr i8, i8* %a, i64 49
  %5891 = load i8, i8* %scevgep35.15.33, align 1
  %5892 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.33 = call zeroext i8 @mult(i8 zeroext %5891, i8 zeroext %5892)
  %conv35.15.33 = zext i8 %call34.15.33 to i32
  %xor36.15.33 = xor i32 %xor.15.33, %conv35.15.33
  %conv37.15.33 = trunc i32 %xor36.15.33 to i8
  store i8 %conv37.15.33, i8* %scevgep41.15.32, align 1
  %scevgep28.15.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5886, i64 0, i64 0, i64 1
  %5893 = bitcast i8* %scevgep28.15.33 to [61 x [61 x i8]]*
  %scevgep41.15.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5887, i64 0, i64 1, i64 0
  %5894 = bitcast i8* %scevgep41.15.33 to [61 x [61 x i8]]*
  %call16.15.34 = call zeroext i8 (...) @rand()
  store i8 %call16.15.34, i8* %scevgep28.15.33, align 1
  %5895 = load i8, i8* %scevgep28.15.33, align 1
  %conv23.15.34 = zext i8 %5895 to i32
  %5896 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.34 = getelementptr i8, i8* %b, i64 50
  %5897 = load i8, i8* %scevgep34.15.34, align 1
  %call28.15.34 = call zeroext i8 @mult(i8 zeroext %5896, i8 zeroext %5897)
  %conv29.15.34 = zext i8 %call28.15.34 to i32
  %xor.15.34 = xor i32 %conv23.15.34, %conv29.15.34
  %scevgep35.15.34 = getelementptr i8, i8* %a, i64 50
  %5898 = load i8, i8* %scevgep35.15.34, align 1
  %5899 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.34 = call zeroext i8 @mult(i8 zeroext %5898, i8 zeroext %5899)
  %conv35.15.34 = zext i8 %call34.15.34 to i32
  %xor36.15.34 = xor i32 %xor.15.34, %conv35.15.34
  %conv37.15.34 = trunc i32 %xor36.15.34 to i8
  store i8 %conv37.15.34, i8* %scevgep41.15.33, align 1
  %scevgep28.15.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5893, i64 0, i64 0, i64 1
  %5900 = bitcast i8* %scevgep28.15.34 to [61 x [61 x i8]]*
  %scevgep41.15.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5894, i64 0, i64 1, i64 0
  %5901 = bitcast i8* %scevgep41.15.34 to [61 x [61 x i8]]*
  %call16.15.35 = call zeroext i8 (...) @rand()
  store i8 %call16.15.35, i8* %scevgep28.15.34, align 1
  %5902 = load i8, i8* %scevgep28.15.34, align 1
  %conv23.15.35 = zext i8 %5902 to i32
  %5903 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.35 = getelementptr i8, i8* %b, i64 51
  %5904 = load i8, i8* %scevgep34.15.35, align 1
  %call28.15.35 = call zeroext i8 @mult(i8 zeroext %5903, i8 zeroext %5904)
  %conv29.15.35 = zext i8 %call28.15.35 to i32
  %xor.15.35 = xor i32 %conv23.15.35, %conv29.15.35
  %scevgep35.15.35 = getelementptr i8, i8* %a, i64 51
  %5905 = load i8, i8* %scevgep35.15.35, align 1
  %5906 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.35 = call zeroext i8 @mult(i8 zeroext %5905, i8 zeroext %5906)
  %conv35.15.35 = zext i8 %call34.15.35 to i32
  %xor36.15.35 = xor i32 %xor.15.35, %conv35.15.35
  %conv37.15.35 = trunc i32 %xor36.15.35 to i8
  store i8 %conv37.15.35, i8* %scevgep41.15.34, align 1
  %scevgep28.15.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5900, i64 0, i64 0, i64 1
  %5907 = bitcast i8* %scevgep28.15.35 to [61 x [61 x i8]]*
  %scevgep41.15.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5901, i64 0, i64 1, i64 0
  %5908 = bitcast i8* %scevgep41.15.35 to [61 x [61 x i8]]*
  %call16.15.36 = call zeroext i8 (...) @rand()
  store i8 %call16.15.36, i8* %scevgep28.15.35, align 1
  %5909 = load i8, i8* %scevgep28.15.35, align 1
  %conv23.15.36 = zext i8 %5909 to i32
  %5910 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.36 = getelementptr i8, i8* %b, i64 52
  %5911 = load i8, i8* %scevgep34.15.36, align 1
  %call28.15.36 = call zeroext i8 @mult(i8 zeroext %5910, i8 zeroext %5911)
  %conv29.15.36 = zext i8 %call28.15.36 to i32
  %xor.15.36 = xor i32 %conv23.15.36, %conv29.15.36
  %scevgep35.15.36 = getelementptr i8, i8* %a, i64 52
  %5912 = load i8, i8* %scevgep35.15.36, align 1
  %5913 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.36 = call zeroext i8 @mult(i8 zeroext %5912, i8 zeroext %5913)
  %conv35.15.36 = zext i8 %call34.15.36 to i32
  %xor36.15.36 = xor i32 %xor.15.36, %conv35.15.36
  %conv37.15.36 = trunc i32 %xor36.15.36 to i8
  store i8 %conv37.15.36, i8* %scevgep41.15.35, align 1
  %scevgep28.15.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5907, i64 0, i64 0, i64 1
  %5914 = bitcast i8* %scevgep28.15.36 to [61 x [61 x i8]]*
  %scevgep41.15.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5908, i64 0, i64 1, i64 0
  %5915 = bitcast i8* %scevgep41.15.36 to [61 x [61 x i8]]*
  %call16.15.37 = call zeroext i8 (...) @rand()
  store i8 %call16.15.37, i8* %scevgep28.15.36, align 1
  %5916 = load i8, i8* %scevgep28.15.36, align 1
  %conv23.15.37 = zext i8 %5916 to i32
  %5917 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.37 = getelementptr i8, i8* %b, i64 53
  %5918 = load i8, i8* %scevgep34.15.37, align 1
  %call28.15.37 = call zeroext i8 @mult(i8 zeroext %5917, i8 zeroext %5918)
  %conv29.15.37 = zext i8 %call28.15.37 to i32
  %xor.15.37 = xor i32 %conv23.15.37, %conv29.15.37
  %scevgep35.15.37 = getelementptr i8, i8* %a, i64 53
  %5919 = load i8, i8* %scevgep35.15.37, align 1
  %5920 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.37 = call zeroext i8 @mult(i8 zeroext %5919, i8 zeroext %5920)
  %conv35.15.37 = zext i8 %call34.15.37 to i32
  %xor36.15.37 = xor i32 %xor.15.37, %conv35.15.37
  %conv37.15.37 = trunc i32 %xor36.15.37 to i8
  store i8 %conv37.15.37, i8* %scevgep41.15.36, align 1
  %scevgep28.15.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5914, i64 0, i64 0, i64 1
  %5921 = bitcast i8* %scevgep28.15.37 to [61 x [61 x i8]]*
  %scevgep41.15.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5915, i64 0, i64 1, i64 0
  %5922 = bitcast i8* %scevgep41.15.37 to [61 x [61 x i8]]*
  %call16.15.38 = call zeroext i8 (...) @rand()
  store i8 %call16.15.38, i8* %scevgep28.15.37, align 1
  %5923 = load i8, i8* %scevgep28.15.37, align 1
  %conv23.15.38 = zext i8 %5923 to i32
  %5924 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.38 = getelementptr i8, i8* %b, i64 54
  %5925 = load i8, i8* %scevgep34.15.38, align 1
  %call28.15.38 = call zeroext i8 @mult(i8 zeroext %5924, i8 zeroext %5925)
  %conv29.15.38 = zext i8 %call28.15.38 to i32
  %xor.15.38 = xor i32 %conv23.15.38, %conv29.15.38
  %scevgep35.15.38 = getelementptr i8, i8* %a, i64 54
  %5926 = load i8, i8* %scevgep35.15.38, align 1
  %5927 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.38 = call zeroext i8 @mult(i8 zeroext %5926, i8 zeroext %5927)
  %conv35.15.38 = zext i8 %call34.15.38 to i32
  %xor36.15.38 = xor i32 %xor.15.38, %conv35.15.38
  %conv37.15.38 = trunc i32 %xor36.15.38 to i8
  store i8 %conv37.15.38, i8* %scevgep41.15.37, align 1
  %scevgep28.15.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5921, i64 0, i64 0, i64 1
  %5928 = bitcast i8* %scevgep28.15.38 to [61 x [61 x i8]]*
  %scevgep41.15.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5922, i64 0, i64 1, i64 0
  %5929 = bitcast i8* %scevgep41.15.38 to [61 x [61 x i8]]*
  %call16.15.39 = call zeroext i8 (...) @rand()
  store i8 %call16.15.39, i8* %scevgep28.15.38, align 1
  %5930 = load i8, i8* %scevgep28.15.38, align 1
  %conv23.15.39 = zext i8 %5930 to i32
  %5931 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.39 = getelementptr i8, i8* %b, i64 55
  %5932 = load i8, i8* %scevgep34.15.39, align 1
  %call28.15.39 = call zeroext i8 @mult(i8 zeroext %5931, i8 zeroext %5932)
  %conv29.15.39 = zext i8 %call28.15.39 to i32
  %xor.15.39 = xor i32 %conv23.15.39, %conv29.15.39
  %scevgep35.15.39 = getelementptr i8, i8* %a, i64 55
  %5933 = load i8, i8* %scevgep35.15.39, align 1
  %5934 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.39 = call zeroext i8 @mult(i8 zeroext %5933, i8 zeroext %5934)
  %conv35.15.39 = zext i8 %call34.15.39 to i32
  %xor36.15.39 = xor i32 %xor.15.39, %conv35.15.39
  %conv37.15.39 = trunc i32 %xor36.15.39 to i8
  store i8 %conv37.15.39, i8* %scevgep41.15.38, align 1
  %scevgep28.15.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5928, i64 0, i64 0, i64 1
  %5935 = bitcast i8* %scevgep28.15.39 to [61 x [61 x i8]]*
  %scevgep41.15.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5929, i64 0, i64 1, i64 0
  %5936 = bitcast i8* %scevgep41.15.39 to [61 x [61 x i8]]*
  %call16.15.40 = call zeroext i8 (...) @rand()
  store i8 %call16.15.40, i8* %scevgep28.15.39, align 1
  %5937 = load i8, i8* %scevgep28.15.39, align 1
  %conv23.15.40 = zext i8 %5937 to i32
  %5938 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.40 = getelementptr i8, i8* %b, i64 56
  %5939 = load i8, i8* %scevgep34.15.40, align 1
  %call28.15.40 = call zeroext i8 @mult(i8 zeroext %5938, i8 zeroext %5939)
  %conv29.15.40 = zext i8 %call28.15.40 to i32
  %xor.15.40 = xor i32 %conv23.15.40, %conv29.15.40
  %scevgep35.15.40 = getelementptr i8, i8* %a, i64 56
  %5940 = load i8, i8* %scevgep35.15.40, align 1
  %5941 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.40 = call zeroext i8 @mult(i8 zeroext %5940, i8 zeroext %5941)
  %conv35.15.40 = zext i8 %call34.15.40 to i32
  %xor36.15.40 = xor i32 %xor.15.40, %conv35.15.40
  %conv37.15.40 = trunc i32 %xor36.15.40 to i8
  store i8 %conv37.15.40, i8* %scevgep41.15.39, align 1
  %scevgep28.15.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5935, i64 0, i64 0, i64 1
  %5942 = bitcast i8* %scevgep28.15.40 to [61 x [61 x i8]]*
  %scevgep41.15.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5936, i64 0, i64 1, i64 0
  %5943 = bitcast i8* %scevgep41.15.40 to [61 x [61 x i8]]*
  %call16.15.41 = call zeroext i8 (...) @rand()
  store i8 %call16.15.41, i8* %scevgep28.15.40, align 1
  %5944 = load i8, i8* %scevgep28.15.40, align 1
  %conv23.15.41 = zext i8 %5944 to i32
  %5945 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.41 = getelementptr i8, i8* %b, i64 57
  %5946 = load i8, i8* %scevgep34.15.41, align 1
  %call28.15.41 = call zeroext i8 @mult(i8 zeroext %5945, i8 zeroext %5946)
  %conv29.15.41 = zext i8 %call28.15.41 to i32
  %xor.15.41 = xor i32 %conv23.15.41, %conv29.15.41
  %scevgep35.15.41 = getelementptr i8, i8* %a, i64 57
  %5947 = load i8, i8* %scevgep35.15.41, align 1
  %5948 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.41 = call zeroext i8 @mult(i8 zeroext %5947, i8 zeroext %5948)
  %conv35.15.41 = zext i8 %call34.15.41 to i32
  %xor36.15.41 = xor i32 %xor.15.41, %conv35.15.41
  %conv37.15.41 = trunc i32 %xor36.15.41 to i8
  store i8 %conv37.15.41, i8* %scevgep41.15.40, align 1
  %scevgep28.15.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5942, i64 0, i64 0, i64 1
  %5949 = bitcast i8* %scevgep28.15.41 to [61 x [61 x i8]]*
  %scevgep41.15.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5943, i64 0, i64 1, i64 0
  %5950 = bitcast i8* %scevgep41.15.41 to [61 x [61 x i8]]*
  %call16.15.42 = call zeroext i8 (...) @rand()
  store i8 %call16.15.42, i8* %scevgep28.15.41, align 1
  %5951 = load i8, i8* %scevgep28.15.41, align 1
  %conv23.15.42 = zext i8 %5951 to i32
  %5952 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.42 = getelementptr i8, i8* %b, i64 58
  %5953 = load i8, i8* %scevgep34.15.42, align 1
  %call28.15.42 = call zeroext i8 @mult(i8 zeroext %5952, i8 zeroext %5953)
  %conv29.15.42 = zext i8 %call28.15.42 to i32
  %xor.15.42 = xor i32 %conv23.15.42, %conv29.15.42
  %scevgep35.15.42 = getelementptr i8, i8* %a, i64 58
  %5954 = load i8, i8* %scevgep35.15.42, align 1
  %5955 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.42 = call zeroext i8 @mult(i8 zeroext %5954, i8 zeroext %5955)
  %conv35.15.42 = zext i8 %call34.15.42 to i32
  %xor36.15.42 = xor i32 %xor.15.42, %conv35.15.42
  %conv37.15.42 = trunc i32 %xor36.15.42 to i8
  store i8 %conv37.15.42, i8* %scevgep41.15.41, align 1
  %scevgep28.15.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5949, i64 0, i64 0, i64 1
  %5956 = bitcast i8* %scevgep28.15.42 to [61 x [61 x i8]]*
  %scevgep41.15.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5950, i64 0, i64 1, i64 0
  %5957 = bitcast i8* %scevgep41.15.42 to [61 x [61 x i8]]*
  %call16.15.43 = call zeroext i8 (...) @rand()
  store i8 %call16.15.43, i8* %scevgep28.15.42, align 1
  %5958 = load i8, i8* %scevgep28.15.42, align 1
  %conv23.15.43 = zext i8 %5958 to i32
  %5959 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.43 = getelementptr i8, i8* %b, i64 59
  %5960 = load i8, i8* %scevgep34.15.43, align 1
  %call28.15.43 = call zeroext i8 @mult(i8 zeroext %5959, i8 zeroext %5960)
  %conv29.15.43 = zext i8 %call28.15.43 to i32
  %xor.15.43 = xor i32 %conv23.15.43, %conv29.15.43
  %scevgep35.15.43 = getelementptr i8, i8* %a, i64 59
  %5961 = load i8, i8* %scevgep35.15.43, align 1
  %5962 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.43 = call zeroext i8 @mult(i8 zeroext %5961, i8 zeroext %5962)
  %conv35.15.43 = zext i8 %call34.15.43 to i32
  %xor36.15.43 = xor i32 %xor.15.43, %conv35.15.43
  %conv37.15.43 = trunc i32 %xor36.15.43 to i8
  store i8 %conv37.15.43, i8* %scevgep41.15.42, align 1
  %scevgep28.15.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5956, i64 0, i64 0, i64 1
  %scevgep41.15.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5957, i64 0, i64 1, i64 0
  %call16.15.44 = call zeroext i8 (...) @rand()
  store i8 %call16.15.44, i8* %scevgep28.15.43, align 1
  %5963 = load i8, i8* %scevgep28.15.43, align 1
  %conv23.15.44 = zext i8 %5963 to i32
  %5964 = load i8, i8* %arrayidx25.15, align 1
  %scevgep34.15.44 = getelementptr i8, i8* %b, i64 60
  %5965 = load i8, i8* %scevgep34.15.44, align 1
  %call28.15.44 = call zeroext i8 @mult(i8 zeroext %5964, i8 zeroext %5965)
  %conv29.15.44 = zext i8 %call28.15.44 to i32
  %xor.15.44 = xor i32 %conv23.15.44, %conv29.15.44
  %scevgep35.15.44 = getelementptr i8, i8* %a, i64 60
  %5966 = load i8, i8* %scevgep35.15.44, align 1
  %5967 = load i8, i8* %arrayidx33.15, align 1
  %call34.15.44 = call zeroext i8 @mult(i8 zeroext %5966, i8 zeroext %5967)
  %conv35.15.44 = zext i8 %call34.15.44 to i32
  %xor36.15.44 = xor i32 %xor.15.44, %conv35.15.44
  %conv37.15.44 = trunc i32 %xor36.15.44 to i8
  store i8 %conv37.15.44, i8* %scevgep41.15.43, align 1
  %scevgep26.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5655, i64 0, i64 1, i64 1
  %5968 = bitcast i8* %scevgep26.15 to [61 x [61 x i8]]*
  %scevgep39.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5656, i64 0, i64 1, i64 1
  %5969 = bitcast i8* %scevgep39.15 to [61 x [61 x i8]]*
  %arrayidx25.16 = getelementptr inbounds i8, i8* %a, i64 16
  %arrayidx33.16 = getelementptr inbounds i8, i8* %b, i64 16
  %call16.16 = call zeroext i8 (...) @rand()
  store i8 %call16.16, i8* %scevgep26.15, align 1
  %5970 = load i8, i8* %scevgep26.15, align 1
  %conv23.16 = zext i8 %5970 to i32
  %5971 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16 = getelementptr i8, i8* %b, i64 17
  %5972 = load i8, i8* %scevgep34.16, align 1
  %call28.16 = call zeroext i8 @mult(i8 zeroext %5971, i8 zeroext %5972)
  %conv29.16 = zext i8 %call28.16 to i32
  %xor.16 = xor i32 %conv23.16, %conv29.16
  %scevgep35.16 = getelementptr i8, i8* %a, i64 17
  %5973 = load i8, i8* %scevgep35.16, align 1
  %5974 = load i8, i8* %arrayidx33.16, align 1
  %call34.16 = call zeroext i8 @mult(i8 zeroext %5973, i8 zeroext %5974)
  %conv35.16 = zext i8 %call34.16 to i32
  %xor36.16 = xor i32 %xor.16, %conv35.16
  %conv37.16 = trunc i32 %xor36.16 to i8
  store i8 %conv37.16, i8* %scevgep39.15, align 1
  %scevgep28.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5968, i64 0, i64 0, i64 1
  %5975 = bitcast i8* %scevgep28.16 to [61 x [61 x i8]]*
  %scevgep41.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5969, i64 0, i64 1, i64 0
  %5976 = bitcast i8* %scevgep41.16 to [61 x [61 x i8]]*
  %call16.16.1 = call zeroext i8 (...) @rand()
  store i8 %call16.16.1, i8* %scevgep28.16, align 1
  %5977 = load i8, i8* %scevgep28.16, align 1
  %conv23.16.1 = zext i8 %5977 to i32
  %5978 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.1 = getelementptr i8, i8* %b, i64 18
  %5979 = load i8, i8* %scevgep34.16.1, align 1
  %call28.16.1 = call zeroext i8 @mult(i8 zeroext %5978, i8 zeroext %5979)
  %conv29.16.1 = zext i8 %call28.16.1 to i32
  %xor.16.1 = xor i32 %conv23.16.1, %conv29.16.1
  %scevgep35.16.1 = getelementptr i8, i8* %a, i64 18
  %5980 = load i8, i8* %scevgep35.16.1, align 1
  %5981 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.1 = call zeroext i8 @mult(i8 zeroext %5980, i8 zeroext %5981)
  %conv35.16.1 = zext i8 %call34.16.1 to i32
  %xor36.16.1 = xor i32 %xor.16.1, %conv35.16.1
  %conv37.16.1 = trunc i32 %xor36.16.1 to i8
  store i8 %conv37.16.1, i8* %scevgep41.16, align 1
  %scevgep28.16.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5975, i64 0, i64 0, i64 1
  %5982 = bitcast i8* %scevgep28.16.1 to [61 x [61 x i8]]*
  %scevgep41.16.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5976, i64 0, i64 1, i64 0
  %5983 = bitcast i8* %scevgep41.16.1 to [61 x [61 x i8]]*
  %call16.16.2 = call zeroext i8 (...) @rand()
  store i8 %call16.16.2, i8* %scevgep28.16.1, align 1
  %5984 = load i8, i8* %scevgep28.16.1, align 1
  %conv23.16.2 = zext i8 %5984 to i32
  %5985 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.2 = getelementptr i8, i8* %b, i64 19
  %5986 = load i8, i8* %scevgep34.16.2, align 1
  %call28.16.2 = call zeroext i8 @mult(i8 zeroext %5985, i8 zeroext %5986)
  %conv29.16.2 = zext i8 %call28.16.2 to i32
  %xor.16.2 = xor i32 %conv23.16.2, %conv29.16.2
  %scevgep35.16.2 = getelementptr i8, i8* %a, i64 19
  %5987 = load i8, i8* %scevgep35.16.2, align 1
  %5988 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.2 = call zeroext i8 @mult(i8 zeroext %5987, i8 zeroext %5988)
  %conv35.16.2 = zext i8 %call34.16.2 to i32
  %xor36.16.2 = xor i32 %xor.16.2, %conv35.16.2
  %conv37.16.2 = trunc i32 %xor36.16.2 to i8
  store i8 %conv37.16.2, i8* %scevgep41.16.1, align 1
  %scevgep28.16.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5982, i64 0, i64 0, i64 1
  %5989 = bitcast i8* %scevgep28.16.2 to [61 x [61 x i8]]*
  %scevgep41.16.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5983, i64 0, i64 1, i64 0
  %5990 = bitcast i8* %scevgep41.16.2 to [61 x [61 x i8]]*
  %call16.16.3 = call zeroext i8 (...) @rand()
  store i8 %call16.16.3, i8* %scevgep28.16.2, align 1
  %5991 = load i8, i8* %scevgep28.16.2, align 1
  %conv23.16.3 = zext i8 %5991 to i32
  %5992 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.3 = getelementptr i8, i8* %b, i64 20
  %5993 = load i8, i8* %scevgep34.16.3, align 1
  %call28.16.3 = call zeroext i8 @mult(i8 zeroext %5992, i8 zeroext %5993)
  %conv29.16.3 = zext i8 %call28.16.3 to i32
  %xor.16.3 = xor i32 %conv23.16.3, %conv29.16.3
  %scevgep35.16.3 = getelementptr i8, i8* %a, i64 20
  %5994 = load i8, i8* %scevgep35.16.3, align 1
  %5995 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.3 = call zeroext i8 @mult(i8 zeroext %5994, i8 zeroext %5995)
  %conv35.16.3 = zext i8 %call34.16.3 to i32
  %xor36.16.3 = xor i32 %xor.16.3, %conv35.16.3
  %conv37.16.3 = trunc i32 %xor36.16.3 to i8
  store i8 %conv37.16.3, i8* %scevgep41.16.2, align 1
  %scevgep28.16.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5989, i64 0, i64 0, i64 1
  %5996 = bitcast i8* %scevgep28.16.3 to [61 x [61 x i8]]*
  %scevgep41.16.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5990, i64 0, i64 1, i64 0
  %5997 = bitcast i8* %scevgep41.16.3 to [61 x [61 x i8]]*
  %call16.16.4 = call zeroext i8 (...) @rand()
  store i8 %call16.16.4, i8* %scevgep28.16.3, align 1
  %5998 = load i8, i8* %scevgep28.16.3, align 1
  %conv23.16.4 = zext i8 %5998 to i32
  %5999 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.4 = getelementptr i8, i8* %b, i64 21
  %6000 = load i8, i8* %scevgep34.16.4, align 1
  %call28.16.4 = call zeroext i8 @mult(i8 zeroext %5999, i8 zeroext %6000)
  %conv29.16.4 = zext i8 %call28.16.4 to i32
  %xor.16.4 = xor i32 %conv23.16.4, %conv29.16.4
  %scevgep35.16.4 = getelementptr i8, i8* %a, i64 21
  %6001 = load i8, i8* %scevgep35.16.4, align 1
  %6002 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.4 = call zeroext i8 @mult(i8 zeroext %6001, i8 zeroext %6002)
  %conv35.16.4 = zext i8 %call34.16.4 to i32
  %xor36.16.4 = xor i32 %xor.16.4, %conv35.16.4
  %conv37.16.4 = trunc i32 %xor36.16.4 to i8
  store i8 %conv37.16.4, i8* %scevgep41.16.3, align 1
  %scevgep28.16.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5996, i64 0, i64 0, i64 1
  %6003 = bitcast i8* %scevgep28.16.4 to [61 x [61 x i8]]*
  %scevgep41.16.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5997, i64 0, i64 1, i64 0
  %6004 = bitcast i8* %scevgep41.16.4 to [61 x [61 x i8]]*
  %call16.16.5 = call zeroext i8 (...) @rand()
  store i8 %call16.16.5, i8* %scevgep28.16.4, align 1
  %6005 = load i8, i8* %scevgep28.16.4, align 1
  %conv23.16.5 = zext i8 %6005 to i32
  %6006 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.5 = getelementptr i8, i8* %b, i64 22
  %6007 = load i8, i8* %scevgep34.16.5, align 1
  %call28.16.5 = call zeroext i8 @mult(i8 zeroext %6006, i8 zeroext %6007)
  %conv29.16.5 = zext i8 %call28.16.5 to i32
  %xor.16.5 = xor i32 %conv23.16.5, %conv29.16.5
  %scevgep35.16.5 = getelementptr i8, i8* %a, i64 22
  %6008 = load i8, i8* %scevgep35.16.5, align 1
  %6009 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.5 = call zeroext i8 @mult(i8 zeroext %6008, i8 zeroext %6009)
  %conv35.16.5 = zext i8 %call34.16.5 to i32
  %xor36.16.5 = xor i32 %xor.16.5, %conv35.16.5
  %conv37.16.5 = trunc i32 %xor36.16.5 to i8
  store i8 %conv37.16.5, i8* %scevgep41.16.4, align 1
  %scevgep28.16.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6003, i64 0, i64 0, i64 1
  %6010 = bitcast i8* %scevgep28.16.5 to [61 x [61 x i8]]*
  %scevgep41.16.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6004, i64 0, i64 1, i64 0
  %6011 = bitcast i8* %scevgep41.16.5 to [61 x [61 x i8]]*
  %call16.16.6 = call zeroext i8 (...) @rand()
  store i8 %call16.16.6, i8* %scevgep28.16.5, align 1
  %6012 = load i8, i8* %scevgep28.16.5, align 1
  %conv23.16.6 = zext i8 %6012 to i32
  %6013 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.6 = getelementptr i8, i8* %b, i64 23
  %6014 = load i8, i8* %scevgep34.16.6, align 1
  %call28.16.6 = call zeroext i8 @mult(i8 zeroext %6013, i8 zeroext %6014)
  %conv29.16.6 = zext i8 %call28.16.6 to i32
  %xor.16.6 = xor i32 %conv23.16.6, %conv29.16.6
  %scevgep35.16.6 = getelementptr i8, i8* %a, i64 23
  %6015 = load i8, i8* %scevgep35.16.6, align 1
  %6016 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.6 = call zeroext i8 @mult(i8 zeroext %6015, i8 zeroext %6016)
  %conv35.16.6 = zext i8 %call34.16.6 to i32
  %xor36.16.6 = xor i32 %xor.16.6, %conv35.16.6
  %conv37.16.6 = trunc i32 %xor36.16.6 to i8
  store i8 %conv37.16.6, i8* %scevgep41.16.5, align 1
  %scevgep28.16.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6010, i64 0, i64 0, i64 1
  %6017 = bitcast i8* %scevgep28.16.6 to [61 x [61 x i8]]*
  %scevgep41.16.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6011, i64 0, i64 1, i64 0
  %6018 = bitcast i8* %scevgep41.16.6 to [61 x [61 x i8]]*
  %call16.16.7 = call zeroext i8 (...) @rand()
  store i8 %call16.16.7, i8* %scevgep28.16.6, align 1
  %6019 = load i8, i8* %scevgep28.16.6, align 1
  %conv23.16.7 = zext i8 %6019 to i32
  %6020 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.7 = getelementptr i8, i8* %b, i64 24
  %6021 = load i8, i8* %scevgep34.16.7, align 1
  %call28.16.7 = call zeroext i8 @mult(i8 zeroext %6020, i8 zeroext %6021)
  %conv29.16.7 = zext i8 %call28.16.7 to i32
  %xor.16.7 = xor i32 %conv23.16.7, %conv29.16.7
  %scevgep35.16.7 = getelementptr i8, i8* %a, i64 24
  %6022 = load i8, i8* %scevgep35.16.7, align 1
  %6023 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.7 = call zeroext i8 @mult(i8 zeroext %6022, i8 zeroext %6023)
  %conv35.16.7 = zext i8 %call34.16.7 to i32
  %xor36.16.7 = xor i32 %xor.16.7, %conv35.16.7
  %conv37.16.7 = trunc i32 %xor36.16.7 to i8
  store i8 %conv37.16.7, i8* %scevgep41.16.6, align 1
  %scevgep28.16.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6017, i64 0, i64 0, i64 1
  %6024 = bitcast i8* %scevgep28.16.7 to [61 x [61 x i8]]*
  %scevgep41.16.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6018, i64 0, i64 1, i64 0
  %6025 = bitcast i8* %scevgep41.16.7 to [61 x [61 x i8]]*
  %call16.16.8 = call zeroext i8 (...) @rand()
  store i8 %call16.16.8, i8* %scevgep28.16.7, align 1
  %6026 = load i8, i8* %scevgep28.16.7, align 1
  %conv23.16.8 = zext i8 %6026 to i32
  %6027 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.8 = getelementptr i8, i8* %b, i64 25
  %6028 = load i8, i8* %scevgep34.16.8, align 1
  %call28.16.8 = call zeroext i8 @mult(i8 zeroext %6027, i8 zeroext %6028)
  %conv29.16.8 = zext i8 %call28.16.8 to i32
  %xor.16.8 = xor i32 %conv23.16.8, %conv29.16.8
  %scevgep35.16.8 = getelementptr i8, i8* %a, i64 25
  %6029 = load i8, i8* %scevgep35.16.8, align 1
  %6030 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.8 = call zeroext i8 @mult(i8 zeroext %6029, i8 zeroext %6030)
  %conv35.16.8 = zext i8 %call34.16.8 to i32
  %xor36.16.8 = xor i32 %xor.16.8, %conv35.16.8
  %conv37.16.8 = trunc i32 %xor36.16.8 to i8
  store i8 %conv37.16.8, i8* %scevgep41.16.7, align 1
  %scevgep28.16.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6024, i64 0, i64 0, i64 1
  %6031 = bitcast i8* %scevgep28.16.8 to [61 x [61 x i8]]*
  %scevgep41.16.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6025, i64 0, i64 1, i64 0
  %6032 = bitcast i8* %scevgep41.16.8 to [61 x [61 x i8]]*
  %call16.16.9 = call zeroext i8 (...) @rand()
  store i8 %call16.16.9, i8* %scevgep28.16.8, align 1
  %6033 = load i8, i8* %scevgep28.16.8, align 1
  %conv23.16.9 = zext i8 %6033 to i32
  %6034 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.9 = getelementptr i8, i8* %b, i64 26
  %6035 = load i8, i8* %scevgep34.16.9, align 1
  %call28.16.9 = call zeroext i8 @mult(i8 zeroext %6034, i8 zeroext %6035)
  %conv29.16.9 = zext i8 %call28.16.9 to i32
  %xor.16.9 = xor i32 %conv23.16.9, %conv29.16.9
  %scevgep35.16.9 = getelementptr i8, i8* %a, i64 26
  %6036 = load i8, i8* %scevgep35.16.9, align 1
  %6037 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.9 = call zeroext i8 @mult(i8 zeroext %6036, i8 zeroext %6037)
  %conv35.16.9 = zext i8 %call34.16.9 to i32
  %xor36.16.9 = xor i32 %xor.16.9, %conv35.16.9
  %conv37.16.9 = trunc i32 %xor36.16.9 to i8
  store i8 %conv37.16.9, i8* %scevgep41.16.8, align 1
  %scevgep28.16.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6031, i64 0, i64 0, i64 1
  %6038 = bitcast i8* %scevgep28.16.9 to [61 x [61 x i8]]*
  %scevgep41.16.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6032, i64 0, i64 1, i64 0
  %6039 = bitcast i8* %scevgep41.16.9 to [61 x [61 x i8]]*
  %call16.16.10 = call zeroext i8 (...) @rand()
  store i8 %call16.16.10, i8* %scevgep28.16.9, align 1
  %6040 = load i8, i8* %scevgep28.16.9, align 1
  %conv23.16.10 = zext i8 %6040 to i32
  %6041 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.10 = getelementptr i8, i8* %b, i64 27
  %6042 = load i8, i8* %scevgep34.16.10, align 1
  %call28.16.10 = call zeroext i8 @mult(i8 zeroext %6041, i8 zeroext %6042)
  %conv29.16.10 = zext i8 %call28.16.10 to i32
  %xor.16.10 = xor i32 %conv23.16.10, %conv29.16.10
  %scevgep35.16.10 = getelementptr i8, i8* %a, i64 27
  %6043 = load i8, i8* %scevgep35.16.10, align 1
  %6044 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.10 = call zeroext i8 @mult(i8 zeroext %6043, i8 zeroext %6044)
  %conv35.16.10 = zext i8 %call34.16.10 to i32
  %xor36.16.10 = xor i32 %xor.16.10, %conv35.16.10
  %conv37.16.10 = trunc i32 %xor36.16.10 to i8
  store i8 %conv37.16.10, i8* %scevgep41.16.9, align 1
  %scevgep28.16.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6038, i64 0, i64 0, i64 1
  %6045 = bitcast i8* %scevgep28.16.10 to [61 x [61 x i8]]*
  %scevgep41.16.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6039, i64 0, i64 1, i64 0
  %6046 = bitcast i8* %scevgep41.16.10 to [61 x [61 x i8]]*
  %call16.16.11 = call zeroext i8 (...) @rand()
  store i8 %call16.16.11, i8* %scevgep28.16.10, align 1
  %6047 = load i8, i8* %scevgep28.16.10, align 1
  %conv23.16.11 = zext i8 %6047 to i32
  %6048 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.11 = getelementptr i8, i8* %b, i64 28
  %6049 = load i8, i8* %scevgep34.16.11, align 1
  %call28.16.11 = call zeroext i8 @mult(i8 zeroext %6048, i8 zeroext %6049)
  %conv29.16.11 = zext i8 %call28.16.11 to i32
  %xor.16.11 = xor i32 %conv23.16.11, %conv29.16.11
  %scevgep35.16.11 = getelementptr i8, i8* %a, i64 28
  %6050 = load i8, i8* %scevgep35.16.11, align 1
  %6051 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.11 = call zeroext i8 @mult(i8 zeroext %6050, i8 zeroext %6051)
  %conv35.16.11 = zext i8 %call34.16.11 to i32
  %xor36.16.11 = xor i32 %xor.16.11, %conv35.16.11
  %conv37.16.11 = trunc i32 %xor36.16.11 to i8
  store i8 %conv37.16.11, i8* %scevgep41.16.10, align 1
  %scevgep28.16.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6045, i64 0, i64 0, i64 1
  %6052 = bitcast i8* %scevgep28.16.11 to [61 x [61 x i8]]*
  %scevgep41.16.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6046, i64 0, i64 1, i64 0
  %6053 = bitcast i8* %scevgep41.16.11 to [61 x [61 x i8]]*
  %call16.16.12 = call zeroext i8 (...) @rand()
  store i8 %call16.16.12, i8* %scevgep28.16.11, align 1
  %6054 = load i8, i8* %scevgep28.16.11, align 1
  %conv23.16.12 = zext i8 %6054 to i32
  %6055 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.12 = getelementptr i8, i8* %b, i64 29
  %6056 = load i8, i8* %scevgep34.16.12, align 1
  %call28.16.12 = call zeroext i8 @mult(i8 zeroext %6055, i8 zeroext %6056)
  %conv29.16.12 = zext i8 %call28.16.12 to i32
  %xor.16.12 = xor i32 %conv23.16.12, %conv29.16.12
  %scevgep35.16.12 = getelementptr i8, i8* %a, i64 29
  %6057 = load i8, i8* %scevgep35.16.12, align 1
  %6058 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.12 = call zeroext i8 @mult(i8 zeroext %6057, i8 zeroext %6058)
  %conv35.16.12 = zext i8 %call34.16.12 to i32
  %xor36.16.12 = xor i32 %xor.16.12, %conv35.16.12
  %conv37.16.12 = trunc i32 %xor36.16.12 to i8
  store i8 %conv37.16.12, i8* %scevgep41.16.11, align 1
  %scevgep28.16.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6052, i64 0, i64 0, i64 1
  %6059 = bitcast i8* %scevgep28.16.12 to [61 x [61 x i8]]*
  %scevgep41.16.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6053, i64 0, i64 1, i64 0
  %6060 = bitcast i8* %scevgep41.16.12 to [61 x [61 x i8]]*
  %call16.16.13 = call zeroext i8 (...) @rand()
  store i8 %call16.16.13, i8* %scevgep28.16.12, align 1
  %6061 = load i8, i8* %scevgep28.16.12, align 1
  %conv23.16.13 = zext i8 %6061 to i32
  %6062 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.13 = getelementptr i8, i8* %b, i64 30
  %6063 = load i8, i8* %scevgep34.16.13, align 1
  %call28.16.13 = call zeroext i8 @mult(i8 zeroext %6062, i8 zeroext %6063)
  %conv29.16.13 = zext i8 %call28.16.13 to i32
  %xor.16.13 = xor i32 %conv23.16.13, %conv29.16.13
  %scevgep35.16.13 = getelementptr i8, i8* %a, i64 30
  %6064 = load i8, i8* %scevgep35.16.13, align 1
  %6065 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.13 = call zeroext i8 @mult(i8 zeroext %6064, i8 zeroext %6065)
  %conv35.16.13 = zext i8 %call34.16.13 to i32
  %xor36.16.13 = xor i32 %xor.16.13, %conv35.16.13
  %conv37.16.13 = trunc i32 %xor36.16.13 to i8
  store i8 %conv37.16.13, i8* %scevgep41.16.12, align 1
  %scevgep28.16.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6059, i64 0, i64 0, i64 1
  %6066 = bitcast i8* %scevgep28.16.13 to [61 x [61 x i8]]*
  %scevgep41.16.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6060, i64 0, i64 1, i64 0
  %6067 = bitcast i8* %scevgep41.16.13 to [61 x [61 x i8]]*
  %call16.16.14 = call zeroext i8 (...) @rand()
  store i8 %call16.16.14, i8* %scevgep28.16.13, align 1
  %6068 = load i8, i8* %scevgep28.16.13, align 1
  %conv23.16.14 = zext i8 %6068 to i32
  %6069 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.14 = getelementptr i8, i8* %b, i64 31
  %6070 = load i8, i8* %scevgep34.16.14, align 1
  %call28.16.14 = call zeroext i8 @mult(i8 zeroext %6069, i8 zeroext %6070)
  %conv29.16.14 = zext i8 %call28.16.14 to i32
  %xor.16.14 = xor i32 %conv23.16.14, %conv29.16.14
  %scevgep35.16.14 = getelementptr i8, i8* %a, i64 31
  %6071 = load i8, i8* %scevgep35.16.14, align 1
  %6072 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.14 = call zeroext i8 @mult(i8 zeroext %6071, i8 zeroext %6072)
  %conv35.16.14 = zext i8 %call34.16.14 to i32
  %xor36.16.14 = xor i32 %xor.16.14, %conv35.16.14
  %conv37.16.14 = trunc i32 %xor36.16.14 to i8
  store i8 %conv37.16.14, i8* %scevgep41.16.13, align 1
  %scevgep28.16.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6066, i64 0, i64 0, i64 1
  %6073 = bitcast i8* %scevgep28.16.14 to [61 x [61 x i8]]*
  %scevgep41.16.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6067, i64 0, i64 1, i64 0
  %6074 = bitcast i8* %scevgep41.16.14 to [61 x [61 x i8]]*
  %call16.16.15 = call zeroext i8 (...) @rand()
  store i8 %call16.16.15, i8* %scevgep28.16.14, align 1
  %6075 = load i8, i8* %scevgep28.16.14, align 1
  %conv23.16.15 = zext i8 %6075 to i32
  %6076 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.15 = getelementptr i8, i8* %b, i64 32
  %6077 = load i8, i8* %scevgep34.16.15, align 1
  %call28.16.15 = call zeroext i8 @mult(i8 zeroext %6076, i8 zeroext %6077)
  %conv29.16.15 = zext i8 %call28.16.15 to i32
  %xor.16.15 = xor i32 %conv23.16.15, %conv29.16.15
  %scevgep35.16.15 = getelementptr i8, i8* %a, i64 32
  %6078 = load i8, i8* %scevgep35.16.15, align 1
  %6079 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.15 = call zeroext i8 @mult(i8 zeroext %6078, i8 zeroext %6079)
  %conv35.16.15 = zext i8 %call34.16.15 to i32
  %xor36.16.15 = xor i32 %xor.16.15, %conv35.16.15
  %conv37.16.15 = trunc i32 %xor36.16.15 to i8
  store i8 %conv37.16.15, i8* %scevgep41.16.14, align 1
  %scevgep28.16.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6073, i64 0, i64 0, i64 1
  %6080 = bitcast i8* %scevgep28.16.15 to [61 x [61 x i8]]*
  %scevgep41.16.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6074, i64 0, i64 1, i64 0
  %6081 = bitcast i8* %scevgep41.16.15 to [61 x [61 x i8]]*
  %call16.16.16 = call zeroext i8 (...) @rand()
  store i8 %call16.16.16, i8* %scevgep28.16.15, align 1
  %6082 = load i8, i8* %scevgep28.16.15, align 1
  %conv23.16.16 = zext i8 %6082 to i32
  %6083 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.16 = getelementptr i8, i8* %b, i64 33
  %6084 = load i8, i8* %scevgep34.16.16, align 1
  %call28.16.16 = call zeroext i8 @mult(i8 zeroext %6083, i8 zeroext %6084)
  %conv29.16.16 = zext i8 %call28.16.16 to i32
  %xor.16.16 = xor i32 %conv23.16.16, %conv29.16.16
  %scevgep35.16.16 = getelementptr i8, i8* %a, i64 33
  %6085 = load i8, i8* %scevgep35.16.16, align 1
  %6086 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.16 = call zeroext i8 @mult(i8 zeroext %6085, i8 zeroext %6086)
  %conv35.16.16 = zext i8 %call34.16.16 to i32
  %xor36.16.16 = xor i32 %xor.16.16, %conv35.16.16
  %conv37.16.16 = trunc i32 %xor36.16.16 to i8
  store i8 %conv37.16.16, i8* %scevgep41.16.15, align 1
  %scevgep28.16.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6080, i64 0, i64 0, i64 1
  %6087 = bitcast i8* %scevgep28.16.16 to [61 x [61 x i8]]*
  %scevgep41.16.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6081, i64 0, i64 1, i64 0
  %6088 = bitcast i8* %scevgep41.16.16 to [61 x [61 x i8]]*
  %call16.16.17 = call zeroext i8 (...) @rand()
  store i8 %call16.16.17, i8* %scevgep28.16.16, align 1
  %6089 = load i8, i8* %scevgep28.16.16, align 1
  %conv23.16.17 = zext i8 %6089 to i32
  %6090 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.17 = getelementptr i8, i8* %b, i64 34
  %6091 = load i8, i8* %scevgep34.16.17, align 1
  %call28.16.17 = call zeroext i8 @mult(i8 zeroext %6090, i8 zeroext %6091)
  %conv29.16.17 = zext i8 %call28.16.17 to i32
  %xor.16.17 = xor i32 %conv23.16.17, %conv29.16.17
  %scevgep35.16.17 = getelementptr i8, i8* %a, i64 34
  %6092 = load i8, i8* %scevgep35.16.17, align 1
  %6093 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.17 = call zeroext i8 @mult(i8 zeroext %6092, i8 zeroext %6093)
  %conv35.16.17 = zext i8 %call34.16.17 to i32
  %xor36.16.17 = xor i32 %xor.16.17, %conv35.16.17
  %conv37.16.17 = trunc i32 %xor36.16.17 to i8
  store i8 %conv37.16.17, i8* %scevgep41.16.16, align 1
  %scevgep28.16.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6087, i64 0, i64 0, i64 1
  %6094 = bitcast i8* %scevgep28.16.17 to [61 x [61 x i8]]*
  %scevgep41.16.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6088, i64 0, i64 1, i64 0
  %6095 = bitcast i8* %scevgep41.16.17 to [61 x [61 x i8]]*
  %call16.16.18 = call zeroext i8 (...) @rand()
  store i8 %call16.16.18, i8* %scevgep28.16.17, align 1
  %6096 = load i8, i8* %scevgep28.16.17, align 1
  %conv23.16.18 = zext i8 %6096 to i32
  %6097 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.18 = getelementptr i8, i8* %b, i64 35
  %6098 = load i8, i8* %scevgep34.16.18, align 1
  %call28.16.18 = call zeroext i8 @mult(i8 zeroext %6097, i8 zeroext %6098)
  %conv29.16.18 = zext i8 %call28.16.18 to i32
  %xor.16.18 = xor i32 %conv23.16.18, %conv29.16.18
  %scevgep35.16.18 = getelementptr i8, i8* %a, i64 35
  %6099 = load i8, i8* %scevgep35.16.18, align 1
  %6100 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.18 = call zeroext i8 @mult(i8 zeroext %6099, i8 zeroext %6100)
  %conv35.16.18 = zext i8 %call34.16.18 to i32
  %xor36.16.18 = xor i32 %xor.16.18, %conv35.16.18
  %conv37.16.18 = trunc i32 %xor36.16.18 to i8
  store i8 %conv37.16.18, i8* %scevgep41.16.17, align 1
  %scevgep28.16.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6094, i64 0, i64 0, i64 1
  %6101 = bitcast i8* %scevgep28.16.18 to [61 x [61 x i8]]*
  %scevgep41.16.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6095, i64 0, i64 1, i64 0
  %6102 = bitcast i8* %scevgep41.16.18 to [61 x [61 x i8]]*
  %call16.16.19 = call zeroext i8 (...) @rand()
  store i8 %call16.16.19, i8* %scevgep28.16.18, align 1
  %6103 = load i8, i8* %scevgep28.16.18, align 1
  %conv23.16.19 = zext i8 %6103 to i32
  %6104 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.19 = getelementptr i8, i8* %b, i64 36
  %6105 = load i8, i8* %scevgep34.16.19, align 1
  %call28.16.19 = call zeroext i8 @mult(i8 zeroext %6104, i8 zeroext %6105)
  %conv29.16.19 = zext i8 %call28.16.19 to i32
  %xor.16.19 = xor i32 %conv23.16.19, %conv29.16.19
  %scevgep35.16.19 = getelementptr i8, i8* %a, i64 36
  %6106 = load i8, i8* %scevgep35.16.19, align 1
  %6107 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.19 = call zeroext i8 @mult(i8 zeroext %6106, i8 zeroext %6107)
  %conv35.16.19 = zext i8 %call34.16.19 to i32
  %xor36.16.19 = xor i32 %xor.16.19, %conv35.16.19
  %conv37.16.19 = trunc i32 %xor36.16.19 to i8
  store i8 %conv37.16.19, i8* %scevgep41.16.18, align 1
  %scevgep28.16.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6101, i64 0, i64 0, i64 1
  %6108 = bitcast i8* %scevgep28.16.19 to [61 x [61 x i8]]*
  %scevgep41.16.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6102, i64 0, i64 1, i64 0
  %6109 = bitcast i8* %scevgep41.16.19 to [61 x [61 x i8]]*
  %call16.16.20 = call zeroext i8 (...) @rand()
  store i8 %call16.16.20, i8* %scevgep28.16.19, align 1
  %6110 = load i8, i8* %scevgep28.16.19, align 1
  %conv23.16.20 = zext i8 %6110 to i32
  %6111 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.20 = getelementptr i8, i8* %b, i64 37
  %6112 = load i8, i8* %scevgep34.16.20, align 1
  %call28.16.20 = call zeroext i8 @mult(i8 zeroext %6111, i8 zeroext %6112)
  %conv29.16.20 = zext i8 %call28.16.20 to i32
  %xor.16.20 = xor i32 %conv23.16.20, %conv29.16.20
  %scevgep35.16.20 = getelementptr i8, i8* %a, i64 37
  %6113 = load i8, i8* %scevgep35.16.20, align 1
  %6114 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.20 = call zeroext i8 @mult(i8 zeroext %6113, i8 zeroext %6114)
  %conv35.16.20 = zext i8 %call34.16.20 to i32
  %xor36.16.20 = xor i32 %xor.16.20, %conv35.16.20
  %conv37.16.20 = trunc i32 %xor36.16.20 to i8
  store i8 %conv37.16.20, i8* %scevgep41.16.19, align 1
  %scevgep28.16.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6108, i64 0, i64 0, i64 1
  %6115 = bitcast i8* %scevgep28.16.20 to [61 x [61 x i8]]*
  %scevgep41.16.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6109, i64 0, i64 1, i64 0
  %6116 = bitcast i8* %scevgep41.16.20 to [61 x [61 x i8]]*
  %call16.16.21 = call zeroext i8 (...) @rand()
  store i8 %call16.16.21, i8* %scevgep28.16.20, align 1
  %6117 = load i8, i8* %scevgep28.16.20, align 1
  %conv23.16.21 = zext i8 %6117 to i32
  %6118 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.21 = getelementptr i8, i8* %b, i64 38
  %6119 = load i8, i8* %scevgep34.16.21, align 1
  %call28.16.21 = call zeroext i8 @mult(i8 zeroext %6118, i8 zeroext %6119)
  %conv29.16.21 = zext i8 %call28.16.21 to i32
  %xor.16.21 = xor i32 %conv23.16.21, %conv29.16.21
  %scevgep35.16.21 = getelementptr i8, i8* %a, i64 38
  %6120 = load i8, i8* %scevgep35.16.21, align 1
  %6121 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.21 = call zeroext i8 @mult(i8 zeroext %6120, i8 zeroext %6121)
  %conv35.16.21 = zext i8 %call34.16.21 to i32
  %xor36.16.21 = xor i32 %xor.16.21, %conv35.16.21
  %conv37.16.21 = trunc i32 %xor36.16.21 to i8
  store i8 %conv37.16.21, i8* %scevgep41.16.20, align 1
  %scevgep28.16.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6115, i64 0, i64 0, i64 1
  %6122 = bitcast i8* %scevgep28.16.21 to [61 x [61 x i8]]*
  %scevgep41.16.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6116, i64 0, i64 1, i64 0
  %6123 = bitcast i8* %scevgep41.16.21 to [61 x [61 x i8]]*
  %call16.16.22 = call zeroext i8 (...) @rand()
  store i8 %call16.16.22, i8* %scevgep28.16.21, align 1
  %6124 = load i8, i8* %scevgep28.16.21, align 1
  %conv23.16.22 = zext i8 %6124 to i32
  %6125 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.22 = getelementptr i8, i8* %b, i64 39
  %6126 = load i8, i8* %scevgep34.16.22, align 1
  %call28.16.22 = call zeroext i8 @mult(i8 zeroext %6125, i8 zeroext %6126)
  %conv29.16.22 = zext i8 %call28.16.22 to i32
  %xor.16.22 = xor i32 %conv23.16.22, %conv29.16.22
  %scevgep35.16.22 = getelementptr i8, i8* %a, i64 39
  %6127 = load i8, i8* %scevgep35.16.22, align 1
  %6128 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.22 = call zeroext i8 @mult(i8 zeroext %6127, i8 zeroext %6128)
  %conv35.16.22 = zext i8 %call34.16.22 to i32
  %xor36.16.22 = xor i32 %xor.16.22, %conv35.16.22
  %conv37.16.22 = trunc i32 %xor36.16.22 to i8
  store i8 %conv37.16.22, i8* %scevgep41.16.21, align 1
  %scevgep28.16.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6122, i64 0, i64 0, i64 1
  %6129 = bitcast i8* %scevgep28.16.22 to [61 x [61 x i8]]*
  %scevgep41.16.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6123, i64 0, i64 1, i64 0
  %6130 = bitcast i8* %scevgep41.16.22 to [61 x [61 x i8]]*
  %call16.16.23 = call zeroext i8 (...) @rand()
  store i8 %call16.16.23, i8* %scevgep28.16.22, align 1
  %6131 = load i8, i8* %scevgep28.16.22, align 1
  %conv23.16.23 = zext i8 %6131 to i32
  %6132 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.23 = getelementptr i8, i8* %b, i64 40
  %6133 = load i8, i8* %scevgep34.16.23, align 1
  %call28.16.23 = call zeroext i8 @mult(i8 zeroext %6132, i8 zeroext %6133)
  %conv29.16.23 = zext i8 %call28.16.23 to i32
  %xor.16.23 = xor i32 %conv23.16.23, %conv29.16.23
  %scevgep35.16.23 = getelementptr i8, i8* %a, i64 40
  %6134 = load i8, i8* %scevgep35.16.23, align 1
  %6135 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.23 = call zeroext i8 @mult(i8 zeroext %6134, i8 zeroext %6135)
  %conv35.16.23 = zext i8 %call34.16.23 to i32
  %xor36.16.23 = xor i32 %xor.16.23, %conv35.16.23
  %conv37.16.23 = trunc i32 %xor36.16.23 to i8
  store i8 %conv37.16.23, i8* %scevgep41.16.22, align 1
  %scevgep28.16.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6129, i64 0, i64 0, i64 1
  %6136 = bitcast i8* %scevgep28.16.23 to [61 x [61 x i8]]*
  %scevgep41.16.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6130, i64 0, i64 1, i64 0
  %6137 = bitcast i8* %scevgep41.16.23 to [61 x [61 x i8]]*
  %call16.16.24 = call zeroext i8 (...) @rand()
  store i8 %call16.16.24, i8* %scevgep28.16.23, align 1
  %6138 = load i8, i8* %scevgep28.16.23, align 1
  %conv23.16.24 = zext i8 %6138 to i32
  %6139 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.24 = getelementptr i8, i8* %b, i64 41
  %6140 = load i8, i8* %scevgep34.16.24, align 1
  %call28.16.24 = call zeroext i8 @mult(i8 zeroext %6139, i8 zeroext %6140)
  %conv29.16.24 = zext i8 %call28.16.24 to i32
  %xor.16.24 = xor i32 %conv23.16.24, %conv29.16.24
  %scevgep35.16.24 = getelementptr i8, i8* %a, i64 41
  %6141 = load i8, i8* %scevgep35.16.24, align 1
  %6142 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.24 = call zeroext i8 @mult(i8 zeroext %6141, i8 zeroext %6142)
  %conv35.16.24 = zext i8 %call34.16.24 to i32
  %xor36.16.24 = xor i32 %xor.16.24, %conv35.16.24
  %conv37.16.24 = trunc i32 %xor36.16.24 to i8
  store i8 %conv37.16.24, i8* %scevgep41.16.23, align 1
  %scevgep28.16.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6136, i64 0, i64 0, i64 1
  %6143 = bitcast i8* %scevgep28.16.24 to [61 x [61 x i8]]*
  %scevgep41.16.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6137, i64 0, i64 1, i64 0
  %6144 = bitcast i8* %scevgep41.16.24 to [61 x [61 x i8]]*
  %call16.16.25 = call zeroext i8 (...) @rand()
  store i8 %call16.16.25, i8* %scevgep28.16.24, align 1
  %6145 = load i8, i8* %scevgep28.16.24, align 1
  %conv23.16.25 = zext i8 %6145 to i32
  %6146 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.25 = getelementptr i8, i8* %b, i64 42
  %6147 = load i8, i8* %scevgep34.16.25, align 1
  %call28.16.25 = call zeroext i8 @mult(i8 zeroext %6146, i8 zeroext %6147)
  %conv29.16.25 = zext i8 %call28.16.25 to i32
  %xor.16.25 = xor i32 %conv23.16.25, %conv29.16.25
  %scevgep35.16.25 = getelementptr i8, i8* %a, i64 42
  %6148 = load i8, i8* %scevgep35.16.25, align 1
  %6149 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.25 = call zeroext i8 @mult(i8 zeroext %6148, i8 zeroext %6149)
  %conv35.16.25 = zext i8 %call34.16.25 to i32
  %xor36.16.25 = xor i32 %xor.16.25, %conv35.16.25
  %conv37.16.25 = trunc i32 %xor36.16.25 to i8
  store i8 %conv37.16.25, i8* %scevgep41.16.24, align 1
  %scevgep28.16.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6143, i64 0, i64 0, i64 1
  %6150 = bitcast i8* %scevgep28.16.25 to [61 x [61 x i8]]*
  %scevgep41.16.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6144, i64 0, i64 1, i64 0
  %6151 = bitcast i8* %scevgep41.16.25 to [61 x [61 x i8]]*
  %call16.16.26 = call zeroext i8 (...) @rand()
  store i8 %call16.16.26, i8* %scevgep28.16.25, align 1
  %6152 = load i8, i8* %scevgep28.16.25, align 1
  %conv23.16.26 = zext i8 %6152 to i32
  %6153 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.26 = getelementptr i8, i8* %b, i64 43
  %6154 = load i8, i8* %scevgep34.16.26, align 1
  %call28.16.26 = call zeroext i8 @mult(i8 zeroext %6153, i8 zeroext %6154)
  %conv29.16.26 = zext i8 %call28.16.26 to i32
  %xor.16.26 = xor i32 %conv23.16.26, %conv29.16.26
  %scevgep35.16.26 = getelementptr i8, i8* %a, i64 43
  %6155 = load i8, i8* %scevgep35.16.26, align 1
  %6156 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.26 = call zeroext i8 @mult(i8 zeroext %6155, i8 zeroext %6156)
  %conv35.16.26 = zext i8 %call34.16.26 to i32
  %xor36.16.26 = xor i32 %xor.16.26, %conv35.16.26
  %conv37.16.26 = trunc i32 %xor36.16.26 to i8
  store i8 %conv37.16.26, i8* %scevgep41.16.25, align 1
  %scevgep28.16.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6150, i64 0, i64 0, i64 1
  %6157 = bitcast i8* %scevgep28.16.26 to [61 x [61 x i8]]*
  %scevgep41.16.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6151, i64 0, i64 1, i64 0
  %6158 = bitcast i8* %scevgep41.16.26 to [61 x [61 x i8]]*
  %call16.16.27 = call zeroext i8 (...) @rand()
  store i8 %call16.16.27, i8* %scevgep28.16.26, align 1
  %6159 = load i8, i8* %scevgep28.16.26, align 1
  %conv23.16.27 = zext i8 %6159 to i32
  %6160 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.27 = getelementptr i8, i8* %b, i64 44
  %6161 = load i8, i8* %scevgep34.16.27, align 1
  %call28.16.27 = call zeroext i8 @mult(i8 zeroext %6160, i8 zeroext %6161)
  %conv29.16.27 = zext i8 %call28.16.27 to i32
  %xor.16.27 = xor i32 %conv23.16.27, %conv29.16.27
  %scevgep35.16.27 = getelementptr i8, i8* %a, i64 44
  %6162 = load i8, i8* %scevgep35.16.27, align 1
  %6163 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.27 = call zeroext i8 @mult(i8 zeroext %6162, i8 zeroext %6163)
  %conv35.16.27 = zext i8 %call34.16.27 to i32
  %xor36.16.27 = xor i32 %xor.16.27, %conv35.16.27
  %conv37.16.27 = trunc i32 %xor36.16.27 to i8
  store i8 %conv37.16.27, i8* %scevgep41.16.26, align 1
  %scevgep28.16.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6157, i64 0, i64 0, i64 1
  %6164 = bitcast i8* %scevgep28.16.27 to [61 x [61 x i8]]*
  %scevgep41.16.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6158, i64 0, i64 1, i64 0
  %6165 = bitcast i8* %scevgep41.16.27 to [61 x [61 x i8]]*
  %call16.16.28 = call zeroext i8 (...) @rand()
  store i8 %call16.16.28, i8* %scevgep28.16.27, align 1
  %6166 = load i8, i8* %scevgep28.16.27, align 1
  %conv23.16.28 = zext i8 %6166 to i32
  %6167 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.28 = getelementptr i8, i8* %b, i64 45
  %6168 = load i8, i8* %scevgep34.16.28, align 1
  %call28.16.28 = call zeroext i8 @mult(i8 zeroext %6167, i8 zeroext %6168)
  %conv29.16.28 = zext i8 %call28.16.28 to i32
  %xor.16.28 = xor i32 %conv23.16.28, %conv29.16.28
  %scevgep35.16.28 = getelementptr i8, i8* %a, i64 45
  %6169 = load i8, i8* %scevgep35.16.28, align 1
  %6170 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.28 = call zeroext i8 @mult(i8 zeroext %6169, i8 zeroext %6170)
  %conv35.16.28 = zext i8 %call34.16.28 to i32
  %xor36.16.28 = xor i32 %xor.16.28, %conv35.16.28
  %conv37.16.28 = trunc i32 %xor36.16.28 to i8
  store i8 %conv37.16.28, i8* %scevgep41.16.27, align 1
  %scevgep28.16.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6164, i64 0, i64 0, i64 1
  %6171 = bitcast i8* %scevgep28.16.28 to [61 x [61 x i8]]*
  %scevgep41.16.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6165, i64 0, i64 1, i64 0
  %6172 = bitcast i8* %scevgep41.16.28 to [61 x [61 x i8]]*
  %call16.16.29 = call zeroext i8 (...) @rand()
  store i8 %call16.16.29, i8* %scevgep28.16.28, align 1
  %6173 = load i8, i8* %scevgep28.16.28, align 1
  %conv23.16.29 = zext i8 %6173 to i32
  %6174 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.29 = getelementptr i8, i8* %b, i64 46
  %6175 = load i8, i8* %scevgep34.16.29, align 1
  %call28.16.29 = call zeroext i8 @mult(i8 zeroext %6174, i8 zeroext %6175)
  %conv29.16.29 = zext i8 %call28.16.29 to i32
  %xor.16.29 = xor i32 %conv23.16.29, %conv29.16.29
  %scevgep35.16.29 = getelementptr i8, i8* %a, i64 46
  %6176 = load i8, i8* %scevgep35.16.29, align 1
  %6177 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.29 = call zeroext i8 @mult(i8 zeroext %6176, i8 zeroext %6177)
  %conv35.16.29 = zext i8 %call34.16.29 to i32
  %xor36.16.29 = xor i32 %xor.16.29, %conv35.16.29
  %conv37.16.29 = trunc i32 %xor36.16.29 to i8
  store i8 %conv37.16.29, i8* %scevgep41.16.28, align 1
  %scevgep28.16.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6171, i64 0, i64 0, i64 1
  %6178 = bitcast i8* %scevgep28.16.29 to [61 x [61 x i8]]*
  %scevgep41.16.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6172, i64 0, i64 1, i64 0
  %6179 = bitcast i8* %scevgep41.16.29 to [61 x [61 x i8]]*
  %call16.16.30 = call zeroext i8 (...) @rand()
  store i8 %call16.16.30, i8* %scevgep28.16.29, align 1
  %6180 = load i8, i8* %scevgep28.16.29, align 1
  %conv23.16.30 = zext i8 %6180 to i32
  %6181 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.30 = getelementptr i8, i8* %b, i64 47
  %6182 = load i8, i8* %scevgep34.16.30, align 1
  %call28.16.30 = call zeroext i8 @mult(i8 zeroext %6181, i8 zeroext %6182)
  %conv29.16.30 = zext i8 %call28.16.30 to i32
  %xor.16.30 = xor i32 %conv23.16.30, %conv29.16.30
  %scevgep35.16.30 = getelementptr i8, i8* %a, i64 47
  %6183 = load i8, i8* %scevgep35.16.30, align 1
  %6184 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.30 = call zeroext i8 @mult(i8 zeroext %6183, i8 zeroext %6184)
  %conv35.16.30 = zext i8 %call34.16.30 to i32
  %xor36.16.30 = xor i32 %xor.16.30, %conv35.16.30
  %conv37.16.30 = trunc i32 %xor36.16.30 to i8
  store i8 %conv37.16.30, i8* %scevgep41.16.29, align 1
  %scevgep28.16.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6178, i64 0, i64 0, i64 1
  %6185 = bitcast i8* %scevgep28.16.30 to [61 x [61 x i8]]*
  %scevgep41.16.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6179, i64 0, i64 1, i64 0
  %6186 = bitcast i8* %scevgep41.16.30 to [61 x [61 x i8]]*
  %call16.16.31 = call zeroext i8 (...) @rand()
  store i8 %call16.16.31, i8* %scevgep28.16.30, align 1
  %6187 = load i8, i8* %scevgep28.16.30, align 1
  %conv23.16.31 = zext i8 %6187 to i32
  %6188 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.31 = getelementptr i8, i8* %b, i64 48
  %6189 = load i8, i8* %scevgep34.16.31, align 1
  %call28.16.31 = call zeroext i8 @mult(i8 zeroext %6188, i8 zeroext %6189)
  %conv29.16.31 = zext i8 %call28.16.31 to i32
  %xor.16.31 = xor i32 %conv23.16.31, %conv29.16.31
  %scevgep35.16.31 = getelementptr i8, i8* %a, i64 48
  %6190 = load i8, i8* %scevgep35.16.31, align 1
  %6191 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.31 = call zeroext i8 @mult(i8 zeroext %6190, i8 zeroext %6191)
  %conv35.16.31 = zext i8 %call34.16.31 to i32
  %xor36.16.31 = xor i32 %xor.16.31, %conv35.16.31
  %conv37.16.31 = trunc i32 %xor36.16.31 to i8
  store i8 %conv37.16.31, i8* %scevgep41.16.30, align 1
  %scevgep28.16.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6185, i64 0, i64 0, i64 1
  %6192 = bitcast i8* %scevgep28.16.31 to [61 x [61 x i8]]*
  %scevgep41.16.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6186, i64 0, i64 1, i64 0
  %6193 = bitcast i8* %scevgep41.16.31 to [61 x [61 x i8]]*
  %call16.16.32 = call zeroext i8 (...) @rand()
  store i8 %call16.16.32, i8* %scevgep28.16.31, align 1
  %6194 = load i8, i8* %scevgep28.16.31, align 1
  %conv23.16.32 = zext i8 %6194 to i32
  %6195 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.32 = getelementptr i8, i8* %b, i64 49
  %6196 = load i8, i8* %scevgep34.16.32, align 1
  %call28.16.32 = call zeroext i8 @mult(i8 zeroext %6195, i8 zeroext %6196)
  %conv29.16.32 = zext i8 %call28.16.32 to i32
  %xor.16.32 = xor i32 %conv23.16.32, %conv29.16.32
  %scevgep35.16.32 = getelementptr i8, i8* %a, i64 49
  %6197 = load i8, i8* %scevgep35.16.32, align 1
  %6198 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.32 = call zeroext i8 @mult(i8 zeroext %6197, i8 zeroext %6198)
  %conv35.16.32 = zext i8 %call34.16.32 to i32
  %xor36.16.32 = xor i32 %xor.16.32, %conv35.16.32
  %conv37.16.32 = trunc i32 %xor36.16.32 to i8
  store i8 %conv37.16.32, i8* %scevgep41.16.31, align 1
  %scevgep28.16.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6192, i64 0, i64 0, i64 1
  %6199 = bitcast i8* %scevgep28.16.32 to [61 x [61 x i8]]*
  %scevgep41.16.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6193, i64 0, i64 1, i64 0
  %6200 = bitcast i8* %scevgep41.16.32 to [61 x [61 x i8]]*
  %call16.16.33 = call zeroext i8 (...) @rand()
  store i8 %call16.16.33, i8* %scevgep28.16.32, align 1
  %6201 = load i8, i8* %scevgep28.16.32, align 1
  %conv23.16.33 = zext i8 %6201 to i32
  %6202 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.33 = getelementptr i8, i8* %b, i64 50
  %6203 = load i8, i8* %scevgep34.16.33, align 1
  %call28.16.33 = call zeroext i8 @mult(i8 zeroext %6202, i8 zeroext %6203)
  %conv29.16.33 = zext i8 %call28.16.33 to i32
  %xor.16.33 = xor i32 %conv23.16.33, %conv29.16.33
  %scevgep35.16.33 = getelementptr i8, i8* %a, i64 50
  %6204 = load i8, i8* %scevgep35.16.33, align 1
  %6205 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.33 = call zeroext i8 @mult(i8 zeroext %6204, i8 zeroext %6205)
  %conv35.16.33 = zext i8 %call34.16.33 to i32
  %xor36.16.33 = xor i32 %xor.16.33, %conv35.16.33
  %conv37.16.33 = trunc i32 %xor36.16.33 to i8
  store i8 %conv37.16.33, i8* %scevgep41.16.32, align 1
  %scevgep28.16.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6199, i64 0, i64 0, i64 1
  %6206 = bitcast i8* %scevgep28.16.33 to [61 x [61 x i8]]*
  %scevgep41.16.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6200, i64 0, i64 1, i64 0
  %6207 = bitcast i8* %scevgep41.16.33 to [61 x [61 x i8]]*
  %call16.16.34 = call zeroext i8 (...) @rand()
  store i8 %call16.16.34, i8* %scevgep28.16.33, align 1
  %6208 = load i8, i8* %scevgep28.16.33, align 1
  %conv23.16.34 = zext i8 %6208 to i32
  %6209 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.34 = getelementptr i8, i8* %b, i64 51
  %6210 = load i8, i8* %scevgep34.16.34, align 1
  %call28.16.34 = call zeroext i8 @mult(i8 zeroext %6209, i8 zeroext %6210)
  %conv29.16.34 = zext i8 %call28.16.34 to i32
  %xor.16.34 = xor i32 %conv23.16.34, %conv29.16.34
  %scevgep35.16.34 = getelementptr i8, i8* %a, i64 51
  %6211 = load i8, i8* %scevgep35.16.34, align 1
  %6212 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.34 = call zeroext i8 @mult(i8 zeroext %6211, i8 zeroext %6212)
  %conv35.16.34 = zext i8 %call34.16.34 to i32
  %xor36.16.34 = xor i32 %xor.16.34, %conv35.16.34
  %conv37.16.34 = trunc i32 %xor36.16.34 to i8
  store i8 %conv37.16.34, i8* %scevgep41.16.33, align 1
  %scevgep28.16.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6206, i64 0, i64 0, i64 1
  %6213 = bitcast i8* %scevgep28.16.34 to [61 x [61 x i8]]*
  %scevgep41.16.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6207, i64 0, i64 1, i64 0
  %6214 = bitcast i8* %scevgep41.16.34 to [61 x [61 x i8]]*
  %call16.16.35 = call zeroext i8 (...) @rand()
  store i8 %call16.16.35, i8* %scevgep28.16.34, align 1
  %6215 = load i8, i8* %scevgep28.16.34, align 1
  %conv23.16.35 = zext i8 %6215 to i32
  %6216 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.35 = getelementptr i8, i8* %b, i64 52
  %6217 = load i8, i8* %scevgep34.16.35, align 1
  %call28.16.35 = call zeroext i8 @mult(i8 zeroext %6216, i8 zeroext %6217)
  %conv29.16.35 = zext i8 %call28.16.35 to i32
  %xor.16.35 = xor i32 %conv23.16.35, %conv29.16.35
  %scevgep35.16.35 = getelementptr i8, i8* %a, i64 52
  %6218 = load i8, i8* %scevgep35.16.35, align 1
  %6219 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.35 = call zeroext i8 @mult(i8 zeroext %6218, i8 zeroext %6219)
  %conv35.16.35 = zext i8 %call34.16.35 to i32
  %xor36.16.35 = xor i32 %xor.16.35, %conv35.16.35
  %conv37.16.35 = trunc i32 %xor36.16.35 to i8
  store i8 %conv37.16.35, i8* %scevgep41.16.34, align 1
  %scevgep28.16.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6213, i64 0, i64 0, i64 1
  %6220 = bitcast i8* %scevgep28.16.35 to [61 x [61 x i8]]*
  %scevgep41.16.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6214, i64 0, i64 1, i64 0
  %6221 = bitcast i8* %scevgep41.16.35 to [61 x [61 x i8]]*
  %call16.16.36 = call zeroext i8 (...) @rand()
  store i8 %call16.16.36, i8* %scevgep28.16.35, align 1
  %6222 = load i8, i8* %scevgep28.16.35, align 1
  %conv23.16.36 = zext i8 %6222 to i32
  %6223 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.36 = getelementptr i8, i8* %b, i64 53
  %6224 = load i8, i8* %scevgep34.16.36, align 1
  %call28.16.36 = call zeroext i8 @mult(i8 zeroext %6223, i8 zeroext %6224)
  %conv29.16.36 = zext i8 %call28.16.36 to i32
  %xor.16.36 = xor i32 %conv23.16.36, %conv29.16.36
  %scevgep35.16.36 = getelementptr i8, i8* %a, i64 53
  %6225 = load i8, i8* %scevgep35.16.36, align 1
  %6226 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.36 = call zeroext i8 @mult(i8 zeroext %6225, i8 zeroext %6226)
  %conv35.16.36 = zext i8 %call34.16.36 to i32
  %xor36.16.36 = xor i32 %xor.16.36, %conv35.16.36
  %conv37.16.36 = trunc i32 %xor36.16.36 to i8
  store i8 %conv37.16.36, i8* %scevgep41.16.35, align 1
  %scevgep28.16.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6220, i64 0, i64 0, i64 1
  %6227 = bitcast i8* %scevgep28.16.36 to [61 x [61 x i8]]*
  %scevgep41.16.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6221, i64 0, i64 1, i64 0
  %6228 = bitcast i8* %scevgep41.16.36 to [61 x [61 x i8]]*
  %call16.16.37 = call zeroext i8 (...) @rand()
  store i8 %call16.16.37, i8* %scevgep28.16.36, align 1
  %6229 = load i8, i8* %scevgep28.16.36, align 1
  %conv23.16.37 = zext i8 %6229 to i32
  %6230 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.37 = getelementptr i8, i8* %b, i64 54
  %6231 = load i8, i8* %scevgep34.16.37, align 1
  %call28.16.37 = call zeroext i8 @mult(i8 zeroext %6230, i8 zeroext %6231)
  %conv29.16.37 = zext i8 %call28.16.37 to i32
  %xor.16.37 = xor i32 %conv23.16.37, %conv29.16.37
  %scevgep35.16.37 = getelementptr i8, i8* %a, i64 54
  %6232 = load i8, i8* %scevgep35.16.37, align 1
  %6233 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.37 = call zeroext i8 @mult(i8 zeroext %6232, i8 zeroext %6233)
  %conv35.16.37 = zext i8 %call34.16.37 to i32
  %xor36.16.37 = xor i32 %xor.16.37, %conv35.16.37
  %conv37.16.37 = trunc i32 %xor36.16.37 to i8
  store i8 %conv37.16.37, i8* %scevgep41.16.36, align 1
  %scevgep28.16.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6227, i64 0, i64 0, i64 1
  %6234 = bitcast i8* %scevgep28.16.37 to [61 x [61 x i8]]*
  %scevgep41.16.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6228, i64 0, i64 1, i64 0
  %6235 = bitcast i8* %scevgep41.16.37 to [61 x [61 x i8]]*
  %call16.16.38 = call zeroext i8 (...) @rand()
  store i8 %call16.16.38, i8* %scevgep28.16.37, align 1
  %6236 = load i8, i8* %scevgep28.16.37, align 1
  %conv23.16.38 = zext i8 %6236 to i32
  %6237 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.38 = getelementptr i8, i8* %b, i64 55
  %6238 = load i8, i8* %scevgep34.16.38, align 1
  %call28.16.38 = call zeroext i8 @mult(i8 zeroext %6237, i8 zeroext %6238)
  %conv29.16.38 = zext i8 %call28.16.38 to i32
  %xor.16.38 = xor i32 %conv23.16.38, %conv29.16.38
  %scevgep35.16.38 = getelementptr i8, i8* %a, i64 55
  %6239 = load i8, i8* %scevgep35.16.38, align 1
  %6240 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.38 = call zeroext i8 @mult(i8 zeroext %6239, i8 zeroext %6240)
  %conv35.16.38 = zext i8 %call34.16.38 to i32
  %xor36.16.38 = xor i32 %xor.16.38, %conv35.16.38
  %conv37.16.38 = trunc i32 %xor36.16.38 to i8
  store i8 %conv37.16.38, i8* %scevgep41.16.37, align 1
  %scevgep28.16.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6234, i64 0, i64 0, i64 1
  %6241 = bitcast i8* %scevgep28.16.38 to [61 x [61 x i8]]*
  %scevgep41.16.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6235, i64 0, i64 1, i64 0
  %6242 = bitcast i8* %scevgep41.16.38 to [61 x [61 x i8]]*
  %call16.16.39 = call zeroext i8 (...) @rand()
  store i8 %call16.16.39, i8* %scevgep28.16.38, align 1
  %6243 = load i8, i8* %scevgep28.16.38, align 1
  %conv23.16.39 = zext i8 %6243 to i32
  %6244 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.39 = getelementptr i8, i8* %b, i64 56
  %6245 = load i8, i8* %scevgep34.16.39, align 1
  %call28.16.39 = call zeroext i8 @mult(i8 zeroext %6244, i8 zeroext %6245)
  %conv29.16.39 = zext i8 %call28.16.39 to i32
  %xor.16.39 = xor i32 %conv23.16.39, %conv29.16.39
  %scevgep35.16.39 = getelementptr i8, i8* %a, i64 56
  %6246 = load i8, i8* %scevgep35.16.39, align 1
  %6247 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.39 = call zeroext i8 @mult(i8 zeroext %6246, i8 zeroext %6247)
  %conv35.16.39 = zext i8 %call34.16.39 to i32
  %xor36.16.39 = xor i32 %xor.16.39, %conv35.16.39
  %conv37.16.39 = trunc i32 %xor36.16.39 to i8
  store i8 %conv37.16.39, i8* %scevgep41.16.38, align 1
  %scevgep28.16.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6241, i64 0, i64 0, i64 1
  %6248 = bitcast i8* %scevgep28.16.39 to [61 x [61 x i8]]*
  %scevgep41.16.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6242, i64 0, i64 1, i64 0
  %6249 = bitcast i8* %scevgep41.16.39 to [61 x [61 x i8]]*
  %call16.16.40 = call zeroext i8 (...) @rand()
  store i8 %call16.16.40, i8* %scevgep28.16.39, align 1
  %6250 = load i8, i8* %scevgep28.16.39, align 1
  %conv23.16.40 = zext i8 %6250 to i32
  %6251 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.40 = getelementptr i8, i8* %b, i64 57
  %6252 = load i8, i8* %scevgep34.16.40, align 1
  %call28.16.40 = call zeroext i8 @mult(i8 zeroext %6251, i8 zeroext %6252)
  %conv29.16.40 = zext i8 %call28.16.40 to i32
  %xor.16.40 = xor i32 %conv23.16.40, %conv29.16.40
  %scevgep35.16.40 = getelementptr i8, i8* %a, i64 57
  %6253 = load i8, i8* %scevgep35.16.40, align 1
  %6254 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.40 = call zeroext i8 @mult(i8 zeroext %6253, i8 zeroext %6254)
  %conv35.16.40 = zext i8 %call34.16.40 to i32
  %xor36.16.40 = xor i32 %xor.16.40, %conv35.16.40
  %conv37.16.40 = trunc i32 %xor36.16.40 to i8
  store i8 %conv37.16.40, i8* %scevgep41.16.39, align 1
  %scevgep28.16.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6248, i64 0, i64 0, i64 1
  %6255 = bitcast i8* %scevgep28.16.40 to [61 x [61 x i8]]*
  %scevgep41.16.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6249, i64 0, i64 1, i64 0
  %6256 = bitcast i8* %scevgep41.16.40 to [61 x [61 x i8]]*
  %call16.16.41 = call zeroext i8 (...) @rand()
  store i8 %call16.16.41, i8* %scevgep28.16.40, align 1
  %6257 = load i8, i8* %scevgep28.16.40, align 1
  %conv23.16.41 = zext i8 %6257 to i32
  %6258 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.41 = getelementptr i8, i8* %b, i64 58
  %6259 = load i8, i8* %scevgep34.16.41, align 1
  %call28.16.41 = call zeroext i8 @mult(i8 zeroext %6258, i8 zeroext %6259)
  %conv29.16.41 = zext i8 %call28.16.41 to i32
  %xor.16.41 = xor i32 %conv23.16.41, %conv29.16.41
  %scevgep35.16.41 = getelementptr i8, i8* %a, i64 58
  %6260 = load i8, i8* %scevgep35.16.41, align 1
  %6261 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.41 = call zeroext i8 @mult(i8 zeroext %6260, i8 zeroext %6261)
  %conv35.16.41 = zext i8 %call34.16.41 to i32
  %xor36.16.41 = xor i32 %xor.16.41, %conv35.16.41
  %conv37.16.41 = trunc i32 %xor36.16.41 to i8
  store i8 %conv37.16.41, i8* %scevgep41.16.40, align 1
  %scevgep28.16.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6255, i64 0, i64 0, i64 1
  %6262 = bitcast i8* %scevgep28.16.41 to [61 x [61 x i8]]*
  %scevgep41.16.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6256, i64 0, i64 1, i64 0
  %6263 = bitcast i8* %scevgep41.16.41 to [61 x [61 x i8]]*
  %call16.16.42 = call zeroext i8 (...) @rand()
  store i8 %call16.16.42, i8* %scevgep28.16.41, align 1
  %6264 = load i8, i8* %scevgep28.16.41, align 1
  %conv23.16.42 = zext i8 %6264 to i32
  %6265 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.42 = getelementptr i8, i8* %b, i64 59
  %6266 = load i8, i8* %scevgep34.16.42, align 1
  %call28.16.42 = call zeroext i8 @mult(i8 zeroext %6265, i8 zeroext %6266)
  %conv29.16.42 = zext i8 %call28.16.42 to i32
  %xor.16.42 = xor i32 %conv23.16.42, %conv29.16.42
  %scevgep35.16.42 = getelementptr i8, i8* %a, i64 59
  %6267 = load i8, i8* %scevgep35.16.42, align 1
  %6268 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.42 = call zeroext i8 @mult(i8 zeroext %6267, i8 zeroext %6268)
  %conv35.16.42 = zext i8 %call34.16.42 to i32
  %xor36.16.42 = xor i32 %xor.16.42, %conv35.16.42
  %conv37.16.42 = trunc i32 %xor36.16.42 to i8
  store i8 %conv37.16.42, i8* %scevgep41.16.41, align 1
  %scevgep28.16.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6262, i64 0, i64 0, i64 1
  %scevgep41.16.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6263, i64 0, i64 1, i64 0
  %call16.16.43 = call zeroext i8 (...) @rand()
  store i8 %call16.16.43, i8* %scevgep28.16.42, align 1
  %6269 = load i8, i8* %scevgep28.16.42, align 1
  %conv23.16.43 = zext i8 %6269 to i32
  %6270 = load i8, i8* %arrayidx25.16, align 1
  %scevgep34.16.43 = getelementptr i8, i8* %b, i64 60
  %6271 = load i8, i8* %scevgep34.16.43, align 1
  %call28.16.43 = call zeroext i8 @mult(i8 zeroext %6270, i8 zeroext %6271)
  %conv29.16.43 = zext i8 %call28.16.43 to i32
  %xor.16.43 = xor i32 %conv23.16.43, %conv29.16.43
  %scevgep35.16.43 = getelementptr i8, i8* %a, i64 60
  %6272 = load i8, i8* %scevgep35.16.43, align 1
  %6273 = load i8, i8* %arrayidx33.16, align 1
  %call34.16.43 = call zeroext i8 @mult(i8 zeroext %6272, i8 zeroext %6273)
  %conv35.16.43 = zext i8 %call34.16.43 to i32
  %xor36.16.43 = xor i32 %xor.16.43, %conv35.16.43
  %conv37.16.43 = trunc i32 %xor36.16.43 to i8
  store i8 %conv37.16.43, i8* %scevgep41.16.42, align 1
  %scevgep26.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5968, i64 0, i64 1, i64 1
  %6274 = bitcast i8* %scevgep26.16 to [61 x [61 x i8]]*
  %scevgep39.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %5969, i64 0, i64 1, i64 1
  %6275 = bitcast i8* %scevgep39.16 to [61 x [61 x i8]]*
  %arrayidx25.17 = getelementptr inbounds i8, i8* %a, i64 17
  %arrayidx33.17 = getelementptr inbounds i8, i8* %b, i64 17
  %call16.17 = call zeroext i8 (...) @rand()
  store i8 %call16.17, i8* %scevgep26.16, align 1
  %6276 = load i8, i8* %scevgep26.16, align 1
  %conv23.17 = zext i8 %6276 to i32
  %6277 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17 = getelementptr i8, i8* %b, i64 18
  %6278 = load i8, i8* %scevgep34.17, align 1
  %call28.17 = call zeroext i8 @mult(i8 zeroext %6277, i8 zeroext %6278)
  %conv29.17 = zext i8 %call28.17 to i32
  %xor.17 = xor i32 %conv23.17, %conv29.17
  %scevgep35.17 = getelementptr i8, i8* %a, i64 18
  %6279 = load i8, i8* %scevgep35.17, align 1
  %6280 = load i8, i8* %arrayidx33.17, align 1
  %call34.17 = call zeroext i8 @mult(i8 zeroext %6279, i8 zeroext %6280)
  %conv35.17 = zext i8 %call34.17 to i32
  %xor36.17 = xor i32 %xor.17, %conv35.17
  %conv37.17 = trunc i32 %xor36.17 to i8
  store i8 %conv37.17, i8* %scevgep39.16, align 1
  %scevgep28.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6274, i64 0, i64 0, i64 1
  %6281 = bitcast i8* %scevgep28.17 to [61 x [61 x i8]]*
  %scevgep41.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6275, i64 0, i64 1, i64 0
  %6282 = bitcast i8* %scevgep41.17 to [61 x [61 x i8]]*
  %call16.17.1 = call zeroext i8 (...) @rand()
  store i8 %call16.17.1, i8* %scevgep28.17, align 1
  %6283 = load i8, i8* %scevgep28.17, align 1
  %conv23.17.1 = zext i8 %6283 to i32
  %6284 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.1 = getelementptr i8, i8* %b, i64 19
  %6285 = load i8, i8* %scevgep34.17.1, align 1
  %call28.17.1 = call zeroext i8 @mult(i8 zeroext %6284, i8 zeroext %6285)
  %conv29.17.1 = zext i8 %call28.17.1 to i32
  %xor.17.1 = xor i32 %conv23.17.1, %conv29.17.1
  %scevgep35.17.1 = getelementptr i8, i8* %a, i64 19
  %6286 = load i8, i8* %scevgep35.17.1, align 1
  %6287 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.1 = call zeroext i8 @mult(i8 zeroext %6286, i8 zeroext %6287)
  %conv35.17.1 = zext i8 %call34.17.1 to i32
  %xor36.17.1 = xor i32 %xor.17.1, %conv35.17.1
  %conv37.17.1 = trunc i32 %xor36.17.1 to i8
  store i8 %conv37.17.1, i8* %scevgep41.17, align 1
  %scevgep28.17.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6281, i64 0, i64 0, i64 1
  %6288 = bitcast i8* %scevgep28.17.1 to [61 x [61 x i8]]*
  %scevgep41.17.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6282, i64 0, i64 1, i64 0
  %6289 = bitcast i8* %scevgep41.17.1 to [61 x [61 x i8]]*
  %call16.17.2 = call zeroext i8 (...) @rand()
  store i8 %call16.17.2, i8* %scevgep28.17.1, align 1
  %6290 = load i8, i8* %scevgep28.17.1, align 1
  %conv23.17.2 = zext i8 %6290 to i32
  %6291 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.2 = getelementptr i8, i8* %b, i64 20
  %6292 = load i8, i8* %scevgep34.17.2, align 1
  %call28.17.2 = call zeroext i8 @mult(i8 zeroext %6291, i8 zeroext %6292)
  %conv29.17.2 = zext i8 %call28.17.2 to i32
  %xor.17.2 = xor i32 %conv23.17.2, %conv29.17.2
  %scevgep35.17.2 = getelementptr i8, i8* %a, i64 20
  %6293 = load i8, i8* %scevgep35.17.2, align 1
  %6294 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.2 = call zeroext i8 @mult(i8 zeroext %6293, i8 zeroext %6294)
  %conv35.17.2 = zext i8 %call34.17.2 to i32
  %xor36.17.2 = xor i32 %xor.17.2, %conv35.17.2
  %conv37.17.2 = trunc i32 %xor36.17.2 to i8
  store i8 %conv37.17.2, i8* %scevgep41.17.1, align 1
  %scevgep28.17.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6288, i64 0, i64 0, i64 1
  %6295 = bitcast i8* %scevgep28.17.2 to [61 x [61 x i8]]*
  %scevgep41.17.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6289, i64 0, i64 1, i64 0
  %6296 = bitcast i8* %scevgep41.17.2 to [61 x [61 x i8]]*
  %call16.17.3 = call zeroext i8 (...) @rand()
  store i8 %call16.17.3, i8* %scevgep28.17.2, align 1
  %6297 = load i8, i8* %scevgep28.17.2, align 1
  %conv23.17.3 = zext i8 %6297 to i32
  %6298 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.3 = getelementptr i8, i8* %b, i64 21
  %6299 = load i8, i8* %scevgep34.17.3, align 1
  %call28.17.3 = call zeroext i8 @mult(i8 zeroext %6298, i8 zeroext %6299)
  %conv29.17.3 = zext i8 %call28.17.3 to i32
  %xor.17.3 = xor i32 %conv23.17.3, %conv29.17.3
  %scevgep35.17.3 = getelementptr i8, i8* %a, i64 21
  %6300 = load i8, i8* %scevgep35.17.3, align 1
  %6301 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.3 = call zeroext i8 @mult(i8 zeroext %6300, i8 zeroext %6301)
  %conv35.17.3 = zext i8 %call34.17.3 to i32
  %xor36.17.3 = xor i32 %xor.17.3, %conv35.17.3
  %conv37.17.3 = trunc i32 %xor36.17.3 to i8
  store i8 %conv37.17.3, i8* %scevgep41.17.2, align 1
  %scevgep28.17.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6295, i64 0, i64 0, i64 1
  %6302 = bitcast i8* %scevgep28.17.3 to [61 x [61 x i8]]*
  %scevgep41.17.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6296, i64 0, i64 1, i64 0
  %6303 = bitcast i8* %scevgep41.17.3 to [61 x [61 x i8]]*
  %call16.17.4 = call zeroext i8 (...) @rand()
  store i8 %call16.17.4, i8* %scevgep28.17.3, align 1
  %6304 = load i8, i8* %scevgep28.17.3, align 1
  %conv23.17.4 = zext i8 %6304 to i32
  %6305 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.4 = getelementptr i8, i8* %b, i64 22
  %6306 = load i8, i8* %scevgep34.17.4, align 1
  %call28.17.4 = call zeroext i8 @mult(i8 zeroext %6305, i8 zeroext %6306)
  %conv29.17.4 = zext i8 %call28.17.4 to i32
  %xor.17.4 = xor i32 %conv23.17.4, %conv29.17.4
  %scevgep35.17.4 = getelementptr i8, i8* %a, i64 22
  %6307 = load i8, i8* %scevgep35.17.4, align 1
  %6308 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.4 = call zeroext i8 @mult(i8 zeroext %6307, i8 zeroext %6308)
  %conv35.17.4 = zext i8 %call34.17.4 to i32
  %xor36.17.4 = xor i32 %xor.17.4, %conv35.17.4
  %conv37.17.4 = trunc i32 %xor36.17.4 to i8
  store i8 %conv37.17.4, i8* %scevgep41.17.3, align 1
  %scevgep28.17.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6302, i64 0, i64 0, i64 1
  %6309 = bitcast i8* %scevgep28.17.4 to [61 x [61 x i8]]*
  %scevgep41.17.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6303, i64 0, i64 1, i64 0
  %6310 = bitcast i8* %scevgep41.17.4 to [61 x [61 x i8]]*
  %call16.17.5 = call zeroext i8 (...) @rand()
  store i8 %call16.17.5, i8* %scevgep28.17.4, align 1
  %6311 = load i8, i8* %scevgep28.17.4, align 1
  %conv23.17.5 = zext i8 %6311 to i32
  %6312 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.5 = getelementptr i8, i8* %b, i64 23
  %6313 = load i8, i8* %scevgep34.17.5, align 1
  %call28.17.5 = call zeroext i8 @mult(i8 zeroext %6312, i8 zeroext %6313)
  %conv29.17.5 = zext i8 %call28.17.5 to i32
  %xor.17.5 = xor i32 %conv23.17.5, %conv29.17.5
  %scevgep35.17.5 = getelementptr i8, i8* %a, i64 23
  %6314 = load i8, i8* %scevgep35.17.5, align 1
  %6315 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.5 = call zeroext i8 @mult(i8 zeroext %6314, i8 zeroext %6315)
  %conv35.17.5 = zext i8 %call34.17.5 to i32
  %xor36.17.5 = xor i32 %xor.17.5, %conv35.17.5
  %conv37.17.5 = trunc i32 %xor36.17.5 to i8
  store i8 %conv37.17.5, i8* %scevgep41.17.4, align 1
  %scevgep28.17.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6309, i64 0, i64 0, i64 1
  %6316 = bitcast i8* %scevgep28.17.5 to [61 x [61 x i8]]*
  %scevgep41.17.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6310, i64 0, i64 1, i64 0
  %6317 = bitcast i8* %scevgep41.17.5 to [61 x [61 x i8]]*
  %call16.17.6 = call zeroext i8 (...) @rand()
  store i8 %call16.17.6, i8* %scevgep28.17.5, align 1
  %6318 = load i8, i8* %scevgep28.17.5, align 1
  %conv23.17.6 = zext i8 %6318 to i32
  %6319 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.6 = getelementptr i8, i8* %b, i64 24
  %6320 = load i8, i8* %scevgep34.17.6, align 1
  %call28.17.6 = call zeroext i8 @mult(i8 zeroext %6319, i8 zeroext %6320)
  %conv29.17.6 = zext i8 %call28.17.6 to i32
  %xor.17.6 = xor i32 %conv23.17.6, %conv29.17.6
  %scevgep35.17.6 = getelementptr i8, i8* %a, i64 24
  %6321 = load i8, i8* %scevgep35.17.6, align 1
  %6322 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.6 = call zeroext i8 @mult(i8 zeroext %6321, i8 zeroext %6322)
  %conv35.17.6 = zext i8 %call34.17.6 to i32
  %xor36.17.6 = xor i32 %xor.17.6, %conv35.17.6
  %conv37.17.6 = trunc i32 %xor36.17.6 to i8
  store i8 %conv37.17.6, i8* %scevgep41.17.5, align 1
  %scevgep28.17.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6316, i64 0, i64 0, i64 1
  %6323 = bitcast i8* %scevgep28.17.6 to [61 x [61 x i8]]*
  %scevgep41.17.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6317, i64 0, i64 1, i64 0
  %6324 = bitcast i8* %scevgep41.17.6 to [61 x [61 x i8]]*
  %call16.17.7 = call zeroext i8 (...) @rand()
  store i8 %call16.17.7, i8* %scevgep28.17.6, align 1
  %6325 = load i8, i8* %scevgep28.17.6, align 1
  %conv23.17.7 = zext i8 %6325 to i32
  %6326 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.7 = getelementptr i8, i8* %b, i64 25
  %6327 = load i8, i8* %scevgep34.17.7, align 1
  %call28.17.7 = call zeroext i8 @mult(i8 zeroext %6326, i8 zeroext %6327)
  %conv29.17.7 = zext i8 %call28.17.7 to i32
  %xor.17.7 = xor i32 %conv23.17.7, %conv29.17.7
  %scevgep35.17.7 = getelementptr i8, i8* %a, i64 25
  %6328 = load i8, i8* %scevgep35.17.7, align 1
  %6329 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.7 = call zeroext i8 @mult(i8 zeroext %6328, i8 zeroext %6329)
  %conv35.17.7 = zext i8 %call34.17.7 to i32
  %xor36.17.7 = xor i32 %xor.17.7, %conv35.17.7
  %conv37.17.7 = trunc i32 %xor36.17.7 to i8
  store i8 %conv37.17.7, i8* %scevgep41.17.6, align 1
  %scevgep28.17.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6323, i64 0, i64 0, i64 1
  %6330 = bitcast i8* %scevgep28.17.7 to [61 x [61 x i8]]*
  %scevgep41.17.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6324, i64 0, i64 1, i64 0
  %6331 = bitcast i8* %scevgep41.17.7 to [61 x [61 x i8]]*
  %call16.17.8 = call zeroext i8 (...) @rand()
  store i8 %call16.17.8, i8* %scevgep28.17.7, align 1
  %6332 = load i8, i8* %scevgep28.17.7, align 1
  %conv23.17.8 = zext i8 %6332 to i32
  %6333 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.8 = getelementptr i8, i8* %b, i64 26
  %6334 = load i8, i8* %scevgep34.17.8, align 1
  %call28.17.8 = call zeroext i8 @mult(i8 zeroext %6333, i8 zeroext %6334)
  %conv29.17.8 = zext i8 %call28.17.8 to i32
  %xor.17.8 = xor i32 %conv23.17.8, %conv29.17.8
  %scevgep35.17.8 = getelementptr i8, i8* %a, i64 26
  %6335 = load i8, i8* %scevgep35.17.8, align 1
  %6336 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.8 = call zeroext i8 @mult(i8 zeroext %6335, i8 zeroext %6336)
  %conv35.17.8 = zext i8 %call34.17.8 to i32
  %xor36.17.8 = xor i32 %xor.17.8, %conv35.17.8
  %conv37.17.8 = trunc i32 %xor36.17.8 to i8
  store i8 %conv37.17.8, i8* %scevgep41.17.7, align 1
  %scevgep28.17.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6330, i64 0, i64 0, i64 1
  %6337 = bitcast i8* %scevgep28.17.8 to [61 x [61 x i8]]*
  %scevgep41.17.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6331, i64 0, i64 1, i64 0
  %6338 = bitcast i8* %scevgep41.17.8 to [61 x [61 x i8]]*
  %call16.17.9 = call zeroext i8 (...) @rand()
  store i8 %call16.17.9, i8* %scevgep28.17.8, align 1
  %6339 = load i8, i8* %scevgep28.17.8, align 1
  %conv23.17.9 = zext i8 %6339 to i32
  %6340 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.9 = getelementptr i8, i8* %b, i64 27
  %6341 = load i8, i8* %scevgep34.17.9, align 1
  %call28.17.9 = call zeroext i8 @mult(i8 zeroext %6340, i8 zeroext %6341)
  %conv29.17.9 = zext i8 %call28.17.9 to i32
  %xor.17.9 = xor i32 %conv23.17.9, %conv29.17.9
  %scevgep35.17.9 = getelementptr i8, i8* %a, i64 27
  %6342 = load i8, i8* %scevgep35.17.9, align 1
  %6343 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.9 = call zeroext i8 @mult(i8 zeroext %6342, i8 zeroext %6343)
  %conv35.17.9 = zext i8 %call34.17.9 to i32
  %xor36.17.9 = xor i32 %xor.17.9, %conv35.17.9
  %conv37.17.9 = trunc i32 %xor36.17.9 to i8
  store i8 %conv37.17.9, i8* %scevgep41.17.8, align 1
  %scevgep28.17.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6337, i64 0, i64 0, i64 1
  %6344 = bitcast i8* %scevgep28.17.9 to [61 x [61 x i8]]*
  %scevgep41.17.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6338, i64 0, i64 1, i64 0
  %6345 = bitcast i8* %scevgep41.17.9 to [61 x [61 x i8]]*
  %call16.17.10 = call zeroext i8 (...) @rand()
  store i8 %call16.17.10, i8* %scevgep28.17.9, align 1
  %6346 = load i8, i8* %scevgep28.17.9, align 1
  %conv23.17.10 = zext i8 %6346 to i32
  %6347 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.10 = getelementptr i8, i8* %b, i64 28
  %6348 = load i8, i8* %scevgep34.17.10, align 1
  %call28.17.10 = call zeroext i8 @mult(i8 zeroext %6347, i8 zeroext %6348)
  %conv29.17.10 = zext i8 %call28.17.10 to i32
  %xor.17.10 = xor i32 %conv23.17.10, %conv29.17.10
  %scevgep35.17.10 = getelementptr i8, i8* %a, i64 28
  %6349 = load i8, i8* %scevgep35.17.10, align 1
  %6350 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.10 = call zeroext i8 @mult(i8 zeroext %6349, i8 zeroext %6350)
  %conv35.17.10 = zext i8 %call34.17.10 to i32
  %xor36.17.10 = xor i32 %xor.17.10, %conv35.17.10
  %conv37.17.10 = trunc i32 %xor36.17.10 to i8
  store i8 %conv37.17.10, i8* %scevgep41.17.9, align 1
  %scevgep28.17.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6344, i64 0, i64 0, i64 1
  %6351 = bitcast i8* %scevgep28.17.10 to [61 x [61 x i8]]*
  %scevgep41.17.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6345, i64 0, i64 1, i64 0
  %6352 = bitcast i8* %scevgep41.17.10 to [61 x [61 x i8]]*
  %call16.17.11 = call zeroext i8 (...) @rand()
  store i8 %call16.17.11, i8* %scevgep28.17.10, align 1
  %6353 = load i8, i8* %scevgep28.17.10, align 1
  %conv23.17.11 = zext i8 %6353 to i32
  %6354 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.11 = getelementptr i8, i8* %b, i64 29
  %6355 = load i8, i8* %scevgep34.17.11, align 1
  %call28.17.11 = call zeroext i8 @mult(i8 zeroext %6354, i8 zeroext %6355)
  %conv29.17.11 = zext i8 %call28.17.11 to i32
  %xor.17.11 = xor i32 %conv23.17.11, %conv29.17.11
  %scevgep35.17.11 = getelementptr i8, i8* %a, i64 29
  %6356 = load i8, i8* %scevgep35.17.11, align 1
  %6357 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.11 = call zeroext i8 @mult(i8 zeroext %6356, i8 zeroext %6357)
  %conv35.17.11 = zext i8 %call34.17.11 to i32
  %xor36.17.11 = xor i32 %xor.17.11, %conv35.17.11
  %conv37.17.11 = trunc i32 %xor36.17.11 to i8
  store i8 %conv37.17.11, i8* %scevgep41.17.10, align 1
  %scevgep28.17.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6351, i64 0, i64 0, i64 1
  %6358 = bitcast i8* %scevgep28.17.11 to [61 x [61 x i8]]*
  %scevgep41.17.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6352, i64 0, i64 1, i64 0
  %6359 = bitcast i8* %scevgep41.17.11 to [61 x [61 x i8]]*
  %call16.17.12 = call zeroext i8 (...) @rand()
  store i8 %call16.17.12, i8* %scevgep28.17.11, align 1
  %6360 = load i8, i8* %scevgep28.17.11, align 1
  %conv23.17.12 = zext i8 %6360 to i32
  %6361 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.12 = getelementptr i8, i8* %b, i64 30
  %6362 = load i8, i8* %scevgep34.17.12, align 1
  %call28.17.12 = call zeroext i8 @mult(i8 zeroext %6361, i8 zeroext %6362)
  %conv29.17.12 = zext i8 %call28.17.12 to i32
  %xor.17.12 = xor i32 %conv23.17.12, %conv29.17.12
  %scevgep35.17.12 = getelementptr i8, i8* %a, i64 30
  %6363 = load i8, i8* %scevgep35.17.12, align 1
  %6364 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.12 = call zeroext i8 @mult(i8 zeroext %6363, i8 zeroext %6364)
  %conv35.17.12 = zext i8 %call34.17.12 to i32
  %xor36.17.12 = xor i32 %xor.17.12, %conv35.17.12
  %conv37.17.12 = trunc i32 %xor36.17.12 to i8
  store i8 %conv37.17.12, i8* %scevgep41.17.11, align 1
  %scevgep28.17.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6358, i64 0, i64 0, i64 1
  %6365 = bitcast i8* %scevgep28.17.12 to [61 x [61 x i8]]*
  %scevgep41.17.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6359, i64 0, i64 1, i64 0
  %6366 = bitcast i8* %scevgep41.17.12 to [61 x [61 x i8]]*
  %call16.17.13 = call zeroext i8 (...) @rand()
  store i8 %call16.17.13, i8* %scevgep28.17.12, align 1
  %6367 = load i8, i8* %scevgep28.17.12, align 1
  %conv23.17.13 = zext i8 %6367 to i32
  %6368 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.13 = getelementptr i8, i8* %b, i64 31
  %6369 = load i8, i8* %scevgep34.17.13, align 1
  %call28.17.13 = call zeroext i8 @mult(i8 zeroext %6368, i8 zeroext %6369)
  %conv29.17.13 = zext i8 %call28.17.13 to i32
  %xor.17.13 = xor i32 %conv23.17.13, %conv29.17.13
  %scevgep35.17.13 = getelementptr i8, i8* %a, i64 31
  %6370 = load i8, i8* %scevgep35.17.13, align 1
  %6371 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.13 = call zeroext i8 @mult(i8 zeroext %6370, i8 zeroext %6371)
  %conv35.17.13 = zext i8 %call34.17.13 to i32
  %xor36.17.13 = xor i32 %xor.17.13, %conv35.17.13
  %conv37.17.13 = trunc i32 %xor36.17.13 to i8
  store i8 %conv37.17.13, i8* %scevgep41.17.12, align 1
  %scevgep28.17.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6365, i64 0, i64 0, i64 1
  %6372 = bitcast i8* %scevgep28.17.13 to [61 x [61 x i8]]*
  %scevgep41.17.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6366, i64 0, i64 1, i64 0
  %6373 = bitcast i8* %scevgep41.17.13 to [61 x [61 x i8]]*
  %call16.17.14 = call zeroext i8 (...) @rand()
  store i8 %call16.17.14, i8* %scevgep28.17.13, align 1
  %6374 = load i8, i8* %scevgep28.17.13, align 1
  %conv23.17.14 = zext i8 %6374 to i32
  %6375 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.14 = getelementptr i8, i8* %b, i64 32
  %6376 = load i8, i8* %scevgep34.17.14, align 1
  %call28.17.14 = call zeroext i8 @mult(i8 zeroext %6375, i8 zeroext %6376)
  %conv29.17.14 = zext i8 %call28.17.14 to i32
  %xor.17.14 = xor i32 %conv23.17.14, %conv29.17.14
  %scevgep35.17.14 = getelementptr i8, i8* %a, i64 32
  %6377 = load i8, i8* %scevgep35.17.14, align 1
  %6378 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.14 = call zeroext i8 @mult(i8 zeroext %6377, i8 zeroext %6378)
  %conv35.17.14 = zext i8 %call34.17.14 to i32
  %xor36.17.14 = xor i32 %xor.17.14, %conv35.17.14
  %conv37.17.14 = trunc i32 %xor36.17.14 to i8
  store i8 %conv37.17.14, i8* %scevgep41.17.13, align 1
  %scevgep28.17.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6372, i64 0, i64 0, i64 1
  %6379 = bitcast i8* %scevgep28.17.14 to [61 x [61 x i8]]*
  %scevgep41.17.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6373, i64 0, i64 1, i64 0
  %6380 = bitcast i8* %scevgep41.17.14 to [61 x [61 x i8]]*
  %call16.17.15 = call zeroext i8 (...) @rand()
  store i8 %call16.17.15, i8* %scevgep28.17.14, align 1
  %6381 = load i8, i8* %scevgep28.17.14, align 1
  %conv23.17.15 = zext i8 %6381 to i32
  %6382 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.15 = getelementptr i8, i8* %b, i64 33
  %6383 = load i8, i8* %scevgep34.17.15, align 1
  %call28.17.15 = call zeroext i8 @mult(i8 zeroext %6382, i8 zeroext %6383)
  %conv29.17.15 = zext i8 %call28.17.15 to i32
  %xor.17.15 = xor i32 %conv23.17.15, %conv29.17.15
  %scevgep35.17.15 = getelementptr i8, i8* %a, i64 33
  %6384 = load i8, i8* %scevgep35.17.15, align 1
  %6385 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.15 = call zeroext i8 @mult(i8 zeroext %6384, i8 zeroext %6385)
  %conv35.17.15 = zext i8 %call34.17.15 to i32
  %xor36.17.15 = xor i32 %xor.17.15, %conv35.17.15
  %conv37.17.15 = trunc i32 %xor36.17.15 to i8
  store i8 %conv37.17.15, i8* %scevgep41.17.14, align 1
  %scevgep28.17.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6379, i64 0, i64 0, i64 1
  %6386 = bitcast i8* %scevgep28.17.15 to [61 x [61 x i8]]*
  %scevgep41.17.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6380, i64 0, i64 1, i64 0
  %6387 = bitcast i8* %scevgep41.17.15 to [61 x [61 x i8]]*
  %call16.17.16 = call zeroext i8 (...) @rand()
  store i8 %call16.17.16, i8* %scevgep28.17.15, align 1
  %6388 = load i8, i8* %scevgep28.17.15, align 1
  %conv23.17.16 = zext i8 %6388 to i32
  %6389 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.16 = getelementptr i8, i8* %b, i64 34
  %6390 = load i8, i8* %scevgep34.17.16, align 1
  %call28.17.16 = call zeroext i8 @mult(i8 zeroext %6389, i8 zeroext %6390)
  %conv29.17.16 = zext i8 %call28.17.16 to i32
  %xor.17.16 = xor i32 %conv23.17.16, %conv29.17.16
  %scevgep35.17.16 = getelementptr i8, i8* %a, i64 34
  %6391 = load i8, i8* %scevgep35.17.16, align 1
  %6392 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.16 = call zeroext i8 @mult(i8 zeroext %6391, i8 zeroext %6392)
  %conv35.17.16 = zext i8 %call34.17.16 to i32
  %xor36.17.16 = xor i32 %xor.17.16, %conv35.17.16
  %conv37.17.16 = trunc i32 %xor36.17.16 to i8
  store i8 %conv37.17.16, i8* %scevgep41.17.15, align 1
  %scevgep28.17.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6386, i64 0, i64 0, i64 1
  %6393 = bitcast i8* %scevgep28.17.16 to [61 x [61 x i8]]*
  %scevgep41.17.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6387, i64 0, i64 1, i64 0
  %6394 = bitcast i8* %scevgep41.17.16 to [61 x [61 x i8]]*
  %call16.17.17 = call zeroext i8 (...) @rand()
  store i8 %call16.17.17, i8* %scevgep28.17.16, align 1
  %6395 = load i8, i8* %scevgep28.17.16, align 1
  %conv23.17.17 = zext i8 %6395 to i32
  %6396 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.17 = getelementptr i8, i8* %b, i64 35
  %6397 = load i8, i8* %scevgep34.17.17, align 1
  %call28.17.17 = call zeroext i8 @mult(i8 zeroext %6396, i8 zeroext %6397)
  %conv29.17.17 = zext i8 %call28.17.17 to i32
  %xor.17.17 = xor i32 %conv23.17.17, %conv29.17.17
  %scevgep35.17.17 = getelementptr i8, i8* %a, i64 35
  %6398 = load i8, i8* %scevgep35.17.17, align 1
  %6399 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.17 = call zeroext i8 @mult(i8 zeroext %6398, i8 zeroext %6399)
  %conv35.17.17 = zext i8 %call34.17.17 to i32
  %xor36.17.17 = xor i32 %xor.17.17, %conv35.17.17
  %conv37.17.17 = trunc i32 %xor36.17.17 to i8
  store i8 %conv37.17.17, i8* %scevgep41.17.16, align 1
  %scevgep28.17.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6393, i64 0, i64 0, i64 1
  %6400 = bitcast i8* %scevgep28.17.17 to [61 x [61 x i8]]*
  %scevgep41.17.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6394, i64 0, i64 1, i64 0
  %6401 = bitcast i8* %scevgep41.17.17 to [61 x [61 x i8]]*
  %call16.17.18 = call zeroext i8 (...) @rand()
  store i8 %call16.17.18, i8* %scevgep28.17.17, align 1
  %6402 = load i8, i8* %scevgep28.17.17, align 1
  %conv23.17.18 = zext i8 %6402 to i32
  %6403 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.18 = getelementptr i8, i8* %b, i64 36
  %6404 = load i8, i8* %scevgep34.17.18, align 1
  %call28.17.18 = call zeroext i8 @mult(i8 zeroext %6403, i8 zeroext %6404)
  %conv29.17.18 = zext i8 %call28.17.18 to i32
  %xor.17.18 = xor i32 %conv23.17.18, %conv29.17.18
  %scevgep35.17.18 = getelementptr i8, i8* %a, i64 36
  %6405 = load i8, i8* %scevgep35.17.18, align 1
  %6406 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.18 = call zeroext i8 @mult(i8 zeroext %6405, i8 zeroext %6406)
  %conv35.17.18 = zext i8 %call34.17.18 to i32
  %xor36.17.18 = xor i32 %xor.17.18, %conv35.17.18
  %conv37.17.18 = trunc i32 %xor36.17.18 to i8
  store i8 %conv37.17.18, i8* %scevgep41.17.17, align 1
  %scevgep28.17.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6400, i64 0, i64 0, i64 1
  %6407 = bitcast i8* %scevgep28.17.18 to [61 x [61 x i8]]*
  %scevgep41.17.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6401, i64 0, i64 1, i64 0
  %6408 = bitcast i8* %scevgep41.17.18 to [61 x [61 x i8]]*
  %call16.17.19 = call zeroext i8 (...) @rand()
  store i8 %call16.17.19, i8* %scevgep28.17.18, align 1
  %6409 = load i8, i8* %scevgep28.17.18, align 1
  %conv23.17.19 = zext i8 %6409 to i32
  %6410 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.19 = getelementptr i8, i8* %b, i64 37
  %6411 = load i8, i8* %scevgep34.17.19, align 1
  %call28.17.19 = call zeroext i8 @mult(i8 zeroext %6410, i8 zeroext %6411)
  %conv29.17.19 = zext i8 %call28.17.19 to i32
  %xor.17.19 = xor i32 %conv23.17.19, %conv29.17.19
  %scevgep35.17.19 = getelementptr i8, i8* %a, i64 37
  %6412 = load i8, i8* %scevgep35.17.19, align 1
  %6413 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.19 = call zeroext i8 @mult(i8 zeroext %6412, i8 zeroext %6413)
  %conv35.17.19 = zext i8 %call34.17.19 to i32
  %xor36.17.19 = xor i32 %xor.17.19, %conv35.17.19
  %conv37.17.19 = trunc i32 %xor36.17.19 to i8
  store i8 %conv37.17.19, i8* %scevgep41.17.18, align 1
  %scevgep28.17.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6407, i64 0, i64 0, i64 1
  %6414 = bitcast i8* %scevgep28.17.19 to [61 x [61 x i8]]*
  %scevgep41.17.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6408, i64 0, i64 1, i64 0
  %6415 = bitcast i8* %scevgep41.17.19 to [61 x [61 x i8]]*
  %call16.17.20 = call zeroext i8 (...) @rand()
  store i8 %call16.17.20, i8* %scevgep28.17.19, align 1
  %6416 = load i8, i8* %scevgep28.17.19, align 1
  %conv23.17.20 = zext i8 %6416 to i32
  %6417 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.20 = getelementptr i8, i8* %b, i64 38
  %6418 = load i8, i8* %scevgep34.17.20, align 1
  %call28.17.20 = call zeroext i8 @mult(i8 zeroext %6417, i8 zeroext %6418)
  %conv29.17.20 = zext i8 %call28.17.20 to i32
  %xor.17.20 = xor i32 %conv23.17.20, %conv29.17.20
  %scevgep35.17.20 = getelementptr i8, i8* %a, i64 38
  %6419 = load i8, i8* %scevgep35.17.20, align 1
  %6420 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.20 = call zeroext i8 @mult(i8 zeroext %6419, i8 zeroext %6420)
  %conv35.17.20 = zext i8 %call34.17.20 to i32
  %xor36.17.20 = xor i32 %xor.17.20, %conv35.17.20
  %conv37.17.20 = trunc i32 %xor36.17.20 to i8
  store i8 %conv37.17.20, i8* %scevgep41.17.19, align 1
  %scevgep28.17.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6414, i64 0, i64 0, i64 1
  %6421 = bitcast i8* %scevgep28.17.20 to [61 x [61 x i8]]*
  %scevgep41.17.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6415, i64 0, i64 1, i64 0
  %6422 = bitcast i8* %scevgep41.17.20 to [61 x [61 x i8]]*
  %call16.17.21 = call zeroext i8 (...) @rand()
  store i8 %call16.17.21, i8* %scevgep28.17.20, align 1
  %6423 = load i8, i8* %scevgep28.17.20, align 1
  %conv23.17.21 = zext i8 %6423 to i32
  %6424 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.21 = getelementptr i8, i8* %b, i64 39
  %6425 = load i8, i8* %scevgep34.17.21, align 1
  %call28.17.21 = call zeroext i8 @mult(i8 zeroext %6424, i8 zeroext %6425)
  %conv29.17.21 = zext i8 %call28.17.21 to i32
  %xor.17.21 = xor i32 %conv23.17.21, %conv29.17.21
  %scevgep35.17.21 = getelementptr i8, i8* %a, i64 39
  %6426 = load i8, i8* %scevgep35.17.21, align 1
  %6427 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.21 = call zeroext i8 @mult(i8 zeroext %6426, i8 zeroext %6427)
  %conv35.17.21 = zext i8 %call34.17.21 to i32
  %xor36.17.21 = xor i32 %xor.17.21, %conv35.17.21
  %conv37.17.21 = trunc i32 %xor36.17.21 to i8
  store i8 %conv37.17.21, i8* %scevgep41.17.20, align 1
  %scevgep28.17.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6421, i64 0, i64 0, i64 1
  %6428 = bitcast i8* %scevgep28.17.21 to [61 x [61 x i8]]*
  %scevgep41.17.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6422, i64 0, i64 1, i64 0
  %6429 = bitcast i8* %scevgep41.17.21 to [61 x [61 x i8]]*
  %call16.17.22 = call zeroext i8 (...) @rand()
  store i8 %call16.17.22, i8* %scevgep28.17.21, align 1
  %6430 = load i8, i8* %scevgep28.17.21, align 1
  %conv23.17.22 = zext i8 %6430 to i32
  %6431 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.22 = getelementptr i8, i8* %b, i64 40
  %6432 = load i8, i8* %scevgep34.17.22, align 1
  %call28.17.22 = call zeroext i8 @mult(i8 zeroext %6431, i8 zeroext %6432)
  %conv29.17.22 = zext i8 %call28.17.22 to i32
  %xor.17.22 = xor i32 %conv23.17.22, %conv29.17.22
  %scevgep35.17.22 = getelementptr i8, i8* %a, i64 40
  %6433 = load i8, i8* %scevgep35.17.22, align 1
  %6434 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.22 = call zeroext i8 @mult(i8 zeroext %6433, i8 zeroext %6434)
  %conv35.17.22 = zext i8 %call34.17.22 to i32
  %xor36.17.22 = xor i32 %xor.17.22, %conv35.17.22
  %conv37.17.22 = trunc i32 %xor36.17.22 to i8
  store i8 %conv37.17.22, i8* %scevgep41.17.21, align 1
  %scevgep28.17.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6428, i64 0, i64 0, i64 1
  %6435 = bitcast i8* %scevgep28.17.22 to [61 x [61 x i8]]*
  %scevgep41.17.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6429, i64 0, i64 1, i64 0
  %6436 = bitcast i8* %scevgep41.17.22 to [61 x [61 x i8]]*
  %call16.17.23 = call zeroext i8 (...) @rand()
  store i8 %call16.17.23, i8* %scevgep28.17.22, align 1
  %6437 = load i8, i8* %scevgep28.17.22, align 1
  %conv23.17.23 = zext i8 %6437 to i32
  %6438 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.23 = getelementptr i8, i8* %b, i64 41
  %6439 = load i8, i8* %scevgep34.17.23, align 1
  %call28.17.23 = call zeroext i8 @mult(i8 zeroext %6438, i8 zeroext %6439)
  %conv29.17.23 = zext i8 %call28.17.23 to i32
  %xor.17.23 = xor i32 %conv23.17.23, %conv29.17.23
  %scevgep35.17.23 = getelementptr i8, i8* %a, i64 41
  %6440 = load i8, i8* %scevgep35.17.23, align 1
  %6441 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.23 = call zeroext i8 @mult(i8 zeroext %6440, i8 zeroext %6441)
  %conv35.17.23 = zext i8 %call34.17.23 to i32
  %xor36.17.23 = xor i32 %xor.17.23, %conv35.17.23
  %conv37.17.23 = trunc i32 %xor36.17.23 to i8
  store i8 %conv37.17.23, i8* %scevgep41.17.22, align 1
  %scevgep28.17.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6435, i64 0, i64 0, i64 1
  %6442 = bitcast i8* %scevgep28.17.23 to [61 x [61 x i8]]*
  %scevgep41.17.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6436, i64 0, i64 1, i64 0
  %6443 = bitcast i8* %scevgep41.17.23 to [61 x [61 x i8]]*
  %call16.17.24 = call zeroext i8 (...) @rand()
  store i8 %call16.17.24, i8* %scevgep28.17.23, align 1
  %6444 = load i8, i8* %scevgep28.17.23, align 1
  %conv23.17.24 = zext i8 %6444 to i32
  %6445 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.24 = getelementptr i8, i8* %b, i64 42
  %6446 = load i8, i8* %scevgep34.17.24, align 1
  %call28.17.24 = call zeroext i8 @mult(i8 zeroext %6445, i8 zeroext %6446)
  %conv29.17.24 = zext i8 %call28.17.24 to i32
  %xor.17.24 = xor i32 %conv23.17.24, %conv29.17.24
  %scevgep35.17.24 = getelementptr i8, i8* %a, i64 42
  %6447 = load i8, i8* %scevgep35.17.24, align 1
  %6448 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.24 = call zeroext i8 @mult(i8 zeroext %6447, i8 zeroext %6448)
  %conv35.17.24 = zext i8 %call34.17.24 to i32
  %xor36.17.24 = xor i32 %xor.17.24, %conv35.17.24
  %conv37.17.24 = trunc i32 %xor36.17.24 to i8
  store i8 %conv37.17.24, i8* %scevgep41.17.23, align 1
  %scevgep28.17.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6442, i64 0, i64 0, i64 1
  %6449 = bitcast i8* %scevgep28.17.24 to [61 x [61 x i8]]*
  %scevgep41.17.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6443, i64 0, i64 1, i64 0
  %6450 = bitcast i8* %scevgep41.17.24 to [61 x [61 x i8]]*
  %call16.17.25 = call zeroext i8 (...) @rand()
  store i8 %call16.17.25, i8* %scevgep28.17.24, align 1
  %6451 = load i8, i8* %scevgep28.17.24, align 1
  %conv23.17.25 = zext i8 %6451 to i32
  %6452 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.25 = getelementptr i8, i8* %b, i64 43
  %6453 = load i8, i8* %scevgep34.17.25, align 1
  %call28.17.25 = call zeroext i8 @mult(i8 zeroext %6452, i8 zeroext %6453)
  %conv29.17.25 = zext i8 %call28.17.25 to i32
  %xor.17.25 = xor i32 %conv23.17.25, %conv29.17.25
  %scevgep35.17.25 = getelementptr i8, i8* %a, i64 43
  %6454 = load i8, i8* %scevgep35.17.25, align 1
  %6455 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.25 = call zeroext i8 @mult(i8 zeroext %6454, i8 zeroext %6455)
  %conv35.17.25 = zext i8 %call34.17.25 to i32
  %xor36.17.25 = xor i32 %xor.17.25, %conv35.17.25
  %conv37.17.25 = trunc i32 %xor36.17.25 to i8
  store i8 %conv37.17.25, i8* %scevgep41.17.24, align 1
  %scevgep28.17.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6449, i64 0, i64 0, i64 1
  %6456 = bitcast i8* %scevgep28.17.25 to [61 x [61 x i8]]*
  %scevgep41.17.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6450, i64 0, i64 1, i64 0
  %6457 = bitcast i8* %scevgep41.17.25 to [61 x [61 x i8]]*
  %call16.17.26 = call zeroext i8 (...) @rand()
  store i8 %call16.17.26, i8* %scevgep28.17.25, align 1
  %6458 = load i8, i8* %scevgep28.17.25, align 1
  %conv23.17.26 = zext i8 %6458 to i32
  %6459 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.26 = getelementptr i8, i8* %b, i64 44
  %6460 = load i8, i8* %scevgep34.17.26, align 1
  %call28.17.26 = call zeroext i8 @mult(i8 zeroext %6459, i8 zeroext %6460)
  %conv29.17.26 = zext i8 %call28.17.26 to i32
  %xor.17.26 = xor i32 %conv23.17.26, %conv29.17.26
  %scevgep35.17.26 = getelementptr i8, i8* %a, i64 44
  %6461 = load i8, i8* %scevgep35.17.26, align 1
  %6462 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.26 = call zeroext i8 @mult(i8 zeroext %6461, i8 zeroext %6462)
  %conv35.17.26 = zext i8 %call34.17.26 to i32
  %xor36.17.26 = xor i32 %xor.17.26, %conv35.17.26
  %conv37.17.26 = trunc i32 %xor36.17.26 to i8
  store i8 %conv37.17.26, i8* %scevgep41.17.25, align 1
  %scevgep28.17.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6456, i64 0, i64 0, i64 1
  %6463 = bitcast i8* %scevgep28.17.26 to [61 x [61 x i8]]*
  %scevgep41.17.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6457, i64 0, i64 1, i64 0
  %6464 = bitcast i8* %scevgep41.17.26 to [61 x [61 x i8]]*
  %call16.17.27 = call zeroext i8 (...) @rand()
  store i8 %call16.17.27, i8* %scevgep28.17.26, align 1
  %6465 = load i8, i8* %scevgep28.17.26, align 1
  %conv23.17.27 = zext i8 %6465 to i32
  %6466 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.27 = getelementptr i8, i8* %b, i64 45
  %6467 = load i8, i8* %scevgep34.17.27, align 1
  %call28.17.27 = call zeroext i8 @mult(i8 zeroext %6466, i8 zeroext %6467)
  %conv29.17.27 = zext i8 %call28.17.27 to i32
  %xor.17.27 = xor i32 %conv23.17.27, %conv29.17.27
  %scevgep35.17.27 = getelementptr i8, i8* %a, i64 45
  %6468 = load i8, i8* %scevgep35.17.27, align 1
  %6469 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.27 = call zeroext i8 @mult(i8 zeroext %6468, i8 zeroext %6469)
  %conv35.17.27 = zext i8 %call34.17.27 to i32
  %xor36.17.27 = xor i32 %xor.17.27, %conv35.17.27
  %conv37.17.27 = trunc i32 %xor36.17.27 to i8
  store i8 %conv37.17.27, i8* %scevgep41.17.26, align 1
  %scevgep28.17.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6463, i64 0, i64 0, i64 1
  %6470 = bitcast i8* %scevgep28.17.27 to [61 x [61 x i8]]*
  %scevgep41.17.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6464, i64 0, i64 1, i64 0
  %6471 = bitcast i8* %scevgep41.17.27 to [61 x [61 x i8]]*
  %call16.17.28 = call zeroext i8 (...) @rand()
  store i8 %call16.17.28, i8* %scevgep28.17.27, align 1
  %6472 = load i8, i8* %scevgep28.17.27, align 1
  %conv23.17.28 = zext i8 %6472 to i32
  %6473 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.28 = getelementptr i8, i8* %b, i64 46
  %6474 = load i8, i8* %scevgep34.17.28, align 1
  %call28.17.28 = call zeroext i8 @mult(i8 zeroext %6473, i8 zeroext %6474)
  %conv29.17.28 = zext i8 %call28.17.28 to i32
  %xor.17.28 = xor i32 %conv23.17.28, %conv29.17.28
  %scevgep35.17.28 = getelementptr i8, i8* %a, i64 46
  %6475 = load i8, i8* %scevgep35.17.28, align 1
  %6476 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.28 = call zeroext i8 @mult(i8 zeroext %6475, i8 zeroext %6476)
  %conv35.17.28 = zext i8 %call34.17.28 to i32
  %xor36.17.28 = xor i32 %xor.17.28, %conv35.17.28
  %conv37.17.28 = trunc i32 %xor36.17.28 to i8
  store i8 %conv37.17.28, i8* %scevgep41.17.27, align 1
  %scevgep28.17.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6470, i64 0, i64 0, i64 1
  %6477 = bitcast i8* %scevgep28.17.28 to [61 x [61 x i8]]*
  %scevgep41.17.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6471, i64 0, i64 1, i64 0
  %6478 = bitcast i8* %scevgep41.17.28 to [61 x [61 x i8]]*
  %call16.17.29 = call zeroext i8 (...) @rand()
  store i8 %call16.17.29, i8* %scevgep28.17.28, align 1
  %6479 = load i8, i8* %scevgep28.17.28, align 1
  %conv23.17.29 = zext i8 %6479 to i32
  %6480 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.29 = getelementptr i8, i8* %b, i64 47
  %6481 = load i8, i8* %scevgep34.17.29, align 1
  %call28.17.29 = call zeroext i8 @mult(i8 zeroext %6480, i8 zeroext %6481)
  %conv29.17.29 = zext i8 %call28.17.29 to i32
  %xor.17.29 = xor i32 %conv23.17.29, %conv29.17.29
  %scevgep35.17.29 = getelementptr i8, i8* %a, i64 47
  %6482 = load i8, i8* %scevgep35.17.29, align 1
  %6483 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.29 = call zeroext i8 @mult(i8 zeroext %6482, i8 zeroext %6483)
  %conv35.17.29 = zext i8 %call34.17.29 to i32
  %xor36.17.29 = xor i32 %xor.17.29, %conv35.17.29
  %conv37.17.29 = trunc i32 %xor36.17.29 to i8
  store i8 %conv37.17.29, i8* %scevgep41.17.28, align 1
  %scevgep28.17.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6477, i64 0, i64 0, i64 1
  %6484 = bitcast i8* %scevgep28.17.29 to [61 x [61 x i8]]*
  %scevgep41.17.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6478, i64 0, i64 1, i64 0
  %6485 = bitcast i8* %scevgep41.17.29 to [61 x [61 x i8]]*
  %call16.17.30 = call zeroext i8 (...) @rand()
  store i8 %call16.17.30, i8* %scevgep28.17.29, align 1
  %6486 = load i8, i8* %scevgep28.17.29, align 1
  %conv23.17.30 = zext i8 %6486 to i32
  %6487 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.30 = getelementptr i8, i8* %b, i64 48
  %6488 = load i8, i8* %scevgep34.17.30, align 1
  %call28.17.30 = call zeroext i8 @mult(i8 zeroext %6487, i8 zeroext %6488)
  %conv29.17.30 = zext i8 %call28.17.30 to i32
  %xor.17.30 = xor i32 %conv23.17.30, %conv29.17.30
  %scevgep35.17.30 = getelementptr i8, i8* %a, i64 48
  %6489 = load i8, i8* %scevgep35.17.30, align 1
  %6490 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.30 = call zeroext i8 @mult(i8 zeroext %6489, i8 zeroext %6490)
  %conv35.17.30 = zext i8 %call34.17.30 to i32
  %xor36.17.30 = xor i32 %xor.17.30, %conv35.17.30
  %conv37.17.30 = trunc i32 %xor36.17.30 to i8
  store i8 %conv37.17.30, i8* %scevgep41.17.29, align 1
  %scevgep28.17.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6484, i64 0, i64 0, i64 1
  %6491 = bitcast i8* %scevgep28.17.30 to [61 x [61 x i8]]*
  %scevgep41.17.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6485, i64 0, i64 1, i64 0
  %6492 = bitcast i8* %scevgep41.17.30 to [61 x [61 x i8]]*
  %call16.17.31 = call zeroext i8 (...) @rand()
  store i8 %call16.17.31, i8* %scevgep28.17.30, align 1
  %6493 = load i8, i8* %scevgep28.17.30, align 1
  %conv23.17.31 = zext i8 %6493 to i32
  %6494 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.31 = getelementptr i8, i8* %b, i64 49
  %6495 = load i8, i8* %scevgep34.17.31, align 1
  %call28.17.31 = call zeroext i8 @mult(i8 zeroext %6494, i8 zeroext %6495)
  %conv29.17.31 = zext i8 %call28.17.31 to i32
  %xor.17.31 = xor i32 %conv23.17.31, %conv29.17.31
  %scevgep35.17.31 = getelementptr i8, i8* %a, i64 49
  %6496 = load i8, i8* %scevgep35.17.31, align 1
  %6497 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.31 = call zeroext i8 @mult(i8 zeroext %6496, i8 zeroext %6497)
  %conv35.17.31 = zext i8 %call34.17.31 to i32
  %xor36.17.31 = xor i32 %xor.17.31, %conv35.17.31
  %conv37.17.31 = trunc i32 %xor36.17.31 to i8
  store i8 %conv37.17.31, i8* %scevgep41.17.30, align 1
  %scevgep28.17.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6491, i64 0, i64 0, i64 1
  %6498 = bitcast i8* %scevgep28.17.31 to [61 x [61 x i8]]*
  %scevgep41.17.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6492, i64 0, i64 1, i64 0
  %6499 = bitcast i8* %scevgep41.17.31 to [61 x [61 x i8]]*
  %call16.17.32 = call zeroext i8 (...) @rand()
  store i8 %call16.17.32, i8* %scevgep28.17.31, align 1
  %6500 = load i8, i8* %scevgep28.17.31, align 1
  %conv23.17.32 = zext i8 %6500 to i32
  %6501 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.32 = getelementptr i8, i8* %b, i64 50
  %6502 = load i8, i8* %scevgep34.17.32, align 1
  %call28.17.32 = call zeroext i8 @mult(i8 zeroext %6501, i8 zeroext %6502)
  %conv29.17.32 = zext i8 %call28.17.32 to i32
  %xor.17.32 = xor i32 %conv23.17.32, %conv29.17.32
  %scevgep35.17.32 = getelementptr i8, i8* %a, i64 50
  %6503 = load i8, i8* %scevgep35.17.32, align 1
  %6504 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.32 = call zeroext i8 @mult(i8 zeroext %6503, i8 zeroext %6504)
  %conv35.17.32 = zext i8 %call34.17.32 to i32
  %xor36.17.32 = xor i32 %xor.17.32, %conv35.17.32
  %conv37.17.32 = trunc i32 %xor36.17.32 to i8
  store i8 %conv37.17.32, i8* %scevgep41.17.31, align 1
  %scevgep28.17.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6498, i64 0, i64 0, i64 1
  %6505 = bitcast i8* %scevgep28.17.32 to [61 x [61 x i8]]*
  %scevgep41.17.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6499, i64 0, i64 1, i64 0
  %6506 = bitcast i8* %scevgep41.17.32 to [61 x [61 x i8]]*
  %call16.17.33 = call zeroext i8 (...) @rand()
  store i8 %call16.17.33, i8* %scevgep28.17.32, align 1
  %6507 = load i8, i8* %scevgep28.17.32, align 1
  %conv23.17.33 = zext i8 %6507 to i32
  %6508 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.33 = getelementptr i8, i8* %b, i64 51
  %6509 = load i8, i8* %scevgep34.17.33, align 1
  %call28.17.33 = call zeroext i8 @mult(i8 zeroext %6508, i8 zeroext %6509)
  %conv29.17.33 = zext i8 %call28.17.33 to i32
  %xor.17.33 = xor i32 %conv23.17.33, %conv29.17.33
  %scevgep35.17.33 = getelementptr i8, i8* %a, i64 51
  %6510 = load i8, i8* %scevgep35.17.33, align 1
  %6511 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.33 = call zeroext i8 @mult(i8 zeroext %6510, i8 zeroext %6511)
  %conv35.17.33 = zext i8 %call34.17.33 to i32
  %xor36.17.33 = xor i32 %xor.17.33, %conv35.17.33
  %conv37.17.33 = trunc i32 %xor36.17.33 to i8
  store i8 %conv37.17.33, i8* %scevgep41.17.32, align 1
  %scevgep28.17.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6505, i64 0, i64 0, i64 1
  %6512 = bitcast i8* %scevgep28.17.33 to [61 x [61 x i8]]*
  %scevgep41.17.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6506, i64 0, i64 1, i64 0
  %6513 = bitcast i8* %scevgep41.17.33 to [61 x [61 x i8]]*
  %call16.17.34 = call zeroext i8 (...) @rand()
  store i8 %call16.17.34, i8* %scevgep28.17.33, align 1
  %6514 = load i8, i8* %scevgep28.17.33, align 1
  %conv23.17.34 = zext i8 %6514 to i32
  %6515 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.34 = getelementptr i8, i8* %b, i64 52
  %6516 = load i8, i8* %scevgep34.17.34, align 1
  %call28.17.34 = call zeroext i8 @mult(i8 zeroext %6515, i8 zeroext %6516)
  %conv29.17.34 = zext i8 %call28.17.34 to i32
  %xor.17.34 = xor i32 %conv23.17.34, %conv29.17.34
  %scevgep35.17.34 = getelementptr i8, i8* %a, i64 52
  %6517 = load i8, i8* %scevgep35.17.34, align 1
  %6518 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.34 = call zeroext i8 @mult(i8 zeroext %6517, i8 zeroext %6518)
  %conv35.17.34 = zext i8 %call34.17.34 to i32
  %xor36.17.34 = xor i32 %xor.17.34, %conv35.17.34
  %conv37.17.34 = trunc i32 %xor36.17.34 to i8
  store i8 %conv37.17.34, i8* %scevgep41.17.33, align 1
  %scevgep28.17.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6512, i64 0, i64 0, i64 1
  %6519 = bitcast i8* %scevgep28.17.34 to [61 x [61 x i8]]*
  %scevgep41.17.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6513, i64 0, i64 1, i64 0
  %6520 = bitcast i8* %scevgep41.17.34 to [61 x [61 x i8]]*
  %call16.17.35 = call zeroext i8 (...) @rand()
  store i8 %call16.17.35, i8* %scevgep28.17.34, align 1
  %6521 = load i8, i8* %scevgep28.17.34, align 1
  %conv23.17.35 = zext i8 %6521 to i32
  %6522 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.35 = getelementptr i8, i8* %b, i64 53
  %6523 = load i8, i8* %scevgep34.17.35, align 1
  %call28.17.35 = call zeroext i8 @mult(i8 zeroext %6522, i8 zeroext %6523)
  %conv29.17.35 = zext i8 %call28.17.35 to i32
  %xor.17.35 = xor i32 %conv23.17.35, %conv29.17.35
  %scevgep35.17.35 = getelementptr i8, i8* %a, i64 53
  %6524 = load i8, i8* %scevgep35.17.35, align 1
  %6525 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.35 = call zeroext i8 @mult(i8 zeroext %6524, i8 zeroext %6525)
  %conv35.17.35 = zext i8 %call34.17.35 to i32
  %xor36.17.35 = xor i32 %xor.17.35, %conv35.17.35
  %conv37.17.35 = trunc i32 %xor36.17.35 to i8
  store i8 %conv37.17.35, i8* %scevgep41.17.34, align 1
  %scevgep28.17.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6519, i64 0, i64 0, i64 1
  %6526 = bitcast i8* %scevgep28.17.35 to [61 x [61 x i8]]*
  %scevgep41.17.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6520, i64 0, i64 1, i64 0
  %6527 = bitcast i8* %scevgep41.17.35 to [61 x [61 x i8]]*
  %call16.17.36 = call zeroext i8 (...) @rand()
  store i8 %call16.17.36, i8* %scevgep28.17.35, align 1
  %6528 = load i8, i8* %scevgep28.17.35, align 1
  %conv23.17.36 = zext i8 %6528 to i32
  %6529 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.36 = getelementptr i8, i8* %b, i64 54
  %6530 = load i8, i8* %scevgep34.17.36, align 1
  %call28.17.36 = call zeroext i8 @mult(i8 zeroext %6529, i8 zeroext %6530)
  %conv29.17.36 = zext i8 %call28.17.36 to i32
  %xor.17.36 = xor i32 %conv23.17.36, %conv29.17.36
  %scevgep35.17.36 = getelementptr i8, i8* %a, i64 54
  %6531 = load i8, i8* %scevgep35.17.36, align 1
  %6532 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.36 = call zeroext i8 @mult(i8 zeroext %6531, i8 zeroext %6532)
  %conv35.17.36 = zext i8 %call34.17.36 to i32
  %xor36.17.36 = xor i32 %xor.17.36, %conv35.17.36
  %conv37.17.36 = trunc i32 %xor36.17.36 to i8
  store i8 %conv37.17.36, i8* %scevgep41.17.35, align 1
  %scevgep28.17.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6526, i64 0, i64 0, i64 1
  %6533 = bitcast i8* %scevgep28.17.36 to [61 x [61 x i8]]*
  %scevgep41.17.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6527, i64 0, i64 1, i64 0
  %6534 = bitcast i8* %scevgep41.17.36 to [61 x [61 x i8]]*
  %call16.17.37 = call zeroext i8 (...) @rand()
  store i8 %call16.17.37, i8* %scevgep28.17.36, align 1
  %6535 = load i8, i8* %scevgep28.17.36, align 1
  %conv23.17.37 = zext i8 %6535 to i32
  %6536 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.37 = getelementptr i8, i8* %b, i64 55
  %6537 = load i8, i8* %scevgep34.17.37, align 1
  %call28.17.37 = call zeroext i8 @mult(i8 zeroext %6536, i8 zeroext %6537)
  %conv29.17.37 = zext i8 %call28.17.37 to i32
  %xor.17.37 = xor i32 %conv23.17.37, %conv29.17.37
  %scevgep35.17.37 = getelementptr i8, i8* %a, i64 55
  %6538 = load i8, i8* %scevgep35.17.37, align 1
  %6539 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.37 = call zeroext i8 @mult(i8 zeroext %6538, i8 zeroext %6539)
  %conv35.17.37 = zext i8 %call34.17.37 to i32
  %xor36.17.37 = xor i32 %xor.17.37, %conv35.17.37
  %conv37.17.37 = trunc i32 %xor36.17.37 to i8
  store i8 %conv37.17.37, i8* %scevgep41.17.36, align 1
  %scevgep28.17.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6533, i64 0, i64 0, i64 1
  %6540 = bitcast i8* %scevgep28.17.37 to [61 x [61 x i8]]*
  %scevgep41.17.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6534, i64 0, i64 1, i64 0
  %6541 = bitcast i8* %scevgep41.17.37 to [61 x [61 x i8]]*
  %call16.17.38 = call zeroext i8 (...) @rand()
  store i8 %call16.17.38, i8* %scevgep28.17.37, align 1
  %6542 = load i8, i8* %scevgep28.17.37, align 1
  %conv23.17.38 = zext i8 %6542 to i32
  %6543 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.38 = getelementptr i8, i8* %b, i64 56
  %6544 = load i8, i8* %scevgep34.17.38, align 1
  %call28.17.38 = call zeroext i8 @mult(i8 zeroext %6543, i8 zeroext %6544)
  %conv29.17.38 = zext i8 %call28.17.38 to i32
  %xor.17.38 = xor i32 %conv23.17.38, %conv29.17.38
  %scevgep35.17.38 = getelementptr i8, i8* %a, i64 56
  %6545 = load i8, i8* %scevgep35.17.38, align 1
  %6546 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.38 = call zeroext i8 @mult(i8 zeroext %6545, i8 zeroext %6546)
  %conv35.17.38 = zext i8 %call34.17.38 to i32
  %xor36.17.38 = xor i32 %xor.17.38, %conv35.17.38
  %conv37.17.38 = trunc i32 %xor36.17.38 to i8
  store i8 %conv37.17.38, i8* %scevgep41.17.37, align 1
  %scevgep28.17.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6540, i64 0, i64 0, i64 1
  %6547 = bitcast i8* %scevgep28.17.38 to [61 x [61 x i8]]*
  %scevgep41.17.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6541, i64 0, i64 1, i64 0
  %6548 = bitcast i8* %scevgep41.17.38 to [61 x [61 x i8]]*
  %call16.17.39 = call zeroext i8 (...) @rand()
  store i8 %call16.17.39, i8* %scevgep28.17.38, align 1
  %6549 = load i8, i8* %scevgep28.17.38, align 1
  %conv23.17.39 = zext i8 %6549 to i32
  %6550 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.39 = getelementptr i8, i8* %b, i64 57
  %6551 = load i8, i8* %scevgep34.17.39, align 1
  %call28.17.39 = call zeroext i8 @mult(i8 zeroext %6550, i8 zeroext %6551)
  %conv29.17.39 = zext i8 %call28.17.39 to i32
  %xor.17.39 = xor i32 %conv23.17.39, %conv29.17.39
  %scevgep35.17.39 = getelementptr i8, i8* %a, i64 57
  %6552 = load i8, i8* %scevgep35.17.39, align 1
  %6553 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.39 = call zeroext i8 @mult(i8 zeroext %6552, i8 zeroext %6553)
  %conv35.17.39 = zext i8 %call34.17.39 to i32
  %xor36.17.39 = xor i32 %xor.17.39, %conv35.17.39
  %conv37.17.39 = trunc i32 %xor36.17.39 to i8
  store i8 %conv37.17.39, i8* %scevgep41.17.38, align 1
  %scevgep28.17.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6547, i64 0, i64 0, i64 1
  %6554 = bitcast i8* %scevgep28.17.39 to [61 x [61 x i8]]*
  %scevgep41.17.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6548, i64 0, i64 1, i64 0
  %6555 = bitcast i8* %scevgep41.17.39 to [61 x [61 x i8]]*
  %call16.17.40 = call zeroext i8 (...) @rand()
  store i8 %call16.17.40, i8* %scevgep28.17.39, align 1
  %6556 = load i8, i8* %scevgep28.17.39, align 1
  %conv23.17.40 = zext i8 %6556 to i32
  %6557 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.40 = getelementptr i8, i8* %b, i64 58
  %6558 = load i8, i8* %scevgep34.17.40, align 1
  %call28.17.40 = call zeroext i8 @mult(i8 zeroext %6557, i8 zeroext %6558)
  %conv29.17.40 = zext i8 %call28.17.40 to i32
  %xor.17.40 = xor i32 %conv23.17.40, %conv29.17.40
  %scevgep35.17.40 = getelementptr i8, i8* %a, i64 58
  %6559 = load i8, i8* %scevgep35.17.40, align 1
  %6560 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.40 = call zeroext i8 @mult(i8 zeroext %6559, i8 zeroext %6560)
  %conv35.17.40 = zext i8 %call34.17.40 to i32
  %xor36.17.40 = xor i32 %xor.17.40, %conv35.17.40
  %conv37.17.40 = trunc i32 %xor36.17.40 to i8
  store i8 %conv37.17.40, i8* %scevgep41.17.39, align 1
  %scevgep28.17.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6554, i64 0, i64 0, i64 1
  %6561 = bitcast i8* %scevgep28.17.40 to [61 x [61 x i8]]*
  %scevgep41.17.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6555, i64 0, i64 1, i64 0
  %6562 = bitcast i8* %scevgep41.17.40 to [61 x [61 x i8]]*
  %call16.17.41 = call zeroext i8 (...) @rand()
  store i8 %call16.17.41, i8* %scevgep28.17.40, align 1
  %6563 = load i8, i8* %scevgep28.17.40, align 1
  %conv23.17.41 = zext i8 %6563 to i32
  %6564 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.41 = getelementptr i8, i8* %b, i64 59
  %6565 = load i8, i8* %scevgep34.17.41, align 1
  %call28.17.41 = call zeroext i8 @mult(i8 zeroext %6564, i8 zeroext %6565)
  %conv29.17.41 = zext i8 %call28.17.41 to i32
  %xor.17.41 = xor i32 %conv23.17.41, %conv29.17.41
  %scevgep35.17.41 = getelementptr i8, i8* %a, i64 59
  %6566 = load i8, i8* %scevgep35.17.41, align 1
  %6567 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.41 = call zeroext i8 @mult(i8 zeroext %6566, i8 zeroext %6567)
  %conv35.17.41 = zext i8 %call34.17.41 to i32
  %xor36.17.41 = xor i32 %xor.17.41, %conv35.17.41
  %conv37.17.41 = trunc i32 %xor36.17.41 to i8
  store i8 %conv37.17.41, i8* %scevgep41.17.40, align 1
  %scevgep28.17.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6561, i64 0, i64 0, i64 1
  %scevgep41.17.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6562, i64 0, i64 1, i64 0
  %call16.17.42 = call zeroext i8 (...) @rand()
  store i8 %call16.17.42, i8* %scevgep28.17.41, align 1
  %6568 = load i8, i8* %scevgep28.17.41, align 1
  %conv23.17.42 = zext i8 %6568 to i32
  %6569 = load i8, i8* %arrayidx25.17, align 1
  %scevgep34.17.42 = getelementptr i8, i8* %b, i64 60
  %6570 = load i8, i8* %scevgep34.17.42, align 1
  %call28.17.42 = call zeroext i8 @mult(i8 zeroext %6569, i8 zeroext %6570)
  %conv29.17.42 = zext i8 %call28.17.42 to i32
  %xor.17.42 = xor i32 %conv23.17.42, %conv29.17.42
  %scevgep35.17.42 = getelementptr i8, i8* %a, i64 60
  %6571 = load i8, i8* %scevgep35.17.42, align 1
  %6572 = load i8, i8* %arrayidx33.17, align 1
  %call34.17.42 = call zeroext i8 @mult(i8 zeroext %6571, i8 zeroext %6572)
  %conv35.17.42 = zext i8 %call34.17.42 to i32
  %xor36.17.42 = xor i32 %xor.17.42, %conv35.17.42
  %conv37.17.42 = trunc i32 %xor36.17.42 to i8
  store i8 %conv37.17.42, i8* %scevgep41.17.41, align 1
  %scevgep26.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6274, i64 0, i64 1, i64 1
  %6573 = bitcast i8* %scevgep26.17 to [61 x [61 x i8]]*
  %scevgep39.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6275, i64 0, i64 1, i64 1
  %6574 = bitcast i8* %scevgep39.17 to [61 x [61 x i8]]*
  %arrayidx25.18 = getelementptr inbounds i8, i8* %a, i64 18
  %arrayidx33.18 = getelementptr inbounds i8, i8* %b, i64 18
  %call16.18 = call zeroext i8 (...) @rand()
  store i8 %call16.18, i8* %scevgep26.17, align 1
  %6575 = load i8, i8* %scevgep26.17, align 1
  %conv23.18 = zext i8 %6575 to i32
  %6576 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18 = getelementptr i8, i8* %b, i64 19
  %6577 = load i8, i8* %scevgep34.18, align 1
  %call28.18 = call zeroext i8 @mult(i8 zeroext %6576, i8 zeroext %6577)
  %conv29.18 = zext i8 %call28.18 to i32
  %xor.18 = xor i32 %conv23.18, %conv29.18
  %scevgep35.18 = getelementptr i8, i8* %a, i64 19
  %6578 = load i8, i8* %scevgep35.18, align 1
  %6579 = load i8, i8* %arrayidx33.18, align 1
  %call34.18 = call zeroext i8 @mult(i8 zeroext %6578, i8 zeroext %6579)
  %conv35.18 = zext i8 %call34.18 to i32
  %xor36.18 = xor i32 %xor.18, %conv35.18
  %conv37.18 = trunc i32 %xor36.18 to i8
  store i8 %conv37.18, i8* %scevgep39.17, align 1
  %scevgep28.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6573, i64 0, i64 0, i64 1
  %6580 = bitcast i8* %scevgep28.18 to [61 x [61 x i8]]*
  %scevgep41.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6574, i64 0, i64 1, i64 0
  %6581 = bitcast i8* %scevgep41.18 to [61 x [61 x i8]]*
  %call16.18.1 = call zeroext i8 (...) @rand()
  store i8 %call16.18.1, i8* %scevgep28.18, align 1
  %6582 = load i8, i8* %scevgep28.18, align 1
  %conv23.18.1 = zext i8 %6582 to i32
  %6583 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.1 = getelementptr i8, i8* %b, i64 20
  %6584 = load i8, i8* %scevgep34.18.1, align 1
  %call28.18.1 = call zeroext i8 @mult(i8 zeroext %6583, i8 zeroext %6584)
  %conv29.18.1 = zext i8 %call28.18.1 to i32
  %xor.18.1 = xor i32 %conv23.18.1, %conv29.18.1
  %scevgep35.18.1 = getelementptr i8, i8* %a, i64 20
  %6585 = load i8, i8* %scevgep35.18.1, align 1
  %6586 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.1 = call zeroext i8 @mult(i8 zeroext %6585, i8 zeroext %6586)
  %conv35.18.1 = zext i8 %call34.18.1 to i32
  %xor36.18.1 = xor i32 %xor.18.1, %conv35.18.1
  %conv37.18.1 = trunc i32 %xor36.18.1 to i8
  store i8 %conv37.18.1, i8* %scevgep41.18, align 1
  %scevgep28.18.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6580, i64 0, i64 0, i64 1
  %6587 = bitcast i8* %scevgep28.18.1 to [61 x [61 x i8]]*
  %scevgep41.18.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6581, i64 0, i64 1, i64 0
  %6588 = bitcast i8* %scevgep41.18.1 to [61 x [61 x i8]]*
  %call16.18.2 = call zeroext i8 (...) @rand()
  store i8 %call16.18.2, i8* %scevgep28.18.1, align 1
  %6589 = load i8, i8* %scevgep28.18.1, align 1
  %conv23.18.2 = zext i8 %6589 to i32
  %6590 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.2 = getelementptr i8, i8* %b, i64 21
  %6591 = load i8, i8* %scevgep34.18.2, align 1
  %call28.18.2 = call zeroext i8 @mult(i8 zeroext %6590, i8 zeroext %6591)
  %conv29.18.2 = zext i8 %call28.18.2 to i32
  %xor.18.2 = xor i32 %conv23.18.2, %conv29.18.2
  %scevgep35.18.2 = getelementptr i8, i8* %a, i64 21
  %6592 = load i8, i8* %scevgep35.18.2, align 1
  %6593 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.2 = call zeroext i8 @mult(i8 zeroext %6592, i8 zeroext %6593)
  %conv35.18.2 = zext i8 %call34.18.2 to i32
  %xor36.18.2 = xor i32 %xor.18.2, %conv35.18.2
  %conv37.18.2 = trunc i32 %xor36.18.2 to i8
  store i8 %conv37.18.2, i8* %scevgep41.18.1, align 1
  %scevgep28.18.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6587, i64 0, i64 0, i64 1
  %6594 = bitcast i8* %scevgep28.18.2 to [61 x [61 x i8]]*
  %scevgep41.18.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6588, i64 0, i64 1, i64 0
  %6595 = bitcast i8* %scevgep41.18.2 to [61 x [61 x i8]]*
  %call16.18.3 = call zeroext i8 (...) @rand()
  store i8 %call16.18.3, i8* %scevgep28.18.2, align 1
  %6596 = load i8, i8* %scevgep28.18.2, align 1
  %conv23.18.3 = zext i8 %6596 to i32
  %6597 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.3 = getelementptr i8, i8* %b, i64 22
  %6598 = load i8, i8* %scevgep34.18.3, align 1
  %call28.18.3 = call zeroext i8 @mult(i8 zeroext %6597, i8 zeroext %6598)
  %conv29.18.3 = zext i8 %call28.18.3 to i32
  %xor.18.3 = xor i32 %conv23.18.3, %conv29.18.3
  %scevgep35.18.3 = getelementptr i8, i8* %a, i64 22
  %6599 = load i8, i8* %scevgep35.18.3, align 1
  %6600 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.3 = call zeroext i8 @mult(i8 zeroext %6599, i8 zeroext %6600)
  %conv35.18.3 = zext i8 %call34.18.3 to i32
  %xor36.18.3 = xor i32 %xor.18.3, %conv35.18.3
  %conv37.18.3 = trunc i32 %xor36.18.3 to i8
  store i8 %conv37.18.3, i8* %scevgep41.18.2, align 1
  %scevgep28.18.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6594, i64 0, i64 0, i64 1
  %6601 = bitcast i8* %scevgep28.18.3 to [61 x [61 x i8]]*
  %scevgep41.18.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6595, i64 0, i64 1, i64 0
  %6602 = bitcast i8* %scevgep41.18.3 to [61 x [61 x i8]]*
  %call16.18.4 = call zeroext i8 (...) @rand()
  store i8 %call16.18.4, i8* %scevgep28.18.3, align 1
  %6603 = load i8, i8* %scevgep28.18.3, align 1
  %conv23.18.4 = zext i8 %6603 to i32
  %6604 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.4 = getelementptr i8, i8* %b, i64 23
  %6605 = load i8, i8* %scevgep34.18.4, align 1
  %call28.18.4 = call zeroext i8 @mult(i8 zeroext %6604, i8 zeroext %6605)
  %conv29.18.4 = zext i8 %call28.18.4 to i32
  %xor.18.4 = xor i32 %conv23.18.4, %conv29.18.4
  %scevgep35.18.4 = getelementptr i8, i8* %a, i64 23
  %6606 = load i8, i8* %scevgep35.18.4, align 1
  %6607 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.4 = call zeroext i8 @mult(i8 zeroext %6606, i8 zeroext %6607)
  %conv35.18.4 = zext i8 %call34.18.4 to i32
  %xor36.18.4 = xor i32 %xor.18.4, %conv35.18.4
  %conv37.18.4 = trunc i32 %xor36.18.4 to i8
  store i8 %conv37.18.4, i8* %scevgep41.18.3, align 1
  %scevgep28.18.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6601, i64 0, i64 0, i64 1
  %6608 = bitcast i8* %scevgep28.18.4 to [61 x [61 x i8]]*
  %scevgep41.18.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6602, i64 0, i64 1, i64 0
  %6609 = bitcast i8* %scevgep41.18.4 to [61 x [61 x i8]]*
  %call16.18.5 = call zeroext i8 (...) @rand()
  store i8 %call16.18.5, i8* %scevgep28.18.4, align 1
  %6610 = load i8, i8* %scevgep28.18.4, align 1
  %conv23.18.5 = zext i8 %6610 to i32
  %6611 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.5 = getelementptr i8, i8* %b, i64 24
  %6612 = load i8, i8* %scevgep34.18.5, align 1
  %call28.18.5 = call zeroext i8 @mult(i8 zeroext %6611, i8 zeroext %6612)
  %conv29.18.5 = zext i8 %call28.18.5 to i32
  %xor.18.5 = xor i32 %conv23.18.5, %conv29.18.5
  %scevgep35.18.5 = getelementptr i8, i8* %a, i64 24
  %6613 = load i8, i8* %scevgep35.18.5, align 1
  %6614 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.5 = call zeroext i8 @mult(i8 zeroext %6613, i8 zeroext %6614)
  %conv35.18.5 = zext i8 %call34.18.5 to i32
  %xor36.18.5 = xor i32 %xor.18.5, %conv35.18.5
  %conv37.18.5 = trunc i32 %xor36.18.5 to i8
  store i8 %conv37.18.5, i8* %scevgep41.18.4, align 1
  %scevgep28.18.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6608, i64 0, i64 0, i64 1
  %6615 = bitcast i8* %scevgep28.18.5 to [61 x [61 x i8]]*
  %scevgep41.18.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6609, i64 0, i64 1, i64 0
  %6616 = bitcast i8* %scevgep41.18.5 to [61 x [61 x i8]]*
  %call16.18.6 = call zeroext i8 (...) @rand()
  store i8 %call16.18.6, i8* %scevgep28.18.5, align 1
  %6617 = load i8, i8* %scevgep28.18.5, align 1
  %conv23.18.6 = zext i8 %6617 to i32
  %6618 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.6 = getelementptr i8, i8* %b, i64 25
  %6619 = load i8, i8* %scevgep34.18.6, align 1
  %call28.18.6 = call zeroext i8 @mult(i8 zeroext %6618, i8 zeroext %6619)
  %conv29.18.6 = zext i8 %call28.18.6 to i32
  %xor.18.6 = xor i32 %conv23.18.6, %conv29.18.6
  %scevgep35.18.6 = getelementptr i8, i8* %a, i64 25
  %6620 = load i8, i8* %scevgep35.18.6, align 1
  %6621 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.6 = call zeroext i8 @mult(i8 zeroext %6620, i8 zeroext %6621)
  %conv35.18.6 = zext i8 %call34.18.6 to i32
  %xor36.18.6 = xor i32 %xor.18.6, %conv35.18.6
  %conv37.18.6 = trunc i32 %xor36.18.6 to i8
  store i8 %conv37.18.6, i8* %scevgep41.18.5, align 1
  %scevgep28.18.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6615, i64 0, i64 0, i64 1
  %6622 = bitcast i8* %scevgep28.18.6 to [61 x [61 x i8]]*
  %scevgep41.18.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6616, i64 0, i64 1, i64 0
  %6623 = bitcast i8* %scevgep41.18.6 to [61 x [61 x i8]]*
  %call16.18.7 = call zeroext i8 (...) @rand()
  store i8 %call16.18.7, i8* %scevgep28.18.6, align 1
  %6624 = load i8, i8* %scevgep28.18.6, align 1
  %conv23.18.7 = zext i8 %6624 to i32
  %6625 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.7 = getelementptr i8, i8* %b, i64 26
  %6626 = load i8, i8* %scevgep34.18.7, align 1
  %call28.18.7 = call zeroext i8 @mult(i8 zeroext %6625, i8 zeroext %6626)
  %conv29.18.7 = zext i8 %call28.18.7 to i32
  %xor.18.7 = xor i32 %conv23.18.7, %conv29.18.7
  %scevgep35.18.7 = getelementptr i8, i8* %a, i64 26
  %6627 = load i8, i8* %scevgep35.18.7, align 1
  %6628 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.7 = call zeroext i8 @mult(i8 zeroext %6627, i8 zeroext %6628)
  %conv35.18.7 = zext i8 %call34.18.7 to i32
  %xor36.18.7 = xor i32 %xor.18.7, %conv35.18.7
  %conv37.18.7 = trunc i32 %xor36.18.7 to i8
  store i8 %conv37.18.7, i8* %scevgep41.18.6, align 1
  %scevgep28.18.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6622, i64 0, i64 0, i64 1
  %6629 = bitcast i8* %scevgep28.18.7 to [61 x [61 x i8]]*
  %scevgep41.18.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6623, i64 0, i64 1, i64 0
  %6630 = bitcast i8* %scevgep41.18.7 to [61 x [61 x i8]]*
  %call16.18.8 = call zeroext i8 (...) @rand()
  store i8 %call16.18.8, i8* %scevgep28.18.7, align 1
  %6631 = load i8, i8* %scevgep28.18.7, align 1
  %conv23.18.8 = zext i8 %6631 to i32
  %6632 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.8 = getelementptr i8, i8* %b, i64 27
  %6633 = load i8, i8* %scevgep34.18.8, align 1
  %call28.18.8 = call zeroext i8 @mult(i8 zeroext %6632, i8 zeroext %6633)
  %conv29.18.8 = zext i8 %call28.18.8 to i32
  %xor.18.8 = xor i32 %conv23.18.8, %conv29.18.8
  %scevgep35.18.8 = getelementptr i8, i8* %a, i64 27
  %6634 = load i8, i8* %scevgep35.18.8, align 1
  %6635 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.8 = call zeroext i8 @mult(i8 zeroext %6634, i8 zeroext %6635)
  %conv35.18.8 = zext i8 %call34.18.8 to i32
  %xor36.18.8 = xor i32 %xor.18.8, %conv35.18.8
  %conv37.18.8 = trunc i32 %xor36.18.8 to i8
  store i8 %conv37.18.8, i8* %scevgep41.18.7, align 1
  %scevgep28.18.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6629, i64 0, i64 0, i64 1
  %6636 = bitcast i8* %scevgep28.18.8 to [61 x [61 x i8]]*
  %scevgep41.18.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6630, i64 0, i64 1, i64 0
  %6637 = bitcast i8* %scevgep41.18.8 to [61 x [61 x i8]]*
  %call16.18.9 = call zeroext i8 (...) @rand()
  store i8 %call16.18.9, i8* %scevgep28.18.8, align 1
  %6638 = load i8, i8* %scevgep28.18.8, align 1
  %conv23.18.9 = zext i8 %6638 to i32
  %6639 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.9 = getelementptr i8, i8* %b, i64 28
  %6640 = load i8, i8* %scevgep34.18.9, align 1
  %call28.18.9 = call zeroext i8 @mult(i8 zeroext %6639, i8 zeroext %6640)
  %conv29.18.9 = zext i8 %call28.18.9 to i32
  %xor.18.9 = xor i32 %conv23.18.9, %conv29.18.9
  %scevgep35.18.9 = getelementptr i8, i8* %a, i64 28
  %6641 = load i8, i8* %scevgep35.18.9, align 1
  %6642 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.9 = call zeroext i8 @mult(i8 zeroext %6641, i8 zeroext %6642)
  %conv35.18.9 = zext i8 %call34.18.9 to i32
  %xor36.18.9 = xor i32 %xor.18.9, %conv35.18.9
  %conv37.18.9 = trunc i32 %xor36.18.9 to i8
  store i8 %conv37.18.9, i8* %scevgep41.18.8, align 1
  %scevgep28.18.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6636, i64 0, i64 0, i64 1
  %6643 = bitcast i8* %scevgep28.18.9 to [61 x [61 x i8]]*
  %scevgep41.18.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6637, i64 0, i64 1, i64 0
  %6644 = bitcast i8* %scevgep41.18.9 to [61 x [61 x i8]]*
  %call16.18.10 = call zeroext i8 (...) @rand()
  store i8 %call16.18.10, i8* %scevgep28.18.9, align 1
  %6645 = load i8, i8* %scevgep28.18.9, align 1
  %conv23.18.10 = zext i8 %6645 to i32
  %6646 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.10 = getelementptr i8, i8* %b, i64 29
  %6647 = load i8, i8* %scevgep34.18.10, align 1
  %call28.18.10 = call zeroext i8 @mult(i8 zeroext %6646, i8 zeroext %6647)
  %conv29.18.10 = zext i8 %call28.18.10 to i32
  %xor.18.10 = xor i32 %conv23.18.10, %conv29.18.10
  %scevgep35.18.10 = getelementptr i8, i8* %a, i64 29
  %6648 = load i8, i8* %scevgep35.18.10, align 1
  %6649 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.10 = call zeroext i8 @mult(i8 zeroext %6648, i8 zeroext %6649)
  %conv35.18.10 = zext i8 %call34.18.10 to i32
  %xor36.18.10 = xor i32 %xor.18.10, %conv35.18.10
  %conv37.18.10 = trunc i32 %xor36.18.10 to i8
  store i8 %conv37.18.10, i8* %scevgep41.18.9, align 1
  %scevgep28.18.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6643, i64 0, i64 0, i64 1
  %6650 = bitcast i8* %scevgep28.18.10 to [61 x [61 x i8]]*
  %scevgep41.18.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6644, i64 0, i64 1, i64 0
  %6651 = bitcast i8* %scevgep41.18.10 to [61 x [61 x i8]]*
  %call16.18.11 = call zeroext i8 (...) @rand()
  store i8 %call16.18.11, i8* %scevgep28.18.10, align 1
  %6652 = load i8, i8* %scevgep28.18.10, align 1
  %conv23.18.11 = zext i8 %6652 to i32
  %6653 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.11 = getelementptr i8, i8* %b, i64 30
  %6654 = load i8, i8* %scevgep34.18.11, align 1
  %call28.18.11 = call zeroext i8 @mult(i8 zeroext %6653, i8 zeroext %6654)
  %conv29.18.11 = zext i8 %call28.18.11 to i32
  %xor.18.11 = xor i32 %conv23.18.11, %conv29.18.11
  %scevgep35.18.11 = getelementptr i8, i8* %a, i64 30
  %6655 = load i8, i8* %scevgep35.18.11, align 1
  %6656 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.11 = call zeroext i8 @mult(i8 zeroext %6655, i8 zeroext %6656)
  %conv35.18.11 = zext i8 %call34.18.11 to i32
  %xor36.18.11 = xor i32 %xor.18.11, %conv35.18.11
  %conv37.18.11 = trunc i32 %xor36.18.11 to i8
  store i8 %conv37.18.11, i8* %scevgep41.18.10, align 1
  %scevgep28.18.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6650, i64 0, i64 0, i64 1
  %6657 = bitcast i8* %scevgep28.18.11 to [61 x [61 x i8]]*
  %scevgep41.18.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6651, i64 0, i64 1, i64 0
  %6658 = bitcast i8* %scevgep41.18.11 to [61 x [61 x i8]]*
  %call16.18.12 = call zeroext i8 (...) @rand()
  store i8 %call16.18.12, i8* %scevgep28.18.11, align 1
  %6659 = load i8, i8* %scevgep28.18.11, align 1
  %conv23.18.12 = zext i8 %6659 to i32
  %6660 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.12 = getelementptr i8, i8* %b, i64 31
  %6661 = load i8, i8* %scevgep34.18.12, align 1
  %call28.18.12 = call zeroext i8 @mult(i8 zeroext %6660, i8 zeroext %6661)
  %conv29.18.12 = zext i8 %call28.18.12 to i32
  %xor.18.12 = xor i32 %conv23.18.12, %conv29.18.12
  %scevgep35.18.12 = getelementptr i8, i8* %a, i64 31
  %6662 = load i8, i8* %scevgep35.18.12, align 1
  %6663 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.12 = call zeroext i8 @mult(i8 zeroext %6662, i8 zeroext %6663)
  %conv35.18.12 = zext i8 %call34.18.12 to i32
  %xor36.18.12 = xor i32 %xor.18.12, %conv35.18.12
  %conv37.18.12 = trunc i32 %xor36.18.12 to i8
  store i8 %conv37.18.12, i8* %scevgep41.18.11, align 1
  %scevgep28.18.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6657, i64 0, i64 0, i64 1
  %6664 = bitcast i8* %scevgep28.18.12 to [61 x [61 x i8]]*
  %scevgep41.18.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6658, i64 0, i64 1, i64 0
  %6665 = bitcast i8* %scevgep41.18.12 to [61 x [61 x i8]]*
  %call16.18.13 = call zeroext i8 (...) @rand()
  store i8 %call16.18.13, i8* %scevgep28.18.12, align 1
  %6666 = load i8, i8* %scevgep28.18.12, align 1
  %conv23.18.13 = zext i8 %6666 to i32
  %6667 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.13 = getelementptr i8, i8* %b, i64 32
  %6668 = load i8, i8* %scevgep34.18.13, align 1
  %call28.18.13 = call zeroext i8 @mult(i8 zeroext %6667, i8 zeroext %6668)
  %conv29.18.13 = zext i8 %call28.18.13 to i32
  %xor.18.13 = xor i32 %conv23.18.13, %conv29.18.13
  %scevgep35.18.13 = getelementptr i8, i8* %a, i64 32
  %6669 = load i8, i8* %scevgep35.18.13, align 1
  %6670 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.13 = call zeroext i8 @mult(i8 zeroext %6669, i8 zeroext %6670)
  %conv35.18.13 = zext i8 %call34.18.13 to i32
  %xor36.18.13 = xor i32 %xor.18.13, %conv35.18.13
  %conv37.18.13 = trunc i32 %xor36.18.13 to i8
  store i8 %conv37.18.13, i8* %scevgep41.18.12, align 1
  %scevgep28.18.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6664, i64 0, i64 0, i64 1
  %6671 = bitcast i8* %scevgep28.18.13 to [61 x [61 x i8]]*
  %scevgep41.18.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6665, i64 0, i64 1, i64 0
  %6672 = bitcast i8* %scevgep41.18.13 to [61 x [61 x i8]]*
  %call16.18.14 = call zeroext i8 (...) @rand()
  store i8 %call16.18.14, i8* %scevgep28.18.13, align 1
  %6673 = load i8, i8* %scevgep28.18.13, align 1
  %conv23.18.14 = zext i8 %6673 to i32
  %6674 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.14 = getelementptr i8, i8* %b, i64 33
  %6675 = load i8, i8* %scevgep34.18.14, align 1
  %call28.18.14 = call zeroext i8 @mult(i8 zeroext %6674, i8 zeroext %6675)
  %conv29.18.14 = zext i8 %call28.18.14 to i32
  %xor.18.14 = xor i32 %conv23.18.14, %conv29.18.14
  %scevgep35.18.14 = getelementptr i8, i8* %a, i64 33
  %6676 = load i8, i8* %scevgep35.18.14, align 1
  %6677 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.14 = call zeroext i8 @mult(i8 zeroext %6676, i8 zeroext %6677)
  %conv35.18.14 = zext i8 %call34.18.14 to i32
  %xor36.18.14 = xor i32 %xor.18.14, %conv35.18.14
  %conv37.18.14 = trunc i32 %xor36.18.14 to i8
  store i8 %conv37.18.14, i8* %scevgep41.18.13, align 1
  %scevgep28.18.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6671, i64 0, i64 0, i64 1
  %6678 = bitcast i8* %scevgep28.18.14 to [61 x [61 x i8]]*
  %scevgep41.18.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6672, i64 0, i64 1, i64 0
  %6679 = bitcast i8* %scevgep41.18.14 to [61 x [61 x i8]]*
  %call16.18.15 = call zeroext i8 (...) @rand()
  store i8 %call16.18.15, i8* %scevgep28.18.14, align 1
  %6680 = load i8, i8* %scevgep28.18.14, align 1
  %conv23.18.15 = zext i8 %6680 to i32
  %6681 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.15 = getelementptr i8, i8* %b, i64 34
  %6682 = load i8, i8* %scevgep34.18.15, align 1
  %call28.18.15 = call zeroext i8 @mult(i8 zeroext %6681, i8 zeroext %6682)
  %conv29.18.15 = zext i8 %call28.18.15 to i32
  %xor.18.15 = xor i32 %conv23.18.15, %conv29.18.15
  %scevgep35.18.15 = getelementptr i8, i8* %a, i64 34
  %6683 = load i8, i8* %scevgep35.18.15, align 1
  %6684 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.15 = call zeroext i8 @mult(i8 zeroext %6683, i8 zeroext %6684)
  %conv35.18.15 = zext i8 %call34.18.15 to i32
  %xor36.18.15 = xor i32 %xor.18.15, %conv35.18.15
  %conv37.18.15 = trunc i32 %xor36.18.15 to i8
  store i8 %conv37.18.15, i8* %scevgep41.18.14, align 1
  %scevgep28.18.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6678, i64 0, i64 0, i64 1
  %6685 = bitcast i8* %scevgep28.18.15 to [61 x [61 x i8]]*
  %scevgep41.18.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6679, i64 0, i64 1, i64 0
  %6686 = bitcast i8* %scevgep41.18.15 to [61 x [61 x i8]]*
  %call16.18.16 = call zeroext i8 (...) @rand()
  store i8 %call16.18.16, i8* %scevgep28.18.15, align 1
  %6687 = load i8, i8* %scevgep28.18.15, align 1
  %conv23.18.16 = zext i8 %6687 to i32
  %6688 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.16 = getelementptr i8, i8* %b, i64 35
  %6689 = load i8, i8* %scevgep34.18.16, align 1
  %call28.18.16 = call zeroext i8 @mult(i8 zeroext %6688, i8 zeroext %6689)
  %conv29.18.16 = zext i8 %call28.18.16 to i32
  %xor.18.16 = xor i32 %conv23.18.16, %conv29.18.16
  %scevgep35.18.16 = getelementptr i8, i8* %a, i64 35
  %6690 = load i8, i8* %scevgep35.18.16, align 1
  %6691 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.16 = call zeroext i8 @mult(i8 zeroext %6690, i8 zeroext %6691)
  %conv35.18.16 = zext i8 %call34.18.16 to i32
  %xor36.18.16 = xor i32 %xor.18.16, %conv35.18.16
  %conv37.18.16 = trunc i32 %xor36.18.16 to i8
  store i8 %conv37.18.16, i8* %scevgep41.18.15, align 1
  %scevgep28.18.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6685, i64 0, i64 0, i64 1
  %6692 = bitcast i8* %scevgep28.18.16 to [61 x [61 x i8]]*
  %scevgep41.18.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6686, i64 0, i64 1, i64 0
  %6693 = bitcast i8* %scevgep41.18.16 to [61 x [61 x i8]]*
  %call16.18.17 = call zeroext i8 (...) @rand()
  store i8 %call16.18.17, i8* %scevgep28.18.16, align 1
  %6694 = load i8, i8* %scevgep28.18.16, align 1
  %conv23.18.17 = zext i8 %6694 to i32
  %6695 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.17 = getelementptr i8, i8* %b, i64 36
  %6696 = load i8, i8* %scevgep34.18.17, align 1
  %call28.18.17 = call zeroext i8 @mult(i8 zeroext %6695, i8 zeroext %6696)
  %conv29.18.17 = zext i8 %call28.18.17 to i32
  %xor.18.17 = xor i32 %conv23.18.17, %conv29.18.17
  %scevgep35.18.17 = getelementptr i8, i8* %a, i64 36
  %6697 = load i8, i8* %scevgep35.18.17, align 1
  %6698 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.17 = call zeroext i8 @mult(i8 zeroext %6697, i8 zeroext %6698)
  %conv35.18.17 = zext i8 %call34.18.17 to i32
  %xor36.18.17 = xor i32 %xor.18.17, %conv35.18.17
  %conv37.18.17 = trunc i32 %xor36.18.17 to i8
  store i8 %conv37.18.17, i8* %scevgep41.18.16, align 1
  %scevgep28.18.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6692, i64 0, i64 0, i64 1
  %6699 = bitcast i8* %scevgep28.18.17 to [61 x [61 x i8]]*
  %scevgep41.18.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6693, i64 0, i64 1, i64 0
  %6700 = bitcast i8* %scevgep41.18.17 to [61 x [61 x i8]]*
  %call16.18.18 = call zeroext i8 (...) @rand()
  store i8 %call16.18.18, i8* %scevgep28.18.17, align 1
  %6701 = load i8, i8* %scevgep28.18.17, align 1
  %conv23.18.18 = zext i8 %6701 to i32
  %6702 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.18 = getelementptr i8, i8* %b, i64 37
  %6703 = load i8, i8* %scevgep34.18.18, align 1
  %call28.18.18 = call zeroext i8 @mult(i8 zeroext %6702, i8 zeroext %6703)
  %conv29.18.18 = zext i8 %call28.18.18 to i32
  %xor.18.18 = xor i32 %conv23.18.18, %conv29.18.18
  %scevgep35.18.18 = getelementptr i8, i8* %a, i64 37
  %6704 = load i8, i8* %scevgep35.18.18, align 1
  %6705 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.18 = call zeroext i8 @mult(i8 zeroext %6704, i8 zeroext %6705)
  %conv35.18.18 = zext i8 %call34.18.18 to i32
  %xor36.18.18 = xor i32 %xor.18.18, %conv35.18.18
  %conv37.18.18 = trunc i32 %xor36.18.18 to i8
  store i8 %conv37.18.18, i8* %scevgep41.18.17, align 1
  %scevgep28.18.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6699, i64 0, i64 0, i64 1
  %6706 = bitcast i8* %scevgep28.18.18 to [61 x [61 x i8]]*
  %scevgep41.18.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6700, i64 0, i64 1, i64 0
  %6707 = bitcast i8* %scevgep41.18.18 to [61 x [61 x i8]]*
  %call16.18.19 = call zeroext i8 (...) @rand()
  store i8 %call16.18.19, i8* %scevgep28.18.18, align 1
  %6708 = load i8, i8* %scevgep28.18.18, align 1
  %conv23.18.19 = zext i8 %6708 to i32
  %6709 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.19 = getelementptr i8, i8* %b, i64 38
  %6710 = load i8, i8* %scevgep34.18.19, align 1
  %call28.18.19 = call zeroext i8 @mult(i8 zeroext %6709, i8 zeroext %6710)
  %conv29.18.19 = zext i8 %call28.18.19 to i32
  %xor.18.19 = xor i32 %conv23.18.19, %conv29.18.19
  %scevgep35.18.19 = getelementptr i8, i8* %a, i64 38
  %6711 = load i8, i8* %scevgep35.18.19, align 1
  %6712 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.19 = call zeroext i8 @mult(i8 zeroext %6711, i8 zeroext %6712)
  %conv35.18.19 = zext i8 %call34.18.19 to i32
  %xor36.18.19 = xor i32 %xor.18.19, %conv35.18.19
  %conv37.18.19 = trunc i32 %xor36.18.19 to i8
  store i8 %conv37.18.19, i8* %scevgep41.18.18, align 1
  %scevgep28.18.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6706, i64 0, i64 0, i64 1
  %6713 = bitcast i8* %scevgep28.18.19 to [61 x [61 x i8]]*
  %scevgep41.18.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6707, i64 0, i64 1, i64 0
  %6714 = bitcast i8* %scevgep41.18.19 to [61 x [61 x i8]]*
  %call16.18.20 = call zeroext i8 (...) @rand()
  store i8 %call16.18.20, i8* %scevgep28.18.19, align 1
  %6715 = load i8, i8* %scevgep28.18.19, align 1
  %conv23.18.20 = zext i8 %6715 to i32
  %6716 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.20 = getelementptr i8, i8* %b, i64 39
  %6717 = load i8, i8* %scevgep34.18.20, align 1
  %call28.18.20 = call zeroext i8 @mult(i8 zeroext %6716, i8 zeroext %6717)
  %conv29.18.20 = zext i8 %call28.18.20 to i32
  %xor.18.20 = xor i32 %conv23.18.20, %conv29.18.20
  %scevgep35.18.20 = getelementptr i8, i8* %a, i64 39
  %6718 = load i8, i8* %scevgep35.18.20, align 1
  %6719 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.20 = call zeroext i8 @mult(i8 zeroext %6718, i8 zeroext %6719)
  %conv35.18.20 = zext i8 %call34.18.20 to i32
  %xor36.18.20 = xor i32 %xor.18.20, %conv35.18.20
  %conv37.18.20 = trunc i32 %xor36.18.20 to i8
  store i8 %conv37.18.20, i8* %scevgep41.18.19, align 1
  %scevgep28.18.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6713, i64 0, i64 0, i64 1
  %6720 = bitcast i8* %scevgep28.18.20 to [61 x [61 x i8]]*
  %scevgep41.18.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6714, i64 0, i64 1, i64 0
  %6721 = bitcast i8* %scevgep41.18.20 to [61 x [61 x i8]]*
  %call16.18.21 = call zeroext i8 (...) @rand()
  store i8 %call16.18.21, i8* %scevgep28.18.20, align 1
  %6722 = load i8, i8* %scevgep28.18.20, align 1
  %conv23.18.21 = zext i8 %6722 to i32
  %6723 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.21 = getelementptr i8, i8* %b, i64 40
  %6724 = load i8, i8* %scevgep34.18.21, align 1
  %call28.18.21 = call zeroext i8 @mult(i8 zeroext %6723, i8 zeroext %6724)
  %conv29.18.21 = zext i8 %call28.18.21 to i32
  %xor.18.21 = xor i32 %conv23.18.21, %conv29.18.21
  %scevgep35.18.21 = getelementptr i8, i8* %a, i64 40
  %6725 = load i8, i8* %scevgep35.18.21, align 1
  %6726 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.21 = call zeroext i8 @mult(i8 zeroext %6725, i8 zeroext %6726)
  %conv35.18.21 = zext i8 %call34.18.21 to i32
  %xor36.18.21 = xor i32 %xor.18.21, %conv35.18.21
  %conv37.18.21 = trunc i32 %xor36.18.21 to i8
  store i8 %conv37.18.21, i8* %scevgep41.18.20, align 1
  %scevgep28.18.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6720, i64 0, i64 0, i64 1
  %6727 = bitcast i8* %scevgep28.18.21 to [61 x [61 x i8]]*
  %scevgep41.18.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6721, i64 0, i64 1, i64 0
  %6728 = bitcast i8* %scevgep41.18.21 to [61 x [61 x i8]]*
  %call16.18.22 = call zeroext i8 (...) @rand()
  store i8 %call16.18.22, i8* %scevgep28.18.21, align 1
  %6729 = load i8, i8* %scevgep28.18.21, align 1
  %conv23.18.22 = zext i8 %6729 to i32
  %6730 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.22 = getelementptr i8, i8* %b, i64 41
  %6731 = load i8, i8* %scevgep34.18.22, align 1
  %call28.18.22 = call zeroext i8 @mult(i8 zeroext %6730, i8 zeroext %6731)
  %conv29.18.22 = zext i8 %call28.18.22 to i32
  %xor.18.22 = xor i32 %conv23.18.22, %conv29.18.22
  %scevgep35.18.22 = getelementptr i8, i8* %a, i64 41
  %6732 = load i8, i8* %scevgep35.18.22, align 1
  %6733 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.22 = call zeroext i8 @mult(i8 zeroext %6732, i8 zeroext %6733)
  %conv35.18.22 = zext i8 %call34.18.22 to i32
  %xor36.18.22 = xor i32 %xor.18.22, %conv35.18.22
  %conv37.18.22 = trunc i32 %xor36.18.22 to i8
  store i8 %conv37.18.22, i8* %scevgep41.18.21, align 1
  %scevgep28.18.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6727, i64 0, i64 0, i64 1
  %6734 = bitcast i8* %scevgep28.18.22 to [61 x [61 x i8]]*
  %scevgep41.18.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6728, i64 0, i64 1, i64 0
  %6735 = bitcast i8* %scevgep41.18.22 to [61 x [61 x i8]]*
  %call16.18.23 = call zeroext i8 (...) @rand()
  store i8 %call16.18.23, i8* %scevgep28.18.22, align 1
  %6736 = load i8, i8* %scevgep28.18.22, align 1
  %conv23.18.23 = zext i8 %6736 to i32
  %6737 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.23 = getelementptr i8, i8* %b, i64 42
  %6738 = load i8, i8* %scevgep34.18.23, align 1
  %call28.18.23 = call zeroext i8 @mult(i8 zeroext %6737, i8 zeroext %6738)
  %conv29.18.23 = zext i8 %call28.18.23 to i32
  %xor.18.23 = xor i32 %conv23.18.23, %conv29.18.23
  %scevgep35.18.23 = getelementptr i8, i8* %a, i64 42
  %6739 = load i8, i8* %scevgep35.18.23, align 1
  %6740 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.23 = call zeroext i8 @mult(i8 zeroext %6739, i8 zeroext %6740)
  %conv35.18.23 = zext i8 %call34.18.23 to i32
  %xor36.18.23 = xor i32 %xor.18.23, %conv35.18.23
  %conv37.18.23 = trunc i32 %xor36.18.23 to i8
  store i8 %conv37.18.23, i8* %scevgep41.18.22, align 1
  %scevgep28.18.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6734, i64 0, i64 0, i64 1
  %6741 = bitcast i8* %scevgep28.18.23 to [61 x [61 x i8]]*
  %scevgep41.18.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6735, i64 0, i64 1, i64 0
  %6742 = bitcast i8* %scevgep41.18.23 to [61 x [61 x i8]]*
  %call16.18.24 = call zeroext i8 (...) @rand()
  store i8 %call16.18.24, i8* %scevgep28.18.23, align 1
  %6743 = load i8, i8* %scevgep28.18.23, align 1
  %conv23.18.24 = zext i8 %6743 to i32
  %6744 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.24 = getelementptr i8, i8* %b, i64 43
  %6745 = load i8, i8* %scevgep34.18.24, align 1
  %call28.18.24 = call zeroext i8 @mult(i8 zeroext %6744, i8 zeroext %6745)
  %conv29.18.24 = zext i8 %call28.18.24 to i32
  %xor.18.24 = xor i32 %conv23.18.24, %conv29.18.24
  %scevgep35.18.24 = getelementptr i8, i8* %a, i64 43
  %6746 = load i8, i8* %scevgep35.18.24, align 1
  %6747 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.24 = call zeroext i8 @mult(i8 zeroext %6746, i8 zeroext %6747)
  %conv35.18.24 = zext i8 %call34.18.24 to i32
  %xor36.18.24 = xor i32 %xor.18.24, %conv35.18.24
  %conv37.18.24 = trunc i32 %xor36.18.24 to i8
  store i8 %conv37.18.24, i8* %scevgep41.18.23, align 1
  %scevgep28.18.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6741, i64 0, i64 0, i64 1
  %6748 = bitcast i8* %scevgep28.18.24 to [61 x [61 x i8]]*
  %scevgep41.18.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6742, i64 0, i64 1, i64 0
  %6749 = bitcast i8* %scevgep41.18.24 to [61 x [61 x i8]]*
  %call16.18.25 = call zeroext i8 (...) @rand()
  store i8 %call16.18.25, i8* %scevgep28.18.24, align 1
  %6750 = load i8, i8* %scevgep28.18.24, align 1
  %conv23.18.25 = zext i8 %6750 to i32
  %6751 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.25 = getelementptr i8, i8* %b, i64 44
  %6752 = load i8, i8* %scevgep34.18.25, align 1
  %call28.18.25 = call zeroext i8 @mult(i8 zeroext %6751, i8 zeroext %6752)
  %conv29.18.25 = zext i8 %call28.18.25 to i32
  %xor.18.25 = xor i32 %conv23.18.25, %conv29.18.25
  %scevgep35.18.25 = getelementptr i8, i8* %a, i64 44
  %6753 = load i8, i8* %scevgep35.18.25, align 1
  %6754 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.25 = call zeroext i8 @mult(i8 zeroext %6753, i8 zeroext %6754)
  %conv35.18.25 = zext i8 %call34.18.25 to i32
  %xor36.18.25 = xor i32 %xor.18.25, %conv35.18.25
  %conv37.18.25 = trunc i32 %xor36.18.25 to i8
  store i8 %conv37.18.25, i8* %scevgep41.18.24, align 1
  %scevgep28.18.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6748, i64 0, i64 0, i64 1
  %6755 = bitcast i8* %scevgep28.18.25 to [61 x [61 x i8]]*
  %scevgep41.18.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6749, i64 0, i64 1, i64 0
  %6756 = bitcast i8* %scevgep41.18.25 to [61 x [61 x i8]]*
  %call16.18.26 = call zeroext i8 (...) @rand()
  store i8 %call16.18.26, i8* %scevgep28.18.25, align 1
  %6757 = load i8, i8* %scevgep28.18.25, align 1
  %conv23.18.26 = zext i8 %6757 to i32
  %6758 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.26 = getelementptr i8, i8* %b, i64 45
  %6759 = load i8, i8* %scevgep34.18.26, align 1
  %call28.18.26 = call zeroext i8 @mult(i8 zeroext %6758, i8 zeroext %6759)
  %conv29.18.26 = zext i8 %call28.18.26 to i32
  %xor.18.26 = xor i32 %conv23.18.26, %conv29.18.26
  %scevgep35.18.26 = getelementptr i8, i8* %a, i64 45
  %6760 = load i8, i8* %scevgep35.18.26, align 1
  %6761 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.26 = call zeroext i8 @mult(i8 zeroext %6760, i8 zeroext %6761)
  %conv35.18.26 = zext i8 %call34.18.26 to i32
  %xor36.18.26 = xor i32 %xor.18.26, %conv35.18.26
  %conv37.18.26 = trunc i32 %xor36.18.26 to i8
  store i8 %conv37.18.26, i8* %scevgep41.18.25, align 1
  %scevgep28.18.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6755, i64 0, i64 0, i64 1
  %6762 = bitcast i8* %scevgep28.18.26 to [61 x [61 x i8]]*
  %scevgep41.18.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6756, i64 0, i64 1, i64 0
  %6763 = bitcast i8* %scevgep41.18.26 to [61 x [61 x i8]]*
  %call16.18.27 = call zeroext i8 (...) @rand()
  store i8 %call16.18.27, i8* %scevgep28.18.26, align 1
  %6764 = load i8, i8* %scevgep28.18.26, align 1
  %conv23.18.27 = zext i8 %6764 to i32
  %6765 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.27 = getelementptr i8, i8* %b, i64 46
  %6766 = load i8, i8* %scevgep34.18.27, align 1
  %call28.18.27 = call zeroext i8 @mult(i8 zeroext %6765, i8 zeroext %6766)
  %conv29.18.27 = zext i8 %call28.18.27 to i32
  %xor.18.27 = xor i32 %conv23.18.27, %conv29.18.27
  %scevgep35.18.27 = getelementptr i8, i8* %a, i64 46
  %6767 = load i8, i8* %scevgep35.18.27, align 1
  %6768 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.27 = call zeroext i8 @mult(i8 zeroext %6767, i8 zeroext %6768)
  %conv35.18.27 = zext i8 %call34.18.27 to i32
  %xor36.18.27 = xor i32 %xor.18.27, %conv35.18.27
  %conv37.18.27 = trunc i32 %xor36.18.27 to i8
  store i8 %conv37.18.27, i8* %scevgep41.18.26, align 1
  %scevgep28.18.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6762, i64 0, i64 0, i64 1
  %6769 = bitcast i8* %scevgep28.18.27 to [61 x [61 x i8]]*
  %scevgep41.18.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6763, i64 0, i64 1, i64 0
  %6770 = bitcast i8* %scevgep41.18.27 to [61 x [61 x i8]]*
  %call16.18.28 = call zeroext i8 (...) @rand()
  store i8 %call16.18.28, i8* %scevgep28.18.27, align 1
  %6771 = load i8, i8* %scevgep28.18.27, align 1
  %conv23.18.28 = zext i8 %6771 to i32
  %6772 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.28 = getelementptr i8, i8* %b, i64 47
  %6773 = load i8, i8* %scevgep34.18.28, align 1
  %call28.18.28 = call zeroext i8 @mult(i8 zeroext %6772, i8 zeroext %6773)
  %conv29.18.28 = zext i8 %call28.18.28 to i32
  %xor.18.28 = xor i32 %conv23.18.28, %conv29.18.28
  %scevgep35.18.28 = getelementptr i8, i8* %a, i64 47
  %6774 = load i8, i8* %scevgep35.18.28, align 1
  %6775 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.28 = call zeroext i8 @mult(i8 zeroext %6774, i8 zeroext %6775)
  %conv35.18.28 = zext i8 %call34.18.28 to i32
  %xor36.18.28 = xor i32 %xor.18.28, %conv35.18.28
  %conv37.18.28 = trunc i32 %xor36.18.28 to i8
  store i8 %conv37.18.28, i8* %scevgep41.18.27, align 1
  %scevgep28.18.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6769, i64 0, i64 0, i64 1
  %6776 = bitcast i8* %scevgep28.18.28 to [61 x [61 x i8]]*
  %scevgep41.18.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6770, i64 0, i64 1, i64 0
  %6777 = bitcast i8* %scevgep41.18.28 to [61 x [61 x i8]]*
  %call16.18.29 = call zeroext i8 (...) @rand()
  store i8 %call16.18.29, i8* %scevgep28.18.28, align 1
  %6778 = load i8, i8* %scevgep28.18.28, align 1
  %conv23.18.29 = zext i8 %6778 to i32
  %6779 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.29 = getelementptr i8, i8* %b, i64 48
  %6780 = load i8, i8* %scevgep34.18.29, align 1
  %call28.18.29 = call zeroext i8 @mult(i8 zeroext %6779, i8 zeroext %6780)
  %conv29.18.29 = zext i8 %call28.18.29 to i32
  %xor.18.29 = xor i32 %conv23.18.29, %conv29.18.29
  %scevgep35.18.29 = getelementptr i8, i8* %a, i64 48
  %6781 = load i8, i8* %scevgep35.18.29, align 1
  %6782 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.29 = call zeroext i8 @mult(i8 zeroext %6781, i8 zeroext %6782)
  %conv35.18.29 = zext i8 %call34.18.29 to i32
  %xor36.18.29 = xor i32 %xor.18.29, %conv35.18.29
  %conv37.18.29 = trunc i32 %xor36.18.29 to i8
  store i8 %conv37.18.29, i8* %scevgep41.18.28, align 1
  %scevgep28.18.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6776, i64 0, i64 0, i64 1
  %6783 = bitcast i8* %scevgep28.18.29 to [61 x [61 x i8]]*
  %scevgep41.18.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6777, i64 0, i64 1, i64 0
  %6784 = bitcast i8* %scevgep41.18.29 to [61 x [61 x i8]]*
  %call16.18.30 = call zeroext i8 (...) @rand()
  store i8 %call16.18.30, i8* %scevgep28.18.29, align 1
  %6785 = load i8, i8* %scevgep28.18.29, align 1
  %conv23.18.30 = zext i8 %6785 to i32
  %6786 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.30 = getelementptr i8, i8* %b, i64 49
  %6787 = load i8, i8* %scevgep34.18.30, align 1
  %call28.18.30 = call zeroext i8 @mult(i8 zeroext %6786, i8 zeroext %6787)
  %conv29.18.30 = zext i8 %call28.18.30 to i32
  %xor.18.30 = xor i32 %conv23.18.30, %conv29.18.30
  %scevgep35.18.30 = getelementptr i8, i8* %a, i64 49
  %6788 = load i8, i8* %scevgep35.18.30, align 1
  %6789 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.30 = call zeroext i8 @mult(i8 zeroext %6788, i8 zeroext %6789)
  %conv35.18.30 = zext i8 %call34.18.30 to i32
  %xor36.18.30 = xor i32 %xor.18.30, %conv35.18.30
  %conv37.18.30 = trunc i32 %xor36.18.30 to i8
  store i8 %conv37.18.30, i8* %scevgep41.18.29, align 1
  %scevgep28.18.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6783, i64 0, i64 0, i64 1
  %6790 = bitcast i8* %scevgep28.18.30 to [61 x [61 x i8]]*
  %scevgep41.18.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6784, i64 0, i64 1, i64 0
  %6791 = bitcast i8* %scevgep41.18.30 to [61 x [61 x i8]]*
  %call16.18.31 = call zeroext i8 (...) @rand()
  store i8 %call16.18.31, i8* %scevgep28.18.30, align 1
  %6792 = load i8, i8* %scevgep28.18.30, align 1
  %conv23.18.31 = zext i8 %6792 to i32
  %6793 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.31 = getelementptr i8, i8* %b, i64 50
  %6794 = load i8, i8* %scevgep34.18.31, align 1
  %call28.18.31 = call zeroext i8 @mult(i8 zeroext %6793, i8 zeroext %6794)
  %conv29.18.31 = zext i8 %call28.18.31 to i32
  %xor.18.31 = xor i32 %conv23.18.31, %conv29.18.31
  %scevgep35.18.31 = getelementptr i8, i8* %a, i64 50
  %6795 = load i8, i8* %scevgep35.18.31, align 1
  %6796 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.31 = call zeroext i8 @mult(i8 zeroext %6795, i8 zeroext %6796)
  %conv35.18.31 = zext i8 %call34.18.31 to i32
  %xor36.18.31 = xor i32 %xor.18.31, %conv35.18.31
  %conv37.18.31 = trunc i32 %xor36.18.31 to i8
  store i8 %conv37.18.31, i8* %scevgep41.18.30, align 1
  %scevgep28.18.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6790, i64 0, i64 0, i64 1
  %6797 = bitcast i8* %scevgep28.18.31 to [61 x [61 x i8]]*
  %scevgep41.18.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6791, i64 0, i64 1, i64 0
  %6798 = bitcast i8* %scevgep41.18.31 to [61 x [61 x i8]]*
  %call16.18.32 = call zeroext i8 (...) @rand()
  store i8 %call16.18.32, i8* %scevgep28.18.31, align 1
  %6799 = load i8, i8* %scevgep28.18.31, align 1
  %conv23.18.32 = zext i8 %6799 to i32
  %6800 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.32 = getelementptr i8, i8* %b, i64 51
  %6801 = load i8, i8* %scevgep34.18.32, align 1
  %call28.18.32 = call zeroext i8 @mult(i8 zeroext %6800, i8 zeroext %6801)
  %conv29.18.32 = zext i8 %call28.18.32 to i32
  %xor.18.32 = xor i32 %conv23.18.32, %conv29.18.32
  %scevgep35.18.32 = getelementptr i8, i8* %a, i64 51
  %6802 = load i8, i8* %scevgep35.18.32, align 1
  %6803 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.32 = call zeroext i8 @mult(i8 zeroext %6802, i8 zeroext %6803)
  %conv35.18.32 = zext i8 %call34.18.32 to i32
  %xor36.18.32 = xor i32 %xor.18.32, %conv35.18.32
  %conv37.18.32 = trunc i32 %xor36.18.32 to i8
  store i8 %conv37.18.32, i8* %scevgep41.18.31, align 1
  %scevgep28.18.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6797, i64 0, i64 0, i64 1
  %6804 = bitcast i8* %scevgep28.18.32 to [61 x [61 x i8]]*
  %scevgep41.18.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6798, i64 0, i64 1, i64 0
  %6805 = bitcast i8* %scevgep41.18.32 to [61 x [61 x i8]]*
  %call16.18.33 = call zeroext i8 (...) @rand()
  store i8 %call16.18.33, i8* %scevgep28.18.32, align 1
  %6806 = load i8, i8* %scevgep28.18.32, align 1
  %conv23.18.33 = zext i8 %6806 to i32
  %6807 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.33 = getelementptr i8, i8* %b, i64 52
  %6808 = load i8, i8* %scevgep34.18.33, align 1
  %call28.18.33 = call zeroext i8 @mult(i8 zeroext %6807, i8 zeroext %6808)
  %conv29.18.33 = zext i8 %call28.18.33 to i32
  %xor.18.33 = xor i32 %conv23.18.33, %conv29.18.33
  %scevgep35.18.33 = getelementptr i8, i8* %a, i64 52
  %6809 = load i8, i8* %scevgep35.18.33, align 1
  %6810 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.33 = call zeroext i8 @mult(i8 zeroext %6809, i8 zeroext %6810)
  %conv35.18.33 = zext i8 %call34.18.33 to i32
  %xor36.18.33 = xor i32 %xor.18.33, %conv35.18.33
  %conv37.18.33 = trunc i32 %xor36.18.33 to i8
  store i8 %conv37.18.33, i8* %scevgep41.18.32, align 1
  %scevgep28.18.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6804, i64 0, i64 0, i64 1
  %6811 = bitcast i8* %scevgep28.18.33 to [61 x [61 x i8]]*
  %scevgep41.18.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6805, i64 0, i64 1, i64 0
  %6812 = bitcast i8* %scevgep41.18.33 to [61 x [61 x i8]]*
  %call16.18.34 = call zeroext i8 (...) @rand()
  store i8 %call16.18.34, i8* %scevgep28.18.33, align 1
  %6813 = load i8, i8* %scevgep28.18.33, align 1
  %conv23.18.34 = zext i8 %6813 to i32
  %6814 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.34 = getelementptr i8, i8* %b, i64 53
  %6815 = load i8, i8* %scevgep34.18.34, align 1
  %call28.18.34 = call zeroext i8 @mult(i8 zeroext %6814, i8 zeroext %6815)
  %conv29.18.34 = zext i8 %call28.18.34 to i32
  %xor.18.34 = xor i32 %conv23.18.34, %conv29.18.34
  %scevgep35.18.34 = getelementptr i8, i8* %a, i64 53
  %6816 = load i8, i8* %scevgep35.18.34, align 1
  %6817 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.34 = call zeroext i8 @mult(i8 zeroext %6816, i8 zeroext %6817)
  %conv35.18.34 = zext i8 %call34.18.34 to i32
  %xor36.18.34 = xor i32 %xor.18.34, %conv35.18.34
  %conv37.18.34 = trunc i32 %xor36.18.34 to i8
  store i8 %conv37.18.34, i8* %scevgep41.18.33, align 1
  %scevgep28.18.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6811, i64 0, i64 0, i64 1
  %6818 = bitcast i8* %scevgep28.18.34 to [61 x [61 x i8]]*
  %scevgep41.18.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6812, i64 0, i64 1, i64 0
  %6819 = bitcast i8* %scevgep41.18.34 to [61 x [61 x i8]]*
  %call16.18.35 = call zeroext i8 (...) @rand()
  store i8 %call16.18.35, i8* %scevgep28.18.34, align 1
  %6820 = load i8, i8* %scevgep28.18.34, align 1
  %conv23.18.35 = zext i8 %6820 to i32
  %6821 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.35 = getelementptr i8, i8* %b, i64 54
  %6822 = load i8, i8* %scevgep34.18.35, align 1
  %call28.18.35 = call zeroext i8 @mult(i8 zeroext %6821, i8 zeroext %6822)
  %conv29.18.35 = zext i8 %call28.18.35 to i32
  %xor.18.35 = xor i32 %conv23.18.35, %conv29.18.35
  %scevgep35.18.35 = getelementptr i8, i8* %a, i64 54
  %6823 = load i8, i8* %scevgep35.18.35, align 1
  %6824 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.35 = call zeroext i8 @mult(i8 zeroext %6823, i8 zeroext %6824)
  %conv35.18.35 = zext i8 %call34.18.35 to i32
  %xor36.18.35 = xor i32 %xor.18.35, %conv35.18.35
  %conv37.18.35 = trunc i32 %xor36.18.35 to i8
  store i8 %conv37.18.35, i8* %scevgep41.18.34, align 1
  %scevgep28.18.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6818, i64 0, i64 0, i64 1
  %6825 = bitcast i8* %scevgep28.18.35 to [61 x [61 x i8]]*
  %scevgep41.18.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6819, i64 0, i64 1, i64 0
  %6826 = bitcast i8* %scevgep41.18.35 to [61 x [61 x i8]]*
  %call16.18.36 = call zeroext i8 (...) @rand()
  store i8 %call16.18.36, i8* %scevgep28.18.35, align 1
  %6827 = load i8, i8* %scevgep28.18.35, align 1
  %conv23.18.36 = zext i8 %6827 to i32
  %6828 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.36 = getelementptr i8, i8* %b, i64 55
  %6829 = load i8, i8* %scevgep34.18.36, align 1
  %call28.18.36 = call zeroext i8 @mult(i8 zeroext %6828, i8 zeroext %6829)
  %conv29.18.36 = zext i8 %call28.18.36 to i32
  %xor.18.36 = xor i32 %conv23.18.36, %conv29.18.36
  %scevgep35.18.36 = getelementptr i8, i8* %a, i64 55
  %6830 = load i8, i8* %scevgep35.18.36, align 1
  %6831 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.36 = call zeroext i8 @mult(i8 zeroext %6830, i8 zeroext %6831)
  %conv35.18.36 = zext i8 %call34.18.36 to i32
  %xor36.18.36 = xor i32 %xor.18.36, %conv35.18.36
  %conv37.18.36 = trunc i32 %xor36.18.36 to i8
  store i8 %conv37.18.36, i8* %scevgep41.18.35, align 1
  %scevgep28.18.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6825, i64 0, i64 0, i64 1
  %6832 = bitcast i8* %scevgep28.18.36 to [61 x [61 x i8]]*
  %scevgep41.18.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6826, i64 0, i64 1, i64 0
  %6833 = bitcast i8* %scevgep41.18.36 to [61 x [61 x i8]]*
  %call16.18.37 = call zeroext i8 (...) @rand()
  store i8 %call16.18.37, i8* %scevgep28.18.36, align 1
  %6834 = load i8, i8* %scevgep28.18.36, align 1
  %conv23.18.37 = zext i8 %6834 to i32
  %6835 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.37 = getelementptr i8, i8* %b, i64 56
  %6836 = load i8, i8* %scevgep34.18.37, align 1
  %call28.18.37 = call zeroext i8 @mult(i8 zeroext %6835, i8 zeroext %6836)
  %conv29.18.37 = zext i8 %call28.18.37 to i32
  %xor.18.37 = xor i32 %conv23.18.37, %conv29.18.37
  %scevgep35.18.37 = getelementptr i8, i8* %a, i64 56
  %6837 = load i8, i8* %scevgep35.18.37, align 1
  %6838 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.37 = call zeroext i8 @mult(i8 zeroext %6837, i8 zeroext %6838)
  %conv35.18.37 = zext i8 %call34.18.37 to i32
  %xor36.18.37 = xor i32 %xor.18.37, %conv35.18.37
  %conv37.18.37 = trunc i32 %xor36.18.37 to i8
  store i8 %conv37.18.37, i8* %scevgep41.18.36, align 1
  %scevgep28.18.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6832, i64 0, i64 0, i64 1
  %6839 = bitcast i8* %scevgep28.18.37 to [61 x [61 x i8]]*
  %scevgep41.18.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6833, i64 0, i64 1, i64 0
  %6840 = bitcast i8* %scevgep41.18.37 to [61 x [61 x i8]]*
  %call16.18.38 = call zeroext i8 (...) @rand()
  store i8 %call16.18.38, i8* %scevgep28.18.37, align 1
  %6841 = load i8, i8* %scevgep28.18.37, align 1
  %conv23.18.38 = zext i8 %6841 to i32
  %6842 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.38 = getelementptr i8, i8* %b, i64 57
  %6843 = load i8, i8* %scevgep34.18.38, align 1
  %call28.18.38 = call zeroext i8 @mult(i8 zeroext %6842, i8 zeroext %6843)
  %conv29.18.38 = zext i8 %call28.18.38 to i32
  %xor.18.38 = xor i32 %conv23.18.38, %conv29.18.38
  %scevgep35.18.38 = getelementptr i8, i8* %a, i64 57
  %6844 = load i8, i8* %scevgep35.18.38, align 1
  %6845 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.38 = call zeroext i8 @mult(i8 zeroext %6844, i8 zeroext %6845)
  %conv35.18.38 = zext i8 %call34.18.38 to i32
  %xor36.18.38 = xor i32 %xor.18.38, %conv35.18.38
  %conv37.18.38 = trunc i32 %xor36.18.38 to i8
  store i8 %conv37.18.38, i8* %scevgep41.18.37, align 1
  %scevgep28.18.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6839, i64 0, i64 0, i64 1
  %6846 = bitcast i8* %scevgep28.18.38 to [61 x [61 x i8]]*
  %scevgep41.18.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6840, i64 0, i64 1, i64 0
  %6847 = bitcast i8* %scevgep41.18.38 to [61 x [61 x i8]]*
  %call16.18.39 = call zeroext i8 (...) @rand()
  store i8 %call16.18.39, i8* %scevgep28.18.38, align 1
  %6848 = load i8, i8* %scevgep28.18.38, align 1
  %conv23.18.39 = zext i8 %6848 to i32
  %6849 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.39 = getelementptr i8, i8* %b, i64 58
  %6850 = load i8, i8* %scevgep34.18.39, align 1
  %call28.18.39 = call zeroext i8 @mult(i8 zeroext %6849, i8 zeroext %6850)
  %conv29.18.39 = zext i8 %call28.18.39 to i32
  %xor.18.39 = xor i32 %conv23.18.39, %conv29.18.39
  %scevgep35.18.39 = getelementptr i8, i8* %a, i64 58
  %6851 = load i8, i8* %scevgep35.18.39, align 1
  %6852 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.39 = call zeroext i8 @mult(i8 zeroext %6851, i8 zeroext %6852)
  %conv35.18.39 = zext i8 %call34.18.39 to i32
  %xor36.18.39 = xor i32 %xor.18.39, %conv35.18.39
  %conv37.18.39 = trunc i32 %xor36.18.39 to i8
  store i8 %conv37.18.39, i8* %scevgep41.18.38, align 1
  %scevgep28.18.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6846, i64 0, i64 0, i64 1
  %6853 = bitcast i8* %scevgep28.18.39 to [61 x [61 x i8]]*
  %scevgep41.18.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6847, i64 0, i64 1, i64 0
  %6854 = bitcast i8* %scevgep41.18.39 to [61 x [61 x i8]]*
  %call16.18.40 = call zeroext i8 (...) @rand()
  store i8 %call16.18.40, i8* %scevgep28.18.39, align 1
  %6855 = load i8, i8* %scevgep28.18.39, align 1
  %conv23.18.40 = zext i8 %6855 to i32
  %6856 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.40 = getelementptr i8, i8* %b, i64 59
  %6857 = load i8, i8* %scevgep34.18.40, align 1
  %call28.18.40 = call zeroext i8 @mult(i8 zeroext %6856, i8 zeroext %6857)
  %conv29.18.40 = zext i8 %call28.18.40 to i32
  %xor.18.40 = xor i32 %conv23.18.40, %conv29.18.40
  %scevgep35.18.40 = getelementptr i8, i8* %a, i64 59
  %6858 = load i8, i8* %scevgep35.18.40, align 1
  %6859 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.40 = call zeroext i8 @mult(i8 zeroext %6858, i8 zeroext %6859)
  %conv35.18.40 = zext i8 %call34.18.40 to i32
  %xor36.18.40 = xor i32 %xor.18.40, %conv35.18.40
  %conv37.18.40 = trunc i32 %xor36.18.40 to i8
  store i8 %conv37.18.40, i8* %scevgep41.18.39, align 1
  %scevgep28.18.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6853, i64 0, i64 0, i64 1
  %scevgep41.18.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6854, i64 0, i64 1, i64 0
  %call16.18.41 = call zeroext i8 (...) @rand()
  store i8 %call16.18.41, i8* %scevgep28.18.40, align 1
  %6860 = load i8, i8* %scevgep28.18.40, align 1
  %conv23.18.41 = zext i8 %6860 to i32
  %6861 = load i8, i8* %arrayidx25.18, align 1
  %scevgep34.18.41 = getelementptr i8, i8* %b, i64 60
  %6862 = load i8, i8* %scevgep34.18.41, align 1
  %call28.18.41 = call zeroext i8 @mult(i8 zeroext %6861, i8 zeroext %6862)
  %conv29.18.41 = zext i8 %call28.18.41 to i32
  %xor.18.41 = xor i32 %conv23.18.41, %conv29.18.41
  %scevgep35.18.41 = getelementptr i8, i8* %a, i64 60
  %6863 = load i8, i8* %scevgep35.18.41, align 1
  %6864 = load i8, i8* %arrayidx33.18, align 1
  %call34.18.41 = call zeroext i8 @mult(i8 zeroext %6863, i8 zeroext %6864)
  %conv35.18.41 = zext i8 %call34.18.41 to i32
  %xor36.18.41 = xor i32 %xor.18.41, %conv35.18.41
  %conv37.18.41 = trunc i32 %xor36.18.41 to i8
  store i8 %conv37.18.41, i8* %scevgep41.18.40, align 1
  %scevgep26.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6573, i64 0, i64 1, i64 1
  %6865 = bitcast i8* %scevgep26.18 to [61 x [61 x i8]]*
  %scevgep39.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6574, i64 0, i64 1, i64 1
  %6866 = bitcast i8* %scevgep39.18 to [61 x [61 x i8]]*
  %arrayidx25.19 = getelementptr inbounds i8, i8* %a, i64 19
  %arrayidx33.19 = getelementptr inbounds i8, i8* %b, i64 19
  %call16.19 = call zeroext i8 (...) @rand()
  store i8 %call16.19, i8* %scevgep26.18, align 1
  %6867 = load i8, i8* %scevgep26.18, align 1
  %conv23.19 = zext i8 %6867 to i32
  %6868 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19 = getelementptr i8, i8* %b, i64 20
  %6869 = load i8, i8* %scevgep34.19, align 1
  %call28.19 = call zeroext i8 @mult(i8 zeroext %6868, i8 zeroext %6869)
  %conv29.19 = zext i8 %call28.19 to i32
  %xor.19 = xor i32 %conv23.19, %conv29.19
  %scevgep35.19 = getelementptr i8, i8* %a, i64 20
  %6870 = load i8, i8* %scevgep35.19, align 1
  %6871 = load i8, i8* %arrayidx33.19, align 1
  %call34.19 = call zeroext i8 @mult(i8 zeroext %6870, i8 zeroext %6871)
  %conv35.19 = zext i8 %call34.19 to i32
  %xor36.19 = xor i32 %xor.19, %conv35.19
  %conv37.19 = trunc i32 %xor36.19 to i8
  store i8 %conv37.19, i8* %scevgep39.18, align 1
  %scevgep28.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6865, i64 0, i64 0, i64 1
  %6872 = bitcast i8* %scevgep28.19 to [61 x [61 x i8]]*
  %scevgep41.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6866, i64 0, i64 1, i64 0
  %6873 = bitcast i8* %scevgep41.19 to [61 x [61 x i8]]*
  %call16.19.1 = call zeroext i8 (...) @rand()
  store i8 %call16.19.1, i8* %scevgep28.19, align 1
  %6874 = load i8, i8* %scevgep28.19, align 1
  %conv23.19.1 = zext i8 %6874 to i32
  %6875 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.1 = getelementptr i8, i8* %b, i64 21
  %6876 = load i8, i8* %scevgep34.19.1, align 1
  %call28.19.1 = call zeroext i8 @mult(i8 zeroext %6875, i8 zeroext %6876)
  %conv29.19.1 = zext i8 %call28.19.1 to i32
  %xor.19.1 = xor i32 %conv23.19.1, %conv29.19.1
  %scevgep35.19.1 = getelementptr i8, i8* %a, i64 21
  %6877 = load i8, i8* %scevgep35.19.1, align 1
  %6878 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.1 = call zeroext i8 @mult(i8 zeroext %6877, i8 zeroext %6878)
  %conv35.19.1 = zext i8 %call34.19.1 to i32
  %xor36.19.1 = xor i32 %xor.19.1, %conv35.19.1
  %conv37.19.1 = trunc i32 %xor36.19.1 to i8
  store i8 %conv37.19.1, i8* %scevgep41.19, align 1
  %scevgep28.19.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6872, i64 0, i64 0, i64 1
  %6879 = bitcast i8* %scevgep28.19.1 to [61 x [61 x i8]]*
  %scevgep41.19.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6873, i64 0, i64 1, i64 0
  %6880 = bitcast i8* %scevgep41.19.1 to [61 x [61 x i8]]*
  %call16.19.2 = call zeroext i8 (...) @rand()
  store i8 %call16.19.2, i8* %scevgep28.19.1, align 1
  %6881 = load i8, i8* %scevgep28.19.1, align 1
  %conv23.19.2 = zext i8 %6881 to i32
  %6882 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.2 = getelementptr i8, i8* %b, i64 22
  %6883 = load i8, i8* %scevgep34.19.2, align 1
  %call28.19.2 = call zeroext i8 @mult(i8 zeroext %6882, i8 zeroext %6883)
  %conv29.19.2 = zext i8 %call28.19.2 to i32
  %xor.19.2 = xor i32 %conv23.19.2, %conv29.19.2
  %scevgep35.19.2 = getelementptr i8, i8* %a, i64 22
  %6884 = load i8, i8* %scevgep35.19.2, align 1
  %6885 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.2 = call zeroext i8 @mult(i8 zeroext %6884, i8 zeroext %6885)
  %conv35.19.2 = zext i8 %call34.19.2 to i32
  %xor36.19.2 = xor i32 %xor.19.2, %conv35.19.2
  %conv37.19.2 = trunc i32 %xor36.19.2 to i8
  store i8 %conv37.19.2, i8* %scevgep41.19.1, align 1
  %scevgep28.19.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6879, i64 0, i64 0, i64 1
  %6886 = bitcast i8* %scevgep28.19.2 to [61 x [61 x i8]]*
  %scevgep41.19.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6880, i64 0, i64 1, i64 0
  %6887 = bitcast i8* %scevgep41.19.2 to [61 x [61 x i8]]*
  %call16.19.3 = call zeroext i8 (...) @rand()
  store i8 %call16.19.3, i8* %scevgep28.19.2, align 1
  %6888 = load i8, i8* %scevgep28.19.2, align 1
  %conv23.19.3 = zext i8 %6888 to i32
  %6889 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.3 = getelementptr i8, i8* %b, i64 23
  %6890 = load i8, i8* %scevgep34.19.3, align 1
  %call28.19.3 = call zeroext i8 @mult(i8 zeroext %6889, i8 zeroext %6890)
  %conv29.19.3 = zext i8 %call28.19.3 to i32
  %xor.19.3 = xor i32 %conv23.19.3, %conv29.19.3
  %scevgep35.19.3 = getelementptr i8, i8* %a, i64 23
  %6891 = load i8, i8* %scevgep35.19.3, align 1
  %6892 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.3 = call zeroext i8 @mult(i8 zeroext %6891, i8 zeroext %6892)
  %conv35.19.3 = zext i8 %call34.19.3 to i32
  %xor36.19.3 = xor i32 %xor.19.3, %conv35.19.3
  %conv37.19.3 = trunc i32 %xor36.19.3 to i8
  store i8 %conv37.19.3, i8* %scevgep41.19.2, align 1
  %scevgep28.19.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6886, i64 0, i64 0, i64 1
  %6893 = bitcast i8* %scevgep28.19.3 to [61 x [61 x i8]]*
  %scevgep41.19.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6887, i64 0, i64 1, i64 0
  %6894 = bitcast i8* %scevgep41.19.3 to [61 x [61 x i8]]*
  %call16.19.4 = call zeroext i8 (...) @rand()
  store i8 %call16.19.4, i8* %scevgep28.19.3, align 1
  %6895 = load i8, i8* %scevgep28.19.3, align 1
  %conv23.19.4 = zext i8 %6895 to i32
  %6896 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.4 = getelementptr i8, i8* %b, i64 24
  %6897 = load i8, i8* %scevgep34.19.4, align 1
  %call28.19.4 = call zeroext i8 @mult(i8 zeroext %6896, i8 zeroext %6897)
  %conv29.19.4 = zext i8 %call28.19.4 to i32
  %xor.19.4 = xor i32 %conv23.19.4, %conv29.19.4
  %scevgep35.19.4 = getelementptr i8, i8* %a, i64 24
  %6898 = load i8, i8* %scevgep35.19.4, align 1
  %6899 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.4 = call zeroext i8 @mult(i8 zeroext %6898, i8 zeroext %6899)
  %conv35.19.4 = zext i8 %call34.19.4 to i32
  %xor36.19.4 = xor i32 %xor.19.4, %conv35.19.4
  %conv37.19.4 = trunc i32 %xor36.19.4 to i8
  store i8 %conv37.19.4, i8* %scevgep41.19.3, align 1
  %scevgep28.19.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6893, i64 0, i64 0, i64 1
  %6900 = bitcast i8* %scevgep28.19.4 to [61 x [61 x i8]]*
  %scevgep41.19.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6894, i64 0, i64 1, i64 0
  %6901 = bitcast i8* %scevgep41.19.4 to [61 x [61 x i8]]*
  %call16.19.5 = call zeroext i8 (...) @rand()
  store i8 %call16.19.5, i8* %scevgep28.19.4, align 1
  %6902 = load i8, i8* %scevgep28.19.4, align 1
  %conv23.19.5 = zext i8 %6902 to i32
  %6903 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.5 = getelementptr i8, i8* %b, i64 25
  %6904 = load i8, i8* %scevgep34.19.5, align 1
  %call28.19.5 = call zeroext i8 @mult(i8 zeroext %6903, i8 zeroext %6904)
  %conv29.19.5 = zext i8 %call28.19.5 to i32
  %xor.19.5 = xor i32 %conv23.19.5, %conv29.19.5
  %scevgep35.19.5 = getelementptr i8, i8* %a, i64 25
  %6905 = load i8, i8* %scevgep35.19.5, align 1
  %6906 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.5 = call zeroext i8 @mult(i8 zeroext %6905, i8 zeroext %6906)
  %conv35.19.5 = zext i8 %call34.19.5 to i32
  %xor36.19.5 = xor i32 %xor.19.5, %conv35.19.5
  %conv37.19.5 = trunc i32 %xor36.19.5 to i8
  store i8 %conv37.19.5, i8* %scevgep41.19.4, align 1
  %scevgep28.19.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6900, i64 0, i64 0, i64 1
  %6907 = bitcast i8* %scevgep28.19.5 to [61 x [61 x i8]]*
  %scevgep41.19.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6901, i64 0, i64 1, i64 0
  %6908 = bitcast i8* %scevgep41.19.5 to [61 x [61 x i8]]*
  %call16.19.6 = call zeroext i8 (...) @rand()
  store i8 %call16.19.6, i8* %scevgep28.19.5, align 1
  %6909 = load i8, i8* %scevgep28.19.5, align 1
  %conv23.19.6 = zext i8 %6909 to i32
  %6910 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.6 = getelementptr i8, i8* %b, i64 26
  %6911 = load i8, i8* %scevgep34.19.6, align 1
  %call28.19.6 = call zeroext i8 @mult(i8 zeroext %6910, i8 zeroext %6911)
  %conv29.19.6 = zext i8 %call28.19.6 to i32
  %xor.19.6 = xor i32 %conv23.19.6, %conv29.19.6
  %scevgep35.19.6 = getelementptr i8, i8* %a, i64 26
  %6912 = load i8, i8* %scevgep35.19.6, align 1
  %6913 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.6 = call zeroext i8 @mult(i8 zeroext %6912, i8 zeroext %6913)
  %conv35.19.6 = zext i8 %call34.19.6 to i32
  %xor36.19.6 = xor i32 %xor.19.6, %conv35.19.6
  %conv37.19.6 = trunc i32 %xor36.19.6 to i8
  store i8 %conv37.19.6, i8* %scevgep41.19.5, align 1
  %scevgep28.19.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6907, i64 0, i64 0, i64 1
  %6914 = bitcast i8* %scevgep28.19.6 to [61 x [61 x i8]]*
  %scevgep41.19.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6908, i64 0, i64 1, i64 0
  %6915 = bitcast i8* %scevgep41.19.6 to [61 x [61 x i8]]*
  %call16.19.7 = call zeroext i8 (...) @rand()
  store i8 %call16.19.7, i8* %scevgep28.19.6, align 1
  %6916 = load i8, i8* %scevgep28.19.6, align 1
  %conv23.19.7 = zext i8 %6916 to i32
  %6917 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.7 = getelementptr i8, i8* %b, i64 27
  %6918 = load i8, i8* %scevgep34.19.7, align 1
  %call28.19.7 = call zeroext i8 @mult(i8 zeroext %6917, i8 zeroext %6918)
  %conv29.19.7 = zext i8 %call28.19.7 to i32
  %xor.19.7 = xor i32 %conv23.19.7, %conv29.19.7
  %scevgep35.19.7 = getelementptr i8, i8* %a, i64 27
  %6919 = load i8, i8* %scevgep35.19.7, align 1
  %6920 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.7 = call zeroext i8 @mult(i8 zeroext %6919, i8 zeroext %6920)
  %conv35.19.7 = zext i8 %call34.19.7 to i32
  %xor36.19.7 = xor i32 %xor.19.7, %conv35.19.7
  %conv37.19.7 = trunc i32 %xor36.19.7 to i8
  store i8 %conv37.19.7, i8* %scevgep41.19.6, align 1
  %scevgep28.19.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6914, i64 0, i64 0, i64 1
  %6921 = bitcast i8* %scevgep28.19.7 to [61 x [61 x i8]]*
  %scevgep41.19.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6915, i64 0, i64 1, i64 0
  %6922 = bitcast i8* %scevgep41.19.7 to [61 x [61 x i8]]*
  %call16.19.8 = call zeroext i8 (...) @rand()
  store i8 %call16.19.8, i8* %scevgep28.19.7, align 1
  %6923 = load i8, i8* %scevgep28.19.7, align 1
  %conv23.19.8 = zext i8 %6923 to i32
  %6924 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.8 = getelementptr i8, i8* %b, i64 28
  %6925 = load i8, i8* %scevgep34.19.8, align 1
  %call28.19.8 = call zeroext i8 @mult(i8 zeroext %6924, i8 zeroext %6925)
  %conv29.19.8 = zext i8 %call28.19.8 to i32
  %xor.19.8 = xor i32 %conv23.19.8, %conv29.19.8
  %scevgep35.19.8 = getelementptr i8, i8* %a, i64 28
  %6926 = load i8, i8* %scevgep35.19.8, align 1
  %6927 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.8 = call zeroext i8 @mult(i8 zeroext %6926, i8 zeroext %6927)
  %conv35.19.8 = zext i8 %call34.19.8 to i32
  %xor36.19.8 = xor i32 %xor.19.8, %conv35.19.8
  %conv37.19.8 = trunc i32 %xor36.19.8 to i8
  store i8 %conv37.19.8, i8* %scevgep41.19.7, align 1
  %scevgep28.19.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6921, i64 0, i64 0, i64 1
  %6928 = bitcast i8* %scevgep28.19.8 to [61 x [61 x i8]]*
  %scevgep41.19.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6922, i64 0, i64 1, i64 0
  %6929 = bitcast i8* %scevgep41.19.8 to [61 x [61 x i8]]*
  %call16.19.9 = call zeroext i8 (...) @rand()
  store i8 %call16.19.9, i8* %scevgep28.19.8, align 1
  %6930 = load i8, i8* %scevgep28.19.8, align 1
  %conv23.19.9 = zext i8 %6930 to i32
  %6931 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.9 = getelementptr i8, i8* %b, i64 29
  %6932 = load i8, i8* %scevgep34.19.9, align 1
  %call28.19.9 = call zeroext i8 @mult(i8 zeroext %6931, i8 zeroext %6932)
  %conv29.19.9 = zext i8 %call28.19.9 to i32
  %xor.19.9 = xor i32 %conv23.19.9, %conv29.19.9
  %scevgep35.19.9 = getelementptr i8, i8* %a, i64 29
  %6933 = load i8, i8* %scevgep35.19.9, align 1
  %6934 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.9 = call zeroext i8 @mult(i8 zeroext %6933, i8 zeroext %6934)
  %conv35.19.9 = zext i8 %call34.19.9 to i32
  %xor36.19.9 = xor i32 %xor.19.9, %conv35.19.9
  %conv37.19.9 = trunc i32 %xor36.19.9 to i8
  store i8 %conv37.19.9, i8* %scevgep41.19.8, align 1
  %scevgep28.19.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6928, i64 0, i64 0, i64 1
  %6935 = bitcast i8* %scevgep28.19.9 to [61 x [61 x i8]]*
  %scevgep41.19.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6929, i64 0, i64 1, i64 0
  %6936 = bitcast i8* %scevgep41.19.9 to [61 x [61 x i8]]*
  %call16.19.10 = call zeroext i8 (...) @rand()
  store i8 %call16.19.10, i8* %scevgep28.19.9, align 1
  %6937 = load i8, i8* %scevgep28.19.9, align 1
  %conv23.19.10 = zext i8 %6937 to i32
  %6938 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.10 = getelementptr i8, i8* %b, i64 30
  %6939 = load i8, i8* %scevgep34.19.10, align 1
  %call28.19.10 = call zeroext i8 @mult(i8 zeroext %6938, i8 zeroext %6939)
  %conv29.19.10 = zext i8 %call28.19.10 to i32
  %xor.19.10 = xor i32 %conv23.19.10, %conv29.19.10
  %scevgep35.19.10 = getelementptr i8, i8* %a, i64 30
  %6940 = load i8, i8* %scevgep35.19.10, align 1
  %6941 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.10 = call zeroext i8 @mult(i8 zeroext %6940, i8 zeroext %6941)
  %conv35.19.10 = zext i8 %call34.19.10 to i32
  %xor36.19.10 = xor i32 %xor.19.10, %conv35.19.10
  %conv37.19.10 = trunc i32 %xor36.19.10 to i8
  store i8 %conv37.19.10, i8* %scevgep41.19.9, align 1
  %scevgep28.19.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6935, i64 0, i64 0, i64 1
  %6942 = bitcast i8* %scevgep28.19.10 to [61 x [61 x i8]]*
  %scevgep41.19.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6936, i64 0, i64 1, i64 0
  %6943 = bitcast i8* %scevgep41.19.10 to [61 x [61 x i8]]*
  %call16.19.11 = call zeroext i8 (...) @rand()
  store i8 %call16.19.11, i8* %scevgep28.19.10, align 1
  %6944 = load i8, i8* %scevgep28.19.10, align 1
  %conv23.19.11 = zext i8 %6944 to i32
  %6945 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.11 = getelementptr i8, i8* %b, i64 31
  %6946 = load i8, i8* %scevgep34.19.11, align 1
  %call28.19.11 = call zeroext i8 @mult(i8 zeroext %6945, i8 zeroext %6946)
  %conv29.19.11 = zext i8 %call28.19.11 to i32
  %xor.19.11 = xor i32 %conv23.19.11, %conv29.19.11
  %scevgep35.19.11 = getelementptr i8, i8* %a, i64 31
  %6947 = load i8, i8* %scevgep35.19.11, align 1
  %6948 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.11 = call zeroext i8 @mult(i8 zeroext %6947, i8 zeroext %6948)
  %conv35.19.11 = zext i8 %call34.19.11 to i32
  %xor36.19.11 = xor i32 %xor.19.11, %conv35.19.11
  %conv37.19.11 = trunc i32 %xor36.19.11 to i8
  store i8 %conv37.19.11, i8* %scevgep41.19.10, align 1
  %scevgep28.19.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6942, i64 0, i64 0, i64 1
  %6949 = bitcast i8* %scevgep28.19.11 to [61 x [61 x i8]]*
  %scevgep41.19.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6943, i64 0, i64 1, i64 0
  %6950 = bitcast i8* %scevgep41.19.11 to [61 x [61 x i8]]*
  %call16.19.12 = call zeroext i8 (...) @rand()
  store i8 %call16.19.12, i8* %scevgep28.19.11, align 1
  %6951 = load i8, i8* %scevgep28.19.11, align 1
  %conv23.19.12 = zext i8 %6951 to i32
  %6952 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.12 = getelementptr i8, i8* %b, i64 32
  %6953 = load i8, i8* %scevgep34.19.12, align 1
  %call28.19.12 = call zeroext i8 @mult(i8 zeroext %6952, i8 zeroext %6953)
  %conv29.19.12 = zext i8 %call28.19.12 to i32
  %xor.19.12 = xor i32 %conv23.19.12, %conv29.19.12
  %scevgep35.19.12 = getelementptr i8, i8* %a, i64 32
  %6954 = load i8, i8* %scevgep35.19.12, align 1
  %6955 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.12 = call zeroext i8 @mult(i8 zeroext %6954, i8 zeroext %6955)
  %conv35.19.12 = zext i8 %call34.19.12 to i32
  %xor36.19.12 = xor i32 %xor.19.12, %conv35.19.12
  %conv37.19.12 = trunc i32 %xor36.19.12 to i8
  store i8 %conv37.19.12, i8* %scevgep41.19.11, align 1
  %scevgep28.19.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6949, i64 0, i64 0, i64 1
  %6956 = bitcast i8* %scevgep28.19.12 to [61 x [61 x i8]]*
  %scevgep41.19.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6950, i64 0, i64 1, i64 0
  %6957 = bitcast i8* %scevgep41.19.12 to [61 x [61 x i8]]*
  %call16.19.13 = call zeroext i8 (...) @rand()
  store i8 %call16.19.13, i8* %scevgep28.19.12, align 1
  %6958 = load i8, i8* %scevgep28.19.12, align 1
  %conv23.19.13 = zext i8 %6958 to i32
  %6959 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.13 = getelementptr i8, i8* %b, i64 33
  %6960 = load i8, i8* %scevgep34.19.13, align 1
  %call28.19.13 = call zeroext i8 @mult(i8 zeroext %6959, i8 zeroext %6960)
  %conv29.19.13 = zext i8 %call28.19.13 to i32
  %xor.19.13 = xor i32 %conv23.19.13, %conv29.19.13
  %scevgep35.19.13 = getelementptr i8, i8* %a, i64 33
  %6961 = load i8, i8* %scevgep35.19.13, align 1
  %6962 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.13 = call zeroext i8 @mult(i8 zeroext %6961, i8 zeroext %6962)
  %conv35.19.13 = zext i8 %call34.19.13 to i32
  %xor36.19.13 = xor i32 %xor.19.13, %conv35.19.13
  %conv37.19.13 = trunc i32 %xor36.19.13 to i8
  store i8 %conv37.19.13, i8* %scevgep41.19.12, align 1
  %scevgep28.19.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6956, i64 0, i64 0, i64 1
  %6963 = bitcast i8* %scevgep28.19.13 to [61 x [61 x i8]]*
  %scevgep41.19.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6957, i64 0, i64 1, i64 0
  %6964 = bitcast i8* %scevgep41.19.13 to [61 x [61 x i8]]*
  %call16.19.14 = call zeroext i8 (...) @rand()
  store i8 %call16.19.14, i8* %scevgep28.19.13, align 1
  %6965 = load i8, i8* %scevgep28.19.13, align 1
  %conv23.19.14 = zext i8 %6965 to i32
  %6966 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.14 = getelementptr i8, i8* %b, i64 34
  %6967 = load i8, i8* %scevgep34.19.14, align 1
  %call28.19.14 = call zeroext i8 @mult(i8 zeroext %6966, i8 zeroext %6967)
  %conv29.19.14 = zext i8 %call28.19.14 to i32
  %xor.19.14 = xor i32 %conv23.19.14, %conv29.19.14
  %scevgep35.19.14 = getelementptr i8, i8* %a, i64 34
  %6968 = load i8, i8* %scevgep35.19.14, align 1
  %6969 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.14 = call zeroext i8 @mult(i8 zeroext %6968, i8 zeroext %6969)
  %conv35.19.14 = zext i8 %call34.19.14 to i32
  %xor36.19.14 = xor i32 %xor.19.14, %conv35.19.14
  %conv37.19.14 = trunc i32 %xor36.19.14 to i8
  store i8 %conv37.19.14, i8* %scevgep41.19.13, align 1
  %scevgep28.19.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6963, i64 0, i64 0, i64 1
  %6970 = bitcast i8* %scevgep28.19.14 to [61 x [61 x i8]]*
  %scevgep41.19.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6964, i64 0, i64 1, i64 0
  %6971 = bitcast i8* %scevgep41.19.14 to [61 x [61 x i8]]*
  %call16.19.15 = call zeroext i8 (...) @rand()
  store i8 %call16.19.15, i8* %scevgep28.19.14, align 1
  %6972 = load i8, i8* %scevgep28.19.14, align 1
  %conv23.19.15 = zext i8 %6972 to i32
  %6973 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.15 = getelementptr i8, i8* %b, i64 35
  %6974 = load i8, i8* %scevgep34.19.15, align 1
  %call28.19.15 = call zeroext i8 @mult(i8 zeroext %6973, i8 zeroext %6974)
  %conv29.19.15 = zext i8 %call28.19.15 to i32
  %xor.19.15 = xor i32 %conv23.19.15, %conv29.19.15
  %scevgep35.19.15 = getelementptr i8, i8* %a, i64 35
  %6975 = load i8, i8* %scevgep35.19.15, align 1
  %6976 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.15 = call zeroext i8 @mult(i8 zeroext %6975, i8 zeroext %6976)
  %conv35.19.15 = zext i8 %call34.19.15 to i32
  %xor36.19.15 = xor i32 %xor.19.15, %conv35.19.15
  %conv37.19.15 = trunc i32 %xor36.19.15 to i8
  store i8 %conv37.19.15, i8* %scevgep41.19.14, align 1
  %scevgep28.19.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6970, i64 0, i64 0, i64 1
  %6977 = bitcast i8* %scevgep28.19.15 to [61 x [61 x i8]]*
  %scevgep41.19.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6971, i64 0, i64 1, i64 0
  %6978 = bitcast i8* %scevgep41.19.15 to [61 x [61 x i8]]*
  %call16.19.16 = call zeroext i8 (...) @rand()
  store i8 %call16.19.16, i8* %scevgep28.19.15, align 1
  %6979 = load i8, i8* %scevgep28.19.15, align 1
  %conv23.19.16 = zext i8 %6979 to i32
  %6980 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.16 = getelementptr i8, i8* %b, i64 36
  %6981 = load i8, i8* %scevgep34.19.16, align 1
  %call28.19.16 = call zeroext i8 @mult(i8 zeroext %6980, i8 zeroext %6981)
  %conv29.19.16 = zext i8 %call28.19.16 to i32
  %xor.19.16 = xor i32 %conv23.19.16, %conv29.19.16
  %scevgep35.19.16 = getelementptr i8, i8* %a, i64 36
  %6982 = load i8, i8* %scevgep35.19.16, align 1
  %6983 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.16 = call zeroext i8 @mult(i8 zeroext %6982, i8 zeroext %6983)
  %conv35.19.16 = zext i8 %call34.19.16 to i32
  %xor36.19.16 = xor i32 %xor.19.16, %conv35.19.16
  %conv37.19.16 = trunc i32 %xor36.19.16 to i8
  store i8 %conv37.19.16, i8* %scevgep41.19.15, align 1
  %scevgep28.19.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6977, i64 0, i64 0, i64 1
  %6984 = bitcast i8* %scevgep28.19.16 to [61 x [61 x i8]]*
  %scevgep41.19.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6978, i64 0, i64 1, i64 0
  %6985 = bitcast i8* %scevgep41.19.16 to [61 x [61 x i8]]*
  %call16.19.17 = call zeroext i8 (...) @rand()
  store i8 %call16.19.17, i8* %scevgep28.19.16, align 1
  %6986 = load i8, i8* %scevgep28.19.16, align 1
  %conv23.19.17 = zext i8 %6986 to i32
  %6987 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.17 = getelementptr i8, i8* %b, i64 37
  %6988 = load i8, i8* %scevgep34.19.17, align 1
  %call28.19.17 = call zeroext i8 @mult(i8 zeroext %6987, i8 zeroext %6988)
  %conv29.19.17 = zext i8 %call28.19.17 to i32
  %xor.19.17 = xor i32 %conv23.19.17, %conv29.19.17
  %scevgep35.19.17 = getelementptr i8, i8* %a, i64 37
  %6989 = load i8, i8* %scevgep35.19.17, align 1
  %6990 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.17 = call zeroext i8 @mult(i8 zeroext %6989, i8 zeroext %6990)
  %conv35.19.17 = zext i8 %call34.19.17 to i32
  %xor36.19.17 = xor i32 %xor.19.17, %conv35.19.17
  %conv37.19.17 = trunc i32 %xor36.19.17 to i8
  store i8 %conv37.19.17, i8* %scevgep41.19.16, align 1
  %scevgep28.19.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6984, i64 0, i64 0, i64 1
  %6991 = bitcast i8* %scevgep28.19.17 to [61 x [61 x i8]]*
  %scevgep41.19.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6985, i64 0, i64 1, i64 0
  %6992 = bitcast i8* %scevgep41.19.17 to [61 x [61 x i8]]*
  %call16.19.18 = call zeroext i8 (...) @rand()
  store i8 %call16.19.18, i8* %scevgep28.19.17, align 1
  %6993 = load i8, i8* %scevgep28.19.17, align 1
  %conv23.19.18 = zext i8 %6993 to i32
  %6994 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.18 = getelementptr i8, i8* %b, i64 38
  %6995 = load i8, i8* %scevgep34.19.18, align 1
  %call28.19.18 = call zeroext i8 @mult(i8 zeroext %6994, i8 zeroext %6995)
  %conv29.19.18 = zext i8 %call28.19.18 to i32
  %xor.19.18 = xor i32 %conv23.19.18, %conv29.19.18
  %scevgep35.19.18 = getelementptr i8, i8* %a, i64 38
  %6996 = load i8, i8* %scevgep35.19.18, align 1
  %6997 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.18 = call zeroext i8 @mult(i8 zeroext %6996, i8 zeroext %6997)
  %conv35.19.18 = zext i8 %call34.19.18 to i32
  %xor36.19.18 = xor i32 %xor.19.18, %conv35.19.18
  %conv37.19.18 = trunc i32 %xor36.19.18 to i8
  store i8 %conv37.19.18, i8* %scevgep41.19.17, align 1
  %scevgep28.19.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6991, i64 0, i64 0, i64 1
  %6998 = bitcast i8* %scevgep28.19.18 to [61 x [61 x i8]]*
  %scevgep41.19.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6992, i64 0, i64 1, i64 0
  %6999 = bitcast i8* %scevgep41.19.18 to [61 x [61 x i8]]*
  %call16.19.19 = call zeroext i8 (...) @rand()
  store i8 %call16.19.19, i8* %scevgep28.19.18, align 1
  %7000 = load i8, i8* %scevgep28.19.18, align 1
  %conv23.19.19 = zext i8 %7000 to i32
  %7001 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.19 = getelementptr i8, i8* %b, i64 39
  %7002 = load i8, i8* %scevgep34.19.19, align 1
  %call28.19.19 = call zeroext i8 @mult(i8 zeroext %7001, i8 zeroext %7002)
  %conv29.19.19 = zext i8 %call28.19.19 to i32
  %xor.19.19 = xor i32 %conv23.19.19, %conv29.19.19
  %scevgep35.19.19 = getelementptr i8, i8* %a, i64 39
  %7003 = load i8, i8* %scevgep35.19.19, align 1
  %7004 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.19 = call zeroext i8 @mult(i8 zeroext %7003, i8 zeroext %7004)
  %conv35.19.19 = zext i8 %call34.19.19 to i32
  %xor36.19.19 = xor i32 %xor.19.19, %conv35.19.19
  %conv37.19.19 = trunc i32 %xor36.19.19 to i8
  store i8 %conv37.19.19, i8* %scevgep41.19.18, align 1
  %scevgep28.19.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6998, i64 0, i64 0, i64 1
  %7005 = bitcast i8* %scevgep28.19.19 to [61 x [61 x i8]]*
  %scevgep41.19.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6999, i64 0, i64 1, i64 0
  %7006 = bitcast i8* %scevgep41.19.19 to [61 x [61 x i8]]*
  %call16.19.20 = call zeroext i8 (...) @rand()
  store i8 %call16.19.20, i8* %scevgep28.19.19, align 1
  %7007 = load i8, i8* %scevgep28.19.19, align 1
  %conv23.19.20 = zext i8 %7007 to i32
  %7008 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.20 = getelementptr i8, i8* %b, i64 40
  %7009 = load i8, i8* %scevgep34.19.20, align 1
  %call28.19.20 = call zeroext i8 @mult(i8 zeroext %7008, i8 zeroext %7009)
  %conv29.19.20 = zext i8 %call28.19.20 to i32
  %xor.19.20 = xor i32 %conv23.19.20, %conv29.19.20
  %scevgep35.19.20 = getelementptr i8, i8* %a, i64 40
  %7010 = load i8, i8* %scevgep35.19.20, align 1
  %7011 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.20 = call zeroext i8 @mult(i8 zeroext %7010, i8 zeroext %7011)
  %conv35.19.20 = zext i8 %call34.19.20 to i32
  %xor36.19.20 = xor i32 %xor.19.20, %conv35.19.20
  %conv37.19.20 = trunc i32 %xor36.19.20 to i8
  store i8 %conv37.19.20, i8* %scevgep41.19.19, align 1
  %scevgep28.19.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7005, i64 0, i64 0, i64 1
  %7012 = bitcast i8* %scevgep28.19.20 to [61 x [61 x i8]]*
  %scevgep41.19.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7006, i64 0, i64 1, i64 0
  %7013 = bitcast i8* %scevgep41.19.20 to [61 x [61 x i8]]*
  %call16.19.21 = call zeroext i8 (...) @rand()
  store i8 %call16.19.21, i8* %scevgep28.19.20, align 1
  %7014 = load i8, i8* %scevgep28.19.20, align 1
  %conv23.19.21 = zext i8 %7014 to i32
  %7015 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.21 = getelementptr i8, i8* %b, i64 41
  %7016 = load i8, i8* %scevgep34.19.21, align 1
  %call28.19.21 = call zeroext i8 @mult(i8 zeroext %7015, i8 zeroext %7016)
  %conv29.19.21 = zext i8 %call28.19.21 to i32
  %xor.19.21 = xor i32 %conv23.19.21, %conv29.19.21
  %scevgep35.19.21 = getelementptr i8, i8* %a, i64 41
  %7017 = load i8, i8* %scevgep35.19.21, align 1
  %7018 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.21 = call zeroext i8 @mult(i8 zeroext %7017, i8 zeroext %7018)
  %conv35.19.21 = zext i8 %call34.19.21 to i32
  %xor36.19.21 = xor i32 %xor.19.21, %conv35.19.21
  %conv37.19.21 = trunc i32 %xor36.19.21 to i8
  store i8 %conv37.19.21, i8* %scevgep41.19.20, align 1
  %scevgep28.19.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7012, i64 0, i64 0, i64 1
  %7019 = bitcast i8* %scevgep28.19.21 to [61 x [61 x i8]]*
  %scevgep41.19.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7013, i64 0, i64 1, i64 0
  %7020 = bitcast i8* %scevgep41.19.21 to [61 x [61 x i8]]*
  %call16.19.22 = call zeroext i8 (...) @rand()
  store i8 %call16.19.22, i8* %scevgep28.19.21, align 1
  %7021 = load i8, i8* %scevgep28.19.21, align 1
  %conv23.19.22 = zext i8 %7021 to i32
  %7022 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.22 = getelementptr i8, i8* %b, i64 42
  %7023 = load i8, i8* %scevgep34.19.22, align 1
  %call28.19.22 = call zeroext i8 @mult(i8 zeroext %7022, i8 zeroext %7023)
  %conv29.19.22 = zext i8 %call28.19.22 to i32
  %xor.19.22 = xor i32 %conv23.19.22, %conv29.19.22
  %scevgep35.19.22 = getelementptr i8, i8* %a, i64 42
  %7024 = load i8, i8* %scevgep35.19.22, align 1
  %7025 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.22 = call zeroext i8 @mult(i8 zeroext %7024, i8 zeroext %7025)
  %conv35.19.22 = zext i8 %call34.19.22 to i32
  %xor36.19.22 = xor i32 %xor.19.22, %conv35.19.22
  %conv37.19.22 = trunc i32 %xor36.19.22 to i8
  store i8 %conv37.19.22, i8* %scevgep41.19.21, align 1
  %scevgep28.19.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7019, i64 0, i64 0, i64 1
  %7026 = bitcast i8* %scevgep28.19.22 to [61 x [61 x i8]]*
  %scevgep41.19.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7020, i64 0, i64 1, i64 0
  %7027 = bitcast i8* %scevgep41.19.22 to [61 x [61 x i8]]*
  %call16.19.23 = call zeroext i8 (...) @rand()
  store i8 %call16.19.23, i8* %scevgep28.19.22, align 1
  %7028 = load i8, i8* %scevgep28.19.22, align 1
  %conv23.19.23 = zext i8 %7028 to i32
  %7029 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.23 = getelementptr i8, i8* %b, i64 43
  %7030 = load i8, i8* %scevgep34.19.23, align 1
  %call28.19.23 = call zeroext i8 @mult(i8 zeroext %7029, i8 zeroext %7030)
  %conv29.19.23 = zext i8 %call28.19.23 to i32
  %xor.19.23 = xor i32 %conv23.19.23, %conv29.19.23
  %scevgep35.19.23 = getelementptr i8, i8* %a, i64 43
  %7031 = load i8, i8* %scevgep35.19.23, align 1
  %7032 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.23 = call zeroext i8 @mult(i8 zeroext %7031, i8 zeroext %7032)
  %conv35.19.23 = zext i8 %call34.19.23 to i32
  %xor36.19.23 = xor i32 %xor.19.23, %conv35.19.23
  %conv37.19.23 = trunc i32 %xor36.19.23 to i8
  store i8 %conv37.19.23, i8* %scevgep41.19.22, align 1
  %scevgep28.19.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7026, i64 0, i64 0, i64 1
  %7033 = bitcast i8* %scevgep28.19.23 to [61 x [61 x i8]]*
  %scevgep41.19.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7027, i64 0, i64 1, i64 0
  %7034 = bitcast i8* %scevgep41.19.23 to [61 x [61 x i8]]*
  %call16.19.24 = call zeroext i8 (...) @rand()
  store i8 %call16.19.24, i8* %scevgep28.19.23, align 1
  %7035 = load i8, i8* %scevgep28.19.23, align 1
  %conv23.19.24 = zext i8 %7035 to i32
  %7036 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.24 = getelementptr i8, i8* %b, i64 44
  %7037 = load i8, i8* %scevgep34.19.24, align 1
  %call28.19.24 = call zeroext i8 @mult(i8 zeroext %7036, i8 zeroext %7037)
  %conv29.19.24 = zext i8 %call28.19.24 to i32
  %xor.19.24 = xor i32 %conv23.19.24, %conv29.19.24
  %scevgep35.19.24 = getelementptr i8, i8* %a, i64 44
  %7038 = load i8, i8* %scevgep35.19.24, align 1
  %7039 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.24 = call zeroext i8 @mult(i8 zeroext %7038, i8 zeroext %7039)
  %conv35.19.24 = zext i8 %call34.19.24 to i32
  %xor36.19.24 = xor i32 %xor.19.24, %conv35.19.24
  %conv37.19.24 = trunc i32 %xor36.19.24 to i8
  store i8 %conv37.19.24, i8* %scevgep41.19.23, align 1
  %scevgep28.19.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7033, i64 0, i64 0, i64 1
  %7040 = bitcast i8* %scevgep28.19.24 to [61 x [61 x i8]]*
  %scevgep41.19.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7034, i64 0, i64 1, i64 0
  %7041 = bitcast i8* %scevgep41.19.24 to [61 x [61 x i8]]*
  %call16.19.25 = call zeroext i8 (...) @rand()
  store i8 %call16.19.25, i8* %scevgep28.19.24, align 1
  %7042 = load i8, i8* %scevgep28.19.24, align 1
  %conv23.19.25 = zext i8 %7042 to i32
  %7043 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.25 = getelementptr i8, i8* %b, i64 45
  %7044 = load i8, i8* %scevgep34.19.25, align 1
  %call28.19.25 = call zeroext i8 @mult(i8 zeroext %7043, i8 zeroext %7044)
  %conv29.19.25 = zext i8 %call28.19.25 to i32
  %xor.19.25 = xor i32 %conv23.19.25, %conv29.19.25
  %scevgep35.19.25 = getelementptr i8, i8* %a, i64 45
  %7045 = load i8, i8* %scevgep35.19.25, align 1
  %7046 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.25 = call zeroext i8 @mult(i8 zeroext %7045, i8 zeroext %7046)
  %conv35.19.25 = zext i8 %call34.19.25 to i32
  %xor36.19.25 = xor i32 %xor.19.25, %conv35.19.25
  %conv37.19.25 = trunc i32 %xor36.19.25 to i8
  store i8 %conv37.19.25, i8* %scevgep41.19.24, align 1
  %scevgep28.19.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7040, i64 0, i64 0, i64 1
  %7047 = bitcast i8* %scevgep28.19.25 to [61 x [61 x i8]]*
  %scevgep41.19.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7041, i64 0, i64 1, i64 0
  %7048 = bitcast i8* %scevgep41.19.25 to [61 x [61 x i8]]*
  %call16.19.26 = call zeroext i8 (...) @rand()
  store i8 %call16.19.26, i8* %scevgep28.19.25, align 1
  %7049 = load i8, i8* %scevgep28.19.25, align 1
  %conv23.19.26 = zext i8 %7049 to i32
  %7050 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.26 = getelementptr i8, i8* %b, i64 46
  %7051 = load i8, i8* %scevgep34.19.26, align 1
  %call28.19.26 = call zeroext i8 @mult(i8 zeroext %7050, i8 zeroext %7051)
  %conv29.19.26 = zext i8 %call28.19.26 to i32
  %xor.19.26 = xor i32 %conv23.19.26, %conv29.19.26
  %scevgep35.19.26 = getelementptr i8, i8* %a, i64 46
  %7052 = load i8, i8* %scevgep35.19.26, align 1
  %7053 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.26 = call zeroext i8 @mult(i8 zeroext %7052, i8 zeroext %7053)
  %conv35.19.26 = zext i8 %call34.19.26 to i32
  %xor36.19.26 = xor i32 %xor.19.26, %conv35.19.26
  %conv37.19.26 = trunc i32 %xor36.19.26 to i8
  store i8 %conv37.19.26, i8* %scevgep41.19.25, align 1
  %scevgep28.19.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7047, i64 0, i64 0, i64 1
  %7054 = bitcast i8* %scevgep28.19.26 to [61 x [61 x i8]]*
  %scevgep41.19.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7048, i64 0, i64 1, i64 0
  %7055 = bitcast i8* %scevgep41.19.26 to [61 x [61 x i8]]*
  %call16.19.27 = call zeroext i8 (...) @rand()
  store i8 %call16.19.27, i8* %scevgep28.19.26, align 1
  %7056 = load i8, i8* %scevgep28.19.26, align 1
  %conv23.19.27 = zext i8 %7056 to i32
  %7057 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.27 = getelementptr i8, i8* %b, i64 47
  %7058 = load i8, i8* %scevgep34.19.27, align 1
  %call28.19.27 = call zeroext i8 @mult(i8 zeroext %7057, i8 zeroext %7058)
  %conv29.19.27 = zext i8 %call28.19.27 to i32
  %xor.19.27 = xor i32 %conv23.19.27, %conv29.19.27
  %scevgep35.19.27 = getelementptr i8, i8* %a, i64 47
  %7059 = load i8, i8* %scevgep35.19.27, align 1
  %7060 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.27 = call zeroext i8 @mult(i8 zeroext %7059, i8 zeroext %7060)
  %conv35.19.27 = zext i8 %call34.19.27 to i32
  %xor36.19.27 = xor i32 %xor.19.27, %conv35.19.27
  %conv37.19.27 = trunc i32 %xor36.19.27 to i8
  store i8 %conv37.19.27, i8* %scevgep41.19.26, align 1
  %scevgep28.19.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7054, i64 0, i64 0, i64 1
  %7061 = bitcast i8* %scevgep28.19.27 to [61 x [61 x i8]]*
  %scevgep41.19.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7055, i64 0, i64 1, i64 0
  %7062 = bitcast i8* %scevgep41.19.27 to [61 x [61 x i8]]*
  %call16.19.28 = call zeroext i8 (...) @rand()
  store i8 %call16.19.28, i8* %scevgep28.19.27, align 1
  %7063 = load i8, i8* %scevgep28.19.27, align 1
  %conv23.19.28 = zext i8 %7063 to i32
  %7064 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.28 = getelementptr i8, i8* %b, i64 48
  %7065 = load i8, i8* %scevgep34.19.28, align 1
  %call28.19.28 = call zeroext i8 @mult(i8 zeroext %7064, i8 zeroext %7065)
  %conv29.19.28 = zext i8 %call28.19.28 to i32
  %xor.19.28 = xor i32 %conv23.19.28, %conv29.19.28
  %scevgep35.19.28 = getelementptr i8, i8* %a, i64 48
  %7066 = load i8, i8* %scevgep35.19.28, align 1
  %7067 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.28 = call zeroext i8 @mult(i8 zeroext %7066, i8 zeroext %7067)
  %conv35.19.28 = zext i8 %call34.19.28 to i32
  %xor36.19.28 = xor i32 %xor.19.28, %conv35.19.28
  %conv37.19.28 = trunc i32 %xor36.19.28 to i8
  store i8 %conv37.19.28, i8* %scevgep41.19.27, align 1
  %scevgep28.19.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7061, i64 0, i64 0, i64 1
  %7068 = bitcast i8* %scevgep28.19.28 to [61 x [61 x i8]]*
  %scevgep41.19.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7062, i64 0, i64 1, i64 0
  %7069 = bitcast i8* %scevgep41.19.28 to [61 x [61 x i8]]*
  %call16.19.29 = call zeroext i8 (...) @rand()
  store i8 %call16.19.29, i8* %scevgep28.19.28, align 1
  %7070 = load i8, i8* %scevgep28.19.28, align 1
  %conv23.19.29 = zext i8 %7070 to i32
  %7071 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.29 = getelementptr i8, i8* %b, i64 49
  %7072 = load i8, i8* %scevgep34.19.29, align 1
  %call28.19.29 = call zeroext i8 @mult(i8 zeroext %7071, i8 zeroext %7072)
  %conv29.19.29 = zext i8 %call28.19.29 to i32
  %xor.19.29 = xor i32 %conv23.19.29, %conv29.19.29
  %scevgep35.19.29 = getelementptr i8, i8* %a, i64 49
  %7073 = load i8, i8* %scevgep35.19.29, align 1
  %7074 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.29 = call zeroext i8 @mult(i8 zeroext %7073, i8 zeroext %7074)
  %conv35.19.29 = zext i8 %call34.19.29 to i32
  %xor36.19.29 = xor i32 %xor.19.29, %conv35.19.29
  %conv37.19.29 = trunc i32 %xor36.19.29 to i8
  store i8 %conv37.19.29, i8* %scevgep41.19.28, align 1
  %scevgep28.19.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7068, i64 0, i64 0, i64 1
  %7075 = bitcast i8* %scevgep28.19.29 to [61 x [61 x i8]]*
  %scevgep41.19.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7069, i64 0, i64 1, i64 0
  %7076 = bitcast i8* %scevgep41.19.29 to [61 x [61 x i8]]*
  %call16.19.30 = call zeroext i8 (...) @rand()
  store i8 %call16.19.30, i8* %scevgep28.19.29, align 1
  %7077 = load i8, i8* %scevgep28.19.29, align 1
  %conv23.19.30 = zext i8 %7077 to i32
  %7078 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.30 = getelementptr i8, i8* %b, i64 50
  %7079 = load i8, i8* %scevgep34.19.30, align 1
  %call28.19.30 = call zeroext i8 @mult(i8 zeroext %7078, i8 zeroext %7079)
  %conv29.19.30 = zext i8 %call28.19.30 to i32
  %xor.19.30 = xor i32 %conv23.19.30, %conv29.19.30
  %scevgep35.19.30 = getelementptr i8, i8* %a, i64 50
  %7080 = load i8, i8* %scevgep35.19.30, align 1
  %7081 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.30 = call zeroext i8 @mult(i8 zeroext %7080, i8 zeroext %7081)
  %conv35.19.30 = zext i8 %call34.19.30 to i32
  %xor36.19.30 = xor i32 %xor.19.30, %conv35.19.30
  %conv37.19.30 = trunc i32 %xor36.19.30 to i8
  store i8 %conv37.19.30, i8* %scevgep41.19.29, align 1
  %scevgep28.19.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7075, i64 0, i64 0, i64 1
  %7082 = bitcast i8* %scevgep28.19.30 to [61 x [61 x i8]]*
  %scevgep41.19.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7076, i64 0, i64 1, i64 0
  %7083 = bitcast i8* %scevgep41.19.30 to [61 x [61 x i8]]*
  %call16.19.31 = call zeroext i8 (...) @rand()
  store i8 %call16.19.31, i8* %scevgep28.19.30, align 1
  %7084 = load i8, i8* %scevgep28.19.30, align 1
  %conv23.19.31 = zext i8 %7084 to i32
  %7085 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.31 = getelementptr i8, i8* %b, i64 51
  %7086 = load i8, i8* %scevgep34.19.31, align 1
  %call28.19.31 = call zeroext i8 @mult(i8 zeroext %7085, i8 zeroext %7086)
  %conv29.19.31 = zext i8 %call28.19.31 to i32
  %xor.19.31 = xor i32 %conv23.19.31, %conv29.19.31
  %scevgep35.19.31 = getelementptr i8, i8* %a, i64 51
  %7087 = load i8, i8* %scevgep35.19.31, align 1
  %7088 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.31 = call zeroext i8 @mult(i8 zeroext %7087, i8 zeroext %7088)
  %conv35.19.31 = zext i8 %call34.19.31 to i32
  %xor36.19.31 = xor i32 %xor.19.31, %conv35.19.31
  %conv37.19.31 = trunc i32 %xor36.19.31 to i8
  store i8 %conv37.19.31, i8* %scevgep41.19.30, align 1
  %scevgep28.19.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7082, i64 0, i64 0, i64 1
  %7089 = bitcast i8* %scevgep28.19.31 to [61 x [61 x i8]]*
  %scevgep41.19.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7083, i64 0, i64 1, i64 0
  %7090 = bitcast i8* %scevgep41.19.31 to [61 x [61 x i8]]*
  %call16.19.32 = call zeroext i8 (...) @rand()
  store i8 %call16.19.32, i8* %scevgep28.19.31, align 1
  %7091 = load i8, i8* %scevgep28.19.31, align 1
  %conv23.19.32 = zext i8 %7091 to i32
  %7092 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.32 = getelementptr i8, i8* %b, i64 52
  %7093 = load i8, i8* %scevgep34.19.32, align 1
  %call28.19.32 = call zeroext i8 @mult(i8 zeroext %7092, i8 zeroext %7093)
  %conv29.19.32 = zext i8 %call28.19.32 to i32
  %xor.19.32 = xor i32 %conv23.19.32, %conv29.19.32
  %scevgep35.19.32 = getelementptr i8, i8* %a, i64 52
  %7094 = load i8, i8* %scevgep35.19.32, align 1
  %7095 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.32 = call zeroext i8 @mult(i8 zeroext %7094, i8 zeroext %7095)
  %conv35.19.32 = zext i8 %call34.19.32 to i32
  %xor36.19.32 = xor i32 %xor.19.32, %conv35.19.32
  %conv37.19.32 = trunc i32 %xor36.19.32 to i8
  store i8 %conv37.19.32, i8* %scevgep41.19.31, align 1
  %scevgep28.19.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7089, i64 0, i64 0, i64 1
  %7096 = bitcast i8* %scevgep28.19.32 to [61 x [61 x i8]]*
  %scevgep41.19.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7090, i64 0, i64 1, i64 0
  %7097 = bitcast i8* %scevgep41.19.32 to [61 x [61 x i8]]*
  %call16.19.33 = call zeroext i8 (...) @rand()
  store i8 %call16.19.33, i8* %scevgep28.19.32, align 1
  %7098 = load i8, i8* %scevgep28.19.32, align 1
  %conv23.19.33 = zext i8 %7098 to i32
  %7099 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.33 = getelementptr i8, i8* %b, i64 53
  %7100 = load i8, i8* %scevgep34.19.33, align 1
  %call28.19.33 = call zeroext i8 @mult(i8 zeroext %7099, i8 zeroext %7100)
  %conv29.19.33 = zext i8 %call28.19.33 to i32
  %xor.19.33 = xor i32 %conv23.19.33, %conv29.19.33
  %scevgep35.19.33 = getelementptr i8, i8* %a, i64 53
  %7101 = load i8, i8* %scevgep35.19.33, align 1
  %7102 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.33 = call zeroext i8 @mult(i8 zeroext %7101, i8 zeroext %7102)
  %conv35.19.33 = zext i8 %call34.19.33 to i32
  %xor36.19.33 = xor i32 %xor.19.33, %conv35.19.33
  %conv37.19.33 = trunc i32 %xor36.19.33 to i8
  store i8 %conv37.19.33, i8* %scevgep41.19.32, align 1
  %scevgep28.19.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7096, i64 0, i64 0, i64 1
  %7103 = bitcast i8* %scevgep28.19.33 to [61 x [61 x i8]]*
  %scevgep41.19.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7097, i64 0, i64 1, i64 0
  %7104 = bitcast i8* %scevgep41.19.33 to [61 x [61 x i8]]*
  %call16.19.34 = call zeroext i8 (...) @rand()
  store i8 %call16.19.34, i8* %scevgep28.19.33, align 1
  %7105 = load i8, i8* %scevgep28.19.33, align 1
  %conv23.19.34 = zext i8 %7105 to i32
  %7106 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.34 = getelementptr i8, i8* %b, i64 54
  %7107 = load i8, i8* %scevgep34.19.34, align 1
  %call28.19.34 = call zeroext i8 @mult(i8 zeroext %7106, i8 zeroext %7107)
  %conv29.19.34 = zext i8 %call28.19.34 to i32
  %xor.19.34 = xor i32 %conv23.19.34, %conv29.19.34
  %scevgep35.19.34 = getelementptr i8, i8* %a, i64 54
  %7108 = load i8, i8* %scevgep35.19.34, align 1
  %7109 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.34 = call zeroext i8 @mult(i8 zeroext %7108, i8 zeroext %7109)
  %conv35.19.34 = zext i8 %call34.19.34 to i32
  %xor36.19.34 = xor i32 %xor.19.34, %conv35.19.34
  %conv37.19.34 = trunc i32 %xor36.19.34 to i8
  store i8 %conv37.19.34, i8* %scevgep41.19.33, align 1
  %scevgep28.19.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7103, i64 0, i64 0, i64 1
  %7110 = bitcast i8* %scevgep28.19.34 to [61 x [61 x i8]]*
  %scevgep41.19.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7104, i64 0, i64 1, i64 0
  %7111 = bitcast i8* %scevgep41.19.34 to [61 x [61 x i8]]*
  %call16.19.35 = call zeroext i8 (...) @rand()
  store i8 %call16.19.35, i8* %scevgep28.19.34, align 1
  %7112 = load i8, i8* %scevgep28.19.34, align 1
  %conv23.19.35 = zext i8 %7112 to i32
  %7113 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.35 = getelementptr i8, i8* %b, i64 55
  %7114 = load i8, i8* %scevgep34.19.35, align 1
  %call28.19.35 = call zeroext i8 @mult(i8 zeroext %7113, i8 zeroext %7114)
  %conv29.19.35 = zext i8 %call28.19.35 to i32
  %xor.19.35 = xor i32 %conv23.19.35, %conv29.19.35
  %scevgep35.19.35 = getelementptr i8, i8* %a, i64 55
  %7115 = load i8, i8* %scevgep35.19.35, align 1
  %7116 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.35 = call zeroext i8 @mult(i8 zeroext %7115, i8 zeroext %7116)
  %conv35.19.35 = zext i8 %call34.19.35 to i32
  %xor36.19.35 = xor i32 %xor.19.35, %conv35.19.35
  %conv37.19.35 = trunc i32 %xor36.19.35 to i8
  store i8 %conv37.19.35, i8* %scevgep41.19.34, align 1
  %scevgep28.19.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7110, i64 0, i64 0, i64 1
  %7117 = bitcast i8* %scevgep28.19.35 to [61 x [61 x i8]]*
  %scevgep41.19.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7111, i64 0, i64 1, i64 0
  %7118 = bitcast i8* %scevgep41.19.35 to [61 x [61 x i8]]*
  %call16.19.36 = call zeroext i8 (...) @rand()
  store i8 %call16.19.36, i8* %scevgep28.19.35, align 1
  %7119 = load i8, i8* %scevgep28.19.35, align 1
  %conv23.19.36 = zext i8 %7119 to i32
  %7120 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.36 = getelementptr i8, i8* %b, i64 56
  %7121 = load i8, i8* %scevgep34.19.36, align 1
  %call28.19.36 = call zeroext i8 @mult(i8 zeroext %7120, i8 zeroext %7121)
  %conv29.19.36 = zext i8 %call28.19.36 to i32
  %xor.19.36 = xor i32 %conv23.19.36, %conv29.19.36
  %scevgep35.19.36 = getelementptr i8, i8* %a, i64 56
  %7122 = load i8, i8* %scevgep35.19.36, align 1
  %7123 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.36 = call zeroext i8 @mult(i8 zeroext %7122, i8 zeroext %7123)
  %conv35.19.36 = zext i8 %call34.19.36 to i32
  %xor36.19.36 = xor i32 %xor.19.36, %conv35.19.36
  %conv37.19.36 = trunc i32 %xor36.19.36 to i8
  store i8 %conv37.19.36, i8* %scevgep41.19.35, align 1
  %scevgep28.19.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7117, i64 0, i64 0, i64 1
  %7124 = bitcast i8* %scevgep28.19.36 to [61 x [61 x i8]]*
  %scevgep41.19.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7118, i64 0, i64 1, i64 0
  %7125 = bitcast i8* %scevgep41.19.36 to [61 x [61 x i8]]*
  %call16.19.37 = call zeroext i8 (...) @rand()
  store i8 %call16.19.37, i8* %scevgep28.19.36, align 1
  %7126 = load i8, i8* %scevgep28.19.36, align 1
  %conv23.19.37 = zext i8 %7126 to i32
  %7127 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.37 = getelementptr i8, i8* %b, i64 57
  %7128 = load i8, i8* %scevgep34.19.37, align 1
  %call28.19.37 = call zeroext i8 @mult(i8 zeroext %7127, i8 zeroext %7128)
  %conv29.19.37 = zext i8 %call28.19.37 to i32
  %xor.19.37 = xor i32 %conv23.19.37, %conv29.19.37
  %scevgep35.19.37 = getelementptr i8, i8* %a, i64 57
  %7129 = load i8, i8* %scevgep35.19.37, align 1
  %7130 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.37 = call zeroext i8 @mult(i8 zeroext %7129, i8 zeroext %7130)
  %conv35.19.37 = zext i8 %call34.19.37 to i32
  %xor36.19.37 = xor i32 %xor.19.37, %conv35.19.37
  %conv37.19.37 = trunc i32 %xor36.19.37 to i8
  store i8 %conv37.19.37, i8* %scevgep41.19.36, align 1
  %scevgep28.19.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7124, i64 0, i64 0, i64 1
  %7131 = bitcast i8* %scevgep28.19.37 to [61 x [61 x i8]]*
  %scevgep41.19.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7125, i64 0, i64 1, i64 0
  %7132 = bitcast i8* %scevgep41.19.37 to [61 x [61 x i8]]*
  %call16.19.38 = call zeroext i8 (...) @rand()
  store i8 %call16.19.38, i8* %scevgep28.19.37, align 1
  %7133 = load i8, i8* %scevgep28.19.37, align 1
  %conv23.19.38 = zext i8 %7133 to i32
  %7134 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.38 = getelementptr i8, i8* %b, i64 58
  %7135 = load i8, i8* %scevgep34.19.38, align 1
  %call28.19.38 = call zeroext i8 @mult(i8 zeroext %7134, i8 zeroext %7135)
  %conv29.19.38 = zext i8 %call28.19.38 to i32
  %xor.19.38 = xor i32 %conv23.19.38, %conv29.19.38
  %scevgep35.19.38 = getelementptr i8, i8* %a, i64 58
  %7136 = load i8, i8* %scevgep35.19.38, align 1
  %7137 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.38 = call zeroext i8 @mult(i8 zeroext %7136, i8 zeroext %7137)
  %conv35.19.38 = zext i8 %call34.19.38 to i32
  %xor36.19.38 = xor i32 %xor.19.38, %conv35.19.38
  %conv37.19.38 = trunc i32 %xor36.19.38 to i8
  store i8 %conv37.19.38, i8* %scevgep41.19.37, align 1
  %scevgep28.19.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7131, i64 0, i64 0, i64 1
  %7138 = bitcast i8* %scevgep28.19.38 to [61 x [61 x i8]]*
  %scevgep41.19.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7132, i64 0, i64 1, i64 0
  %7139 = bitcast i8* %scevgep41.19.38 to [61 x [61 x i8]]*
  %call16.19.39 = call zeroext i8 (...) @rand()
  store i8 %call16.19.39, i8* %scevgep28.19.38, align 1
  %7140 = load i8, i8* %scevgep28.19.38, align 1
  %conv23.19.39 = zext i8 %7140 to i32
  %7141 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.39 = getelementptr i8, i8* %b, i64 59
  %7142 = load i8, i8* %scevgep34.19.39, align 1
  %call28.19.39 = call zeroext i8 @mult(i8 zeroext %7141, i8 zeroext %7142)
  %conv29.19.39 = zext i8 %call28.19.39 to i32
  %xor.19.39 = xor i32 %conv23.19.39, %conv29.19.39
  %scevgep35.19.39 = getelementptr i8, i8* %a, i64 59
  %7143 = load i8, i8* %scevgep35.19.39, align 1
  %7144 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.39 = call zeroext i8 @mult(i8 zeroext %7143, i8 zeroext %7144)
  %conv35.19.39 = zext i8 %call34.19.39 to i32
  %xor36.19.39 = xor i32 %xor.19.39, %conv35.19.39
  %conv37.19.39 = trunc i32 %xor36.19.39 to i8
  store i8 %conv37.19.39, i8* %scevgep41.19.38, align 1
  %scevgep28.19.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7138, i64 0, i64 0, i64 1
  %scevgep41.19.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7139, i64 0, i64 1, i64 0
  %call16.19.40 = call zeroext i8 (...) @rand()
  store i8 %call16.19.40, i8* %scevgep28.19.39, align 1
  %7145 = load i8, i8* %scevgep28.19.39, align 1
  %conv23.19.40 = zext i8 %7145 to i32
  %7146 = load i8, i8* %arrayidx25.19, align 1
  %scevgep34.19.40 = getelementptr i8, i8* %b, i64 60
  %7147 = load i8, i8* %scevgep34.19.40, align 1
  %call28.19.40 = call zeroext i8 @mult(i8 zeroext %7146, i8 zeroext %7147)
  %conv29.19.40 = zext i8 %call28.19.40 to i32
  %xor.19.40 = xor i32 %conv23.19.40, %conv29.19.40
  %scevgep35.19.40 = getelementptr i8, i8* %a, i64 60
  %7148 = load i8, i8* %scevgep35.19.40, align 1
  %7149 = load i8, i8* %arrayidx33.19, align 1
  %call34.19.40 = call zeroext i8 @mult(i8 zeroext %7148, i8 zeroext %7149)
  %conv35.19.40 = zext i8 %call34.19.40 to i32
  %xor36.19.40 = xor i32 %xor.19.40, %conv35.19.40
  %conv37.19.40 = trunc i32 %xor36.19.40 to i8
  store i8 %conv37.19.40, i8* %scevgep41.19.39, align 1
  %scevgep26.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6865, i64 0, i64 1, i64 1
  %7150 = bitcast i8* %scevgep26.19 to [61 x [61 x i8]]*
  %scevgep39.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %6866, i64 0, i64 1, i64 1
  %7151 = bitcast i8* %scevgep39.19 to [61 x [61 x i8]]*
  %arrayidx25.20 = getelementptr inbounds i8, i8* %a, i64 20
  %arrayidx33.20 = getelementptr inbounds i8, i8* %b, i64 20
  %call16.20 = call zeroext i8 (...) @rand()
  store i8 %call16.20, i8* %scevgep26.19, align 1
  %7152 = load i8, i8* %scevgep26.19, align 1
  %conv23.20 = zext i8 %7152 to i32
  %7153 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20 = getelementptr i8, i8* %b, i64 21
  %7154 = load i8, i8* %scevgep34.20, align 1
  %call28.20 = call zeroext i8 @mult(i8 zeroext %7153, i8 zeroext %7154)
  %conv29.20 = zext i8 %call28.20 to i32
  %xor.20 = xor i32 %conv23.20, %conv29.20
  %scevgep35.20 = getelementptr i8, i8* %a, i64 21
  %7155 = load i8, i8* %scevgep35.20, align 1
  %7156 = load i8, i8* %arrayidx33.20, align 1
  %call34.20 = call zeroext i8 @mult(i8 zeroext %7155, i8 zeroext %7156)
  %conv35.20 = zext i8 %call34.20 to i32
  %xor36.20 = xor i32 %xor.20, %conv35.20
  %conv37.20 = trunc i32 %xor36.20 to i8
  store i8 %conv37.20, i8* %scevgep39.19, align 1
  %scevgep28.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7150, i64 0, i64 0, i64 1
  %7157 = bitcast i8* %scevgep28.20 to [61 x [61 x i8]]*
  %scevgep41.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7151, i64 0, i64 1, i64 0
  %7158 = bitcast i8* %scevgep41.20 to [61 x [61 x i8]]*
  %call16.20.1 = call zeroext i8 (...) @rand()
  store i8 %call16.20.1, i8* %scevgep28.20, align 1
  %7159 = load i8, i8* %scevgep28.20, align 1
  %conv23.20.1 = zext i8 %7159 to i32
  %7160 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.1 = getelementptr i8, i8* %b, i64 22
  %7161 = load i8, i8* %scevgep34.20.1, align 1
  %call28.20.1 = call zeroext i8 @mult(i8 zeroext %7160, i8 zeroext %7161)
  %conv29.20.1 = zext i8 %call28.20.1 to i32
  %xor.20.1 = xor i32 %conv23.20.1, %conv29.20.1
  %scevgep35.20.1 = getelementptr i8, i8* %a, i64 22
  %7162 = load i8, i8* %scevgep35.20.1, align 1
  %7163 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.1 = call zeroext i8 @mult(i8 zeroext %7162, i8 zeroext %7163)
  %conv35.20.1 = zext i8 %call34.20.1 to i32
  %xor36.20.1 = xor i32 %xor.20.1, %conv35.20.1
  %conv37.20.1 = trunc i32 %xor36.20.1 to i8
  store i8 %conv37.20.1, i8* %scevgep41.20, align 1
  %scevgep28.20.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7157, i64 0, i64 0, i64 1
  %7164 = bitcast i8* %scevgep28.20.1 to [61 x [61 x i8]]*
  %scevgep41.20.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7158, i64 0, i64 1, i64 0
  %7165 = bitcast i8* %scevgep41.20.1 to [61 x [61 x i8]]*
  %call16.20.2 = call zeroext i8 (...) @rand()
  store i8 %call16.20.2, i8* %scevgep28.20.1, align 1
  %7166 = load i8, i8* %scevgep28.20.1, align 1
  %conv23.20.2 = zext i8 %7166 to i32
  %7167 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.2 = getelementptr i8, i8* %b, i64 23
  %7168 = load i8, i8* %scevgep34.20.2, align 1
  %call28.20.2 = call zeroext i8 @mult(i8 zeroext %7167, i8 zeroext %7168)
  %conv29.20.2 = zext i8 %call28.20.2 to i32
  %xor.20.2 = xor i32 %conv23.20.2, %conv29.20.2
  %scevgep35.20.2 = getelementptr i8, i8* %a, i64 23
  %7169 = load i8, i8* %scevgep35.20.2, align 1
  %7170 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.2 = call zeroext i8 @mult(i8 zeroext %7169, i8 zeroext %7170)
  %conv35.20.2 = zext i8 %call34.20.2 to i32
  %xor36.20.2 = xor i32 %xor.20.2, %conv35.20.2
  %conv37.20.2 = trunc i32 %xor36.20.2 to i8
  store i8 %conv37.20.2, i8* %scevgep41.20.1, align 1
  %scevgep28.20.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7164, i64 0, i64 0, i64 1
  %7171 = bitcast i8* %scevgep28.20.2 to [61 x [61 x i8]]*
  %scevgep41.20.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7165, i64 0, i64 1, i64 0
  %7172 = bitcast i8* %scevgep41.20.2 to [61 x [61 x i8]]*
  %call16.20.3 = call zeroext i8 (...) @rand()
  store i8 %call16.20.3, i8* %scevgep28.20.2, align 1
  %7173 = load i8, i8* %scevgep28.20.2, align 1
  %conv23.20.3 = zext i8 %7173 to i32
  %7174 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.3 = getelementptr i8, i8* %b, i64 24
  %7175 = load i8, i8* %scevgep34.20.3, align 1
  %call28.20.3 = call zeroext i8 @mult(i8 zeroext %7174, i8 zeroext %7175)
  %conv29.20.3 = zext i8 %call28.20.3 to i32
  %xor.20.3 = xor i32 %conv23.20.3, %conv29.20.3
  %scevgep35.20.3 = getelementptr i8, i8* %a, i64 24
  %7176 = load i8, i8* %scevgep35.20.3, align 1
  %7177 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.3 = call zeroext i8 @mult(i8 zeroext %7176, i8 zeroext %7177)
  %conv35.20.3 = zext i8 %call34.20.3 to i32
  %xor36.20.3 = xor i32 %xor.20.3, %conv35.20.3
  %conv37.20.3 = trunc i32 %xor36.20.3 to i8
  store i8 %conv37.20.3, i8* %scevgep41.20.2, align 1
  %scevgep28.20.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7171, i64 0, i64 0, i64 1
  %7178 = bitcast i8* %scevgep28.20.3 to [61 x [61 x i8]]*
  %scevgep41.20.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7172, i64 0, i64 1, i64 0
  %7179 = bitcast i8* %scevgep41.20.3 to [61 x [61 x i8]]*
  %call16.20.4 = call zeroext i8 (...) @rand()
  store i8 %call16.20.4, i8* %scevgep28.20.3, align 1
  %7180 = load i8, i8* %scevgep28.20.3, align 1
  %conv23.20.4 = zext i8 %7180 to i32
  %7181 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.4 = getelementptr i8, i8* %b, i64 25
  %7182 = load i8, i8* %scevgep34.20.4, align 1
  %call28.20.4 = call zeroext i8 @mult(i8 zeroext %7181, i8 zeroext %7182)
  %conv29.20.4 = zext i8 %call28.20.4 to i32
  %xor.20.4 = xor i32 %conv23.20.4, %conv29.20.4
  %scevgep35.20.4 = getelementptr i8, i8* %a, i64 25
  %7183 = load i8, i8* %scevgep35.20.4, align 1
  %7184 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.4 = call zeroext i8 @mult(i8 zeroext %7183, i8 zeroext %7184)
  %conv35.20.4 = zext i8 %call34.20.4 to i32
  %xor36.20.4 = xor i32 %xor.20.4, %conv35.20.4
  %conv37.20.4 = trunc i32 %xor36.20.4 to i8
  store i8 %conv37.20.4, i8* %scevgep41.20.3, align 1
  %scevgep28.20.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7178, i64 0, i64 0, i64 1
  %7185 = bitcast i8* %scevgep28.20.4 to [61 x [61 x i8]]*
  %scevgep41.20.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7179, i64 0, i64 1, i64 0
  %7186 = bitcast i8* %scevgep41.20.4 to [61 x [61 x i8]]*
  %call16.20.5 = call zeroext i8 (...) @rand()
  store i8 %call16.20.5, i8* %scevgep28.20.4, align 1
  %7187 = load i8, i8* %scevgep28.20.4, align 1
  %conv23.20.5 = zext i8 %7187 to i32
  %7188 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.5 = getelementptr i8, i8* %b, i64 26
  %7189 = load i8, i8* %scevgep34.20.5, align 1
  %call28.20.5 = call zeroext i8 @mult(i8 zeroext %7188, i8 zeroext %7189)
  %conv29.20.5 = zext i8 %call28.20.5 to i32
  %xor.20.5 = xor i32 %conv23.20.5, %conv29.20.5
  %scevgep35.20.5 = getelementptr i8, i8* %a, i64 26
  %7190 = load i8, i8* %scevgep35.20.5, align 1
  %7191 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.5 = call zeroext i8 @mult(i8 zeroext %7190, i8 zeroext %7191)
  %conv35.20.5 = zext i8 %call34.20.5 to i32
  %xor36.20.5 = xor i32 %xor.20.5, %conv35.20.5
  %conv37.20.5 = trunc i32 %xor36.20.5 to i8
  store i8 %conv37.20.5, i8* %scevgep41.20.4, align 1
  %scevgep28.20.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7185, i64 0, i64 0, i64 1
  %7192 = bitcast i8* %scevgep28.20.5 to [61 x [61 x i8]]*
  %scevgep41.20.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7186, i64 0, i64 1, i64 0
  %7193 = bitcast i8* %scevgep41.20.5 to [61 x [61 x i8]]*
  %call16.20.6 = call zeroext i8 (...) @rand()
  store i8 %call16.20.6, i8* %scevgep28.20.5, align 1
  %7194 = load i8, i8* %scevgep28.20.5, align 1
  %conv23.20.6 = zext i8 %7194 to i32
  %7195 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.6 = getelementptr i8, i8* %b, i64 27
  %7196 = load i8, i8* %scevgep34.20.6, align 1
  %call28.20.6 = call zeroext i8 @mult(i8 zeroext %7195, i8 zeroext %7196)
  %conv29.20.6 = zext i8 %call28.20.6 to i32
  %xor.20.6 = xor i32 %conv23.20.6, %conv29.20.6
  %scevgep35.20.6 = getelementptr i8, i8* %a, i64 27
  %7197 = load i8, i8* %scevgep35.20.6, align 1
  %7198 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.6 = call zeroext i8 @mult(i8 zeroext %7197, i8 zeroext %7198)
  %conv35.20.6 = zext i8 %call34.20.6 to i32
  %xor36.20.6 = xor i32 %xor.20.6, %conv35.20.6
  %conv37.20.6 = trunc i32 %xor36.20.6 to i8
  store i8 %conv37.20.6, i8* %scevgep41.20.5, align 1
  %scevgep28.20.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7192, i64 0, i64 0, i64 1
  %7199 = bitcast i8* %scevgep28.20.6 to [61 x [61 x i8]]*
  %scevgep41.20.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7193, i64 0, i64 1, i64 0
  %7200 = bitcast i8* %scevgep41.20.6 to [61 x [61 x i8]]*
  %call16.20.7 = call zeroext i8 (...) @rand()
  store i8 %call16.20.7, i8* %scevgep28.20.6, align 1
  %7201 = load i8, i8* %scevgep28.20.6, align 1
  %conv23.20.7 = zext i8 %7201 to i32
  %7202 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.7 = getelementptr i8, i8* %b, i64 28
  %7203 = load i8, i8* %scevgep34.20.7, align 1
  %call28.20.7 = call zeroext i8 @mult(i8 zeroext %7202, i8 zeroext %7203)
  %conv29.20.7 = zext i8 %call28.20.7 to i32
  %xor.20.7 = xor i32 %conv23.20.7, %conv29.20.7
  %scevgep35.20.7 = getelementptr i8, i8* %a, i64 28
  %7204 = load i8, i8* %scevgep35.20.7, align 1
  %7205 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.7 = call zeroext i8 @mult(i8 zeroext %7204, i8 zeroext %7205)
  %conv35.20.7 = zext i8 %call34.20.7 to i32
  %xor36.20.7 = xor i32 %xor.20.7, %conv35.20.7
  %conv37.20.7 = trunc i32 %xor36.20.7 to i8
  store i8 %conv37.20.7, i8* %scevgep41.20.6, align 1
  %scevgep28.20.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7199, i64 0, i64 0, i64 1
  %7206 = bitcast i8* %scevgep28.20.7 to [61 x [61 x i8]]*
  %scevgep41.20.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7200, i64 0, i64 1, i64 0
  %7207 = bitcast i8* %scevgep41.20.7 to [61 x [61 x i8]]*
  %call16.20.8 = call zeroext i8 (...) @rand()
  store i8 %call16.20.8, i8* %scevgep28.20.7, align 1
  %7208 = load i8, i8* %scevgep28.20.7, align 1
  %conv23.20.8 = zext i8 %7208 to i32
  %7209 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.8 = getelementptr i8, i8* %b, i64 29
  %7210 = load i8, i8* %scevgep34.20.8, align 1
  %call28.20.8 = call zeroext i8 @mult(i8 zeroext %7209, i8 zeroext %7210)
  %conv29.20.8 = zext i8 %call28.20.8 to i32
  %xor.20.8 = xor i32 %conv23.20.8, %conv29.20.8
  %scevgep35.20.8 = getelementptr i8, i8* %a, i64 29
  %7211 = load i8, i8* %scevgep35.20.8, align 1
  %7212 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.8 = call zeroext i8 @mult(i8 zeroext %7211, i8 zeroext %7212)
  %conv35.20.8 = zext i8 %call34.20.8 to i32
  %xor36.20.8 = xor i32 %xor.20.8, %conv35.20.8
  %conv37.20.8 = trunc i32 %xor36.20.8 to i8
  store i8 %conv37.20.8, i8* %scevgep41.20.7, align 1
  %scevgep28.20.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7206, i64 0, i64 0, i64 1
  %7213 = bitcast i8* %scevgep28.20.8 to [61 x [61 x i8]]*
  %scevgep41.20.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7207, i64 0, i64 1, i64 0
  %7214 = bitcast i8* %scevgep41.20.8 to [61 x [61 x i8]]*
  %call16.20.9 = call zeroext i8 (...) @rand()
  store i8 %call16.20.9, i8* %scevgep28.20.8, align 1
  %7215 = load i8, i8* %scevgep28.20.8, align 1
  %conv23.20.9 = zext i8 %7215 to i32
  %7216 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.9 = getelementptr i8, i8* %b, i64 30
  %7217 = load i8, i8* %scevgep34.20.9, align 1
  %call28.20.9 = call zeroext i8 @mult(i8 zeroext %7216, i8 zeroext %7217)
  %conv29.20.9 = zext i8 %call28.20.9 to i32
  %xor.20.9 = xor i32 %conv23.20.9, %conv29.20.9
  %scevgep35.20.9 = getelementptr i8, i8* %a, i64 30
  %7218 = load i8, i8* %scevgep35.20.9, align 1
  %7219 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.9 = call zeroext i8 @mult(i8 zeroext %7218, i8 zeroext %7219)
  %conv35.20.9 = zext i8 %call34.20.9 to i32
  %xor36.20.9 = xor i32 %xor.20.9, %conv35.20.9
  %conv37.20.9 = trunc i32 %xor36.20.9 to i8
  store i8 %conv37.20.9, i8* %scevgep41.20.8, align 1
  %scevgep28.20.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7213, i64 0, i64 0, i64 1
  %7220 = bitcast i8* %scevgep28.20.9 to [61 x [61 x i8]]*
  %scevgep41.20.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7214, i64 0, i64 1, i64 0
  %7221 = bitcast i8* %scevgep41.20.9 to [61 x [61 x i8]]*
  %call16.20.10 = call zeroext i8 (...) @rand()
  store i8 %call16.20.10, i8* %scevgep28.20.9, align 1
  %7222 = load i8, i8* %scevgep28.20.9, align 1
  %conv23.20.10 = zext i8 %7222 to i32
  %7223 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.10 = getelementptr i8, i8* %b, i64 31
  %7224 = load i8, i8* %scevgep34.20.10, align 1
  %call28.20.10 = call zeroext i8 @mult(i8 zeroext %7223, i8 zeroext %7224)
  %conv29.20.10 = zext i8 %call28.20.10 to i32
  %xor.20.10 = xor i32 %conv23.20.10, %conv29.20.10
  %scevgep35.20.10 = getelementptr i8, i8* %a, i64 31
  %7225 = load i8, i8* %scevgep35.20.10, align 1
  %7226 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.10 = call zeroext i8 @mult(i8 zeroext %7225, i8 zeroext %7226)
  %conv35.20.10 = zext i8 %call34.20.10 to i32
  %xor36.20.10 = xor i32 %xor.20.10, %conv35.20.10
  %conv37.20.10 = trunc i32 %xor36.20.10 to i8
  store i8 %conv37.20.10, i8* %scevgep41.20.9, align 1
  %scevgep28.20.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7220, i64 0, i64 0, i64 1
  %7227 = bitcast i8* %scevgep28.20.10 to [61 x [61 x i8]]*
  %scevgep41.20.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7221, i64 0, i64 1, i64 0
  %7228 = bitcast i8* %scevgep41.20.10 to [61 x [61 x i8]]*
  %call16.20.11 = call zeroext i8 (...) @rand()
  store i8 %call16.20.11, i8* %scevgep28.20.10, align 1
  %7229 = load i8, i8* %scevgep28.20.10, align 1
  %conv23.20.11 = zext i8 %7229 to i32
  %7230 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.11 = getelementptr i8, i8* %b, i64 32
  %7231 = load i8, i8* %scevgep34.20.11, align 1
  %call28.20.11 = call zeroext i8 @mult(i8 zeroext %7230, i8 zeroext %7231)
  %conv29.20.11 = zext i8 %call28.20.11 to i32
  %xor.20.11 = xor i32 %conv23.20.11, %conv29.20.11
  %scevgep35.20.11 = getelementptr i8, i8* %a, i64 32
  %7232 = load i8, i8* %scevgep35.20.11, align 1
  %7233 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.11 = call zeroext i8 @mult(i8 zeroext %7232, i8 zeroext %7233)
  %conv35.20.11 = zext i8 %call34.20.11 to i32
  %xor36.20.11 = xor i32 %xor.20.11, %conv35.20.11
  %conv37.20.11 = trunc i32 %xor36.20.11 to i8
  store i8 %conv37.20.11, i8* %scevgep41.20.10, align 1
  %scevgep28.20.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7227, i64 0, i64 0, i64 1
  %7234 = bitcast i8* %scevgep28.20.11 to [61 x [61 x i8]]*
  %scevgep41.20.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7228, i64 0, i64 1, i64 0
  %7235 = bitcast i8* %scevgep41.20.11 to [61 x [61 x i8]]*
  %call16.20.12 = call zeroext i8 (...) @rand()
  store i8 %call16.20.12, i8* %scevgep28.20.11, align 1
  %7236 = load i8, i8* %scevgep28.20.11, align 1
  %conv23.20.12 = zext i8 %7236 to i32
  %7237 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.12 = getelementptr i8, i8* %b, i64 33
  %7238 = load i8, i8* %scevgep34.20.12, align 1
  %call28.20.12 = call zeroext i8 @mult(i8 zeroext %7237, i8 zeroext %7238)
  %conv29.20.12 = zext i8 %call28.20.12 to i32
  %xor.20.12 = xor i32 %conv23.20.12, %conv29.20.12
  %scevgep35.20.12 = getelementptr i8, i8* %a, i64 33
  %7239 = load i8, i8* %scevgep35.20.12, align 1
  %7240 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.12 = call zeroext i8 @mult(i8 zeroext %7239, i8 zeroext %7240)
  %conv35.20.12 = zext i8 %call34.20.12 to i32
  %xor36.20.12 = xor i32 %xor.20.12, %conv35.20.12
  %conv37.20.12 = trunc i32 %xor36.20.12 to i8
  store i8 %conv37.20.12, i8* %scevgep41.20.11, align 1
  %scevgep28.20.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7234, i64 0, i64 0, i64 1
  %7241 = bitcast i8* %scevgep28.20.12 to [61 x [61 x i8]]*
  %scevgep41.20.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7235, i64 0, i64 1, i64 0
  %7242 = bitcast i8* %scevgep41.20.12 to [61 x [61 x i8]]*
  %call16.20.13 = call zeroext i8 (...) @rand()
  store i8 %call16.20.13, i8* %scevgep28.20.12, align 1
  %7243 = load i8, i8* %scevgep28.20.12, align 1
  %conv23.20.13 = zext i8 %7243 to i32
  %7244 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.13 = getelementptr i8, i8* %b, i64 34
  %7245 = load i8, i8* %scevgep34.20.13, align 1
  %call28.20.13 = call zeroext i8 @mult(i8 zeroext %7244, i8 zeroext %7245)
  %conv29.20.13 = zext i8 %call28.20.13 to i32
  %xor.20.13 = xor i32 %conv23.20.13, %conv29.20.13
  %scevgep35.20.13 = getelementptr i8, i8* %a, i64 34
  %7246 = load i8, i8* %scevgep35.20.13, align 1
  %7247 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.13 = call zeroext i8 @mult(i8 zeroext %7246, i8 zeroext %7247)
  %conv35.20.13 = zext i8 %call34.20.13 to i32
  %xor36.20.13 = xor i32 %xor.20.13, %conv35.20.13
  %conv37.20.13 = trunc i32 %xor36.20.13 to i8
  store i8 %conv37.20.13, i8* %scevgep41.20.12, align 1
  %scevgep28.20.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7241, i64 0, i64 0, i64 1
  %7248 = bitcast i8* %scevgep28.20.13 to [61 x [61 x i8]]*
  %scevgep41.20.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7242, i64 0, i64 1, i64 0
  %7249 = bitcast i8* %scevgep41.20.13 to [61 x [61 x i8]]*
  %call16.20.14 = call zeroext i8 (...) @rand()
  store i8 %call16.20.14, i8* %scevgep28.20.13, align 1
  %7250 = load i8, i8* %scevgep28.20.13, align 1
  %conv23.20.14 = zext i8 %7250 to i32
  %7251 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.14 = getelementptr i8, i8* %b, i64 35
  %7252 = load i8, i8* %scevgep34.20.14, align 1
  %call28.20.14 = call zeroext i8 @mult(i8 zeroext %7251, i8 zeroext %7252)
  %conv29.20.14 = zext i8 %call28.20.14 to i32
  %xor.20.14 = xor i32 %conv23.20.14, %conv29.20.14
  %scevgep35.20.14 = getelementptr i8, i8* %a, i64 35
  %7253 = load i8, i8* %scevgep35.20.14, align 1
  %7254 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.14 = call zeroext i8 @mult(i8 zeroext %7253, i8 zeroext %7254)
  %conv35.20.14 = zext i8 %call34.20.14 to i32
  %xor36.20.14 = xor i32 %xor.20.14, %conv35.20.14
  %conv37.20.14 = trunc i32 %xor36.20.14 to i8
  store i8 %conv37.20.14, i8* %scevgep41.20.13, align 1
  %scevgep28.20.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7248, i64 0, i64 0, i64 1
  %7255 = bitcast i8* %scevgep28.20.14 to [61 x [61 x i8]]*
  %scevgep41.20.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7249, i64 0, i64 1, i64 0
  %7256 = bitcast i8* %scevgep41.20.14 to [61 x [61 x i8]]*
  %call16.20.15 = call zeroext i8 (...) @rand()
  store i8 %call16.20.15, i8* %scevgep28.20.14, align 1
  %7257 = load i8, i8* %scevgep28.20.14, align 1
  %conv23.20.15 = zext i8 %7257 to i32
  %7258 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.15 = getelementptr i8, i8* %b, i64 36
  %7259 = load i8, i8* %scevgep34.20.15, align 1
  %call28.20.15 = call zeroext i8 @mult(i8 zeroext %7258, i8 zeroext %7259)
  %conv29.20.15 = zext i8 %call28.20.15 to i32
  %xor.20.15 = xor i32 %conv23.20.15, %conv29.20.15
  %scevgep35.20.15 = getelementptr i8, i8* %a, i64 36
  %7260 = load i8, i8* %scevgep35.20.15, align 1
  %7261 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.15 = call zeroext i8 @mult(i8 zeroext %7260, i8 zeroext %7261)
  %conv35.20.15 = zext i8 %call34.20.15 to i32
  %xor36.20.15 = xor i32 %xor.20.15, %conv35.20.15
  %conv37.20.15 = trunc i32 %xor36.20.15 to i8
  store i8 %conv37.20.15, i8* %scevgep41.20.14, align 1
  %scevgep28.20.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7255, i64 0, i64 0, i64 1
  %7262 = bitcast i8* %scevgep28.20.15 to [61 x [61 x i8]]*
  %scevgep41.20.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7256, i64 0, i64 1, i64 0
  %7263 = bitcast i8* %scevgep41.20.15 to [61 x [61 x i8]]*
  %call16.20.16 = call zeroext i8 (...) @rand()
  store i8 %call16.20.16, i8* %scevgep28.20.15, align 1
  %7264 = load i8, i8* %scevgep28.20.15, align 1
  %conv23.20.16 = zext i8 %7264 to i32
  %7265 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.16 = getelementptr i8, i8* %b, i64 37
  %7266 = load i8, i8* %scevgep34.20.16, align 1
  %call28.20.16 = call zeroext i8 @mult(i8 zeroext %7265, i8 zeroext %7266)
  %conv29.20.16 = zext i8 %call28.20.16 to i32
  %xor.20.16 = xor i32 %conv23.20.16, %conv29.20.16
  %scevgep35.20.16 = getelementptr i8, i8* %a, i64 37
  %7267 = load i8, i8* %scevgep35.20.16, align 1
  %7268 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.16 = call zeroext i8 @mult(i8 zeroext %7267, i8 zeroext %7268)
  %conv35.20.16 = zext i8 %call34.20.16 to i32
  %xor36.20.16 = xor i32 %xor.20.16, %conv35.20.16
  %conv37.20.16 = trunc i32 %xor36.20.16 to i8
  store i8 %conv37.20.16, i8* %scevgep41.20.15, align 1
  %scevgep28.20.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7262, i64 0, i64 0, i64 1
  %7269 = bitcast i8* %scevgep28.20.16 to [61 x [61 x i8]]*
  %scevgep41.20.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7263, i64 0, i64 1, i64 0
  %7270 = bitcast i8* %scevgep41.20.16 to [61 x [61 x i8]]*
  %call16.20.17 = call zeroext i8 (...) @rand()
  store i8 %call16.20.17, i8* %scevgep28.20.16, align 1
  %7271 = load i8, i8* %scevgep28.20.16, align 1
  %conv23.20.17 = zext i8 %7271 to i32
  %7272 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.17 = getelementptr i8, i8* %b, i64 38
  %7273 = load i8, i8* %scevgep34.20.17, align 1
  %call28.20.17 = call zeroext i8 @mult(i8 zeroext %7272, i8 zeroext %7273)
  %conv29.20.17 = zext i8 %call28.20.17 to i32
  %xor.20.17 = xor i32 %conv23.20.17, %conv29.20.17
  %scevgep35.20.17 = getelementptr i8, i8* %a, i64 38
  %7274 = load i8, i8* %scevgep35.20.17, align 1
  %7275 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.17 = call zeroext i8 @mult(i8 zeroext %7274, i8 zeroext %7275)
  %conv35.20.17 = zext i8 %call34.20.17 to i32
  %xor36.20.17 = xor i32 %xor.20.17, %conv35.20.17
  %conv37.20.17 = trunc i32 %xor36.20.17 to i8
  store i8 %conv37.20.17, i8* %scevgep41.20.16, align 1
  %scevgep28.20.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7269, i64 0, i64 0, i64 1
  %7276 = bitcast i8* %scevgep28.20.17 to [61 x [61 x i8]]*
  %scevgep41.20.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7270, i64 0, i64 1, i64 0
  %7277 = bitcast i8* %scevgep41.20.17 to [61 x [61 x i8]]*
  %call16.20.18 = call zeroext i8 (...) @rand()
  store i8 %call16.20.18, i8* %scevgep28.20.17, align 1
  %7278 = load i8, i8* %scevgep28.20.17, align 1
  %conv23.20.18 = zext i8 %7278 to i32
  %7279 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.18 = getelementptr i8, i8* %b, i64 39
  %7280 = load i8, i8* %scevgep34.20.18, align 1
  %call28.20.18 = call zeroext i8 @mult(i8 zeroext %7279, i8 zeroext %7280)
  %conv29.20.18 = zext i8 %call28.20.18 to i32
  %xor.20.18 = xor i32 %conv23.20.18, %conv29.20.18
  %scevgep35.20.18 = getelementptr i8, i8* %a, i64 39
  %7281 = load i8, i8* %scevgep35.20.18, align 1
  %7282 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.18 = call zeroext i8 @mult(i8 zeroext %7281, i8 zeroext %7282)
  %conv35.20.18 = zext i8 %call34.20.18 to i32
  %xor36.20.18 = xor i32 %xor.20.18, %conv35.20.18
  %conv37.20.18 = trunc i32 %xor36.20.18 to i8
  store i8 %conv37.20.18, i8* %scevgep41.20.17, align 1
  %scevgep28.20.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7276, i64 0, i64 0, i64 1
  %7283 = bitcast i8* %scevgep28.20.18 to [61 x [61 x i8]]*
  %scevgep41.20.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7277, i64 0, i64 1, i64 0
  %7284 = bitcast i8* %scevgep41.20.18 to [61 x [61 x i8]]*
  %call16.20.19 = call zeroext i8 (...) @rand()
  store i8 %call16.20.19, i8* %scevgep28.20.18, align 1
  %7285 = load i8, i8* %scevgep28.20.18, align 1
  %conv23.20.19 = zext i8 %7285 to i32
  %7286 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.19 = getelementptr i8, i8* %b, i64 40
  %7287 = load i8, i8* %scevgep34.20.19, align 1
  %call28.20.19 = call zeroext i8 @mult(i8 zeroext %7286, i8 zeroext %7287)
  %conv29.20.19 = zext i8 %call28.20.19 to i32
  %xor.20.19 = xor i32 %conv23.20.19, %conv29.20.19
  %scevgep35.20.19 = getelementptr i8, i8* %a, i64 40
  %7288 = load i8, i8* %scevgep35.20.19, align 1
  %7289 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.19 = call zeroext i8 @mult(i8 zeroext %7288, i8 zeroext %7289)
  %conv35.20.19 = zext i8 %call34.20.19 to i32
  %xor36.20.19 = xor i32 %xor.20.19, %conv35.20.19
  %conv37.20.19 = trunc i32 %xor36.20.19 to i8
  store i8 %conv37.20.19, i8* %scevgep41.20.18, align 1
  %scevgep28.20.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7283, i64 0, i64 0, i64 1
  %7290 = bitcast i8* %scevgep28.20.19 to [61 x [61 x i8]]*
  %scevgep41.20.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7284, i64 0, i64 1, i64 0
  %7291 = bitcast i8* %scevgep41.20.19 to [61 x [61 x i8]]*
  %call16.20.20 = call zeroext i8 (...) @rand()
  store i8 %call16.20.20, i8* %scevgep28.20.19, align 1
  %7292 = load i8, i8* %scevgep28.20.19, align 1
  %conv23.20.20 = zext i8 %7292 to i32
  %7293 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.20 = getelementptr i8, i8* %b, i64 41
  %7294 = load i8, i8* %scevgep34.20.20, align 1
  %call28.20.20 = call zeroext i8 @mult(i8 zeroext %7293, i8 zeroext %7294)
  %conv29.20.20 = zext i8 %call28.20.20 to i32
  %xor.20.20 = xor i32 %conv23.20.20, %conv29.20.20
  %scevgep35.20.20 = getelementptr i8, i8* %a, i64 41
  %7295 = load i8, i8* %scevgep35.20.20, align 1
  %7296 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.20 = call zeroext i8 @mult(i8 zeroext %7295, i8 zeroext %7296)
  %conv35.20.20 = zext i8 %call34.20.20 to i32
  %xor36.20.20 = xor i32 %xor.20.20, %conv35.20.20
  %conv37.20.20 = trunc i32 %xor36.20.20 to i8
  store i8 %conv37.20.20, i8* %scevgep41.20.19, align 1
  %scevgep28.20.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7290, i64 0, i64 0, i64 1
  %7297 = bitcast i8* %scevgep28.20.20 to [61 x [61 x i8]]*
  %scevgep41.20.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7291, i64 0, i64 1, i64 0
  %7298 = bitcast i8* %scevgep41.20.20 to [61 x [61 x i8]]*
  %call16.20.21 = call zeroext i8 (...) @rand()
  store i8 %call16.20.21, i8* %scevgep28.20.20, align 1
  %7299 = load i8, i8* %scevgep28.20.20, align 1
  %conv23.20.21 = zext i8 %7299 to i32
  %7300 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.21 = getelementptr i8, i8* %b, i64 42
  %7301 = load i8, i8* %scevgep34.20.21, align 1
  %call28.20.21 = call zeroext i8 @mult(i8 zeroext %7300, i8 zeroext %7301)
  %conv29.20.21 = zext i8 %call28.20.21 to i32
  %xor.20.21 = xor i32 %conv23.20.21, %conv29.20.21
  %scevgep35.20.21 = getelementptr i8, i8* %a, i64 42
  %7302 = load i8, i8* %scevgep35.20.21, align 1
  %7303 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.21 = call zeroext i8 @mult(i8 zeroext %7302, i8 zeroext %7303)
  %conv35.20.21 = zext i8 %call34.20.21 to i32
  %xor36.20.21 = xor i32 %xor.20.21, %conv35.20.21
  %conv37.20.21 = trunc i32 %xor36.20.21 to i8
  store i8 %conv37.20.21, i8* %scevgep41.20.20, align 1
  %scevgep28.20.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7297, i64 0, i64 0, i64 1
  %7304 = bitcast i8* %scevgep28.20.21 to [61 x [61 x i8]]*
  %scevgep41.20.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7298, i64 0, i64 1, i64 0
  %7305 = bitcast i8* %scevgep41.20.21 to [61 x [61 x i8]]*
  %call16.20.22 = call zeroext i8 (...) @rand()
  store i8 %call16.20.22, i8* %scevgep28.20.21, align 1
  %7306 = load i8, i8* %scevgep28.20.21, align 1
  %conv23.20.22 = zext i8 %7306 to i32
  %7307 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.22 = getelementptr i8, i8* %b, i64 43
  %7308 = load i8, i8* %scevgep34.20.22, align 1
  %call28.20.22 = call zeroext i8 @mult(i8 zeroext %7307, i8 zeroext %7308)
  %conv29.20.22 = zext i8 %call28.20.22 to i32
  %xor.20.22 = xor i32 %conv23.20.22, %conv29.20.22
  %scevgep35.20.22 = getelementptr i8, i8* %a, i64 43
  %7309 = load i8, i8* %scevgep35.20.22, align 1
  %7310 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.22 = call zeroext i8 @mult(i8 zeroext %7309, i8 zeroext %7310)
  %conv35.20.22 = zext i8 %call34.20.22 to i32
  %xor36.20.22 = xor i32 %xor.20.22, %conv35.20.22
  %conv37.20.22 = trunc i32 %xor36.20.22 to i8
  store i8 %conv37.20.22, i8* %scevgep41.20.21, align 1
  %scevgep28.20.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7304, i64 0, i64 0, i64 1
  %7311 = bitcast i8* %scevgep28.20.22 to [61 x [61 x i8]]*
  %scevgep41.20.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7305, i64 0, i64 1, i64 0
  %7312 = bitcast i8* %scevgep41.20.22 to [61 x [61 x i8]]*
  %call16.20.23 = call zeroext i8 (...) @rand()
  store i8 %call16.20.23, i8* %scevgep28.20.22, align 1
  %7313 = load i8, i8* %scevgep28.20.22, align 1
  %conv23.20.23 = zext i8 %7313 to i32
  %7314 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.23 = getelementptr i8, i8* %b, i64 44
  %7315 = load i8, i8* %scevgep34.20.23, align 1
  %call28.20.23 = call zeroext i8 @mult(i8 zeroext %7314, i8 zeroext %7315)
  %conv29.20.23 = zext i8 %call28.20.23 to i32
  %xor.20.23 = xor i32 %conv23.20.23, %conv29.20.23
  %scevgep35.20.23 = getelementptr i8, i8* %a, i64 44
  %7316 = load i8, i8* %scevgep35.20.23, align 1
  %7317 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.23 = call zeroext i8 @mult(i8 zeroext %7316, i8 zeroext %7317)
  %conv35.20.23 = zext i8 %call34.20.23 to i32
  %xor36.20.23 = xor i32 %xor.20.23, %conv35.20.23
  %conv37.20.23 = trunc i32 %xor36.20.23 to i8
  store i8 %conv37.20.23, i8* %scevgep41.20.22, align 1
  %scevgep28.20.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7311, i64 0, i64 0, i64 1
  %7318 = bitcast i8* %scevgep28.20.23 to [61 x [61 x i8]]*
  %scevgep41.20.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7312, i64 0, i64 1, i64 0
  %7319 = bitcast i8* %scevgep41.20.23 to [61 x [61 x i8]]*
  %call16.20.24 = call zeroext i8 (...) @rand()
  store i8 %call16.20.24, i8* %scevgep28.20.23, align 1
  %7320 = load i8, i8* %scevgep28.20.23, align 1
  %conv23.20.24 = zext i8 %7320 to i32
  %7321 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.24 = getelementptr i8, i8* %b, i64 45
  %7322 = load i8, i8* %scevgep34.20.24, align 1
  %call28.20.24 = call zeroext i8 @mult(i8 zeroext %7321, i8 zeroext %7322)
  %conv29.20.24 = zext i8 %call28.20.24 to i32
  %xor.20.24 = xor i32 %conv23.20.24, %conv29.20.24
  %scevgep35.20.24 = getelementptr i8, i8* %a, i64 45
  %7323 = load i8, i8* %scevgep35.20.24, align 1
  %7324 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.24 = call zeroext i8 @mult(i8 zeroext %7323, i8 zeroext %7324)
  %conv35.20.24 = zext i8 %call34.20.24 to i32
  %xor36.20.24 = xor i32 %xor.20.24, %conv35.20.24
  %conv37.20.24 = trunc i32 %xor36.20.24 to i8
  store i8 %conv37.20.24, i8* %scevgep41.20.23, align 1
  %scevgep28.20.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7318, i64 0, i64 0, i64 1
  %7325 = bitcast i8* %scevgep28.20.24 to [61 x [61 x i8]]*
  %scevgep41.20.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7319, i64 0, i64 1, i64 0
  %7326 = bitcast i8* %scevgep41.20.24 to [61 x [61 x i8]]*
  %call16.20.25 = call zeroext i8 (...) @rand()
  store i8 %call16.20.25, i8* %scevgep28.20.24, align 1
  %7327 = load i8, i8* %scevgep28.20.24, align 1
  %conv23.20.25 = zext i8 %7327 to i32
  %7328 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.25 = getelementptr i8, i8* %b, i64 46
  %7329 = load i8, i8* %scevgep34.20.25, align 1
  %call28.20.25 = call zeroext i8 @mult(i8 zeroext %7328, i8 zeroext %7329)
  %conv29.20.25 = zext i8 %call28.20.25 to i32
  %xor.20.25 = xor i32 %conv23.20.25, %conv29.20.25
  %scevgep35.20.25 = getelementptr i8, i8* %a, i64 46
  %7330 = load i8, i8* %scevgep35.20.25, align 1
  %7331 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.25 = call zeroext i8 @mult(i8 zeroext %7330, i8 zeroext %7331)
  %conv35.20.25 = zext i8 %call34.20.25 to i32
  %xor36.20.25 = xor i32 %xor.20.25, %conv35.20.25
  %conv37.20.25 = trunc i32 %xor36.20.25 to i8
  store i8 %conv37.20.25, i8* %scevgep41.20.24, align 1
  %scevgep28.20.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7325, i64 0, i64 0, i64 1
  %7332 = bitcast i8* %scevgep28.20.25 to [61 x [61 x i8]]*
  %scevgep41.20.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7326, i64 0, i64 1, i64 0
  %7333 = bitcast i8* %scevgep41.20.25 to [61 x [61 x i8]]*
  %call16.20.26 = call zeroext i8 (...) @rand()
  store i8 %call16.20.26, i8* %scevgep28.20.25, align 1
  %7334 = load i8, i8* %scevgep28.20.25, align 1
  %conv23.20.26 = zext i8 %7334 to i32
  %7335 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.26 = getelementptr i8, i8* %b, i64 47
  %7336 = load i8, i8* %scevgep34.20.26, align 1
  %call28.20.26 = call zeroext i8 @mult(i8 zeroext %7335, i8 zeroext %7336)
  %conv29.20.26 = zext i8 %call28.20.26 to i32
  %xor.20.26 = xor i32 %conv23.20.26, %conv29.20.26
  %scevgep35.20.26 = getelementptr i8, i8* %a, i64 47
  %7337 = load i8, i8* %scevgep35.20.26, align 1
  %7338 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.26 = call zeroext i8 @mult(i8 zeroext %7337, i8 zeroext %7338)
  %conv35.20.26 = zext i8 %call34.20.26 to i32
  %xor36.20.26 = xor i32 %xor.20.26, %conv35.20.26
  %conv37.20.26 = trunc i32 %xor36.20.26 to i8
  store i8 %conv37.20.26, i8* %scevgep41.20.25, align 1
  %scevgep28.20.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7332, i64 0, i64 0, i64 1
  %7339 = bitcast i8* %scevgep28.20.26 to [61 x [61 x i8]]*
  %scevgep41.20.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7333, i64 0, i64 1, i64 0
  %7340 = bitcast i8* %scevgep41.20.26 to [61 x [61 x i8]]*
  %call16.20.27 = call zeroext i8 (...) @rand()
  store i8 %call16.20.27, i8* %scevgep28.20.26, align 1
  %7341 = load i8, i8* %scevgep28.20.26, align 1
  %conv23.20.27 = zext i8 %7341 to i32
  %7342 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.27 = getelementptr i8, i8* %b, i64 48
  %7343 = load i8, i8* %scevgep34.20.27, align 1
  %call28.20.27 = call zeroext i8 @mult(i8 zeroext %7342, i8 zeroext %7343)
  %conv29.20.27 = zext i8 %call28.20.27 to i32
  %xor.20.27 = xor i32 %conv23.20.27, %conv29.20.27
  %scevgep35.20.27 = getelementptr i8, i8* %a, i64 48
  %7344 = load i8, i8* %scevgep35.20.27, align 1
  %7345 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.27 = call zeroext i8 @mult(i8 zeroext %7344, i8 zeroext %7345)
  %conv35.20.27 = zext i8 %call34.20.27 to i32
  %xor36.20.27 = xor i32 %xor.20.27, %conv35.20.27
  %conv37.20.27 = trunc i32 %xor36.20.27 to i8
  store i8 %conv37.20.27, i8* %scevgep41.20.26, align 1
  %scevgep28.20.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7339, i64 0, i64 0, i64 1
  %7346 = bitcast i8* %scevgep28.20.27 to [61 x [61 x i8]]*
  %scevgep41.20.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7340, i64 0, i64 1, i64 0
  %7347 = bitcast i8* %scevgep41.20.27 to [61 x [61 x i8]]*
  %call16.20.28 = call zeroext i8 (...) @rand()
  store i8 %call16.20.28, i8* %scevgep28.20.27, align 1
  %7348 = load i8, i8* %scevgep28.20.27, align 1
  %conv23.20.28 = zext i8 %7348 to i32
  %7349 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.28 = getelementptr i8, i8* %b, i64 49
  %7350 = load i8, i8* %scevgep34.20.28, align 1
  %call28.20.28 = call zeroext i8 @mult(i8 zeroext %7349, i8 zeroext %7350)
  %conv29.20.28 = zext i8 %call28.20.28 to i32
  %xor.20.28 = xor i32 %conv23.20.28, %conv29.20.28
  %scevgep35.20.28 = getelementptr i8, i8* %a, i64 49
  %7351 = load i8, i8* %scevgep35.20.28, align 1
  %7352 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.28 = call zeroext i8 @mult(i8 zeroext %7351, i8 zeroext %7352)
  %conv35.20.28 = zext i8 %call34.20.28 to i32
  %xor36.20.28 = xor i32 %xor.20.28, %conv35.20.28
  %conv37.20.28 = trunc i32 %xor36.20.28 to i8
  store i8 %conv37.20.28, i8* %scevgep41.20.27, align 1
  %scevgep28.20.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7346, i64 0, i64 0, i64 1
  %7353 = bitcast i8* %scevgep28.20.28 to [61 x [61 x i8]]*
  %scevgep41.20.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7347, i64 0, i64 1, i64 0
  %7354 = bitcast i8* %scevgep41.20.28 to [61 x [61 x i8]]*
  %call16.20.29 = call zeroext i8 (...) @rand()
  store i8 %call16.20.29, i8* %scevgep28.20.28, align 1
  %7355 = load i8, i8* %scevgep28.20.28, align 1
  %conv23.20.29 = zext i8 %7355 to i32
  %7356 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.29 = getelementptr i8, i8* %b, i64 50
  %7357 = load i8, i8* %scevgep34.20.29, align 1
  %call28.20.29 = call zeroext i8 @mult(i8 zeroext %7356, i8 zeroext %7357)
  %conv29.20.29 = zext i8 %call28.20.29 to i32
  %xor.20.29 = xor i32 %conv23.20.29, %conv29.20.29
  %scevgep35.20.29 = getelementptr i8, i8* %a, i64 50
  %7358 = load i8, i8* %scevgep35.20.29, align 1
  %7359 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.29 = call zeroext i8 @mult(i8 zeroext %7358, i8 zeroext %7359)
  %conv35.20.29 = zext i8 %call34.20.29 to i32
  %xor36.20.29 = xor i32 %xor.20.29, %conv35.20.29
  %conv37.20.29 = trunc i32 %xor36.20.29 to i8
  store i8 %conv37.20.29, i8* %scevgep41.20.28, align 1
  %scevgep28.20.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7353, i64 0, i64 0, i64 1
  %7360 = bitcast i8* %scevgep28.20.29 to [61 x [61 x i8]]*
  %scevgep41.20.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7354, i64 0, i64 1, i64 0
  %7361 = bitcast i8* %scevgep41.20.29 to [61 x [61 x i8]]*
  %call16.20.30 = call zeroext i8 (...) @rand()
  store i8 %call16.20.30, i8* %scevgep28.20.29, align 1
  %7362 = load i8, i8* %scevgep28.20.29, align 1
  %conv23.20.30 = zext i8 %7362 to i32
  %7363 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.30 = getelementptr i8, i8* %b, i64 51
  %7364 = load i8, i8* %scevgep34.20.30, align 1
  %call28.20.30 = call zeroext i8 @mult(i8 zeroext %7363, i8 zeroext %7364)
  %conv29.20.30 = zext i8 %call28.20.30 to i32
  %xor.20.30 = xor i32 %conv23.20.30, %conv29.20.30
  %scevgep35.20.30 = getelementptr i8, i8* %a, i64 51
  %7365 = load i8, i8* %scevgep35.20.30, align 1
  %7366 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.30 = call zeroext i8 @mult(i8 zeroext %7365, i8 zeroext %7366)
  %conv35.20.30 = zext i8 %call34.20.30 to i32
  %xor36.20.30 = xor i32 %xor.20.30, %conv35.20.30
  %conv37.20.30 = trunc i32 %xor36.20.30 to i8
  store i8 %conv37.20.30, i8* %scevgep41.20.29, align 1
  %scevgep28.20.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7360, i64 0, i64 0, i64 1
  %7367 = bitcast i8* %scevgep28.20.30 to [61 x [61 x i8]]*
  %scevgep41.20.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7361, i64 0, i64 1, i64 0
  %7368 = bitcast i8* %scevgep41.20.30 to [61 x [61 x i8]]*
  %call16.20.31 = call zeroext i8 (...) @rand()
  store i8 %call16.20.31, i8* %scevgep28.20.30, align 1
  %7369 = load i8, i8* %scevgep28.20.30, align 1
  %conv23.20.31 = zext i8 %7369 to i32
  %7370 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.31 = getelementptr i8, i8* %b, i64 52
  %7371 = load i8, i8* %scevgep34.20.31, align 1
  %call28.20.31 = call zeroext i8 @mult(i8 zeroext %7370, i8 zeroext %7371)
  %conv29.20.31 = zext i8 %call28.20.31 to i32
  %xor.20.31 = xor i32 %conv23.20.31, %conv29.20.31
  %scevgep35.20.31 = getelementptr i8, i8* %a, i64 52
  %7372 = load i8, i8* %scevgep35.20.31, align 1
  %7373 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.31 = call zeroext i8 @mult(i8 zeroext %7372, i8 zeroext %7373)
  %conv35.20.31 = zext i8 %call34.20.31 to i32
  %xor36.20.31 = xor i32 %xor.20.31, %conv35.20.31
  %conv37.20.31 = trunc i32 %xor36.20.31 to i8
  store i8 %conv37.20.31, i8* %scevgep41.20.30, align 1
  %scevgep28.20.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7367, i64 0, i64 0, i64 1
  %7374 = bitcast i8* %scevgep28.20.31 to [61 x [61 x i8]]*
  %scevgep41.20.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7368, i64 0, i64 1, i64 0
  %7375 = bitcast i8* %scevgep41.20.31 to [61 x [61 x i8]]*
  %call16.20.32 = call zeroext i8 (...) @rand()
  store i8 %call16.20.32, i8* %scevgep28.20.31, align 1
  %7376 = load i8, i8* %scevgep28.20.31, align 1
  %conv23.20.32 = zext i8 %7376 to i32
  %7377 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.32 = getelementptr i8, i8* %b, i64 53
  %7378 = load i8, i8* %scevgep34.20.32, align 1
  %call28.20.32 = call zeroext i8 @mult(i8 zeroext %7377, i8 zeroext %7378)
  %conv29.20.32 = zext i8 %call28.20.32 to i32
  %xor.20.32 = xor i32 %conv23.20.32, %conv29.20.32
  %scevgep35.20.32 = getelementptr i8, i8* %a, i64 53
  %7379 = load i8, i8* %scevgep35.20.32, align 1
  %7380 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.32 = call zeroext i8 @mult(i8 zeroext %7379, i8 zeroext %7380)
  %conv35.20.32 = zext i8 %call34.20.32 to i32
  %xor36.20.32 = xor i32 %xor.20.32, %conv35.20.32
  %conv37.20.32 = trunc i32 %xor36.20.32 to i8
  store i8 %conv37.20.32, i8* %scevgep41.20.31, align 1
  %scevgep28.20.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7374, i64 0, i64 0, i64 1
  %7381 = bitcast i8* %scevgep28.20.32 to [61 x [61 x i8]]*
  %scevgep41.20.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7375, i64 0, i64 1, i64 0
  %7382 = bitcast i8* %scevgep41.20.32 to [61 x [61 x i8]]*
  %call16.20.33 = call zeroext i8 (...) @rand()
  store i8 %call16.20.33, i8* %scevgep28.20.32, align 1
  %7383 = load i8, i8* %scevgep28.20.32, align 1
  %conv23.20.33 = zext i8 %7383 to i32
  %7384 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.33 = getelementptr i8, i8* %b, i64 54
  %7385 = load i8, i8* %scevgep34.20.33, align 1
  %call28.20.33 = call zeroext i8 @mult(i8 zeroext %7384, i8 zeroext %7385)
  %conv29.20.33 = zext i8 %call28.20.33 to i32
  %xor.20.33 = xor i32 %conv23.20.33, %conv29.20.33
  %scevgep35.20.33 = getelementptr i8, i8* %a, i64 54
  %7386 = load i8, i8* %scevgep35.20.33, align 1
  %7387 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.33 = call zeroext i8 @mult(i8 zeroext %7386, i8 zeroext %7387)
  %conv35.20.33 = zext i8 %call34.20.33 to i32
  %xor36.20.33 = xor i32 %xor.20.33, %conv35.20.33
  %conv37.20.33 = trunc i32 %xor36.20.33 to i8
  store i8 %conv37.20.33, i8* %scevgep41.20.32, align 1
  %scevgep28.20.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7381, i64 0, i64 0, i64 1
  %7388 = bitcast i8* %scevgep28.20.33 to [61 x [61 x i8]]*
  %scevgep41.20.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7382, i64 0, i64 1, i64 0
  %7389 = bitcast i8* %scevgep41.20.33 to [61 x [61 x i8]]*
  %call16.20.34 = call zeroext i8 (...) @rand()
  store i8 %call16.20.34, i8* %scevgep28.20.33, align 1
  %7390 = load i8, i8* %scevgep28.20.33, align 1
  %conv23.20.34 = zext i8 %7390 to i32
  %7391 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.34 = getelementptr i8, i8* %b, i64 55
  %7392 = load i8, i8* %scevgep34.20.34, align 1
  %call28.20.34 = call zeroext i8 @mult(i8 zeroext %7391, i8 zeroext %7392)
  %conv29.20.34 = zext i8 %call28.20.34 to i32
  %xor.20.34 = xor i32 %conv23.20.34, %conv29.20.34
  %scevgep35.20.34 = getelementptr i8, i8* %a, i64 55
  %7393 = load i8, i8* %scevgep35.20.34, align 1
  %7394 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.34 = call zeroext i8 @mult(i8 zeroext %7393, i8 zeroext %7394)
  %conv35.20.34 = zext i8 %call34.20.34 to i32
  %xor36.20.34 = xor i32 %xor.20.34, %conv35.20.34
  %conv37.20.34 = trunc i32 %xor36.20.34 to i8
  store i8 %conv37.20.34, i8* %scevgep41.20.33, align 1
  %scevgep28.20.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7388, i64 0, i64 0, i64 1
  %7395 = bitcast i8* %scevgep28.20.34 to [61 x [61 x i8]]*
  %scevgep41.20.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7389, i64 0, i64 1, i64 0
  %7396 = bitcast i8* %scevgep41.20.34 to [61 x [61 x i8]]*
  %call16.20.35 = call zeroext i8 (...) @rand()
  store i8 %call16.20.35, i8* %scevgep28.20.34, align 1
  %7397 = load i8, i8* %scevgep28.20.34, align 1
  %conv23.20.35 = zext i8 %7397 to i32
  %7398 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.35 = getelementptr i8, i8* %b, i64 56
  %7399 = load i8, i8* %scevgep34.20.35, align 1
  %call28.20.35 = call zeroext i8 @mult(i8 zeroext %7398, i8 zeroext %7399)
  %conv29.20.35 = zext i8 %call28.20.35 to i32
  %xor.20.35 = xor i32 %conv23.20.35, %conv29.20.35
  %scevgep35.20.35 = getelementptr i8, i8* %a, i64 56
  %7400 = load i8, i8* %scevgep35.20.35, align 1
  %7401 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.35 = call zeroext i8 @mult(i8 zeroext %7400, i8 zeroext %7401)
  %conv35.20.35 = zext i8 %call34.20.35 to i32
  %xor36.20.35 = xor i32 %xor.20.35, %conv35.20.35
  %conv37.20.35 = trunc i32 %xor36.20.35 to i8
  store i8 %conv37.20.35, i8* %scevgep41.20.34, align 1
  %scevgep28.20.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7395, i64 0, i64 0, i64 1
  %7402 = bitcast i8* %scevgep28.20.35 to [61 x [61 x i8]]*
  %scevgep41.20.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7396, i64 0, i64 1, i64 0
  %7403 = bitcast i8* %scevgep41.20.35 to [61 x [61 x i8]]*
  %call16.20.36 = call zeroext i8 (...) @rand()
  store i8 %call16.20.36, i8* %scevgep28.20.35, align 1
  %7404 = load i8, i8* %scevgep28.20.35, align 1
  %conv23.20.36 = zext i8 %7404 to i32
  %7405 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.36 = getelementptr i8, i8* %b, i64 57
  %7406 = load i8, i8* %scevgep34.20.36, align 1
  %call28.20.36 = call zeroext i8 @mult(i8 zeroext %7405, i8 zeroext %7406)
  %conv29.20.36 = zext i8 %call28.20.36 to i32
  %xor.20.36 = xor i32 %conv23.20.36, %conv29.20.36
  %scevgep35.20.36 = getelementptr i8, i8* %a, i64 57
  %7407 = load i8, i8* %scevgep35.20.36, align 1
  %7408 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.36 = call zeroext i8 @mult(i8 zeroext %7407, i8 zeroext %7408)
  %conv35.20.36 = zext i8 %call34.20.36 to i32
  %xor36.20.36 = xor i32 %xor.20.36, %conv35.20.36
  %conv37.20.36 = trunc i32 %xor36.20.36 to i8
  store i8 %conv37.20.36, i8* %scevgep41.20.35, align 1
  %scevgep28.20.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7402, i64 0, i64 0, i64 1
  %7409 = bitcast i8* %scevgep28.20.36 to [61 x [61 x i8]]*
  %scevgep41.20.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7403, i64 0, i64 1, i64 0
  %7410 = bitcast i8* %scevgep41.20.36 to [61 x [61 x i8]]*
  %call16.20.37 = call zeroext i8 (...) @rand()
  store i8 %call16.20.37, i8* %scevgep28.20.36, align 1
  %7411 = load i8, i8* %scevgep28.20.36, align 1
  %conv23.20.37 = zext i8 %7411 to i32
  %7412 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.37 = getelementptr i8, i8* %b, i64 58
  %7413 = load i8, i8* %scevgep34.20.37, align 1
  %call28.20.37 = call zeroext i8 @mult(i8 zeroext %7412, i8 zeroext %7413)
  %conv29.20.37 = zext i8 %call28.20.37 to i32
  %xor.20.37 = xor i32 %conv23.20.37, %conv29.20.37
  %scevgep35.20.37 = getelementptr i8, i8* %a, i64 58
  %7414 = load i8, i8* %scevgep35.20.37, align 1
  %7415 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.37 = call zeroext i8 @mult(i8 zeroext %7414, i8 zeroext %7415)
  %conv35.20.37 = zext i8 %call34.20.37 to i32
  %xor36.20.37 = xor i32 %xor.20.37, %conv35.20.37
  %conv37.20.37 = trunc i32 %xor36.20.37 to i8
  store i8 %conv37.20.37, i8* %scevgep41.20.36, align 1
  %scevgep28.20.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7409, i64 0, i64 0, i64 1
  %7416 = bitcast i8* %scevgep28.20.37 to [61 x [61 x i8]]*
  %scevgep41.20.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7410, i64 0, i64 1, i64 0
  %7417 = bitcast i8* %scevgep41.20.37 to [61 x [61 x i8]]*
  %call16.20.38 = call zeroext i8 (...) @rand()
  store i8 %call16.20.38, i8* %scevgep28.20.37, align 1
  %7418 = load i8, i8* %scevgep28.20.37, align 1
  %conv23.20.38 = zext i8 %7418 to i32
  %7419 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.38 = getelementptr i8, i8* %b, i64 59
  %7420 = load i8, i8* %scevgep34.20.38, align 1
  %call28.20.38 = call zeroext i8 @mult(i8 zeroext %7419, i8 zeroext %7420)
  %conv29.20.38 = zext i8 %call28.20.38 to i32
  %xor.20.38 = xor i32 %conv23.20.38, %conv29.20.38
  %scevgep35.20.38 = getelementptr i8, i8* %a, i64 59
  %7421 = load i8, i8* %scevgep35.20.38, align 1
  %7422 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.38 = call zeroext i8 @mult(i8 zeroext %7421, i8 zeroext %7422)
  %conv35.20.38 = zext i8 %call34.20.38 to i32
  %xor36.20.38 = xor i32 %xor.20.38, %conv35.20.38
  %conv37.20.38 = trunc i32 %xor36.20.38 to i8
  store i8 %conv37.20.38, i8* %scevgep41.20.37, align 1
  %scevgep28.20.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7416, i64 0, i64 0, i64 1
  %scevgep41.20.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7417, i64 0, i64 1, i64 0
  %call16.20.39 = call zeroext i8 (...) @rand()
  store i8 %call16.20.39, i8* %scevgep28.20.38, align 1
  %7423 = load i8, i8* %scevgep28.20.38, align 1
  %conv23.20.39 = zext i8 %7423 to i32
  %7424 = load i8, i8* %arrayidx25.20, align 1
  %scevgep34.20.39 = getelementptr i8, i8* %b, i64 60
  %7425 = load i8, i8* %scevgep34.20.39, align 1
  %call28.20.39 = call zeroext i8 @mult(i8 zeroext %7424, i8 zeroext %7425)
  %conv29.20.39 = zext i8 %call28.20.39 to i32
  %xor.20.39 = xor i32 %conv23.20.39, %conv29.20.39
  %scevgep35.20.39 = getelementptr i8, i8* %a, i64 60
  %7426 = load i8, i8* %scevgep35.20.39, align 1
  %7427 = load i8, i8* %arrayidx33.20, align 1
  %call34.20.39 = call zeroext i8 @mult(i8 zeroext %7426, i8 zeroext %7427)
  %conv35.20.39 = zext i8 %call34.20.39 to i32
  %xor36.20.39 = xor i32 %xor.20.39, %conv35.20.39
  %conv37.20.39 = trunc i32 %xor36.20.39 to i8
  store i8 %conv37.20.39, i8* %scevgep41.20.38, align 1
  %scevgep26.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7150, i64 0, i64 1, i64 1
  %7428 = bitcast i8* %scevgep26.20 to [61 x [61 x i8]]*
  %scevgep39.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7151, i64 0, i64 1, i64 1
  %7429 = bitcast i8* %scevgep39.20 to [61 x [61 x i8]]*
  %arrayidx25.21 = getelementptr inbounds i8, i8* %a, i64 21
  %arrayidx33.21 = getelementptr inbounds i8, i8* %b, i64 21
  %call16.21 = call zeroext i8 (...) @rand()
  store i8 %call16.21, i8* %scevgep26.20, align 1
  %7430 = load i8, i8* %scevgep26.20, align 1
  %conv23.21 = zext i8 %7430 to i32
  %7431 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21 = getelementptr i8, i8* %b, i64 22
  %7432 = load i8, i8* %scevgep34.21, align 1
  %call28.21 = call zeroext i8 @mult(i8 zeroext %7431, i8 zeroext %7432)
  %conv29.21 = zext i8 %call28.21 to i32
  %xor.21 = xor i32 %conv23.21, %conv29.21
  %scevgep35.21 = getelementptr i8, i8* %a, i64 22
  %7433 = load i8, i8* %scevgep35.21, align 1
  %7434 = load i8, i8* %arrayidx33.21, align 1
  %call34.21 = call zeroext i8 @mult(i8 zeroext %7433, i8 zeroext %7434)
  %conv35.21 = zext i8 %call34.21 to i32
  %xor36.21 = xor i32 %xor.21, %conv35.21
  %conv37.21 = trunc i32 %xor36.21 to i8
  store i8 %conv37.21, i8* %scevgep39.20, align 1
  %scevgep28.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7428, i64 0, i64 0, i64 1
  %7435 = bitcast i8* %scevgep28.21 to [61 x [61 x i8]]*
  %scevgep41.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7429, i64 0, i64 1, i64 0
  %7436 = bitcast i8* %scevgep41.21 to [61 x [61 x i8]]*
  %call16.21.1 = call zeroext i8 (...) @rand()
  store i8 %call16.21.1, i8* %scevgep28.21, align 1
  %7437 = load i8, i8* %scevgep28.21, align 1
  %conv23.21.1 = zext i8 %7437 to i32
  %7438 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.1 = getelementptr i8, i8* %b, i64 23
  %7439 = load i8, i8* %scevgep34.21.1, align 1
  %call28.21.1 = call zeroext i8 @mult(i8 zeroext %7438, i8 zeroext %7439)
  %conv29.21.1 = zext i8 %call28.21.1 to i32
  %xor.21.1 = xor i32 %conv23.21.1, %conv29.21.1
  %scevgep35.21.1 = getelementptr i8, i8* %a, i64 23
  %7440 = load i8, i8* %scevgep35.21.1, align 1
  %7441 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.1 = call zeroext i8 @mult(i8 zeroext %7440, i8 zeroext %7441)
  %conv35.21.1 = zext i8 %call34.21.1 to i32
  %xor36.21.1 = xor i32 %xor.21.1, %conv35.21.1
  %conv37.21.1 = trunc i32 %xor36.21.1 to i8
  store i8 %conv37.21.1, i8* %scevgep41.21, align 1
  %scevgep28.21.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7435, i64 0, i64 0, i64 1
  %7442 = bitcast i8* %scevgep28.21.1 to [61 x [61 x i8]]*
  %scevgep41.21.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7436, i64 0, i64 1, i64 0
  %7443 = bitcast i8* %scevgep41.21.1 to [61 x [61 x i8]]*
  %call16.21.2 = call zeroext i8 (...) @rand()
  store i8 %call16.21.2, i8* %scevgep28.21.1, align 1
  %7444 = load i8, i8* %scevgep28.21.1, align 1
  %conv23.21.2 = zext i8 %7444 to i32
  %7445 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.2 = getelementptr i8, i8* %b, i64 24
  %7446 = load i8, i8* %scevgep34.21.2, align 1
  %call28.21.2 = call zeroext i8 @mult(i8 zeroext %7445, i8 zeroext %7446)
  %conv29.21.2 = zext i8 %call28.21.2 to i32
  %xor.21.2 = xor i32 %conv23.21.2, %conv29.21.2
  %scevgep35.21.2 = getelementptr i8, i8* %a, i64 24
  %7447 = load i8, i8* %scevgep35.21.2, align 1
  %7448 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.2 = call zeroext i8 @mult(i8 zeroext %7447, i8 zeroext %7448)
  %conv35.21.2 = zext i8 %call34.21.2 to i32
  %xor36.21.2 = xor i32 %xor.21.2, %conv35.21.2
  %conv37.21.2 = trunc i32 %xor36.21.2 to i8
  store i8 %conv37.21.2, i8* %scevgep41.21.1, align 1
  %scevgep28.21.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7442, i64 0, i64 0, i64 1
  %7449 = bitcast i8* %scevgep28.21.2 to [61 x [61 x i8]]*
  %scevgep41.21.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7443, i64 0, i64 1, i64 0
  %7450 = bitcast i8* %scevgep41.21.2 to [61 x [61 x i8]]*
  %call16.21.3 = call zeroext i8 (...) @rand()
  store i8 %call16.21.3, i8* %scevgep28.21.2, align 1
  %7451 = load i8, i8* %scevgep28.21.2, align 1
  %conv23.21.3 = zext i8 %7451 to i32
  %7452 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.3 = getelementptr i8, i8* %b, i64 25
  %7453 = load i8, i8* %scevgep34.21.3, align 1
  %call28.21.3 = call zeroext i8 @mult(i8 zeroext %7452, i8 zeroext %7453)
  %conv29.21.3 = zext i8 %call28.21.3 to i32
  %xor.21.3 = xor i32 %conv23.21.3, %conv29.21.3
  %scevgep35.21.3 = getelementptr i8, i8* %a, i64 25
  %7454 = load i8, i8* %scevgep35.21.3, align 1
  %7455 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.3 = call zeroext i8 @mult(i8 zeroext %7454, i8 zeroext %7455)
  %conv35.21.3 = zext i8 %call34.21.3 to i32
  %xor36.21.3 = xor i32 %xor.21.3, %conv35.21.3
  %conv37.21.3 = trunc i32 %xor36.21.3 to i8
  store i8 %conv37.21.3, i8* %scevgep41.21.2, align 1
  %scevgep28.21.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7449, i64 0, i64 0, i64 1
  %7456 = bitcast i8* %scevgep28.21.3 to [61 x [61 x i8]]*
  %scevgep41.21.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7450, i64 0, i64 1, i64 0
  %7457 = bitcast i8* %scevgep41.21.3 to [61 x [61 x i8]]*
  %call16.21.4 = call zeroext i8 (...) @rand()
  store i8 %call16.21.4, i8* %scevgep28.21.3, align 1
  %7458 = load i8, i8* %scevgep28.21.3, align 1
  %conv23.21.4 = zext i8 %7458 to i32
  %7459 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.4 = getelementptr i8, i8* %b, i64 26
  %7460 = load i8, i8* %scevgep34.21.4, align 1
  %call28.21.4 = call zeroext i8 @mult(i8 zeroext %7459, i8 zeroext %7460)
  %conv29.21.4 = zext i8 %call28.21.4 to i32
  %xor.21.4 = xor i32 %conv23.21.4, %conv29.21.4
  %scevgep35.21.4 = getelementptr i8, i8* %a, i64 26
  %7461 = load i8, i8* %scevgep35.21.4, align 1
  %7462 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.4 = call zeroext i8 @mult(i8 zeroext %7461, i8 zeroext %7462)
  %conv35.21.4 = zext i8 %call34.21.4 to i32
  %xor36.21.4 = xor i32 %xor.21.4, %conv35.21.4
  %conv37.21.4 = trunc i32 %xor36.21.4 to i8
  store i8 %conv37.21.4, i8* %scevgep41.21.3, align 1
  %scevgep28.21.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7456, i64 0, i64 0, i64 1
  %7463 = bitcast i8* %scevgep28.21.4 to [61 x [61 x i8]]*
  %scevgep41.21.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7457, i64 0, i64 1, i64 0
  %7464 = bitcast i8* %scevgep41.21.4 to [61 x [61 x i8]]*
  %call16.21.5 = call zeroext i8 (...) @rand()
  store i8 %call16.21.5, i8* %scevgep28.21.4, align 1
  %7465 = load i8, i8* %scevgep28.21.4, align 1
  %conv23.21.5 = zext i8 %7465 to i32
  %7466 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.5 = getelementptr i8, i8* %b, i64 27
  %7467 = load i8, i8* %scevgep34.21.5, align 1
  %call28.21.5 = call zeroext i8 @mult(i8 zeroext %7466, i8 zeroext %7467)
  %conv29.21.5 = zext i8 %call28.21.5 to i32
  %xor.21.5 = xor i32 %conv23.21.5, %conv29.21.5
  %scevgep35.21.5 = getelementptr i8, i8* %a, i64 27
  %7468 = load i8, i8* %scevgep35.21.5, align 1
  %7469 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.5 = call zeroext i8 @mult(i8 zeroext %7468, i8 zeroext %7469)
  %conv35.21.5 = zext i8 %call34.21.5 to i32
  %xor36.21.5 = xor i32 %xor.21.5, %conv35.21.5
  %conv37.21.5 = trunc i32 %xor36.21.5 to i8
  store i8 %conv37.21.5, i8* %scevgep41.21.4, align 1
  %scevgep28.21.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7463, i64 0, i64 0, i64 1
  %7470 = bitcast i8* %scevgep28.21.5 to [61 x [61 x i8]]*
  %scevgep41.21.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7464, i64 0, i64 1, i64 0
  %7471 = bitcast i8* %scevgep41.21.5 to [61 x [61 x i8]]*
  %call16.21.6 = call zeroext i8 (...) @rand()
  store i8 %call16.21.6, i8* %scevgep28.21.5, align 1
  %7472 = load i8, i8* %scevgep28.21.5, align 1
  %conv23.21.6 = zext i8 %7472 to i32
  %7473 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.6 = getelementptr i8, i8* %b, i64 28
  %7474 = load i8, i8* %scevgep34.21.6, align 1
  %call28.21.6 = call zeroext i8 @mult(i8 zeroext %7473, i8 zeroext %7474)
  %conv29.21.6 = zext i8 %call28.21.6 to i32
  %xor.21.6 = xor i32 %conv23.21.6, %conv29.21.6
  %scevgep35.21.6 = getelementptr i8, i8* %a, i64 28
  %7475 = load i8, i8* %scevgep35.21.6, align 1
  %7476 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.6 = call zeroext i8 @mult(i8 zeroext %7475, i8 zeroext %7476)
  %conv35.21.6 = zext i8 %call34.21.6 to i32
  %xor36.21.6 = xor i32 %xor.21.6, %conv35.21.6
  %conv37.21.6 = trunc i32 %xor36.21.6 to i8
  store i8 %conv37.21.6, i8* %scevgep41.21.5, align 1
  %scevgep28.21.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7470, i64 0, i64 0, i64 1
  %7477 = bitcast i8* %scevgep28.21.6 to [61 x [61 x i8]]*
  %scevgep41.21.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7471, i64 0, i64 1, i64 0
  %7478 = bitcast i8* %scevgep41.21.6 to [61 x [61 x i8]]*
  %call16.21.7 = call zeroext i8 (...) @rand()
  store i8 %call16.21.7, i8* %scevgep28.21.6, align 1
  %7479 = load i8, i8* %scevgep28.21.6, align 1
  %conv23.21.7 = zext i8 %7479 to i32
  %7480 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.7 = getelementptr i8, i8* %b, i64 29
  %7481 = load i8, i8* %scevgep34.21.7, align 1
  %call28.21.7 = call zeroext i8 @mult(i8 zeroext %7480, i8 zeroext %7481)
  %conv29.21.7 = zext i8 %call28.21.7 to i32
  %xor.21.7 = xor i32 %conv23.21.7, %conv29.21.7
  %scevgep35.21.7 = getelementptr i8, i8* %a, i64 29
  %7482 = load i8, i8* %scevgep35.21.7, align 1
  %7483 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.7 = call zeroext i8 @mult(i8 zeroext %7482, i8 zeroext %7483)
  %conv35.21.7 = zext i8 %call34.21.7 to i32
  %xor36.21.7 = xor i32 %xor.21.7, %conv35.21.7
  %conv37.21.7 = trunc i32 %xor36.21.7 to i8
  store i8 %conv37.21.7, i8* %scevgep41.21.6, align 1
  %scevgep28.21.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7477, i64 0, i64 0, i64 1
  %7484 = bitcast i8* %scevgep28.21.7 to [61 x [61 x i8]]*
  %scevgep41.21.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7478, i64 0, i64 1, i64 0
  %7485 = bitcast i8* %scevgep41.21.7 to [61 x [61 x i8]]*
  %call16.21.8 = call zeroext i8 (...) @rand()
  store i8 %call16.21.8, i8* %scevgep28.21.7, align 1
  %7486 = load i8, i8* %scevgep28.21.7, align 1
  %conv23.21.8 = zext i8 %7486 to i32
  %7487 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.8 = getelementptr i8, i8* %b, i64 30
  %7488 = load i8, i8* %scevgep34.21.8, align 1
  %call28.21.8 = call zeroext i8 @mult(i8 zeroext %7487, i8 zeroext %7488)
  %conv29.21.8 = zext i8 %call28.21.8 to i32
  %xor.21.8 = xor i32 %conv23.21.8, %conv29.21.8
  %scevgep35.21.8 = getelementptr i8, i8* %a, i64 30
  %7489 = load i8, i8* %scevgep35.21.8, align 1
  %7490 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.8 = call zeroext i8 @mult(i8 zeroext %7489, i8 zeroext %7490)
  %conv35.21.8 = zext i8 %call34.21.8 to i32
  %xor36.21.8 = xor i32 %xor.21.8, %conv35.21.8
  %conv37.21.8 = trunc i32 %xor36.21.8 to i8
  store i8 %conv37.21.8, i8* %scevgep41.21.7, align 1
  %scevgep28.21.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7484, i64 0, i64 0, i64 1
  %7491 = bitcast i8* %scevgep28.21.8 to [61 x [61 x i8]]*
  %scevgep41.21.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7485, i64 0, i64 1, i64 0
  %7492 = bitcast i8* %scevgep41.21.8 to [61 x [61 x i8]]*
  %call16.21.9 = call zeroext i8 (...) @rand()
  store i8 %call16.21.9, i8* %scevgep28.21.8, align 1
  %7493 = load i8, i8* %scevgep28.21.8, align 1
  %conv23.21.9 = zext i8 %7493 to i32
  %7494 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.9 = getelementptr i8, i8* %b, i64 31
  %7495 = load i8, i8* %scevgep34.21.9, align 1
  %call28.21.9 = call zeroext i8 @mult(i8 zeroext %7494, i8 zeroext %7495)
  %conv29.21.9 = zext i8 %call28.21.9 to i32
  %xor.21.9 = xor i32 %conv23.21.9, %conv29.21.9
  %scevgep35.21.9 = getelementptr i8, i8* %a, i64 31
  %7496 = load i8, i8* %scevgep35.21.9, align 1
  %7497 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.9 = call zeroext i8 @mult(i8 zeroext %7496, i8 zeroext %7497)
  %conv35.21.9 = zext i8 %call34.21.9 to i32
  %xor36.21.9 = xor i32 %xor.21.9, %conv35.21.9
  %conv37.21.9 = trunc i32 %xor36.21.9 to i8
  store i8 %conv37.21.9, i8* %scevgep41.21.8, align 1
  %scevgep28.21.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7491, i64 0, i64 0, i64 1
  %7498 = bitcast i8* %scevgep28.21.9 to [61 x [61 x i8]]*
  %scevgep41.21.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7492, i64 0, i64 1, i64 0
  %7499 = bitcast i8* %scevgep41.21.9 to [61 x [61 x i8]]*
  %call16.21.10 = call zeroext i8 (...) @rand()
  store i8 %call16.21.10, i8* %scevgep28.21.9, align 1
  %7500 = load i8, i8* %scevgep28.21.9, align 1
  %conv23.21.10 = zext i8 %7500 to i32
  %7501 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.10 = getelementptr i8, i8* %b, i64 32
  %7502 = load i8, i8* %scevgep34.21.10, align 1
  %call28.21.10 = call zeroext i8 @mult(i8 zeroext %7501, i8 zeroext %7502)
  %conv29.21.10 = zext i8 %call28.21.10 to i32
  %xor.21.10 = xor i32 %conv23.21.10, %conv29.21.10
  %scevgep35.21.10 = getelementptr i8, i8* %a, i64 32
  %7503 = load i8, i8* %scevgep35.21.10, align 1
  %7504 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.10 = call zeroext i8 @mult(i8 zeroext %7503, i8 zeroext %7504)
  %conv35.21.10 = zext i8 %call34.21.10 to i32
  %xor36.21.10 = xor i32 %xor.21.10, %conv35.21.10
  %conv37.21.10 = trunc i32 %xor36.21.10 to i8
  store i8 %conv37.21.10, i8* %scevgep41.21.9, align 1
  %scevgep28.21.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7498, i64 0, i64 0, i64 1
  %7505 = bitcast i8* %scevgep28.21.10 to [61 x [61 x i8]]*
  %scevgep41.21.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7499, i64 0, i64 1, i64 0
  %7506 = bitcast i8* %scevgep41.21.10 to [61 x [61 x i8]]*
  %call16.21.11 = call zeroext i8 (...) @rand()
  store i8 %call16.21.11, i8* %scevgep28.21.10, align 1
  %7507 = load i8, i8* %scevgep28.21.10, align 1
  %conv23.21.11 = zext i8 %7507 to i32
  %7508 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.11 = getelementptr i8, i8* %b, i64 33
  %7509 = load i8, i8* %scevgep34.21.11, align 1
  %call28.21.11 = call zeroext i8 @mult(i8 zeroext %7508, i8 zeroext %7509)
  %conv29.21.11 = zext i8 %call28.21.11 to i32
  %xor.21.11 = xor i32 %conv23.21.11, %conv29.21.11
  %scevgep35.21.11 = getelementptr i8, i8* %a, i64 33
  %7510 = load i8, i8* %scevgep35.21.11, align 1
  %7511 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.11 = call zeroext i8 @mult(i8 zeroext %7510, i8 zeroext %7511)
  %conv35.21.11 = zext i8 %call34.21.11 to i32
  %xor36.21.11 = xor i32 %xor.21.11, %conv35.21.11
  %conv37.21.11 = trunc i32 %xor36.21.11 to i8
  store i8 %conv37.21.11, i8* %scevgep41.21.10, align 1
  %scevgep28.21.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7505, i64 0, i64 0, i64 1
  %7512 = bitcast i8* %scevgep28.21.11 to [61 x [61 x i8]]*
  %scevgep41.21.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7506, i64 0, i64 1, i64 0
  %7513 = bitcast i8* %scevgep41.21.11 to [61 x [61 x i8]]*
  %call16.21.12 = call zeroext i8 (...) @rand()
  store i8 %call16.21.12, i8* %scevgep28.21.11, align 1
  %7514 = load i8, i8* %scevgep28.21.11, align 1
  %conv23.21.12 = zext i8 %7514 to i32
  %7515 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.12 = getelementptr i8, i8* %b, i64 34
  %7516 = load i8, i8* %scevgep34.21.12, align 1
  %call28.21.12 = call zeroext i8 @mult(i8 zeroext %7515, i8 zeroext %7516)
  %conv29.21.12 = zext i8 %call28.21.12 to i32
  %xor.21.12 = xor i32 %conv23.21.12, %conv29.21.12
  %scevgep35.21.12 = getelementptr i8, i8* %a, i64 34
  %7517 = load i8, i8* %scevgep35.21.12, align 1
  %7518 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.12 = call zeroext i8 @mult(i8 zeroext %7517, i8 zeroext %7518)
  %conv35.21.12 = zext i8 %call34.21.12 to i32
  %xor36.21.12 = xor i32 %xor.21.12, %conv35.21.12
  %conv37.21.12 = trunc i32 %xor36.21.12 to i8
  store i8 %conv37.21.12, i8* %scevgep41.21.11, align 1
  %scevgep28.21.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7512, i64 0, i64 0, i64 1
  %7519 = bitcast i8* %scevgep28.21.12 to [61 x [61 x i8]]*
  %scevgep41.21.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7513, i64 0, i64 1, i64 0
  %7520 = bitcast i8* %scevgep41.21.12 to [61 x [61 x i8]]*
  %call16.21.13 = call zeroext i8 (...) @rand()
  store i8 %call16.21.13, i8* %scevgep28.21.12, align 1
  %7521 = load i8, i8* %scevgep28.21.12, align 1
  %conv23.21.13 = zext i8 %7521 to i32
  %7522 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.13 = getelementptr i8, i8* %b, i64 35
  %7523 = load i8, i8* %scevgep34.21.13, align 1
  %call28.21.13 = call zeroext i8 @mult(i8 zeroext %7522, i8 zeroext %7523)
  %conv29.21.13 = zext i8 %call28.21.13 to i32
  %xor.21.13 = xor i32 %conv23.21.13, %conv29.21.13
  %scevgep35.21.13 = getelementptr i8, i8* %a, i64 35
  %7524 = load i8, i8* %scevgep35.21.13, align 1
  %7525 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.13 = call zeroext i8 @mult(i8 zeroext %7524, i8 zeroext %7525)
  %conv35.21.13 = zext i8 %call34.21.13 to i32
  %xor36.21.13 = xor i32 %xor.21.13, %conv35.21.13
  %conv37.21.13 = trunc i32 %xor36.21.13 to i8
  store i8 %conv37.21.13, i8* %scevgep41.21.12, align 1
  %scevgep28.21.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7519, i64 0, i64 0, i64 1
  %7526 = bitcast i8* %scevgep28.21.13 to [61 x [61 x i8]]*
  %scevgep41.21.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7520, i64 0, i64 1, i64 0
  %7527 = bitcast i8* %scevgep41.21.13 to [61 x [61 x i8]]*
  %call16.21.14 = call zeroext i8 (...) @rand()
  store i8 %call16.21.14, i8* %scevgep28.21.13, align 1
  %7528 = load i8, i8* %scevgep28.21.13, align 1
  %conv23.21.14 = zext i8 %7528 to i32
  %7529 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.14 = getelementptr i8, i8* %b, i64 36
  %7530 = load i8, i8* %scevgep34.21.14, align 1
  %call28.21.14 = call zeroext i8 @mult(i8 zeroext %7529, i8 zeroext %7530)
  %conv29.21.14 = zext i8 %call28.21.14 to i32
  %xor.21.14 = xor i32 %conv23.21.14, %conv29.21.14
  %scevgep35.21.14 = getelementptr i8, i8* %a, i64 36
  %7531 = load i8, i8* %scevgep35.21.14, align 1
  %7532 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.14 = call zeroext i8 @mult(i8 zeroext %7531, i8 zeroext %7532)
  %conv35.21.14 = zext i8 %call34.21.14 to i32
  %xor36.21.14 = xor i32 %xor.21.14, %conv35.21.14
  %conv37.21.14 = trunc i32 %xor36.21.14 to i8
  store i8 %conv37.21.14, i8* %scevgep41.21.13, align 1
  %scevgep28.21.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7526, i64 0, i64 0, i64 1
  %7533 = bitcast i8* %scevgep28.21.14 to [61 x [61 x i8]]*
  %scevgep41.21.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7527, i64 0, i64 1, i64 0
  %7534 = bitcast i8* %scevgep41.21.14 to [61 x [61 x i8]]*
  %call16.21.15 = call zeroext i8 (...) @rand()
  store i8 %call16.21.15, i8* %scevgep28.21.14, align 1
  %7535 = load i8, i8* %scevgep28.21.14, align 1
  %conv23.21.15 = zext i8 %7535 to i32
  %7536 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.15 = getelementptr i8, i8* %b, i64 37
  %7537 = load i8, i8* %scevgep34.21.15, align 1
  %call28.21.15 = call zeroext i8 @mult(i8 zeroext %7536, i8 zeroext %7537)
  %conv29.21.15 = zext i8 %call28.21.15 to i32
  %xor.21.15 = xor i32 %conv23.21.15, %conv29.21.15
  %scevgep35.21.15 = getelementptr i8, i8* %a, i64 37
  %7538 = load i8, i8* %scevgep35.21.15, align 1
  %7539 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.15 = call zeroext i8 @mult(i8 zeroext %7538, i8 zeroext %7539)
  %conv35.21.15 = zext i8 %call34.21.15 to i32
  %xor36.21.15 = xor i32 %xor.21.15, %conv35.21.15
  %conv37.21.15 = trunc i32 %xor36.21.15 to i8
  store i8 %conv37.21.15, i8* %scevgep41.21.14, align 1
  %scevgep28.21.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7533, i64 0, i64 0, i64 1
  %7540 = bitcast i8* %scevgep28.21.15 to [61 x [61 x i8]]*
  %scevgep41.21.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7534, i64 0, i64 1, i64 0
  %7541 = bitcast i8* %scevgep41.21.15 to [61 x [61 x i8]]*
  %call16.21.16 = call zeroext i8 (...) @rand()
  store i8 %call16.21.16, i8* %scevgep28.21.15, align 1
  %7542 = load i8, i8* %scevgep28.21.15, align 1
  %conv23.21.16 = zext i8 %7542 to i32
  %7543 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.16 = getelementptr i8, i8* %b, i64 38
  %7544 = load i8, i8* %scevgep34.21.16, align 1
  %call28.21.16 = call zeroext i8 @mult(i8 zeroext %7543, i8 zeroext %7544)
  %conv29.21.16 = zext i8 %call28.21.16 to i32
  %xor.21.16 = xor i32 %conv23.21.16, %conv29.21.16
  %scevgep35.21.16 = getelementptr i8, i8* %a, i64 38
  %7545 = load i8, i8* %scevgep35.21.16, align 1
  %7546 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.16 = call zeroext i8 @mult(i8 zeroext %7545, i8 zeroext %7546)
  %conv35.21.16 = zext i8 %call34.21.16 to i32
  %xor36.21.16 = xor i32 %xor.21.16, %conv35.21.16
  %conv37.21.16 = trunc i32 %xor36.21.16 to i8
  store i8 %conv37.21.16, i8* %scevgep41.21.15, align 1
  %scevgep28.21.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7540, i64 0, i64 0, i64 1
  %7547 = bitcast i8* %scevgep28.21.16 to [61 x [61 x i8]]*
  %scevgep41.21.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7541, i64 0, i64 1, i64 0
  %7548 = bitcast i8* %scevgep41.21.16 to [61 x [61 x i8]]*
  %call16.21.17 = call zeroext i8 (...) @rand()
  store i8 %call16.21.17, i8* %scevgep28.21.16, align 1
  %7549 = load i8, i8* %scevgep28.21.16, align 1
  %conv23.21.17 = zext i8 %7549 to i32
  %7550 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.17 = getelementptr i8, i8* %b, i64 39
  %7551 = load i8, i8* %scevgep34.21.17, align 1
  %call28.21.17 = call zeroext i8 @mult(i8 zeroext %7550, i8 zeroext %7551)
  %conv29.21.17 = zext i8 %call28.21.17 to i32
  %xor.21.17 = xor i32 %conv23.21.17, %conv29.21.17
  %scevgep35.21.17 = getelementptr i8, i8* %a, i64 39
  %7552 = load i8, i8* %scevgep35.21.17, align 1
  %7553 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.17 = call zeroext i8 @mult(i8 zeroext %7552, i8 zeroext %7553)
  %conv35.21.17 = zext i8 %call34.21.17 to i32
  %xor36.21.17 = xor i32 %xor.21.17, %conv35.21.17
  %conv37.21.17 = trunc i32 %xor36.21.17 to i8
  store i8 %conv37.21.17, i8* %scevgep41.21.16, align 1
  %scevgep28.21.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7547, i64 0, i64 0, i64 1
  %7554 = bitcast i8* %scevgep28.21.17 to [61 x [61 x i8]]*
  %scevgep41.21.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7548, i64 0, i64 1, i64 0
  %7555 = bitcast i8* %scevgep41.21.17 to [61 x [61 x i8]]*
  %call16.21.18 = call zeroext i8 (...) @rand()
  store i8 %call16.21.18, i8* %scevgep28.21.17, align 1
  %7556 = load i8, i8* %scevgep28.21.17, align 1
  %conv23.21.18 = zext i8 %7556 to i32
  %7557 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.18 = getelementptr i8, i8* %b, i64 40
  %7558 = load i8, i8* %scevgep34.21.18, align 1
  %call28.21.18 = call zeroext i8 @mult(i8 zeroext %7557, i8 zeroext %7558)
  %conv29.21.18 = zext i8 %call28.21.18 to i32
  %xor.21.18 = xor i32 %conv23.21.18, %conv29.21.18
  %scevgep35.21.18 = getelementptr i8, i8* %a, i64 40
  %7559 = load i8, i8* %scevgep35.21.18, align 1
  %7560 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.18 = call zeroext i8 @mult(i8 zeroext %7559, i8 zeroext %7560)
  %conv35.21.18 = zext i8 %call34.21.18 to i32
  %xor36.21.18 = xor i32 %xor.21.18, %conv35.21.18
  %conv37.21.18 = trunc i32 %xor36.21.18 to i8
  store i8 %conv37.21.18, i8* %scevgep41.21.17, align 1
  %scevgep28.21.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7554, i64 0, i64 0, i64 1
  %7561 = bitcast i8* %scevgep28.21.18 to [61 x [61 x i8]]*
  %scevgep41.21.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7555, i64 0, i64 1, i64 0
  %7562 = bitcast i8* %scevgep41.21.18 to [61 x [61 x i8]]*
  %call16.21.19 = call zeroext i8 (...) @rand()
  store i8 %call16.21.19, i8* %scevgep28.21.18, align 1
  %7563 = load i8, i8* %scevgep28.21.18, align 1
  %conv23.21.19 = zext i8 %7563 to i32
  %7564 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.19 = getelementptr i8, i8* %b, i64 41
  %7565 = load i8, i8* %scevgep34.21.19, align 1
  %call28.21.19 = call zeroext i8 @mult(i8 zeroext %7564, i8 zeroext %7565)
  %conv29.21.19 = zext i8 %call28.21.19 to i32
  %xor.21.19 = xor i32 %conv23.21.19, %conv29.21.19
  %scevgep35.21.19 = getelementptr i8, i8* %a, i64 41
  %7566 = load i8, i8* %scevgep35.21.19, align 1
  %7567 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.19 = call zeroext i8 @mult(i8 zeroext %7566, i8 zeroext %7567)
  %conv35.21.19 = zext i8 %call34.21.19 to i32
  %xor36.21.19 = xor i32 %xor.21.19, %conv35.21.19
  %conv37.21.19 = trunc i32 %xor36.21.19 to i8
  store i8 %conv37.21.19, i8* %scevgep41.21.18, align 1
  %scevgep28.21.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7561, i64 0, i64 0, i64 1
  %7568 = bitcast i8* %scevgep28.21.19 to [61 x [61 x i8]]*
  %scevgep41.21.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7562, i64 0, i64 1, i64 0
  %7569 = bitcast i8* %scevgep41.21.19 to [61 x [61 x i8]]*
  %call16.21.20 = call zeroext i8 (...) @rand()
  store i8 %call16.21.20, i8* %scevgep28.21.19, align 1
  %7570 = load i8, i8* %scevgep28.21.19, align 1
  %conv23.21.20 = zext i8 %7570 to i32
  %7571 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.20 = getelementptr i8, i8* %b, i64 42
  %7572 = load i8, i8* %scevgep34.21.20, align 1
  %call28.21.20 = call zeroext i8 @mult(i8 zeroext %7571, i8 zeroext %7572)
  %conv29.21.20 = zext i8 %call28.21.20 to i32
  %xor.21.20 = xor i32 %conv23.21.20, %conv29.21.20
  %scevgep35.21.20 = getelementptr i8, i8* %a, i64 42
  %7573 = load i8, i8* %scevgep35.21.20, align 1
  %7574 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.20 = call zeroext i8 @mult(i8 zeroext %7573, i8 zeroext %7574)
  %conv35.21.20 = zext i8 %call34.21.20 to i32
  %xor36.21.20 = xor i32 %xor.21.20, %conv35.21.20
  %conv37.21.20 = trunc i32 %xor36.21.20 to i8
  store i8 %conv37.21.20, i8* %scevgep41.21.19, align 1
  %scevgep28.21.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7568, i64 0, i64 0, i64 1
  %7575 = bitcast i8* %scevgep28.21.20 to [61 x [61 x i8]]*
  %scevgep41.21.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7569, i64 0, i64 1, i64 0
  %7576 = bitcast i8* %scevgep41.21.20 to [61 x [61 x i8]]*
  %call16.21.21 = call zeroext i8 (...) @rand()
  store i8 %call16.21.21, i8* %scevgep28.21.20, align 1
  %7577 = load i8, i8* %scevgep28.21.20, align 1
  %conv23.21.21 = zext i8 %7577 to i32
  %7578 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.21 = getelementptr i8, i8* %b, i64 43
  %7579 = load i8, i8* %scevgep34.21.21, align 1
  %call28.21.21 = call zeroext i8 @mult(i8 zeroext %7578, i8 zeroext %7579)
  %conv29.21.21 = zext i8 %call28.21.21 to i32
  %xor.21.21 = xor i32 %conv23.21.21, %conv29.21.21
  %scevgep35.21.21 = getelementptr i8, i8* %a, i64 43
  %7580 = load i8, i8* %scevgep35.21.21, align 1
  %7581 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.21 = call zeroext i8 @mult(i8 zeroext %7580, i8 zeroext %7581)
  %conv35.21.21 = zext i8 %call34.21.21 to i32
  %xor36.21.21 = xor i32 %xor.21.21, %conv35.21.21
  %conv37.21.21 = trunc i32 %xor36.21.21 to i8
  store i8 %conv37.21.21, i8* %scevgep41.21.20, align 1
  %scevgep28.21.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7575, i64 0, i64 0, i64 1
  %7582 = bitcast i8* %scevgep28.21.21 to [61 x [61 x i8]]*
  %scevgep41.21.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7576, i64 0, i64 1, i64 0
  %7583 = bitcast i8* %scevgep41.21.21 to [61 x [61 x i8]]*
  %call16.21.22 = call zeroext i8 (...) @rand()
  store i8 %call16.21.22, i8* %scevgep28.21.21, align 1
  %7584 = load i8, i8* %scevgep28.21.21, align 1
  %conv23.21.22 = zext i8 %7584 to i32
  %7585 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.22 = getelementptr i8, i8* %b, i64 44
  %7586 = load i8, i8* %scevgep34.21.22, align 1
  %call28.21.22 = call zeroext i8 @mult(i8 zeroext %7585, i8 zeroext %7586)
  %conv29.21.22 = zext i8 %call28.21.22 to i32
  %xor.21.22 = xor i32 %conv23.21.22, %conv29.21.22
  %scevgep35.21.22 = getelementptr i8, i8* %a, i64 44
  %7587 = load i8, i8* %scevgep35.21.22, align 1
  %7588 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.22 = call zeroext i8 @mult(i8 zeroext %7587, i8 zeroext %7588)
  %conv35.21.22 = zext i8 %call34.21.22 to i32
  %xor36.21.22 = xor i32 %xor.21.22, %conv35.21.22
  %conv37.21.22 = trunc i32 %xor36.21.22 to i8
  store i8 %conv37.21.22, i8* %scevgep41.21.21, align 1
  %scevgep28.21.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7582, i64 0, i64 0, i64 1
  %7589 = bitcast i8* %scevgep28.21.22 to [61 x [61 x i8]]*
  %scevgep41.21.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7583, i64 0, i64 1, i64 0
  %7590 = bitcast i8* %scevgep41.21.22 to [61 x [61 x i8]]*
  %call16.21.23 = call zeroext i8 (...) @rand()
  store i8 %call16.21.23, i8* %scevgep28.21.22, align 1
  %7591 = load i8, i8* %scevgep28.21.22, align 1
  %conv23.21.23 = zext i8 %7591 to i32
  %7592 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.23 = getelementptr i8, i8* %b, i64 45
  %7593 = load i8, i8* %scevgep34.21.23, align 1
  %call28.21.23 = call zeroext i8 @mult(i8 zeroext %7592, i8 zeroext %7593)
  %conv29.21.23 = zext i8 %call28.21.23 to i32
  %xor.21.23 = xor i32 %conv23.21.23, %conv29.21.23
  %scevgep35.21.23 = getelementptr i8, i8* %a, i64 45
  %7594 = load i8, i8* %scevgep35.21.23, align 1
  %7595 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.23 = call zeroext i8 @mult(i8 zeroext %7594, i8 zeroext %7595)
  %conv35.21.23 = zext i8 %call34.21.23 to i32
  %xor36.21.23 = xor i32 %xor.21.23, %conv35.21.23
  %conv37.21.23 = trunc i32 %xor36.21.23 to i8
  store i8 %conv37.21.23, i8* %scevgep41.21.22, align 1
  %scevgep28.21.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7589, i64 0, i64 0, i64 1
  %7596 = bitcast i8* %scevgep28.21.23 to [61 x [61 x i8]]*
  %scevgep41.21.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7590, i64 0, i64 1, i64 0
  %7597 = bitcast i8* %scevgep41.21.23 to [61 x [61 x i8]]*
  %call16.21.24 = call zeroext i8 (...) @rand()
  store i8 %call16.21.24, i8* %scevgep28.21.23, align 1
  %7598 = load i8, i8* %scevgep28.21.23, align 1
  %conv23.21.24 = zext i8 %7598 to i32
  %7599 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.24 = getelementptr i8, i8* %b, i64 46
  %7600 = load i8, i8* %scevgep34.21.24, align 1
  %call28.21.24 = call zeroext i8 @mult(i8 zeroext %7599, i8 zeroext %7600)
  %conv29.21.24 = zext i8 %call28.21.24 to i32
  %xor.21.24 = xor i32 %conv23.21.24, %conv29.21.24
  %scevgep35.21.24 = getelementptr i8, i8* %a, i64 46
  %7601 = load i8, i8* %scevgep35.21.24, align 1
  %7602 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.24 = call zeroext i8 @mult(i8 zeroext %7601, i8 zeroext %7602)
  %conv35.21.24 = zext i8 %call34.21.24 to i32
  %xor36.21.24 = xor i32 %xor.21.24, %conv35.21.24
  %conv37.21.24 = trunc i32 %xor36.21.24 to i8
  store i8 %conv37.21.24, i8* %scevgep41.21.23, align 1
  %scevgep28.21.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7596, i64 0, i64 0, i64 1
  %7603 = bitcast i8* %scevgep28.21.24 to [61 x [61 x i8]]*
  %scevgep41.21.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7597, i64 0, i64 1, i64 0
  %7604 = bitcast i8* %scevgep41.21.24 to [61 x [61 x i8]]*
  %call16.21.25 = call zeroext i8 (...) @rand()
  store i8 %call16.21.25, i8* %scevgep28.21.24, align 1
  %7605 = load i8, i8* %scevgep28.21.24, align 1
  %conv23.21.25 = zext i8 %7605 to i32
  %7606 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.25 = getelementptr i8, i8* %b, i64 47
  %7607 = load i8, i8* %scevgep34.21.25, align 1
  %call28.21.25 = call zeroext i8 @mult(i8 zeroext %7606, i8 zeroext %7607)
  %conv29.21.25 = zext i8 %call28.21.25 to i32
  %xor.21.25 = xor i32 %conv23.21.25, %conv29.21.25
  %scevgep35.21.25 = getelementptr i8, i8* %a, i64 47
  %7608 = load i8, i8* %scevgep35.21.25, align 1
  %7609 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.25 = call zeroext i8 @mult(i8 zeroext %7608, i8 zeroext %7609)
  %conv35.21.25 = zext i8 %call34.21.25 to i32
  %xor36.21.25 = xor i32 %xor.21.25, %conv35.21.25
  %conv37.21.25 = trunc i32 %xor36.21.25 to i8
  store i8 %conv37.21.25, i8* %scevgep41.21.24, align 1
  %scevgep28.21.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7603, i64 0, i64 0, i64 1
  %7610 = bitcast i8* %scevgep28.21.25 to [61 x [61 x i8]]*
  %scevgep41.21.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7604, i64 0, i64 1, i64 0
  %7611 = bitcast i8* %scevgep41.21.25 to [61 x [61 x i8]]*
  %call16.21.26 = call zeroext i8 (...) @rand()
  store i8 %call16.21.26, i8* %scevgep28.21.25, align 1
  %7612 = load i8, i8* %scevgep28.21.25, align 1
  %conv23.21.26 = zext i8 %7612 to i32
  %7613 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.26 = getelementptr i8, i8* %b, i64 48
  %7614 = load i8, i8* %scevgep34.21.26, align 1
  %call28.21.26 = call zeroext i8 @mult(i8 zeroext %7613, i8 zeroext %7614)
  %conv29.21.26 = zext i8 %call28.21.26 to i32
  %xor.21.26 = xor i32 %conv23.21.26, %conv29.21.26
  %scevgep35.21.26 = getelementptr i8, i8* %a, i64 48
  %7615 = load i8, i8* %scevgep35.21.26, align 1
  %7616 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.26 = call zeroext i8 @mult(i8 zeroext %7615, i8 zeroext %7616)
  %conv35.21.26 = zext i8 %call34.21.26 to i32
  %xor36.21.26 = xor i32 %xor.21.26, %conv35.21.26
  %conv37.21.26 = trunc i32 %xor36.21.26 to i8
  store i8 %conv37.21.26, i8* %scevgep41.21.25, align 1
  %scevgep28.21.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7610, i64 0, i64 0, i64 1
  %7617 = bitcast i8* %scevgep28.21.26 to [61 x [61 x i8]]*
  %scevgep41.21.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7611, i64 0, i64 1, i64 0
  %7618 = bitcast i8* %scevgep41.21.26 to [61 x [61 x i8]]*
  %call16.21.27 = call zeroext i8 (...) @rand()
  store i8 %call16.21.27, i8* %scevgep28.21.26, align 1
  %7619 = load i8, i8* %scevgep28.21.26, align 1
  %conv23.21.27 = zext i8 %7619 to i32
  %7620 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.27 = getelementptr i8, i8* %b, i64 49
  %7621 = load i8, i8* %scevgep34.21.27, align 1
  %call28.21.27 = call zeroext i8 @mult(i8 zeroext %7620, i8 zeroext %7621)
  %conv29.21.27 = zext i8 %call28.21.27 to i32
  %xor.21.27 = xor i32 %conv23.21.27, %conv29.21.27
  %scevgep35.21.27 = getelementptr i8, i8* %a, i64 49
  %7622 = load i8, i8* %scevgep35.21.27, align 1
  %7623 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.27 = call zeroext i8 @mult(i8 zeroext %7622, i8 zeroext %7623)
  %conv35.21.27 = zext i8 %call34.21.27 to i32
  %xor36.21.27 = xor i32 %xor.21.27, %conv35.21.27
  %conv37.21.27 = trunc i32 %xor36.21.27 to i8
  store i8 %conv37.21.27, i8* %scevgep41.21.26, align 1
  %scevgep28.21.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7617, i64 0, i64 0, i64 1
  %7624 = bitcast i8* %scevgep28.21.27 to [61 x [61 x i8]]*
  %scevgep41.21.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7618, i64 0, i64 1, i64 0
  %7625 = bitcast i8* %scevgep41.21.27 to [61 x [61 x i8]]*
  %call16.21.28 = call zeroext i8 (...) @rand()
  store i8 %call16.21.28, i8* %scevgep28.21.27, align 1
  %7626 = load i8, i8* %scevgep28.21.27, align 1
  %conv23.21.28 = zext i8 %7626 to i32
  %7627 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.28 = getelementptr i8, i8* %b, i64 50
  %7628 = load i8, i8* %scevgep34.21.28, align 1
  %call28.21.28 = call zeroext i8 @mult(i8 zeroext %7627, i8 zeroext %7628)
  %conv29.21.28 = zext i8 %call28.21.28 to i32
  %xor.21.28 = xor i32 %conv23.21.28, %conv29.21.28
  %scevgep35.21.28 = getelementptr i8, i8* %a, i64 50
  %7629 = load i8, i8* %scevgep35.21.28, align 1
  %7630 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.28 = call zeroext i8 @mult(i8 zeroext %7629, i8 zeroext %7630)
  %conv35.21.28 = zext i8 %call34.21.28 to i32
  %xor36.21.28 = xor i32 %xor.21.28, %conv35.21.28
  %conv37.21.28 = trunc i32 %xor36.21.28 to i8
  store i8 %conv37.21.28, i8* %scevgep41.21.27, align 1
  %scevgep28.21.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7624, i64 0, i64 0, i64 1
  %7631 = bitcast i8* %scevgep28.21.28 to [61 x [61 x i8]]*
  %scevgep41.21.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7625, i64 0, i64 1, i64 0
  %7632 = bitcast i8* %scevgep41.21.28 to [61 x [61 x i8]]*
  %call16.21.29 = call zeroext i8 (...) @rand()
  store i8 %call16.21.29, i8* %scevgep28.21.28, align 1
  %7633 = load i8, i8* %scevgep28.21.28, align 1
  %conv23.21.29 = zext i8 %7633 to i32
  %7634 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.29 = getelementptr i8, i8* %b, i64 51
  %7635 = load i8, i8* %scevgep34.21.29, align 1
  %call28.21.29 = call zeroext i8 @mult(i8 zeroext %7634, i8 zeroext %7635)
  %conv29.21.29 = zext i8 %call28.21.29 to i32
  %xor.21.29 = xor i32 %conv23.21.29, %conv29.21.29
  %scevgep35.21.29 = getelementptr i8, i8* %a, i64 51
  %7636 = load i8, i8* %scevgep35.21.29, align 1
  %7637 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.29 = call zeroext i8 @mult(i8 zeroext %7636, i8 zeroext %7637)
  %conv35.21.29 = zext i8 %call34.21.29 to i32
  %xor36.21.29 = xor i32 %xor.21.29, %conv35.21.29
  %conv37.21.29 = trunc i32 %xor36.21.29 to i8
  store i8 %conv37.21.29, i8* %scevgep41.21.28, align 1
  %scevgep28.21.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7631, i64 0, i64 0, i64 1
  %7638 = bitcast i8* %scevgep28.21.29 to [61 x [61 x i8]]*
  %scevgep41.21.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7632, i64 0, i64 1, i64 0
  %7639 = bitcast i8* %scevgep41.21.29 to [61 x [61 x i8]]*
  %call16.21.30 = call zeroext i8 (...) @rand()
  store i8 %call16.21.30, i8* %scevgep28.21.29, align 1
  %7640 = load i8, i8* %scevgep28.21.29, align 1
  %conv23.21.30 = zext i8 %7640 to i32
  %7641 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.30 = getelementptr i8, i8* %b, i64 52
  %7642 = load i8, i8* %scevgep34.21.30, align 1
  %call28.21.30 = call zeroext i8 @mult(i8 zeroext %7641, i8 zeroext %7642)
  %conv29.21.30 = zext i8 %call28.21.30 to i32
  %xor.21.30 = xor i32 %conv23.21.30, %conv29.21.30
  %scevgep35.21.30 = getelementptr i8, i8* %a, i64 52
  %7643 = load i8, i8* %scevgep35.21.30, align 1
  %7644 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.30 = call zeroext i8 @mult(i8 zeroext %7643, i8 zeroext %7644)
  %conv35.21.30 = zext i8 %call34.21.30 to i32
  %xor36.21.30 = xor i32 %xor.21.30, %conv35.21.30
  %conv37.21.30 = trunc i32 %xor36.21.30 to i8
  store i8 %conv37.21.30, i8* %scevgep41.21.29, align 1
  %scevgep28.21.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7638, i64 0, i64 0, i64 1
  %7645 = bitcast i8* %scevgep28.21.30 to [61 x [61 x i8]]*
  %scevgep41.21.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7639, i64 0, i64 1, i64 0
  %7646 = bitcast i8* %scevgep41.21.30 to [61 x [61 x i8]]*
  %call16.21.31 = call zeroext i8 (...) @rand()
  store i8 %call16.21.31, i8* %scevgep28.21.30, align 1
  %7647 = load i8, i8* %scevgep28.21.30, align 1
  %conv23.21.31 = zext i8 %7647 to i32
  %7648 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.31 = getelementptr i8, i8* %b, i64 53
  %7649 = load i8, i8* %scevgep34.21.31, align 1
  %call28.21.31 = call zeroext i8 @mult(i8 zeroext %7648, i8 zeroext %7649)
  %conv29.21.31 = zext i8 %call28.21.31 to i32
  %xor.21.31 = xor i32 %conv23.21.31, %conv29.21.31
  %scevgep35.21.31 = getelementptr i8, i8* %a, i64 53
  %7650 = load i8, i8* %scevgep35.21.31, align 1
  %7651 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.31 = call zeroext i8 @mult(i8 zeroext %7650, i8 zeroext %7651)
  %conv35.21.31 = zext i8 %call34.21.31 to i32
  %xor36.21.31 = xor i32 %xor.21.31, %conv35.21.31
  %conv37.21.31 = trunc i32 %xor36.21.31 to i8
  store i8 %conv37.21.31, i8* %scevgep41.21.30, align 1
  %scevgep28.21.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7645, i64 0, i64 0, i64 1
  %7652 = bitcast i8* %scevgep28.21.31 to [61 x [61 x i8]]*
  %scevgep41.21.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7646, i64 0, i64 1, i64 0
  %7653 = bitcast i8* %scevgep41.21.31 to [61 x [61 x i8]]*
  %call16.21.32 = call zeroext i8 (...) @rand()
  store i8 %call16.21.32, i8* %scevgep28.21.31, align 1
  %7654 = load i8, i8* %scevgep28.21.31, align 1
  %conv23.21.32 = zext i8 %7654 to i32
  %7655 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.32 = getelementptr i8, i8* %b, i64 54
  %7656 = load i8, i8* %scevgep34.21.32, align 1
  %call28.21.32 = call zeroext i8 @mult(i8 zeroext %7655, i8 zeroext %7656)
  %conv29.21.32 = zext i8 %call28.21.32 to i32
  %xor.21.32 = xor i32 %conv23.21.32, %conv29.21.32
  %scevgep35.21.32 = getelementptr i8, i8* %a, i64 54
  %7657 = load i8, i8* %scevgep35.21.32, align 1
  %7658 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.32 = call zeroext i8 @mult(i8 zeroext %7657, i8 zeroext %7658)
  %conv35.21.32 = zext i8 %call34.21.32 to i32
  %xor36.21.32 = xor i32 %xor.21.32, %conv35.21.32
  %conv37.21.32 = trunc i32 %xor36.21.32 to i8
  store i8 %conv37.21.32, i8* %scevgep41.21.31, align 1
  %scevgep28.21.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7652, i64 0, i64 0, i64 1
  %7659 = bitcast i8* %scevgep28.21.32 to [61 x [61 x i8]]*
  %scevgep41.21.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7653, i64 0, i64 1, i64 0
  %7660 = bitcast i8* %scevgep41.21.32 to [61 x [61 x i8]]*
  %call16.21.33 = call zeroext i8 (...) @rand()
  store i8 %call16.21.33, i8* %scevgep28.21.32, align 1
  %7661 = load i8, i8* %scevgep28.21.32, align 1
  %conv23.21.33 = zext i8 %7661 to i32
  %7662 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.33 = getelementptr i8, i8* %b, i64 55
  %7663 = load i8, i8* %scevgep34.21.33, align 1
  %call28.21.33 = call zeroext i8 @mult(i8 zeroext %7662, i8 zeroext %7663)
  %conv29.21.33 = zext i8 %call28.21.33 to i32
  %xor.21.33 = xor i32 %conv23.21.33, %conv29.21.33
  %scevgep35.21.33 = getelementptr i8, i8* %a, i64 55
  %7664 = load i8, i8* %scevgep35.21.33, align 1
  %7665 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.33 = call zeroext i8 @mult(i8 zeroext %7664, i8 zeroext %7665)
  %conv35.21.33 = zext i8 %call34.21.33 to i32
  %xor36.21.33 = xor i32 %xor.21.33, %conv35.21.33
  %conv37.21.33 = trunc i32 %xor36.21.33 to i8
  store i8 %conv37.21.33, i8* %scevgep41.21.32, align 1
  %scevgep28.21.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7659, i64 0, i64 0, i64 1
  %7666 = bitcast i8* %scevgep28.21.33 to [61 x [61 x i8]]*
  %scevgep41.21.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7660, i64 0, i64 1, i64 0
  %7667 = bitcast i8* %scevgep41.21.33 to [61 x [61 x i8]]*
  %call16.21.34 = call zeroext i8 (...) @rand()
  store i8 %call16.21.34, i8* %scevgep28.21.33, align 1
  %7668 = load i8, i8* %scevgep28.21.33, align 1
  %conv23.21.34 = zext i8 %7668 to i32
  %7669 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.34 = getelementptr i8, i8* %b, i64 56
  %7670 = load i8, i8* %scevgep34.21.34, align 1
  %call28.21.34 = call zeroext i8 @mult(i8 zeroext %7669, i8 zeroext %7670)
  %conv29.21.34 = zext i8 %call28.21.34 to i32
  %xor.21.34 = xor i32 %conv23.21.34, %conv29.21.34
  %scevgep35.21.34 = getelementptr i8, i8* %a, i64 56
  %7671 = load i8, i8* %scevgep35.21.34, align 1
  %7672 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.34 = call zeroext i8 @mult(i8 zeroext %7671, i8 zeroext %7672)
  %conv35.21.34 = zext i8 %call34.21.34 to i32
  %xor36.21.34 = xor i32 %xor.21.34, %conv35.21.34
  %conv37.21.34 = trunc i32 %xor36.21.34 to i8
  store i8 %conv37.21.34, i8* %scevgep41.21.33, align 1
  %scevgep28.21.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7666, i64 0, i64 0, i64 1
  %7673 = bitcast i8* %scevgep28.21.34 to [61 x [61 x i8]]*
  %scevgep41.21.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7667, i64 0, i64 1, i64 0
  %7674 = bitcast i8* %scevgep41.21.34 to [61 x [61 x i8]]*
  %call16.21.35 = call zeroext i8 (...) @rand()
  store i8 %call16.21.35, i8* %scevgep28.21.34, align 1
  %7675 = load i8, i8* %scevgep28.21.34, align 1
  %conv23.21.35 = zext i8 %7675 to i32
  %7676 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.35 = getelementptr i8, i8* %b, i64 57
  %7677 = load i8, i8* %scevgep34.21.35, align 1
  %call28.21.35 = call zeroext i8 @mult(i8 zeroext %7676, i8 zeroext %7677)
  %conv29.21.35 = zext i8 %call28.21.35 to i32
  %xor.21.35 = xor i32 %conv23.21.35, %conv29.21.35
  %scevgep35.21.35 = getelementptr i8, i8* %a, i64 57
  %7678 = load i8, i8* %scevgep35.21.35, align 1
  %7679 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.35 = call zeroext i8 @mult(i8 zeroext %7678, i8 zeroext %7679)
  %conv35.21.35 = zext i8 %call34.21.35 to i32
  %xor36.21.35 = xor i32 %xor.21.35, %conv35.21.35
  %conv37.21.35 = trunc i32 %xor36.21.35 to i8
  store i8 %conv37.21.35, i8* %scevgep41.21.34, align 1
  %scevgep28.21.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7673, i64 0, i64 0, i64 1
  %7680 = bitcast i8* %scevgep28.21.35 to [61 x [61 x i8]]*
  %scevgep41.21.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7674, i64 0, i64 1, i64 0
  %7681 = bitcast i8* %scevgep41.21.35 to [61 x [61 x i8]]*
  %call16.21.36 = call zeroext i8 (...) @rand()
  store i8 %call16.21.36, i8* %scevgep28.21.35, align 1
  %7682 = load i8, i8* %scevgep28.21.35, align 1
  %conv23.21.36 = zext i8 %7682 to i32
  %7683 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.36 = getelementptr i8, i8* %b, i64 58
  %7684 = load i8, i8* %scevgep34.21.36, align 1
  %call28.21.36 = call zeroext i8 @mult(i8 zeroext %7683, i8 zeroext %7684)
  %conv29.21.36 = zext i8 %call28.21.36 to i32
  %xor.21.36 = xor i32 %conv23.21.36, %conv29.21.36
  %scevgep35.21.36 = getelementptr i8, i8* %a, i64 58
  %7685 = load i8, i8* %scevgep35.21.36, align 1
  %7686 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.36 = call zeroext i8 @mult(i8 zeroext %7685, i8 zeroext %7686)
  %conv35.21.36 = zext i8 %call34.21.36 to i32
  %xor36.21.36 = xor i32 %xor.21.36, %conv35.21.36
  %conv37.21.36 = trunc i32 %xor36.21.36 to i8
  store i8 %conv37.21.36, i8* %scevgep41.21.35, align 1
  %scevgep28.21.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7680, i64 0, i64 0, i64 1
  %7687 = bitcast i8* %scevgep28.21.36 to [61 x [61 x i8]]*
  %scevgep41.21.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7681, i64 0, i64 1, i64 0
  %7688 = bitcast i8* %scevgep41.21.36 to [61 x [61 x i8]]*
  %call16.21.37 = call zeroext i8 (...) @rand()
  store i8 %call16.21.37, i8* %scevgep28.21.36, align 1
  %7689 = load i8, i8* %scevgep28.21.36, align 1
  %conv23.21.37 = zext i8 %7689 to i32
  %7690 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.37 = getelementptr i8, i8* %b, i64 59
  %7691 = load i8, i8* %scevgep34.21.37, align 1
  %call28.21.37 = call zeroext i8 @mult(i8 zeroext %7690, i8 zeroext %7691)
  %conv29.21.37 = zext i8 %call28.21.37 to i32
  %xor.21.37 = xor i32 %conv23.21.37, %conv29.21.37
  %scevgep35.21.37 = getelementptr i8, i8* %a, i64 59
  %7692 = load i8, i8* %scevgep35.21.37, align 1
  %7693 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.37 = call zeroext i8 @mult(i8 zeroext %7692, i8 zeroext %7693)
  %conv35.21.37 = zext i8 %call34.21.37 to i32
  %xor36.21.37 = xor i32 %xor.21.37, %conv35.21.37
  %conv37.21.37 = trunc i32 %xor36.21.37 to i8
  store i8 %conv37.21.37, i8* %scevgep41.21.36, align 1
  %scevgep28.21.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7687, i64 0, i64 0, i64 1
  %scevgep41.21.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7688, i64 0, i64 1, i64 0
  %call16.21.38 = call zeroext i8 (...) @rand()
  store i8 %call16.21.38, i8* %scevgep28.21.37, align 1
  %7694 = load i8, i8* %scevgep28.21.37, align 1
  %conv23.21.38 = zext i8 %7694 to i32
  %7695 = load i8, i8* %arrayidx25.21, align 1
  %scevgep34.21.38 = getelementptr i8, i8* %b, i64 60
  %7696 = load i8, i8* %scevgep34.21.38, align 1
  %call28.21.38 = call zeroext i8 @mult(i8 zeroext %7695, i8 zeroext %7696)
  %conv29.21.38 = zext i8 %call28.21.38 to i32
  %xor.21.38 = xor i32 %conv23.21.38, %conv29.21.38
  %scevgep35.21.38 = getelementptr i8, i8* %a, i64 60
  %7697 = load i8, i8* %scevgep35.21.38, align 1
  %7698 = load i8, i8* %arrayidx33.21, align 1
  %call34.21.38 = call zeroext i8 @mult(i8 zeroext %7697, i8 zeroext %7698)
  %conv35.21.38 = zext i8 %call34.21.38 to i32
  %xor36.21.38 = xor i32 %xor.21.38, %conv35.21.38
  %conv37.21.38 = trunc i32 %xor36.21.38 to i8
  store i8 %conv37.21.38, i8* %scevgep41.21.37, align 1
  %scevgep26.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7428, i64 0, i64 1, i64 1
  %7699 = bitcast i8* %scevgep26.21 to [61 x [61 x i8]]*
  %scevgep39.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7429, i64 0, i64 1, i64 1
  %7700 = bitcast i8* %scevgep39.21 to [61 x [61 x i8]]*
  %arrayidx25.22 = getelementptr inbounds i8, i8* %a, i64 22
  %arrayidx33.22 = getelementptr inbounds i8, i8* %b, i64 22
  %call16.22 = call zeroext i8 (...) @rand()
  store i8 %call16.22, i8* %scevgep26.21, align 1
  %7701 = load i8, i8* %scevgep26.21, align 1
  %conv23.22 = zext i8 %7701 to i32
  %7702 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22 = getelementptr i8, i8* %b, i64 23
  %7703 = load i8, i8* %scevgep34.22, align 1
  %call28.22 = call zeroext i8 @mult(i8 zeroext %7702, i8 zeroext %7703)
  %conv29.22 = zext i8 %call28.22 to i32
  %xor.22 = xor i32 %conv23.22, %conv29.22
  %scevgep35.22 = getelementptr i8, i8* %a, i64 23
  %7704 = load i8, i8* %scevgep35.22, align 1
  %7705 = load i8, i8* %arrayidx33.22, align 1
  %call34.22 = call zeroext i8 @mult(i8 zeroext %7704, i8 zeroext %7705)
  %conv35.22 = zext i8 %call34.22 to i32
  %xor36.22 = xor i32 %xor.22, %conv35.22
  %conv37.22 = trunc i32 %xor36.22 to i8
  store i8 %conv37.22, i8* %scevgep39.21, align 1
  %scevgep28.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7699, i64 0, i64 0, i64 1
  %7706 = bitcast i8* %scevgep28.22 to [61 x [61 x i8]]*
  %scevgep41.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7700, i64 0, i64 1, i64 0
  %7707 = bitcast i8* %scevgep41.22 to [61 x [61 x i8]]*
  %call16.22.1 = call zeroext i8 (...) @rand()
  store i8 %call16.22.1, i8* %scevgep28.22, align 1
  %7708 = load i8, i8* %scevgep28.22, align 1
  %conv23.22.1 = zext i8 %7708 to i32
  %7709 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.1 = getelementptr i8, i8* %b, i64 24
  %7710 = load i8, i8* %scevgep34.22.1, align 1
  %call28.22.1 = call zeroext i8 @mult(i8 zeroext %7709, i8 zeroext %7710)
  %conv29.22.1 = zext i8 %call28.22.1 to i32
  %xor.22.1 = xor i32 %conv23.22.1, %conv29.22.1
  %scevgep35.22.1 = getelementptr i8, i8* %a, i64 24
  %7711 = load i8, i8* %scevgep35.22.1, align 1
  %7712 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.1 = call zeroext i8 @mult(i8 zeroext %7711, i8 zeroext %7712)
  %conv35.22.1 = zext i8 %call34.22.1 to i32
  %xor36.22.1 = xor i32 %xor.22.1, %conv35.22.1
  %conv37.22.1 = trunc i32 %xor36.22.1 to i8
  store i8 %conv37.22.1, i8* %scevgep41.22, align 1
  %scevgep28.22.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7706, i64 0, i64 0, i64 1
  %7713 = bitcast i8* %scevgep28.22.1 to [61 x [61 x i8]]*
  %scevgep41.22.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7707, i64 0, i64 1, i64 0
  %7714 = bitcast i8* %scevgep41.22.1 to [61 x [61 x i8]]*
  %call16.22.2 = call zeroext i8 (...) @rand()
  store i8 %call16.22.2, i8* %scevgep28.22.1, align 1
  %7715 = load i8, i8* %scevgep28.22.1, align 1
  %conv23.22.2 = zext i8 %7715 to i32
  %7716 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.2 = getelementptr i8, i8* %b, i64 25
  %7717 = load i8, i8* %scevgep34.22.2, align 1
  %call28.22.2 = call zeroext i8 @mult(i8 zeroext %7716, i8 zeroext %7717)
  %conv29.22.2 = zext i8 %call28.22.2 to i32
  %xor.22.2 = xor i32 %conv23.22.2, %conv29.22.2
  %scevgep35.22.2 = getelementptr i8, i8* %a, i64 25
  %7718 = load i8, i8* %scevgep35.22.2, align 1
  %7719 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.2 = call zeroext i8 @mult(i8 zeroext %7718, i8 zeroext %7719)
  %conv35.22.2 = zext i8 %call34.22.2 to i32
  %xor36.22.2 = xor i32 %xor.22.2, %conv35.22.2
  %conv37.22.2 = trunc i32 %xor36.22.2 to i8
  store i8 %conv37.22.2, i8* %scevgep41.22.1, align 1
  %scevgep28.22.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7713, i64 0, i64 0, i64 1
  %7720 = bitcast i8* %scevgep28.22.2 to [61 x [61 x i8]]*
  %scevgep41.22.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7714, i64 0, i64 1, i64 0
  %7721 = bitcast i8* %scevgep41.22.2 to [61 x [61 x i8]]*
  %call16.22.3 = call zeroext i8 (...) @rand()
  store i8 %call16.22.3, i8* %scevgep28.22.2, align 1
  %7722 = load i8, i8* %scevgep28.22.2, align 1
  %conv23.22.3 = zext i8 %7722 to i32
  %7723 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.3 = getelementptr i8, i8* %b, i64 26
  %7724 = load i8, i8* %scevgep34.22.3, align 1
  %call28.22.3 = call zeroext i8 @mult(i8 zeroext %7723, i8 zeroext %7724)
  %conv29.22.3 = zext i8 %call28.22.3 to i32
  %xor.22.3 = xor i32 %conv23.22.3, %conv29.22.3
  %scevgep35.22.3 = getelementptr i8, i8* %a, i64 26
  %7725 = load i8, i8* %scevgep35.22.3, align 1
  %7726 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.3 = call zeroext i8 @mult(i8 zeroext %7725, i8 zeroext %7726)
  %conv35.22.3 = zext i8 %call34.22.3 to i32
  %xor36.22.3 = xor i32 %xor.22.3, %conv35.22.3
  %conv37.22.3 = trunc i32 %xor36.22.3 to i8
  store i8 %conv37.22.3, i8* %scevgep41.22.2, align 1
  %scevgep28.22.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7720, i64 0, i64 0, i64 1
  %7727 = bitcast i8* %scevgep28.22.3 to [61 x [61 x i8]]*
  %scevgep41.22.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7721, i64 0, i64 1, i64 0
  %7728 = bitcast i8* %scevgep41.22.3 to [61 x [61 x i8]]*
  %call16.22.4 = call zeroext i8 (...) @rand()
  store i8 %call16.22.4, i8* %scevgep28.22.3, align 1
  %7729 = load i8, i8* %scevgep28.22.3, align 1
  %conv23.22.4 = zext i8 %7729 to i32
  %7730 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.4 = getelementptr i8, i8* %b, i64 27
  %7731 = load i8, i8* %scevgep34.22.4, align 1
  %call28.22.4 = call zeroext i8 @mult(i8 zeroext %7730, i8 zeroext %7731)
  %conv29.22.4 = zext i8 %call28.22.4 to i32
  %xor.22.4 = xor i32 %conv23.22.4, %conv29.22.4
  %scevgep35.22.4 = getelementptr i8, i8* %a, i64 27
  %7732 = load i8, i8* %scevgep35.22.4, align 1
  %7733 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.4 = call zeroext i8 @mult(i8 zeroext %7732, i8 zeroext %7733)
  %conv35.22.4 = zext i8 %call34.22.4 to i32
  %xor36.22.4 = xor i32 %xor.22.4, %conv35.22.4
  %conv37.22.4 = trunc i32 %xor36.22.4 to i8
  store i8 %conv37.22.4, i8* %scevgep41.22.3, align 1
  %scevgep28.22.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7727, i64 0, i64 0, i64 1
  %7734 = bitcast i8* %scevgep28.22.4 to [61 x [61 x i8]]*
  %scevgep41.22.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7728, i64 0, i64 1, i64 0
  %7735 = bitcast i8* %scevgep41.22.4 to [61 x [61 x i8]]*
  %call16.22.5 = call zeroext i8 (...) @rand()
  store i8 %call16.22.5, i8* %scevgep28.22.4, align 1
  %7736 = load i8, i8* %scevgep28.22.4, align 1
  %conv23.22.5 = zext i8 %7736 to i32
  %7737 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.5 = getelementptr i8, i8* %b, i64 28
  %7738 = load i8, i8* %scevgep34.22.5, align 1
  %call28.22.5 = call zeroext i8 @mult(i8 zeroext %7737, i8 zeroext %7738)
  %conv29.22.5 = zext i8 %call28.22.5 to i32
  %xor.22.5 = xor i32 %conv23.22.5, %conv29.22.5
  %scevgep35.22.5 = getelementptr i8, i8* %a, i64 28
  %7739 = load i8, i8* %scevgep35.22.5, align 1
  %7740 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.5 = call zeroext i8 @mult(i8 zeroext %7739, i8 zeroext %7740)
  %conv35.22.5 = zext i8 %call34.22.5 to i32
  %xor36.22.5 = xor i32 %xor.22.5, %conv35.22.5
  %conv37.22.5 = trunc i32 %xor36.22.5 to i8
  store i8 %conv37.22.5, i8* %scevgep41.22.4, align 1
  %scevgep28.22.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7734, i64 0, i64 0, i64 1
  %7741 = bitcast i8* %scevgep28.22.5 to [61 x [61 x i8]]*
  %scevgep41.22.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7735, i64 0, i64 1, i64 0
  %7742 = bitcast i8* %scevgep41.22.5 to [61 x [61 x i8]]*
  %call16.22.6 = call zeroext i8 (...) @rand()
  store i8 %call16.22.6, i8* %scevgep28.22.5, align 1
  %7743 = load i8, i8* %scevgep28.22.5, align 1
  %conv23.22.6 = zext i8 %7743 to i32
  %7744 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.6 = getelementptr i8, i8* %b, i64 29
  %7745 = load i8, i8* %scevgep34.22.6, align 1
  %call28.22.6 = call zeroext i8 @mult(i8 zeroext %7744, i8 zeroext %7745)
  %conv29.22.6 = zext i8 %call28.22.6 to i32
  %xor.22.6 = xor i32 %conv23.22.6, %conv29.22.6
  %scevgep35.22.6 = getelementptr i8, i8* %a, i64 29
  %7746 = load i8, i8* %scevgep35.22.6, align 1
  %7747 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.6 = call zeroext i8 @mult(i8 zeroext %7746, i8 zeroext %7747)
  %conv35.22.6 = zext i8 %call34.22.6 to i32
  %xor36.22.6 = xor i32 %xor.22.6, %conv35.22.6
  %conv37.22.6 = trunc i32 %xor36.22.6 to i8
  store i8 %conv37.22.6, i8* %scevgep41.22.5, align 1
  %scevgep28.22.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7741, i64 0, i64 0, i64 1
  %7748 = bitcast i8* %scevgep28.22.6 to [61 x [61 x i8]]*
  %scevgep41.22.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7742, i64 0, i64 1, i64 0
  %7749 = bitcast i8* %scevgep41.22.6 to [61 x [61 x i8]]*
  %call16.22.7 = call zeroext i8 (...) @rand()
  store i8 %call16.22.7, i8* %scevgep28.22.6, align 1
  %7750 = load i8, i8* %scevgep28.22.6, align 1
  %conv23.22.7 = zext i8 %7750 to i32
  %7751 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.7 = getelementptr i8, i8* %b, i64 30
  %7752 = load i8, i8* %scevgep34.22.7, align 1
  %call28.22.7 = call zeroext i8 @mult(i8 zeroext %7751, i8 zeroext %7752)
  %conv29.22.7 = zext i8 %call28.22.7 to i32
  %xor.22.7 = xor i32 %conv23.22.7, %conv29.22.7
  %scevgep35.22.7 = getelementptr i8, i8* %a, i64 30
  %7753 = load i8, i8* %scevgep35.22.7, align 1
  %7754 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.7 = call zeroext i8 @mult(i8 zeroext %7753, i8 zeroext %7754)
  %conv35.22.7 = zext i8 %call34.22.7 to i32
  %xor36.22.7 = xor i32 %xor.22.7, %conv35.22.7
  %conv37.22.7 = trunc i32 %xor36.22.7 to i8
  store i8 %conv37.22.7, i8* %scevgep41.22.6, align 1
  %scevgep28.22.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7748, i64 0, i64 0, i64 1
  %7755 = bitcast i8* %scevgep28.22.7 to [61 x [61 x i8]]*
  %scevgep41.22.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7749, i64 0, i64 1, i64 0
  %7756 = bitcast i8* %scevgep41.22.7 to [61 x [61 x i8]]*
  %call16.22.8 = call zeroext i8 (...) @rand()
  store i8 %call16.22.8, i8* %scevgep28.22.7, align 1
  %7757 = load i8, i8* %scevgep28.22.7, align 1
  %conv23.22.8 = zext i8 %7757 to i32
  %7758 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.8 = getelementptr i8, i8* %b, i64 31
  %7759 = load i8, i8* %scevgep34.22.8, align 1
  %call28.22.8 = call zeroext i8 @mult(i8 zeroext %7758, i8 zeroext %7759)
  %conv29.22.8 = zext i8 %call28.22.8 to i32
  %xor.22.8 = xor i32 %conv23.22.8, %conv29.22.8
  %scevgep35.22.8 = getelementptr i8, i8* %a, i64 31
  %7760 = load i8, i8* %scevgep35.22.8, align 1
  %7761 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.8 = call zeroext i8 @mult(i8 zeroext %7760, i8 zeroext %7761)
  %conv35.22.8 = zext i8 %call34.22.8 to i32
  %xor36.22.8 = xor i32 %xor.22.8, %conv35.22.8
  %conv37.22.8 = trunc i32 %xor36.22.8 to i8
  store i8 %conv37.22.8, i8* %scevgep41.22.7, align 1
  %scevgep28.22.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7755, i64 0, i64 0, i64 1
  %7762 = bitcast i8* %scevgep28.22.8 to [61 x [61 x i8]]*
  %scevgep41.22.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7756, i64 0, i64 1, i64 0
  %7763 = bitcast i8* %scevgep41.22.8 to [61 x [61 x i8]]*
  %call16.22.9 = call zeroext i8 (...) @rand()
  store i8 %call16.22.9, i8* %scevgep28.22.8, align 1
  %7764 = load i8, i8* %scevgep28.22.8, align 1
  %conv23.22.9 = zext i8 %7764 to i32
  %7765 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.9 = getelementptr i8, i8* %b, i64 32
  %7766 = load i8, i8* %scevgep34.22.9, align 1
  %call28.22.9 = call zeroext i8 @mult(i8 zeroext %7765, i8 zeroext %7766)
  %conv29.22.9 = zext i8 %call28.22.9 to i32
  %xor.22.9 = xor i32 %conv23.22.9, %conv29.22.9
  %scevgep35.22.9 = getelementptr i8, i8* %a, i64 32
  %7767 = load i8, i8* %scevgep35.22.9, align 1
  %7768 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.9 = call zeroext i8 @mult(i8 zeroext %7767, i8 zeroext %7768)
  %conv35.22.9 = zext i8 %call34.22.9 to i32
  %xor36.22.9 = xor i32 %xor.22.9, %conv35.22.9
  %conv37.22.9 = trunc i32 %xor36.22.9 to i8
  store i8 %conv37.22.9, i8* %scevgep41.22.8, align 1
  %scevgep28.22.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7762, i64 0, i64 0, i64 1
  %7769 = bitcast i8* %scevgep28.22.9 to [61 x [61 x i8]]*
  %scevgep41.22.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7763, i64 0, i64 1, i64 0
  %7770 = bitcast i8* %scevgep41.22.9 to [61 x [61 x i8]]*
  %call16.22.10 = call zeroext i8 (...) @rand()
  store i8 %call16.22.10, i8* %scevgep28.22.9, align 1
  %7771 = load i8, i8* %scevgep28.22.9, align 1
  %conv23.22.10 = zext i8 %7771 to i32
  %7772 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.10 = getelementptr i8, i8* %b, i64 33
  %7773 = load i8, i8* %scevgep34.22.10, align 1
  %call28.22.10 = call zeroext i8 @mult(i8 zeroext %7772, i8 zeroext %7773)
  %conv29.22.10 = zext i8 %call28.22.10 to i32
  %xor.22.10 = xor i32 %conv23.22.10, %conv29.22.10
  %scevgep35.22.10 = getelementptr i8, i8* %a, i64 33
  %7774 = load i8, i8* %scevgep35.22.10, align 1
  %7775 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.10 = call zeroext i8 @mult(i8 zeroext %7774, i8 zeroext %7775)
  %conv35.22.10 = zext i8 %call34.22.10 to i32
  %xor36.22.10 = xor i32 %xor.22.10, %conv35.22.10
  %conv37.22.10 = trunc i32 %xor36.22.10 to i8
  store i8 %conv37.22.10, i8* %scevgep41.22.9, align 1
  %scevgep28.22.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7769, i64 0, i64 0, i64 1
  %7776 = bitcast i8* %scevgep28.22.10 to [61 x [61 x i8]]*
  %scevgep41.22.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7770, i64 0, i64 1, i64 0
  %7777 = bitcast i8* %scevgep41.22.10 to [61 x [61 x i8]]*
  %call16.22.11 = call zeroext i8 (...) @rand()
  store i8 %call16.22.11, i8* %scevgep28.22.10, align 1
  %7778 = load i8, i8* %scevgep28.22.10, align 1
  %conv23.22.11 = zext i8 %7778 to i32
  %7779 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.11 = getelementptr i8, i8* %b, i64 34
  %7780 = load i8, i8* %scevgep34.22.11, align 1
  %call28.22.11 = call zeroext i8 @mult(i8 zeroext %7779, i8 zeroext %7780)
  %conv29.22.11 = zext i8 %call28.22.11 to i32
  %xor.22.11 = xor i32 %conv23.22.11, %conv29.22.11
  %scevgep35.22.11 = getelementptr i8, i8* %a, i64 34
  %7781 = load i8, i8* %scevgep35.22.11, align 1
  %7782 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.11 = call zeroext i8 @mult(i8 zeroext %7781, i8 zeroext %7782)
  %conv35.22.11 = zext i8 %call34.22.11 to i32
  %xor36.22.11 = xor i32 %xor.22.11, %conv35.22.11
  %conv37.22.11 = trunc i32 %xor36.22.11 to i8
  store i8 %conv37.22.11, i8* %scevgep41.22.10, align 1
  %scevgep28.22.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7776, i64 0, i64 0, i64 1
  %7783 = bitcast i8* %scevgep28.22.11 to [61 x [61 x i8]]*
  %scevgep41.22.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7777, i64 0, i64 1, i64 0
  %7784 = bitcast i8* %scevgep41.22.11 to [61 x [61 x i8]]*
  %call16.22.12 = call zeroext i8 (...) @rand()
  store i8 %call16.22.12, i8* %scevgep28.22.11, align 1
  %7785 = load i8, i8* %scevgep28.22.11, align 1
  %conv23.22.12 = zext i8 %7785 to i32
  %7786 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.12 = getelementptr i8, i8* %b, i64 35
  %7787 = load i8, i8* %scevgep34.22.12, align 1
  %call28.22.12 = call zeroext i8 @mult(i8 zeroext %7786, i8 zeroext %7787)
  %conv29.22.12 = zext i8 %call28.22.12 to i32
  %xor.22.12 = xor i32 %conv23.22.12, %conv29.22.12
  %scevgep35.22.12 = getelementptr i8, i8* %a, i64 35
  %7788 = load i8, i8* %scevgep35.22.12, align 1
  %7789 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.12 = call zeroext i8 @mult(i8 zeroext %7788, i8 zeroext %7789)
  %conv35.22.12 = zext i8 %call34.22.12 to i32
  %xor36.22.12 = xor i32 %xor.22.12, %conv35.22.12
  %conv37.22.12 = trunc i32 %xor36.22.12 to i8
  store i8 %conv37.22.12, i8* %scevgep41.22.11, align 1
  %scevgep28.22.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7783, i64 0, i64 0, i64 1
  %7790 = bitcast i8* %scevgep28.22.12 to [61 x [61 x i8]]*
  %scevgep41.22.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7784, i64 0, i64 1, i64 0
  %7791 = bitcast i8* %scevgep41.22.12 to [61 x [61 x i8]]*
  %call16.22.13 = call zeroext i8 (...) @rand()
  store i8 %call16.22.13, i8* %scevgep28.22.12, align 1
  %7792 = load i8, i8* %scevgep28.22.12, align 1
  %conv23.22.13 = zext i8 %7792 to i32
  %7793 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.13 = getelementptr i8, i8* %b, i64 36
  %7794 = load i8, i8* %scevgep34.22.13, align 1
  %call28.22.13 = call zeroext i8 @mult(i8 zeroext %7793, i8 zeroext %7794)
  %conv29.22.13 = zext i8 %call28.22.13 to i32
  %xor.22.13 = xor i32 %conv23.22.13, %conv29.22.13
  %scevgep35.22.13 = getelementptr i8, i8* %a, i64 36
  %7795 = load i8, i8* %scevgep35.22.13, align 1
  %7796 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.13 = call zeroext i8 @mult(i8 zeroext %7795, i8 zeroext %7796)
  %conv35.22.13 = zext i8 %call34.22.13 to i32
  %xor36.22.13 = xor i32 %xor.22.13, %conv35.22.13
  %conv37.22.13 = trunc i32 %xor36.22.13 to i8
  store i8 %conv37.22.13, i8* %scevgep41.22.12, align 1
  %scevgep28.22.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7790, i64 0, i64 0, i64 1
  %7797 = bitcast i8* %scevgep28.22.13 to [61 x [61 x i8]]*
  %scevgep41.22.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7791, i64 0, i64 1, i64 0
  %7798 = bitcast i8* %scevgep41.22.13 to [61 x [61 x i8]]*
  %call16.22.14 = call zeroext i8 (...) @rand()
  store i8 %call16.22.14, i8* %scevgep28.22.13, align 1
  %7799 = load i8, i8* %scevgep28.22.13, align 1
  %conv23.22.14 = zext i8 %7799 to i32
  %7800 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.14 = getelementptr i8, i8* %b, i64 37
  %7801 = load i8, i8* %scevgep34.22.14, align 1
  %call28.22.14 = call zeroext i8 @mult(i8 zeroext %7800, i8 zeroext %7801)
  %conv29.22.14 = zext i8 %call28.22.14 to i32
  %xor.22.14 = xor i32 %conv23.22.14, %conv29.22.14
  %scevgep35.22.14 = getelementptr i8, i8* %a, i64 37
  %7802 = load i8, i8* %scevgep35.22.14, align 1
  %7803 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.14 = call zeroext i8 @mult(i8 zeroext %7802, i8 zeroext %7803)
  %conv35.22.14 = zext i8 %call34.22.14 to i32
  %xor36.22.14 = xor i32 %xor.22.14, %conv35.22.14
  %conv37.22.14 = trunc i32 %xor36.22.14 to i8
  store i8 %conv37.22.14, i8* %scevgep41.22.13, align 1
  %scevgep28.22.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7797, i64 0, i64 0, i64 1
  %7804 = bitcast i8* %scevgep28.22.14 to [61 x [61 x i8]]*
  %scevgep41.22.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7798, i64 0, i64 1, i64 0
  %7805 = bitcast i8* %scevgep41.22.14 to [61 x [61 x i8]]*
  %call16.22.15 = call zeroext i8 (...) @rand()
  store i8 %call16.22.15, i8* %scevgep28.22.14, align 1
  %7806 = load i8, i8* %scevgep28.22.14, align 1
  %conv23.22.15 = zext i8 %7806 to i32
  %7807 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.15 = getelementptr i8, i8* %b, i64 38
  %7808 = load i8, i8* %scevgep34.22.15, align 1
  %call28.22.15 = call zeroext i8 @mult(i8 zeroext %7807, i8 zeroext %7808)
  %conv29.22.15 = zext i8 %call28.22.15 to i32
  %xor.22.15 = xor i32 %conv23.22.15, %conv29.22.15
  %scevgep35.22.15 = getelementptr i8, i8* %a, i64 38
  %7809 = load i8, i8* %scevgep35.22.15, align 1
  %7810 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.15 = call zeroext i8 @mult(i8 zeroext %7809, i8 zeroext %7810)
  %conv35.22.15 = zext i8 %call34.22.15 to i32
  %xor36.22.15 = xor i32 %xor.22.15, %conv35.22.15
  %conv37.22.15 = trunc i32 %xor36.22.15 to i8
  store i8 %conv37.22.15, i8* %scevgep41.22.14, align 1
  %scevgep28.22.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7804, i64 0, i64 0, i64 1
  %7811 = bitcast i8* %scevgep28.22.15 to [61 x [61 x i8]]*
  %scevgep41.22.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7805, i64 0, i64 1, i64 0
  %7812 = bitcast i8* %scevgep41.22.15 to [61 x [61 x i8]]*
  %call16.22.16 = call zeroext i8 (...) @rand()
  store i8 %call16.22.16, i8* %scevgep28.22.15, align 1
  %7813 = load i8, i8* %scevgep28.22.15, align 1
  %conv23.22.16 = zext i8 %7813 to i32
  %7814 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.16 = getelementptr i8, i8* %b, i64 39
  %7815 = load i8, i8* %scevgep34.22.16, align 1
  %call28.22.16 = call zeroext i8 @mult(i8 zeroext %7814, i8 zeroext %7815)
  %conv29.22.16 = zext i8 %call28.22.16 to i32
  %xor.22.16 = xor i32 %conv23.22.16, %conv29.22.16
  %scevgep35.22.16 = getelementptr i8, i8* %a, i64 39
  %7816 = load i8, i8* %scevgep35.22.16, align 1
  %7817 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.16 = call zeroext i8 @mult(i8 zeroext %7816, i8 zeroext %7817)
  %conv35.22.16 = zext i8 %call34.22.16 to i32
  %xor36.22.16 = xor i32 %xor.22.16, %conv35.22.16
  %conv37.22.16 = trunc i32 %xor36.22.16 to i8
  store i8 %conv37.22.16, i8* %scevgep41.22.15, align 1
  %scevgep28.22.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7811, i64 0, i64 0, i64 1
  %7818 = bitcast i8* %scevgep28.22.16 to [61 x [61 x i8]]*
  %scevgep41.22.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7812, i64 0, i64 1, i64 0
  %7819 = bitcast i8* %scevgep41.22.16 to [61 x [61 x i8]]*
  %call16.22.17 = call zeroext i8 (...) @rand()
  store i8 %call16.22.17, i8* %scevgep28.22.16, align 1
  %7820 = load i8, i8* %scevgep28.22.16, align 1
  %conv23.22.17 = zext i8 %7820 to i32
  %7821 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.17 = getelementptr i8, i8* %b, i64 40
  %7822 = load i8, i8* %scevgep34.22.17, align 1
  %call28.22.17 = call zeroext i8 @mult(i8 zeroext %7821, i8 zeroext %7822)
  %conv29.22.17 = zext i8 %call28.22.17 to i32
  %xor.22.17 = xor i32 %conv23.22.17, %conv29.22.17
  %scevgep35.22.17 = getelementptr i8, i8* %a, i64 40
  %7823 = load i8, i8* %scevgep35.22.17, align 1
  %7824 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.17 = call zeroext i8 @mult(i8 zeroext %7823, i8 zeroext %7824)
  %conv35.22.17 = zext i8 %call34.22.17 to i32
  %xor36.22.17 = xor i32 %xor.22.17, %conv35.22.17
  %conv37.22.17 = trunc i32 %xor36.22.17 to i8
  store i8 %conv37.22.17, i8* %scevgep41.22.16, align 1
  %scevgep28.22.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7818, i64 0, i64 0, i64 1
  %7825 = bitcast i8* %scevgep28.22.17 to [61 x [61 x i8]]*
  %scevgep41.22.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7819, i64 0, i64 1, i64 0
  %7826 = bitcast i8* %scevgep41.22.17 to [61 x [61 x i8]]*
  %call16.22.18 = call zeroext i8 (...) @rand()
  store i8 %call16.22.18, i8* %scevgep28.22.17, align 1
  %7827 = load i8, i8* %scevgep28.22.17, align 1
  %conv23.22.18 = zext i8 %7827 to i32
  %7828 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.18 = getelementptr i8, i8* %b, i64 41
  %7829 = load i8, i8* %scevgep34.22.18, align 1
  %call28.22.18 = call zeroext i8 @mult(i8 zeroext %7828, i8 zeroext %7829)
  %conv29.22.18 = zext i8 %call28.22.18 to i32
  %xor.22.18 = xor i32 %conv23.22.18, %conv29.22.18
  %scevgep35.22.18 = getelementptr i8, i8* %a, i64 41
  %7830 = load i8, i8* %scevgep35.22.18, align 1
  %7831 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.18 = call zeroext i8 @mult(i8 zeroext %7830, i8 zeroext %7831)
  %conv35.22.18 = zext i8 %call34.22.18 to i32
  %xor36.22.18 = xor i32 %xor.22.18, %conv35.22.18
  %conv37.22.18 = trunc i32 %xor36.22.18 to i8
  store i8 %conv37.22.18, i8* %scevgep41.22.17, align 1
  %scevgep28.22.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7825, i64 0, i64 0, i64 1
  %7832 = bitcast i8* %scevgep28.22.18 to [61 x [61 x i8]]*
  %scevgep41.22.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7826, i64 0, i64 1, i64 0
  %7833 = bitcast i8* %scevgep41.22.18 to [61 x [61 x i8]]*
  %call16.22.19 = call zeroext i8 (...) @rand()
  store i8 %call16.22.19, i8* %scevgep28.22.18, align 1
  %7834 = load i8, i8* %scevgep28.22.18, align 1
  %conv23.22.19 = zext i8 %7834 to i32
  %7835 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.19 = getelementptr i8, i8* %b, i64 42
  %7836 = load i8, i8* %scevgep34.22.19, align 1
  %call28.22.19 = call zeroext i8 @mult(i8 zeroext %7835, i8 zeroext %7836)
  %conv29.22.19 = zext i8 %call28.22.19 to i32
  %xor.22.19 = xor i32 %conv23.22.19, %conv29.22.19
  %scevgep35.22.19 = getelementptr i8, i8* %a, i64 42
  %7837 = load i8, i8* %scevgep35.22.19, align 1
  %7838 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.19 = call zeroext i8 @mult(i8 zeroext %7837, i8 zeroext %7838)
  %conv35.22.19 = zext i8 %call34.22.19 to i32
  %xor36.22.19 = xor i32 %xor.22.19, %conv35.22.19
  %conv37.22.19 = trunc i32 %xor36.22.19 to i8
  store i8 %conv37.22.19, i8* %scevgep41.22.18, align 1
  %scevgep28.22.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7832, i64 0, i64 0, i64 1
  %7839 = bitcast i8* %scevgep28.22.19 to [61 x [61 x i8]]*
  %scevgep41.22.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7833, i64 0, i64 1, i64 0
  %7840 = bitcast i8* %scevgep41.22.19 to [61 x [61 x i8]]*
  %call16.22.20 = call zeroext i8 (...) @rand()
  store i8 %call16.22.20, i8* %scevgep28.22.19, align 1
  %7841 = load i8, i8* %scevgep28.22.19, align 1
  %conv23.22.20 = zext i8 %7841 to i32
  %7842 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.20 = getelementptr i8, i8* %b, i64 43
  %7843 = load i8, i8* %scevgep34.22.20, align 1
  %call28.22.20 = call zeroext i8 @mult(i8 zeroext %7842, i8 zeroext %7843)
  %conv29.22.20 = zext i8 %call28.22.20 to i32
  %xor.22.20 = xor i32 %conv23.22.20, %conv29.22.20
  %scevgep35.22.20 = getelementptr i8, i8* %a, i64 43
  %7844 = load i8, i8* %scevgep35.22.20, align 1
  %7845 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.20 = call zeroext i8 @mult(i8 zeroext %7844, i8 zeroext %7845)
  %conv35.22.20 = zext i8 %call34.22.20 to i32
  %xor36.22.20 = xor i32 %xor.22.20, %conv35.22.20
  %conv37.22.20 = trunc i32 %xor36.22.20 to i8
  store i8 %conv37.22.20, i8* %scevgep41.22.19, align 1
  %scevgep28.22.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7839, i64 0, i64 0, i64 1
  %7846 = bitcast i8* %scevgep28.22.20 to [61 x [61 x i8]]*
  %scevgep41.22.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7840, i64 0, i64 1, i64 0
  %7847 = bitcast i8* %scevgep41.22.20 to [61 x [61 x i8]]*
  %call16.22.21 = call zeroext i8 (...) @rand()
  store i8 %call16.22.21, i8* %scevgep28.22.20, align 1
  %7848 = load i8, i8* %scevgep28.22.20, align 1
  %conv23.22.21 = zext i8 %7848 to i32
  %7849 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.21 = getelementptr i8, i8* %b, i64 44
  %7850 = load i8, i8* %scevgep34.22.21, align 1
  %call28.22.21 = call zeroext i8 @mult(i8 zeroext %7849, i8 zeroext %7850)
  %conv29.22.21 = zext i8 %call28.22.21 to i32
  %xor.22.21 = xor i32 %conv23.22.21, %conv29.22.21
  %scevgep35.22.21 = getelementptr i8, i8* %a, i64 44
  %7851 = load i8, i8* %scevgep35.22.21, align 1
  %7852 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.21 = call zeroext i8 @mult(i8 zeroext %7851, i8 zeroext %7852)
  %conv35.22.21 = zext i8 %call34.22.21 to i32
  %xor36.22.21 = xor i32 %xor.22.21, %conv35.22.21
  %conv37.22.21 = trunc i32 %xor36.22.21 to i8
  store i8 %conv37.22.21, i8* %scevgep41.22.20, align 1
  %scevgep28.22.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7846, i64 0, i64 0, i64 1
  %7853 = bitcast i8* %scevgep28.22.21 to [61 x [61 x i8]]*
  %scevgep41.22.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7847, i64 0, i64 1, i64 0
  %7854 = bitcast i8* %scevgep41.22.21 to [61 x [61 x i8]]*
  %call16.22.22 = call zeroext i8 (...) @rand()
  store i8 %call16.22.22, i8* %scevgep28.22.21, align 1
  %7855 = load i8, i8* %scevgep28.22.21, align 1
  %conv23.22.22 = zext i8 %7855 to i32
  %7856 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.22 = getelementptr i8, i8* %b, i64 45
  %7857 = load i8, i8* %scevgep34.22.22, align 1
  %call28.22.22 = call zeroext i8 @mult(i8 zeroext %7856, i8 zeroext %7857)
  %conv29.22.22 = zext i8 %call28.22.22 to i32
  %xor.22.22 = xor i32 %conv23.22.22, %conv29.22.22
  %scevgep35.22.22 = getelementptr i8, i8* %a, i64 45
  %7858 = load i8, i8* %scevgep35.22.22, align 1
  %7859 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.22 = call zeroext i8 @mult(i8 zeroext %7858, i8 zeroext %7859)
  %conv35.22.22 = zext i8 %call34.22.22 to i32
  %xor36.22.22 = xor i32 %xor.22.22, %conv35.22.22
  %conv37.22.22 = trunc i32 %xor36.22.22 to i8
  store i8 %conv37.22.22, i8* %scevgep41.22.21, align 1
  %scevgep28.22.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7853, i64 0, i64 0, i64 1
  %7860 = bitcast i8* %scevgep28.22.22 to [61 x [61 x i8]]*
  %scevgep41.22.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7854, i64 0, i64 1, i64 0
  %7861 = bitcast i8* %scevgep41.22.22 to [61 x [61 x i8]]*
  %call16.22.23 = call zeroext i8 (...) @rand()
  store i8 %call16.22.23, i8* %scevgep28.22.22, align 1
  %7862 = load i8, i8* %scevgep28.22.22, align 1
  %conv23.22.23 = zext i8 %7862 to i32
  %7863 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.23 = getelementptr i8, i8* %b, i64 46
  %7864 = load i8, i8* %scevgep34.22.23, align 1
  %call28.22.23 = call zeroext i8 @mult(i8 zeroext %7863, i8 zeroext %7864)
  %conv29.22.23 = zext i8 %call28.22.23 to i32
  %xor.22.23 = xor i32 %conv23.22.23, %conv29.22.23
  %scevgep35.22.23 = getelementptr i8, i8* %a, i64 46
  %7865 = load i8, i8* %scevgep35.22.23, align 1
  %7866 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.23 = call zeroext i8 @mult(i8 zeroext %7865, i8 zeroext %7866)
  %conv35.22.23 = zext i8 %call34.22.23 to i32
  %xor36.22.23 = xor i32 %xor.22.23, %conv35.22.23
  %conv37.22.23 = trunc i32 %xor36.22.23 to i8
  store i8 %conv37.22.23, i8* %scevgep41.22.22, align 1
  %scevgep28.22.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7860, i64 0, i64 0, i64 1
  %7867 = bitcast i8* %scevgep28.22.23 to [61 x [61 x i8]]*
  %scevgep41.22.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7861, i64 0, i64 1, i64 0
  %7868 = bitcast i8* %scevgep41.22.23 to [61 x [61 x i8]]*
  %call16.22.24 = call zeroext i8 (...) @rand()
  store i8 %call16.22.24, i8* %scevgep28.22.23, align 1
  %7869 = load i8, i8* %scevgep28.22.23, align 1
  %conv23.22.24 = zext i8 %7869 to i32
  %7870 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.24 = getelementptr i8, i8* %b, i64 47
  %7871 = load i8, i8* %scevgep34.22.24, align 1
  %call28.22.24 = call zeroext i8 @mult(i8 zeroext %7870, i8 zeroext %7871)
  %conv29.22.24 = zext i8 %call28.22.24 to i32
  %xor.22.24 = xor i32 %conv23.22.24, %conv29.22.24
  %scevgep35.22.24 = getelementptr i8, i8* %a, i64 47
  %7872 = load i8, i8* %scevgep35.22.24, align 1
  %7873 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.24 = call zeroext i8 @mult(i8 zeroext %7872, i8 zeroext %7873)
  %conv35.22.24 = zext i8 %call34.22.24 to i32
  %xor36.22.24 = xor i32 %xor.22.24, %conv35.22.24
  %conv37.22.24 = trunc i32 %xor36.22.24 to i8
  store i8 %conv37.22.24, i8* %scevgep41.22.23, align 1
  %scevgep28.22.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7867, i64 0, i64 0, i64 1
  %7874 = bitcast i8* %scevgep28.22.24 to [61 x [61 x i8]]*
  %scevgep41.22.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7868, i64 0, i64 1, i64 0
  %7875 = bitcast i8* %scevgep41.22.24 to [61 x [61 x i8]]*
  %call16.22.25 = call zeroext i8 (...) @rand()
  store i8 %call16.22.25, i8* %scevgep28.22.24, align 1
  %7876 = load i8, i8* %scevgep28.22.24, align 1
  %conv23.22.25 = zext i8 %7876 to i32
  %7877 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.25 = getelementptr i8, i8* %b, i64 48
  %7878 = load i8, i8* %scevgep34.22.25, align 1
  %call28.22.25 = call zeroext i8 @mult(i8 zeroext %7877, i8 zeroext %7878)
  %conv29.22.25 = zext i8 %call28.22.25 to i32
  %xor.22.25 = xor i32 %conv23.22.25, %conv29.22.25
  %scevgep35.22.25 = getelementptr i8, i8* %a, i64 48
  %7879 = load i8, i8* %scevgep35.22.25, align 1
  %7880 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.25 = call zeroext i8 @mult(i8 zeroext %7879, i8 zeroext %7880)
  %conv35.22.25 = zext i8 %call34.22.25 to i32
  %xor36.22.25 = xor i32 %xor.22.25, %conv35.22.25
  %conv37.22.25 = trunc i32 %xor36.22.25 to i8
  store i8 %conv37.22.25, i8* %scevgep41.22.24, align 1
  %scevgep28.22.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7874, i64 0, i64 0, i64 1
  %7881 = bitcast i8* %scevgep28.22.25 to [61 x [61 x i8]]*
  %scevgep41.22.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7875, i64 0, i64 1, i64 0
  %7882 = bitcast i8* %scevgep41.22.25 to [61 x [61 x i8]]*
  %call16.22.26 = call zeroext i8 (...) @rand()
  store i8 %call16.22.26, i8* %scevgep28.22.25, align 1
  %7883 = load i8, i8* %scevgep28.22.25, align 1
  %conv23.22.26 = zext i8 %7883 to i32
  %7884 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.26 = getelementptr i8, i8* %b, i64 49
  %7885 = load i8, i8* %scevgep34.22.26, align 1
  %call28.22.26 = call zeroext i8 @mult(i8 zeroext %7884, i8 zeroext %7885)
  %conv29.22.26 = zext i8 %call28.22.26 to i32
  %xor.22.26 = xor i32 %conv23.22.26, %conv29.22.26
  %scevgep35.22.26 = getelementptr i8, i8* %a, i64 49
  %7886 = load i8, i8* %scevgep35.22.26, align 1
  %7887 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.26 = call zeroext i8 @mult(i8 zeroext %7886, i8 zeroext %7887)
  %conv35.22.26 = zext i8 %call34.22.26 to i32
  %xor36.22.26 = xor i32 %xor.22.26, %conv35.22.26
  %conv37.22.26 = trunc i32 %xor36.22.26 to i8
  store i8 %conv37.22.26, i8* %scevgep41.22.25, align 1
  %scevgep28.22.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7881, i64 0, i64 0, i64 1
  %7888 = bitcast i8* %scevgep28.22.26 to [61 x [61 x i8]]*
  %scevgep41.22.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7882, i64 0, i64 1, i64 0
  %7889 = bitcast i8* %scevgep41.22.26 to [61 x [61 x i8]]*
  %call16.22.27 = call zeroext i8 (...) @rand()
  store i8 %call16.22.27, i8* %scevgep28.22.26, align 1
  %7890 = load i8, i8* %scevgep28.22.26, align 1
  %conv23.22.27 = zext i8 %7890 to i32
  %7891 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.27 = getelementptr i8, i8* %b, i64 50
  %7892 = load i8, i8* %scevgep34.22.27, align 1
  %call28.22.27 = call zeroext i8 @mult(i8 zeroext %7891, i8 zeroext %7892)
  %conv29.22.27 = zext i8 %call28.22.27 to i32
  %xor.22.27 = xor i32 %conv23.22.27, %conv29.22.27
  %scevgep35.22.27 = getelementptr i8, i8* %a, i64 50
  %7893 = load i8, i8* %scevgep35.22.27, align 1
  %7894 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.27 = call zeroext i8 @mult(i8 zeroext %7893, i8 zeroext %7894)
  %conv35.22.27 = zext i8 %call34.22.27 to i32
  %xor36.22.27 = xor i32 %xor.22.27, %conv35.22.27
  %conv37.22.27 = trunc i32 %xor36.22.27 to i8
  store i8 %conv37.22.27, i8* %scevgep41.22.26, align 1
  %scevgep28.22.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7888, i64 0, i64 0, i64 1
  %7895 = bitcast i8* %scevgep28.22.27 to [61 x [61 x i8]]*
  %scevgep41.22.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7889, i64 0, i64 1, i64 0
  %7896 = bitcast i8* %scevgep41.22.27 to [61 x [61 x i8]]*
  %call16.22.28 = call zeroext i8 (...) @rand()
  store i8 %call16.22.28, i8* %scevgep28.22.27, align 1
  %7897 = load i8, i8* %scevgep28.22.27, align 1
  %conv23.22.28 = zext i8 %7897 to i32
  %7898 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.28 = getelementptr i8, i8* %b, i64 51
  %7899 = load i8, i8* %scevgep34.22.28, align 1
  %call28.22.28 = call zeroext i8 @mult(i8 zeroext %7898, i8 zeroext %7899)
  %conv29.22.28 = zext i8 %call28.22.28 to i32
  %xor.22.28 = xor i32 %conv23.22.28, %conv29.22.28
  %scevgep35.22.28 = getelementptr i8, i8* %a, i64 51
  %7900 = load i8, i8* %scevgep35.22.28, align 1
  %7901 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.28 = call zeroext i8 @mult(i8 zeroext %7900, i8 zeroext %7901)
  %conv35.22.28 = zext i8 %call34.22.28 to i32
  %xor36.22.28 = xor i32 %xor.22.28, %conv35.22.28
  %conv37.22.28 = trunc i32 %xor36.22.28 to i8
  store i8 %conv37.22.28, i8* %scevgep41.22.27, align 1
  %scevgep28.22.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7895, i64 0, i64 0, i64 1
  %7902 = bitcast i8* %scevgep28.22.28 to [61 x [61 x i8]]*
  %scevgep41.22.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7896, i64 0, i64 1, i64 0
  %7903 = bitcast i8* %scevgep41.22.28 to [61 x [61 x i8]]*
  %call16.22.29 = call zeroext i8 (...) @rand()
  store i8 %call16.22.29, i8* %scevgep28.22.28, align 1
  %7904 = load i8, i8* %scevgep28.22.28, align 1
  %conv23.22.29 = zext i8 %7904 to i32
  %7905 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.29 = getelementptr i8, i8* %b, i64 52
  %7906 = load i8, i8* %scevgep34.22.29, align 1
  %call28.22.29 = call zeroext i8 @mult(i8 zeroext %7905, i8 zeroext %7906)
  %conv29.22.29 = zext i8 %call28.22.29 to i32
  %xor.22.29 = xor i32 %conv23.22.29, %conv29.22.29
  %scevgep35.22.29 = getelementptr i8, i8* %a, i64 52
  %7907 = load i8, i8* %scevgep35.22.29, align 1
  %7908 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.29 = call zeroext i8 @mult(i8 zeroext %7907, i8 zeroext %7908)
  %conv35.22.29 = zext i8 %call34.22.29 to i32
  %xor36.22.29 = xor i32 %xor.22.29, %conv35.22.29
  %conv37.22.29 = trunc i32 %xor36.22.29 to i8
  store i8 %conv37.22.29, i8* %scevgep41.22.28, align 1
  %scevgep28.22.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7902, i64 0, i64 0, i64 1
  %7909 = bitcast i8* %scevgep28.22.29 to [61 x [61 x i8]]*
  %scevgep41.22.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7903, i64 0, i64 1, i64 0
  %7910 = bitcast i8* %scevgep41.22.29 to [61 x [61 x i8]]*
  %call16.22.30 = call zeroext i8 (...) @rand()
  store i8 %call16.22.30, i8* %scevgep28.22.29, align 1
  %7911 = load i8, i8* %scevgep28.22.29, align 1
  %conv23.22.30 = zext i8 %7911 to i32
  %7912 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.30 = getelementptr i8, i8* %b, i64 53
  %7913 = load i8, i8* %scevgep34.22.30, align 1
  %call28.22.30 = call zeroext i8 @mult(i8 zeroext %7912, i8 zeroext %7913)
  %conv29.22.30 = zext i8 %call28.22.30 to i32
  %xor.22.30 = xor i32 %conv23.22.30, %conv29.22.30
  %scevgep35.22.30 = getelementptr i8, i8* %a, i64 53
  %7914 = load i8, i8* %scevgep35.22.30, align 1
  %7915 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.30 = call zeroext i8 @mult(i8 zeroext %7914, i8 zeroext %7915)
  %conv35.22.30 = zext i8 %call34.22.30 to i32
  %xor36.22.30 = xor i32 %xor.22.30, %conv35.22.30
  %conv37.22.30 = trunc i32 %xor36.22.30 to i8
  store i8 %conv37.22.30, i8* %scevgep41.22.29, align 1
  %scevgep28.22.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7909, i64 0, i64 0, i64 1
  %7916 = bitcast i8* %scevgep28.22.30 to [61 x [61 x i8]]*
  %scevgep41.22.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7910, i64 0, i64 1, i64 0
  %7917 = bitcast i8* %scevgep41.22.30 to [61 x [61 x i8]]*
  %call16.22.31 = call zeroext i8 (...) @rand()
  store i8 %call16.22.31, i8* %scevgep28.22.30, align 1
  %7918 = load i8, i8* %scevgep28.22.30, align 1
  %conv23.22.31 = zext i8 %7918 to i32
  %7919 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.31 = getelementptr i8, i8* %b, i64 54
  %7920 = load i8, i8* %scevgep34.22.31, align 1
  %call28.22.31 = call zeroext i8 @mult(i8 zeroext %7919, i8 zeroext %7920)
  %conv29.22.31 = zext i8 %call28.22.31 to i32
  %xor.22.31 = xor i32 %conv23.22.31, %conv29.22.31
  %scevgep35.22.31 = getelementptr i8, i8* %a, i64 54
  %7921 = load i8, i8* %scevgep35.22.31, align 1
  %7922 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.31 = call zeroext i8 @mult(i8 zeroext %7921, i8 zeroext %7922)
  %conv35.22.31 = zext i8 %call34.22.31 to i32
  %xor36.22.31 = xor i32 %xor.22.31, %conv35.22.31
  %conv37.22.31 = trunc i32 %xor36.22.31 to i8
  store i8 %conv37.22.31, i8* %scevgep41.22.30, align 1
  %scevgep28.22.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7916, i64 0, i64 0, i64 1
  %7923 = bitcast i8* %scevgep28.22.31 to [61 x [61 x i8]]*
  %scevgep41.22.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7917, i64 0, i64 1, i64 0
  %7924 = bitcast i8* %scevgep41.22.31 to [61 x [61 x i8]]*
  %call16.22.32 = call zeroext i8 (...) @rand()
  store i8 %call16.22.32, i8* %scevgep28.22.31, align 1
  %7925 = load i8, i8* %scevgep28.22.31, align 1
  %conv23.22.32 = zext i8 %7925 to i32
  %7926 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.32 = getelementptr i8, i8* %b, i64 55
  %7927 = load i8, i8* %scevgep34.22.32, align 1
  %call28.22.32 = call zeroext i8 @mult(i8 zeroext %7926, i8 zeroext %7927)
  %conv29.22.32 = zext i8 %call28.22.32 to i32
  %xor.22.32 = xor i32 %conv23.22.32, %conv29.22.32
  %scevgep35.22.32 = getelementptr i8, i8* %a, i64 55
  %7928 = load i8, i8* %scevgep35.22.32, align 1
  %7929 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.32 = call zeroext i8 @mult(i8 zeroext %7928, i8 zeroext %7929)
  %conv35.22.32 = zext i8 %call34.22.32 to i32
  %xor36.22.32 = xor i32 %xor.22.32, %conv35.22.32
  %conv37.22.32 = trunc i32 %xor36.22.32 to i8
  store i8 %conv37.22.32, i8* %scevgep41.22.31, align 1
  %scevgep28.22.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7923, i64 0, i64 0, i64 1
  %7930 = bitcast i8* %scevgep28.22.32 to [61 x [61 x i8]]*
  %scevgep41.22.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7924, i64 0, i64 1, i64 0
  %7931 = bitcast i8* %scevgep41.22.32 to [61 x [61 x i8]]*
  %call16.22.33 = call zeroext i8 (...) @rand()
  store i8 %call16.22.33, i8* %scevgep28.22.32, align 1
  %7932 = load i8, i8* %scevgep28.22.32, align 1
  %conv23.22.33 = zext i8 %7932 to i32
  %7933 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.33 = getelementptr i8, i8* %b, i64 56
  %7934 = load i8, i8* %scevgep34.22.33, align 1
  %call28.22.33 = call zeroext i8 @mult(i8 zeroext %7933, i8 zeroext %7934)
  %conv29.22.33 = zext i8 %call28.22.33 to i32
  %xor.22.33 = xor i32 %conv23.22.33, %conv29.22.33
  %scevgep35.22.33 = getelementptr i8, i8* %a, i64 56
  %7935 = load i8, i8* %scevgep35.22.33, align 1
  %7936 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.33 = call zeroext i8 @mult(i8 zeroext %7935, i8 zeroext %7936)
  %conv35.22.33 = zext i8 %call34.22.33 to i32
  %xor36.22.33 = xor i32 %xor.22.33, %conv35.22.33
  %conv37.22.33 = trunc i32 %xor36.22.33 to i8
  store i8 %conv37.22.33, i8* %scevgep41.22.32, align 1
  %scevgep28.22.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7930, i64 0, i64 0, i64 1
  %7937 = bitcast i8* %scevgep28.22.33 to [61 x [61 x i8]]*
  %scevgep41.22.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7931, i64 0, i64 1, i64 0
  %7938 = bitcast i8* %scevgep41.22.33 to [61 x [61 x i8]]*
  %call16.22.34 = call zeroext i8 (...) @rand()
  store i8 %call16.22.34, i8* %scevgep28.22.33, align 1
  %7939 = load i8, i8* %scevgep28.22.33, align 1
  %conv23.22.34 = zext i8 %7939 to i32
  %7940 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.34 = getelementptr i8, i8* %b, i64 57
  %7941 = load i8, i8* %scevgep34.22.34, align 1
  %call28.22.34 = call zeroext i8 @mult(i8 zeroext %7940, i8 zeroext %7941)
  %conv29.22.34 = zext i8 %call28.22.34 to i32
  %xor.22.34 = xor i32 %conv23.22.34, %conv29.22.34
  %scevgep35.22.34 = getelementptr i8, i8* %a, i64 57
  %7942 = load i8, i8* %scevgep35.22.34, align 1
  %7943 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.34 = call zeroext i8 @mult(i8 zeroext %7942, i8 zeroext %7943)
  %conv35.22.34 = zext i8 %call34.22.34 to i32
  %xor36.22.34 = xor i32 %xor.22.34, %conv35.22.34
  %conv37.22.34 = trunc i32 %xor36.22.34 to i8
  store i8 %conv37.22.34, i8* %scevgep41.22.33, align 1
  %scevgep28.22.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7937, i64 0, i64 0, i64 1
  %7944 = bitcast i8* %scevgep28.22.34 to [61 x [61 x i8]]*
  %scevgep41.22.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7938, i64 0, i64 1, i64 0
  %7945 = bitcast i8* %scevgep41.22.34 to [61 x [61 x i8]]*
  %call16.22.35 = call zeroext i8 (...) @rand()
  store i8 %call16.22.35, i8* %scevgep28.22.34, align 1
  %7946 = load i8, i8* %scevgep28.22.34, align 1
  %conv23.22.35 = zext i8 %7946 to i32
  %7947 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.35 = getelementptr i8, i8* %b, i64 58
  %7948 = load i8, i8* %scevgep34.22.35, align 1
  %call28.22.35 = call zeroext i8 @mult(i8 zeroext %7947, i8 zeroext %7948)
  %conv29.22.35 = zext i8 %call28.22.35 to i32
  %xor.22.35 = xor i32 %conv23.22.35, %conv29.22.35
  %scevgep35.22.35 = getelementptr i8, i8* %a, i64 58
  %7949 = load i8, i8* %scevgep35.22.35, align 1
  %7950 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.35 = call zeroext i8 @mult(i8 zeroext %7949, i8 zeroext %7950)
  %conv35.22.35 = zext i8 %call34.22.35 to i32
  %xor36.22.35 = xor i32 %xor.22.35, %conv35.22.35
  %conv37.22.35 = trunc i32 %xor36.22.35 to i8
  store i8 %conv37.22.35, i8* %scevgep41.22.34, align 1
  %scevgep28.22.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7944, i64 0, i64 0, i64 1
  %7951 = bitcast i8* %scevgep28.22.35 to [61 x [61 x i8]]*
  %scevgep41.22.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7945, i64 0, i64 1, i64 0
  %7952 = bitcast i8* %scevgep41.22.35 to [61 x [61 x i8]]*
  %call16.22.36 = call zeroext i8 (...) @rand()
  store i8 %call16.22.36, i8* %scevgep28.22.35, align 1
  %7953 = load i8, i8* %scevgep28.22.35, align 1
  %conv23.22.36 = zext i8 %7953 to i32
  %7954 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.36 = getelementptr i8, i8* %b, i64 59
  %7955 = load i8, i8* %scevgep34.22.36, align 1
  %call28.22.36 = call zeroext i8 @mult(i8 zeroext %7954, i8 zeroext %7955)
  %conv29.22.36 = zext i8 %call28.22.36 to i32
  %xor.22.36 = xor i32 %conv23.22.36, %conv29.22.36
  %scevgep35.22.36 = getelementptr i8, i8* %a, i64 59
  %7956 = load i8, i8* %scevgep35.22.36, align 1
  %7957 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.36 = call zeroext i8 @mult(i8 zeroext %7956, i8 zeroext %7957)
  %conv35.22.36 = zext i8 %call34.22.36 to i32
  %xor36.22.36 = xor i32 %xor.22.36, %conv35.22.36
  %conv37.22.36 = trunc i32 %xor36.22.36 to i8
  store i8 %conv37.22.36, i8* %scevgep41.22.35, align 1
  %scevgep28.22.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7951, i64 0, i64 0, i64 1
  %scevgep41.22.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7952, i64 0, i64 1, i64 0
  %call16.22.37 = call zeroext i8 (...) @rand()
  store i8 %call16.22.37, i8* %scevgep28.22.36, align 1
  %7958 = load i8, i8* %scevgep28.22.36, align 1
  %conv23.22.37 = zext i8 %7958 to i32
  %7959 = load i8, i8* %arrayidx25.22, align 1
  %scevgep34.22.37 = getelementptr i8, i8* %b, i64 60
  %7960 = load i8, i8* %scevgep34.22.37, align 1
  %call28.22.37 = call zeroext i8 @mult(i8 zeroext %7959, i8 zeroext %7960)
  %conv29.22.37 = zext i8 %call28.22.37 to i32
  %xor.22.37 = xor i32 %conv23.22.37, %conv29.22.37
  %scevgep35.22.37 = getelementptr i8, i8* %a, i64 60
  %7961 = load i8, i8* %scevgep35.22.37, align 1
  %7962 = load i8, i8* %arrayidx33.22, align 1
  %call34.22.37 = call zeroext i8 @mult(i8 zeroext %7961, i8 zeroext %7962)
  %conv35.22.37 = zext i8 %call34.22.37 to i32
  %xor36.22.37 = xor i32 %xor.22.37, %conv35.22.37
  %conv37.22.37 = trunc i32 %xor36.22.37 to i8
  store i8 %conv37.22.37, i8* %scevgep41.22.36, align 1
  %scevgep26.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7699, i64 0, i64 1, i64 1
  %7963 = bitcast i8* %scevgep26.22 to [61 x [61 x i8]]*
  %scevgep39.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7700, i64 0, i64 1, i64 1
  %7964 = bitcast i8* %scevgep39.22 to [61 x [61 x i8]]*
  %arrayidx25.23 = getelementptr inbounds i8, i8* %a, i64 23
  %arrayidx33.23 = getelementptr inbounds i8, i8* %b, i64 23
  %call16.23 = call zeroext i8 (...) @rand()
  store i8 %call16.23, i8* %scevgep26.22, align 1
  %7965 = load i8, i8* %scevgep26.22, align 1
  %conv23.23 = zext i8 %7965 to i32
  %7966 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23 = getelementptr i8, i8* %b, i64 24
  %7967 = load i8, i8* %scevgep34.23, align 1
  %call28.23 = call zeroext i8 @mult(i8 zeroext %7966, i8 zeroext %7967)
  %conv29.23 = zext i8 %call28.23 to i32
  %xor.23 = xor i32 %conv23.23, %conv29.23
  %scevgep35.23 = getelementptr i8, i8* %a, i64 24
  %7968 = load i8, i8* %scevgep35.23, align 1
  %7969 = load i8, i8* %arrayidx33.23, align 1
  %call34.23 = call zeroext i8 @mult(i8 zeroext %7968, i8 zeroext %7969)
  %conv35.23 = zext i8 %call34.23 to i32
  %xor36.23 = xor i32 %xor.23, %conv35.23
  %conv37.23 = trunc i32 %xor36.23 to i8
  store i8 %conv37.23, i8* %scevgep39.22, align 1
  %scevgep28.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7963, i64 0, i64 0, i64 1
  %7970 = bitcast i8* %scevgep28.23 to [61 x [61 x i8]]*
  %scevgep41.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7964, i64 0, i64 1, i64 0
  %7971 = bitcast i8* %scevgep41.23 to [61 x [61 x i8]]*
  %call16.23.1 = call zeroext i8 (...) @rand()
  store i8 %call16.23.1, i8* %scevgep28.23, align 1
  %7972 = load i8, i8* %scevgep28.23, align 1
  %conv23.23.1 = zext i8 %7972 to i32
  %7973 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.1 = getelementptr i8, i8* %b, i64 25
  %7974 = load i8, i8* %scevgep34.23.1, align 1
  %call28.23.1 = call zeroext i8 @mult(i8 zeroext %7973, i8 zeroext %7974)
  %conv29.23.1 = zext i8 %call28.23.1 to i32
  %xor.23.1 = xor i32 %conv23.23.1, %conv29.23.1
  %scevgep35.23.1 = getelementptr i8, i8* %a, i64 25
  %7975 = load i8, i8* %scevgep35.23.1, align 1
  %7976 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.1 = call zeroext i8 @mult(i8 zeroext %7975, i8 zeroext %7976)
  %conv35.23.1 = zext i8 %call34.23.1 to i32
  %xor36.23.1 = xor i32 %xor.23.1, %conv35.23.1
  %conv37.23.1 = trunc i32 %xor36.23.1 to i8
  store i8 %conv37.23.1, i8* %scevgep41.23, align 1
  %scevgep28.23.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7970, i64 0, i64 0, i64 1
  %7977 = bitcast i8* %scevgep28.23.1 to [61 x [61 x i8]]*
  %scevgep41.23.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7971, i64 0, i64 1, i64 0
  %7978 = bitcast i8* %scevgep41.23.1 to [61 x [61 x i8]]*
  %call16.23.2 = call zeroext i8 (...) @rand()
  store i8 %call16.23.2, i8* %scevgep28.23.1, align 1
  %7979 = load i8, i8* %scevgep28.23.1, align 1
  %conv23.23.2 = zext i8 %7979 to i32
  %7980 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.2 = getelementptr i8, i8* %b, i64 26
  %7981 = load i8, i8* %scevgep34.23.2, align 1
  %call28.23.2 = call zeroext i8 @mult(i8 zeroext %7980, i8 zeroext %7981)
  %conv29.23.2 = zext i8 %call28.23.2 to i32
  %xor.23.2 = xor i32 %conv23.23.2, %conv29.23.2
  %scevgep35.23.2 = getelementptr i8, i8* %a, i64 26
  %7982 = load i8, i8* %scevgep35.23.2, align 1
  %7983 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.2 = call zeroext i8 @mult(i8 zeroext %7982, i8 zeroext %7983)
  %conv35.23.2 = zext i8 %call34.23.2 to i32
  %xor36.23.2 = xor i32 %xor.23.2, %conv35.23.2
  %conv37.23.2 = trunc i32 %xor36.23.2 to i8
  store i8 %conv37.23.2, i8* %scevgep41.23.1, align 1
  %scevgep28.23.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7977, i64 0, i64 0, i64 1
  %7984 = bitcast i8* %scevgep28.23.2 to [61 x [61 x i8]]*
  %scevgep41.23.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7978, i64 0, i64 1, i64 0
  %7985 = bitcast i8* %scevgep41.23.2 to [61 x [61 x i8]]*
  %call16.23.3 = call zeroext i8 (...) @rand()
  store i8 %call16.23.3, i8* %scevgep28.23.2, align 1
  %7986 = load i8, i8* %scevgep28.23.2, align 1
  %conv23.23.3 = zext i8 %7986 to i32
  %7987 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.3 = getelementptr i8, i8* %b, i64 27
  %7988 = load i8, i8* %scevgep34.23.3, align 1
  %call28.23.3 = call zeroext i8 @mult(i8 zeroext %7987, i8 zeroext %7988)
  %conv29.23.3 = zext i8 %call28.23.3 to i32
  %xor.23.3 = xor i32 %conv23.23.3, %conv29.23.3
  %scevgep35.23.3 = getelementptr i8, i8* %a, i64 27
  %7989 = load i8, i8* %scevgep35.23.3, align 1
  %7990 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.3 = call zeroext i8 @mult(i8 zeroext %7989, i8 zeroext %7990)
  %conv35.23.3 = zext i8 %call34.23.3 to i32
  %xor36.23.3 = xor i32 %xor.23.3, %conv35.23.3
  %conv37.23.3 = trunc i32 %xor36.23.3 to i8
  store i8 %conv37.23.3, i8* %scevgep41.23.2, align 1
  %scevgep28.23.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7984, i64 0, i64 0, i64 1
  %7991 = bitcast i8* %scevgep28.23.3 to [61 x [61 x i8]]*
  %scevgep41.23.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7985, i64 0, i64 1, i64 0
  %7992 = bitcast i8* %scevgep41.23.3 to [61 x [61 x i8]]*
  %call16.23.4 = call zeroext i8 (...) @rand()
  store i8 %call16.23.4, i8* %scevgep28.23.3, align 1
  %7993 = load i8, i8* %scevgep28.23.3, align 1
  %conv23.23.4 = zext i8 %7993 to i32
  %7994 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.4 = getelementptr i8, i8* %b, i64 28
  %7995 = load i8, i8* %scevgep34.23.4, align 1
  %call28.23.4 = call zeroext i8 @mult(i8 zeroext %7994, i8 zeroext %7995)
  %conv29.23.4 = zext i8 %call28.23.4 to i32
  %xor.23.4 = xor i32 %conv23.23.4, %conv29.23.4
  %scevgep35.23.4 = getelementptr i8, i8* %a, i64 28
  %7996 = load i8, i8* %scevgep35.23.4, align 1
  %7997 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.4 = call zeroext i8 @mult(i8 zeroext %7996, i8 zeroext %7997)
  %conv35.23.4 = zext i8 %call34.23.4 to i32
  %xor36.23.4 = xor i32 %xor.23.4, %conv35.23.4
  %conv37.23.4 = trunc i32 %xor36.23.4 to i8
  store i8 %conv37.23.4, i8* %scevgep41.23.3, align 1
  %scevgep28.23.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7991, i64 0, i64 0, i64 1
  %7998 = bitcast i8* %scevgep28.23.4 to [61 x [61 x i8]]*
  %scevgep41.23.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7992, i64 0, i64 1, i64 0
  %7999 = bitcast i8* %scevgep41.23.4 to [61 x [61 x i8]]*
  %call16.23.5 = call zeroext i8 (...) @rand()
  store i8 %call16.23.5, i8* %scevgep28.23.4, align 1
  %8000 = load i8, i8* %scevgep28.23.4, align 1
  %conv23.23.5 = zext i8 %8000 to i32
  %8001 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.5 = getelementptr i8, i8* %b, i64 29
  %8002 = load i8, i8* %scevgep34.23.5, align 1
  %call28.23.5 = call zeroext i8 @mult(i8 zeroext %8001, i8 zeroext %8002)
  %conv29.23.5 = zext i8 %call28.23.5 to i32
  %xor.23.5 = xor i32 %conv23.23.5, %conv29.23.5
  %scevgep35.23.5 = getelementptr i8, i8* %a, i64 29
  %8003 = load i8, i8* %scevgep35.23.5, align 1
  %8004 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.5 = call zeroext i8 @mult(i8 zeroext %8003, i8 zeroext %8004)
  %conv35.23.5 = zext i8 %call34.23.5 to i32
  %xor36.23.5 = xor i32 %xor.23.5, %conv35.23.5
  %conv37.23.5 = trunc i32 %xor36.23.5 to i8
  store i8 %conv37.23.5, i8* %scevgep41.23.4, align 1
  %scevgep28.23.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7998, i64 0, i64 0, i64 1
  %8005 = bitcast i8* %scevgep28.23.5 to [61 x [61 x i8]]*
  %scevgep41.23.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7999, i64 0, i64 1, i64 0
  %8006 = bitcast i8* %scevgep41.23.5 to [61 x [61 x i8]]*
  %call16.23.6 = call zeroext i8 (...) @rand()
  store i8 %call16.23.6, i8* %scevgep28.23.5, align 1
  %8007 = load i8, i8* %scevgep28.23.5, align 1
  %conv23.23.6 = zext i8 %8007 to i32
  %8008 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.6 = getelementptr i8, i8* %b, i64 30
  %8009 = load i8, i8* %scevgep34.23.6, align 1
  %call28.23.6 = call zeroext i8 @mult(i8 zeroext %8008, i8 zeroext %8009)
  %conv29.23.6 = zext i8 %call28.23.6 to i32
  %xor.23.6 = xor i32 %conv23.23.6, %conv29.23.6
  %scevgep35.23.6 = getelementptr i8, i8* %a, i64 30
  %8010 = load i8, i8* %scevgep35.23.6, align 1
  %8011 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.6 = call zeroext i8 @mult(i8 zeroext %8010, i8 zeroext %8011)
  %conv35.23.6 = zext i8 %call34.23.6 to i32
  %xor36.23.6 = xor i32 %xor.23.6, %conv35.23.6
  %conv37.23.6 = trunc i32 %xor36.23.6 to i8
  store i8 %conv37.23.6, i8* %scevgep41.23.5, align 1
  %scevgep28.23.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8005, i64 0, i64 0, i64 1
  %8012 = bitcast i8* %scevgep28.23.6 to [61 x [61 x i8]]*
  %scevgep41.23.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8006, i64 0, i64 1, i64 0
  %8013 = bitcast i8* %scevgep41.23.6 to [61 x [61 x i8]]*
  %call16.23.7 = call zeroext i8 (...) @rand()
  store i8 %call16.23.7, i8* %scevgep28.23.6, align 1
  %8014 = load i8, i8* %scevgep28.23.6, align 1
  %conv23.23.7 = zext i8 %8014 to i32
  %8015 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.7 = getelementptr i8, i8* %b, i64 31
  %8016 = load i8, i8* %scevgep34.23.7, align 1
  %call28.23.7 = call zeroext i8 @mult(i8 zeroext %8015, i8 zeroext %8016)
  %conv29.23.7 = zext i8 %call28.23.7 to i32
  %xor.23.7 = xor i32 %conv23.23.7, %conv29.23.7
  %scevgep35.23.7 = getelementptr i8, i8* %a, i64 31
  %8017 = load i8, i8* %scevgep35.23.7, align 1
  %8018 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.7 = call zeroext i8 @mult(i8 zeroext %8017, i8 zeroext %8018)
  %conv35.23.7 = zext i8 %call34.23.7 to i32
  %xor36.23.7 = xor i32 %xor.23.7, %conv35.23.7
  %conv37.23.7 = trunc i32 %xor36.23.7 to i8
  store i8 %conv37.23.7, i8* %scevgep41.23.6, align 1
  %scevgep28.23.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8012, i64 0, i64 0, i64 1
  %8019 = bitcast i8* %scevgep28.23.7 to [61 x [61 x i8]]*
  %scevgep41.23.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8013, i64 0, i64 1, i64 0
  %8020 = bitcast i8* %scevgep41.23.7 to [61 x [61 x i8]]*
  %call16.23.8 = call zeroext i8 (...) @rand()
  store i8 %call16.23.8, i8* %scevgep28.23.7, align 1
  %8021 = load i8, i8* %scevgep28.23.7, align 1
  %conv23.23.8 = zext i8 %8021 to i32
  %8022 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.8 = getelementptr i8, i8* %b, i64 32
  %8023 = load i8, i8* %scevgep34.23.8, align 1
  %call28.23.8 = call zeroext i8 @mult(i8 zeroext %8022, i8 zeroext %8023)
  %conv29.23.8 = zext i8 %call28.23.8 to i32
  %xor.23.8 = xor i32 %conv23.23.8, %conv29.23.8
  %scevgep35.23.8 = getelementptr i8, i8* %a, i64 32
  %8024 = load i8, i8* %scevgep35.23.8, align 1
  %8025 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.8 = call zeroext i8 @mult(i8 zeroext %8024, i8 zeroext %8025)
  %conv35.23.8 = zext i8 %call34.23.8 to i32
  %xor36.23.8 = xor i32 %xor.23.8, %conv35.23.8
  %conv37.23.8 = trunc i32 %xor36.23.8 to i8
  store i8 %conv37.23.8, i8* %scevgep41.23.7, align 1
  %scevgep28.23.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8019, i64 0, i64 0, i64 1
  %8026 = bitcast i8* %scevgep28.23.8 to [61 x [61 x i8]]*
  %scevgep41.23.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8020, i64 0, i64 1, i64 0
  %8027 = bitcast i8* %scevgep41.23.8 to [61 x [61 x i8]]*
  %call16.23.9 = call zeroext i8 (...) @rand()
  store i8 %call16.23.9, i8* %scevgep28.23.8, align 1
  %8028 = load i8, i8* %scevgep28.23.8, align 1
  %conv23.23.9 = zext i8 %8028 to i32
  %8029 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.9 = getelementptr i8, i8* %b, i64 33
  %8030 = load i8, i8* %scevgep34.23.9, align 1
  %call28.23.9 = call zeroext i8 @mult(i8 zeroext %8029, i8 zeroext %8030)
  %conv29.23.9 = zext i8 %call28.23.9 to i32
  %xor.23.9 = xor i32 %conv23.23.9, %conv29.23.9
  %scevgep35.23.9 = getelementptr i8, i8* %a, i64 33
  %8031 = load i8, i8* %scevgep35.23.9, align 1
  %8032 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.9 = call zeroext i8 @mult(i8 zeroext %8031, i8 zeroext %8032)
  %conv35.23.9 = zext i8 %call34.23.9 to i32
  %xor36.23.9 = xor i32 %xor.23.9, %conv35.23.9
  %conv37.23.9 = trunc i32 %xor36.23.9 to i8
  store i8 %conv37.23.9, i8* %scevgep41.23.8, align 1
  %scevgep28.23.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8026, i64 0, i64 0, i64 1
  %8033 = bitcast i8* %scevgep28.23.9 to [61 x [61 x i8]]*
  %scevgep41.23.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8027, i64 0, i64 1, i64 0
  %8034 = bitcast i8* %scevgep41.23.9 to [61 x [61 x i8]]*
  %call16.23.10 = call zeroext i8 (...) @rand()
  store i8 %call16.23.10, i8* %scevgep28.23.9, align 1
  %8035 = load i8, i8* %scevgep28.23.9, align 1
  %conv23.23.10 = zext i8 %8035 to i32
  %8036 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.10 = getelementptr i8, i8* %b, i64 34
  %8037 = load i8, i8* %scevgep34.23.10, align 1
  %call28.23.10 = call zeroext i8 @mult(i8 zeroext %8036, i8 zeroext %8037)
  %conv29.23.10 = zext i8 %call28.23.10 to i32
  %xor.23.10 = xor i32 %conv23.23.10, %conv29.23.10
  %scevgep35.23.10 = getelementptr i8, i8* %a, i64 34
  %8038 = load i8, i8* %scevgep35.23.10, align 1
  %8039 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.10 = call zeroext i8 @mult(i8 zeroext %8038, i8 zeroext %8039)
  %conv35.23.10 = zext i8 %call34.23.10 to i32
  %xor36.23.10 = xor i32 %xor.23.10, %conv35.23.10
  %conv37.23.10 = trunc i32 %xor36.23.10 to i8
  store i8 %conv37.23.10, i8* %scevgep41.23.9, align 1
  %scevgep28.23.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8033, i64 0, i64 0, i64 1
  %8040 = bitcast i8* %scevgep28.23.10 to [61 x [61 x i8]]*
  %scevgep41.23.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8034, i64 0, i64 1, i64 0
  %8041 = bitcast i8* %scevgep41.23.10 to [61 x [61 x i8]]*
  %call16.23.11 = call zeroext i8 (...) @rand()
  store i8 %call16.23.11, i8* %scevgep28.23.10, align 1
  %8042 = load i8, i8* %scevgep28.23.10, align 1
  %conv23.23.11 = zext i8 %8042 to i32
  %8043 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.11 = getelementptr i8, i8* %b, i64 35
  %8044 = load i8, i8* %scevgep34.23.11, align 1
  %call28.23.11 = call zeroext i8 @mult(i8 zeroext %8043, i8 zeroext %8044)
  %conv29.23.11 = zext i8 %call28.23.11 to i32
  %xor.23.11 = xor i32 %conv23.23.11, %conv29.23.11
  %scevgep35.23.11 = getelementptr i8, i8* %a, i64 35
  %8045 = load i8, i8* %scevgep35.23.11, align 1
  %8046 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.11 = call zeroext i8 @mult(i8 zeroext %8045, i8 zeroext %8046)
  %conv35.23.11 = zext i8 %call34.23.11 to i32
  %xor36.23.11 = xor i32 %xor.23.11, %conv35.23.11
  %conv37.23.11 = trunc i32 %xor36.23.11 to i8
  store i8 %conv37.23.11, i8* %scevgep41.23.10, align 1
  %scevgep28.23.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8040, i64 0, i64 0, i64 1
  %8047 = bitcast i8* %scevgep28.23.11 to [61 x [61 x i8]]*
  %scevgep41.23.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8041, i64 0, i64 1, i64 0
  %8048 = bitcast i8* %scevgep41.23.11 to [61 x [61 x i8]]*
  %call16.23.12 = call zeroext i8 (...) @rand()
  store i8 %call16.23.12, i8* %scevgep28.23.11, align 1
  %8049 = load i8, i8* %scevgep28.23.11, align 1
  %conv23.23.12 = zext i8 %8049 to i32
  %8050 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.12 = getelementptr i8, i8* %b, i64 36
  %8051 = load i8, i8* %scevgep34.23.12, align 1
  %call28.23.12 = call zeroext i8 @mult(i8 zeroext %8050, i8 zeroext %8051)
  %conv29.23.12 = zext i8 %call28.23.12 to i32
  %xor.23.12 = xor i32 %conv23.23.12, %conv29.23.12
  %scevgep35.23.12 = getelementptr i8, i8* %a, i64 36
  %8052 = load i8, i8* %scevgep35.23.12, align 1
  %8053 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.12 = call zeroext i8 @mult(i8 zeroext %8052, i8 zeroext %8053)
  %conv35.23.12 = zext i8 %call34.23.12 to i32
  %xor36.23.12 = xor i32 %xor.23.12, %conv35.23.12
  %conv37.23.12 = trunc i32 %xor36.23.12 to i8
  store i8 %conv37.23.12, i8* %scevgep41.23.11, align 1
  %scevgep28.23.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8047, i64 0, i64 0, i64 1
  %8054 = bitcast i8* %scevgep28.23.12 to [61 x [61 x i8]]*
  %scevgep41.23.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8048, i64 0, i64 1, i64 0
  %8055 = bitcast i8* %scevgep41.23.12 to [61 x [61 x i8]]*
  %call16.23.13 = call zeroext i8 (...) @rand()
  store i8 %call16.23.13, i8* %scevgep28.23.12, align 1
  %8056 = load i8, i8* %scevgep28.23.12, align 1
  %conv23.23.13 = zext i8 %8056 to i32
  %8057 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.13 = getelementptr i8, i8* %b, i64 37
  %8058 = load i8, i8* %scevgep34.23.13, align 1
  %call28.23.13 = call zeroext i8 @mult(i8 zeroext %8057, i8 zeroext %8058)
  %conv29.23.13 = zext i8 %call28.23.13 to i32
  %xor.23.13 = xor i32 %conv23.23.13, %conv29.23.13
  %scevgep35.23.13 = getelementptr i8, i8* %a, i64 37
  %8059 = load i8, i8* %scevgep35.23.13, align 1
  %8060 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.13 = call zeroext i8 @mult(i8 zeroext %8059, i8 zeroext %8060)
  %conv35.23.13 = zext i8 %call34.23.13 to i32
  %xor36.23.13 = xor i32 %xor.23.13, %conv35.23.13
  %conv37.23.13 = trunc i32 %xor36.23.13 to i8
  store i8 %conv37.23.13, i8* %scevgep41.23.12, align 1
  %scevgep28.23.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8054, i64 0, i64 0, i64 1
  %8061 = bitcast i8* %scevgep28.23.13 to [61 x [61 x i8]]*
  %scevgep41.23.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8055, i64 0, i64 1, i64 0
  %8062 = bitcast i8* %scevgep41.23.13 to [61 x [61 x i8]]*
  %call16.23.14 = call zeroext i8 (...) @rand()
  store i8 %call16.23.14, i8* %scevgep28.23.13, align 1
  %8063 = load i8, i8* %scevgep28.23.13, align 1
  %conv23.23.14 = zext i8 %8063 to i32
  %8064 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.14 = getelementptr i8, i8* %b, i64 38
  %8065 = load i8, i8* %scevgep34.23.14, align 1
  %call28.23.14 = call zeroext i8 @mult(i8 zeroext %8064, i8 zeroext %8065)
  %conv29.23.14 = zext i8 %call28.23.14 to i32
  %xor.23.14 = xor i32 %conv23.23.14, %conv29.23.14
  %scevgep35.23.14 = getelementptr i8, i8* %a, i64 38
  %8066 = load i8, i8* %scevgep35.23.14, align 1
  %8067 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.14 = call zeroext i8 @mult(i8 zeroext %8066, i8 zeroext %8067)
  %conv35.23.14 = zext i8 %call34.23.14 to i32
  %xor36.23.14 = xor i32 %xor.23.14, %conv35.23.14
  %conv37.23.14 = trunc i32 %xor36.23.14 to i8
  store i8 %conv37.23.14, i8* %scevgep41.23.13, align 1
  %scevgep28.23.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8061, i64 0, i64 0, i64 1
  %8068 = bitcast i8* %scevgep28.23.14 to [61 x [61 x i8]]*
  %scevgep41.23.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8062, i64 0, i64 1, i64 0
  %8069 = bitcast i8* %scevgep41.23.14 to [61 x [61 x i8]]*
  %call16.23.15 = call zeroext i8 (...) @rand()
  store i8 %call16.23.15, i8* %scevgep28.23.14, align 1
  %8070 = load i8, i8* %scevgep28.23.14, align 1
  %conv23.23.15 = zext i8 %8070 to i32
  %8071 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.15 = getelementptr i8, i8* %b, i64 39
  %8072 = load i8, i8* %scevgep34.23.15, align 1
  %call28.23.15 = call zeroext i8 @mult(i8 zeroext %8071, i8 zeroext %8072)
  %conv29.23.15 = zext i8 %call28.23.15 to i32
  %xor.23.15 = xor i32 %conv23.23.15, %conv29.23.15
  %scevgep35.23.15 = getelementptr i8, i8* %a, i64 39
  %8073 = load i8, i8* %scevgep35.23.15, align 1
  %8074 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.15 = call zeroext i8 @mult(i8 zeroext %8073, i8 zeroext %8074)
  %conv35.23.15 = zext i8 %call34.23.15 to i32
  %xor36.23.15 = xor i32 %xor.23.15, %conv35.23.15
  %conv37.23.15 = trunc i32 %xor36.23.15 to i8
  store i8 %conv37.23.15, i8* %scevgep41.23.14, align 1
  %scevgep28.23.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8068, i64 0, i64 0, i64 1
  %8075 = bitcast i8* %scevgep28.23.15 to [61 x [61 x i8]]*
  %scevgep41.23.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8069, i64 0, i64 1, i64 0
  %8076 = bitcast i8* %scevgep41.23.15 to [61 x [61 x i8]]*
  %call16.23.16 = call zeroext i8 (...) @rand()
  store i8 %call16.23.16, i8* %scevgep28.23.15, align 1
  %8077 = load i8, i8* %scevgep28.23.15, align 1
  %conv23.23.16 = zext i8 %8077 to i32
  %8078 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.16 = getelementptr i8, i8* %b, i64 40
  %8079 = load i8, i8* %scevgep34.23.16, align 1
  %call28.23.16 = call zeroext i8 @mult(i8 zeroext %8078, i8 zeroext %8079)
  %conv29.23.16 = zext i8 %call28.23.16 to i32
  %xor.23.16 = xor i32 %conv23.23.16, %conv29.23.16
  %scevgep35.23.16 = getelementptr i8, i8* %a, i64 40
  %8080 = load i8, i8* %scevgep35.23.16, align 1
  %8081 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.16 = call zeroext i8 @mult(i8 zeroext %8080, i8 zeroext %8081)
  %conv35.23.16 = zext i8 %call34.23.16 to i32
  %xor36.23.16 = xor i32 %xor.23.16, %conv35.23.16
  %conv37.23.16 = trunc i32 %xor36.23.16 to i8
  store i8 %conv37.23.16, i8* %scevgep41.23.15, align 1
  %scevgep28.23.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8075, i64 0, i64 0, i64 1
  %8082 = bitcast i8* %scevgep28.23.16 to [61 x [61 x i8]]*
  %scevgep41.23.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8076, i64 0, i64 1, i64 0
  %8083 = bitcast i8* %scevgep41.23.16 to [61 x [61 x i8]]*
  %call16.23.17 = call zeroext i8 (...) @rand()
  store i8 %call16.23.17, i8* %scevgep28.23.16, align 1
  %8084 = load i8, i8* %scevgep28.23.16, align 1
  %conv23.23.17 = zext i8 %8084 to i32
  %8085 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.17 = getelementptr i8, i8* %b, i64 41
  %8086 = load i8, i8* %scevgep34.23.17, align 1
  %call28.23.17 = call zeroext i8 @mult(i8 zeroext %8085, i8 zeroext %8086)
  %conv29.23.17 = zext i8 %call28.23.17 to i32
  %xor.23.17 = xor i32 %conv23.23.17, %conv29.23.17
  %scevgep35.23.17 = getelementptr i8, i8* %a, i64 41
  %8087 = load i8, i8* %scevgep35.23.17, align 1
  %8088 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.17 = call zeroext i8 @mult(i8 zeroext %8087, i8 zeroext %8088)
  %conv35.23.17 = zext i8 %call34.23.17 to i32
  %xor36.23.17 = xor i32 %xor.23.17, %conv35.23.17
  %conv37.23.17 = trunc i32 %xor36.23.17 to i8
  store i8 %conv37.23.17, i8* %scevgep41.23.16, align 1
  %scevgep28.23.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8082, i64 0, i64 0, i64 1
  %8089 = bitcast i8* %scevgep28.23.17 to [61 x [61 x i8]]*
  %scevgep41.23.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8083, i64 0, i64 1, i64 0
  %8090 = bitcast i8* %scevgep41.23.17 to [61 x [61 x i8]]*
  %call16.23.18 = call zeroext i8 (...) @rand()
  store i8 %call16.23.18, i8* %scevgep28.23.17, align 1
  %8091 = load i8, i8* %scevgep28.23.17, align 1
  %conv23.23.18 = zext i8 %8091 to i32
  %8092 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.18 = getelementptr i8, i8* %b, i64 42
  %8093 = load i8, i8* %scevgep34.23.18, align 1
  %call28.23.18 = call zeroext i8 @mult(i8 zeroext %8092, i8 zeroext %8093)
  %conv29.23.18 = zext i8 %call28.23.18 to i32
  %xor.23.18 = xor i32 %conv23.23.18, %conv29.23.18
  %scevgep35.23.18 = getelementptr i8, i8* %a, i64 42
  %8094 = load i8, i8* %scevgep35.23.18, align 1
  %8095 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.18 = call zeroext i8 @mult(i8 zeroext %8094, i8 zeroext %8095)
  %conv35.23.18 = zext i8 %call34.23.18 to i32
  %xor36.23.18 = xor i32 %xor.23.18, %conv35.23.18
  %conv37.23.18 = trunc i32 %xor36.23.18 to i8
  store i8 %conv37.23.18, i8* %scevgep41.23.17, align 1
  %scevgep28.23.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8089, i64 0, i64 0, i64 1
  %8096 = bitcast i8* %scevgep28.23.18 to [61 x [61 x i8]]*
  %scevgep41.23.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8090, i64 0, i64 1, i64 0
  %8097 = bitcast i8* %scevgep41.23.18 to [61 x [61 x i8]]*
  %call16.23.19 = call zeroext i8 (...) @rand()
  store i8 %call16.23.19, i8* %scevgep28.23.18, align 1
  %8098 = load i8, i8* %scevgep28.23.18, align 1
  %conv23.23.19 = zext i8 %8098 to i32
  %8099 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.19 = getelementptr i8, i8* %b, i64 43
  %8100 = load i8, i8* %scevgep34.23.19, align 1
  %call28.23.19 = call zeroext i8 @mult(i8 zeroext %8099, i8 zeroext %8100)
  %conv29.23.19 = zext i8 %call28.23.19 to i32
  %xor.23.19 = xor i32 %conv23.23.19, %conv29.23.19
  %scevgep35.23.19 = getelementptr i8, i8* %a, i64 43
  %8101 = load i8, i8* %scevgep35.23.19, align 1
  %8102 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.19 = call zeroext i8 @mult(i8 zeroext %8101, i8 zeroext %8102)
  %conv35.23.19 = zext i8 %call34.23.19 to i32
  %xor36.23.19 = xor i32 %xor.23.19, %conv35.23.19
  %conv37.23.19 = trunc i32 %xor36.23.19 to i8
  store i8 %conv37.23.19, i8* %scevgep41.23.18, align 1
  %scevgep28.23.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8096, i64 0, i64 0, i64 1
  %8103 = bitcast i8* %scevgep28.23.19 to [61 x [61 x i8]]*
  %scevgep41.23.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8097, i64 0, i64 1, i64 0
  %8104 = bitcast i8* %scevgep41.23.19 to [61 x [61 x i8]]*
  %call16.23.20 = call zeroext i8 (...) @rand()
  store i8 %call16.23.20, i8* %scevgep28.23.19, align 1
  %8105 = load i8, i8* %scevgep28.23.19, align 1
  %conv23.23.20 = zext i8 %8105 to i32
  %8106 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.20 = getelementptr i8, i8* %b, i64 44
  %8107 = load i8, i8* %scevgep34.23.20, align 1
  %call28.23.20 = call zeroext i8 @mult(i8 zeroext %8106, i8 zeroext %8107)
  %conv29.23.20 = zext i8 %call28.23.20 to i32
  %xor.23.20 = xor i32 %conv23.23.20, %conv29.23.20
  %scevgep35.23.20 = getelementptr i8, i8* %a, i64 44
  %8108 = load i8, i8* %scevgep35.23.20, align 1
  %8109 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.20 = call zeroext i8 @mult(i8 zeroext %8108, i8 zeroext %8109)
  %conv35.23.20 = zext i8 %call34.23.20 to i32
  %xor36.23.20 = xor i32 %xor.23.20, %conv35.23.20
  %conv37.23.20 = trunc i32 %xor36.23.20 to i8
  store i8 %conv37.23.20, i8* %scevgep41.23.19, align 1
  %scevgep28.23.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8103, i64 0, i64 0, i64 1
  %8110 = bitcast i8* %scevgep28.23.20 to [61 x [61 x i8]]*
  %scevgep41.23.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8104, i64 0, i64 1, i64 0
  %8111 = bitcast i8* %scevgep41.23.20 to [61 x [61 x i8]]*
  %call16.23.21 = call zeroext i8 (...) @rand()
  store i8 %call16.23.21, i8* %scevgep28.23.20, align 1
  %8112 = load i8, i8* %scevgep28.23.20, align 1
  %conv23.23.21 = zext i8 %8112 to i32
  %8113 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.21 = getelementptr i8, i8* %b, i64 45
  %8114 = load i8, i8* %scevgep34.23.21, align 1
  %call28.23.21 = call zeroext i8 @mult(i8 zeroext %8113, i8 zeroext %8114)
  %conv29.23.21 = zext i8 %call28.23.21 to i32
  %xor.23.21 = xor i32 %conv23.23.21, %conv29.23.21
  %scevgep35.23.21 = getelementptr i8, i8* %a, i64 45
  %8115 = load i8, i8* %scevgep35.23.21, align 1
  %8116 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.21 = call zeroext i8 @mult(i8 zeroext %8115, i8 zeroext %8116)
  %conv35.23.21 = zext i8 %call34.23.21 to i32
  %xor36.23.21 = xor i32 %xor.23.21, %conv35.23.21
  %conv37.23.21 = trunc i32 %xor36.23.21 to i8
  store i8 %conv37.23.21, i8* %scevgep41.23.20, align 1
  %scevgep28.23.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8110, i64 0, i64 0, i64 1
  %8117 = bitcast i8* %scevgep28.23.21 to [61 x [61 x i8]]*
  %scevgep41.23.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8111, i64 0, i64 1, i64 0
  %8118 = bitcast i8* %scevgep41.23.21 to [61 x [61 x i8]]*
  %call16.23.22 = call zeroext i8 (...) @rand()
  store i8 %call16.23.22, i8* %scevgep28.23.21, align 1
  %8119 = load i8, i8* %scevgep28.23.21, align 1
  %conv23.23.22 = zext i8 %8119 to i32
  %8120 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.22 = getelementptr i8, i8* %b, i64 46
  %8121 = load i8, i8* %scevgep34.23.22, align 1
  %call28.23.22 = call zeroext i8 @mult(i8 zeroext %8120, i8 zeroext %8121)
  %conv29.23.22 = zext i8 %call28.23.22 to i32
  %xor.23.22 = xor i32 %conv23.23.22, %conv29.23.22
  %scevgep35.23.22 = getelementptr i8, i8* %a, i64 46
  %8122 = load i8, i8* %scevgep35.23.22, align 1
  %8123 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.22 = call zeroext i8 @mult(i8 zeroext %8122, i8 zeroext %8123)
  %conv35.23.22 = zext i8 %call34.23.22 to i32
  %xor36.23.22 = xor i32 %xor.23.22, %conv35.23.22
  %conv37.23.22 = trunc i32 %xor36.23.22 to i8
  store i8 %conv37.23.22, i8* %scevgep41.23.21, align 1
  %scevgep28.23.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8117, i64 0, i64 0, i64 1
  %8124 = bitcast i8* %scevgep28.23.22 to [61 x [61 x i8]]*
  %scevgep41.23.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8118, i64 0, i64 1, i64 0
  %8125 = bitcast i8* %scevgep41.23.22 to [61 x [61 x i8]]*
  %call16.23.23 = call zeroext i8 (...) @rand()
  store i8 %call16.23.23, i8* %scevgep28.23.22, align 1
  %8126 = load i8, i8* %scevgep28.23.22, align 1
  %conv23.23.23 = zext i8 %8126 to i32
  %8127 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.23 = getelementptr i8, i8* %b, i64 47
  %8128 = load i8, i8* %scevgep34.23.23, align 1
  %call28.23.23 = call zeroext i8 @mult(i8 zeroext %8127, i8 zeroext %8128)
  %conv29.23.23 = zext i8 %call28.23.23 to i32
  %xor.23.23 = xor i32 %conv23.23.23, %conv29.23.23
  %scevgep35.23.23 = getelementptr i8, i8* %a, i64 47
  %8129 = load i8, i8* %scevgep35.23.23, align 1
  %8130 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.23 = call zeroext i8 @mult(i8 zeroext %8129, i8 zeroext %8130)
  %conv35.23.23 = zext i8 %call34.23.23 to i32
  %xor36.23.23 = xor i32 %xor.23.23, %conv35.23.23
  %conv37.23.23 = trunc i32 %xor36.23.23 to i8
  store i8 %conv37.23.23, i8* %scevgep41.23.22, align 1
  %scevgep28.23.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8124, i64 0, i64 0, i64 1
  %8131 = bitcast i8* %scevgep28.23.23 to [61 x [61 x i8]]*
  %scevgep41.23.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8125, i64 0, i64 1, i64 0
  %8132 = bitcast i8* %scevgep41.23.23 to [61 x [61 x i8]]*
  %call16.23.24 = call zeroext i8 (...) @rand()
  store i8 %call16.23.24, i8* %scevgep28.23.23, align 1
  %8133 = load i8, i8* %scevgep28.23.23, align 1
  %conv23.23.24 = zext i8 %8133 to i32
  %8134 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.24 = getelementptr i8, i8* %b, i64 48
  %8135 = load i8, i8* %scevgep34.23.24, align 1
  %call28.23.24 = call zeroext i8 @mult(i8 zeroext %8134, i8 zeroext %8135)
  %conv29.23.24 = zext i8 %call28.23.24 to i32
  %xor.23.24 = xor i32 %conv23.23.24, %conv29.23.24
  %scevgep35.23.24 = getelementptr i8, i8* %a, i64 48
  %8136 = load i8, i8* %scevgep35.23.24, align 1
  %8137 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.24 = call zeroext i8 @mult(i8 zeroext %8136, i8 zeroext %8137)
  %conv35.23.24 = zext i8 %call34.23.24 to i32
  %xor36.23.24 = xor i32 %xor.23.24, %conv35.23.24
  %conv37.23.24 = trunc i32 %xor36.23.24 to i8
  store i8 %conv37.23.24, i8* %scevgep41.23.23, align 1
  %scevgep28.23.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8131, i64 0, i64 0, i64 1
  %8138 = bitcast i8* %scevgep28.23.24 to [61 x [61 x i8]]*
  %scevgep41.23.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8132, i64 0, i64 1, i64 0
  %8139 = bitcast i8* %scevgep41.23.24 to [61 x [61 x i8]]*
  %call16.23.25 = call zeroext i8 (...) @rand()
  store i8 %call16.23.25, i8* %scevgep28.23.24, align 1
  %8140 = load i8, i8* %scevgep28.23.24, align 1
  %conv23.23.25 = zext i8 %8140 to i32
  %8141 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.25 = getelementptr i8, i8* %b, i64 49
  %8142 = load i8, i8* %scevgep34.23.25, align 1
  %call28.23.25 = call zeroext i8 @mult(i8 zeroext %8141, i8 zeroext %8142)
  %conv29.23.25 = zext i8 %call28.23.25 to i32
  %xor.23.25 = xor i32 %conv23.23.25, %conv29.23.25
  %scevgep35.23.25 = getelementptr i8, i8* %a, i64 49
  %8143 = load i8, i8* %scevgep35.23.25, align 1
  %8144 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.25 = call zeroext i8 @mult(i8 zeroext %8143, i8 zeroext %8144)
  %conv35.23.25 = zext i8 %call34.23.25 to i32
  %xor36.23.25 = xor i32 %xor.23.25, %conv35.23.25
  %conv37.23.25 = trunc i32 %xor36.23.25 to i8
  store i8 %conv37.23.25, i8* %scevgep41.23.24, align 1
  %scevgep28.23.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8138, i64 0, i64 0, i64 1
  %8145 = bitcast i8* %scevgep28.23.25 to [61 x [61 x i8]]*
  %scevgep41.23.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8139, i64 0, i64 1, i64 0
  %8146 = bitcast i8* %scevgep41.23.25 to [61 x [61 x i8]]*
  %call16.23.26 = call zeroext i8 (...) @rand()
  store i8 %call16.23.26, i8* %scevgep28.23.25, align 1
  %8147 = load i8, i8* %scevgep28.23.25, align 1
  %conv23.23.26 = zext i8 %8147 to i32
  %8148 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.26 = getelementptr i8, i8* %b, i64 50
  %8149 = load i8, i8* %scevgep34.23.26, align 1
  %call28.23.26 = call zeroext i8 @mult(i8 zeroext %8148, i8 zeroext %8149)
  %conv29.23.26 = zext i8 %call28.23.26 to i32
  %xor.23.26 = xor i32 %conv23.23.26, %conv29.23.26
  %scevgep35.23.26 = getelementptr i8, i8* %a, i64 50
  %8150 = load i8, i8* %scevgep35.23.26, align 1
  %8151 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.26 = call zeroext i8 @mult(i8 zeroext %8150, i8 zeroext %8151)
  %conv35.23.26 = zext i8 %call34.23.26 to i32
  %xor36.23.26 = xor i32 %xor.23.26, %conv35.23.26
  %conv37.23.26 = trunc i32 %xor36.23.26 to i8
  store i8 %conv37.23.26, i8* %scevgep41.23.25, align 1
  %scevgep28.23.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8145, i64 0, i64 0, i64 1
  %8152 = bitcast i8* %scevgep28.23.26 to [61 x [61 x i8]]*
  %scevgep41.23.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8146, i64 0, i64 1, i64 0
  %8153 = bitcast i8* %scevgep41.23.26 to [61 x [61 x i8]]*
  %call16.23.27 = call zeroext i8 (...) @rand()
  store i8 %call16.23.27, i8* %scevgep28.23.26, align 1
  %8154 = load i8, i8* %scevgep28.23.26, align 1
  %conv23.23.27 = zext i8 %8154 to i32
  %8155 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.27 = getelementptr i8, i8* %b, i64 51
  %8156 = load i8, i8* %scevgep34.23.27, align 1
  %call28.23.27 = call zeroext i8 @mult(i8 zeroext %8155, i8 zeroext %8156)
  %conv29.23.27 = zext i8 %call28.23.27 to i32
  %xor.23.27 = xor i32 %conv23.23.27, %conv29.23.27
  %scevgep35.23.27 = getelementptr i8, i8* %a, i64 51
  %8157 = load i8, i8* %scevgep35.23.27, align 1
  %8158 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.27 = call zeroext i8 @mult(i8 zeroext %8157, i8 zeroext %8158)
  %conv35.23.27 = zext i8 %call34.23.27 to i32
  %xor36.23.27 = xor i32 %xor.23.27, %conv35.23.27
  %conv37.23.27 = trunc i32 %xor36.23.27 to i8
  store i8 %conv37.23.27, i8* %scevgep41.23.26, align 1
  %scevgep28.23.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8152, i64 0, i64 0, i64 1
  %8159 = bitcast i8* %scevgep28.23.27 to [61 x [61 x i8]]*
  %scevgep41.23.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8153, i64 0, i64 1, i64 0
  %8160 = bitcast i8* %scevgep41.23.27 to [61 x [61 x i8]]*
  %call16.23.28 = call zeroext i8 (...) @rand()
  store i8 %call16.23.28, i8* %scevgep28.23.27, align 1
  %8161 = load i8, i8* %scevgep28.23.27, align 1
  %conv23.23.28 = zext i8 %8161 to i32
  %8162 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.28 = getelementptr i8, i8* %b, i64 52
  %8163 = load i8, i8* %scevgep34.23.28, align 1
  %call28.23.28 = call zeroext i8 @mult(i8 zeroext %8162, i8 zeroext %8163)
  %conv29.23.28 = zext i8 %call28.23.28 to i32
  %xor.23.28 = xor i32 %conv23.23.28, %conv29.23.28
  %scevgep35.23.28 = getelementptr i8, i8* %a, i64 52
  %8164 = load i8, i8* %scevgep35.23.28, align 1
  %8165 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.28 = call zeroext i8 @mult(i8 zeroext %8164, i8 zeroext %8165)
  %conv35.23.28 = zext i8 %call34.23.28 to i32
  %xor36.23.28 = xor i32 %xor.23.28, %conv35.23.28
  %conv37.23.28 = trunc i32 %xor36.23.28 to i8
  store i8 %conv37.23.28, i8* %scevgep41.23.27, align 1
  %scevgep28.23.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8159, i64 0, i64 0, i64 1
  %8166 = bitcast i8* %scevgep28.23.28 to [61 x [61 x i8]]*
  %scevgep41.23.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8160, i64 0, i64 1, i64 0
  %8167 = bitcast i8* %scevgep41.23.28 to [61 x [61 x i8]]*
  %call16.23.29 = call zeroext i8 (...) @rand()
  store i8 %call16.23.29, i8* %scevgep28.23.28, align 1
  %8168 = load i8, i8* %scevgep28.23.28, align 1
  %conv23.23.29 = zext i8 %8168 to i32
  %8169 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.29 = getelementptr i8, i8* %b, i64 53
  %8170 = load i8, i8* %scevgep34.23.29, align 1
  %call28.23.29 = call zeroext i8 @mult(i8 zeroext %8169, i8 zeroext %8170)
  %conv29.23.29 = zext i8 %call28.23.29 to i32
  %xor.23.29 = xor i32 %conv23.23.29, %conv29.23.29
  %scevgep35.23.29 = getelementptr i8, i8* %a, i64 53
  %8171 = load i8, i8* %scevgep35.23.29, align 1
  %8172 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.29 = call zeroext i8 @mult(i8 zeroext %8171, i8 zeroext %8172)
  %conv35.23.29 = zext i8 %call34.23.29 to i32
  %xor36.23.29 = xor i32 %xor.23.29, %conv35.23.29
  %conv37.23.29 = trunc i32 %xor36.23.29 to i8
  store i8 %conv37.23.29, i8* %scevgep41.23.28, align 1
  %scevgep28.23.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8166, i64 0, i64 0, i64 1
  %8173 = bitcast i8* %scevgep28.23.29 to [61 x [61 x i8]]*
  %scevgep41.23.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8167, i64 0, i64 1, i64 0
  %8174 = bitcast i8* %scevgep41.23.29 to [61 x [61 x i8]]*
  %call16.23.30 = call zeroext i8 (...) @rand()
  store i8 %call16.23.30, i8* %scevgep28.23.29, align 1
  %8175 = load i8, i8* %scevgep28.23.29, align 1
  %conv23.23.30 = zext i8 %8175 to i32
  %8176 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.30 = getelementptr i8, i8* %b, i64 54
  %8177 = load i8, i8* %scevgep34.23.30, align 1
  %call28.23.30 = call zeroext i8 @mult(i8 zeroext %8176, i8 zeroext %8177)
  %conv29.23.30 = zext i8 %call28.23.30 to i32
  %xor.23.30 = xor i32 %conv23.23.30, %conv29.23.30
  %scevgep35.23.30 = getelementptr i8, i8* %a, i64 54
  %8178 = load i8, i8* %scevgep35.23.30, align 1
  %8179 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.30 = call zeroext i8 @mult(i8 zeroext %8178, i8 zeroext %8179)
  %conv35.23.30 = zext i8 %call34.23.30 to i32
  %xor36.23.30 = xor i32 %xor.23.30, %conv35.23.30
  %conv37.23.30 = trunc i32 %xor36.23.30 to i8
  store i8 %conv37.23.30, i8* %scevgep41.23.29, align 1
  %scevgep28.23.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8173, i64 0, i64 0, i64 1
  %8180 = bitcast i8* %scevgep28.23.30 to [61 x [61 x i8]]*
  %scevgep41.23.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8174, i64 0, i64 1, i64 0
  %8181 = bitcast i8* %scevgep41.23.30 to [61 x [61 x i8]]*
  %call16.23.31 = call zeroext i8 (...) @rand()
  store i8 %call16.23.31, i8* %scevgep28.23.30, align 1
  %8182 = load i8, i8* %scevgep28.23.30, align 1
  %conv23.23.31 = zext i8 %8182 to i32
  %8183 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.31 = getelementptr i8, i8* %b, i64 55
  %8184 = load i8, i8* %scevgep34.23.31, align 1
  %call28.23.31 = call zeroext i8 @mult(i8 zeroext %8183, i8 zeroext %8184)
  %conv29.23.31 = zext i8 %call28.23.31 to i32
  %xor.23.31 = xor i32 %conv23.23.31, %conv29.23.31
  %scevgep35.23.31 = getelementptr i8, i8* %a, i64 55
  %8185 = load i8, i8* %scevgep35.23.31, align 1
  %8186 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.31 = call zeroext i8 @mult(i8 zeroext %8185, i8 zeroext %8186)
  %conv35.23.31 = zext i8 %call34.23.31 to i32
  %xor36.23.31 = xor i32 %xor.23.31, %conv35.23.31
  %conv37.23.31 = trunc i32 %xor36.23.31 to i8
  store i8 %conv37.23.31, i8* %scevgep41.23.30, align 1
  %scevgep28.23.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8180, i64 0, i64 0, i64 1
  %8187 = bitcast i8* %scevgep28.23.31 to [61 x [61 x i8]]*
  %scevgep41.23.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8181, i64 0, i64 1, i64 0
  %8188 = bitcast i8* %scevgep41.23.31 to [61 x [61 x i8]]*
  %call16.23.32 = call zeroext i8 (...) @rand()
  store i8 %call16.23.32, i8* %scevgep28.23.31, align 1
  %8189 = load i8, i8* %scevgep28.23.31, align 1
  %conv23.23.32 = zext i8 %8189 to i32
  %8190 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.32 = getelementptr i8, i8* %b, i64 56
  %8191 = load i8, i8* %scevgep34.23.32, align 1
  %call28.23.32 = call zeroext i8 @mult(i8 zeroext %8190, i8 zeroext %8191)
  %conv29.23.32 = zext i8 %call28.23.32 to i32
  %xor.23.32 = xor i32 %conv23.23.32, %conv29.23.32
  %scevgep35.23.32 = getelementptr i8, i8* %a, i64 56
  %8192 = load i8, i8* %scevgep35.23.32, align 1
  %8193 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.32 = call zeroext i8 @mult(i8 zeroext %8192, i8 zeroext %8193)
  %conv35.23.32 = zext i8 %call34.23.32 to i32
  %xor36.23.32 = xor i32 %xor.23.32, %conv35.23.32
  %conv37.23.32 = trunc i32 %xor36.23.32 to i8
  store i8 %conv37.23.32, i8* %scevgep41.23.31, align 1
  %scevgep28.23.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8187, i64 0, i64 0, i64 1
  %8194 = bitcast i8* %scevgep28.23.32 to [61 x [61 x i8]]*
  %scevgep41.23.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8188, i64 0, i64 1, i64 0
  %8195 = bitcast i8* %scevgep41.23.32 to [61 x [61 x i8]]*
  %call16.23.33 = call zeroext i8 (...) @rand()
  store i8 %call16.23.33, i8* %scevgep28.23.32, align 1
  %8196 = load i8, i8* %scevgep28.23.32, align 1
  %conv23.23.33 = zext i8 %8196 to i32
  %8197 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.33 = getelementptr i8, i8* %b, i64 57
  %8198 = load i8, i8* %scevgep34.23.33, align 1
  %call28.23.33 = call zeroext i8 @mult(i8 zeroext %8197, i8 zeroext %8198)
  %conv29.23.33 = zext i8 %call28.23.33 to i32
  %xor.23.33 = xor i32 %conv23.23.33, %conv29.23.33
  %scevgep35.23.33 = getelementptr i8, i8* %a, i64 57
  %8199 = load i8, i8* %scevgep35.23.33, align 1
  %8200 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.33 = call zeroext i8 @mult(i8 zeroext %8199, i8 zeroext %8200)
  %conv35.23.33 = zext i8 %call34.23.33 to i32
  %xor36.23.33 = xor i32 %xor.23.33, %conv35.23.33
  %conv37.23.33 = trunc i32 %xor36.23.33 to i8
  store i8 %conv37.23.33, i8* %scevgep41.23.32, align 1
  %scevgep28.23.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8194, i64 0, i64 0, i64 1
  %8201 = bitcast i8* %scevgep28.23.33 to [61 x [61 x i8]]*
  %scevgep41.23.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8195, i64 0, i64 1, i64 0
  %8202 = bitcast i8* %scevgep41.23.33 to [61 x [61 x i8]]*
  %call16.23.34 = call zeroext i8 (...) @rand()
  store i8 %call16.23.34, i8* %scevgep28.23.33, align 1
  %8203 = load i8, i8* %scevgep28.23.33, align 1
  %conv23.23.34 = zext i8 %8203 to i32
  %8204 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.34 = getelementptr i8, i8* %b, i64 58
  %8205 = load i8, i8* %scevgep34.23.34, align 1
  %call28.23.34 = call zeroext i8 @mult(i8 zeroext %8204, i8 zeroext %8205)
  %conv29.23.34 = zext i8 %call28.23.34 to i32
  %xor.23.34 = xor i32 %conv23.23.34, %conv29.23.34
  %scevgep35.23.34 = getelementptr i8, i8* %a, i64 58
  %8206 = load i8, i8* %scevgep35.23.34, align 1
  %8207 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.34 = call zeroext i8 @mult(i8 zeroext %8206, i8 zeroext %8207)
  %conv35.23.34 = zext i8 %call34.23.34 to i32
  %xor36.23.34 = xor i32 %xor.23.34, %conv35.23.34
  %conv37.23.34 = trunc i32 %xor36.23.34 to i8
  store i8 %conv37.23.34, i8* %scevgep41.23.33, align 1
  %scevgep28.23.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8201, i64 0, i64 0, i64 1
  %8208 = bitcast i8* %scevgep28.23.34 to [61 x [61 x i8]]*
  %scevgep41.23.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8202, i64 0, i64 1, i64 0
  %8209 = bitcast i8* %scevgep41.23.34 to [61 x [61 x i8]]*
  %call16.23.35 = call zeroext i8 (...) @rand()
  store i8 %call16.23.35, i8* %scevgep28.23.34, align 1
  %8210 = load i8, i8* %scevgep28.23.34, align 1
  %conv23.23.35 = zext i8 %8210 to i32
  %8211 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.35 = getelementptr i8, i8* %b, i64 59
  %8212 = load i8, i8* %scevgep34.23.35, align 1
  %call28.23.35 = call zeroext i8 @mult(i8 zeroext %8211, i8 zeroext %8212)
  %conv29.23.35 = zext i8 %call28.23.35 to i32
  %xor.23.35 = xor i32 %conv23.23.35, %conv29.23.35
  %scevgep35.23.35 = getelementptr i8, i8* %a, i64 59
  %8213 = load i8, i8* %scevgep35.23.35, align 1
  %8214 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.35 = call zeroext i8 @mult(i8 zeroext %8213, i8 zeroext %8214)
  %conv35.23.35 = zext i8 %call34.23.35 to i32
  %xor36.23.35 = xor i32 %xor.23.35, %conv35.23.35
  %conv37.23.35 = trunc i32 %xor36.23.35 to i8
  store i8 %conv37.23.35, i8* %scevgep41.23.34, align 1
  %scevgep28.23.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8208, i64 0, i64 0, i64 1
  %scevgep41.23.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8209, i64 0, i64 1, i64 0
  %call16.23.36 = call zeroext i8 (...) @rand()
  store i8 %call16.23.36, i8* %scevgep28.23.35, align 1
  %8215 = load i8, i8* %scevgep28.23.35, align 1
  %conv23.23.36 = zext i8 %8215 to i32
  %8216 = load i8, i8* %arrayidx25.23, align 1
  %scevgep34.23.36 = getelementptr i8, i8* %b, i64 60
  %8217 = load i8, i8* %scevgep34.23.36, align 1
  %call28.23.36 = call zeroext i8 @mult(i8 zeroext %8216, i8 zeroext %8217)
  %conv29.23.36 = zext i8 %call28.23.36 to i32
  %xor.23.36 = xor i32 %conv23.23.36, %conv29.23.36
  %scevgep35.23.36 = getelementptr i8, i8* %a, i64 60
  %8218 = load i8, i8* %scevgep35.23.36, align 1
  %8219 = load i8, i8* %arrayidx33.23, align 1
  %call34.23.36 = call zeroext i8 @mult(i8 zeroext %8218, i8 zeroext %8219)
  %conv35.23.36 = zext i8 %call34.23.36 to i32
  %xor36.23.36 = xor i32 %xor.23.36, %conv35.23.36
  %conv37.23.36 = trunc i32 %xor36.23.36 to i8
  store i8 %conv37.23.36, i8* %scevgep41.23.35, align 1
  %scevgep26.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7963, i64 0, i64 1, i64 1
  %8220 = bitcast i8* %scevgep26.23 to [61 x [61 x i8]]*
  %scevgep39.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %7964, i64 0, i64 1, i64 1
  %8221 = bitcast i8* %scevgep39.23 to [61 x [61 x i8]]*
  %arrayidx25.24 = getelementptr inbounds i8, i8* %a, i64 24
  %arrayidx33.24 = getelementptr inbounds i8, i8* %b, i64 24
  %call16.24 = call zeroext i8 (...) @rand()
  store i8 %call16.24, i8* %scevgep26.23, align 1
  %8222 = load i8, i8* %scevgep26.23, align 1
  %conv23.24 = zext i8 %8222 to i32
  %8223 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24 = getelementptr i8, i8* %b, i64 25
  %8224 = load i8, i8* %scevgep34.24, align 1
  %call28.24 = call zeroext i8 @mult(i8 zeroext %8223, i8 zeroext %8224)
  %conv29.24 = zext i8 %call28.24 to i32
  %xor.24 = xor i32 %conv23.24, %conv29.24
  %scevgep35.24 = getelementptr i8, i8* %a, i64 25
  %8225 = load i8, i8* %scevgep35.24, align 1
  %8226 = load i8, i8* %arrayidx33.24, align 1
  %call34.24 = call zeroext i8 @mult(i8 zeroext %8225, i8 zeroext %8226)
  %conv35.24 = zext i8 %call34.24 to i32
  %xor36.24 = xor i32 %xor.24, %conv35.24
  %conv37.24 = trunc i32 %xor36.24 to i8
  store i8 %conv37.24, i8* %scevgep39.23, align 1
  %scevgep28.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8220, i64 0, i64 0, i64 1
  %8227 = bitcast i8* %scevgep28.24 to [61 x [61 x i8]]*
  %scevgep41.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8221, i64 0, i64 1, i64 0
  %8228 = bitcast i8* %scevgep41.24 to [61 x [61 x i8]]*
  %call16.24.1 = call zeroext i8 (...) @rand()
  store i8 %call16.24.1, i8* %scevgep28.24, align 1
  %8229 = load i8, i8* %scevgep28.24, align 1
  %conv23.24.1 = zext i8 %8229 to i32
  %8230 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.1 = getelementptr i8, i8* %b, i64 26
  %8231 = load i8, i8* %scevgep34.24.1, align 1
  %call28.24.1 = call zeroext i8 @mult(i8 zeroext %8230, i8 zeroext %8231)
  %conv29.24.1 = zext i8 %call28.24.1 to i32
  %xor.24.1 = xor i32 %conv23.24.1, %conv29.24.1
  %scevgep35.24.1 = getelementptr i8, i8* %a, i64 26
  %8232 = load i8, i8* %scevgep35.24.1, align 1
  %8233 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.1 = call zeroext i8 @mult(i8 zeroext %8232, i8 zeroext %8233)
  %conv35.24.1 = zext i8 %call34.24.1 to i32
  %xor36.24.1 = xor i32 %xor.24.1, %conv35.24.1
  %conv37.24.1 = trunc i32 %xor36.24.1 to i8
  store i8 %conv37.24.1, i8* %scevgep41.24, align 1
  %scevgep28.24.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8227, i64 0, i64 0, i64 1
  %8234 = bitcast i8* %scevgep28.24.1 to [61 x [61 x i8]]*
  %scevgep41.24.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8228, i64 0, i64 1, i64 0
  %8235 = bitcast i8* %scevgep41.24.1 to [61 x [61 x i8]]*
  %call16.24.2 = call zeroext i8 (...) @rand()
  store i8 %call16.24.2, i8* %scevgep28.24.1, align 1
  %8236 = load i8, i8* %scevgep28.24.1, align 1
  %conv23.24.2 = zext i8 %8236 to i32
  %8237 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.2 = getelementptr i8, i8* %b, i64 27
  %8238 = load i8, i8* %scevgep34.24.2, align 1
  %call28.24.2 = call zeroext i8 @mult(i8 zeroext %8237, i8 zeroext %8238)
  %conv29.24.2 = zext i8 %call28.24.2 to i32
  %xor.24.2 = xor i32 %conv23.24.2, %conv29.24.2
  %scevgep35.24.2 = getelementptr i8, i8* %a, i64 27
  %8239 = load i8, i8* %scevgep35.24.2, align 1
  %8240 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.2 = call zeroext i8 @mult(i8 zeroext %8239, i8 zeroext %8240)
  %conv35.24.2 = zext i8 %call34.24.2 to i32
  %xor36.24.2 = xor i32 %xor.24.2, %conv35.24.2
  %conv37.24.2 = trunc i32 %xor36.24.2 to i8
  store i8 %conv37.24.2, i8* %scevgep41.24.1, align 1
  %scevgep28.24.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8234, i64 0, i64 0, i64 1
  %8241 = bitcast i8* %scevgep28.24.2 to [61 x [61 x i8]]*
  %scevgep41.24.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8235, i64 0, i64 1, i64 0
  %8242 = bitcast i8* %scevgep41.24.2 to [61 x [61 x i8]]*
  %call16.24.3 = call zeroext i8 (...) @rand()
  store i8 %call16.24.3, i8* %scevgep28.24.2, align 1
  %8243 = load i8, i8* %scevgep28.24.2, align 1
  %conv23.24.3 = zext i8 %8243 to i32
  %8244 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.3 = getelementptr i8, i8* %b, i64 28
  %8245 = load i8, i8* %scevgep34.24.3, align 1
  %call28.24.3 = call zeroext i8 @mult(i8 zeroext %8244, i8 zeroext %8245)
  %conv29.24.3 = zext i8 %call28.24.3 to i32
  %xor.24.3 = xor i32 %conv23.24.3, %conv29.24.3
  %scevgep35.24.3 = getelementptr i8, i8* %a, i64 28
  %8246 = load i8, i8* %scevgep35.24.3, align 1
  %8247 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.3 = call zeroext i8 @mult(i8 zeroext %8246, i8 zeroext %8247)
  %conv35.24.3 = zext i8 %call34.24.3 to i32
  %xor36.24.3 = xor i32 %xor.24.3, %conv35.24.3
  %conv37.24.3 = trunc i32 %xor36.24.3 to i8
  store i8 %conv37.24.3, i8* %scevgep41.24.2, align 1
  %scevgep28.24.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8241, i64 0, i64 0, i64 1
  %8248 = bitcast i8* %scevgep28.24.3 to [61 x [61 x i8]]*
  %scevgep41.24.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8242, i64 0, i64 1, i64 0
  %8249 = bitcast i8* %scevgep41.24.3 to [61 x [61 x i8]]*
  %call16.24.4 = call zeroext i8 (...) @rand()
  store i8 %call16.24.4, i8* %scevgep28.24.3, align 1
  %8250 = load i8, i8* %scevgep28.24.3, align 1
  %conv23.24.4 = zext i8 %8250 to i32
  %8251 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.4 = getelementptr i8, i8* %b, i64 29
  %8252 = load i8, i8* %scevgep34.24.4, align 1
  %call28.24.4 = call zeroext i8 @mult(i8 zeroext %8251, i8 zeroext %8252)
  %conv29.24.4 = zext i8 %call28.24.4 to i32
  %xor.24.4 = xor i32 %conv23.24.4, %conv29.24.4
  %scevgep35.24.4 = getelementptr i8, i8* %a, i64 29
  %8253 = load i8, i8* %scevgep35.24.4, align 1
  %8254 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.4 = call zeroext i8 @mult(i8 zeroext %8253, i8 zeroext %8254)
  %conv35.24.4 = zext i8 %call34.24.4 to i32
  %xor36.24.4 = xor i32 %xor.24.4, %conv35.24.4
  %conv37.24.4 = trunc i32 %xor36.24.4 to i8
  store i8 %conv37.24.4, i8* %scevgep41.24.3, align 1
  %scevgep28.24.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8248, i64 0, i64 0, i64 1
  %8255 = bitcast i8* %scevgep28.24.4 to [61 x [61 x i8]]*
  %scevgep41.24.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8249, i64 0, i64 1, i64 0
  %8256 = bitcast i8* %scevgep41.24.4 to [61 x [61 x i8]]*
  %call16.24.5 = call zeroext i8 (...) @rand()
  store i8 %call16.24.5, i8* %scevgep28.24.4, align 1
  %8257 = load i8, i8* %scevgep28.24.4, align 1
  %conv23.24.5 = zext i8 %8257 to i32
  %8258 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.5 = getelementptr i8, i8* %b, i64 30
  %8259 = load i8, i8* %scevgep34.24.5, align 1
  %call28.24.5 = call zeroext i8 @mult(i8 zeroext %8258, i8 zeroext %8259)
  %conv29.24.5 = zext i8 %call28.24.5 to i32
  %xor.24.5 = xor i32 %conv23.24.5, %conv29.24.5
  %scevgep35.24.5 = getelementptr i8, i8* %a, i64 30
  %8260 = load i8, i8* %scevgep35.24.5, align 1
  %8261 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.5 = call zeroext i8 @mult(i8 zeroext %8260, i8 zeroext %8261)
  %conv35.24.5 = zext i8 %call34.24.5 to i32
  %xor36.24.5 = xor i32 %xor.24.5, %conv35.24.5
  %conv37.24.5 = trunc i32 %xor36.24.5 to i8
  store i8 %conv37.24.5, i8* %scevgep41.24.4, align 1
  %scevgep28.24.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8255, i64 0, i64 0, i64 1
  %8262 = bitcast i8* %scevgep28.24.5 to [61 x [61 x i8]]*
  %scevgep41.24.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8256, i64 0, i64 1, i64 0
  %8263 = bitcast i8* %scevgep41.24.5 to [61 x [61 x i8]]*
  %call16.24.6 = call zeroext i8 (...) @rand()
  store i8 %call16.24.6, i8* %scevgep28.24.5, align 1
  %8264 = load i8, i8* %scevgep28.24.5, align 1
  %conv23.24.6 = zext i8 %8264 to i32
  %8265 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.6 = getelementptr i8, i8* %b, i64 31
  %8266 = load i8, i8* %scevgep34.24.6, align 1
  %call28.24.6 = call zeroext i8 @mult(i8 zeroext %8265, i8 zeroext %8266)
  %conv29.24.6 = zext i8 %call28.24.6 to i32
  %xor.24.6 = xor i32 %conv23.24.6, %conv29.24.6
  %scevgep35.24.6 = getelementptr i8, i8* %a, i64 31
  %8267 = load i8, i8* %scevgep35.24.6, align 1
  %8268 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.6 = call zeroext i8 @mult(i8 zeroext %8267, i8 zeroext %8268)
  %conv35.24.6 = zext i8 %call34.24.6 to i32
  %xor36.24.6 = xor i32 %xor.24.6, %conv35.24.6
  %conv37.24.6 = trunc i32 %xor36.24.6 to i8
  store i8 %conv37.24.6, i8* %scevgep41.24.5, align 1
  %scevgep28.24.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8262, i64 0, i64 0, i64 1
  %8269 = bitcast i8* %scevgep28.24.6 to [61 x [61 x i8]]*
  %scevgep41.24.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8263, i64 0, i64 1, i64 0
  %8270 = bitcast i8* %scevgep41.24.6 to [61 x [61 x i8]]*
  %call16.24.7 = call zeroext i8 (...) @rand()
  store i8 %call16.24.7, i8* %scevgep28.24.6, align 1
  %8271 = load i8, i8* %scevgep28.24.6, align 1
  %conv23.24.7 = zext i8 %8271 to i32
  %8272 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.7 = getelementptr i8, i8* %b, i64 32
  %8273 = load i8, i8* %scevgep34.24.7, align 1
  %call28.24.7 = call zeroext i8 @mult(i8 zeroext %8272, i8 zeroext %8273)
  %conv29.24.7 = zext i8 %call28.24.7 to i32
  %xor.24.7 = xor i32 %conv23.24.7, %conv29.24.7
  %scevgep35.24.7 = getelementptr i8, i8* %a, i64 32
  %8274 = load i8, i8* %scevgep35.24.7, align 1
  %8275 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.7 = call zeroext i8 @mult(i8 zeroext %8274, i8 zeroext %8275)
  %conv35.24.7 = zext i8 %call34.24.7 to i32
  %xor36.24.7 = xor i32 %xor.24.7, %conv35.24.7
  %conv37.24.7 = trunc i32 %xor36.24.7 to i8
  store i8 %conv37.24.7, i8* %scevgep41.24.6, align 1
  %scevgep28.24.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8269, i64 0, i64 0, i64 1
  %8276 = bitcast i8* %scevgep28.24.7 to [61 x [61 x i8]]*
  %scevgep41.24.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8270, i64 0, i64 1, i64 0
  %8277 = bitcast i8* %scevgep41.24.7 to [61 x [61 x i8]]*
  %call16.24.8 = call zeroext i8 (...) @rand()
  store i8 %call16.24.8, i8* %scevgep28.24.7, align 1
  %8278 = load i8, i8* %scevgep28.24.7, align 1
  %conv23.24.8 = zext i8 %8278 to i32
  %8279 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.8 = getelementptr i8, i8* %b, i64 33
  %8280 = load i8, i8* %scevgep34.24.8, align 1
  %call28.24.8 = call zeroext i8 @mult(i8 zeroext %8279, i8 zeroext %8280)
  %conv29.24.8 = zext i8 %call28.24.8 to i32
  %xor.24.8 = xor i32 %conv23.24.8, %conv29.24.8
  %scevgep35.24.8 = getelementptr i8, i8* %a, i64 33
  %8281 = load i8, i8* %scevgep35.24.8, align 1
  %8282 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.8 = call zeroext i8 @mult(i8 zeroext %8281, i8 zeroext %8282)
  %conv35.24.8 = zext i8 %call34.24.8 to i32
  %xor36.24.8 = xor i32 %xor.24.8, %conv35.24.8
  %conv37.24.8 = trunc i32 %xor36.24.8 to i8
  store i8 %conv37.24.8, i8* %scevgep41.24.7, align 1
  %scevgep28.24.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8276, i64 0, i64 0, i64 1
  %8283 = bitcast i8* %scevgep28.24.8 to [61 x [61 x i8]]*
  %scevgep41.24.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8277, i64 0, i64 1, i64 0
  %8284 = bitcast i8* %scevgep41.24.8 to [61 x [61 x i8]]*
  %call16.24.9 = call zeroext i8 (...) @rand()
  store i8 %call16.24.9, i8* %scevgep28.24.8, align 1
  %8285 = load i8, i8* %scevgep28.24.8, align 1
  %conv23.24.9 = zext i8 %8285 to i32
  %8286 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.9 = getelementptr i8, i8* %b, i64 34
  %8287 = load i8, i8* %scevgep34.24.9, align 1
  %call28.24.9 = call zeroext i8 @mult(i8 zeroext %8286, i8 zeroext %8287)
  %conv29.24.9 = zext i8 %call28.24.9 to i32
  %xor.24.9 = xor i32 %conv23.24.9, %conv29.24.9
  %scevgep35.24.9 = getelementptr i8, i8* %a, i64 34
  %8288 = load i8, i8* %scevgep35.24.9, align 1
  %8289 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.9 = call zeroext i8 @mult(i8 zeroext %8288, i8 zeroext %8289)
  %conv35.24.9 = zext i8 %call34.24.9 to i32
  %xor36.24.9 = xor i32 %xor.24.9, %conv35.24.9
  %conv37.24.9 = trunc i32 %xor36.24.9 to i8
  store i8 %conv37.24.9, i8* %scevgep41.24.8, align 1
  %scevgep28.24.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8283, i64 0, i64 0, i64 1
  %8290 = bitcast i8* %scevgep28.24.9 to [61 x [61 x i8]]*
  %scevgep41.24.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8284, i64 0, i64 1, i64 0
  %8291 = bitcast i8* %scevgep41.24.9 to [61 x [61 x i8]]*
  %call16.24.10 = call zeroext i8 (...) @rand()
  store i8 %call16.24.10, i8* %scevgep28.24.9, align 1
  %8292 = load i8, i8* %scevgep28.24.9, align 1
  %conv23.24.10 = zext i8 %8292 to i32
  %8293 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.10 = getelementptr i8, i8* %b, i64 35
  %8294 = load i8, i8* %scevgep34.24.10, align 1
  %call28.24.10 = call zeroext i8 @mult(i8 zeroext %8293, i8 zeroext %8294)
  %conv29.24.10 = zext i8 %call28.24.10 to i32
  %xor.24.10 = xor i32 %conv23.24.10, %conv29.24.10
  %scevgep35.24.10 = getelementptr i8, i8* %a, i64 35
  %8295 = load i8, i8* %scevgep35.24.10, align 1
  %8296 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.10 = call zeroext i8 @mult(i8 zeroext %8295, i8 zeroext %8296)
  %conv35.24.10 = zext i8 %call34.24.10 to i32
  %xor36.24.10 = xor i32 %xor.24.10, %conv35.24.10
  %conv37.24.10 = trunc i32 %xor36.24.10 to i8
  store i8 %conv37.24.10, i8* %scevgep41.24.9, align 1
  %scevgep28.24.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8290, i64 0, i64 0, i64 1
  %8297 = bitcast i8* %scevgep28.24.10 to [61 x [61 x i8]]*
  %scevgep41.24.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8291, i64 0, i64 1, i64 0
  %8298 = bitcast i8* %scevgep41.24.10 to [61 x [61 x i8]]*
  %call16.24.11 = call zeroext i8 (...) @rand()
  store i8 %call16.24.11, i8* %scevgep28.24.10, align 1
  %8299 = load i8, i8* %scevgep28.24.10, align 1
  %conv23.24.11 = zext i8 %8299 to i32
  %8300 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.11 = getelementptr i8, i8* %b, i64 36
  %8301 = load i8, i8* %scevgep34.24.11, align 1
  %call28.24.11 = call zeroext i8 @mult(i8 zeroext %8300, i8 zeroext %8301)
  %conv29.24.11 = zext i8 %call28.24.11 to i32
  %xor.24.11 = xor i32 %conv23.24.11, %conv29.24.11
  %scevgep35.24.11 = getelementptr i8, i8* %a, i64 36
  %8302 = load i8, i8* %scevgep35.24.11, align 1
  %8303 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.11 = call zeroext i8 @mult(i8 zeroext %8302, i8 zeroext %8303)
  %conv35.24.11 = zext i8 %call34.24.11 to i32
  %xor36.24.11 = xor i32 %xor.24.11, %conv35.24.11
  %conv37.24.11 = trunc i32 %xor36.24.11 to i8
  store i8 %conv37.24.11, i8* %scevgep41.24.10, align 1
  %scevgep28.24.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8297, i64 0, i64 0, i64 1
  %8304 = bitcast i8* %scevgep28.24.11 to [61 x [61 x i8]]*
  %scevgep41.24.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8298, i64 0, i64 1, i64 0
  %8305 = bitcast i8* %scevgep41.24.11 to [61 x [61 x i8]]*
  %call16.24.12 = call zeroext i8 (...) @rand()
  store i8 %call16.24.12, i8* %scevgep28.24.11, align 1
  %8306 = load i8, i8* %scevgep28.24.11, align 1
  %conv23.24.12 = zext i8 %8306 to i32
  %8307 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.12 = getelementptr i8, i8* %b, i64 37
  %8308 = load i8, i8* %scevgep34.24.12, align 1
  %call28.24.12 = call zeroext i8 @mult(i8 zeroext %8307, i8 zeroext %8308)
  %conv29.24.12 = zext i8 %call28.24.12 to i32
  %xor.24.12 = xor i32 %conv23.24.12, %conv29.24.12
  %scevgep35.24.12 = getelementptr i8, i8* %a, i64 37
  %8309 = load i8, i8* %scevgep35.24.12, align 1
  %8310 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.12 = call zeroext i8 @mult(i8 zeroext %8309, i8 zeroext %8310)
  %conv35.24.12 = zext i8 %call34.24.12 to i32
  %xor36.24.12 = xor i32 %xor.24.12, %conv35.24.12
  %conv37.24.12 = trunc i32 %xor36.24.12 to i8
  store i8 %conv37.24.12, i8* %scevgep41.24.11, align 1
  %scevgep28.24.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8304, i64 0, i64 0, i64 1
  %8311 = bitcast i8* %scevgep28.24.12 to [61 x [61 x i8]]*
  %scevgep41.24.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8305, i64 0, i64 1, i64 0
  %8312 = bitcast i8* %scevgep41.24.12 to [61 x [61 x i8]]*
  %call16.24.13 = call zeroext i8 (...) @rand()
  store i8 %call16.24.13, i8* %scevgep28.24.12, align 1
  %8313 = load i8, i8* %scevgep28.24.12, align 1
  %conv23.24.13 = zext i8 %8313 to i32
  %8314 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.13 = getelementptr i8, i8* %b, i64 38
  %8315 = load i8, i8* %scevgep34.24.13, align 1
  %call28.24.13 = call zeroext i8 @mult(i8 zeroext %8314, i8 zeroext %8315)
  %conv29.24.13 = zext i8 %call28.24.13 to i32
  %xor.24.13 = xor i32 %conv23.24.13, %conv29.24.13
  %scevgep35.24.13 = getelementptr i8, i8* %a, i64 38
  %8316 = load i8, i8* %scevgep35.24.13, align 1
  %8317 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.13 = call zeroext i8 @mult(i8 zeroext %8316, i8 zeroext %8317)
  %conv35.24.13 = zext i8 %call34.24.13 to i32
  %xor36.24.13 = xor i32 %xor.24.13, %conv35.24.13
  %conv37.24.13 = trunc i32 %xor36.24.13 to i8
  store i8 %conv37.24.13, i8* %scevgep41.24.12, align 1
  %scevgep28.24.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8311, i64 0, i64 0, i64 1
  %8318 = bitcast i8* %scevgep28.24.13 to [61 x [61 x i8]]*
  %scevgep41.24.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8312, i64 0, i64 1, i64 0
  %8319 = bitcast i8* %scevgep41.24.13 to [61 x [61 x i8]]*
  %call16.24.14 = call zeroext i8 (...) @rand()
  store i8 %call16.24.14, i8* %scevgep28.24.13, align 1
  %8320 = load i8, i8* %scevgep28.24.13, align 1
  %conv23.24.14 = zext i8 %8320 to i32
  %8321 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.14 = getelementptr i8, i8* %b, i64 39
  %8322 = load i8, i8* %scevgep34.24.14, align 1
  %call28.24.14 = call zeroext i8 @mult(i8 zeroext %8321, i8 zeroext %8322)
  %conv29.24.14 = zext i8 %call28.24.14 to i32
  %xor.24.14 = xor i32 %conv23.24.14, %conv29.24.14
  %scevgep35.24.14 = getelementptr i8, i8* %a, i64 39
  %8323 = load i8, i8* %scevgep35.24.14, align 1
  %8324 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.14 = call zeroext i8 @mult(i8 zeroext %8323, i8 zeroext %8324)
  %conv35.24.14 = zext i8 %call34.24.14 to i32
  %xor36.24.14 = xor i32 %xor.24.14, %conv35.24.14
  %conv37.24.14 = trunc i32 %xor36.24.14 to i8
  store i8 %conv37.24.14, i8* %scevgep41.24.13, align 1
  %scevgep28.24.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8318, i64 0, i64 0, i64 1
  %8325 = bitcast i8* %scevgep28.24.14 to [61 x [61 x i8]]*
  %scevgep41.24.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8319, i64 0, i64 1, i64 0
  %8326 = bitcast i8* %scevgep41.24.14 to [61 x [61 x i8]]*
  %call16.24.15 = call zeroext i8 (...) @rand()
  store i8 %call16.24.15, i8* %scevgep28.24.14, align 1
  %8327 = load i8, i8* %scevgep28.24.14, align 1
  %conv23.24.15 = zext i8 %8327 to i32
  %8328 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.15 = getelementptr i8, i8* %b, i64 40
  %8329 = load i8, i8* %scevgep34.24.15, align 1
  %call28.24.15 = call zeroext i8 @mult(i8 zeroext %8328, i8 zeroext %8329)
  %conv29.24.15 = zext i8 %call28.24.15 to i32
  %xor.24.15 = xor i32 %conv23.24.15, %conv29.24.15
  %scevgep35.24.15 = getelementptr i8, i8* %a, i64 40
  %8330 = load i8, i8* %scevgep35.24.15, align 1
  %8331 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.15 = call zeroext i8 @mult(i8 zeroext %8330, i8 zeroext %8331)
  %conv35.24.15 = zext i8 %call34.24.15 to i32
  %xor36.24.15 = xor i32 %xor.24.15, %conv35.24.15
  %conv37.24.15 = trunc i32 %xor36.24.15 to i8
  store i8 %conv37.24.15, i8* %scevgep41.24.14, align 1
  %scevgep28.24.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8325, i64 0, i64 0, i64 1
  %8332 = bitcast i8* %scevgep28.24.15 to [61 x [61 x i8]]*
  %scevgep41.24.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8326, i64 0, i64 1, i64 0
  %8333 = bitcast i8* %scevgep41.24.15 to [61 x [61 x i8]]*
  %call16.24.16 = call zeroext i8 (...) @rand()
  store i8 %call16.24.16, i8* %scevgep28.24.15, align 1
  %8334 = load i8, i8* %scevgep28.24.15, align 1
  %conv23.24.16 = zext i8 %8334 to i32
  %8335 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.16 = getelementptr i8, i8* %b, i64 41
  %8336 = load i8, i8* %scevgep34.24.16, align 1
  %call28.24.16 = call zeroext i8 @mult(i8 zeroext %8335, i8 zeroext %8336)
  %conv29.24.16 = zext i8 %call28.24.16 to i32
  %xor.24.16 = xor i32 %conv23.24.16, %conv29.24.16
  %scevgep35.24.16 = getelementptr i8, i8* %a, i64 41
  %8337 = load i8, i8* %scevgep35.24.16, align 1
  %8338 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.16 = call zeroext i8 @mult(i8 zeroext %8337, i8 zeroext %8338)
  %conv35.24.16 = zext i8 %call34.24.16 to i32
  %xor36.24.16 = xor i32 %xor.24.16, %conv35.24.16
  %conv37.24.16 = trunc i32 %xor36.24.16 to i8
  store i8 %conv37.24.16, i8* %scevgep41.24.15, align 1
  %scevgep28.24.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8332, i64 0, i64 0, i64 1
  %8339 = bitcast i8* %scevgep28.24.16 to [61 x [61 x i8]]*
  %scevgep41.24.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8333, i64 0, i64 1, i64 0
  %8340 = bitcast i8* %scevgep41.24.16 to [61 x [61 x i8]]*
  %call16.24.17 = call zeroext i8 (...) @rand()
  store i8 %call16.24.17, i8* %scevgep28.24.16, align 1
  %8341 = load i8, i8* %scevgep28.24.16, align 1
  %conv23.24.17 = zext i8 %8341 to i32
  %8342 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.17 = getelementptr i8, i8* %b, i64 42
  %8343 = load i8, i8* %scevgep34.24.17, align 1
  %call28.24.17 = call zeroext i8 @mult(i8 zeroext %8342, i8 zeroext %8343)
  %conv29.24.17 = zext i8 %call28.24.17 to i32
  %xor.24.17 = xor i32 %conv23.24.17, %conv29.24.17
  %scevgep35.24.17 = getelementptr i8, i8* %a, i64 42
  %8344 = load i8, i8* %scevgep35.24.17, align 1
  %8345 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.17 = call zeroext i8 @mult(i8 zeroext %8344, i8 zeroext %8345)
  %conv35.24.17 = zext i8 %call34.24.17 to i32
  %xor36.24.17 = xor i32 %xor.24.17, %conv35.24.17
  %conv37.24.17 = trunc i32 %xor36.24.17 to i8
  store i8 %conv37.24.17, i8* %scevgep41.24.16, align 1
  %scevgep28.24.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8339, i64 0, i64 0, i64 1
  %8346 = bitcast i8* %scevgep28.24.17 to [61 x [61 x i8]]*
  %scevgep41.24.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8340, i64 0, i64 1, i64 0
  %8347 = bitcast i8* %scevgep41.24.17 to [61 x [61 x i8]]*
  %call16.24.18 = call zeroext i8 (...) @rand()
  store i8 %call16.24.18, i8* %scevgep28.24.17, align 1
  %8348 = load i8, i8* %scevgep28.24.17, align 1
  %conv23.24.18 = zext i8 %8348 to i32
  %8349 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.18 = getelementptr i8, i8* %b, i64 43
  %8350 = load i8, i8* %scevgep34.24.18, align 1
  %call28.24.18 = call zeroext i8 @mult(i8 zeroext %8349, i8 zeroext %8350)
  %conv29.24.18 = zext i8 %call28.24.18 to i32
  %xor.24.18 = xor i32 %conv23.24.18, %conv29.24.18
  %scevgep35.24.18 = getelementptr i8, i8* %a, i64 43
  %8351 = load i8, i8* %scevgep35.24.18, align 1
  %8352 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.18 = call zeroext i8 @mult(i8 zeroext %8351, i8 zeroext %8352)
  %conv35.24.18 = zext i8 %call34.24.18 to i32
  %xor36.24.18 = xor i32 %xor.24.18, %conv35.24.18
  %conv37.24.18 = trunc i32 %xor36.24.18 to i8
  store i8 %conv37.24.18, i8* %scevgep41.24.17, align 1
  %scevgep28.24.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8346, i64 0, i64 0, i64 1
  %8353 = bitcast i8* %scevgep28.24.18 to [61 x [61 x i8]]*
  %scevgep41.24.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8347, i64 0, i64 1, i64 0
  %8354 = bitcast i8* %scevgep41.24.18 to [61 x [61 x i8]]*
  %call16.24.19 = call zeroext i8 (...) @rand()
  store i8 %call16.24.19, i8* %scevgep28.24.18, align 1
  %8355 = load i8, i8* %scevgep28.24.18, align 1
  %conv23.24.19 = zext i8 %8355 to i32
  %8356 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.19 = getelementptr i8, i8* %b, i64 44
  %8357 = load i8, i8* %scevgep34.24.19, align 1
  %call28.24.19 = call zeroext i8 @mult(i8 zeroext %8356, i8 zeroext %8357)
  %conv29.24.19 = zext i8 %call28.24.19 to i32
  %xor.24.19 = xor i32 %conv23.24.19, %conv29.24.19
  %scevgep35.24.19 = getelementptr i8, i8* %a, i64 44
  %8358 = load i8, i8* %scevgep35.24.19, align 1
  %8359 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.19 = call zeroext i8 @mult(i8 zeroext %8358, i8 zeroext %8359)
  %conv35.24.19 = zext i8 %call34.24.19 to i32
  %xor36.24.19 = xor i32 %xor.24.19, %conv35.24.19
  %conv37.24.19 = trunc i32 %xor36.24.19 to i8
  store i8 %conv37.24.19, i8* %scevgep41.24.18, align 1
  %scevgep28.24.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8353, i64 0, i64 0, i64 1
  %8360 = bitcast i8* %scevgep28.24.19 to [61 x [61 x i8]]*
  %scevgep41.24.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8354, i64 0, i64 1, i64 0
  %8361 = bitcast i8* %scevgep41.24.19 to [61 x [61 x i8]]*
  %call16.24.20 = call zeroext i8 (...) @rand()
  store i8 %call16.24.20, i8* %scevgep28.24.19, align 1
  %8362 = load i8, i8* %scevgep28.24.19, align 1
  %conv23.24.20 = zext i8 %8362 to i32
  %8363 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.20 = getelementptr i8, i8* %b, i64 45
  %8364 = load i8, i8* %scevgep34.24.20, align 1
  %call28.24.20 = call zeroext i8 @mult(i8 zeroext %8363, i8 zeroext %8364)
  %conv29.24.20 = zext i8 %call28.24.20 to i32
  %xor.24.20 = xor i32 %conv23.24.20, %conv29.24.20
  %scevgep35.24.20 = getelementptr i8, i8* %a, i64 45
  %8365 = load i8, i8* %scevgep35.24.20, align 1
  %8366 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.20 = call zeroext i8 @mult(i8 zeroext %8365, i8 zeroext %8366)
  %conv35.24.20 = zext i8 %call34.24.20 to i32
  %xor36.24.20 = xor i32 %xor.24.20, %conv35.24.20
  %conv37.24.20 = trunc i32 %xor36.24.20 to i8
  store i8 %conv37.24.20, i8* %scevgep41.24.19, align 1
  %scevgep28.24.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8360, i64 0, i64 0, i64 1
  %8367 = bitcast i8* %scevgep28.24.20 to [61 x [61 x i8]]*
  %scevgep41.24.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8361, i64 0, i64 1, i64 0
  %8368 = bitcast i8* %scevgep41.24.20 to [61 x [61 x i8]]*
  %call16.24.21 = call zeroext i8 (...) @rand()
  store i8 %call16.24.21, i8* %scevgep28.24.20, align 1
  %8369 = load i8, i8* %scevgep28.24.20, align 1
  %conv23.24.21 = zext i8 %8369 to i32
  %8370 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.21 = getelementptr i8, i8* %b, i64 46
  %8371 = load i8, i8* %scevgep34.24.21, align 1
  %call28.24.21 = call zeroext i8 @mult(i8 zeroext %8370, i8 zeroext %8371)
  %conv29.24.21 = zext i8 %call28.24.21 to i32
  %xor.24.21 = xor i32 %conv23.24.21, %conv29.24.21
  %scevgep35.24.21 = getelementptr i8, i8* %a, i64 46
  %8372 = load i8, i8* %scevgep35.24.21, align 1
  %8373 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.21 = call zeroext i8 @mult(i8 zeroext %8372, i8 zeroext %8373)
  %conv35.24.21 = zext i8 %call34.24.21 to i32
  %xor36.24.21 = xor i32 %xor.24.21, %conv35.24.21
  %conv37.24.21 = trunc i32 %xor36.24.21 to i8
  store i8 %conv37.24.21, i8* %scevgep41.24.20, align 1
  %scevgep28.24.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8367, i64 0, i64 0, i64 1
  %8374 = bitcast i8* %scevgep28.24.21 to [61 x [61 x i8]]*
  %scevgep41.24.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8368, i64 0, i64 1, i64 0
  %8375 = bitcast i8* %scevgep41.24.21 to [61 x [61 x i8]]*
  %call16.24.22 = call zeroext i8 (...) @rand()
  store i8 %call16.24.22, i8* %scevgep28.24.21, align 1
  %8376 = load i8, i8* %scevgep28.24.21, align 1
  %conv23.24.22 = zext i8 %8376 to i32
  %8377 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.22 = getelementptr i8, i8* %b, i64 47
  %8378 = load i8, i8* %scevgep34.24.22, align 1
  %call28.24.22 = call zeroext i8 @mult(i8 zeroext %8377, i8 zeroext %8378)
  %conv29.24.22 = zext i8 %call28.24.22 to i32
  %xor.24.22 = xor i32 %conv23.24.22, %conv29.24.22
  %scevgep35.24.22 = getelementptr i8, i8* %a, i64 47
  %8379 = load i8, i8* %scevgep35.24.22, align 1
  %8380 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.22 = call zeroext i8 @mult(i8 zeroext %8379, i8 zeroext %8380)
  %conv35.24.22 = zext i8 %call34.24.22 to i32
  %xor36.24.22 = xor i32 %xor.24.22, %conv35.24.22
  %conv37.24.22 = trunc i32 %xor36.24.22 to i8
  store i8 %conv37.24.22, i8* %scevgep41.24.21, align 1
  %scevgep28.24.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8374, i64 0, i64 0, i64 1
  %8381 = bitcast i8* %scevgep28.24.22 to [61 x [61 x i8]]*
  %scevgep41.24.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8375, i64 0, i64 1, i64 0
  %8382 = bitcast i8* %scevgep41.24.22 to [61 x [61 x i8]]*
  %call16.24.23 = call zeroext i8 (...) @rand()
  store i8 %call16.24.23, i8* %scevgep28.24.22, align 1
  %8383 = load i8, i8* %scevgep28.24.22, align 1
  %conv23.24.23 = zext i8 %8383 to i32
  %8384 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.23 = getelementptr i8, i8* %b, i64 48
  %8385 = load i8, i8* %scevgep34.24.23, align 1
  %call28.24.23 = call zeroext i8 @mult(i8 zeroext %8384, i8 zeroext %8385)
  %conv29.24.23 = zext i8 %call28.24.23 to i32
  %xor.24.23 = xor i32 %conv23.24.23, %conv29.24.23
  %scevgep35.24.23 = getelementptr i8, i8* %a, i64 48
  %8386 = load i8, i8* %scevgep35.24.23, align 1
  %8387 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.23 = call zeroext i8 @mult(i8 zeroext %8386, i8 zeroext %8387)
  %conv35.24.23 = zext i8 %call34.24.23 to i32
  %xor36.24.23 = xor i32 %xor.24.23, %conv35.24.23
  %conv37.24.23 = trunc i32 %xor36.24.23 to i8
  store i8 %conv37.24.23, i8* %scevgep41.24.22, align 1
  %scevgep28.24.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8381, i64 0, i64 0, i64 1
  %8388 = bitcast i8* %scevgep28.24.23 to [61 x [61 x i8]]*
  %scevgep41.24.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8382, i64 0, i64 1, i64 0
  %8389 = bitcast i8* %scevgep41.24.23 to [61 x [61 x i8]]*
  %call16.24.24 = call zeroext i8 (...) @rand()
  store i8 %call16.24.24, i8* %scevgep28.24.23, align 1
  %8390 = load i8, i8* %scevgep28.24.23, align 1
  %conv23.24.24 = zext i8 %8390 to i32
  %8391 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.24 = getelementptr i8, i8* %b, i64 49
  %8392 = load i8, i8* %scevgep34.24.24, align 1
  %call28.24.24 = call zeroext i8 @mult(i8 zeroext %8391, i8 zeroext %8392)
  %conv29.24.24 = zext i8 %call28.24.24 to i32
  %xor.24.24 = xor i32 %conv23.24.24, %conv29.24.24
  %scevgep35.24.24 = getelementptr i8, i8* %a, i64 49
  %8393 = load i8, i8* %scevgep35.24.24, align 1
  %8394 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.24 = call zeroext i8 @mult(i8 zeroext %8393, i8 zeroext %8394)
  %conv35.24.24 = zext i8 %call34.24.24 to i32
  %xor36.24.24 = xor i32 %xor.24.24, %conv35.24.24
  %conv37.24.24 = trunc i32 %xor36.24.24 to i8
  store i8 %conv37.24.24, i8* %scevgep41.24.23, align 1
  %scevgep28.24.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8388, i64 0, i64 0, i64 1
  %8395 = bitcast i8* %scevgep28.24.24 to [61 x [61 x i8]]*
  %scevgep41.24.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8389, i64 0, i64 1, i64 0
  %8396 = bitcast i8* %scevgep41.24.24 to [61 x [61 x i8]]*
  %call16.24.25 = call zeroext i8 (...) @rand()
  store i8 %call16.24.25, i8* %scevgep28.24.24, align 1
  %8397 = load i8, i8* %scevgep28.24.24, align 1
  %conv23.24.25 = zext i8 %8397 to i32
  %8398 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.25 = getelementptr i8, i8* %b, i64 50
  %8399 = load i8, i8* %scevgep34.24.25, align 1
  %call28.24.25 = call zeroext i8 @mult(i8 zeroext %8398, i8 zeroext %8399)
  %conv29.24.25 = zext i8 %call28.24.25 to i32
  %xor.24.25 = xor i32 %conv23.24.25, %conv29.24.25
  %scevgep35.24.25 = getelementptr i8, i8* %a, i64 50
  %8400 = load i8, i8* %scevgep35.24.25, align 1
  %8401 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.25 = call zeroext i8 @mult(i8 zeroext %8400, i8 zeroext %8401)
  %conv35.24.25 = zext i8 %call34.24.25 to i32
  %xor36.24.25 = xor i32 %xor.24.25, %conv35.24.25
  %conv37.24.25 = trunc i32 %xor36.24.25 to i8
  store i8 %conv37.24.25, i8* %scevgep41.24.24, align 1
  %scevgep28.24.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8395, i64 0, i64 0, i64 1
  %8402 = bitcast i8* %scevgep28.24.25 to [61 x [61 x i8]]*
  %scevgep41.24.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8396, i64 0, i64 1, i64 0
  %8403 = bitcast i8* %scevgep41.24.25 to [61 x [61 x i8]]*
  %call16.24.26 = call zeroext i8 (...) @rand()
  store i8 %call16.24.26, i8* %scevgep28.24.25, align 1
  %8404 = load i8, i8* %scevgep28.24.25, align 1
  %conv23.24.26 = zext i8 %8404 to i32
  %8405 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.26 = getelementptr i8, i8* %b, i64 51
  %8406 = load i8, i8* %scevgep34.24.26, align 1
  %call28.24.26 = call zeroext i8 @mult(i8 zeroext %8405, i8 zeroext %8406)
  %conv29.24.26 = zext i8 %call28.24.26 to i32
  %xor.24.26 = xor i32 %conv23.24.26, %conv29.24.26
  %scevgep35.24.26 = getelementptr i8, i8* %a, i64 51
  %8407 = load i8, i8* %scevgep35.24.26, align 1
  %8408 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.26 = call zeroext i8 @mult(i8 zeroext %8407, i8 zeroext %8408)
  %conv35.24.26 = zext i8 %call34.24.26 to i32
  %xor36.24.26 = xor i32 %xor.24.26, %conv35.24.26
  %conv37.24.26 = trunc i32 %xor36.24.26 to i8
  store i8 %conv37.24.26, i8* %scevgep41.24.25, align 1
  %scevgep28.24.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8402, i64 0, i64 0, i64 1
  %8409 = bitcast i8* %scevgep28.24.26 to [61 x [61 x i8]]*
  %scevgep41.24.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8403, i64 0, i64 1, i64 0
  %8410 = bitcast i8* %scevgep41.24.26 to [61 x [61 x i8]]*
  %call16.24.27 = call zeroext i8 (...) @rand()
  store i8 %call16.24.27, i8* %scevgep28.24.26, align 1
  %8411 = load i8, i8* %scevgep28.24.26, align 1
  %conv23.24.27 = zext i8 %8411 to i32
  %8412 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.27 = getelementptr i8, i8* %b, i64 52
  %8413 = load i8, i8* %scevgep34.24.27, align 1
  %call28.24.27 = call zeroext i8 @mult(i8 zeroext %8412, i8 zeroext %8413)
  %conv29.24.27 = zext i8 %call28.24.27 to i32
  %xor.24.27 = xor i32 %conv23.24.27, %conv29.24.27
  %scevgep35.24.27 = getelementptr i8, i8* %a, i64 52
  %8414 = load i8, i8* %scevgep35.24.27, align 1
  %8415 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.27 = call zeroext i8 @mult(i8 zeroext %8414, i8 zeroext %8415)
  %conv35.24.27 = zext i8 %call34.24.27 to i32
  %xor36.24.27 = xor i32 %xor.24.27, %conv35.24.27
  %conv37.24.27 = trunc i32 %xor36.24.27 to i8
  store i8 %conv37.24.27, i8* %scevgep41.24.26, align 1
  %scevgep28.24.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8409, i64 0, i64 0, i64 1
  %8416 = bitcast i8* %scevgep28.24.27 to [61 x [61 x i8]]*
  %scevgep41.24.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8410, i64 0, i64 1, i64 0
  %8417 = bitcast i8* %scevgep41.24.27 to [61 x [61 x i8]]*
  %call16.24.28 = call zeroext i8 (...) @rand()
  store i8 %call16.24.28, i8* %scevgep28.24.27, align 1
  %8418 = load i8, i8* %scevgep28.24.27, align 1
  %conv23.24.28 = zext i8 %8418 to i32
  %8419 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.28 = getelementptr i8, i8* %b, i64 53
  %8420 = load i8, i8* %scevgep34.24.28, align 1
  %call28.24.28 = call zeroext i8 @mult(i8 zeroext %8419, i8 zeroext %8420)
  %conv29.24.28 = zext i8 %call28.24.28 to i32
  %xor.24.28 = xor i32 %conv23.24.28, %conv29.24.28
  %scevgep35.24.28 = getelementptr i8, i8* %a, i64 53
  %8421 = load i8, i8* %scevgep35.24.28, align 1
  %8422 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.28 = call zeroext i8 @mult(i8 zeroext %8421, i8 zeroext %8422)
  %conv35.24.28 = zext i8 %call34.24.28 to i32
  %xor36.24.28 = xor i32 %xor.24.28, %conv35.24.28
  %conv37.24.28 = trunc i32 %xor36.24.28 to i8
  store i8 %conv37.24.28, i8* %scevgep41.24.27, align 1
  %scevgep28.24.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8416, i64 0, i64 0, i64 1
  %8423 = bitcast i8* %scevgep28.24.28 to [61 x [61 x i8]]*
  %scevgep41.24.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8417, i64 0, i64 1, i64 0
  %8424 = bitcast i8* %scevgep41.24.28 to [61 x [61 x i8]]*
  %call16.24.29 = call zeroext i8 (...) @rand()
  store i8 %call16.24.29, i8* %scevgep28.24.28, align 1
  %8425 = load i8, i8* %scevgep28.24.28, align 1
  %conv23.24.29 = zext i8 %8425 to i32
  %8426 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.29 = getelementptr i8, i8* %b, i64 54
  %8427 = load i8, i8* %scevgep34.24.29, align 1
  %call28.24.29 = call zeroext i8 @mult(i8 zeroext %8426, i8 zeroext %8427)
  %conv29.24.29 = zext i8 %call28.24.29 to i32
  %xor.24.29 = xor i32 %conv23.24.29, %conv29.24.29
  %scevgep35.24.29 = getelementptr i8, i8* %a, i64 54
  %8428 = load i8, i8* %scevgep35.24.29, align 1
  %8429 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.29 = call zeroext i8 @mult(i8 zeroext %8428, i8 zeroext %8429)
  %conv35.24.29 = zext i8 %call34.24.29 to i32
  %xor36.24.29 = xor i32 %xor.24.29, %conv35.24.29
  %conv37.24.29 = trunc i32 %xor36.24.29 to i8
  store i8 %conv37.24.29, i8* %scevgep41.24.28, align 1
  %scevgep28.24.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8423, i64 0, i64 0, i64 1
  %8430 = bitcast i8* %scevgep28.24.29 to [61 x [61 x i8]]*
  %scevgep41.24.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8424, i64 0, i64 1, i64 0
  %8431 = bitcast i8* %scevgep41.24.29 to [61 x [61 x i8]]*
  %call16.24.30 = call zeroext i8 (...) @rand()
  store i8 %call16.24.30, i8* %scevgep28.24.29, align 1
  %8432 = load i8, i8* %scevgep28.24.29, align 1
  %conv23.24.30 = zext i8 %8432 to i32
  %8433 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.30 = getelementptr i8, i8* %b, i64 55
  %8434 = load i8, i8* %scevgep34.24.30, align 1
  %call28.24.30 = call zeroext i8 @mult(i8 zeroext %8433, i8 zeroext %8434)
  %conv29.24.30 = zext i8 %call28.24.30 to i32
  %xor.24.30 = xor i32 %conv23.24.30, %conv29.24.30
  %scevgep35.24.30 = getelementptr i8, i8* %a, i64 55
  %8435 = load i8, i8* %scevgep35.24.30, align 1
  %8436 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.30 = call zeroext i8 @mult(i8 zeroext %8435, i8 zeroext %8436)
  %conv35.24.30 = zext i8 %call34.24.30 to i32
  %xor36.24.30 = xor i32 %xor.24.30, %conv35.24.30
  %conv37.24.30 = trunc i32 %xor36.24.30 to i8
  store i8 %conv37.24.30, i8* %scevgep41.24.29, align 1
  %scevgep28.24.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8430, i64 0, i64 0, i64 1
  %8437 = bitcast i8* %scevgep28.24.30 to [61 x [61 x i8]]*
  %scevgep41.24.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8431, i64 0, i64 1, i64 0
  %8438 = bitcast i8* %scevgep41.24.30 to [61 x [61 x i8]]*
  %call16.24.31 = call zeroext i8 (...) @rand()
  store i8 %call16.24.31, i8* %scevgep28.24.30, align 1
  %8439 = load i8, i8* %scevgep28.24.30, align 1
  %conv23.24.31 = zext i8 %8439 to i32
  %8440 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.31 = getelementptr i8, i8* %b, i64 56
  %8441 = load i8, i8* %scevgep34.24.31, align 1
  %call28.24.31 = call zeroext i8 @mult(i8 zeroext %8440, i8 zeroext %8441)
  %conv29.24.31 = zext i8 %call28.24.31 to i32
  %xor.24.31 = xor i32 %conv23.24.31, %conv29.24.31
  %scevgep35.24.31 = getelementptr i8, i8* %a, i64 56
  %8442 = load i8, i8* %scevgep35.24.31, align 1
  %8443 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.31 = call zeroext i8 @mult(i8 zeroext %8442, i8 zeroext %8443)
  %conv35.24.31 = zext i8 %call34.24.31 to i32
  %xor36.24.31 = xor i32 %xor.24.31, %conv35.24.31
  %conv37.24.31 = trunc i32 %xor36.24.31 to i8
  store i8 %conv37.24.31, i8* %scevgep41.24.30, align 1
  %scevgep28.24.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8437, i64 0, i64 0, i64 1
  %8444 = bitcast i8* %scevgep28.24.31 to [61 x [61 x i8]]*
  %scevgep41.24.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8438, i64 0, i64 1, i64 0
  %8445 = bitcast i8* %scevgep41.24.31 to [61 x [61 x i8]]*
  %call16.24.32 = call zeroext i8 (...) @rand()
  store i8 %call16.24.32, i8* %scevgep28.24.31, align 1
  %8446 = load i8, i8* %scevgep28.24.31, align 1
  %conv23.24.32 = zext i8 %8446 to i32
  %8447 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.32 = getelementptr i8, i8* %b, i64 57
  %8448 = load i8, i8* %scevgep34.24.32, align 1
  %call28.24.32 = call zeroext i8 @mult(i8 zeroext %8447, i8 zeroext %8448)
  %conv29.24.32 = zext i8 %call28.24.32 to i32
  %xor.24.32 = xor i32 %conv23.24.32, %conv29.24.32
  %scevgep35.24.32 = getelementptr i8, i8* %a, i64 57
  %8449 = load i8, i8* %scevgep35.24.32, align 1
  %8450 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.32 = call zeroext i8 @mult(i8 zeroext %8449, i8 zeroext %8450)
  %conv35.24.32 = zext i8 %call34.24.32 to i32
  %xor36.24.32 = xor i32 %xor.24.32, %conv35.24.32
  %conv37.24.32 = trunc i32 %xor36.24.32 to i8
  store i8 %conv37.24.32, i8* %scevgep41.24.31, align 1
  %scevgep28.24.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8444, i64 0, i64 0, i64 1
  %8451 = bitcast i8* %scevgep28.24.32 to [61 x [61 x i8]]*
  %scevgep41.24.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8445, i64 0, i64 1, i64 0
  %8452 = bitcast i8* %scevgep41.24.32 to [61 x [61 x i8]]*
  %call16.24.33 = call zeroext i8 (...) @rand()
  store i8 %call16.24.33, i8* %scevgep28.24.32, align 1
  %8453 = load i8, i8* %scevgep28.24.32, align 1
  %conv23.24.33 = zext i8 %8453 to i32
  %8454 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.33 = getelementptr i8, i8* %b, i64 58
  %8455 = load i8, i8* %scevgep34.24.33, align 1
  %call28.24.33 = call zeroext i8 @mult(i8 zeroext %8454, i8 zeroext %8455)
  %conv29.24.33 = zext i8 %call28.24.33 to i32
  %xor.24.33 = xor i32 %conv23.24.33, %conv29.24.33
  %scevgep35.24.33 = getelementptr i8, i8* %a, i64 58
  %8456 = load i8, i8* %scevgep35.24.33, align 1
  %8457 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.33 = call zeroext i8 @mult(i8 zeroext %8456, i8 zeroext %8457)
  %conv35.24.33 = zext i8 %call34.24.33 to i32
  %xor36.24.33 = xor i32 %xor.24.33, %conv35.24.33
  %conv37.24.33 = trunc i32 %xor36.24.33 to i8
  store i8 %conv37.24.33, i8* %scevgep41.24.32, align 1
  %scevgep28.24.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8451, i64 0, i64 0, i64 1
  %8458 = bitcast i8* %scevgep28.24.33 to [61 x [61 x i8]]*
  %scevgep41.24.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8452, i64 0, i64 1, i64 0
  %8459 = bitcast i8* %scevgep41.24.33 to [61 x [61 x i8]]*
  %call16.24.34 = call zeroext i8 (...) @rand()
  store i8 %call16.24.34, i8* %scevgep28.24.33, align 1
  %8460 = load i8, i8* %scevgep28.24.33, align 1
  %conv23.24.34 = zext i8 %8460 to i32
  %8461 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.34 = getelementptr i8, i8* %b, i64 59
  %8462 = load i8, i8* %scevgep34.24.34, align 1
  %call28.24.34 = call zeroext i8 @mult(i8 zeroext %8461, i8 zeroext %8462)
  %conv29.24.34 = zext i8 %call28.24.34 to i32
  %xor.24.34 = xor i32 %conv23.24.34, %conv29.24.34
  %scevgep35.24.34 = getelementptr i8, i8* %a, i64 59
  %8463 = load i8, i8* %scevgep35.24.34, align 1
  %8464 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.34 = call zeroext i8 @mult(i8 zeroext %8463, i8 zeroext %8464)
  %conv35.24.34 = zext i8 %call34.24.34 to i32
  %xor36.24.34 = xor i32 %xor.24.34, %conv35.24.34
  %conv37.24.34 = trunc i32 %xor36.24.34 to i8
  store i8 %conv37.24.34, i8* %scevgep41.24.33, align 1
  %scevgep28.24.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8458, i64 0, i64 0, i64 1
  %scevgep41.24.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8459, i64 0, i64 1, i64 0
  %call16.24.35 = call zeroext i8 (...) @rand()
  store i8 %call16.24.35, i8* %scevgep28.24.34, align 1
  %8465 = load i8, i8* %scevgep28.24.34, align 1
  %conv23.24.35 = zext i8 %8465 to i32
  %8466 = load i8, i8* %arrayidx25.24, align 1
  %scevgep34.24.35 = getelementptr i8, i8* %b, i64 60
  %8467 = load i8, i8* %scevgep34.24.35, align 1
  %call28.24.35 = call zeroext i8 @mult(i8 zeroext %8466, i8 zeroext %8467)
  %conv29.24.35 = zext i8 %call28.24.35 to i32
  %xor.24.35 = xor i32 %conv23.24.35, %conv29.24.35
  %scevgep35.24.35 = getelementptr i8, i8* %a, i64 60
  %8468 = load i8, i8* %scevgep35.24.35, align 1
  %8469 = load i8, i8* %arrayidx33.24, align 1
  %call34.24.35 = call zeroext i8 @mult(i8 zeroext %8468, i8 zeroext %8469)
  %conv35.24.35 = zext i8 %call34.24.35 to i32
  %xor36.24.35 = xor i32 %xor.24.35, %conv35.24.35
  %conv37.24.35 = trunc i32 %xor36.24.35 to i8
  store i8 %conv37.24.35, i8* %scevgep41.24.34, align 1
  %scevgep26.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8220, i64 0, i64 1, i64 1
  %8470 = bitcast i8* %scevgep26.24 to [61 x [61 x i8]]*
  %scevgep39.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8221, i64 0, i64 1, i64 1
  %8471 = bitcast i8* %scevgep39.24 to [61 x [61 x i8]]*
  %arrayidx25.25 = getelementptr inbounds i8, i8* %a, i64 25
  %arrayidx33.25 = getelementptr inbounds i8, i8* %b, i64 25
  %call16.25 = call zeroext i8 (...) @rand()
  store i8 %call16.25, i8* %scevgep26.24, align 1
  %8472 = load i8, i8* %scevgep26.24, align 1
  %conv23.25 = zext i8 %8472 to i32
  %8473 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25 = getelementptr i8, i8* %b, i64 26
  %8474 = load i8, i8* %scevgep34.25, align 1
  %call28.25 = call zeroext i8 @mult(i8 zeroext %8473, i8 zeroext %8474)
  %conv29.25 = zext i8 %call28.25 to i32
  %xor.25 = xor i32 %conv23.25, %conv29.25
  %scevgep35.25 = getelementptr i8, i8* %a, i64 26
  %8475 = load i8, i8* %scevgep35.25, align 1
  %8476 = load i8, i8* %arrayidx33.25, align 1
  %call34.25 = call zeroext i8 @mult(i8 zeroext %8475, i8 zeroext %8476)
  %conv35.25 = zext i8 %call34.25 to i32
  %xor36.25 = xor i32 %xor.25, %conv35.25
  %conv37.25 = trunc i32 %xor36.25 to i8
  store i8 %conv37.25, i8* %scevgep39.24, align 1
  %scevgep28.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8470, i64 0, i64 0, i64 1
  %8477 = bitcast i8* %scevgep28.25 to [61 x [61 x i8]]*
  %scevgep41.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8471, i64 0, i64 1, i64 0
  %8478 = bitcast i8* %scevgep41.25 to [61 x [61 x i8]]*
  %call16.25.1 = call zeroext i8 (...) @rand()
  store i8 %call16.25.1, i8* %scevgep28.25, align 1
  %8479 = load i8, i8* %scevgep28.25, align 1
  %conv23.25.1 = zext i8 %8479 to i32
  %8480 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.1 = getelementptr i8, i8* %b, i64 27
  %8481 = load i8, i8* %scevgep34.25.1, align 1
  %call28.25.1 = call zeroext i8 @mult(i8 zeroext %8480, i8 zeroext %8481)
  %conv29.25.1 = zext i8 %call28.25.1 to i32
  %xor.25.1 = xor i32 %conv23.25.1, %conv29.25.1
  %scevgep35.25.1 = getelementptr i8, i8* %a, i64 27
  %8482 = load i8, i8* %scevgep35.25.1, align 1
  %8483 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.1 = call zeroext i8 @mult(i8 zeroext %8482, i8 zeroext %8483)
  %conv35.25.1 = zext i8 %call34.25.1 to i32
  %xor36.25.1 = xor i32 %xor.25.1, %conv35.25.1
  %conv37.25.1 = trunc i32 %xor36.25.1 to i8
  store i8 %conv37.25.1, i8* %scevgep41.25, align 1
  %scevgep28.25.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8477, i64 0, i64 0, i64 1
  %8484 = bitcast i8* %scevgep28.25.1 to [61 x [61 x i8]]*
  %scevgep41.25.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8478, i64 0, i64 1, i64 0
  %8485 = bitcast i8* %scevgep41.25.1 to [61 x [61 x i8]]*
  %call16.25.2 = call zeroext i8 (...) @rand()
  store i8 %call16.25.2, i8* %scevgep28.25.1, align 1
  %8486 = load i8, i8* %scevgep28.25.1, align 1
  %conv23.25.2 = zext i8 %8486 to i32
  %8487 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.2 = getelementptr i8, i8* %b, i64 28
  %8488 = load i8, i8* %scevgep34.25.2, align 1
  %call28.25.2 = call zeroext i8 @mult(i8 zeroext %8487, i8 zeroext %8488)
  %conv29.25.2 = zext i8 %call28.25.2 to i32
  %xor.25.2 = xor i32 %conv23.25.2, %conv29.25.2
  %scevgep35.25.2 = getelementptr i8, i8* %a, i64 28
  %8489 = load i8, i8* %scevgep35.25.2, align 1
  %8490 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.2 = call zeroext i8 @mult(i8 zeroext %8489, i8 zeroext %8490)
  %conv35.25.2 = zext i8 %call34.25.2 to i32
  %xor36.25.2 = xor i32 %xor.25.2, %conv35.25.2
  %conv37.25.2 = trunc i32 %xor36.25.2 to i8
  store i8 %conv37.25.2, i8* %scevgep41.25.1, align 1
  %scevgep28.25.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8484, i64 0, i64 0, i64 1
  %8491 = bitcast i8* %scevgep28.25.2 to [61 x [61 x i8]]*
  %scevgep41.25.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8485, i64 0, i64 1, i64 0
  %8492 = bitcast i8* %scevgep41.25.2 to [61 x [61 x i8]]*
  %call16.25.3 = call zeroext i8 (...) @rand()
  store i8 %call16.25.3, i8* %scevgep28.25.2, align 1
  %8493 = load i8, i8* %scevgep28.25.2, align 1
  %conv23.25.3 = zext i8 %8493 to i32
  %8494 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.3 = getelementptr i8, i8* %b, i64 29
  %8495 = load i8, i8* %scevgep34.25.3, align 1
  %call28.25.3 = call zeroext i8 @mult(i8 zeroext %8494, i8 zeroext %8495)
  %conv29.25.3 = zext i8 %call28.25.3 to i32
  %xor.25.3 = xor i32 %conv23.25.3, %conv29.25.3
  %scevgep35.25.3 = getelementptr i8, i8* %a, i64 29
  %8496 = load i8, i8* %scevgep35.25.3, align 1
  %8497 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.3 = call zeroext i8 @mult(i8 zeroext %8496, i8 zeroext %8497)
  %conv35.25.3 = zext i8 %call34.25.3 to i32
  %xor36.25.3 = xor i32 %xor.25.3, %conv35.25.3
  %conv37.25.3 = trunc i32 %xor36.25.3 to i8
  store i8 %conv37.25.3, i8* %scevgep41.25.2, align 1
  %scevgep28.25.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8491, i64 0, i64 0, i64 1
  %8498 = bitcast i8* %scevgep28.25.3 to [61 x [61 x i8]]*
  %scevgep41.25.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8492, i64 0, i64 1, i64 0
  %8499 = bitcast i8* %scevgep41.25.3 to [61 x [61 x i8]]*
  %call16.25.4 = call zeroext i8 (...) @rand()
  store i8 %call16.25.4, i8* %scevgep28.25.3, align 1
  %8500 = load i8, i8* %scevgep28.25.3, align 1
  %conv23.25.4 = zext i8 %8500 to i32
  %8501 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.4 = getelementptr i8, i8* %b, i64 30
  %8502 = load i8, i8* %scevgep34.25.4, align 1
  %call28.25.4 = call zeroext i8 @mult(i8 zeroext %8501, i8 zeroext %8502)
  %conv29.25.4 = zext i8 %call28.25.4 to i32
  %xor.25.4 = xor i32 %conv23.25.4, %conv29.25.4
  %scevgep35.25.4 = getelementptr i8, i8* %a, i64 30
  %8503 = load i8, i8* %scevgep35.25.4, align 1
  %8504 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.4 = call zeroext i8 @mult(i8 zeroext %8503, i8 zeroext %8504)
  %conv35.25.4 = zext i8 %call34.25.4 to i32
  %xor36.25.4 = xor i32 %xor.25.4, %conv35.25.4
  %conv37.25.4 = trunc i32 %xor36.25.4 to i8
  store i8 %conv37.25.4, i8* %scevgep41.25.3, align 1
  %scevgep28.25.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8498, i64 0, i64 0, i64 1
  %8505 = bitcast i8* %scevgep28.25.4 to [61 x [61 x i8]]*
  %scevgep41.25.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8499, i64 0, i64 1, i64 0
  %8506 = bitcast i8* %scevgep41.25.4 to [61 x [61 x i8]]*
  %call16.25.5 = call zeroext i8 (...) @rand()
  store i8 %call16.25.5, i8* %scevgep28.25.4, align 1
  %8507 = load i8, i8* %scevgep28.25.4, align 1
  %conv23.25.5 = zext i8 %8507 to i32
  %8508 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.5 = getelementptr i8, i8* %b, i64 31
  %8509 = load i8, i8* %scevgep34.25.5, align 1
  %call28.25.5 = call zeroext i8 @mult(i8 zeroext %8508, i8 zeroext %8509)
  %conv29.25.5 = zext i8 %call28.25.5 to i32
  %xor.25.5 = xor i32 %conv23.25.5, %conv29.25.5
  %scevgep35.25.5 = getelementptr i8, i8* %a, i64 31
  %8510 = load i8, i8* %scevgep35.25.5, align 1
  %8511 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.5 = call zeroext i8 @mult(i8 zeroext %8510, i8 zeroext %8511)
  %conv35.25.5 = zext i8 %call34.25.5 to i32
  %xor36.25.5 = xor i32 %xor.25.5, %conv35.25.5
  %conv37.25.5 = trunc i32 %xor36.25.5 to i8
  store i8 %conv37.25.5, i8* %scevgep41.25.4, align 1
  %scevgep28.25.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8505, i64 0, i64 0, i64 1
  %8512 = bitcast i8* %scevgep28.25.5 to [61 x [61 x i8]]*
  %scevgep41.25.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8506, i64 0, i64 1, i64 0
  %8513 = bitcast i8* %scevgep41.25.5 to [61 x [61 x i8]]*
  %call16.25.6 = call zeroext i8 (...) @rand()
  store i8 %call16.25.6, i8* %scevgep28.25.5, align 1
  %8514 = load i8, i8* %scevgep28.25.5, align 1
  %conv23.25.6 = zext i8 %8514 to i32
  %8515 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.6 = getelementptr i8, i8* %b, i64 32
  %8516 = load i8, i8* %scevgep34.25.6, align 1
  %call28.25.6 = call zeroext i8 @mult(i8 zeroext %8515, i8 zeroext %8516)
  %conv29.25.6 = zext i8 %call28.25.6 to i32
  %xor.25.6 = xor i32 %conv23.25.6, %conv29.25.6
  %scevgep35.25.6 = getelementptr i8, i8* %a, i64 32
  %8517 = load i8, i8* %scevgep35.25.6, align 1
  %8518 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.6 = call zeroext i8 @mult(i8 zeroext %8517, i8 zeroext %8518)
  %conv35.25.6 = zext i8 %call34.25.6 to i32
  %xor36.25.6 = xor i32 %xor.25.6, %conv35.25.6
  %conv37.25.6 = trunc i32 %xor36.25.6 to i8
  store i8 %conv37.25.6, i8* %scevgep41.25.5, align 1
  %scevgep28.25.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8512, i64 0, i64 0, i64 1
  %8519 = bitcast i8* %scevgep28.25.6 to [61 x [61 x i8]]*
  %scevgep41.25.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8513, i64 0, i64 1, i64 0
  %8520 = bitcast i8* %scevgep41.25.6 to [61 x [61 x i8]]*
  %call16.25.7 = call zeroext i8 (...) @rand()
  store i8 %call16.25.7, i8* %scevgep28.25.6, align 1
  %8521 = load i8, i8* %scevgep28.25.6, align 1
  %conv23.25.7 = zext i8 %8521 to i32
  %8522 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.7 = getelementptr i8, i8* %b, i64 33
  %8523 = load i8, i8* %scevgep34.25.7, align 1
  %call28.25.7 = call zeroext i8 @mult(i8 zeroext %8522, i8 zeroext %8523)
  %conv29.25.7 = zext i8 %call28.25.7 to i32
  %xor.25.7 = xor i32 %conv23.25.7, %conv29.25.7
  %scevgep35.25.7 = getelementptr i8, i8* %a, i64 33
  %8524 = load i8, i8* %scevgep35.25.7, align 1
  %8525 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.7 = call zeroext i8 @mult(i8 zeroext %8524, i8 zeroext %8525)
  %conv35.25.7 = zext i8 %call34.25.7 to i32
  %xor36.25.7 = xor i32 %xor.25.7, %conv35.25.7
  %conv37.25.7 = trunc i32 %xor36.25.7 to i8
  store i8 %conv37.25.7, i8* %scevgep41.25.6, align 1
  %scevgep28.25.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8519, i64 0, i64 0, i64 1
  %8526 = bitcast i8* %scevgep28.25.7 to [61 x [61 x i8]]*
  %scevgep41.25.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8520, i64 0, i64 1, i64 0
  %8527 = bitcast i8* %scevgep41.25.7 to [61 x [61 x i8]]*
  %call16.25.8 = call zeroext i8 (...) @rand()
  store i8 %call16.25.8, i8* %scevgep28.25.7, align 1
  %8528 = load i8, i8* %scevgep28.25.7, align 1
  %conv23.25.8 = zext i8 %8528 to i32
  %8529 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.8 = getelementptr i8, i8* %b, i64 34
  %8530 = load i8, i8* %scevgep34.25.8, align 1
  %call28.25.8 = call zeroext i8 @mult(i8 zeroext %8529, i8 zeroext %8530)
  %conv29.25.8 = zext i8 %call28.25.8 to i32
  %xor.25.8 = xor i32 %conv23.25.8, %conv29.25.8
  %scevgep35.25.8 = getelementptr i8, i8* %a, i64 34
  %8531 = load i8, i8* %scevgep35.25.8, align 1
  %8532 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.8 = call zeroext i8 @mult(i8 zeroext %8531, i8 zeroext %8532)
  %conv35.25.8 = zext i8 %call34.25.8 to i32
  %xor36.25.8 = xor i32 %xor.25.8, %conv35.25.8
  %conv37.25.8 = trunc i32 %xor36.25.8 to i8
  store i8 %conv37.25.8, i8* %scevgep41.25.7, align 1
  %scevgep28.25.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8526, i64 0, i64 0, i64 1
  %8533 = bitcast i8* %scevgep28.25.8 to [61 x [61 x i8]]*
  %scevgep41.25.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8527, i64 0, i64 1, i64 0
  %8534 = bitcast i8* %scevgep41.25.8 to [61 x [61 x i8]]*
  %call16.25.9 = call zeroext i8 (...) @rand()
  store i8 %call16.25.9, i8* %scevgep28.25.8, align 1
  %8535 = load i8, i8* %scevgep28.25.8, align 1
  %conv23.25.9 = zext i8 %8535 to i32
  %8536 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.9 = getelementptr i8, i8* %b, i64 35
  %8537 = load i8, i8* %scevgep34.25.9, align 1
  %call28.25.9 = call zeroext i8 @mult(i8 zeroext %8536, i8 zeroext %8537)
  %conv29.25.9 = zext i8 %call28.25.9 to i32
  %xor.25.9 = xor i32 %conv23.25.9, %conv29.25.9
  %scevgep35.25.9 = getelementptr i8, i8* %a, i64 35
  %8538 = load i8, i8* %scevgep35.25.9, align 1
  %8539 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.9 = call zeroext i8 @mult(i8 zeroext %8538, i8 zeroext %8539)
  %conv35.25.9 = zext i8 %call34.25.9 to i32
  %xor36.25.9 = xor i32 %xor.25.9, %conv35.25.9
  %conv37.25.9 = trunc i32 %xor36.25.9 to i8
  store i8 %conv37.25.9, i8* %scevgep41.25.8, align 1
  %scevgep28.25.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8533, i64 0, i64 0, i64 1
  %8540 = bitcast i8* %scevgep28.25.9 to [61 x [61 x i8]]*
  %scevgep41.25.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8534, i64 0, i64 1, i64 0
  %8541 = bitcast i8* %scevgep41.25.9 to [61 x [61 x i8]]*
  %call16.25.10 = call zeroext i8 (...) @rand()
  store i8 %call16.25.10, i8* %scevgep28.25.9, align 1
  %8542 = load i8, i8* %scevgep28.25.9, align 1
  %conv23.25.10 = zext i8 %8542 to i32
  %8543 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.10 = getelementptr i8, i8* %b, i64 36
  %8544 = load i8, i8* %scevgep34.25.10, align 1
  %call28.25.10 = call zeroext i8 @mult(i8 zeroext %8543, i8 zeroext %8544)
  %conv29.25.10 = zext i8 %call28.25.10 to i32
  %xor.25.10 = xor i32 %conv23.25.10, %conv29.25.10
  %scevgep35.25.10 = getelementptr i8, i8* %a, i64 36
  %8545 = load i8, i8* %scevgep35.25.10, align 1
  %8546 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.10 = call zeroext i8 @mult(i8 zeroext %8545, i8 zeroext %8546)
  %conv35.25.10 = zext i8 %call34.25.10 to i32
  %xor36.25.10 = xor i32 %xor.25.10, %conv35.25.10
  %conv37.25.10 = trunc i32 %xor36.25.10 to i8
  store i8 %conv37.25.10, i8* %scevgep41.25.9, align 1
  %scevgep28.25.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8540, i64 0, i64 0, i64 1
  %8547 = bitcast i8* %scevgep28.25.10 to [61 x [61 x i8]]*
  %scevgep41.25.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8541, i64 0, i64 1, i64 0
  %8548 = bitcast i8* %scevgep41.25.10 to [61 x [61 x i8]]*
  %call16.25.11 = call zeroext i8 (...) @rand()
  store i8 %call16.25.11, i8* %scevgep28.25.10, align 1
  %8549 = load i8, i8* %scevgep28.25.10, align 1
  %conv23.25.11 = zext i8 %8549 to i32
  %8550 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.11 = getelementptr i8, i8* %b, i64 37
  %8551 = load i8, i8* %scevgep34.25.11, align 1
  %call28.25.11 = call zeroext i8 @mult(i8 zeroext %8550, i8 zeroext %8551)
  %conv29.25.11 = zext i8 %call28.25.11 to i32
  %xor.25.11 = xor i32 %conv23.25.11, %conv29.25.11
  %scevgep35.25.11 = getelementptr i8, i8* %a, i64 37
  %8552 = load i8, i8* %scevgep35.25.11, align 1
  %8553 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.11 = call zeroext i8 @mult(i8 zeroext %8552, i8 zeroext %8553)
  %conv35.25.11 = zext i8 %call34.25.11 to i32
  %xor36.25.11 = xor i32 %xor.25.11, %conv35.25.11
  %conv37.25.11 = trunc i32 %xor36.25.11 to i8
  store i8 %conv37.25.11, i8* %scevgep41.25.10, align 1
  %scevgep28.25.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8547, i64 0, i64 0, i64 1
  %8554 = bitcast i8* %scevgep28.25.11 to [61 x [61 x i8]]*
  %scevgep41.25.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8548, i64 0, i64 1, i64 0
  %8555 = bitcast i8* %scevgep41.25.11 to [61 x [61 x i8]]*
  %call16.25.12 = call zeroext i8 (...) @rand()
  store i8 %call16.25.12, i8* %scevgep28.25.11, align 1
  %8556 = load i8, i8* %scevgep28.25.11, align 1
  %conv23.25.12 = zext i8 %8556 to i32
  %8557 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.12 = getelementptr i8, i8* %b, i64 38
  %8558 = load i8, i8* %scevgep34.25.12, align 1
  %call28.25.12 = call zeroext i8 @mult(i8 zeroext %8557, i8 zeroext %8558)
  %conv29.25.12 = zext i8 %call28.25.12 to i32
  %xor.25.12 = xor i32 %conv23.25.12, %conv29.25.12
  %scevgep35.25.12 = getelementptr i8, i8* %a, i64 38
  %8559 = load i8, i8* %scevgep35.25.12, align 1
  %8560 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.12 = call zeroext i8 @mult(i8 zeroext %8559, i8 zeroext %8560)
  %conv35.25.12 = zext i8 %call34.25.12 to i32
  %xor36.25.12 = xor i32 %xor.25.12, %conv35.25.12
  %conv37.25.12 = trunc i32 %xor36.25.12 to i8
  store i8 %conv37.25.12, i8* %scevgep41.25.11, align 1
  %scevgep28.25.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8554, i64 0, i64 0, i64 1
  %8561 = bitcast i8* %scevgep28.25.12 to [61 x [61 x i8]]*
  %scevgep41.25.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8555, i64 0, i64 1, i64 0
  %8562 = bitcast i8* %scevgep41.25.12 to [61 x [61 x i8]]*
  %call16.25.13 = call zeroext i8 (...) @rand()
  store i8 %call16.25.13, i8* %scevgep28.25.12, align 1
  %8563 = load i8, i8* %scevgep28.25.12, align 1
  %conv23.25.13 = zext i8 %8563 to i32
  %8564 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.13 = getelementptr i8, i8* %b, i64 39
  %8565 = load i8, i8* %scevgep34.25.13, align 1
  %call28.25.13 = call zeroext i8 @mult(i8 zeroext %8564, i8 zeroext %8565)
  %conv29.25.13 = zext i8 %call28.25.13 to i32
  %xor.25.13 = xor i32 %conv23.25.13, %conv29.25.13
  %scevgep35.25.13 = getelementptr i8, i8* %a, i64 39
  %8566 = load i8, i8* %scevgep35.25.13, align 1
  %8567 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.13 = call zeroext i8 @mult(i8 zeroext %8566, i8 zeroext %8567)
  %conv35.25.13 = zext i8 %call34.25.13 to i32
  %xor36.25.13 = xor i32 %xor.25.13, %conv35.25.13
  %conv37.25.13 = trunc i32 %xor36.25.13 to i8
  store i8 %conv37.25.13, i8* %scevgep41.25.12, align 1
  %scevgep28.25.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8561, i64 0, i64 0, i64 1
  %8568 = bitcast i8* %scevgep28.25.13 to [61 x [61 x i8]]*
  %scevgep41.25.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8562, i64 0, i64 1, i64 0
  %8569 = bitcast i8* %scevgep41.25.13 to [61 x [61 x i8]]*
  %call16.25.14 = call zeroext i8 (...) @rand()
  store i8 %call16.25.14, i8* %scevgep28.25.13, align 1
  %8570 = load i8, i8* %scevgep28.25.13, align 1
  %conv23.25.14 = zext i8 %8570 to i32
  %8571 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.14 = getelementptr i8, i8* %b, i64 40
  %8572 = load i8, i8* %scevgep34.25.14, align 1
  %call28.25.14 = call zeroext i8 @mult(i8 zeroext %8571, i8 zeroext %8572)
  %conv29.25.14 = zext i8 %call28.25.14 to i32
  %xor.25.14 = xor i32 %conv23.25.14, %conv29.25.14
  %scevgep35.25.14 = getelementptr i8, i8* %a, i64 40
  %8573 = load i8, i8* %scevgep35.25.14, align 1
  %8574 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.14 = call zeroext i8 @mult(i8 zeroext %8573, i8 zeroext %8574)
  %conv35.25.14 = zext i8 %call34.25.14 to i32
  %xor36.25.14 = xor i32 %xor.25.14, %conv35.25.14
  %conv37.25.14 = trunc i32 %xor36.25.14 to i8
  store i8 %conv37.25.14, i8* %scevgep41.25.13, align 1
  %scevgep28.25.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8568, i64 0, i64 0, i64 1
  %8575 = bitcast i8* %scevgep28.25.14 to [61 x [61 x i8]]*
  %scevgep41.25.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8569, i64 0, i64 1, i64 0
  %8576 = bitcast i8* %scevgep41.25.14 to [61 x [61 x i8]]*
  %call16.25.15 = call zeroext i8 (...) @rand()
  store i8 %call16.25.15, i8* %scevgep28.25.14, align 1
  %8577 = load i8, i8* %scevgep28.25.14, align 1
  %conv23.25.15 = zext i8 %8577 to i32
  %8578 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.15 = getelementptr i8, i8* %b, i64 41
  %8579 = load i8, i8* %scevgep34.25.15, align 1
  %call28.25.15 = call zeroext i8 @mult(i8 zeroext %8578, i8 zeroext %8579)
  %conv29.25.15 = zext i8 %call28.25.15 to i32
  %xor.25.15 = xor i32 %conv23.25.15, %conv29.25.15
  %scevgep35.25.15 = getelementptr i8, i8* %a, i64 41
  %8580 = load i8, i8* %scevgep35.25.15, align 1
  %8581 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.15 = call zeroext i8 @mult(i8 zeroext %8580, i8 zeroext %8581)
  %conv35.25.15 = zext i8 %call34.25.15 to i32
  %xor36.25.15 = xor i32 %xor.25.15, %conv35.25.15
  %conv37.25.15 = trunc i32 %xor36.25.15 to i8
  store i8 %conv37.25.15, i8* %scevgep41.25.14, align 1
  %scevgep28.25.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8575, i64 0, i64 0, i64 1
  %8582 = bitcast i8* %scevgep28.25.15 to [61 x [61 x i8]]*
  %scevgep41.25.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8576, i64 0, i64 1, i64 0
  %8583 = bitcast i8* %scevgep41.25.15 to [61 x [61 x i8]]*
  %call16.25.16 = call zeroext i8 (...) @rand()
  store i8 %call16.25.16, i8* %scevgep28.25.15, align 1
  %8584 = load i8, i8* %scevgep28.25.15, align 1
  %conv23.25.16 = zext i8 %8584 to i32
  %8585 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.16 = getelementptr i8, i8* %b, i64 42
  %8586 = load i8, i8* %scevgep34.25.16, align 1
  %call28.25.16 = call zeroext i8 @mult(i8 zeroext %8585, i8 zeroext %8586)
  %conv29.25.16 = zext i8 %call28.25.16 to i32
  %xor.25.16 = xor i32 %conv23.25.16, %conv29.25.16
  %scevgep35.25.16 = getelementptr i8, i8* %a, i64 42
  %8587 = load i8, i8* %scevgep35.25.16, align 1
  %8588 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.16 = call zeroext i8 @mult(i8 zeroext %8587, i8 zeroext %8588)
  %conv35.25.16 = zext i8 %call34.25.16 to i32
  %xor36.25.16 = xor i32 %xor.25.16, %conv35.25.16
  %conv37.25.16 = trunc i32 %xor36.25.16 to i8
  store i8 %conv37.25.16, i8* %scevgep41.25.15, align 1
  %scevgep28.25.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8582, i64 0, i64 0, i64 1
  %8589 = bitcast i8* %scevgep28.25.16 to [61 x [61 x i8]]*
  %scevgep41.25.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8583, i64 0, i64 1, i64 0
  %8590 = bitcast i8* %scevgep41.25.16 to [61 x [61 x i8]]*
  %call16.25.17 = call zeroext i8 (...) @rand()
  store i8 %call16.25.17, i8* %scevgep28.25.16, align 1
  %8591 = load i8, i8* %scevgep28.25.16, align 1
  %conv23.25.17 = zext i8 %8591 to i32
  %8592 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.17 = getelementptr i8, i8* %b, i64 43
  %8593 = load i8, i8* %scevgep34.25.17, align 1
  %call28.25.17 = call zeroext i8 @mult(i8 zeroext %8592, i8 zeroext %8593)
  %conv29.25.17 = zext i8 %call28.25.17 to i32
  %xor.25.17 = xor i32 %conv23.25.17, %conv29.25.17
  %scevgep35.25.17 = getelementptr i8, i8* %a, i64 43
  %8594 = load i8, i8* %scevgep35.25.17, align 1
  %8595 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.17 = call zeroext i8 @mult(i8 zeroext %8594, i8 zeroext %8595)
  %conv35.25.17 = zext i8 %call34.25.17 to i32
  %xor36.25.17 = xor i32 %xor.25.17, %conv35.25.17
  %conv37.25.17 = trunc i32 %xor36.25.17 to i8
  store i8 %conv37.25.17, i8* %scevgep41.25.16, align 1
  %scevgep28.25.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8589, i64 0, i64 0, i64 1
  %8596 = bitcast i8* %scevgep28.25.17 to [61 x [61 x i8]]*
  %scevgep41.25.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8590, i64 0, i64 1, i64 0
  %8597 = bitcast i8* %scevgep41.25.17 to [61 x [61 x i8]]*
  %call16.25.18 = call zeroext i8 (...) @rand()
  store i8 %call16.25.18, i8* %scevgep28.25.17, align 1
  %8598 = load i8, i8* %scevgep28.25.17, align 1
  %conv23.25.18 = zext i8 %8598 to i32
  %8599 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.18 = getelementptr i8, i8* %b, i64 44
  %8600 = load i8, i8* %scevgep34.25.18, align 1
  %call28.25.18 = call zeroext i8 @mult(i8 zeroext %8599, i8 zeroext %8600)
  %conv29.25.18 = zext i8 %call28.25.18 to i32
  %xor.25.18 = xor i32 %conv23.25.18, %conv29.25.18
  %scevgep35.25.18 = getelementptr i8, i8* %a, i64 44
  %8601 = load i8, i8* %scevgep35.25.18, align 1
  %8602 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.18 = call zeroext i8 @mult(i8 zeroext %8601, i8 zeroext %8602)
  %conv35.25.18 = zext i8 %call34.25.18 to i32
  %xor36.25.18 = xor i32 %xor.25.18, %conv35.25.18
  %conv37.25.18 = trunc i32 %xor36.25.18 to i8
  store i8 %conv37.25.18, i8* %scevgep41.25.17, align 1
  %scevgep28.25.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8596, i64 0, i64 0, i64 1
  %8603 = bitcast i8* %scevgep28.25.18 to [61 x [61 x i8]]*
  %scevgep41.25.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8597, i64 0, i64 1, i64 0
  %8604 = bitcast i8* %scevgep41.25.18 to [61 x [61 x i8]]*
  %call16.25.19 = call zeroext i8 (...) @rand()
  store i8 %call16.25.19, i8* %scevgep28.25.18, align 1
  %8605 = load i8, i8* %scevgep28.25.18, align 1
  %conv23.25.19 = zext i8 %8605 to i32
  %8606 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.19 = getelementptr i8, i8* %b, i64 45
  %8607 = load i8, i8* %scevgep34.25.19, align 1
  %call28.25.19 = call zeroext i8 @mult(i8 zeroext %8606, i8 zeroext %8607)
  %conv29.25.19 = zext i8 %call28.25.19 to i32
  %xor.25.19 = xor i32 %conv23.25.19, %conv29.25.19
  %scevgep35.25.19 = getelementptr i8, i8* %a, i64 45
  %8608 = load i8, i8* %scevgep35.25.19, align 1
  %8609 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.19 = call zeroext i8 @mult(i8 zeroext %8608, i8 zeroext %8609)
  %conv35.25.19 = zext i8 %call34.25.19 to i32
  %xor36.25.19 = xor i32 %xor.25.19, %conv35.25.19
  %conv37.25.19 = trunc i32 %xor36.25.19 to i8
  store i8 %conv37.25.19, i8* %scevgep41.25.18, align 1
  %scevgep28.25.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8603, i64 0, i64 0, i64 1
  %8610 = bitcast i8* %scevgep28.25.19 to [61 x [61 x i8]]*
  %scevgep41.25.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8604, i64 0, i64 1, i64 0
  %8611 = bitcast i8* %scevgep41.25.19 to [61 x [61 x i8]]*
  %call16.25.20 = call zeroext i8 (...) @rand()
  store i8 %call16.25.20, i8* %scevgep28.25.19, align 1
  %8612 = load i8, i8* %scevgep28.25.19, align 1
  %conv23.25.20 = zext i8 %8612 to i32
  %8613 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.20 = getelementptr i8, i8* %b, i64 46
  %8614 = load i8, i8* %scevgep34.25.20, align 1
  %call28.25.20 = call zeroext i8 @mult(i8 zeroext %8613, i8 zeroext %8614)
  %conv29.25.20 = zext i8 %call28.25.20 to i32
  %xor.25.20 = xor i32 %conv23.25.20, %conv29.25.20
  %scevgep35.25.20 = getelementptr i8, i8* %a, i64 46
  %8615 = load i8, i8* %scevgep35.25.20, align 1
  %8616 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.20 = call zeroext i8 @mult(i8 zeroext %8615, i8 zeroext %8616)
  %conv35.25.20 = zext i8 %call34.25.20 to i32
  %xor36.25.20 = xor i32 %xor.25.20, %conv35.25.20
  %conv37.25.20 = trunc i32 %xor36.25.20 to i8
  store i8 %conv37.25.20, i8* %scevgep41.25.19, align 1
  %scevgep28.25.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8610, i64 0, i64 0, i64 1
  %8617 = bitcast i8* %scevgep28.25.20 to [61 x [61 x i8]]*
  %scevgep41.25.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8611, i64 0, i64 1, i64 0
  %8618 = bitcast i8* %scevgep41.25.20 to [61 x [61 x i8]]*
  %call16.25.21 = call zeroext i8 (...) @rand()
  store i8 %call16.25.21, i8* %scevgep28.25.20, align 1
  %8619 = load i8, i8* %scevgep28.25.20, align 1
  %conv23.25.21 = zext i8 %8619 to i32
  %8620 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.21 = getelementptr i8, i8* %b, i64 47
  %8621 = load i8, i8* %scevgep34.25.21, align 1
  %call28.25.21 = call zeroext i8 @mult(i8 zeroext %8620, i8 zeroext %8621)
  %conv29.25.21 = zext i8 %call28.25.21 to i32
  %xor.25.21 = xor i32 %conv23.25.21, %conv29.25.21
  %scevgep35.25.21 = getelementptr i8, i8* %a, i64 47
  %8622 = load i8, i8* %scevgep35.25.21, align 1
  %8623 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.21 = call zeroext i8 @mult(i8 zeroext %8622, i8 zeroext %8623)
  %conv35.25.21 = zext i8 %call34.25.21 to i32
  %xor36.25.21 = xor i32 %xor.25.21, %conv35.25.21
  %conv37.25.21 = trunc i32 %xor36.25.21 to i8
  store i8 %conv37.25.21, i8* %scevgep41.25.20, align 1
  %scevgep28.25.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8617, i64 0, i64 0, i64 1
  %8624 = bitcast i8* %scevgep28.25.21 to [61 x [61 x i8]]*
  %scevgep41.25.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8618, i64 0, i64 1, i64 0
  %8625 = bitcast i8* %scevgep41.25.21 to [61 x [61 x i8]]*
  %call16.25.22 = call zeroext i8 (...) @rand()
  store i8 %call16.25.22, i8* %scevgep28.25.21, align 1
  %8626 = load i8, i8* %scevgep28.25.21, align 1
  %conv23.25.22 = zext i8 %8626 to i32
  %8627 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.22 = getelementptr i8, i8* %b, i64 48
  %8628 = load i8, i8* %scevgep34.25.22, align 1
  %call28.25.22 = call zeroext i8 @mult(i8 zeroext %8627, i8 zeroext %8628)
  %conv29.25.22 = zext i8 %call28.25.22 to i32
  %xor.25.22 = xor i32 %conv23.25.22, %conv29.25.22
  %scevgep35.25.22 = getelementptr i8, i8* %a, i64 48
  %8629 = load i8, i8* %scevgep35.25.22, align 1
  %8630 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.22 = call zeroext i8 @mult(i8 zeroext %8629, i8 zeroext %8630)
  %conv35.25.22 = zext i8 %call34.25.22 to i32
  %xor36.25.22 = xor i32 %xor.25.22, %conv35.25.22
  %conv37.25.22 = trunc i32 %xor36.25.22 to i8
  store i8 %conv37.25.22, i8* %scevgep41.25.21, align 1
  %scevgep28.25.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8624, i64 0, i64 0, i64 1
  %8631 = bitcast i8* %scevgep28.25.22 to [61 x [61 x i8]]*
  %scevgep41.25.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8625, i64 0, i64 1, i64 0
  %8632 = bitcast i8* %scevgep41.25.22 to [61 x [61 x i8]]*
  %call16.25.23 = call zeroext i8 (...) @rand()
  store i8 %call16.25.23, i8* %scevgep28.25.22, align 1
  %8633 = load i8, i8* %scevgep28.25.22, align 1
  %conv23.25.23 = zext i8 %8633 to i32
  %8634 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.23 = getelementptr i8, i8* %b, i64 49
  %8635 = load i8, i8* %scevgep34.25.23, align 1
  %call28.25.23 = call zeroext i8 @mult(i8 zeroext %8634, i8 zeroext %8635)
  %conv29.25.23 = zext i8 %call28.25.23 to i32
  %xor.25.23 = xor i32 %conv23.25.23, %conv29.25.23
  %scevgep35.25.23 = getelementptr i8, i8* %a, i64 49
  %8636 = load i8, i8* %scevgep35.25.23, align 1
  %8637 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.23 = call zeroext i8 @mult(i8 zeroext %8636, i8 zeroext %8637)
  %conv35.25.23 = zext i8 %call34.25.23 to i32
  %xor36.25.23 = xor i32 %xor.25.23, %conv35.25.23
  %conv37.25.23 = trunc i32 %xor36.25.23 to i8
  store i8 %conv37.25.23, i8* %scevgep41.25.22, align 1
  %scevgep28.25.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8631, i64 0, i64 0, i64 1
  %8638 = bitcast i8* %scevgep28.25.23 to [61 x [61 x i8]]*
  %scevgep41.25.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8632, i64 0, i64 1, i64 0
  %8639 = bitcast i8* %scevgep41.25.23 to [61 x [61 x i8]]*
  %call16.25.24 = call zeroext i8 (...) @rand()
  store i8 %call16.25.24, i8* %scevgep28.25.23, align 1
  %8640 = load i8, i8* %scevgep28.25.23, align 1
  %conv23.25.24 = zext i8 %8640 to i32
  %8641 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.24 = getelementptr i8, i8* %b, i64 50
  %8642 = load i8, i8* %scevgep34.25.24, align 1
  %call28.25.24 = call zeroext i8 @mult(i8 zeroext %8641, i8 zeroext %8642)
  %conv29.25.24 = zext i8 %call28.25.24 to i32
  %xor.25.24 = xor i32 %conv23.25.24, %conv29.25.24
  %scevgep35.25.24 = getelementptr i8, i8* %a, i64 50
  %8643 = load i8, i8* %scevgep35.25.24, align 1
  %8644 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.24 = call zeroext i8 @mult(i8 zeroext %8643, i8 zeroext %8644)
  %conv35.25.24 = zext i8 %call34.25.24 to i32
  %xor36.25.24 = xor i32 %xor.25.24, %conv35.25.24
  %conv37.25.24 = trunc i32 %xor36.25.24 to i8
  store i8 %conv37.25.24, i8* %scevgep41.25.23, align 1
  %scevgep28.25.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8638, i64 0, i64 0, i64 1
  %8645 = bitcast i8* %scevgep28.25.24 to [61 x [61 x i8]]*
  %scevgep41.25.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8639, i64 0, i64 1, i64 0
  %8646 = bitcast i8* %scevgep41.25.24 to [61 x [61 x i8]]*
  %call16.25.25 = call zeroext i8 (...) @rand()
  store i8 %call16.25.25, i8* %scevgep28.25.24, align 1
  %8647 = load i8, i8* %scevgep28.25.24, align 1
  %conv23.25.25 = zext i8 %8647 to i32
  %8648 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.25 = getelementptr i8, i8* %b, i64 51
  %8649 = load i8, i8* %scevgep34.25.25, align 1
  %call28.25.25 = call zeroext i8 @mult(i8 zeroext %8648, i8 zeroext %8649)
  %conv29.25.25 = zext i8 %call28.25.25 to i32
  %xor.25.25 = xor i32 %conv23.25.25, %conv29.25.25
  %scevgep35.25.25 = getelementptr i8, i8* %a, i64 51
  %8650 = load i8, i8* %scevgep35.25.25, align 1
  %8651 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.25 = call zeroext i8 @mult(i8 zeroext %8650, i8 zeroext %8651)
  %conv35.25.25 = zext i8 %call34.25.25 to i32
  %xor36.25.25 = xor i32 %xor.25.25, %conv35.25.25
  %conv37.25.25 = trunc i32 %xor36.25.25 to i8
  store i8 %conv37.25.25, i8* %scevgep41.25.24, align 1
  %scevgep28.25.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8645, i64 0, i64 0, i64 1
  %8652 = bitcast i8* %scevgep28.25.25 to [61 x [61 x i8]]*
  %scevgep41.25.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8646, i64 0, i64 1, i64 0
  %8653 = bitcast i8* %scevgep41.25.25 to [61 x [61 x i8]]*
  %call16.25.26 = call zeroext i8 (...) @rand()
  store i8 %call16.25.26, i8* %scevgep28.25.25, align 1
  %8654 = load i8, i8* %scevgep28.25.25, align 1
  %conv23.25.26 = zext i8 %8654 to i32
  %8655 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.26 = getelementptr i8, i8* %b, i64 52
  %8656 = load i8, i8* %scevgep34.25.26, align 1
  %call28.25.26 = call zeroext i8 @mult(i8 zeroext %8655, i8 zeroext %8656)
  %conv29.25.26 = zext i8 %call28.25.26 to i32
  %xor.25.26 = xor i32 %conv23.25.26, %conv29.25.26
  %scevgep35.25.26 = getelementptr i8, i8* %a, i64 52
  %8657 = load i8, i8* %scevgep35.25.26, align 1
  %8658 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.26 = call zeroext i8 @mult(i8 zeroext %8657, i8 zeroext %8658)
  %conv35.25.26 = zext i8 %call34.25.26 to i32
  %xor36.25.26 = xor i32 %xor.25.26, %conv35.25.26
  %conv37.25.26 = trunc i32 %xor36.25.26 to i8
  store i8 %conv37.25.26, i8* %scevgep41.25.25, align 1
  %scevgep28.25.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8652, i64 0, i64 0, i64 1
  %8659 = bitcast i8* %scevgep28.25.26 to [61 x [61 x i8]]*
  %scevgep41.25.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8653, i64 0, i64 1, i64 0
  %8660 = bitcast i8* %scevgep41.25.26 to [61 x [61 x i8]]*
  %call16.25.27 = call zeroext i8 (...) @rand()
  store i8 %call16.25.27, i8* %scevgep28.25.26, align 1
  %8661 = load i8, i8* %scevgep28.25.26, align 1
  %conv23.25.27 = zext i8 %8661 to i32
  %8662 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.27 = getelementptr i8, i8* %b, i64 53
  %8663 = load i8, i8* %scevgep34.25.27, align 1
  %call28.25.27 = call zeroext i8 @mult(i8 zeroext %8662, i8 zeroext %8663)
  %conv29.25.27 = zext i8 %call28.25.27 to i32
  %xor.25.27 = xor i32 %conv23.25.27, %conv29.25.27
  %scevgep35.25.27 = getelementptr i8, i8* %a, i64 53
  %8664 = load i8, i8* %scevgep35.25.27, align 1
  %8665 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.27 = call zeroext i8 @mult(i8 zeroext %8664, i8 zeroext %8665)
  %conv35.25.27 = zext i8 %call34.25.27 to i32
  %xor36.25.27 = xor i32 %xor.25.27, %conv35.25.27
  %conv37.25.27 = trunc i32 %xor36.25.27 to i8
  store i8 %conv37.25.27, i8* %scevgep41.25.26, align 1
  %scevgep28.25.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8659, i64 0, i64 0, i64 1
  %8666 = bitcast i8* %scevgep28.25.27 to [61 x [61 x i8]]*
  %scevgep41.25.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8660, i64 0, i64 1, i64 0
  %8667 = bitcast i8* %scevgep41.25.27 to [61 x [61 x i8]]*
  %call16.25.28 = call zeroext i8 (...) @rand()
  store i8 %call16.25.28, i8* %scevgep28.25.27, align 1
  %8668 = load i8, i8* %scevgep28.25.27, align 1
  %conv23.25.28 = zext i8 %8668 to i32
  %8669 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.28 = getelementptr i8, i8* %b, i64 54
  %8670 = load i8, i8* %scevgep34.25.28, align 1
  %call28.25.28 = call zeroext i8 @mult(i8 zeroext %8669, i8 zeroext %8670)
  %conv29.25.28 = zext i8 %call28.25.28 to i32
  %xor.25.28 = xor i32 %conv23.25.28, %conv29.25.28
  %scevgep35.25.28 = getelementptr i8, i8* %a, i64 54
  %8671 = load i8, i8* %scevgep35.25.28, align 1
  %8672 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.28 = call zeroext i8 @mult(i8 zeroext %8671, i8 zeroext %8672)
  %conv35.25.28 = zext i8 %call34.25.28 to i32
  %xor36.25.28 = xor i32 %xor.25.28, %conv35.25.28
  %conv37.25.28 = trunc i32 %xor36.25.28 to i8
  store i8 %conv37.25.28, i8* %scevgep41.25.27, align 1
  %scevgep28.25.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8666, i64 0, i64 0, i64 1
  %8673 = bitcast i8* %scevgep28.25.28 to [61 x [61 x i8]]*
  %scevgep41.25.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8667, i64 0, i64 1, i64 0
  %8674 = bitcast i8* %scevgep41.25.28 to [61 x [61 x i8]]*
  %call16.25.29 = call zeroext i8 (...) @rand()
  store i8 %call16.25.29, i8* %scevgep28.25.28, align 1
  %8675 = load i8, i8* %scevgep28.25.28, align 1
  %conv23.25.29 = zext i8 %8675 to i32
  %8676 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.29 = getelementptr i8, i8* %b, i64 55
  %8677 = load i8, i8* %scevgep34.25.29, align 1
  %call28.25.29 = call zeroext i8 @mult(i8 zeroext %8676, i8 zeroext %8677)
  %conv29.25.29 = zext i8 %call28.25.29 to i32
  %xor.25.29 = xor i32 %conv23.25.29, %conv29.25.29
  %scevgep35.25.29 = getelementptr i8, i8* %a, i64 55
  %8678 = load i8, i8* %scevgep35.25.29, align 1
  %8679 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.29 = call zeroext i8 @mult(i8 zeroext %8678, i8 zeroext %8679)
  %conv35.25.29 = zext i8 %call34.25.29 to i32
  %xor36.25.29 = xor i32 %xor.25.29, %conv35.25.29
  %conv37.25.29 = trunc i32 %xor36.25.29 to i8
  store i8 %conv37.25.29, i8* %scevgep41.25.28, align 1
  %scevgep28.25.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8673, i64 0, i64 0, i64 1
  %8680 = bitcast i8* %scevgep28.25.29 to [61 x [61 x i8]]*
  %scevgep41.25.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8674, i64 0, i64 1, i64 0
  %8681 = bitcast i8* %scevgep41.25.29 to [61 x [61 x i8]]*
  %call16.25.30 = call zeroext i8 (...) @rand()
  store i8 %call16.25.30, i8* %scevgep28.25.29, align 1
  %8682 = load i8, i8* %scevgep28.25.29, align 1
  %conv23.25.30 = zext i8 %8682 to i32
  %8683 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.30 = getelementptr i8, i8* %b, i64 56
  %8684 = load i8, i8* %scevgep34.25.30, align 1
  %call28.25.30 = call zeroext i8 @mult(i8 zeroext %8683, i8 zeroext %8684)
  %conv29.25.30 = zext i8 %call28.25.30 to i32
  %xor.25.30 = xor i32 %conv23.25.30, %conv29.25.30
  %scevgep35.25.30 = getelementptr i8, i8* %a, i64 56
  %8685 = load i8, i8* %scevgep35.25.30, align 1
  %8686 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.30 = call zeroext i8 @mult(i8 zeroext %8685, i8 zeroext %8686)
  %conv35.25.30 = zext i8 %call34.25.30 to i32
  %xor36.25.30 = xor i32 %xor.25.30, %conv35.25.30
  %conv37.25.30 = trunc i32 %xor36.25.30 to i8
  store i8 %conv37.25.30, i8* %scevgep41.25.29, align 1
  %scevgep28.25.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8680, i64 0, i64 0, i64 1
  %8687 = bitcast i8* %scevgep28.25.30 to [61 x [61 x i8]]*
  %scevgep41.25.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8681, i64 0, i64 1, i64 0
  %8688 = bitcast i8* %scevgep41.25.30 to [61 x [61 x i8]]*
  %call16.25.31 = call zeroext i8 (...) @rand()
  store i8 %call16.25.31, i8* %scevgep28.25.30, align 1
  %8689 = load i8, i8* %scevgep28.25.30, align 1
  %conv23.25.31 = zext i8 %8689 to i32
  %8690 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.31 = getelementptr i8, i8* %b, i64 57
  %8691 = load i8, i8* %scevgep34.25.31, align 1
  %call28.25.31 = call zeroext i8 @mult(i8 zeroext %8690, i8 zeroext %8691)
  %conv29.25.31 = zext i8 %call28.25.31 to i32
  %xor.25.31 = xor i32 %conv23.25.31, %conv29.25.31
  %scevgep35.25.31 = getelementptr i8, i8* %a, i64 57
  %8692 = load i8, i8* %scevgep35.25.31, align 1
  %8693 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.31 = call zeroext i8 @mult(i8 zeroext %8692, i8 zeroext %8693)
  %conv35.25.31 = zext i8 %call34.25.31 to i32
  %xor36.25.31 = xor i32 %xor.25.31, %conv35.25.31
  %conv37.25.31 = trunc i32 %xor36.25.31 to i8
  store i8 %conv37.25.31, i8* %scevgep41.25.30, align 1
  %scevgep28.25.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8687, i64 0, i64 0, i64 1
  %8694 = bitcast i8* %scevgep28.25.31 to [61 x [61 x i8]]*
  %scevgep41.25.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8688, i64 0, i64 1, i64 0
  %8695 = bitcast i8* %scevgep41.25.31 to [61 x [61 x i8]]*
  %call16.25.32 = call zeroext i8 (...) @rand()
  store i8 %call16.25.32, i8* %scevgep28.25.31, align 1
  %8696 = load i8, i8* %scevgep28.25.31, align 1
  %conv23.25.32 = zext i8 %8696 to i32
  %8697 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.32 = getelementptr i8, i8* %b, i64 58
  %8698 = load i8, i8* %scevgep34.25.32, align 1
  %call28.25.32 = call zeroext i8 @mult(i8 zeroext %8697, i8 zeroext %8698)
  %conv29.25.32 = zext i8 %call28.25.32 to i32
  %xor.25.32 = xor i32 %conv23.25.32, %conv29.25.32
  %scevgep35.25.32 = getelementptr i8, i8* %a, i64 58
  %8699 = load i8, i8* %scevgep35.25.32, align 1
  %8700 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.32 = call zeroext i8 @mult(i8 zeroext %8699, i8 zeroext %8700)
  %conv35.25.32 = zext i8 %call34.25.32 to i32
  %xor36.25.32 = xor i32 %xor.25.32, %conv35.25.32
  %conv37.25.32 = trunc i32 %xor36.25.32 to i8
  store i8 %conv37.25.32, i8* %scevgep41.25.31, align 1
  %scevgep28.25.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8694, i64 0, i64 0, i64 1
  %8701 = bitcast i8* %scevgep28.25.32 to [61 x [61 x i8]]*
  %scevgep41.25.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8695, i64 0, i64 1, i64 0
  %8702 = bitcast i8* %scevgep41.25.32 to [61 x [61 x i8]]*
  %call16.25.33 = call zeroext i8 (...) @rand()
  store i8 %call16.25.33, i8* %scevgep28.25.32, align 1
  %8703 = load i8, i8* %scevgep28.25.32, align 1
  %conv23.25.33 = zext i8 %8703 to i32
  %8704 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.33 = getelementptr i8, i8* %b, i64 59
  %8705 = load i8, i8* %scevgep34.25.33, align 1
  %call28.25.33 = call zeroext i8 @mult(i8 zeroext %8704, i8 zeroext %8705)
  %conv29.25.33 = zext i8 %call28.25.33 to i32
  %xor.25.33 = xor i32 %conv23.25.33, %conv29.25.33
  %scevgep35.25.33 = getelementptr i8, i8* %a, i64 59
  %8706 = load i8, i8* %scevgep35.25.33, align 1
  %8707 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.33 = call zeroext i8 @mult(i8 zeroext %8706, i8 zeroext %8707)
  %conv35.25.33 = zext i8 %call34.25.33 to i32
  %xor36.25.33 = xor i32 %xor.25.33, %conv35.25.33
  %conv37.25.33 = trunc i32 %xor36.25.33 to i8
  store i8 %conv37.25.33, i8* %scevgep41.25.32, align 1
  %scevgep28.25.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8701, i64 0, i64 0, i64 1
  %scevgep41.25.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8702, i64 0, i64 1, i64 0
  %call16.25.34 = call zeroext i8 (...) @rand()
  store i8 %call16.25.34, i8* %scevgep28.25.33, align 1
  %8708 = load i8, i8* %scevgep28.25.33, align 1
  %conv23.25.34 = zext i8 %8708 to i32
  %8709 = load i8, i8* %arrayidx25.25, align 1
  %scevgep34.25.34 = getelementptr i8, i8* %b, i64 60
  %8710 = load i8, i8* %scevgep34.25.34, align 1
  %call28.25.34 = call zeroext i8 @mult(i8 zeroext %8709, i8 zeroext %8710)
  %conv29.25.34 = zext i8 %call28.25.34 to i32
  %xor.25.34 = xor i32 %conv23.25.34, %conv29.25.34
  %scevgep35.25.34 = getelementptr i8, i8* %a, i64 60
  %8711 = load i8, i8* %scevgep35.25.34, align 1
  %8712 = load i8, i8* %arrayidx33.25, align 1
  %call34.25.34 = call zeroext i8 @mult(i8 zeroext %8711, i8 zeroext %8712)
  %conv35.25.34 = zext i8 %call34.25.34 to i32
  %xor36.25.34 = xor i32 %xor.25.34, %conv35.25.34
  %conv37.25.34 = trunc i32 %xor36.25.34 to i8
  store i8 %conv37.25.34, i8* %scevgep41.25.33, align 1
  %scevgep26.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8470, i64 0, i64 1, i64 1
  %8713 = bitcast i8* %scevgep26.25 to [61 x [61 x i8]]*
  %scevgep39.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8471, i64 0, i64 1, i64 1
  %8714 = bitcast i8* %scevgep39.25 to [61 x [61 x i8]]*
  %arrayidx25.26 = getelementptr inbounds i8, i8* %a, i64 26
  %arrayidx33.26 = getelementptr inbounds i8, i8* %b, i64 26
  %call16.26 = call zeroext i8 (...) @rand()
  store i8 %call16.26, i8* %scevgep26.25, align 1
  %8715 = load i8, i8* %scevgep26.25, align 1
  %conv23.26 = zext i8 %8715 to i32
  %8716 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26 = getelementptr i8, i8* %b, i64 27
  %8717 = load i8, i8* %scevgep34.26, align 1
  %call28.26 = call zeroext i8 @mult(i8 zeroext %8716, i8 zeroext %8717)
  %conv29.26 = zext i8 %call28.26 to i32
  %xor.26 = xor i32 %conv23.26, %conv29.26
  %scevgep35.26 = getelementptr i8, i8* %a, i64 27
  %8718 = load i8, i8* %scevgep35.26, align 1
  %8719 = load i8, i8* %arrayidx33.26, align 1
  %call34.26 = call zeroext i8 @mult(i8 zeroext %8718, i8 zeroext %8719)
  %conv35.26 = zext i8 %call34.26 to i32
  %xor36.26 = xor i32 %xor.26, %conv35.26
  %conv37.26 = trunc i32 %xor36.26 to i8
  store i8 %conv37.26, i8* %scevgep39.25, align 1
  %scevgep28.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8713, i64 0, i64 0, i64 1
  %8720 = bitcast i8* %scevgep28.26 to [61 x [61 x i8]]*
  %scevgep41.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8714, i64 0, i64 1, i64 0
  %8721 = bitcast i8* %scevgep41.26 to [61 x [61 x i8]]*
  %call16.26.1 = call zeroext i8 (...) @rand()
  store i8 %call16.26.1, i8* %scevgep28.26, align 1
  %8722 = load i8, i8* %scevgep28.26, align 1
  %conv23.26.1 = zext i8 %8722 to i32
  %8723 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.1 = getelementptr i8, i8* %b, i64 28
  %8724 = load i8, i8* %scevgep34.26.1, align 1
  %call28.26.1 = call zeroext i8 @mult(i8 zeroext %8723, i8 zeroext %8724)
  %conv29.26.1 = zext i8 %call28.26.1 to i32
  %xor.26.1 = xor i32 %conv23.26.1, %conv29.26.1
  %scevgep35.26.1 = getelementptr i8, i8* %a, i64 28
  %8725 = load i8, i8* %scevgep35.26.1, align 1
  %8726 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.1 = call zeroext i8 @mult(i8 zeroext %8725, i8 zeroext %8726)
  %conv35.26.1 = zext i8 %call34.26.1 to i32
  %xor36.26.1 = xor i32 %xor.26.1, %conv35.26.1
  %conv37.26.1 = trunc i32 %xor36.26.1 to i8
  store i8 %conv37.26.1, i8* %scevgep41.26, align 1
  %scevgep28.26.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8720, i64 0, i64 0, i64 1
  %8727 = bitcast i8* %scevgep28.26.1 to [61 x [61 x i8]]*
  %scevgep41.26.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8721, i64 0, i64 1, i64 0
  %8728 = bitcast i8* %scevgep41.26.1 to [61 x [61 x i8]]*
  %call16.26.2 = call zeroext i8 (...) @rand()
  store i8 %call16.26.2, i8* %scevgep28.26.1, align 1
  %8729 = load i8, i8* %scevgep28.26.1, align 1
  %conv23.26.2 = zext i8 %8729 to i32
  %8730 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.2 = getelementptr i8, i8* %b, i64 29
  %8731 = load i8, i8* %scevgep34.26.2, align 1
  %call28.26.2 = call zeroext i8 @mult(i8 zeroext %8730, i8 zeroext %8731)
  %conv29.26.2 = zext i8 %call28.26.2 to i32
  %xor.26.2 = xor i32 %conv23.26.2, %conv29.26.2
  %scevgep35.26.2 = getelementptr i8, i8* %a, i64 29
  %8732 = load i8, i8* %scevgep35.26.2, align 1
  %8733 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.2 = call zeroext i8 @mult(i8 zeroext %8732, i8 zeroext %8733)
  %conv35.26.2 = zext i8 %call34.26.2 to i32
  %xor36.26.2 = xor i32 %xor.26.2, %conv35.26.2
  %conv37.26.2 = trunc i32 %xor36.26.2 to i8
  store i8 %conv37.26.2, i8* %scevgep41.26.1, align 1
  %scevgep28.26.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8727, i64 0, i64 0, i64 1
  %8734 = bitcast i8* %scevgep28.26.2 to [61 x [61 x i8]]*
  %scevgep41.26.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8728, i64 0, i64 1, i64 0
  %8735 = bitcast i8* %scevgep41.26.2 to [61 x [61 x i8]]*
  %call16.26.3 = call zeroext i8 (...) @rand()
  store i8 %call16.26.3, i8* %scevgep28.26.2, align 1
  %8736 = load i8, i8* %scevgep28.26.2, align 1
  %conv23.26.3 = zext i8 %8736 to i32
  %8737 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.3 = getelementptr i8, i8* %b, i64 30
  %8738 = load i8, i8* %scevgep34.26.3, align 1
  %call28.26.3 = call zeroext i8 @mult(i8 zeroext %8737, i8 zeroext %8738)
  %conv29.26.3 = zext i8 %call28.26.3 to i32
  %xor.26.3 = xor i32 %conv23.26.3, %conv29.26.3
  %scevgep35.26.3 = getelementptr i8, i8* %a, i64 30
  %8739 = load i8, i8* %scevgep35.26.3, align 1
  %8740 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.3 = call zeroext i8 @mult(i8 zeroext %8739, i8 zeroext %8740)
  %conv35.26.3 = zext i8 %call34.26.3 to i32
  %xor36.26.3 = xor i32 %xor.26.3, %conv35.26.3
  %conv37.26.3 = trunc i32 %xor36.26.3 to i8
  store i8 %conv37.26.3, i8* %scevgep41.26.2, align 1
  %scevgep28.26.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8734, i64 0, i64 0, i64 1
  %8741 = bitcast i8* %scevgep28.26.3 to [61 x [61 x i8]]*
  %scevgep41.26.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8735, i64 0, i64 1, i64 0
  %8742 = bitcast i8* %scevgep41.26.3 to [61 x [61 x i8]]*
  %call16.26.4 = call zeroext i8 (...) @rand()
  store i8 %call16.26.4, i8* %scevgep28.26.3, align 1
  %8743 = load i8, i8* %scevgep28.26.3, align 1
  %conv23.26.4 = zext i8 %8743 to i32
  %8744 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.4 = getelementptr i8, i8* %b, i64 31
  %8745 = load i8, i8* %scevgep34.26.4, align 1
  %call28.26.4 = call zeroext i8 @mult(i8 zeroext %8744, i8 zeroext %8745)
  %conv29.26.4 = zext i8 %call28.26.4 to i32
  %xor.26.4 = xor i32 %conv23.26.4, %conv29.26.4
  %scevgep35.26.4 = getelementptr i8, i8* %a, i64 31
  %8746 = load i8, i8* %scevgep35.26.4, align 1
  %8747 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.4 = call zeroext i8 @mult(i8 zeroext %8746, i8 zeroext %8747)
  %conv35.26.4 = zext i8 %call34.26.4 to i32
  %xor36.26.4 = xor i32 %xor.26.4, %conv35.26.4
  %conv37.26.4 = trunc i32 %xor36.26.4 to i8
  store i8 %conv37.26.4, i8* %scevgep41.26.3, align 1
  %scevgep28.26.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8741, i64 0, i64 0, i64 1
  %8748 = bitcast i8* %scevgep28.26.4 to [61 x [61 x i8]]*
  %scevgep41.26.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8742, i64 0, i64 1, i64 0
  %8749 = bitcast i8* %scevgep41.26.4 to [61 x [61 x i8]]*
  %call16.26.5 = call zeroext i8 (...) @rand()
  store i8 %call16.26.5, i8* %scevgep28.26.4, align 1
  %8750 = load i8, i8* %scevgep28.26.4, align 1
  %conv23.26.5 = zext i8 %8750 to i32
  %8751 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.5 = getelementptr i8, i8* %b, i64 32
  %8752 = load i8, i8* %scevgep34.26.5, align 1
  %call28.26.5 = call zeroext i8 @mult(i8 zeroext %8751, i8 zeroext %8752)
  %conv29.26.5 = zext i8 %call28.26.5 to i32
  %xor.26.5 = xor i32 %conv23.26.5, %conv29.26.5
  %scevgep35.26.5 = getelementptr i8, i8* %a, i64 32
  %8753 = load i8, i8* %scevgep35.26.5, align 1
  %8754 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.5 = call zeroext i8 @mult(i8 zeroext %8753, i8 zeroext %8754)
  %conv35.26.5 = zext i8 %call34.26.5 to i32
  %xor36.26.5 = xor i32 %xor.26.5, %conv35.26.5
  %conv37.26.5 = trunc i32 %xor36.26.5 to i8
  store i8 %conv37.26.5, i8* %scevgep41.26.4, align 1
  %scevgep28.26.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8748, i64 0, i64 0, i64 1
  %8755 = bitcast i8* %scevgep28.26.5 to [61 x [61 x i8]]*
  %scevgep41.26.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8749, i64 0, i64 1, i64 0
  %8756 = bitcast i8* %scevgep41.26.5 to [61 x [61 x i8]]*
  %call16.26.6 = call zeroext i8 (...) @rand()
  store i8 %call16.26.6, i8* %scevgep28.26.5, align 1
  %8757 = load i8, i8* %scevgep28.26.5, align 1
  %conv23.26.6 = zext i8 %8757 to i32
  %8758 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.6 = getelementptr i8, i8* %b, i64 33
  %8759 = load i8, i8* %scevgep34.26.6, align 1
  %call28.26.6 = call zeroext i8 @mult(i8 zeroext %8758, i8 zeroext %8759)
  %conv29.26.6 = zext i8 %call28.26.6 to i32
  %xor.26.6 = xor i32 %conv23.26.6, %conv29.26.6
  %scevgep35.26.6 = getelementptr i8, i8* %a, i64 33
  %8760 = load i8, i8* %scevgep35.26.6, align 1
  %8761 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.6 = call zeroext i8 @mult(i8 zeroext %8760, i8 zeroext %8761)
  %conv35.26.6 = zext i8 %call34.26.6 to i32
  %xor36.26.6 = xor i32 %xor.26.6, %conv35.26.6
  %conv37.26.6 = trunc i32 %xor36.26.6 to i8
  store i8 %conv37.26.6, i8* %scevgep41.26.5, align 1
  %scevgep28.26.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8755, i64 0, i64 0, i64 1
  %8762 = bitcast i8* %scevgep28.26.6 to [61 x [61 x i8]]*
  %scevgep41.26.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8756, i64 0, i64 1, i64 0
  %8763 = bitcast i8* %scevgep41.26.6 to [61 x [61 x i8]]*
  %call16.26.7 = call zeroext i8 (...) @rand()
  store i8 %call16.26.7, i8* %scevgep28.26.6, align 1
  %8764 = load i8, i8* %scevgep28.26.6, align 1
  %conv23.26.7 = zext i8 %8764 to i32
  %8765 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.7 = getelementptr i8, i8* %b, i64 34
  %8766 = load i8, i8* %scevgep34.26.7, align 1
  %call28.26.7 = call zeroext i8 @mult(i8 zeroext %8765, i8 zeroext %8766)
  %conv29.26.7 = zext i8 %call28.26.7 to i32
  %xor.26.7 = xor i32 %conv23.26.7, %conv29.26.7
  %scevgep35.26.7 = getelementptr i8, i8* %a, i64 34
  %8767 = load i8, i8* %scevgep35.26.7, align 1
  %8768 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.7 = call zeroext i8 @mult(i8 zeroext %8767, i8 zeroext %8768)
  %conv35.26.7 = zext i8 %call34.26.7 to i32
  %xor36.26.7 = xor i32 %xor.26.7, %conv35.26.7
  %conv37.26.7 = trunc i32 %xor36.26.7 to i8
  store i8 %conv37.26.7, i8* %scevgep41.26.6, align 1
  %scevgep28.26.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8762, i64 0, i64 0, i64 1
  %8769 = bitcast i8* %scevgep28.26.7 to [61 x [61 x i8]]*
  %scevgep41.26.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8763, i64 0, i64 1, i64 0
  %8770 = bitcast i8* %scevgep41.26.7 to [61 x [61 x i8]]*
  %call16.26.8 = call zeroext i8 (...) @rand()
  store i8 %call16.26.8, i8* %scevgep28.26.7, align 1
  %8771 = load i8, i8* %scevgep28.26.7, align 1
  %conv23.26.8 = zext i8 %8771 to i32
  %8772 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.8 = getelementptr i8, i8* %b, i64 35
  %8773 = load i8, i8* %scevgep34.26.8, align 1
  %call28.26.8 = call zeroext i8 @mult(i8 zeroext %8772, i8 zeroext %8773)
  %conv29.26.8 = zext i8 %call28.26.8 to i32
  %xor.26.8 = xor i32 %conv23.26.8, %conv29.26.8
  %scevgep35.26.8 = getelementptr i8, i8* %a, i64 35
  %8774 = load i8, i8* %scevgep35.26.8, align 1
  %8775 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.8 = call zeroext i8 @mult(i8 zeroext %8774, i8 zeroext %8775)
  %conv35.26.8 = zext i8 %call34.26.8 to i32
  %xor36.26.8 = xor i32 %xor.26.8, %conv35.26.8
  %conv37.26.8 = trunc i32 %xor36.26.8 to i8
  store i8 %conv37.26.8, i8* %scevgep41.26.7, align 1
  %scevgep28.26.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8769, i64 0, i64 0, i64 1
  %8776 = bitcast i8* %scevgep28.26.8 to [61 x [61 x i8]]*
  %scevgep41.26.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8770, i64 0, i64 1, i64 0
  %8777 = bitcast i8* %scevgep41.26.8 to [61 x [61 x i8]]*
  %call16.26.9 = call zeroext i8 (...) @rand()
  store i8 %call16.26.9, i8* %scevgep28.26.8, align 1
  %8778 = load i8, i8* %scevgep28.26.8, align 1
  %conv23.26.9 = zext i8 %8778 to i32
  %8779 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.9 = getelementptr i8, i8* %b, i64 36
  %8780 = load i8, i8* %scevgep34.26.9, align 1
  %call28.26.9 = call zeroext i8 @mult(i8 zeroext %8779, i8 zeroext %8780)
  %conv29.26.9 = zext i8 %call28.26.9 to i32
  %xor.26.9 = xor i32 %conv23.26.9, %conv29.26.9
  %scevgep35.26.9 = getelementptr i8, i8* %a, i64 36
  %8781 = load i8, i8* %scevgep35.26.9, align 1
  %8782 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.9 = call zeroext i8 @mult(i8 zeroext %8781, i8 zeroext %8782)
  %conv35.26.9 = zext i8 %call34.26.9 to i32
  %xor36.26.9 = xor i32 %xor.26.9, %conv35.26.9
  %conv37.26.9 = trunc i32 %xor36.26.9 to i8
  store i8 %conv37.26.9, i8* %scevgep41.26.8, align 1
  %scevgep28.26.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8776, i64 0, i64 0, i64 1
  %8783 = bitcast i8* %scevgep28.26.9 to [61 x [61 x i8]]*
  %scevgep41.26.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8777, i64 0, i64 1, i64 0
  %8784 = bitcast i8* %scevgep41.26.9 to [61 x [61 x i8]]*
  %call16.26.10 = call zeroext i8 (...) @rand()
  store i8 %call16.26.10, i8* %scevgep28.26.9, align 1
  %8785 = load i8, i8* %scevgep28.26.9, align 1
  %conv23.26.10 = zext i8 %8785 to i32
  %8786 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.10 = getelementptr i8, i8* %b, i64 37
  %8787 = load i8, i8* %scevgep34.26.10, align 1
  %call28.26.10 = call zeroext i8 @mult(i8 zeroext %8786, i8 zeroext %8787)
  %conv29.26.10 = zext i8 %call28.26.10 to i32
  %xor.26.10 = xor i32 %conv23.26.10, %conv29.26.10
  %scevgep35.26.10 = getelementptr i8, i8* %a, i64 37
  %8788 = load i8, i8* %scevgep35.26.10, align 1
  %8789 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.10 = call zeroext i8 @mult(i8 zeroext %8788, i8 zeroext %8789)
  %conv35.26.10 = zext i8 %call34.26.10 to i32
  %xor36.26.10 = xor i32 %xor.26.10, %conv35.26.10
  %conv37.26.10 = trunc i32 %xor36.26.10 to i8
  store i8 %conv37.26.10, i8* %scevgep41.26.9, align 1
  %scevgep28.26.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8783, i64 0, i64 0, i64 1
  %8790 = bitcast i8* %scevgep28.26.10 to [61 x [61 x i8]]*
  %scevgep41.26.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8784, i64 0, i64 1, i64 0
  %8791 = bitcast i8* %scevgep41.26.10 to [61 x [61 x i8]]*
  %call16.26.11 = call zeroext i8 (...) @rand()
  store i8 %call16.26.11, i8* %scevgep28.26.10, align 1
  %8792 = load i8, i8* %scevgep28.26.10, align 1
  %conv23.26.11 = zext i8 %8792 to i32
  %8793 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.11 = getelementptr i8, i8* %b, i64 38
  %8794 = load i8, i8* %scevgep34.26.11, align 1
  %call28.26.11 = call zeroext i8 @mult(i8 zeroext %8793, i8 zeroext %8794)
  %conv29.26.11 = zext i8 %call28.26.11 to i32
  %xor.26.11 = xor i32 %conv23.26.11, %conv29.26.11
  %scevgep35.26.11 = getelementptr i8, i8* %a, i64 38
  %8795 = load i8, i8* %scevgep35.26.11, align 1
  %8796 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.11 = call zeroext i8 @mult(i8 zeroext %8795, i8 zeroext %8796)
  %conv35.26.11 = zext i8 %call34.26.11 to i32
  %xor36.26.11 = xor i32 %xor.26.11, %conv35.26.11
  %conv37.26.11 = trunc i32 %xor36.26.11 to i8
  store i8 %conv37.26.11, i8* %scevgep41.26.10, align 1
  %scevgep28.26.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8790, i64 0, i64 0, i64 1
  %8797 = bitcast i8* %scevgep28.26.11 to [61 x [61 x i8]]*
  %scevgep41.26.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8791, i64 0, i64 1, i64 0
  %8798 = bitcast i8* %scevgep41.26.11 to [61 x [61 x i8]]*
  %call16.26.12 = call zeroext i8 (...) @rand()
  store i8 %call16.26.12, i8* %scevgep28.26.11, align 1
  %8799 = load i8, i8* %scevgep28.26.11, align 1
  %conv23.26.12 = zext i8 %8799 to i32
  %8800 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.12 = getelementptr i8, i8* %b, i64 39
  %8801 = load i8, i8* %scevgep34.26.12, align 1
  %call28.26.12 = call zeroext i8 @mult(i8 zeroext %8800, i8 zeroext %8801)
  %conv29.26.12 = zext i8 %call28.26.12 to i32
  %xor.26.12 = xor i32 %conv23.26.12, %conv29.26.12
  %scevgep35.26.12 = getelementptr i8, i8* %a, i64 39
  %8802 = load i8, i8* %scevgep35.26.12, align 1
  %8803 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.12 = call zeroext i8 @mult(i8 zeroext %8802, i8 zeroext %8803)
  %conv35.26.12 = zext i8 %call34.26.12 to i32
  %xor36.26.12 = xor i32 %xor.26.12, %conv35.26.12
  %conv37.26.12 = trunc i32 %xor36.26.12 to i8
  store i8 %conv37.26.12, i8* %scevgep41.26.11, align 1
  %scevgep28.26.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8797, i64 0, i64 0, i64 1
  %8804 = bitcast i8* %scevgep28.26.12 to [61 x [61 x i8]]*
  %scevgep41.26.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8798, i64 0, i64 1, i64 0
  %8805 = bitcast i8* %scevgep41.26.12 to [61 x [61 x i8]]*
  %call16.26.13 = call zeroext i8 (...) @rand()
  store i8 %call16.26.13, i8* %scevgep28.26.12, align 1
  %8806 = load i8, i8* %scevgep28.26.12, align 1
  %conv23.26.13 = zext i8 %8806 to i32
  %8807 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.13 = getelementptr i8, i8* %b, i64 40
  %8808 = load i8, i8* %scevgep34.26.13, align 1
  %call28.26.13 = call zeroext i8 @mult(i8 zeroext %8807, i8 zeroext %8808)
  %conv29.26.13 = zext i8 %call28.26.13 to i32
  %xor.26.13 = xor i32 %conv23.26.13, %conv29.26.13
  %scevgep35.26.13 = getelementptr i8, i8* %a, i64 40
  %8809 = load i8, i8* %scevgep35.26.13, align 1
  %8810 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.13 = call zeroext i8 @mult(i8 zeroext %8809, i8 zeroext %8810)
  %conv35.26.13 = zext i8 %call34.26.13 to i32
  %xor36.26.13 = xor i32 %xor.26.13, %conv35.26.13
  %conv37.26.13 = trunc i32 %xor36.26.13 to i8
  store i8 %conv37.26.13, i8* %scevgep41.26.12, align 1
  %scevgep28.26.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8804, i64 0, i64 0, i64 1
  %8811 = bitcast i8* %scevgep28.26.13 to [61 x [61 x i8]]*
  %scevgep41.26.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8805, i64 0, i64 1, i64 0
  %8812 = bitcast i8* %scevgep41.26.13 to [61 x [61 x i8]]*
  %call16.26.14 = call zeroext i8 (...) @rand()
  store i8 %call16.26.14, i8* %scevgep28.26.13, align 1
  %8813 = load i8, i8* %scevgep28.26.13, align 1
  %conv23.26.14 = zext i8 %8813 to i32
  %8814 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.14 = getelementptr i8, i8* %b, i64 41
  %8815 = load i8, i8* %scevgep34.26.14, align 1
  %call28.26.14 = call zeroext i8 @mult(i8 zeroext %8814, i8 zeroext %8815)
  %conv29.26.14 = zext i8 %call28.26.14 to i32
  %xor.26.14 = xor i32 %conv23.26.14, %conv29.26.14
  %scevgep35.26.14 = getelementptr i8, i8* %a, i64 41
  %8816 = load i8, i8* %scevgep35.26.14, align 1
  %8817 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.14 = call zeroext i8 @mult(i8 zeroext %8816, i8 zeroext %8817)
  %conv35.26.14 = zext i8 %call34.26.14 to i32
  %xor36.26.14 = xor i32 %xor.26.14, %conv35.26.14
  %conv37.26.14 = trunc i32 %xor36.26.14 to i8
  store i8 %conv37.26.14, i8* %scevgep41.26.13, align 1
  %scevgep28.26.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8811, i64 0, i64 0, i64 1
  %8818 = bitcast i8* %scevgep28.26.14 to [61 x [61 x i8]]*
  %scevgep41.26.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8812, i64 0, i64 1, i64 0
  %8819 = bitcast i8* %scevgep41.26.14 to [61 x [61 x i8]]*
  %call16.26.15 = call zeroext i8 (...) @rand()
  store i8 %call16.26.15, i8* %scevgep28.26.14, align 1
  %8820 = load i8, i8* %scevgep28.26.14, align 1
  %conv23.26.15 = zext i8 %8820 to i32
  %8821 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.15 = getelementptr i8, i8* %b, i64 42
  %8822 = load i8, i8* %scevgep34.26.15, align 1
  %call28.26.15 = call zeroext i8 @mult(i8 zeroext %8821, i8 zeroext %8822)
  %conv29.26.15 = zext i8 %call28.26.15 to i32
  %xor.26.15 = xor i32 %conv23.26.15, %conv29.26.15
  %scevgep35.26.15 = getelementptr i8, i8* %a, i64 42
  %8823 = load i8, i8* %scevgep35.26.15, align 1
  %8824 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.15 = call zeroext i8 @mult(i8 zeroext %8823, i8 zeroext %8824)
  %conv35.26.15 = zext i8 %call34.26.15 to i32
  %xor36.26.15 = xor i32 %xor.26.15, %conv35.26.15
  %conv37.26.15 = trunc i32 %xor36.26.15 to i8
  store i8 %conv37.26.15, i8* %scevgep41.26.14, align 1
  %scevgep28.26.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8818, i64 0, i64 0, i64 1
  %8825 = bitcast i8* %scevgep28.26.15 to [61 x [61 x i8]]*
  %scevgep41.26.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8819, i64 0, i64 1, i64 0
  %8826 = bitcast i8* %scevgep41.26.15 to [61 x [61 x i8]]*
  %call16.26.16 = call zeroext i8 (...) @rand()
  store i8 %call16.26.16, i8* %scevgep28.26.15, align 1
  %8827 = load i8, i8* %scevgep28.26.15, align 1
  %conv23.26.16 = zext i8 %8827 to i32
  %8828 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.16 = getelementptr i8, i8* %b, i64 43
  %8829 = load i8, i8* %scevgep34.26.16, align 1
  %call28.26.16 = call zeroext i8 @mult(i8 zeroext %8828, i8 zeroext %8829)
  %conv29.26.16 = zext i8 %call28.26.16 to i32
  %xor.26.16 = xor i32 %conv23.26.16, %conv29.26.16
  %scevgep35.26.16 = getelementptr i8, i8* %a, i64 43
  %8830 = load i8, i8* %scevgep35.26.16, align 1
  %8831 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.16 = call zeroext i8 @mult(i8 zeroext %8830, i8 zeroext %8831)
  %conv35.26.16 = zext i8 %call34.26.16 to i32
  %xor36.26.16 = xor i32 %xor.26.16, %conv35.26.16
  %conv37.26.16 = trunc i32 %xor36.26.16 to i8
  store i8 %conv37.26.16, i8* %scevgep41.26.15, align 1
  %scevgep28.26.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8825, i64 0, i64 0, i64 1
  %8832 = bitcast i8* %scevgep28.26.16 to [61 x [61 x i8]]*
  %scevgep41.26.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8826, i64 0, i64 1, i64 0
  %8833 = bitcast i8* %scevgep41.26.16 to [61 x [61 x i8]]*
  %call16.26.17 = call zeroext i8 (...) @rand()
  store i8 %call16.26.17, i8* %scevgep28.26.16, align 1
  %8834 = load i8, i8* %scevgep28.26.16, align 1
  %conv23.26.17 = zext i8 %8834 to i32
  %8835 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.17 = getelementptr i8, i8* %b, i64 44
  %8836 = load i8, i8* %scevgep34.26.17, align 1
  %call28.26.17 = call zeroext i8 @mult(i8 zeroext %8835, i8 zeroext %8836)
  %conv29.26.17 = zext i8 %call28.26.17 to i32
  %xor.26.17 = xor i32 %conv23.26.17, %conv29.26.17
  %scevgep35.26.17 = getelementptr i8, i8* %a, i64 44
  %8837 = load i8, i8* %scevgep35.26.17, align 1
  %8838 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.17 = call zeroext i8 @mult(i8 zeroext %8837, i8 zeroext %8838)
  %conv35.26.17 = zext i8 %call34.26.17 to i32
  %xor36.26.17 = xor i32 %xor.26.17, %conv35.26.17
  %conv37.26.17 = trunc i32 %xor36.26.17 to i8
  store i8 %conv37.26.17, i8* %scevgep41.26.16, align 1
  %scevgep28.26.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8832, i64 0, i64 0, i64 1
  %8839 = bitcast i8* %scevgep28.26.17 to [61 x [61 x i8]]*
  %scevgep41.26.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8833, i64 0, i64 1, i64 0
  %8840 = bitcast i8* %scevgep41.26.17 to [61 x [61 x i8]]*
  %call16.26.18 = call zeroext i8 (...) @rand()
  store i8 %call16.26.18, i8* %scevgep28.26.17, align 1
  %8841 = load i8, i8* %scevgep28.26.17, align 1
  %conv23.26.18 = zext i8 %8841 to i32
  %8842 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.18 = getelementptr i8, i8* %b, i64 45
  %8843 = load i8, i8* %scevgep34.26.18, align 1
  %call28.26.18 = call zeroext i8 @mult(i8 zeroext %8842, i8 zeroext %8843)
  %conv29.26.18 = zext i8 %call28.26.18 to i32
  %xor.26.18 = xor i32 %conv23.26.18, %conv29.26.18
  %scevgep35.26.18 = getelementptr i8, i8* %a, i64 45
  %8844 = load i8, i8* %scevgep35.26.18, align 1
  %8845 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.18 = call zeroext i8 @mult(i8 zeroext %8844, i8 zeroext %8845)
  %conv35.26.18 = zext i8 %call34.26.18 to i32
  %xor36.26.18 = xor i32 %xor.26.18, %conv35.26.18
  %conv37.26.18 = trunc i32 %xor36.26.18 to i8
  store i8 %conv37.26.18, i8* %scevgep41.26.17, align 1
  %scevgep28.26.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8839, i64 0, i64 0, i64 1
  %8846 = bitcast i8* %scevgep28.26.18 to [61 x [61 x i8]]*
  %scevgep41.26.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8840, i64 0, i64 1, i64 0
  %8847 = bitcast i8* %scevgep41.26.18 to [61 x [61 x i8]]*
  %call16.26.19 = call zeroext i8 (...) @rand()
  store i8 %call16.26.19, i8* %scevgep28.26.18, align 1
  %8848 = load i8, i8* %scevgep28.26.18, align 1
  %conv23.26.19 = zext i8 %8848 to i32
  %8849 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.19 = getelementptr i8, i8* %b, i64 46
  %8850 = load i8, i8* %scevgep34.26.19, align 1
  %call28.26.19 = call zeroext i8 @mult(i8 zeroext %8849, i8 zeroext %8850)
  %conv29.26.19 = zext i8 %call28.26.19 to i32
  %xor.26.19 = xor i32 %conv23.26.19, %conv29.26.19
  %scevgep35.26.19 = getelementptr i8, i8* %a, i64 46
  %8851 = load i8, i8* %scevgep35.26.19, align 1
  %8852 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.19 = call zeroext i8 @mult(i8 zeroext %8851, i8 zeroext %8852)
  %conv35.26.19 = zext i8 %call34.26.19 to i32
  %xor36.26.19 = xor i32 %xor.26.19, %conv35.26.19
  %conv37.26.19 = trunc i32 %xor36.26.19 to i8
  store i8 %conv37.26.19, i8* %scevgep41.26.18, align 1
  %scevgep28.26.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8846, i64 0, i64 0, i64 1
  %8853 = bitcast i8* %scevgep28.26.19 to [61 x [61 x i8]]*
  %scevgep41.26.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8847, i64 0, i64 1, i64 0
  %8854 = bitcast i8* %scevgep41.26.19 to [61 x [61 x i8]]*
  %call16.26.20 = call zeroext i8 (...) @rand()
  store i8 %call16.26.20, i8* %scevgep28.26.19, align 1
  %8855 = load i8, i8* %scevgep28.26.19, align 1
  %conv23.26.20 = zext i8 %8855 to i32
  %8856 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.20 = getelementptr i8, i8* %b, i64 47
  %8857 = load i8, i8* %scevgep34.26.20, align 1
  %call28.26.20 = call zeroext i8 @mult(i8 zeroext %8856, i8 zeroext %8857)
  %conv29.26.20 = zext i8 %call28.26.20 to i32
  %xor.26.20 = xor i32 %conv23.26.20, %conv29.26.20
  %scevgep35.26.20 = getelementptr i8, i8* %a, i64 47
  %8858 = load i8, i8* %scevgep35.26.20, align 1
  %8859 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.20 = call zeroext i8 @mult(i8 zeroext %8858, i8 zeroext %8859)
  %conv35.26.20 = zext i8 %call34.26.20 to i32
  %xor36.26.20 = xor i32 %xor.26.20, %conv35.26.20
  %conv37.26.20 = trunc i32 %xor36.26.20 to i8
  store i8 %conv37.26.20, i8* %scevgep41.26.19, align 1
  %scevgep28.26.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8853, i64 0, i64 0, i64 1
  %8860 = bitcast i8* %scevgep28.26.20 to [61 x [61 x i8]]*
  %scevgep41.26.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8854, i64 0, i64 1, i64 0
  %8861 = bitcast i8* %scevgep41.26.20 to [61 x [61 x i8]]*
  %call16.26.21 = call zeroext i8 (...) @rand()
  store i8 %call16.26.21, i8* %scevgep28.26.20, align 1
  %8862 = load i8, i8* %scevgep28.26.20, align 1
  %conv23.26.21 = zext i8 %8862 to i32
  %8863 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.21 = getelementptr i8, i8* %b, i64 48
  %8864 = load i8, i8* %scevgep34.26.21, align 1
  %call28.26.21 = call zeroext i8 @mult(i8 zeroext %8863, i8 zeroext %8864)
  %conv29.26.21 = zext i8 %call28.26.21 to i32
  %xor.26.21 = xor i32 %conv23.26.21, %conv29.26.21
  %scevgep35.26.21 = getelementptr i8, i8* %a, i64 48
  %8865 = load i8, i8* %scevgep35.26.21, align 1
  %8866 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.21 = call zeroext i8 @mult(i8 zeroext %8865, i8 zeroext %8866)
  %conv35.26.21 = zext i8 %call34.26.21 to i32
  %xor36.26.21 = xor i32 %xor.26.21, %conv35.26.21
  %conv37.26.21 = trunc i32 %xor36.26.21 to i8
  store i8 %conv37.26.21, i8* %scevgep41.26.20, align 1
  %scevgep28.26.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8860, i64 0, i64 0, i64 1
  %8867 = bitcast i8* %scevgep28.26.21 to [61 x [61 x i8]]*
  %scevgep41.26.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8861, i64 0, i64 1, i64 0
  %8868 = bitcast i8* %scevgep41.26.21 to [61 x [61 x i8]]*
  %call16.26.22 = call zeroext i8 (...) @rand()
  store i8 %call16.26.22, i8* %scevgep28.26.21, align 1
  %8869 = load i8, i8* %scevgep28.26.21, align 1
  %conv23.26.22 = zext i8 %8869 to i32
  %8870 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.22 = getelementptr i8, i8* %b, i64 49
  %8871 = load i8, i8* %scevgep34.26.22, align 1
  %call28.26.22 = call zeroext i8 @mult(i8 zeroext %8870, i8 zeroext %8871)
  %conv29.26.22 = zext i8 %call28.26.22 to i32
  %xor.26.22 = xor i32 %conv23.26.22, %conv29.26.22
  %scevgep35.26.22 = getelementptr i8, i8* %a, i64 49
  %8872 = load i8, i8* %scevgep35.26.22, align 1
  %8873 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.22 = call zeroext i8 @mult(i8 zeroext %8872, i8 zeroext %8873)
  %conv35.26.22 = zext i8 %call34.26.22 to i32
  %xor36.26.22 = xor i32 %xor.26.22, %conv35.26.22
  %conv37.26.22 = trunc i32 %xor36.26.22 to i8
  store i8 %conv37.26.22, i8* %scevgep41.26.21, align 1
  %scevgep28.26.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8867, i64 0, i64 0, i64 1
  %8874 = bitcast i8* %scevgep28.26.22 to [61 x [61 x i8]]*
  %scevgep41.26.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8868, i64 0, i64 1, i64 0
  %8875 = bitcast i8* %scevgep41.26.22 to [61 x [61 x i8]]*
  %call16.26.23 = call zeroext i8 (...) @rand()
  store i8 %call16.26.23, i8* %scevgep28.26.22, align 1
  %8876 = load i8, i8* %scevgep28.26.22, align 1
  %conv23.26.23 = zext i8 %8876 to i32
  %8877 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.23 = getelementptr i8, i8* %b, i64 50
  %8878 = load i8, i8* %scevgep34.26.23, align 1
  %call28.26.23 = call zeroext i8 @mult(i8 zeroext %8877, i8 zeroext %8878)
  %conv29.26.23 = zext i8 %call28.26.23 to i32
  %xor.26.23 = xor i32 %conv23.26.23, %conv29.26.23
  %scevgep35.26.23 = getelementptr i8, i8* %a, i64 50
  %8879 = load i8, i8* %scevgep35.26.23, align 1
  %8880 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.23 = call zeroext i8 @mult(i8 zeroext %8879, i8 zeroext %8880)
  %conv35.26.23 = zext i8 %call34.26.23 to i32
  %xor36.26.23 = xor i32 %xor.26.23, %conv35.26.23
  %conv37.26.23 = trunc i32 %xor36.26.23 to i8
  store i8 %conv37.26.23, i8* %scevgep41.26.22, align 1
  %scevgep28.26.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8874, i64 0, i64 0, i64 1
  %8881 = bitcast i8* %scevgep28.26.23 to [61 x [61 x i8]]*
  %scevgep41.26.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8875, i64 0, i64 1, i64 0
  %8882 = bitcast i8* %scevgep41.26.23 to [61 x [61 x i8]]*
  %call16.26.24 = call zeroext i8 (...) @rand()
  store i8 %call16.26.24, i8* %scevgep28.26.23, align 1
  %8883 = load i8, i8* %scevgep28.26.23, align 1
  %conv23.26.24 = zext i8 %8883 to i32
  %8884 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.24 = getelementptr i8, i8* %b, i64 51
  %8885 = load i8, i8* %scevgep34.26.24, align 1
  %call28.26.24 = call zeroext i8 @mult(i8 zeroext %8884, i8 zeroext %8885)
  %conv29.26.24 = zext i8 %call28.26.24 to i32
  %xor.26.24 = xor i32 %conv23.26.24, %conv29.26.24
  %scevgep35.26.24 = getelementptr i8, i8* %a, i64 51
  %8886 = load i8, i8* %scevgep35.26.24, align 1
  %8887 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.24 = call zeroext i8 @mult(i8 zeroext %8886, i8 zeroext %8887)
  %conv35.26.24 = zext i8 %call34.26.24 to i32
  %xor36.26.24 = xor i32 %xor.26.24, %conv35.26.24
  %conv37.26.24 = trunc i32 %xor36.26.24 to i8
  store i8 %conv37.26.24, i8* %scevgep41.26.23, align 1
  %scevgep28.26.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8881, i64 0, i64 0, i64 1
  %8888 = bitcast i8* %scevgep28.26.24 to [61 x [61 x i8]]*
  %scevgep41.26.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8882, i64 0, i64 1, i64 0
  %8889 = bitcast i8* %scevgep41.26.24 to [61 x [61 x i8]]*
  %call16.26.25 = call zeroext i8 (...) @rand()
  store i8 %call16.26.25, i8* %scevgep28.26.24, align 1
  %8890 = load i8, i8* %scevgep28.26.24, align 1
  %conv23.26.25 = zext i8 %8890 to i32
  %8891 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.25 = getelementptr i8, i8* %b, i64 52
  %8892 = load i8, i8* %scevgep34.26.25, align 1
  %call28.26.25 = call zeroext i8 @mult(i8 zeroext %8891, i8 zeroext %8892)
  %conv29.26.25 = zext i8 %call28.26.25 to i32
  %xor.26.25 = xor i32 %conv23.26.25, %conv29.26.25
  %scevgep35.26.25 = getelementptr i8, i8* %a, i64 52
  %8893 = load i8, i8* %scevgep35.26.25, align 1
  %8894 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.25 = call zeroext i8 @mult(i8 zeroext %8893, i8 zeroext %8894)
  %conv35.26.25 = zext i8 %call34.26.25 to i32
  %xor36.26.25 = xor i32 %xor.26.25, %conv35.26.25
  %conv37.26.25 = trunc i32 %xor36.26.25 to i8
  store i8 %conv37.26.25, i8* %scevgep41.26.24, align 1
  %scevgep28.26.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8888, i64 0, i64 0, i64 1
  %8895 = bitcast i8* %scevgep28.26.25 to [61 x [61 x i8]]*
  %scevgep41.26.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8889, i64 0, i64 1, i64 0
  %8896 = bitcast i8* %scevgep41.26.25 to [61 x [61 x i8]]*
  %call16.26.26 = call zeroext i8 (...) @rand()
  store i8 %call16.26.26, i8* %scevgep28.26.25, align 1
  %8897 = load i8, i8* %scevgep28.26.25, align 1
  %conv23.26.26 = zext i8 %8897 to i32
  %8898 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.26 = getelementptr i8, i8* %b, i64 53
  %8899 = load i8, i8* %scevgep34.26.26, align 1
  %call28.26.26 = call zeroext i8 @mult(i8 zeroext %8898, i8 zeroext %8899)
  %conv29.26.26 = zext i8 %call28.26.26 to i32
  %xor.26.26 = xor i32 %conv23.26.26, %conv29.26.26
  %scevgep35.26.26 = getelementptr i8, i8* %a, i64 53
  %8900 = load i8, i8* %scevgep35.26.26, align 1
  %8901 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.26 = call zeroext i8 @mult(i8 zeroext %8900, i8 zeroext %8901)
  %conv35.26.26 = zext i8 %call34.26.26 to i32
  %xor36.26.26 = xor i32 %xor.26.26, %conv35.26.26
  %conv37.26.26 = trunc i32 %xor36.26.26 to i8
  store i8 %conv37.26.26, i8* %scevgep41.26.25, align 1
  %scevgep28.26.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8895, i64 0, i64 0, i64 1
  %8902 = bitcast i8* %scevgep28.26.26 to [61 x [61 x i8]]*
  %scevgep41.26.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8896, i64 0, i64 1, i64 0
  %8903 = bitcast i8* %scevgep41.26.26 to [61 x [61 x i8]]*
  %call16.26.27 = call zeroext i8 (...) @rand()
  store i8 %call16.26.27, i8* %scevgep28.26.26, align 1
  %8904 = load i8, i8* %scevgep28.26.26, align 1
  %conv23.26.27 = zext i8 %8904 to i32
  %8905 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.27 = getelementptr i8, i8* %b, i64 54
  %8906 = load i8, i8* %scevgep34.26.27, align 1
  %call28.26.27 = call zeroext i8 @mult(i8 zeroext %8905, i8 zeroext %8906)
  %conv29.26.27 = zext i8 %call28.26.27 to i32
  %xor.26.27 = xor i32 %conv23.26.27, %conv29.26.27
  %scevgep35.26.27 = getelementptr i8, i8* %a, i64 54
  %8907 = load i8, i8* %scevgep35.26.27, align 1
  %8908 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.27 = call zeroext i8 @mult(i8 zeroext %8907, i8 zeroext %8908)
  %conv35.26.27 = zext i8 %call34.26.27 to i32
  %xor36.26.27 = xor i32 %xor.26.27, %conv35.26.27
  %conv37.26.27 = trunc i32 %xor36.26.27 to i8
  store i8 %conv37.26.27, i8* %scevgep41.26.26, align 1
  %scevgep28.26.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8902, i64 0, i64 0, i64 1
  %8909 = bitcast i8* %scevgep28.26.27 to [61 x [61 x i8]]*
  %scevgep41.26.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8903, i64 0, i64 1, i64 0
  %8910 = bitcast i8* %scevgep41.26.27 to [61 x [61 x i8]]*
  %call16.26.28 = call zeroext i8 (...) @rand()
  store i8 %call16.26.28, i8* %scevgep28.26.27, align 1
  %8911 = load i8, i8* %scevgep28.26.27, align 1
  %conv23.26.28 = zext i8 %8911 to i32
  %8912 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.28 = getelementptr i8, i8* %b, i64 55
  %8913 = load i8, i8* %scevgep34.26.28, align 1
  %call28.26.28 = call zeroext i8 @mult(i8 zeroext %8912, i8 zeroext %8913)
  %conv29.26.28 = zext i8 %call28.26.28 to i32
  %xor.26.28 = xor i32 %conv23.26.28, %conv29.26.28
  %scevgep35.26.28 = getelementptr i8, i8* %a, i64 55
  %8914 = load i8, i8* %scevgep35.26.28, align 1
  %8915 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.28 = call zeroext i8 @mult(i8 zeroext %8914, i8 zeroext %8915)
  %conv35.26.28 = zext i8 %call34.26.28 to i32
  %xor36.26.28 = xor i32 %xor.26.28, %conv35.26.28
  %conv37.26.28 = trunc i32 %xor36.26.28 to i8
  store i8 %conv37.26.28, i8* %scevgep41.26.27, align 1
  %scevgep28.26.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8909, i64 0, i64 0, i64 1
  %8916 = bitcast i8* %scevgep28.26.28 to [61 x [61 x i8]]*
  %scevgep41.26.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8910, i64 0, i64 1, i64 0
  %8917 = bitcast i8* %scevgep41.26.28 to [61 x [61 x i8]]*
  %call16.26.29 = call zeroext i8 (...) @rand()
  store i8 %call16.26.29, i8* %scevgep28.26.28, align 1
  %8918 = load i8, i8* %scevgep28.26.28, align 1
  %conv23.26.29 = zext i8 %8918 to i32
  %8919 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.29 = getelementptr i8, i8* %b, i64 56
  %8920 = load i8, i8* %scevgep34.26.29, align 1
  %call28.26.29 = call zeroext i8 @mult(i8 zeroext %8919, i8 zeroext %8920)
  %conv29.26.29 = zext i8 %call28.26.29 to i32
  %xor.26.29 = xor i32 %conv23.26.29, %conv29.26.29
  %scevgep35.26.29 = getelementptr i8, i8* %a, i64 56
  %8921 = load i8, i8* %scevgep35.26.29, align 1
  %8922 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.29 = call zeroext i8 @mult(i8 zeroext %8921, i8 zeroext %8922)
  %conv35.26.29 = zext i8 %call34.26.29 to i32
  %xor36.26.29 = xor i32 %xor.26.29, %conv35.26.29
  %conv37.26.29 = trunc i32 %xor36.26.29 to i8
  store i8 %conv37.26.29, i8* %scevgep41.26.28, align 1
  %scevgep28.26.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8916, i64 0, i64 0, i64 1
  %8923 = bitcast i8* %scevgep28.26.29 to [61 x [61 x i8]]*
  %scevgep41.26.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8917, i64 0, i64 1, i64 0
  %8924 = bitcast i8* %scevgep41.26.29 to [61 x [61 x i8]]*
  %call16.26.30 = call zeroext i8 (...) @rand()
  store i8 %call16.26.30, i8* %scevgep28.26.29, align 1
  %8925 = load i8, i8* %scevgep28.26.29, align 1
  %conv23.26.30 = zext i8 %8925 to i32
  %8926 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.30 = getelementptr i8, i8* %b, i64 57
  %8927 = load i8, i8* %scevgep34.26.30, align 1
  %call28.26.30 = call zeroext i8 @mult(i8 zeroext %8926, i8 zeroext %8927)
  %conv29.26.30 = zext i8 %call28.26.30 to i32
  %xor.26.30 = xor i32 %conv23.26.30, %conv29.26.30
  %scevgep35.26.30 = getelementptr i8, i8* %a, i64 57
  %8928 = load i8, i8* %scevgep35.26.30, align 1
  %8929 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.30 = call zeroext i8 @mult(i8 zeroext %8928, i8 zeroext %8929)
  %conv35.26.30 = zext i8 %call34.26.30 to i32
  %xor36.26.30 = xor i32 %xor.26.30, %conv35.26.30
  %conv37.26.30 = trunc i32 %xor36.26.30 to i8
  store i8 %conv37.26.30, i8* %scevgep41.26.29, align 1
  %scevgep28.26.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8923, i64 0, i64 0, i64 1
  %8930 = bitcast i8* %scevgep28.26.30 to [61 x [61 x i8]]*
  %scevgep41.26.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8924, i64 0, i64 1, i64 0
  %8931 = bitcast i8* %scevgep41.26.30 to [61 x [61 x i8]]*
  %call16.26.31 = call zeroext i8 (...) @rand()
  store i8 %call16.26.31, i8* %scevgep28.26.30, align 1
  %8932 = load i8, i8* %scevgep28.26.30, align 1
  %conv23.26.31 = zext i8 %8932 to i32
  %8933 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.31 = getelementptr i8, i8* %b, i64 58
  %8934 = load i8, i8* %scevgep34.26.31, align 1
  %call28.26.31 = call zeroext i8 @mult(i8 zeroext %8933, i8 zeroext %8934)
  %conv29.26.31 = zext i8 %call28.26.31 to i32
  %xor.26.31 = xor i32 %conv23.26.31, %conv29.26.31
  %scevgep35.26.31 = getelementptr i8, i8* %a, i64 58
  %8935 = load i8, i8* %scevgep35.26.31, align 1
  %8936 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.31 = call zeroext i8 @mult(i8 zeroext %8935, i8 zeroext %8936)
  %conv35.26.31 = zext i8 %call34.26.31 to i32
  %xor36.26.31 = xor i32 %xor.26.31, %conv35.26.31
  %conv37.26.31 = trunc i32 %xor36.26.31 to i8
  store i8 %conv37.26.31, i8* %scevgep41.26.30, align 1
  %scevgep28.26.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8930, i64 0, i64 0, i64 1
  %8937 = bitcast i8* %scevgep28.26.31 to [61 x [61 x i8]]*
  %scevgep41.26.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8931, i64 0, i64 1, i64 0
  %8938 = bitcast i8* %scevgep41.26.31 to [61 x [61 x i8]]*
  %call16.26.32 = call zeroext i8 (...) @rand()
  store i8 %call16.26.32, i8* %scevgep28.26.31, align 1
  %8939 = load i8, i8* %scevgep28.26.31, align 1
  %conv23.26.32 = zext i8 %8939 to i32
  %8940 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.32 = getelementptr i8, i8* %b, i64 59
  %8941 = load i8, i8* %scevgep34.26.32, align 1
  %call28.26.32 = call zeroext i8 @mult(i8 zeroext %8940, i8 zeroext %8941)
  %conv29.26.32 = zext i8 %call28.26.32 to i32
  %xor.26.32 = xor i32 %conv23.26.32, %conv29.26.32
  %scevgep35.26.32 = getelementptr i8, i8* %a, i64 59
  %8942 = load i8, i8* %scevgep35.26.32, align 1
  %8943 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.32 = call zeroext i8 @mult(i8 zeroext %8942, i8 zeroext %8943)
  %conv35.26.32 = zext i8 %call34.26.32 to i32
  %xor36.26.32 = xor i32 %xor.26.32, %conv35.26.32
  %conv37.26.32 = trunc i32 %xor36.26.32 to i8
  store i8 %conv37.26.32, i8* %scevgep41.26.31, align 1
  %scevgep28.26.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8937, i64 0, i64 0, i64 1
  %scevgep41.26.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8938, i64 0, i64 1, i64 0
  %call16.26.33 = call zeroext i8 (...) @rand()
  store i8 %call16.26.33, i8* %scevgep28.26.32, align 1
  %8944 = load i8, i8* %scevgep28.26.32, align 1
  %conv23.26.33 = zext i8 %8944 to i32
  %8945 = load i8, i8* %arrayidx25.26, align 1
  %scevgep34.26.33 = getelementptr i8, i8* %b, i64 60
  %8946 = load i8, i8* %scevgep34.26.33, align 1
  %call28.26.33 = call zeroext i8 @mult(i8 zeroext %8945, i8 zeroext %8946)
  %conv29.26.33 = zext i8 %call28.26.33 to i32
  %xor.26.33 = xor i32 %conv23.26.33, %conv29.26.33
  %scevgep35.26.33 = getelementptr i8, i8* %a, i64 60
  %8947 = load i8, i8* %scevgep35.26.33, align 1
  %8948 = load i8, i8* %arrayidx33.26, align 1
  %call34.26.33 = call zeroext i8 @mult(i8 zeroext %8947, i8 zeroext %8948)
  %conv35.26.33 = zext i8 %call34.26.33 to i32
  %xor36.26.33 = xor i32 %xor.26.33, %conv35.26.33
  %conv37.26.33 = trunc i32 %xor36.26.33 to i8
  store i8 %conv37.26.33, i8* %scevgep41.26.32, align 1
  %scevgep26.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8713, i64 0, i64 1, i64 1
  %8949 = bitcast i8* %scevgep26.26 to [61 x [61 x i8]]*
  %scevgep39.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8714, i64 0, i64 1, i64 1
  %8950 = bitcast i8* %scevgep39.26 to [61 x [61 x i8]]*
  %arrayidx25.27 = getelementptr inbounds i8, i8* %a, i64 27
  %arrayidx33.27 = getelementptr inbounds i8, i8* %b, i64 27
  %call16.27 = call zeroext i8 (...) @rand()
  store i8 %call16.27, i8* %scevgep26.26, align 1
  %8951 = load i8, i8* %scevgep26.26, align 1
  %conv23.27 = zext i8 %8951 to i32
  %8952 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27 = getelementptr i8, i8* %b, i64 28
  %8953 = load i8, i8* %scevgep34.27, align 1
  %call28.27 = call zeroext i8 @mult(i8 zeroext %8952, i8 zeroext %8953)
  %conv29.27 = zext i8 %call28.27 to i32
  %xor.27 = xor i32 %conv23.27, %conv29.27
  %scevgep35.27 = getelementptr i8, i8* %a, i64 28
  %8954 = load i8, i8* %scevgep35.27, align 1
  %8955 = load i8, i8* %arrayidx33.27, align 1
  %call34.27 = call zeroext i8 @mult(i8 zeroext %8954, i8 zeroext %8955)
  %conv35.27 = zext i8 %call34.27 to i32
  %xor36.27 = xor i32 %xor.27, %conv35.27
  %conv37.27 = trunc i32 %xor36.27 to i8
  store i8 %conv37.27, i8* %scevgep39.26, align 1
  %scevgep28.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8949, i64 0, i64 0, i64 1
  %8956 = bitcast i8* %scevgep28.27 to [61 x [61 x i8]]*
  %scevgep41.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8950, i64 0, i64 1, i64 0
  %8957 = bitcast i8* %scevgep41.27 to [61 x [61 x i8]]*
  %call16.27.1 = call zeroext i8 (...) @rand()
  store i8 %call16.27.1, i8* %scevgep28.27, align 1
  %8958 = load i8, i8* %scevgep28.27, align 1
  %conv23.27.1 = zext i8 %8958 to i32
  %8959 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.1 = getelementptr i8, i8* %b, i64 29
  %8960 = load i8, i8* %scevgep34.27.1, align 1
  %call28.27.1 = call zeroext i8 @mult(i8 zeroext %8959, i8 zeroext %8960)
  %conv29.27.1 = zext i8 %call28.27.1 to i32
  %xor.27.1 = xor i32 %conv23.27.1, %conv29.27.1
  %scevgep35.27.1 = getelementptr i8, i8* %a, i64 29
  %8961 = load i8, i8* %scevgep35.27.1, align 1
  %8962 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.1 = call zeroext i8 @mult(i8 zeroext %8961, i8 zeroext %8962)
  %conv35.27.1 = zext i8 %call34.27.1 to i32
  %xor36.27.1 = xor i32 %xor.27.1, %conv35.27.1
  %conv37.27.1 = trunc i32 %xor36.27.1 to i8
  store i8 %conv37.27.1, i8* %scevgep41.27, align 1
  %scevgep28.27.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8956, i64 0, i64 0, i64 1
  %8963 = bitcast i8* %scevgep28.27.1 to [61 x [61 x i8]]*
  %scevgep41.27.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8957, i64 0, i64 1, i64 0
  %8964 = bitcast i8* %scevgep41.27.1 to [61 x [61 x i8]]*
  %call16.27.2 = call zeroext i8 (...) @rand()
  store i8 %call16.27.2, i8* %scevgep28.27.1, align 1
  %8965 = load i8, i8* %scevgep28.27.1, align 1
  %conv23.27.2 = zext i8 %8965 to i32
  %8966 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.2 = getelementptr i8, i8* %b, i64 30
  %8967 = load i8, i8* %scevgep34.27.2, align 1
  %call28.27.2 = call zeroext i8 @mult(i8 zeroext %8966, i8 zeroext %8967)
  %conv29.27.2 = zext i8 %call28.27.2 to i32
  %xor.27.2 = xor i32 %conv23.27.2, %conv29.27.2
  %scevgep35.27.2 = getelementptr i8, i8* %a, i64 30
  %8968 = load i8, i8* %scevgep35.27.2, align 1
  %8969 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.2 = call zeroext i8 @mult(i8 zeroext %8968, i8 zeroext %8969)
  %conv35.27.2 = zext i8 %call34.27.2 to i32
  %xor36.27.2 = xor i32 %xor.27.2, %conv35.27.2
  %conv37.27.2 = trunc i32 %xor36.27.2 to i8
  store i8 %conv37.27.2, i8* %scevgep41.27.1, align 1
  %scevgep28.27.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8963, i64 0, i64 0, i64 1
  %8970 = bitcast i8* %scevgep28.27.2 to [61 x [61 x i8]]*
  %scevgep41.27.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8964, i64 0, i64 1, i64 0
  %8971 = bitcast i8* %scevgep41.27.2 to [61 x [61 x i8]]*
  %call16.27.3 = call zeroext i8 (...) @rand()
  store i8 %call16.27.3, i8* %scevgep28.27.2, align 1
  %8972 = load i8, i8* %scevgep28.27.2, align 1
  %conv23.27.3 = zext i8 %8972 to i32
  %8973 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.3 = getelementptr i8, i8* %b, i64 31
  %8974 = load i8, i8* %scevgep34.27.3, align 1
  %call28.27.3 = call zeroext i8 @mult(i8 zeroext %8973, i8 zeroext %8974)
  %conv29.27.3 = zext i8 %call28.27.3 to i32
  %xor.27.3 = xor i32 %conv23.27.3, %conv29.27.3
  %scevgep35.27.3 = getelementptr i8, i8* %a, i64 31
  %8975 = load i8, i8* %scevgep35.27.3, align 1
  %8976 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.3 = call zeroext i8 @mult(i8 zeroext %8975, i8 zeroext %8976)
  %conv35.27.3 = zext i8 %call34.27.3 to i32
  %xor36.27.3 = xor i32 %xor.27.3, %conv35.27.3
  %conv37.27.3 = trunc i32 %xor36.27.3 to i8
  store i8 %conv37.27.3, i8* %scevgep41.27.2, align 1
  %scevgep28.27.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8970, i64 0, i64 0, i64 1
  %8977 = bitcast i8* %scevgep28.27.3 to [61 x [61 x i8]]*
  %scevgep41.27.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8971, i64 0, i64 1, i64 0
  %8978 = bitcast i8* %scevgep41.27.3 to [61 x [61 x i8]]*
  %call16.27.4 = call zeroext i8 (...) @rand()
  store i8 %call16.27.4, i8* %scevgep28.27.3, align 1
  %8979 = load i8, i8* %scevgep28.27.3, align 1
  %conv23.27.4 = zext i8 %8979 to i32
  %8980 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.4 = getelementptr i8, i8* %b, i64 32
  %8981 = load i8, i8* %scevgep34.27.4, align 1
  %call28.27.4 = call zeroext i8 @mult(i8 zeroext %8980, i8 zeroext %8981)
  %conv29.27.4 = zext i8 %call28.27.4 to i32
  %xor.27.4 = xor i32 %conv23.27.4, %conv29.27.4
  %scevgep35.27.4 = getelementptr i8, i8* %a, i64 32
  %8982 = load i8, i8* %scevgep35.27.4, align 1
  %8983 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.4 = call zeroext i8 @mult(i8 zeroext %8982, i8 zeroext %8983)
  %conv35.27.4 = zext i8 %call34.27.4 to i32
  %xor36.27.4 = xor i32 %xor.27.4, %conv35.27.4
  %conv37.27.4 = trunc i32 %xor36.27.4 to i8
  store i8 %conv37.27.4, i8* %scevgep41.27.3, align 1
  %scevgep28.27.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8977, i64 0, i64 0, i64 1
  %8984 = bitcast i8* %scevgep28.27.4 to [61 x [61 x i8]]*
  %scevgep41.27.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8978, i64 0, i64 1, i64 0
  %8985 = bitcast i8* %scevgep41.27.4 to [61 x [61 x i8]]*
  %call16.27.5 = call zeroext i8 (...) @rand()
  store i8 %call16.27.5, i8* %scevgep28.27.4, align 1
  %8986 = load i8, i8* %scevgep28.27.4, align 1
  %conv23.27.5 = zext i8 %8986 to i32
  %8987 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.5 = getelementptr i8, i8* %b, i64 33
  %8988 = load i8, i8* %scevgep34.27.5, align 1
  %call28.27.5 = call zeroext i8 @mult(i8 zeroext %8987, i8 zeroext %8988)
  %conv29.27.5 = zext i8 %call28.27.5 to i32
  %xor.27.5 = xor i32 %conv23.27.5, %conv29.27.5
  %scevgep35.27.5 = getelementptr i8, i8* %a, i64 33
  %8989 = load i8, i8* %scevgep35.27.5, align 1
  %8990 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.5 = call zeroext i8 @mult(i8 zeroext %8989, i8 zeroext %8990)
  %conv35.27.5 = zext i8 %call34.27.5 to i32
  %xor36.27.5 = xor i32 %xor.27.5, %conv35.27.5
  %conv37.27.5 = trunc i32 %xor36.27.5 to i8
  store i8 %conv37.27.5, i8* %scevgep41.27.4, align 1
  %scevgep28.27.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8984, i64 0, i64 0, i64 1
  %8991 = bitcast i8* %scevgep28.27.5 to [61 x [61 x i8]]*
  %scevgep41.27.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8985, i64 0, i64 1, i64 0
  %8992 = bitcast i8* %scevgep41.27.5 to [61 x [61 x i8]]*
  %call16.27.6 = call zeroext i8 (...) @rand()
  store i8 %call16.27.6, i8* %scevgep28.27.5, align 1
  %8993 = load i8, i8* %scevgep28.27.5, align 1
  %conv23.27.6 = zext i8 %8993 to i32
  %8994 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.6 = getelementptr i8, i8* %b, i64 34
  %8995 = load i8, i8* %scevgep34.27.6, align 1
  %call28.27.6 = call zeroext i8 @mult(i8 zeroext %8994, i8 zeroext %8995)
  %conv29.27.6 = zext i8 %call28.27.6 to i32
  %xor.27.6 = xor i32 %conv23.27.6, %conv29.27.6
  %scevgep35.27.6 = getelementptr i8, i8* %a, i64 34
  %8996 = load i8, i8* %scevgep35.27.6, align 1
  %8997 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.6 = call zeroext i8 @mult(i8 zeroext %8996, i8 zeroext %8997)
  %conv35.27.6 = zext i8 %call34.27.6 to i32
  %xor36.27.6 = xor i32 %xor.27.6, %conv35.27.6
  %conv37.27.6 = trunc i32 %xor36.27.6 to i8
  store i8 %conv37.27.6, i8* %scevgep41.27.5, align 1
  %scevgep28.27.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8991, i64 0, i64 0, i64 1
  %8998 = bitcast i8* %scevgep28.27.6 to [61 x [61 x i8]]*
  %scevgep41.27.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8992, i64 0, i64 1, i64 0
  %8999 = bitcast i8* %scevgep41.27.6 to [61 x [61 x i8]]*
  %call16.27.7 = call zeroext i8 (...) @rand()
  store i8 %call16.27.7, i8* %scevgep28.27.6, align 1
  %9000 = load i8, i8* %scevgep28.27.6, align 1
  %conv23.27.7 = zext i8 %9000 to i32
  %9001 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.7 = getelementptr i8, i8* %b, i64 35
  %9002 = load i8, i8* %scevgep34.27.7, align 1
  %call28.27.7 = call zeroext i8 @mult(i8 zeroext %9001, i8 zeroext %9002)
  %conv29.27.7 = zext i8 %call28.27.7 to i32
  %xor.27.7 = xor i32 %conv23.27.7, %conv29.27.7
  %scevgep35.27.7 = getelementptr i8, i8* %a, i64 35
  %9003 = load i8, i8* %scevgep35.27.7, align 1
  %9004 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.7 = call zeroext i8 @mult(i8 zeroext %9003, i8 zeroext %9004)
  %conv35.27.7 = zext i8 %call34.27.7 to i32
  %xor36.27.7 = xor i32 %xor.27.7, %conv35.27.7
  %conv37.27.7 = trunc i32 %xor36.27.7 to i8
  store i8 %conv37.27.7, i8* %scevgep41.27.6, align 1
  %scevgep28.27.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8998, i64 0, i64 0, i64 1
  %9005 = bitcast i8* %scevgep28.27.7 to [61 x [61 x i8]]*
  %scevgep41.27.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8999, i64 0, i64 1, i64 0
  %9006 = bitcast i8* %scevgep41.27.7 to [61 x [61 x i8]]*
  %call16.27.8 = call zeroext i8 (...) @rand()
  store i8 %call16.27.8, i8* %scevgep28.27.7, align 1
  %9007 = load i8, i8* %scevgep28.27.7, align 1
  %conv23.27.8 = zext i8 %9007 to i32
  %9008 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.8 = getelementptr i8, i8* %b, i64 36
  %9009 = load i8, i8* %scevgep34.27.8, align 1
  %call28.27.8 = call zeroext i8 @mult(i8 zeroext %9008, i8 zeroext %9009)
  %conv29.27.8 = zext i8 %call28.27.8 to i32
  %xor.27.8 = xor i32 %conv23.27.8, %conv29.27.8
  %scevgep35.27.8 = getelementptr i8, i8* %a, i64 36
  %9010 = load i8, i8* %scevgep35.27.8, align 1
  %9011 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.8 = call zeroext i8 @mult(i8 zeroext %9010, i8 zeroext %9011)
  %conv35.27.8 = zext i8 %call34.27.8 to i32
  %xor36.27.8 = xor i32 %xor.27.8, %conv35.27.8
  %conv37.27.8 = trunc i32 %xor36.27.8 to i8
  store i8 %conv37.27.8, i8* %scevgep41.27.7, align 1
  %scevgep28.27.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9005, i64 0, i64 0, i64 1
  %9012 = bitcast i8* %scevgep28.27.8 to [61 x [61 x i8]]*
  %scevgep41.27.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9006, i64 0, i64 1, i64 0
  %9013 = bitcast i8* %scevgep41.27.8 to [61 x [61 x i8]]*
  %call16.27.9 = call zeroext i8 (...) @rand()
  store i8 %call16.27.9, i8* %scevgep28.27.8, align 1
  %9014 = load i8, i8* %scevgep28.27.8, align 1
  %conv23.27.9 = zext i8 %9014 to i32
  %9015 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.9 = getelementptr i8, i8* %b, i64 37
  %9016 = load i8, i8* %scevgep34.27.9, align 1
  %call28.27.9 = call zeroext i8 @mult(i8 zeroext %9015, i8 zeroext %9016)
  %conv29.27.9 = zext i8 %call28.27.9 to i32
  %xor.27.9 = xor i32 %conv23.27.9, %conv29.27.9
  %scevgep35.27.9 = getelementptr i8, i8* %a, i64 37
  %9017 = load i8, i8* %scevgep35.27.9, align 1
  %9018 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.9 = call zeroext i8 @mult(i8 zeroext %9017, i8 zeroext %9018)
  %conv35.27.9 = zext i8 %call34.27.9 to i32
  %xor36.27.9 = xor i32 %xor.27.9, %conv35.27.9
  %conv37.27.9 = trunc i32 %xor36.27.9 to i8
  store i8 %conv37.27.9, i8* %scevgep41.27.8, align 1
  %scevgep28.27.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9012, i64 0, i64 0, i64 1
  %9019 = bitcast i8* %scevgep28.27.9 to [61 x [61 x i8]]*
  %scevgep41.27.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9013, i64 0, i64 1, i64 0
  %9020 = bitcast i8* %scevgep41.27.9 to [61 x [61 x i8]]*
  %call16.27.10 = call zeroext i8 (...) @rand()
  store i8 %call16.27.10, i8* %scevgep28.27.9, align 1
  %9021 = load i8, i8* %scevgep28.27.9, align 1
  %conv23.27.10 = zext i8 %9021 to i32
  %9022 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.10 = getelementptr i8, i8* %b, i64 38
  %9023 = load i8, i8* %scevgep34.27.10, align 1
  %call28.27.10 = call zeroext i8 @mult(i8 zeroext %9022, i8 zeroext %9023)
  %conv29.27.10 = zext i8 %call28.27.10 to i32
  %xor.27.10 = xor i32 %conv23.27.10, %conv29.27.10
  %scevgep35.27.10 = getelementptr i8, i8* %a, i64 38
  %9024 = load i8, i8* %scevgep35.27.10, align 1
  %9025 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.10 = call zeroext i8 @mult(i8 zeroext %9024, i8 zeroext %9025)
  %conv35.27.10 = zext i8 %call34.27.10 to i32
  %xor36.27.10 = xor i32 %xor.27.10, %conv35.27.10
  %conv37.27.10 = trunc i32 %xor36.27.10 to i8
  store i8 %conv37.27.10, i8* %scevgep41.27.9, align 1
  %scevgep28.27.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9019, i64 0, i64 0, i64 1
  %9026 = bitcast i8* %scevgep28.27.10 to [61 x [61 x i8]]*
  %scevgep41.27.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9020, i64 0, i64 1, i64 0
  %9027 = bitcast i8* %scevgep41.27.10 to [61 x [61 x i8]]*
  %call16.27.11 = call zeroext i8 (...) @rand()
  store i8 %call16.27.11, i8* %scevgep28.27.10, align 1
  %9028 = load i8, i8* %scevgep28.27.10, align 1
  %conv23.27.11 = zext i8 %9028 to i32
  %9029 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.11 = getelementptr i8, i8* %b, i64 39
  %9030 = load i8, i8* %scevgep34.27.11, align 1
  %call28.27.11 = call zeroext i8 @mult(i8 zeroext %9029, i8 zeroext %9030)
  %conv29.27.11 = zext i8 %call28.27.11 to i32
  %xor.27.11 = xor i32 %conv23.27.11, %conv29.27.11
  %scevgep35.27.11 = getelementptr i8, i8* %a, i64 39
  %9031 = load i8, i8* %scevgep35.27.11, align 1
  %9032 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.11 = call zeroext i8 @mult(i8 zeroext %9031, i8 zeroext %9032)
  %conv35.27.11 = zext i8 %call34.27.11 to i32
  %xor36.27.11 = xor i32 %xor.27.11, %conv35.27.11
  %conv37.27.11 = trunc i32 %xor36.27.11 to i8
  store i8 %conv37.27.11, i8* %scevgep41.27.10, align 1
  %scevgep28.27.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9026, i64 0, i64 0, i64 1
  %9033 = bitcast i8* %scevgep28.27.11 to [61 x [61 x i8]]*
  %scevgep41.27.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9027, i64 0, i64 1, i64 0
  %9034 = bitcast i8* %scevgep41.27.11 to [61 x [61 x i8]]*
  %call16.27.12 = call zeroext i8 (...) @rand()
  store i8 %call16.27.12, i8* %scevgep28.27.11, align 1
  %9035 = load i8, i8* %scevgep28.27.11, align 1
  %conv23.27.12 = zext i8 %9035 to i32
  %9036 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.12 = getelementptr i8, i8* %b, i64 40
  %9037 = load i8, i8* %scevgep34.27.12, align 1
  %call28.27.12 = call zeroext i8 @mult(i8 zeroext %9036, i8 zeroext %9037)
  %conv29.27.12 = zext i8 %call28.27.12 to i32
  %xor.27.12 = xor i32 %conv23.27.12, %conv29.27.12
  %scevgep35.27.12 = getelementptr i8, i8* %a, i64 40
  %9038 = load i8, i8* %scevgep35.27.12, align 1
  %9039 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.12 = call zeroext i8 @mult(i8 zeroext %9038, i8 zeroext %9039)
  %conv35.27.12 = zext i8 %call34.27.12 to i32
  %xor36.27.12 = xor i32 %xor.27.12, %conv35.27.12
  %conv37.27.12 = trunc i32 %xor36.27.12 to i8
  store i8 %conv37.27.12, i8* %scevgep41.27.11, align 1
  %scevgep28.27.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9033, i64 0, i64 0, i64 1
  %9040 = bitcast i8* %scevgep28.27.12 to [61 x [61 x i8]]*
  %scevgep41.27.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9034, i64 0, i64 1, i64 0
  %9041 = bitcast i8* %scevgep41.27.12 to [61 x [61 x i8]]*
  %call16.27.13 = call zeroext i8 (...) @rand()
  store i8 %call16.27.13, i8* %scevgep28.27.12, align 1
  %9042 = load i8, i8* %scevgep28.27.12, align 1
  %conv23.27.13 = zext i8 %9042 to i32
  %9043 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.13 = getelementptr i8, i8* %b, i64 41
  %9044 = load i8, i8* %scevgep34.27.13, align 1
  %call28.27.13 = call zeroext i8 @mult(i8 zeroext %9043, i8 zeroext %9044)
  %conv29.27.13 = zext i8 %call28.27.13 to i32
  %xor.27.13 = xor i32 %conv23.27.13, %conv29.27.13
  %scevgep35.27.13 = getelementptr i8, i8* %a, i64 41
  %9045 = load i8, i8* %scevgep35.27.13, align 1
  %9046 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.13 = call zeroext i8 @mult(i8 zeroext %9045, i8 zeroext %9046)
  %conv35.27.13 = zext i8 %call34.27.13 to i32
  %xor36.27.13 = xor i32 %xor.27.13, %conv35.27.13
  %conv37.27.13 = trunc i32 %xor36.27.13 to i8
  store i8 %conv37.27.13, i8* %scevgep41.27.12, align 1
  %scevgep28.27.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9040, i64 0, i64 0, i64 1
  %9047 = bitcast i8* %scevgep28.27.13 to [61 x [61 x i8]]*
  %scevgep41.27.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9041, i64 0, i64 1, i64 0
  %9048 = bitcast i8* %scevgep41.27.13 to [61 x [61 x i8]]*
  %call16.27.14 = call zeroext i8 (...) @rand()
  store i8 %call16.27.14, i8* %scevgep28.27.13, align 1
  %9049 = load i8, i8* %scevgep28.27.13, align 1
  %conv23.27.14 = zext i8 %9049 to i32
  %9050 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.14 = getelementptr i8, i8* %b, i64 42
  %9051 = load i8, i8* %scevgep34.27.14, align 1
  %call28.27.14 = call zeroext i8 @mult(i8 zeroext %9050, i8 zeroext %9051)
  %conv29.27.14 = zext i8 %call28.27.14 to i32
  %xor.27.14 = xor i32 %conv23.27.14, %conv29.27.14
  %scevgep35.27.14 = getelementptr i8, i8* %a, i64 42
  %9052 = load i8, i8* %scevgep35.27.14, align 1
  %9053 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.14 = call zeroext i8 @mult(i8 zeroext %9052, i8 zeroext %9053)
  %conv35.27.14 = zext i8 %call34.27.14 to i32
  %xor36.27.14 = xor i32 %xor.27.14, %conv35.27.14
  %conv37.27.14 = trunc i32 %xor36.27.14 to i8
  store i8 %conv37.27.14, i8* %scevgep41.27.13, align 1
  %scevgep28.27.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9047, i64 0, i64 0, i64 1
  %9054 = bitcast i8* %scevgep28.27.14 to [61 x [61 x i8]]*
  %scevgep41.27.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9048, i64 0, i64 1, i64 0
  %9055 = bitcast i8* %scevgep41.27.14 to [61 x [61 x i8]]*
  %call16.27.15 = call zeroext i8 (...) @rand()
  store i8 %call16.27.15, i8* %scevgep28.27.14, align 1
  %9056 = load i8, i8* %scevgep28.27.14, align 1
  %conv23.27.15 = zext i8 %9056 to i32
  %9057 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.15 = getelementptr i8, i8* %b, i64 43
  %9058 = load i8, i8* %scevgep34.27.15, align 1
  %call28.27.15 = call zeroext i8 @mult(i8 zeroext %9057, i8 zeroext %9058)
  %conv29.27.15 = zext i8 %call28.27.15 to i32
  %xor.27.15 = xor i32 %conv23.27.15, %conv29.27.15
  %scevgep35.27.15 = getelementptr i8, i8* %a, i64 43
  %9059 = load i8, i8* %scevgep35.27.15, align 1
  %9060 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.15 = call zeroext i8 @mult(i8 zeroext %9059, i8 zeroext %9060)
  %conv35.27.15 = zext i8 %call34.27.15 to i32
  %xor36.27.15 = xor i32 %xor.27.15, %conv35.27.15
  %conv37.27.15 = trunc i32 %xor36.27.15 to i8
  store i8 %conv37.27.15, i8* %scevgep41.27.14, align 1
  %scevgep28.27.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9054, i64 0, i64 0, i64 1
  %9061 = bitcast i8* %scevgep28.27.15 to [61 x [61 x i8]]*
  %scevgep41.27.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9055, i64 0, i64 1, i64 0
  %9062 = bitcast i8* %scevgep41.27.15 to [61 x [61 x i8]]*
  %call16.27.16 = call zeroext i8 (...) @rand()
  store i8 %call16.27.16, i8* %scevgep28.27.15, align 1
  %9063 = load i8, i8* %scevgep28.27.15, align 1
  %conv23.27.16 = zext i8 %9063 to i32
  %9064 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.16 = getelementptr i8, i8* %b, i64 44
  %9065 = load i8, i8* %scevgep34.27.16, align 1
  %call28.27.16 = call zeroext i8 @mult(i8 zeroext %9064, i8 zeroext %9065)
  %conv29.27.16 = zext i8 %call28.27.16 to i32
  %xor.27.16 = xor i32 %conv23.27.16, %conv29.27.16
  %scevgep35.27.16 = getelementptr i8, i8* %a, i64 44
  %9066 = load i8, i8* %scevgep35.27.16, align 1
  %9067 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.16 = call zeroext i8 @mult(i8 zeroext %9066, i8 zeroext %9067)
  %conv35.27.16 = zext i8 %call34.27.16 to i32
  %xor36.27.16 = xor i32 %xor.27.16, %conv35.27.16
  %conv37.27.16 = trunc i32 %xor36.27.16 to i8
  store i8 %conv37.27.16, i8* %scevgep41.27.15, align 1
  %scevgep28.27.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9061, i64 0, i64 0, i64 1
  %9068 = bitcast i8* %scevgep28.27.16 to [61 x [61 x i8]]*
  %scevgep41.27.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9062, i64 0, i64 1, i64 0
  %9069 = bitcast i8* %scevgep41.27.16 to [61 x [61 x i8]]*
  %call16.27.17 = call zeroext i8 (...) @rand()
  store i8 %call16.27.17, i8* %scevgep28.27.16, align 1
  %9070 = load i8, i8* %scevgep28.27.16, align 1
  %conv23.27.17 = zext i8 %9070 to i32
  %9071 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.17 = getelementptr i8, i8* %b, i64 45
  %9072 = load i8, i8* %scevgep34.27.17, align 1
  %call28.27.17 = call zeroext i8 @mult(i8 zeroext %9071, i8 zeroext %9072)
  %conv29.27.17 = zext i8 %call28.27.17 to i32
  %xor.27.17 = xor i32 %conv23.27.17, %conv29.27.17
  %scevgep35.27.17 = getelementptr i8, i8* %a, i64 45
  %9073 = load i8, i8* %scevgep35.27.17, align 1
  %9074 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.17 = call zeroext i8 @mult(i8 zeroext %9073, i8 zeroext %9074)
  %conv35.27.17 = zext i8 %call34.27.17 to i32
  %xor36.27.17 = xor i32 %xor.27.17, %conv35.27.17
  %conv37.27.17 = trunc i32 %xor36.27.17 to i8
  store i8 %conv37.27.17, i8* %scevgep41.27.16, align 1
  %scevgep28.27.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9068, i64 0, i64 0, i64 1
  %9075 = bitcast i8* %scevgep28.27.17 to [61 x [61 x i8]]*
  %scevgep41.27.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9069, i64 0, i64 1, i64 0
  %9076 = bitcast i8* %scevgep41.27.17 to [61 x [61 x i8]]*
  %call16.27.18 = call zeroext i8 (...) @rand()
  store i8 %call16.27.18, i8* %scevgep28.27.17, align 1
  %9077 = load i8, i8* %scevgep28.27.17, align 1
  %conv23.27.18 = zext i8 %9077 to i32
  %9078 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.18 = getelementptr i8, i8* %b, i64 46
  %9079 = load i8, i8* %scevgep34.27.18, align 1
  %call28.27.18 = call zeroext i8 @mult(i8 zeroext %9078, i8 zeroext %9079)
  %conv29.27.18 = zext i8 %call28.27.18 to i32
  %xor.27.18 = xor i32 %conv23.27.18, %conv29.27.18
  %scevgep35.27.18 = getelementptr i8, i8* %a, i64 46
  %9080 = load i8, i8* %scevgep35.27.18, align 1
  %9081 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.18 = call zeroext i8 @mult(i8 zeroext %9080, i8 zeroext %9081)
  %conv35.27.18 = zext i8 %call34.27.18 to i32
  %xor36.27.18 = xor i32 %xor.27.18, %conv35.27.18
  %conv37.27.18 = trunc i32 %xor36.27.18 to i8
  store i8 %conv37.27.18, i8* %scevgep41.27.17, align 1
  %scevgep28.27.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9075, i64 0, i64 0, i64 1
  %9082 = bitcast i8* %scevgep28.27.18 to [61 x [61 x i8]]*
  %scevgep41.27.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9076, i64 0, i64 1, i64 0
  %9083 = bitcast i8* %scevgep41.27.18 to [61 x [61 x i8]]*
  %call16.27.19 = call zeroext i8 (...) @rand()
  store i8 %call16.27.19, i8* %scevgep28.27.18, align 1
  %9084 = load i8, i8* %scevgep28.27.18, align 1
  %conv23.27.19 = zext i8 %9084 to i32
  %9085 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.19 = getelementptr i8, i8* %b, i64 47
  %9086 = load i8, i8* %scevgep34.27.19, align 1
  %call28.27.19 = call zeroext i8 @mult(i8 zeroext %9085, i8 zeroext %9086)
  %conv29.27.19 = zext i8 %call28.27.19 to i32
  %xor.27.19 = xor i32 %conv23.27.19, %conv29.27.19
  %scevgep35.27.19 = getelementptr i8, i8* %a, i64 47
  %9087 = load i8, i8* %scevgep35.27.19, align 1
  %9088 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.19 = call zeroext i8 @mult(i8 zeroext %9087, i8 zeroext %9088)
  %conv35.27.19 = zext i8 %call34.27.19 to i32
  %xor36.27.19 = xor i32 %xor.27.19, %conv35.27.19
  %conv37.27.19 = trunc i32 %xor36.27.19 to i8
  store i8 %conv37.27.19, i8* %scevgep41.27.18, align 1
  %scevgep28.27.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9082, i64 0, i64 0, i64 1
  %9089 = bitcast i8* %scevgep28.27.19 to [61 x [61 x i8]]*
  %scevgep41.27.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9083, i64 0, i64 1, i64 0
  %9090 = bitcast i8* %scevgep41.27.19 to [61 x [61 x i8]]*
  %call16.27.20 = call zeroext i8 (...) @rand()
  store i8 %call16.27.20, i8* %scevgep28.27.19, align 1
  %9091 = load i8, i8* %scevgep28.27.19, align 1
  %conv23.27.20 = zext i8 %9091 to i32
  %9092 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.20 = getelementptr i8, i8* %b, i64 48
  %9093 = load i8, i8* %scevgep34.27.20, align 1
  %call28.27.20 = call zeroext i8 @mult(i8 zeroext %9092, i8 zeroext %9093)
  %conv29.27.20 = zext i8 %call28.27.20 to i32
  %xor.27.20 = xor i32 %conv23.27.20, %conv29.27.20
  %scevgep35.27.20 = getelementptr i8, i8* %a, i64 48
  %9094 = load i8, i8* %scevgep35.27.20, align 1
  %9095 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.20 = call zeroext i8 @mult(i8 zeroext %9094, i8 zeroext %9095)
  %conv35.27.20 = zext i8 %call34.27.20 to i32
  %xor36.27.20 = xor i32 %xor.27.20, %conv35.27.20
  %conv37.27.20 = trunc i32 %xor36.27.20 to i8
  store i8 %conv37.27.20, i8* %scevgep41.27.19, align 1
  %scevgep28.27.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9089, i64 0, i64 0, i64 1
  %9096 = bitcast i8* %scevgep28.27.20 to [61 x [61 x i8]]*
  %scevgep41.27.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9090, i64 0, i64 1, i64 0
  %9097 = bitcast i8* %scevgep41.27.20 to [61 x [61 x i8]]*
  %call16.27.21 = call zeroext i8 (...) @rand()
  store i8 %call16.27.21, i8* %scevgep28.27.20, align 1
  %9098 = load i8, i8* %scevgep28.27.20, align 1
  %conv23.27.21 = zext i8 %9098 to i32
  %9099 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.21 = getelementptr i8, i8* %b, i64 49
  %9100 = load i8, i8* %scevgep34.27.21, align 1
  %call28.27.21 = call zeroext i8 @mult(i8 zeroext %9099, i8 zeroext %9100)
  %conv29.27.21 = zext i8 %call28.27.21 to i32
  %xor.27.21 = xor i32 %conv23.27.21, %conv29.27.21
  %scevgep35.27.21 = getelementptr i8, i8* %a, i64 49
  %9101 = load i8, i8* %scevgep35.27.21, align 1
  %9102 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.21 = call zeroext i8 @mult(i8 zeroext %9101, i8 zeroext %9102)
  %conv35.27.21 = zext i8 %call34.27.21 to i32
  %xor36.27.21 = xor i32 %xor.27.21, %conv35.27.21
  %conv37.27.21 = trunc i32 %xor36.27.21 to i8
  store i8 %conv37.27.21, i8* %scevgep41.27.20, align 1
  %scevgep28.27.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9096, i64 0, i64 0, i64 1
  %9103 = bitcast i8* %scevgep28.27.21 to [61 x [61 x i8]]*
  %scevgep41.27.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9097, i64 0, i64 1, i64 0
  %9104 = bitcast i8* %scevgep41.27.21 to [61 x [61 x i8]]*
  %call16.27.22 = call zeroext i8 (...) @rand()
  store i8 %call16.27.22, i8* %scevgep28.27.21, align 1
  %9105 = load i8, i8* %scevgep28.27.21, align 1
  %conv23.27.22 = zext i8 %9105 to i32
  %9106 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.22 = getelementptr i8, i8* %b, i64 50
  %9107 = load i8, i8* %scevgep34.27.22, align 1
  %call28.27.22 = call zeroext i8 @mult(i8 zeroext %9106, i8 zeroext %9107)
  %conv29.27.22 = zext i8 %call28.27.22 to i32
  %xor.27.22 = xor i32 %conv23.27.22, %conv29.27.22
  %scevgep35.27.22 = getelementptr i8, i8* %a, i64 50
  %9108 = load i8, i8* %scevgep35.27.22, align 1
  %9109 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.22 = call zeroext i8 @mult(i8 zeroext %9108, i8 zeroext %9109)
  %conv35.27.22 = zext i8 %call34.27.22 to i32
  %xor36.27.22 = xor i32 %xor.27.22, %conv35.27.22
  %conv37.27.22 = trunc i32 %xor36.27.22 to i8
  store i8 %conv37.27.22, i8* %scevgep41.27.21, align 1
  %scevgep28.27.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9103, i64 0, i64 0, i64 1
  %9110 = bitcast i8* %scevgep28.27.22 to [61 x [61 x i8]]*
  %scevgep41.27.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9104, i64 0, i64 1, i64 0
  %9111 = bitcast i8* %scevgep41.27.22 to [61 x [61 x i8]]*
  %call16.27.23 = call zeroext i8 (...) @rand()
  store i8 %call16.27.23, i8* %scevgep28.27.22, align 1
  %9112 = load i8, i8* %scevgep28.27.22, align 1
  %conv23.27.23 = zext i8 %9112 to i32
  %9113 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.23 = getelementptr i8, i8* %b, i64 51
  %9114 = load i8, i8* %scevgep34.27.23, align 1
  %call28.27.23 = call zeroext i8 @mult(i8 zeroext %9113, i8 zeroext %9114)
  %conv29.27.23 = zext i8 %call28.27.23 to i32
  %xor.27.23 = xor i32 %conv23.27.23, %conv29.27.23
  %scevgep35.27.23 = getelementptr i8, i8* %a, i64 51
  %9115 = load i8, i8* %scevgep35.27.23, align 1
  %9116 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.23 = call zeroext i8 @mult(i8 zeroext %9115, i8 zeroext %9116)
  %conv35.27.23 = zext i8 %call34.27.23 to i32
  %xor36.27.23 = xor i32 %xor.27.23, %conv35.27.23
  %conv37.27.23 = trunc i32 %xor36.27.23 to i8
  store i8 %conv37.27.23, i8* %scevgep41.27.22, align 1
  %scevgep28.27.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9110, i64 0, i64 0, i64 1
  %9117 = bitcast i8* %scevgep28.27.23 to [61 x [61 x i8]]*
  %scevgep41.27.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9111, i64 0, i64 1, i64 0
  %9118 = bitcast i8* %scevgep41.27.23 to [61 x [61 x i8]]*
  %call16.27.24 = call zeroext i8 (...) @rand()
  store i8 %call16.27.24, i8* %scevgep28.27.23, align 1
  %9119 = load i8, i8* %scevgep28.27.23, align 1
  %conv23.27.24 = zext i8 %9119 to i32
  %9120 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.24 = getelementptr i8, i8* %b, i64 52
  %9121 = load i8, i8* %scevgep34.27.24, align 1
  %call28.27.24 = call zeroext i8 @mult(i8 zeroext %9120, i8 zeroext %9121)
  %conv29.27.24 = zext i8 %call28.27.24 to i32
  %xor.27.24 = xor i32 %conv23.27.24, %conv29.27.24
  %scevgep35.27.24 = getelementptr i8, i8* %a, i64 52
  %9122 = load i8, i8* %scevgep35.27.24, align 1
  %9123 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.24 = call zeroext i8 @mult(i8 zeroext %9122, i8 zeroext %9123)
  %conv35.27.24 = zext i8 %call34.27.24 to i32
  %xor36.27.24 = xor i32 %xor.27.24, %conv35.27.24
  %conv37.27.24 = trunc i32 %xor36.27.24 to i8
  store i8 %conv37.27.24, i8* %scevgep41.27.23, align 1
  %scevgep28.27.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9117, i64 0, i64 0, i64 1
  %9124 = bitcast i8* %scevgep28.27.24 to [61 x [61 x i8]]*
  %scevgep41.27.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9118, i64 0, i64 1, i64 0
  %9125 = bitcast i8* %scevgep41.27.24 to [61 x [61 x i8]]*
  %call16.27.25 = call zeroext i8 (...) @rand()
  store i8 %call16.27.25, i8* %scevgep28.27.24, align 1
  %9126 = load i8, i8* %scevgep28.27.24, align 1
  %conv23.27.25 = zext i8 %9126 to i32
  %9127 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.25 = getelementptr i8, i8* %b, i64 53
  %9128 = load i8, i8* %scevgep34.27.25, align 1
  %call28.27.25 = call zeroext i8 @mult(i8 zeroext %9127, i8 zeroext %9128)
  %conv29.27.25 = zext i8 %call28.27.25 to i32
  %xor.27.25 = xor i32 %conv23.27.25, %conv29.27.25
  %scevgep35.27.25 = getelementptr i8, i8* %a, i64 53
  %9129 = load i8, i8* %scevgep35.27.25, align 1
  %9130 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.25 = call zeroext i8 @mult(i8 zeroext %9129, i8 zeroext %9130)
  %conv35.27.25 = zext i8 %call34.27.25 to i32
  %xor36.27.25 = xor i32 %xor.27.25, %conv35.27.25
  %conv37.27.25 = trunc i32 %xor36.27.25 to i8
  store i8 %conv37.27.25, i8* %scevgep41.27.24, align 1
  %scevgep28.27.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9124, i64 0, i64 0, i64 1
  %9131 = bitcast i8* %scevgep28.27.25 to [61 x [61 x i8]]*
  %scevgep41.27.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9125, i64 0, i64 1, i64 0
  %9132 = bitcast i8* %scevgep41.27.25 to [61 x [61 x i8]]*
  %call16.27.26 = call zeroext i8 (...) @rand()
  store i8 %call16.27.26, i8* %scevgep28.27.25, align 1
  %9133 = load i8, i8* %scevgep28.27.25, align 1
  %conv23.27.26 = zext i8 %9133 to i32
  %9134 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.26 = getelementptr i8, i8* %b, i64 54
  %9135 = load i8, i8* %scevgep34.27.26, align 1
  %call28.27.26 = call zeroext i8 @mult(i8 zeroext %9134, i8 zeroext %9135)
  %conv29.27.26 = zext i8 %call28.27.26 to i32
  %xor.27.26 = xor i32 %conv23.27.26, %conv29.27.26
  %scevgep35.27.26 = getelementptr i8, i8* %a, i64 54
  %9136 = load i8, i8* %scevgep35.27.26, align 1
  %9137 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.26 = call zeroext i8 @mult(i8 zeroext %9136, i8 zeroext %9137)
  %conv35.27.26 = zext i8 %call34.27.26 to i32
  %xor36.27.26 = xor i32 %xor.27.26, %conv35.27.26
  %conv37.27.26 = trunc i32 %xor36.27.26 to i8
  store i8 %conv37.27.26, i8* %scevgep41.27.25, align 1
  %scevgep28.27.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9131, i64 0, i64 0, i64 1
  %9138 = bitcast i8* %scevgep28.27.26 to [61 x [61 x i8]]*
  %scevgep41.27.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9132, i64 0, i64 1, i64 0
  %9139 = bitcast i8* %scevgep41.27.26 to [61 x [61 x i8]]*
  %call16.27.27 = call zeroext i8 (...) @rand()
  store i8 %call16.27.27, i8* %scevgep28.27.26, align 1
  %9140 = load i8, i8* %scevgep28.27.26, align 1
  %conv23.27.27 = zext i8 %9140 to i32
  %9141 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.27 = getelementptr i8, i8* %b, i64 55
  %9142 = load i8, i8* %scevgep34.27.27, align 1
  %call28.27.27 = call zeroext i8 @mult(i8 zeroext %9141, i8 zeroext %9142)
  %conv29.27.27 = zext i8 %call28.27.27 to i32
  %xor.27.27 = xor i32 %conv23.27.27, %conv29.27.27
  %scevgep35.27.27 = getelementptr i8, i8* %a, i64 55
  %9143 = load i8, i8* %scevgep35.27.27, align 1
  %9144 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.27 = call zeroext i8 @mult(i8 zeroext %9143, i8 zeroext %9144)
  %conv35.27.27 = zext i8 %call34.27.27 to i32
  %xor36.27.27 = xor i32 %xor.27.27, %conv35.27.27
  %conv37.27.27 = trunc i32 %xor36.27.27 to i8
  store i8 %conv37.27.27, i8* %scevgep41.27.26, align 1
  %scevgep28.27.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9138, i64 0, i64 0, i64 1
  %9145 = bitcast i8* %scevgep28.27.27 to [61 x [61 x i8]]*
  %scevgep41.27.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9139, i64 0, i64 1, i64 0
  %9146 = bitcast i8* %scevgep41.27.27 to [61 x [61 x i8]]*
  %call16.27.28 = call zeroext i8 (...) @rand()
  store i8 %call16.27.28, i8* %scevgep28.27.27, align 1
  %9147 = load i8, i8* %scevgep28.27.27, align 1
  %conv23.27.28 = zext i8 %9147 to i32
  %9148 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.28 = getelementptr i8, i8* %b, i64 56
  %9149 = load i8, i8* %scevgep34.27.28, align 1
  %call28.27.28 = call zeroext i8 @mult(i8 zeroext %9148, i8 zeroext %9149)
  %conv29.27.28 = zext i8 %call28.27.28 to i32
  %xor.27.28 = xor i32 %conv23.27.28, %conv29.27.28
  %scevgep35.27.28 = getelementptr i8, i8* %a, i64 56
  %9150 = load i8, i8* %scevgep35.27.28, align 1
  %9151 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.28 = call zeroext i8 @mult(i8 zeroext %9150, i8 zeroext %9151)
  %conv35.27.28 = zext i8 %call34.27.28 to i32
  %xor36.27.28 = xor i32 %xor.27.28, %conv35.27.28
  %conv37.27.28 = trunc i32 %xor36.27.28 to i8
  store i8 %conv37.27.28, i8* %scevgep41.27.27, align 1
  %scevgep28.27.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9145, i64 0, i64 0, i64 1
  %9152 = bitcast i8* %scevgep28.27.28 to [61 x [61 x i8]]*
  %scevgep41.27.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9146, i64 0, i64 1, i64 0
  %9153 = bitcast i8* %scevgep41.27.28 to [61 x [61 x i8]]*
  %call16.27.29 = call zeroext i8 (...) @rand()
  store i8 %call16.27.29, i8* %scevgep28.27.28, align 1
  %9154 = load i8, i8* %scevgep28.27.28, align 1
  %conv23.27.29 = zext i8 %9154 to i32
  %9155 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.29 = getelementptr i8, i8* %b, i64 57
  %9156 = load i8, i8* %scevgep34.27.29, align 1
  %call28.27.29 = call zeroext i8 @mult(i8 zeroext %9155, i8 zeroext %9156)
  %conv29.27.29 = zext i8 %call28.27.29 to i32
  %xor.27.29 = xor i32 %conv23.27.29, %conv29.27.29
  %scevgep35.27.29 = getelementptr i8, i8* %a, i64 57
  %9157 = load i8, i8* %scevgep35.27.29, align 1
  %9158 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.29 = call zeroext i8 @mult(i8 zeroext %9157, i8 zeroext %9158)
  %conv35.27.29 = zext i8 %call34.27.29 to i32
  %xor36.27.29 = xor i32 %xor.27.29, %conv35.27.29
  %conv37.27.29 = trunc i32 %xor36.27.29 to i8
  store i8 %conv37.27.29, i8* %scevgep41.27.28, align 1
  %scevgep28.27.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9152, i64 0, i64 0, i64 1
  %9159 = bitcast i8* %scevgep28.27.29 to [61 x [61 x i8]]*
  %scevgep41.27.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9153, i64 0, i64 1, i64 0
  %9160 = bitcast i8* %scevgep41.27.29 to [61 x [61 x i8]]*
  %call16.27.30 = call zeroext i8 (...) @rand()
  store i8 %call16.27.30, i8* %scevgep28.27.29, align 1
  %9161 = load i8, i8* %scevgep28.27.29, align 1
  %conv23.27.30 = zext i8 %9161 to i32
  %9162 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.30 = getelementptr i8, i8* %b, i64 58
  %9163 = load i8, i8* %scevgep34.27.30, align 1
  %call28.27.30 = call zeroext i8 @mult(i8 zeroext %9162, i8 zeroext %9163)
  %conv29.27.30 = zext i8 %call28.27.30 to i32
  %xor.27.30 = xor i32 %conv23.27.30, %conv29.27.30
  %scevgep35.27.30 = getelementptr i8, i8* %a, i64 58
  %9164 = load i8, i8* %scevgep35.27.30, align 1
  %9165 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.30 = call zeroext i8 @mult(i8 zeroext %9164, i8 zeroext %9165)
  %conv35.27.30 = zext i8 %call34.27.30 to i32
  %xor36.27.30 = xor i32 %xor.27.30, %conv35.27.30
  %conv37.27.30 = trunc i32 %xor36.27.30 to i8
  store i8 %conv37.27.30, i8* %scevgep41.27.29, align 1
  %scevgep28.27.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9159, i64 0, i64 0, i64 1
  %9166 = bitcast i8* %scevgep28.27.30 to [61 x [61 x i8]]*
  %scevgep41.27.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9160, i64 0, i64 1, i64 0
  %9167 = bitcast i8* %scevgep41.27.30 to [61 x [61 x i8]]*
  %call16.27.31 = call zeroext i8 (...) @rand()
  store i8 %call16.27.31, i8* %scevgep28.27.30, align 1
  %9168 = load i8, i8* %scevgep28.27.30, align 1
  %conv23.27.31 = zext i8 %9168 to i32
  %9169 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.31 = getelementptr i8, i8* %b, i64 59
  %9170 = load i8, i8* %scevgep34.27.31, align 1
  %call28.27.31 = call zeroext i8 @mult(i8 zeroext %9169, i8 zeroext %9170)
  %conv29.27.31 = zext i8 %call28.27.31 to i32
  %xor.27.31 = xor i32 %conv23.27.31, %conv29.27.31
  %scevgep35.27.31 = getelementptr i8, i8* %a, i64 59
  %9171 = load i8, i8* %scevgep35.27.31, align 1
  %9172 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.31 = call zeroext i8 @mult(i8 zeroext %9171, i8 zeroext %9172)
  %conv35.27.31 = zext i8 %call34.27.31 to i32
  %xor36.27.31 = xor i32 %xor.27.31, %conv35.27.31
  %conv37.27.31 = trunc i32 %xor36.27.31 to i8
  store i8 %conv37.27.31, i8* %scevgep41.27.30, align 1
  %scevgep28.27.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9166, i64 0, i64 0, i64 1
  %scevgep41.27.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9167, i64 0, i64 1, i64 0
  %call16.27.32 = call zeroext i8 (...) @rand()
  store i8 %call16.27.32, i8* %scevgep28.27.31, align 1
  %9173 = load i8, i8* %scevgep28.27.31, align 1
  %conv23.27.32 = zext i8 %9173 to i32
  %9174 = load i8, i8* %arrayidx25.27, align 1
  %scevgep34.27.32 = getelementptr i8, i8* %b, i64 60
  %9175 = load i8, i8* %scevgep34.27.32, align 1
  %call28.27.32 = call zeroext i8 @mult(i8 zeroext %9174, i8 zeroext %9175)
  %conv29.27.32 = zext i8 %call28.27.32 to i32
  %xor.27.32 = xor i32 %conv23.27.32, %conv29.27.32
  %scevgep35.27.32 = getelementptr i8, i8* %a, i64 60
  %9176 = load i8, i8* %scevgep35.27.32, align 1
  %9177 = load i8, i8* %arrayidx33.27, align 1
  %call34.27.32 = call zeroext i8 @mult(i8 zeroext %9176, i8 zeroext %9177)
  %conv35.27.32 = zext i8 %call34.27.32 to i32
  %xor36.27.32 = xor i32 %xor.27.32, %conv35.27.32
  %conv37.27.32 = trunc i32 %xor36.27.32 to i8
  store i8 %conv37.27.32, i8* %scevgep41.27.31, align 1
  %scevgep26.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8949, i64 0, i64 1, i64 1
  %9178 = bitcast i8* %scevgep26.27 to [61 x [61 x i8]]*
  %scevgep39.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %8950, i64 0, i64 1, i64 1
  %9179 = bitcast i8* %scevgep39.27 to [61 x [61 x i8]]*
  %arrayidx25.28 = getelementptr inbounds i8, i8* %a, i64 28
  %arrayidx33.28 = getelementptr inbounds i8, i8* %b, i64 28
  %call16.28 = call zeroext i8 (...) @rand()
  store i8 %call16.28, i8* %scevgep26.27, align 1
  %9180 = load i8, i8* %scevgep26.27, align 1
  %conv23.28 = zext i8 %9180 to i32
  %9181 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28 = getelementptr i8, i8* %b, i64 29
  %9182 = load i8, i8* %scevgep34.28, align 1
  %call28.28 = call zeroext i8 @mult(i8 zeroext %9181, i8 zeroext %9182)
  %conv29.28 = zext i8 %call28.28 to i32
  %xor.28 = xor i32 %conv23.28, %conv29.28
  %scevgep35.28 = getelementptr i8, i8* %a, i64 29
  %9183 = load i8, i8* %scevgep35.28, align 1
  %9184 = load i8, i8* %arrayidx33.28, align 1
  %call34.28 = call zeroext i8 @mult(i8 zeroext %9183, i8 zeroext %9184)
  %conv35.28 = zext i8 %call34.28 to i32
  %xor36.28 = xor i32 %xor.28, %conv35.28
  %conv37.28 = trunc i32 %xor36.28 to i8
  store i8 %conv37.28, i8* %scevgep39.27, align 1
  %scevgep28.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9178, i64 0, i64 0, i64 1
  %9185 = bitcast i8* %scevgep28.28 to [61 x [61 x i8]]*
  %scevgep41.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9179, i64 0, i64 1, i64 0
  %9186 = bitcast i8* %scevgep41.28 to [61 x [61 x i8]]*
  %call16.28.1 = call zeroext i8 (...) @rand()
  store i8 %call16.28.1, i8* %scevgep28.28, align 1
  %9187 = load i8, i8* %scevgep28.28, align 1
  %conv23.28.1 = zext i8 %9187 to i32
  %9188 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.1 = getelementptr i8, i8* %b, i64 30
  %9189 = load i8, i8* %scevgep34.28.1, align 1
  %call28.28.1 = call zeroext i8 @mult(i8 zeroext %9188, i8 zeroext %9189)
  %conv29.28.1 = zext i8 %call28.28.1 to i32
  %xor.28.1 = xor i32 %conv23.28.1, %conv29.28.1
  %scevgep35.28.1 = getelementptr i8, i8* %a, i64 30
  %9190 = load i8, i8* %scevgep35.28.1, align 1
  %9191 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.1 = call zeroext i8 @mult(i8 zeroext %9190, i8 zeroext %9191)
  %conv35.28.1 = zext i8 %call34.28.1 to i32
  %xor36.28.1 = xor i32 %xor.28.1, %conv35.28.1
  %conv37.28.1 = trunc i32 %xor36.28.1 to i8
  store i8 %conv37.28.1, i8* %scevgep41.28, align 1
  %scevgep28.28.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9185, i64 0, i64 0, i64 1
  %9192 = bitcast i8* %scevgep28.28.1 to [61 x [61 x i8]]*
  %scevgep41.28.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9186, i64 0, i64 1, i64 0
  %9193 = bitcast i8* %scevgep41.28.1 to [61 x [61 x i8]]*
  %call16.28.2 = call zeroext i8 (...) @rand()
  store i8 %call16.28.2, i8* %scevgep28.28.1, align 1
  %9194 = load i8, i8* %scevgep28.28.1, align 1
  %conv23.28.2 = zext i8 %9194 to i32
  %9195 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.2 = getelementptr i8, i8* %b, i64 31
  %9196 = load i8, i8* %scevgep34.28.2, align 1
  %call28.28.2 = call zeroext i8 @mult(i8 zeroext %9195, i8 zeroext %9196)
  %conv29.28.2 = zext i8 %call28.28.2 to i32
  %xor.28.2 = xor i32 %conv23.28.2, %conv29.28.2
  %scevgep35.28.2 = getelementptr i8, i8* %a, i64 31
  %9197 = load i8, i8* %scevgep35.28.2, align 1
  %9198 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.2 = call zeroext i8 @mult(i8 zeroext %9197, i8 zeroext %9198)
  %conv35.28.2 = zext i8 %call34.28.2 to i32
  %xor36.28.2 = xor i32 %xor.28.2, %conv35.28.2
  %conv37.28.2 = trunc i32 %xor36.28.2 to i8
  store i8 %conv37.28.2, i8* %scevgep41.28.1, align 1
  %scevgep28.28.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9192, i64 0, i64 0, i64 1
  %9199 = bitcast i8* %scevgep28.28.2 to [61 x [61 x i8]]*
  %scevgep41.28.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9193, i64 0, i64 1, i64 0
  %9200 = bitcast i8* %scevgep41.28.2 to [61 x [61 x i8]]*
  %call16.28.3 = call zeroext i8 (...) @rand()
  store i8 %call16.28.3, i8* %scevgep28.28.2, align 1
  %9201 = load i8, i8* %scevgep28.28.2, align 1
  %conv23.28.3 = zext i8 %9201 to i32
  %9202 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.3 = getelementptr i8, i8* %b, i64 32
  %9203 = load i8, i8* %scevgep34.28.3, align 1
  %call28.28.3 = call zeroext i8 @mult(i8 zeroext %9202, i8 zeroext %9203)
  %conv29.28.3 = zext i8 %call28.28.3 to i32
  %xor.28.3 = xor i32 %conv23.28.3, %conv29.28.3
  %scevgep35.28.3 = getelementptr i8, i8* %a, i64 32
  %9204 = load i8, i8* %scevgep35.28.3, align 1
  %9205 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.3 = call zeroext i8 @mult(i8 zeroext %9204, i8 zeroext %9205)
  %conv35.28.3 = zext i8 %call34.28.3 to i32
  %xor36.28.3 = xor i32 %xor.28.3, %conv35.28.3
  %conv37.28.3 = trunc i32 %xor36.28.3 to i8
  store i8 %conv37.28.3, i8* %scevgep41.28.2, align 1
  %scevgep28.28.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9199, i64 0, i64 0, i64 1
  %9206 = bitcast i8* %scevgep28.28.3 to [61 x [61 x i8]]*
  %scevgep41.28.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9200, i64 0, i64 1, i64 0
  %9207 = bitcast i8* %scevgep41.28.3 to [61 x [61 x i8]]*
  %call16.28.4 = call zeroext i8 (...) @rand()
  store i8 %call16.28.4, i8* %scevgep28.28.3, align 1
  %9208 = load i8, i8* %scevgep28.28.3, align 1
  %conv23.28.4 = zext i8 %9208 to i32
  %9209 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.4 = getelementptr i8, i8* %b, i64 33
  %9210 = load i8, i8* %scevgep34.28.4, align 1
  %call28.28.4 = call zeroext i8 @mult(i8 zeroext %9209, i8 zeroext %9210)
  %conv29.28.4 = zext i8 %call28.28.4 to i32
  %xor.28.4 = xor i32 %conv23.28.4, %conv29.28.4
  %scevgep35.28.4 = getelementptr i8, i8* %a, i64 33
  %9211 = load i8, i8* %scevgep35.28.4, align 1
  %9212 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.4 = call zeroext i8 @mult(i8 zeroext %9211, i8 zeroext %9212)
  %conv35.28.4 = zext i8 %call34.28.4 to i32
  %xor36.28.4 = xor i32 %xor.28.4, %conv35.28.4
  %conv37.28.4 = trunc i32 %xor36.28.4 to i8
  store i8 %conv37.28.4, i8* %scevgep41.28.3, align 1
  %scevgep28.28.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9206, i64 0, i64 0, i64 1
  %9213 = bitcast i8* %scevgep28.28.4 to [61 x [61 x i8]]*
  %scevgep41.28.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9207, i64 0, i64 1, i64 0
  %9214 = bitcast i8* %scevgep41.28.4 to [61 x [61 x i8]]*
  %call16.28.5 = call zeroext i8 (...) @rand()
  store i8 %call16.28.5, i8* %scevgep28.28.4, align 1
  %9215 = load i8, i8* %scevgep28.28.4, align 1
  %conv23.28.5 = zext i8 %9215 to i32
  %9216 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.5 = getelementptr i8, i8* %b, i64 34
  %9217 = load i8, i8* %scevgep34.28.5, align 1
  %call28.28.5 = call zeroext i8 @mult(i8 zeroext %9216, i8 zeroext %9217)
  %conv29.28.5 = zext i8 %call28.28.5 to i32
  %xor.28.5 = xor i32 %conv23.28.5, %conv29.28.5
  %scevgep35.28.5 = getelementptr i8, i8* %a, i64 34
  %9218 = load i8, i8* %scevgep35.28.5, align 1
  %9219 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.5 = call zeroext i8 @mult(i8 zeroext %9218, i8 zeroext %9219)
  %conv35.28.5 = zext i8 %call34.28.5 to i32
  %xor36.28.5 = xor i32 %xor.28.5, %conv35.28.5
  %conv37.28.5 = trunc i32 %xor36.28.5 to i8
  store i8 %conv37.28.5, i8* %scevgep41.28.4, align 1
  %scevgep28.28.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9213, i64 0, i64 0, i64 1
  %9220 = bitcast i8* %scevgep28.28.5 to [61 x [61 x i8]]*
  %scevgep41.28.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9214, i64 0, i64 1, i64 0
  %9221 = bitcast i8* %scevgep41.28.5 to [61 x [61 x i8]]*
  %call16.28.6 = call zeroext i8 (...) @rand()
  store i8 %call16.28.6, i8* %scevgep28.28.5, align 1
  %9222 = load i8, i8* %scevgep28.28.5, align 1
  %conv23.28.6 = zext i8 %9222 to i32
  %9223 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.6 = getelementptr i8, i8* %b, i64 35
  %9224 = load i8, i8* %scevgep34.28.6, align 1
  %call28.28.6 = call zeroext i8 @mult(i8 zeroext %9223, i8 zeroext %9224)
  %conv29.28.6 = zext i8 %call28.28.6 to i32
  %xor.28.6 = xor i32 %conv23.28.6, %conv29.28.6
  %scevgep35.28.6 = getelementptr i8, i8* %a, i64 35
  %9225 = load i8, i8* %scevgep35.28.6, align 1
  %9226 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.6 = call zeroext i8 @mult(i8 zeroext %9225, i8 zeroext %9226)
  %conv35.28.6 = zext i8 %call34.28.6 to i32
  %xor36.28.6 = xor i32 %xor.28.6, %conv35.28.6
  %conv37.28.6 = trunc i32 %xor36.28.6 to i8
  store i8 %conv37.28.6, i8* %scevgep41.28.5, align 1
  %scevgep28.28.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9220, i64 0, i64 0, i64 1
  %9227 = bitcast i8* %scevgep28.28.6 to [61 x [61 x i8]]*
  %scevgep41.28.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9221, i64 0, i64 1, i64 0
  %9228 = bitcast i8* %scevgep41.28.6 to [61 x [61 x i8]]*
  %call16.28.7 = call zeroext i8 (...) @rand()
  store i8 %call16.28.7, i8* %scevgep28.28.6, align 1
  %9229 = load i8, i8* %scevgep28.28.6, align 1
  %conv23.28.7 = zext i8 %9229 to i32
  %9230 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.7 = getelementptr i8, i8* %b, i64 36
  %9231 = load i8, i8* %scevgep34.28.7, align 1
  %call28.28.7 = call zeroext i8 @mult(i8 zeroext %9230, i8 zeroext %9231)
  %conv29.28.7 = zext i8 %call28.28.7 to i32
  %xor.28.7 = xor i32 %conv23.28.7, %conv29.28.7
  %scevgep35.28.7 = getelementptr i8, i8* %a, i64 36
  %9232 = load i8, i8* %scevgep35.28.7, align 1
  %9233 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.7 = call zeroext i8 @mult(i8 zeroext %9232, i8 zeroext %9233)
  %conv35.28.7 = zext i8 %call34.28.7 to i32
  %xor36.28.7 = xor i32 %xor.28.7, %conv35.28.7
  %conv37.28.7 = trunc i32 %xor36.28.7 to i8
  store i8 %conv37.28.7, i8* %scevgep41.28.6, align 1
  %scevgep28.28.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9227, i64 0, i64 0, i64 1
  %9234 = bitcast i8* %scevgep28.28.7 to [61 x [61 x i8]]*
  %scevgep41.28.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9228, i64 0, i64 1, i64 0
  %9235 = bitcast i8* %scevgep41.28.7 to [61 x [61 x i8]]*
  %call16.28.8 = call zeroext i8 (...) @rand()
  store i8 %call16.28.8, i8* %scevgep28.28.7, align 1
  %9236 = load i8, i8* %scevgep28.28.7, align 1
  %conv23.28.8 = zext i8 %9236 to i32
  %9237 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.8 = getelementptr i8, i8* %b, i64 37
  %9238 = load i8, i8* %scevgep34.28.8, align 1
  %call28.28.8 = call zeroext i8 @mult(i8 zeroext %9237, i8 zeroext %9238)
  %conv29.28.8 = zext i8 %call28.28.8 to i32
  %xor.28.8 = xor i32 %conv23.28.8, %conv29.28.8
  %scevgep35.28.8 = getelementptr i8, i8* %a, i64 37
  %9239 = load i8, i8* %scevgep35.28.8, align 1
  %9240 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.8 = call zeroext i8 @mult(i8 zeroext %9239, i8 zeroext %9240)
  %conv35.28.8 = zext i8 %call34.28.8 to i32
  %xor36.28.8 = xor i32 %xor.28.8, %conv35.28.8
  %conv37.28.8 = trunc i32 %xor36.28.8 to i8
  store i8 %conv37.28.8, i8* %scevgep41.28.7, align 1
  %scevgep28.28.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9234, i64 0, i64 0, i64 1
  %9241 = bitcast i8* %scevgep28.28.8 to [61 x [61 x i8]]*
  %scevgep41.28.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9235, i64 0, i64 1, i64 0
  %9242 = bitcast i8* %scevgep41.28.8 to [61 x [61 x i8]]*
  %call16.28.9 = call zeroext i8 (...) @rand()
  store i8 %call16.28.9, i8* %scevgep28.28.8, align 1
  %9243 = load i8, i8* %scevgep28.28.8, align 1
  %conv23.28.9 = zext i8 %9243 to i32
  %9244 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.9 = getelementptr i8, i8* %b, i64 38
  %9245 = load i8, i8* %scevgep34.28.9, align 1
  %call28.28.9 = call zeroext i8 @mult(i8 zeroext %9244, i8 zeroext %9245)
  %conv29.28.9 = zext i8 %call28.28.9 to i32
  %xor.28.9 = xor i32 %conv23.28.9, %conv29.28.9
  %scevgep35.28.9 = getelementptr i8, i8* %a, i64 38
  %9246 = load i8, i8* %scevgep35.28.9, align 1
  %9247 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.9 = call zeroext i8 @mult(i8 zeroext %9246, i8 zeroext %9247)
  %conv35.28.9 = zext i8 %call34.28.9 to i32
  %xor36.28.9 = xor i32 %xor.28.9, %conv35.28.9
  %conv37.28.9 = trunc i32 %xor36.28.9 to i8
  store i8 %conv37.28.9, i8* %scevgep41.28.8, align 1
  %scevgep28.28.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9241, i64 0, i64 0, i64 1
  %9248 = bitcast i8* %scevgep28.28.9 to [61 x [61 x i8]]*
  %scevgep41.28.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9242, i64 0, i64 1, i64 0
  %9249 = bitcast i8* %scevgep41.28.9 to [61 x [61 x i8]]*
  %call16.28.10 = call zeroext i8 (...) @rand()
  store i8 %call16.28.10, i8* %scevgep28.28.9, align 1
  %9250 = load i8, i8* %scevgep28.28.9, align 1
  %conv23.28.10 = zext i8 %9250 to i32
  %9251 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.10 = getelementptr i8, i8* %b, i64 39
  %9252 = load i8, i8* %scevgep34.28.10, align 1
  %call28.28.10 = call zeroext i8 @mult(i8 zeroext %9251, i8 zeroext %9252)
  %conv29.28.10 = zext i8 %call28.28.10 to i32
  %xor.28.10 = xor i32 %conv23.28.10, %conv29.28.10
  %scevgep35.28.10 = getelementptr i8, i8* %a, i64 39
  %9253 = load i8, i8* %scevgep35.28.10, align 1
  %9254 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.10 = call zeroext i8 @mult(i8 zeroext %9253, i8 zeroext %9254)
  %conv35.28.10 = zext i8 %call34.28.10 to i32
  %xor36.28.10 = xor i32 %xor.28.10, %conv35.28.10
  %conv37.28.10 = trunc i32 %xor36.28.10 to i8
  store i8 %conv37.28.10, i8* %scevgep41.28.9, align 1
  %scevgep28.28.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9248, i64 0, i64 0, i64 1
  %9255 = bitcast i8* %scevgep28.28.10 to [61 x [61 x i8]]*
  %scevgep41.28.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9249, i64 0, i64 1, i64 0
  %9256 = bitcast i8* %scevgep41.28.10 to [61 x [61 x i8]]*
  %call16.28.11 = call zeroext i8 (...) @rand()
  store i8 %call16.28.11, i8* %scevgep28.28.10, align 1
  %9257 = load i8, i8* %scevgep28.28.10, align 1
  %conv23.28.11 = zext i8 %9257 to i32
  %9258 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.11 = getelementptr i8, i8* %b, i64 40
  %9259 = load i8, i8* %scevgep34.28.11, align 1
  %call28.28.11 = call zeroext i8 @mult(i8 zeroext %9258, i8 zeroext %9259)
  %conv29.28.11 = zext i8 %call28.28.11 to i32
  %xor.28.11 = xor i32 %conv23.28.11, %conv29.28.11
  %scevgep35.28.11 = getelementptr i8, i8* %a, i64 40
  %9260 = load i8, i8* %scevgep35.28.11, align 1
  %9261 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.11 = call zeroext i8 @mult(i8 zeroext %9260, i8 zeroext %9261)
  %conv35.28.11 = zext i8 %call34.28.11 to i32
  %xor36.28.11 = xor i32 %xor.28.11, %conv35.28.11
  %conv37.28.11 = trunc i32 %xor36.28.11 to i8
  store i8 %conv37.28.11, i8* %scevgep41.28.10, align 1
  %scevgep28.28.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9255, i64 0, i64 0, i64 1
  %9262 = bitcast i8* %scevgep28.28.11 to [61 x [61 x i8]]*
  %scevgep41.28.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9256, i64 0, i64 1, i64 0
  %9263 = bitcast i8* %scevgep41.28.11 to [61 x [61 x i8]]*
  %call16.28.12 = call zeroext i8 (...) @rand()
  store i8 %call16.28.12, i8* %scevgep28.28.11, align 1
  %9264 = load i8, i8* %scevgep28.28.11, align 1
  %conv23.28.12 = zext i8 %9264 to i32
  %9265 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.12 = getelementptr i8, i8* %b, i64 41
  %9266 = load i8, i8* %scevgep34.28.12, align 1
  %call28.28.12 = call zeroext i8 @mult(i8 zeroext %9265, i8 zeroext %9266)
  %conv29.28.12 = zext i8 %call28.28.12 to i32
  %xor.28.12 = xor i32 %conv23.28.12, %conv29.28.12
  %scevgep35.28.12 = getelementptr i8, i8* %a, i64 41
  %9267 = load i8, i8* %scevgep35.28.12, align 1
  %9268 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.12 = call zeroext i8 @mult(i8 zeroext %9267, i8 zeroext %9268)
  %conv35.28.12 = zext i8 %call34.28.12 to i32
  %xor36.28.12 = xor i32 %xor.28.12, %conv35.28.12
  %conv37.28.12 = trunc i32 %xor36.28.12 to i8
  store i8 %conv37.28.12, i8* %scevgep41.28.11, align 1
  %scevgep28.28.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9262, i64 0, i64 0, i64 1
  %9269 = bitcast i8* %scevgep28.28.12 to [61 x [61 x i8]]*
  %scevgep41.28.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9263, i64 0, i64 1, i64 0
  %9270 = bitcast i8* %scevgep41.28.12 to [61 x [61 x i8]]*
  %call16.28.13 = call zeroext i8 (...) @rand()
  store i8 %call16.28.13, i8* %scevgep28.28.12, align 1
  %9271 = load i8, i8* %scevgep28.28.12, align 1
  %conv23.28.13 = zext i8 %9271 to i32
  %9272 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.13 = getelementptr i8, i8* %b, i64 42
  %9273 = load i8, i8* %scevgep34.28.13, align 1
  %call28.28.13 = call zeroext i8 @mult(i8 zeroext %9272, i8 zeroext %9273)
  %conv29.28.13 = zext i8 %call28.28.13 to i32
  %xor.28.13 = xor i32 %conv23.28.13, %conv29.28.13
  %scevgep35.28.13 = getelementptr i8, i8* %a, i64 42
  %9274 = load i8, i8* %scevgep35.28.13, align 1
  %9275 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.13 = call zeroext i8 @mult(i8 zeroext %9274, i8 zeroext %9275)
  %conv35.28.13 = zext i8 %call34.28.13 to i32
  %xor36.28.13 = xor i32 %xor.28.13, %conv35.28.13
  %conv37.28.13 = trunc i32 %xor36.28.13 to i8
  store i8 %conv37.28.13, i8* %scevgep41.28.12, align 1
  %scevgep28.28.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9269, i64 0, i64 0, i64 1
  %9276 = bitcast i8* %scevgep28.28.13 to [61 x [61 x i8]]*
  %scevgep41.28.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9270, i64 0, i64 1, i64 0
  %9277 = bitcast i8* %scevgep41.28.13 to [61 x [61 x i8]]*
  %call16.28.14 = call zeroext i8 (...) @rand()
  store i8 %call16.28.14, i8* %scevgep28.28.13, align 1
  %9278 = load i8, i8* %scevgep28.28.13, align 1
  %conv23.28.14 = zext i8 %9278 to i32
  %9279 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.14 = getelementptr i8, i8* %b, i64 43
  %9280 = load i8, i8* %scevgep34.28.14, align 1
  %call28.28.14 = call zeroext i8 @mult(i8 zeroext %9279, i8 zeroext %9280)
  %conv29.28.14 = zext i8 %call28.28.14 to i32
  %xor.28.14 = xor i32 %conv23.28.14, %conv29.28.14
  %scevgep35.28.14 = getelementptr i8, i8* %a, i64 43
  %9281 = load i8, i8* %scevgep35.28.14, align 1
  %9282 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.14 = call zeroext i8 @mult(i8 zeroext %9281, i8 zeroext %9282)
  %conv35.28.14 = zext i8 %call34.28.14 to i32
  %xor36.28.14 = xor i32 %xor.28.14, %conv35.28.14
  %conv37.28.14 = trunc i32 %xor36.28.14 to i8
  store i8 %conv37.28.14, i8* %scevgep41.28.13, align 1
  %scevgep28.28.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9276, i64 0, i64 0, i64 1
  %9283 = bitcast i8* %scevgep28.28.14 to [61 x [61 x i8]]*
  %scevgep41.28.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9277, i64 0, i64 1, i64 0
  %9284 = bitcast i8* %scevgep41.28.14 to [61 x [61 x i8]]*
  %call16.28.15 = call zeroext i8 (...) @rand()
  store i8 %call16.28.15, i8* %scevgep28.28.14, align 1
  %9285 = load i8, i8* %scevgep28.28.14, align 1
  %conv23.28.15 = zext i8 %9285 to i32
  %9286 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.15 = getelementptr i8, i8* %b, i64 44
  %9287 = load i8, i8* %scevgep34.28.15, align 1
  %call28.28.15 = call zeroext i8 @mult(i8 zeroext %9286, i8 zeroext %9287)
  %conv29.28.15 = zext i8 %call28.28.15 to i32
  %xor.28.15 = xor i32 %conv23.28.15, %conv29.28.15
  %scevgep35.28.15 = getelementptr i8, i8* %a, i64 44
  %9288 = load i8, i8* %scevgep35.28.15, align 1
  %9289 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.15 = call zeroext i8 @mult(i8 zeroext %9288, i8 zeroext %9289)
  %conv35.28.15 = zext i8 %call34.28.15 to i32
  %xor36.28.15 = xor i32 %xor.28.15, %conv35.28.15
  %conv37.28.15 = trunc i32 %xor36.28.15 to i8
  store i8 %conv37.28.15, i8* %scevgep41.28.14, align 1
  %scevgep28.28.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9283, i64 0, i64 0, i64 1
  %9290 = bitcast i8* %scevgep28.28.15 to [61 x [61 x i8]]*
  %scevgep41.28.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9284, i64 0, i64 1, i64 0
  %9291 = bitcast i8* %scevgep41.28.15 to [61 x [61 x i8]]*
  %call16.28.16 = call zeroext i8 (...) @rand()
  store i8 %call16.28.16, i8* %scevgep28.28.15, align 1
  %9292 = load i8, i8* %scevgep28.28.15, align 1
  %conv23.28.16 = zext i8 %9292 to i32
  %9293 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.16 = getelementptr i8, i8* %b, i64 45
  %9294 = load i8, i8* %scevgep34.28.16, align 1
  %call28.28.16 = call zeroext i8 @mult(i8 zeroext %9293, i8 zeroext %9294)
  %conv29.28.16 = zext i8 %call28.28.16 to i32
  %xor.28.16 = xor i32 %conv23.28.16, %conv29.28.16
  %scevgep35.28.16 = getelementptr i8, i8* %a, i64 45
  %9295 = load i8, i8* %scevgep35.28.16, align 1
  %9296 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.16 = call zeroext i8 @mult(i8 zeroext %9295, i8 zeroext %9296)
  %conv35.28.16 = zext i8 %call34.28.16 to i32
  %xor36.28.16 = xor i32 %xor.28.16, %conv35.28.16
  %conv37.28.16 = trunc i32 %xor36.28.16 to i8
  store i8 %conv37.28.16, i8* %scevgep41.28.15, align 1
  %scevgep28.28.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9290, i64 0, i64 0, i64 1
  %9297 = bitcast i8* %scevgep28.28.16 to [61 x [61 x i8]]*
  %scevgep41.28.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9291, i64 0, i64 1, i64 0
  %9298 = bitcast i8* %scevgep41.28.16 to [61 x [61 x i8]]*
  %call16.28.17 = call zeroext i8 (...) @rand()
  store i8 %call16.28.17, i8* %scevgep28.28.16, align 1
  %9299 = load i8, i8* %scevgep28.28.16, align 1
  %conv23.28.17 = zext i8 %9299 to i32
  %9300 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.17 = getelementptr i8, i8* %b, i64 46
  %9301 = load i8, i8* %scevgep34.28.17, align 1
  %call28.28.17 = call zeroext i8 @mult(i8 zeroext %9300, i8 zeroext %9301)
  %conv29.28.17 = zext i8 %call28.28.17 to i32
  %xor.28.17 = xor i32 %conv23.28.17, %conv29.28.17
  %scevgep35.28.17 = getelementptr i8, i8* %a, i64 46
  %9302 = load i8, i8* %scevgep35.28.17, align 1
  %9303 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.17 = call zeroext i8 @mult(i8 zeroext %9302, i8 zeroext %9303)
  %conv35.28.17 = zext i8 %call34.28.17 to i32
  %xor36.28.17 = xor i32 %xor.28.17, %conv35.28.17
  %conv37.28.17 = trunc i32 %xor36.28.17 to i8
  store i8 %conv37.28.17, i8* %scevgep41.28.16, align 1
  %scevgep28.28.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9297, i64 0, i64 0, i64 1
  %9304 = bitcast i8* %scevgep28.28.17 to [61 x [61 x i8]]*
  %scevgep41.28.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9298, i64 0, i64 1, i64 0
  %9305 = bitcast i8* %scevgep41.28.17 to [61 x [61 x i8]]*
  %call16.28.18 = call zeroext i8 (...) @rand()
  store i8 %call16.28.18, i8* %scevgep28.28.17, align 1
  %9306 = load i8, i8* %scevgep28.28.17, align 1
  %conv23.28.18 = zext i8 %9306 to i32
  %9307 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.18 = getelementptr i8, i8* %b, i64 47
  %9308 = load i8, i8* %scevgep34.28.18, align 1
  %call28.28.18 = call zeroext i8 @mult(i8 zeroext %9307, i8 zeroext %9308)
  %conv29.28.18 = zext i8 %call28.28.18 to i32
  %xor.28.18 = xor i32 %conv23.28.18, %conv29.28.18
  %scevgep35.28.18 = getelementptr i8, i8* %a, i64 47
  %9309 = load i8, i8* %scevgep35.28.18, align 1
  %9310 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.18 = call zeroext i8 @mult(i8 zeroext %9309, i8 zeroext %9310)
  %conv35.28.18 = zext i8 %call34.28.18 to i32
  %xor36.28.18 = xor i32 %xor.28.18, %conv35.28.18
  %conv37.28.18 = trunc i32 %xor36.28.18 to i8
  store i8 %conv37.28.18, i8* %scevgep41.28.17, align 1
  %scevgep28.28.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9304, i64 0, i64 0, i64 1
  %9311 = bitcast i8* %scevgep28.28.18 to [61 x [61 x i8]]*
  %scevgep41.28.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9305, i64 0, i64 1, i64 0
  %9312 = bitcast i8* %scevgep41.28.18 to [61 x [61 x i8]]*
  %call16.28.19 = call zeroext i8 (...) @rand()
  store i8 %call16.28.19, i8* %scevgep28.28.18, align 1
  %9313 = load i8, i8* %scevgep28.28.18, align 1
  %conv23.28.19 = zext i8 %9313 to i32
  %9314 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.19 = getelementptr i8, i8* %b, i64 48
  %9315 = load i8, i8* %scevgep34.28.19, align 1
  %call28.28.19 = call zeroext i8 @mult(i8 zeroext %9314, i8 zeroext %9315)
  %conv29.28.19 = zext i8 %call28.28.19 to i32
  %xor.28.19 = xor i32 %conv23.28.19, %conv29.28.19
  %scevgep35.28.19 = getelementptr i8, i8* %a, i64 48
  %9316 = load i8, i8* %scevgep35.28.19, align 1
  %9317 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.19 = call zeroext i8 @mult(i8 zeroext %9316, i8 zeroext %9317)
  %conv35.28.19 = zext i8 %call34.28.19 to i32
  %xor36.28.19 = xor i32 %xor.28.19, %conv35.28.19
  %conv37.28.19 = trunc i32 %xor36.28.19 to i8
  store i8 %conv37.28.19, i8* %scevgep41.28.18, align 1
  %scevgep28.28.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9311, i64 0, i64 0, i64 1
  %9318 = bitcast i8* %scevgep28.28.19 to [61 x [61 x i8]]*
  %scevgep41.28.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9312, i64 0, i64 1, i64 0
  %9319 = bitcast i8* %scevgep41.28.19 to [61 x [61 x i8]]*
  %call16.28.20 = call zeroext i8 (...) @rand()
  store i8 %call16.28.20, i8* %scevgep28.28.19, align 1
  %9320 = load i8, i8* %scevgep28.28.19, align 1
  %conv23.28.20 = zext i8 %9320 to i32
  %9321 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.20 = getelementptr i8, i8* %b, i64 49
  %9322 = load i8, i8* %scevgep34.28.20, align 1
  %call28.28.20 = call zeroext i8 @mult(i8 zeroext %9321, i8 zeroext %9322)
  %conv29.28.20 = zext i8 %call28.28.20 to i32
  %xor.28.20 = xor i32 %conv23.28.20, %conv29.28.20
  %scevgep35.28.20 = getelementptr i8, i8* %a, i64 49
  %9323 = load i8, i8* %scevgep35.28.20, align 1
  %9324 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.20 = call zeroext i8 @mult(i8 zeroext %9323, i8 zeroext %9324)
  %conv35.28.20 = zext i8 %call34.28.20 to i32
  %xor36.28.20 = xor i32 %xor.28.20, %conv35.28.20
  %conv37.28.20 = trunc i32 %xor36.28.20 to i8
  store i8 %conv37.28.20, i8* %scevgep41.28.19, align 1
  %scevgep28.28.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9318, i64 0, i64 0, i64 1
  %9325 = bitcast i8* %scevgep28.28.20 to [61 x [61 x i8]]*
  %scevgep41.28.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9319, i64 0, i64 1, i64 0
  %9326 = bitcast i8* %scevgep41.28.20 to [61 x [61 x i8]]*
  %call16.28.21 = call zeroext i8 (...) @rand()
  store i8 %call16.28.21, i8* %scevgep28.28.20, align 1
  %9327 = load i8, i8* %scevgep28.28.20, align 1
  %conv23.28.21 = zext i8 %9327 to i32
  %9328 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.21 = getelementptr i8, i8* %b, i64 50
  %9329 = load i8, i8* %scevgep34.28.21, align 1
  %call28.28.21 = call zeroext i8 @mult(i8 zeroext %9328, i8 zeroext %9329)
  %conv29.28.21 = zext i8 %call28.28.21 to i32
  %xor.28.21 = xor i32 %conv23.28.21, %conv29.28.21
  %scevgep35.28.21 = getelementptr i8, i8* %a, i64 50
  %9330 = load i8, i8* %scevgep35.28.21, align 1
  %9331 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.21 = call zeroext i8 @mult(i8 zeroext %9330, i8 zeroext %9331)
  %conv35.28.21 = zext i8 %call34.28.21 to i32
  %xor36.28.21 = xor i32 %xor.28.21, %conv35.28.21
  %conv37.28.21 = trunc i32 %xor36.28.21 to i8
  store i8 %conv37.28.21, i8* %scevgep41.28.20, align 1
  %scevgep28.28.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9325, i64 0, i64 0, i64 1
  %9332 = bitcast i8* %scevgep28.28.21 to [61 x [61 x i8]]*
  %scevgep41.28.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9326, i64 0, i64 1, i64 0
  %9333 = bitcast i8* %scevgep41.28.21 to [61 x [61 x i8]]*
  %call16.28.22 = call zeroext i8 (...) @rand()
  store i8 %call16.28.22, i8* %scevgep28.28.21, align 1
  %9334 = load i8, i8* %scevgep28.28.21, align 1
  %conv23.28.22 = zext i8 %9334 to i32
  %9335 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.22 = getelementptr i8, i8* %b, i64 51
  %9336 = load i8, i8* %scevgep34.28.22, align 1
  %call28.28.22 = call zeroext i8 @mult(i8 zeroext %9335, i8 zeroext %9336)
  %conv29.28.22 = zext i8 %call28.28.22 to i32
  %xor.28.22 = xor i32 %conv23.28.22, %conv29.28.22
  %scevgep35.28.22 = getelementptr i8, i8* %a, i64 51
  %9337 = load i8, i8* %scevgep35.28.22, align 1
  %9338 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.22 = call zeroext i8 @mult(i8 zeroext %9337, i8 zeroext %9338)
  %conv35.28.22 = zext i8 %call34.28.22 to i32
  %xor36.28.22 = xor i32 %xor.28.22, %conv35.28.22
  %conv37.28.22 = trunc i32 %xor36.28.22 to i8
  store i8 %conv37.28.22, i8* %scevgep41.28.21, align 1
  %scevgep28.28.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9332, i64 0, i64 0, i64 1
  %9339 = bitcast i8* %scevgep28.28.22 to [61 x [61 x i8]]*
  %scevgep41.28.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9333, i64 0, i64 1, i64 0
  %9340 = bitcast i8* %scevgep41.28.22 to [61 x [61 x i8]]*
  %call16.28.23 = call zeroext i8 (...) @rand()
  store i8 %call16.28.23, i8* %scevgep28.28.22, align 1
  %9341 = load i8, i8* %scevgep28.28.22, align 1
  %conv23.28.23 = zext i8 %9341 to i32
  %9342 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.23 = getelementptr i8, i8* %b, i64 52
  %9343 = load i8, i8* %scevgep34.28.23, align 1
  %call28.28.23 = call zeroext i8 @mult(i8 zeroext %9342, i8 zeroext %9343)
  %conv29.28.23 = zext i8 %call28.28.23 to i32
  %xor.28.23 = xor i32 %conv23.28.23, %conv29.28.23
  %scevgep35.28.23 = getelementptr i8, i8* %a, i64 52
  %9344 = load i8, i8* %scevgep35.28.23, align 1
  %9345 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.23 = call zeroext i8 @mult(i8 zeroext %9344, i8 zeroext %9345)
  %conv35.28.23 = zext i8 %call34.28.23 to i32
  %xor36.28.23 = xor i32 %xor.28.23, %conv35.28.23
  %conv37.28.23 = trunc i32 %xor36.28.23 to i8
  store i8 %conv37.28.23, i8* %scevgep41.28.22, align 1
  %scevgep28.28.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9339, i64 0, i64 0, i64 1
  %9346 = bitcast i8* %scevgep28.28.23 to [61 x [61 x i8]]*
  %scevgep41.28.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9340, i64 0, i64 1, i64 0
  %9347 = bitcast i8* %scevgep41.28.23 to [61 x [61 x i8]]*
  %call16.28.24 = call zeroext i8 (...) @rand()
  store i8 %call16.28.24, i8* %scevgep28.28.23, align 1
  %9348 = load i8, i8* %scevgep28.28.23, align 1
  %conv23.28.24 = zext i8 %9348 to i32
  %9349 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.24 = getelementptr i8, i8* %b, i64 53
  %9350 = load i8, i8* %scevgep34.28.24, align 1
  %call28.28.24 = call zeroext i8 @mult(i8 zeroext %9349, i8 zeroext %9350)
  %conv29.28.24 = zext i8 %call28.28.24 to i32
  %xor.28.24 = xor i32 %conv23.28.24, %conv29.28.24
  %scevgep35.28.24 = getelementptr i8, i8* %a, i64 53
  %9351 = load i8, i8* %scevgep35.28.24, align 1
  %9352 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.24 = call zeroext i8 @mult(i8 zeroext %9351, i8 zeroext %9352)
  %conv35.28.24 = zext i8 %call34.28.24 to i32
  %xor36.28.24 = xor i32 %xor.28.24, %conv35.28.24
  %conv37.28.24 = trunc i32 %xor36.28.24 to i8
  store i8 %conv37.28.24, i8* %scevgep41.28.23, align 1
  %scevgep28.28.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9346, i64 0, i64 0, i64 1
  %9353 = bitcast i8* %scevgep28.28.24 to [61 x [61 x i8]]*
  %scevgep41.28.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9347, i64 0, i64 1, i64 0
  %9354 = bitcast i8* %scevgep41.28.24 to [61 x [61 x i8]]*
  %call16.28.25 = call zeroext i8 (...) @rand()
  store i8 %call16.28.25, i8* %scevgep28.28.24, align 1
  %9355 = load i8, i8* %scevgep28.28.24, align 1
  %conv23.28.25 = zext i8 %9355 to i32
  %9356 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.25 = getelementptr i8, i8* %b, i64 54
  %9357 = load i8, i8* %scevgep34.28.25, align 1
  %call28.28.25 = call zeroext i8 @mult(i8 zeroext %9356, i8 zeroext %9357)
  %conv29.28.25 = zext i8 %call28.28.25 to i32
  %xor.28.25 = xor i32 %conv23.28.25, %conv29.28.25
  %scevgep35.28.25 = getelementptr i8, i8* %a, i64 54
  %9358 = load i8, i8* %scevgep35.28.25, align 1
  %9359 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.25 = call zeroext i8 @mult(i8 zeroext %9358, i8 zeroext %9359)
  %conv35.28.25 = zext i8 %call34.28.25 to i32
  %xor36.28.25 = xor i32 %xor.28.25, %conv35.28.25
  %conv37.28.25 = trunc i32 %xor36.28.25 to i8
  store i8 %conv37.28.25, i8* %scevgep41.28.24, align 1
  %scevgep28.28.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9353, i64 0, i64 0, i64 1
  %9360 = bitcast i8* %scevgep28.28.25 to [61 x [61 x i8]]*
  %scevgep41.28.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9354, i64 0, i64 1, i64 0
  %9361 = bitcast i8* %scevgep41.28.25 to [61 x [61 x i8]]*
  %call16.28.26 = call zeroext i8 (...) @rand()
  store i8 %call16.28.26, i8* %scevgep28.28.25, align 1
  %9362 = load i8, i8* %scevgep28.28.25, align 1
  %conv23.28.26 = zext i8 %9362 to i32
  %9363 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.26 = getelementptr i8, i8* %b, i64 55
  %9364 = load i8, i8* %scevgep34.28.26, align 1
  %call28.28.26 = call zeroext i8 @mult(i8 zeroext %9363, i8 zeroext %9364)
  %conv29.28.26 = zext i8 %call28.28.26 to i32
  %xor.28.26 = xor i32 %conv23.28.26, %conv29.28.26
  %scevgep35.28.26 = getelementptr i8, i8* %a, i64 55
  %9365 = load i8, i8* %scevgep35.28.26, align 1
  %9366 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.26 = call zeroext i8 @mult(i8 zeroext %9365, i8 zeroext %9366)
  %conv35.28.26 = zext i8 %call34.28.26 to i32
  %xor36.28.26 = xor i32 %xor.28.26, %conv35.28.26
  %conv37.28.26 = trunc i32 %xor36.28.26 to i8
  store i8 %conv37.28.26, i8* %scevgep41.28.25, align 1
  %scevgep28.28.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9360, i64 0, i64 0, i64 1
  %9367 = bitcast i8* %scevgep28.28.26 to [61 x [61 x i8]]*
  %scevgep41.28.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9361, i64 0, i64 1, i64 0
  %9368 = bitcast i8* %scevgep41.28.26 to [61 x [61 x i8]]*
  %call16.28.27 = call zeroext i8 (...) @rand()
  store i8 %call16.28.27, i8* %scevgep28.28.26, align 1
  %9369 = load i8, i8* %scevgep28.28.26, align 1
  %conv23.28.27 = zext i8 %9369 to i32
  %9370 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.27 = getelementptr i8, i8* %b, i64 56
  %9371 = load i8, i8* %scevgep34.28.27, align 1
  %call28.28.27 = call zeroext i8 @mult(i8 zeroext %9370, i8 zeroext %9371)
  %conv29.28.27 = zext i8 %call28.28.27 to i32
  %xor.28.27 = xor i32 %conv23.28.27, %conv29.28.27
  %scevgep35.28.27 = getelementptr i8, i8* %a, i64 56
  %9372 = load i8, i8* %scevgep35.28.27, align 1
  %9373 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.27 = call zeroext i8 @mult(i8 zeroext %9372, i8 zeroext %9373)
  %conv35.28.27 = zext i8 %call34.28.27 to i32
  %xor36.28.27 = xor i32 %xor.28.27, %conv35.28.27
  %conv37.28.27 = trunc i32 %xor36.28.27 to i8
  store i8 %conv37.28.27, i8* %scevgep41.28.26, align 1
  %scevgep28.28.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9367, i64 0, i64 0, i64 1
  %9374 = bitcast i8* %scevgep28.28.27 to [61 x [61 x i8]]*
  %scevgep41.28.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9368, i64 0, i64 1, i64 0
  %9375 = bitcast i8* %scevgep41.28.27 to [61 x [61 x i8]]*
  %call16.28.28 = call zeroext i8 (...) @rand()
  store i8 %call16.28.28, i8* %scevgep28.28.27, align 1
  %9376 = load i8, i8* %scevgep28.28.27, align 1
  %conv23.28.28 = zext i8 %9376 to i32
  %9377 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.28 = getelementptr i8, i8* %b, i64 57
  %9378 = load i8, i8* %scevgep34.28.28, align 1
  %call28.28.28 = call zeroext i8 @mult(i8 zeroext %9377, i8 zeroext %9378)
  %conv29.28.28 = zext i8 %call28.28.28 to i32
  %xor.28.28 = xor i32 %conv23.28.28, %conv29.28.28
  %scevgep35.28.28 = getelementptr i8, i8* %a, i64 57
  %9379 = load i8, i8* %scevgep35.28.28, align 1
  %9380 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.28 = call zeroext i8 @mult(i8 zeroext %9379, i8 zeroext %9380)
  %conv35.28.28 = zext i8 %call34.28.28 to i32
  %xor36.28.28 = xor i32 %xor.28.28, %conv35.28.28
  %conv37.28.28 = trunc i32 %xor36.28.28 to i8
  store i8 %conv37.28.28, i8* %scevgep41.28.27, align 1
  %scevgep28.28.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9374, i64 0, i64 0, i64 1
  %9381 = bitcast i8* %scevgep28.28.28 to [61 x [61 x i8]]*
  %scevgep41.28.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9375, i64 0, i64 1, i64 0
  %9382 = bitcast i8* %scevgep41.28.28 to [61 x [61 x i8]]*
  %call16.28.29 = call zeroext i8 (...) @rand()
  store i8 %call16.28.29, i8* %scevgep28.28.28, align 1
  %9383 = load i8, i8* %scevgep28.28.28, align 1
  %conv23.28.29 = zext i8 %9383 to i32
  %9384 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.29 = getelementptr i8, i8* %b, i64 58
  %9385 = load i8, i8* %scevgep34.28.29, align 1
  %call28.28.29 = call zeroext i8 @mult(i8 zeroext %9384, i8 zeroext %9385)
  %conv29.28.29 = zext i8 %call28.28.29 to i32
  %xor.28.29 = xor i32 %conv23.28.29, %conv29.28.29
  %scevgep35.28.29 = getelementptr i8, i8* %a, i64 58
  %9386 = load i8, i8* %scevgep35.28.29, align 1
  %9387 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.29 = call zeroext i8 @mult(i8 zeroext %9386, i8 zeroext %9387)
  %conv35.28.29 = zext i8 %call34.28.29 to i32
  %xor36.28.29 = xor i32 %xor.28.29, %conv35.28.29
  %conv37.28.29 = trunc i32 %xor36.28.29 to i8
  store i8 %conv37.28.29, i8* %scevgep41.28.28, align 1
  %scevgep28.28.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9381, i64 0, i64 0, i64 1
  %9388 = bitcast i8* %scevgep28.28.29 to [61 x [61 x i8]]*
  %scevgep41.28.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9382, i64 0, i64 1, i64 0
  %9389 = bitcast i8* %scevgep41.28.29 to [61 x [61 x i8]]*
  %call16.28.30 = call zeroext i8 (...) @rand()
  store i8 %call16.28.30, i8* %scevgep28.28.29, align 1
  %9390 = load i8, i8* %scevgep28.28.29, align 1
  %conv23.28.30 = zext i8 %9390 to i32
  %9391 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.30 = getelementptr i8, i8* %b, i64 59
  %9392 = load i8, i8* %scevgep34.28.30, align 1
  %call28.28.30 = call zeroext i8 @mult(i8 zeroext %9391, i8 zeroext %9392)
  %conv29.28.30 = zext i8 %call28.28.30 to i32
  %xor.28.30 = xor i32 %conv23.28.30, %conv29.28.30
  %scevgep35.28.30 = getelementptr i8, i8* %a, i64 59
  %9393 = load i8, i8* %scevgep35.28.30, align 1
  %9394 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.30 = call zeroext i8 @mult(i8 zeroext %9393, i8 zeroext %9394)
  %conv35.28.30 = zext i8 %call34.28.30 to i32
  %xor36.28.30 = xor i32 %xor.28.30, %conv35.28.30
  %conv37.28.30 = trunc i32 %xor36.28.30 to i8
  store i8 %conv37.28.30, i8* %scevgep41.28.29, align 1
  %scevgep28.28.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9388, i64 0, i64 0, i64 1
  %scevgep41.28.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9389, i64 0, i64 1, i64 0
  %call16.28.31 = call zeroext i8 (...) @rand()
  store i8 %call16.28.31, i8* %scevgep28.28.30, align 1
  %9395 = load i8, i8* %scevgep28.28.30, align 1
  %conv23.28.31 = zext i8 %9395 to i32
  %9396 = load i8, i8* %arrayidx25.28, align 1
  %scevgep34.28.31 = getelementptr i8, i8* %b, i64 60
  %9397 = load i8, i8* %scevgep34.28.31, align 1
  %call28.28.31 = call zeroext i8 @mult(i8 zeroext %9396, i8 zeroext %9397)
  %conv29.28.31 = zext i8 %call28.28.31 to i32
  %xor.28.31 = xor i32 %conv23.28.31, %conv29.28.31
  %scevgep35.28.31 = getelementptr i8, i8* %a, i64 60
  %9398 = load i8, i8* %scevgep35.28.31, align 1
  %9399 = load i8, i8* %arrayidx33.28, align 1
  %call34.28.31 = call zeroext i8 @mult(i8 zeroext %9398, i8 zeroext %9399)
  %conv35.28.31 = zext i8 %call34.28.31 to i32
  %xor36.28.31 = xor i32 %xor.28.31, %conv35.28.31
  %conv37.28.31 = trunc i32 %xor36.28.31 to i8
  store i8 %conv37.28.31, i8* %scevgep41.28.30, align 1
  %scevgep26.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9178, i64 0, i64 1, i64 1
  %9400 = bitcast i8* %scevgep26.28 to [61 x [61 x i8]]*
  %scevgep39.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9179, i64 0, i64 1, i64 1
  %9401 = bitcast i8* %scevgep39.28 to [61 x [61 x i8]]*
  %arrayidx25.29 = getelementptr inbounds i8, i8* %a, i64 29
  %arrayidx33.29 = getelementptr inbounds i8, i8* %b, i64 29
  %call16.29 = call zeroext i8 (...) @rand()
  store i8 %call16.29, i8* %scevgep26.28, align 1
  %9402 = load i8, i8* %scevgep26.28, align 1
  %conv23.29 = zext i8 %9402 to i32
  %9403 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29 = getelementptr i8, i8* %b, i64 30
  %9404 = load i8, i8* %scevgep34.29, align 1
  %call28.29 = call zeroext i8 @mult(i8 zeroext %9403, i8 zeroext %9404)
  %conv29.29 = zext i8 %call28.29 to i32
  %xor.29 = xor i32 %conv23.29, %conv29.29
  %scevgep35.29 = getelementptr i8, i8* %a, i64 30
  %9405 = load i8, i8* %scevgep35.29, align 1
  %9406 = load i8, i8* %arrayidx33.29, align 1
  %call34.29 = call zeroext i8 @mult(i8 zeroext %9405, i8 zeroext %9406)
  %conv35.29 = zext i8 %call34.29 to i32
  %xor36.29 = xor i32 %xor.29, %conv35.29
  %conv37.29 = trunc i32 %xor36.29 to i8
  store i8 %conv37.29, i8* %scevgep39.28, align 1
  %scevgep28.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9400, i64 0, i64 0, i64 1
  %9407 = bitcast i8* %scevgep28.29 to [61 x [61 x i8]]*
  %scevgep41.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9401, i64 0, i64 1, i64 0
  %9408 = bitcast i8* %scevgep41.29 to [61 x [61 x i8]]*
  %call16.29.1 = call zeroext i8 (...) @rand()
  store i8 %call16.29.1, i8* %scevgep28.29, align 1
  %9409 = load i8, i8* %scevgep28.29, align 1
  %conv23.29.1 = zext i8 %9409 to i32
  %9410 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.1 = getelementptr i8, i8* %b, i64 31
  %9411 = load i8, i8* %scevgep34.29.1, align 1
  %call28.29.1 = call zeroext i8 @mult(i8 zeroext %9410, i8 zeroext %9411)
  %conv29.29.1 = zext i8 %call28.29.1 to i32
  %xor.29.1 = xor i32 %conv23.29.1, %conv29.29.1
  %scevgep35.29.1 = getelementptr i8, i8* %a, i64 31
  %9412 = load i8, i8* %scevgep35.29.1, align 1
  %9413 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.1 = call zeroext i8 @mult(i8 zeroext %9412, i8 zeroext %9413)
  %conv35.29.1 = zext i8 %call34.29.1 to i32
  %xor36.29.1 = xor i32 %xor.29.1, %conv35.29.1
  %conv37.29.1 = trunc i32 %xor36.29.1 to i8
  store i8 %conv37.29.1, i8* %scevgep41.29, align 1
  %scevgep28.29.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9407, i64 0, i64 0, i64 1
  %9414 = bitcast i8* %scevgep28.29.1 to [61 x [61 x i8]]*
  %scevgep41.29.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9408, i64 0, i64 1, i64 0
  %9415 = bitcast i8* %scevgep41.29.1 to [61 x [61 x i8]]*
  %call16.29.2 = call zeroext i8 (...) @rand()
  store i8 %call16.29.2, i8* %scevgep28.29.1, align 1
  %9416 = load i8, i8* %scevgep28.29.1, align 1
  %conv23.29.2 = zext i8 %9416 to i32
  %9417 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.2 = getelementptr i8, i8* %b, i64 32
  %9418 = load i8, i8* %scevgep34.29.2, align 1
  %call28.29.2 = call zeroext i8 @mult(i8 zeroext %9417, i8 zeroext %9418)
  %conv29.29.2 = zext i8 %call28.29.2 to i32
  %xor.29.2 = xor i32 %conv23.29.2, %conv29.29.2
  %scevgep35.29.2 = getelementptr i8, i8* %a, i64 32
  %9419 = load i8, i8* %scevgep35.29.2, align 1
  %9420 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.2 = call zeroext i8 @mult(i8 zeroext %9419, i8 zeroext %9420)
  %conv35.29.2 = zext i8 %call34.29.2 to i32
  %xor36.29.2 = xor i32 %xor.29.2, %conv35.29.2
  %conv37.29.2 = trunc i32 %xor36.29.2 to i8
  store i8 %conv37.29.2, i8* %scevgep41.29.1, align 1
  %scevgep28.29.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9414, i64 0, i64 0, i64 1
  %9421 = bitcast i8* %scevgep28.29.2 to [61 x [61 x i8]]*
  %scevgep41.29.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9415, i64 0, i64 1, i64 0
  %9422 = bitcast i8* %scevgep41.29.2 to [61 x [61 x i8]]*
  %call16.29.3 = call zeroext i8 (...) @rand()
  store i8 %call16.29.3, i8* %scevgep28.29.2, align 1
  %9423 = load i8, i8* %scevgep28.29.2, align 1
  %conv23.29.3 = zext i8 %9423 to i32
  %9424 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.3 = getelementptr i8, i8* %b, i64 33
  %9425 = load i8, i8* %scevgep34.29.3, align 1
  %call28.29.3 = call zeroext i8 @mult(i8 zeroext %9424, i8 zeroext %9425)
  %conv29.29.3 = zext i8 %call28.29.3 to i32
  %xor.29.3 = xor i32 %conv23.29.3, %conv29.29.3
  %scevgep35.29.3 = getelementptr i8, i8* %a, i64 33
  %9426 = load i8, i8* %scevgep35.29.3, align 1
  %9427 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.3 = call zeroext i8 @mult(i8 zeroext %9426, i8 zeroext %9427)
  %conv35.29.3 = zext i8 %call34.29.3 to i32
  %xor36.29.3 = xor i32 %xor.29.3, %conv35.29.3
  %conv37.29.3 = trunc i32 %xor36.29.3 to i8
  store i8 %conv37.29.3, i8* %scevgep41.29.2, align 1
  %scevgep28.29.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9421, i64 0, i64 0, i64 1
  %9428 = bitcast i8* %scevgep28.29.3 to [61 x [61 x i8]]*
  %scevgep41.29.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9422, i64 0, i64 1, i64 0
  %9429 = bitcast i8* %scevgep41.29.3 to [61 x [61 x i8]]*
  %call16.29.4 = call zeroext i8 (...) @rand()
  store i8 %call16.29.4, i8* %scevgep28.29.3, align 1
  %9430 = load i8, i8* %scevgep28.29.3, align 1
  %conv23.29.4 = zext i8 %9430 to i32
  %9431 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.4 = getelementptr i8, i8* %b, i64 34
  %9432 = load i8, i8* %scevgep34.29.4, align 1
  %call28.29.4 = call zeroext i8 @mult(i8 zeroext %9431, i8 zeroext %9432)
  %conv29.29.4 = zext i8 %call28.29.4 to i32
  %xor.29.4 = xor i32 %conv23.29.4, %conv29.29.4
  %scevgep35.29.4 = getelementptr i8, i8* %a, i64 34
  %9433 = load i8, i8* %scevgep35.29.4, align 1
  %9434 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.4 = call zeroext i8 @mult(i8 zeroext %9433, i8 zeroext %9434)
  %conv35.29.4 = zext i8 %call34.29.4 to i32
  %xor36.29.4 = xor i32 %xor.29.4, %conv35.29.4
  %conv37.29.4 = trunc i32 %xor36.29.4 to i8
  store i8 %conv37.29.4, i8* %scevgep41.29.3, align 1
  %scevgep28.29.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9428, i64 0, i64 0, i64 1
  %9435 = bitcast i8* %scevgep28.29.4 to [61 x [61 x i8]]*
  %scevgep41.29.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9429, i64 0, i64 1, i64 0
  %9436 = bitcast i8* %scevgep41.29.4 to [61 x [61 x i8]]*
  %call16.29.5 = call zeroext i8 (...) @rand()
  store i8 %call16.29.5, i8* %scevgep28.29.4, align 1
  %9437 = load i8, i8* %scevgep28.29.4, align 1
  %conv23.29.5 = zext i8 %9437 to i32
  %9438 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.5 = getelementptr i8, i8* %b, i64 35
  %9439 = load i8, i8* %scevgep34.29.5, align 1
  %call28.29.5 = call zeroext i8 @mult(i8 zeroext %9438, i8 zeroext %9439)
  %conv29.29.5 = zext i8 %call28.29.5 to i32
  %xor.29.5 = xor i32 %conv23.29.5, %conv29.29.5
  %scevgep35.29.5 = getelementptr i8, i8* %a, i64 35
  %9440 = load i8, i8* %scevgep35.29.5, align 1
  %9441 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.5 = call zeroext i8 @mult(i8 zeroext %9440, i8 zeroext %9441)
  %conv35.29.5 = zext i8 %call34.29.5 to i32
  %xor36.29.5 = xor i32 %xor.29.5, %conv35.29.5
  %conv37.29.5 = trunc i32 %xor36.29.5 to i8
  store i8 %conv37.29.5, i8* %scevgep41.29.4, align 1
  %scevgep28.29.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9435, i64 0, i64 0, i64 1
  %9442 = bitcast i8* %scevgep28.29.5 to [61 x [61 x i8]]*
  %scevgep41.29.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9436, i64 0, i64 1, i64 0
  %9443 = bitcast i8* %scevgep41.29.5 to [61 x [61 x i8]]*
  %call16.29.6 = call zeroext i8 (...) @rand()
  store i8 %call16.29.6, i8* %scevgep28.29.5, align 1
  %9444 = load i8, i8* %scevgep28.29.5, align 1
  %conv23.29.6 = zext i8 %9444 to i32
  %9445 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.6 = getelementptr i8, i8* %b, i64 36
  %9446 = load i8, i8* %scevgep34.29.6, align 1
  %call28.29.6 = call zeroext i8 @mult(i8 zeroext %9445, i8 zeroext %9446)
  %conv29.29.6 = zext i8 %call28.29.6 to i32
  %xor.29.6 = xor i32 %conv23.29.6, %conv29.29.6
  %scevgep35.29.6 = getelementptr i8, i8* %a, i64 36
  %9447 = load i8, i8* %scevgep35.29.6, align 1
  %9448 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.6 = call zeroext i8 @mult(i8 zeroext %9447, i8 zeroext %9448)
  %conv35.29.6 = zext i8 %call34.29.6 to i32
  %xor36.29.6 = xor i32 %xor.29.6, %conv35.29.6
  %conv37.29.6 = trunc i32 %xor36.29.6 to i8
  store i8 %conv37.29.6, i8* %scevgep41.29.5, align 1
  %scevgep28.29.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9442, i64 0, i64 0, i64 1
  %9449 = bitcast i8* %scevgep28.29.6 to [61 x [61 x i8]]*
  %scevgep41.29.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9443, i64 0, i64 1, i64 0
  %9450 = bitcast i8* %scevgep41.29.6 to [61 x [61 x i8]]*
  %call16.29.7 = call zeroext i8 (...) @rand()
  store i8 %call16.29.7, i8* %scevgep28.29.6, align 1
  %9451 = load i8, i8* %scevgep28.29.6, align 1
  %conv23.29.7 = zext i8 %9451 to i32
  %9452 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.7 = getelementptr i8, i8* %b, i64 37
  %9453 = load i8, i8* %scevgep34.29.7, align 1
  %call28.29.7 = call zeroext i8 @mult(i8 zeroext %9452, i8 zeroext %9453)
  %conv29.29.7 = zext i8 %call28.29.7 to i32
  %xor.29.7 = xor i32 %conv23.29.7, %conv29.29.7
  %scevgep35.29.7 = getelementptr i8, i8* %a, i64 37
  %9454 = load i8, i8* %scevgep35.29.7, align 1
  %9455 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.7 = call zeroext i8 @mult(i8 zeroext %9454, i8 zeroext %9455)
  %conv35.29.7 = zext i8 %call34.29.7 to i32
  %xor36.29.7 = xor i32 %xor.29.7, %conv35.29.7
  %conv37.29.7 = trunc i32 %xor36.29.7 to i8
  store i8 %conv37.29.7, i8* %scevgep41.29.6, align 1
  %scevgep28.29.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9449, i64 0, i64 0, i64 1
  %9456 = bitcast i8* %scevgep28.29.7 to [61 x [61 x i8]]*
  %scevgep41.29.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9450, i64 0, i64 1, i64 0
  %9457 = bitcast i8* %scevgep41.29.7 to [61 x [61 x i8]]*
  %call16.29.8 = call zeroext i8 (...) @rand()
  store i8 %call16.29.8, i8* %scevgep28.29.7, align 1
  %9458 = load i8, i8* %scevgep28.29.7, align 1
  %conv23.29.8 = zext i8 %9458 to i32
  %9459 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.8 = getelementptr i8, i8* %b, i64 38
  %9460 = load i8, i8* %scevgep34.29.8, align 1
  %call28.29.8 = call zeroext i8 @mult(i8 zeroext %9459, i8 zeroext %9460)
  %conv29.29.8 = zext i8 %call28.29.8 to i32
  %xor.29.8 = xor i32 %conv23.29.8, %conv29.29.8
  %scevgep35.29.8 = getelementptr i8, i8* %a, i64 38
  %9461 = load i8, i8* %scevgep35.29.8, align 1
  %9462 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.8 = call zeroext i8 @mult(i8 zeroext %9461, i8 zeroext %9462)
  %conv35.29.8 = zext i8 %call34.29.8 to i32
  %xor36.29.8 = xor i32 %xor.29.8, %conv35.29.8
  %conv37.29.8 = trunc i32 %xor36.29.8 to i8
  store i8 %conv37.29.8, i8* %scevgep41.29.7, align 1
  %scevgep28.29.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9456, i64 0, i64 0, i64 1
  %9463 = bitcast i8* %scevgep28.29.8 to [61 x [61 x i8]]*
  %scevgep41.29.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9457, i64 0, i64 1, i64 0
  %9464 = bitcast i8* %scevgep41.29.8 to [61 x [61 x i8]]*
  %call16.29.9 = call zeroext i8 (...) @rand()
  store i8 %call16.29.9, i8* %scevgep28.29.8, align 1
  %9465 = load i8, i8* %scevgep28.29.8, align 1
  %conv23.29.9 = zext i8 %9465 to i32
  %9466 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.9 = getelementptr i8, i8* %b, i64 39
  %9467 = load i8, i8* %scevgep34.29.9, align 1
  %call28.29.9 = call zeroext i8 @mult(i8 zeroext %9466, i8 zeroext %9467)
  %conv29.29.9 = zext i8 %call28.29.9 to i32
  %xor.29.9 = xor i32 %conv23.29.9, %conv29.29.9
  %scevgep35.29.9 = getelementptr i8, i8* %a, i64 39
  %9468 = load i8, i8* %scevgep35.29.9, align 1
  %9469 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.9 = call zeroext i8 @mult(i8 zeroext %9468, i8 zeroext %9469)
  %conv35.29.9 = zext i8 %call34.29.9 to i32
  %xor36.29.9 = xor i32 %xor.29.9, %conv35.29.9
  %conv37.29.9 = trunc i32 %xor36.29.9 to i8
  store i8 %conv37.29.9, i8* %scevgep41.29.8, align 1
  %scevgep28.29.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9463, i64 0, i64 0, i64 1
  %9470 = bitcast i8* %scevgep28.29.9 to [61 x [61 x i8]]*
  %scevgep41.29.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9464, i64 0, i64 1, i64 0
  %9471 = bitcast i8* %scevgep41.29.9 to [61 x [61 x i8]]*
  %call16.29.10 = call zeroext i8 (...) @rand()
  store i8 %call16.29.10, i8* %scevgep28.29.9, align 1
  %9472 = load i8, i8* %scevgep28.29.9, align 1
  %conv23.29.10 = zext i8 %9472 to i32
  %9473 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.10 = getelementptr i8, i8* %b, i64 40
  %9474 = load i8, i8* %scevgep34.29.10, align 1
  %call28.29.10 = call zeroext i8 @mult(i8 zeroext %9473, i8 zeroext %9474)
  %conv29.29.10 = zext i8 %call28.29.10 to i32
  %xor.29.10 = xor i32 %conv23.29.10, %conv29.29.10
  %scevgep35.29.10 = getelementptr i8, i8* %a, i64 40
  %9475 = load i8, i8* %scevgep35.29.10, align 1
  %9476 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.10 = call zeroext i8 @mult(i8 zeroext %9475, i8 zeroext %9476)
  %conv35.29.10 = zext i8 %call34.29.10 to i32
  %xor36.29.10 = xor i32 %xor.29.10, %conv35.29.10
  %conv37.29.10 = trunc i32 %xor36.29.10 to i8
  store i8 %conv37.29.10, i8* %scevgep41.29.9, align 1
  %scevgep28.29.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9470, i64 0, i64 0, i64 1
  %9477 = bitcast i8* %scevgep28.29.10 to [61 x [61 x i8]]*
  %scevgep41.29.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9471, i64 0, i64 1, i64 0
  %9478 = bitcast i8* %scevgep41.29.10 to [61 x [61 x i8]]*
  %call16.29.11 = call zeroext i8 (...) @rand()
  store i8 %call16.29.11, i8* %scevgep28.29.10, align 1
  %9479 = load i8, i8* %scevgep28.29.10, align 1
  %conv23.29.11 = zext i8 %9479 to i32
  %9480 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.11 = getelementptr i8, i8* %b, i64 41
  %9481 = load i8, i8* %scevgep34.29.11, align 1
  %call28.29.11 = call zeroext i8 @mult(i8 zeroext %9480, i8 zeroext %9481)
  %conv29.29.11 = zext i8 %call28.29.11 to i32
  %xor.29.11 = xor i32 %conv23.29.11, %conv29.29.11
  %scevgep35.29.11 = getelementptr i8, i8* %a, i64 41
  %9482 = load i8, i8* %scevgep35.29.11, align 1
  %9483 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.11 = call zeroext i8 @mult(i8 zeroext %9482, i8 zeroext %9483)
  %conv35.29.11 = zext i8 %call34.29.11 to i32
  %xor36.29.11 = xor i32 %xor.29.11, %conv35.29.11
  %conv37.29.11 = trunc i32 %xor36.29.11 to i8
  store i8 %conv37.29.11, i8* %scevgep41.29.10, align 1
  %scevgep28.29.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9477, i64 0, i64 0, i64 1
  %9484 = bitcast i8* %scevgep28.29.11 to [61 x [61 x i8]]*
  %scevgep41.29.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9478, i64 0, i64 1, i64 0
  %9485 = bitcast i8* %scevgep41.29.11 to [61 x [61 x i8]]*
  %call16.29.12 = call zeroext i8 (...) @rand()
  store i8 %call16.29.12, i8* %scevgep28.29.11, align 1
  %9486 = load i8, i8* %scevgep28.29.11, align 1
  %conv23.29.12 = zext i8 %9486 to i32
  %9487 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.12 = getelementptr i8, i8* %b, i64 42
  %9488 = load i8, i8* %scevgep34.29.12, align 1
  %call28.29.12 = call zeroext i8 @mult(i8 zeroext %9487, i8 zeroext %9488)
  %conv29.29.12 = zext i8 %call28.29.12 to i32
  %xor.29.12 = xor i32 %conv23.29.12, %conv29.29.12
  %scevgep35.29.12 = getelementptr i8, i8* %a, i64 42
  %9489 = load i8, i8* %scevgep35.29.12, align 1
  %9490 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.12 = call zeroext i8 @mult(i8 zeroext %9489, i8 zeroext %9490)
  %conv35.29.12 = zext i8 %call34.29.12 to i32
  %xor36.29.12 = xor i32 %xor.29.12, %conv35.29.12
  %conv37.29.12 = trunc i32 %xor36.29.12 to i8
  store i8 %conv37.29.12, i8* %scevgep41.29.11, align 1
  %scevgep28.29.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9484, i64 0, i64 0, i64 1
  %9491 = bitcast i8* %scevgep28.29.12 to [61 x [61 x i8]]*
  %scevgep41.29.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9485, i64 0, i64 1, i64 0
  %9492 = bitcast i8* %scevgep41.29.12 to [61 x [61 x i8]]*
  %call16.29.13 = call zeroext i8 (...) @rand()
  store i8 %call16.29.13, i8* %scevgep28.29.12, align 1
  %9493 = load i8, i8* %scevgep28.29.12, align 1
  %conv23.29.13 = zext i8 %9493 to i32
  %9494 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.13 = getelementptr i8, i8* %b, i64 43
  %9495 = load i8, i8* %scevgep34.29.13, align 1
  %call28.29.13 = call zeroext i8 @mult(i8 zeroext %9494, i8 zeroext %9495)
  %conv29.29.13 = zext i8 %call28.29.13 to i32
  %xor.29.13 = xor i32 %conv23.29.13, %conv29.29.13
  %scevgep35.29.13 = getelementptr i8, i8* %a, i64 43
  %9496 = load i8, i8* %scevgep35.29.13, align 1
  %9497 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.13 = call zeroext i8 @mult(i8 zeroext %9496, i8 zeroext %9497)
  %conv35.29.13 = zext i8 %call34.29.13 to i32
  %xor36.29.13 = xor i32 %xor.29.13, %conv35.29.13
  %conv37.29.13 = trunc i32 %xor36.29.13 to i8
  store i8 %conv37.29.13, i8* %scevgep41.29.12, align 1
  %scevgep28.29.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9491, i64 0, i64 0, i64 1
  %9498 = bitcast i8* %scevgep28.29.13 to [61 x [61 x i8]]*
  %scevgep41.29.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9492, i64 0, i64 1, i64 0
  %9499 = bitcast i8* %scevgep41.29.13 to [61 x [61 x i8]]*
  %call16.29.14 = call zeroext i8 (...) @rand()
  store i8 %call16.29.14, i8* %scevgep28.29.13, align 1
  %9500 = load i8, i8* %scevgep28.29.13, align 1
  %conv23.29.14 = zext i8 %9500 to i32
  %9501 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.14 = getelementptr i8, i8* %b, i64 44
  %9502 = load i8, i8* %scevgep34.29.14, align 1
  %call28.29.14 = call zeroext i8 @mult(i8 zeroext %9501, i8 zeroext %9502)
  %conv29.29.14 = zext i8 %call28.29.14 to i32
  %xor.29.14 = xor i32 %conv23.29.14, %conv29.29.14
  %scevgep35.29.14 = getelementptr i8, i8* %a, i64 44
  %9503 = load i8, i8* %scevgep35.29.14, align 1
  %9504 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.14 = call zeroext i8 @mult(i8 zeroext %9503, i8 zeroext %9504)
  %conv35.29.14 = zext i8 %call34.29.14 to i32
  %xor36.29.14 = xor i32 %xor.29.14, %conv35.29.14
  %conv37.29.14 = trunc i32 %xor36.29.14 to i8
  store i8 %conv37.29.14, i8* %scevgep41.29.13, align 1
  %scevgep28.29.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9498, i64 0, i64 0, i64 1
  %9505 = bitcast i8* %scevgep28.29.14 to [61 x [61 x i8]]*
  %scevgep41.29.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9499, i64 0, i64 1, i64 0
  %9506 = bitcast i8* %scevgep41.29.14 to [61 x [61 x i8]]*
  %call16.29.15 = call zeroext i8 (...) @rand()
  store i8 %call16.29.15, i8* %scevgep28.29.14, align 1
  %9507 = load i8, i8* %scevgep28.29.14, align 1
  %conv23.29.15 = zext i8 %9507 to i32
  %9508 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.15 = getelementptr i8, i8* %b, i64 45
  %9509 = load i8, i8* %scevgep34.29.15, align 1
  %call28.29.15 = call zeroext i8 @mult(i8 zeroext %9508, i8 zeroext %9509)
  %conv29.29.15 = zext i8 %call28.29.15 to i32
  %xor.29.15 = xor i32 %conv23.29.15, %conv29.29.15
  %scevgep35.29.15 = getelementptr i8, i8* %a, i64 45
  %9510 = load i8, i8* %scevgep35.29.15, align 1
  %9511 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.15 = call zeroext i8 @mult(i8 zeroext %9510, i8 zeroext %9511)
  %conv35.29.15 = zext i8 %call34.29.15 to i32
  %xor36.29.15 = xor i32 %xor.29.15, %conv35.29.15
  %conv37.29.15 = trunc i32 %xor36.29.15 to i8
  store i8 %conv37.29.15, i8* %scevgep41.29.14, align 1
  %scevgep28.29.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9505, i64 0, i64 0, i64 1
  %9512 = bitcast i8* %scevgep28.29.15 to [61 x [61 x i8]]*
  %scevgep41.29.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9506, i64 0, i64 1, i64 0
  %9513 = bitcast i8* %scevgep41.29.15 to [61 x [61 x i8]]*
  %call16.29.16 = call zeroext i8 (...) @rand()
  store i8 %call16.29.16, i8* %scevgep28.29.15, align 1
  %9514 = load i8, i8* %scevgep28.29.15, align 1
  %conv23.29.16 = zext i8 %9514 to i32
  %9515 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.16 = getelementptr i8, i8* %b, i64 46
  %9516 = load i8, i8* %scevgep34.29.16, align 1
  %call28.29.16 = call zeroext i8 @mult(i8 zeroext %9515, i8 zeroext %9516)
  %conv29.29.16 = zext i8 %call28.29.16 to i32
  %xor.29.16 = xor i32 %conv23.29.16, %conv29.29.16
  %scevgep35.29.16 = getelementptr i8, i8* %a, i64 46
  %9517 = load i8, i8* %scevgep35.29.16, align 1
  %9518 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.16 = call zeroext i8 @mult(i8 zeroext %9517, i8 zeroext %9518)
  %conv35.29.16 = zext i8 %call34.29.16 to i32
  %xor36.29.16 = xor i32 %xor.29.16, %conv35.29.16
  %conv37.29.16 = trunc i32 %xor36.29.16 to i8
  store i8 %conv37.29.16, i8* %scevgep41.29.15, align 1
  %scevgep28.29.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9512, i64 0, i64 0, i64 1
  %9519 = bitcast i8* %scevgep28.29.16 to [61 x [61 x i8]]*
  %scevgep41.29.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9513, i64 0, i64 1, i64 0
  %9520 = bitcast i8* %scevgep41.29.16 to [61 x [61 x i8]]*
  %call16.29.17 = call zeroext i8 (...) @rand()
  store i8 %call16.29.17, i8* %scevgep28.29.16, align 1
  %9521 = load i8, i8* %scevgep28.29.16, align 1
  %conv23.29.17 = zext i8 %9521 to i32
  %9522 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.17 = getelementptr i8, i8* %b, i64 47
  %9523 = load i8, i8* %scevgep34.29.17, align 1
  %call28.29.17 = call zeroext i8 @mult(i8 zeroext %9522, i8 zeroext %9523)
  %conv29.29.17 = zext i8 %call28.29.17 to i32
  %xor.29.17 = xor i32 %conv23.29.17, %conv29.29.17
  %scevgep35.29.17 = getelementptr i8, i8* %a, i64 47
  %9524 = load i8, i8* %scevgep35.29.17, align 1
  %9525 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.17 = call zeroext i8 @mult(i8 zeroext %9524, i8 zeroext %9525)
  %conv35.29.17 = zext i8 %call34.29.17 to i32
  %xor36.29.17 = xor i32 %xor.29.17, %conv35.29.17
  %conv37.29.17 = trunc i32 %xor36.29.17 to i8
  store i8 %conv37.29.17, i8* %scevgep41.29.16, align 1
  %scevgep28.29.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9519, i64 0, i64 0, i64 1
  %9526 = bitcast i8* %scevgep28.29.17 to [61 x [61 x i8]]*
  %scevgep41.29.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9520, i64 0, i64 1, i64 0
  %9527 = bitcast i8* %scevgep41.29.17 to [61 x [61 x i8]]*
  %call16.29.18 = call zeroext i8 (...) @rand()
  store i8 %call16.29.18, i8* %scevgep28.29.17, align 1
  %9528 = load i8, i8* %scevgep28.29.17, align 1
  %conv23.29.18 = zext i8 %9528 to i32
  %9529 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.18 = getelementptr i8, i8* %b, i64 48
  %9530 = load i8, i8* %scevgep34.29.18, align 1
  %call28.29.18 = call zeroext i8 @mult(i8 zeroext %9529, i8 zeroext %9530)
  %conv29.29.18 = zext i8 %call28.29.18 to i32
  %xor.29.18 = xor i32 %conv23.29.18, %conv29.29.18
  %scevgep35.29.18 = getelementptr i8, i8* %a, i64 48
  %9531 = load i8, i8* %scevgep35.29.18, align 1
  %9532 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.18 = call zeroext i8 @mult(i8 zeroext %9531, i8 zeroext %9532)
  %conv35.29.18 = zext i8 %call34.29.18 to i32
  %xor36.29.18 = xor i32 %xor.29.18, %conv35.29.18
  %conv37.29.18 = trunc i32 %xor36.29.18 to i8
  store i8 %conv37.29.18, i8* %scevgep41.29.17, align 1
  %scevgep28.29.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9526, i64 0, i64 0, i64 1
  %9533 = bitcast i8* %scevgep28.29.18 to [61 x [61 x i8]]*
  %scevgep41.29.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9527, i64 0, i64 1, i64 0
  %9534 = bitcast i8* %scevgep41.29.18 to [61 x [61 x i8]]*
  %call16.29.19 = call zeroext i8 (...) @rand()
  store i8 %call16.29.19, i8* %scevgep28.29.18, align 1
  %9535 = load i8, i8* %scevgep28.29.18, align 1
  %conv23.29.19 = zext i8 %9535 to i32
  %9536 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.19 = getelementptr i8, i8* %b, i64 49
  %9537 = load i8, i8* %scevgep34.29.19, align 1
  %call28.29.19 = call zeroext i8 @mult(i8 zeroext %9536, i8 zeroext %9537)
  %conv29.29.19 = zext i8 %call28.29.19 to i32
  %xor.29.19 = xor i32 %conv23.29.19, %conv29.29.19
  %scevgep35.29.19 = getelementptr i8, i8* %a, i64 49
  %9538 = load i8, i8* %scevgep35.29.19, align 1
  %9539 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.19 = call zeroext i8 @mult(i8 zeroext %9538, i8 zeroext %9539)
  %conv35.29.19 = zext i8 %call34.29.19 to i32
  %xor36.29.19 = xor i32 %xor.29.19, %conv35.29.19
  %conv37.29.19 = trunc i32 %xor36.29.19 to i8
  store i8 %conv37.29.19, i8* %scevgep41.29.18, align 1
  %scevgep28.29.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9533, i64 0, i64 0, i64 1
  %9540 = bitcast i8* %scevgep28.29.19 to [61 x [61 x i8]]*
  %scevgep41.29.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9534, i64 0, i64 1, i64 0
  %9541 = bitcast i8* %scevgep41.29.19 to [61 x [61 x i8]]*
  %call16.29.20 = call zeroext i8 (...) @rand()
  store i8 %call16.29.20, i8* %scevgep28.29.19, align 1
  %9542 = load i8, i8* %scevgep28.29.19, align 1
  %conv23.29.20 = zext i8 %9542 to i32
  %9543 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.20 = getelementptr i8, i8* %b, i64 50
  %9544 = load i8, i8* %scevgep34.29.20, align 1
  %call28.29.20 = call zeroext i8 @mult(i8 zeroext %9543, i8 zeroext %9544)
  %conv29.29.20 = zext i8 %call28.29.20 to i32
  %xor.29.20 = xor i32 %conv23.29.20, %conv29.29.20
  %scevgep35.29.20 = getelementptr i8, i8* %a, i64 50
  %9545 = load i8, i8* %scevgep35.29.20, align 1
  %9546 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.20 = call zeroext i8 @mult(i8 zeroext %9545, i8 zeroext %9546)
  %conv35.29.20 = zext i8 %call34.29.20 to i32
  %xor36.29.20 = xor i32 %xor.29.20, %conv35.29.20
  %conv37.29.20 = trunc i32 %xor36.29.20 to i8
  store i8 %conv37.29.20, i8* %scevgep41.29.19, align 1
  %scevgep28.29.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9540, i64 0, i64 0, i64 1
  %9547 = bitcast i8* %scevgep28.29.20 to [61 x [61 x i8]]*
  %scevgep41.29.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9541, i64 0, i64 1, i64 0
  %9548 = bitcast i8* %scevgep41.29.20 to [61 x [61 x i8]]*
  %call16.29.21 = call zeroext i8 (...) @rand()
  store i8 %call16.29.21, i8* %scevgep28.29.20, align 1
  %9549 = load i8, i8* %scevgep28.29.20, align 1
  %conv23.29.21 = zext i8 %9549 to i32
  %9550 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.21 = getelementptr i8, i8* %b, i64 51
  %9551 = load i8, i8* %scevgep34.29.21, align 1
  %call28.29.21 = call zeroext i8 @mult(i8 zeroext %9550, i8 zeroext %9551)
  %conv29.29.21 = zext i8 %call28.29.21 to i32
  %xor.29.21 = xor i32 %conv23.29.21, %conv29.29.21
  %scevgep35.29.21 = getelementptr i8, i8* %a, i64 51
  %9552 = load i8, i8* %scevgep35.29.21, align 1
  %9553 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.21 = call zeroext i8 @mult(i8 zeroext %9552, i8 zeroext %9553)
  %conv35.29.21 = zext i8 %call34.29.21 to i32
  %xor36.29.21 = xor i32 %xor.29.21, %conv35.29.21
  %conv37.29.21 = trunc i32 %xor36.29.21 to i8
  store i8 %conv37.29.21, i8* %scevgep41.29.20, align 1
  %scevgep28.29.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9547, i64 0, i64 0, i64 1
  %9554 = bitcast i8* %scevgep28.29.21 to [61 x [61 x i8]]*
  %scevgep41.29.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9548, i64 0, i64 1, i64 0
  %9555 = bitcast i8* %scevgep41.29.21 to [61 x [61 x i8]]*
  %call16.29.22 = call zeroext i8 (...) @rand()
  store i8 %call16.29.22, i8* %scevgep28.29.21, align 1
  %9556 = load i8, i8* %scevgep28.29.21, align 1
  %conv23.29.22 = zext i8 %9556 to i32
  %9557 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.22 = getelementptr i8, i8* %b, i64 52
  %9558 = load i8, i8* %scevgep34.29.22, align 1
  %call28.29.22 = call zeroext i8 @mult(i8 zeroext %9557, i8 zeroext %9558)
  %conv29.29.22 = zext i8 %call28.29.22 to i32
  %xor.29.22 = xor i32 %conv23.29.22, %conv29.29.22
  %scevgep35.29.22 = getelementptr i8, i8* %a, i64 52
  %9559 = load i8, i8* %scevgep35.29.22, align 1
  %9560 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.22 = call zeroext i8 @mult(i8 zeroext %9559, i8 zeroext %9560)
  %conv35.29.22 = zext i8 %call34.29.22 to i32
  %xor36.29.22 = xor i32 %xor.29.22, %conv35.29.22
  %conv37.29.22 = trunc i32 %xor36.29.22 to i8
  store i8 %conv37.29.22, i8* %scevgep41.29.21, align 1
  %scevgep28.29.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9554, i64 0, i64 0, i64 1
  %9561 = bitcast i8* %scevgep28.29.22 to [61 x [61 x i8]]*
  %scevgep41.29.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9555, i64 0, i64 1, i64 0
  %9562 = bitcast i8* %scevgep41.29.22 to [61 x [61 x i8]]*
  %call16.29.23 = call zeroext i8 (...) @rand()
  store i8 %call16.29.23, i8* %scevgep28.29.22, align 1
  %9563 = load i8, i8* %scevgep28.29.22, align 1
  %conv23.29.23 = zext i8 %9563 to i32
  %9564 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.23 = getelementptr i8, i8* %b, i64 53
  %9565 = load i8, i8* %scevgep34.29.23, align 1
  %call28.29.23 = call zeroext i8 @mult(i8 zeroext %9564, i8 zeroext %9565)
  %conv29.29.23 = zext i8 %call28.29.23 to i32
  %xor.29.23 = xor i32 %conv23.29.23, %conv29.29.23
  %scevgep35.29.23 = getelementptr i8, i8* %a, i64 53
  %9566 = load i8, i8* %scevgep35.29.23, align 1
  %9567 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.23 = call zeroext i8 @mult(i8 zeroext %9566, i8 zeroext %9567)
  %conv35.29.23 = zext i8 %call34.29.23 to i32
  %xor36.29.23 = xor i32 %xor.29.23, %conv35.29.23
  %conv37.29.23 = trunc i32 %xor36.29.23 to i8
  store i8 %conv37.29.23, i8* %scevgep41.29.22, align 1
  %scevgep28.29.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9561, i64 0, i64 0, i64 1
  %9568 = bitcast i8* %scevgep28.29.23 to [61 x [61 x i8]]*
  %scevgep41.29.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9562, i64 0, i64 1, i64 0
  %9569 = bitcast i8* %scevgep41.29.23 to [61 x [61 x i8]]*
  %call16.29.24 = call zeroext i8 (...) @rand()
  store i8 %call16.29.24, i8* %scevgep28.29.23, align 1
  %9570 = load i8, i8* %scevgep28.29.23, align 1
  %conv23.29.24 = zext i8 %9570 to i32
  %9571 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.24 = getelementptr i8, i8* %b, i64 54
  %9572 = load i8, i8* %scevgep34.29.24, align 1
  %call28.29.24 = call zeroext i8 @mult(i8 zeroext %9571, i8 zeroext %9572)
  %conv29.29.24 = zext i8 %call28.29.24 to i32
  %xor.29.24 = xor i32 %conv23.29.24, %conv29.29.24
  %scevgep35.29.24 = getelementptr i8, i8* %a, i64 54
  %9573 = load i8, i8* %scevgep35.29.24, align 1
  %9574 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.24 = call zeroext i8 @mult(i8 zeroext %9573, i8 zeroext %9574)
  %conv35.29.24 = zext i8 %call34.29.24 to i32
  %xor36.29.24 = xor i32 %xor.29.24, %conv35.29.24
  %conv37.29.24 = trunc i32 %xor36.29.24 to i8
  store i8 %conv37.29.24, i8* %scevgep41.29.23, align 1
  %scevgep28.29.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9568, i64 0, i64 0, i64 1
  %9575 = bitcast i8* %scevgep28.29.24 to [61 x [61 x i8]]*
  %scevgep41.29.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9569, i64 0, i64 1, i64 0
  %9576 = bitcast i8* %scevgep41.29.24 to [61 x [61 x i8]]*
  %call16.29.25 = call zeroext i8 (...) @rand()
  store i8 %call16.29.25, i8* %scevgep28.29.24, align 1
  %9577 = load i8, i8* %scevgep28.29.24, align 1
  %conv23.29.25 = zext i8 %9577 to i32
  %9578 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.25 = getelementptr i8, i8* %b, i64 55
  %9579 = load i8, i8* %scevgep34.29.25, align 1
  %call28.29.25 = call zeroext i8 @mult(i8 zeroext %9578, i8 zeroext %9579)
  %conv29.29.25 = zext i8 %call28.29.25 to i32
  %xor.29.25 = xor i32 %conv23.29.25, %conv29.29.25
  %scevgep35.29.25 = getelementptr i8, i8* %a, i64 55
  %9580 = load i8, i8* %scevgep35.29.25, align 1
  %9581 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.25 = call zeroext i8 @mult(i8 zeroext %9580, i8 zeroext %9581)
  %conv35.29.25 = zext i8 %call34.29.25 to i32
  %xor36.29.25 = xor i32 %xor.29.25, %conv35.29.25
  %conv37.29.25 = trunc i32 %xor36.29.25 to i8
  store i8 %conv37.29.25, i8* %scevgep41.29.24, align 1
  %scevgep28.29.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9575, i64 0, i64 0, i64 1
  %9582 = bitcast i8* %scevgep28.29.25 to [61 x [61 x i8]]*
  %scevgep41.29.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9576, i64 0, i64 1, i64 0
  %9583 = bitcast i8* %scevgep41.29.25 to [61 x [61 x i8]]*
  %call16.29.26 = call zeroext i8 (...) @rand()
  store i8 %call16.29.26, i8* %scevgep28.29.25, align 1
  %9584 = load i8, i8* %scevgep28.29.25, align 1
  %conv23.29.26 = zext i8 %9584 to i32
  %9585 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.26 = getelementptr i8, i8* %b, i64 56
  %9586 = load i8, i8* %scevgep34.29.26, align 1
  %call28.29.26 = call zeroext i8 @mult(i8 zeroext %9585, i8 zeroext %9586)
  %conv29.29.26 = zext i8 %call28.29.26 to i32
  %xor.29.26 = xor i32 %conv23.29.26, %conv29.29.26
  %scevgep35.29.26 = getelementptr i8, i8* %a, i64 56
  %9587 = load i8, i8* %scevgep35.29.26, align 1
  %9588 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.26 = call zeroext i8 @mult(i8 zeroext %9587, i8 zeroext %9588)
  %conv35.29.26 = zext i8 %call34.29.26 to i32
  %xor36.29.26 = xor i32 %xor.29.26, %conv35.29.26
  %conv37.29.26 = trunc i32 %xor36.29.26 to i8
  store i8 %conv37.29.26, i8* %scevgep41.29.25, align 1
  %scevgep28.29.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9582, i64 0, i64 0, i64 1
  %9589 = bitcast i8* %scevgep28.29.26 to [61 x [61 x i8]]*
  %scevgep41.29.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9583, i64 0, i64 1, i64 0
  %9590 = bitcast i8* %scevgep41.29.26 to [61 x [61 x i8]]*
  %call16.29.27 = call zeroext i8 (...) @rand()
  store i8 %call16.29.27, i8* %scevgep28.29.26, align 1
  %9591 = load i8, i8* %scevgep28.29.26, align 1
  %conv23.29.27 = zext i8 %9591 to i32
  %9592 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.27 = getelementptr i8, i8* %b, i64 57
  %9593 = load i8, i8* %scevgep34.29.27, align 1
  %call28.29.27 = call zeroext i8 @mult(i8 zeroext %9592, i8 zeroext %9593)
  %conv29.29.27 = zext i8 %call28.29.27 to i32
  %xor.29.27 = xor i32 %conv23.29.27, %conv29.29.27
  %scevgep35.29.27 = getelementptr i8, i8* %a, i64 57
  %9594 = load i8, i8* %scevgep35.29.27, align 1
  %9595 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.27 = call zeroext i8 @mult(i8 zeroext %9594, i8 zeroext %9595)
  %conv35.29.27 = zext i8 %call34.29.27 to i32
  %xor36.29.27 = xor i32 %xor.29.27, %conv35.29.27
  %conv37.29.27 = trunc i32 %xor36.29.27 to i8
  store i8 %conv37.29.27, i8* %scevgep41.29.26, align 1
  %scevgep28.29.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9589, i64 0, i64 0, i64 1
  %9596 = bitcast i8* %scevgep28.29.27 to [61 x [61 x i8]]*
  %scevgep41.29.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9590, i64 0, i64 1, i64 0
  %9597 = bitcast i8* %scevgep41.29.27 to [61 x [61 x i8]]*
  %call16.29.28 = call zeroext i8 (...) @rand()
  store i8 %call16.29.28, i8* %scevgep28.29.27, align 1
  %9598 = load i8, i8* %scevgep28.29.27, align 1
  %conv23.29.28 = zext i8 %9598 to i32
  %9599 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.28 = getelementptr i8, i8* %b, i64 58
  %9600 = load i8, i8* %scevgep34.29.28, align 1
  %call28.29.28 = call zeroext i8 @mult(i8 zeroext %9599, i8 zeroext %9600)
  %conv29.29.28 = zext i8 %call28.29.28 to i32
  %xor.29.28 = xor i32 %conv23.29.28, %conv29.29.28
  %scevgep35.29.28 = getelementptr i8, i8* %a, i64 58
  %9601 = load i8, i8* %scevgep35.29.28, align 1
  %9602 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.28 = call zeroext i8 @mult(i8 zeroext %9601, i8 zeroext %9602)
  %conv35.29.28 = zext i8 %call34.29.28 to i32
  %xor36.29.28 = xor i32 %xor.29.28, %conv35.29.28
  %conv37.29.28 = trunc i32 %xor36.29.28 to i8
  store i8 %conv37.29.28, i8* %scevgep41.29.27, align 1
  %scevgep28.29.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9596, i64 0, i64 0, i64 1
  %9603 = bitcast i8* %scevgep28.29.28 to [61 x [61 x i8]]*
  %scevgep41.29.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9597, i64 0, i64 1, i64 0
  %9604 = bitcast i8* %scevgep41.29.28 to [61 x [61 x i8]]*
  %call16.29.29 = call zeroext i8 (...) @rand()
  store i8 %call16.29.29, i8* %scevgep28.29.28, align 1
  %9605 = load i8, i8* %scevgep28.29.28, align 1
  %conv23.29.29 = zext i8 %9605 to i32
  %9606 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.29 = getelementptr i8, i8* %b, i64 59
  %9607 = load i8, i8* %scevgep34.29.29, align 1
  %call28.29.29 = call zeroext i8 @mult(i8 zeroext %9606, i8 zeroext %9607)
  %conv29.29.29 = zext i8 %call28.29.29 to i32
  %xor.29.29 = xor i32 %conv23.29.29, %conv29.29.29
  %scevgep35.29.29 = getelementptr i8, i8* %a, i64 59
  %9608 = load i8, i8* %scevgep35.29.29, align 1
  %9609 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.29 = call zeroext i8 @mult(i8 zeroext %9608, i8 zeroext %9609)
  %conv35.29.29 = zext i8 %call34.29.29 to i32
  %xor36.29.29 = xor i32 %xor.29.29, %conv35.29.29
  %conv37.29.29 = trunc i32 %xor36.29.29 to i8
  store i8 %conv37.29.29, i8* %scevgep41.29.28, align 1
  %scevgep28.29.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9603, i64 0, i64 0, i64 1
  %scevgep41.29.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9604, i64 0, i64 1, i64 0
  %call16.29.30 = call zeroext i8 (...) @rand()
  store i8 %call16.29.30, i8* %scevgep28.29.29, align 1
  %9610 = load i8, i8* %scevgep28.29.29, align 1
  %conv23.29.30 = zext i8 %9610 to i32
  %9611 = load i8, i8* %arrayidx25.29, align 1
  %scevgep34.29.30 = getelementptr i8, i8* %b, i64 60
  %9612 = load i8, i8* %scevgep34.29.30, align 1
  %call28.29.30 = call zeroext i8 @mult(i8 zeroext %9611, i8 zeroext %9612)
  %conv29.29.30 = zext i8 %call28.29.30 to i32
  %xor.29.30 = xor i32 %conv23.29.30, %conv29.29.30
  %scevgep35.29.30 = getelementptr i8, i8* %a, i64 60
  %9613 = load i8, i8* %scevgep35.29.30, align 1
  %9614 = load i8, i8* %arrayidx33.29, align 1
  %call34.29.30 = call zeroext i8 @mult(i8 zeroext %9613, i8 zeroext %9614)
  %conv35.29.30 = zext i8 %call34.29.30 to i32
  %xor36.29.30 = xor i32 %xor.29.30, %conv35.29.30
  %conv37.29.30 = trunc i32 %xor36.29.30 to i8
  store i8 %conv37.29.30, i8* %scevgep41.29.29, align 1
  %scevgep26.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9400, i64 0, i64 1, i64 1
  %9615 = bitcast i8* %scevgep26.29 to [61 x [61 x i8]]*
  %scevgep39.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9401, i64 0, i64 1, i64 1
  %9616 = bitcast i8* %scevgep39.29 to [61 x [61 x i8]]*
  %arrayidx25.30 = getelementptr inbounds i8, i8* %a, i64 30
  %arrayidx33.30 = getelementptr inbounds i8, i8* %b, i64 30
  %call16.30 = call zeroext i8 (...) @rand()
  store i8 %call16.30, i8* %scevgep26.29, align 1
  %9617 = load i8, i8* %scevgep26.29, align 1
  %conv23.30 = zext i8 %9617 to i32
  %9618 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30 = getelementptr i8, i8* %b, i64 31
  %9619 = load i8, i8* %scevgep34.30, align 1
  %call28.30 = call zeroext i8 @mult(i8 zeroext %9618, i8 zeroext %9619)
  %conv29.30 = zext i8 %call28.30 to i32
  %xor.30 = xor i32 %conv23.30, %conv29.30
  %scevgep35.30 = getelementptr i8, i8* %a, i64 31
  %9620 = load i8, i8* %scevgep35.30, align 1
  %9621 = load i8, i8* %arrayidx33.30, align 1
  %call34.30 = call zeroext i8 @mult(i8 zeroext %9620, i8 zeroext %9621)
  %conv35.30 = zext i8 %call34.30 to i32
  %xor36.30 = xor i32 %xor.30, %conv35.30
  %conv37.30 = trunc i32 %xor36.30 to i8
  store i8 %conv37.30, i8* %scevgep39.29, align 1
  %scevgep28.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9615, i64 0, i64 0, i64 1
  %9622 = bitcast i8* %scevgep28.30 to [61 x [61 x i8]]*
  %scevgep41.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9616, i64 0, i64 1, i64 0
  %9623 = bitcast i8* %scevgep41.30 to [61 x [61 x i8]]*
  %call16.30.1 = call zeroext i8 (...) @rand()
  store i8 %call16.30.1, i8* %scevgep28.30, align 1
  %9624 = load i8, i8* %scevgep28.30, align 1
  %conv23.30.1 = zext i8 %9624 to i32
  %9625 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.1 = getelementptr i8, i8* %b, i64 32
  %9626 = load i8, i8* %scevgep34.30.1, align 1
  %call28.30.1 = call zeroext i8 @mult(i8 zeroext %9625, i8 zeroext %9626)
  %conv29.30.1 = zext i8 %call28.30.1 to i32
  %xor.30.1 = xor i32 %conv23.30.1, %conv29.30.1
  %scevgep35.30.1 = getelementptr i8, i8* %a, i64 32
  %9627 = load i8, i8* %scevgep35.30.1, align 1
  %9628 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.1 = call zeroext i8 @mult(i8 zeroext %9627, i8 zeroext %9628)
  %conv35.30.1 = zext i8 %call34.30.1 to i32
  %xor36.30.1 = xor i32 %xor.30.1, %conv35.30.1
  %conv37.30.1 = trunc i32 %xor36.30.1 to i8
  store i8 %conv37.30.1, i8* %scevgep41.30, align 1
  %scevgep28.30.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9622, i64 0, i64 0, i64 1
  %9629 = bitcast i8* %scevgep28.30.1 to [61 x [61 x i8]]*
  %scevgep41.30.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9623, i64 0, i64 1, i64 0
  %9630 = bitcast i8* %scevgep41.30.1 to [61 x [61 x i8]]*
  %call16.30.2 = call zeroext i8 (...) @rand()
  store i8 %call16.30.2, i8* %scevgep28.30.1, align 1
  %9631 = load i8, i8* %scevgep28.30.1, align 1
  %conv23.30.2 = zext i8 %9631 to i32
  %9632 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.2 = getelementptr i8, i8* %b, i64 33
  %9633 = load i8, i8* %scevgep34.30.2, align 1
  %call28.30.2 = call zeroext i8 @mult(i8 zeroext %9632, i8 zeroext %9633)
  %conv29.30.2 = zext i8 %call28.30.2 to i32
  %xor.30.2 = xor i32 %conv23.30.2, %conv29.30.2
  %scevgep35.30.2 = getelementptr i8, i8* %a, i64 33
  %9634 = load i8, i8* %scevgep35.30.2, align 1
  %9635 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.2 = call zeroext i8 @mult(i8 zeroext %9634, i8 zeroext %9635)
  %conv35.30.2 = zext i8 %call34.30.2 to i32
  %xor36.30.2 = xor i32 %xor.30.2, %conv35.30.2
  %conv37.30.2 = trunc i32 %xor36.30.2 to i8
  store i8 %conv37.30.2, i8* %scevgep41.30.1, align 1
  %scevgep28.30.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9629, i64 0, i64 0, i64 1
  %9636 = bitcast i8* %scevgep28.30.2 to [61 x [61 x i8]]*
  %scevgep41.30.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9630, i64 0, i64 1, i64 0
  %9637 = bitcast i8* %scevgep41.30.2 to [61 x [61 x i8]]*
  %call16.30.3 = call zeroext i8 (...) @rand()
  store i8 %call16.30.3, i8* %scevgep28.30.2, align 1
  %9638 = load i8, i8* %scevgep28.30.2, align 1
  %conv23.30.3 = zext i8 %9638 to i32
  %9639 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.3 = getelementptr i8, i8* %b, i64 34
  %9640 = load i8, i8* %scevgep34.30.3, align 1
  %call28.30.3 = call zeroext i8 @mult(i8 zeroext %9639, i8 zeroext %9640)
  %conv29.30.3 = zext i8 %call28.30.3 to i32
  %xor.30.3 = xor i32 %conv23.30.3, %conv29.30.3
  %scevgep35.30.3 = getelementptr i8, i8* %a, i64 34
  %9641 = load i8, i8* %scevgep35.30.3, align 1
  %9642 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.3 = call zeroext i8 @mult(i8 zeroext %9641, i8 zeroext %9642)
  %conv35.30.3 = zext i8 %call34.30.3 to i32
  %xor36.30.3 = xor i32 %xor.30.3, %conv35.30.3
  %conv37.30.3 = trunc i32 %xor36.30.3 to i8
  store i8 %conv37.30.3, i8* %scevgep41.30.2, align 1
  %scevgep28.30.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9636, i64 0, i64 0, i64 1
  %9643 = bitcast i8* %scevgep28.30.3 to [61 x [61 x i8]]*
  %scevgep41.30.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9637, i64 0, i64 1, i64 0
  %9644 = bitcast i8* %scevgep41.30.3 to [61 x [61 x i8]]*
  %call16.30.4 = call zeroext i8 (...) @rand()
  store i8 %call16.30.4, i8* %scevgep28.30.3, align 1
  %9645 = load i8, i8* %scevgep28.30.3, align 1
  %conv23.30.4 = zext i8 %9645 to i32
  %9646 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.4 = getelementptr i8, i8* %b, i64 35
  %9647 = load i8, i8* %scevgep34.30.4, align 1
  %call28.30.4 = call zeroext i8 @mult(i8 zeroext %9646, i8 zeroext %9647)
  %conv29.30.4 = zext i8 %call28.30.4 to i32
  %xor.30.4 = xor i32 %conv23.30.4, %conv29.30.4
  %scevgep35.30.4 = getelementptr i8, i8* %a, i64 35
  %9648 = load i8, i8* %scevgep35.30.4, align 1
  %9649 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.4 = call zeroext i8 @mult(i8 zeroext %9648, i8 zeroext %9649)
  %conv35.30.4 = zext i8 %call34.30.4 to i32
  %xor36.30.4 = xor i32 %xor.30.4, %conv35.30.4
  %conv37.30.4 = trunc i32 %xor36.30.4 to i8
  store i8 %conv37.30.4, i8* %scevgep41.30.3, align 1
  %scevgep28.30.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9643, i64 0, i64 0, i64 1
  %9650 = bitcast i8* %scevgep28.30.4 to [61 x [61 x i8]]*
  %scevgep41.30.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9644, i64 0, i64 1, i64 0
  %9651 = bitcast i8* %scevgep41.30.4 to [61 x [61 x i8]]*
  %call16.30.5 = call zeroext i8 (...) @rand()
  store i8 %call16.30.5, i8* %scevgep28.30.4, align 1
  %9652 = load i8, i8* %scevgep28.30.4, align 1
  %conv23.30.5 = zext i8 %9652 to i32
  %9653 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.5 = getelementptr i8, i8* %b, i64 36
  %9654 = load i8, i8* %scevgep34.30.5, align 1
  %call28.30.5 = call zeroext i8 @mult(i8 zeroext %9653, i8 zeroext %9654)
  %conv29.30.5 = zext i8 %call28.30.5 to i32
  %xor.30.5 = xor i32 %conv23.30.5, %conv29.30.5
  %scevgep35.30.5 = getelementptr i8, i8* %a, i64 36
  %9655 = load i8, i8* %scevgep35.30.5, align 1
  %9656 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.5 = call zeroext i8 @mult(i8 zeroext %9655, i8 zeroext %9656)
  %conv35.30.5 = zext i8 %call34.30.5 to i32
  %xor36.30.5 = xor i32 %xor.30.5, %conv35.30.5
  %conv37.30.5 = trunc i32 %xor36.30.5 to i8
  store i8 %conv37.30.5, i8* %scevgep41.30.4, align 1
  %scevgep28.30.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9650, i64 0, i64 0, i64 1
  %9657 = bitcast i8* %scevgep28.30.5 to [61 x [61 x i8]]*
  %scevgep41.30.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9651, i64 0, i64 1, i64 0
  %9658 = bitcast i8* %scevgep41.30.5 to [61 x [61 x i8]]*
  %call16.30.6 = call zeroext i8 (...) @rand()
  store i8 %call16.30.6, i8* %scevgep28.30.5, align 1
  %9659 = load i8, i8* %scevgep28.30.5, align 1
  %conv23.30.6 = zext i8 %9659 to i32
  %9660 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.6 = getelementptr i8, i8* %b, i64 37
  %9661 = load i8, i8* %scevgep34.30.6, align 1
  %call28.30.6 = call zeroext i8 @mult(i8 zeroext %9660, i8 zeroext %9661)
  %conv29.30.6 = zext i8 %call28.30.6 to i32
  %xor.30.6 = xor i32 %conv23.30.6, %conv29.30.6
  %scevgep35.30.6 = getelementptr i8, i8* %a, i64 37
  %9662 = load i8, i8* %scevgep35.30.6, align 1
  %9663 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.6 = call zeroext i8 @mult(i8 zeroext %9662, i8 zeroext %9663)
  %conv35.30.6 = zext i8 %call34.30.6 to i32
  %xor36.30.6 = xor i32 %xor.30.6, %conv35.30.6
  %conv37.30.6 = trunc i32 %xor36.30.6 to i8
  store i8 %conv37.30.6, i8* %scevgep41.30.5, align 1
  %scevgep28.30.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9657, i64 0, i64 0, i64 1
  %9664 = bitcast i8* %scevgep28.30.6 to [61 x [61 x i8]]*
  %scevgep41.30.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9658, i64 0, i64 1, i64 0
  %9665 = bitcast i8* %scevgep41.30.6 to [61 x [61 x i8]]*
  %call16.30.7 = call zeroext i8 (...) @rand()
  store i8 %call16.30.7, i8* %scevgep28.30.6, align 1
  %9666 = load i8, i8* %scevgep28.30.6, align 1
  %conv23.30.7 = zext i8 %9666 to i32
  %9667 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.7 = getelementptr i8, i8* %b, i64 38
  %9668 = load i8, i8* %scevgep34.30.7, align 1
  %call28.30.7 = call zeroext i8 @mult(i8 zeroext %9667, i8 zeroext %9668)
  %conv29.30.7 = zext i8 %call28.30.7 to i32
  %xor.30.7 = xor i32 %conv23.30.7, %conv29.30.7
  %scevgep35.30.7 = getelementptr i8, i8* %a, i64 38
  %9669 = load i8, i8* %scevgep35.30.7, align 1
  %9670 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.7 = call zeroext i8 @mult(i8 zeroext %9669, i8 zeroext %9670)
  %conv35.30.7 = zext i8 %call34.30.7 to i32
  %xor36.30.7 = xor i32 %xor.30.7, %conv35.30.7
  %conv37.30.7 = trunc i32 %xor36.30.7 to i8
  store i8 %conv37.30.7, i8* %scevgep41.30.6, align 1
  %scevgep28.30.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9664, i64 0, i64 0, i64 1
  %9671 = bitcast i8* %scevgep28.30.7 to [61 x [61 x i8]]*
  %scevgep41.30.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9665, i64 0, i64 1, i64 0
  %9672 = bitcast i8* %scevgep41.30.7 to [61 x [61 x i8]]*
  %call16.30.8 = call zeroext i8 (...) @rand()
  store i8 %call16.30.8, i8* %scevgep28.30.7, align 1
  %9673 = load i8, i8* %scevgep28.30.7, align 1
  %conv23.30.8 = zext i8 %9673 to i32
  %9674 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.8 = getelementptr i8, i8* %b, i64 39
  %9675 = load i8, i8* %scevgep34.30.8, align 1
  %call28.30.8 = call zeroext i8 @mult(i8 zeroext %9674, i8 zeroext %9675)
  %conv29.30.8 = zext i8 %call28.30.8 to i32
  %xor.30.8 = xor i32 %conv23.30.8, %conv29.30.8
  %scevgep35.30.8 = getelementptr i8, i8* %a, i64 39
  %9676 = load i8, i8* %scevgep35.30.8, align 1
  %9677 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.8 = call zeroext i8 @mult(i8 zeroext %9676, i8 zeroext %9677)
  %conv35.30.8 = zext i8 %call34.30.8 to i32
  %xor36.30.8 = xor i32 %xor.30.8, %conv35.30.8
  %conv37.30.8 = trunc i32 %xor36.30.8 to i8
  store i8 %conv37.30.8, i8* %scevgep41.30.7, align 1
  %scevgep28.30.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9671, i64 0, i64 0, i64 1
  %9678 = bitcast i8* %scevgep28.30.8 to [61 x [61 x i8]]*
  %scevgep41.30.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9672, i64 0, i64 1, i64 0
  %9679 = bitcast i8* %scevgep41.30.8 to [61 x [61 x i8]]*
  %call16.30.9 = call zeroext i8 (...) @rand()
  store i8 %call16.30.9, i8* %scevgep28.30.8, align 1
  %9680 = load i8, i8* %scevgep28.30.8, align 1
  %conv23.30.9 = zext i8 %9680 to i32
  %9681 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.9 = getelementptr i8, i8* %b, i64 40
  %9682 = load i8, i8* %scevgep34.30.9, align 1
  %call28.30.9 = call zeroext i8 @mult(i8 zeroext %9681, i8 zeroext %9682)
  %conv29.30.9 = zext i8 %call28.30.9 to i32
  %xor.30.9 = xor i32 %conv23.30.9, %conv29.30.9
  %scevgep35.30.9 = getelementptr i8, i8* %a, i64 40
  %9683 = load i8, i8* %scevgep35.30.9, align 1
  %9684 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.9 = call zeroext i8 @mult(i8 zeroext %9683, i8 zeroext %9684)
  %conv35.30.9 = zext i8 %call34.30.9 to i32
  %xor36.30.9 = xor i32 %xor.30.9, %conv35.30.9
  %conv37.30.9 = trunc i32 %xor36.30.9 to i8
  store i8 %conv37.30.9, i8* %scevgep41.30.8, align 1
  %scevgep28.30.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9678, i64 0, i64 0, i64 1
  %9685 = bitcast i8* %scevgep28.30.9 to [61 x [61 x i8]]*
  %scevgep41.30.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9679, i64 0, i64 1, i64 0
  %9686 = bitcast i8* %scevgep41.30.9 to [61 x [61 x i8]]*
  %call16.30.10 = call zeroext i8 (...) @rand()
  store i8 %call16.30.10, i8* %scevgep28.30.9, align 1
  %9687 = load i8, i8* %scevgep28.30.9, align 1
  %conv23.30.10 = zext i8 %9687 to i32
  %9688 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.10 = getelementptr i8, i8* %b, i64 41
  %9689 = load i8, i8* %scevgep34.30.10, align 1
  %call28.30.10 = call zeroext i8 @mult(i8 zeroext %9688, i8 zeroext %9689)
  %conv29.30.10 = zext i8 %call28.30.10 to i32
  %xor.30.10 = xor i32 %conv23.30.10, %conv29.30.10
  %scevgep35.30.10 = getelementptr i8, i8* %a, i64 41
  %9690 = load i8, i8* %scevgep35.30.10, align 1
  %9691 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.10 = call zeroext i8 @mult(i8 zeroext %9690, i8 zeroext %9691)
  %conv35.30.10 = zext i8 %call34.30.10 to i32
  %xor36.30.10 = xor i32 %xor.30.10, %conv35.30.10
  %conv37.30.10 = trunc i32 %xor36.30.10 to i8
  store i8 %conv37.30.10, i8* %scevgep41.30.9, align 1
  %scevgep28.30.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9685, i64 0, i64 0, i64 1
  %9692 = bitcast i8* %scevgep28.30.10 to [61 x [61 x i8]]*
  %scevgep41.30.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9686, i64 0, i64 1, i64 0
  %9693 = bitcast i8* %scevgep41.30.10 to [61 x [61 x i8]]*
  %call16.30.11 = call zeroext i8 (...) @rand()
  store i8 %call16.30.11, i8* %scevgep28.30.10, align 1
  %9694 = load i8, i8* %scevgep28.30.10, align 1
  %conv23.30.11 = zext i8 %9694 to i32
  %9695 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.11 = getelementptr i8, i8* %b, i64 42
  %9696 = load i8, i8* %scevgep34.30.11, align 1
  %call28.30.11 = call zeroext i8 @mult(i8 zeroext %9695, i8 zeroext %9696)
  %conv29.30.11 = zext i8 %call28.30.11 to i32
  %xor.30.11 = xor i32 %conv23.30.11, %conv29.30.11
  %scevgep35.30.11 = getelementptr i8, i8* %a, i64 42
  %9697 = load i8, i8* %scevgep35.30.11, align 1
  %9698 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.11 = call zeroext i8 @mult(i8 zeroext %9697, i8 zeroext %9698)
  %conv35.30.11 = zext i8 %call34.30.11 to i32
  %xor36.30.11 = xor i32 %xor.30.11, %conv35.30.11
  %conv37.30.11 = trunc i32 %xor36.30.11 to i8
  store i8 %conv37.30.11, i8* %scevgep41.30.10, align 1
  %scevgep28.30.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9692, i64 0, i64 0, i64 1
  %9699 = bitcast i8* %scevgep28.30.11 to [61 x [61 x i8]]*
  %scevgep41.30.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9693, i64 0, i64 1, i64 0
  %9700 = bitcast i8* %scevgep41.30.11 to [61 x [61 x i8]]*
  %call16.30.12 = call zeroext i8 (...) @rand()
  store i8 %call16.30.12, i8* %scevgep28.30.11, align 1
  %9701 = load i8, i8* %scevgep28.30.11, align 1
  %conv23.30.12 = zext i8 %9701 to i32
  %9702 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.12 = getelementptr i8, i8* %b, i64 43
  %9703 = load i8, i8* %scevgep34.30.12, align 1
  %call28.30.12 = call zeroext i8 @mult(i8 zeroext %9702, i8 zeroext %9703)
  %conv29.30.12 = zext i8 %call28.30.12 to i32
  %xor.30.12 = xor i32 %conv23.30.12, %conv29.30.12
  %scevgep35.30.12 = getelementptr i8, i8* %a, i64 43
  %9704 = load i8, i8* %scevgep35.30.12, align 1
  %9705 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.12 = call zeroext i8 @mult(i8 zeroext %9704, i8 zeroext %9705)
  %conv35.30.12 = zext i8 %call34.30.12 to i32
  %xor36.30.12 = xor i32 %xor.30.12, %conv35.30.12
  %conv37.30.12 = trunc i32 %xor36.30.12 to i8
  store i8 %conv37.30.12, i8* %scevgep41.30.11, align 1
  %scevgep28.30.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9699, i64 0, i64 0, i64 1
  %9706 = bitcast i8* %scevgep28.30.12 to [61 x [61 x i8]]*
  %scevgep41.30.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9700, i64 0, i64 1, i64 0
  %9707 = bitcast i8* %scevgep41.30.12 to [61 x [61 x i8]]*
  %call16.30.13 = call zeroext i8 (...) @rand()
  store i8 %call16.30.13, i8* %scevgep28.30.12, align 1
  %9708 = load i8, i8* %scevgep28.30.12, align 1
  %conv23.30.13 = zext i8 %9708 to i32
  %9709 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.13 = getelementptr i8, i8* %b, i64 44
  %9710 = load i8, i8* %scevgep34.30.13, align 1
  %call28.30.13 = call zeroext i8 @mult(i8 zeroext %9709, i8 zeroext %9710)
  %conv29.30.13 = zext i8 %call28.30.13 to i32
  %xor.30.13 = xor i32 %conv23.30.13, %conv29.30.13
  %scevgep35.30.13 = getelementptr i8, i8* %a, i64 44
  %9711 = load i8, i8* %scevgep35.30.13, align 1
  %9712 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.13 = call zeroext i8 @mult(i8 zeroext %9711, i8 zeroext %9712)
  %conv35.30.13 = zext i8 %call34.30.13 to i32
  %xor36.30.13 = xor i32 %xor.30.13, %conv35.30.13
  %conv37.30.13 = trunc i32 %xor36.30.13 to i8
  store i8 %conv37.30.13, i8* %scevgep41.30.12, align 1
  %scevgep28.30.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9706, i64 0, i64 0, i64 1
  %9713 = bitcast i8* %scevgep28.30.13 to [61 x [61 x i8]]*
  %scevgep41.30.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9707, i64 0, i64 1, i64 0
  %9714 = bitcast i8* %scevgep41.30.13 to [61 x [61 x i8]]*
  %call16.30.14 = call zeroext i8 (...) @rand()
  store i8 %call16.30.14, i8* %scevgep28.30.13, align 1
  %9715 = load i8, i8* %scevgep28.30.13, align 1
  %conv23.30.14 = zext i8 %9715 to i32
  %9716 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.14 = getelementptr i8, i8* %b, i64 45
  %9717 = load i8, i8* %scevgep34.30.14, align 1
  %call28.30.14 = call zeroext i8 @mult(i8 zeroext %9716, i8 zeroext %9717)
  %conv29.30.14 = zext i8 %call28.30.14 to i32
  %xor.30.14 = xor i32 %conv23.30.14, %conv29.30.14
  %scevgep35.30.14 = getelementptr i8, i8* %a, i64 45
  %9718 = load i8, i8* %scevgep35.30.14, align 1
  %9719 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.14 = call zeroext i8 @mult(i8 zeroext %9718, i8 zeroext %9719)
  %conv35.30.14 = zext i8 %call34.30.14 to i32
  %xor36.30.14 = xor i32 %xor.30.14, %conv35.30.14
  %conv37.30.14 = trunc i32 %xor36.30.14 to i8
  store i8 %conv37.30.14, i8* %scevgep41.30.13, align 1
  %scevgep28.30.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9713, i64 0, i64 0, i64 1
  %9720 = bitcast i8* %scevgep28.30.14 to [61 x [61 x i8]]*
  %scevgep41.30.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9714, i64 0, i64 1, i64 0
  %9721 = bitcast i8* %scevgep41.30.14 to [61 x [61 x i8]]*
  %call16.30.15 = call zeroext i8 (...) @rand()
  store i8 %call16.30.15, i8* %scevgep28.30.14, align 1
  %9722 = load i8, i8* %scevgep28.30.14, align 1
  %conv23.30.15 = zext i8 %9722 to i32
  %9723 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.15 = getelementptr i8, i8* %b, i64 46
  %9724 = load i8, i8* %scevgep34.30.15, align 1
  %call28.30.15 = call zeroext i8 @mult(i8 zeroext %9723, i8 zeroext %9724)
  %conv29.30.15 = zext i8 %call28.30.15 to i32
  %xor.30.15 = xor i32 %conv23.30.15, %conv29.30.15
  %scevgep35.30.15 = getelementptr i8, i8* %a, i64 46
  %9725 = load i8, i8* %scevgep35.30.15, align 1
  %9726 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.15 = call zeroext i8 @mult(i8 zeroext %9725, i8 zeroext %9726)
  %conv35.30.15 = zext i8 %call34.30.15 to i32
  %xor36.30.15 = xor i32 %xor.30.15, %conv35.30.15
  %conv37.30.15 = trunc i32 %xor36.30.15 to i8
  store i8 %conv37.30.15, i8* %scevgep41.30.14, align 1
  %scevgep28.30.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9720, i64 0, i64 0, i64 1
  %9727 = bitcast i8* %scevgep28.30.15 to [61 x [61 x i8]]*
  %scevgep41.30.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9721, i64 0, i64 1, i64 0
  %9728 = bitcast i8* %scevgep41.30.15 to [61 x [61 x i8]]*
  %call16.30.16 = call zeroext i8 (...) @rand()
  store i8 %call16.30.16, i8* %scevgep28.30.15, align 1
  %9729 = load i8, i8* %scevgep28.30.15, align 1
  %conv23.30.16 = zext i8 %9729 to i32
  %9730 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.16 = getelementptr i8, i8* %b, i64 47
  %9731 = load i8, i8* %scevgep34.30.16, align 1
  %call28.30.16 = call zeroext i8 @mult(i8 zeroext %9730, i8 zeroext %9731)
  %conv29.30.16 = zext i8 %call28.30.16 to i32
  %xor.30.16 = xor i32 %conv23.30.16, %conv29.30.16
  %scevgep35.30.16 = getelementptr i8, i8* %a, i64 47
  %9732 = load i8, i8* %scevgep35.30.16, align 1
  %9733 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.16 = call zeroext i8 @mult(i8 zeroext %9732, i8 zeroext %9733)
  %conv35.30.16 = zext i8 %call34.30.16 to i32
  %xor36.30.16 = xor i32 %xor.30.16, %conv35.30.16
  %conv37.30.16 = trunc i32 %xor36.30.16 to i8
  store i8 %conv37.30.16, i8* %scevgep41.30.15, align 1
  %scevgep28.30.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9727, i64 0, i64 0, i64 1
  %9734 = bitcast i8* %scevgep28.30.16 to [61 x [61 x i8]]*
  %scevgep41.30.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9728, i64 0, i64 1, i64 0
  %9735 = bitcast i8* %scevgep41.30.16 to [61 x [61 x i8]]*
  %call16.30.17 = call zeroext i8 (...) @rand()
  store i8 %call16.30.17, i8* %scevgep28.30.16, align 1
  %9736 = load i8, i8* %scevgep28.30.16, align 1
  %conv23.30.17 = zext i8 %9736 to i32
  %9737 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.17 = getelementptr i8, i8* %b, i64 48
  %9738 = load i8, i8* %scevgep34.30.17, align 1
  %call28.30.17 = call zeroext i8 @mult(i8 zeroext %9737, i8 zeroext %9738)
  %conv29.30.17 = zext i8 %call28.30.17 to i32
  %xor.30.17 = xor i32 %conv23.30.17, %conv29.30.17
  %scevgep35.30.17 = getelementptr i8, i8* %a, i64 48
  %9739 = load i8, i8* %scevgep35.30.17, align 1
  %9740 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.17 = call zeroext i8 @mult(i8 zeroext %9739, i8 zeroext %9740)
  %conv35.30.17 = zext i8 %call34.30.17 to i32
  %xor36.30.17 = xor i32 %xor.30.17, %conv35.30.17
  %conv37.30.17 = trunc i32 %xor36.30.17 to i8
  store i8 %conv37.30.17, i8* %scevgep41.30.16, align 1
  %scevgep28.30.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9734, i64 0, i64 0, i64 1
  %9741 = bitcast i8* %scevgep28.30.17 to [61 x [61 x i8]]*
  %scevgep41.30.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9735, i64 0, i64 1, i64 0
  %9742 = bitcast i8* %scevgep41.30.17 to [61 x [61 x i8]]*
  %call16.30.18 = call zeroext i8 (...) @rand()
  store i8 %call16.30.18, i8* %scevgep28.30.17, align 1
  %9743 = load i8, i8* %scevgep28.30.17, align 1
  %conv23.30.18 = zext i8 %9743 to i32
  %9744 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.18 = getelementptr i8, i8* %b, i64 49
  %9745 = load i8, i8* %scevgep34.30.18, align 1
  %call28.30.18 = call zeroext i8 @mult(i8 zeroext %9744, i8 zeroext %9745)
  %conv29.30.18 = zext i8 %call28.30.18 to i32
  %xor.30.18 = xor i32 %conv23.30.18, %conv29.30.18
  %scevgep35.30.18 = getelementptr i8, i8* %a, i64 49
  %9746 = load i8, i8* %scevgep35.30.18, align 1
  %9747 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.18 = call zeroext i8 @mult(i8 zeroext %9746, i8 zeroext %9747)
  %conv35.30.18 = zext i8 %call34.30.18 to i32
  %xor36.30.18 = xor i32 %xor.30.18, %conv35.30.18
  %conv37.30.18 = trunc i32 %xor36.30.18 to i8
  store i8 %conv37.30.18, i8* %scevgep41.30.17, align 1
  %scevgep28.30.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9741, i64 0, i64 0, i64 1
  %9748 = bitcast i8* %scevgep28.30.18 to [61 x [61 x i8]]*
  %scevgep41.30.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9742, i64 0, i64 1, i64 0
  %9749 = bitcast i8* %scevgep41.30.18 to [61 x [61 x i8]]*
  %call16.30.19 = call zeroext i8 (...) @rand()
  store i8 %call16.30.19, i8* %scevgep28.30.18, align 1
  %9750 = load i8, i8* %scevgep28.30.18, align 1
  %conv23.30.19 = zext i8 %9750 to i32
  %9751 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.19 = getelementptr i8, i8* %b, i64 50
  %9752 = load i8, i8* %scevgep34.30.19, align 1
  %call28.30.19 = call zeroext i8 @mult(i8 zeroext %9751, i8 zeroext %9752)
  %conv29.30.19 = zext i8 %call28.30.19 to i32
  %xor.30.19 = xor i32 %conv23.30.19, %conv29.30.19
  %scevgep35.30.19 = getelementptr i8, i8* %a, i64 50
  %9753 = load i8, i8* %scevgep35.30.19, align 1
  %9754 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.19 = call zeroext i8 @mult(i8 zeroext %9753, i8 zeroext %9754)
  %conv35.30.19 = zext i8 %call34.30.19 to i32
  %xor36.30.19 = xor i32 %xor.30.19, %conv35.30.19
  %conv37.30.19 = trunc i32 %xor36.30.19 to i8
  store i8 %conv37.30.19, i8* %scevgep41.30.18, align 1
  %scevgep28.30.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9748, i64 0, i64 0, i64 1
  %9755 = bitcast i8* %scevgep28.30.19 to [61 x [61 x i8]]*
  %scevgep41.30.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9749, i64 0, i64 1, i64 0
  %9756 = bitcast i8* %scevgep41.30.19 to [61 x [61 x i8]]*
  %call16.30.20 = call zeroext i8 (...) @rand()
  store i8 %call16.30.20, i8* %scevgep28.30.19, align 1
  %9757 = load i8, i8* %scevgep28.30.19, align 1
  %conv23.30.20 = zext i8 %9757 to i32
  %9758 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.20 = getelementptr i8, i8* %b, i64 51
  %9759 = load i8, i8* %scevgep34.30.20, align 1
  %call28.30.20 = call zeroext i8 @mult(i8 zeroext %9758, i8 zeroext %9759)
  %conv29.30.20 = zext i8 %call28.30.20 to i32
  %xor.30.20 = xor i32 %conv23.30.20, %conv29.30.20
  %scevgep35.30.20 = getelementptr i8, i8* %a, i64 51
  %9760 = load i8, i8* %scevgep35.30.20, align 1
  %9761 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.20 = call zeroext i8 @mult(i8 zeroext %9760, i8 zeroext %9761)
  %conv35.30.20 = zext i8 %call34.30.20 to i32
  %xor36.30.20 = xor i32 %xor.30.20, %conv35.30.20
  %conv37.30.20 = trunc i32 %xor36.30.20 to i8
  store i8 %conv37.30.20, i8* %scevgep41.30.19, align 1
  %scevgep28.30.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9755, i64 0, i64 0, i64 1
  %9762 = bitcast i8* %scevgep28.30.20 to [61 x [61 x i8]]*
  %scevgep41.30.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9756, i64 0, i64 1, i64 0
  %9763 = bitcast i8* %scevgep41.30.20 to [61 x [61 x i8]]*
  %call16.30.21 = call zeroext i8 (...) @rand()
  store i8 %call16.30.21, i8* %scevgep28.30.20, align 1
  %9764 = load i8, i8* %scevgep28.30.20, align 1
  %conv23.30.21 = zext i8 %9764 to i32
  %9765 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.21 = getelementptr i8, i8* %b, i64 52
  %9766 = load i8, i8* %scevgep34.30.21, align 1
  %call28.30.21 = call zeroext i8 @mult(i8 zeroext %9765, i8 zeroext %9766)
  %conv29.30.21 = zext i8 %call28.30.21 to i32
  %xor.30.21 = xor i32 %conv23.30.21, %conv29.30.21
  %scevgep35.30.21 = getelementptr i8, i8* %a, i64 52
  %9767 = load i8, i8* %scevgep35.30.21, align 1
  %9768 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.21 = call zeroext i8 @mult(i8 zeroext %9767, i8 zeroext %9768)
  %conv35.30.21 = zext i8 %call34.30.21 to i32
  %xor36.30.21 = xor i32 %xor.30.21, %conv35.30.21
  %conv37.30.21 = trunc i32 %xor36.30.21 to i8
  store i8 %conv37.30.21, i8* %scevgep41.30.20, align 1
  %scevgep28.30.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9762, i64 0, i64 0, i64 1
  %9769 = bitcast i8* %scevgep28.30.21 to [61 x [61 x i8]]*
  %scevgep41.30.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9763, i64 0, i64 1, i64 0
  %9770 = bitcast i8* %scevgep41.30.21 to [61 x [61 x i8]]*
  %call16.30.22 = call zeroext i8 (...) @rand()
  store i8 %call16.30.22, i8* %scevgep28.30.21, align 1
  %9771 = load i8, i8* %scevgep28.30.21, align 1
  %conv23.30.22 = zext i8 %9771 to i32
  %9772 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.22 = getelementptr i8, i8* %b, i64 53
  %9773 = load i8, i8* %scevgep34.30.22, align 1
  %call28.30.22 = call zeroext i8 @mult(i8 zeroext %9772, i8 zeroext %9773)
  %conv29.30.22 = zext i8 %call28.30.22 to i32
  %xor.30.22 = xor i32 %conv23.30.22, %conv29.30.22
  %scevgep35.30.22 = getelementptr i8, i8* %a, i64 53
  %9774 = load i8, i8* %scevgep35.30.22, align 1
  %9775 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.22 = call zeroext i8 @mult(i8 zeroext %9774, i8 zeroext %9775)
  %conv35.30.22 = zext i8 %call34.30.22 to i32
  %xor36.30.22 = xor i32 %xor.30.22, %conv35.30.22
  %conv37.30.22 = trunc i32 %xor36.30.22 to i8
  store i8 %conv37.30.22, i8* %scevgep41.30.21, align 1
  %scevgep28.30.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9769, i64 0, i64 0, i64 1
  %9776 = bitcast i8* %scevgep28.30.22 to [61 x [61 x i8]]*
  %scevgep41.30.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9770, i64 0, i64 1, i64 0
  %9777 = bitcast i8* %scevgep41.30.22 to [61 x [61 x i8]]*
  %call16.30.23 = call zeroext i8 (...) @rand()
  store i8 %call16.30.23, i8* %scevgep28.30.22, align 1
  %9778 = load i8, i8* %scevgep28.30.22, align 1
  %conv23.30.23 = zext i8 %9778 to i32
  %9779 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.23 = getelementptr i8, i8* %b, i64 54
  %9780 = load i8, i8* %scevgep34.30.23, align 1
  %call28.30.23 = call zeroext i8 @mult(i8 zeroext %9779, i8 zeroext %9780)
  %conv29.30.23 = zext i8 %call28.30.23 to i32
  %xor.30.23 = xor i32 %conv23.30.23, %conv29.30.23
  %scevgep35.30.23 = getelementptr i8, i8* %a, i64 54
  %9781 = load i8, i8* %scevgep35.30.23, align 1
  %9782 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.23 = call zeroext i8 @mult(i8 zeroext %9781, i8 zeroext %9782)
  %conv35.30.23 = zext i8 %call34.30.23 to i32
  %xor36.30.23 = xor i32 %xor.30.23, %conv35.30.23
  %conv37.30.23 = trunc i32 %xor36.30.23 to i8
  store i8 %conv37.30.23, i8* %scevgep41.30.22, align 1
  %scevgep28.30.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9776, i64 0, i64 0, i64 1
  %9783 = bitcast i8* %scevgep28.30.23 to [61 x [61 x i8]]*
  %scevgep41.30.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9777, i64 0, i64 1, i64 0
  %9784 = bitcast i8* %scevgep41.30.23 to [61 x [61 x i8]]*
  %call16.30.24 = call zeroext i8 (...) @rand()
  store i8 %call16.30.24, i8* %scevgep28.30.23, align 1
  %9785 = load i8, i8* %scevgep28.30.23, align 1
  %conv23.30.24 = zext i8 %9785 to i32
  %9786 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.24 = getelementptr i8, i8* %b, i64 55
  %9787 = load i8, i8* %scevgep34.30.24, align 1
  %call28.30.24 = call zeroext i8 @mult(i8 zeroext %9786, i8 zeroext %9787)
  %conv29.30.24 = zext i8 %call28.30.24 to i32
  %xor.30.24 = xor i32 %conv23.30.24, %conv29.30.24
  %scevgep35.30.24 = getelementptr i8, i8* %a, i64 55
  %9788 = load i8, i8* %scevgep35.30.24, align 1
  %9789 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.24 = call zeroext i8 @mult(i8 zeroext %9788, i8 zeroext %9789)
  %conv35.30.24 = zext i8 %call34.30.24 to i32
  %xor36.30.24 = xor i32 %xor.30.24, %conv35.30.24
  %conv37.30.24 = trunc i32 %xor36.30.24 to i8
  store i8 %conv37.30.24, i8* %scevgep41.30.23, align 1
  %scevgep28.30.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9783, i64 0, i64 0, i64 1
  %9790 = bitcast i8* %scevgep28.30.24 to [61 x [61 x i8]]*
  %scevgep41.30.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9784, i64 0, i64 1, i64 0
  %9791 = bitcast i8* %scevgep41.30.24 to [61 x [61 x i8]]*
  %call16.30.25 = call zeroext i8 (...) @rand()
  store i8 %call16.30.25, i8* %scevgep28.30.24, align 1
  %9792 = load i8, i8* %scevgep28.30.24, align 1
  %conv23.30.25 = zext i8 %9792 to i32
  %9793 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.25 = getelementptr i8, i8* %b, i64 56
  %9794 = load i8, i8* %scevgep34.30.25, align 1
  %call28.30.25 = call zeroext i8 @mult(i8 zeroext %9793, i8 zeroext %9794)
  %conv29.30.25 = zext i8 %call28.30.25 to i32
  %xor.30.25 = xor i32 %conv23.30.25, %conv29.30.25
  %scevgep35.30.25 = getelementptr i8, i8* %a, i64 56
  %9795 = load i8, i8* %scevgep35.30.25, align 1
  %9796 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.25 = call zeroext i8 @mult(i8 zeroext %9795, i8 zeroext %9796)
  %conv35.30.25 = zext i8 %call34.30.25 to i32
  %xor36.30.25 = xor i32 %xor.30.25, %conv35.30.25
  %conv37.30.25 = trunc i32 %xor36.30.25 to i8
  store i8 %conv37.30.25, i8* %scevgep41.30.24, align 1
  %scevgep28.30.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9790, i64 0, i64 0, i64 1
  %9797 = bitcast i8* %scevgep28.30.25 to [61 x [61 x i8]]*
  %scevgep41.30.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9791, i64 0, i64 1, i64 0
  %9798 = bitcast i8* %scevgep41.30.25 to [61 x [61 x i8]]*
  %call16.30.26 = call zeroext i8 (...) @rand()
  store i8 %call16.30.26, i8* %scevgep28.30.25, align 1
  %9799 = load i8, i8* %scevgep28.30.25, align 1
  %conv23.30.26 = zext i8 %9799 to i32
  %9800 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.26 = getelementptr i8, i8* %b, i64 57
  %9801 = load i8, i8* %scevgep34.30.26, align 1
  %call28.30.26 = call zeroext i8 @mult(i8 zeroext %9800, i8 zeroext %9801)
  %conv29.30.26 = zext i8 %call28.30.26 to i32
  %xor.30.26 = xor i32 %conv23.30.26, %conv29.30.26
  %scevgep35.30.26 = getelementptr i8, i8* %a, i64 57
  %9802 = load i8, i8* %scevgep35.30.26, align 1
  %9803 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.26 = call zeroext i8 @mult(i8 zeroext %9802, i8 zeroext %9803)
  %conv35.30.26 = zext i8 %call34.30.26 to i32
  %xor36.30.26 = xor i32 %xor.30.26, %conv35.30.26
  %conv37.30.26 = trunc i32 %xor36.30.26 to i8
  store i8 %conv37.30.26, i8* %scevgep41.30.25, align 1
  %scevgep28.30.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9797, i64 0, i64 0, i64 1
  %9804 = bitcast i8* %scevgep28.30.26 to [61 x [61 x i8]]*
  %scevgep41.30.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9798, i64 0, i64 1, i64 0
  %9805 = bitcast i8* %scevgep41.30.26 to [61 x [61 x i8]]*
  %call16.30.27 = call zeroext i8 (...) @rand()
  store i8 %call16.30.27, i8* %scevgep28.30.26, align 1
  %9806 = load i8, i8* %scevgep28.30.26, align 1
  %conv23.30.27 = zext i8 %9806 to i32
  %9807 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.27 = getelementptr i8, i8* %b, i64 58
  %9808 = load i8, i8* %scevgep34.30.27, align 1
  %call28.30.27 = call zeroext i8 @mult(i8 zeroext %9807, i8 zeroext %9808)
  %conv29.30.27 = zext i8 %call28.30.27 to i32
  %xor.30.27 = xor i32 %conv23.30.27, %conv29.30.27
  %scevgep35.30.27 = getelementptr i8, i8* %a, i64 58
  %9809 = load i8, i8* %scevgep35.30.27, align 1
  %9810 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.27 = call zeroext i8 @mult(i8 zeroext %9809, i8 zeroext %9810)
  %conv35.30.27 = zext i8 %call34.30.27 to i32
  %xor36.30.27 = xor i32 %xor.30.27, %conv35.30.27
  %conv37.30.27 = trunc i32 %xor36.30.27 to i8
  store i8 %conv37.30.27, i8* %scevgep41.30.26, align 1
  %scevgep28.30.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9804, i64 0, i64 0, i64 1
  %9811 = bitcast i8* %scevgep28.30.27 to [61 x [61 x i8]]*
  %scevgep41.30.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9805, i64 0, i64 1, i64 0
  %9812 = bitcast i8* %scevgep41.30.27 to [61 x [61 x i8]]*
  %call16.30.28 = call zeroext i8 (...) @rand()
  store i8 %call16.30.28, i8* %scevgep28.30.27, align 1
  %9813 = load i8, i8* %scevgep28.30.27, align 1
  %conv23.30.28 = zext i8 %9813 to i32
  %9814 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.28 = getelementptr i8, i8* %b, i64 59
  %9815 = load i8, i8* %scevgep34.30.28, align 1
  %call28.30.28 = call zeroext i8 @mult(i8 zeroext %9814, i8 zeroext %9815)
  %conv29.30.28 = zext i8 %call28.30.28 to i32
  %xor.30.28 = xor i32 %conv23.30.28, %conv29.30.28
  %scevgep35.30.28 = getelementptr i8, i8* %a, i64 59
  %9816 = load i8, i8* %scevgep35.30.28, align 1
  %9817 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.28 = call zeroext i8 @mult(i8 zeroext %9816, i8 zeroext %9817)
  %conv35.30.28 = zext i8 %call34.30.28 to i32
  %xor36.30.28 = xor i32 %xor.30.28, %conv35.30.28
  %conv37.30.28 = trunc i32 %xor36.30.28 to i8
  store i8 %conv37.30.28, i8* %scevgep41.30.27, align 1
  %scevgep28.30.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9811, i64 0, i64 0, i64 1
  %scevgep41.30.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9812, i64 0, i64 1, i64 0
  %call16.30.29 = call zeroext i8 (...) @rand()
  store i8 %call16.30.29, i8* %scevgep28.30.28, align 1
  %9818 = load i8, i8* %scevgep28.30.28, align 1
  %conv23.30.29 = zext i8 %9818 to i32
  %9819 = load i8, i8* %arrayidx25.30, align 1
  %scevgep34.30.29 = getelementptr i8, i8* %b, i64 60
  %9820 = load i8, i8* %scevgep34.30.29, align 1
  %call28.30.29 = call zeroext i8 @mult(i8 zeroext %9819, i8 zeroext %9820)
  %conv29.30.29 = zext i8 %call28.30.29 to i32
  %xor.30.29 = xor i32 %conv23.30.29, %conv29.30.29
  %scevgep35.30.29 = getelementptr i8, i8* %a, i64 60
  %9821 = load i8, i8* %scevgep35.30.29, align 1
  %9822 = load i8, i8* %arrayidx33.30, align 1
  %call34.30.29 = call zeroext i8 @mult(i8 zeroext %9821, i8 zeroext %9822)
  %conv35.30.29 = zext i8 %call34.30.29 to i32
  %xor36.30.29 = xor i32 %xor.30.29, %conv35.30.29
  %conv37.30.29 = trunc i32 %xor36.30.29 to i8
  store i8 %conv37.30.29, i8* %scevgep41.30.28, align 1
  %scevgep26.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9615, i64 0, i64 1, i64 1
  %9823 = bitcast i8* %scevgep26.30 to [61 x [61 x i8]]*
  %scevgep39.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9616, i64 0, i64 1, i64 1
  %9824 = bitcast i8* %scevgep39.30 to [61 x [61 x i8]]*
  %arrayidx25.31 = getelementptr inbounds i8, i8* %a, i64 31
  %arrayidx33.31 = getelementptr inbounds i8, i8* %b, i64 31
  %call16.31 = call zeroext i8 (...) @rand()
  store i8 %call16.31, i8* %scevgep26.30, align 1
  %9825 = load i8, i8* %scevgep26.30, align 1
  %conv23.31 = zext i8 %9825 to i32
  %9826 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31 = getelementptr i8, i8* %b, i64 32
  %9827 = load i8, i8* %scevgep34.31, align 1
  %call28.31 = call zeroext i8 @mult(i8 zeroext %9826, i8 zeroext %9827)
  %conv29.31 = zext i8 %call28.31 to i32
  %xor.31 = xor i32 %conv23.31, %conv29.31
  %scevgep35.31 = getelementptr i8, i8* %a, i64 32
  %9828 = load i8, i8* %scevgep35.31, align 1
  %9829 = load i8, i8* %arrayidx33.31, align 1
  %call34.31 = call zeroext i8 @mult(i8 zeroext %9828, i8 zeroext %9829)
  %conv35.31 = zext i8 %call34.31 to i32
  %xor36.31 = xor i32 %xor.31, %conv35.31
  %conv37.31 = trunc i32 %xor36.31 to i8
  store i8 %conv37.31, i8* %scevgep39.30, align 1
  %scevgep28.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9823, i64 0, i64 0, i64 1
  %9830 = bitcast i8* %scevgep28.31 to [61 x [61 x i8]]*
  %scevgep41.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9824, i64 0, i64 1, i64 0
  %9831 = bitcast i8* %scevgep41.31 to [61 x [61 x i8]]*
  %call16.31.1 = call zeroext i8 (...) @rand()
  store i8 %call16.31.1, i8* %scevgep28.31, align 1
  %9832 = load i8, i8* %scevgep28.31, align 1
  %conv23.31.1 = zext i8 %9832 to i32
  %9833 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.1 = getelementptr i8, i8* %b, i64 33
  %9834 = load i8, i8* %scevgep34.31.1, align 1
  %call28.31.1 = call zeroext i8 @mult(i8 zeroext %9833, i8 zeroext %9834)
  %conv29.31.1 = zext i8 %call28.31.1 to i32
  %xor.31.1 = xor i32 %conv23.31.1, %conv29.31.1
  %scevgep35.31.1 = getelementptr i8, i8* %a, i64 33
  %9835 = load i8, i8* %scevgep35.31.1, align 1
  %9836 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.1 = call zeroext i8 @mult(i8 zeroext %9835, i8 zeroext %9836)
  %conv35.31.1 = zext i8 %call34.31.1 to i32
  %xor36.31.1 = xor i32 %xor.31.1, %conv35.31.1
  %conv37.31.1 = trunc i32 %xor36.31.1 to i8
  store i8 %conv37.31.1, i8* %scevgep41.31, align 1
  %scevgep28.31.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9830, i64 0, i64 0, i64 1
  %9837 = bitcast i8* %scevgep28.31.1 to [61 x [61 x i8]]*
  %scevgep41.31.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9831, i64 0, i64 1, i64 0
  %9838 = bitcast i8* %scevgep41.31.1 to [61 x [61 x i8]]*
  %call16.31.2 = call zeroext i8 (...) @rand()
  store i8 %call16.31.2, i8* %scevgep28.31.1, align 1
  %9839 = load i8, i8* %scevgep28.31.1, align 1
  %conv23.31.2 = zext i8 %9839 to i32
  %9840 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.2 = getelementptr i8, i8* %b, i64 34
  %9841 = load i8, i8* %scevgep34.31.2, align 1
  %call28.31.2 = call zeroext i8 @mult(i8 zeroext %9840, i8 zeroext %9841)
  %conv29.31.2 = zext i8 %call28.31.2 to i32
  %xor.31.2 = xor i32 %conv23.31.2, %conv29.31.2
  %scevgep35.31.2 = getelementptr i8, i8* %a, i64 34
  %9842 = load i8, i8* %scevgep35.31.2, align 1
  %9843 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.2 = call zeroext i8 @mult(i8 zeroext %9842, i8 zeroext %9843)
  %conv35.31.2 = zext i8 %call34.31.2 to i32
  %xor36.31.2 = xor i32 %xor.31.2, %conv35.31.2
  %conv37.31.2 = trunc i32 %xor36.31.2 to i8
  store i8 %conv37.31.2, i8* %scevgep41.31.1, align 1
  %scevgep28.31.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9837, i64 0, i64 0, i64 1
  %9844 = bitcast i8* %scevgep28.31.2 to [61 x [61 x i8]]*
  %scevgep41.31.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9838, i64 0, i64 1, i64 0
  %9845 = bitcast i8* %scevgep41.31.2 to [61 x [61 x i8]]*
  %call16.31.3 = call zeroext i8 (...) @rand()
  store i8 %call16.31.3, i8* %scevgep28.31.2, align 1
  %9846 = load i8, i8* %scevgep28.31.2, align 1
  %conv23.31.3 = zext i8 %9846 to i32
  %9847 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.3 = getelementptr i8, i8* %b, i64 35
  %9848 = load i8, i8* %scevgep34.31.3, align 1
  %call28.31.3 = call zeroext i8 @mult(i8 zeroext %9847, i8 zeroext %9848)
  %conv29.31.3 = zext i8 %call28.31.3 to i32
  %xor.31.3 = xor i32 %conv23.31.3, %conv29.31.3
  %scevgep35.31.3 = getelementptr i8, i8* %a, i64 35
  %9849 = load i8, i8* %scevgep35.31.3, align 1
  %9850 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.3 = call zeroext i8 @mult(i8 zeroext %9849, i8 zeroext %9850)
  %conv35.31.3 = zext i8 %call34.31.3 to i32
  %xor36.31.3 = xor i32 %xor.31.3, %conv35.31.3
  %conv37.31.3 = trunc i32 %xor36.31.3 to i8
  store i8 %conv37.31.3, i8* %scevgep41.31.2, align 1
  %scevgep28.31.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9844, i64 0, i64 0, i64 1
  %9851 = bitcast i8* %scevgep28.31.3 to [61 x [61 x i8]]*
  %scevgep41.31.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9845, i64 0, i64 1, i64 0
  %9852 = bitcast i8* %scevgep41.31.3 to [61 x [61 x i8]]*
  %call16.31.4 = call zeroext i8 (...) @rand()
  store i8 %call16.31.4, i8* %scevgep28.31.3, align 1
  %9853 = load i8, i8* %scevgep28.31.3, align 1
  %conv23.31.4 = zext i8 %9853 to i32
  %9854 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.4 = getelementptr i8, i8* %b, i64 36
  %9855 = load i8, i8* %scevgep34.31.4, align 1
  %call28.31.4 = call zeroext i8 @mult(i8 zeroext %9854, i8 zeroext %9855)
  %conv29.31.4 = zext i8 %call28.31.4 to i32
  %xor.31.4 = xor i32 %conv23.31.4, %conv29.31.4
  %scevgep35.31.4 = getelementptr i8, i8* %a, i64 36
  %9856 = load i8, i8* %scevgep35.31.4, align 1
  %9857 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.4 = call zeroext i8 @mult(i8 zeroext %9856, i8 zeroext %9857)
  %conv35.31.4 = zext i8 %call34.31.4 to i32
  %xor36.31.4 = xor i32 %xor.31.4, %conv35.31.4
  %conv37.31.4 = trunc i32 %xor36.31.4 to i8
  store i8 %conv37.31.4, i8* %scevgep41.31.3, align 1
  %scevgep28.31.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9851, i64 0, i64 0, i64 1
  %9858 = bitcast i8* %scevgep28.31.4 to [61 x [61 x i8]]*
  %scevgep41.31.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9852, i64 0, i64 1, i64 0
  %9859 = bitcast i8* %scevgep41.31.4 to [61 x [61 x i8]]*
  %call16.31.5 = call zeroext i8 (...) @rand()
  store i8 %call16.31.5, i8* %scevgep28.31.4, align 1
  %9860 = load i8, i8* %scevgep28.31.4, align 1
  %conv23.31.5 = zext i8 %9860 to i32
  %9861 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.5 = getelementptr i8, i8* %b, i64 37
  %9862 = load i8, i8* %scevgep34.31.5, align 1
  %call28.31.5 = call zeroext i8 @mult(i8 zeroext %9861, i8 zeroext %9862)
  %conv29.31.5 = zext i8 %call28.31.5 to i32
  %xor.31.5 = xor i32 %conv23.31.5, %conv29.31.5
  %scevgep35.31.5 = getelementptr i8, i8* %a, i64 37
  %9863 = load i8, i8* %scevgep35.31.5, align 1
  %9864 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.5 = call zeroext i8 @mult(i8 zeroext %9863, i8 zeroext %9864)
  %conv35.31.5 = zext i8 %call34.31.5 to i32
  %xor36.31.5 = xor i32 %xor.31.5, %conv35.31.5
  %conv37.31.5 = trunc i32 %xor36.31.5 to i8
  store i8 %conv37.31.5, i8* %scevgep41.31.4, align 1
  %scevgep28.31.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9858, i64 0, i64 0, i64 1
  %9865 = bitcast i8* %scevgep28.31.5 to [61 x [61 x i8]]*
  %scevgep41.31.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9859, i64 0, i64 1, i64 0
  %9866 = bitcast i8* %scevgep41.31.5 to [61 x [61 x i8]]*
  %call16.31.6 = call zeroext i8 (...) @rand()
  store i8 %call16.31.6, i8* %scevgep28.31.5, align 1
  %9867 = load i8, i8* %scevgep28.31.5, align 1
  %conv23.31.6 = zext i8 %9867 to i32
  %9868 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.6 = getelementptr i8, i8* %b, i64 38
  %9869 = load i8, i8* %scevgep34.31.6, align 1
  %call28.31.6 = call zeroext i8 @mult(i8 zeroext %9868, i8 zeroext %9869)
  %conv29.31.6 = zext i8 %call28.31.6 to i32
  %xor.31.6 = xor i32 %conv23.31.6, %conv29.31.6
  %scevgep35.31.6 = getelementptr i8, i8* %a, i64 38
  %9870 = load i8, i8* %scevgep35.31.6, align 1
  %9871 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.6 = call zeroext i8 @mult(i8 zeroext %9870, i8 zeroext %9871)
  %conv35.31.6 = zext i8 %call34.31.6 to i32
  %xor36.31.6 = xor i32 %xor.31.6, %conv35.31.6
  %conv37.31.6 = trunc i32 %xor36.31.6 to i8
  store i8 %conv37.31.6, i8* %scevgep41.31.5, align 1
  %scevgep28.31.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9865, i64 0, i64 0, i64 1
  %9872 = bitcast i8* %scevgep28.31.6 to [61 x [61 x i8]]*
  %scevgep41.31.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9866, i64 0, i64 1, i64 0
  %9873 = bitcast i8* %scevgep41.31.6 to [61 x [61 x i8]]*
  %call16.31.7 = call zeroext i8 (...) @rand()
  store i8 %call16.31.7, i8* %scevgep28.31.6, align 1
  %9874 = load i8, i8* %scevgep28.31.6, align 1
  %conv23.31.7 = zext i8 %9874 to i32
  %9875 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.7 = getelementptr i8, i8* %b, i64 39
  %9876 = load i8, i8* %scevgep34.31.7, align 1
  %call28.31.7 = call zeroext i8 @mult(i8 zeroext %9875, i8 zeroext %9876)
  %conv29.31.7 = zext i8 %call28.31.7 to i32
  %xor.31.7 = xor i32 %conv23.31.7, %conv29.31.7
  %scevgep35.31.7 = getelementptr i8, i8* %a, i64 39
  %9877 = load i8, i8* %scevgep35.31.7, align 1
  %9878 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.7 = call zeroext i8 @mult(i8 zeroext %9877, i8 zeroext %9878)
  %conv35.31.7 = zext i8 %call34.31.7 to i32
  %xor36.31.7 = xor i32 %xor.31.7, %conv35.31.7
  %conv37.31.7 = trunc i32 %xor36.31.7 to i8
  store i8 %conv37.31.7, i8* %scevgep41.31.6, align 1
  %scevgep28.31.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9872, i64 0, i64 0, i64 1
  %9879 = bitcast i8* %scevgep28.31.7 to [61 x [61 x i8]]*
  %scevgep41.31.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9873, i64 0, i64 1, i64 0
  %9880 = bitcast i8* %scevgep41.31.7 to [61 x [61 x i8]]*
  %call16.31.8 = call zeroext i8 (...) @rand()
  store i8 %call16.31.8, i8* %scevgep28.31.7, align 1
  %9881 = load i8, i8* %scevgep28.31.7, align 1
  %conv23.31.8 = zext i8 %9881 to i32
  %9882 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.8 = getelementptr i8, i8* %b, i64 40
  %9883 = load i8, i8* %scevgep34.31.8, align 1
  %call28.31.8 = call zeroext i8 @mult(i8 zeroext %9882, i8 zeroext %9883)
  %conv29.31.8 = zext i8 %call28.31.8 to i32
  %xor.31.8 = xor i32 %conv23.31.8, %conv29.31.8
  %scevgep35.31.8 = getelementptr i8, i8* %a, i64 40
  %9884 = load i8, i8* %scevgep35.31.8, align 1
  %9885 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.8 = call zeroext i8 @mult(i8 zeroext %9884, i8 zeroext %9885)
  %conv35.31.8 = zext i8 %call34.31.8 to i32
  %xor36.31.8 = xor i32 %xor.31.8, %conv35.31.8
  %conv37.31.8 = trunc i32 %xor36.31.8 to i8
  store i8 %conv37.31.8, i8* %scevgep41.31.7, align 1
  %scevgep28.31.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9879, i64 0, i64 0, i64 1
  %9886 = bitcast i8* %scevgep28.31.8 to [61 x [61 x i8]]*
  %scevgep41.31.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9880, i64 0, i64 1, i64 0
  %9887 = bitcast i8* %scevgep41.31.8 to [61 x [61 x i8]]*
  %call16.31.9 = call zeroext i8 (...) @rand()
  store i8 %call16.31.9, i8* %scevgep28.31.8, align 1
  %9888 = load i8, i8* %scevgep28.31.8, align 1
  %conv23.31.9 = zext i8 %9888 to i32
  %9889 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.9 = getelementptr i8, i8* %b, i64 41
  %9890 = load i8, i8* %scevgep34.31.9, align 1
  %call28.31.9 = call zeroext i8 @mult(i8 zeroext %9889, i8 zeroext %9890)
  %conv29.31.9 = zext i8 %call28.31.9 to i32
  %xor.31.9 = xor i32 %conv23.31.9, %conv29.31.9
  %scevgep35.31.9 = getelementptr i8, i8* %a, i64 41
  %9891 = load i8, i8* %scevgep35.31.9, align 1
  %9892 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.9 = call zeroext i8 @mult(i8 zeroext %9891, i8 zeroext %9892)
  %conv35.31.9 = zext i8 %call34.31.9 to i32
  %xor36.31.9 = xor i32 %xor.31.9, %conv35.31.9
  %conv37.31.9 = trunc i32 %xor36.31.9 to i8
  store i8 %conv37.31.9, i8* %scevgep41.31.8, align 1
  %scevgep28.31.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9886, i64 0, i64 0, i64 1
  %9893 = bitcast i8* %scevgep28.31.9 to [61 x [61 x i8]]*
  %scevgep41.31.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9887, i64 0, i64 1, i64 0
  %9894 = bitcast i8* %scevgep41.31.9 to [61 x [61 x i8]]*
  %call16.31.10 = call zeroext i8 (...) @rand()
  store i8 %call16.31.10, i8* %scevgep28.31.9, align 1
  %9895 = load i8, i8* %scevgep28.31.9, align 1
  %conv23.31.10 = zext i8 %9895 to i32
  %9896 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.10 = getelementptr i8, i8* %b, i64 42
  %9897 = load i8, i8* %scevgep34.31.10, align 1
  %call28.31.10 = call zeroext i8 @mult(i8 zeroext %9896, i8 zeroext %9897)
  %conv29.31.10 = zext i8 %call28.31.10 to i32
  %xor.31.10 = xor i32 %conv23.31.10, %conv29.31.10
  %scevgep35.31.10 = getelementptr i8, i8* %a, i64 42
  %9898 = load i8, i8* %scevgep35.31.10, align 1
  %9899 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.10 = call zeroext i8 @mult(i8 zeroext %9898, i8 zeroext %9899)
  %conv35.31.10 = zext i8 %call34.31.10 to i32
  %xor36.31.10 = xor i32 %xor.31.10, %conv35.31.10
  %conv37.31.10 = trunc i32 %xor36.31.10 to i8
  store i8 %conv37.31.10, i8* %scevgep41.31.9, align 1
  %scevgep28.31.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9893, i64 0, i64 0, i64 1
  %9900 = bitcast i8* %scevgep28.31.10 to [61 x [61 x i8]]*
  %scevgep41.31.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9894, i64 0, i64 1, i64 0
  %9901 = bitcast i8* %scevgep41.31.10 to [61 x [61 x i8]]*
  %call16.31.11 = call zeroext i8 (...) @rand()
  store i8 %call16.31.11, i8* %scevgep28.31.10, align 1
  %9902 = load i8, i8* %scevgep28.31.10, align 1
  %conv23.31.11 = zext i8 %9902 to i32
  %9903 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.11 = getelementptr i8, i8* %b, i64 43
  %9904 = load i8, i8* %scevgep34.31.11, align 1
  %call28.31.11 = call zeroext i8 @mult(i8 zeroext %9903, i8 zeroext %9904)
  %conv29.31.11 = zext i8 %call28.31.11 to i32
  %xor.31.11 = xor i32 %conv23.31.11, %conv29.31.11
  %scevgep35.31.11 = getelementptr i8, i8* %a, i64 43
  %9905 = load i8, i8* %scevgep35.31.11, align 1
  %9906 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.11 = call zeroext i8 @mult(i8 zeroext %9905, i8 zeroext %9906)
  %conv35.31.11 = zext i8 %call34.31.11 to i32
  %xor36.31.11 = xor i32 %xor.31.11, %conv35.31.11
  %conv37.31.11 = trunc i32 %xor36.31.11 to i8
  store i8 %conv37.31.11, i8* %scevgep41.31.10, align 1
  %scevgep28.31.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9900, i64 0, i64 0, i64 1
  %9907 = bitcast i8* %scevgep28.31.11 to [61 x [61 x i8]]*
  %scevgep41.31.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9901, i64 0, i64 1, i64 0
  %9908 = bitcast i8* %scevgep41.31.11 to [61 x [61 x i8]]*
  %call16.31.12 = call zeroext i8 (...) @rand()
  store i8 %call16.31.12, i8* %scevgep28.31.11, align 1
  %9909 = load i8, i8* %scevgep28.31.11, align 1
  %conv23.31.12 = zext i8 %9909 to i32
  %9910 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.12 = getelementptr i8, i8* %b, i64 44
  %9911 = load i8, i8* %scevgep34.31.12, align 1
  %call28.31.12 = call zeroext i8 @mult(i8 zeroext %9910, i8 zeroext %9911)
  %conv29.31.12 = zext i8 %call28.31.12 to i32
  %xor.31.12 = xor i32 %conv23.31.12, %conv29.31.12
  %scevgep35.31.12 = getelementptr i8, i8* %a, i64 44
  %9912 = load i8, i8* %scevgep35.31.12, align 1
  %9913 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.12 = call zeroext i8 @mult(i8 zeroext %9912, i8 zeroext %9913)
  %conv35.31.12 = zext i8 %call34.31.12 to i32
  %xor36.31.12 = xor i32 %xor.31.12, %conv35.31.12
  %conv37.31.12 = trunc i32 %xor36.31.12 to i8
  store i8 %conv37.31.12, i8* %scevgep41.31.11, align 1
  %scevgep28.31.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9907, i64 0, i64 0, i64 1
  %9914 = bitcast i8* %scevgep28.31.12 to [61 x [61 x i8]]*
  %scevgep41.31.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9908, i64 0, i64 1, i64 0
  %9915 = bitcast i8* %scevgep41.31.12 to [61 x [61 x i8]]*
  %call16.31.13 = call zeroext i8 (...) @rand()
  store i8 %call16.31.13, i8* %scevgep28.31.12, align 1
  %9916 = load i8, i8* %scevgep28.31.12, align 1
  %conv23.31.13 = zext i8 %9916 to i32
  %9917 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.13 = getelementptr i8, i8* %b, i64 45
  %9918 = load i8, i8* %scevgep34.31.13, align 1
  %call28.31.13 = call zeroext i8 @mult(i8 zeroext %9917, i8 zeroext %9918)
  %conv29.31.13 = zext i8 %call28.31.13 to i32
  %xor.31.13 = xor i32 %conv23.31.13, %conv29.31.13
  %scevgep35.31.13 = getelementptr i8, i8* %a, i64 45
  %9919 = load i8, i8* %scevgep35.31.13, align 1
  %9920 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.13 = call zeroext i8 @mult(i8 zeroext %9919, i8 zeroext %9920)
  %conv35.31.13 = zext i8 %call34.31.13 to i32
  %xor36.31.13 = xor i32 %xor.31.13, %conv35.31.13
  %conv37.31.13 = trunc i32 %xor36.31.13 to i8
  store i8 %conv37.31.13, i8* %scevgep41.31.12, align 1
  %scevgep28.31.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9914, i64 0, i64 0, i64 1
  %9921 = bitcast i8* %scevgep28.31.13 to [61 x [61 x i8]]*
  %scevgep41.31.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9915, i64 0, i64 1, i64 0
  %9922 = bitcast i8* %scevgep41.31.13 to [61 x [61 x i8]]*
  %call16.31.14 = call zeroext i8 (...) @rand()
  store i8 %call16.31.14, i8* %scevgep28.31.13, align 1
  %9923 = load i8, i8* %scevgep28.31.13, align 1
  %conv23.31.14 = zext i8 %9923 to i32
  %9924 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.14 = getelementptr i8, i8* %b, i64 46
  %9925 = load i8, i8* %scevgep34.31.14, align 1
  %call28.31.14 = call zeroext i8 @mult(i8 zeroext %9924, i8 zeroext %9925)
  %conv29.31.14 = zext i8 %call28.31.14 to i32
  %xor.31.14 = xor i32 %conv23.31.14, %conv29.31.14
  %scevgep35.31.14 = getelementptr i8, i8* %a, i64 46
  %9926 = load i8, i8* %scevgep35.31.14, align 1
  %9927 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.14 = call zeroext i8 @mult(i8 zeroext %9926, i8 zeroext %9927)
  %conv35.31.14 = zext i8 %call34.31.14 to i32
  %xor36.31.14 = xor i32 %xor.31.14, %conv35.31.14
  %conv37.31.14 = trunc i32 %xor36.31.14 to i8
  store i8 %conv37.31.14, i8* %scevgep41.31.13, align 1
  %scevgep28.31.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9921, i64 0, i64 0, i64 1
  %9928 = bitcast i8* %scevgep28.31.14 to [61 x [61 x i8]]*
  %scevgep41.31.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9922, i64 0, i64 1, i64 0
  %9929 = bitcast i8* %scevgep41.31.14 to [61 x [61 x i8]]*
  %call16.31.15 = call zeroext i8 (...) @rand()
  store i8 %call16.31.15, i8* %scevgep28.31.14, align 1
  %9930 = load i8, i8* %scevgep28.31.14, align 1
  %conv23.31.15 = zext i8 %9930 to i32
  %9931 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.15 = getelementptr i8, i8* %b, i64 47
  %9932 = load i8, i8* %scevgep34.31.15, align 1
  %call28.31.15 = call zeroext i8 @mult(i8 zeroext %9931, i8 zeroext %9932)
  %conv29.31.15 = zext i8 %call28.31.15 to i32
  %xor.31.15 = xor i32 %conv23.31.15, %conv29.31.15
  %scevgep35.31.15 = getelementptr i8, i8* %a, i64 47
  %9933 = load i8, i8* %scevgep35.31.15, align 1
  %9934 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.15 = call zeroext i8 @mult(i8 zeroext %9933, i8 zeroext %9934)
  %conv35.31.15 = zext i8 %call34.31.15 to i32
  %xor36.31.15 = xor i32 %xor.31.15, %conv35.31.15
  %conv37.31.15 = trunc i32 %xor36.31.15 to i8
  store i8 %conv37.31.15, i8* %scevgep41.31.14, align 1
  %scevgep28.31.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9928, i64 0, i64 0, i64 1
  %9935 = bitcast i8* %scevgep28.31.15 to [61 x [61 x i8]]*
  %scevgep41.31.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9929, i64 0, i64 1, i64 0
  %9936 = bitcast i8* %scevgep41.31.15 to [61 x [61 x i8]]*
  %call16.31.16 = call zeroext i8 (...) @rand()
  store i8 %call16.31.16, i8* %scevgep28.31.15, align 1
  %9937 = load i8, i8* %scevgep28.31.15, align 1
  %conv23.31.16 = zext i8 %9937 to i32
  %9938 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.16 = getelementptr i8, i8* %b, i64 48
  %9939 = load i8, i8* %scevgep34.31.16, align 1
  %call28.31.16 = call zeroext i8 @mult(i8 zeroext %9938, i8 zeroext %9939)
  %conv29.31.16 = zext i8 %call28.31.16 to i32
  %xor.31.16 = xor i32 %conv23.31.16, %conv29.31.16
  %scevgep35.31.16 = getelementptr i8, i8* %a, i64 48
  %9940 = load i8, i8* %scevgep35.31.16, align 1
  %9941 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.16 = call zeroext i8 @mult(i8 zeroext %9940, i8 zeroext %9941)
  %conv35.31.16 = zext i8 %call34.31.16 to i32
  %xor36.31.16 = xor i32 %xor.31.16, %conv35.31.16
  %conv37.31.16 = trunc i32 %xor36.31.16 to i8
  store i8 %conv37.31.16, i8* %scevgep41.31.15, align 1
  %scevgep28.31.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9935, i64 0, i64 0, i64 1
  %9942 = bitcast i8* %scevgep28.31.16 to [61 x [61 x i8]]*
  %scevgep41.31.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9936, i64 0, i64 1, i64 0
  %9943 = bitcast i8* %scevgep41.31.16 to [61 x [61 x i8]]*
  %call16.31.17 = call zeroext i8 (...) @rand()
  store i8 %call16.31.17, i8* %scevgep28.31.16, align 1
  %9944 = load i8, i8* %scevgep28.31.16, align 1
  %conv23.31.17 = zext i8 %9944 to i32
  %9945 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.17 = getelementptr i8, i8* %b, i64 49
  %9946 = load i8, i8* %scevgep34.31.17, align 1
  %call28.31.17 = call zeroext i8 @mult(i8 zeroext %9945, i8 zeroext %9946)
  %conv29.31.17 = zext i8 %call28.31.17 to i32
  %xor.31.17 = xor i32 %conv23.31.17, %conv29.31.17
  %scevgep35.31.17 = getelementptr i8, i8* %a, i64 49
  %9947 = load i8, i8* %scevgep35.31.17, align 1
  %9948 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.17 = call zeroext i8 @mult(i8 zeroext %9947, i8 zeroext %9948)
  %conv35.31.17 = zext i8 %call34.31.17 to i32
  %xor36.31.17 = xor i32 %xor.31.17, %conv35.31.17
  %conv37.31.17 = trunc i32 %xor36.31.17 to i8
  store i8 %conv37.31.17, i8* %scevgep41.31.16, align 1
  %scevgep28.31.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9942, i64 0, i64 0, i64 1
  %9949 = bitcast i8* %scevgep28.31.17 to [61 x [61 x i8]]*
  %scevgep41.31.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9943, i64 0, i64 1, i64 0
  %9950 = bitcast i8* %scevgep41.31.17 to [61 x [61 x i8]]*
  %call16.31.18 = call zeroext i8 (...) @rand()
  store i8 %call16.31.18, i8* %scevgep28.31.17, align 1
  %9951 = load i8, i8* %scevgep28.31.17, align 1
  %conv23.31.18 = zext i8 %9951 to i32
  %9952 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.18 = getelementptr i8, i8* %b, i64 50
  %9953 = load i8, i8* %scevgep34.31.18, align 1
  %call28.31.18 = call zeroext i8 @mult(i8 zeroext %9952, i8 zeroext %9953)
  %conv29.31.18 = zext i8 %call28.31.18 to i32
  %xor.31.18 = xor i32 %conv23.31.18, %conv29.31.18
  %scevgep35.31.18 = getelementptr i8, i8* %a, i64 50
  %9954 = load i8, i8* %scevgep35.31.18, align 1
  %9955 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.18 = call zeroext i8 @mult(i8 zeroext %9954, i8 zeroext %9955)
  %conv35.31.18 = zext i8 %call34.31.18 to i32
  %xor36.31.18 = xor i32 %xor.31.18, %conv35.31.18
  %conv37.31.18 = trunc i32 %xor36.31.18 to i8
  store i8 %conv37.31.18, i8* %scevgep41.31.17, align 1
  %scevgep28.31.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9949, i64 0, i64 0, i64 1
  %9956 = bitcast i8* %scevgep28.31.18 to [61 x [61 x i8]]*
  %scevgep41.31.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9950, i64 0, i64 1, i64 0
  %9957 = bitcast i8* %scevgep41.31.18 to [61 x [61 x i8]]*
  %call16.31.19 = call zeroext i8 (...) @rand()
  store i8 %call16.31.19, i8* %scevgep28.31.18, align 1
  %9958 = load i8, i8* %scevgep28.31.18, align 1
  %conv23.31.19 = zext i8 %9958 to i32
  %9959 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.19 = getelementptr i8, i8* %b, i64 51
  %9960 = load i8, i8* %scevgep34.31.19, align 1
  %call28.31.19 = call zeroext i8 @mult(i8 zeroext %9959, i8 zeroext %9960)
  %conv29.31.19 = zext i8 %call28.31.19 to i32
  %xor.31.19 = xor i32 %conv23.31.19, %conv29.31.19
  %scevgep35.31.19 = getelementptr i8, i8* %a, i64 51
  %9961 = load i8, i8* %scevgep35.31.19, align 1
  %9962 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.19 = call zeroext i8 @mult(i8 zeroext %9961, i8 zeroext %9962)
  %conv35.31.19 = zext i8 %call34.31.19 to i32
  %xor36.31.19 = xor i32 %xor.31.19, %conv35.31.19
  %conv37.31.19 = trunc i32 %xor36.31.19 to i8
  store i8 %conv37.31.19, i8* %scevgep41.31.18, align 1
  %scevgep28.31.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9956, i64 0, i64 0, i64 1
  %9963 = bitcast i8* %scevgep28.31.19 to [61 x [61 x i8]]*
  %scevgep41.31.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9957, i64 0, i64 1, i64 0
  %9964 = bitcast i8* %scevgep41.31.19 to [61 x [61 x i8]]*
  %call16.31.20 = call zeroext i8 (...) @rand()
  store i8 %call16.31.20, i8* %scevgep28.31.19, align 1
  %9965 = load i8, i8* %scevgep28.31.19, align 1
  %conv23.31.20 = zext i8 %9965 to i32
  %9966 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.20 = getelementptr i8, i8* %b, i64 52
  %9967 = load i8, i8* %scevgep34.31.20, align 1
  %call28.31.20 = call zeroext i8 @mult(i8 zeroext %9966, i8 zeroext %9967)
  %conv29.31.20 = zext i8 %call28.31.20 to i32
  %xor.31.20 = xor i32 %conv23.31.20, %conv29.31.20
  %scevgep35.31.20 = getelementptr i8, i8* %a, i64 52
  %9968 = load i8, i8* %scevgep35.31.20, align 1
  %9969 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.20 = call zeroext i8 @mult(i8 zeroext %9968, i8 zeroext %9969)
  %conv35.31.20 = zext i8 %call34.31.20 to i32
  %xor36.31.20 = xor i32 %xor.31.20, %conv35.31.20
  %conv37.31.20 = trunc i32 %xor36.31.20 to i8
  store i8 %conv37.31.20, i8* %scevgep41.31.19, align 1
  %scevgep28.31.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9963, i64 0, i64 0, i64 1
  %9970 = bitcast i8* %scevgep28.31.20 to [61 x [61 x i8]]*
  %scevgep41.31.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9964, i64 0, i64 1, i64 0
  %9971 = bitcast i8* %scevgep41.31.20 to [61 x [61 x i8]]*
  %call16.31.21 = call zeroext i8 (...) @rand()
  store i8 %call16.31.21, i8* %scevgep28.31.20, align 1
  %9972 = load i8, i8* %scevgep28.31.20, align 1
  %conv23.31.21 = zext i8 %9972 to i32
  %9973 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.21 = getelementptr i8, i8* %b, i64 53
  %9974 = load i8, i8* %scevgep34.31.21, align 1
  %call28.31.21 = call zeroext i8 @mult(i8 zeroext %9973, i8 zeroext %9974)
  %conv29.31.21 = zext i8 %call28.31.21 to i32
  %xor.31.21 = xor i32 %conv23.31.21, %conv29.31.21
  %scevgep35.31.21 = getelementptr i8, i8* %a, i64 53
  %9975 = load i8, i8* %scevgep35.31.21, align 1
  %9976 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.21 = call zeroext i8 @mult(i8 zeroext %9975, i8 zeroext %9976)
  %conv35.31.21 = zext i8 %call34.31.21 to i32
  %xor36.31.21 = xor i32 %xor.31.21, %conv35.31.21
  %conv37.31.21 = trunc i32 %xor36.31.21 to i8
  store i8 %conv37.31.21, i8* %scevgep41.31.20, align 1
  %scevgep28.31.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9970, i64 0, i64 0, i64 1
  %9977 = bitcast i8* %scevgep28.31.21 to [61 x [61 x i8]]*
  %scevgep41.31.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9971, i64 0, i64 1, i64 0
  %9978 = bitcast i8* %scevgep41.31.21 to [61 x [61 x i8]]*
  %call16.31.22 = call zeroext i8 (...) @rand()
  store i8 %call16.31.22, i8* %scevgep28.31.21, align 1
  %9979 = load i8, i8* %scevgep28.31.21, align 1
  %conv23.31.22 = zext i8 %9979 to i32
  %9980 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.22 = getelementptr i8, i8* %b, i64 54
  %9981 = load i8, i8* %scevgep34.31.22, align 1
  %call28.31.22 = call zeroext i8 @mult(i8 zeroext %9980, i8 zeroext %9981)
  %conv29.31.22 = zext i8 %call28.31.22 to i32
  %xor.31.22 = xor i32 %conv23.31.22, %conv29.31.22
  %scevgep35.31.22 = getelementptr i8, i8* %a, i64 54
  %9982 = load i8, i8* %scevgep35.31.22, align 1
  %9983 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.22 = call zeroext i8 @mult(i8 zeroext %9982, i8 zeroext %9983)
  %conv35.31.22 = zext i8 %call34.31.22 to i32
  %xor36.31.22 = xor i32 %xor.31.22, %conv35.31.22
  %conv37.31.22 = trunc i32 %xor36.31.22 to i8
  store i8 %conv37.31.22, i8* %scevgep41.31.21, align 1
  %scevgep28.31.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9977, i64 0, i64 0, i64 1
  %9984 = bitcast i8* %scevgep28.31.22 to [61 x [61 x i8]]*
  %scevgep41.31.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9978, i64 0, i64 1, i64 0
  %9985 = bitcast i8* %scevgep41.31.22 to [61 x [61 x i8]]*
  %call16.31.23 = call zeroext i8 (...) @rand()
  store i8 %call16.31.23, i8* %scevgep28.31.22, align 1
  %9986 = load i8, i8* %scevgep28.31.22, align 1
  %conv23.31.23 = zext i8 %9986 to i32
  %9987 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.23 = getelementptr i8, i8* %b, i64 55
  %9988 = load i8, i8* %scevgep34.31.23, align 1
  %call28.31.23 = call zeroext i8 @mult(i8 zeroext %9987, i8 zeroext %9988)
  %conv29.31.23 = zext i8 %call28.31.23 to i32
  %xor.31.23 = xor i32 %conv23.31.23, %conv29.31.23
  %scevgep35.31.23 = getelementptr i8, i8* %a, i64 55
  %9989 = load i8, i8* %scevgep35.31.23, align 1
  %9990 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.23 = call zeroext i8 @mult(i8 zeroext %9989, i8 zeroext %9990)
  %conv35.31.23 = zext i8 %call34.31.23 to i32
  %xor36.31.23 = xor i32 %xor.31.23, %conv35.31.23
  %conv37.31.23 = trunc i32 %xor36.31.23 to i8
  store i8 %conv37.31.23, i8* %scevgep41.31.22, align 1
  %scevgep28.31.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9984, i64 0, i64 0, i64 1
  %9991 = bitcast i8* %scevgep28.31.23 to [61 x [61 x i8]]*
  %scevgep41.31.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9985, i64 0, i64 1, i64 0
  %9992 = bitcast i8* %scevgep41.31.23 to [61 x [61 x i8]]*
  %call16.31.24 = call zeroext i8 (...) @rand()
  store i8 %call16.31.24, i8* %scevgep28.31.23, align 1
  %9993 = load i8, i8* %scevgep28.31.23, align 1
  %conv23.31.24 = zext i8 %9993 to i32
  %9994 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.24 = getelementptr i8, i8* %b, i64 56
  %9995 = load i8, i8* %scevgep34.31.24, align 1
  %call28.31.24 = call zeroext i8 @mult(i8 zeroext %9994, i8 zeroext %9995)
  %conv29.31.24 = zext i8 %call28.31.24 to i32
  %xor.31.24 = xor i32 %conv23.31.24, %conv29.31.24
  %scevgep35.31.24 = getelementptr i8, i8* %a, i64 56
  %9996 = load i8, i8* %scevgep35.31.24, align 1
  %9997 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.24 = call zeroext i8 @mult(i8 zeroext %9996, i8 zeroext %9997)
  %conv35.31.24 = zext i8 %call34.31.24 to i32
  %xor36.31.24 = xor i32 %xor.31.24, %conv35.31.24
  %conv37.31.24 = trunc i32 %xor36.31.24 to i8
  store i8 %conv37.31.24, i8* %scevgep41.31.23, align 1
  %scevgep28.31.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9991, i64 0, i64 0, i64 1
  %9998 = bitcast i8* %scevgep28.31.24 to [61 x [61 x i8]]*
  %scevgep41.31.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9992, i64 0, i64 1, i64 0
  %9999 = bitcast i8* %scevgep41.31.24 to [61 x [61 x i8]]*
  %call16.31.25 = call zeroext i8 (...) @rand()
  store i8 %call16.31.25, i8* %scevgep28.31.24, align 1
  %10000 = load i8, i8* %scevgep28.31.24, align 1
  %conv23.31.25 = zext i8 %10000 to i32
  %10001 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.25 = getelementptr i8, i8* %b, i64 57
  %10002 = load i8, i8* %scevgep34.31.25, align 1
  %call28.31.25 = call zeroext i8 @mult(i8 zeroext %10001, i8 zeroext %10002)
  %conv29.31.25 = zext i8 %call28.31.25 to i32
  %xor.31.25 = xor i32 %conv23.31.25, %conv29.31.25
  %scevgep35.31.25 = getelementptr i8, i8* %a, i64 57
  %10003 = load i8, i8* %scevgep35.31.25, align 1
  %10004 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.25 = call zeroext i8 @mult(i8 zeroext %10003, i8 zeroext %10004)
  %conv35.31.25 = zext i8 %call34.31.25 to i32
  %xor36.31.25 = xor i32 %xor.31.25, %conv35.31.25
  %conv37.31.25 = trunc i32 %xor36.31.25 to i8
  store i8 %conv37.31.25, i8* %scevgep41.31.24, align 1
  %scevgep28.31.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9998, i64 0, i64 0, i64 1
  %10005 = bitcast i8* %scevgep28.31.25 to [61 x [61 x i8]]*
  %scevgep41.31.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9999, i64 0, i64 1, i64 0
  %10006 = bitcast i8* %scevgep41.31.25 to [61 x [61 x i8]]*
  %call16.31.26 = call zeroext i8 (...) @rand()
  store i8 %call16.31.26, i8* %scevgep28.31.25, align 1
  %10007 = load i8, i8* %scevgep28.31.25, align 1
  %conv23.31.26 = zext i8 %10007 to i32
  %10008 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.26 = getelementptr i8, i8* %b, i64 58
  %10009 = load i8, i8* %scevgep34.31.26, align 1
  %call28.31.26 = call zeroext i8 @mult(i8 zeroext %10008, i8 zeroext %10009)
  %conv29.31.26 = zext i8 %call28.31.26 to i32
  %xor.31.26 = xor i32 %conv23.31.26, %conv29.31.26
  %scevgep35.31.26 = getelementptr i8, i8* %a, i64 58
  %10010 = load i8, i8* %scevgep35.31.26, align 1
  %10011 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.26 = call zeroext i8 @mult(i8 zeroext %10010, i8 zeroext %10011)
  %conv35.31.26 = zext i8 %call34.31.26 to i32
  %xor36.31.26 = xor i32 %xor.31.26, %conv35.31.26
  %conv37.31.26 = trunc i32 %xor36.31.26 to i8
  store i8 %conv37.31.26, i8* %scevgep41.31.25, align 1
  %scevgep28.31.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10005, i64 0, i64 0, i64 1
  %10012 = bitcast i8* %scevgep28.31.26 to [61 x [61 x i8]]*
  %scevgep41.31.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10006, i64 0, i64 1, i64 0
  %10013 = bitcast i8* %scevgep41.31.26 to [61 x [61 x i8]]*
  %call16.31.27 = call zeroext i8 (...) @rand()
  store i8 %call16.31.27, i8* %scevgep28.31.26, align 1
  %10014 = load i8, i8* %scevgep28.31.26, align 1
  %conv23.31.27 = zext i8 %10014 to i32
  %10015 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.27 = getelementptr i8, i8* %b, i64 59
  %10016 = load i8, i8* %scevgep34.31.27, align 1
  %call28.31.27 = call zeroext i8 @mult(i8 zeroext %10015, i8 zeroext %10016)
  %conv29.31.27 = zext i8 %call28.31.27 to i32
  %xor.31.27 = xor i32 %conv23.31.27, %conv29.31.27
  %scevgep35.31.27 = getelementptr i8, i8* %a, i64 59
  %10017 = load i8, i8* %scevgep35.31.27, align 1
  %10018 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.27 = call zeroext i8 @mult(i8 zeroext %10017, i8 zeroext %10018)
  %conv35.31.27 = zext i8 %call34.31.27 to i32
  %xor36.31.27 = xor i32 %xor.31.27, %conv35.31.27
  %conv37.31.27 = trunc i32 %xor36.31.27 to i8
  store i8 %conv37.31.27, i8* %scevgep41.31.26, align 1
  %scevgep28.31.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10012, i64 0, i64 0, i64 1
  %scevgep41.31.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10013, i64 0, i64 1, i64 0
  %call16.31.28 = call zeroext i8 (...) @rand()
  store i8 %call16.31.28, i8* %scevgep28.31.27, align 1
  %10019 = load i8, i8* %scevgep28.31.27, align 1
  %conv23.31.28 = zext i8 %10019 to i32
  %10020 = load i8, i8* %arrayidx25.31, align 1
  %scevgep34.31.28 = getelementptr i8, i8* %b, i64 60
  %10021 = load i8, i8* %scevgep34.31.28, align 1
  %call28.31.28 = call zeroext i8 @mult(i8 zeroext %10020, i8 zeroext %10021)
  %conv29.31.28 = zext i8 %call28.31.28 to i32
  %xor.31.28 = xor i32 %conv23.31.28, %conv29.31.28
  %scevgep35.31.28 = getelementptr i8, i8* %a, i64 60
  %10022 = load i8, i8* %scevgep35.31.28, align 1
  %10023 = load i8, i8* %arrayidx33.31, align 1
  %call34.31.28 = call zeroext i8 @mult(i8 zeroext %10022, i8 zeroext %10023)
  %conv35.31.28 = zext i8 %call34.31.28 to i32
  %xor36.31.28 = xor i32 %xor.31.28, %conv35.31.28
  %conv37.31.28 = trunc i32 %xor36.31.28 to i8
  store i8 %conv37.31.28, i8* %scevgep41.31.27, align 1
  %scevgep26.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9823, i64 0, i64 1, i64 1
  %10024 = bitcast i8* %scevgep26.31 to [61 x [61 x i8]]*
  %scevgep39.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %9824, i64 0, i64 1, i64 1
  %10025 = bitcast i8* %scevgep39.31 to [61 x [61 x i8]]*
  %arrayidx25.32 = getelementptr inbounds i8, i8* %a, i64 32
  %arrayidx33.32 = getelementptr inbounds i8, i8* %b, i64 32
  %call16.32 = call zeroext i8 (...) @rand()
  store i8 %call16.32, i8* %scevgep26.31, align 1
  %10026 = load i8, i8* %scevgep26.31, align 1
  %conv23.32 = zext i8 %10026 to i32
  %10027 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32 = getelementptr i8, i8* %b, i64 33
  %10028 = load i8, i8* %scevgep34.32, align 1
  %call28.32 = call zeroext i8 @mult(i8 zeroext %10027, i8 zeroext %10028)
  %conv29.32 = zext i8 %call28.32 to i32
  %xor.32 = xor i32 %conv23.32, %conv29.32
  %scevgep35.32 = getelementptr i8, i8* %a, i64 33
  %10029 = load i8, i8* %scevgep35.32, align 1
  %10030 = load i8, i8* %arrayidx33.32, align 1
  %call34.32 = call zeroext i8 @mult(i8 zeroext %10029, i8 zeroext %10030)
  %conv35.32 = zext i8 %call34.32 to i32
  %xor36.32 = xor i32 %xor.32, %conv35.32
  %conv37.32 = trunc i32 %xor36.32 to i8
  store i8 %conv37.32, i8* %scevgep39.31, align 1
  %scevgep28.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10024, i64 0, i64 0, i64 1
  %10031 = bitcast i8* %scevgep28.32 to [61 x [61 x i8]]*
  %scevgep41.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10025, i64 0, i64 1, i64 0
  %10032 = bitcast i8* %scevgep41.32 to [61 x [61 x i8]]*
  %call16.32.1 = call zeroext i8 (...) @rand()
  store i8 %call16.32.1, i8* %scevgep28.32, align 1
  %10033 = load i8, i8* %scevgep28.32, align 1
  %conv23.32.1 = zext i8 %10033 to i32
  %10034 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.1 = getelementptr i8, i8* %b, i64 34
  %10035 = load i8, i8* %scevgep34.32.1, align 1
  %call28.32.1 = call zeroext i8 @mult(i8 zeroext %10034, i8 zeroext %10035)
  %conv29.32.1 = zext i8 %call28.32.1 to i32
  %xor.32.1 = xor i32 %conv23.32.1, %conv29.32.1
  %scevgep35.32.1 = getelementptr i8, i8* %a, i64 34
  %10036 = load i8, i8* %scevgep35.32.1, align 1
  %10037 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.1 = call zeroext i8 @mult(i8 zeroext %10036, i8 zeroext %10037)
  %conv35.32.1 = zext i8 %call34.32.1 to i32
  %xor36.32.1 = xor i32 %xor.32.1, %conv35.32.1
  %conv37.32.1 = trunc i32 %xor36.32.1 to i8
  store i8 %conv37.32.1, i8* %scevgep41.32, align 1
  %scevgep28.32.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10031, i64 0, i64 0, i64 1
  %10038 = bitcast i8* %scevgep28.32.1 to [61 x [61 x i8]]*
  %scevgep41.32.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10032, i64 0, i64 1, i64 0
  %10039 = bitcast i8* %scevgep41.32.1 to [61 x [61 x i8]]*
  %call16.32.2 = call zeroext i8 (...) @rand()
  store i8 %call16.32.2, i8* %scevgep28.32.1, align 1
  %10040 = load i8, i8* %scevgep28.32.1, align 1
  %conv23.32.2 = zext i8 %10040 to i32
  %10041 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.2 = getelementptr i8, i8* %b, i64 35
  %10042 = load i8, i8* %scevgep34.32.2, align 1
  %call28.32.2 = call zeroext i8 @mult(i8 zeroext %10041, i8 zeroext %10042)
  %conv29.32.2 = zext i8 %call28.32.2 to i32
  %xor.32.2 = xor i32 %conv23.32.2, %conv29.32.2
  %scevgep35.32.2 = getelementptr i8, i8* %a, i64 35
  %10043 = load i8, i8* %scevgep35.32.2, align 1
  %10044 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.2 = call zeroext i8 @mult(i8 zeroext %10043, i8 zeroext %10044)
  %conv35.32.2 = zext i8 %call34.32.2 to i32
  %xor36.32.2 = xor i32 %xor.32.2, %conv35.32.2
  %conv37.32.2 = trunc i32 %xor36.32.2 to i8
  store i8 %conv37.32.2, i8* %scevgep41.32.1, align 1
  %scevgep28.32.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10038, i64 0, i64 0, i64 1
  %10045 = bitcast i8* %scevgep28.32.2 to [61 x [61 x i8]]*
  %scevgep41.32.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10039, i64 0, i64 1, i64 0
  %10046 = bitcast i8* %scevgep41.32.2 to [61 x [61 x i8]]*
  %call16.32.3 = call zeroext i8 (...) @rand()
  store i8 %call16.32.3, i8* %scevgep28.32.2, align 1
  %10047 = load i8, i8* %scevgep28.32.2, align 1
  %conv23.32.3 = zext i8 %10047 to i32
  %10048 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.3 = getelementptr i8, i8* %b, i64 36
  %10049 = load i8, i8* %scevgep34.32.3, align 1
  %call28.32.3 = call zeroext i8 @mult(i8 zeroext %10048, i8 zeroext %10049)
  %conv29.32.3 = zext i8 %call28.32.3 to i32
  %xor.32.3 = xor i32 %conv23.32.3, %conv29.32.3
  %scevgep35.32.3 = getelementptr i8, i8* %a, i64 36
  %10050 = load i8, i8* %scevgep35.32.3, align 1
  %10051 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.3 = call zeroext i8 @mult(i8 zeroext %10050, i8 zeroext %10051)
  %conv35.32.3 = zext i8 %call34.32.3 to i32
  %xor36.32.3 = xor i32 %xor.32.3, %conv35.32.3
  %conv37.32.3 = trunc i32 %xor36.32.3 to i8
  store i8 %conv37.32.3, i8* %scevgep41.32.2, align 1
  %scevgep28.32.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10045, i64 0, i64 0, i64 1
  %10052 = bitcast i8* %scevgep28.32.3 to [61 x [61 x i8]]*
  %scevgep41.32.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10046, i64 0, i64 1, i64 0
  %10053 = bitcast i8* %scevgep41.32.3 to [61 x [61 x i8]]*
  %call16.32.4 = call zeroext i8 (...) @rand()
  store i8 %call16.32.4, i8* %scevgep28.32.3, align 1
  %10054 = load i8, i8* %scevgep28.32.3, align 1
  %conv23.32.4 = zext i8 %10054 to i32
  %10055 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.4 = getelementptr i8, i8* %b, i64 37
  %10056 = load i8, i8* %scevgep34.32.4, align 1
  %call28.32.4 = call zeroext i8 @mult(i8 zeroext %10055, i8 zeroext %10056)
  %conv29.32.4 = zext i8 %call28.32.4 to i32
  %xor.32.4 = xor i32 %conv23.32.4, %conv29.32.4
  %scevgep35.32.4 = getelementptr i8, i8* %a, i64 37
  %10057 = load i8, i8* %scevgep35.32.4, align 1
  %10058 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.4 = call zeroext i8 @mult(i8 zeroext %10057, i8 zeroext %10058)
  %conv35.32.4 = zext i8 %call34.32.4 to i32
  %xor36.32.4 = xor i32 %xor.32.4, %conv35.32.4
  %conv37.32.4 = trunc i32 %xor36.32.4 to i8
  store i8 %conv37.32.4, i8* %scevgep41.32.3, align 1
  %scevgep28.32.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10052, i64 0, i64 0, i64 1
  %10059 = bitcast i8* %scevgep28.32.4 to [61 x [61 x i8]]*
  %scevgep41.32.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10053, i64 0, i64 1, i64 0
  %10060 = bitcast i8* %scevgep41.32.4 to [61 x [61 x i8]]*
  %call16.32.5 = call zeroext i8 (...) @rand()
  store i8 %call16.32.5, i8* %scevgep28.32.4, align 1
  %10061 = load i8, i8* %scevgep28.32.4, align 1
  %conv23.32.5 = zext i8 %10061 to i32
  %10062 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.5 = getelementptr i8, i8* %b, i64 38
  %10063 = load i8, i8* %scevgep34.32.5, align 1
  %call28.32.5 = call zeroext i8 @mult(i8 zeroext %10062, i8 zeroext %10063)
  %conv29.32.5 = zext i8 %call28.32.5 to i32
  %xor.32.5 = xor i32 %conv23.32.5, %conv29.32.5
  %scevgep35.32.5 = getelementptr i8, i8* %a, i64 38
  %10064 = load i8, i8* %scevgep35.32.5, align 1
  %10065 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.5 = call zeroext i8 @mult(i8 zeroext %10064, i8 zeroext %10065)
  %conv35.32.5 = zext i8 %call34.32.5 to i32
  %xor36.32.5 = xor i32 %xor.32.5, %conv35.32.5
  %conv37.32.5 = trunc i32 %xor36.32.5 to i8
  store i8 %conv37.32.5, i8* %scevgep41.32.4, align 1
  %scevgep28.32.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10059, i64 0, i64 0, i64 1
  %10066 = bitcast i8* %scevgep28.32.5 to [61 x [61 x i8]]*
  %scevgep41.32.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10060, i64 0, i64 1, i64 0
  %10067 = bitcast i8* %scevgep41.32.5 to [61 x [61 x i8]]*
  %call16.32.6 = call zeroext i8 (...) @rand()
  store i8 %call16.32.6, i8* %scevgep28.32.5, align 1
  %10068 = load i8, i8* %scevgep28.32.5, align 1
  %conv23.32.6 = zext i8 %10068 to i32
  %10069 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.6 = getelementptr i8, i8* %b, i64 39
  %10070 = load i8, i8* %scevgep34.32.6, align 1
  %call28.32.6 = call zeroext i8 @mult(i8 zeroext %10069, i8 zeroext %10070)
  %conv29.32.6 = zext i8 %call28.32.6 to i32
  %xor.32.6 = xor i32 %conv23.32.6, %conv29.32.6
  %scevgep35.32.6 = getelementptr i8, i8* %a, i64 39
  %10071 = load i8, i8* %scevgep35.32.6, align 1
  %10072 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.6 = call zeroext i8 @mult(i8 zeroext %10071, i8 zeroext %10072)
  %conv35.32.6 = zext i8 %call34.32.6 to i32
  %xor36.32.6 = xor i32 %xor.32.6, %conv35.32.6
  %conv37.32.6 = trunc i32 %xor36.32.6 to i8
  store i8 %conv37.32.6, i8* %scevgep41.32.5, align 1
  %scevgep28.32.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10066, i64 0, i64 0, i64 1
  %10073 = bitcast i8* %scevgep28.32.6 to [61 x [61 x i8]]*
  %scevgep41.32.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10067, i64 0, i64 1, i64 0
  %10074 = bitcast i8* %scevgep41.32.6 to [61 x [61 x i8]]*
  %call16.32.7 = call zeroext i8 (...) @rand()
  store i8 %call16.32.7, i8* %scevgep28.32.6, align 1
  %10075 = load i8, i8* %scevgep28.32.6, align 1
  %conv23.32.7 = zext i8 %10075 to i32
  %10076 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.7 = getelementptr i8, i8* %b, i64 40
  %10077 = load i8, i8* %scevgep34.32.7, align 1
  %call28.32.7 = call zeroext i8 @mult(i8 zeroext %10076, i8 zeroext %10077)
  %conv29.32.7 = zext i8 %call28.32.7 to i32
  %xor.32.7 = xor i32 %conv23.32.7, %conv29.32.7
  %scevgep35.32.7 = getelementptr i8, i8* %a, i64 40
  %10078 = load i8, i8* %scevgep35.32.7, align 1
  %10079 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.7 = call zeroext i8 @mult(i8 zeroext %10078, i8 zeroext %10079)
  %conv35.32.7 = zext i8 %call34.32.7 to i32
  %xor36.32.7 = xor i32 %xor.32.7, %conv35.32.7
  %conv37.32.7 = trunc i32 %xor36.32.7 to i8
  store i8 %conv37.32.7, i8* %scevgep41.32.6, align 1
  %scevgep28.32.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10073, i64 0, i64 0, i64 1
  %10080 = bitcast i8* %scevgep28.32.7 to [61 x [61 x i8]]*
  %scevgep41.32.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10074, i64 0, i64 1, i64 0
  %10081 = bitcast i8* %scevgep41.32.7 to [61 x [61 x i8]]*
  %call16.32.8 = call zeroext i8 (...) @rand()
  store i8 %call16.32.8, i8* %scevgep28.32.7, align 1
  %10082 = load i8, i8* %scevgep28.32.7, align 1
  %conv23.32.8 = zext i8 %10082 to i32
  %10083 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.8 = getelementptr i8, i8* %b, i64 41
  %10084 = load i8, i8* %scevgep34.32.8, align 1
  %call28.32.8 = call zeroext i8 @mult(i8 zeroext %10083, i8 zeroext %10084)
  %conv29.32.8 = zext i8 %call28.32.8 to i32
  %xor.32.8 = xor i32 %conv23.32.8, %conv29.32.8
  %scevgep35.32.8 = getelementptr i8, i8* %a, i64 41
  %10085 = load i8, i8* %scevgep35.32.8, align 1
  %10086 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.8 = call zeroext i8 @mult(i8 zeroext %10085, i8 zeroext %10086)
  %conv35.32.8 = zext i8 %call34.32.8 to i32
  %xor36.32.8 = xor i32 %xor.32.8, %conv35.32.8
  %conv37.32.8 = trunc i32 %xor36.32.8 to i8
  store i8 %conv37.32.8, i8* %scevgep41.32.7, align 1
  %scevgep28.32.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10080, i64 0, i64 0, i64 1
  %10087 = bitcast i8* %scevgep28.32.8 to [61 x [61 x i8]]*
  %scevgep41.32.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10081, i64 0, i64 1, i64 0
  %10088 = bitcast i8* %scevgep41.32.8 to [61 x [61 x i8]]*
  %call16.32.9 = call zeroext i8 (...) @rand()
  store i8 %call16.32.9, i8* %scevgep28.32.8, align 1
  %10089 = load i8, i8* %scevgep28.32.8, align 1
  %conv23.32.9 = zext i8 %10089 to i32
  %10090 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.9 = getelementptr i8, i8* %b, i64 42
  %10091 = load i8, i8* %scevgep34.32.9, align 1
  %call28.32.9 = call zeroext i8 @mult(i8 zeroext %10090, i8 zeroext %10091)
  %conv29.32.9 = zext i8 %call28.32.9 to i32
  %xor.32.9 = xor i32 %conv23.32.9, %conv29.32.9
  %scevgep35.32.9 = getelementptr i8, i8* %a, i64 42
  %10092 = load i8, i8* %scevgep35.32.9, align 1
  %10093 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.9 = call zeroext i8 @mult(i8 zeroext %10092, i8 zeroext %10093)
  %conv35.32.9 = zext i8 %call34.32.9 to i32
  %xor36.32.9 = xor i32 %xor.32.9, %conv35.32.9
  %conv37.32.9 = trunc i32 %xor36.32.9 to i8
  store i8 %conv37.32.9, i8* %scevgep41.32.8, align 1
  %scevgep28.32.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10087, i64 0, i64 0, i64 1
  %10094 = bitcast i8* %scevgep28.32.9 to [61 x [61 x i8]]*
  %scevgep41.32.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10088, i64 0, i64 1, i64 0
  %10095 = bitcast i8* %scevgep41.32.9 to [61 x [61 x i8]]*
  %call16.32.10 = call zeroext i8 (...) @rand()
  store i8 %call16.32.10, i8* %scevgep28.32.9, align 1
  %10096 = load i8, i8* %scevgep28.32.9, align 1
  %conv23.32.10 = zext i8 %10096 to i32
  %10097 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.10 = getelementptr i8, i8* %b, i64 43
  %10098 = load i8, i8* %scevgep34.32.10, align 1
  %call28.32.10 = call zeroext i8 @mult(i8 zeroext %10097, i8 zeroext %10098)
  %conv29.32.10 = zext i8 %call28.32.10 to i32
  %xor.32.10 = xor i32 %conv23.32.10, %conv29.32.10
  %scevgep35.32.10 = getelementptr i8, i8* %a, i64 43
  %10099 = load i8, i8* %scevgep35.32.10, align 1
  %10100 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.10 = call zeroext i8 @mult(i8 zeroext %10099, i8 zeroext %10100)
  %conv35.32.10 = zext i8 %call34.32.10 to i32
  %xor36.32.10 = xor i32 %xor.32.10, %conv35.32.10
  %conv37.32.10 = trunc i32 %xor36.32.10 to i8
  store i8 %conv37.32.10, i8* %scevgep41.32.9, align 1
  %scevgep28.32.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10094, i64 0, i64 0, i64 1
  %10101 = bitcast i8* %scevgep28.32.10 to [61 x [61 x i8]]*
  %scevgep41.32.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10095, i64 0, i64 1, i64 0
  %10102 = bitcast i8* %scevgep41.32.10 to [61 x [61 x i8]]*
  %call16.32.11 = call zeroext i8 (...) @rand()
  store i8 %call16.32.11, i8* %scevgep28.32.10, align 1
  %10103 = load i8, i8* %scevgep28.32.10, align 1
  %conv23.32.11 = zext i8 %10103 to i32
  %10104 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.11 = getelementptr i8, i8* %b, i64 44
  %10105 = load i8, i8* %scevgep34.32.11, align 1
  %call28.32.11 = call zeroext i8 @mult(i8 zeroext %10104, i8 zeroext %10105)
  %conv29.32.11 = zext i8 %call28.32.11 to i32
  %xor.32.11 = xor i32 %conv23.32.11, %conv29.32.11
  %scevgep35.32.11 = getelementptr i8, i8* %a, i64 44
  %10106 = load i8, i8* %scevgep35.32.11, align 1
  %10107 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.11 = call zeroext i8 @mult(i8 zeroext %10106, i8 zeroext %10107)
  %conv35.32.11 = zext i8 %call34.32.11 to i32
  %xor36.32.11 = xor i32 %xor.32.11, %conv35.32.11
  %conv37.32.11 = trunc i32 %xor36.32.11 to i8
  store i8 %conv37.32.11, i8* %scevgep41.32.10, align 1
  %scevgep28.32.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10101, i64 0, i64 0, i64 1
  %10108 = bitcast i8* %scevgep28.32.11 to [61 x [61 x i8]]*
  %scevgep41.32.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10102, i64 0, i64 1, i64 0
  %10109 = bitcast i8* %scevgep41.32.11 to [61 x [61 x i8]]*
  %call16.32.12 = call zeroext i8 (...) @rand()
  store i8 %call16.32.12, i8* %scevgep28.32.11, align 1
  %10110 = load i8, i8* %scevgep28.32.11, align 1
  %conv23.32.12 = zext i8 %10110 to i32
  %10111 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.12 = getelementptr i8, i8* %b, i64 45
  %10112 = load i8, i8* %scevgep34.32.12, align 1
  %call28.32.12 = call zeroext i8 @mult(i8 zeroext %10111, i8 zeroext %10112)
  %conv29.32.12 = zext i8 %call28.32.12 to i32
  %xor.32.12 = xor i32 %conv23.32.12, %conv29.32.12
  %scevgep35.32.12 = getelementptr i8, i8* %a, i64 45
  %10113 = load i8, i8* %scevgep35.32.12, align 1
  %10114 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.12 = call zeroext i8 @mult(i8 zeroext %10113, i8 zeroext %10114)
  %conv35.32.12 = zext i8 %call34.32.12 to i32
  %xor36.32.12 = xor i32 %xor.32.12, %conv35.32.12
  %conv37.32.12 = trunc i32 %xor36.32.12 to i8
  store i8 %conv37.32.12, i8* %scevgep41.32.11, align 1
  %scevgep28.32.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10108, i64 0, i64 0, i64 1
  %10115 = bitcast i8* %scevgep28.32.12 to [61 x [61 x i8]]*
  %scevgep41.32.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10109, i64 0, i64 1, i64 0
  %10116 = bitcast i8* %scevgep41.32.12 to [61 x [61 x i8]]*
  %call16.32.13 = call zeroext i8 (...) @rand()
  store i8 %call16.32.13, i8* %scevgep28.32.12, align 1
  %10117 = load i8, i8* %scevgep28.32.12, align 1
  %conv23.32.13 = zext i8 %10117 to i32
  %10118 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.13 = getelementptr i8, i8* %b, i64 46
  %10119 = load i8, i8* %scevgep34.32.13, align 1
  %call28.32.13 = call zeroext i8 @mult(i8 zeroext %10118, i8 zeroext %10119)
  %conv29.32.13 = zext i8 %call28.32.13 to i32
  %xor.32.13 = xor i32 %conv23.32.13, %conv29.32.13
  %scevgep35.32.13 = getelementptr i8, i8* %a, i64 46
  %10120 = load i8, i8* %scevgep35.32.13, align 1
  %10121 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.13 = call zeroext i8 @mult(i8 zeroext %10120, i8 zeroext %10121)
  %conv35.32.13 = zext i8 %call34.32.13 to i32
  %xor36.32.13 = xor i32 %xor.32.13, %conv35.32.13
  %conv37.32.13 = trunc i32 %xor36.32.13 to i8
  store i8 %conv37.32.13, i8* %scevgep41.32.12, align 1
  %scevgep28.32.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10115, i64 0, i64 0, i64 1
  %10122 = bitcast i8* %scevgep28.32.13 to [61 x [61 x i8]]*
  %scevgep41.32.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10116, i64 0, i64 1, i64 0
  %10123 = bitcast i8* %scevgep41.32.13 to [61 x [61 x i8]]*
  %call16.32.14 = call zeroext i8 (...) @rand()
  store i8 %call16.32.14, i8* %scevgep28.32.13, align 1
  %10124 = load i8, i8* %scevgep28.32.13, align 1
  %conv23.32.14 = zext i8 %10124 to i32
  %10125 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.14 = getelementptr i8, i8* %b, i64 47
  %10126 = load i8, i8* %scevgep34.32.14, align 1
  %call28.32.14 = call zeroext i8 @mult(i8 zeroext %10125, i8 zeroext %10126)
  %conv29.32.14 = zext i8 %call28.32.14 to i32
  %xor.32.14 = xor i32 %conv23.32.14, %conv29.32.14
  %scevgep35.32.14 = getelementptr i8, i8* %a, i64 47
  %10127 = load i8, i8* %scevgep35.32.14, align 1
  %10128 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.14 = call zeroext i8 @mult(i8 zeroext %10127, i8 zeroext %10128)
  %conv35.32.14 = zext i8 %call34.32.14 to i32
  %xor36.32.14 = xor i32 %xor.32.14, %conv35.32.14
  %conv37.32.14 = trunc i32 %xor36.32.14 to i8
  store i8 %conv37.32.14, i8* %scevgep41.32.13, align 1
  %scevgep28.32.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10122, i64 0, i64 0, i64 1
  %10129 = bitcast i8* %scevgep28.32.14 to [61 x [61 x i8]]*
  %scevgep41.32.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10123, i64 0, i64 1, i64 0
  %10130 = bitcast i8* %scevgep41.32.14 to [61 x [61 x i8]]*
  %call16.32.15 = call zeroext i8 (...) @rand()
  store i8 %call16.32.15, i8* %scevgep28.32.14, align 1
  %10131 = load i8, i8* %scevgep28.32.14, align 1
  %conv23.32.15 = zext i8 %10131 to i32
  %10132 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.15 = getelementptr i8, i8* %b, i64 48
  %10133 = load i8, i8* %scevgep34.32.15, align 1
  %call28.32.15 = call zeroext i8 @mult(i8 zeroext %10132, i8 zeroext %10133)
  %conv29.32.15 = zext i8 %call28.32.15 to i32
  %xor.32.15 = xor i32 %conv23.32.15, %conv29.32.15
  %scevgep35.32.15 = getelementptr i8, i8* %a, i64 48
  %10134 = load i8, i8* %scevgep35.32.15, align 1
  %10135 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.15 = call zeroext i8 @mult(i8 zeroext %10134, i8 zeroext %10135)
  %conv35.32.15 = zext i8 %call34.32.15 to i32
  %xor36.32.15 = xor i32 %xor.32.15, %conv35.32.15
  %conv37.32.15 = trunc i32 %xor36.32.15 to i8
  store i8 %conv37.32.15, i8* %scevgep41.32.14, align 1
  %scevgep28.32.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10129, i64 0, i64 0, i64 1
  %10136 = bitcast i8* %scevgep28.32.15 to [61 x [61 x i8]]*
  %scevgep41.32.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10130, i64 0, i64 1, i64 0
  %10137 = bitcast i8* %scevgep41.32.15 to [61 x [61 x i8]]*
  %call16.32.16 = call zeroext i8 (...) @rand()
  store i8 %call16.32.16, i8* %scevgep28.32.15, align 1
  %10138 = load i8, i8* %scevgep28.32.15, align 1
  %conv23.32.16 = zext i8 %10138 to i32
  %10139 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.16 = getelementptr i8, i8* %b, i64 49
  %10140 = load i8, i8* %scevgep34.32.16, align 1
  %call28.32.16 = call zeroext i8 @mult(i8 zeroext %10139, i8 zeroext %10140)
  %conv29.32.16 = zext i8 %call28.32.16 to i32
  %xor.32.16 = xor i32 %conv23.32.16, %conv29.32.16
  %scevgep35.32.16 = getelementptr i8, i8* %a, i64 49
  %10141 = load i8, i8* %scevgep35.32.16, align 1
  %10142 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.16 = call zeroext i8 @mult(i8 zeroext %10141, i8 zeroext %10142)
  %conv35.32.16 = zext i8 %call34.32.16 to i32
  %xor36.32.16 = xor i32 %xor.32.16, %conv35.32.16
  %conv37.32.16 = trunc i32 %xor36.32.16 to i8
  store i8 %conv37.32.16, i8* %scevgep41.32.15, align 1
  %scevgep28.32.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10136, i64 0, i64 0, i64 1
  %10143 = bitcast i8* %scevgep28.32.16 to [61 x [61 x i8]]*
  %scevgep41.32.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10137, i64 0, i64 1, i64 0
  %10144 = bitcast i8* %scevgep41.32.16 to [61 x [61 x i8]]*
  %call16.32.17 = call zeroext i8 (...) @rand()
  store i8 %call16.32.17, i8* %scevgep28.32.16, align 1
  %10145 = load i8, i8* %scevgep28.32.16, align 1
  %conv23.32.17 = zext i8 %10145 to i32
  %10146 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.17 = getelementptr i8, i8* %b, i64 50
  %10147 = load i8, i8* %scevgep34.32.17, align 1
  %call28.32.17 = call zeroext i8 @mult(i8 zeroext %10146, i8 zeroext %10147)
  %conv29.32.17 = zext i8 %call28.32.17 to i32
  %xor.32.17 = xor i32 %conv23.32.17, %conv29.32.17
  %scevgep35.32.17 = getelementptr i8, i8* %a, i64 50
  %10148 = load i8, i8* %scevgep35.32.17, align 1
  %10149 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.17 = call zeroext i8 @mult(i8 zeroext %10148, i8 zeroext %10149)
  %conv35.32.17 = zext i8 %call34.32.17 to i32
  %xor36.32.17 = xor i32 %xor.32.17, %conv35.32.17
  %conv37.32.17 = trunc i32 %xor36.32.17 to i8
  store i8 %conv37.32.17, i8* %scevgep41.32.16, align 1
  %scevgep28.32.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10143, i64 0, i64 0, i64 1
  %10150 = bitcast i8* %scevgep28.32.17 to [61 x [61 x i8]]*
  %scevgep41.32.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10144, i64 0, i64 1, i64 0
  %10151 = bitcast i8* %scevgep41.32.17 to [61 x [61 x i8]]*
  %call16.32.18 = call zeroext i8 (...) @rand()
  store i8 %call16.32.18, i8* %scevgep28.32.17, align 1
  %10152 = load i8, i8* %scevgep28.32.17, align 1
  %conv23.32.18 = zext i8 %10152 to i32
  %10153 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.18 = getelementptr i8, i8* %b, i64 51
  %10154 = load i8, i8* %scevgep34.32.18, align 1
  %call28.32.18 = call zeroext i8 @mult(i8 zeroext %10153, i8 zeroext %10154)
  %conv29.32.18 = zext i8 %call28.32.18 to i32
  %xor.32.18 = xor i32 %conv23.32.18, %conv29.32.18
  %scevgep35.32.18 = getelementptr i8, i8* %a, i64 51
  %10155 = load i8, i8* %scevgep35.32.18, align 1
  %10156 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.18 = call zeroext i8 @mult(i8 zeroext %10155, i8 zeroext %10156)
  %conv35.32.18 = zext i8 %call34.32.18 to i32
  %xor36.32.18 = xor i32 %xor.32.18, %conv35.32.18
  %conv37.32.18 = trunc i32 %xor36.32.18 to i8
  store i8 %conv37.32.18, i8* %scevgep41.32.17, align 1
  %scevgep28.32.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10150, i64 0, i64 0, i64 1
  %10157 = bitcast i8* %scevgep28.32.18 to [61 x [61 x i8]]*
  %scevgep41.32.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10151, i64 0, i64 1, i64 0
  %10158 = bitcast i8* %scevgep41.32.18 to [61 x [61 x i8]]*
  %call16.32.19 = call zeroext i8 (...) @rand()
  store i8 %call16.32.19, i8* %scevgep28.32.18, align 1
  %10159 = load i8, i8* %scevgep28.32.18, align 1
  %conv23.32.19 = zext i8 %10159 to i32
  %10160 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.19 = getelementptr i8, i8* %b, i64 52
  %10161 = load i8, i8* %scevgep34.32.19, align 1
  %call28.32.19 = call zeroext i8 @mult(i8 zeroext %10160, i8 zeroext %10161)
  %conv29.32.19 = zext i8 %call28.32.19 to i32
  %xor.32.19 = xor i32 %conv23.32.19, %conv29.32.19
  %scevgep35.32.19 = getelementptr i8, i8* %a, i64 52
  %10162 = load i8, i8* %scevgep35.32.19, align 1
  %10163 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.19 = call zeroext i8 @mult(i8 zeroext %10162, i8 zeroext %10163)
  %conv35.32.19 = zext i8 %call34.32.19 to i32
  %xor36.32.19 = xor i32 %xor.32.19, %conv35.32.19
  %conv37.32.19 = trunc i32 %xor36.32.19 to i8
  store i8 %conv37.32.19, i8* %scevgep41.32.18, align 1
  %scevgep28.32.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10157, i64 0, i64 0, i64 1
  %10164 = bitcast i8* %scevgep28.32.19 to [61 x [61 x i8]]*
  %scevgep41.32.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10158, i64 0, i64 1, i64 0
  %10165 = bitcast i8* %scevgep41.32.19 to [61 x [61 x i8]]*
  %call16.32.20 = call zeroext i8 (...) @rand()
  store i8 %call16.32.20, i8* %scevgep28.32.19, align 1
  %10166 = load i8, i8* %scevgep28.32.19, align 1
  %conv23.32.20 = zext i8 %10166 to i32
  %10167 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.20 = getelementptr i8, i8* %b, i64 53
  %10168 = load i8, i8* %scevgep34.32.20, align 1
  %call28.32.20 = call zeroext i8 @mult(i8 zeroext %10167, i8 zeroext %10168)
  %conv29.32.20 = zext i8 %call28.32.20 to i32
  %xor.32.20 = xor i32 %conv23.32.20, %conv29.32.20
  %scevgep35.32.20 = getelementptr i8, i8* %a, i64 53
  %10169 = load i8, i8* %scevgep35.32.20, align 1
  %10170 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.20 = call zeroext i8 @mult(i8 zeroext %10169, i8 zeroext %10170)
  %conv35.32.20 = zext i8 %call34.32.20 to i32
  %xor36.32.20 = xor i32 %xor.32.20, %conv35.32.20
  %conv37.32.20 = trunc i32 %xor36.32.20 to i8
  store i8 %conv37.32.20, i8* %scevgep41.32.19, align 1
  %scevgep28.32.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10164, i64 0, i64 0, i64 1
  %10171 = bitcast i8* %scevgep28.32.20 to [61 x [61 x i8]]*
  %scevgep41.32.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10165, i64 0, i64 1, i64 0
  %10172 = bitcast i8* %scevgep41.32.20 to [61 x [61 x i8]]*
  %call16.32.21 = call zeroext i8 (...) @rand()
  store i8 %call16.32.21, i8* %scevgep28.32.20, align 1
  %10173 = load i8, i8* %scevgep28.32.20, align 1
  %conv23.32.21 = zext i8 %10173 to i32
  %10174 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.21 = getelementptr i8, i8* %b, i64 54
  %10175 = load i8, i8* %scevgep34.32.21, align 1
  %call28.32.21 = call zeroext i8 @mult(i8 zeroext %10174, i8 zeroext %10175)
  %conv29.32.21 = zext i8 %call28.32.21 to i32
  %xor.32.21 = xor i32 %conv23.32.21, %conv29.32.21
  %scevgep35.32.21 = getelementptr i8, i8* %a, i64 54
  %10176 = load i8, i8* %scevgep35.32.21, align 1
  %10177 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.21 = call zeroext i8 @mult(i8 zeroext %10176, i8 zeroext %10177)
  %conv35.32.21 = zext i8 %call34.32.21 to i32
  %xor36.32.21 = xor i32 %xor.32.21, %conv35.32.21
  %conv37.32.21 = trunc i32 %xor36.32.21 to i8
  store i8 %conv37.32.21, i8* %scevgep41.32.20, align 1
  %scevgep28.32.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10171, i64 0, i64 0, i64 1
  %10178 = bitcast i8* %scevgep28.32.21 to [61 x [61 x i8]]*
  %scevgep41.32.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10172, i64 0, i64 1, i64 0
  %10179 = bitcast i8* %scevgep41.32.21 to [61 x [61 x i8]]*
  %call16.32.22 = call zeroext i8 (...) @rand()
  store i8 %call16.32.22, i8* %scevgep28.32.21, align 1
  %10180 = load i8, i8* %scevgep28.32.21, align 1
  %conv23.32.22 = zext i8 %10180 to i32
  %10181 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.22 = getelementptr i8, i8* %b, i64 55
  %10182 = load i8, i8* %scevgep34.32.22, align 1
  %call28.32.22 = call zeroext i8 @mult(i8 zeroext %10181, i8 zeroext %10182)
  %conv29.32.22 = zext i8 %call28.32.22 to i32
  %xor.32.22 = xor i32 %conv23.32.22, %conv29.32.22
  %scevgep35.32.22 = getelementptr i8, i8* %a, i64 55
  %10183 = load i8, i8* %scevgep35.32.22, align 1
  %10184 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.22 = call zeroext i8 @mult(i8 zeroext %10183, i8 zeroext %10184)
  %conv35.32.22 = zext i8 %call34.32.22 to i32
  %xor36.32.22 = xor i32 %xor.32.22, %conv35.32.22
  %conv37.32.22 = trunc i32 %xor36.32.22 to i8
  store i8 %conv37.32.22, i8* %scevgep41.32.21, align 1
  %scevgep28.32.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10178, i64 0, i64 0, i64 1
  %10185 = bitcast i8* %scevgep28.32.22 to [61 x [61 x i8]]*
  %scevgep41.32.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10179, i64 0, i64 1, i64 0
  %10186 = bitcast i8* %scevgep41.32.22 to [61 x [61 x i8]]*
  %call16.32.23 = call zeroext i8 (...) @rand()
  store i8 %call16.32.23, i8* %scevgep28.32.22, align 1
  %10187 = load i8, i8* %scevgep28.32.22, align 1
  %conv23.32.23 = zext i8 %10187 to i32
  %10188 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.23 = getelementptr i8, i8* %b, i64 56
  %10189 = load i8, i8* %scevgep34.32.23, align 1
  %call28.32.23 = call zeroext i8 @mult(i8 zeroext %10188, i8 zeroext %10189)
  %conv29.32.23 = zext i8 %call28.32.23 to i32
  %xor.32.23 = xor i32 %conv23.32.23, %conv29.32.23
  %scevgep35.32.23 = getelementptr i8, i8* %a, i64 56
  %10190 = load i8, i8* %scevgep35.32.23, align 1
  %10191 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.23 = call zeroext i8 @mult(i8 zeroext %10190, i8 zeroext %10191)
  %conv35.32.23 = zext i8 %call34.32.23 to i32
  %xor36.32.23 = xor i32 %xor.32.23, %conv35.32.23
  %conv37.32.23 = trunc i32 %xor36.32.23 to i8
  store i8 %conv37.32.23, i8* %scevgep41.32.22, align 1
  %scevgep28.32.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10185, i64 0, i64 0, i64 1
  %10192 = bitcast i8* %scevgep28.32.23 to [61 x [61 x i8]]*
  %scevgep41.32.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10186, i64 0, i64 1, i64 0
  %10193 = bitcast i8* %scevgep41.32.23 to [61 x [61 x i8]]*
  %call16.32.24 = call zeroext i8 (...) @rand()
  store i8 %call16.32.24, i8* %scevgep28.32.23, align 1
  %10194 = load i8, i8* %scevgep28.32.23, align 1
  %conv23.32.24 = zext i8 %10194 to i32
  %10195 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.24 = getelementptr i8, i8* %b, i64 57
  %10196 = load i8, i8* %scevgep34.32.24, align 1
  %call28.32.24 = call zeroext i8 @mult(i8 zeroext %10195, i8 zeroext %10196)
  %conv29.32.24 = zext i8 %call28.32.24 to i32
  %xor.32.24 = xor i32 %conv23.32.24, %conv29.32.24
  %scevgep35.32.24 = getelementptr i8, i8* %a, i64 57
  %10197 = load i8, i8* %scevgep35.32.24, align 1
  %10198 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.24 = call zeroext i8 @mult(i8 zeroext %10197, i8 zeroext %10198)
  %conv35.32.24 = zext i8 %call34.32.24 to i32
  %xor36.32.24 = xor i32 %xor.32.24, %conv35.32.24
  %conv37.32.24 = trunc i32 %xor36.32.24 to i8
  store i8 %conv37.32.24, i8* %scevgep41.32.23, align 1
  %scevgep28.32.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10192, i64 0, i64 0, i64 1
  %10199 = bitcast i8* %scevgep28.32.24 to [61 x [61 x i8]]*
  %scevgep41.32.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10193, i64 0, i64 1, i64 0
  %10200 = bitcast i8* %scevgep41.32.24 to [61 x [61 x i8]]*
  %call16.32.25 = call zeroext i8 (...) @rand()
  store i8 %call16.32.25, i8* %scevgep28.32.24, align 1
  %10201 = load i8, i8* %scevgep28.32.24, align 1
  %conv23.32.25 = zext i8 %10201 to i32
  %10202 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.25 = getelementptr i8, i8* %b, i64 58
  %10203 = load i8, i8* %scevgep34.32.25, align 1
  %call28.32.25 = call zeroext i8 @mult(i8 zeroext %10202, i8 zeroext %10203)
  %conv29.32.25 = zext i8 %call28.32.25 to i32
  %xor.32.25 = xor i32 %conv23.32.25, %conv29.32.25
  %scevgep35.32.25 = getelementptr i8, i8* %a, i64 58
  %10204 = load i8, i8* %scevgep35.32.25, align 1
  %10205 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.25 = call zeroext i8 @mult(i8 zeroext %10204, i8 zeroext %10205)
  %conv35.32.25 = zext i8 %call34.32.25 to i32
  %xor36.32.25 = xor i32 %xor.32.25, %conv35.32.25
  %conv37.32.25 = trunc i32 %xor36.32.25 to i8
  store i8 %conv37.32.25, i8* %scevgep41.32.24, align 1
  %scevgep28.32.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10199, i64 0, i64 0, i64 1
  %10206 = bitcast i8* %scevgep28.32.25 to [61 x [61 x i8]]*
  %scevgep41.32.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10200, i64 0, i64 1, i64 0
  %10207 = bitcast i8* %scevgep41.32.25 to [61 x [61 x i8]]*
  %call16.32.26 = call zeroext i8 (...) @rand()
  store i8 %call16.32.26, i8* %scevgep28.32.25, align 1
  %10208 = load i8, i8* %scevgep28.32.25, align 1
  %conv23.32.26 = zext i8 %10208 to i32
  %10209 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.26 = getelementptr i8, i8* %b, i64 59
  %10210 = load i8, i8* %scevgep34.32.26, align 1
  %call28.32.26 = call zeroext i8 @mult(i8 zeroext %10209, i8 zeroext %10210)
  %conv29.32.26 = zext i8 %call28.32.26 to i32
  %xor.32.26 = xor i32 %conv23.32.26, %conv29.32.26
  %scevgep35.32.26 = getelementptr i8, i8* %a, i64 59
  %10211 = load i8, i8* %scevgep35.32.26, align 1
  %10212 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.26 = call zeroext i8 @mult(i8 zeroext %10211, i8 zeroext %10212)
  %conv35.32.26 = zext i8 %call34.32.26 to i32
  %xor36.32.26 = xor i32 %xor.32.26, %conv35.32.26
  %conv37.32.26 = trunc i32 %xor36.32.26 to i8
  store i8 %conv37.32.26, i8* %scevgep41.32.25, align 1
  %scevgep28.32.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10206, i64 0, i64 0, i64 1
  %scevgep41.32.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10207, i64 0, i64 1, i64 0
  %call16.32.27 = call zeroext i8 (...) @rand()
  store i8 %call16.32.27, i8* %scevgep28.32.26, align 1
  %10213 = load i8, i8* %scevgep28.32.26, align 1
  %conv23.32.27 = zext i8 %10213 to i32
  %10214 = load i8, i8* %arrayidx25.32, align 1
  %scevgep34.32.27 = getelementptr i8, i8* %b, i64 60
  %10215 = load i8, i8* %scevgep34.32.27, align 1
  %call28.32.27 = call zeroext i8 @mult(i8 zeroext %10214, i8 zeroext %10215)
  %conv29.32.27 = zext i8 %call28.32.27 to i32
  %xor.32.27 = xor i32 %conv23.32.27, %conv29.32.27
  %scevgep35.32.27 = getelementptr i8, i8* %a, i64 60
  %10216 = load i8, i8* %scevgep35.32.27, align 1
  %10217 = load i8, i8* %arrayidx33.32, align 1
  %call34.32.27 = call zeroext i8 @mult(i8 zeroext %10216, i8 zeroext %10217)
  %conv35.32.27 = zext i8 %call34.32.27 to i32
  %xor36.32.27 = xor i32 %xor.32.27, %conv35.32.27
  %conv37.32.27 = trunc i32 %xor36.32.27 to i8
  store i8 %conv37.32.27, i8* %scevgep41.32.26, align 1
  %scevgep26.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10024, i64 0, i64 1, i64 1
  %10218 = bitcast i8* %scevgep26.32 to [61 x [61 x i8]]*
  %scevgep39.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10025, i64 0, i64 1, i64 1
  %10219 = bitcast i8* %scevgep39.32 to [61 x [61 x i8]]*
  %arrayidx25.33 = getelementptr inbounds i8, i8* %a, i64 33
  %arrayidx33.33 = getelementptr inbounds i8, i8* %b, i64 33
  %call16.33 = call zeroext i8 (...) @rand()
  store i8 %call16.33, i8* %scevgep26.32, align 1
  %10220 = load i8, i8* %scevgep26.32, align 1
  %conv23.33 = zext i8 %10220 to i32
  %10221 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33 = getelementptr i8, i8* %b, i64 34
  %10222 = load i8, i8* %scevgep34.33, align 1
  %call28.33 = call zeroext i8 @mult(i8 zeroext %10221, i8 zeroext %10222)
  %conv29.33 = zext i8 %call28.33 to i32
  %xor.33 = xor i32 %conv23.33, %conv29.33
  %scevgep35.33 = getelementptr i8, i8* %a, i64 34
  %10223 = load i8, i8* %scevgep35.33, align 1
  %10224 = load i8, i8* %arrayidx33.33, align 1
  %call34.33 = call zeroext i8 @mult(i8 zeroext %10223, i8 zeroext %10224)
  %conv35.33 = zext i8 %call34.33 to i32
  %xor36.33 = xor i32 %xor.33, %conv35.33
  %conv37.33 = trunc i32 %xor36.33 to i8
  store i8 %conv37.33, i8* %scevgep39.32, align 1
  %scevgep28.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10218, i64 0, i64 0, i64 1
  %10225 = bitcast i8* %scevgep28.33 to [61 x [61 x i8]]*
  %scevgep41.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10219, i64 0, i64 1, i64 0
  %10226 = bitcast i8* %scevgep41.33 to [61 x [61 x i8]]*
  %call16.33.1 = call zeroext i8 (...) @rand()
  store i8 %call16.33.1, i8* %scevgep28.33, align 1
  %10227 = load i8, i8* %scevgep28.33, align 1
  %conv23.33.1 = zext i8 %10227 to i32
  %10228 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.1 = getelementptr i8, i8* %b, i64 35
  %10229 = load i8, i8* %scevgep34.33.1, align 1
  %call28.33.1 = call zeroext i8 @mult(i8 zeroext %10228, i8 zeroext %10229)
  %conv29.33.1 = zext i8 %call28.33.1 to i32
  %xor.33.1 = xor i32 %conv23.33.1, %conv29.33.1
  %scevgep35.33.1 = getelementptr i8, i8* %a, i64 35
  %10230 = load i8, i8* %scevgep35.33.1, align 1
  %10231 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.1 = call zeroext i8 @mult(i8 zeroext %10230, i8 zeroext %10231)
  %conv35.33.1 = zext i8 %call34.33.1 to i32
  %xor36.33.1 = xor i32 %xor.33.1, %conv35.33.1
  %conv37.33.1 = trunc i32 %xor36.33.1 to i8
  store i8 %conv37.33.1, i8* %scevgep41.33, align 1
  %scevgep28.33.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10225, i64 0, i64 0, i64 1
  %10232 = bitcast i8* %scevgep28.33.1 to [61 x [61 x i8]]*
  %scevgep41.33.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10226, i64 0, i64 1, i64 0
  %10233 = bitcast i8* %scevgep41.33.1 to [61 x [61 x i8]]*
  %call16.33.2 = call zeroext i8 (...) @rand()
  store i8 %call16.33.2, i8* %scevgep28.33.1, align 1
  %10234 = load i8, i8* %scevgep28.33.1, align 1
  %conv23.33.2 = zext i8 %10234 to i32
  %10235 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.2 = getelementptr i8, i8* %b, i64 36
  %10236 = load i8, i8* %scevgep34.33.2, align 1
  %call28.33.2 = call zeroext i8 @mult(i8 zeroext %10235, i8 zeroext %10236)
  %conv29.33.2 = zext i8 %call28.33.2 to i32
  %xor.33.2 = xor i32 %conv23.33.2, %conv29.33.2
  %scevgep35.33.2 = getelementptr i8, i8* %a, i64 36
  %10237 = load i8, i8* %scevgep35.33.2, align 1
  %10238 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.2 = call zeroext i8 @mult(i8 zeroext %10237, i8 zeroext %10238)
  %conv35.33.2 = zext i8 %call34.33.2 to i32
  %xor36.33.2 = xor i32 %xor.33.2, %conv35.33.2
  %conv37.33.2 = trunc i32 %xor36.33.2 to i8
  store i8 %conv37.33.2, i8* %scevgep41.33.1, align 1
  %scevgep28.33.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10232, i64 0, i64 0, i64 1
  %10239 = bitcast i8* %scevgep28.33.2 to [61 x [61 x i8]]*
  %scevgep41.33.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10233, i64 0, i64 1, i64 0
  %10240 = bitcast i8* %scevgep41.33.2 to [61 x [61 x i8]]*
  %call16.33.3 = call zeroext i8 (...) @rand()
  store i8 %call16.33.3, i8* %scevgep28.33.2, align 1
  %10241 = load i8, i8* %scevgep28.33.2, align 1
  %conv23.33.3 = zext i8 %10241 to i32
  %10242 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.3 = getelementptr i8, i8* %b, i64 37
  %10243 = load i8, i8* %scevgep34.33.3, align 1
  %call28.33.3 = call zeroext i8 @mult(i8 zeroext %10242, i8 zeroext %10243)
  %conv29.33.3 = zext i8 %call28.33.3 to i32
  %xor.33.3 = xor i32 %conv23.33.3, %conv29.33.3
  %scevgep35.33.3 = getelementptr i8, i8* %a, i64 37
  %10244 = load i8, i8* %scevgep35.33.3, align 1
  %10245 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.3 = call zeroext i8 @mult(i8 zeroext %10244, i8 zeroext %10245)
  %conv35.33.3 = zext i8 %call34.33.3 to i32
  %xor36.33.3 = xor i32 %xor.33.3, %conv35.33.3
  %conv37.33.3 = trunc i32 %xor36.33.3 to i8
  store i8 %conv37.33.3, i8* %scevgep41.33.2, align 1
  %scevgep28.33.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10239, i64 0, i64 0, i64 1
  %10246 = bitcast i8* %scevgep28.33.3 to [61 x [61 x i8]]*
  %scevgep41.33.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10240, i64 0, i64 1, i64 0
  %10247 = bitcast i8* %scevgep41.33.3 to [61 x [61 x i8]]*
  %call16.33.4 = call zeroext i8 (...) @rand()
  store i8 %call16.33.4, i8* %scevgep28.33.3, align 1
  %10248 = load i8, i8* %scevgep28.33.3, align 1
  %conv23.33.4 = zext i8 %10248 to i32
  %10249 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.4 = getelementptr i8, i8* %b, i64 38
  %10250 = load i8, i8* %scevgep34.33.4, align 1
  %call28.33.4 = call zeroext i8 @mult(i8 zeroext %10249, i8 zeroext %10250)
  %conv29.33.4 = zext i8 %call28.33.4 to i32
  %xor.33.4 = xor i32 %conv23.33.4, %conv29.33.4
  %scevgep35.33.4 = getelementptr i8, i8* %a, i64 38
  %10251 = load i8, i8* %scevgep35.33.4, align 1
  %10252 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.4 = call zeroext i8 @mult(i8 zeroext %10251, i8 zeroext %10252)
  %conv35.33.4 = zext i8 %call34.33.4 to i32
  %xor36.33.4 = xor i32 %xor.33.4, %conv35.33.4
  %conv37.33.4 = trunc i32 %xor36.33.4 to i8
  store i8 %conv37.33.4, i8* %scevgep41.33.3, align 1
  %scevgep28.33.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10246, i64 0, i64 0, i64 1
  %10253 = bitcast i8* %scevgep28.33.4 to [61 x [61 x i8]]*
  %scevgep41.33.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10247, i64 0, i64 1, i64 0
  %10254 = bitcast i8* %scevgep41.33.4 to [61 x [61 x i8]]*
  %call16.33.5 = call zeroext i8 (...) @rand()
  store i8 %call16.33.5, i8* %scevgep28.33.4, align 1
  %10255 = load i8, i8* %scevgep28.33.4, align 1
  %conv23.33.5 = zext i8 %10255 to i32
  %10256 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.5 = getelementptr i8, i8* %b, i64 39
  %10257 = load i8, i8* %scevgep34.33.5, align 1
  %call28.33.5 = call zeroext i8 @mult(i8 zeroext %10256, i8 zeroext %10257)
  %conv29.33.5 = zext i8 %call28.33.5 to i32
  %xor.33.5 = xor i32 %conv23.33.5, %conv29.33.5
  %scevgep35.33.5 = getelementptr i8, i8* %a, i64 39
  %10258 = load i8, i8* %scevgep35.33.5, align 1
  %10259 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.5 = call zeroext i8 @mult(i8 zeroext %10258, i8 zeroext %10259)
  %conv35.33.5 = zext i8 %call34.33.5 to i32
  %xor36.33.5 = xor i32 %xor.33.5, %conv35.33.5
  %conv37.33.5 = trunc i32 %xor36.33.5 to i8
  store i8 %conv37.33.5, i8* %scevgep41.33.4, align 1
  %scevgep28.33.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10253, i64 0, i64 0, i64 1
  %10260 = bitcast i8* %scevgep28.33.5 to [61 x [61 x i8]]*
  %scevgep41.33.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10254, i64 0, i64 1, i64 0
  %10261 = bitcast i8* %scevgep41.33.5 to [61 x [61 x i8]]*
  %call16.33.6 = call zeroext i8 (...) @rand()
  store i8 %call16.33.6, i8* %scevgep28.33.5, align 1
  %10262 = load i8, i8* %scevgep28.33.5, align 1
  %conv23.33.6 = zext i8 %10262 to i32
  %10263 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.6 = getelementptr i8, i8* %b, i64 40
  %10264 = load i8, i8* %scevgep34.33.6, align 1
  %call28.33.6 = call zeroext i8 @mult(i8 zeroext %10263, i8 zeroext %10264)
  %conv29.33.6 = zext i8 %call28.33.6 to i32
  %xor.33.6 = xor i32 %conv23.33.6, %conv29.33.6
  %scevgep35.33.6 = getelementptr i8, i8* %a, i64 40
  %10265 = load i8, i8* %scevgep35.33.6, align 1
  %10266 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.6 = call zeroext i8 @mult(i8 zeroext %10265, i8 zeroext %10266)
  %conv35.33.6 = zext i8 %call34.33.6 to i32
  %xor36.33.6 = xor i32 %xor.33.6, %conv35.33.6
  %conv37.33.6 = trunc i32 %xor36.33.6 to i8
  store i8 %conv37.33.6, i8* %scevgep41.33.5, align 1
  %scevgep28.33.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10260, i64 0, i64 0, i64 1
  %10267 = bitcast i8* %scevgep28.33.6 to [61 x [61 x i8]]*
  %scevgep41.33.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10261, i64 0, i64 1, i64 0
  %10268 = bitcast i8* %scevgep41.33.6 to [61 x [61 x i8]]*
  %call16.33.7 = call zeroext i8 (...) @rand()
  store i8 %call16.33.7, i8* %scevgep28.33.6, align 1
  %10269 = load i8, i8* %scevgep28.33.6, align 1
  %conv23.33.7 = zext i8 %10269 to i32
  %10270 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.7 = getelementptr i8, i8* %b, i64 41
  %10271 = load i8, i8* %scevgep34.33.7, align 1
  %call28.33.7 = call zeroext i8 @mult(i8 zeroext %10270, i8 zeroext %10271)
  %conv29.33.7 = zext i8 %call28.33.7 to i32
  %xor.33.7 = xor i32 %conv23.33.7, %conv29.33.7
  %scevgep35.33.7 = getelementptr i8, i8* %a, i64 41
  %10272 = load i8, i8* %scevgep35.33.7, align 1
  %10273 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.7 = call zeroext i8 @mult(i8 zeroext %10272, i8 zeroext %10273)
  %conv35.33.7 = zext i8 %call34.33.7 to i32
  %xor36.33.7 = xor i32 %xor.33.7, %conv35.33.7
  %conv37.33.7 = trunc i32 %xor36.33.7 to i8
  store i8 %conv37.33.7, i8* %scevgep41.33.6, align 1
  %scevgep28.33.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10267, i64 0, i64 0, i64 1
  %10274 = bitcast i8* %scevgep28.33.7 to [61 x [61 x i8]]*
  %scevgep41.33.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10268, i64 0, i64 1, i64 0
  %10275 = bitcast i8* %scevgep41.33.7 to [61 x [61 x i8]]*
  %call16.33.8 = call zeroext i8 (...) @rand()
  store i8 %call16.33.8, i8* %scevgep28.33.7, align 1
  %10276 = load i8, i8* %scevgep28.33.7, align 1
  %conv23.33.8 = zext i8 %10276 to i32
  %10277 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.8 = getelementptr i8, i8* %b, i64 42
  %10278 = load i8, i8* %scevgep34.33.8, align 1
  %call28.33.8 = call zeroext i8 @mult(i8 zeroext %10277, i8 zeroext %10278)
  %conv29.33.8 = zext i8 %call28.33.8 to i32
  %xor.33.8 = xor i32 %conv23.33.8, %conv29.33.8
  %scevgep35.33.8 = getelementptr i8, i8* %a, i64 42
  %10279 = load i8, i8* %scevgep35.33.8, align 1
  %10280 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.8 = call zeroext i8 @mult(i8 zeroext %10279, i8 zeroext %10280)
  %conv35.33.8 = zext i8 %call34.33.8 to i32
  %xor36.33.8 = xor i32 %xor.33.8, %conv35.33.8
  %conv37.33.8 = trunc i32 %xor36.33.8 to i8
  store i8 %conv37.33.8, i8* %scevgep41.33.7, align 1
  %scevgep28.33.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10274, i64 0, i64 0, i64 1
  %10281 = bitcast i8* %scevgep28.33.8 to [61 x [61 x i8]]*
  %scevgep41.33.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10275, i64 0, i64 1, i64 0
  %10282 = bitcast i8* %scevgep41.33.8 to [61 x [61 x i8]]*
  %call16.33.9 = call zeroext i8 (...) @rand()
  store i8 %call16.33.9, i8* %scevgep28.33.8, align 1
  %10283 = load i8, i8* %scevgep28.33.8, align 1
  %conv23.33.9 = zext i8 %10283 to i32
  %10284 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.9 = getelementptr i8, i8* %b, i64 43
  %10285 = load i8, i8* %scevgep34.33.9, align 1
  %call28.33.9 = call zeroext i8 @mult(i8 zeroext %10284, i8 zeroext %10285)
  %conv29.33.9 = zext i8 %call28.33.9 to i32
  %xor.33.9 = xor i32 %conv23.33.9, %conv29.33.9
  %scevgep35.33.9 = getelementptr i8, i8* %a, i64 43
  %10286 = load i8, i8* %scevgep35.33.9, align 1
  %10287 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.9 = call zeroext i8 @mult(i8 zeroext %10286, i8 zeroext %10287)
  %conv35.33.9 = zext i8 %call34.33.9 to i32
  %xor36.33.9 = xor i32 %xor.33.9, %conv35.33.9
  %conv37.33.9 = trunc i32 %xor36.33.9 to i8
  store i8 %conv37.33.9, i8* %scevgep41.33.8, align 1
  %scevgep28.33.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10281, i64 0, i64 0, i64 1
  %10288 = bitcast i8* %scevgep28.33.9 to [61 x [61 x i8]]*
  %scevgep41.33.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10282, i64 0, i64 1, i64 0
  %10289 = bitcast i8* %scevgep41.33.9 to [61 x [61 x i8]]*
  %call16.33.10 = call zeroext i8 (...) @rand()
  store i8 %call16.33.10, i8* %scevgep28.33.9, align 1
  %10290 = load i8, i8* %scevgep28.33.9, align 1
  %conv23.33.10 = zext i8 %10290 to i32
  %10291 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.10 = getelementptr i8, i8* %b, i64 44
  %10292 = load i8, i8* %scevgep34.33.10, align 1
  %call28.33.10 = call zeroext i8 @mult(i8 zeroext %10291, i8 zeroext %10292)
  %conv29.33.10 = zext i8 %call28.33.10 to i32
  %xor.33.10 = xor i32 %conv23.33.10, %conv29.33.10
  %scevgep35.33.10 = getelementptr i8, i8* %a, i64 44
  %10293 = load i8, i8* %scevgep35.33.10, align 1
  %10294 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.10 = call zeroext i8 @mult(i8 zeroext %10293, i8 zeroext %10294)
  %conv35.33.10 = zext i8 %call34.33.10 to i32
  %xor36.33.10 = xor i32 %xor.33.10, %conv35.33.10
  %conv37.33.10 = trunc i32 %xor36.33.10 to i8
  store i8 %conv37.33.10, i8* %scevgep41.33.9, align 1
  %scevgep28.33.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10288, i64 0, i64 0, i64 1
  %10295 = bitcast i8* %scevgep28.33.10 to [61 x [61 x i8]]*
  %scevgep41.33.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10289, i64 0, i64 1, i64 0
  %10296 = bitcast i8* %scevgep41.33.10 to [61 x [61 x i8]]*
  %call16.33.11 = call zeroext i8 (...) @rand()
  store i8 %call16.33.11, i8* %scevgep28.33.10, align 1
  %10297 = load i8, i8* %scevgep28.33.10, align 1
  %conv23.33.11 = zext i8 %10297 to i32
  %10298 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.11 = getelementptr i8, i8* %b, i64 45
  %10299 = load i8, i8* %scevgep34.33.11, align 1
  %call28.33.11 = call zeroext i8 @mult(i8 zeroext %10298, i8 zeroext %10299)
  %conv29.33.11 = zext i8 %call28.33.11 to i32
  %xor.33.11 = xor i32 %conv23.33.11, %conv29.33.11
  %scevgep35.33.11 = getelementptr i8, i8* %a, i64 45
  %10300 = load i8, i8* %scevgep35.33.11, align 1
  %10301 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.11 = call zeroext i8 @mult(i8 zeroext %10300, i8 zeroext %10301)
  %conv35.33.11 = zext i8 %call34.33.11 to i32
  %xor36.33.11 = xor i32 %xor.33.11, %conv35.33.11
  %conv37.33.11 = trunc i32 %xor36.33.11 to i8
  store i8 %conv37.33.11, i8* %scevgep41.33.10, align 1
  %scevgep28.33.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10295, i64 0, i64 0, i64 1
  %10302 = bitcast i8* %scevgep28.33.11 to [61 x [61 x i8]]*
  %scevgep41.33.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10296, i64 0, i64 1, i64 0
  %10303 = bitcast i8* %scevgep41.33.11 to [61 x [61 x i8]]*
  %call16.33.12 = call zeroext i8 (...) @rand()
  store i8 %call16.33.12, i8* %scevgep28.33.11, align 1
  %10304 = load i8, i8* %scevgep28.33.11, align 1
  %conv23.33.12 = zext i8 %10304 to i32
  %10305 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.12 = getelementptr i8, i8* %b, i64 46
  %10306 = load i8, i8* %scevgep34.33.12, align 1
  %call28.33.12 = call zeroext i8 @mult(i8 zeroext %10305, i8 zeroext %10306)
  %conv29.33.12 = zext i8 %call28.33.12 to i32
  %xor.33.12 = xor i32 %conv23.33.12, %conv29.33.12
  %scevgep35.33.12 = getelementptr i8, i8* %a, i64 46
  %10307 = load i8, i8* %scevgep35.33.12, align 1
  %10308 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.12 = call zeroext i8 @mult(i8 zeroext %10307, i8 zeroext %10308)
  %conv35.33.12 = zext i8 %call34.33.12 to i32
  %xor36.33.12 = xor i32 %xor.33.12, %conv35.33.12
  %conv37.33.12 = trunc i32 %xor36.33.12 to i8
  store i8 %conv37.33.12, i8* %scevgep41.33.11, align 1
  %scevgep28.33.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10302, i64 0, i64 0, i64 1
  %10309 = bitcast i8* %scevgep28.33.12 to [61 x [61 x i8]]*
  %scevgep41.33.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10303, i64 0, i64 1, i64 0
  %10310 = bitcast i8* %scevgep41.33.12 to [61 x [61 x i8]]*
  %call16.33.13 = call zeroext i8 (...) @rand()
  store i8 %call16.33.13, i8* %scevgep28.33.12, align 1
  %10311 = load i8, i8* %scevgep28.33.12, align 1
  %conv23.33.13 = zext i8 %10311 to i32
  %10312 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.13 = getelementptr i8, i8* %b, i64 47
  %10313 = load i8, i8* %scevgep34.33.13, align 1
  %call28.33.13 = call zeroext i8 @mult(i8 zeroext %10312, i8 zeroext %10313)
  %conv29.33.13 = zext i8 %call28.33.13 to i32
  %xor.33.13 = xor i32 %conv23.33.13, %conv29.33.13
  %scevgep35.33.13 = getelementptr i8, i8* %a, i64 47
  %10314 = load i8, i8* %scevgep35.33.13, align 1
  %10315 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.13 = call zeroext i8 @mult(i8 zeroext %10314, i8 zeroext %10315)
  %conv35.33.13 = zext i8 %call34.33.13 to i32
  %xor36.33.13 = xor i32 %xor.33.13, %conv35.33.13
  %conv37.33.13 = trunc i32 %xor36.33.13 to i8
  store i8 %conv37.33.13, i8* %scevgep41.33.12, align 1
  %scevgep28.33.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10309, i64 0, i64 0, i64 1
  %10316 = bitcast i8* %scevgep28.33.13 to [61 x [61 x i8]]*
  %scevgep41.33.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10310, i64 0, i64 1, i64 0
  %10317 = bitcast i8* %scevgep41.33.13 to [61 x [61 x i8]]*
  %call16.33.14 = call zeroext i8 (...) @rand()
  store i8 %call16.33.14, i8* %scevgep28.33.13, align 1
  %10318 = load i8, i8* %scevgep28.33.13, align 1
  %conv23.33.14 = zext i8 %10318 to i32
  %10319 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.14 = getelementptr i8, i8* %b, i64 48
  %10320 = load i8, i8* %scevgep34.33.14, align 1
  %call28.33.14 = call zeroext i8 @mult(i8 zeroext %10319, i8 zeroext %10320)
  %conv29.33.14 = zext i8 %call28.33.14 to i32
  %xor.33.14 = xor i32 %conv23.33.14, %conv29.33.14
  %scevgep35.33.14 = getelementptr i8, i8* %a, i64 48
  %10321 = load i8, i8* %scevgep35.33.14, align 1
  %10322 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.14 = call zeroext i8 @mult(i8 zeroext %10321, i8 zeroext %10322)
  %conv35.33.14 = zext i8 %call34.33.14 to i32
  %xor36.33.14 = xor i32 %xor.33.14, %conv35.33.14
  %conv37.33.14 = trunc i32 %xor36.33.14 to i8
  store i8 %conv37.33.14, i8* %scevgep41.33.13, align 1
  %scevgep28.33.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10316, i64 0, i64 0, i64 1
  %10323 = bitcast i8* %scevgep28.33.14 to [61 x [61 x i8]]*
  %scevgep41.33.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10317, i64 0, i64 1, i64 0
  %10324 = bitcast i8* %scevgep41.33.14 to [61 x [61 x i8]]*
  %call16.33.15 = call zeroext i8 (...) @rand()
  store i8 %call16.33.15, i8* %scevgep28.33.14, align 1
  %10325 = load i8, i8* %scevgep28.33.14, align 1
  %conv23.33.15 = zext i8 %10325 to i32
  %10326 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.15 = getelementptr i8, i8* %b, i64 49
  %10327 = load i8, i8* %scevgep34.33.15, align 1
  %call28.33.15 = call zeroext i8 @mult(i8 zeroext %10326, i8 zeroext %10327)
  %conv29.33.15 = zext i8 %call28.33.15 to i32
  %xor.33.15 = xor i32 %conv23.33.15, %conv29.33.15
  %scevgep35.33.15 = getelementptr i8, i8* %a, i64 49
  %10328 = load i8, i8* %scevgep35.33.15, align 1
  %10329 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.15 = call zeroext i8 @mult(i8 zeroext %10328, i8 zeroext %10329)
  %conv35.33.15 = zext i8 %call34.33.15 to i32
  %xor36.33.15 = xor i32 %xor.33.15, %conv35.33.15
  %conv37.33.15 = trunc i32 %xor36.33.15 to i8
  store i8 %conv37.33.15, i8* %scevgep41.33.14, align 1
  %scevgep28.33.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10323, i64 0, i64 0, i64 1
  %10330 = bitcast i8* %scevgep28.33.15 to [61 x [61 x i8]]*
  %scevgep41.33.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10324, i64 0, i64 1, i64 0
  %10331 = bitcast i8* %scevgep41.33.15 to [61 x [61 x i8]]*
  %call16.33.16 = call zeroext i8 (...) @rand()
  store i8 %call16.33.16, i8* %scevgep28.33.15, align 1
  %10332 = load i8, i8* %scevgep28.33.15, align 1
  %conv23.33.16 = zext i8 %10332 to i32
  %10333 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.16 = getelementptr i8, i8* %b, i64 50
  %10334 = load i8, i8* %scevgep34.33.16, align 1
  %call28.33.16 = call zeroext i8 @mult(i8 zeroext %10333, i8 zeroext %10334)
  %conv29.33.16 = zext i8 %call28.33.16 to i32
  %xor.33.16 = xor i32 %conv23.33.16, %conv29.33.16
  %scevgep35.33.16 = getelementptr i8, i8* %a, i64 50
  %10335 = load i8, i8* %scevgep35.33.16, align 1
  %10336 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.16 = call zeroext i8 @mult(i8 zeroext %10335, i8 zeroext %10336)
  %conv35.33.16 = zext i8 %call34.33.16 to i32
  %xor36.33.16 = xor i32 %xor.33.16, %conv35.33.16
  %conv37.33.16 = trunc i32 %xor36.33.16 to i8
  store i8 %conv37.33.16, i8* %scevgep41.33.15, align 1
  %scevgep28.33.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10330, i64 0, i64 0, i64 1
  %10337 = bitcast i8* %scevgep28.33.16 to [61 x [61 x i8]]*
  %scevgep41.33.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10331, i64 0, i64 1, i64 0
  %10338 = bitcast i8* %scevgep41.33.16 to [61 x [61 x i8]]*
  %call16.33.17 = call zeroext i8 (...) @rand()
  store i8 %call16.33.17, i8* %scevgep28.33.16, align 1
  %10339 = load i8, i8* %scevgep28.33.16, align 1
  %conv23.33.17 = zext i8 %10339 to i32
  %10340 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.17 = getelementptr i8, i8* %b, i64 51
  %10341 = load i8, i8* %scevgep34.33.17, align 1
  %call28.33.17 = call zeroext i8 @mult(i8 zeroext %10340, i8 zeroext %10341)
  %conv29.33.17 = zext i8 %call28.33.17 to i32
  %xor.33.17 = xor i32 %conv23.33.17, %conv29.33.17
  %scevgep35.33.17 = getelementptr i8, i8* %a, i64 51
  %10342 = load i8, i8* %scevgep35.33.17, align 1
  %10343 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.17 = call zeroext i8 @mult(i8 zeroext %10342, i8 zeroext %10343)
  %conv35.33.17 = zext i8 %call34.33.17 to i32
  %xor36.33.17 = xor i32 %xor.33.17, %conv35.33.17
  %conv37.33.17 = trunc i32 %xor36.33.17 to i8
  store i8 %conv37.33.17, i8* %scevgep41.33.16, align 1
  %scevgep28.33.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10337, i64 0, i64 0, i64 1
  %10344 = bitcast i8* %scevgep28.33.17 to [61 x [61 x i8]]*
  %scevgep41.33.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10338, i64 0, i64 1, i64 0
  %10345 = bitcast i8* %scevgep41.33.17 to [61 x [61 x i8]]*
  %call16.33.18 = call zeroext i8 (...) @rand()
  store i8 %call16.33.18, i8* %scevgep28.33.17, align 1
  %10346 = load i8, i8* %scevgep28.33.17, align 1
  %conv23.33.18 = zext i8 %10346 to i32
  %10347 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.18 = getelementptr i8, i8* %b, i64 52
  %10348 = load i8, i8* %scevgep34.33.18, align 1
  %call28.33.18 = call zeroext i8 @mult(i8 zeroext %10347, i8 zeroext %10348)
  %conv29.33.18 = zext i8 %call28.33.18 to i32
  %xor.33.18 = xor i32 %conv23.33.18, %conv29.33.18
  %scevgep35.33.18 = getelementptr i8, i8* %a, i64 52
  %10349 = load i8, i8* %scevgep35.33.18, align 1
  %10350 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.18 = call zeroext i8 @mult(i8 zeroext %10349, i8 zeroext %10350)
  %conv35.33.18 = zext i8 %call34.33.18 to i32
  %xor36.33.18 = xor i32 %xor.33.18, %conv35.33.18
  %conv37.33.18 = trunc i32 %xor36.33.18 to i8
  store i8 %conv37.33.18, i8* %scevgep41.33.17, align 1
  %scevgep28.33.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10344, i64 0, i64 0, i64 1
  %10351 = bitcast i8* %scevgep28.33.18 to [61 x [61 x i8]]*
  %scevgep41.33.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10345, i64 0, i64 1, i64 0
  %10352 = bitcast i8* %scevgep41.33.18 to [61 x [61 x i8]]*
  %call16.33.19 = call zeroext i8 (...) @rand()
  store i8 %call16.33.19, i8* %scevgep28.33.18, align 1
  %10353 = load i8, i8* %scevgep28.33.18, align 1
  %conv23.33.19 = zext i8 %10353 to i32
  %10354 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.19 = getelementptr i8, i8* %b, i64 53
  %10355 = load i8, i8* %scevgep34.33.19, align 1
  %call28.33.19 = call zeroext i8 @mult(i8 zeroext %10354, i8 zeroext %10355)
  %conv29.33.19 = zext i8 %call28.33.19 to i32
  %xor.33.19 = xor i32 %conv23.33.19, %conv29.33.19
  %scevgep35.33.19 = getelementptr i8, i8* %a, i64 53
  %10356 = load i8, i8* %scevgep35.33.19, align 1
  %10357 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.19 = call zeroext i8 @mult(i8 zeroext %10356, i8 zeroext %10357)
  %conv35.33.19 = zext i8 %call34.33.19 to i32
  %xor36.33.19 = xor i32 %xor.33.19, %conv35.33.19
  %conv37.33.19 = trunc i32 %xor36.33.19 to i8
  store i8 %conv37.33.19, i8* %scevgep41.33.18, align 1
  %scevgep28.33.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10351, i64 0, i64 0, i64 1
  %10358 = bitcast i8* %scevgep28.33.19 to [61 x [61 x i8]]*
  %scevgep41.33.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10352, i64 0, i64 1, i64 0
  %10359 = bitcast i8* %scevgep41.33.19 to [61 x [61 x i8]]*
  %call16.33.20 = call zeroext i8 (...) @rand()
  store i8 %call16.33.20, i8* %scevgep28.33.19, align 1
  %10360 = load i8, i8* %scevgep28.33.19, align 1
  %conv23.33.20 = zext i8 %10360 to i32
  %10361 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.20 = getelementptr i8, i8* %b, i64 54
  %10362 = load i8, i8* %scevgep34.33.20, align 1
  %call28.33.20 = call zeroext i8 @mult(i8 zeroext %10361, i8 zeroext %10362)
  %conv29.33.20 = zext i8 %call28.33.20 to i32
  %xor.33.20 = xor i32 %conv23.33.20, %conv29.33.20
  %scevgep35.33.20 = getelementptr i8, i8* %a, i64 54
  %10363 = load i8, i8* %scevgep35.33.20, align 1
  %10364 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.20 = call zeroext i8 @mult(i8 zeroext %10363, i8 zeroext %10364)
  %conv35.33.20 = zext i8 %call34.33.20 to i32
  %xor36.33.20 = xor i32 %xor.33.20, %conv35.33.20
  %conv37.33.20 = trunc i32 %xor36.33.20 to i8
  store i8 %conv37.33.20, i8* %scevgep41.33.19, align 1
  %scevgep28.33.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10358, i64 0, i64 0, i64 1
  %10365 = bitcast i8* %scevgep28.33.20 to [61 x [61 x i8]]*
  %scevgep41.33.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10359, i64 0, i64 1, i64 0
  %10366 = bitcast i8* %scevgep41.33.20 to [61 x [61 x i8]]*
  %call16.33.21 = call zeroext i8 (...) @rand()
  store i8 %call16.33.21, i8* %scevgep28.33.20, align 1
  %10367 = load i8, i8* %scevgep28.33.20, align 1
  %conv23.33.21 = zext i8 %10367 to i32
  %10368 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.21 = getelementptr i8, i8* %b, i64 55
  %10369 = load i8, i8* %scevgep34.33.21, align 1
  %call28.33.21 = call zeroext i8 @mult(i8 zeroext %10368, i8 zeroext %10369)
  %conv29.33.21 = zext i8 %call28.33.21 to i32
  %xor.33.21 = xor i32 %conv23.33.21, %conv29.33.21
  %scevgep35.33.21 = getelementptr i8, i8* %a, i64 55
  %10370 = load i8, i8* %scevgep35.33.21, align 1
  %10371 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.21 = call zeroext i8 @mult(i8 zeroext %10370, i8 zeroext %10371)
  %conv35.33.21 = zext i8 %call34.33.21 to i32
  %xor36.33.21 = xor i32 %xor.33.21, %conv35.33.21
  %conv37.33.21 = trunc i32 %xor36.33.21 to i8
  store i8 %conv37.33.21, i8* %scevgep41.33.20, align 1
  %scevgep28.33.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10365, i64 0, i64 0, i64 1
  %10372 = bitcast i8* %scevgep28.33.21 to [61 x [61 x i8]]*
  %scevgep41.33.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10366, i64 0, i64 1, i64 0
  %10373 = bitcast i8* %scevgep41.33.21 to [61 x [61 x i8]]*
  %call16.33.22 = call zeroext i8 (...) @rand()
  store i8 %call16.33.22, i8* %scevgep28.33.21, align 1
  %10374 = load i8, i8* %scevgep28.33.21, align 1
  %conv23.33.22 = zext i8 %10374 to i32
  %10375 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.22 = getelementptr i8, i8* %b, i64 56
  %10376 = load i8, i8* %scevgep34.33.22, align 1
  %call28.33.22 = call zeroext i8 @mult(i8 zeroext %10375, i8 zeroext %10376)
  %conv29.33.22 = zext i8 %call28.33.22 to i32
  %xor.33.22 = xor i32 %conv23.33.22, %conv29.33.22
  %scevgep35.33.22 = getelementptr i8, i8* %a, i64 56
  %10377 = load i8, i8* %scevgep35.33.22, align 1
  %10378 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.22 = call zeroext i8 @mult(i8 zeroext %10377, i8 zeroext %10378)
  %conv35.33.22 = zext i8 %call34.33.22 to i32
  %xor36.33.22 = xor i32 %xor.33.22, %conv35.33.22
  %conv37.33.22 = trunc i32 %xor36.33.22 to i8
  store i8 %conv37.33.22, i8* %scevgep41.33.21, align 1
  %scevgep28.33.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10372, i64 0, i64 0, i64 1
  %10379 = bitcast i8* %scevgep28.33.22 to [61 x [61 x i8]]*
  %scevgep41.33.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10373, i64 0, i64 1, i64 0
  %10380 = bitcast i8* %scevgep41.33.22 to [61 x [61 x i8]]*
  %call16.33.23 = call zeroext i8 (...) @rand()
  store i8 %call16.33.23, i8* %scevgep28.33.22, align 1
  %10381 = load i8, i8* %scevgep28.33.22, align 1
  %conv23.33.23 = zext i8 %10381 to i32
  %10382 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.23 = getelementptr i8, i8* %b, i64 57
  %10383 = load i8, i8* %scevgep34.33.23, align 1
  %call28.33.23 = call zeroext i8 @mult(i8 zeroext %10382, i8 zeroext %10383)
  %conv29.33.23 = zext i8 %call28.33.23 to i32
  %xor.33.23 = xor i32 %conv23.33.23, %conv29.33.23
  %scevgep35.33.23 = getelementptr i8, i8* %a, i64 57
  %10384 = load i8, i8* %scevgep35.33.23, align 1
  %10385 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.23 = call zeroext i8 @mult(i8 zeroext %10384, i8 zeroext %10385)
  %conv35.33.23 = zext i8 %call34.33.23 to i32
  %xor36.33.23 = xor i32 %xor.33.23, %conv35.33.23
  %conv37.33.23 = trunc i32 %xor36.33.23 to i8
  store i8 %conv37.33.23, i8* %scevgep41.33.22, align 1
  %scevgep28.33.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10379, i64 0, i64 0, i64 1
  %10386 = bitcast i8* %scevgep28.33.23 to [61 x [61 x i8]]*
  %scevgep41.33.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10380, i64 0, i64 1, i64 0
  %10387 = bitcast i8* %scevgep41.33.23 to [61 x [61 x i8]]*
  %call16.33.24 = call zeroext i8 (...) @rand()
  store i8 %call16.33.24, i8* %scevgep28.33.23, align 1
  %10388 = load i8, i8* %scevgep28.33.23, align 1
  %conv23.33.24 = zext i8 %10388 to i32
  %10389 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.24 = getelementptr i8, i8* %b, i64 58
  %10390 = load i8, i8* %scevgep34.33.24, align 1
  %call28.33.24 = call zeroext i8 @mult(i8 zeroext %10389, i8 zeroext %10390)
  %conv29.33.24 = zext i8 %call28.33.24 to i32
  %xor.33.24 = xor i32 %conv23.33.24, %conv29.33.24
  %scevgep35.33.24 = getelementptr i8, i8* %a, i64 58
  %10391 = load i8, i8* %scevgep35.33.24, align 1
  %10392 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.24 = call zeroext i8 @mult(i8 zeroext %10391, i8 zeroext %10392)
  %conv35.33.24 = zext i8 %call34.33.24 to i32
  %xor36.33.24 = xor i32 %xor.33.24, %conv35.33.24
  %conv37.33.24 = trunc i32 %xor36.33.24 to i8
  store i8 %conv37.33.24, i8* %scevgep41.33.23, align 1
  %scevgep28.33.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10386, i64 0, i64 0, i64 1
  %10393 = bitcast i8* %scevgep28.33.24 to [61 x [61 x i8]]*
  %scevgep41.33.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10387, i64 0, i64 1, i64 0
  %10394 = bitcast i8* %scevgep41.33.24 to [61 x [61 x i8]]*
  %call16.33.25 = call zeroext i8 (...) @rand()
  store i8 %call16.33.25, i8* %scevgep28.33.24, align 1
  %10395 = load i8, i8* %scevgep28.33.24, align 1
  %conv23.33.25 = zext i8 %10395 to i32
  %10396 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.25 = getelementptr i8, i8* %b, i64 59
  %10397 = load i8, i8* %scevgep34.33.25, align 1
  %call28.33.25 = call zeroext i8 @mult(i8 zeroext %10396, i8 zeroext %10397)
  %conv29.33.25 = zext i8 %call28.33.25 to i32
  %xor.33.25 = xor i32 %conv23.33.25, %conv29.33.25
  %scevgep35.33.25 = getelementptr i8, i8* %a, i64 59
  %10398 = load i8, i8* %scevgep35.33.25, align 1
  %10399 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.25 = call zeroext i8 @mult(i8 zeroext %10398, i8 zeroext %10399)
  %conv35.33.25 = zext i8 %call34.33.25 to i32
  %xor36.33.25 = xor i32 %xor.33.25, %conv35.33.25
  %conv37.33.25 = trunc i32 %xor36.33.25 to i8
  store i8 %conv37.33.25, i8* %scevgep41.33.24, align 1
  %scevgep28.33.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10393, i64 0, i64 0, i64 1
  %scevgep41.33.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10394, i64 0, i64 1, i64 0
  %call16.33.26 = call zeroext i8 (...) @rand()
  store i8 %call16.33.26, i8* %scevgep28.33.25, align 1
  %10400 = load i8, i8* %scevgep28.33.25, align 1
  %conv23.33.26 = zext i8 %10400 to i32
  %10401 = load i8, i8* %arrayidx25.33, align 1
  %scevgep34.33.26 = getelementptr i8, i8* %b, i64 60
  %10402 = load i8, i8* %scevgep34.33.26, align 1
  %call28.33.26 = call zeroext i8 @mult(i8 zeroext %10401, i8 zeroext %10402)
  %conv29.33.26 = zext i8 %call28.33.26 to i32
  %xor.33.26 = xor i32 %conv23.33.26, %conv29.33.26
  %scevgep35.33.26 = getelementptr i8, i8* %a, i64 60
  %10403 = load i8, i8* %scevgep35.33.26, align 1
  %10404 = load i8, i8* %arrayidx33.33, align 1
  %call34.33.26 = call zeroext i8 @mult(i8 zeroext %10403, i8 zeroext %10404)
  %conv35.33.26 = zext i8 %call34.33.26 to i32
  %xor36.33.26 = xor i32 %xor.33.26, %conv35.33.26
  %conv37.33.26 = trunc i32 %xor36.33.26 to i8
  store i8 %conv37.33.26, i8* %scevgep41.33.25, align 1
  %scevgep26.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10218, i64 0, i64 1, i64 1
  %10405 = bitcast i8* %scevgep26.33 to [61 x [61 x i8]]*
  %scevgep39.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10219, i64 0, i64 1, i64 1
  %10406 = bitcast i8* %scevgep39.33 to [61 x [61 x i8]]*
  %arrayidx25.34 = getelementptr inbounds i8, i8* %a, i64 34
  %arrayidx33.34 = getelementptr inbounds i8, i8* %b, i64 34
  %call16.34 = call zeroext i8 (...) @rand()
  store i8 %call16.34, i8* %scevgep26.33, align 1
  %10407 = load i8, i8* %scevgep26.33, align 1
  %conv23.34 = zext i8 %10407 to i32
  %10408 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34 = getelementptr i8, i8* %b, i64 35
  %10409 = load i8, i8* %scevgep34.34, align 1
  %call28.34 = call zeroext i8 @mult(i8 zeroext %10408, i8 zeroext %10409)
  %conv29.34 = zext i8 %call28.34 to i32
  %xor.34 = xor i32 %conv23.34, %conv29.34
  %scevgep35.34 = getelementptr i8, i8* %a, i64 35
  %10410 = load i8, i8* %scevgep35.34, align 1
  %10411 = load i8, i8* %arrayidx33.34, align 1
  %call34.34 = call zeroext i8 @mult(i8 zeroext %10410, i8 zeroext %10411)
  %conv35.34 = zext i8 %call34.34 to i32
  %xor36.34 = xor i32 %xor.34, %conv35.34
  %conv37.34 = trunc i32 %xor36.34 to i8
  store i8 %conv37.34, i8* %scevgep39.33, align 1
  %scevgep28.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10405, i64 0, i64 0, i64 1
  %10412 = bitcast i8* %scevgep28.34 to [61 x [61 x i8]]*
  %scevgep41.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10406, i64 0, i64 1, i64 0
  %10413 = bitcast i8* %scevgep41.34 to [61 x [61 x i8]]*
  %call16.34.1 = call zeroext i8 (...) @rand()
  store i8 %call16.34.1, i8* %scevgep28.34, align 1
  %10414 = load i8, i8* %scevgep28.34, align 1
  %conv23.34.1 = zext i8 %10414 to i32
  %10415 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.1 = getelementptr i8, i8* %b, i64 36
  %10416 = load i8, i8* %scevgep34.34.1, align 1
  %call28.34.1 = call zeroext i8 @mult(i8 zeroext %10415, i8 zeroext %10416)
  %conv29.34.1 = zext i8 %call28.34.1 to i32
  %xor.34.1 = xor i32 %conv23.34.1, %conv29.34.1
  %scevgep35.34.1 = getelementptr i8, i8* %a, i64 36
  %10417 = load i8, i8* %scevgep35.34.1, align 1
  %10418 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.1 = call zeroext i8 @mult(i8 zeroext %10417, i8 zeroext %10418)
  %conv35.34.1 = zext i8 %call34.34.1 to i32
  %xor36.34.1 = xor i32 %xor.34.1, %conv35.34.1
  %conv37.34.1 = trunc i32 %xor36.34.1 to i8
  store i8 %conv37.34.1, i8* %scevgep41.34, align 1
  %scevgep28.34.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10412, i64 0, i64 0, i64 1
  %10419 = bitcast i8* %scevgep28.34.1 to [61 x [61 x i8]]*
  %scevgep41.34.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10413, i64 0, i64 1, i64 0
  %10420 = bitcast i8* %scevgep41.34.1 to [61 x [61 x i8]]*
  %call16.34.2 = call zeroext i8 (...) @rand()
  store i8 %call16.34.2, i8* %scevgep28.34.1, align 1
  %10421 = load i8, i8* %scevgep28.34.1, align 1
  %conv23.34.2 = zext i8 %10421 to i32
  %10422 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.2 = getelementptr i8, i8* %b, i64 37
  %10423 = load i8, i8* %scevgep34.34.2, align 1
  %call28.34.2 = call zeroext i8 @mult(i8 zeroext %10422, i8 zeroext %10423)
  %conv29.34.2 = zext i8 %call28.34.2 to i32
  %xor.34.2 = xor i32 %conv23.34.2, %conv29.34.2
  %scevgep35.34.2 = getelementptr i8, i8* %a, i64 37
  %10424 = load i8, i8* %scevgep35.34.2, align 1
  %10425 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.2 = call zeroext i8 @mult(i8 zeroext %10424, i8 zeroext %10425)
  %conv35.34.2 = zext i8 %call34.34.2 to i32
  %xor36.34.2 = xor i32 %xor.34.2, %conv35.34.2
  %conv37.34.2 = trunc i32 %xor36.34.2 to i8
  store i8 %conv37.34.2, i8* %scevgep41.34.1, align 1
  %scevgep28.34.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10419, i64 0, i64 0, i64 1
  %10426 = bitcast i8* %scevgep28.34.2 to [61 x [61 x i8]]*
  %scevgep41.34.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10420, i64 0, i64 1, i64 0
  %10427 = bitcast i8* %scevgep41.34.2 to [61 x [61 x i8]]*
  %call16.34.3 = call zeroext i8 (...) @rand()
  store i8 %call16.34.3, i8* %scevgep28.34.2, align 1
  %10428 = load i8, i8* %scevgep28.34.2, align 1
  %conv23.34.3 = zext i8 %10428 to i32
  %10429 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.3 = getelementptr i8, i8* %b, i64 38
  %10430 = load i8, i8* %scevgep34.34.3, align 1
  %call28.34.3 = call zeroext i8 @mult(i8 zeroext %10429, i8 zeroext %10430)
  %conv29.34.3 = zext i8 %call28.34.3 to i32
  %xor.34.3 = xor i32 %conv23.34.3, %conv29.34.3
  %scevgep35.34.3 = getelementptr i8, i8* %a, i64 38
  %10431 = load i8, i8* %scevgep35.34.3, align 1
  %10432 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.3 = call zeroext i8 @mult(i8 zeroext %10431, i8 zeroext %10432)
  %conv35.34.3 = zext i8 %call34.34.3 to i32
  %xor36.34.3 = xor i32 %xor.34.3, %conv35.34.3
  %conv37.34.3 = trunc i32 %xor36.34.3 to i8
  store i8 %conv37.34.3, i8* %scevgep41.34.2, align 1
  %scevgep28.34.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10426, i64 0, i64 0, i64 1
  %10433 = bitcast i8* %scevgep28.34.3 to [61 x [61 x i8]]*
  %scevgep41.34.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10427, i64 0, i64 1, i64 0
  %10434 = bitcast i8* %scevgep41.34.3 to [61 x [61 x i8]]*
  %call16.34.4 = call zeroext i8 (...) @rand()
  store i8 %call16.34.4, i8* %scevgep28.34.3, align 1
  %10435 = load i8, i8* %scevgep28.34.3, align 1
  %conv23.34.4 = zext i8 %10435 to i32
  %10436 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.4 = getelementptr i8, i8* %b, i64 39
  %10437 = load i8, i8* %scevgep34.34.4, align 1
  %call28.34.4 = call zeroext i8 @mult(i8 zeroext %10436, i8 zeroext %10437)
  %conv29.34.4 = zext i8 %call28.34.4 to i32
  %xor.34.4 = xor i32 %conv23.34.4, %conv29.34.4
  %scevgep35.34.4 = getelementptr i8, i8* %a, i64 39
  %10438 = load i8, i8* %scevgep35.34.4, align 1
  %10439 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.4 = call zeroext i8 @mult(i8 zeroext %10438, i8 zeroext %10439)
  %conv35.34.4 = zext i8 %call34.34.4 to i32
  %xor36.34.4 = xor i32 %xor.34.4, %conv35.34.4
  %conv37.34.4 = trunc i32 %xor36.34.4 to i8
  store i8 %conv37.34.4, i8* %scevgep41.34.3, align 1
  %scevgep28.34.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10433, i64 0, i64 0, i64 1
  %10440 = bitcast i8* %scevgep28.34.4 to [61 x [61 x i8]]*
  %scevgep41.34.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10434, i64 0, i64 1, i64 0
  %10441 = bitcast i8* %scevgep41.34.4 to [61 x [61 x i8]]*
  %call16.34.5 = call zeroext i8 (...) @rand()
  store i8 %call16.34.5, i8* %scevgep28.34.4, align 1
  %10442 = load i8, i8* %scevgep28.34.4, align 1
  %conv23.34.5 = zext i8 %10442 to i32
  %10443 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.5 = getelementptr i8, i8* %b, i64 40
  %10444 = load i8, i8* %scevgep34.34.5, align 1
  %call28.34.5 = call zeroext i8 @mult(i8 zeroext %10443, i8 zeroext %10444)
  %conv29.34.5 = zext i8 %call28.34.5 to i32
  %xor.34.5 = xor i32 %conv23.34.5, %conv29.34.5
  %scevgep35.34.5 = getelementptr i8, i8* %a, i64 40
  %10445 = load i8, i8* %scevgep35.34.5, align 1
  %10446 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.5 = call zeroext i8 @mult(i8 zeroext %10445, i8 zeroext %10446)
  %conv35.34.5 = zext i8 %call34.34.5 to i32
  %xor36.34.5 = xor i32 %xor.34.5, %conv35.34.5
  %conv37.34.5 = trunc i32 %xor36.34.5 to i8
  store i8 %conv37.34.5, i8* %scevgep41.34.4, align 1
  %scevgep28.34.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10440, i64 0, i64 0, i64 1
  %10447 = bitcast i8* %scevgep28.34.5 to [61 x [61 x i8]]*
  %scevgep41.34.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10441, i64 0, i64 1, i64 0
  %10448 = bitcast i8* %scevgep41.34.5 to [61 x [61 x i8]]*
  %call16.34.6 = call zeroext i8 (...) @rand()
  store i8 %call16.34.6, i8* %scevgep28.34.5, align 1
  %10449 = load i8, i8* %scevgep28.34.5, align 1
  %conv23.34.6 = zext i8 %10449 to i32
  %10450 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.6 = getelementptr i8, i8* %b, i64 41
  %10451 = load i8, i8* %scevgep34.34.6, align 1
  %call28.34.6 = call zeroext i8 @mult(i8 zeroext %10450, i8 zeroext %10451)
  %conv29.34.6 = zext i8 %call28.34.6 to i32
  %xor.34.6 = xor i32 %conv23.34.6, %conv29.34.6
  %scevgep35.34.6 = getelementptr i8, i8* %a, i64 41
  %10452 = load i8, i8* %scevgep35.34.6, align 1
  %10453 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.6 = call zeroext i8 @mult(i8 zeroext %10452, i8 zeroext %10453)
  %conv35.34.6 = zext i8 %call34.34.6 to i32
  %xor36.34.6 = xor i32 %xor.34.6, %conv35.34.6
  %conv37.34.6 = trunc i32 %xor36.34.6 to i8
  store i8 %conv37.34.6, i8* %scevgep41.34.5, align 1
  %scevgep28.34.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10447, i64 0, i64 0, i64 1
  %10454 = bitcast i8* %scevgep28.34.6 to [61 x [61 x i8]]*
  %scevgep41.34.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10448, i64 0, i64 1, i64 0
  %10455 = bitcast i8* %scevgep41.34.6 to [61 x [61 x i8]]*
  %call16.34.7 = call zeroext i8 (...) @rand()
  store i8 %call16.34.7, i8* %scevgep28.34.6, align 1
  %10456 = load i8, i8* %scevgep28.34.6, align 1
  %conv23.34.7 = zext i8 %10456 to i32
  %10457 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.7 = getelementptr i8, i8* %b, i64 42
  %10458 = load i8, i8* %scevgep34.34.7, align 1
  %call28.34.7 = call zeroext i8 @mult(i8 zeroext %10457, i8 zeroext %10458)
  %conv29.34.7 = zext i8 %call28.34.7 to i32
  %xor.34.7 = xor i32 %conv23.34.7, %conv29.34.7
  %scevgep35.34.7 = getelementptr i8, i8* %a, i64 42
  %10459 = load i8, i8* %scevgep35.34.7, align 1
  %10460 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.7 = call zeroext i8 @mult(i8 zeroext %10459, i8 zeroext %10460)
  %conv35.34.7 = zext i8 %call34.34.7 to i32
  %xor36.34.7 = xor i32 %xor.34.7, %conv35.34.7
  %conv37.34.7 = trunc i32 %xor36.34.7 to i8
  store i8 %conv37.34.7, i8* %scevgep41.34.6, align 1
  %scevgep28.34.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10454, i64 0, i64 0, i64 1
  %10461 = bitcast i8* %scevgep28.34.7 to [61 x [61 x i8]]*
  %scevgep41.34.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10455, i64 0, i64 1, i64 0
  %10462 = bitcast i8* %scevgep41.34.7 to [61 x [61 x i8]]*
  %call16.34.8 = call zeroext i8 (...) @rand()
  store i8 %call16.34.8, i8* %scevgep28.34.7, align 1
  %10463 = load i8, i8* %scevgep28.34.7, align 1
  %conv23.34.8 = zext i8 %10463 to i32
  %10464 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.8 = getelementptr i8, i8* %b, i64 43
  %10465 = load i8, i8* %scevgep34.34.8, align 1
  %call28.34.8 = call zeroext i8 @mult(i8 zeroext %10464, i8 zeroext %10465)
  %conv29.34.8 = zext i8 %call28.34.8 to i32
  %xor.34.8 = xor i32 %conv23.34.8, %conv29.34.8
  %scevgep35.34.8 = getelementptr i8, i8* %a, i64 43
  %10466 = load i8, i8* %scevgep35.34.8, align 1
  %10467 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.8 = call zeroext i8 @mult(i8 zeroext %10466, i8 zeroext %10467)
  %conv35.34.8 = zext i8 %call34.34.8 to i32
  %xor36.34.8 = xor i32 %xor.34.8, %conv35.34.8
  %conv37.34.8 = trunc i32 %xor36.34.8 to i8
  store i8 %conv37.34.8, i8* %scevgep41.34.7, align 1
  %scevgep28.34.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10461, i64 0, i64 0, i64 1
  %10468 = bitcast i8* %scevgep28.34.8 to [61 x [61 x i8]]*
  %scevgep41.34.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10462, i64 0, i64 1, i64 0
  %10469 = bitcast i8* %scevgep41.34.8 to [61 x [61 x i8]]*
  %call16.34.9 = call zeroext i8 (...) @rand()
  store i8 %call16.34.9, i8* %scevgep28.34.8, align 1
  %10470 = load i8, i8* %scevgep28.34.8, align 1
  %conv23.34.9 = zext i8 %10470 to i32
  %10471 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.9 = getelementptr i8, i8* %b, i64 44
  %10472 = load i8, i8* %scevgep34.34.9, align 1
  %call28.34.9 = call zeroext i8 @mult(i8 zeroext %10471, i8 zeroext %10472)
  %conv29.34.9 = zext i8 %call28.34.9 to i32
  %xor.34.9 = xor i32 %conv23.34.9, %conv29.34.9
  %scevgep35.34.9 = getelementptr i8, i8* %a, i64 44
  %10473 = load i8, i8* %scevgep35.34.9, align 1
  %10474 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.9 = call zeroext i8 @mult(i8 zeroext %10473, i8 zeroext %10474)
  %conv35.34.9 = zext i8 %call34.34.9 to i32
  %xor36.34.9 = xor i32 %xor.34.9, %conv35.34.9
  %conv37.34.9 = trunc i32 %xor36.34.9 to i8
  store i8 %conv37.34.9, i8* %scevgep41.34.8, align 1
  %scevgep28.34.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10468, i64 0, i64 0, i64 1
  %10475 = bitcast i8* %scevgep28.34.9 to [61 x [61 x i8]]*
  %scevgep41.34.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10469, i64 0, i64 1, i64 0
  %10476 = bitcast i8* %scevgep41.34.9 to [61 x [61 x i8]]*
  %call16.34.10 = call zeroext i8 (...) @rand()
  store i8 %call16.34.10, i8* %scevgep28.34.9, align 1
  %10477 = load i8, i8* %scevgep28.34.9, align 1
  %conv23.34.10 = zext i8 %10477 to i32
  %10478 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.10 = getelementptr i8, i8* %b, i64 45
  %10479 = load i8, i8* %scevgep34.34.10, align 1
  %call28.34.10 = call zeroext i8 @mult(i8 zeroext %10478, i8 zeroext %10479)
  %conv29.34.10 = zext i8 %call28.34.10 to i32
  %xor.34.10 = xor i32 %conv23.34.10, %conv29.34.10
  %scevgep35.34.10 = getelementptr i8, i8* %a, i64 45
  %10480 = load i8, i8* %scevgep35.34.10, align 1
  %10481 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.10 = call zeroext i8 @mult(i8 zeroext %10480, i8 zeroext %10481)
  %conv35.34.10 = zext i8 %call34.34.10 to i32
  %xor36.34.10 = xor i32 %xor.34.10, %conv35.34.10
  %conv37.34.10 = trunc i32 %xor36.34.10 to i8
  store i8 %conv37.34.10, i8* %scevgep41.34.9, align 1
  %scevgep28.34.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10475, i64 0, i64 0, i64 1
  %10482 = bitcast i8* %scevgep28.34.10 to [61 x [61 x i8]]*
  %scevgep41.34.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10476, i64 0, i64 1, i64 0
  %10483 = bitcast i8* %scevgep41.34.10 to [61 x [61 x i8]]*
  %call16.34.11 = call zeroext i8 (...) @rand()
  store i8 %call16.34.11, i8* %scevgep28.34.10, align 1
  %10484 = load i8, i8* %scevgep28.34.10, align 1
  %conv23.34.11 = zext i8 %10484 to i32
  %10485 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.11 = getelementptr i8, i8* %b, i64 46
  %10486 = load i8, i8* %scevgep34.34.11, align 1
  %call28.34.11 = call zeroext i8 @mult(i8 zeroext %10485, i8 zeroext %10486)
  %conv29.34.11 = zext i8 %call28.34.11 to i32
  %xor.34.11 = xor i32 %conv23.34.11, %conv29.34.11
  %scevgep35.34.11 = getelementptr i8, i8* %a, i64 46
  %10487 = load i8, i8* %scevgep35.34.11, align 1
  %10488 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.11 = call zeroext i8 @mult(i8 zeroext %10487, i8 zeroext %10488)
  %conv35.34.11 = zext i8 %call34.34.11 to i32
  %xor36.34.11 = xor i32 %xor.34.11, %conv35.34.11
  %conv37.34.11 = trunc i32 %xor36.34.11 to i8
  store i8 %conv37.34.11, i8* %scevgep41.34.10, align 1
  %scevgep28.34.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10482, i64 0, i64 0, i64 1
  %10489 = bitcast i8* %scevgep28.34.11 to [61 x [61 x i8]]*
  %scevgep41.34.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10483, i64 0, i64 1, i64 0
  %10490 = bitcast i8* %scevgep41.34.11 to [61 x [61 x i8]]*
  %call16.34.12 = call zeroext i8 (...) @rand()
  store i8 %call16.34.12, i8* %scevgep28.34.11, align 1
  %10491 = load i8, i8* %scevgep28.34.11, align 1
  %conv23.34.12 = zext i8 %10491 to i32
  %10492 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.12 = getelementptr i8, i8* %b, i64 47
  %10493 = load i8, i8* %scevgep34.34.12, align 1
  %call28.34.12 = call zeroext i8 @mult(i8 zeroext %10492, i8 zeroext %10493)
  %conv29.34.12 = zext i8 %call28.34.12 to i32
  %xor.34.12 = xor i32 %conv23.34.12, %conv29.34.12
  %scevgep35.34.12 = getelementptr i8, i8* %a, i64 47
  %10494 = load i8, i8* %scevgep35.34.12, align 1
  %10495 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.12 = call zeroext i8 @mult(i8 zeroext %10494, i8 zeroext %10495)
  %conv35.34.12 = zext i8 %call34.34.12 to i32
  %xor36.34.12 = xor i32 %xor.34.12, %conv35.34.12
  %conv37.34.12 = trunc i32 %xor36.34.12 to i8
  store i8 %conv37.34.12, i8* %scevgep41.34.11, align 1
  %scevgep28.34.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10489, i64 0, i64 0, i64 1
  %10496 = bitcast i8* %scevgep28.34.12 to [61 x [61 x i8]]*
  %scevgep41.34.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10490, i64 0, i64 1, i64 0
  %10497 = bitcast i8* %scevgep41.34.12 to [61 x [61 x i8]]*
  %call16.34.13 = call zeroext i8 (...) @rand()
  store i8 %call16.34.13, i8* %scevgep28.34.12, align 1
  %10498 = load i8, i8* %scevgep28.34.12, align 1
  %conv23.34.13 = zext i8 %10498 to i32
  %10499 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.13 = getelementptr i8, i8* %b, i64 48
  %10500 = load i8, i8* %scevgep34.34.13, align 1
  %call28.34.13 = call zeroext i8 @mult(i8 zeroext %10499, i8 zeroext %10500)
  %conv29.34.13 = zext i8 %call28.34.13 to i32
  %xor.34.13 = xor i32 %conv23.34.13, %conv29.34.13
  %scevgep35.34.13 = getelementptr i8, i8* %a, i64 48
  %10501 = load i8, i8* %scevgep35.34.13, align 1
  %10502 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.13 = call zeroext i8 @mult(i8 zeroext %10501, i8 zeroext %10502)
  %conv35.34.13 = zext i8 %call34.34.13 to i32
  %xor36.34.13 = xor i32 %xor.34.13, %conv35.34.13
  %conv37.34.13 = trunc i32 %xor36.34.13 to i8
  store i8 %conv37.34.13, i8* %scevgep41.34.12, align 1
  %scevgep28.34.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10496, i64 0, i64 0, i64 1
  %10503 = bitcast i8* %scevgep28.34.13 to [61 x [61 x i8]]*
  %scevgep41.34.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10497, i64 0, i64 1, i64 0
  %10504 = bitcast i8* %scevgep41.34.13 to [61 x [61 x i8]]*
  %call16.34.14 = call zeroext i8 (...) @rand()
  store i8 %call16.34.14, i8* %scevgep28.34.13, align 1
  %10505 = load i8, i8* %scevgep28.34.13, align 1
  %conv23.34.14 = zext i8 %10505 to i32
  %10506 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.14 = getelementptr i8, i8* %b, i64 49
  %10507 = load i8, i8* %scevgep34.34.14, align 1
  %call28.34.14 = call zeroext i8 @mult(i8 zeroext %10506, i8 zeroext %10507)
  %conv29.34.14 = zext i8 %call28.34.14 to i32
  %xor.34.14 = xor i32 %conv23.34.14, %conv29.34.14
  %scevgep35.34.14 = getelementptr i8, i8* %a, i64 49
  %10508 = load i8, i8* %scevgep35.34.14, align 1
  %10509 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.14 = call zeroext i8 @mult(i8 zeroext %10508, i8 zeroext %10509)
  %conv35.34.14 = zext i8 %call34.34.14 to i32
  %xor36.34.14 = xor i32 %xor.34.14, %conv35.34.14
  %conv37.34.14 = trunc i32 %xor36.34.14 to i8
  store i8 %conv37.34.14, i8* %scevgep41.34.13, align 1
  %scevgep28.34.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10503, i64 0, i64 0, i64 1
  %10510 = bitcast i8* %scevgep28.34.14 to [61 x [61 x i8]]*
  %scevgep41.34.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10504, i64 0, i64 1, i64 0
  %10511 = bitcast i8* %scevgep41.34.14 to [61 x [61 x i8]]*
  %call16.34.15 = call zeroext i8 (...) @rand()
  store i8 %call16.34.15, i8* %scevgep28.34.14, align 1
  %10512 = load i8, i8* %scevgep28.34.14, align 1
  %conv23.34.15 = zext i8 %10512 to i32
  %10513 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.15 = getelementptr i8, i8* %b, i64 50
  %10514 = load i8, i8* %scevgep34.34.15, align 1
  %call28.34.15 = call zeroext i8 @mult(i8 zeroext %10513, i8 zeroext %10514)
  %conv29.34.15 = zext i8 %call28.34.15 to i32
  %xor.34.15 = xor i32 %conv23.34.15, %conv29.34.15
  %scevgep35.34.15 = getelementptr i8, i8* %a, i64 50
  %10515 = load i8, i8* %scevgep35.34.15, align 1
  %10516 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.15 = call zeroext i8 @mult(i8 zeroext %10515, i8 zeroext %10516)
  %conv35.34.15 = zext i8 %call34.34.15 to i32
  %xor36.34.15 = xor i32 %xor.34.15, %conv35.34.15
  %conv37.34.15 = trunc i32 %xor36.34.15 to i8
  store i8 %conv37.34.15, i8* %scevgep41.34.14, align 1
  %scevgep28.34.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10510, i64 0, i64 0, i64 1
  %10517 = bitcast i8* %scevgep28.34.15 to [61 x [61 x i8]]*
  %scevgep41.34.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10511, i64 0, i64 1, i64 0
  %10518 = bitcast i8* %scevgep41.34.15 to [61 x [61 x i8]]*
  %call16.34.16 = call zeroext i8 (...) @rand()
  store i8 %call16.34.16, i8* %scevgep28.34.15, align 1
  %10519 = load i8, i8* %scevgep28.34.15, align 1
  %conv23.34.16 = zext i8 %10519 to i32
  %10520 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.16 = getelementptr i8, i8* %b, i64 51
  %10521 = load i8, i8* %scevgep34.34.16, align 1
  %call28.34.16 = call zeroext i8 @mult(i8 zeroext %10520, i8 zeroext %10521)
  %conv29.34.16 = zext i8 %call28.34.16 to i32
  %xor.34.16 = xor i32 %conv23.34.16, %conv29.34.16
  %scevgep35.34.16 = getelementptr i8, i8* %a, i64 51
  %10522 = load i8, i8* %scevgep35.34.16, align 1
  %10523 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.16 = call zeroext i8 @mult(i8 zeroext %10522, i8 zeroext %10523)
  %conv35.34.16 = zext i8 %call34.34.16 to i32
  %xor36.34.16 = xor i32 %xor.34.16, %conv35.34.16
  %conv37.34.16 = trunc i32 %xor36.34.16 to i8
  store i8 %conv37.34.16, i8* %scevgep41.34.15, align 1
  %scevgep28.34.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10517, i64 0, i64 0, i64 1
  %10524 = bitcast i8* %scevgep28.34.16 to [61 x [61 x i8]]*
  %scevgep41.34.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10518, i64 0, i64 1, i64 0
  %10525 = bitcast i8* %scevgep41.34.16 to [61 x [61 x i8]]*
  %call16.34.17 = call zeroext i8 (...) @rand()
  store i8 %call16.34.17, i8* %scevgep28.34.16, align 1
  %10526 = load i8, i8* %scevgep28.34.16, align 1
  %conv23.34.17 = zext i8 %10526 to i32
  %10527 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.17 = getelementptr i8, i8* %b, i64 52
  %10528 = load i8, i8* %scevgep34.34.17, align 1
  %call28.34.17 = call zeroext i8 @mult(i8 zeroext %10527, i8 zeroext %10528)
  %conv29.34.17 = zext i8 %call28.34.17 to i32
  %xor.34.17 = xor i32 %conv23.34.17, %conv29.34.17
  %scevgep35.34.17 = getelementptr i8, i8* %a, i64 52
  %10529 = load i8, i8* %scevgep35.34.17, align 1
  %10530 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.17 = call zeroext i8 @mult(i8 zeroext %10529, i8 zeroext %10530)
  %conv35.34.17 = zext i8 %call34.34.17 to i32
  %xor36.34.17 = xor i32 %xor.34.17, %conv35.34.17
  %conv37.34.17 = trunc i32 %xor36.34.17 to i8
  store i8 %conv37.34.17, i8* %scevgep41.34.16, align 1
  %scevgep28.34.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10524, i64 0, i64 0, i64 1
  %10531 = bitcast i8* %scevgep28.34.17 to [61 x [61 x i8]]*
  %scevgep41.34.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10525, i64 0, i64 1, i64 0
  %10532 = bitcast i8* %scevgep41.34.17 to [61 x [61 x i8]]*
  %call16.34.18 = call zeroext i8 (...) @rand()
  store i8 %call16.34.18, i8* %scevgep28.34.17, align 1
  %10533 = load i8, i8* %scevgep28.34.17, align 1
  %conv23.34.18 = zext i8 %10533 to i32
  %10534 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.18 = getelementptr i8, i8* %b, i64 53
  %10535 = load i8, i8* %scevgep34.34.18, align 1
  %call28.34.18 = call zeroext i8 @mult(i8 zeroext %10534, i8 zeroext %10535)
  %conv29.34.18 = zext i8 %call28.34.18 to i32
  %xor.34.18 = xor i32 %conv23.34.18, %conv29.34.18
  %scevgep35.34.18 = getelementptr i8, i8* %a, i64 53
  %10536 = load i8, i8* %scevgep35.34.18, align 1
  %10537 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.18 = call zeroext i8 @mult(i8 zeroext %10536, i8 zeroext %10537)
  %conv35.34.18 = zext i8 %call34.34.18 to i32
  %xor36.34.18 = xor i32 %xor.34.18, %conv35.34.18
  %conv37.34.18 = trunc i32 %xor36.34.18 to i8
  store i8 %conv37.34.18, i8* %scevgep41.34.17, align 1
  %scevgep28.34.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10531, i64 0, i64 0, i64 1
  %10538 = bitcast i8* %scevgep28.34.18 to [61 x [61 x i8]]*
  %scevgep41.34.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10532, i64 0, i64 1, i64 0
  %10539 = bitcast i8* %scevgep41.34.18 to [61 x [61 x i8]]*
  %call16.34.19 = call zeroext i8 (...) @rand()
  store i8 %call16.34.19, i8* %scevgep28.34.18, align 1
  %10540 = load i8, i8* %scevgep28.34.18, align 1
  %conv23.34.19 = zext i8 %10540 to i32
  %10541 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.19 = getelementptr i8, i8* %b, i64 54
  %10542 = load i8, i8* %scevgep34.34.19, align 1
  %call28.34.19 = call zeroext i8 @mult(i8 zeroext %10541, i8 zeroext %10542)
  %conv29.34.19 = zext i8 %call28.34.19 to i32
  %xor.34.19 = xor i32 %conv23.34.19, %conv29.34.19
  %scevgep35.34.19 = getelementptr i8, i8* %a, i64 54
  %10543 = load i8, i8* %scevgep35.34.19, align 1
  %10544 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.19 = call zeroext i8 @mult(i8 zeroext %10543, i8 zeroext %10544)
  %conv35.34.19 = zext i8 %call34.34.19 to i32
  %xor36.34.19 = xor i32 %xor.34.19, %conv35.34.19
  %conv37.34.19 = trunc i32 %xor36.34.19 to i8
  store i8 %conv37.34.19, i8* %scevgep41.34.18, align 1
  %scevgep28.34.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10538, i64 0, i64 0, i64 1
  %10545 = bitcast i8* %scevgep28.34.19 to [61 x [61 x i8]]*
  %scevgep41.34.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10539, i64 0, i64 1, i64 0
  %10546 = bitcast i8* %scevgep41.34.19 to [61 x [61 x i8]]*
  %call16.34.20 = call zeroext i8 (...) @rand()
  store i8 %call16.34.20, i8* %scevgep28.34.19, align 1
  %10547 = load i8, i8* %scevgep28.34.19, align 1
  %conv23.34.20 = zext i8 %10547 to i32
  %10548 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.20 = getelementptr i8, i8* %b, i64 55
  %10549 = load i8, i8* %scevgep34.34.20, align 1
  %call28.34.20 = call zeroext i8 @mult(i8 zeroext %10548, i8 zeroext %10549)
  %conv29.34.20 = zext i8 %call28.34.20 to i32
  %xor.34.20 = xor i32 %conv23.34.20, %conv29.34.20
  %scevgep35.34.20 = getelementptr i8, i8* %a, i64 55
  %10550 = load i8, i8* %scevgep35.34.20, align 1
  %10551 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.20 = call zeroext i8 @mult(i8 zeroext %10550, i8 zeroext %10551)
  %conv35.34.20 = zext i8 %call34.34.20 to i32
  %xor36.34.20 = xor i32 %xor.34.20, %conv35.34.20
  %conv37.34.20 = trunc i32 %xor36.34.20 to i8
  store i8 %conv37.34.20, i8* %scevgep41.34.19, align 1
  %scevgep28.34.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10545, i64 0, i64 0, i64 1
  %10552 = bitcast i8* %scevgep28.34.20 to [61 x [61 x i8]]*
  %scevgep41.34.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10546, i64 0, i64 1, i64 0
  %10553 = bitcast i8* %scevgep41.34.20 to [61 x [61 x i8]]*
  %call16.34.21 = call zeroext i8 (...) @rand()
  store i8 %call16.34.21, i8* %scevgep28.34.20, align 1
  %10554 = load i8, i8* %scevgep28.34.20, align 1
  %conv23.34.21 = zext i8 %10554 to i32
  %10555 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.21 = getelementptr i8, i8* %b, i64 56
  %10556 = load i8, i8* %scevgep34.34.21, align 1
  %call28.34.21 = call zeroext i8 @mult(i8 zeroext %10555, i8 zeroext %10556)
  %conv29.34.21 = zext i8 %call28.34.21 to i32
  %xor.34.21 = xor i32 %conv23.34.21, %conv29.34.21
  %scevgep35.34.21 = getelementptr i8, i8* %a, i64 56
  %10557 = load i8, i8* %scevgep35.34.21, align 1
  %10558 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.21 = call zeroext i8 @mult(i8 zeroext %10557, i8 zeroext %10558)
  %conv35.34.21 = zext i8 %call34.34.21 to i32
  %xor36.34.21 = xor i32 %xor.34.21, %conv35.34.21
  %conv37.34.21 = trunc i32 %xor36.34.21 to i8
  store i8 %conv37.34.21, i8* %scevgep41.34.20, align 1
  %scevgep28.34.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10552, i64 0, i64 0, i64 1
  %10559 = bitcast i8* %scevgep28.34.21 to [61 x [61 x i8]]*
  %scevgep41.34.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10553, i64 0, i64 1, i64 0
  %10560 = bitcast i8* %scevgep41.34.21 to [61 x [61 x i8]]*
  %call16.34.22 = call zeroext i8 (...) @rand()
  store i8 %call16.34.22, i8* %scevgep28.34.21, align 1
  %10561 = load i8, i8* %scevgep28.34.21, align 1
  %conv23.34.22 = zext i8 %10561 to i32
  %10562 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.22 = getelementptr i8, i8* %b, i64 57
  %10563 = load i8, i8* %scevgep34.34.22, align 1
  %call28.34.22 = call zeroext i8 @mult(i8 zeroext %10562, i8 zeroext %10563)
  %conv29.34.22 = zext i8 %call28.34.22 to i32
  %xor.34.22 = xor i32 %conv23.34.22, %conv29.34.22
  %scevgep35.34.22 = getelementptr i8, i8* %a, i64 57
  %10564 = load i8, i8* %scevgep35.34.22, align 1
  %10565 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.22 = call zeroext i8 @mult(i8 zeroext %10564, i8 zeroext %10565)
  %conv35.34.22 = zext i8 %call34.34.22 to i32
  %xor36.34.22 = xor i32 %xor.34.22, %conv35.34.22
  %conv37.34.22 = trunc i32 %xor36.34.22 to i8
  store i8 %conv37.34.22, i8* %scevgep41.34.21, align 1
  %scevgep28.34.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10559, i64 0, i64 0, i64 1
  %10566 = bitcast i8* %scevgep28.34.22 to [61 x [61 x i8]]*
  %scevgep41.34.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10560, i64 0, i64 1, i64 0
  %10567 = bitcast i8* %scevgep41.34.22 to [61 x [61 x i8]]*
  %call16.34.23 = call zeroext i8 (...) @rand()
  store i8 %call16.34.23, i8* %scevgep28.34.22, align 1
  %10568 = load i8, i8* %scevgep28.34.22, align 1
  %conv23.34.23 = zext i8 %10568 to i32
  %10569 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.23 = getelementptr i8, i8* %b, i64 58
  %10570 = load i8, i8* %scevgep34.34.23, align 1
  %call28.34.23 = call zeroext i8 @mult(i8 zeroext %10569, i8 zeroext %10570)
  %conv29.34.23 = zext i8 %call28.34.23 to i32
  %xor.34.23 = xor i32 %conv23.34.23, %conv29.34.23
  %scevgep35.34.23 = getelementptr i8, i8* %a, i64 58
  %10571 = load i8, i8* %scevgep35.34.23, align 1
  %10572 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.23 = call zeroext i8 @mult(i8 zeroext %10571, i8 zeroext %10572)
  %conv35.34.23 = zext i8 %call34.34.23 to i32
  %xor36.34.23 = xor i32 %xor.34.23, %conv35.34.23
  %conv37.34.23 = trunc i32 %xor36.34.23 to i8
  store i8 %conv37.34.23, i8* %scevgep41.34.22, align 1
  %scevgep28.34.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10566, i64 0, i64 0, i64 1
  %10573 = bitcast i8* %scevgep28.34.23 to [61 x [61 x i8]]*
  %scevgep41.34.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10567, i64 0, i64 1, i64 0
  %10574 = bitcast i8* %scevgep41.34.23 to [61 x [61 x i8]]*
  %call16.34.24 = call zeroext i8 (...) @rand()
  store i8 %call16.34.24, i8* %scevgep28.34.23, align 1
  %10575 = load i8, i8* %scevgep28.34.23, align 1
  %conv23.34.24 = zext i8 %10575 to i32
  %10576 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.24 = getelementptr i8, i8* %b, i64 59
  %10577 = load i8, i8* %scevgep34.34.24, align 1
  %call28.34.24 = call zeroext i8 @mult(i8 zeroext %10576, i8 zeroext %10577)
  %conv29.34.24 = zext i8 %call28.34.24 to i32
  %xor.34.24 = xor i32 %conv23.34.24, %conv29.34.24
  %scevgep35.34.24 = getelementptr i8, i8* %a, i64 59
  %10578 = load i8, i8* %scevgep35.34.24, align 1
  %10579 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.24 = call zeroext i8 @mult(i8 zeroext %10578, i8 zeroext %10579)
  %conv35.34.24 = zext i8 %call34.34.24 to i32
  %xor36.34.24 = xor i32 %xor.34.24, %conv35.34.24
  %conv37.34.24 = trunc i32 %xor36.34.24 to i8
  store i8 %conv37.34.24, i8* %scevgep41.34.23, align 1
  %scevgep28.34.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10573, i64 0, i64 0, i64 1
  %scevgep41.34.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10574, i64 0, i64 1, i64 0
  %call16.34.25 = call zeroext i8 (...) @rand()
  store i8 %call16.34.25, i8* %scevgep28.34.24, align 1
  %10580 = load i8, i8* %scevgep28.34.24, align 1
  %conv23.34.25 = zext i8 %10580 to i32
  %10581 = load i8, i8* %arrayidx25.34, align 1
  %scevgep34.34.25 = getelementptr i8, i8* %b, i64 60
  %10582 = load i8, i8* %scevgep34.34.25, align 1
  %call28.34.25 = call zeroext i8 @mult(i8 zeroext %10581, i8 zeroext %10582)
  %conv29.34.25 = zext i8 %call28.34.25 to i32
  %xor.34.25 = xor i32 %conv23.34.25, %conv29.34.25
  %scevgep35.34.25 = getelementptr i8, i8* %a, i64 60
  %10583 = load i8, i8* %scevgep35.34.25, align 1
  %10584 = load i8, i8* %arrayidx33.34, align 1
  %call34.34.25 = call zeroext i8 @mult(i8 zeroext %10583, i8 zeroext %10584)
  %conv35.34.25 = zext i8 %call34.34.25 to i32
  %xor36.34.25 = xor i32 %xor.34.25, %conv35.34.25
  %conv37.34.25 = trunc i32 %xor36.34.25 to i8
  store i8 %conv37.34.25, i8* %scevgep41.34.24, align 1
  %scevgep26.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10405, i64 0, i64 1, i64 1
  %10585 = bitcast i8* %scevgep26.34 to [61 x [61 x i8]]*
  %scevgep39.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10406, i64 0, i64 1, i64 1
  %10586 = bitcast i8* %scevgep39.34 to [61 x [61 x i8]]*
  %arrayidx25.35 = getelementptr inbounds i8, i8* %a, i64 35
  %arrayidx33.35 = getelementptr inbounds i8, i8* %b, i64 35
  %call16.35 = call zeroext i8 (...) @rand()
  store i8 %call16.35, i8* %scevgep26.34, align 1
  %10587 = load i8, i8* %scevgep26.34, align 1
  %conv23.35 = zext i8 %10587 to i32
  %10588 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35 = getelementptr i8, i8* %b, i64 36
  %10589 = load i8, i8* %scevgep34.35, align 1
  %call28.35 = call zeroext i8 @mult(i8 zeroext %10588, i8 zeroext %10589)
  %conv29.35 = zext i8 %call28.35 to i32
  %xor.35 = xor i32 %conv23.35, %conv29.35
  %scevgep35.35 = getelementptr i8, i8* %a, i64 36
  %10590 = load i8, i8* %scevgep35.35, align 1
  %10591 = load i8, i8* %arrayidx33.35, align 1
  %call34.35 = call zeroext i8 @mult(i8 zeroext %10590, i8 zeroext %10591)
  %conv35.35 = zext i8 %call34.35 to i32
  %xor36.35 = xor i32 %xor.35, %conv35.35
  %conv37.35 = trunc i32 %xor36.35 to i8
  store i8 %conv37.35, i8* %scevgep39.34, align 1
  %scevgep28.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10585, i64 0, i64 0, i64 1
  %10592 = bitcast i8* %scevgep28.35 to [61 x [61 x i8]]*
  %scevgep41.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10586, i64 0, i64 1, i64 0
  %10593 = bitcast i8* %scevgep41.35 to [61 x [61 x i8]]*
  %call16.35.1 = call zeroext i8 (...) @rand()
  store i8 %call16.35.1, i8* %scevgep28.35, align 1
  %10594 = load i8, i8* %scevgep28.35, align 1
  %conv23.35.1 = zext i8 %10594 to i32
  %10595 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.1 = getelementptr i8, i8* %b, i64 37
  %10596 = load i8, i8* %scevgep34.35.1, align 1
  %call28.35.1 = call zeroext i8 @mult(i8 zeroext %10595, i8 zeroext %10596)
  %conv29.35.1 = zext i8 %call28.35.1 to i32
  %xor.35.1 = xor i32 %conv23.35.1, %conv29.35.1
  %scevgep35.35.1 = getelementptr i8, i8* %a, i64 37
  %10597 = load i8, i8* %scevgep35.35.1, align 1
  %10598 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.1 = call zeroext i8 @mult(i8 zeroext %10597, i8 zeroext %10598)
  %conv35.35.1 = zext i8 %call34.35.1 to i32
  %xor36.35.1 = xor i32 %xor.35.1, %conv35.35.1
  %conv37.35.1 = trunc i32 %xor36.35.1 to i8
  store i8 %conv37.35.1, i8* %scevgep41.35, align 1
  %scevgep28.35.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10592, i64 0, i64 0, i64 1
  %10599 = bitcast i8* %scevgep28.35.1 to [61 x [61 x i8]]*
  %scevgep41.35.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10593, i64 0, i64 1, i64 0
  %10600 = bitcast i8* %scevgep41.35.1 to [61 x [61 x i8]]*
  %call16.35.2 = call zeroext i8 (...) @rand()
  store i8 %call16.35.2, i8* %scevgep28.35.1, align 1
  %10601 = load i8, i8* %scevgep28.35.1, align 1
  %conv23.35.2 = zext i8 %10601 to i32
  %10602 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.2 = getelementptr i8, i8* %b, i64 38
  %10603 = load i8, i8* %scevgep34.35.2, align 1
  %call28.35.2 = call zeroext i8 @mult(i8 zeroext %10602, i8 zeroext %10603)
  %conv29.35.2 = zext i8 %call28.35.2 to i32
  %xor.35.2 = xor i32 %conv23.35.2, %conv29.35.2
  %scevgep35.35.2 = getelementptr i8, i8* %a, i64 38
  %10604 = load i8, i8* %scevgep35.35.2, align 1
  %10605 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.2 = call zeroext i8 @mult(i8 zeroext %10604, i8 zeroext %10605)
  %conv35.35.2 = zext i8 %call34.35.2 to i32
  %xor36.35.2 = xor i32 %xor.35.2, %conv35.35.2
  %conv37.35.2 = trunc i32 %xor36.35.2 to i8
  store i8 %conv37.35.2, i8* %scevgep41.35.1, align 1
  %scevgep28.35.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10599, i64 0, i64 0, i64 1
  %10606 = bitcast i8* %scevgep28.35.2 to [61 x [61 x i8]]*
  %scevgep41.35.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10600, i64 0, i64 1, i64 0
  %10607 = bitcast i8* %scevgep41.35.2 to [61 x [61 x i8]]*
  %call16.35.3 = call zeroext i8 (...) @rand()
  store i8 %call16.35.3, i8* %scevgep28.35.2, align 1
  %10608 = load i8, i8* %scevgep28.35.2, align 1
  %conv23.35.3 = zext i8 %10608 to i32
  %10609 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.3 = getelementptr i8, i8* %b, i64 39
  %10610 = load i8, i8* %scevgep34.35.3, align 1
  %call28.35.3 = call zeroext i8 @mult(i8 zeroext %10609, i8 zeroext %10610)
  %conv29.35.3 = zext i8 %call28.35.3 to i32
  %xor.35.3 = xor i32 %conv23.35.3, %conv29.35.3
  %scevgep35.35.3 = getelementptr i8, i8* %a, i64 39
  %10611 = load i8, i8* %scevgep35.35.3, align 1
  %10612 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.3 = call zeroext i8 @mult(i8 zeroext %10611, i8 zeroext %10612)
  %conv35.35.3 = zext i8 %call34.35.3 to i32
  %xor36.35.3 = xor i32 %xor.35.3, %conv35.35.3
  %conv37.35.3 = trunc i32 %xor36.35.3 to i8
  store i8 %conv37.35.3, i8* %scevgep41.35.2, align 1
  %scevgep28.35.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10606, i64 0, i64 0, i64 1
  %10613 = bitcast i8* %scevgep28.35.3 to [61 x [61 x i8]]*
  %scevgep41.35.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10607, i64 0, i64 1, i64 0
  %10614 = bitcast i8* %scevgep41.35.3 to [61 x [61 x i8]]*
  %call16.35.4 = call zeroext i8 (...) @rand()
  store i8 %call16.35.4, i8* %scevgep28.35.3, align 1
  %10615 = load i8, i8* %scevgep28.35.3, align 1
  %conv23.35.4 = zext i8 %10615 to i32
  %10616 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.4 = getelementptr i8, i8* %b, i64 40
  %10617 = load i8, i8* %scevgep34.35.4, align 1
  %call28.35.4 = call zeroext i8 @mult(i8 zeroext %10616, i8 zeroext %10617)
  %conv29.35.4 = zext i8 %call28.35.4 to i32
  %xor.35.4 = xor i32 %conv23.35.4, %conv29.35.4
  %scevgep35.35.4 = getelementptr i8, i8* %a, i64 40
  %10618 = load i8, i8* %scevgep35.35.4, align 1
  %10619 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.4 = call zeroext i8 @mult(i8 zeroext %10618, i8 zeroext %10619)
  %conv35.35.4 = zext i8 %call34.35.4 to i32
  %xor36.35.4 = xor i32 %xor.35.4, %conv35.35.4
  %conv37.35.4 = trunc i32 %xor36.35.4 to i8
  store i8 %conv37.35.4, i8* %scevgep41.35.3, align 1
  %scevgep28.35.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10613, i64 0, i64 0, i64 1
  %10620 = bitcast i8* %scevgep28.35.4 to [61 x [61 x i8]]*
  %scevgep41.35.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10614, i64 0, i64 1, i64 0
  %10621 = bitcast i8* %scevgep41.35.4 to [61 x [61 x i8]]*
  %call16.35.5 = call zeroext i8 (...) @rand()
  store i8 %call16.35.5, i8* %scevgep28.35.4, align 1
  %10622 = load i8, i8* %scevgep28.35.4, align 1
  %conv23.35.5 = zext i8 %10622 to i32
  %10623 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.5 = getelementptr i8, i8* %b, i64 41
  %10624 = load i8, i8* %scevgep34.35.5, align 1
  %call28.35.5 = call zeroext i8 @mult(i8 zeroext %10623, i8 zeroext %10624)
  %conv29.35.5 = zext i8 %call28.35.5 to i32
  %xor.35.5 = xor i32 %conv23.35.5, %conv29.35.5
  %scevgep35.35.5 = getelementptr i8, i8* %a, i64 41
  %10625 = load i8, i8* %scevgep35.35.5, align 1
  %10626 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.5 = call zeroext i8 @mult(i8 zeroext %10625, i8 zeroext %10626)
  %conv35.35.5 = zext i8 %call34.35.5 to i32
  %xor36.35.5 = xor i32 %xor.35.5, %conv35.35.5
  %conv37.35.5 = trunc i32 %xor36.35.5 to i8
  store i8 %conv37.35.5, i8* %scevgep41.35.4, align 1
  %scevgep28.35.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10620, i64 0, i64 0, i64 1
  %10627 = bitcast i8* %scevgep28.35.5 to [61 x [61 x i8]]*
  %scevgep41.35.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10621, i64 0, i64 1, i64 0
  %10628 = bitcast i8* %scevgep41.35.5 to [61 x [61 x i8]]*
  %call16.35.6 = call zeroext i8 (...) @rand()
  store i8 %call16.35.6, i8* %scevgep28.35.5, align 1
  %10629 = load i8, i8* %scevgep28.35.5, align 1
  %conv23.35.6 = zext i8 %10629 to i32
  %10630 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.6 = getelementptr i8, i8* %b, i64 42
  %10631 = load i8, i8* %scevgep34.35.6, align 1
  %call28.35.6 = call zeroext i8 @mult(i8 zeroext %10630, i8 zeroext %10631)
  %conv29.35.6 = zext i8 %call28.35.6 to i32
  %xor.35.6 = xor i32 %conv23.35.6, %conv29.35.6
  %scevgep35.35.6 = getelementptr i8, i8* %a, i64 42
  %10632 = load i8, i8* %scevgep35.35.6, align 1
  %10633 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.6 = call zeroext i8 @mult(i8 zeroext %10632, i8 zeroext %10633)
  %conv35.35.6 = zext i8 %call34.35.6 to i32
  %xor36.35.6 = xor i32 %xor.35.6, %conv35.35.6
  %conv37.35.6 = trunc i32 %xor36.35.6 to i8
  store i8 %conv37.35.6, i8* %scevgep41.35.5, align 1
  %scevgep28.35.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10627, i64 0, i64 0, i64 1
  %10634 = bitcast i8* %scevgep28.35.6 to [61 x [61 x i8]]*
  %scevgep41.35.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10628, i64 0, i64 1, i64 0
  %10635 = bitcast i8* %scevgep41.35.6 to [61 x [61 x i8]]*
  %call16.35.7 = call zeroext i8 (...) @rand()
  store i8 %call16.35.7, i8* %scevgep28.35.6, align 1
  %10636 = load i8, i8* %scevgep28.35.6, align 1
  %conv23.35.7 = zext i8 %10636 to i32
  %10637 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.7 = getelementptr i8, i8* %b, i64 43
  %10638 = load i8, i8* %scevgep34.35.7, align 1
  %call28.35.7 = call zeroext i8 @mult(i8 zeroext %10637, i8 zeroext %10638)
  %conv29.35.7 = zext i8 %call28.35.7 to i32
  %xor.35.7 = xor i32 %conv23.35.7, %conv29.35.7
  %scevgep35.35.7 = getelementptr i8, i8* %a, i64 43
  %10639 = load i8, i8* %scevgep35.35.7, align 1
  %10640 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.7 = call zeroext i8 @mult(i8 zeroext %10639, i8 zeroext %10640)
  %conv35.35.7 = zext i8 %call34.35.7 to i32
  %xor36.35.7 = xor i32 %xor.35.7, %conv35.35.7
  %conv37.35.7 = trunc i32 %xor36.35.7 to i8
  store i8 %conv37.35.7, i8* %scevgep41.35.6, align 1
  %scevgep28.35.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10634, i64 0, i64 0, i64 1
  %10641 = bitcast i8* %scevgep28.35.7 to [61 x [61 x i8]]*
  %scevgep41.35.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10635, i64 0, i64 1, i64 0
  %10642 = bitcast i8* %scevgep41.35.7 to [61 x [61 x i8]]*
  %call16.35.8 = call zeroext i8 (...) @rand()
  store i8 %call16.35.8, i8* %scevgep28.35.7, align 1
  %10643 = load i8, i8* %scevgep28.35.7, align 1
  %conv23.35.8 = zext i8 %10643 to i32
  %10644 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.8 = getelementptr i8, i8* %b, i64 44
  %10645 = load i8, i8* %scevgep34.35.8, align 1
  %call28.35.8 = call zeroext i8 @mult(i8 zeroext %10644, i8 zeroext %10645)
  %conv29.35.8 = zext i8 %call28.35.8 to i32
  %xor.35.8 = xor i32 %conv23.35.8, %conv29.35.8
  %scevgep35.35.8 = getelementptr i8, i8* %a, i64 44
  %10646 = load i8, i8* %scevgep35.35.8, align 1
  %10647 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.8 = call zeroext i8 @mult(i8 zeroext %10646, i8 zeroext %10647)
  %conv35.35.8 = zext i8 %call34.35.8 to i32
  %xor36.35.8 = xor i32 %xor.35.8, %conv35.35.8
  %conv37.35.8 = trunc i32 %xor36.35.8 to i8
  store i8 %conv37.35.8, i8* %scevgep41.35.7, align 1
  %scevgep28.35.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10641, i64 0, i64 0, i64 1
  %10648 = bitcast i8* %scevgep28.35.8 to [61 x [61 x i8]]*
  %scevgep41.35.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10642, i64 0, i64 1, i64 0
  %10649 = bitcast i8* %scevgep41.35.8 to [61 x [61 x i8]]*
  %call16.35.9 = call zeroext i8 (...) @rand()
  store i8 %call16.35.9, i8* %scevgep28.35.8, align 1
  %10650 = load i8, i8* %scevgep28.35.8, align 1
  %conv23.35.9 = zext i8 %10650 to i32
  %10651 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.9 = getelementptr i8, i8* %b, i64 45
  %10652 = load i8, i8* %scevgep34.35.9, align 1
  %call28.35.9 = call zeroext i8 @mult(i8 zeroext %10651, i8 zeroext %10652)
  %conv29.35.9 = zext i8 %call28.35.9 to i32
  %xor.35.9 = xor i32 %conv23.35.9, %conv29.35.9
  %scevgep35.35.9 = getelementptr i8, i8* %a, i64 45
  %10653 = load i8, i8* %scevgep35.35.9, align 1
  %10654 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.9 = call zeroext i8 @mult(i8 zeroext %10653, i8 zeroext %10654)
  %conv35.35.9 = zext i8 %call34.35.9 to i32
  %xor36.35.9 = xor i32 %xor.35.9, %conv35.35.9
  %conv37.35.9 = trunc i32 %xor36.35.9 to i8
  store i8 %conv37.35.9, i8* %scevgep41.35.8, align 1
  %scevgep28.35.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10648, i64 0, i64 0, i64 1
  %10655 = bitcast i8* %scevgep28.35.9 to [61 x [61 x i8]]*
  %scevgep41.35.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10649, i64 0, i64 1, i64 0
  %10656 = bitcast i8* %scevgep41.35.9 to [61 x [61 x i8]]*
  %call16.35.10 = call zeroext i8 (...) @rand()
  store i8 %call16.35.10, i8* %scevgep28.35.9, align 1
  %10657 = load i8, i8* %scevgep28.35.9, align 1
  %conv23.35.10 = zext i8 %10657 to i32
  %10658 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.10 = getelementptr i8, i8* %b, i64 46
  %10659 = load i8, i8* %scevgep34.35.10, align 1
  %call28.35.10 = call zeroext i8 @mult(i8 zeroext %10658, i8 zeroext %10659)
  %conv29.35.10 = zext i8 %call28.35.10 to i32
  %xor.35.10 = xor i32 %conv23.35.10, %conv29.35.10
  %scevgep35.35.10 = getelementptr i8, i8* %a, i64 46
  %10660 = load i8, i8* %scevgep35.35.10, align 1
  %10661 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.10 = call zeroext i8 @mult(i8 zeroext %10660, i8 zeroext %10661)
  %conv35.35.10 = zext i8 %call34.35.10 to i32
  %xor36.35.10 = xor i32 %xor.35.10, %conv35.35.10
  %conv37.35.10 = trunc i32 %xor36.35.10 to i8
  store i8 %conv37.35.10, i8* %scevgep41.35.9, align 1
  %scevgep28.35.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10655, i64 0, i64 0, i64 1
  %10662 = bitcast i8* %scevgep28.35.10 to [61 x [61 x i8]]*
  %scevgep41.35.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10656, i64 0, i64 1, i64 0
  %10663 = bitcast i8* %scevgep41.35.10 to [61 x [61 x i8]]*
  %call16.35.11 = call zeroext i8 (...) @rand()
  store i8 %call16.35.11, i8* %scevgep28.35.10, align 1
  %10664 = load i8, i8* %scevgep28.35.10, align 1
  %conv23.35.11 = zext i8 %10664 to i32
  %10665 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.11 = getelementptr i8, i8* %b, i64 47
  %10666 = load i8, i8* %scevgep34.35.11, align 1
  %call28.35.11 = call zeroext i8 @mult(i8 zeroext %10665, i8 zeroext %10666)
  %conv29.35.11 = zext i8 %call28.35.11 to i32
  %xor.35.11 = xor i32 %conv23.35.11, %conv29.35.11
  %scevgep35.35.11 = getelementptr i8, i8* %a, i64 47
  %10667 = load i8, i8* %scevgep35.35.11, align 1
  %10668 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.11 = call zeroext i8 @mult(i8 zeroext %10667, i8 zeroext %10668)
  %conv35.35.11 = zext i8 %call34.35.11 to i32
  %xor36.35.11 = xor i32 %xor.35.11, %conv35.35.11
  %conv37.35.11 = trunc i32 %xor36.35.11 to i8
  store i8 %conv37.35.11, i8* %scevgep41.35.10, align 1
  %scevgep28.35.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10662, i64 0, i64 0, i64 1
  %10669 = bitcast i8* %scevgep28.35.11 to [61 x [61 x i8]]*
  %scevgep41.35.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10663, i64 0, i64 1, i64 0
  %10670 = bitcast i8* %scevgep41.35.11 to [61 x [61 x i8]]*
  %call16.35.12 = call zeroext i8 (...) @rand()
  store i8 %call16.35.12, i8* %scevgep28.35.11, align 1
  %10671 = load i8, i8* %scevgep28.35.11, align 1
  %conv23.35.12 = zext i8 %10671 to i32
  %10672 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.12 = getelementptr i8, i8* %b, i64 48
  %10673 = load i8, i8* %scevgep34.35.12, align 1
  %call28.35.12 = call zeroext i8 @mult(i8 zeroext %10672, i8 zeroext %10673)
  %conv29.35.12 = zext i8 %call28.35.12 to i32
  %xor.35.12 = xor i32 %conv23.35.12, %conv29.35.12
  %scevgep35.35.12 = getelementptr i8, i8* %a, i64 48
  %10674 = load i8, i8* %scevgep35.35.12, align 1
  %10675 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.12 = call zeroext i8 @mult(i8 zeroext %10674, i8 zeroext %10675)
  %conv35.35.12 = zext i8 %call34.35.12 to i32
  %xor36.35.12 = xor i32 %xor.35.12, %conv35.35.12
  %conv37.35.12 = trunc i32 %xor36.35.12 to i8
  store i8 %conv37.35.12, i8* %scevgep41.35.11, align 1
  %scevgep28.35.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10669, i64 0, i64 0, i64 1
  %10676 = bitcast i8* %scevgep28.35.12 to [61 x [61 x i8]]*
  %scevgep41.35.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10670, i64 0, i64 1, i64 0
  %10677 = bitcast i8* %scevgep41.35.12 to [61 x [61 x i8]]*
  %call16.35.13 = call zeroext i8 (...) @rand()
  store i8 %call16.35.13, i8* %scevgep28.35.12, align 1
  %10678 = load i8, i8* %scevgep28.35.12, align 1
  %conv23.35.13 = zext i8 %10678 to i32
  %10679 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.13 = getelementptr i8, i8* %b, i64 49
  %10680 = load i8, i8* %scevgep34.35.13, align 1
  %call28.35.13 = call zeroext i8 @mult(i8 zeroext %10679, i8 zeroext %10680)
  %conv29.35.13 = zext i8 %call28.35.13 to i32
  %xor.35.13 = xor i32 %conv23.35.13, %conv29.35.13
  %scevgep35.35.13 = getelementptr i8, i8* %a, i64 49
  %10681 = load i8, i8* %scevgep35.35.13, align 1
  %10682 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.13 = call zeroext i8 @mult(i8 zeroext %10681, i8 zeroext %10682)
  %conv35.35.13 = zext i8 %call34.35.13 to i32
  %xor36.35.13 = xor i32 %xor.35.13, %conv35.35.13
  %conv37.35.13 = trunc i32 %xor36.35.13 to i8
  store i8 %conv37.35.13, i8* %scevgep41.35.12, align 1
  %scevgep28.35.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10676, i64 0, i64 0, i64 1
  %10683 = bitcast i8* %scevgep28.35.13 to [61 x [61 x i8]]*
  %scevgep41.35.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10677, i64 0, i64 1, i64 0
  %10684 = bitcast i8* %scevgep41.35.13 to [61 x [61 x i8]]*
  %call16.35.14 = call zeroext i8 (...) @rand()
  store i8 %call16.35.14, i8* %scevgep28.35.13, align 1
  %10685 = load i8, i8* %scevgep28.35.13, align 1
  %conv23.35.14 = zext i8 %10685 to i32
  %10686 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.14 = getelementptr i8, i8* %b, i64 50
  %10687 = load i8, i8* %scevgep34.35.14, align 1
  %call28.35.14 = call zeroext i8 @mult(i8 zeroext %10686, i8 zeroext %10687)
  %conv29.35.14 = zext i8 %call28.35.14 to i32
  %xor.35.14 = xor i32 %conv23.35.14, %conv29.35.14
  %scevgep35.35.14 = getelementptr i8, i8* %a, i64 50
  %10688 = load i8, i8* %scevgep35.35.14, align 1
  %10689 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.14 = call zeroext i8 @mult(i8 zeroext %10688, i8 zeroext %10689)
  %conv35.35.14 = zext i8 %call34.35.14 to i32
  %xor36.35.14 = xor i32 %xor.35.14, %conv35.35.14
  %conv37.35.14 = trunc i32 %xor36.35.14 to i8
  store i8 %conv37.35.14, i8* %scevgep41.35.13, align 1
  %scevgep28.35.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10683, i64 0, i64 0, i64 1
  %10690 = bitcast i8* %scevgep28.35.14 to [61 x [61 x i8]]*
  %scevgep41.35.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10684, i64 0, i64 1, i64 0
  %10691 = bitcast i8* %scevgep41.35.14 to [61 x [61 x i8]]*
  %call16.35.15 = call zeroext i8 (...) @rand()
  store i8 %call16.35.15, i8* %scevgep28.35.14, align 1
  %10692 = load i8, i8* %scevgep28.35.14, align 1
  %conv23.35.15 = zext i8 %10692 to i32
  %10693 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.15 = getelementptr i8, i8* %b, i64 51
  %10694 = load i8, i8* %scevgep34.35.15, align 1
  %call28.35.15 = call zeroext i8 @mult(i8 zeroext %10693, i8 zeroext %10694)
  %conv29.35.15 = zext i8 %call28.35.15 to i32
  %xor.35.15 = xor i32 %conv23.35.15, %conv29.35.15
  %scevgep35.35.15 = getelementptr i8, i8* %a, i64 51
  %10695 = load i8, i8* %scevgep35.35.15, align 1
  %10696 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.15 = call zeroext i8 @mult(i8 zeroext %10695, i8 zeroext %10696)
  %conv35.35.15 = zext i8 %call34.35.15 to i32
  %xor36.35.15 = xor i32 %xor.35.15, %conv35.35.15
  %conv37.35.15 = trunc i32 %xor36.35.15 to i8
  store i8 %conv37.35.15, i8* %scevgep41.35.14, align 1
  %scevgep28.35.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10690, i64 0, i64 0, i64 1
  %10697 = bitcast i8* %scevgep28.35.15 to [61 x [61 x i8]]*
  %scevgep41.35.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10691, i64 0, i64 1, i64 0
  %10698 = bitcast i8* %scevgep41.35.15 to [61 x [61 x i8]]*
  %call16.35.16 = call zeroext i8 (...) @rand()
  store i8 %call16.35.16, i8* %scevgep28.35.15, align 1
  %10699 = load i8, i8* %scevgep28.35.15, align 1
  %conv23.35.16 = zext i8 %10699 to i32
  %10700 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.16 = getelementptr i8, i8* %b, i64 52
  %10701 = load i8, i8* %scevgep34.35.16, align 1
  %call28.35.16 = call zeroext i8 @mult(i8 zeroext %10700, i8 zeroext %10701)
  %conv29.35.16 = zext i8 %call28.35.16 to i32
  %xor.35.16 = xor i32 %conv23.35.16, %conv29.35.16
  %scevgep35.35.16 = getelementptr i8, i8* %a, i64 52
  %10702 = load i8, i8* %scevgep35.35.16, align 1
  %10703 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.16 = call zeroext i8 @mult(i8 zeroext %10702, i8 zeroext %10703)
  %conv35.35.16 = zext i8 %call34.35.16 to i32
  %xor36.35.16 = xor i32 %xor.35.16, %conv35.35.16
  %conv37.35.16 = trunc i32 %xor36.35.16 to i8
  store i8 %conv37.35.16, i8* %scevgep41.35.15, align 1
  %scevgep28.35.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10697, i64 0, i64 0, i64 1
  %10704 = bitcast i8* %scevgep28.35.16 to [61 x [61 x i8]]*
  %scevgep41.35.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10698, i64 0, i64 1, i64 0
  %10705 = bitcast i8* %scevgep41.35.16 to [61 x [61 x i8]]*
  %call16.35.17 = call zeroext i8 (...) @rand()
  store i8 %call16.35.17, i8* %scevgep28.35.16, align 1
  %10706 = load i8, i8* %scevgep28.35.16, align 1
  %conv23.35.17 = zext i8 %10706 to i32
  %10707 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.17 = getelementptr i8, i8* %b, i64 53
  %10708 = load i8, i8* %scevgep34.35.17, align 1
  %call28.35.17 = call zeroext i8 @mult(i8 zeroext %10707, i8 zeroext %10708)
  %conv29.35.17 = zext i8 %call28.35.17 to i32
  %xor.35.17 = xor i32 %conv23.35.17, %conv29.35.17
  %scevgep35.35.17 = getelementptr i8, i8* %a, i64 53
  %10709 = load i8, i8* %scevgep35.35.17, align 1
  %10710 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.17 = call zeroext i8 @mult(i8 zeroext %10709, i8 zeroext %10710)
  %conv35.35.17 = zext i8 %call34.35.17 to i32
  %xor36.35.17 = xor i32 %xor.35.17, %conv35.35.17
  %conv37.35.17 = trunc i32 %xor36.35.17 to i8
  store i8 %conv37.35.17, i8* %scevgep41.35.16, align 1
  %scevgep28.35.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10704, i64 0, i64 0, i64 1
  %10711 = bitcast i8* %scevgep28.35.17 to [61 x [61 x i8]]*
  %scevgep41.35.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10705, i64 0, i64 1, i64 0
  %10712 = bitcast i8* %scevgep41.35.17 to [61 x [61 x i8]]*
  %call16.35.18 = call zeroext i8 (...) @rand()
  store i8 %call16.35.18, i8* %scevgep28.35.17, align 1
  %10713 = load i8, i8* %scevgep28.35.17, align 1
  %conv23.35.18 = zext i8 %10713 to i32
  %10714 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.18 = getelementptr i8, i8* %b, i64 54
  %10715 = load i8, i8* %scevgep34.35.18, align 1
  %call28.35.18 = call zeroext i8 @mult(i8 zeroext %10714, i8 zeroext %10715)
  %conv29.35.18 = zext i8 %call28.35.18 to i32
  %xor.35.18 = xor i32 %conv23.35.18, %conv29.35.18
  %scevgep35.35.18 = getelementptr i8, i8* %a, i64 54
  %10716 = load i8, i8* %scevgep35.35.18, align 1
  %10717 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.18 = call zeroext i8 @mult(i8 zeroext %10716, i8 zeroext %10717)
  %conv35.35.18 = zext i8 %call34.35.18 to i32
  %xor36.35.18 = xor i32 %xor.35.18, %conv35.35.18
  %conv37.35.18 = trunc i32 %xor36.35.18 to i8
  store i8 %conv37.35.18, i8* %scevgep41.35.17, align 1
  %scevgep28.35.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10711, i64 0, i64 0, i64 1
  %10718 = bitcast i8* %scevgep28.35.18 to [61 x [61 x i8]]*
  %scevgep41.35.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10712, i64 0, i64 1, i64 0
  %10719 = bitcast i8* %scevgep41.35.18 to [61 x [61 x i8]]*
  %call16.35.19 = call zeroext i8 (...) @rand()
  store i8 %call16.35.19, i8* %scevgep28.35.18, align 1
  %10720 = load i8, i8* %scevgep28.35.18, align 1
  %conv23.35.19 = zext i8 %10720 to i32
  %10721 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.19 = getelementptr i8, i8* %b, i64 55
  %10722 = load i8, i8* %scevgep34.35.19, align 1
  %call28.35.19 = call zeroext i8 @mult(i8 zeroext %10721, i8 zeroext %10722)
  %conv29.35.19 = zext i8 %call28.35.19 to i32
  %xor.35.19 = xor i32 %conv23.35.19, %conv29.35.19
  %scevgep35.35.19 = getelementptr i8, i8* %a, i64 55
  %10723 = load i8, i8* %scevgep35.35.19, align 1
  %10724 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.19 = call zeroext i8 @mult(i8 zeroext %10723, i8 zeroext %10724)
  %conv35.35.19 = zext i8 %call34.35.19 to i32
  %xor36.35.19 = xor i32 %xor.35.19, %conv35.35.19
  %conv37.35.19 = trunc i32 %xor36.35.19 to i8
  store i8 %conv37.35.19, i8* %scevgep41.35.18, align 1
  %scevgep28.35.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10718, i64 0, i64 0, i64 1
  %10725 = bitcast i8* %scevgep28.35.19 to [61 x [61 x i8]]*
  %scevgep41.35.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10719, i64 0, i64 1, i64 0
  %10726 = bitcast i8* %scevgep41.35.19 to [61 x [61 x i8]]*
  %call16.35.20 = call zeroext i8 (...) @rand()
  store i8 %call16.35.20, i8* %scevgep28.35.19, align 1
  %10727 = load i8, i8* %scevgep28.35.19, align 1
  %conv23.35.20 = zext i8 %10727 to i32
  %10728 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.20 = getelementptr i8, i8* %b, i64 56
  %10729 = load i8, i8* %scevgep34.35.20, align 1
  %call28.35.20 = call zeroext i8 @mult(i8 zeroext %10728, i8 zeroext %10729)
  %conv29.35.20 = zext i8 %call28.35.20 to i32
  %xor.35.20 = xor i32 %conv23.35.20, %conv29.35.20
  %scevgep35.35.20 = getelementptr i8, i8* %a, i64 56
  %10730 = load i8, i8* %scevgep35.35.20, align 1
  %10731 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.20 = call zeroext i8 @mult(i8 zeroext %10730, i8 zeroext %10731)
  %conv35.35.20 = zext i8 %call34.35.20 to i32
  %xor36.35.20 = xor i32 %xor.35.20, %conv35.35.20
  %conv37.35.20 = trunc i32 %xor36.35.20 to i8
  store i8 %conv37.35.20, i8* %scevgep41.35.19, align 1
  %scevgep28.35.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10725, i64 0, i64 0, i64 1
  %10732 = bitcast i8* %scevgep28.35.20 to [61 x [61 x i8]]*
  %scevgep41.35.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10726, i64 0, i64 1, i64 0
  %10733 = bitcast i8* %scevgep41.35.20 to [61 x [61 x i8]]*
  %call16.35.21 = call zeroext i8 (...) @rand()
  store i8 %call16.35.21, i8* %scevgep28.35.20, align 1
  %10734 = load i8, i8* %scevgep28.35.20, align 1
  %conv23.35.21 = zext i8 %10734 to i32
  %10735 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.21 = getelementptr i8, i8* %b, i64 57
  %10736 = load i8, i8* %scevgep34.35.21, align 1
  %call28.35.21 = call zeroext i8 @mult(i8 zeroext %10735, i8 zeroext %10736)
  %conv29.35.21 = zext i8 %call28.35.21 to i32
  %xor.35.21 = xor i32 %conv23.35.21, %conv29.35.21
  %scevgep35.35.21 = getelementptr i8, i8* %a, i64 57
  %10737 = load i8, i8* %scevgep35.35.21, align 1
  %10738 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.21 = call zeroext i8 @mult(i8 zeroext %10737, i8 zeroext %10738)
  %conv35.35.21 = zext i8 %call34.35.21 to i32
  %xor36.35.21 = xor i32 %xor.35.21, %conv35.35.21
  %conv37.35.21 = trunc i32 %xor36.35.21 to i8
  store i8 %conv37.35.21, i8* %scevgep41.35.20, align 1
  %scevgep28.35.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10732, i64 0, i64 0, i64 1
  %10739 = bitcast i8* %scevgep28.35.21 to [61 x [61 x i8]]*
  %scevgep41.35.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10733, i64 0, i64 1, i64 0
  %10740 = bitcast i8* %scevgep41.35.21 to [61 x [61 x i8]]*
  %call16.35.22 = call zeroext i8 (...) @rand()
  store i8 %call16.35.22, i8* %scevgep28.35.21, align 1
  %10741 = load i8, i8* %scevgep28.35.21, align 1
  %conv23.35.22 = zext i8 %10741 to i32
  %10742 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.22 = getelementptr i8, i8* %b, i64 58
  %10743 = load i8, i8* %scevgep34.35.22, align 1
  %call28.35.22 = call zeroext i8 @mult(i8 zeroext %10742, i8 zeroext %10743)
  %conv29.35.22 = zext i8 %call28.35.22 to i32
  %xor.35.22 = xor i32 %conv23.35.22, %conv29.35.22
  %scevgep35.35.22 = getelementptr i8, i8* %a, i64 58
  %10744 = load i8, i8* %scevgep35.35.22, align 1
  %10745 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.22 = call zeroext i8 @mult(i8 zeroext %10744, i8 zeroext %10745)
  %conv35.35.22 = zext i8 %call34.35.22 to i32
  %xor36.35.22 = xor i32 %xor.35.22, %conv35.35.22
  %conv37.35.22 = trunc i32 %xor36.35.22 to i8
  store i8 %conv37.35.22, i8* %scevgep41.35.21, align 1
  %scevgep28.35.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10739, i64 0, i64 0, i64 1
  %10746 = bitcast i8* %scevgep28.35.22 to [61 x [61 x i8]]*
  %scevgep41.35.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10740, i64 0, i64 1, i64 0
  %10747 = bitcast i8* %scevgep41.35.22 to [61 x [61 x i8]]*
  %call16.35.23 = call zeroext i8 (...) @rand()
  store i8 %call16.35.23, i8* %scevgep28.35.22, align 1
  %10748 = load i8, i8* %scevgep28.35.22, align 1
  %conv23.35.23 = zext i8 %10748 to i32
  %10749 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.23 = getelementptr i8, i8* %b, i64 59
  %10750 = load i8, i8* %scevgep34.35.23, align 1
  %call28.35.23 = call zeroext i8 @mult(i8 zeroext %10749, i8 zeroext %10750)
  %conv29.35.23 = zext i8 %call28.35.23 to i32
  %xor.35.23 = xor i32 %conv23.35.23, %conv29.35.23
  %scevgep35.35.23 = getelementptr i8, i8* %a, i64 59
  %10751 = load i8, i8* %scevgep35.35.23, align 1
  %10752 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.23 = call zeroext i8 @mult(i8 zeroext %10751, i8 zeroext %10752)
  %conv35.35.23 = zext i8 %call34.35.23 to i32
  %xor36.35.23 = xor i32 %xor.35.23, %conv35.35.23
  %conv37.35.23 = trunc i32 %xor36.35.23 to i8
  store i8 %conv37.35.23, i8* %scevgep41.35.22, align 1
  %scevgep28.35.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10746, i64 0, i64 0, i64 1
  %scevgep41.35.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10747, i64 0, i64 1, i64 0
  %call16.35.24 = call zeroext i8 (...) @rand()
  store i8 %call16.35.24, i8* %scevgep28.35.23, align 1
  %10753 = load i8, i8* %scevgep28.35.23, align 1
  %conv23.35.24 = zext i8 %10753 to i32
  %10754 = load i8, i8* %arrayidx25.35, align 1
  %scevgep34.35.24 = getelementptr i8, i8* %b, i64 60
  %10755 = load i8, i8* %scevgep34.35.24, align 1
  %call28.35.24 = call zeroext i8 @mult(i8 zeroext %10754, i8 zeroext %10755)
  %conv29.35.24 = zext i8 %call28.35.24 to i32
  %xor.35.24 = xor i32 %conv23.35.24, %conv29.35.24
  %scevgep35.35.24 = getelementptr i8, i8* %a, i64 60
  %10756 = load i8, i8* %scevgep35.35.24, align 1
  %10757 = load i8, i8* %arrayidx33.35, align 1
  %call34.35.24 = call zeroext i8 @mult(i8 zeroext %10756, i8 zeroext %10757)
  %conv35.35.24 = zext i8 %call34.35.24 to i32
  %xor36.35.24 = xor i32 %xor.35.24, %conv35.35.24
  %conv37.35.24 = trunc i32 %xor36.35.24 to i8
  store i8 %conv37.35.24, i8* %scevgep41.35.23, align 1
  %scevgep26.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10585, i64 0, i64 1, i64 1
  %10758 = bitcast i8* %scevgep26.35 to [61 x [61 x i8]]*
  %scevgep39.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10586, i64 0, i64 1, i64 1
  %10759 = bitcast i8* %scevgep39.35 to [61 x [61 x i8]]*
  %arrayidx25.36 = getelementptr inbounds i8, i8* %a, i64 36
  %arrayidx33.36 = getelementptr inbounds i8, i8* %b, i64 36
  %call16.36 = call zeroext i8 (...) @rand()
  store i8 %call16.36, i8* %scevgep26.35, align 1
  %10760 = load i8, i8* %scevgep26.35, align 1
  %conv23.36 = zext i8 %10760 to i32
  %10761 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36 = getelementptr i8, i8* %b, i64 37
  %10762 = load i8, i8* %scevgep34.36, align 1
  %call28.36 = call zeroext i8 @mult(i8 zeroext %10761, i8 zeroext %10762)
  %conv29.36 = zext i8 %call28.36 to i32
  %xor.36 = xor i32 %conv23.36, %conv29.36
  %scevgep35.36 = getelementptr i8, i8* %a, i64 37
  %10763 = load i8, i8* %scevgep35.36, align 1
  %10764 = load i8, i8* %arrayidx33.36, align 1
  %call34.36 = call zeroext i8 @mult(i8 zeroext %10763, i8 zeroext %10764)
  %conv35.36 = zext i8 %call34.36 to i32
  %xor36.36 = xor i32 %xor.36, %conv35.36
  %conv37.36 = trunc i32 %xor36.36 to i8
  store i8 %conv37.36, i8* %scevgep39.35, align 1
  %scevgep28.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10758, i64 0, i64 0, i64 1
  %10765 = bitcast i8* %scevgep28.36 to [61 x [61 x i8]]*
  %scevgep41.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10759, i64 0, i64 1, i64 0
  %10766 = bitcast i8* %scevgep41.36 to [61 x [61 x i8]]*
  %call16.36.1 = call zeroext i8 (...) @rand()
  store i8 %call16.36.1, i8* %scevgep28.36, align 1
  %10767 = load i8, i8* %scevgep28.36, align 1
  %conv23.36.1 = zext i8 %10767 to i32
  %10768 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.1 = getelementptr i8, i8* %b, i64 38
  %10769 = load i8, i8* %scevgep34.36.1, align 1
  %call28.36.1 = call zeroext i8 @mult(i8 zeroext %10768, i8 zeroext %10769)
  %conv29.36.1 = zext i8 %call28.36.1 to i32
  %xor.36.1 = xor i32 %conv23.36.1, %conv29.36.1
  %scevgep35.36.1 = getelementptr i8, i8* %a, i64 38
  %10770 = load i8, i8* %scevgep35.36.1, align 1
  %10771 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.1 = call zeroext i8 @mult(i8 zeroext %10770, i8 zeroext %10771)
  %conv35.36.1 = zext i8 %call34.36.1 to i32
  %xor36.36.1 = xor i32 %xor.36.1, %conv35.36.1
  %conv37.36.1 = trunc i32 %xor36.36.1 to i8
  store i8 %conv37.36.1, i8* %scevgep41.36, align 1
  %scevgep28.36.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10765, i64 0, i64 0, i64 1
  %10772 = bitcast i8* %scevgep28.36.1 to [61 x [61 x i8]]*
  %scevgep41.36.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10766, i64 0, i64 1, i64 0
  %10773 = bitcast i8* %scevgep41.36.1 to [61 x [61 x i8]]*
  %call16.36.2 = call zeroext i8 (...) @rand()
  store i8 %call16.36.2, i8* %scevgep28.36.1, align 1
  %10774 = load i8, i8* %scevgep28.36.1, align 1
  %conv23.36.2 = zext i8 %10774 to i32
  %10775 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.2 = getelementptr i8, i8* %b, i64 39
  %10776 = load i8, i8* %scevgep34.36.2, align 1
  %call28.36.2 = call zeroext i8 @mult(i8 zeroext %10775, i8 zeroext %10776)
  %conv29.36.2 = zext i8 %call28.36.2 to i32
  %xor.36.2 = xor i32 %conv23.36.2, %conv29.36.2
  %scevgep35.36.2 = getelementptr i8, i8* %a, i64 39
  %10777 = load i8, i8* %scevgep35.36.2, align 1
  %10778 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.2 = call zeroext i8 @mult(i8 zeroext %10777, i8 zeroext %10778)
  %conv35.36.2 = zext i8 %call34.36.2 to i32
  %xor36.36.2 = xor i32 %xor.36.2, %conv35.36.2
  %conv37.36.2 = trunc i32 %xor36.36.2 to i8
  store i8 %conv37.36.2, i8* %scevgep41.36.1, align 1
  %scevgep28.36.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10772, i64 0, i64 0, i64 1
  %10779 = bitcast i8* %scevgep28.36.2 to [61 x [61 x i8]]*
  %scevgep41.36.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10773, i64 0, i64 1, i64 0
  %10780 = bitcast i8* %scevgep41.36.2 to [61 x [61 x i8]]*
  %call16.36.3 = call zeroext i8 (...) @rand()
  store i8 %call16.36.3, i8* %scevgep28.36.2, align 1
  %10781 = load i8, i8* %scevgep28.36.2, align 1
  %conv23.36.3 = zext i8 %10781 to i32
  %10782 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.3 = getelementptr i8, i8* %b, i64 40
  %10783 = load i8, i8* %scevgep34.36.3, align 1
  %call28.36.3 = call zeroext i8 @mult(i8 zeroext %10782, i8 zeroext %10783)
  %conv29.36.3 = zext i8 %call28.36.3 to i32
  %xor.36.3 = xor i32 %conv23.36.3, %conv29.36.3
  %scevgep35.36.3 = getelementptr i8, i8* %a, i64 40
  %10784 = load i8, i8* %scevgep35.36.3, align 1
  %10785 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.3 = call zeroext i8 @mult(i8 zeroext %10784, i8 zeroext %10785)
  %conv35.36.3 = zext i8 %call34.36.3 to i32
  %xor36.36.3 = xor i32 %xor.36.3, %conv35.36.3
  %conv37.36.3 = trunc i32 %xor36.36.3 to i8
  store i8 %conv37.36.3, i8* %scevgep41.36.2, align 1
  %scevgep28.36.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10779, i64 0, i64 0, i64 1
  %10786 = bitcast i8* %scevgep28.36.3 to [61 x [61 x i8]]*
  %scevgep41.36.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10780, i64 0, i64 1, i64 0
  %10787 = bitcast i8* %scevgep41.36.3 to [61 x [61 x i8]]*
  %call16.36.4 = call zeroext i8 (...) @rand()
  store i8 %call16.36.4, i8* %scevgep28.36.3, align 1
  %10788 = load i8, i8* %scevgep28.36.3, align 1
  %conv23.36.4 = zext i8 %10788 to i32
  %10789 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.4 = getelementptr i8, i8* %b, i64 41
  %10790 = load i8, i8* %scevgep34.36.4, align 1
  %call28.36.4 = call zeroext i8 @mult(i8 zeroext %10789, i8 zeroext %10790)
  %conv29.36.4 = zext i8 %call28.36.4 to i32
  %xor.36.4 = xor i32 %conv23.36.4, %conv29.36.4
  %scevgep35.36.4 = getelementptr i8, i8* %a, i64 41
  %10791 = load i8, i8* %scevgep35.36.4, align 1
  %10792 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.4 = call zeroext i8 @mult(i8 zeroext %10791, i8 zeroext %10792)
  %conv35.36.4 = zext i8 %call34.36.4 to i32
  %xor36.36.4 = xor i32 %xor.36.4, %conv35.36.4
  %conv37.36.4 = trunc i32 %xor36.36.4 to i8
  store i8 %conv37.36.4, i8* %scevgep41.36.3, align 1
  %scevgep28.36.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10786, i64 0, i64 0, i64 1
  %10793 = bitcast i8* %scevgep28.36.4 to [61 x [61 x i8]]*
  %scevgep41.36.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10787, i64 0, i64 1, i64 0
  %10794 = bitcast i8* %scevgep41.36.4 to [61 x [61 x i8]]*
  %call16.36.5 = call zeroext i8 (...) @rand()
  store i8 %call16.36.5, i8* %scevgep28.36.4, align 1
  %10795 = load i8, i8* %scevgep28.36.4, align 1
  %conv23.36.5 = zext i8 %10795 to i32
  %10796 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.5 = getelementptr i8, i8* %b, i64 42
  %10797 = load i8, i8* %scevgep34.36.5, align 1
  %call28.36.5 = call zeroext i8 @mult(i8 zeroext %10796, i8 zeroext %10797)
  %conv29.36.5 = zext i8 %call28.36.5 to i32
  %xor.36.5 = xor i32 %conv23.36.5, %conv29.36.5
  %scevgep35.36.5 = getelementptr i8, i8* %a, i64 42
  %10798 = load i8, i8* %scevgep35.36.5, align 1
  %10799 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.5 = call zeroext i8 @mult(i8 zeroext %10798, i8 zeroext %10799)
  %conv35.36.5 = zext i8 %call34.36.5 to i32
  %xor36.36.5 = xor i32 %xor.36.5, %conv35.36.5
  %conv37.36.5 = trunc i32 %xor36.36.5 to i8
  store i8 %conv37.36.5, i8* %scevgep41.36.4, align 1
  %scevgep28.36.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10793, i64 0, i64 0, i64 1
  %10800 = bitcast i8* %scevgep28.36.5 to [61 x [61 x i8]]*
  %scevgep41.36.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10794, i64 0, i64 1, i64 0
  %10801 = bitcast i8* %scevgep41.36.5 to [61 x [61 x i8]]*
  %call16.36.6 = call zeroext i8 (...) @rand()
  store i8 %call16.36.6, i8* %scevgep28.36.5, align 1
  %10802 = load i8, i8* %scevgep28.36.5, align 1
  %conv23.36.6 = zext i8 %10802 to i32
  %10803 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.6 = getelementptr i8, i8* %b, i64 43
  %10804 = load i8, i8* %scevgep34.36.6, align 1
  %call28.36.6 = call zeroext i8 @mult(i8 zeroext %10803, i8 zeroext %10804)
  %conv29.36.6 = zext i8 %call28.36.6 to i32
  %xor.36.6 = xor i32 %conv23.36.6, %conv29.36.6
  %scevgep35.36.6 = getelementptr i8, i8* %a, i64 43
  %10805 = load i8, i8* %scevgep35.36.6, align 1
  %10806 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.6 = call zeroext i8 @mult(i8 zeroext %10805, i8 zeroext %10806)
  %conv35.36.6 = zext i8 %call34.36.6 to i32
  %xor36.36.6 = xor i32 %xor.36.6, %conv35.36.6
  %conv37.36.6 = trunc i32 %xor36.36.6 to i8
  store i8 %conv37.36.6, i8* %scevgep41.36.5, align 1
  %scevgep28.36.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10800, i64 0, i64 0, i64 1
  %10807 = bitcast i8* %scevgep28.36.6 to [61 x [61 x i8]]*
  %scevgep41.36.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10801, i64 0, i64 1, i64 0
  %10808 = bitcast i8* %scevgep41.36.6 to [61 x [61 x i8]]*
  %call16.36.7 = call zeroext i8 (...) @rand()
  store i8 %call16.36.7, i8* %scevgep28.36.6, align 1
  %10809 = load i8, i8* %scevgep28.36.6, align 1
  %conv23.36.7 = zext i8 %10809 to i32
  %10810 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.7 = getelementptr i8, i8* %b, i64 44
  %10811 = load i8, i8* %scevgep34.36.7, align 1
  %call28.36.7 = call zeroext i8 @mult(i8 zeroext %10810, i8 zeroext %10811)
  %conv29.36.7 = zext i8 %call28.36.7 to i32
  %xor.36.7 = xor i32 %conv23.36.7, %conv29.36.7
  %scevgep35.36.7 = getelementptr i8, i8* %a, i64 44
  %10812 = load i8, i8* %scevgep35.36.7, align 1
  %10813 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.7 = call zeroext i8 @mult(i8 zeroext %10812, i8 zeroext %10813)
  %conv35.36.7 = zext i8 %call34.36.7 to i32
  %xor36.36.7 = xor i32 %xor.36.7, %conv35.36.7
  %conv37.36.7 = trunc i32 %xor36.36.7 to i8
  store i8 %conv37.36.7, i8* %scevgep41.36.6, align 1
  %scevgep28.36.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10807, i64 0, i64 0, i64 1
  %10814 = bitcast i8* %scevgep28.36.7 to [61 x [61 x i8]]*
  %scevgep41.36.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10808, i64 0, i64 1, i64 0
  %10815 = bitcast i8* %scevgep41.36.7 to [61 x [61 x i8]]*
  %call16.36.8 = call zeroext i8 (...) @rand()
  store i8 %call16.36.8, i8* %scevgep28.36.7, align 1
  %10816 = load i8, i8* %scevgep28.36.7, align 1
  %conv23.36.8 = zext i8 %10816 to i32
  %10817 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.8 = getelementptr i8, i8* %b, i64 45
  %10818 = load i8, i8* %scevgep34.36.8, align 1
  %call28.36.8 = call zeroext i8 @mult(i8 zeroext %10817, i8 zeroext %10818)
  %conv29.36.8 = zext i8 %call28.36.8 to i32
  %xor.36.8 = xor i32 %conv23.36.8, %conv29.36.8
  %scevgep35.36.8 = getelementptr i8, i8* %a, i64 45
  %10819 = load i8, i8* %scevgep35.36.8, align 1
  %10820 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.8 = call zeroext i8 @mult(i8 zeroext %10819, i8 zeroext %10820)
  %conv35.36.8 = zext i8 %call34.36.8 to i32
  %xor36.36.8 = xor i32 %xor.36.8, %conv35.36.8
  %conv37.36.8 = trunc i32 %xor36.36.8 to i8
  store i8 %conv37.36.8, i8* %scevgep41.36.7, align 1
  %scevgep28.36.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10814, i64 0, i64 0, i64 1
  %10821 = bitcast i8* %scevgep28.36.8 to [61 x [61 x i8]]*
  %scevgep41.36.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10815, i64 0, i64 1, i64 0
  %10822 = bitcast i8* %scevgep41.36.8 to [61 x [61 x i8]]*
  %call16.36.9 = call zeroext i8 (...) @rand()
  store i8 %call16.36.9, i8* %scevgep28.36.8, align 1
  %10823 = load i8, i8* %scevgep28.36.8, align 1
  %conv23.36.9 = zext i8 %10823 to i32
  %10824 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.9 = getelementptr i8, i8* %b, i64 46
  %10825 = load i8, i8* %scevgep34.36.9, align 1
  %call28.36.9 = call zeroext i8 @mult(i8 zeroext %10824, i8 zeroext %10825)
  %conv29.36.9 = zext i8 %call28.36.9 to i32
  %xor.36.9 = xor i32 %conv23.36.9, %conv29.36.9
  %scevgep35.36.9 = getelementptr i8, i8* %a, i64 46
  %10826 = load i8, i8* %scevgep35.36.9, align 1
  %10827 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.9 = call zeroext i8 @mult(i8 zeroext %10826, i8 zeroext %10827)
  %conv35.36.9 = zext i8 %call34.36.9 to i32
  %xor36.36.9 = xor i32 %xor.36.9, %conv35.36.9
  %conv37.36.9 = trunc i32 %xor36.36.9 to i8
  store i8 %conv37.36.9, i8* %scevgep41.36.8, align 1
  %scevgep28.36.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10821, i64 0, i64 0, i64 1
  %10828 = bitcast i8* %scevgep28.36.9 to [61 x [61 x i8]]*
  %scevgep41.36.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10822, i64 0, i64 1, i64 0
  %10829 = bitcast i8* %scevgep41.36.9 to [61 x [61 x i8]]*
  %call16.36.10 = call zeroext i8 (...) @rand()
  store i8 %call16.36.10, i8* %scevgep28.36.9, align 1
  %10830 = load i8, i8* %scevgep28.36.9, align 1
  %conv23.36.10 = zext i8 %10830 to i32
  %10831 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.10 = getelementptr i8, i8* %b, i64 47
  %10832 = load i8, i8* %scevgep34.36.10, align 1
  %call28.36.10 = call zeroext i8 @mult(i8 zeroext %10831, i8 zeroext %10832)
  %conv29.36.10 = zext i8 %call28.36.10 to i32
  %xor.36.10 = xor i32 %conv23.36.10, %conv29.36.10
  %scevgep35.36.10 = getelementptr i8, i8* %a, i64 47
  %10833 = load i8, i8* %scevgep35.36.10, align 1
  %10834 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.10 = call zeroext i8 @mult(i8 zeroext %10833, i8 zeroext %10834)
  %conv35.36.10 = zext i8 %call34.36.10 to i32
  %xor36.36.10 = xor i32 %xor.36.10, %conv35.36.10
  %conv37.36.10 = trunc i32 %xor36.36.10 to i8
  store i8 %conv37.36.10, i8* %scevgep41.36.9, align 1
  %scevgep28.36.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10828, i64 0, i64 0, i64 1
  %10835 = bitcast i8* %scevgep28.36.10 to [61 x [61 x i8]]*
  %scevgep41.36.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10829, i64 0, i64 1, i64 0
  %10836 = bitcast i8* %scevgep41.36.10 to [61 x [61 x i8]]*
  %call16.36.11 = call zeroext i8 (...) @rand()
  store i8 %call16.36.11, i8* %scevgep28.36.10, align 1
  %10837 = load i8, i8* %scevgep28.36.10, align 1
  %conv23.36.11 = zext i8 %10837 to i32
  %10838 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.11 = getelementptr i8, i8* %b, i64 48
  %10839 = load i8, i8* %scevgep34.36.11, align 1
  %call28.36.11 = call zeroext i8 @mult(i8 zeroext %10838, i8 zeroext %10839)
  %conv29.36.11 = zext i8 %call28.36.11 to i32
  %xor.36.11 = xor i32 %conv23.36.11, %conv29.36.11
  %scevgep35.36.11 = getelementptr i8, i8* %a, i64 48
  %10840 = load i8, i8* %scevgep35.36.11, align 1
  %10841 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.11 = call zeroext i8 @mult(i8 zeroext %10840, i8 zeroext %10841)
  %conv35.36.11 = zext i8 %call34.36.11 to i32
  %xor36.36.11 = xor i32 %xor.36.11, %conv35.36.11
  %conv37.36.11 = trunc i32 %xor36.36.11 to i8
  store i8 %conv37.36.11, i8* %scevgep41.36.10, align 1
  %scevgep28.36.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10835, i64 0, i64 0, i64 1
  %10842 = bitcast i8* %scevgep28.36.11 to [61 x [61 x i8]]*
  %scevgep41.36.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10836, i64 0, i64 1, i64 0
  %10843 = bitcast i8* %scevgep41.36.11 to [61 x [61 x i8]]*
  %call16.36.12 = call zeroext i8 (...) @rand()
  store i8 %call16.36.12, i8* %scevgep28.36.11, align 1
  %10844 = load i8, i8* %scevgep28.36.11, align 1
  %conv23.36.12 = zext i8 %10844 to i32
  %10845 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.12 = getelementptr i8, i8* %b, i64 49
  %10846 = load i8, i8* %scevgep34.36.12, align 1
  %call28.36.12 = call zeroext i8 @mult(i8 zeroext %10845, i8 zeroext %10846)
  %conv29.36.12 = zext i8 %call28.36.12 to i32
  %xor.36.12 = xor i32 %conv23.36.12, %conv29.36.12
  %scevgep35.36.12 = getelementptr i8, i8* %a, i64 49
  %10847 = load i8, i8* %scevgep35.36.12, align 1
  %10848 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.12 = call zeroext i8 @mult(i8 zeroext %10847, i8 zeroext %10848)
  %conv35.36.12 = zext i8 %call34.36.12 to i32
  %xor36.36.12 = xor i32 %xor.36.12, %conv35.36.12
  %conv37.36.12 = trunc i32 %xor36.36.12 to i8
  store i8 %conv37.36.12, i8* %scevgep41.36.11, align 1
  %scevgep28.36.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10842, i64 0, i64 0, i64 1
  %10849 = bitcast i8* %scevgep28.36.12 to [61 x [61 x i8]]*
  %scevgep41.36.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10843, i64 0, i64 1, i64 0
  %10850 = bitcast i8* %scevgep41.36.12 to [61 x [61 x i8]]*
  %call16.36.13 = call zeroext i8 (...) @rand()
  store i8 %call16.36.13, i8* %scevgep28.36.12, align 1
  %10851 = load i8, i8* %scevgep28.36.12, align 1
  %conv23.36.13 = zext i8 %10851 to i32
  %10852 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.13 = getelementptr i8, i8* %b, i64 50
  %10853 = load i8, i8* %scevgep34.36.13, align 1
  %call28.36.13 = call zeroext i8 @mult(i8 zeroext %10852, i8 zeroext %10853)
  %conv29.36.13 = zext i8 %call28.36.13 to i32
  %xor.36.13 = xor i32 %conv23.36.13, %conv29.36.13
  %scevgep35.36.13 = getelementptr i8, i8* %a, i64 50
  %10854 = load i8, i8* %scevgep35.36.13, align 1
  %10855 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.13 = call zeroext i8 @mult(i8 zeroext %10854, i8 zeroext %10855)
  %conv35.36.13 = zext i8 %call34.36.13 to i32
  %xor36.36.13 = xor i32 %xor.36.13, %conv35.36.13
  %conv37.36.13 = trunc i32 %xor36.36.13 to i8
  store i8 %conv37.36.13, i8* %scevgep41.36.12, align 1
  %scevgep28.36.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10849, i64 0, i64 0, i64 1
  %10856 = bitcast i8* %scevgep28.36.13 to [61 x [61 x i8]]*
  %scevgep41.36.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10850, i64 0, i64 1, i64 0
  %10857 = bitcast i8* %scevgep41.36.13 to [61 x [61 x i8]]*
  %call16.36.14 = call zeroext i8 (...) @rand()
  store i8 %call16.36.14, i8* %scevgep28.36.13, align 1
  %10858 = load i8, i8* %scevgep28.36.13, align 1
  %conv23.36.14 = zext i8 %10858 to i32
  %10859 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.14 = getelementptr i8, i8* %b, i64 51
  %10860 = load i8, i8* %scevgep34.36.14, align 1
  %call28.36.14 = call zeroext i8 @mult(i8 zeroext %10859, i8 zeroext %10860)
  %conv29.36.14 = zext i8 %call28.36.14 to i32
  %xor.36.14 = xor i32 %conv23.36.14, %conv29.36.14
  %scevgep35.36.14 = getelementptr i8, i8* %a, i64 51
  %10861 = load i8, i8* %scevgep35.36.14, align 1
  %10862 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.14 = call zeroext i8 @mult(i8 zeroext %10861, i8 zeroext %10862)
  %conv35.36.14 = zext i8 %call34.36.14 to i32
  %xor36.36.14 = xor i32 %xor.36.14, %conv35.36.14
  %conv37.36.14 = trunc i32 %xor36.36.14 to i8
  store i8 %conv37.36.14, i8* %scevgep41.36.13, align 1
  %scevgep28.36.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10856, i64 0, i64 0, i64 1
  %10863 = bitcast i8* %scevgep28.36.14 to [61 x [61 x i8]]*
  %scevgep41.36.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10857, i64 0, i64 1, i64 0
  %10864 = bitcast i8* %scevgep41.36.14 to [61 x [61 x i8]]*
  %call16.36.15 = call zeroext i8 (...) @rand()
  store i8 %call16.36.15, i8* %scevgep28.36.14, align 1
  %10865 = load i8, i8* %scevgep28.36.14, align 1
  %conv23.36.15 = zext i8 %10865 to i32
  %10866 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.15 = getelementptr i8, i8* %b, i64 52
  %10867 = load i8, i8* %scevgep34.36.15, align 1
  %call28.36.15 = call zeroext i8 @mult(i8 zeroext %10866, i8 zeroext %10867)
  %conv29.36.15 = zext i8 %call28.36.15 to i32
  %xor.36.15 = xor i32 %conv23.36.15, %conv29.36.15
  %scevgep35.36.15 = getelementptr i8, i8* %a, i64 52
  %10868 = load i8, i8* %scevgep35.36.15, align 1
  %10869 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.15 = call zeroext i8 @mult(i8 zeroext %10868, i8 zeroext %10869)
  %conv35.36.15 = zext i8 %call34.36.15 to i32
  %xor36.36.15 = xor i32 %xor.36.15, %conv35.36.15
  %conv37.36.15 = trunc i32 %xor36.36.15 to i8
  store i8 %conv37.36.15, i8* %scevgep41.36.14, align 1
  %scevgep28.36.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10863, i64 0, i64 0, i64 1
  %10870 = bitcast i8* %scevgep28.36.15 to [61 x [61 x i8]]*
  %scevgep41.36.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10864, i64 0, i64 1, i64 0
  %10871 = bitcast i8* %scevgep41.36.15 to [61 x [61 x i8]]*
  %call16.36.16 = call zeroext i8 (...) @rand()
  store i8 %call16.36.16, i8* %scevgep28.36.15, align 1
  %10872 = load i8, i8* %scevgep28.36.15, align 1
  %conv23.36.16 = zext i8 %10872 to i32
  %10873 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.16 = getelementptr i8, i8* %b, i64 53
  %10874 = load i8, i8* %scevgep34.36.16, align 1
  %call28.36.16 = call zeroext i8 @mult(i8 zeroext %10873, i8 zeroext %10874)
  %conv29.36.16 = zext i8 %call28.36.16 to i32
  %xor.36.16 = xor i32 %conv23.36.16, %conv29.36.16
  %scevgep35.36.16 = getelementptr i8, i8* %a, i64 53
  %10875 = load i8, i8* %scevgep35.36.16, align 1
  %10876 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.16 = call zeroext i8 @mult(i8 zeroext %10875, i8 zeroext %10876)
  %conv35.36.16 = zext i8 %call34.36.16 to i32
  %xor36.36.16 = xor i32 %xor.36.16, %conv35.36.16
  %conv37.36.16 = trunc i32 %xor36.36.16 to i8
  store i8 %conv37.36.16, i8* %scevgep41.36.15, align 1
  %scevgep28.36.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10870, i64 0, i64 0, i64 1
  %10877 = bitcast i8* %scevgep28.36.16 to [61 x [61 x i8]]*
  %scevgep41.36.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10871, i64 0, i64 1, i64 0
  %10878 = bitcast i8* %scevgep41.36.16 to [61 x [61 x i8]]*
  %call16.36.17 = call zeroext i8 (...) @rand()
  store i8 %call16.36.17, i8* %scevgep28.36.16, align 1
  %10879 = load i8, i8* %scevgep28.36.16, align 1
  %conv23.36.17 = zext i8 %10879 to i32
  %10880 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.17 = getelementptr i8, i8* %b, i64 54
  %10881 = load i8, i8* %scevgep34.36.17, align 1
  %call28.36.17 = call zeroext i8 @mult(i8 zeroext %10880, i8 zeroext %10881)
  %conv29.36.17 = zext i8 %call28.36.17 to i32
  %xor.36.17 = xor i32 %conv23.36.17, %conv29.36.17
  %scevgep35.36.17 = getelementptr i8, i8* %a, i64 54
  %10882 = load i8, i8* %scevgep35.36.17, align 1
  %10883 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.17 = call zeroext i8 @mult(i8 zeroext %10882, i8 zeroext %10883)
  %conv35.36.17 = zext i8 %call34.36.17 to i32
  %xor36.36.17 = xor i32 %xor.36.17, %conv35.36.17
  %conv37.36.17 = trunc i32 %xor36.36.17 to i8
  store i8 %conv37.36.17, i8* %scevgep41.36.16, align 1
  %scevgep28.36.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10877, i64 0, i64 0, i64 1
  %10884 = bitcast i8* %scevgep28.36.17 to [61 x [61 x i8]]*
  %scevgep41.36.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10878, i64 0, i64 1, i64 0
  %10885 = bitcast i8* %scevgep41.36.17 to [61 x [61 x i8]]*
  %call16.36.18 = call zeroext i8 (...) @rand()
  store i8 %call16.36.18, i8* %scevgep28.36.17, align 1
  %10886 = load i8, i8* %scevgep28.36.17, align 1
  %conv23.36.18 = zext i8 %10886 to i32
  %10887 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.18 = getelementptr i8, i8* %b, i64 55
  %10888 = load i8, i8* %scevgep34.36.18, align 1
  %call28.36.18 = call zeroext i8 @mult(i8 zeroext %10887, i8 zeroext %10888)
  %conv29.36.18 = zext i8 %call28.36.18 to i32
  %xor.36.18 = xor i32 %conv23.36.18, %conv29.36.18
  %scevgep35.36.18 = getelementptr i8, i8* %a, i64 55
  %10889 = load i8, i8* %scevgep35.36.18, align 1
  %10890 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.18 = call zeroext i8 @mult(i8 zeroext %10889, i8 zeroext %10890)
  %conv35.36.18 = zext i8 %call34.36.18 to i32
  %xor36.36.18 = xor i32 %xor.36.18, %conv35.36.18
  %conv37.36.18 = trunc i32 %xor36.36.18 to i8
  store i8 %conv37.36.18, i8* %scevgep41.36.17, align 1
  %scevgep28.36.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10884, i64 0, i64 0, i64 1
  %10891 = bitcast i8* %scevgep28.36.18 to [61 x [61 x i8]]*
  %scevgep41.36.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10885, i64 0, i64 1, i64 0
  %10892 = bitcast i8* %scevgep41.36.18 to [61 x [61 x i8]]*
  %call16.36.19 = call zeroext i8 (...) @rand()
  store i8 %call16.36.19, i8* %scevgep28.36.18, align 1
  %10893 = load i8, i8* %scevgep28.36.18, align 1
  %conv23.36.19 = zext i8 %10893 to i32
  %10894 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.19 = getelementptr i8, i8* %b, i64 56
  %10895 = load i8, i8* %scevgep34.36.19, align 1
  %call28.36.19 = call zeroext i8 @mult(i8 zeroext %10894, i8 zeroext %10895)
  %conv29.36.19 = zext i8 %call28.36.19 to i32
  %xor.36.19 = xor i32 %conv23.36.19, %conv29.36.19
  %scevgep35.36.19 = getelementptr i8, i8* %a, i64 56
  %10896 = load i8, i8* %scevgep35.36.19, align 1
  %10897 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.19 = call zeroext i8 @mult(i8 zeroext %10896, i8 zeroext %10897)
  %conv35.36.19 = zext i8 %call34.36.19 to i32
  %xor36.36.19 = xor i32 %xor.36.19, %conv35.36.19
  %conv37.36.19 = trunc i32 %xor36.36.19 to i8
  store i8 %conv37.36.19, i8* %scevgep41.36.18, align 1
  %scevgep28.36.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10891, i64 0, i64 0, i64 1
  %10898 = bitcast i8* %scevgep28.36.19 to [61 x [61 x i8]]*
  %scevgep41.36.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10892, i64 0, i64 1, i64 0
  %10899 = bitcast i8* %scevgep41.36.19 to [61 x [61 x i8]]*
  %call16.36.20 = call zeroext i8 (...) @rand()
  store i8 %call16.36.20, i8* %scevgep28.36.19, align 1
  %10900 = load i8, i8* %scevgep28.36.19, align 1
  %conv23.36.20 = zext i8 %10900 to i32
  %10901 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.20 = getelementptr i8, i8* %b, i64 57
  %10902 = load i8, i8* %scevgep34.36.20, align 1
  %call28.36.20 = call zeroext i8 @mult(i8 zeroext %10901, i8 zeroext %10902)
  %conv29.36.20 = zext i8 %call28.36.20 to i32
  %xor.36.20 = xor i32 %conv23.36.20, %conv29.36.20
  %scevgep35.36.20 = getelementptr i8, i8* %a, i64 57
  %10903 = load i8, i8* %scevgep35.36.20, align 1
  %10904 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.20 = call zeroext i8 @mult(i8 zeroext %10903, i8 zeroext %10904)
  %conv35.36.20 = zext i8 %call34.36.20 to i32
  %xor36.36.20 = xor i32 %xor.36.20, %conv35.36.20
  %conv37.36.20 = trunc i32 %xor36.36.20 to i8
  store i8 %conv37.36.20, i8* %scevgep41.36.19, align 1
  %scevgep28.36.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10898, i64 0, i64 0, i64 1
  %10905 = bitcast i8* %scevgep28.36.20 to [61 x [61 x i8]]*
  %scevgep41.36.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10899, i64 0, i64 1, i64 0
  %10906 = bitcast i8* %scevgep41.36.20 to [61 x [61 x i8]]*
  %call16.36.21 = call zeroext i8 (...) @rand()
  store i8 %call16.36.21, i8* %scevgep28.36.20, align 1
  %10907 = load i8, i8* %scevgep28.36.20, align 1
  %conv23.36.21 = zext i8 %10907 to i32
  %10908 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.21 = getelementptr i8, i8* %b, i64 58
  %10909 = load i8, i8* %scevgep34.36.21, align 1
  %call28.36.21 = call zeroext i8 @mult(i8 zeroext %10908, i8 zeroext %10909)
  %conv29.36.21 = zext i8 %call28.36.21 to i32
  %xor.36.21 = xor i32 %conv23.36.21, %conv29.36.21
  %scevgep35.36.21 = getelementptr i8, i8* %a, i64 58
  %10910 = load i8, i8* %scevgep35.36.21, align 1
  %10911 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.21 = call zeroext i8 @mult(i8 zeroext %10910, i8 zeroext %10911)
  %conv35.36.21 = zext i8 %call34.36.21 to i32
  %xor36.36.21 = xor i32 %xor.36.21, %conv35.36.21
  %conv37.36.21 = trunc i32 %xor36.36.21 to i8
  store i8 %conv37.36.21, i8* %scevgep41.36.20, align 1
  %scevgep28.36.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10905, i64 0, i64 0, i64 1
  %10912 = bitcast i8* %scevgep28.36.21 to [61 x [61 x i8]]*
  %scevgep41.36.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10906, i64 0, i64 1, i64 0
  %10913 = bitcast i8* %scevgep41.36.21 to [61 x [61 x i8]]*
  %call16.36.22 = call zeroext i8 (...) @rand()
  store i8 %call16.36.22, i8* %scevgep28.36.21, align 1
  %10914 = load i8, i8* %scevgep28.36.21, align 1
  %conv23.36.22 = zext i8 %10914 to i32
  %10915 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.22 = getelementptr i8, i8* %b, i64 59
  %10916 = load i8, i8* %scevgep34.36.22, align 1
  %call28.36.22 = call zeroext i8 @mult(i8 zeroext %10915, i8 zeroext %10916)
  %conv29.36.22 = zext i8 %call28.36.22 to i32
  %xor.36.22 = xor i32 %conv23.36.22, %conv29.36.22
  %scevgep35.36.22 = getelementptr i8, i8* %a, i64 59
  %10917 = load i8, i8* %scevgep35.36.22, align 1
  %10918 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.22 = call zeroext i8 @mult(i8 zeroext %10917, i8 zeroext %10918)
  %conv35.36.22 = zext i8 %call34.36.22 to i32
  %xor36.36.22 = xor i32 %xor.36.22, %conv35.36.22
  %conv37.36.22 = trunc i32 %xor36.36.22 to i8
  store i8 %conv37.36.22, i8* %scevgep41.36.21, align 1
  %scevgep28.36.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10912, i64 0, i64 0, i64 1
  %scevgep41.36.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10913, i64 0, i64 1, i64 0
  %call16.36.23 = call zeroext i8 (...) @rand()
  store i8 %call16.36.23, i8* %scevgep28.36.22, align 1
  %10919 = load i8, i8* %scevgep28.36.22, align 1
  %conv23.36.23 = zext i8 %10919 to i32
  %10920 = load i8, i8* %arrayidx25.36, align 1
  %scevgep34.36.23 = getelementptr i8, i8* %b, i64 60
  %10921 = load i8, i8* %scevgep34.36.23, align 1
  %call28.36.23 = call zeroext i8 @mult(i8 zeroext %10920, i8 zeroext %10921)
  %conv29.36.23 = zext i8 %call28.36.23 to i32
  %xor.36.23 = xor i32 %conv23.36.23, %conv29.36.23
  %scevgep35.36.23 = getelementptr i8, i8* %a, i64 60
  %10922 = load i8, i8* %scevgep35.36.23, align 1
  %10923 = load i8, i8* %arrayidx33.36, align 1
  %call34.36.23 = call zeroext i8 @mult(i8 zeroext %10922, i8 zeroext %10923)
  %conv35.36.23 = zext i8 %call34.36.23 to i32
  %xor36.36.23 = xor i32 %xor.36.23, %conv35.36.23
  %conv37.36.23 = trunc i32 %xor36.36.23 to i8
  store i8 %conv37.36.23, i8* %scevgep41.36.22, align 1
  %scevgep26.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10758, i64 0, i64 1, i64 1
  %10924 = bitcast i8* %scevgep26.36 to [61 x [61 x i8]]*
  %scevgep39.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10759, i64 0, i64 1, i64 1
  %10925 = bitcast i8* %scevgep39.36 to [61 x [61 x i8]]*
  %arrayidx25.37 = getelementptr inbounds i8, i8* %a, i64 37
  %arrayidx33.37 = getelementptr inbounds i8, i8* %b, i64 37
  %call16.37 = call zeroext i8 (...) @rand()
  store i8 %call16.37, i8* %scevgep26.36, align 1
  %10926 = load i8, i8* %scevgep26.36, align 1
  %conv23.37 = zext i8 %10926 to i32
  %10927 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37 = getelementptr i8, i8* %b, i64 38
  %10928 = load i8, i8* %scevgep34.37, align 1
  %call28.37 = call zeroext i8 @mult(i8 zeroext %10927, i8 zeroext %10928)
  %conv29.37 = zext i8 %call28.37 to i32
  %xor.37 = xor i32 %conv23.37, %conv29.37
  %scevgep35.37 = getelementptr i8, i8* %a, i64 38
  %10929 = load i8, i8* %scevgep35.37, align 1
  %10930 = load i8, i8* %arrayidx33.37, align 1
  %call34.37 = call zeroext i8 @mult(i8 zeroext %10929, i8 zeroext %10930)
  %conv35.37 = zext i8 %call34.37 to i32
  %xor36.37 = xor i32 %xor.37, %conv35.37
  %conv37.37 = trunc i32 %xor36.37 to i8
  store i8 %conv37.37, i8* %scevgep39.36, align 1
  %scevgep28.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10924, i64 0, i64 0, i64 1
  %10931 = bitcast i8* %scevgep28.37 to [61 x [61 x i8]]*
  %scevgep41.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10925, i64 0, i64 1, i64 0
  %10932 = bitcast i8* %scevgep41.37 to [61 x [61 x i8]]*
  %call16.37.1 = call zeroext i8 (...) @rand()
  store i8 %call16.37.1, i8* %scevgep28.37, align 1
  %10933 = load i8, i8* %scevgep28.37, align 1
  %conv23.37.1 = zext i8 %10933 to i32
  %10934 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.1 = getelementptr i8, i8* %b, i64 39
  %10935 = load i8, i8* %scevgep34.37.1, align 1
  %call28.37.1 = call zeroext i8 @mult(i8 zeroext %10934, i8 zeroext %10935)
  %conv29.37.1 = zext i8 %call28.37.1 to i32
  %xor.37.1 = xor i32 %conv23.37.1, %conv29.37.1
  %scevgep35.37.1 = getelementptr i8, i8* %a, i64 39
  %10936 = load i8, i8* %scevgep35.37.1, align 1
  %10937 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.1 = call zeroext i8 @mult(i8 zeroext %10936, i8 zeroext %10937)
  %conv35.37.1 = zext i8 %call34.37.1 to i32
  %xor36.37.1 = xor i32 %xor.37.1, %conv35.37.1
  %conv37.37.1 = trunc i32 %xor36.37.1 to i8
  store i8 %conv37.37.1, i8* %scevgep41.37, align 1
  %scevgep28.37.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10931, i64 0, i64 0, i64 1
  %10938 = bitcast i8* %scevgep28.37.1 to [61 x [61 x i8]]*
  %scevgep41.37.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10932, i64 0, i64 1, i64 0
  %10939 = bitcast i8* %scevgep41.37.1 to [61 x [61 x i8]]*
  %call16.37.2 = call zeroext i8 (...) @rand()
  store i8 %call16.37.2, i8* %scevgep28.37.1, align 1
  %10940 = load i8, i8* %scevgep28.37.1, align 1
  %conv23.37.2 = zext i8 %10940 to i32
  %10941 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.2 = getelementptr i8, i8* %b, i64 40
  %10942 = load i8, i8* %scevgep34.37.2, align 1
  %call28.37.2 = call zeroext i8 @mult(i8 zeroext %10941, i8 zeroext %10942)
  %conv29.37.2 = zext i8 %call28.37.2 to i32
  %xor.37.2 = xor i32 %conv23.37.2, %conv29.37.2
  %scevgep35.37.2 = getelementptr i8, i8* %a, i64 40
  %10943 = load i8, i8* %scevgep35.37.2, align 1
  %10944 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.2 = call zeroext i8 @mult(i8 zeroext %10943, i8 zeroext %10944)
  %conv35.37.2 = zext i8 %call34.37.2 to i32
  %xor36.37.2 = xor i32 %xor.37.2, %conv35.37.2
  %conv37.37.2 = trunc i32 %xor36.37.2 to i8
  store i8 %conv37.37.2, i8* %scevgep41.37.1, align 1
  %scevgep28.37.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10938, i64 0, i64 0, i64 1
  %10945 = bitcast i8* %scevgep28.37.2 to [61 x [61 x i8]]*
  %scevgep41.37.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10939, i64 0, i64 1, i64 0
  %10946 = bitcast i8* %scevgep41.37.2 to [61 x [61 x i8]]*
  %call16.37.3 = call zeroext i8 (...) @rand()
  store i8 %call16.37.3, i8* %scevgep28.37.2, align 1
  %10947 = load i8, i8* %scevgep28.37.2, align 1
  %conv23.37.3 = zext i8 %10947 to i32
  %10948 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.3 = getelementptr i8, i8* %b, i64 41
  %10949 = load i8, i8* %scevgep34.37.3, align 1
  %call28.37.3 = call zeroext i8 @mult(i8 zeroext %10948, i8 zeroext %10949)
  %conv29.37.3 = zext i8 %call28.37.3 to i32
  %xor.37.3 = xor i32 %conv23.37.3, %conv29.37.3
  %scevgep35.37.3 = getelementptr i8, i8* %a, i64 41
  %10950 = load i8, i8* %scevgep35.37.3, align 1
  %10951 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.3 = call zeroext i8 @mult(i8 zeroext %10950, i8 zeroext %10951)
  %conv35.37.3 = zext i8 %call34.37.3 to i32
  %xor36.37.3 = xor i32 %xor.37.3, %conv35.37.3
  %conv37.37.3 = trunc i32 %xor36.37.3 to i8
  store i8 %conv37.37.3, i8* %scevgep41.37.2, align 1
  %scevgep28.37.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10945, i64 0, i64 0, i64 1
  %10952 = bitcast i8* %scevgep28.37.3 to [61 x [61 x i8]]*
  %scevgep41.37.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10946, i64 0, i64 1, i64 0
  %10953 = bitcast i8* %scevgep41.37.3 to [61 x [61 x i8]]*
  %call16.37.4 = call zeroext i8 (...) @rand()
  store i8 %call16.37.4, i8* %scevgep28.37.3, align 1
  %10954 = load i8, i8* %scevgep28.37.3, align 1
  %conv23.37.4 = zext i8 %10954 to i32
  %10955 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.4 = getelementptr i8, i8* %b, i64 42
  %10956 = load i8, i8* %scevgep34.37.4, align 1
  %call28.37.4 = call zeroext i8 @mult(i8 zeroext %10955, i8 zeroext %10956)
  %conv29.37.4 = zext i8 %call28.37.4 to i32
  %xor.37.4 = xor i32 %conv23.37.4, %conv29.37.4
  %scevgep35.37.4 = getelementptr i8, i8* %a, i64 42
  %10957 = load i8, i8* %scevgep35.37.4, align 1
  %10958 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.4 = call zeroext i8 @mult(i8 zeroext %10957, i8 zeroext %10958)
  %conv35.37.4 = zext i8 %call34.37.4 to i32
  %xor36.37.4 = xor i32 %xor.37.4, %conv35.37.4
  %conv37.37.4 = trunc i32 %xor36.37.4 to i8
  store i8 %conv37.37.4, i8* %scevgep41.37.3, align 1
  %scevgep28.37.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10952, i64 0, i64 0, i64 1
  %10959 = bitcast i8* %scevgep28.37.4 to [61 x [61 x i8]]*
  %scevgep41.37.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10953, i64 0, i64 1, i64 0
  %10960 = bitcast i8* %scevgep41.37.4 to [61 x [61 x i8]]*
  %call16.37.5 = call zeroext i8 (...) @rand()
  store i8 %call16.37.5, i8* %scevgep28.37.4, align 1
  %10961 = load i8, i8* %scevgep28.37.4, align 1
  %conv23.37.5 = zext i8 %10961 to i32
  %10962 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.5 = getelementptr i8, i8* %b, i64 43
  %10963 = load i8, i8* %scevgep34.37.5, align 1
  %call28.37.5 = call zeroext i8 @mult(i8 zeroext %10962, i8 zeroext %10963)
  %conv29.37.5 = zext i8 %call28.37.5 to i32
  %xor.37.5 = xor i32 %conv23.37.5, %conv29.37.5
  %scevgep35.37.5 = getelementptr i8, i8* %a, i64 43
  %10964 = load i8, i8* %scevgep35.37.5, align 1
  %10965 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.5 = call zeroext i8 @mult(i8 zeroext %10964, i8 zeroext %10965)
  %conv35.37.5 = zext i8 %call34.37.5 to i32
  %xor36.37.5 = xor i32 %xor.37.5, %conv35.37.5
  %conv37.37.5 = trunc i32 %xor36.37.5 to i8
  store i8 %conv37.37.5, i8* %scevgep41.37.4, align 1
  %scevgep28.37.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10959, i64 0, i64 0, i64 1
  %10966 = bitcast i8* %scevgep28.37.5 to [61 x [61 x i8]]*
  %scevgep41.37.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10960, i64 0, i64 1, i64 0
  %10967 = bitcast i8* %scevgep41.37.5 to [61 x [61 x i8]]*
  %call16.37.6 = call zeroext i8 (...) @rand()
  store i8 %call16.37.6, i8* %scevgep28.37.5, align 1
  %10968 = load i8, i8* %scevgep28.37.5, align 1
  %conv23.37.6 = zext i8 %10968 to i32
  %10969 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.6 = getelementptr i8, i8* %b, i64 44
  %10970 = load i8, i8* %scevgep34.37.6, align 1
  %call28.37.6 = call zeroext i8 @mult(i8 zeroext %10969, i8 zeroext %10970)
  %conv29.37.6 = zext i8 %call28.37.6 to i32
  %xor.37.6 = xor i32 %conv23.37.6, %conv29.37.6
  %scevgep35.37.6 = getelementptr i8, i8* %a, i64 44
  %10971 = load i8, i8* %scevgep35.37.6, align 1
  %10972 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.6 = call zeroext i8 @mult(i8 zeroext %10971, i8 zeroext %10972)
  %conv35.37.6 = zext i8 %call34.37.6 to i32
  %xor36.37.6 = xor i32 %xor.37.6, %conv35.37.6
  %conv37.37.6 = trunc i32 %xor36.37.6 to i8
  store i8 %conv37.37.6, i8* %scevgep41.37.5, align 1
  %scevgep28.37.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10966, i64 0, i64 0, i64 1
  %10973 = bitcast i8* %scevgep28.37.6 to [61 x [61 x i8]]*
  %scevgep41.37.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10967, i64 0, i64 1, i64 0
  %10974 = bitcast i8* %scevgep41.37.6 to [61 x [61 x i8]]*
  %call16.37.7 = call zeroext i8 (...) @rand()
  store i8 %call16.37.7, i8* %scevgep28.37.6, align 1
  %10975 = load i8, i8* %scevgep28.37.6, align 1
  %conv23.37.7 = zext i8 %10975 to i32
  %10976 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.7 = getelementptr i8, i8* %b, i64 45
  %10977 = load i8, i8* %scevgep34.37.7, align 1
  %call28.37.7 = call zeroext i8 @mult(i8 zeroext %10976, i8 zeroext %10977)
  %conv29.37.7 = zext i8 %call28.37.7 to i32
  %xor.37.7 = xor i32 %conv23.37.7, %conv29.37.7
  %scevgep35.37.7 = getelementptr i8, i8* %a, i64 45
  %10978 = load i8, i8* %scevgep35.37.7, align 1
  %10979 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.7 = call zeroext i8 @mult(i8 zeroext %10978, i8 zeroext %10979)
  %conv35.37.7 = zext i8 %call34.37.7 to i32
  %xor36.37.7 = xor i32 %xor.37.7, %conv35.37.7
  %conv37.37.7 = trunc i32 %xor36.37.7 to i8
  store i8 %conv37.37.7, i8* %scevgep41.37.6, align 1
  %scevgep28.37.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10973, i64 0, i64 0, i64 1
  %10980 = bitcast i8* %scevgep28.37.7 to [61 x [61 x i8]]*
  %scevgep41.37.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10974, i64 0, i64 1, i64 0
  %10981 = bitcast i8* %scevgep41.37.7 to [61 x [61 x i8]]*
  %call16.37.8 = call zeroext i8 (...) @rand()
  store i8 %call16.37.8, i8* %scevgep28.37.7, align 1
  %10982 = load i8, i8* %scevgep28.37.7, align 1
  %conv23.37.8 = zext i8 %10982 to i32
  %10983 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.8 = getelementptr i8, i8* %b, i64 46
  %10984 = load i8, i8* %scevgep34.37.8, align 1
  %call28.37.8 = call zeroext i8 @mult(i8 zeroext %10983, i8 zeroext %10984)
  %conv29.37.8 = zext i8 %call28.37.8 to i32
  %xor.37.8 = xor i32 %conv23.37.8, %conv29.37.8
  %scevgep35.37.8 = getelementptr i8, i8* %a, i64 46
  %10985 = load i8, i8* %scevgep35.37.8, align 1
  %10986 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.8 = call zeroext i8 @mult(i8 zeroext %10985, i8 zeroext %10986)
  %conv35.37.8 = zext i8 %call34.37.8 to i32
  %xor36.37.8 = xor i32 %xor.37.8, %conv35.37.8
  %conv37.37.8 = trunc i32 %xor36.37.8 to i8
  store i8 %conv37.37.8, i8* %scevgep41.37.7, align 1
  %scevgep28.37.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10980, i64 0, i64 0, i64 1
  %10987 = bitcast i8* %scevgep28.37.8 to [61 x [61 x i8]]*
  %scevgep41.37.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10981, i64 0, i64 1, i64 0
  %10988 = bitcast i8* %scevgep41.37.8 to [61 x [61 x i8]]*
  %call16.37.9 = call zeroext i8 (...) @rand()
  store i8 %call16.37.9, i8* %scevgep28.37.8, align 1
  %10989 = load i8, i8* %scevgep28.37.8, align 1
  %conv23.37.9 = zext i8 %10989 to i32
  %10990 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.9 = getelementptr i8, i8* %b, i64 47
  %10991 = load i8, i8* %scevgep34.37.9, align 1
  %call28.37.9 = call zeroext i8 @mult(i8 zeroext %10990, i8 zeroext %10991)
  %conv29.37.9 = zext i8 %call28.37.9 to i32
  %xor.37.9 = xor i32 %conv23.37.9, %conv29.37.9
  %scevgep35.37.9 = getelementptr i8, i8* %a, i64 47
  %10992 = load i8, i8* %scevgep35.37.9, align 1
  %10993 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.9 = call zeroext i8 @mult(i8 zeroext %10992, i8 zeroext %10993)
  %conv35.37.9 = zext i8 %call34.37.9 to i32
  %xor36.37.9 = xor i32 %xor.37.9, %conv35.37.9
  %conv37.37.9 = trunc i32 %xor36.37.9 to i8
  store i8 %conv37.37.9, i8* %scevgep41.37.8, align 1
  %scevgep28.37.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10987, i64 0, i64 0, i64 1
  %10994 = bitcast i8* %scevgep28.37.9 to [61 x [61 x i8]]*
  %scevgep41.37.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10988, i64 0, i64 1, i64 0
  %10995 = bitcast i8* %scevgep41.37.9 to [61 x [61 x i8]]*
  %call16.37.10 = call zeroext i8 (...) @rand()
  store i8 %call16.37.10, i8* %scevgep28.37.9, align 1
  %10996 = load i8, i8* %scevgep28.37.9, align 1
  %conv23.37.10 = zext i8 %10996 to i32
  %10997 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.10 = getelementptr i8, i8* %b, i64 48
  %10998 = load i8, i8* %scevgep34.37.10, align 1
  %call28.37.10 = call zeroext i8 @mult(i8 zeroext %10997, i8 zeroext %10998)
  %conv29.37.10 = zext i8 %call28.37.10 to i32
  %xor.37.10 = xor i32 %conv23.37.10, %conv29.37.10
  %scevgep35.37.10 = getelementptr i8, i8* %a, i64 48
  %10999 = load i8, i8* %scevgep35.37.10, align 1
  %11000 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.10 = call zeroext i8 @mult(i8 zeroext %10999, i8 zeroext %11000)
  %conv35.37.10 = zext i8 %call34.37.10 to i32
  %xor36.37.10 = xor i32 %xor.37.10, %conv35.37.10
  %conv37.37.10 = trunc i32 %xor36.37.10 to i8
  store i8 %conv37.37.10, i8* %scevgep41.37.9, align 1
  %scevgep28.37.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10994, i64 0, i64 0, i64 1
  %11001 = bitcast i8* %scevgep28.37.10 to [61 x [61 x i8]]*
  %scevgep41.37.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10995, i64 0, i64 1, i64 0
  %11002 = bitcast i8* %scevgep41.37.10 to [61 x [61 x i8]]*
  %call16.37.11 = call zeroext i8 (...) @rand()
  store i8 %call16.37.11, i8* %scevgep28.37.10, align 1
  %11003 = load i8, i8* %scevgep28.37.10, align 1
  %conv23.37.11 = zext i8 %11003 to i32
  %11004 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.11 = getelementptr i8, i8* %b, i64 49
  %11005 = load i8, i8* %scevgep34.37.11, align 1
  %call28.37.11 = call zeroext i8 @mult(i8 zeroext %11004, i8 zeroext %11005)
  %conv29.37.11 = zext i8 %call28.37.11 to i32
  %xor.37.11 = xor i32 %conv23.37.11, %conv29.37.11
  %scevgep35.37.11 = getelementptr i8, i8* %a, i64 49
  %11006 = load i8, i8* %scevgep35.37.11, align 1
  %11007 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.11 = call zeroext i8 @mult(i8 zeroext %11006, i8 zeroext %11007)
  %conv35.37.11 = zext i8 %call34.37.11 to i32
  %xor36.37.11 = xor i32 %xor.37.11, %conv35.37.11
  %conv37.37.11 = trunc i32 %xor36.37.11 to i8
  store i8 %conv37.37.11, i8* %scevgep41.37.10, align 1
  %scevgep28.37.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11001, i64 0, i64 0, i64 1
  %11008 = bitcast i8* %scevgep28.37.11 to [61 x [61 x i8]]*
  %scevgep41.37.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11002, i64 0, i64 1, i64 0
  %11009 = bitcast i8* %scevgep41.37.11 to [61 x [61 x i8]]*
  %call16.37.12 = call zeroext i8 (...) @rand()
  store i8 %call16.37.12, i8* %scevgep28.37.11, align 1
  %11010 = load i8, i8* %scevgep28.37.11, align 1
  %conv23.37.12 = zext i8 %11010 to i32
  %11011 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.12 = getelementptr i8, i8* %b, i64 50
  %11012 = load i8, i8* %scevgep34.37.12, align 1
  %call28.37.12 = call zeroext i8 @mult(i8 zeroext %11011, i8 zeroext %11012)
  %conv29.37.12 = zext i8 %call28.37.12 to i32
  %xor.37.12 = xor i32 %conv23.37.12, %conv29.37.12
  %scevgep35.37.12 = getelementptr i8, i8* %a, i64 50
  %11013 = load i8, i8* %scevgep35.37.12, align 1
  %11014 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.12 = call zeroext i8 @mult(i8 zeroext %11013, i8 zeroext %11014)
  %conv35.37.12 = zext i8 %call34.37.12 to i32
  %xor36.37.12 = xor i32 %xor.37.12, %conv35.37.12
  %conv37.37.12 = trunc i32 %xor36.37.12 to i8
  store i8 %conv37.37.12, i8* %scevgep41.37.11, align 1
  %scevgep28.37.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11008, i64 0, i64 0, i64 1
  %11015 = bitcast i8* %scevgep28.37.12 to [61 x [61 x i8]]*
  %scevgep41.37.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11009, i64 0, i64 1, i64 0
  %11016 = bitcast i8* %scevgep41.37.12 to [61 x [61 x i8]]*
  %call16.37.13 = call zeroext i8 (...) @rand()
  store i8 %call16.37.13, i8* %scevgep28.37.12, align 1
  %11017 = load i8, i8* %scevgep28.37.12, align 1
  %conv23.37.13 = zext i8 %11017 to i32
  %11018 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.13 = getelementptr i8, i8* %b, i64 51
  %11019 = load i8, i8* %scevgep34.37.13, align 1
  %call28.37.13 = call zeroext i8 @mult(i8 zeroext %11018, i8 zeroext %11019)
  %conv29.37.13 = zext i8 %call28.37.13 to i32
  %xor.37.13 = xor i32 %conv23.37.13, %conv29.37.13
  %scevgep35.37.13 = getelementptr i8, i8* %a, i64 51
  %11020 = load i8, i8* %scevgep35.37.13, align 1
  %11021 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.13 = call zeroext i8 @mult(i8 zeroext %11020, i8 zeroext %11021)
  %conv35.37.13 = zext i8 %call34.37.13 to i32
  %xor36.37.13 = xor i32 %xor.37.13, %conv35.37.13
  %conv37.37.13 = trunc i32 %xor36.37.13 to i8
  store i8 %conv37.37.13, i8* %scevgep41.37.12, align 1
  %scevgep28.37.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11015, i64 0, i64 0, i64 1
  %11022 = bitcast i8* %scevgep28.37.13 to [61 x [61 x i8]]*
  %scevgep41.37.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11016, i64 0, i64 1, i64 0
  %11023 = bitcast i8* %scevgep41.37.13 to [61 x [61 x i8]]*
  %call16.37.14 = call zeroext i8 (...) @rand()
  store i8 %call16.37.14, i8* %scevgep28.37.13, align 1
  %11024 = load i8, i8* %scevgep28.37.13, align 1
  %conv23.37.14 = zext i8 %11024 to i32
  %11025 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.14 = getelementptr i8, i8* %b, i64 52
  %11026 = load i8, i8* %scevgep34.37.14, align 1
  %call28.37.14 = call zeroext i8 @mult(i8 zeroext %11025, i8 zeroext %11026)
  %conv29.37.14 = zext i8 %call28.37.14 to i32
  %xor.37.14 = xor i32 %conv23.37.14, %conv29.37.14
  %scevgep35.37.14 = getelementptr i8, i8* %a, i64 52
  %11027 = load i8, i8* %scevgep35.37.14, align 1
  %11028 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.14 = call zeroext i8 @mult(i8 zeroext %11027, i8 zeroext %11028)
  %conv35.37.14 = zext i8 %call34.37.14 to i32
  %xor36.37.14 = xor i32 %xor.37.14, %conv35.37.14
  %conv37.37.14 = trunc i32 %xor36.37.14 to i8
  store i8 %conv37.37.14, i8* %scevgep41.37.13, align 1
  %scevgep28.37.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11022, i64 0, i64 0, i64 1
  %11029 = bitcast i8* %scevgep28.37.14 to [61 x [61 x i8]]*
  %scevgep41.37.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11023, i64 0, i64 1, i64 0
  %11030 = bitcast i8* %scevgep41.37.14 to [61 x [61 x i8]]*
  %call16.37.15 = call zeroext i8 (...) @rand()
  store i8 %call16.37.15, i8* %scevgep28.37.14, align 1
  %11031 = load i8, i8* %scevgep28.37.14, align 1
  %conv23.37.15 = zext i8 %11031 to i32
  %11032 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.15 = getelementptr i8, i8* %b, i64 53
  %11033 = load i8, i8* %scevgep34.37.15, align 1
  %call28.37.15 = call zeroext i8 @mult(i8 zeroext %11032, i8 zeroext %11033)
  %conv29.37.15 = zext i8 %call28.37.15 to i32
  %xor.37.15 = xor i32 %conv23.37.15, %conv29.37.15
  %scevgep35.37.15 = getelementptr i8, i8* %a, i64 53
  %11034 = load i8, i8* %scevgep35.37.15, align 1
  %11035 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.15 = call zeroext i8 @mult(i8 zeroext %11034, i8 zeroext %11035)
  %conv35.37.15 = zext i8 %call34.37.15 to i32
  %xor36.37.15 = xor i32 %xor.37.15, %conv35.37.15
  %conv37.37.15 = trunc i32 %xor36.37.15 to i8
  store i8 %conv37.37.15, i8* %scevgep41.37.14, align 1
  %scevgep28.37.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11029, i64 0, i64 0, i64 1
  %11036 = bitcast i8* %scevgep28.37.15 to [61 x [61 x i8]]*
  %scevgep41.37.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11030, i64 0, i64 1, i64 0
  %11037 = bitcast i8* %scevgep41.37.15 to [61 x [61 x i8]]*
  %call16.37.16 = call zeroext i8 (...) @rand()
  store i8 %call16.37.16, i8* %scevgep28.37.15, align 1
  %11038 = load i8, i8* %scevgep28.37.15, align 1
  %conv23.37.16 = zext i8 %11038 to i32
  %11039 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.16 = getelementptr i8, i8* %b, i64 54
  %11040 = load i8, i8* %scevgep34.37.16, align 1
  %call28.37.16 = call zeroext i8 @mult(i8 zeroext %11039, i8 zeroext %11040)
  %conv29.37.16 = zext i8 %call28.37.16 to i32
  %xor.37.16 = xor i32 %conv23.37.16, %conv29.37.16
  %scevgep35.37.16 = getelementptr i8, i8* %a, i64 54
  %11041 = load i8, i8* %scevgep35.37.16, align 1
  %11042 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.16 = call zeroext i8 @mult(i8 zeroext %11041, i8 zeroext %11042)
  %conv35.37.16 = zext i8 %call34.37.16 to i32
  %xor36.37.16 = xor i32 %xor.37.16, %conv35.37.16
  %conv37.37.16 = trunc i32 %xor36.37.16 to i8
  store i8 %conv37.37.16, i8* %scevgep41.37.15, align 1
  %scevgep28.37.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11036, i64 0, i64 0, i64 1
  %11043 = bitcast i8* %scevgep28.37.16 to [61 x [61 x i8]]*
  %scevgep41.37.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11037, i64 0, i64 1, i64 0
  %11044 = bitcast i8* %scevgep41.37.16 to [61 x [61 x i8]]*
  %call16.37.17 = call zeroext i8 (...) @rand()
  store i8 %call16.37.17, i8* %scevgep28.37.16, align 1
  %11045 = load i8, i8* %scevgep28.37.16, align 1
  %conv23.37.17 = zext i8 %11045 to i32
  %11046 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.17 = getelementptr i8, i8* %b, i64 55
  %11047 = load i8, i8* %scevgep34.37.17, align 1
  %call28.37.17 = call zeroext i8 @mult(i8 zeroext %11046, i8 zeroext %11047)
  %conv29.37.17 = zext i8 %call28.37.17 to i32
  %xor.37.17 = xor i32 %conv23.37.17, %conv29.37.17
  %scevgep35.37.17 = getelementptr i8, i8* %a, i64 55
  %11048 = load i8, i8* %scevgep35.37.17, align 1
  %11049 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.17 = call zeroext i8 @mult(i8 zeroext %11048, i8 zeroext %11049)
  %conv35.37.17 = zext i8 %call34.37.17 to i32
  %xor36.37.17 = xor i32 %xor.37.17, %conv35.37.17
  %conv37.37.17 = trunc i32 %xor36.37.17 to i8
  store i8 %conv37.37.17, i8* %scevgep41.37.16, align 1
  %scevgep28.37.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11043, i64 0, i64 0, i64 1
  %11050 = bitcast i8* %scevgep28.37.17 to [61 x [61 x i8]]*
  %scevgep41.37.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11044, i64 0, i64 1, i64 0
  %11051 = bitcast i8* %scevgep41.37.17 to [61 x [61 x i8]]*
  %call16.37.18 = call zeroext i8 (...) @rand()
  store i8 %call16.37.18, i8* %scevgep28.37.17, align 1
  %11052 = load i8, i8* %scevgep28.37.17, align 1
  %conv23.37.18 = zext i8 %11052 to i32
  %11053 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.18 = getelementptr i8, i8* %b, i64 56
  %11054 = load i8, i8* %scevgep34.37.18, align 1
  %call28.37.18 = call zeroext i8 @mult(i8 zeroext %11053, i8 zeroext %11054)
  %conv29.37.18 = zext i8 %call28.37.18 to i32
  %xor.37.18 = xor i32 %conv23.37.18, %conv29.37.18
  %scevgep35.37.18 = getelementptr i8, i8* %a, i64 56
  %11055 = load i8, i8* %scevgep35.37.18, align 1
  %11056 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.18 = call zeroext i8 @mult(i8 zeroext %11055, i8 zeroext %11056)
  %conv35.37.18 = zext i8 %call34.37.18 to i32
  %xor36.37.18 = xor i32 %xor.37.18, %conv35.37.18
  %conv37.37.18 = trunc i32 %xor36.37.18 to i8
  store i8 %conv37.37.18, i8* %scevgep41.37.17, align 1
  %scevgep28.37.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11050, i64 0, i64 0, i64 1
  %11057 = bitcast i8* %scevgep28.37.18 to [61 x [61 x i8]]*
  %scevgep41.37.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11051, i64 0, i64 1, i64 0
  %11058 = bitcast i8* %scevgep41.37.18 to [61 x [61 x i8]]*
  %call16.37.19 = call zeroext i8 (...) @rand()
  store i8 %call16.37.19, i8* %scevgep28.37.18, align 1
  %11059 = load i8, i8* %scevgep28.37.18, align 1
  %conv23.37.19 = zext i8 %11059 to i32
  %11060 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.19 = getelementptr i8, i8* %b, i64 57
  %11061 = load i8, i8* %scevgep34.37.19, align 1
  %call28.37.19 = call zeroext i8 @mult(i8 zeroext %11060, i8 zeroext %11061)
  %conv29.37.19 = zext i8 %call28.37.19 to i32
  %xor.37.19 = xor i32 %conv23.37.19, %conv29.37.19
  %scevgep35.37.19 = getelementptr i8, i8* %a, i64 57
  %11062 = load i8, i8* %scevgep35.37.19, align 1
  %11063 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.19 = call zeroext i8 @mult(i8 zeroext %11062, i8 zeroext %11063)
  %conv35.37.19 = zext i8 %call34.37.19 to i32
  %xor36.37.19 = xor i32 %xor.37.19, %conv35.37.19
  %conv37.37.19 = trunc i32 %xor36.37.19 to i8
  store i8 %conv37.37.19, i8* %scevgep41.37.18, align 1
  %scevgep28.37.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11057, i64 0, i64 0, i64 1
  %11064 = bitcast i8* %scevgep28.37.19 to [61 x [61 x i8]]*
  %scevgep41.37.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11058, i64 0, i64 1, i64 0
  %11065 = bitcast i8* %scevgep41.37.19 to [61 x [61 x i8]]*
  %call16.37.20 = call zeroext i8 (...) @rand()
  store i8 %call16.37.20, i8* %scevgep28.37.19, align 1
  %11066 = load i8, i8* %scevgep28.37.19, align 1
  %conv23.37.20 = zext i8 %11066 to i32
  %11067 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.20 = getelementptr i8, i8* %b, i64 58
  %11068 = load i8, i8* %scevgep34.37.20, align 1
  %call28.37.20 = call zeroext i8 @mult(i8 zeroext %11067, i8 zeroext %11068)
  %conv29.37.20 = zext i8 %call28.37.20 to i32
  %xor.37.20 = xor i32 %conv23.37.20, %conv29.37.20
  %scevgep35.37.20 = getelementptr i8, i8* %a, i64 58
  %11069 = load i8, i8* %scevgep35.37.20, align 1
  %11070 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.20 = call zeroext i8 @mult(i8 zeroext %11069, i8 zeroext %11070)
  %conv35.37.20 = zext i8 %call34.37.20 to i32
  %xor36.37.20 = xor i32 %xor.37.20, %conv35.37.20
  %conv37.37.20 = trunc i32 %xor36.37.20 to i8
  store i8 %conv37.37.20, i8* %scevgep41.37.19, align 1
  %scevgep28.37.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11064, i64 0, i64 0, i64 1
  %11071 = bitcast i8* %scevgep28.37.20 to [61 x [61 x i8]]*
  %scevgep41.37.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11065, i64 0, i64 1, i64 0
  %11072 = bitcast i8* %scevgep41.37.20 to [61 x [61 x i8]]*
  %call16.37.21 = call zeroext i8 (...) @rand()
  store i8 %call16.37.21, i8* %scevgep28.37.20, align 1
  %11073 = load i8, i8* %scevgep28.37.20, align 1
  %conv23.37.21 = zext i8 %11073 to i32
  %11074 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.21 = getelementptr i8, i8* %b, i64 59
  %11075 = load i8, i8* %scevgep34.37.21, align 1
  %call28.37.21 = call zeroext i8 @mult(i8 zeroext %11074, i8 zeroext %11075)
  %conv29.37.21 = zext i8 %call28.37.21 to i32
  %xor.37.21 = xor i32 %conv23.37.21, %conv29.37.21
  %scevgep35.37.21 = getelementptr i8, i8* %a, i64 59
  %11076 = load i8, i8* %scevgep35.37.21, align 1
  %11077 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.21 = call zeroext i8 @mult(i8 zeroext %11076, i8 zeroext %11077)
  %conv35.37.21 = zext i8 %call34.37.21 to i32
  %xor36.37.21 = xor i32 %xor.37.21, %conv35.37.21
  %conv37.37.21 = trunc i32 %xor36.37.21 to i8
  store i8 %conv37.37.21, i8* %scevgep41.37.20, align 1
  %scevgep28.37.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11071, i64 0, i64 0, i64 1
  %scevgep41.37.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11072, i64 0, i64 1, i64 0
  %call16.37.22 = call zeroext i8 (...) @rand()
  store i8 %call16.37.22, i8* %scevgep28.37.21, align 1
  %11078 = load i8, i8* %scevgep28.37.21, align 1
  %conv23.37.22 = zext i8 %11078 to i32
  %11079 = load i8, i8* %arrayidx25.37, align 1
  %scevgep34.37.22 = getelementptr i8, i8* %b, i64 60
  %11080 = load i8, i8* %scevgep34.37.22, align 1
  %call28.37.22 = call zeroext i8 @mult(i8 zeroext %11079, i8 zeroext %11080)
  %conv29.37.22 = zext i8 %call28.37.22 to i32
  %xor.37.22 = xor i32 %conv23.37.22, %conv29.37.22
  %scevgep35.37.22 = getelementptr i8, i8* %a, i64 60
  %11081 = load i8, i8* %scevgep35.37.22, align 1
  %11082 = load i8, i8* %arrayidx33.37, align 1
  %call34.37.22 = call zeroext i8 @mult(i8 zeroext %11081, i8 zeroext %11082)
  %conv35.37.22 = zext i8 %call34.37.22 to i32
  %xor36.37.22 = xor i32 %xor.37.22, %conv35.37.22
  %conv37.37.22 = trunc i32 %xor36.37.22 to i8
  store i8 %conv37.37.22, i8* %scevgep41.37.21, align 1
  %scevgep26.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10924, i64 0, i64 1, i64 1
  %11083 = bitcast i8* %scevgep26.37 to [61 x [61 x i8]]*
  %scevgep39.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %10925, i64 0, i64 1, i64 1
  %11084 = bitcast i8* %scevgep39.37 to [61 x [61 x i8]]*
  %arrayidx25.38 = getelementptr inbounds i8, i8* %a, i64 38
  %arrayidx33.38 = getelementptr inbounds i8, i8* %b, i64 38
  %call16.38 = call zeroext i8 (...) @rand()
  store i8 %call16.38, i8* %scevgep26.37, align 1
  %11085 = load i8, i8* %scevgep26.37, align 1
  %conv23.38 = zext i8 %11085 to i32
  %11086 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38 = getelementptr i8, i8* %b, i64 39
  %11087 = load i8, i8* %scevgep34.38, align 1
  %call28.38 = call zeroext i8 @mult(i8 zeroext %11086, i8 zeroext %11087)
  %conv29.38 = zext i8 %call28.38 to i32
  %xor.38 = xor i32 %conv23.38, %conv29.38
  %scevgep35.38 = getelementptr i8, i8* %a, i64 39
  %11088 = load i8, i8* %scevgep35.38, align 1
  %11089 = load i8, i8* %arrayidx33.38, align 1
  %call34.38 = call zeroext i8 @mult(i8 zeroext %11088, i8 zeroext %11089)
  %conv35.38 = zext i8 %call34.38 to i32
  %xor36.38 = xor i32 %xor.38, %conv35.38
  %conv37.38 = trunc i32 %xor36.38 to i8
  store i8 %conv37.38, i8* %scevgep39.37, align 1
  %scevgep28.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11083, i64 0, i64 0, i64 1
  %11090 = bitcast i8* %scevgep28.38 to [61 x [61 x i8]]*
  %scevgep41.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11084, i64 0, i64 1, i64 0
  %11091 = bitcast i8* %scevgep41.38 to [61 x [61 x i8]]*
  %call16.38.1 = call zeroext i8 (...) @rand()
  store i8 %call16.38.1, i8* %scevgep28.38, align 1
  %11092 = load i8, i8* %scevgep28.38, align 1
  %conv23.38.1 = zext i8 %11092 to i32
  %11093 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.1 = getelementptr i8, i8* %b, i64 40
  %11094 = load i8, i8* %scevgep34.38.1, align 1
  %call28.38.1 = call zeroext i8 @mult(i8 zeroext %11093, i8 zeroext %11094)
  %conv29.38.1 = zext i8 %call28.38.1 to i32
  %xor.38.1 = xor i32 %conv23.38.1, %conv29.38.1
  %scevgep35.38.1 = getelementptr i8, i8* %a, i64 40
  %11095 = load i8, i8* %scevgep35.38.1, align 1
  %11096 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.1 = call zeroext i8 @mult(i8 zeroext %11095, i8 zeroext %11096)
  %conv35.38.1 = zext i8 %call34.38.1 to i32
  %xor36.38.1 = xor i32 %xor.38.1, %conv35.38.1
  %conv37.38.1 = trunc i32 %xor36.38.1 to i8
  store i8 %conv37.38.1, i8* %scevgep41.38, align 1
  %scevgep28.38.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11090, i64 0, i64 0, i64 1
  %11097 = bitcast i8* %scevgep28.38.1 to [61 x [61 x i8]]*
  %scevgep41.38.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11091, i64 0, i64 1, i64 0
  %11098 = bitcast i8* %scevgep41.38.1 to [61 x [61 x i8]]*
  %call16.38.2 = call zeroext i8 (...) @rand()
  store i8 %call16.38.2, i8* %scevgep28.38.1, align 1
  %11099 = load i8, i8* %scevgep28.38.1, align 1
  %conv23.38.2 = zext i8 %11099 to i32
  %11100 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.2 = getelementptr i8, i8* %b, i64 41
  %11101 = load i8, i8* %scevgep34.38.2, align 1
  %call28.38.2 = call zeroext i8 @mult(i8 zeroext %11100, i8 zeroext %11101)
  %conv29.38.2 = zext i8 %call28.38.2 to i32
  %xor.38.2 = xor i32 %conv23.38.2, %conv29.38.2
  %scevgep35.38.2 = getelementptr i8, i8* %a, i64 41
  %11102 = load i8, i8* %scevgep35.38.2, align 1
  %11103 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.2 = call zeroext i8 @mult(i8 zeroext %11102, i8 zeroext %11103)
  %conv35.38.2 = zext i8 %call34.38.2 to i32
  %xor36.38.2 = xor i32 %xor.38.2, %conv35.38.2
  %conv37.38.2 = trunc i32 %xor36.38.2 to i8
  store i8 %conv37.38.2, i8* %scevgep41.38.1, align 1
  %scevgep28.38.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11097, i64 0, i64 0, i64 1
  %11104 = bitcast i8* %scevgep28.38.2 to [61 x [61 x i8]]*
  %scevgep41.38.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11098, i64 0, i64 1, i64 0
  %11105 = bitcast i8* %scevgep41.38.2 to [61 x [61 x i8]]*
  %call16.38.3 = call zeroext i8 (...) @rand()
  store i8 %call16.38.3, i8* %scevgep28.38.2, align 1
  %11106 = load i8, i8* %scevgep28.38.2, align 1
  %conv23.38.3 = zext i8 %11106 to i32
  %11107 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.3 = getelementptr i8, i8* %b, i64 42
  %11108 = load i8, i8* %scevgep34.38.3, align 1
  %call28.38.3 = call zeroext i8 @mult(i8 zeroext %11107, i8 zeroext %11108)
  %conv29.38.3 = zext i8 %call28.38.3 to i32
  %xor.38.3 = xor i32 %conv23.38.3, %conv29.38.3
  %scevgep35.38.3 = getelementptr i8, i8* %a, i64 42
  %11109 = load i8, i8* %scevgep35.38.3, align 1
  %11110 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.3 = call zeroext i8 @mult(i8 zeroext %11109, i8 zeroext %11110)
  %conv35.38.3 = zext i8 %call34.38.3 to i32
  %xor36.38.3 = xor i32 %xor.38.3, %conv35.38.3
  %conv37.38.3 = trunc i32 %xor36.38.3 to i8
  store i8 %conv37.38.3, i8* %scevgep41.38.2, align 1
  %scevgep28.38.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11104, i64 0, i64 0, i64 1
  %11111 = bitcast i8* %scevgep28.38.3 to [61 x [61 x i8]]*
  %scevgep41.38.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11105, i64 0, i64 1, i64 0
  %11112 = bitcast i8* %scevgep41.38.3 to [61 x [61 x i8]]*
  %call16.38.4 = call zeroext i8 (...) @rand()
  store i8 %call16.38.4, i8* %scevgep28.38.3, align 1
  %11113 = load i8, i8* %scevgep28.38.3, align 1
  %conv23.38.4 = zext i8 %11113 to i32
  %11114 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.4 = getelementptr i8, i8* %b, i64 43
  %11115 = load i8, i8* %scevgep34.38.4, align 1
  %call28.38.4 = call zeroext i8 @mult(i8 zeroext %11114, i8 zeroext %11115)
  %conv29.38.4 = zext i8 %call28.38.4 to i32
  %xor.38.4 = xor i32 %conv23.38.4, %conv29.38.4
  %scevgep35.38.4 = getelementptr i8, i8* %a, i64 43
  %11116 = load i8, i8* %scevgep35.38.4, align 1
  %11117 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.4 = call zeroext i8 @mult(i8 zeroext %11116, i8 zeroext %11117)
  %conv35.38.4 = zext i8 %call34.38.4 to i32
  %xor36.38.4 = xor i32 %xor.38.4, %conv35.38.4
  %conv37.38.4 = trunc i32 %xor36.38.4 to i8
  store i8 %conv37.38.4, i8* %scevgep41.38.3, align 1
  %scevgep28.38.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11111, i64 0, i64 0, i64 1
  %11118 = bitcast i8* %scevgep28.38.4 to [61 x [61 x i8]]*
  %scevgep41.38.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11112, i64 0, i64 1, i64 0
  %11119 = bitcast i8* %scevgep41.38.4 to [61 x [61 x i8]]*
  %call16.38.5 = call zeroext i8 (...) @rand()
  store i8 %call16.38.5, i8* %scevgep28.38.4, align 1
  %11120 = load i8, i8* %scevgep28.38.4, align 1
  %conv23.38.5 = zext i8 %11120 to i32
  %11121 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.5 = getelementptr i8, i8* %b, i64 44
  %11122 = load i8, i8* %scevgep34.38.5, align 1
  %call28.38.5 = call zeroext i8 @mult(i8 zeroext %11121, i8 zeroext %11122)
  %conv29.38.5 = zext i8 %call28.38.5 to i32
  %xor.38.5 = xor i32 %conv23.38.5, %conv29.38.5
  %scevgep35.38.5 = getelementptr i8, i8* %a, i64 44
  %11123 = load i8, i8* %scevgep35.38.5, align 1
  %11124 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.5 = call zeroext i8 @mult(i8 zeroext %11123, i8 zeroext %11124)
  %conv35.38.5 = zext i8 %call34.38.5 to i32
  %xor36.38.5 = xor i32 %xor.38.5, %conv35.38.5
  %conv37.38.5 = trunc i32 %xor36.38.5 to i8
  store i8 %conv37.38.5, i8* %scevgep41.38.4, align 1
  %scevgep28.38.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11118, i64 0, i64 0, i64 1
  %11125 = bitcast i8* %scevgep28.38.5 to [61 x [61 x i8]]*
  %scevgep41.38.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11119, i64 0, i64 1, i64 0
  %11126 = bitcast i8* %scevgep41.38.5 to [61 x [61 x i8]]*
  %call16.38.6 = call zeroext i8 (...) @rand()
  store i8 %call16.38.6, i8* %scevgep28.38.5, align 1
  %11127 = load i8, i8* %scevgep28.38.5, align 1
  %conv23.38.6 = zext i8 %11127 to i32
  %11128 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.6 = getelementptr i8, i8* %b, i64 45
  %11129 = load i8, i8* %scevgep34.38.6, align 1
  %call28.38.6 = call zeroext i8 @mult(i8 zeroext %11128, i8 zeroext %11129)
  %conv29.38.6 = zext i8 %call28.38.6 to i32
  %xor.38.6 = xor i32 %conv23.38.6, %conv29.38.6
  %scevgep35.38.6 = getelementptr i8, i8* %a, i64 45
  %11130 = load i8, i8* %scevgep35.38.6, align 1
  %11131 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.6 = call zeroext i8 @mult(i8 zeroext %11130, i8 zeroext %11131)
  %conv35.38.6 = zext i8 %call34.38.6 to i32
  %xor36.38.6 = xor i32 %xor.38.6, %conv35.38.6
  %conv37.38.6 = trunc i32 %xor36.38.6 to i8
  store i8 %conv37.38.6, i8* %scevgep41.38.5, align 1
  %scevgep28.38.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11125, i64 0, i64 0, i64 1
  %11132 = bitcast i8* %scevgep28.38.6 to [61 x [61 x i8]]*
  %scevgep41.38.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11126, i64 0, i64 1, i64 0
  %11133 = bitcast i8* %scevgep41.38.6 to [61 x [61 x i8]]*
  %call16.38.7 = call zeroext i8 (...) @rand()
  store i8 %call16.38.7, i8* %scevgep28.38.6, align 1
  %11134 = load i8, i8* %scevgep28.38.6, align 1
  %conv23.38.7 = zext i8 %11134 to i32
  %11135 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.7 = getelementptr i8, i8* %b, i64 46
  %11136 = load i8, i8* %scevgep34.38.7, align 1
  %call28.38.7 = call zeroext i8 @mult(i8 zeroext %11135, i8 zeroext %11136)
  %conv29.38.7 = zext i8 %call28.38.7 to i32
  %xor.38.7 = xor i32 %conv23.38.7, %conv29.38.7
  %scevgep35.38.7 = getelementptr i8, i8* %a, i64 46
  %11137 = load i8, i8* %scevgep35.38.7, align 1
  %11138 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.7 = call zeroext i8 @mult(i8 zeroext %11137, i8 zeroext %11138)
  %conv35.38.7 = zext i8 %call34.38.7 to i32
  %xor36.38.7 = xor i32 %xor.38.7, %conv35.38.7
  %conv37.38.7 = trunc i32 %xor36.38.7 to i8
  store i8 %conv37.38.7, i8* %scevgep41.38.6, align 1
  %scevgep28.38.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11132, i64 0, i64 0, i64 1
  %11139 = bitcast i8* %scevgep28.38.7 to [61 x [61 x i8]]*
  %scevgep41.38.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11133, i64 0, i64 1, i64 0
  %11140 = bitcast i8* %scevgep41.38.7 to [61 x [61 x i8]]*
  %call16.38.8 = call zeroext i8 (...) @rand()
  store i8 %call16.38.8, i8* %scevgep28.38.7, align 1
  %11141 = load i8, i8* %scevgep28.38.7, align 1
  %conv23.38.8 = zext i8 %11141 to i32
  %11142 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.8 = getelementptr i8, i8* %b, i64 47
  %11143 = load i8, i8* %scevgep34.38.8, align 1
  %call28.38.8 = call zeroext i8 @mult(i8 zeroext %11142, i8 zeroext %11143)
  %conv29.38.8 = zext i8 %call28.38.8 to i32
  %xor.38.8 = xor i32 %conv23.38.8, %conv29.38.8
  %scevgep35.38.8 = getelementptr i8, i8* %a, i64 47
  %11144 = load i8, i8* %scevgep35.38.8, align 1
  %11145 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.8 = call zeroext i8 @mult(i8 zeroext %11144, i8 zeroext %11145)
  %conv35.38.8 = zext i8 %call34.38.8 to i32
  %xor36.38.8 = xor i32 %xor.38.8, %conv35.38.8
  %conv37.38.8 = trunc i32 %xor36.38.8 to i8
  store i8 %conv37.38.8, i8* %scevgep41.38.7, align 1
  %scevgep28.38.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11139, i64 0, i64 0, i64 1
  %11146 = bitcast i8* %scevgep28.38.8 to [61 x [61 x i8]]*
  %scevgep41.38.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11140, i64 0, i64 1, i64 0
  %11147 = bitcast i8* %scevgep41.38.8 to [61 x [61 x i8]]*
  %call16.38.9 = call zeroext i8 (...) @rand()
  store i8 %call16.38.9, i8* %scevgep28.38.8, align 1
  %11148 = load i8, i8* %scevgep28.38.8, align 1
  %conv23.38.9 = zext i8 %11148 to i32
  %11149 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.9 = getelementptr i8, i8* %b, i64 48
  %11150 = load i8, i8* %scevgep34.38.9, align 1
  %call28.38.9 = call zeroext i8 @mult(i8 zeroext %11149, i8 zeroext %11150)
  %conv29.38.9 = zext i8 %call28.38.9 to i32
  %xor.38.9 = xor i32 %conv23.38.9, %conv29.38.9
  %scevgep35.38.9 = getelementptr i8, i8* %a, i64 48
  %11151 = load i8, i8* %scevgep35.38.9, align 1
  %11152 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.9 = call zeroext i8 @mult(i8 zeroext %11151, i8 zeroext %11152)
  %conv35.38.9 = zext i8 %call34.38.9 to i32
  %xor36.38.9 = xor i32 %xor.38.9, %conv35.38.9
  %conv37.38.9 = trunc i32 %xor36.38.9 to i8
  store i8 %conv37.38.9, i8* %scevgep41.38.8, align 1
  %scevgep28.38.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11146, i64 0, i64 0, i64 1
  %11153 = bitcast i8* %scevgep28.38.9 to [61 x [61 x i8]]*
  %scevgep41.38.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11147, i64 0, i64 1, i64 0
  %11154 = bitcast i8* %scevgep41.38.9 to [61 x [61 x i8]]*
  %call16.38.10 = call zeroext i8 (...) @rand()
  store i8 %call16.38.10, i8* %scevgep28.38.9, align 1
  %11155 = load i8, i8* %scevgep28.38.9, align 1
  %conv23.38.10 = zext i8 %11155 to i32
  %11156 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.10 = getelementptr i8, i8* %b, i64 49
  %11157 = load i8, i8* %scevgep34.38.10, align 1
  %call28.38.10 = call zeroext i8 @mult(i8 zeroext %11156, i8 zeroext %11157)
  %conv29.38.10 = zext i8 %call28.38.10 to i32
  %xor.38.10 = xor i32 %conv23.38.10, %conv29.38.10
  %scevgep35.38.10 = getelementptr i8, i8* %a, i64 49
  %11158 = load i8, i8* %scevgep35.38.10, align 1
  %11159 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.10 = call zeroext i8 @mult(i8 zeroext %11158, i8 zeroext %11159)
  %conv35.38.10 = zext i8 %call34.38.10 to i32
  %xor36.38.10 = xor i32 %xor.38.10, %conv35.38.10
  %conv37.38.10 = trunc i32 %xor36.38.10 to i8
  store i8 %conv37.38.10, i8* %scevgep41.38.9, align 1
  %scevgep28.38.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11153, i64 0, i64 0, i64 1
  %11160 = bitcast i8* %scevgep28.38.10 to [61 x [61 x i8]]*
  %scevgep41.38.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11154, i64 0, i64 1, i64 0
  %11161 = bitcast i8* %scevgep41.38.10 to [61 x [61 x i8]]*
  %call16.38.11 = call zeroext i8 (...) @rand()
  store i8 %call16.38.11, i8* %scevgep28.38.10, align 1
  %11162 = load i8, i8* %scevgep28.38.10, align 1
  %conv23.38.11 = zext i8 %11162 to i32
  %11163 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.11 = getelementptr i8, i8* %b, i64 50
  %11164 = load i8, i8* %scevgep34.38.11, align 1
  %call28.38.11 = call zeroext i8 @mult(i8 zeroext %11163, i8 zeroext %11164)
  %conv29.38.11 = zext i8 %call28.38.11 to i32
  %xor.38.11 = xor i32 %conv23.38.11, %conv29.38.11
  %scevgep35.38.11 = getelementptr i8, i8* %a, i64 50
  %11165 = load i8, i8* %scevgep35.38.11, align 1
  %11166 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.11 = call zeroext i8 @mult(i8 zeroext %11165, i8 zeroext %11166)
  %conv35.38.11 = zext i8 %call34.38.11 to i32
  %xor36.38.11 = xor i32 %xor.38.11, %conv35.38.11
  %conv37.38.11 = trunc i32 %xor36.38.11 to i8
  store i8 %conv37.38.11, i8* %scevgep41.38.10, align 1
  %scevgep28.38.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11160, i64 0, i64 0, i64 1
  %11167 = bitcast i8* %scevgep28.38.11 to [61 x [61 x i8]]*
  %scevgep41.38.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11161, i64 0, i64 1, i64 0
  %11168 = bitcast i8* %scevgep41.38.11 to [61 x [61 x i8]]*
  %call16.38.12 = call zeroext i8 (...) @rand()
  store i8 %call16.38.12, i8* %scevgep28.38.11, align 1
  %11169 = load i8, i8* %scevgep28.38.11, align 1
  %conv23.38.12 = zext i8 %11169 to i32
  %11170 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.12 = getelementptr i8, i8* %b, i64 51
  %11171 = load i8, i8* %scevgep34.38.12, align 1
  %call28.38.12 = call zeroext i8 @mult(i8 zeroext %11170, i8 zeroext %11171)
  %conv29.38.12 = zext i8 %call28.38.12 to i32
  %xor.38.12 = xor i32 %conv23.38.12, %conv29.38.12
  %scevgep35.38.12 = getelementptr i8, i8* %a, i64 51
  %11172 = load i8, i8* %scevgep35.38.12, align 1
  %11173 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.12 = call zeroext i8 @mult(i8 zeroext %11172, i8 zeroext %11173)
  %conv35.38.12 = zext i8 %call34.38.12 to i32
  %xor36.38.12 = xor i32 %xor.38.12, %conv35.38.12
  %conv37.38.12 = trunc i32 %xor36.38.12 to i8
  store i8 %conv37.38.12, i8* %scevgep41.38.11, align 1
  %scevgep28.38.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11167, i64 0, i64 0, i64 1
  %11174 = bitcast i8* %scevgep28.38.12 to [61 x [61 x i8]]*
  %scevgep41.38.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11168, i64 0, i64 1, i64 0
  %11175 = bitcast i8* %scevgep41.38.12 to [61 x [61 x i8]]*
  %call16.38.13 = call zeroext i8 (...) @rand()
  store i8 %call16.38.13, i8* %scevgep28.38.12, align 1
  %11176 = load i8, i8* %scevgep28.38.12, align 1
  %conv23.38.13 = zext i8 %11176 to i32
  %11177 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.13 = getelementptr i8, i8* %b, i64 52
  %11178 = load i8, i8* %scevgep34.38.13, align 1
  %call28.38.13 = call zeroext i8 @mult(i8 zeroext %11177, i8 zeroext %11178)
  %conv29.38.13 = zext i8 %call28.38.13 to i32
  %xor.38.13 = xor i32 %conv23.38.13, %conv29.38.13
  %scevgep35.38.13 = getelementptr i8, i8* %a, i64 52
  %11179 = load i8, i8* %scevgep35.38.13, align 1
  %11180 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.13 = call zeroext i8 @mult(i8 zeroext %11179, i8 zeroext %11180)
  %conv35.38.13 = zext i8 %call34.38.13 to i32
  %xor36.38.13 = xor i32 %xor.38.13, %conv35.38.13
  %conv37.38.13 = trunc i32 %xor36.38.13 to i8
  store i8 %conv37.38.13, i8* %scevgep41.38.12, align 1
  %scevgep28.38.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11174, i64 0, i64 0, i64 1
  %11181 = bitcast i8* %scevgep28.38.13 to [61 x [61 x i8]]*
  %scevgep41.38.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11175, i64 0, i64 1, i64 0
  %11182 = bitcast i8* %scevgep41.38.13 to [61 x [61 x i8]]*
  %call16.38.14 = call zeroext i8 (...) @rand()
  store i8 %call16.38.14, i8* %scevgep28.38.13, align 1
  %11183 = load i8, i8* %scevgep28.38.13, align 1
  %conv23.38.14 = zext i8 %11183 to i32
  %11184 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.14 = getelementptr i8, i8* %b, i64 53
  %11185 = load i8, i8* %scevgep34.38.14, align 1
  %call28.38.14 = call zeroext i8 @mult(i8 zeroext %11184, i8 zeroext %11185)
  %conv29.38.14 = zext i8 %call28.38.14 to i32
  %xor.38.14 = xor i32 %conv23.38.14, %conv29.38.14
  %scevgep35.38.14 = getelementptr i8, i8* %a, i64 53
  %11186 = load i8, i8* %scevgep35.38.14, align 1
  %11187 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.14 = call zeroext i8 @mult(i8 zeroext %11186, i8 zeroext %11187)
  %conv35.38.14 = zext i8 %call34.38.14 to i32
  %xor36.38.14 = xor i32 %xor.38.14, %conv35.38.14
  %conv37.38.14 = trunc i32 %xor36.38.14 to i8
  store i8 %conv37.38.14, i8* %scevgep41.38.13, align 1
  %scevgep28.38.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11181, i64 0, i64 0, i64 1
  %11188 = bitcast i8* %scevgep28.38.14 to [61 x [61 x i8]]*
  %scevgep41.38.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11182, i64 0, i64 1, i64 0
  %11189 = bitcast i8* %scevgep41.38.14 to [61 x [61 x i8]]*
  %call16.38.15 = call zeroext i8 (...) @rand()
  store i8 %call16.38.15, i8* %scevgep28.38.14, align 1
  %11190 = load i8, i8* %scevgep28.38.14, align 1
  %conv23.38.15 = zext i8 %11190 to i32
  %11191 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.15 = getelementptr i8, i8* %b, i64 54
  %11192 = load i8, i8* %scevgep34.38.15, align 1
  %call28.38.15 = call zeroext i8 @mult(i8 zeroext %11191, i8 zeroext %11192)
  %conv29.38.15 = zext i8 %call28.38.15 to i32
  %xor.38.15 = xor i32 %conv23.38.15, %conv29.38.15
  %scevgep35.38.15 = getelementptr i8, i8* %a, i64 54
  %11193 = load i8, i8* %scevgep35.38.15, align 1
  %11194 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.15 = call zeroext i8 @mult(i8 zeroext %11193, i8 zeroext %11194)
  %conv35.38.15 = zext i8 %call34.38.15 to i32
  %xor36.38.15 = xor i32 %xor.38.15, %conv35.38.15
  %conv37.38.15 = trunc i32 %xor36.38.15 to i8
  store i8 %conv37.38.15, i8* %scevgep41.38.14, align 1
  %scevgep28.38.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11188, i64 0, i64 0, i64 1
  %11195 = bitcast i8* %scevgep28.38.15 to [61 x [61 x i8]]*
  %scevgep41.38.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11189, i64 0, i64 1, i64 0
  %11196 = bitcast i8* %scevgep41.38.15 to [61 x [61 x i8]]*
  %call16.38.16 = call zeroext i8 (...) @rand()
  store i8 %call16.38.16, i8* %scevgep28.38.15, align 1
  %11197 = load i8, i8* %scevgep28.38.15, align 1
  %conv23.38.16 = zext i8 %11197 to i32
  %11198 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.16 = getelementptr i8, i8* %b, i64 55
  %11199 = load i8, i8* %scevgep34.38.16, align 1
  %call28.38.16 = call zeroext i8 @mult(i8 zeroext %11198, i8 zeroext %11199)
  %conv29.38.16 = zext i8 %call28.38.16 to i32
  %xor.38.16 = xor i32 %conv23.38.16, %conv29.38.16
  %scevgep35.38.16 = getelementptr i8, i8* %a, i64 55
  %11200 = load i8, i8* %scevgep35.38.16, align 1
  %11201 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.16 = call zeroext i8 @mult(i8 zeroext %11200, i8 zeroext %11201)
  %conv35.38.16 = zext i8 %call34.38.16 to i32
  %xor36.38.16 = xor i32 %xor.38.16, %conv35.38.16
  %conv37.38.16 = trunc i32 %xor36.38.16 to i8
  store i8 %conv37.38.16, i8* %scevgep41.38.15, align 1
  %scevgep28.38.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11195, i64 0, i64 0, i64 1
  %11202 = bitcast i8* %scevgep28.38.16 to [61 x [61 x i8]]*
  %scevgep41.38.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11196, i64 0, i64 1, i64 0
  %11203 = bitcast i8* %scevgep41.38.16 to [61 x [61 x i8]]*
  %call16.38.17 = call zeroext i8 (...) @rand()
  store i8 %call16.38.17, i8* %scevgep28.38.16, align 1
  %11204 = load i8, i8* %scevgep28.38.16, align 1
  %conv23.38.17 = zext i8 %11204 to i32
  %11205 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.17 = getelementptr i8, i8* %b, i64 56
  %11206 = load i8, i8* %scevgep34.38.17, align 1
  %call28.38.17 = call zeroext i8 @mult(i8 zeroext %11205, i8 zeroext %11206)
  %conv29.38.17 = zext i8 %call28.38.17 to i32
  %xor.38.17 = xor i32 %conv23.38.17, %conv29.38.17
  %scevgep35.38.17 = getelementptr i8, i8* %a, i64 56
  %11207 = load i8, i8* %scevgep35.38.17, align 1
  %11208 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.17 = call zeroext i8 @mult(i8 zeroext %11207, i8 zeroext %11208)
  %conv35.38.17 = zext i8 %call34.38.17 to i32
  %xor36.38.17 = xor i32 %xor.38.17, %conv35.38.17
  %conv37.38.17 = trunc i32 %xor36.38.17 to i8
  store i8 %conv37.38.17, i8* %scevgep41.38.16, align 1
  %scevgep28.38.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11202, i64 0, i64 0, i64 1
  %11209 = bitcast i8* %scevgep28.38.17 to [61 x [61 x i8]]*
  %scevgep41.38.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11203, i64 0, i64 1, i64 0
  %11210 = bitcast i8* %scevgep41.38.17 to [61 x [61 x i8]]*
  %call16.38.18 = call zeroext i8 (...) @rand()
  store i8 %call16.38.18, i8* %scevgep28.38.17, align 1
  %11211 = load i8, i8* %scevgep28.38.17, align 1
  %conv23.38.18 = zext i8 %11211 to i32
  %11212 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.18 = getelementptr i8, i8* %b, i64 57
  %11213 = load i8, i8* %scevgep34.38.18, align 1
  %call28.38.18 = call zeroext i8 @mult(i8 zeroext %11212, i8 zeroext %11213)
  %conv29.38.18 = zext i8 %call28.38.18 to i32
  %xor.38.18 = xor i32 %conv23.38.18, %conv29.38.18
  %scevgep35.38.18 = getelementptr i8, i8* %a, i64 57
  %11214 = load i8, i8* %scevgep35.38.18, align 1
  %11215 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.18 = call zeroext i8 @mult(i8 zeroext %11214, i8 zeroext %11215)
  %conv35.38.18 = zext i8 %call34.38.18 to i32
  %xor36.38.18 = xor i32 %xor.38.18, %conv35.38.18
  %conv37.38.18 = trunc i32 %xor36.38.18 to i8
  store i8 %conv37.38.18, i8* %scevgep41.38.17, align 1
  %scevgep28.38.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11209, i64 0, i64 0, i64 1
  %11216 = bitcast i8* %scevgep28.38.18 to [61 x [61 x i8]]*
  %scevgep41.38.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11210, i64 0, i64 1, i64 0
  %11217 = bitcast i8* %scevgep41.38.18 to [61 x [61 x i8]]*
  %call16.38.19 = call zeroext i8 (...) @rand()
  store i8 %call16.38.19, i8* %scevgep28.38.18, align 1
  %11218 = load i8, i8* %scevgep28.38.18, align 1
  %conv23.38.19 = zext i8 %11218 to i32
  %11219 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.19 = getelementptr i8, i8* %b, i64 58
  %11220 = load i8, i8* %scevgep34.38.19, align 1
  %call28.38.19 = call zeroext i8 @mult(i8 zeroext %11219, i8 zeroext %11220)
  %conv29.38.19 = zext i8 %call28.38.19 to i32
  %xor.38.19 = xor i32 %conv23.38.19, %conv29.38.19
  %scevgep35.38.19 = getelementptr i8, i8* %a, i64 58
  %11221 = load i8, i8* %scevgep35.38.19, align 1
  %11222 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.19 = call zeroext i8 @mult(i8 zeroext %11221, i8 zeroext %11222)
  %conv35.38.19 = zext i8 %call34.38.19 to i32
  %xor36.38.19 = xor i32 %xor.38.19, %conv35.38.19
  %conv37.38.19 = trunc i32 %xor36.38.19 to i8
  store i8 %conv37.38.19, i8* %scevgep41.38.18, align 1
  %scevgep28.38.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11216, i64 0, i64 0, i64 1
  %11223 = bitcast i8* %scevgep28.38.19 to [61 x [61 x i8]]*
  %scevgep41.38.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11217, i64 0, i64 1, i64 0
  %11224 = bitcast i8* %scevgep41.38.19 to [61 x [61 x i8]]*
  %call16.38.20 = call zeroext i8 (...) @rand()
  store i8 %call16.38.20, i8* %scevgep28.38.19, align 1
  %11225 = load i8, i8* %scevgep28.38.19, align 1
  %conv23.38.20 = zext i8 %11225 to i32
  %11226 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.20 = getelementptr i8, i8* %b, i64 59
  %11227 = load i8, i8* %scevgep34.38.20, align 1
  %call28.38.20 = call zeroext i8 @mult(i8 zeroext %11226, i8 zeroext %11227)
  %conv29.38.20 = zext i8 %call28.38.20 to i32
  %xor.38.20 = xor i32 %conv23.38.20, %conv29.38.20
  %scevgep35.38.20 = getelementptr i8, i8* %a, i64 59
  %11228 = load i8, i8* %scevgep35.38.20, align 1
  %11229 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.20 = call zeroext i8 @mult(i8 zeroext %11228, i8 zeroext %11229)
  %conv35.38.20 = zext i8 %call34.38.20 to i32
  %xor36.38.20 = xor i32 %xor.38.20, %conv35.38.20
  %conv37.38.20 = trunc i32 %xor36.38.20 to i8
  store i8 %conv37.38.20, i8* %scevgep41.38.19, align 1
  %scevgep28.38.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11223, i64 0, i64 0, i64 1
  %scevgep41.38.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11224, i64 0, i64 1, i64 0
  %call16.38.21 = call zeroext i8 (...) @rand()
  store i8 %call16.38.21, i8* %scevgep28.38.20, align 1
  %11230 = load i8, i8* %scevgep28.38.20, align 1
  %conv23.38.21 = zext i8 %11230 to i32
  %11231 = load i8, i8* %arrayidx25.38, align 1
  %scevgep34.38.21 = getelementptr i8, i8* %b, i64 60
  %11232 = load i8, i8* %scevgep34.38.21, align 1
  %call28.38.21 = call zeroext i8 @mult(i8 zeroext %11231, i8 zeroext %11232)
  %conv29.38.21 = zext i8 %call28.38.21 to i32
  %xor.38.21 = xor i32 %conv23.38.21, %conv29.38.21
  %scevgep35.38.21 = getelementptr i8, i8* %a, i64 60
  %11233 = load i8, i8* %scevgep35.38.21, align 1
  %11234 = load i8, i8* %arrayidx33.38, align 1
  %call34.38.21 = call zeroext i8 @mult(i8 zeroext %11233, i8 zeroext %11234)
  %conv35.38.21 = zext i8 %call34.38.21 to i32
  %xor36.38.21 = xor i32 %xor.38.21, %conv35.38.21
  %conv37.38.21 = trunc i32 %xor36.38.21 to i8
  store i8 %conv37.38.21, i8* %scevgep41.38.20, align 1
  %scevgep26.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11083, i64 0, i64 1, i64 1
  %11235 = bitcast i8* %scevgep26.38 to [61 x [61 x i8]]*
  %scevgep39.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11084, i64 0, i64 1, i64 1
  %11236 = bitcast i8* %scevgep39.38 to [61 x [61 x i8]]*
  %arrayidx25.39 = getelementptr inbounds i8, i8* %a, i64 39
  %arrayidx33.39 = getelementptr inbounds i8, i8* %b, i64 39
  %call16.39 = call zeroext i8 (...) @rand()
  store i8 %call16.39, i8* %scevgep26.38, align 1
  %11237 = load i8, i8* %scevgep26.38, align 1
  %conv23.39 = zext i8 %11237 to i32
  %11238 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39 = getelementptr i8, i8* %b, i64 40
  %11239 = load i8, i8* %scevgep34.39, align 1
  %call28.39 = call zeroext i8 @mult(i8 zeroext %11238, i8 zeroext %11239)
  %conv29.39 = zext i8 %call28.39 to i32
  %xor.39 = xor i32 %conv23.39, %conv29.39
  %scevgep35.39 = getelementptr i8, i8* %a, i64 40
  %11240 = load i8, i8* %scevgep35.39, align 1
  %11241 = load i8, i8* %arrayidx33.39, align 1
  %call34.39 = call zeroext i8 @mult(i8 zeroext %11240, i8 zeroext %11241)
  %conv35.39 = zext i8 %call34.39 to i32
  %xor36.39 = xor i32 %xor.39, %conv35.39
  %conv37.39 = trunc i32 %xor36.39 to i8
  store i8 %conv37.39, i8* %scevgep39.38, align 1
  %scevgep28.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11235, i64 0, i64 0, i64 1
  %11242 = bitcast i8* %scevgep28.39 to [61 x [61 x i8]]*
  %scevgep41.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11236, i64 0, i64 1, i64 0
  %11243 = bitcast i8* %scevgep41.39 to [61 x [61 x i8]]*
  %call16.39.1 = call zeroext i8 (...) @rand()
  store i8 %call16.39.1, i8* %scevgep28.39, align 1
  %11244 = load i8, i8* %scevgep28.39, align 1
  %conv23.39.1 = zext i8 %11244 to i32
  %11245 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.1 = getelementptr i8, i8* %b, i64 41
  %11246 = load i8, i8* %scevgep34.39.1, align 1
  %call28.39.1 = call zeroext i8 @mult(i8 zeroext %11245, i8 zeroext %11246)
  %conv29.39.1 = zext i8 %call28.39.1 to i32
  %xor.39.1 = xor i32 %conv23.39.1, %conv29.39.1
  %scevgep35.39.1 = getelementptr i8, i8* %a, i64 41
  %11247 = load i8, i8* %scevgep35.39.1, align 1
  %11248 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.1 = call zeroext i8 @mult(i8 zeroext %11247, i8 zeroext %11248)
  %conv35.39.1 = zext i8 %call34.39.1 to i32
  %xor36.39.1 = xor i32 %xor.39.1, %conv35.39.1
  %conv37.39.1 = trunc i32 %xor36.39.1 to i8
  store i8 %conv37.39.1, i8* %scevgep41.39, align 1
  %scevgep28.39.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11242, i64 0, i64 0, i64 1
  %11249 = bitcast i8* %scevgep28.39.1 to [61 x [61 x i8]]*
  %scevgep41.39.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11243, i64 0, i64 1, i64 0
  %11250 = bitcast i8* %scevgep41.39.1 to [61 x [61 x i8]]*
  %call16.39.2 = call zeroext i8 (...) @rand()
  store i8 %call16.39.2, i8* %scevgep28.39.1, align 1
  %11251 = load i8, i8* %scevgep28.39.1, align 1
  %conv23.39.2 = zext i8 %11251 to i32
  %11252 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.2 = getelementptr i8, i8* %b, i64 42
  %11253 = load i8, i8* %scevgep34.39.2, align 1
  %call28.39.2 = call zeroext i8 @mult(i8 zeroext %11252, i8 zeroext %11253)
  %conv29.39.2 = zext i8 %call28.39.2 to i32
  %xor.39.2 = xor i32 %conv23.39.2, %conv29.39.2
  %scevgep35.39.2 = getelementptr i8, i8* %a, i64 42
  %11254 = load i8, i8* %scevgep35.39.2, align 1
  %11255 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.2 = call zeroext i8 @mult(i8 zeroext %11254, i8 zeroext %11255)
  %conv35.39.2 = zext i8 %call34.39.2 to i32
  %xor36.39.2 = xor i32 %xor.39.2, %conv35.39.2
  %conv37.39.2 = trunc i32 %xor36.39.2 to i8
  store i8 %conv37.39.2, i8* %scevgep41.39.1, align 1
  %scevgep28.39.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11249, i64 0, i64 0, i64 1
  %11256 = bitcast i8* %scevgep28.39.2 to [61 x [61 x i8]]*
  %scevgep41.39.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11250, i64 0, i64 1, i64 0
  %11257 = bitcast i8* %scevgep41.39.2 to [61 x [61 x i8]]*
  %call16.39.3 = call zeroext i8 (...) @rand()
  store i8 %call16.39.3, i8* %scevgep28.39.2, align 1
  %11258 = load i8, i8* %scevgep28.39.2, align 1
  %conv23.39.3 = zext i8 %11258 to i32
  %11259 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.3 = getelementptr i8, i8* %b, i64 43
  %11260 = load i8, i8* %scevgep34.39.3, align 1
  %call28.39.3 = call zeroext i8 @mult(i8 zeroext %11259, i8 zeroext %11260)
  %conv29.39.3 = zext i8 %call28.39.3 to i32
  %xor.39.3 = xor i32 %conv23.39.3, %conv29.39.3
  %scevgep35.39.3 = getelementptr i8, i8* %a, i64 43
  %11261 = load i8, i8* %scevgep35.39.3, align 1
  %11262 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.3 = call zeroext i8 @mult(i8 zeroext %11261, i8 zeroext %11262)
  %conv35.39.3 = zext i8 %call34.39.3 to i32
  %xor36.39.3 = xor i32 %xor.39.3, %conv35.39.3
  %conv37.39.3 = trunc i32 %xor36.39.3 to i8
  store i8 %conv37.39.3, i8* %scevgep41.39.2, align 1
  %scevgep28.39.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11256, i64 0, i64 0, i64 1
  %11263 = bitcast i8* %scevgep28.39.3 to [61 x [61 x i8]]*
  %scevgep41.39.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11257, i64 0, i64 1, i64 0
  %11264 = bitcast i8* %scevgep41.39.3 to [61 x [61 x i8]]*
  %call16.39.4 = call zeroext i8 (...) @rand()
  store i8 %call16.39.4, i8* %scevgep28.39.3, align 1
  %11265 = load i8, i8* %scevgep28.39.3, align 1
  %conv23.39.4 = zext i8 %11265 to i32
  %11266 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.4 = getelementptr i8, i8* %b, i64 44
  %11267 = load i8, i8* %scevgep34.39.4, align 1
  %call28.39.4 = call zeroext i8 @mult(i8 zeroext %11266, i8 zeroext %11267)
  %conv29.39.4 = zext i8 %call28.39.4 to i32
  %xor.39.4 = xor i32 %conv23.39.4, %conv29.39.4
  %scevgep35.39.4 = getelementptr i8, i8* %a, i64 44
  %11268 = load i8, i8* %scevgep35.39.4, align 1
  %11269 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.4 = call zeroext i8 @mult(i8 zeroext %11268, i8 zeroext %11269)
  %conv35.39.4 = zext i8 %call34.39.4 to i32
  %xor36.39.4 = xor i32 %xor.39.4, %conv35.39.4
  %conv37.39.4 = trunc i32 %xor36.39.4 to i8
  store i8 %conv37.39.4, i8* %scevgep41.39.3, align 1
  %scevgep28.39.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11263, i64 0, i64 0, i64 1
  %11270 = bitcast i8* %scevgep28.39.4 to [61 x [61 x i8]]*
  %scevgep41.39.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11264, i64 0, i64 1, i64 0
  %11271 = bitcast i8* %scevgep41.39.4 to [61 x [61 x i8]]*
  %call16.39.5 = call zeroext i8 (...) @rand()
  store i8 %call16.39.5, i8* %scevgep28.39.4, align 1
  %11272 = load i8, i8* %scevgep28.39.4, align 1
  %conv23.39.5 = zext i8 %11272 to i32
  %11273 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.5 = getelementptr i8, i8* %b, i64 45
  %11274 = load i8, i8* %scevgep34.39.5, align 1
  %call28.39.5 = call zeroext i8 @mult(i8 zeroext %11273, i8 zeroext %11274)
  %conv29.39.5 = zext i8 %call28.39.5 to i32
  %xor.39.5 = xor i32 %conv23.39.5, %conv29.39.5
  %scevgep35.39.5 = getelementptr i8, i8* %a, i64 45
  %11275 = load i8, i8* %scevgep35.39.5, align 1
  %11276 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.5 = call zeroext i8 @mult(i8 zeroext %11275, i8 zeroext %11276)
  %conv35.39.5 = zext i8 %call34.39.5 to i32
  %xor36.39.5 = xor i32 %xor.39.5, %conv35.39.5
  %conv37.39.5 = trunc i32 %xor36.39.5 to i8
  store i8 %conv37.39.5, i8* %scevgep41.39.4, align 1
  %scevgep28.39.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11270, i64 0, i64 0, i64 1
  %11277 = bitcast i8* %scevgep28.39.5 to [61 x [61 x i8]]*
  %scevgep41.39.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11271, i64 0, i64 1, i64 0
  %11278 = bitcast i8* %scevgep41.39.5 to [61 x [61 x i8]]*
  %call16.39.6 = call zeroext i8 (...) @rand()
  store i8 %call16.39.6, i8* %scevgep28.39.5, align 1
  %11279 = load i8, i8* %scevgep28.39.5, align 1
  %conv23.39.6 = zext i8 %11279 to i32
  %11280 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.6 = getelementptr i8, i8* %b, i64 46
  %11281 = load i8, i8* %scevgep34.39.6, align 1
  %call28.39.6 = call zeroext i8 @mult(i8 zeroext %11280, i8 zeroext %11281)
  %conv29.39.6 = zext i8 %call28.39.6 to i32
  %xor.39.6 = xor i32 %conv23.39.6, %conv29.39.6
  %scevgep35.39.6 = getelementptr i8, i8* %a, i64 46
  %11282 = load i8, i8* %scevgep35.39.6, align 1
  %11283 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.6 = call zeroext i8 @mult(i8 zeroext %11282, i8 zeroext %11283)
  %conv35.39.6 = zext i8 %call34.39.6 to i32
  %xor36.39.6 = xor i32 %xor.39.6, %conv35.39.6
  %conv37.39.6 = trunc i32 %xor36.39.6 to i8
  store i8 %conv37.39.6, i8* %scevgep41.39.5, align 1
  %scevgep28.39.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11277, i64 0, i64 0, i64 1
  %11284 = bitcast i8* %scevgep28.39.6 to [61 x [61 x i8]]*
  %scevgep41.39.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11278, i64 0, i64 1, i64 0
  %11285 = bitcast i8* %scevgep41.39.6 to [61 x [61 x i8]]*
  %call16.39.7 = call zeroext i8 (...) @rand()
  store i8 %call16.39.7, i8* %scevgep28.39.6, align 1
  %11286 = load i8, i8* %scevgep28.39.6, align 1
  %conv23.39.7 = zext i8 %11286 to i32
  %11287 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.7 = getelementptr i8, i8* %b, i64 47
  %11288 = load i8, i8* %scevgep34.39.7, align 1
  %call28.39.7 = call zeroext i8 @mult(i8 zeroext %11287, i8 zeroext %11288)
  %conv29.39.7 = zext i8 %call28.39.7 to i32
  %xor.39.7 = xor i32 %conv23.39.7, %conv29.39.7
  %scevgep35.39.7 = getelementptr i8, i8* %a, i64 47
  %11289 = load i8, i8* %scevgep35.39.7, align 1
  %11290 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.7 = call zeroext i8 @mult(i8 zeroext %11289, i8 zeroext %11290)
  %conv35.39.7 = zext i8 %call34.39.7 to i32
  %xor36.39.7 = xor i32 %xor.39.7, %conv35.39.7
  %conv37.39.7 = trunc i32 %xor36.39.7 to i8
  store i8 %conv37.39.7, i8* %scevgep41.39.6, align 1
  %scevgep28.39.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11284, i64 0, i64 0, i64 1
  %11291 = bitcast i8* %scevgep28.39.7 to [61 x [61 x i8]]*
  %scevgep41.39.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11285, i64 0, i64 1, i64 0
  %11292 = bitcast i8* %scevgep41.39.7 to [61 x [61 x i8]]*
  %call16.39.8 = call zeroext i8 (...) @rand()
  store i8 %call16.39.8, i8* %scevgep28.39.7, align 1
  %11293 = load i8, i8* %scevgep28.39.7, align 1
  %conv23.39.8 = zext i8 %11293 to i32
  %11294 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.8 = getelementptr i8, i8* %b, i64 48
  %11295 = load i8, i8* %scevgep34.39.8, align 1
  %call28.39.8 = call zeroext i8 @mult(i8 zeroext %11294, i8 zeroext %11295)
  %conv29.39.8 = zext i8 %call28.39.8 to i32
  %xor.39.8 = xor i32 %conv23.39.8, %conv29.39.8
  %scevgep35.39.8 = getelementptr i8, i8* %a, i64 48
  %11296 = load i8, i8* %scevgep35.39.8, align 1
  %11297 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.8 = call zeroext i8 @mult(i8 zeroext %11296, i8 zeroext %11297)
  %conv35.39.8 = zext i8 %call34.39.8 to i32
  %xor36.39.8 = xor i32 %xor.39.8, %conv35.39.8
  %conv37.39.8 = trunc i32 %xor36.39.8 to i8
  store i8 %conv37.39.8, i8* %scevgep41.39.7, align 1
  %scevgep28.39.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11291, i64 0, i64 0, i64 1
  %11298 = bitcast i8* %scevgep28.39.8 to [61 x [61 x i8]]*
  %scevgep41.39.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11292, i64 0, i64 1, i64 0
  %11299 = bitcast i8* %scevgep41.39.8 to [61 x [61 x i8]]*
  %call16.39.9 = call zeroext i8 (...) @rand()
  store i8 %call16.39.9, i8* %scevgep28.39.8, align 1
  %11300 = load i8, i8* %scevgep28.39.8, align 1
  %conv23.39.9 = zext i8 %11300 to i32
  %11301 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.9 = getelementptr i8, i8* %b, i64 49
  %11302 = load i8, i8* %scevgep34.39.9, align 1
  %call28.39.9 = call zeroext i8 @mult(i8 zeroext %11301, i8 zeroext %11302)
  %conv29.39.9 = zext i8 %call28.39.9 to i32
  %xor.39.9 = xor i32 %conv23.39.9, %conv29.39.9
  %scevgep35.39.9 = getelementptr i8, i8* %a, i64 49
  %11303 = load i8, i8* %scevgep35.39.9, align 1
  %11304 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.9 = call zeroext i8 @mult(i8 zeroext %11303, i8 zeroext %11304)
  %conv35.39.9 = zext i8 %call34.39.9 to i32
  %xor36.39.9 = xor i32 %xor.39.9, %conv35.39.9
  %conv37.39.9 = trunc i32 %xor36.39.9 to i8
  store i8 %conv37.39.9, i8* %scevgep41.39.8, align 1
  %scevgep28.39.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11298, i64 0, i64 0, i64 1
  %11305 = bitcast i8* %scevgep28.39.9 to [61 x [61 x i8]]*
  %scevgep41.39.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11299, i64 0, i64 1, i64 0
  %11306 = bitcast i8* %scevgep41.39.9 to [61 x [61 x i8]]*
  %call16.39.10 = call zeroext i8 (...) @rand()
  store i8 %call16.39.10, i8* %scevgep28.39.9, align 1
  %11307 = load i8, i8* %scevgep28.39.9, align 1
  %conv23.39.10 = zext i8 %11307 to i32
  %11308 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.10 = getelementptr i8, i8* %b, i64 50
  %11309 = load i8, i8* %scevgep34.39.10, align 1
  %call28.39.10 = call zeroext i8 @mult(i8 zeroext %11308, i8 zeroext %11309)
  %conv29.39.10 = zext i8 %call28.39.10 to i32
  %xor.39.10 = xor i32 %conv23.39.10, %conv29.39.10
  %scevgep35.39.10 = getelementptr i8, i8* %a, i64 50
  %11310 = load i8, i8* %scevgep35.39.10, align 1
  %11311 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.10 = call zeroext i8 @mult(i8 zeroext %11310, i8 zeroext %11311)
  %conv35.39.10 = zext i8 %call34.39.10 to i32
  %xor36.39.10 = xor i32 %xor.39.10, %conv35.39.10
  %conv37.39.10 = trunc i32 %xor36.39.10 to i8
  store i8 %conv37.39.10, i8* %scevgep41.39.9, align 1
  %scevgep28.39.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11305, i64 0, i64 0, i64 1
  %11312 = bitcast i8* %scevgep28.39.10 to [61 x [61 x i8]]*
  %scevgep41.39.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11306, i64 0, i64 1, i64 0
  %11313 = bitcast i8* %scevgep41.39.10 to [61 x [61 x i8]]*
  %call16.39.11 = call zeroext i8 (...) @rand()
  store i8 %call16.39.11, i8* %scevgep28.39.10, align 1
  %11314 = load i8, i8* %scevgep28.39.10, align 1
  %conv23.39.11 = zext i8 %11314 to i32
  %11315 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.11 = getelementptr i8, i8* %b, i64 51
  %11316 = load i8, i8* %scevgep34.39.11, align 1
  %call28.39.11 = call zeroext i8 @mult(i8 zeroext %11315, i8 zeroext %11316)
  %conv29.39.11 = zext i8 %call28.39.11 to i32
  %xor.39.11 = xor i32 %conv23.39.11, %conv29.39.11
  %scevgep35.39.11 = getelementptr i8, i8* %a, i64 51
  %11317 = load i8, i8* %scevgep35.39.11, align 1
  %11318 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.11 = call zeroext i8 @mult(i8 zeroext %11317, i8 zeroext %11318)
  %conv35.39.11 = zext i8 %call34.39.11 to i32
  %xor36.39.11 = xor i32 %xor.39.11, %conv35.39.11
  %conv37.39.11 = trunc i32 %xor36.39.11 to i8
  store i8 %conv37.39.11, i8* %scevgep41.39.10, align 1
  %scevgep28.39.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11312, i64 0, i64 0, i64 1
  %11319 = bitcast i8* %scevgep28.39.11 to [61 x [61 x i8]]*
  %scevgep41.39.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11313, i64 0, i64 1, i64 0
  %11320 = bitcast i8* %scevgep41.39.11 to [61 x [61 x i8]]*
  %call16.39.12 = call zeroext i8 (...) @rand()
  store i8 %call16.39.12, i8* %scevgep28.39.11, align 1
  %11321 = load i8, i8* %scevgep28.39.11, align 1
  %conv23.39.12 = zext i8 %11321 to i32
  %11322 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.12 = getelementptr i8, i8* %b, i64 52
  %11323 = load i8, i8* %scevgep34.39.12, align 1
  %call28.39.12 = call zeroext i8 @mult(i8 zeroext %11322, i8 zeroext %11323)
  %conv29.39.12 = zext i8 %call28.39.12 to i32
  %xor.39.12 = xor i32 %conv23.39.12, %conv29.39.12
  %scevgep35.39.12 = getelementptr i8, i8* %a, i64 52
  %11324 = load i8, i8* %scevgep35.39.12, align 1
  %11325 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.12 = call zeroext i8 @mult(i8 zeroext %11324, i8 zeroext %11325)
  %conv35.39.12 = zext i8 %call34.39.12 to i32
  %xor36.39.12 = xor i32 %xor.39.12, %conv35.39.12
  %conv37.39.12 = trunc i32 %xor36.39.12 to i8
  store i8 %conv37.39.12, i8* %scevgep41.39.11, align 1
  %scevgep28.39.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11319, i64 0, i64 0, i64 1
  %11326 = bitcast i8* %scevgep28.39.12 to [61 x [61 x i8]]*
  %scevgep41.39.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11320, i64 0, i64 1, i64 0
  %11327 = bitcast i8* %scevgep41.39.12 to [61 x [61 x i8]]*
  %call16.39.13 = call zeroext i8 (...) @rand()
  store i8 %call16.39.13, i8* %scevgep28.39.12, align 1
  %11328 = load i8, i8* %scevgep28.39.12, align 1
  %conv23.39.13 = zext i8 %11328 to i32
  %11329 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.13 = getelementptr i8, i8* %b, i64 53
  %11330 = load i8, i8* %scevgep34.39.13, align 1
  %call28.39.13 = call zeroext i8 @mult(i8 zeroext %11329, i8 zeroext %11330)
  %conv29.39.13 = zext i8 %call28.39.13 to i32
  %xor.39.13 = xor i32 %conv23.39.13, %conv29.39.13
  %scevgep35.39.13 = getelementptr i8, i8* %a, i64 53
  %11331 = load i8, i8* %scevgep35.39.13, align 1
  %11332 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.13 = call zeroext i8 @mult(i8 zeroext %11331, i8 zeroext %11332)
  %conv35.39.13 = zext i8 %call34.39.13 to i32
  %xor36.39.13 = xor i32 %xor.39.13, %conv35.39.13
  %conv37.39.13 = trunc i32 %xor36.39.13 to i8
  store i8 %conv37.39.13, i8* %scevgep41.39.12, align 1
  %scevgep28.39.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11326, i64 0, i64 0, i64 1
  %11333 = bitcast i8* %scevgep28.39.13 to [61 x [61 x i8]]*
  %scevgep41.39.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11327, i64 0, i64 1, i64 0
  %11334 = bitcast i8* %scevgep41.39.13 to [61 x [61 x i8]]*
  %call16.39.14 = call zeroext i8 (...) @rand()
  store i8 %call16.39.14, i8* %scevgep28.39.13, align 1
  %11335 = load i8, i8* %scevgep28.39.13, align 1
  %conv23.39.14 = zext i8 %11335 to i32
  %11336 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.14 = getelementptr i8, i8* %b, i64 54
  %11337 = load i8, i8* %scevgep34.39.14, align 1
  %call28.39.14 = call zeroext i8 @mult(i8 zeroext %11336, i8 zeroext %11337)
  %conv29.39.14 = zext i8 %call28.39.14 to i32
  %xor.39.14 = xor i32 %conv23.39.14, %conv29.39.14
  %scevgep35.39.14 = getelementptr i8, i8* %a, i64 54
  %11338 = load i8, i8* %scevgep35.39.14, align 1
  %11339 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.14 = call zeroext i8 @mult(i8 zeroext %11338, i8 zeroext %11339)
  %conv35.39.14 = zext i8 %call34.39.14 to i32
  %xor36.39.14 = xor i32 %xor.39.14, %conv35.39.14
  %conv37.39.14 = trunc i32 %xor36.39.14 to i8
  store i8 %conv37.39.14, i8* %scevgep41.39.13, align 1
  %scevgep28.39.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11333, i64 0, i64 0, i64 1
  %11340 = bitcast i8* %scevgep28.39.14 to [61 x [61 x i8]]*
  %scevgep41.39.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11334, i64 0, i64 1, i64 0
  %11341 = bitcast i8* %scevgep41.39.14 to [61 x [61 x i8]]*
  %call16.39.15 = call zeroext i8 (...) @rand()
  store i8 %call16.39.15, i8* %scevgep28.39.14, align 1
  %11342 = load i8, i8* %scevgep28.39.14, align 1
  %conv23.39.15 = zext i8 %11342 to i32
  %11343 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.15 = getelementptr i8, i8* %b, i64 55
  %11344 = load i8, i8* %scevgep34.39.15, align 1
  %call28.39.15 = call zeroext i8 @mult(i8 zeroext %11343, i8 zeroext %11344)
  %conv29.39.15 = zext i8 %call28.39.15 to i32
  %xor.39.15 = xor i32 %conv23.39.15, %conv29.39.15
  %scevgep35.39.15 = getelementptr i8, i8* %a, i64 55
  %11345 = load i8, i8* %scevgep35.39.15, align 1
  %11346 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.15 = call zeroext i8 @mult(i8 zeroext %11345, i8 zeroext %11346)
  %conv35.39.15 = zext i8 %call34.39.15 to i32
  %xor36.39.15 = xor i32 %xor.39.15, %conv35.39.15
  %conv37.39.15 = trunc i32 %xor36.39.15 to i8
  store i8 %conv37.39.15, i8* %scevgep41.39.14, align 1
  %scevgep28.39.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11340, i64 0, i64 0, i64 1
  %11347 = bitcast i8* %scevgep28.39.15 to [61 x [61 x i8]]*
  %scevgep41.39.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11341, i64 0, i64 1, i64 0
  %11348 = bitcast i8* %scevgep41.39.15 to [61 x [61 x i8]]*
  %call16.39.16 = call zeroext i8 (...) @rand()
  store i8 %call16.39.16, i8* %scevgep28.39.15, align 1
  %11349 = load i8, i8* %scevgep28.39.15, align 1
  %conv23.39.16 = zext i8 %11349 to i32
  %11350 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.16 = getelementptr i8, i8* %b, i64 56
  %11351 = load i8, i8* %scevgep34.39.16, align 1
  %call28.39.16 = call zeroext i8 @mult(i8 zeroext %11350, i8 zeroext %11351)
  %conv29.39.16 = zext i8 %call28.39.16 to i32
  %xor.39.16 = xor i32 %conv23.39.16, %conv29.39.16
  %scevgep35.39.16 = getelementptr i8, i8* %a, i64 56
  %11352 = load i8, i8* %scevgep35.39.16, align 1
  %11353 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.16 = call zeroext i8 @mult(i8 zeroext %11352, i8 zeroext %11353)
  %conv35.39.16 = zext i8 %call34.39.16 to i32
  %xor36.39.16 = xor i32 %xor.39.16, %conv35.39.16
  %conv37.39.16 = trunc i32 %xor36.39.16 to i8
  store i8 %conv37.39.16, i8* %scevgep41.39.15, align 1
  %scevgep28.39.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11347, i64 0, i64 0, i64 1
  %11354 = bitcast i8* %scevgep28.39.16 to [61 x [61 x i8]]*
  %scevgep41.39.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11348, i64 0, i64 1, i64 0
  %11355 = bitcast i8* %scevgep41.39.16 to [61 x [61 x i8]]*
  %call16.39.17 = call zeroext i8 (...) @rand()
  store i8 %call16.39.17, i8* %scevgep28.39.16, align 1
  %11356 = load i8, i8* %scevgep28.39.16, align 1
  %conv23.39.17 = zext i8 %11356 to i32
  %11357 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.17 = getelementptr i8, i8* %b, i64 57
  %11358 = load i8, i8* %scevgep34.39.17, align 1
  %call28.39.17 = call zeroext i8 @mult(i8 zeroext %11357, i8 zeroext %11358)
  %conv29.39.17 = zext i8 %call28.39.17 to i32
  %xor.39.17 = xor i32 %conv23.39.17, %conv29.39.17
  %scevgep35.39.17 = getelementptr i8, i8* %a, i64 57
  %11359 = load i8, i8* %scevgep35.39.17, align 1
  %11360 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.17 = call zeroext i8 @mult(i8 zeroext %11359, i8 zeroext %11360)
  %conv35.39.17 = zext i8 %call34.39.17 to i32
  %xor36.39.17 = xor i32 %xor.39.17, %conv35.39.17
  %conv37.39.17 = trunc i32 %xor36.39.17 to i8
  store i8 %conv37.39.17, i8* %scevgep41.39.16, align 1
  %scevgep28.39.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11354, i64 0, i64 0, i64 1
  %11361 = bitcast i8* %scevgep28.39.17 to [61 x [61 x i8]]*
  %scevgep41.39.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11355, i64 0, i64 1, i64 0
  %11362 = bitcast i8* %scevgep41.39.17 to [61 x [61 x i8]]*
  %call16.39.18 = call zeroext i8 (...) @rand()
  store i8 %call16.39.18, i8* %scevgep28.39.17, align 1
  %11363 = load i8, i8* %scevgep28.39.17, align 1
  %conv23.39.18 = zext i8 %11363 to i32
  %11364 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.18 = getelementptr i8, i8* %b, i64 58
  %11365 = load i8, i8* %scevgep34.39.18, align 1
  %call28.39.18 = call zeroext i8 @mult(i8 zeroext %11364, i8 zeroext %11365)
  %conv29.39.18 = zext i8 %call28.39.18 to i32
  %xor.39.18 = xor i32 %conv23.39.18, %conv29.39.18
  %scevgep35.39.18 = getelementptr i8, i8* %a, i64 58
  %11366 = load i8, i8* %scevgep35.39.18, align 1
  %11367 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.18 = call zeroext i8 @mult(i8 zeroext %11366, i8 zeroext %11367)
  %conv35.39.18 = zext i8 %call34.39.18 to i32
  %xor36.39.18 = xor i32 %xor.39.18, %conv35.39.18
  %conv37.39.18 = trunc i32 %xor36.39.18 to i8
  store i8 %conv37.39.18, i8* %scevgep41.39.17, align 1
  %scevgep28.39.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11361, i64 0, i64 0, i64 1
  %11368 = bitcast i8* %scevgep28.39.18 to [61 x [61 x i8]]*
  %scevgep41.39.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11362, i64 0, i64 1, i64 0
  %11369 = bitcast i8* %scevgep41.39.18 to [61 x [61 x i8]]*
  %call16.39.19 = call zeroext i8 (...) @rand()
  store i8 %call16.39.19, i8* %scevgep28.39.18, align 1
  %11370 = load i8, i8* %scevgep28.39.18, align 1
  %conv23.39.19 = zext i8 %11370 to i32
  %11371 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.19 = getelementptr i8, i8* %b, i64 59
  %11372 = load i8, i8* %scevgep34.39.19, align 1
  %call28.39.19 = call zeroext i8 @mult(i8 zeroext %11371, i8 zeroext %11372)
  %conv29.39.19 = zext i8 %call28.39.19 to i32
  %xor.39.19 = xor i32 %conv23.39.19, %conv29.39.19
  %scevgep35.39.19 = getelementptr i8, i8* %a, i64 59
  %11373 = load i8, i8* %scevgep35.39.19, align 1
  %11374 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.19 = call zeroext i8 @mult(i8 zeroext %11373, i8 zeroext %11374)
  %conv35.39.19 = zext i8 %call34.39.19 to i32
  %xor36.39.19 = xor i32 %xor.39.19, %conv35.39.19
  %conv37.39.19 = trunc i32 %xor36.39.19 to i8
  store i8 %conv37.39.19, i8* %scevgep41.39.18, align 1
  %scevgep28.39.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11368, i64 0, i64 0, i64 1
  %scevgep41.39.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11369, i64 0, i64 1, i64 0
  %call16.39.20 = call zeroext i8 (...) @rand()
  store i8 %call16.39.20, i8* %scevgep28.39.19, align 1
  %11375 = load i8, i8* %scevgep28.39.19, align 1
  %conv23.39.20 = zext i8 %11375 to i32
  %11376 = load i8, i8* %arrayidx25.39, align 1
  %scevgep34.39.20 = getelementptr i8, i8* %b, i64 60
  %11377 = load i8, i8* %scevgep34.39.20, align 1
  %call28.39.20 = call zeroext i8 @mult(i8 zeroext %11376, i8 zeroext %11377)
  %conv29.39.20 = zext i8 %call28.39.20 to i32
  %xor.39.20 = xor i32 %conv23.39.20, %conv29.39.20
  %scevgep35.39.20 = getelementptr i8, i8* %a, i64 60
  %11378 = load i8, i8* %scevgep35.39.20, align 1
  %11379 = load i8, i8* %arrayidx33.39, align 1
  %call34.39.20 = call zeroext i8 @mult(i8 zeroext %11378, i8 zeroext %11379)
  %conv35.39.20 = zext i8 %call34.39.20 to i32
  %xor36.39.20 = xor i32 %xor.39.20, %conv35.39.20
  %conv37.39.20 = trunc i32 %xor36.39.20 to i8
  store i8 %conv37.39.20, i8* %scevgep41.39.19, align 1
  %scevgep26.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11235, i64 0, i64 1, i64 1
  %11380 = bitcast i8* %scevgep26.39 to [61 x [61 x i8]]*
  %scevgep39.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11236, i64 0, i64 1, i64 1
  %11381 = bitcast i8* %scevgep39.39 to [61 x [61 x i8]]*
  %arrayidx25.40 = getelementptr inbounds i8, i8* %a, i64 40
  %arrayidx33.40 = getelementptr inbounds i8, i8* %b, i64 40
  %call16.40 = call zeroext i8 (...) @rand()
  store i8 %call16.40, i8* %scevgep26.39, align 1
  %11382 = load i8, i8* %scevgep26.39, align 1
  %conv23.40 = zext i8 %11382 to i32
  %11383 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40 = getelementptr i8, i8* %b, i64 41
  %11384 = load i8, i8* %scevgep34.40, align 1
  %call28.40 = call zeroext i8 @mult(i8 zeroext %11383, i8 zeroext %11384)
  %conv29.40 = zext i8 %call28.40 to i32
  %xor.40 = xor i32 %conv23.40, %conv29.40
  %scevgep35.40 = getelementptr i8, i8* %a, i64 41
  %11385 = load i8, i8* %scevgep35.40, align 1
  %11386 = load i8, i8* %arrayidx33.40, align 1
  %call34.40 = call zeroext i8 @mult(i8 zeroext %11385, i8 zeroext %11386)
  %conv35.40 = zext i8 %call34.40 to i32
  %xor36.40 = xor i32 %xor.40, %conv35.40
  %conv37.40 = trunc i32 %xor36.40 to i8
  store i8 %conv37.40, i8* %scevgep39.39, align 1
  %scevgep28.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11380, i64 0, i64 0, i64 1
  %11387 = bitcast i8* %scevgep28.40 to [61 x [61 x i8]]*
  %scevgep41.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11381, i64 0, i64 1, i64 0
  %11388 = bitcast i8* %scevgep41.40 to [61 x [61 x i8]]*
  %call16.40.1 = call zeroext i8 (...) @rand()
  store i8 %call16.40.1, i8* %scevgep28.40, align 1
  %11389 = load i8, i8* %scevgep28.40, align 1
  %conv23.40.1 = zext i8 %11389 to i32
  %11390 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.1 = getelementptr i8, i8* %b, i64 42
  %11391 = load i8, i8* %scevgep34.40.1, align 1
  %call28.40.1 = call zeroext i8 @mult(i8 zeroext %11390, i8 zeroext %11391)
  %conv29.40.1 = zext i8 %call28.40.1 to i32
  %xor.40.1 = xor i32 %conv23.40.1, %conv29.40.1
  %scevgep35.40.1 = getelementptr i8, i8* %a, i64 42
  %11392 = load i8, i8* %scevgep35.40.1, align 1
  %11393 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.1 = call zeroext i8 @mult(i8 zeroext %11392, i8 zeroext %11393)
  %conv35.40.1 = zext i8 %call34.40.1 to i32
  %xor36.40.1 = xor i32 %xor.40.1, %conv35.40.1
  %conv37.40.1 = trunc i32 %xor36.40.1 to i8
  store i8 %conv37.40.1, i8* %scevgep41.40, align 1
  %scevgep28.40.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11387, i64 0, i64 0, i64 1
  %11394 = bitcast i8* %scevgep28.40.1 to [61 x [61 x i8]]*
  %scevgep41.40.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11388, i64 0, i64 1, i64 0
  %11395 = bitcast i8* %scevgep41.40.1 to [61 x [61 x i8]]*
  %call16.40.2 = call zeroext i8 (...) @rand()
  store i8 %call16.40.2, i8* %scevgep28.40.1, align 1
  %11396 = load i8, i8* %scevgep28.40.1, align 1
  %conv23.40.2 = zext i8 %11396 to i32
  %11397 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.2 = getelementptr i8, i8* %b, i64 43
  %11398 = load i8, i8* %scevgep34.40.2, align 1
  %call28.40.2 = call zeroext i8 @mult(i8 zeroext %11397, i8 zeroext %11398)
  %conv29.40.2 = zext i8 %call28.40.2 to i32
  %xor.40.2 = xor i32 %conv23.40.2, %conv29.40.2
  %scevgep35.40.2 = getelementptr i8, i8* %a, i64 43
  %11399 = load i8, i8* %scevgep35.40.2, align 1
  %11400 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.2 = call zeroext i8 @mult(i8 zeroext %11399, i8 zeroext %11400)
  %conv35.40.2 = zext i8 %call34.40.2 to i32
  %xor36.40.2 = xor i32 %xor.40.2, %conv35.40.2
  %conv37.40.2 = trunc i32 %xor36.40.2 to i8
  store i8 %conv37.40.2, i8* %scevgep41.40.1, align 1
  %scevgep28.40.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11394, i64 0, i64 0, i64 1
  %11401 = bitcast i8* %scevgep28.40.2 to [61 x [61 x i8]]*
  %scevgep41.40.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11395, i64 0, i64 1, i64 0
  %11402 = bitcast i8* %scevgep41.40.2 to [61 x [61 x i8]]*
  %call16.40.3 = call zeroext i8 (...) @rand()
  store i8 %call16.40.3, i8* %scevgep28.40.2, align 1
  %11403 = load i8, i8* %scevgep28.40.2, align 1
  %conv23.40.3 = zext i8 %11403 to i32
  %11404 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.3 = getelementptr i8, i8* %b, i64 44
  %11405 = load i8, i8* %scevgep34.40.3, align 1
  %call28.40.3 = call zeroext i8 @mult(i8 zeroext %11404, i8 zeroext %11405)
  %conv29.40.3 = zext i8 %call28.40.3 to i32
  %xor.40.3 = xor i32 %conv23.40.3, %conv29.40.3
  %scevgep35.40.3 = getelementptr i8, i8* %a, i64 44
  %11406 = load i8, i8* %scevgep35.40.3, align 1
  %11407 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.3 = call zeroext i8 @mult(i8 zeroext %11406, i8 zeroext %11407)
  %conv35.40.3 = zext i8 %call34.40.3 to i32
  %xor36.40.3 = xor i32 %xor.40.3, %conv35.40.3
  %conv37.40.3 = trunc i32 %xor36.40.3 to i8
  store i8 %conv37.40.3, i8* %scevgep41.40.2, align 1
  %scevgep28.40.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11401, i64 0, i64 0, i64 1
  %11408 = bitcast i8* %scevgep28.40.3 to [61 x [61 x i8]]*
  %scevgep41.40.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11402, i64 0, i64 1, i64 0
  %11409 = bitcast i8* %scevgep41.40.3 to [61 x [61 x i8]]*
  %call16.40.4 = call zeroext i8 (...) @rand()
  store i8 %call16.40.4, i8* %scevgep28.40.3, align 1
  %11410 = load i8, i8* %scevgep28.40.3, align 1
  %conv23.40.4 = zext i8 %11410 to i32
  %11411 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.4 = getelementptr i8, i8* %b, i64 45
  %11412 = load i8, i8* %scevgep34.40.4, align 1
  %call28.40.4 = call zeroext i8 @mult(i8 zeroext %11411, i8 zeroext %11412)
  %conv29.40.4 = zext i8 %call28.40.4 to i32
  %xor.40.4 = xor i32 %conv23.40.4, %conv29.40.4
  %scevgep35.40.4 = getelementptr i8, i8* %a, i64 45
  %11413 = load i8, i8* %scevgep35.40.4, align 1
  %11414 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.4 = call zeroext i8 @mult(i8 zeroext %11413, i8 zeroext %11414)
  %conv35.40.4 = zext i8 %call34.40.4 to i32
  %xor36.40.4 = xor i32 %xor.40.4, %conv35.40.4
  %conv37.40.4 = trunc i32 %xor36.40.4 to i8
  store i8 %conv37.40.4, i8* %scevgep41.40.3, align 1
  %scevgep28.40.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11408, i64 0, i64 0, i64 1
  %11415 = bitcast i8* %scevgep28.40.4 to [61 x [61 x i8]]*
  %scevgep41.40.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11409, i64 0, i64 1, i64 0
  %11416 = bitcast i8* %scevgep41.40.4 to [61 x [61 x i8]]*
  %call16.40.5 = call zeroext i8 (...) @rand()
  store i8 %call16.40.5, i8* %scevgep28.40.4, align 1
  %11417 = load i8, i8* %scevgep28.40.4, align 1
  %conv23.40.5 = zext i8 %11417 to i32
  %11418 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.5 = getelementptr i8, i8* %b, i64 46
  %11419 = load i8, i8* %scevgep34.40.5, align 1
  %call28.40.5 = call zeroext i8 @mult(i8 zeroext %11418, i8 zeroext %11419)
  %conv29.40.5 = zext i8 %call28.40.5 to i32
  %xor.40.5 = xor i32 %conv23.40.5, %conv29.40.5
  %scevgep35.40.5 = getelementptr i8, i8* %a, i64 46
  %11420 = load i8, i8* %scevgep35.40.5, align 1
  %11421 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.5 = call zeroext i8 @mult(i8 zeroext %11420, i8 zeroext %11421)
  %conv35.40.5 = zext i8 %call34.40.5 to i32
  %xor36.40.5 = xor i32 %xor.40.5, %conv35.40.5
  %conv37.40.5 = trunc i32 %xor36.40.5 to i8
  store i8 %conv37.40.5, i8* %scevgep41.40.4, align 1
  %scevgep28.40.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11415, i64 0, i64 0, i64 1
  %11422 = bitcast i8* %scevgep28.40.5 to [61 x [61 x i8]]*
  %scevgep41.40.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11416, i64 0, i64 1, i64 0
  %11423 = bitcast i8* %scevgep41.40.5 to [61 x [61 x i8]]*
  %call16.40.6 = call zeroext i8 (...) @rand()
  store i8 %call16.40.6, i8* %scevgep28.40.5, align 1
  %11424 = load i8, i8* %scevgep28.40.5, align 1
  %conv23.40.6 = zext i8 %11424 to i32
  %11425 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.6 = getelementptr i8, i8* %b, i64 47
  %11426 = load i8, i8* %scevgep34.40.6, align 1
  %call28.40.6 = call zeroext i8 @mult(i8 zeroext %11425, i8 zeroext %11426)
  %conv29.40.6 = zext i8 %call28.40.6 to i32
  %xor.40.6 = xor i32 %conv23.40.6, %conv29.40.6
  %scevgep35.40.6 = getelementptr i8, i8* %a, i64 47
  %11427 = load i8, i8* %scevgep35.40.6, align 1
  %11428 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.6 = call zeroext i8 @mult(i8 zeroext %11427, i8 zeroext %11428)
  %conv35.40.6 = zext i8 %call34.40.6 to i32
  %xor36.40.6 = xor i32 %xor.40.6, %conv35.40.6
  %conv37.40.6 = trunc i32 %xor36.40.6 to i8
  store i8 %conv37.40.6, i8* %scevgep41.40.5, align 1
  %scevgep28.40.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11422, i64 0, i64 0, i64 1
  %11429 = bitcast i8* %scevgep28.40.6 to [61 x [61 x i8]]*
  %scevgep41.40.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11423, i64 0, i64 1, i64 0
  %11430 = bitcast i8* %scevgep41.40.6 to [61 x [61 x i8]]*
  %call16.40.7 = call zeroext i8 (...) @rand()
  store i8 %call16.40.7, i8* %scevgep28.40.6, align 1
  %11431 = load i8, i8* %scevgep28.40.6, align 1
  %conv23.40.7 = zext i8 %11431 to i32
  %11432 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.7 = getelementptr i8, i8* %b, i64 48
  %11433 = load i8, i8* %scevgep34.40.7, align 1
  %call28.40.7 = call zeroext i8 @mult(i8 zeroext %11432, i8 zeroext %11433)
  %conv29.40.7 = zext i8 %call28.40.7 to i32
  %xor.40.7 = xor i32 %conv23.40.7, %conv29.40.7
  %scevgep35.40.7 = getelementptr i8, i8* %a, i64 48
  %11434 = load i8, i8* %scevgep35.40.7, align 1
  %11435 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.7 = call zeroext i8 @mult(i8 zeroext %11434, i8 zeroext %11435)
  %conv35.40.7 = zext i8 %call34.40.7 to i32
  %xor36.40.7 = xor i32 %xor.40.7, %conv35.40.7
  %conv37.40.7 = trunc i32 %xor36.40.7 to i8
  store i8 %conv37.40.7, i8* %scevgep41.40.6, align 1
  %scevgep28.40.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11429, i64 0, i64 0, i64 1
  %11436 = bitcast i8* %scevgep28.40.7 to [61 x [61 x i8]]*
  %scevgep41.40.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11430, i64 0, i64 1, i64 0
  %11437 = bitcast i8* %scevgep41.40.7 to [61 x [61 x i8]]*
  %call16.40.8 = call zeroext i8 (...) @rand()
  store i8 %call16.40.8, i8* %scevgep28.40.7, align 1
  %11438 = load i8, i8* %scevgep28.40.7, align 1
  %conv23.40.8 = zext i8 %11438 to i32
  %11439 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.8 = getelementptr i8, i8* %b, i64 49
  %11440 = load i8, i8* %scevgep34.40.8, align 1
  %call28.40.8 = call zeroext i8 @mult(i8 zeroext %11439, i8 zeroext %11440)
  %conv29.40.8 = zext i8 %call28.40.8 to i32
  %xor.40.8 = xor i32 %conv23.40.8, %conv29.40.8
  %scevgep35.40.8 = getelementptr i8, i8* %a, i64 49
  %11441 = load i8, i8* %scevgep35.40.8, align 1
  %11442 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.8 = call zeroext i8 @mult(i8 zeroext %11441, i8 zeroext %11442)
  %conv35.40.8 = zext i8 %call34.40.8 to i32
  %xor36.40.8 = xor i32 %xor.40.8, %conv35.40.8
  %conv37.40.8 = trunc i32 %xor36.40.8 to i8
  store i8 %conv37.40.8, i8* %scevgep41.40.7, align 1
  %scevgep28.40.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11436, i64 0, i64 0, i64 1
  %11443 = bitcast i8* %scevgep28.40.8 to [61 x [61 x i8]]*
  %scevgep41.40.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11437, i64 0, i64 1, i64 0
  %11444 = bitcast i8* %scevgep41.40.8 to [61 x [61 x i8]]*
  %call16.40.9 = call zeroext i8 (...) @rand()
  store i8 %call16.40.9, i8* %scevgep28.40.8, align 1
  %11445 = load i8, i8* %scevgep28.40.8, align 1
  %conv23.40.9 = zext i8 %11445 to i32
  %11446 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.9 = getelementptr i8, i8* %b, i64 50
  %11447 = load i8, i8* %scevgep34.40.9, align 1
  %call28.40.9 = call zeroext i8 @mult(i8 zeroext %11446, i8 zeroext %11447)
  %conv29.40.9 = zext i8 %call28.40.9 to i32
  %xor.40.9 = xor i32 %conv23.40.9, %conv29.40.9
  %scevgep35.40.9 = getelementptr i8, i8* %a, i64 50
  %11448 = load i8, i8* %scevgep35.40.9, align 1
  %11449 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.9 = call zeroext i8 @mult(i8 zeroext %11448, i8 zeroext %11449)
  %conv35.40.9 = zext i8 %call34.40.9 to i32
  %xor36.40.9 = xor i32 %xor.40.9, %conv35.40.9
  %conv37.40.9 = trunc i32 %xor36.40.9 to i8
  store i8 %conv37.40.9, i8* %scevgep41.40.8, align 1
  %scevgep28.40.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11443, i64 0, i64 0, i64 1
  %11450 = bitcast i8* %scevgep28.40.9 to [61 x [61 x i8]]*
  %scevgep41.40.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11444, i64 0, i64 1, i64 0
  %11451 = bitcast i8* %scevgep41.40.9 to [61 x [61 x i8]]*
  %call16.40.10 = call zeroext i8 (...) @rand()
  store i8 %call16.40.10, i8* %scevgep28.40.9, align 1
  %11452 = load i8, i8* %scevgep28.40.9, align 1
  %conv23.40.10 = zext i8 %11452 to i32
  %11453 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.10 = getelementptr i8, i8* %b, i64 51
  %11454 = load i8, i8* %scevgep34.40.10, align 1
  %call28.40.10 = call zeroext i8 @mult(i8 zeroext %11453, i8 zeroext %11454)
  %conv29.40.10 = zext i8 %call28.40.10 to i32
  %xor.40.10 = xor i32 %conv23.40.10, %conv29.40.10
  %scevgep35.40.10 = getelementptr i8, i8* %a, i64 51
  %11455 = load i8, i8* %scevgep35.40.10, align 1
  %11456 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.10 = call zeroext i8 @mult(i8 zeroext %11455, i8 zeroext %11456)
  %conv35.40.10 = zext i8 %call34.40.10 to i32
  %xor36.40.10 = xor i32 %xor.40.10, %conv35.40.10
  %conv37.40.10 = trunc i32 %xor36.40.10 to i8
  store i8 %conv37.40.10, i8* %scevgep41.40.9, align 1
  %scevgep28.40.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11450, i64 0, i64 0, i64 1
  %11457 = bitcast i8* %scevgep28.40.10 to [61 x [61 x i8]]*
  %scevgep41.40.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11451, i64 0, i64 1, i64 0
  %11458 = bitcast i8* %scevgep41.40.10 to [61 x [61 x i8]]*
  %call16.40.11 = call zeroext i8 (...) @rand()
  store i8 %call16.40.11, i8* %scevgep28.40.10, align 1
  %11459 = load i8, i8* %scevgep28.40.10, align 1
  %conv23.40.11 = zext i8 %11459 to i32
  %11460 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.11 = getelementptr i8, i8* %b, i64 52
  %11461 = load i8, i8* %scevgep34.40.11, align 1
  %call28.40.11 = call zeroext i8 @mult(i8 zeroext %11460, i8 zeroext %11461)
  %conv29.40.11 = zext i8 %call28.40.11 to i32
  %xor.40.11 = xor i32 %conv23.40.11, %conv29.40.11
  %scevgep35.40.11 = getelementptr i8, i8* %a, i64 52
  %11462 = load i8, i8* %scevgep35.40.11, align 1
  %11463 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.11 = call zeroext i8 @mult(i8 zeroext %11462, i8 zeroext %11463)
  %conv35.40.11 = zext i8 %call34.40.11 to i32
  %xor36.40.11 = xor i32 %xor.40.11, %conv35.40.11
  %conv37.40.11 = trunc i32 %xor36.40.11 to i8
  store i8 %conv37.40.11, i8* %scevgep41.40.10, align 1
  %scevgep28.40.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11457, i64 0, i64 0, i64 1
  %11464 = bitcast i8* %scevgep28.40.11 to [61 x [61 x i8]]*
  %scevgep41.40.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11458, i64 0, i64 1, i64 0
  %11465 = bitcast i8* %scevgep41.40.11 to [61 x [61 x i8]]*
  %call16.40.12 = call zeroext i8 (...) @rand()
  store i8 %call16.40.12, i8* %scevgep28.40.11, align 1
  %11466 = load i8, i8* %scevgep28.40.11, align 1
  %conv23.40.12 = zext i8 %11466 to i32
  %11467 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.12 = getelementptr i8, i8* %b, i64 53
  %11468 = load i8, i8* %scevgep34.40.12, align 1
  %call28.40.12 = call zeroext i8 @mult(i8 zeroext %11467, i8 zeroext %11468)
  %conv29.40.12 = zext i8 %call28.40.12 to i32
  %xor.40.12 = xor i32 %conv23.40.12, %conv29.40.12
  %scevgep35.40.12 = getelementptr i8, i8* %a, i64 53
  %11469 = load i8, i8* %scevgep35.40.12, align 1
  %11470 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.12 = call zeroext i8 @mult(i8 zeroext %11469, i8 zeroext %11470)
  %conv35.40.12 = zext i8 %call34.40.12 to i32
  %xor36.40.12 = xor i32 %xor.40.12, %conv35.40.12
  %conv37.40.12 = trunc i32 %xor36.40.12 to i8
  store i8 %conv37.40.12, i8* %scevgep41.40.11, align 1
  %scevgep28.40.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11464, i64 0, i64 0, i64 1
  %11471 = bitcast i8* %scevgep28.40.12 to [61 x [61 x i8]]*
  %scevgep41.40.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11465, i64 0, i64 1, i64 0
  %11472 = bitcast i8* %scevgep41.40.12 to [61 x [61 x i8]]*
  %call16.40.13 = call zeroext i8 (...) @rand()
  store i8 %call16.40.13, i8* %scevgep28.40.12, align 1
  %11473 = load i8, i8* %scevgep28.40.12, align 1
  %conv23.40.13 = zext i8 %11473 to i32
  %11474 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.13 = getelementptr i8, i8* %b, i64 54
  %11475 = load i8, i8* %scevgep34.40.13, align 1
  %call28.40.13 = call zeroext i8 @mult(i8 zeroext %11474, i8 zeroext %11475)
  %conv29.40.13 = zext i8 %call28.40.13 to i32
  %xor.40.13 = xor i32 %conv23.40.13, %conv29.40.13
  %scevgep35.40.13 = getelementptr i8, i8* %a, i64 54
  %11476 = load i8, i8* %scevgep35.40.13, align 1
  %11477 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.13 = call zeroext i8 @mult(i8 zeroext %11476, i8 zeroext %11477)
  %conv35.40.13 = zext i8 %call34.40.13 to i32
  %xor36.40.13 = xor i32 %xor.40.13, %conv35.40.13
  %conv37.40.13 = trunc i32 %xor36.40.13 to i8
  store i8 %conv37.40.13, i8* %scevgep41.40.12, align 1
  %scevgep28.40.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11471, i64 0, i64 0, i64 1
  %11478 = bitcast i8* %scevgep28.40.13 to [61 x [61 x i8]]*
  %scevgep41.40.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11472, i64 0, i64 1, i64 0
  %11479 = bitcast i8* %scevgep41.40.13 to [61 x [61 x i8]]*
  %call16.40.14 = call zeroext i8 (...) @rand()
  store i8 %call16.40.14, i8* %scevgep28.40.13, align 1
  %11480 = load i8, i8* %scevgep28.40.13, align 1
  %conv23.40.14 = zext i8 %11480 to i32
  %11481 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.14 = getelementptr i8, i8* %b, i64 55
  %11482 = load i8, i8* %scevgep34.40.14, align 1
  %call28.40.14 = call zeroext i8 @mult(i8 zeroext %11481, i8 zeroext %11482)
  %conv29.40.14 = zext i8 %call28.40.14 to i32
  %xor.40.14 = xor i32 %conv23.40.14, %conv29.40.14
  %scevgep35.40.14 = getelementptr i8, i8* %a, i64 55
  %11483 = load i8, i8* %scevgep35.40.14, align 1
  %11484 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.14 = call zeroext i8 @mult(i8 zeroext %11483, i8 zeroext %11484)
  %conv35.40.14 = zext i8 %call34.40.14 to i32
  %xor36.40.14 = xor i32 %xor.40.14, %conv35.40.14
  %conv37.40.14 = trunc i32 %xor36.40.14 to i8
  store i8 %conv37.40.14, i8* %scevgep41.40.13, align 1
  %scevgep28.40.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11478, i64 0, i64 0, i64 1
  %11485 = bitcast i8* %scevgep28.40.14 to [61 x [61 x i8]]*
  %scevgep41.40.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11479, i64 0, i64 1, i64 0
  %11486 = bitcast i8* %scevgep41.40.14 to [61 x [61 x i8]]*
  %call16.40.15 = call zeroext i8 (...) @rand()
  store i8 %call16.40.15, i8* %scevgep28.40.14, align 1
  %11487 = load i8, i8* %scevgep28.40.14, align 1
  %conv23.40.15 = zext i8 %11487 to i32
  %11488 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.15 = getelementptr i8, i8* %b, i64 56
  %11489 = load i8, i8* %scevgep34.40.15, align 1
  %call28.40.15 = call zeroext i8 @mult(i8 zeroext %11488, i8 zeroext %11489)
  %conv29.40.15 = zext i8 %call28.40.15 to i32
  %xor.40.15 = xor i32 %conv23.40.15, %conv29.40.15
  %scevgep35.40.15 = getelementptr i8, i8* %a, i64 56
  %11490 = load i8, i8* %scevgep35.40.15, align 1
  %11491 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.15 = call zeroext i8 @mult(i8 zeroext %11490, i8 zeroext %11491)
  %conv35.40.15 = zext i8 %call34.40.15 to i32
  %xor36.40.15 = xor i32 %xor.40.15, %conv35.40.15
  %conv37.40.15 = trunc i32 %xor36.40.15 to i8
  store i8 %conv37.40.15, i8* %scevgep41.40.14, align 1
  %scevgep28.40.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11485, i64 0, i64 0, i64 1
  %11492 = bitcast i8* %scevgep28.40.15 to [61 x [61 x i8]]*
  %scevgep41.40.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11486, i64 0, i64 1, i64 0
  %11493 = bitcast i8* %scevgep41.40.15 to [61 x [61 x i8]]*
  %call16.40.16 = call zeroext i8 (...) @rand()
  store i8 %call16.40.16, i8* %scevgep28.40.15, align 1
  %11494 = load i8, i8* %scevgep28.40.15, align 1
  %conv23.40.16 = zext i8 %11494 to i32
  %11495 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.16 = getelementptr i8, i8* %b, i64 57
  %11496 = load i8, i8* %scevgep34.40.16, align 1
  %call28.40.16 = call zeroext i8 @mult(i8 zeroext %11495, i8 zeroext %11496)
  %conv29.40.16 = zext i8 %call28.40.16 to i32
  %xor.40.16 = xor i32 %conv23.40.16, %conv29.40.16
  %scevgep35.40.16 = getelementptr i8, i8* %a, i64 57
  %11497 = load i8, i8* %scevgep35.40.16, align 1
  %11498 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.16 = call zeroext i8 @mult(i8 zeroext %11497, i8 zeroext %11498)
  %conv35.40.16 = zext i8 %call34.40.16 to i32
  %xor36.40.16 = xor i32 %xor.40.16, %conv35.40.16
  %conv37.40.16 = trunc i32 %xor36.40.16 to i8
  store i8 %conv37.40.16, i8* %scevgep41.40.15, align 1
  %scevgep28.40.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11492, i64 0, i64 0, i64 1
  %11499 = bitcast i8* %scevgep28.40.16 to [61 x [61 x i8]]*
  %scevgep41.40.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11493, i64 0, i64 1, i64 0
  %11500 = bitcast i8* %scevgep41.40.16 to [61 x [61 x i8]]*
  %call16.40.17 = call zeroext i8 (...) @rand()
  store i8 %call16.40.17, i8* %scevgep28.40.16, align 1
  %11501 = load i8, i8* %scevgep28.40.16, align 1
  %conv23.40.17 = zext i8 %11501 to i32
  %11502 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.17 = getelementptr i8, i8* %b, i64 58
  %11503 = load i8, i8* %scevgep34.40.17, align 1
  %call28.40.17 = call zeroext i8 @mult(i8 zeroext %11502, i8 zeroext %11503)
  %conv29.40.17 = zext i8 %call28.40.17 to i32
  %xor.40.17 = xor i32 %conv23.40.17, %conv29.40.17
  %scevgep35.40.17 = getelementptr i8, i8* %a, i64 58
  %11504 = load i8, i8* %scevgep35.40.17, align 1
  %11505 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.17 = call zeroext i8 @mult(i8 zeroext %11504, i8 zeroext %11505)
  %conv35.40.17 = zext i8 %call34.40.17 to i32
  %xor36.40.17 = xor i32 %xor.40.17, %conv35.40.17
  %conv37.40.17 = trunc i32 %xor36.40.17 to i8
  store i8 %conv37.40.17, i8* %scevgep41.40.16, align 1
  %scevgep28.40.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11499, i64 0, i64 0, i64 1
  %11506 = bitcast i8* %scevgep28.40.17 to [61 x [61 x i8]]*
  %scevgep41.40.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11500, i64 0, i64 1, i64 0
  %11507 = bitcast i8* %scevgep41.40.17 to [61 x [61 x i8]]*
  %call16.40.18 = call zeroext i8 (...) @rand()
  store i8 %call16.40.18, i8* %scevgep28.40.17, align 1
  %11508 = load i8, i8* %scevgep28.40.17, align 1
  %conv23.40.18 = zext i8 %11508 to i32
  %11509 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.18 = getelementptr i8, i8* %b, i64 59
  %11510 = load i8, i8* %scevgep34.40.18, align 1
  %call28.40.18 = call zeroext i8 @mult(i8 zeroext %11509, i8 zeroext %11510)
  %conv29.40.18 = zext i8 %call28.40.18 to i32
  %xor.40.18 = xor i32 %conv23.40.18, %conv29.40.18
  %scevgep35.40.18 = getelementptr i8, i8* %a, i64 59
  %11511 = load i8, i8* %scevgep35.40.18, align 1
  %11512 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.18 = call zeroext i8 @mult(i8 zeroext %11511, i8 zeroext %11512)
  %conv35.40.18 = zext i8 %call34.40.18 to i32
  %xor36.40.18 = xor i32 %xor.40.18, %conv35.40.18
  %conv37.40.18 = trunc i32 %xor36.40.18 to i8
  store i8 %conv37.40.18, i8* %scevgep41.40.17, align 1
  %scevgep28.40.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11506, i64 0, i64 0, i64 1
  %scevgep41.40.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11507, i64 0, i64 1, i64 0
  %call16.40.19 = call zeroext i8 (...) @rand()
  store i8 %call16.40.19, i8* %scevgep28.40.18, align 1
  %11513 = load i8, i8* %scevgep28.40.18, align 1
  %conv23.40.19 = zext i8 %11513 to i32
  %11514 = load i8, i8* %arrayidx25.40, align 1
  %scevgep34.40.19 = getelementptr i8, i8* %b, i64 60
  %11515 = load i8, i8* %scevgep34.40.19, align 1
  %call28.40.19 = call zeroext i8 @mult(i8 zeroext %11514, i8 zeroext %11515)
  %conv29.40.19 = zext i8 %call28.40.19 to i32
  %xor.40.19 = xor i32 %conv23.40.19, %conv29.40.19
  %scevgep35.40.19 = getelementptr i8, i8* %a, i64 60
  %11516 = load i8, i8* %scevgep35.40.19, align 1
  %11517 = load i8, i8* %arrayidx33.40, align 1
  %call34.40.19 = call zeroext i8 @mult(i8 zeroext %11516, i8 zeroext %11517)
  %conv35.40.19 = zext i8 %call34.40.19 to i32
  %xor36.40.19 = xor i32 %xor.40.19, %conv35.40.19
  %conv37.40.19 = trunc i32 %xor36.40.19 to i8
  store i8 %conv37.40.19, i8* %scevgep41.40.18, align 1
  %scevgep26.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11380, i64 0, i64 1, i64 1
  %11518 = bitcast i8* %scevgep26.40 to [61 x [61 x i8]]*
  %scevgep39.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11381, i64 0, i64 1, i64 1
  %11519 = bitcast i8* %scevgep39.40 to [61 x [61 x i8]]*
  %arrayidx25.41 = getelementptr inbounds i8, i8* %a, i64 41
  %arrayidx33.41 = getelementptr inbounds i8, i8* %b, i64 41
  %call16.41 = call zeroext i8 (...) @rand()
  store i8 %call16.41, i8* %scevgep26.40, align 1
  %11520 = load i8, i8* %scevgep26.40, align 1
  %conv23.41 = zext i8 %11520 to i32
  %11521 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41 = getelementptr i8, i8* %b, i64 42
  %11522 = load i8, i8* %scevgep34.41, align 1
  %call28.41 = call zeroext i8 @mult(i8 zeroext %11521, i8 zeroext %11522)
  %conv29.41 = zext i8 %call28.41 to i32
  %xor.41 = xor i32 %conv23.41, %conv29.41
  %scevgep35.41 = getelementptr i8, i8* %a, i64 42
  %11523 = load i8, i8* %scevgep35.41, align 1
  %11524 = load i8, i8* %arrayidx33.41, align 1
  %call34.41 = call zeroext i8 @mult(i8 zeroext %11523, i8 zeroext %11524)
  %conv35.41 = zext i8 %call34.41 to i32
  %xor36.41 = xor i32 %xor.41, %conv35.41
  %conv37.41 = trunc i32 %xor36.41 to i8
  store i8 %conv37.41, i8* %scevgep39.40, align 1
  %scevgep28.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11518, i64 0, i64 0, i64 1
  %11525 = bitcast i8* %scevgep28.41 to [61 x [61 x i8]]*
  %scevgep41.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11519, i64 0, i64 1, i64 0
  %11526 = bitcast i8* %scevgep41.41 to [61 x [61 x i8]]*
  %call16.41.1 = call zeroext i8 (...) @rand()
  store i8 %call16.41.1, i8* %scevgep28.41, align 1
  %11527 = load i8, i8* %scevgep28.41, align 1
  %conv23.41.1 = zext i8 %11527 to i32
  %11528 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.1 = getelementptr i8, i8* %b, i64 43
  %11529 = load i8, i8* %scevgep34.41.1, align 1
  %call28.41.1 = call zeroext i8 @mult(i8 zeroext %11528, i8 zeroext %11529)
  %conv29.41.1 = zext i8 %call28.41.1 to i32
  %xor.41.1 = xor i32 %conv23.41.1, %conv29.41.1
  %scevgep35.41.1 = getelementptr i8, i8* %a, i64 43
  %11530 = load i8, i8* %scevgep35.41.1, align 1
  %11531 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.1 = call zeroext i8 @mult(i8 zeroext %11530, i8 zeroext %11531)
  %conv35.41.1 = zext i8 %call34.41.1 to i32
  %xor36.41.1 = xor i32 %xor.41.1, %conv35.41.1
  %conv37.41.1 = trunc i32 %xor36.41.1 to i8
  store i8 %conv37.41.1, i8* %scevgep41.41, align 1
  %scevgep28.41.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11525, i64 0, i64 0, i64 1
  %11532 = bitcast i8* %scevgep28.41.1 to [61 x [61 x i8]]*
  %scevgep41.41.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11526, i64 0, i64 1, i64 0
  %11533 = bitcast i8* %scevgep41.41.1 to [61 x [61 x i8]]*
  %call16.41.2 = call zeroext i8 (...) @rand()
  store i8 %call16.41.2, i8* %scevgep28.41.1, align 1
  %11534 = load i8, i8* %scevgep28.41.1, align 1
  %conv23.41.2 = zext i8 %11534 to i32
  %11535 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.2 = getelementptr i8, i8* %b, i64 44
  %11536 = load i8, i8* %scevgep34.41.2, align 1
  %call28.41.2 = call zeroext i8 @mult(i8 zeroext %11535, i8 zeroext %11536)
  %conv29.41.2 = zext i8 %call28.41.2 to i32
  %xor.41.2 = xor i32 %conv23.41.2, %conv29.41.2
  %scevgep35.41.2 = getelementptr i8, i8* %a, i64 44
  %11537 = load i8, i8* %scevgep35.41.2, align 1
  %11538 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.2 = call zeroext i8 @mult(i8 zeroext %11537, i8 zeroext %11538)
  %conv35.41.2 = zext i8 %call34.41.2 to i32
  %xor36.41.2 = xor i32 %xor.41.2, %conv35.41.2
  %conv37.41.2 = trunc i32 %xor36.41.2 to i8
  store i8 %conv37.41.2, i8* %scevgep41.41.1, align 1
  %scevgep28.41.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11532, i64 0, i64 0, i64 1
  %11539 = bitcast i8* %scevgep28.41.2 to [61 x [61 x i8]]*
  %scevgep41.41.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11533, i64 0, i64 1, i64 0
  %11540 = bitcast i8* %scevgep41.41.2 to [61 x [61 x i8]]*
  %call16.41.3 = call zeroext i8 (...) @rand()
  store i8 %call16.41.3, i8* %scevgep28.41.2, align 1
  %11541 = load i8, i8* %scevgep28.41.2, align 1
  %conv23.41.3 = zext i8 %11541 to i32
  %11542 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.3 = getelementptr i8, i8* %b, i64 45
  %11543 = load i8, i8* %scevgep34.41.3, align 1
  %call28.41.3 = call zeroext i8 @mult(i8 zeroext %11542, i8 zeroext %11543)
  %conv29.41.3 = zext i8 %call28.41.3 to i32
  %xor.41.3 = xor i32 %conv23.41.3, %conv29.41.3
  %scevgep35.41.3 = getelementptr i8, i8* %a, i64 45
  %11544 = load i8, i8* %scevgep35.41.3, align 1
  %11545 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.3 = call zeroext i8 @mult(i8 zeroext %11544, i8 zeroext %11545)
  %conv35.41.3 = zext i8 %call34.41.3 to i32
  %xor36.41.3 = xor i32 %xor.41.3, %conv35.41.3
  %conv37.41.3 = trunc i32 %xor36.41.3 to i8
  store i8 %conv37.41.3, i8* %scevgep41.41.2, align 1
  %scevgep28.41.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11539, i64 0, i64 0, i64 1
  %11546 = bitcast i8* %scevgep28.41.3 to [61 x [61 x i8]]*
  %scevgep41.41.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11540, i64 0, i64 1, i64 0
  %11547 = bitcast i8* %scevgep41.41.3 to [61 x [61 x i8]]*
  %call16.41.4 = call zeroext i8 (...) @rand()
  store i8 %call16.41.4, i8* %scevgep28.41.3, align 1
  %11548 = load i8, i8* %scevgep28.41.3, align 1
  %conv23.41.4 = zext i8 %11548 to i32
  %11549 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.4 = getelementptr i8, i8* %b, i64 46
  %11550 = load i8, i8* %scevgep34.41.4, align 1
  %call28.41.4 = call zeroext i8 @mult(i8 zeroext %11549, i8 zeroext %11550)
  %conv29.41.4 = zext i8 %call28.41.4 to i32
  %xor.41.4 = xor i32 %conv23.41.4, %conv29.41.4
  %scevgep35.41.4 = getelementptr i8, i8* %a, i64 46
  %11551 = load i8, i8* %scevgep35.41.4, align 1
  %11552 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.4 = call zeroext i8 @mult(i8 zeroext %11551, i8 zeroext %11552)
  %conv35.41.4 = zext i8 %call34.41.4 to i32
  %xor36.41.4 = xor i32 %xor.41.4, %conv35.41.4
  %conv37.41.4 = trunc i32 %xor36.41.4 to i8
  store i8 %conv37.41.4, i8* %scevgep41.41.3, align 1
  %scevgep28.41.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11546, i64 0, i64 0, i64 1
  %11553 = bitcast i8* %scevgep28.41.4 to [61 x [61 x i8]]*
  %scevgep41.41.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11547, i64 0, i64 1, i64 0
  %11554 = bitcast i8* %scevgep41.41.4 to [61 x [61 x i8]]*
  %call16.41.5 = call zeroext i8 (...) @rand()
  store i8 %call16.41.5, i8* %scevgep28.41.4, align 1
  %11555 = load i8, i8* %scevgep28.41.4, align 1
  %conv23.41.5 = zext i8 %11555 to i32
  %11556 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.5 = getelementptr i8, i8* %b, i64 47
  %11557 = load i8, i8* %scevgep34.41.5, align 1
  %call28.41.5 = call zeroext i8 @mult(i8 zeroext %11556, i8 zeroext %11557)
  %conv29.41.5 = zext i8 %call28.41.5 to i32
  %xor.41.5 = xor i32 %conv23.41.5, %conv29.41.5
  %scevgep35.41.5 = getelementptr i8, i8* %a, i64 47
  %11558 = load i8, i8* %scevgep35.41.5, align 1
  %11559 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.5 = call zeroext i8 @mult(i8 zeroext %11558, i8 zeroext %11559)
  %conv35.41.5 = zext i8 %call34.41.5 to i32
  %xor36.41.5 = xor i32 %xor.41.5, %conv35.41.5
  %conv37.41.5 = trunc i32 %xor36.41.5 to i8
  store i8 %conv37.41.5, i8* %scevgep41.41.4, align 1
  %scevgep28.41.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11553, i64 0, i64 0, i64 1
  %11560 = bitcast i8* %scevgep28.41.5 to [61 x [61 x i8]]*
  %scevgep41.41.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11554, i64 0, i64 1, i64 0
  %11561 = bitcast i8* %scevgep41.41.5 to [61 x [61 x i8]]*
  %call16.41.6 = call zeroext i8 (...) @rand()
  store i8 %call16.41.6, i8* %scevgep28.41.5, align 1
  %11562 = load i8, i8* %scevgep28.41.5, align 1
  %conv23.41.6 = zext i8 %11562 to i32
  %11563 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.6 = getelementptr i8, i8* %b, i64 48
  %11564 = load i8, i8* %scevgep34.41.6, align 1
  %call28.41.6 = call zeroext i8 @mult(i8 zeroext %11563, i8 zeroext %11564)
  %conv29.41.6 = zext i8 %call28.41.6 to i32
  %xor.41.6 = xor i32 %conv23.41.6, %conv29.41.6
  %scevgep35.41.6 = getelementptr i8, i8* %a, i64 48
  %11565 = load i8, i8* %scevgep35.41.6, align 1
  %11566 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.6 = call zeroext i8 @mult(i8 zeroext %11565, i8 zeroext %11566)
  %conv35.41.6 = zext i8 %call34.41.6 to i32
  %xor36.41.6 = xor i32 %xor.41.6, %conv35.41.6
  %conv37.41.6 = trunc i32 %xor36.41.6 to i8
  store i8 %conv37.41.6, i8* %scevgep41.41.5, align 1
  %scevgep28.41.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11560, i64 0, i64 0, i64 1
  %11567 = bitcast i8* %scevgep28.41.6 to [61 x [61 x i8]]*
  %scevgep41.41.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11561, i64 0, i64 1, i64 0
  %11568 = bitcast i8* %scevgep41.41.6 to [61 x [61 x i8]]*
  %call16.41.7 = call zeroext i8 (...) @rand()
  store i8 %call16.41.7, i8* %scevgep28.41.6, align 1
  %11569 = load i8, i8* %scevgep28.41.6, align 1
  %conv23.41.7 = zext i8 %11569 to i32
  %11570 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.7 = getelementptr i8, i8* %b, i64 49
  %11571 = load i8, i8* %scevgep34.41.7, align 1
  %call28.41.7 = call zeroext i8 @mult(i8 zeroext %11570, i8 zeroext %11571)
  %conv29.41.7 = zext i8 %call28.41.7 to i32
  %xor.41.7 = xor i32 %conv23.41.7, %conv29.41.7
  %scevgep35.41.7 = getelementptr i8, i8* %a, i64 49
  %11572 = load i8, i8* %scevgep35.41.7, align 1
  %11573 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.7 = call zeroext i8 @mult(i8 zeroext %11572, i8 zeroext %11573)
  %conv35.41.7 = zext i8 %call34.41.7 to i32
  %xor36.41.7 = xor i32 %xor.41.7, %conv35.41.7
  %conv37.41.7 = trunc i32 %xor36.41.7 to i8
  store i8 %conv37.41.7, i8* %scevgep41.41.6, align 1
  %scevgep28.41.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11567, i64 0, i64 0, i64 1
  %11574 = bitcast i8* %scevgep28.41.7 to [61 x [61 x i8]]*
  %scevgep41.41.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11568, i64 0, i64 1, i64 0
  %11575 = bitcast i8* %scevgep41.41.7 to [61 x [61 x i8]]*
  %call16.41.8 = call zeroext i8 (...) @rand()
  store i8 %call16.41.8, i8* %scevgep28.41.7, align 1
  %11576 = load i8, i8* %scevgep28.41.7, align 1
  %conv23.41.8 = zext i8 %11576 to i32
  %11577 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.8 = getelementptr i8, i8* %b, i64 50
  %11578 = load i8, i8* %scevgep34.41.8, align 1
  %call28.41.8 = call zeroext i8 @mult(i8 zeroext %11577, i8 zeroext %11578)
  %conv29.41.8 = zext i8 %call28.41.8 to i32
  %xor.41.8 = xor i32 %conv23.41.8, %conv29.41.8
  %scevgep35.41.8 = getelementptr i8, i8* %a, i64 50
  %11579 = load i8, i8* %scevgep35.41.8, align 1
  %11580 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.8 = call zeroext i8 @mult(i8 zeroext %11579, i8 zeroext %11580)
  %conv35.41.8 = zext i8 %call34.41.8 to i32
  %xor36.41.8 = xor i32 %xor.41.8, %conv35.41.8
  %conv37.41.8 = trunc i32 %xor36.41.8 to i8
  store i8 %conv37.41.8, i8* %scevgep41.41.7, align 1
  %scevgep28.41.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11574, i64 0, i64 0, i64 1
  %11581 = bitcast i8* %scevgep28.41.8 to [61 x [61 x i8]]*
  %scevgep41.41.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11575, i64 0, i64 1, i64 0
  %11582 = bitcast i8* %scevgep41.41.8 to [61 x [61 x i8]]*
  %call16.41.9 = call zeroext i8 (...) @rand()
  store i8 %call16.41.9, i8* %scevgep28.41.8, align 1
  %11583 = load i8, i8* %scevgep28.41.8, align 1
  %conv23.41.9 = zext i8 %11583 to i32
  %11584 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.9 = getelementptr i8, i8* %b, i64 51
  %11585 = load i8, i8* %scevgep34.41.9, align 1
  %call28.41.9 = call zeroext i8 @mult(i8 zeroext %11584, i8 zeroext %11585)
  %conv29.41.9 = zext i8 %call28.41.9 to i32
  %xor.41.9 = xor i32 %conv23.41.9, %conv29.41.9
  %scevgep35.41.9 = getelementptr i8, i8* %a, i64 51
  %11586 = load i8, i8* %scevgep35.41.9, align 1
  %11587 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.9 = call zeroext i8 @mult(i8 zeroext %11586, i8 zeroext %11587)
  %conv35.41.9 = zext i8 %call34.41.9 to i32
  %xor36.41.9 = xor i32 %xor.41.9, %conv35.41.9
  %conv37.41.9 = trunc i32 %xor36.41.9 to i8
  store i8 %conv37.41.9, i8* %scevgep41.41.8, align 1
  %scevgep28.41.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11581, i64 0, i64 0, i64 1
  %11588 = bitcast i8* %scevgep28.41.9 to [61 x [61 x i8]]*
  %scevgep41.41.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11582, i64 0, i64 1, i64 0
  %11589 = bitcast i8* %scevgep41.41.9 to [61 x [61 x i8]]*
  %call16.41.10 = call zeroext i8 (...) @rand()
  store i8 %call16.41.10, i8* %scevgep28.41.9, align 1
  %11590 = load i8, i8* %scevgep28.41.9, align 1
  %conv23.41.10 = zext i8 %11590 to i32
  %11591 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.10 = getelementptr i8, i8* %b, i64 52
  %11592 = load i8, i8* %scevgep34.41.10, align 1
  %call28.41.10 = call zeroext i8 @mult(i8 zeroext %11591, i8 zeroext %11592)
  %conv29.41.10 = zext i8 %call28.41.10 to i32
  %xor.41.10 = xor i32 %conv23.41.10, %conv29.41.10
  %scevgep35.41.10 = getelementptr i8, i8* %a, i64 52
  %11593 = load i8, i8* %scevgep35.41.10, align 1
  %11594 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.10 = call zeroext i8 @mult(i8 zeroext %11593, i8 zeroext %11594)
  %conv35.41.10 = zext i8 %call34.41.10 to i32
  %xor36.41.10 = xor i32 %xor.41.10, %conv35.41.10
  %conv37.41.10 = trunc i32 %xor36.41.10 to i8
  store i8 %conv37.41.10, i8* %scevgep41.41.9, align 1
  %scevgep28.41.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11588, i64 0, i64 0, i64 1
  %11595 = bitcast i8* %scevgep28.41.10 to [61 x [61 x i8]]*
  %scevgep41.41.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11589, i64 0, i64 1, i64 0
  %11596 = bitcast i8* %scevgep41.41.10 to [61 x [61 x i8]]*
  %call16.41.11 = call zeroext i8 (...) @rand()
  store i8 %call16.41.11, i8* %scevgep28.41.10, align 1
  %11597 = load i8, i8* %scevgep28.41.10, align 1
  %conv23.41.11 = zext i8 %11597 to i32
  %11598 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.11 = getelementptr i8, i8* %b, i64 53
  %11599 = load i8, i8* %scevgep34.41.11, align 1
  %call28.41.11 = call zeroext i8 @mult(i8 zeroext %11598, i8 zeroext %11599)
  %conv29.41.11 = zext i8 %call28.41.11 to i32
  %xor.41.11 = xor i32 %conv23.41.11, %conv29.41.11
  %scevgep35.41.11 = getelementptr i8, i8* %a, i64 53
  %11600 = load i8, i8* %scevgep35.41.11, align 1
  %11601 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.11 = call zeroext i8 @mult(i8 zeroext %11600, i8 zeroext %11601)
  %conv35.41.11 = zext i8 %call34.41.11 to i32
  %xor36.41.11 = xor i32 %xor.41.11, %conv35.41.11
  %conv37.41.11 = trunc i32 %xor36.41.11 to i8
  store i8 %conv37.41.11, i8* %scevgep41.41.10, align 1
  %scevgep28.41.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11595, i64 0, i64 0, i64 1
  %11602 = bitcast i8* %scevgep28.41.11 to [61 x [61 x i8]]*
  %scevgep41.41.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11596, i64 0, i64 1, i64 0
  %11603 = bitcast i8* %scevgep41.41.11 to [61 x [61 x i8]]*
  %call16.41.12 = call zeroext i8 (...) @rand()
  store i8 %call16.41.12, i8* %scevgep28.41.11, align 1
  %11604 = load i8, i8* %scevgep28.41.11, align 1
  %conv23.41.12 = zext i8 %11604 to i32
  %11605 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.12 = getelementptr i8, i8* %b, i64 54
  %11606 = load i8, i8* %scevgep34.41.12, align 1
  %call28.41.12 = call zeroext i8 @mult(i8 zeroext %11605, i8 zeroext %11606)
  %conv29.41.12 = zext i8 %call28.41.12 to i32
  %xor.41.12 = xor i32 %conv23.41.12, %conv29.41.12
  %scevgep35.41.12 = getelementptr i8, i8* %a, i64 54
  %11607 = load i8, i8* %scevgep35.41.12, align 1
  %11608 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.12 = call zeroext i8 @mult(i8 zeroext %11607, i8 zeroext %11608)
  %conv35.41.12 = zext i8 %call34.41.12 to i32
  %xor36.41.12 = xor i32 %xor.41.12, %conv35.41.12
  %conv37.41.12 = trunc i32 %xor36.41.12 to i8
  store i8 %conv37.41.12, i8* %scevgep41.41.11, align 1
  %scevgep28.41.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11602, i64 0, i64 0, i64 1
  %11609 = bitcast i8* %scevgep28.41.12 to [61 x [61 x i8]]*
  %scevgep41.41.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11603, i64 0, i64 1, i64 0
  %11610 = bitcast i8* %scevgep41.41.12 to [61 x [61 x i8]]*
  %call16.41.13 = call zeroext i8 (...) @rand()
  store i8 %call16.41.13, i8* %scevgep28.41.12, align 1
  %11611 = load i8, i8* %scevgep28.41.12, align 1
  %conv23.41.13 = zext i8 %11611 to i32
  %11612 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.13 = getelementptr i8, i8* %b, i64 55
  %11613 = load i8, i8* %scevgep34.41.13, align 1
  %call28.41.13 = call zeroext i8 @mult(i8 zeroext %11612, i8 zeroext %11613)
  %conv29.41.13 = zext i8 %call28.41.13 to i32
  %xor.41.13 = xor i32 %conv23.41.13, %conv29.41.13
  %scevgep35.41.13 = getelementptr i8, i8* %a, i64 55
  %11614 = load i8, i8* %scevgep35.41.13, align 1
  %11615 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.13 = call zeroext i8 @mult(i8 zeroext %11614, i8 zeroext %11615)
  %conv35.41.13 = zext i8 %call34.41.13 to i32
  %xor36.41.13 = xor i32 %xor.41.13, %conv35.41.13
  %conv37.41.13 = trunc i32 %xor36.41.13 to i8
  store i8 %conv37.41.13, i8* %scevgep41.41.12, align 1
  %scevgep28.41.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11609, i64 0, i64 0, i64 1
  %11616 = bitcast i8* %scevgep28.41.13 to [61 x [61 x i8]]*
  %scevgep41.41.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11610, i64 0, i64 1, i64 0
  %11617 = bitcast i8* %scevgep41.41.13 to [61 x [61 x i8]]*
  %call16.41.14 = call zeroext i8 (...) @rand()
  store i8 %call16.41.14, i8* %scevgep28.41.13, align 1
  %11618 = load i8, i8* %scevgep28.41.13, align 1
  %conv23.41.14 = zext i8 %11618 to i32
  %11619 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.14 = getelementptr i8, i8* %b, i64 56
  %11620 = load i8, i8* %scevgep34.41.14, align 1
  %call28.41.14 = call zeroext i8 @mult(i8 zeroext %11619, i8 zeroext %11620)
  %conv29.41.14 = zext i8 %call28.41.14 to i32
  %xor.41.14 = xor i32 %conv23.41.14, %conv29.41.14
  %scevgep35.41.14 = getelementptr i8, i8* %a, i64 56
  %11621 = load i8, i8* %scevgep35.41.14, align 1
  %11622 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.14 = call zeroext i8 @mult(i8 zeroext %11621, i8 zeroext %11622)
  %conv35.41.14 = zext i8 %call34.41.14 to i32
  %xor36.41.14 = xor i32 %xor.41.14, %conv35.41.14
  %conv37.41.14 = trunc i32 %xor36.41.14 to i8
  store i8 %conv37.41.14, i8* %scevgep41.41.13, align 1
  %scevgep28.41.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11616, i64 0, i64 0, i64 1
  %11623 = bitcast i8* %scevgep28.41.14 to [61 x [61 x i8]]*
  %scevgep41.41.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11617, i64 0, i64 1, i64 0
  %11624 = bitcast i8* %scevgep41.41.14 to [61 x [61 x i8]]*
  %call16.41.15 = call zeroext i8 (...) @rand()
  store i8 %call16.41.15, i8* %scevgep28.41.14, align 1
  %11625 = load i8, i8* %scevgep28.41.14, align 1
  %conv23.41.15 = zext i8 %11625 to i32
  %11626 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.15 = getelementptr i8, i8* %b, i64 57
  %11627 = load i8, i8* %scevgep34.41.15, align 1
  %call28.41.15 = call zeroext i8 @mult(i8 zeroext %11626, i8 zeroext %11627)
  %conv29.41.15 = zext i8 %call28.41.15 to i32
  %xor.41.15 = xor i32 %conv23.41.15, %conv29.41.15
  %scevgep35.41.15 = getelementptr i8, i8* %a, i64 57
  %11628 = load i8, i8* %scevgep35.41.15, align 1
  %11629 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.15 = call zeroext i8 @mult(i8 zeroext %11628, i8 zeroext %11629)
  %conv35.41.15 = zext i8 %call34.41.15 to i32
  %xor36.41.15 = xor i32 %xor.41.15, %conv35.41.15
  %conv37.41.15 = trunc i32 %xor36.41.15 to i8
  store i8 %conv37.41.15, i8* %scevgep41.41.14, align 1
  %scevgep28.41.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11623, i64 0, i64 0, i64 1
  %11630 = bitcast i8* %scevgep28.41.15 to [61 x [61 x i8]]*
  %scevgep41.41.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11624, i64 0, i64 1, i64 0
  %11631 = bitcast i8* %scevgep41.41.15 to [61 x [61 x i8]]*
  %call16.41.16 = call zeroext i8 (...) @rand()
  store i8 %call16.41.16, i8* %scevgep28.41.15, align 1
  %11632 = load i8, i8* %scevgep28.41.15, align 1
  %conv23.41.16 = zext i8 %11632 to i32
  %11633 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.16 = getelementptr i8, i8* %b, i64 58
  %11634 = load i8, i8* %scevgep34.41.16, align 1
  %call28.41.16 = call zeroext i8 @mult(i8 zeroext %11633, i8 zeroext %11634)
  %conv29.41.16 = zext i8 %call28.41.16 to i32
  %xor.41.16 = xor i32 %conv23.41.16, %conv29.41.16
  %scevgep35.41.16 = getelementptr i8, i8* %a, i64 58
  %11635 = load i8, i8* %scevgep35.41.16, align 1
  %11636 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.16 = call zeroext i8 @mult(i8 zeroext %11635, i8 zeroext %11636)
  %conv35.41.16 = zext i8 %call34.41.16 to i32
  %xor36.41.16 = xor i32 %xor.41.16, %conv35.41.16
  %conv37.41.16 = trunc i32 %xor36.41.16 to i8
  store i8 %conv37.41.16, i8* %scevgep41.41.15, align 1
  %scevgep28.41.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11630, i64 0, i64 0, i64 1
  %11637 = bitcast i8* %scevgep28.41.16 to [61 x [61 x i8]]*
  %scevgep41.41.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11631, i64 0, i64 1, i64 0
  %11638 = bitcast i8* %scevgep41.41.16 to [61 x [61 x i8]]*
  %call16.41.17 = call zeroext i8 (...) @rand()
  store i8 %call16.41.17, i8* %scevgep28.41.16, align 1
  %11639 = load i8, i8* %scevgep28.41.16, align 1
  %conv23.41.17 = zext i8 %11639 to i32
  %11640 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.17 = getelementptr i8, i8* %b, i64 59
  %11641 = load i8, i8* %scevgep34.41.17, align 1
  %call28.41.17 = call zeroext i8 @mult(i8 zeroext %11640, i8 zeroext %11641)
  %conv29.41.17 = zext i8 %call28.41.17 to i32
  %xor.41.17 = xor i32 %conv23.41.17, %conv29.41.17
  %scevgep35.41.17 = getelementptr i8, i8* %a, i64 59
  %11642 = load i8, i8* %scevgep35.41.17, align 1
  %11643 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.17 = call zeroext i8 @mult(i8 zeroext %11642, i8 zeroext %11643)
  %conv35.41.17 = zext i8 %call34.41.17 to i32
  %xor36.41.17 = xor i32 %xor.41.17, %conv35.41.17
  %conv37.41.17 = trunc i32 %xor36.41.17 to i8
  store i8 %conv37.41.17, i8* %scevgep41.41.16, align 1
  %scevgep28.41.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11637, i64 0, i64 0, i64 1
  %scevgep41.41.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11638, i64 0, i64 1, i64 0
  %call16.41.18 = call zeroext i8 (...) @rand()
  store i8 %call16.41.18, i8* %scevgep28.41.17, align 1
  %11644 = load i8, i8* %scevgep28.41.17, align 1
  %conv23.41.18 = zext i8 %11644 to i32
  %11645 = load i8, i8* %arrayidx25.41, align 1
  %scevgep34.41.18 = getelementptr i8, i8* %b, i64 60
  %11646 = load i8, i8* %scevgep34.41.18, align 1
  %call28.41.18 = call zeroext i8 @mult(i8 zeroext %11645, i8 zeroext %11646)
  %conv29.41.18 = zext i8 %call28.41.18 to i32
  %xor.41.18 = xor i32 %conv23.41.18, %conv29.41.18
  %scevgep35.41.18 = getelementptr i8, i8* %a, i64 60
  %11647 = load i8, i8* %scevgep35.41.18, align 1
  %11648 = load i8, i8* %arrayidx33.41, align 1
  %call34.41.18 = call zeroext i8 @mult(i8 zeroext %11647, i8 zeroext %11648)
  %conv35.41.18 = zext i8 %call34.41.18 to i32
  %xor36.41.18 = xor i32 %xor.41.18, %conv35.41.18
  %conv37.41.18 = trunc i32 %xor36.41.18 to i8
  store i8 %conv37.41.18, i8* %scevgep41.41.17, align 1
  %scevgep26.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11518, i64 0, i64 1, i64 1
  %11649 = bitcast i8* %scevgep26.41 to [61 x [61 x i8]]*
  %scevgep39.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11519, i64 0, i64 1, i64 1
  %11650 = bitcast i8* %scevgep39.41 to [61 x [61 x i8]]*
  %arrayidx25.42 = getelementptr inbounds i8, i8* %a, i64 42
  %arrayidx33.42 = getelementptr inbounds i8, i8* %b, i64 42
  %call16.42 = call zeroext i8 (...) @rand()
  store i8 %call16.42, i8* %scevgep26.41, align 1
  %11651 = load i8, i8* %scevgep26.41, align 1
  %conv23.42 = zext i8 %11651 to i32
  %11652 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42 = getelementptr i8, i8* %b, i64 43
  %11653 = load i8, i8* %scevgep34.42, align 1
  %call28.42 = call zeroext i8 @mult(i8 zeroext %11652, i8 zeroext %11653)
  %conv29.42 = zext i8 %call28.42 to i32
  %xor.42 = xor i32 %conv23.42, %conv29.42
  %scevgep35.42 = getelementptr i8, i8* %a, i64 43
  %11654 = load i8, i8* %scevgep35.42, align 1
  %11655 = load i8, i8* %arrayidx33.42, align 1
  %call34.42 = call zeroext i8 @mult(i8 zeroext %11654, i8 zeroext %11655)
  %conv35.42 = zext i8 %call34.42 to i32
  %xor36.42 = xor i32 %xor.42, %conv35.42
  %conv37.42 = trunc i32 %xor36.42 to i8
  store i8 %conv37.42, i8* %scevgep39.41, align 1
  %scevgep28.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11649, i64 0, i64 0, i64 1
  %11656 = bitcast i8* %scevgep28.42 to [61 x [61 x i8]]*
  %scevgep41.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11650, i64 0, i64 1, i64 0
  %11657 = bitcast i8* %scevgep41.42 to [61 x [61 x i8]]*
  %call16.42.1 = call zeroext i8 (...) @rand()
  store i8 %call16.42.1, i8* %scevgep28.42, align 1
  %11658 = load i8, i8* %scevgep28.42, align 1
  %conv23.42.1 = zext i8 %11658 to i32
  %11659 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.1 = getelementptr i8, i8* %b, i64 44
  %11660 = load i8, i8* %scevgep34.42.1, align 1
  %call28.42.1 = call zeroext i8 @mult(i8 zeroext %11659, i8 zeroext %11660)
  %conv29.42.1 = zext i8 %call28.42.1 to i32
  %xor.42.1 = xor i32 %conv23.42.1, %conv29.42.1
  %scevgep35.42.1 = getelementptr i8, i8* %a, i64 44
  %11661 = load i8, i8* %scevgep35.42.1, align 1
  %11662 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.1 = call zeroext i8 @mult(i8 zeroext %11661, i8 zeroext %11662)
  %conv35.42.1 = zext i8 %call34.42.1 to i32
  %xor36.42.1 = xor i32 %xor.42.1, %conv35.42.1
  %conv37.42.1 = trunc i32 %xor36.42.1 to i8
  store i8 %conv37.42.1, i8* %scevgep41.42, align 1
  %scevgep28.42.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11656, i64 0, i64 0, i64 1
  %11663 = bitcast i8* %scevgep28.42.1 to [61 x [61 x i8]]*
  %scevgep41.42.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11657, i64 0, i64 1, i64 0
  %11664 = bitcast i8* %scevgep41.42.1 to [61 x [61 x i8]]*
  %call16.42.2 = call zeroext i8 (...) @rand()
  store i8 %call16.42.2, i8* %scevgep28.42.1, align 1
  %11665 = load i8, i8* %scevgep28.42.1, align 1
  %conv23.42.2 = zext i8 %11665 to i32
  %11666 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.2 = getelementptr i8, i8* %b, i64 45
  %11667 = load i8, i8* %scevgep34.42.2, align 1
  %call28.42.2 = call zeroext i8 @mult(i8 zeroext %11666, i8 zeroext %11667)
  %conv29.42.2 = zext i8 %call28.42.2 to i32
  %xor.42.2 = xor i32 %conv23.42.2, %conv29.42.2
  %scevgep35.42.2 = getelementptr i8, i8* %a, i64 45
  %11668 = load i8, i8* %scevgep35.42.2, align 1
  %11669 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.2 = call zeroext i8 @mult(i8 zeroext %11668, i8 zeroext %11669)
  %conv35.42.2 = zext i8 %call34.42.2 to i32
  %xor36.42.2 = xor i32 %xor.42.2, %conv35.42.2
  %conv37.42.2 = trunc i32 %xor36.42.2 to i8
  store i8 %conv37.42.2, i8* %scevgep41.42.1, align 1
  %scevgep28.42.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11663, i64 0, i64 0, i64 1
  %11670 = bitcast i8* %scevgep28.42.2 to [61 x [61 x i8]]*
  %scevgep41.42.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11664, i64 0, i64 1, i64 0
  %11671 = bitcast i8* %scevgep41.42.2 to [61 x [61 x i8]]*
  %call16.42.3 = call zeroext i8 (...) @rand()
  store i8 %call16.42.3, i8* %scevgep28.42.2, align 1
  %11672 = load i8, i8* %scevgep28.42.2, align 1
  %conv23.42.3 = zext i8 %11672 to i32
  %11673 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.3 = getelementptr i8, i8* %b, i64 46
  %11674 = load i8, i8* %scevgep34.42.3, align 1
  %call28.42.3 = call zeroext i8 @mult(i8 zeroext %11673, i8 zeroext %11674)
  %conv29.42.3 = zext i8 %call28.42.3 to i32
  %xor.42.3 = xor i32 %conv23.42.3, %conv29.42.3
  %scevgep35.42.3 = getelementptr i8, i8* %a, i64 46
  %11675 = load i8, i8* %scevgep35.42.3, align 1
  %11676 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.3 = call zeroext i8 @mult(i8 zeroext %11675, i8 zeroext %11676)
  %conv35.42.3 = zext i8 %call34.42.3 to i32
  %xor36.42.3 = xor i32 %xor.42.3, %conv35.42.3
  %conv37.42.3 = trunc i32 %xor36.42.3 to i8
  store i8 %conv37.42.3, i8* %scevgep41.42.2, align 1
  %scevgep28.42.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11670, i64 0, i64 0, i64 1
  %11677 = bitcast i8* %scevgep28.42.3 to [61 x [61 x i8]]*
  %scevgep41.42.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11671, i64 0, i64 1, i64 0
  %11678 = bitcast i8* %scevgep41.42.3 to [61 x [61 x i8]]*
  %call16.42.4 = call zeroext i8 (...) @rand()
  store i8 %call16.42.4, i8* %scevgep28.42.3, align 1
  %11679 = load i8, i8* %scevgep28.42.3, align 1
  %conv23.42.4 = zext i8 %11679 to i32
  %11680 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.4 = getelementptr i8, i8* %b, i64 47
  %11681 = load i8, i8* %scevgep34.42.4, align 1
  %call28.42.4 = call zeroext i8 @mult(i8 zeroext %11680, i8 zeroext %11681)
  %conv29.42.4 = zext i8 %call28.42.4 to i32
  %xor.42.4 = xor i32 %conv23.42.4, %conv29.42.4
  %scevgep35.42.4 = getelementptr i8, i8* %a, i64 47
  %11682 = load i8, i8* %scevgep35.42.4, align 1
  %11683 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.4 = call zeroext i8 @mult(i8 zeroext %11682, i8 zeroext %11683)
  %conv35.42.4 = zext i8 %call34.42.4 to i32
  %xor36.42.4 = xor i32 %xor.42.4, %conv35.42.4
  %conv37.42.4 = trunc i32 %xor36.42.4 to i8
  store i8 %conv37.42.4, i8* %scevgep41.42.3, align 1
  %scevgep28.42.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11677, i64 0, i64 0, i64 1
  %11684 = bitcast i8* %scevgep28.42.4 to [61 x [61 x i8]]*
  %scevgep41.42.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11678, i64 0, i64 1, i64 0
  %11685 = bitcast i8* %scevgep41.42.4 to [61 x [61 x i8]]*
  %call16.42.5 = call zeroext i8 (...) @rand()
  store i8 %call16.42.5, i8* %scevgep28.42.4, align 1
  %11686 = load i8, i8* %scevgep28.42.4, align 1
  %conv23.42.5 = zext i8 %11686 to i32
  %11687 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.5 = getelementptr i8, i8* %b, i64 48
  %11688 = load i8, i8* %scevgep34.42.5, align 1
  %call28.42.5 = call zeroext i8 @mult(i8 zeroext %11687, i8 zeroext %11688)
  %conv29.42.5 = zext i8 %call28.42.5 to i32
  %xor.42.5 = xor i32 %conv23.42.5, %conv29.42.5
  %scevgep35.42.5 = getelementptr i8, i8* %a, i64 48
  %11689 = load i8, i8* %scevgep35.42.5, align 1
  %11690 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.5 = call zeroext i8 @mult(i8 zeroext %11689, i8 zeroext %11690)
  %conv35.42.5 = zext i8 %call34.42.5 to i32
  %xor36.42.5 = xor i32 %xor.42.5, %conv35.42.5
  %conv37.42.5 = trunc i32 %xor36.42.5 to i8
  store i8 %conv37.42.5, i8* %scevgep41.42.4, align 1
  %scevgep28.42.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11684, i64 0, i64 0, i64 1
  %11691 = bitcast i8* %scevgep28.42.5 to [61 x [61 x i8]]*
  %scevgep41.42.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11685, i64 0, i64 1, i64 0
  %11692 = bitcast i8* %scevgep41.42.5 to [61 x [61 x i8]]*
  %call16.42.6 = call zeroext i8 (...) @rand()
  store i8 %call16.42.6, i8* %scevgep28.42.5, align 1
  %11693 = load i8, i8* %scevgep28.42.5, align 1
  %conv23.42.6 = zext i8 %11693 to i32
  %11694 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.6 = getelementptr i8, i8* %b, i64 49
  %11695 = load i8, i8* %scevgep34.42.6, align 1
  %call28.42.6 = call zeroext i8 @mult(i8 zeroext %11694, i8 zeroext %11695)
  %conv29.42.6 = zext i8 %call28.42.6 to i32
  %xor.42.6 = xor i32 %conv23.42.6, %conv29.42.6
  %scevgep35.42.6 = getelementptr i8, i8* %a, i64 49
  %11696 = load i8, i8* %scevgep35.42.6, align 1
  %11697 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.6 = call zeroext i8 @mult(i8 zeroext %11696, i8 zeroext %11697)
  %conv35.42.6 = zext i8 %call34.42.6 to i32
  %xor36.42.6 = xor i32 %xor.42.6, %conv35.42.6
  %conv37.42.6 = trunc i32 %xor36.42.6 to i8
  store i8 %conv37.42.6, i8* %scevgep41.42.5, align 1
  %scevgep28.42.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11691, i64 0, i64 0, i64 1
  %11698 = bitcast i8* %scevgep28.42.6 to [61 x [61 x i8]]*
  %scevgep41.42.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11692, i64 0, i64 1, i64 0
  %11699 = bitcast i8* %scevgep41.42.6 to [61 x [61 x i8]]*
  %call16.42.7 = call zeroext i8 (...) @rand()
  store i8 %call16.42.7, i8* %scevgep28.42.6, align 1
  %11700 = load i8, i8* %scevgep28.42.6, align 1
  %conv23.42.7 = zext i8 %11700 to i32
  %11701 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.7 = getelementptr i8, i8* %b, i64 50
  %11702 = load i8, i8* %scevgep34.42.7, align 1
  %call28.42.7 = call zeroext i8 @mult(i8 zeroext %11701, i8 zeroext %11702)
  %conv29.42.7 = zext i8 %call28.42.7 to i32
  %xor.42.7 = xor i32 %conv23.42.7, %conv29.42.7
  %scevgep35.42.7 = getelementptr i8, i8* %a, i64 50
  %11703 = load i8, i8* %scevgep35.42.7, align 1
  %11704 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.7 = call zeroext i8 @mult(i8 zeroext %11703, i8 zeroext %11704)
  %conv35.42.7 = zext i8 %call34.42.7 to i32
  %xor36.42.7 = xor i32 %xor.42.7, %conv35.42.7
  %conv37.42.7 = trunc i32 %xor36.42.7 to i8
  store i8 %conv37.42.7, i8* %scevgep41.42.6, align 1
  %scevgep28.42.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11698, i64 0, i64 0, i64 1
  %11705 = bitcast i8* %scevgep28.42.7 to [61 x [61 x i8]]*
  %scevgep41.42.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11699, i64 0, i64 1, i64 0
  %11706 = bitcast i8* %scevgep41.42.7 to [61 x [61 x i8]]*
  %call16.42.8 = call zeroext i8 (...) @rand()
  store i8 %call16.42.8, i8* %scevgep28.42.7, align 1
  %11707 = load i8, i8* %scevgep28.42.7, align 1
  %conv23.42.8 = zext i8 %11707 to i32
  %11708 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.8 = getelementptr i8, i8* %b, i64 51
  %11709 = load i8, i8* %scevgep34.42.8, align 1
  %call28.42.8 = call zeroext i8 @mult(i8 zeroext %11708, i8 zeroext %11709)
  %conv29.42.8 = zext i8 %call28.42.8 to i32
  %xor.42.8 = xor i32 %conv23.42.8, %conv29.42.8
  %scevgep35.42.8 = getelementptr i8, i8* %a, i64 51
  %11710 = load i8, i8* %scevgep35.42.8, align 1
  %11711 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.8 = call zeroext i8 @mult(i8 zeroext %11710, i8 zeroext %11711)
  %conv35.42.8 = zext i8 %call34.42.8 to i32
  %xor36.42.8 = xor i32 %xor.42.8, %conv35.42.8
  %conv37.42.8 = trunc i32 %xor36.42.8 to i8
  store i8 %conv37.42.8, i8* %scevgep41.42.7, align 1
  %scevgep28.42.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11705, i64 0, i64 0, i64 1
  %11712 = bitcast i8* %scevgep28.42.8 to [61 x [61 x i8]]*
  %scevgep41.42.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11706, i64 0, i64 1, i64 0
  %11713 = bitcast i8* %scevgep41.42.8 to [61 x [61 x i8]]*
  %call16.42.9 = call zeroext i8 (...) @rand()
  store i8 %call16.42.9, i8* %scevgep28.42.8, align 1
  %11714 = load i8, i8* %scevgep28.42.8, align 1
  %conv23.42.9 = zext i8 %11714 to i32
  %11715 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.9 = getelementptr i8, i8* %b, i64 52
  %11716 = load i8, i8* %scevgep34.42.9, align 1
  %call28.42.9 = call zeroext i8 @mult(i8 zeroext %11715, i8 zeroext %11716)
  %conv29.42.9 = zext i8 %call28.42.9 to i32
  %xor.42.9 = xor i32 %conv23.42.9, %conv29.42.9
  %scevgep35.42.9 = getelementptr i8, i8* %a, i64 52
  %11717 = load i8, i8* %scevgep35.42.9, align 1
  %11718 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.9 = call zeroext i8 @mult(i8 zeroext %11717, i8 zeroext %11718)
  %conv35.42.9 = zext i8 %call34.42.9 to i32
  %xor36.42.9 = xor i32 %xor.42.9, %conv35.42.9
  %conv37.42.9 = trunc i32 %xor36.42.9 to i8
  store i8 %conv37.42.9, i8* %scevgep41.42.8, align 1
  %scevgep28.42.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11712, i64 0, i64 0, i64 1
  %11719 = bitcast i8* %scevgep28.42.9 to [61 x [61 x i8]]*
  %scevgep41.42.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11713, i64 0, i64 1, i64 0
  %11720 = bitcast i8* %scevgep41.42.9 to [61 x [61 x i8]]*
  %call16.42.10 = call zeroext i8 (...) @rand()
  store i8 %call16.42.10, i8* %scevgep28.42.9, align 1
  %11721 = load i8, i8* %scevgep28.42.9, align 1
  %conv23.42.10 = zext i8 %11721 to i32
  %11722 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.10 = getelementptr i8, i8* %b, i64 53
  %11723 = load i8, i8* %scevgep34.42.10, align 1
  %call28.42.10 = call zeroext i8 @mult(i8 zeroext %11722, i8 zeroext %11723)
  %conv29.42.10 = zext i8 %call28.42.10 to i32
  %xor.42.10 = xor i32 %conv23.42.10, %conv29.42.10
  %scevgep35.42.10 = getelementptr i8, i8* %a, i64 53
  %11724 = load i8, i8* %scevgep35.42.10, align 1
  %11725 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.10 = call zeroext i8 @mult(i8 zeroext %11724, i8 zeroext %11725)
  %conv35.42.10 = zext i8 %call34.42.10 to i32
  %xor36.42.10 = xor i32 %xor.42.10, %conv35.42.10
  %conv37.42.10 = trunc i32 %xor36.42.10 to i8
  store i8 %conv37.42.10, i8* %scevgep41.42.9, align 1
  %scevgep28.42.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11719, i64 0, i64 0, i64 1
  %11726 = bitcast i8* %scevgep28.42.10 to [61 x [61 x i8]]*
  %scevgep41.42.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11720, i64 0, i64 1, i64 0
  %11727 = bitcast i8* %scevgep41.42.10 to [61 x [61 x i8]]*
  %call16.42.11 = call zeroext i8 (...) @rand()
  store i8 %call16.42.11, i8* %scevgep28.42.10, align 1
  %11728 = load i8, i8* %scevgep28.42.10, align 1
  %conv23.42.11 = zext i8 %11728 to i32
  %11729 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.11 = getelementptr i8, i8* %b, i64 54
  %11730 = load i8, i8* %scevgep34.42.11, align 1
  %call28.42.11 = call zeroext i8 @mult(i8 zeroext %11729, i8 zeroext %11730)
  %conv29.42.11 = zext i8 %call28.42.11 to i32
  %xor.42.11 = xor i32 %conv23.42.11, %conv29.42.11
  %scevgep35.42.11 = getelementptr i8, i8* %a, i64 54
  %11731 = load i8, i8* %scevgep35.42.11, align 1
  %11732 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.11 = call zeroext i8 @mult(i8 zeroext %11731, i8 zeroext %11732)
  %conv35.42.11 = zext i8 %call34.42.11 to i32
  %xor36.42.11 = xor i32 %xor.42.11, %conv35.42.11
  %conv37.42.11 = trunc i32 %xor36.42.11 to i8
  store i8 %conv37.42.11, i8* %scevgep41.42.10, align 1
  %scevgep28.42.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11726, i64 0, i64 0, i64 1
  %11733 = bitcast i8* %scevgep28.42.11 to [61 x [61 x i8]]*
  %scevgep41.42.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11727, i64 0, i64 1, i64 0
  %11734 = bitcast i8* %scevgep41.42.11 to [61 x [61 x i8]]*
  %call16.42.12 = call zeroext i8 (...) @rand()
  store i8 %call16.42.12, i8* %scevgep28.42.11, align 1
  %11735 = load i8, i8* %scevgep28.42.11, align 1
  %conv23.42.12 = zext i8 %11735 to i32
  %11736 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.12 = getelementptr i8, i8* %b, i64 55
  %11737 = load i8, i8* %scevgep34.42.12, align 1
  %call28.42.12 = call zeroext i8 @mult(i8 zeroext %11736, i8 zeroext %11737)
  %conv29.42.12 = zext i8 %call28.42.12 to i32
  %xor.42.12 = xor i32 %conv23.42.12, %conv29.42.12
  %scevgep35.42.12 = getelementptr i8, i8* %a, i64 55
  %11738 = load i8, i8* %scevgep35.42.12, align 1
  %11739 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.12 = call zeroext i8 @mult(i8 zeroext %11738, i8 zeroext %11739)
  %conv35.42.12 = zext i8 %call34.42.12 to i32
  %xor36.42.12 = xor i32 %xor.42.12, %conv35.42.12
  %conv37.42.12 = trunc i32 %xor36.42.12 to i8
  store i8 %conv37.42.12, i8* %scevgep41.42.11, align 1
  %scevgep28.42.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11733, i64 0, i64 0, i64 1
  %11740 = bitcast i8* %scevgep28.42.12 to [61 x [61 x i8]]*
  %scevgep41.42.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11734, i64 0, i64 1, i64 0
  %11741 = bitcast i8* %scevgep41.42.12 to [61 x [61 x i8]]*
  %call16.42.13 = call zeroext i8 (...) @rand()
  store i8 %call16.42.13, i8* %scevgep28.42.12, align 1
  %11742 = load i8, i8* %scevgep28.42.12, align 1
  %conv23.42.13 = zext i8 %11742 to i32
  %11743 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.13 = getelementptr i8, i8* %b, i64 56
  %11744 = load i8, i8* %scevgep34.42.13, align 1
  %call28.42.13 = call zeroext i8 @mult(i8 zeroext %11743, i8 zeroext %11744)
  %conv29.42.13 = zext i8 %call28.42.13 to i32
  %xor.42.13 = xor i32 %conv23.42.13, %conv29.42.13
  %scevgep35.42.13 = getelementptr i8, i8* %a, i64 56
  %11745 = load i8, i8* %scevgep35.42.13, align 1
  %11746 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.13 = call zeroext i8 @mult(i8 zeroext %11745, i8 zeroext %11746)
  %conv35.42.13 = zext i8 %call34.42.13 to i32
  %xor36.42.13 = xor i32 %xor.42.13, %conv35.42.13
  %conv37.42.13 = trunc i32 %xor36.42.13 to i8
  store i8 %conv37.42.13, i8* %scevgep41.42.12, align 1
  %scevgep28.42.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11740, i64 0, i64 0, i64 1
  %11747 = bitcast i8* %scevgep28.42.13 to [61 x [61 x i8]]*
  %scevgep41.42.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11741, i64 0, i64 1, i64 0
  %11748 = bitcast i8* %scevgep41.42.13 to [61 x [61 x i8]]*
  %call16.42.14 = call zeroext i8 (...) @rand()
  store i8 %call16.42.14, i8* %scevgep28.42.13, align 1
  %11749 = load i8, i8* %scevgep28.42.13, align 1
  %conv23.42.14 = zext i8 %11749 to i32
  %11750 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.14 = getelementptr i8, i8* %b, i64 57
  %11751 = load i8, i8* %scevgep34.42.14, align 1
  %call28.42.14 = call zeroext i8 @mult(i8 zeroext %11750, i8 zeroext %11751)
  %conv29.42.14 = zext i8 %call28.42.14 to i32
  %xor.42.14 = xor i32 %conv23.42.14, %conv29.42.14
  %scevgep35.42.14 = getelementptr i8, i8* %a, i64 57
  %11752 = load i8, i8* %scevgep35.42.14, align 1
  %11753 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.14 = call zeroext i8 @mult(i8 zeroext %11752, i8 zeroext %11753)
  %conv35.42.14 = zext i8 %call34.42.14 to i32
  %xor36.42.14 = xor i32 %xor.42.14, %conv35.42.14
  %conv37.42.14 = trunc i32 %xor36.42.14 to i8
  store i8 %conv37.42.14, i8* %scevgep41.42.13, align 1
  %scevgep28.42.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11747, i64 0, i64 0, i64 1
  %11754 = bitcast i8* %scevgep28.42.14 to [61 x [61 x i8]]*
  %scevgep41.42.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11748, i64 0, i64 1, i64 0
  %11755 = bitcast i8* %scevgep41.42.14 to [61 x [61 x i8]]*
  %call16.42.15 = call zeroext i8 (...) @rand()
  store i8 %call16.42.15, i8* %scevgep28.42.14, align 1
  %11756 = load i8, i8* %scevgep28.42.14, align 1
  %conv23.42.15 = zext i8 %11756 to i32
  %11757 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.15 = getelementptr i8, i8* %b, i64 58
  %11758 = load i8, i8* %scevgep34.42.15, align 1
  %call28.42.15 = call zeroext i8 @mult(i8 zeroext %11757, i8 zeroext %11758)
  %conv29.42.15 = zext i8 %call28.42.15 to i32
  %xor.42.15 = xor i32 %conv23.42.15, %conv29.42.15
  %scevgep35.42.15 = getelementptr i8, i8* %a, i64 58
  %11759 = load i8, i8* %scevgep35.42.15, align 1
  %11760 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.15 = call zeroext i8 @mult(i8 zeroext %11759, i8 zeroext %11760)
  %conv35.42.15 = zext i8 %call34.42.15 to i32
  %xor36.42.15 = xor i32 %xor.42.15, %conv35.42.15
  %conv37.42.15 = trunc i32 %xor36.42.15 to i8
  store i8 %conv37.42.15, i8* %scevgep41.42.14, align 1
  %scevgep28.42.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11754, i64 0, i64 0, i64 1
  %11761 = bitcast i8* %scevgep28.42.15 to [61 x [61 x i8]]*
  %scevgep41.42.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11755, i64 0, i64 1, i64 0
  %11762 = bitcast i8* %scevgep41.42.15 to [61 x [61 x i8]]*
  %call16.42.16 = call zeroext i8 (...) @rand()
  store i8 %call16.42.16, i8* %scevgep28.42.15, align 1
  %11763 = load i8, i8* %scevgep28.42.15, align 1
  %conv23.42.16 = zext i8 %11763 to i32
  %11764 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.16 = getelementptr i8, i8* %b, i64 59
  %11765 = load i8, i8* %scevgep34.42.16, align 1
  %call28.42.16 = call zeroext i8 @mult(i8 zeroext %11764, i8 zeroext %11765)
  %conv29.42.16 = zext i8 %call28.42.16 to i32
  %xor.42.16 = xor i32 %conv23.42.16, %conv29.42.16
  %scevgep35.42.16 = getelementptr i8, i8* %a, i64 59
  %11766 = load i8, i8* %scevgep35.42.16, align 1
  %11767 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.16 = call zeroext i8 @mult(i8 zeroext %11766, i8 zeroext %11767)
  %conv35.42.16 = zext i8 %call34.42.16 to i32
  %xor36.42.16 = xor i32 %xor.42.16, %conv35.42.16
  %conv37.42.16 = trunc i32 %xor36.42.16 to i8
  store i8 %conv37.42.16, i8* %scevgep41.42.15, align 1
  %scevgep28.42.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11761, i64 0, i64 0, i64 1
  %scevgep41.42.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11762, i64 0, i64 1, i64 0
  %call16.42.17 = call zeroext i8 (...) @rand()
  store i8 %call16.42.17, i8* %scevgep28.42.16, align 1
  %11768 = load i8, i8* %scevgep28.42.16, align 1
  %conv23.42.17 = zext i8 %11768 to i32
  %11769 = load i8, i8* %arrayidx25.42, align 1
  %scevgep34.42.17 = getelementptr i8, i8* %b, i64 60
  %11770 = load i8, i8* %scevgep34.42.17, align 1
  %call28.42.17 = call zeroext i8 @mult(i8 zeroext %11769, i8 zeroext %11770)
  %conv29.42.17 = zext i8 %call28.42.17 to i32
  %xor.42.17 = xor i32 %conv23.42.17, %conv29.42.17
  %scevgep35.42.17 = getelementptr i8, i8* %a, i64 60
  %11771 = load i8, i8* %scevgep35.42.17, align 1
  %11772 = load i8, i8* %arrayidx33.42, align 1
  %call34.42.17 = call zeroext i8 @mult(i8 zeroext %11771, i8 zeroext %11772)
  %conv35.42.17 = zext i8 %call34.42.17 to i32
  %xor36.42.17 = xor i32 %xor.42.17, %conv35.42.17
  %conv37.42.17 = trunc i32 %xor36.42.17 to i8
  store i8 %conv37.42.17, i8* %scevgep41.42.16, align 1
  %scevgep26.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11649, i64 0, i64 1, i64 1
  %11773 = bitcast i8* %scevgep26.42 to [61 x [61 x i8]]*
  %scevgep39.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11650, i64 0, i64 1, i64 1
  %11774 = bitcast i8* %scevgep39.42 to [61 x [61 x i8]]*
  %arrayidx25.43 = getelementptr inbounds i8, i8* %a, i64 43
  %arrayidx33.43 = getelementptr inbounds i8, i8* %b, i64 43
  %call16.43 = call zeroext i8 (...) @rand()
  store i8 %call16.43, i8* %scevgep26.42, align 1
  %11775 = load i8, i8* %scevgep26.42, align 1
  %conv23.43 = zext i8 %11775 to i32
  %11776 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43 = getelementptr i8, i8* %b, i64 44
  %11777 = load i8, i8* %scevgep34.43, align 1
  %call28.43 = call zeroext i8 @mult(i8 zeroext %11776, i8 zeroext %11777)
  %conv29.43 = zext i8 %call28.43 to i32
  %xor.43 = xor i32 %conv23.43, %conv29.43
  %scevgep35.43 = getelementptr i8, i8* %a, i64 44
  %11778 = load i8, i8* %scevgep35.43, align 1
  %11779 = load i8, i8* %arrayidx33.43, align 1
  %call34.43 = call zeroext i8 @mult(i8 zeroext %11778, i8 zeroext %11779)
  %conv35.43 = zext i8 %call34.43 to i32
  %xor36.43 = xor i32 %xor.43, %conv35.43
  %conv37.43 = trunc i32 %xor36.43 to i8
  store i8 %conv37.43, i8* %scevgep39.42, align 1
  %scevgep28.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11773, i64 0, i64 0, i64 1
  %11780 = bitcast i8* %scevgep28.43 to [61 x [61 x i8]]*
  %scevgep41.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11774, i64 0, i64 1, i64 0
  %11781 = bitcast i8* %scevgep41.43 to [61 x [61 x i8]]*
  %call16.43.1 = call zeroext i8 (...) @rand()
  store i8 %call16.43.1, i8* %scevgep28.43, align 1
  %11782 = load i8, i8* %scevgep28.43, align 1
  %conv23.43.1 = zext i8 %11782 to i32
  %11783 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.1 = getelementptr i8, i8* %b, i64 45
  %11784 = load i8, i8* %scevgep34.43.1, align 1
  %call28.43.1 = call zeroext i8 @mult(i8 zeroext %11783, i8 zeroext %11784)
  %conv29.43.1 = zext i8 %call28.43.1 to i32
  %xor.43.1 = xor i32 %conv23.43.1, %conv29.43.1
  %scevgep35.43.1 = getelementptr i8, i8* %a, i64 45
  %11785 = load i8, i8* %scevgep35.43.1, align 1
  %11786 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.1 = call zeroext i8 @mult(i8 zeroext %11785, i8 zeroext %11786)
  %conv35.43.1 = zext i8 %call34.43.1 to i32
  %xor36.43.1 = xor i32 %xor.43.1, %conv35.43.1
  %conv37.43.1 = trunc i32 %xor36.43.1 to i8
  store i8 %conv37.43.1, i8* %scevgep41.43, align 1
  %scevgep28.43.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11780, i64 0, i64 0, i64 1
  %11787 = bitcast i8* %scevgep28.43.1 to [61 x [61 x i8]]*
  %scevgep41.43.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11781, i64 0, i64 1, i64 0
  %11788 = bitcast i8* %scevgep41.43.1 to [61 x [61 x i8]]*
  %call16.43.2 = call zeroext i8 (...) @rand()
  store i8 %call16.43.2, i8* %scevgep28.43.1, align 1
  %11789 = load i8, i8* %scevgep28.43.1, align 1
  %conv23.43.2 = zext i8 %11789 to i32
  %11790 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.2 = getelementptr i8, i8* %b, i64 46
  %11791 = load i8, i8* %scevgep34.43.2, align 1
  %call28.43.2 = call zeroext i8 @mult(i8 zeroext %11790, i8 zeroext %11791)
  %conv29.43.2 = zext i8 %call28.43.2 to i32
  %xor.43.2 = xor i32 %conv23.43.2, %conv29.43.2
  %scevgep35.43.2 = getelementptr i8, i8* %a, i64 46
  %11792 = load i8, i8* %scevgep35.43.2, align 1
  %11793 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.2 = call zeroext i8 @mult(i8 zeroext %11792, i8 zeroext %11793)
  %conv35.43.2 = zext i8 %call34.43.2 to i32
  %xor36.43.2 = xor i32 %xor.43.2, %conv35.43.2
  %conv37.43.2 = trunc i32 %xor36.43.2 to i8
  store i8 %conv37.43.2, i8* %scevgep41.43.1, align 1
  %scevgep28.43.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11787, i64 0, i64 0, i64 1
  %11794 = bitcast i8* %scevgep28.43.2 to [61 x [61 x i8]]*
  %scevgep41.43.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11788, i64 0, i64 1, i64 0
  %11795 = bitcast i8* %scevgep41.43.2 to [61 x [61 x i8]]*
  %call16.43.3 = call zeroext i8 (...) @rand()
  store i8 %call16.43.3, i8* %scevgep28.43.2, align 1
  %11796 = load i8, i8* %scevgep28.43.2, align 1
  %conv23.43.3 = zext i8 %11796 to i32
  %11797 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.3 = getelementptr i8, i8* %b, i64 47
  %11798 = load i8, i8* %scevgep34.43.3, align 1
  %call28.43.3 = call zeroext i8 @mult(i8 zeroext %11797, i8 zeroext %11798)
  %conv29.43.3 = zext i8 %call28.43.3 to i32
  %xor.43.3 = xor i32 %conv23.43.3, %conv29.43.3
  %scevgep35.43.3 = getelementptr i8, i8* %a, i64 47
  %11799 = load i8, i8* %scevgep35.43.3, align 1
  %11800 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.3 = call zeroext i8 @mult(i8 zeroext %11799, i8 zeroext %11800)
  %conv35.43.3 = zext i8 %call34.43.3 to i32
  %xor36.43.3 = xor i32 %xor.43.3, %conv35.43.3
  %conv37.43.3 = trunc i32 %xor36.43.3 to i8
  store i8 %conv37.43.3, i8* %scevgep41.43.2, align 1
  %scevgep28.43.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11794, i64 0, i64 0, i64 1
  %11801 = bitcast i8* %scevgep28.43.3 to [61 x [61 x i8]]*
  %scevgep41.43.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11795, i64 0, i64 1, i64 0
  %11802 = bitcast i8* %scevgep41.43.3 to [61 x [61 x i8]]*
  %call16.43.4 = call zeroext i8 (...) @rand()
  store i8 %call16.43.4, i8* %scevgep28.43.3, align 1
  %11803 = load i8, i8* %scevgep28.43.3, align 1
  %conv23.43.4 = zext i8 %11803 to i32
  %11804 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.4 = getelementptr i8, i8* %b, i64 48
  %11805 = load i8, i8* %scevgep34.43.4, align 1
  %call28.43.4 = call zeroext i8 @mult(i8 zeroext %11804, i8 zeroext %11805)
  %conv29.43.4 = zext i8 %call28.43.4 to i32
  %xor.43.4 = xor i32 %conv23.43.4, %conv29.43.4
  %scevgep35.43.4 = getelementptr i8, i8* %a, i64 48
  %11806 = load i8, i8* %scevgep35.43.4, align 1
  %11807 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.4 = call zeroext i8 @mult(i8 zeroext %11806, i8 zeroext %11807)
  %conv35.43.4 = zext i8 %call34.43.4 to i32
  %xor36.43.4 = xor i32 %xor.43.4, %conv35.43.4
  %conv37.43.4 = trunc i32 %xor36.43.4 to i8
  store i8 %conv37.43.4, i8* %scevgep41.43.3, align 1
  %scevgep28.43.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11801, i64 0, i64 0, i64 1
  %11808 = bitcast i8* %scevgep28.43.4 to [61 x [61 x i8]]*
  %scevgep41.43.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11802, i64 0, i64 1, i64 0
  %11809 = bitcast i8* %scevgep41.43.4 to [61 x [61 x i8]]*
  %call16.43.5 = call zeroext i8 (...) @rand()
  store i8 %call16.43.5, i8* %scevgep28.43.4, align 1
  %11810 = load i8, i8* %scevgep28.43.4, align 1
  %conv23.43.5 = zext i8 %11810 to i32
  %11811 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.5 = getelementptr i8, i8* %b, i64 49
  %11812 = load i8, i8* %scevgep34.43.5, align 1
  %call28.43.5 = call zeroext i8 @mult(i8 zeroext %11811, i8 zeroext %11812)
  %conv29.43.5 = zext i8 %call28.43.5 to i32
  %xor.43.5 = xor i32 %conv23.43.5, %conv29.43.5
  %scevgep35.43.5 = getelementptr i8, i8* %a, i64 49
  %11813 = load i8, i8* %scevgep35.43.5, align 1
  %11814 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.5 = call zeroext i8 @mult(i8 zeroext %11813, i8 zeroext %11814)
  %conv35.43.5 = zext i8 %call34.43.5 to i32
  %xor36.43.5 = xor i32 %xor.43.5, %conv35.43.5
  %conv37.43.5 = trunc i32 %xor36.43.5 to i8
  store i8 %conv37.43.5, i8* %scevgep41.43.4, align 1
  %scevgep28.43.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11808, i64 0, i64 0, i64 1
  %11815 = bitcast i8* %scevgep28.43.5 to [61 x [61 x i8]]*
  %scevgep41.43.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11809, i64 0, i64 1, i64 0
  %11816 = bitcast i8* %scevgep41.43.5 to [61 x [61 x i8]]*
  %call16.43.6 = call zeroext i8 (...) @rand()
  store i8 %call16.43.6, i8* %scevgep28.43.5, align 1
  %11817 = load i8, i8* %scevgep28.43.5, align 1
  %conv23.43.6 = zext i8 %11817 to i32
  %11818 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.6 = getelementptr i8, i8* %b, i64 50
  %11819 = load i8, i8* %scevgep34.43.6, align 1
  %call28.43.6 = call zeroext i8 @mult(i8 zeroext %11818, i8 zeroext %11819)
  %conv29.43.6 = zext i8 %call28.43.6 to i32
  %xor.43.6 = xor i32 %conv23.43.6, %conv29.43.6
  %scevgep35.43.6 = getelementptr i8, i8* %a, i64 50
  %11820 = load i8, i8* %scevgep35.43.6, align 1
  %11821 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.6 = call zeroext i8 @mult(i8 zeroext %11820, i8 zeroext %11821)
  %conv35.43.6 = zext i8 %call34.43.6 to i32
  %xor36.43.6 = xor i32 %xor.43.6, %conv35.43.6
  %conv37.43.6 = trunc i32 %xor36.43.6 to i8
  store i8 %conv37.43.6, i8* %scevgep41.43.5, align 1
  %scevgep28.43.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11815, i64 0, i64 0, i64 1
  %11822 = bitcast i8* %scevgep28.43.6 to [61 x [61 x i8]]*
  %scevgep41.43.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11816, i64 0, i64 1, i64 0
  %11823 = bitcast i8* %scevgep41.43.6 to [61 x [61 x i8]]*
  %call16.43.7 = call zeroext i8 (...) @rand()
  store i8 %call16.43.7, i8* %scevgep28.43.6, align 1
  %11824 = load i8, i8* %scevgep28.43.6, align 1
  %conv23.43.7 = zext i8 %11824 to i32
  %11825 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.7 = getelementptr i8, i8* %b, i64 51
  %11826 = load i8, i8* %scevgep34.43.7, align 1
  %call28.43.7 = call zeroext i8 @mult(i8 zeroext %11825, i8 zeroext %11826)
  %conv29.43.7 = zext i8 %call28.43.7 to i32
  %xor.43.7 = xor i32 %conv23.43.7, %conv29.43.7
  %scevgep35.43.7 = getelementptr i8, i8* %a, i64 51
  %11827 = load i8, i8* %scevgep35.43.7, align 1
  %11828 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.7 = call zeroext i8 @mult(i8 zeroext %11827, i8 zeroext %11828)
  %conv35.43.7 = zext i8 %call34.43.7 to i32
  %xor36.43.7 = xor i32 %xor.43.7, %conv35.43.7
  %conv37.43.7 = trunc i32 %xor36.43.7 to i8
  store i8 %conv37.43.7, i8* %scevgep41.43.6, align 1
  %scevgep28.43.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11822, i64 0, i64 0, i64 1
  %11829 = bitcast i8* %scevgep28.43.7 to [61 x [61 x i8]]*
  %scevgep41.43.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11823, i64 0, i64 1, i64 0
  %11830 = bitcast i8* %scevgep41.43.7 to [61 x [61 x i8]]*
  %call16.43.8 = call zeroext i8 (...) @rand()
  store i8 %call16.43.8, i8* %scevgep28.43.7, align 1
  %11831 = load i8, i8* %scevgep28.43.7, align 1
  %conv23.43.8 = zext i8 %11831 to i32
  %11832 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.8 = getelementptr i8, i8* %b, i64 52
  %11833 = load i8, i8* %scevgep34.43.8, align 1
  %call28.43.8 = call zeroext i8 @mult(i8 zeroext %11832, i8 zeroext %11833)
  %conv29.43.8 = zext i8 %call28.43.8 to i32
  %xor.43.8 = xor i32 %conv23.43.8, %conv29.43.8
  %scevgep35.43.8 = getelementptr i8, i8* %a, i64 52
  %11834 = load i8, i8* %scevgep35.43.8, align 1
  %11835 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.8 = call zeroext i8 @mult(i8 zeroext %11834, i8 zeroext %11835)
  %conv35.43.8 = zext i8 %call34.43.8 to i32
  %xor36.43.8 = xor i32 %xor.43.8, %conv35.43.8
  %conv37.43.8 = trunc i32 %xor36.43.8 to i8
  store i8 %conv37.43.8, i8* %scevgep41.43.7, align 1
  %scevgep28.43.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11829, i64 0, i64 0, i64 1
  %11836 = bitcast i8* %scevgep28.43.8 to [61 x [61 x i8]]*
  %scevgep41.43.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11830, i64 0, i64 1, i64 0
  %11837 = bitcast i8* %scevgep41.43.8 to [61 x [61 x i8]]*
  %call16.43.9 = call zeroext i8 (...) @rand()
  store i8 %call16.43.9, i8* %scevgep28.43.8, align 1
  %11838 = load i8, i8* %scevgep28.43.8, align 1
  %conv23.43.9 = zext i8 %11838 to i32
  %11839 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.9 = getelementptr i8, i8* %b, i64 53
  %11840 = load i8, i8* %scevgep34.43.9, align 1
  %call28.43.9 = call zeroext i8 @mult(i8 zeroext %11839, i8 zeroext %11840)
  %conv29.43.9 = zext i8 %call28.43.9 to i32
  %xor.43.9 = xor i32 %conv23.43.9, %conv29.43.9
  %scevgep35.43.9 = getelementptr i8, i8* %a, i64 53
  %11841 = load i8, i8* %scevgep35.43.9, align 1
  %11842 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.9 = call zeroext i8 @mult(i8 zeroext %11841, i8 zeroext %11842)
  %conv35.43.9 = zext i8 %call34.43.9 to i32
  %xor36.43.9 = xor i32 %xor.43.9, %conv35.43.9
  %conv37.43.9 = trunc i32 %xor36.43.9 to i8
  store i8 %conv37.43.9, i8* %scevgep41.43.8, align 1
  %scevgep28.43.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11836, i64 0, i64 0, i64 1
  %11843 = bitcast i8* %scevgep28.43.9 to [61 x [61 x i8]]*
  %scevgep41.43.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11837, i64 0, i64 1, i64 0
  %11844 = bitcast i8* %scevgep41.43.9 to [61 x [61 x i8]]*
  %call16.43.10 = call zeroext i8 (...) @rand()
  store i8 %call16.43.10, i8* %scevgep28.43.9, align 1
  %11845 = load i8, i8* %scevgep28.43.9, align 1
  %conv23.43.10 = zext i8 %11845 to i32
  %11846 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.10 = getelementptr i8, i8* %b, i64 54
  %11847 = load i8, i8* %scevgep34.43.10, align 1
  %call28.43.10 = call zeroext i8 @mult(i8 zeroext %11846, i8 zeroext %11847)
  %conv29.43.10 = zext i8 %call28.43.10 to i32
  %xor.43.10 = xor i32 %conv23.43.10, %conv29.43.10
  %scevgep35.43.10 = getelementptr i8, i8* %a, i64 54
  %11848 = load i8, i8* %scevgep35.43.10, align 1
  %11849 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.10 = call zeroext i8 @mult(i8 zeroext %11848, i8 zeroext %11849)
  %conv35.43.10 = zext i8 %call34.43.10 to i32
  %xor36.43.10 = xor i32 %xor.43.10, %conv35.43.10
  %conv37.43.10 = trunc i32 %xor36.43.10 to i8
  store i8 %conv37.43.10, i8* %scevgep41.43.9, align 1
  %scevgep28.43.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11843, i64 0, i64 0, i64 1
  %11850 = bitcast i8* %scevgep28.43.10 to [61 x [61 x i8]]*
  %scevgep41.43.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11844, i64 0, i64 1, i64 0
  %11851 = bitcast i8* %scevgep41.43.10 to [61 x [61 x i8]]*
  %call16.43.11 = call zeroext i8 (...) @rand()
  store i8 %call16.43.11, i8* %scevgep28.43.10, align 1
  %11852 = load i8, i8* %scevgep28.43.10, align 1
  %conv23.43.11 = zext i8 %11852 to i32
  %11853 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.11 = getelementptr i8, i8* %b, i64 55
  %11854 = load i8, i8* %scevgep34.43.11, align 1
  %call28.43.11 = call zeroext i8 @mult(i8 zeroext %11853, i8 zeroext %11854)
  %conv29.43.11 = zext i8 %call28.43.11 to i32
  %xor.43.11 = xor i32 %conv23.43.11, %conv29.43.11
  %scevgep35.43.11 = getelementptr i8, i8* %a, i64 55
  %11855 = load i8, i8* %scevgep35.43.11, align 1
  %11856 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.11 = call zeroext i8 @mult(i8 zeroext %11855, i8 zeroext %11856)
  %conv35.43.11 = zext i8 %call34.43.11 to i32
  %xor36.43.11 = xor i32 %xor.43.11, %conv35.43.11
  %conv37.43.11 = trunc i32 %xor36.43.11 to i8
  store i8 %conv37.43.11, i8* %scevgep41.43.10, align 1
  %scevgep28.43.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11850, i64 0, i64 0, i64 1
  %11857 = bitcast i8* %scevgep28.43.11 to [61 x [61 x i8]]*
  %scevgep41.43.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11851, i64 0, i64 1, i64 0
  %11858 = bitcast i8* %scevgep41.43.11 to [61 x [61 x i8]]*
  %call16.43.12 = call zeroext i8 (...) @rand()
  store i8 %call16.43.12, i8* %scevgep28.43.11, align 1
  %11859 = load i8, i8* %scevgep28.43.11, align 1
  %conv23.43.12 = zext i8 %11859 to i32
  %11860 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.12 = getelementptr i8, i8* %b, i64 56
  %11861 = load i8, i8* %scevgep34.43.12, align 1
  %call28.43.12 = call zeroext i8 @mult(i8 zeroext %11860, i8 zeroext %11861)
  %conv29.43.12 = zext i8 %call28.43.12 to i32
  %xor.43.12 = xor i32 %conv23.43.12, %conv29.43.12
  %scevgep35.43.12 = getelementptr i8, i8* %a, i64 56
  %11862 = load i8, i8* %scevgep35.43.12, align 1
  %11863 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.12 = call zeroext i8 @mult(i8 zeroext %11862, i8 zeroext %11863)
  %conv35.43.12 = zext i8 %call34.43.12 to i32
  %xor36.43.12 = xor i32 %xor.43.12, %conv35.43.12
  %conv37.43.12 = trunc i32 %xor36.43.12 to i8
  store i8 %conv37.43.12, i8* %scevgep41.43.11, align 1
  %scevgep28.43.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11857, i64 0, i64 0, i64 1
  %11864 = bitcast i8* %scevgep28.43.12 to [61 x [61 x i8]]*
  %scevgep41.43.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11858, i64 0, i64 1, i64 0
  %11865 = bitcast i8* %scevgep41.43.12 to [61 x [61 x i8]]*
  %call16.43.13 = call zeroext i8 (...) @rand()
  store i8 %call16.43.13, i8* %scevgep28.43.12, align 1
  %11866 = load i8, i8* %scevgep28.43.12, align 1
  %conv23.43.13 = zext i8 %11866 to i32
  %11867 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.13 = getelementptr i8, i8* %b, i64 57
  %11868 = load i8, i8* %scevgep34.43.13, align 1
  %call28.43.13 = call zeroext i8 @mult(i8 zeroext %11867, i8 zeroext %11868)
  %conv29.43.13 = zext i8 %call28.43.13 to i32
  %xor.43.13 = xor i32 %conv23.43.13, %conv29.43.13
  %scevgep35.43.13 = getelementptr i8, i8* %a, i64 57
  %11869 = load i8, i8* %scevgep35.43.13, align 1
  %11870 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.13 = call zeroext i8 @mult(i8 zeroext %11869, i8 zeroext %11870)
  %conv35.43.13 = zext i8 %call34.43.13 to i32
  %xor36.43.13 = xor i32 %xor.43.13, %conv35.43.13
  %conv37.43.13 = trunc i32 %xor36.43.13 to i8
  store i8 %conv37.43.13, i8* %scevgep41.43.12, align 1
  %scevgep28.43.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11864, i64 0, i64 0, i64 1
  %11871 = bitcast i8* %scevgep28.43.13 to [61 x [61 x i8]]*
  %scevgep41.43.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11865, i64 0, i64 1, i64 0
  %11872 = bitcast i8* %scevgep41.43.13 to [61 x [61 x i8]]*
  %call16.43.14 = call zeroext i8 (...) @rand()
  store i8 %call16.43.14, i8* %scevgep28.43.13, align 1
  %11873 = load i8, i8* %scevgep28.43.13, align 1
  %conv23.43.14 = zext i8 %11873 to i32
  %11874 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.14 = getelementptr i8, i8* %b, i64 58
  %11875 = load i8, i8* %scevgep34.43.14, align 1
  %call28.43.14 = call zeroext i8 @mult(i8 zeroext %11874, i8 zeroext %11875)
  %conv29.43.14 = zext i8 %call28.43.14 to i32
  %xor.43.14 = xor i32 %conv23.43.14, %conv29.43.14
  %scevgep35.43.14 = getelementptr i8, i8* %a, i64 58
  %11876 = load i8, i8* %scevgep35.43.14, align 1
  %11877 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.14 = call zeroext i8 @mult(i8 zeroext %11876, i8 zeroext %11877)
  %conv35.43.14 = zext i8 %call34.43.14 to i32
  %xor36.43.14 = xor i32 %xor.43.14, %conv35.43.14
  %conv37.43.14 = trunc i32 %xor36.43.14 to i8
  store i8 %conv37.43.14, i8* %scevgep41.43.13, align 1
  %scevgep28.43.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11871, i64 0, i64 0, i64 1
  %11878 = bitcast i8* %scevgep28.43.14 to [61 x [61 x i8]]*
  %scevgep41.43.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11872, i64 0, i64 1, i64 0
  %11879 = bitcast i8* %scevgep41.43.14 to [61 x [61 x i8]]*
  %call16.43.15 = call zeroext i8 (...) @rand()
  store i8 %call16.43.15, i8* %scevgep28.43.14, align 1
  %11880 = load i8, i8* %scevgep28.43.14, align 1
  %conv23.43.15 = zext i8 %11880 to i32
  %11881 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.15 = getelementptr i8, i8* %b, i64 59
  %11882 = load i8, i8* %scevgep34.43.15, align 1
  %call28.43.15 = call zeroext i8 @mult(i8 zeroext %11881, i8 zeroext %11882)
  %conv29.43.15 = zext i8 %call28.43.15 to i32
  %xor.43.15 = xor i32 %conv23.43.15, %conv29.43.15
  %scevgep35.43.15 = getelementptr i8, i8* %a, i64 59
  %11883 = load i8, i8* %scevgep35.43.15, align 1
  %11884 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.15 = call zeroext i8 @mult(i8 zeroext %11883, i8 zeroext %11884)
  %conv35.43.15 = zext i8 %call34.43.15 to i32
  %xor36.43.15 = xor i32 %xor.43.15, %conv35.43.15
  %conv37.43.15 = trunc i32 %xor36.43.15 to i8
  store i8 %conv37.43.15, i8* %scevgep41.43.14, align 1
  %scevgep28.43.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11878, i64 0, i64 0, i64 1
  %scevgep41.43.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11879, i64 0, i64 1, i64 0
  %call16.43.16 = call zeroext i8 (...) @rand()
  store i8 %call16.43.16, i8* %scevgep28.43.15, align 1
  %11885 = load i8, i8* %scevgep28.43.15, align 1
  %conv23.43.16 = zext i8 %11885 to i32
  %11886 = load i8, i8* %arrayidx25.43, align 1
  %scevgep34.43.16 = getelementptr i8, i8* %b, i64 60
  %11887 = load i8, i8* %scevgep34.43.16, align 1
  %call28.43.16 = call zeroext i8 @mult(i8 zeroext %11886, i8 zeroext %11887)
  %conv29.43.16 = zext i8 %call28.43.16 to i32
  %xor.43.16 = xor i32 %conv23.43.16, %conv29.43.16
  %scevgep35.43.16 = getelementptr i8, i8* %a, i64 60
  %11888 = load i8, i8* %scevgep35.43.16, align 1
  %11889 = load i8, i8* %arrayidx33.43, align 1
  %call34.43.16 = call zeroext i8 @mult(i8 zeroext %11888, i8 zeroext %11889)
  %conv35.43.16 = zext i8 %call34.43.16 to i32
  %xor36.43.16 = xor i32 %xor.43.16, %conv35.43.16
  %conv37.43.16 = trunc i32 %xor36.43.16 to i8
  store i8 %conv37.43.16, i8* %scevgep41.43.15, align 1
  %scevgep26.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11773, i64 0, i64 1, i64 1
  %11890 = bitcast i8* %scevgep26.43 to [61 x [61 x i8]]*
  %scevgep39.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11774, i64 0, i64 1, i64 1
  %11891 = bitcast i8* %scevgep39.43 to [61 x [61 x i8]]*
  %arrayidx25.44 = getelementptr inbounds i8, i8* %a, i64 44
  %arrayidx33.44 = getelementptr inbounds i8, i8* %b, i64 44
  %call16.44 = call zeroext i8 (...) @rand()
  store i8 %call16.44, i8* %scevgep26.43, align 1
  %11892 = load i8, i8* %scevgep26.43, align 1
  %conv23.44 = zext i8 %11892 to i32
  %11893 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44 = getelementptr i8, i8* %b, i64 45
  %11894 = load i8, i8* %scevgep34.44, align 1
  %call28.44 = call zeroext i8 @mult(i8 zeroext %11893, i8 zeroext %11894)
  %conv29.44 = zext i8 %call28.44 to i32
  %xor.44 = xor i32 %conv23.44, %conv29.44
  %scevgep35.44 = getelementptr i8, i8* %a, i64 45
  %11895 = load i8, i8* %scevgep35.44, align 1
  %11896 = load i8, i8* %arrayidx33.44, align 1
  %call34.44 = call zeroext i8 @mult(i8 zeroext %11895, i8 zeroext %11896)
  %conv35.44 = zext i8 %call34.44 to i32
  %xor36.44 = xor i32 %xor.44, %conv35.44
  %conv37.44 = trunc i32 %xor36.44 to i8
  store i8 %conv37.44, i8* %scevgep39.43, align 1
  %scevgep28.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11890, i64 0, i64 0, i64 1
  %11897 = bitcast i8* %scevgep28.44 to [61 x [61 x i8]]*
  %scevgep41.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11891, i64 0, i64 1, i64 0
  %11898 = bitcast i8* %scevgep41.44 to [61 x [61 x i8]]*
  %call16.44.1 = call zeroext i8 (...) @rand()
  store i8 %call16.44.1, i8* %scevgep28.44, align 1
  %11899 = load i8, i8* %scevgep28.44, align 1
  %conv23.44.1 = zext i8 %11899 to i32
  %11900 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.1 = getelementptr i8, i8* %b, i64 46
  %11901 = load i8, i8* %scevgep34.44.1, align 1
  %call28.44.1 = call zeroext i8 @mult(i8 zeroext %11900, i8 zeroext %11901)
  %conv29.44.1 = zext i8 %call28.44.1 to i32
  %xor.44.1 = xor i32 %conv23.44.1, %conv29.44.1
  %scevgep35.44.1 = getelementptr i8, i8* %a, i64 46
  %11902 = load i8, i8* %scevgep35.44.1, align 1
  %11903 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.1 = call zeroext i8 @mult(i8 zeroext %11902, i8 zeroext %11903)
  %conv35.44.1 = zext i8 %call34.44.1 to i32
  %xor36.44.1 = xor i32 %xor.44.1, %conv35.44.1
  %conv37.44.1 = trunc i32 %xor36.44.1 to i8
  store i8 %conv37.44.1, i8* %scevgep41.44, align 1
  %scevgep28.44.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11897, i64 0, i64 0, i64 1
  %11904 = bitcast i8* %scevgep28.44.1 to [61 x [61 x i8]]*
  %scevgep41.44.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11898, i64 0, i64 1, i64 0
  %11905 = bitcast i8* %scevgep41.44.1 to [61 x [61 x i8]]*
  %call16.44.2 = call zeroext i8 (...) @rand()
  store i8 %call16.44.2, i8* %scevgep28.44.1, align 1
  %11906 = load i8, i8* %scevgep28.44.1, align 1
  %conv23.44.2 = zext i8 %11906 to i32
  %11907 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.2 = getelementptr i8, i8* %b, i64 47
  %11908 = load i8, i8* %scevgep34.44.2, align 1
  %call28.44.2 = call zeroext i8 @mult(i8 zeroext %11907, i8 zeroext %11908)
  %conv29.44.2 = zext i8 %call28.44.2 to i32
  %xor.44.2 = xor i32 %conv23.44.2, %conv29.44.2
  %scevgep35.44.2 = getelementptr i8, i8* %a, i64 47
  %11909 = load i8, i8* %scevgep35.44.2, align 1
  %11910 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.2 = call zeroext i8 @mult(i8 zeroext %11909, i8 zeroext %11910)
  %conv35.44.2 = zext i8 %call34.44.2 to i32
  %xor36.44.2 = xor i32 %xor.44.2, %conv35.44.2
  %conv37.44.2 = trunc i32 %xor36.44.2 to i8
  store i8 %conv37.44.2, i8* %scevgep41.44.1, align 1
  %scevgep28.44.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11904, i64 0, i64 0, i64 1
  %11911 = bitcast i8* %scevgep28.44.2 to [61 x [61 x i8]]*
  %scevgep41.44.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11905, i64 0, i64 1, i64 0
  %11912 = bitcast i8* %scevgep41.44.2 to [61 x [61 x i8]]*
  %call16.44.3 = call zeroext i8 (...) @rand()
  store i8 %call16.44.3, i8* %scevgep28.44.2, align 1
  %11913 = load i8, i8* %scevgep28.44.2, align 1
  %conv23.44.3 = zext i8 %11913 to i32
  %11914 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.3 = getelementptr i8, i8* %b, i64 48
  %11915 = load i8, i8* %scevgep34.44.3, align 1
  %call28.44.3 = call zeroext i8 @mult(i8 zeroext %11914, i8 zeroext %11915)
  %conv29.44.3 = zext i8 %call28.44.3 to i32
  %xor.44.3 = xor i32 %conv23.44.3, %conv29.44.3
  %scevgep35.44.3 = getelementptr i8, i8* %a, i64 48
  %11916 = load i8, i8* %scevgep35.44.3, align 1
  %11917 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.3 = call zeroext i8 @mult(i8 zeroext %11916, i8 zeroext %11917)
  %conv35.44.3 = zext i8 %call34.44.3 to i32
  %xor36.44.3 = xor i32 %xor.44.3, %conv35.44.3
  %conv37.44.3 = trunc i32 %xor36.44.3 to i8
  store i8 %conv37.44.3, i8* %scevgep41.44.2, align 1
  %scevgep28.44.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11911, i64 0, i64 0, i64 1
  %11918 = bitcast i8* %scevgep28.44.3 to [61 x [61 x i8]]*
  %scevgep41.44.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11912, i64 0, i64 1, i64 0
  %11919 = bitcast i8* %scevgep41.44.3 to [61 x [61 x i8]]*
  %call16.44.4 = call zeroext i8 (...) @rand()
  store i8 %call16.44.4, i8* %scevgep28.44.3, align 1
  %11920 = load i8, i8* %scevgep28.44.3, align 1
  %conv23.44.4 = zext i8 %11920 to i32
  %11921 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.4 = getelementptr i8, i8* %b, i64 49
  %11922 = load i8, i8* %scevgep34.44.4, align 1
  %call28.44.4 = call zeroext i8 @mult(i8 zeroext %11921, i8 zeroext %11922)
  %conv29.44.4 = zext i8 %call28.44.4 to i32
  %xor.44.4 = xor i32 %conv23.44.4, %conv29.44.4
  %scevgep35.44.4 = getelementptr i8, i8* %a, i64 49
  %11923 = load i8, i8* %scevgep35.44.4, align 1
  %11924 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.4 = call zeroext i8 @mult(i8 zeroext %11923, i8 zeroext %11924)
  %conv35.44.4 = zext i8 %call34.44.4 to i32
  %xor36.44.4 = xor i32 %xor.44.4, %conv35.44.4
  %conv37.44.4 = trunc i32 %xor36.44.4 to i8
  store i8 %conv37.44.4, i8* %scevgep41.44.3, align 1
  %scevgep28.44.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11918, i64 0, i64 0, i64 1
  %11925 = bitcast i8* %scevgep28.44.4 to [61 x [61 x i8]]*
  %scevgep41.44.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11919, i64 0, i64 1, i64 0
  %11926 = bitcast i8* %scevgep41.44.4 to [61 x [61 x i8]]*
  %call16.44.5 = call zeroext i8 (...) @rand()
  store i8 %call16.44.5, i8* %scevgep28.44.4, align 1
  %11927 = load i8, i8* %scevgep28.44.4, align 1
  %conv23.44.5 = zext i8 %11927 to i32
  %11928 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.5 = getelementptr i8, i8* %b, i64 50
  %11929 = load i8, i8* %scevgep34.44.5, align 1
  %call28.44.5 = call zeroext i8 @mult(i8 zeroext %11928, i8 zeroext %11929)
  %conv29.44.5 = zext i8 %call28.44.5 to i32
  %xor.44.5 = xor i32 %conv23.44.5, %conv29.44.5
  %scevgep35.44.5 = getelementptr i8, i8* %a, i64 50
  %11930 = load i8, i8* %scevgep35.44.5, align 1
  %11931 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.5 = call zeroext i8 @mult(i8 zeroext %11930, i8 zeroext %11931)
  %conv35.44.5 = zext i8 %call34.44.5 to i32
  %xor36.44.5 = xor i32 %xor.44.5, %conv35.44.5
  %conv37.44.5 = trunc i32 %xor36.44.5 to i8
  store i8 %conv37.44.5, i8* %scevgep41.44.4, align 1
  %scevgep28.44.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11925, i64 0, i64 0, i64 1
  %11932 = bitcast i8* %scevgep28.44.5 to [61 x [61 x i8]]*
  %scevgep41.44.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11926, i64 0, i64 1, i64 0
  %11933 = bitcast i8* %scevgep41.44.5 to [61 x [61 x i8]]*
  %call16.44.6 = call zeroext i8 (...) @rand()
  store i8 %call16.44.6, i8* %scevgep28.44.5, align 1
  %11934 = load i8, i8* %scevgep28.44.5, align 1
  %conv23.44.6 = zext i8 %11934 to i32
  %11935 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.6 = getelementptr i8, i8* %b, i64 51
  %11936 = load i8, i8* %scevgep34.44.6, align 1
  %call28.44.6 = call zeroext i8 @mult(i8 zeroext %11935, i8 zeroext %11936)
  %conv29.44.6 = zext i8 %call28.44.6 to i32
  %xor.44.6 = xor i32 %conv23.44.6, %conv29.44.6
  %scevgep35.44.6 = getelementptr i8, i8* %a, i64 51
  %11937 = load i8, i8* %scevgep35.44.6, align 1
  %11938 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.6 = call zeroext i8 @mult(i8 zeroext %11937, i8 zeroext %11938)
  %conv35.44.6 = zext i8 %call34.44.6 to i32
  %xor36.44.6 = xor i32 %xor.44.6, %conv35.44.6
  %conv37.44.6 = trunc i32 %xor36.44.6 to i8
  store i8 %conv37.44.6, i8* %scevgep41.44.5, align 1
  %scevgep28.44.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11932, i64 0, i64 0, i64 1
  %11939 = bitcast i8* %scevgep28.44.6 to [61 x [61 x i8]]*
  %scevgep41.44.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11933, i64 0, i64 1, i64 0
  %11940 = bitcast i8* %scevgep41.44.6 to [61 x [61 x i8]]*
  %call16.44.7 = call zeroext i8 (...) @rand()
  store i8 %call16.44.7, i8* %scevgep28.44.6, align 1
  %11941 = load i8, i8* %scevgep28.44.6, align 1
  %conv23.44.7 = zext i8 %11941 to i32
  %11942 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.7 = getelementptr i8, i8* %b, i64 52
  %11943 = load i8, i8* %scevgep34.44.7, align 1
  %call28.44.7 = call zeroext i8 @mult(i8 zeroext %11942, i8 zeroext %11943)
  %conv29.44.7 = zext i8 %call28.44.7 to i32
  %xor.44.7 = xor i32 %conv23.44.7, %conv29.44.7
  %scevgep35.44.7 = getelementptr i8, i8* %a, i64 52
  %11944 = load i8, i8* %scevgep35.44.7, align 1
  %11945 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.7 = call zeroext i8 @mult(i8 zeroext %11944, i8 zeroext %11945)
  %conv35.44.7 = zext i8 %call34.44.7 to i32
  %xor36.44.7 = xor i32 %xor.44.7, %conv35.44.7
  %conv37.44.7 = trunc i32 %xor36.44.7 to i8
  store i8 %conv37.44.7, i8* %scevgep41.44.6, align 1
  %scevgep28.44.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11939, i64 0, i64 0, i64 1
  %11946 = bitcast i8* %scevgep28.44.7 to [61 x [61 x i8]]*
  %scevgep41.44.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11940, i64 0, i64 1, i64 0
  %11947 = bitcast i8* %scevgep41.44.7 to [61 x [61 x i8]]*
  %call16.44.8 = call zeroext i8 (...) @rand()
  store i8 %call16.44.8, i8* %scevgep28.44.7, align 1
  %11948 = load i8, i8* %scevgep28.44.7, align 1
  %conv23.44.8 = zext i8 %11948 to i32
  %11949 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.8 = getelementptr i8, i8* %b, i64 53
  %11950 = load i8, i8* %scevgep34.44.8, align 1
  %call28.44.8 = call zeroext i8 @mult(i8 zeroext %11949, i8 zeroext %11950)
  %conv29.44.8 = zext i8 %call28.44.8 to i32
  %xor.44.8 = xor i32 %conv23.44.8, %conv29.44.8
  %scevgep35.44.8 = getelementptr i8, i8* %a, i64 53
  %11951 = load i8, i8* %scevgep35.44.8, align 1
  %11952 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.8 = call zeroext i8 @mult(i8 zeroext %11951, i8 zeroext %11952)
  %conv35.44.8 = zext i8 %call34.44.8 to i32
  %xor36.44.8 = xor i32 %xor.44.8, %conv35.44.8
  %conv37.44.8 = trunc i32 %xor36.44.8 to i8
  store i8 %conv37.44.8, i8* %scevgep41.44.7, align 1
  %scevgep28.44.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11946, i64 0, i64 0, i64 1
  %11953 = bitcast i8* %scevgep28.44.8 to [61 x [61 x i8]]*
  %scevgep41.44.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11947, i64 0, i64 1, i64 0
  %11954 = bitcast i8* %scevgep41.44.8 to [61 x [61 x i8]]*
  %call16.44.9 = call zeroext i8 (...) @rand()
  store i8 %call16.44.9, i8* %scevgep28.44.8, align 1
  %11955 = load i8, i8* %scevgep28.44.8, align 1
  %conv23.44.9 = zext i8 %11955 to i32
  %11956 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.9 = getelementptr i8, i8* %b, i64 54
  %11957 = load i8, i8* %scevgep34.44.9, align 1
  %call28.44.9 = call zeroext i8 @mult(i8 zeroext %11956, i8 zeroext %11957)
  %conv29.44.9 = zext i8 %call28.44.9 to i32
  %xor.44.9 = xor i32 %conv23.44.9, %conv29.44.9
  %scevgep35.44.9 = getelementptr i8, i8* %a, i64 54
  %11958 = load i8, i8* %scevgep35.44.9, align 1
  %11959 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.9 = call zeroext i8 @mult(i8 zeroext %11958, i8 zeroext %11959)
  %conv35.44.9 = zext i8 %call34.44.9 to i32
  %xor36.44.9 = xor i32 %xor.44.9, %conv35.44.9
  %conv37.44.9 = trunc i32 %xor36.44.9 to i8
  store i8 %conv37.44.9, i8* %scevgep41.44.8, align 1
  %scevgep28.44.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11953, i64 0, i64 0, i64 1
  %11960 = bitcast i8* %scevgep28.44.9 to [61 x [61 x i8]]*
  %scevgep41.44.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11954, i64 0, i64 1, i64 0
  %11961 = bitcast i8* %scevgep41.44.9 to [61 x [61 x i8]]*
  %call16.44.10 = call zeroext i8 (...) @rand()
  store i8 %call16.44.10, i8* %scevgep28.44.9, align 1
  %11962 = load i8, i8* %scevgep28.44.9, align 1
  %conv23.44.10 = zext i8 %11962 to i32
  %11963 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.10 = getelementptr i8, i8* %b, i64 55
  %11964 = load i8, i8* %scevgep34.44.10, align 1
  %call28.44.10 = call zeroext i8 @mult(i8 zeroext %11963, i8 zeroext %11964)
  %conv29.44.10 = zext i8 %call28.44.10 to i32
  %xor.44.10 = xor i32 %conv23.44.10, %conv29.44.10
  %scevgep35.44.10 = getelementptr i8, i8* %a, i64 55
  %11965 = load i8, i8* %scevgep35.44.10, align 1
  %11966 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.10 = call zeroext i8 @mult(i8 zeroext %11965, i8 zeroext %11966)
  %conv35.44.10 = zext i8 %call34.44.10 to i32
  %xor36.44.10 = xor i32 %xor.44.10, %conv35.44.10
  %conv37.44.10 = trunc i32 %xor36.44.10 to i8
  store i8 %conv37.44.10, i8* %scevgep41.44.9, align 1
  %scevgep28.44.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11960, i64 0, i64 0, i64 1
  %11967 = bitcast i8* %scevgep28.44.10 to [61 x [61 x i8]]*
  %scevgep41.44.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11961, i64 0, i64 1, i64 0
  %11968 = bitcast i8* %scevgep41.44.10 to [61 x [61 x i8]]*
  %call16.44.11 = call zeroext i8 (...) @rand()
  store i8 %call16.44.11, i8* %scevgep28.44.10, align 1
  %11969 = load i8, i8* %scevgep28.44.10, align 1
  %conv23.44.11 = zext i8 %11969 to i32
  %11970 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.11 = getelementptr i8, i8* %b, i64 56
  %11971 = load i8, i8* %scevgep34.44.11, align 1
  %call28.44.11 = call zeroext i8 @mult(i8 zeroext %11970, i8 zeroext %11971)
  %conv29.44.11 = zext i8 %call28.44.11 to i32
  %xor.44.11 = xor i32 %conv23.44.11, %conv29.44.11
  %scevgep35.44.11 = getelementptr i8, i8* %a, i64 56
  %11972 = load i8, i8* %scevgep35.44.11, align 1
  %11973 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.11 = call zeroext i8 @mult(i8 zeroext %11972, i8 zeroext %11973)
  %conv35.44.11 = zext i8 %call34.44.11 to i32
  %xor36.44.11 = xor i32 %xor.44.11, %conv35.44.11
  %conv37.44.11 = trunc i32 %xor36.44.11 to i8
  store i8 %conv37.44.11, i8* %scevgep41.44.10, align 1
  %scevgep28.44.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11967, i64 0, i64 0, i64 1
  %11974 = bitcast i8* %scevgep28.44.11 to [61 x [61 x i8]]*
  %scevgep41.44.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11968, i64 0, i64 1, i64 0
  %11975 = bitcast i8* %scevgep41.44.11 to [61 x [61 x i8]]*
  %call16.44.12 = call zeroext i8 (...) @rand()
  store i8 %call16.44.12, i8* %scevgep28.44.11, align 1
  %11976 = load i8, i8* %scevgep28.44.11, align 1
  %conv23.44.12 = zext i8 %11976 to i32
  %11977 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.12 = getelementptr i8, i8* %b, i64 57
  %11978 = load i8, i8* %scevgep34.44.12, align 1
  %call28.44.12 = call zeroext i8 @mult(i8 zeroext %11977, i8 zeroext %11978)
  %conv29.44.12 = zext i8 %call28.44.12 to i32
  %xor.44.12 = xor i32 %conv23.44.12, %conv29.44.12
  %scevgep35.44.12 = getelementptr i8, i8* %a, i64 57
  %11979 = load i8, i8* %scevgep35.44.12, align 1
  %11980 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.12 = call zeroext i8 @mult(i8 zeroext %11979, i8 zeroext %11980)
  %conv35.44.12 = zext i8 %call34.44.12 to i32
  %xor36.44.12 = xor i32 %xor.44.12, %conv35.44.12
  %conv37.44.12 = trunc i32 %xor36.44.12 to i8
  store i8 %conv37.44.12, i8* %scevgep41.44.11, align 1
  %scevgep28.44.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11974, i64 0, i64 0, i64 1
  %11981 = bitcast i8* %scevgep28.44.12 to [61 x [61 x i8]]*
  %scevgep41.44.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11975, i64 0, i64 1, i64 0
  %11982 = bitcast i8* %scevgep41.44.12 to [61 x [61 x i8]]*
  %call16.44.13 = call zeroext i8 (...) @rand()
  store i8 %call16.44.13, i8* %scevgep28.44.12, align 1
  %11983 = load i8, i8* %scevgep28.44.12, align 1
  %conv23.44.13 = zext i8 %11983 to i32
  %11984 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.13 = getelementptr i8, i8* %b, i64 58
  %11985 = load i8, i8* %scevgep34.44.13, align 1
  %call28.44.13 = call zeroext i8 @mult(i8 zeroext %11984, i8 zeroext %11985)
  %conv29.44.13 = zext i8 %call28.44.13 to i32
  %xor.44.13 = xor i32 %conv23.44.13, %conv29.44.13
  %scevgep35.44.13 = getelementptr i8, i8* %a, i64 58
  %11986 = load i8, i8* %scevgep35.44.13, align 1
  %11987 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.13 = call zeroext i8 @mult(i8 zeroext %11986, i8 zeroext %11987)
  %conv35.44.13 = zext i8 %call34.44.13 to i32
  %xor36.44.13 = xor i32 %xor.44.13, %conv35.44.13
  %conv37.44.13 = trunc i32 %xor36.44.13 to i8
  store i8 %conv37.44.13, i8* %scevgep41.44.12, align 1
  %scevgep28.44.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11981, i64 0, i64 0, i64 1
  %11988 = bitcast i8* %scevgep28.44.13 to [61 x [61 x i8]]*
  %scevgep41.44.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11982, i64 0, i64 1, i64 0
  %11989 = bitcast i8* %scevgep41.44.13 to [61 x [61 x i8]]*
  %call16.44.14 = call zeroext i8 (...) @rand()
  store i8 %call16.44.14, i8* %scevgep28.44.13, align 1
  %11990 = load i8, i8* %scevgep28.44.13, align 1
  %conv23.44.14 = zext i8 %11990 to i32
  %11991 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.14 = getelementptr i8, i8* %b, i64 59
  %11992 = load i8, i8* %scevgep34.44.14, align 1
  %call28.44.14 = call zeroext i8 @mult(i8 zeroext %11991, i8 zeroext %11992)
  %conv29.44.14 = zext i8 %call28.44.14 to i32
  %xor.44.14 = xor i32 %conv23.44.14, %conv29.44.14
  %scevgep35.44.14 = getelementptr i8, i8* %a, i64 59
  %11993 = load i8, i8* %scevgep35.44.14, align 1
  %11994 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.14 = call zeroext i8 @mult(i8 zeroext %11993, i8 zeroext %11994)
  %conv35.44.14 = zext i8 %call34.44.14 to i32
  %xor36.44.14 = xor i32 %xor.44.14, %conv35.44.14
  %conv37.44.14 = trunc i32 %xor36.44.14 to i8
  store i8 %conv37.44.14, i8* %scevgep41.44.13, align 1
  %scevgep28.44.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11988, i64 0, i64 0, i64 1
  %scevgep41.44.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11989, i64 0, i64 1, i64 0
  %call16.44.15 = call zeroext i8 (...) @rand()
  store i8 %call16.44.15, i8* %scevgep28.44.14, align 1
  %11995 = load i8, i8* %scevgep28.44.14, align 1
  %conv23.44.15 = zext i8 %11995 to i32
  %11996 = load i8, i8* %arrayidx25.44, align 1
  %scevgep34.44.15 = getelementptr i8, i8* %b, i64 60
  %11997 = load i8, i8* %scevgep34.44.15, align 1
  %call28.44.15 = call zeroext i8 @mult(i8 zeroext %11996, i8 zeroext %11997)
  %conv29.44.15 = zext i8 %call28.44.15 to i32
  %xor.44.15 = xor i32 %conv23.44.15, %conv29.44.15
  %scevgep35.44.15 = getelementptr i8, i8* %a, i64 60
  %11998 = load i8, i8* %scevgep35.44.15, align 1
  %11999 = load i8, i8* %arrayidx33.44, align 1
  %call34.44.15 = call zeroext i8 @mult(i8 zeroext %11998, i8 zeroext %11999)
  %conv35.44.15 = zext i8 %call34.44.15 to i32
  %xor36.44.15 = xor i32 %xor.44.15, %conv35.44.15
  %conv37.44.15 = trunc i32 %xor36.44.15 to i8
  store i8 %conv37.44.15, i8* %scevgep41.44.14, align 1
  %scevgep26.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11890, i64 0, i64 1, i64 1
  %12000 = bitcast i8* %scevgep26.44 to [61 x [61 x i8]]*
  %scevgep39.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %11891, i64 0, i64 1, i64 1
  %12001 = bitcast i8* %scevgep39.44 to [61 x [61 x i8]]*
  %arrayidx25.45 = getelementptr inbounds i8, i8* %a, i64 45
  %arrayidx33.45 = getelementptr inbounds i8, i8* %b, i64 45
  %call16.45 = call zeroext i8 (...) @rand()
  store i8 %call16.45, i8* %scevgep26.44, align 1
  %12002 = load i8, i8* %scevgep26.44, align 1
  %conv23.45 = zext i8 %12002 to i32
  %12003 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45 = getelementptr i8, i8* %b, i64 46
  %12004 = load i8, i8* %scevgep34.45, align 1
  %call28.45 = call zeroext i8 @mult(i8 zeroext %12003, i8 zeroext %12004)
  %conv29.45 = zext i8 %call28.45 to i32
  %xor.45 = xor i32 %conv23.45, %conv29.45
  %scevgep35.45 = getelementptr i8, i8* %a, i64 46
  %12005 = load i8, i8* %scevgep35.45, align 1
  %12006 = load i8, i8* %arrayidx33.45, align 1
  %call34.45 = call zeroext i8 @mult(i8 zeroext %12005, i8 zeroext %12006)
  %conv35.45 = zext i8 %call34.45 to i32
  %xor36.45 = xor i32 %xor.45, %conv35.45
  %conv37.45 = trunc i32 %xor36.45 to i8
  store i8 %conv37.45, i8* %scevgep39.44, align 1
  %scevgep28.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12000, i64 0, i64 0, i64 1
  %12007 = bitcast i8* %scevgep28.45 to [61 x [61 x i8]]*
  %scevgep41.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12001, i64 0, i64 1, i64 0
  %12008 = bitcast i8* %scevgep41.45 to [61 x [61 x i8]]*
  %call16.45.1 = call zeroext i8 (...) @rand()
  store i8 %call16.45.1, i8* %scevgep28.45, align 1
  %12009 = load i8, i8* %scevgep28.45, align 1
  %conv23.45.1 = zext i8 %12009 to i32
  %12010 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.1 = getelementptr i8, i8* %b, i64 47
  %12011 = load i8, i8* %scevgep34.45.1, align 1
  %call28.45.1 = call zeroext i8 @mult(i8 zeroext %12010, i8 zeroext %12011)
  %conv29.45.1 = zext i8 %call28.45.1 to i32
  %xor.45.1 = xor i32 %conv23.45.1, %conv29.45.1
  %scevgep35.45.1 = getelementptr i8, i8* %a, i64 47
  %12012 = load i8, i8* %scevgep35.45.1, align 1
  %12013 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.1 = call zeroext i8 @mult(i8 zeroext %12012, i8 zeroext %12013)
  %conv35.45.1 = zext i8 %call34.45.1 to i32
  %xor36.45.1 = xor i32 %xor.45.1, %conv35.45.1
  %conv37.45.1 = trunc i32 %xor36.45.1 to i8
  store i8 %conv37.45.1, i8* %scevgep41.45, align 1
  %scevgep28.45.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12007, i64 0, i64 0, i64 1
  %12014 = bitcast i8* %scevgep28.45.1 to [61 x [61 x i8]]*
  %scevgep41.45.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12008, i64 0, i64 1, i64 0
  %12015 = bitcast i8* %scevgep41.45.1 to [61 x [61 x i8]]*
  %call16.45.2 = call zeroext i8 (...) @rand()
  store i8 %call16.45.2, i8* %scevgep28.45.1, align 1
  %12016 = load i8, i8* %scevgep28.45.1, align 1
  %conv23.45.2 = zext i8 %12016 to i32
  %12017 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.2 = getelementptr i8, i8* %b, i64 48
  %12018 = load i8, i8* %scevgep34.45.2, align 1
  %call28.45.2 = call zeroext i8 @mult(i8 zeroext %12017, i8 zeroext %12018)
  %conv29.45.2 = zext i8 %call28.45.2 to i32
  %xor.45.2 = xor i32 %conv23.45.2, %conv29.45.2
  %scevgep35.45.2 = getelementptr i8, i8* %a, i64 48
  %12019 = load i8, i8* %scevgep35.45.2, align 1
  %12020 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.2 = call zeroext i8 @mult(i8 zeroext %12019, i8 zeroext %12020)
  %conv35.45.2 = zext i8 %call34.45.2 to i32
  %xor36.45.2 = xor i32 %xor.45.2, %conv35.45.2
  %conv37.45.2 = trunc i32 %xor36.45.2 to i8
  store i8 %conv37.45.2, i8* %scevgep41.45.1, align 1
  %scevgep28.45.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12014, i64 0, i64 0, i64 1
  %12021 = bitcast i8* %scevgep28.45.2 to [61 x [61 x i8]]*
  %scevgep41.45.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12015, i64 0, i64 1, i64 0
  %12022 = bitcast i8* %scevgep41.45.2 to [61 x [61 x i8]]*
  %call16.45.3 = call zeroext i8 (...) @rand()
  store i8 %call16.45.3, i8* %scevgep28.45.2, align 1
  %12023 = load i8, i8* %scevgep28.45.2, align 1
  %conv23.45.3 = zext i8 %12023 to i32
  %12024 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.3 = getelementptr i8, i8* %b, i64 49
  %12025 = load i8, i8* %scevgep34.45.3, align 1
  %call28.45.3 = call zeroext i8 @mult(i8 zeroext %12024, i8 zeroext %12025)
  %conv29.45.3 = zext i8 %call28.45.3 to i32
  %xor.45.3 = xor i32 %conv23.45.3, %conv29.45.3
  %scevgep35.45.3 = getelementptr i8, i8* %a, i64 49
  %12026 = load i8, i8* %scevgep35.45.3, align 1
  %12027 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.3 = call zeroext i8 @mult(i8 zeroext %12026, i8 zeroext %12027)
  %conv35.45.3 = zext i8 %call34.45.3 to i32
  %xor36.45.3 = xor i32 %xor.45.3, %conv35.45.3
  %conv37.45.3 = trunc i32 %xor36.45.3 to i8
  store i8 %conv37.45.3, i8* %scevgep41.45.2, align 1
  %scevgep28.45.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12021, i64 0, i64 0, i64 1
  %12028 = bitcast i8* %scevgep28.45.3 to [61 x [61 x i8]]*
  %scevgep41.45.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12022, i64 0, i64 1, i64 0
  %12029 = bitcast i8* %scevgep41.45.3 to [61 x [61 x i8]]*
  %call16.45.4 = call zeroext i8 (...) @rand()
  store i8 %call16.45.4, i8* %scevgep28.45.3, align 1
  %12030 = load i8, i8* %scevgep28.45.3, align 1
  %conv23.45.4 = zext i8 %12030 to i32
  %12031 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.4 = getelementptr i8, i8* %b, i64 50
  %12032 = load i8, i8* %scevgep34.45.4, align 1
  %call28.45.4 = call zeroext i8 @mult(i8 zeroext %12031, i8 zeroext %12032)
  %conv29.45.4 = zext i8 %call28.45.4 to i32
  %xor.45.4 = xor i32 %conv23.45.4, %conv29.45.4
  %scevgep35.45.4 = getelementptr i8, i8* %a, i64 50
  %12033 = load i8, i8* %scevgep35.45.4, align 1
  %12034 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.4 = call zeroext i8 @mult(i8 zeroext %12033, i8 zeroext %12034)
  %conv35.45.4 = zext i8 %call34.45.4 to i32
  %xor36.45.4 = xor i32 %xor.45.4, %conv35.45.4
  %conv37.45.4 = trunc i32 %xor36.45.4 to i8
  store i8 %conv37.45.4, i8* %scevgep41.45.3, align 1
  %scevgep28.45.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12028, i64 0, i64 0, i64 1
  %12035 = bitcast i8* %scevgep28.45.4 to [61 x [61 x i8]]*
  %scevgep41.45.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12029, i64 0, i64 1, i64 0
  %12036 = bitcast i8* %scevgep41.45.4 to [61 x [61 x i8]]*
  %call16.45.5 = call zeroext i8 (...) @rand()
  store i8 %call16.45.5, i8* %scevgep28.45.4, align 1
  %12037 = load i8, i8* %scevgep28.45.4, align 1
  %conv23.45.5 = zext i8 %12037 to i32
  %12038 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.5 = getelementptr i8, i8* %b, i64 51
  %12039 = load i8, i8* %scevgep34.45.5, align 1
  %call28.45.5 = call zeroext i8 @mult(i8 zeroext %12038, i8 zeroext %12039)
  %conv29.45.5 = zext i8 %call28.45.5 to i32
  %xor.45.5 = xor i32 %conv23.45.5, %conv29.45.5
  %scevgep35.45.5 = getelementptr i8, i8* %a, i64 51
  %12040 = load i8, i8* %scevgep35.45.5, align 1
  %12041 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.5 = call zeroext i8 @mult(i8 zeroext %12040, i8 zeroext %12041)
  %conv35.45.5 = zext i8 %call34.45.5 to i32
  %xor36.45.5 = xor i32 %xor.45.5, %conv35.45.5
  %conv37.45.5 = trunc i32 %xor36.45.5 to i8
  store i8 %conv37.45.5, i8* %scevgep41.45.4, align 1
  %scevgep28.45.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12035, i64 0, i64 0, i64 1
  %12042 = bitcast i8* %scevgep28.45.5 to [61 x [61 x i8]]*
  %scevgep41.45.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12036, i64 0, i64 1, i64 0
  %12043 = bitcast i8* %scevgep41.45.5 to [61 x [61 x i8]]*
  %call16.45.6 = call zeroext i8 (...) @rand()
  store i8 %call16.45.6, i8* %scevgep28.45.5, align 1
  %12044 = load i8, i8* %scevgep28.45.5, align 1
  %conv23.45.6 = zext i8 %12044 to i32
  %12045 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.6 = getelementptr i8, i8* %b, i64 52
  %12046 = load i8, i8* %scevgep34.45.6, align 1
  %call28.45.6 = call zeroext i8 @mult(i8 zeroext %12045, i8 zeroext %12046)
  %conv29.45.6 = zext i8 %call28.45.6 to i32
  %xor.45.6 = xor i32 %conv23.45.6, %conv29.45.6
  %scevgep35.45.6 = getelementptr i8, i8* %a, i64 52
  %12047 = load i8, i8* %scevgep35.45.6, align 1
  %12048 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.6 = call zeroext i8 @mult(i8 zeroext %12047, i8 zeroext %12048)
  %conv35.45.6 = zext i8 %call34.45.6 to i32
  %xor36.45.6 = xor i32 %xor.45.6, %conv35.45.6
  %conv37.45.6 = trunc i32 %xor36.45.6 to i8
  store i8 %conv37.45.6, i8* %scevgep41.45.5, align 1
  %scevgep28.45.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12042, i64 0, i64 0, i64 1
  %12049 = bitcast i8* %scevgep28.45.6 to [61 x [61 x i8]]*
  %scevgep41.45.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12043, i64 0, i64 1, i64 0
  %12050 = bitcast i8* %scevgep41.45.6 to [61 x [61 x i8]]*
  %call16.45.7 = call zeroext i8 (...) @rand()
  store i8 %call16.45.7, i8* %scevgep28.45.6, align 1
  %12051 = load i8, i8* %scevgep28.45.6, align 1
  %conv23.45.7 = zext i8 %12051 to i32
  %12052 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.7 = getelementptr i8, i8* %b, i64 53
  %12053 = load i8, i8* %scevgep34.45.7, align 1
  %call28.45.7 = call zeroext i8 @mult(i8 zeroext %12052, i8 zeroext %12053)
  %conv29.45.7 = zext i8 %call28.45.7 to i32
  %xor.45.7 = xor i32 %conv23.45.7, %conv29.45.7
  %scevgep35.45.7 = getelementptr i8, i8* %a, i64 53
  %12054 = load i8, i8* %scevgep35.45.7, align 1
  %12055 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.7 = call zeroext i8 @mult(i8 zeroext %12054, i8 zeroext %12055)
  %conv35.45.7 = zext i8 %call34.45.7 to i32
  %xor36.45.7 = xor i32 %xor.45.7, %conv35.45.7
  %conv37.45.7 = trunc i32 %xor36.45.7 to i8
  store i8 %conv37.45.7, i8* %scevgep41.45.6, align 1
  %scevgep28.45.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12049, i64 0, i64 0, i64 1
  %12056 = bitcast i8* %scevgep28.45.7 to [61 x [61 x i8]]*
  %scevgep41.45.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12050, i64 0, i64 1, i64 0
  %12057 = bitcast i8* %scevgep41.45.7 to [61 x [61 x i8]]*
  %call16.45.8 = call zeroext i8 (...) @rand()
  store i8 %call16.45.8, i8* %scevgep28.45.7, align 1
  %12058 = load i8, i8* %scevgep28.45.7, align 1
  %conv23.45.8 = zext i8 %12058 to i32
  %12059 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.8 = getelementptr i8, i8* %b, i64 54
  %12060 = load i8, i8* %scevgep34.45.8, align 1
  %call28.45.8 = call zeroext i8 @mult(i8 zeroext %12059, i8 zeroext %12060)
  %conv29.45.8 = zext i8 %call28.45.8 to i32
  %xor.45.8 = xor i32 %conv23.45.8, %conv29.45.8
  %scevgep35.45.8 = getelementptr i8, i8* %a, i64 54
  %12061 = load i8, i8* %scevgep35.45.8, align 1
  %12062 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.8 = call zeroext i8 @mult(i8 zeroext %12061, i8 zeroext %12062)
  %conv35.45.8 = zext i8 %call34.45.8 to i32
  %xor36.45.8 = xor i32 %xor.45.8, %conv35.45.8
  %conv37.45.8 = trunc i32 %xor36.45.8 to i8
  store i8 %conv37.45.8, i8* %scevgep41.45.7, align 1
  %scevgep28.45.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12056, i64 0, i64 0, i64 1
  %12063 = bitcast i8* %scevgep28.45.8 to [61 x [61 x i8]]*
  %scevgep41.45.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12057, i64 0, i64 1, i64 0
  %12064 = bitcast i8* %scevgep41.45.8 to [61 x [61 x i8]]*
  %call16.45.9 = call zeroext i8 (...) @rand()
  store i8 %call16.45.9, i8* %scevgep28.45.8, align 1
  %12065 = load i8, i8* %scevgep28.45.8, align 1
  %conv23.45.9 = zext i8 %12065 to i32
  %12066 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.9 = getelementptr i8, i8* %b, i64 55
  %12067 = load i8, i8* %scevgep34.45.9, align 1
  %call28.45.9 = call zeroext i8 @mult(i8 zeroext %12066, i8 zeroext %12067)
  %conv29.45.9 = zext i8 %call28.45.9 to i32
  %xor.45.9 = xor i32 %conv23.45.9, %conv29.45.9
  %scevgep35.45.9 = getelementptr i8, i8* %a, i64 55
  %12068 = load i8, i8* %scevgep35.45.9, align 1
  %12069 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.9 = call zeroext i8 @mult(i8 zeroext %12068, i8 zeroext %12069)
  %conv35.45.9 = zext i8 %call34.45.9 to i32
  %xor36.45.9 = xor i32 %xor.45.9, %conv35.45.9
  %conv37.45.9 = trunc i32 %xor36.45.9 to i8
  store i8 %conv37.45.9, i8* %scevgep41.45.8, align 1
  %scevgep28.45.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12063, i64 0, i64 0, i64 1
  %12070 = bitcast i8* %scevgep28.45.9 to [61 x [61 x i8]]*
  %scevgep41.45.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12064, i64 0, i64 1, i64 0
  %12071 = bitcast i8* %scevgep41.45.9 to [61 x [61 x i8]]*
  %call16.45.10 = call zeroext i8 (...) @rand()
  store i8 %call16.45.10, i8* %scevgep28.45.9, align 1
  %12072 = load i8, i8* %scevgep28.45.9, align 1
  %conv23.45.10 = zext i8 %12072 to i32
  %12073 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.10 = getelementptr i8, i8* %b, i64 56
  %12074 = load i8, i8* %scevgep34.45.10, align 1
  %call28.45.10 = call zeroext i8 @mult(i8 zeroext %12073, i8 zeroext %12074)
  %conv29.45.10 = zext i8 %call28.45.10 to i32
  %xor.45.10 = xor i32 %conv23.45.10, %conv29.45.10
  %scevgep35.45.10 = getelementptr i8, i8* %a, i64 56
  %12075 = load i8, i8* %scevgep35.45.10, align 1
  %12076 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.10 = call zeroext i8 @mult(i8 zeroext %12075, i8 zeroext %12076)
  %conv35.45.10 = zext i8 %call34.45.10 to i32
  %xor36.45.10 = xor i32 %xor.45.10, %conv35.45.10
  %conv37.45.10 = trunc i32 %xor36.45.10 to i8
  store i8 %conv37.45.10, i8* %scevgep41.45.9, align 1
  %scevgep28.45.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12070, i64 0, i64 0, i64 1
  %12077 = bitcast i8* %scevgep28.45.10 to [61 x [61 x i8]]*
  %scevgep41.45.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12071, i64 0, i64 1, i64 0
  %12078 = bitcast i8* %scevgep41.45.10 to [61 x [61 x i8]]*
  %call16.45.11 = call zeroext i8 (...) @rand()
  store i8 %call16.45.11, i8* %scevgep28.45.10, align 1
  %12079 = load i8, i8* %scevgep28.45.10, align 1
  %conv23.45.11 = zext i8 %12079 to i32
  %12080 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.11 = getelementptr i8, i8* %b, i64 57
  %12081 = load i8, i8* %scevgep34.45.11, align 1
  %call28.45.11 = call zeroext i8 @mult(i8 zeroext %12080, i8 zeroext %12081)
  %conv29.45.11 = zext i8 %call28.45.11 to i32
  %xor.45.11 = xor i32 %conv23.45.11, %conv29.45.11
  %scevgep35.45.11 = getelementptr i8, i8* %a, i64 57
  %12082 = load i8, i8* %scevgep35.45.11, align 1
  %12083 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.11 = call zeroext i8 @mult(i8 zeroext %12082, i8 zeroext %12083)
  %conv35.45.11 = zext i8 %call34.45.11 to i32
  %xor36.45.11 = xor i32 %xor.45.11, %conv35.45.11
  %conv37.45.11 = trunc i32 %xor36.45.11 to i8
  store i8 %conv37.45.11, i8* %scevgep41.45.10, align 1
  %scevgep28.45.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12077, i64 0, i64 0, i64 1
  %12084 = bitcast i8* %scevgep28.45.11 to [61 x [61 x i8]]*
  %scevgep41.45.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12078, i64 0, i64 1, i64 0
  %12085 = bitcast i8* %scevgep41.45.11 to [61 x [61 x i8]]*
  %call16.45.12 = call zeroext i8 (...) @rand()
  store i8 %call16.45.12, i8* %scevgep28.45.11, align 1
  %12086 = load i8, i8* %scevgep28.45.11, align 1
  %conv23.45.12 = zext i8 %12086 to i32
  %12087 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.12 = getelementptr i8, i8* %b, i64 58
  %12088 = load i8, i8* %scevgep34.45.12, align 1
  %call28.45.12 = call zeroext i8 @mult(i8 zeroext %12087, i8 zeroext %12088)
  %conv29.45.12 = zext i8 %call28.45.12 to i32
  %xor.45.12 = xor i32 %conv23.45.12, %conv29.45.12
  %scevgep35.45.12 = getelementptr i8, i8* %a, i64 58
  %12089 = load i8, i8* %scevgep35.45.12, align 1
  %12090 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.12 = call zeroext i8 @mult(i8 zeroext %12089, i8 zeroext %12090)
  %conv35.45.12 = zext i8 %call34.45.12 to i32
  %xor36.45.12 = xor i32 %xor.45.12, %conv35.45.12
  %conv37.45.12 = trunc i32 %xor36.45.12 to i8
  store i8 %conv37.45.12, i8* %scevgep41.45.11, align 1
  %scevgep28.45.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12084, i64 0, i64 0, i64 1
  %12091 = bitcast i8* %scevgep28.45.12 to [61 x [61 x i8]]*
  %scevgep41.45.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12085, i64 0, i64 1, i64 0
  %12092 = bitcast i8* %scevgep41.45.12 to [61 x [61 x i8]]*
  %call16.45.13 = call zeroext i8 (...) @rand()
  store i8 %call16.45.13, i8* %scevgep28.45.12, align 1
  %12093 = load i8, i8* %scevgep28.45.12, align 1
  %conv23.45.13 = zext i8 %12093 to i32
  %12094 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.13 = getelementptr i8, i8* %b, i64 59
  %12095 = load i8, i8* %scevgep34.45.13, align 1
  %call28.45.13 = call zeroext i8 @mult(i8 zeroext %12094, i8 zeroext %12095)
  %conv29.45.13 = zext i8 %call28.45.13 to i32
  %xor.45.13 = xor i32 %conv23.45.13, %conv29.45.13
  %scevgep35.45.13 = getelementptr i8, i8* %a, i64 59
  %12096 = load i8, i8* %scevgep35.45.13, align 1
  %12097 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.13 = call zeroext i8 @mult(i8 zeroext %12096, i8 zeroext %12097)
  %conv35.45.13 = zext i8 %call34.45.13 to i32
  %xor36.45.13 = xor i32 %xor.45.13, %conv35.45.13
  %conv37.45.13 = trunc i32 %xor36.45.13 to i8
  store i8 %conv37.45.13, i8* %scevgep41.45.12, align 1
  %scevgep28.45.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12091, i64 0, i64 0, i64 1
  %scevgep41.45.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12092, i64 0, i64 1, i64 0
  %call16.45.14 = call zeroext i8 (...) @rand()
  store i8 %call16.45.14, i8* %scevgep28.45.13, align 1
  %12098 = load i8, i8* %scevgep28.45.13, align 1
  %conv23.45.14 = zext i8 %12098 to i32
  %12099 = load i8, i8* %arrayidx25.45, align 1
  %scevgep34.45.14 = getelementptr i8, i8* %b, i64 60
  %12100 = load i8, i8* %scevgep34.45.14, align 1
  %call28.45.14 = call zeroext i8 @mult(i8 zeroext %12099, i8 zeroext %12100)
  %conv29.45.14 = zext i8 %call28.45.14 to i32
  %xor.45.14 = xor i32 %conv23.45.14, %conv29.45.14
  %scevgep35.45.14 = getelementptr i8, i8* %a, i64 60
  %12101 = load i8, i8* %scevgep35.45.14, align 1
  %12102 = load i8, i8* %arrayidx33.45, align 1
  %call34.45.14 = call zeroext i8 @mult(i8 zeroext %12101, i8 zeroext %12102)
  %conv35.45.14 = zext i8 %call34.45.14 to i32
  %xor36.45.14 = xor i32 %xor.45.14, %conv35.45.14
  %conv37.45.14 = trunc i32 %xor36.45.14 to i8
  store i8 %conv37.45.14, i8* %scevgep41.45.13, align 1
  %scevgep26.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12000, i64 0, i64 1, i64 1
  %12103 = bitcast i8* %scevgep26.45 to [61 x [61 x i8]]*
  %scevgep39.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12001, i64 0, i64 1, i64 1
  %12104 = bitcast i8* %scevgep39.45 to [61 x [61 x i8]]*
  %arrayidx25.46 = getelementptr inbounds i8, i8* %a, i64 46
  %arrayidx33.46 = getelementptr inbounds i8, i8* %b, i64 46
  %call16.46 = call zeroext i8 (...) @rand()
  store i8 %call16.46, i8* %scevgep26.45, align 1
  %12105 = load i8, i8* %scevgep26.45, align 1
  %conv23.46 = zext i8 %12105 to i32
  %12106 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46 = getelementptr i8, i8* %b, i64 47
  %12107 = load i8, i8* %scevgep34.46, align 1
  %call28.46 = call zeroext i8 @mult(i8 zeroext %12106, i8 zeroext %12107)
  %conv29.46 = zext i8 %call28.46 to i32
  %xor.46 = xor i32 %conv23.46, %conv29.46
  %scevgep35.46 = getelementptr i8, i8* %a, i64 47
  %12108 = load i8, i8* %scevgep35.46, align 1
  %12109 = load i8, i8* %arrayidx33.46, align 1
  %call34.46 = call zeroext i8 @mult(i8 zeroext %12108, i8 zeroext %12109)
  %conv35.46 = zext i8 %call34.46 to i32
  %xor36.46 = xor i32 %xor.46, %conv35.46
  %conv37.46 = trunc i32 %xor36.46 to i8
  store i8 %conv37.46, i8* %scevgep39.45, align 1
  %scevgep28.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12103, i64 0, i64 0, i64 1
  %12110 = bitcast i8* %scevgep28.46 to [61 x [61 x i8]]*
  %scevgep41.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12104, i64 0, i64 1, i64 0
  %12111 = bitcast i8* %scevgep41.46 to [61 x [61 x i8]]*
  %call16.46.1 = call zeroext i8 (...) @rand()
  store i8 %call16.46.1, i8* %scevgep28.46, align 1
  %12112 = load i8, i8* %scevgep28.46, align 1
  %conv23.46.1 = zext i8 %12112 to i32
  %12113 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.1 = getelementptr i8, i8* %b, i64 48
  %12114 = load i8, i8* %scevgep34.46.1, align 1
  %call28.46.1 = call zeroext i8 @mult(i8 zeroext %12113, i8 zeroext %12114)
  %conv29.46.1 = zext i8 %call28.46.1 to i32
  %xor.46.1 = xor i32 %conv23.46.1, %conv29.46.1
  %scevgep35.46.1 = getelementptr i8, i8* %a, i64 48
  %12115 = load i8, i8* %scevgep35.46.1, align 1
  %12116 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.1 = call zeroext i8 @mult(i8 zeroext %12115, i8 zeroext %12116)
  %conv35.46.1 = zext i8 %call34.46.1 to i32
  %xor36.46.1 = xor i32 %xor.46.1, %conv35.46.1
  %conv37.46.1 = trunc i32 %xor36.46.1 to i8
  store i8 %conv37.46.1, i8* %scevgep41.46, align 1
  %scevgep28.46.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12110, i64 0, i64 0, i64 1
  %12117 = bitcast i8* %scevgep28.46.1 to [61 x [61 x i8]]*
  %scevgep41.46.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12111, i64 0, i64 1, i64 0
  %12118 = bitcast i8* %scevgep41.46.1 to [61 x [61 x i8]]*
  %call16.46.2 = call zeroext i8 (...) @rand()
  store i8 %call16.46.2, i8* %scevgep28.46.1, align 1
  %12119 = load i8, i8* %scevgep28.46.1, align 1
  %conv23.46.2 = zext i8 %12119 to i32
  %12120 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.2 = getelementptr i8, i8* %b, i64 49
  %12121 = load i8, i8* %scevgep34.46.2, align 1
  %call28.46.2 = call zeroext i8 @mult(i8 zeroext %12120, i8 zeroext %12121)
  %conv29.46.2 = zext i8 %call28.46.2 to i32
  %xor.46.2 = xor i32 %conv23.46.2, %conv29.46.2
  %scevgep35.46.2 = getelementptr i8, i8* %a, i64 49
  %12122 = load i8, i8* %scevgep35.46.2, align 1
  %12123 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.2 = call zeroext i8 @mult(i8 zeroext %12122, i8 zeroext %12123)
  %conv35.46.2 = zext i8 %call34.46.2 to i32
  %xor36.46.2 = xor i32 %xor.46.2, %conv35.46.2
  %conv37.46.2 = trunc i32 %xor36.46.2 to i8
  store i8 %conv37.46.2, i8* %scevgep41.46.1, align 1
  %scevgep28.46.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12117, i64 0, i64 0, i64 1
  %12124 = bitcast i8* %scevgep28.46.2 to [61 x [61 x i8]]*
  %scevgep41.46.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12118, i64 0, i64 1, i64 0
  %12125 = bitcast i8* %scevgep41.46.2 to [61 x [61 x i8]]*
  %call16.46.3 = call zeroext i8 (...) @rand()
  store i8 %call16.46.3, i8* %scevgep28.46.2, align 1
  %12126 = load i8, i8* %scevgep28.46.2, align 1
  %conv23.46.3 = zext i8 %12126 to i32
  %12127 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.3 = getelementptr i8, i8* %b, i64 50
  %12128 = load i8, i8* %scevgep34.46.3, align 1
  %call28.46.3 = call zeroext i8 @mult(i8 zeroext %12127, i8 zeroext %12128)
  %conv29.46.3 = zext i8 %call28.46.3 to i32
  %xor.46.3 = xor i32 %conv23.46.3, %conv29.46.3
  %scevgep35.46.3 = getelementptr i8, i8* %a, i64 50
  %12129 = load i8, i8* %scevgep35.46.3, align 1
  %12130 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.3 = call zeroext i8 @mult(i8 zeroext %12129, i8 zeroext %12130)
  %conv35.46.3 = zext i8 %call34.46.3 to i32
  %xor36.46.3 = xor i32 %xor.46.3, %conv35.46.3
  %conv37.46.3 = trunc i32 %xor36.46.3 to i8
  store i8 %conv37.46.3, i8* %scevgep41.46.2, align 1
  %scevgep28.46.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12124, i64 0, i64 0, i64 1
  %12131 = bitcast i8* %scevgep28.46.3 to [61 x [61 x i8]]*
  %scevgep41.46.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12125, i64 0, i64 1, i64 0
  %12132 = bitcast i8* %scevgep41.46.3 to [61 x [61 x i8]]*
  %call16.46.4 = call zeroext i8 (...) @rand()
  store i8 %call16.46.4, i8* %scevgep28.46.3, align 1
  %12133 = load i8, i8* %scevgep28.46.3, align 1
  %conv23.46.4 = zext i8 %12133 to i32
  %12134 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.4 = getelementptr i8, i8* %b, i64 51
  %12135 = load i8, i8* %scevgep34.46.4, align 1
  %call28.46.4 = call zeroext i8 @mult(i8 zeroext %12134, i8 zeroext %12135)
  %conv29.46.4 = zext i8 %call28.46.4 to i32
  %xor.46.4 = xor i32 %conv23.46.4, %conv29.46.4
  %scevgep35.46.4 = getelementptr i8, i8* %a, i64 51
  %12136 = load i8, i8* %scevgep35.46.4, align 1
  %12137 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.4 = call zeroext i8 @mult(i8 zeroext %12136, i8 zeroext %12137)
  %conv35.46.4 = zext i8 %call34.46.4 to i32
  %xor36.46.4 = xor i32 %xor.46.4, %conv35.46.4
  %conv37.46.4 = trunc i32 %xor36.46.4 to i8
  store i8 %conv37.46.4, i8* %scevgep41.46.3, align 1
  %scevgep28.46.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12131, i64 0, i64 0, i64 1
  %12138 = bitcast i8* %scevgep28.46.4 to [61 x [61 x i8]]*
  %scevgep41.46.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12132, i64 0, i64 1, i64 0
  %12139 = bitcast i8* %scevgep41.46.4 to [61 x [61 x i8]]*
  %call16.46.5 = call zeroext i8 (...) @rand()
  store i8 %call16.46.5, i8* %scevgep28.46.4, align 1
  %12140 = load i8, i8* %scevgep28.46.4, align 1
  %conv23.46.5 = zext i8 %12140 to i32
  %12141 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.5 = getelementptr i8, i8* %b, i64 52
  %12142 = load i8, i8* %scevgep34.46.5, align 1
  %call28.46.5 = call zeroext i8 @mult(i8 zeroext %12141, i8 zeroext %12142)
  %conv29.46.5 = zext i8 %call28.46.5 to i32
  %xor.46.5 = xor i32 %conv23.46.5, %conv29.46.5
  %scevgep35.46.5 = getelementptr i8, i8* %a, i64 52
  %12143 = load i8, i8* %scevgep35.46.5, align 1
  %12144 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.5 = call zeroext i8 @mult(i8 zeroext %12143, i8 zeroext %12144)
  %conv35.46.5 = zext i8 %call34.46.5 to i32
  %xor36.46.5 = xor i32 %xor.46.5, %conv35.46.5
  %conv37.46.5 = trunc i32 %xor36.46.5 to i8
  store i8 %conv37.46.5, i8* %scevgep41.46.4, align 1
  %scevgep28.46.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12138, i64 0, i64 0, i64 1
  %12145 = bitcast i8* %scevgep28.46.5 to [61 x [61 x i8]]*
  %scevgep41.46.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12139, i64 0, i64 1, i64 0
  %12146 = bitcast i8* %scevgep41.46.5 to [61 x [61 x i8]]*
  %call16.46.6 = call zeroext i8 (...) @rand()
  store i8 %call16.46.6, i8* %scevgep28.46.5, align 1
  %12147 = load i8, i8* %scevgep28.46.5, align 1
  %conv23.46.6 = zext i8 %12147 to i32
  %12148 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.6 = getelementptr i8, i8* %b, i64 53
  %12149 = load i8, i8* %scevgep34.46.6, align 1
  %call28.46.6 = call zeroext i8 @mult(i8 zeroext %12148, i8 zeroext %12149)
  %conv29.46.6 = zext i8 %call28.46.6 to i32
  %xor.46.6 = xor i32 %conv23.46.6, %conv29.46.6
  %scevgep35.46.6 = getelementptr i8, i8* %a, i64 53
  %12150 = load i8, i8* %scevgep35.46.6, align 1
  %12151 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.6 = call zeroext i8 @mult(i8 zeroext %12150, i8 zeroext %12151)
  %conv35.46.6 = zext i8 %call34.46.6 to i32
  %xor36.46.6 = xor i32 %xor.46.6, %conv35.46.6
  %conv37.46.6 = trunc i32 %xor36.46.6 to i8
  store i8 %conv37.46.6, i8* %scevgep41.46.5, align 1
  %scevgep28.46.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12145, i64 0, i64 0, i64 1
  %12152 = bitcast i8* %scevgep28.46.6 to [61 x [61 x i8]]*
  %scevgep41.46.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12146, i64 0, i64 1, i64 0
  %12153 = bitcast i8* %scevgep41.46.6 to [61 x [61 x i8]]*
  %call16.46.7 = call zeroext i8 (...) @rand()
  store i8 %call16.46.7, i8* %scevgep28.46.6, align 1
  %12154 = load i8, i8* %scevgep28.46.6, align 1
  %conv23.46.7 = zext i8 %12154 to i32
  %12155 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.7 = getelementptr i8, i8* %b, i64 54
  %12156 = load i8, i8* %scevgep34.46.7, align 1
  %call28.46.7 = call zeroext i8 @mult(i8 zeroext %12155, i8 zeroext %12156)
  %conv29.46.7 = zext i8 %call28.46.7 to i32
  %xor.46.7 = xor i32 %conv23.46.7, %conv29.46.7
  %scevgep35.46.7 = getelementptr i8, i8* %a, i64 54
  %12157 = load i8, i8* %scevgep35.46.7, align 1
  %12158 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.7 = call zeroext i8 @mult(i8 zeroext %12157, i8 zeroext %12158)
  %conv35.46.7 = zext i8 %call34.46.7 to i32
  %xor36.46.7 = xor i32 %xor.46.7, %conv35.46.7
  %conv37.46.7 = trunc i32 %xor36.46.7 to i8
  store i8 %conv37.46.7, i8* %scevgep41.46.6, align 1
  %scevgep28.46.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12152, i64 0, i64 0, i64 1
  %12159 = bitcast i8* %scevgep28.46.7 to [61 x [61 x i8]]*
  %scevgep41.46.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12153, i64 0, i64 1, i64 0
  %12160 = bitcast i8* %scevgep41.46.7 to [61 x [61 x i8]]*
  %call16.46.8 = call zeroext i8 (...) @rand()
  store i8 %call16.46.8, i8* %scevgep28.46.7, align 1
  %12161 = load i8, i8* %scevgep28.46.7, align 1
  %conv23.46.8 = zext i8 %12161 to i32
  %12162 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.8 = getelementptr i8, i8* %b, i64 55
  %12163 = load i8, i8* %scevgep34.46.8, align 1
  %call28.46.8 = call zeroext i8 @mult(i8 zeroext %12162, i8 zeroext %12163)
  %conv29.46.8 = zext i8 %call28.46.8 to i32
  %xor.46.8 = xor i32 %conv23.46.8, %conv29.46.8
  %scevgep35.46.8 = getelementptr i8, i8* %a, i64 55
  %12164 = load i8, i8* %scevgep35.46.8, align 1
  %12165 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.8 = call zeroext i8 @mult(i8 zeroext %12164, i8 zeroext %12165)
  %conv35.46.8 = zext i8 %call34.46.8 to i32
  %xor36.46.8 = xor i32 %xor.46.8, %conv35.46.8
  %conv37.46.8 = trunc i32 %xor36.46.8 to i8
  store i8 %conv37.46.8, i8* %scevgep41.46.7, align 1
  %scevgep28.46.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12159, i64 0, i64 0, i64 1
  %12166 = bitcast i8* %scevgep28.46.8 to [61 x [61 x i8]]*
  %scevgep41.46.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12160, i64 0, i64 1, i64 0
  %12167 = bitcast i8* %scevgep41.46.8 to [61 x [61 x i8]]*
  %call16.46.9 = call zeroext i8 (...) @rand()
  store i8 %call16.46.9, i8* %scevgep28.46.8, align 1
  %12168 = load i8, i8* %scevgep28.46.8, align 1
  %conv23.46.9 = zext i8 %12168 to i32
  %12169 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.9 = getelementptr i8, i8* %b, i64 56
  %12170 = load i8, i8* %scevgep34.46.9, align 1
  %call28.46.9 = call zeroext i8 @mult(i8 zeroext %12169, i8 zeroext %12170)
  %conv29.46.9 = zext i8 %call28.46.9 to i32
  %xor.46.9 = xor i32 %conv23.46.9, %conv29.46.9
  %scevgep35.46.9 = getelementptr i8, i8* %a, i64 56
  %12171 = load i8, i8* %scevgep35.46.9, align 1
  %12172 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.9 = call zeroext i8 @mult(i8 zeroext %12171, i8 zeroext %12172)
  %conv35.46.9 = zext i8 %call34.46.9 to i32
  %xor36.46.9 = xor i32 %xor.46.9, %conv35.46.9
  %conv37.46.9 = trunc i32 %xor36.46.9 to i8
  store i8 %conv37.46.9, i8* %scevgep41.46.8, align 1
  %scevgep28.46.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12166, i64 0, i64 0, i64 1
  %12173 = bitcast i8* %scevgep28.46.9 to [61 x [61 x i8]]*
  %scevgep41.46.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12167, i64 0, i64 1, i64 0
  %12174 = bitcast i8* %scevgep41.46.9 to [61 x [61 x i8]]*
  %call16.46.10 = call zeroext i8 (...) @rand()
  store i8 %call16.46.10, i8* %scevgep28.46.9, align 1
  %12175 = load i8, i8* %scevgep28.46.9, align 1
  %conv23.46.10 = zext i8 %12175 to i32
  %12176 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.10 = getelementptr i8, i8* %b, i64 57
  %12177 = load i8, i8* %scevgep34.46.10, align 1
  %call28.46.10 = call zeroext i8 @mult(i8 zeroext %12176, i8 zeroext %12177)
  %conv29.46.10 = zext i8 %call28.46.10 to i32
  %xor.46.10 = xor i32 %conv23.46.10, %conv29.46.10
  %scevgep35.46.10 = getelementptr i8, i8* %a, i64 57
  %12178 = load i8, i8* %scevgep35.46.10, align 1
  %12179 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.10 = call zeroext i8 @mult(i8 zeroext %12178, i8 zeroext %12179)
  %conv35.46.10 = zext i8 %call34.46.10 to i32
  %xor36.46.10 = xor i32 %xor.46.10, %conv35.46.10
  %conv37.46.10 = trunc i32 %xor36.46.10 to i8
  store i8 %conv37.46.10, i8* %scevgep41.46.9, align 1
  %scevgep28.46.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12173, i64 0, i64 0, i64 1
  %12180 = bitcast i8* %scevgep28.46.10 to [61 x [61 x i8]]*
  %scevgep41.46.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12174, i64 0, i64 1, i64 0
  %12181 = bitcast i8* %scevgep41.46.10 to [61 x [61 x i8]]*
  %call16.46.11 = call zeroext i8 (...) @rand()
  store i8 %call16.46.11, i8* %scevgep28.46.10, align 1
  %12182 = load i8, i8* %scevgep28.46.10, align 1
  %conv23.46.11 = zext i8 %12182 to i32
  %12183 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.11 = getelementptr i8, i8* %b, i64 58
  %12184 = load i8, i8* %scevgep34.46.11, align 1
  %call28.46.11 = call zeroext i8 @mult(i8 zeroext %12183, i8 zeroext %12184)
  %conv29.46.11 = zext i8 %call28.46.11 to i32
  %xor.46.11 = xor i32 %conv23.46.11, %conv29.46.11
  %scevgep35.46.11 = getelementptr i8, i8* %a, i64 58
  %12185 = load i8, i8* %scevgep35.46.11, align 1
  %12186 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.11 = call zeroext i8 @mult(i8 zeroext %12185, i8 zeroext %12186)
  %conv35.46.11 = zext i8 %call34.46.11 to i32
  %xor36.46.11 = xor i32 %xor.46.11, %conv35.46.11
  %conv37.46.11 = trunc i32 %xor36.46.11 to i8
  store i8 %conv37.46.11, i8* %scevgep41.46.10, align 1
  %scevgep28.46.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12180, i64 0, i64 0, i64 1
  %12187 = bitcast i8* %scevgep28.46.11 to [61 x [61 x i8]]*
  %scevgep41.46.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12181, i64 0, i64 1, i64 0
  %12188 = bitcast i8* %scevgep41.46.11 to [61 x [61 x i8]]*
  %call16.46.12 = call zeroext i8 (...) @rand()
  store i8 %call16.46.12, i8* %scevgep28.46.11, align 1
  %12189 = load i8, i8* %scevgep28.46.11, align 1
  %conv23.46.12 = zext i8 %12189 to i32
  %12190 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.12 = getelementptr i8, i8* %b, i64 59
  %12191 = load i8, i8* %scevgep34.46.12, align 1
  %call28.46.12 = call zeroext i8 @mult(i8 zeroext %12190, i8 zeroext %12191)
  %conv29.46.12 = zext i8 %call28.46.12 to i32
  %xor.46.12 = xor i32 %conv23.46.12, %conv29.46.12
  %scevgep35.46.12 = getelementptr i8, i8* %a, i64 59
  %12192 = load i8, i8* %scevgep35.46.12, align 1
  %12193 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.12 = call zeroext i8 @mult(i8 zeroext %12192, i8 zeroext %12193)
  %conv35.46.12 = zext i8 %call34.46.12 to i32
  %xor36.46.12 = xor i32 %xor.46.12, %conv35.46.12
  %conv37.46.12 = trunc i32 %xor36.46.12 to i8
  store i8 %conv37.46.12, i8* %scevgep41.46.11, align 1
  %scevgep28.46.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12187, i64 0, i64 0, i64 1
  %scevgep41.46.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12188, i64 0, i64 1, i64 0
  %call16.46.13 = call zeroext i8 (...) @rand()
  store i8 %call16.46.13, i8* %scevgep28.46.12, align 1
  %12194 = load i8, i8* %scevgep28.46.12, align 1
  %conv23.46.13 = zext i8 %12194 to i32
  %12195 = load i8, i8* %arrayidx25.46, align 1
  %scevgep34.46.13 = getelementptr i8, i8* %b, i64 60
  %12196 = load i8, i8* %scevgep34.46.13, align 1
  %call28.46.13 = call zeroext i8 @mult(i8 zeroext %12195, i8 zeroext %12196)
  %conv29.46.13 = zext i8 %call28.46.13 to i32
  %xor.46.13 = xor i32 %conv23.46.13, %conv29.46.13
  %scevgep35.46.13 = getelementptr i8, i8* %a, i64 60
  %12197 = load i8, i8* %scevgep35.46.13, align 1
  %12198 = load i8, i8* %arrayidx33.46, align 1
  %call34.46.13 = call zeroext i8 @mult(i8 zeroext %12197, i8 zeroext %12198)
  %conv35.46.13 = zext i8 %call34.46.13 to i32
  %xor36.46.13 = xor i32 %xor.46.13, %conv35.46.13
  %conv37.46.13 = trunc i32 %xor36.46.13 to i8
  store i8 %conv37.46.13, i8* %scevgep41.46.12, align 1
  %scevgep26.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12103, i64 0, i64 1, i64 1
  %12199 = bitcast i8* %scevgep26.46 to [61 x [61 x i8]]*
  %scevgep39.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12104, i64 0, i64 1, i64 1
  %12200 = bitcast i8* %scevgep39.46 to [61 x [61 x i8]]*
  %arrayidx25.47 = getelementptr inbounds i8, i8* %a, i64 47
  %arrayidx33.47 = getelementptr inbounds i8, i8* %b, i64 47
  %call16.47 = call zeroext i8 (...) @rand()
  store i8 %call16.47, i8* %scevgep26.46, align 1
  %12201 = load i8, i8* %scevgep26.46, align 1
  %conv23.47 = zext i8 %12201 to i32
  %12202 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47 = getelementptr i8, i8* %b, i64 48
  %12203 = load i8, i8* %scevgep34.47, align 1
  %call28.47 = call zeroext i8 @mult(i8 zeroext %12202, i8 zeroext %12203)
  %conv29.47 = zext i8 %call28.47 to i32
  %xor.47 = xor i32 %conv23.47, %conv29.47
  %scevgep35.47 = getelementptr i8, i8* %a, i64 48
  %12204 = load i8, i8* %scevgep35.47, align 1
  %12205 = load i8, i8* %arrayidx33.47, align 1
  %call34.47 = call zeroext i8 @mult(i8 zeroext %12204, i8 zeroext %12205)
  %conv35.47 = zext i8 %call34.47 to i32
  %xor36.47 = xor i32 %xor.47, %conv35.47
  %conv37.47 = trunc i32 %xor36.47 to i8
  store i8 %conv37.47, i8* %scevgep39.46, align 1
  %scevgep28.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12199, i64 0, i64 0, i64 1
  %12206 = bitcast i8* %scevgep28.47 to [61 x [61 x i8]]*
  %scevgep41.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12200, i64 0, i64 1, i64 0
  %12207 = bitcast i8* %scevgep41.47 to [61 x [61 x i8]]*
  %call16.47.1 = call zeroext i8 (...) @rand()
  store i8 %call16.47.1, i8* %scevgep28.47, align 1
  %12208 = load i8, i8* %scevgep28.47, align 1
  %conv23.47.1 = zext i8 %12208 to i32
  %12209 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.1 = getelementptr i8, i8* %b, i64 49
  %12210 = load i8, i8* %scevgep34.47.1, align 1
  %call28.47.1 = call zeroext i8 @mult(i8 zeroext %12209, i8 zeroext %12210)
  %conv29.47.1 = zext i8 %call28.47.1 to i32
  %xor.47.1 = xor i32 %conv23.47.1, %conv29.47.1
  %scevgep35.47.1 = getelementptr i8, i8* %a, i64 49
  %12211 = load i8, i8* %scevgep35.47.1, align 1
  %12212 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.1 = call zeroext i8 @mult(i8 zeroext %12211, i8 zeroext %12212)
  %conv35.47.1 = zext i8 %call34.47.1 to i32
  %xor36.47.1 = xor i32 %xor.47.1, %conv35.47.1
  %conv37.47.1 = trunc i32 %xor36.47.1 to i8
  store i8 %conv37.47.1, i8* %scevgep41.47, align 1
  %scevgep28.47.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12206, i64 0, i64 0, i64 1
  %12213 = bitcast i8* %scevgep28.47.1 to [61 x [61 x i8]]*
  %scevgep41.47.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12207, i64 0, i64 1, i64 0
  %12214 = bitcast i8* %scevgep41.47.1 to [61 x [61 x i8]]*
  %call16.47.2 = call zeroext i8 (...) @rand()
  store i8 %call16.47.2, i8* %scevgep28.47.1, align 1
  %12215 = load i8, i8* %scevgep28.47.1, align 1
  %conv23.47.2 = zext i8 %12215 to i32
  %12216 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.2 = getelementptr i8, i8* %b, i64 50
  %12217 = load i8, i8* %scevgep34.47.2, align 1
  %call28.47.2 = call zeroext i8 @mult(i8 zeroext %12216, i8 zeroext %12217)
  %conv29.47.2 = zext i8 %call28.47.2 to i32
  %xor.47.2 = xor i32 %conv23.47.2, %conv29.47.2
  %scevgep35.47.2 = getelementptr i8, i8* %a, i64 50
  %12218 = load i8, i8* %scevgep35.47.2, align 1
  %12219 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.2 = call zeroext i8 @mult(i8 zeroext %12218, i8 zeroext %12219)
  %conv35.47.2 = zext i8 %call34.47.2 to i32
  %xor36.47.2 = xor i32 %xor.47.2, %conv35.47.2
  %conv37.47.2 = trunc i32 %xor36.47.2 to i8
  store i8 %conv37.47.2, i8* %scevgep41.47.1, align 1
  %scevgep28.47.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12213, i64 0, i64 0, i64 1
  %12220 = bitcast i8* %scevgep28.47.2 to [61 x [61 x i8]]*
  %scevgep41.47.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12214, i64 0, i64 1, i64 0
  %12221 = bitcast i8* %scevgep41.47.2 to [61 x [61 x i8]]*
  %call16.47.3 = call zeroext i8 (...) @rand()
  store i8 %call16.47.3, i8* %scevgep28.47.2, align 1
  %12222 = load i8, i8* %scevgep28.47.2, align 1
  %conv23.47.3 = zext i8 %12222 to i32
  %12223 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.3 = getelementptr i8, i8* %b, i64 51
  %12224 = load i8, i8* %scevgep34.47.3, align 1
  %call28.47.3 = call zeroext i8 @mult(i8 zeroext %12223, i8 zeroext %12224)
  %conv29.47.3 = zext i8 %call28.47.3 to i32
  %xor.47.3 = xor i32 %conv23.47.3, %conv29.47.3
  %scevgep35.47.3 = getelementptr i8, i8* %a, i64 51
  %12225 = load i8, i8* %scevgep35.47.3, align 1
  %12226 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.3 = call zeroext i8 @mult(i8 zeroext %12225, i8 zeroext %12226)
  %conv35.47.3 = zext i8 %call34.47.3 to i32
  %xor36.47.3 = xor i32 %xor.47.3, %conv35.47.3
  %conv37.47.3 = trunc i32 %xor36.47.3 to i8
  store i8 %conv37.47.3, i8* %scevgep41.47.2, align 1
  %scevgep28.47.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12220, i64 0, i64 0, i64 1
  %12227 = bitcast i8* %scevgep28.47.3 to [61 x [61 x i8]]*
  %scevgep41.47.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12221, i64 0, i64 1, i64 0
  %12228 = bitcast i8* %scevgep41.47.3 to [61 x [61 x i8]]*
  %call16.47.4 = call zeroext i8 (...) @rand()
  store i8 %call16.47.4, i8* %scevgep28.47.3, align 1
  %12229 = load i8, i8* %scevgep28.47.3, align 1
  %conv23.47.4 = zext i8 %12229 to i32
  %12230 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.4 = getelementptr i8, i8* %b, i64 52
  %12231 = load i8, i8* %scevgep34.47.4, align 1
  %call28.47.4 = call zeroext i8 @mult(i8 zeroext %12230, i8 zeroext %12231)
  %conv29.47.4 = zext i8 %call28.47.4 to i32
  %xor.47.4 = xor i32 %conv23.47.4, %conv29.47.4
  %scevgep35.47.4 = getelementptr i8, i8* %a, i64 52
  %12232 = load i8, i8* %scevgep35.47.4, align 1
  %12233 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.4 = call zeroext i8 @mult(i8 zeroext %12232, i8 zeroext %12233)
  %conv35.47.4 = zext i8 %call34.47.4 to i32
  %xor36.47.4 = xor i32 %xor.47.4, %conv35.47.4
  %conv37.47.4 = trunc i32 %xor36.47.4 to i8
  store i8 %conv37.47.4, i8* %scevgep41.47.3, align 1
  %scevgep28.47.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12227, i64 0, i64 0, i64 1
  %12234 = bitcast i8* %scevgep28.47.4 to [61 x [61 x i8]]*
  %scevgep41.47.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12228, i64 0, i64 1, i64 0
  %12235 = bitcast i8* %scevgep41.47.4 to [61 x [61 x i8]]*
  %call16.47.5 = call zeroext i8 (...) @rand()
  store i8 %call16.47.5, i8* %scevgep28.47.4, align 1
  %12236 = load i8, i8* %scevgep28.47.4, align 1
  %conv23.47.5 = zext i8 %12236 to i32
  %12237 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.5 = getelementptr i8, i8* %b, i64 53
  %12238 = load i8, i8* %scevgep34.47.5, align 1
  %call28.47.5 = call zeroext i8 @mult(i8 zeroext %12237, i8 zeroext %12238)
  %conv29.47.5 = zext i8 %call28.47.5 to i32
  %xor.47.5 = xor i32 %conv23.47.5, %conv29.47.5
  %scevgep35.47.5 = getelementptr i8, i8* %a, i64 53
  %12239 = load i8, i8* %scevgep35.47.5, align 1
  %12240 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.5 = call zeroext i8 @mult(i8 zeroext %12239, i8 zeroext %12240)
  %conv35.47.5 = zext i8 %call34.47.5 to i32
  %xor36.47.5 = xor i32 %xor.47.5, %conv35.47.5
  %conv37.47.5 = trunc i32 %xor36.47.5 to i8
  store i8 %conv37.47.5, i8* %scevgep41.47.4, align 1
  %scevgep28.47.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12234, i64 0, i64 0, i64 1
  %12241 = bitcast i8* %scevgep28.47.5 to [61 x [61 x i8]]*
  %scevgep41.47.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12235, i64 0, i64 1, i64 0
  %12242 = bitcast i8* %scevgep41.47.5 to [61 x [61 x i8]]*
  %call16.47.6 = call zeroext i8 (...) @rand()
  store i8 %call16.47.6, i8* %scevgep28.47.5, align 1
  %12243 = load i8, i8* %scevgep28.47.5, align 1
  %conv23.47.6 = zext i8 %12243 to i32
  %12244 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.6 = getelementptr i8, i8* %b, i64 54
  %12245 = load i8, i8* %scevgep34.47.6, align 1
  %call28.47.6 = call zeroext i8 @mult(i8 zeroext %12244, i8 zeroext %12245)
  %conv29.47.6 = zext i8 %call28.47.6 to i32
  %xor.47.6 = xor i32 %conv23.47.6, %conv29.47.6
  %scevgep35.47.6 = getelementptr i8, i8* %a, i64 54
  %12246 = load i8, i8* %scevgep35.47.6, align 1
  %12247 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.6 = call zeroext i8 @mult(i8 zeroext %12246, i8 zeroext %12247)
  %conv35.47.6 = zext i8 %call34.47.6 to i32
  %xor36.47.6 = xor i32 %xor.47.6, %conv35.47.6
  %conv37.47.6 = trunc i32 %xor36.47.6 to i8
  store i8 %conv37.47.6, i8* %scevgep41.47.5, align 1
  %scevgep28.47.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12241, i64 0, i64 0, i64 1
  %12248 = bitcast i8* %scevgep28.47.6 to [61 x [61 x i8]]*
  %scevgep41.47.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12242, i64 0, i64 1, i64 0
  %12249 = bitcast i8* %scevgep41.47.6 to [61 x [61 x i8]]*
  %call16.47.7 = call zeroext i8 (...) @rand()
  store i8 %call16.47.7, i8* %scevgep28.47.6, align 1
  %12250 = load i8, i8* %scevgep28.47.6, align 1
  %conv23.47.7 = zext i8 %12250 to i32
  %12251 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.7 = getelementptr i8, i8* %b, i64 55
  %12252 = load i8, i8* %scevgep34.47.7, align 1
  %call28.47.7 = call zeroext i8 @mult(i8 zeroext %12251, i8 zeroext %12252)
  %conv29.47.7 = zext i8 %call28.47.7 to i32
  %xor.47.7 = xor i32 %conv23.47.7, %conv29.47.7
  %scevgep35.47.7 = getelementptr i8, i8* %a, i64 55
  %12253 = load i8, i8* %scevgep35.47.7, align 1
  %12254 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.7 = call zeroext i8 @mult(i8 zeroext %12253, i8 zeroext %12254)
  %conv35.47.7 = zext i8 %call34.47.7 to i32
  %xor36.47.7 = xor i32 %xor.47.7, %conv35.47.7
  %conv37.47.7 = trunc i32 %xor36.47.7 to i8
  store i8 %conv37.47.7, i8* %scevgep41.47.6, align 1
  %scevgep28.47.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12248, i64 0, i64 0, i64 1
  %12255 = bitcast i8* %scevgep28.47.7 to [61 x [61 x i8]]*
  %scevgep41.47.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12249, i64 0, i64 1, i64 0
  %12256 = bitcast i8* %scevgep41.47.7 to [61 x [61 x i8]]*
  %call16.47.8 = call zeroext i8 (...) @rand()
  store i8 %call16.47.8, i8* %scevgep28.47.7, align 1
  %12257 = load i8, i8* %scevgep28.47.7, align 1
  %conv23.47.8 = zext i8 %12257 to i32
  %12258 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.8 = getelementptr i8, i8* %b, i64 56
  %12259 = load i8, i8* %scevgep34.47.8, align 1
  %call28.47.8 = call zeroext i8 @mult(i8 zeroext %12258, i8 zeroext %12259)
  %conv29.47.8 = zext i8 %call28.47.8 to i32
  %xor.47.8 = xor i32 %conv23.47.8, %conv29.47.8
  %scevgep35.47.8 = getelementptr i8, i8* %a, i64 56
  %12260 = load i8, i8* %scevgep35.47.8, align 1
  %12261 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.8 = call zeroext i8 @mult(i8 zeroext %12260, i8 zeroext %12261)
  %conv35.47.8 = zext i8 %call34.47.8 to i32
  %xor36.47.8 = xor i32 %xor.47.8, %conv35.47.8
  %conv37.47.8 = trunc i32 %xor36.47.8 to i8
  store i8 %conv37.47.8, i8* %scevgep41.47.7, align 1
  %scevgep28.47.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12255, i64 0, i64 0, i64 1
  %12262 = bitcast i8* %scevgep28.47.8 to [61 x [61 x i8]]*
  %scevgep41.47.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12256, i64 0, i64 1, i64 0
  %12263 = bitcast i8* %scevgep41.47.8 to [61 x [61 x i8]]*
  %call16.47.9 = call zeroext i8 (...) @rand()
  store i8 %call16.47.9, i8* %scevgep28.47.8, align 1
  %12264 = load i8, i8* %scevgep28.47.8, align 1
  %conv23.47.9 = zext i8 %12264 to i32
  %12265 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.9 = getelementptr i8, i8* %b, i64 57
  %12266 = load i8, i8* %scevgep34.47.9, align 1
  %call28.47.9 = call zeroext i8 @mult(i8 zeroext %12265, i8 zeroext %12266)
  %conv29.47.9 = zext i8 %call28.47.9 to i32
  %xor.47.9 = xor i32 %conv23.47.9, %conv29.47.9
  %scevgep35.47.9 = getelementptr i8, i8* %a, i64 57
  %12267 = load i8, i8* %scevgep35.47.9, align 1
  %12268 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.9 = call zeroext i8 @mult(i8 zeroext %12267, i8 zeroext %12268)
  %conv35.47.9 = zext i8 %call34.47.9 to i32
  %xor36.47.9 = xor i32 %xor.47.9, %conv35.47.9
  %conv37.47.9 = trunc i32 %xor36.47.9 to i8
  store i8 %conv37.47.9, i8* %scevgep41.47.8, align 1
  %scevgep28.47.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12262, i64 0, i64 0, i64 1
  %12269 = bitcast i8* %scevgep28.47.9 to [61 x [61 x i8]]*
  %scevgep41.47.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12263, i64 0, i64 1, i64 0
  %12270 = bitcast i8* %scevgep41.47.9 to [61 x [61 x i8]]*
  %call16.47.10 = call zeroext i8 (...) @rand()
  store i8 %call16.47.10, i8* %scevgep28.47.9, align 1
  %12271 = load i8, i8* %scevgep28.47.9, align 1
  %conv23.47.10 = zext i8 %12271 to i32
  %12272 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.10 = getelementptr i8, i8* %b, i64 58
  %12273 = load i8, i8* %scevgep34.47.10, align 1
  %call28.47.10 = call zeroext i8 @mult(i8 zeroext %12272, i8 zeroext %12273)
  %conv29.47.10 = zext i8 %call28.47.10 to i32
  %xor.47.10 = xor i32 %conv23.47.10, %conv29.47.10
  %scevgep35.47.10 = getelementptr i8, i8* %a, i64 58
  %12274 = load i8, i8* %scevgep35.47.10, align 1
  %12275 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.10 = call zeroext i8 @mult(i8 zeroext %12274, i8 zeroext %12275)
  %conv35.47.10 = zext i8 %call34.47.10 to i32
  %xor36.47.10 = xor i32 %xor.47.10, %conv35.47.10
  %conv37.47.10 = trunc i32 %xor36.47.10 to i8
  store i8 %conv37.47.10, i8* %scevgep41.47.9, align 1
  %scevgep28.47.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12269, i64 0, i64 0, i64 1
  %12276 = bitcast i8* %scevgep28.47.10 to [61 x [61 x i8]]*
  %scevgep41.47.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12270, i64 0, i64 1, i64 0
  %12277 = bitcast i8* %scevgep41.47.10 to [61 x [61 x i8]]*
  %call16.47.11 = call zeroext i8 (...) @rand()
  store i8 %call16.47.11, i8* %scevgep28.47.10, align 1
  %12278 = load i8, i8* %scevgep28.47.10, align 1
  %conv23.47.11 = zext i8 %12278 to i32
  %12279 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.11 = getelementptr i8, i8* %b, i64 59
  %12280 = load i8, i8* %scevgep34.47.11, align 1
  %call28.47.11 = call zeroext i8 @mult(i8 zeroext %12279, i8 zeroext %12280)
  %conv29.47.11 = zext i8 %call28.47.11 to i32
  %xor.47.11 = xor i32 %conv23.47.11, %conv29.47.11
  %scevgep35.47.11 = getelementptr i8, i8* %a, i64 59
  %12281 = load i8, i8* %scevgep35.47.11, align 1
  %12282 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.11 = call zeroext i8 @mult(i8 zeroext %12281, i8 zeroext %12282)
  %conv35.47.11 = zext i8 %call34.47.11 to i32
  %xor36.47.11 = xor i32 %xor.47.11, %conv35.47.11
  %conv37.47.11 = trunc i32 %xor36.47.11 to i8
  store i8 %conv37.47.11, i8* %scevgep41.47.10, align 1
  %scevgep28.47.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12276, i64 0, i64 0, i64 1
  %scevgep41.47.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12277, i64 0, i64 1, i64 0
  %call16.47.12 = call zeroext i8 (...) @rand()
  store i8 %call16.47.12, i8* %scevgep28.47.11, align 1
  %12283 = load i8, i8* %scevgep28.47.11, align 1
  %conv23.47.12 = zext i8 %12283 to i32
  %12284 = load i8, i8* %arrayidx25.47, align 1
  %scevgep34.47.12 = getelementptr i8, i8* %b, i64 60
  %12285 = load i8, i8* %scevgep34.47.12, align 1
  %call28.47.12 = call zeroext i8 @mult(i8 zeroext %12284, i8 zeroext %12285)
  %conv29.47.12 = zext i8 %call28.47.12 to i32
  %xor.47.12 = xor i32 %conv23.47.12, %conv29.47.12
  %scevgep35.47.12 = getelementptr i8, i8* %a, i64 60
  %12286 = load i8, i8* %scevgep35.47.12, align 1
  %12287 = load i8, i8* %arrayidx33.47, align 1
  %call34.47.12 = call zeroext i8 @mult(i8 zeroext %12286, i8 zeroext %12287)
  %conv35.47.12 = zext i8 %call34.47.12 to i32
  %xor36.47.12 = xor i32 %xor.47.12, %conv35.47.12
  %conv37.47.12 = trunc i32 %xor36.47.12 to i8
  store i8 %conv37.47.12, i8* %scevgep41.47.11, align 1
  %scevgep26.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12199, i64 0, i64 1, i64 1
  %12288 = bitcast i8* %scevgep26.47 to [61 x [61 x i8]]*
  %scevgep39.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12200, i64 0, i64 1, i64 1
  %12289 = bitcast i8* %scevgep39.47 to [61 x [61 x i8]]*
  %arrayidx25.48 = getelementptr inbounds i8, i8* %a, i64 48
  %arrayidx33.48 = getelementptr inbounds i8, i8* %b, i64 48
  %call16.48 = call zeroext i8 (...) @rand()
  store i8 %call16.48, i8* %scevgep26.47, align 1
  %12290 = load i8, i8* %scevgep26.47, align 1
  %conv23.48 = zext i8 %12290 to i32
  %12291 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48 = getelementptr i8, i8* %b, i64 49
  %12292 = load i8, i8* %scevgep34.48, align 1
  %call28.48 = call zeroext i8 @mult(i8 zeroext %12291, i8 zeroext %12292)
  %conv29.48 = zext i8 %call28.48 to i32
  %xor.48 = xor i32 %conv23.48, %conv29.48
  %scevgep35.48 = getelementptr i8, i8* %a, i64 49
  %12293 = load i8, i8* %scevgep35.48, align 1
  %12294 = load i8, i8* %arrayidx33.48, align 1
  %call34.48 = call zeroext i8 @mult(i8 zeroext %12293, i8 zeroext %12294)
  %conv35.48 = zext i8 %call34.48 to i32
  %xor36.48 = xor i32 %xor.48, %conv35.48
  %conv37.48 = trunc i32 %xor36.48 to i8
  store i8 %conv37.48, i8* %scevgep39.47, align 1
  %scevgep28.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12288, i64 0, i64 0, i64 1
  %12295 = bitcast i8* %scevgep28.48 to [61 x [61 x i8]]*
  %scevgep41.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12289, i64 0, i64 1, i64 0
  %12296 = bitcast i8* %scevgep41.48 to [61 x [61 x i8]]*
  %call16.48.1 = call zeroext i8 (...) @rand()
  store i8 %call16.48.1, i8* %scevgep28.48, align 1
  %12297 = load i8, i8* %scevgep28.48, align 1
  %conv23.48.1 = zext i8 %12297 to i32
  %12298 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.1 = getelementptr i8, i8* %b, i64 50
  %12299 = load i8, i8* %scevgep34.48.1, align 1
  %call28.48.1 = call zeroext i8 @mult(i8 zeroext %12298, i8 zeroext %12299)
  %conv29.48.1 = zext i8 %call28.48.1 to i32
  %xor.48.1 = xor i32 %conv23.48.1, %conv29.48.1
  %scevgep35.48.1 = getelementptr i8, i8* %a, i64 50
  %12300 = load i8, i8* %scevgep35.48.1, align 1
  %12301 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.1 = call zeroext i8 @mult(i8 zeroext %12300, i8 zeroext %12301)
  %conv35.48.1 = zext i8 %call34.48.1 to i32
  %xor36.48.1 = xor i32 %xor.48.1, %conv35.48.1
  %conv37.48.1 = trunc i32 %xor36.48.1 to i8
  store i8 %conv37.48.1, i8* %scevgep41.48, align 1
  %scevgep28.48.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12295, i64 0, i64 0, i64 1
  %12302 = bitcast i8* %scevgep28.48.1 to [61 x [61 x i8]]*
  %scevgep41.48.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12296, i64 0, i64 1, i64 0
  %12303 = bitcast i8* %scevgep41.48.1 to [61 x [61 x i8]]*
  %call16.48.2 = call zeroext i8 (...) @rand()
  store i8 %call16.48.2, i8* %scevgep28.48.1, align 1
  %12304 = load i8, i8* %scevgep28.48.1, align 1
  %conv23.48.2 = zext i8 %12304 to i32
  %12305 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.2 = getelementptr i8, i8* %b, i64 51
  %12306 = load i8, i8* %scevgep34.48.2, align 1
  %call28.48.2 = call zeroext i8 @mult(i8 zeroext %12305, i8 zeroext %12306)
  %conv29.48.2 = zext i8 %call28.48.2 to i32
  %xor.48.2 = xor i32 %conv23.48.2, %conv29.48.2
  %scevgep35.48.2 = getelementptr i8, i8* %a, i64 51
  %12307 = load i8, i8* %scevgep35.48.2, align 1
  %12308 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.2 = call zeroext i8 @mult(i8 zeroext %12307, i8 zeroext %12308)
  %conv35.48.2 = zext i8 %call34.48.2 to i32
  %xor36.48.2 = xor i32 %xor.48.2, %conv35.48.2
  %conv37.48.2 = trunc i32 %xor36.48.2 to i8
  store i8 %conv37.48.2, i8* %scevgep41.48.1, align 1
  %scevgep28.48.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12302, i64 0, i64 0, i64 1
  %12309 = bitcast i8* %scevgep28.48.2 to [61 x [61 x i8]]*
  %scevgep41.48.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12303, i64 0, i64 1, i64 0
  %12310 = bitcast i8* %scevgep41.48.2 to [61 x [61 x i8]]*
  %call16.48.3 = call zeroext i8 (...) @rand()
  store i8 %call16.48.3, i8* %scevgep28.48.2, align 1
  %12311 = load i8, i8* %scevgep28.48.2, align 1
  %conv23.48.3 = zext i8 %12311 to i32
  %12312 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.3 = getelementptr i8, i8* %b, i64 52
  %12313 = load i8, i8* %scevgep34.48.3, align 1
  %call28.48.3 = call zeroext i8 @mult(i8 zeroext %12312, i8 zeroext %12313)
  %conv29.48.3 = zext i8 %call28.48.3 to i32
  %xor.48.3 = xor i32 %conv23.48.3, %conv29.48.3
  %scevgep35.48.3 = getelementptr i8, i8* %a, i64 52
  %12314 = load i8, i8* %scevgep35.48.3, align 1
  %12315 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.3 = call zeroext i8 @mult(i8 zeroext %12314, i8 zeroext %12315)
  %conv35.48.3 = zext i8 %call34.48.3 to i32
  %xor36.48.3 = xor i32 %xor.48.3, %conv35.48.3
  %conv37.48.3 = trunc i32 %xor36.48.3 to i8
  store i8 %conv37.48.3, i8* %scevgep41.48.2, align 1
  %scevgep28.48.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12309, i64 0, i64 0, i64 1
  %12316 = bitcast i8* %scevgep28.48.3 to [61 x [61 x i8]]*
  %scevgep41.48.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12310, i64 0, i64 1, i64 0
  %12317 = bitcast i8* %scevgep41.48.3 to [61 x [61 x i8]]*
  %call16.48.4 = call zeroext i8 (...) @rand()
  store i8 %call16.48.4, i8* %scevgep28.48.3, align 1
  %12318 = load i8, i8* %scevgep28.48.3, align 1
  %conv23.48.4 = zext i8 %12318 to i32
  %12319 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.4 = getelementptr i8, i8* %b, i64 53
  %12320 = load i8, i8* %scevgep34.48.4, align 1
  %call28.48.4 = call zeroext i8 @mult(i8 zeroext %12319, i8 zeroext %12320)
  %conv29.48.4 = zext i8 %call28.48.4 to i32
  %xor.48.4 = xor i32 %conv23.48.4, %conv29.48.4
  %scevgep35.48.4 = getelementptr i8, i8* %a, i64 53
  %12321 = load i8, i8* %scevgep35.48.4, align 1
  %12322 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.4 = call zeroext i8 @mult(i8 zeroext %12321, i8 zeroext %12322)
  %conv35.48.4 = zext i8 %call34.48.4 to i32
  %xor36.48.4 = xor i32 %xor.48.4, %conv35.48.4
  %conv37.48.4 = trunc i32 %xor36.48.4 to i8
  store i8 %conv37.48.4, i8* %scevgep41.48.3, align 1
  %scevgep28.48.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12316, i64 0, i64 0, i64 1
  %12323 = bitcast i8* %scevgep28.48.4 to [61 x [61 x i8]]*
  %scevgep41.48.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12317, i64 0, i64 1, i64 0
  %12324 = bitcast i8* %scevgep41.48.4 to [61 x [61 x i8]]*
  %call16.48.5 = call zeroext i8 (...) @rand()
  store i8 %call16.48.5, i8* %scevgep28.48.4, align 1
  %12325 = load i8, i8* %scevgep28.48.4, align 1
  %conv23.48.5 = zext i8 %12325 to i32
  %12326 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.5 = getelementptr i8, i8* %b, i64 54
  %12327 = load i8, i8* %scevgep34.48.5, align 1
  %call28.48.5 = call zeroext i8 @mult(i8 zeroext %12326, i8 zeroext %12327)
  %conv29.48.5 = zext i8 %call28.48.5 to i32
  %xor.48.5 = xor i32 %conv23.48.5, %conv29.48.5
  %scevgep35.48.5 = getelementptr i8, i8* %a, i64 54
  %12328 = load i8, i8* %scevgep35.48.5, align 1
  %12329 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.5 = call zeroext i8 @mult(i8 zeroext %12328, i8 zeroext %12329)
  %conv35.48.5 = zext i8 %call34.48.5 to i32
  %xor36.48.5 = xor i32 %xor.48.5, %conv35.48.5
  %conv37.48.5 = trunc i32 %xor36.48.5 to i8
  store i8 %conv37.48.5, i8* %scevgep41.48.4, align 1
  %scevgep28.48.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12323, i64 0, i64 0, i64 1
  %12330 = bitcast i8* %scevgep28.48.5 to [61 x [61 x i8]]*
  %scevgep41.48.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12324, i64 0, i64 1, i64 0
  %12331 = bitcast i8* %scevgep41.48.5 to [61 x [61 x i8]]*
  %call16.48.6 = call zeroext i8 (...) @rand()
  store i8 %call16.48.6, i8* %scevgep28.48.5, align 1
  %12332 = load i8, i8* %scevgep28.48.5, align 1
  %conv23.48.6 = zext i8 %12332 to i32
  %12333 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.6 = getelementptr i8, i8* %b, i64 55
  %12334 = load i8, i8* %scevgep34.48.6, align 1
  %call28.48.6 = call zeroext i8 @mult(i8 zeroext %12333, i8 zeroext %12334)
  %conv29.48.6 = zext i8 %call28.48.6 to i32
  %xor.48.6 = xor i32 %conv23.48.6, %conv29.48.6
  %scevgep35.48.6 = getelementptr i8, i8* %a, i64 55
  %12335 = load i8, i8* %scevgep35.48.6, align 1
  %12336 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.6 = call zeroext i8 @mult(i8 zeroext %12335, i8 zeroext %12336)
  %conv35.48.6 = zext i8 %call34.48.6 to i32
  %xor36.48.6 = xor i32 %xor.48.6, %conv35.48.6
  %conv37.48.6 = trunc i32 %xor36.48.6 to i8
  store i8 %conv37.48.6, i8* %scevgep41.48.5, align 1
  %scevgep28.48.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12330, i64 0, i64 0, i64 1
  %12337 = bitcast i8* %scevgep28.48.6 to [61 x [61 x i8]]*
  %scevgep41.48.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12331, i64 0, i64 1, i64 0
  %12338 = bitcast i8* %scevgep41.48.6 to [61 x [61 x i8]]*
  %call16.48.7 = call zeroext i8 (...) @rand()
  store i8 %call16.48.7, i8* %scevgep28.48.6, align 1
  %12339 = load i8, i8* %scevgep28.48.6, align 1
  %conv23.48.7 = zext i8 %12339 to i32
  %12340 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.7 = getelementptr i8, i8* %b, i64 56
  %12341 = load i8, i8* %scevgep34.48.7, align 1
  %call28.48.7 = call zeroext i8 @mult(i8 zeroext %12340, i8 zeroext %12341)
  %conv29.48.7 = zext i8 %call28.48.7 to i32
  %xor.48.7 = xor i32 %conv23.48.7, %conv29.48.7
  %scevgep35.48.7 = getelementptr i8, i8* %a, i64 56
  %12342 = load i8, i8* %scevgep35.48.7, align 1
  %12343 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.7 = call zeroext i8 @mult(i8 zeroext %12342, i8 zeroext %12343)
  %conv35.48.7 = zext i8 %call34.48.7 to i32
  %xor36.48.7 = xor i32 %xor.48.7, %conv35.48.7
  %conv37.48.7 = trunc i32 %xor36.48.7 to i8
  store i8 %conv37.48.7, i8* %scevgep41.48.6, align 1
  %scevgep28.48.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12337, i64 0, i64 0, i64 1
  %12344 = bitcast i8* %scevgep28.48.7 to [61 x [61 x i8]]*
  %scevgep41.48.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12338, i64 0, i64 1, i64 0
  %12345 = bitcast i8* %scevgep41.48.7 to [61 x [61 x i8]]*
  %call16.48.8 = call zeroext i8 (...) @rand()
  store i8 %call16.48.8, i8* %scevgep28.48.7, align 1
  %12346 = load i8, i8* %scevgep28.48.7, align 1
  %conv23.48.8 = zext i8 %12346 to i32
  %12347 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.8 = getelementptr i8, i8* %b, i64 57
  %12348 = load i8, i8* %scevgep34.48.8, align 1
  %call28.48.8 = call zeroext i8 @mult(i8 zeroext %12347, i8 zeroext %12348)
  %conv29.48.8 = zext i8 %call28.48.8 to i32
  %xor.48.8 = xor i32 %conv23.48.8, %conv29.48.8
  %scevgep35.48.8 = getelementptr i8, i8* %a, i64 57
  %12349 = load i8, i8* %scevgep35.48.8, align 1
  %12350 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.8 = call zeroext i8 @mult(i8 zeroext %12349, i8 zeroext %12350)
  %conv35.48.8 = zext i8 %call34.48.8 to i32
  %xor36.48.8 = xor i32 %xor.48.8, %conv35.48.8
  %conv37.48.8 = trunc i32 %xor36.48.8 to i8
  store i8 %conv37.48.8, i8* %scevgep41.48.7, align 1
  %scevgep28.48.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12344, i64 0, i64 0, i64 1
  %12351 = bitcast i8* %scevgep28.48.8 to [61 x [61 x i8]]*
  %scevgep41.48.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12345, i64 0, i64 1, i64 0
  %12352 = bitcast i8* %scevgep41.48.8 to [61 x [61 x i8]]*
  %call16.48.9 = call zeroext i8 (...) @rand()
  store i8 %call16.48.9, i8* %scevgep28.48.8, align 1
  %12353 = load i8, i8* %scevgep28.48.8, align 1
  %conv23.48.9 = zext i8 %12353 to i32
  %12354 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.9 = getelementptr i8, i8* %b, i64 58
  %12355 = load i8, i8* %scevgep34.48.9, align 1
  %call28.48.9 = call zeroext i8 @mult(i8 zeroext %12354, i8 zeroext %12355)
  %conv29.48.9 = zext i8 %call28.48.9 to i32
  %xor.48.9 = xor i32 %conv23.48.9, %conv29.48.9
  %scevgep35.48.9 = getelementptr i8, i8* %a, i64 58
  %12356 = load i8, i8* %scevgep35.48.9, align 1
  %12357 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.9 = call zeroext i8 @mult(i8 zeroext %12356, i8 zeroext %12357)
  %conv35.48.9 = zext i8 %call34.48.9 to i32
  %xor36.48.9 = xor i32 %xor.48.9, %conv35.48.9
  %conv37.48.9 = trunc i32 %xor36.48.9 to i8
  store i8 %conv37.48.9, i8* %scevgep41.48.8, align 1
  %scevgep28.48.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12351, i64 0, i64 0, i64 1
  %12358 = bitcast i8* %scevgep28.48.9 to [61 x [61 x i8]]*
  %scevgep41.48.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12352, i64 0, i64 1, i64 0
  %12359 = bitcast i8* %scevgep41.48.9 to [61 x [61 x i8]]*
  %call16.48.10 = call zeroext i8 (...) @rand()
  store i8 %call16.48.10, i8* %scevgep28.48.9, align 1
  %12360 = load i8, i8* %scevgep28.48.9, align 1
  %conv23.48.10 = zext i8 %12360 to i32
  %12361 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.10 = getelementptr i8, i8* %b, i64 59
  %12362 = load i8, i8* %scevgep34.48.10, align 1
  %call28.48.10 = call zeroext i8 @mult(i8 zeroext %12361, i8 zeroext %12362)
  %conv29.48.10 = zext i8 %call28.48.10 to i32
  %xor.48.10 = xor i32 %conv23.48.10, %conv29.48.10
  %scevgep35.48.10 = getelementptr i8, i8* %a, i64 59
  %12363 = load i8, i8* %scevgep35.48.10, align 1
  %12364 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.10 = call zeroext i8 @mult(i8 zeroext %12363, i8 zeroext %12364)
  %conv35.48.10 = zext i8 %call34.48.10 to i32
  %xor36.48.10 = xor i32 %xor.48.10, %conv35.48.10
  %conv37.48.10 = trunc i32 %xor36.48.10 to i8
  store i8 %conv37.48.10, i8* %scevgep41.48.9, align 1
  %scevgep28.48.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12358, i64 0, i64 0, i64 1
  %scevgep41.48.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12359, i64 0, i64 1, i64 0
  %call16.48.11 = call zeroext i8 (...) @rand()
  store i8 %call16.48.11, i8* %scevgep28.48.10, align 1
  %12365 = load i8, i8* %scevgep28.48.10, align 1
  %conv23.48.11 = zext i8 %12365 to i32
  %12366 = load i8, i8* %arrayidx25.48, align 1
  %scevgep34.48.11 = getelementptr i8, i8* %b, i64 60
  %12367 = load i8, i8* %scevgep34.48.11, align 1
  %call28.48.11 = call zeroext i8 @mult(i8 zeroext %12366, i8 zeroext %12367)
  %conv29.48.11 = zext i8 %call28.48.11 to i32
  %xor.48.11 = xor i32 %conv23.48.11, %conv29.48.11
  %scevgep35.48.11 = getelementptr i8, i8* %a, i64 60
  %12368 = load i8, i8* %scevgep35.48.11, align 1
  %12369 = load i8, i8* %arrayidx33.48, align 1
  %call34.48.11 = call zeroext i8 @mult(i8 zeroext %12368, i8 zeroext %12369)
  %conv35.48.11 = zext i8 %call34.48.11 to i32
  %xor36.48.11 = xor i32 %xor.48.11, %conv35.48.11
  %conv37.48.11 = trunc i32 %xor36.48.11 to i8
  store i8 %conv37.48.11, i8* %scevgep41.48.10, align 1
  %scevgep26.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12288, i64 0, i64 1, i64 1
  %12370 = bitcast i8* %scevgep26.48 to [61 x [61 x i8]]*
  %scevgep39.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12289, i64 0, i64 1, i64 1
  %12371 = bitcast i8* %scevgep39.48 to [61 x [61 x i8]]*
  %arrayidx25.49 = getelementptr inbounds i8, i8* %a, i64 49
  %arrayidx33.49 = getelementptr inbounds i8, i8* %b, i64 49
  %call16.49 = call zeroext i8 (...) @rand()
  store i8 %call16.49, i8* %scevgep26.48, align 1
  %12372 = load i8, i8* %scevgep26.48, align 1
  %conv23.49 = zext i8 %12372 to i32
  %12373 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49 = getelementptr i8, i8* %b, i64 50
  %12374 = load i8, i8* %scevgep34.49, align 1
  %call28.49 = call zeroext i8 @mult(i8 zeroext %12373, i8 zeroext %12374)
  %conv29.49 = zext i8 %call28.49 to i32
  %xor.49 = xor i32 %conv23.49, %conv29.49
  %scevgep35.49 = getelementptr i8, i8* %a, i64 50
  %12375 = load i8, i8* %scevgep35.49, align 1
  %12376 = load i8, i8* %arrayidx33.49, align 1
  %call34.49 = call zeroext i8 @mult(i8 zeroext %12375, i8 zeroext %12376)
  %conv35.49 = zext i8 %call34.49 to i32
  %xor36.49 = xor i32 %xor.49, %conv35.49
  %conv37.49 = trunc i32 %xor36.49 to i8
  store i8 %conv37.49, i8* %scevgep39.48, align 1
  %scevgep28.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12370, i64 0, i64 0, i64 1
  %12377 = bitcast i8* %scevgep28.49 to [61 x [61 x i8]]*
  %scevgep41.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12371, i64 0, i64 1, i64 0
  %12378 = bitcast i8* %scevgep41.49 to [61 x [61 x i8]]*
  %call16.49.1 = call zeroext i8 (...) @rand()
  store i8 %call16.49.1, i8* %scevgep28.49, align 1
  %12379 = load i8, i8* %scevgep28.49, align 1
  %conv23.49.1 = zext i8 %12379 to i32
  %12380 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.1 = getelementptr i8, i8* %b, i64 51
  %12381 = load i8, i8* %scevgep34.49.1, align 1
  %call28.49.1 = call zeroext i8 @mult(i8 zeroext %12380, i8 zeroext %12381)
  %conv29.49.1 = zext i8 %call28.49.1 to i32
  %xor.49.1 = xor i32 %conv23.49.1, %conv29.49.1
  %scevgep35.49.1 = getelementptr i8, i8* %a, i64 51
  %12382 = load i8, i8* %scevgep35.49.1, align 1
  %12383 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.1 = call zeroext i8 @mult(i8 zeroext %12382, i8 zeroext %12383)
  %conv35.49.1 = zext i8 %call34.49.1 to i32
  %xor36.49.1 = xor i32 %xor.49.1, %conv35.49.1
  %conv37.49.1 = trunc i32 %xor36.49.1 to i8
  store i8 %conv37.49.1, i8* %scevgep41.49, align 1
  %scevgep28.49.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12377, i64 0, i64 0, i64 1
  %12384 = bitcast i8* %scevgep28.49.1 to [61 x [61 x i8]]*
  %scevgep41.49.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12378, i64 0, i64 1, i64 0
  %12385 = bitcast i8* %scevgep41.49.1 to [61 x [61 x i8]]*
  %call16.49.2 = call zeroext i8 (...) @rand()
  store i8 %call16.49.2, i8* %scevgep28.49.1, align 1
  %12386 = load i8, i8* %scevgep28.49.1, align 1
  %conv23.49.2 = zext i8 %12386 to i32
  %12387 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.2 = getelementptr i8, i8* %b, i64 52
  %12388 = load i8, i8* %scevgep34.49.2, align 1
  %call28.49.2 = call zeroext i8 @mult(i8 zeroext %12387, i8 zeroext %12388)
  %conv29.49.2 = zext i8 %call28.49.2 to i32
  %xor.49.2 = xor i32 %conv23.49.2, %conv29.49.2
  %scevgep35.49.2 = getelementptr i8, i8* %a, i64 52
  %12389 = load i8, i8* %scevgep35.49.2, align 1
  %12390 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.2 = call zeroext i8 @mult(i8 zeroext %12389, i8 zeroext %12390)
  %conv35.49.2 = zext i8 %call34.49.2 to i32
  %xor36.49.2 = xor i32 %xor.49.2, %conv35.49.2
  %conv37.49.2 = trunc i32 %xor36.49.2 to i8
  store i8 %conv37.49.2, i8* %scevgep41.49.1, align 1
  %scevgep28.49.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12384, i64 0, i64 0, i64 1
  %12391 = bitcast i8* %scevgep28.49.2 to [61 x [61 x i8]]*
  %scevgep41.49.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12385, i64 0, i64 1, i64 0
  %12392 = bitcast i8* %scevgep41.49.2 to [61 x [61 x i8]]*
  %call16.49.3 = call zeroext i8 (...) @rand()
  store i8 %call16.49.3, i8* %scevgep28.49.2, align 1
  %12393 = load i8, i8* %scevgep28.49.2, align 1
  %conv23.49.3 = zext i8 %12393 to i32
  %12394 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.3 = getelementptr i8, i8* %b, i64 53
  %12395 = load i8, i8* %scevgep34.49.3, align 1
  %call28.49.3 = call zeroext i8 @mult(i8 zeroext %12394, i8 zeroext %12395)
  %conv29.49.3 = zext i8 %call28.49.3 to i32
  %xor.49.3 = xor i32 %conv23.49.3, %conv29.49.3
  %scevgep35.49.3 = getelementptr i8, i8* %a, i64 53
  %12396 = load i8, i8* %scevgep35.49.3, align 1
  %12397 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.3 = call zeroext i8 @mult(i8 zeroext %12396, i8 zeroext %12397)
  %conv35.49.3 = zext i8 %call34.49.3 to i32
  %xor36.49.3 = xor i32 %xor.49.3, %conv35.49.3
  %conv37.49.3 = trunc i32 %xor36.49.3 to i8
  store i8 %conv37.49.3, i8* %scevgep41.49.2, align 1
  %scevgep28.49.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12391, i64 0, i64 0, i64 1
  %12398 = bitcast i8* %scevgep28.49.3 to [61 x [61 x i8]]*
  %scevgep41.49.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12392, i64 0, i64 1, i64 0
  %12399 = bitcast i8* %scevgep41.49.3 to [61 x [61 x i8]]*
  %call16.49.4 = call zeroext i8 (...) @rand()
  store i8 %call16.49.4, i8* %scevgep28.49.3, align 1
  %12400 = load i8, i8* %scevgep28.49.3, align 1
  %conv23.49.4 = zext i8 %12400 to i32
  %12401 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.4 = getelementptr i8, i8* %b, i64 54
  %12402 = load i8, i8* %scevgep34.49.4, align 1
  %call28.49.4 = call zeroext i8 @mult(i8 zeroext %12401, i8 zeroext %12402)
  %conv29.49.4 = zext i8 %call28.49.4 to i32
  %xor.49.4 = xor i32 %conv23.49.4, %conv29.49.4
  %scevgep35.49.4 = getelementptr i8, i8* %a, i64 54
  %12403 = load i8, i8* %scevgep35.49.4, align 1
  %12404 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.4 = call zeroext i8 @mult(i8 zeroext %12403, i8 zeroext %12404)
  %conv35.49.4 = zext i8 %call34.49.4 to i32
  %xor36.49.4 = xor i32 %xor.49.4, %conv35.49.4
  %conv37.49.4 = trunc i32 %xor36.49.4 to i8
  store i8 %conv37.49.4, i8* %scevgep41.49.3, align 1
  %scevgep28.49.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12398, i64 0, i64 0, i64 1
  %12405 = bitcast i8* %scevgep28.49.4 to [61 x [61 x i8]]*
  %scevgep41.49.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12399, i64 0, i64 1, i64 0
  %12406 = bitcast i8* %scevgep41.49.4 to [61 x [61 x i8]]*
  %call16.49.5 = call zeroext i8 (...) @rand()
  store i8 %call16.49.5, i8* %scevgep28.49.4, align 1
  %12407 = load i8, i8* %scevgep28.49.4, align 1
  %conv23.49.5 = zext i8 %12407 to i32
  %12408 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.5 = getelementptr i8, i8* %b, i64 55
  %12409 = load i8, i8* %scevgep34.49.5, align 1
  %call28.49.5 = call zeroext i8 @mult(i8 zeroext %12408, i8 zeroext %12409)
  %conv29.49.5 = zext i8 %call28.49.5 to i32
  %xor.49.5 = xor i32 %conv23.49.5, %conv29.49.5
  %scevgep35.49.5 = getelementptr i8, i8* %a, i64 55
  %12410 = load i8, i8* %scevgep35.49.5, align 1
  %12411 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.5 = call zeroext i8 @mult(i8 zeroext %12410, i8 zeroext %12411)
  %conv35.49.5 = zext i8 %call34.49.5 to i32
  %xor36.49.5 = xor i32 %xor.49.5, %conv35.49.5
  %conv37.49.5 = trunc i32 %xor36.49.5 to i8
  store i8 %conv37.49.5, i8* %scevgep41.49.4, align 1
  %scevgep28.49.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12405, i64 0, i64 0, i64 1
  %12412 = bitcast i8* %scevgep28.49.5 to [61 x [61 x i8]]*
  %scevgep41.49.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12406, i64 0, i64 1, i64 0
  %12413 = bitcast i8* %scevgep41.49.5 to [61 x [61 x i8]]*
  %call16.49.6 = call zeroext i8 (...) @rand()
  store i8 %call16.49.6, i8* %scevgep28.49.5, align 1
  %12414 = load i8, i8* %scevgep28.49.5, align 1
  %conv23.49.6 = zext i8 %12414 to i32
  %12415 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.6 = getelementptr i8, i8* %b, i64 56
  %12416 = load i8, i8* %scevgep34.49.6, align 1
  %call28.49.6 = call zeroext i8 @mult(i8 zeroext %12415, i8 zeroext %12416)
  %conv29.49.6 = zext i8 %call28.49.6 to i32
  %xor.49.6 = xor i32 %conv23.49.6, %conv29.49.6
  %scevgep35.49.6 = getelementptr i8, i8* %a, i64 56
  %12417 = load i8, i8* %scevgep35.49.6, align 1
  %12418 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.6 = call zeroext i8 @mult(i8 zeroext %12417, i8 zeroext %12418)
  %conv35.49.6 = zext i8 %call34.49.6 to i32
  %xor36.49.6 = xor i32 %xor.49.6, %conv35.49.6
  %conv37.49.6 = trunc i32 %xor36.49.6 to i8
  store i8 %conv37.49.6, i8* %scevgep41.49.5, align 1
  %scevgep28.49.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12412, i64 0, i64 0, i64 1
  %12419 = bitcast i8* %scevgep28.49.6 to [61 x [61 x i8]]*
  %scevgep41.49.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12413, i64 0, i64 1, i64 0
  %12420 = bitcast i8* %scevgep41.49.6 to [61 x [61 x i8]]*
  %call16.49.7 = call zeroext i8 (...) @rand()
  store i8 %call16.49.7, i8* %scevgep28.49.6, align 1
  %12421 = load i8, i8* %scevgep28.49.6, align 1
  %conv23.49.7 = zext i8 %12421 to i32
  %12422 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.7 = getelementptr i8, i8* %b, i64 57
  %12423 = load i8, i8* %scevgep34.49.7, align 1
  %call28.49.7 = call zeroext i8 @mult(i8 zeroext %12422, i8 zeroext %12423)
  %conv29.49.7 = zext i8 %call28.49.7 to i32
  %xor.49.7 = xor i32 %conv23.49.7, %conv29.49.7
  %scevgep35.49.7 = getelementptr i8, i8* %a, i64 57
  %12424 = load i8, i8* %scevgep35.49.7, align 1
  %12425 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.7 = call zeroext i8 @mult(i8 zeroext %12424, i8 zeroext %12425)
  %conv35.49.7 = zext i8 %call34.49.7 to i32
  %xor36.49.7 = xor i32 %xor.49.7, %conv35.49.7
  %conv37.49.7 = trunc i32 %xor36.49.7 to i8
  store i8 %conv37.49.7, i8* %scevgep41.49.6, align 1
  %scevgep28.49.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12419, i64 0, i64 0, i64 1
  %12426 = bitcast i8* %scevgep28.49.7 to [61 x [61 x i8]]*
  %scevgep41.49.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12420, i64 0, i64 1, i64 0
  %12427 = bitcast i8* %scevgep41.49.7 to [61 x [61 x i8]]*
  %call16.49.8 = call zeroext i8 (...) @rand()
  store i8 %call16.49.8, i8* %scevgep28.49.7, align 1
  %12428 = load i8, i8* %scevgep28.49.7, align 1
  %conv23.49.8 = zext i8 %12428 to i32
  %12429 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.8 = getelementptr i8, i8* %b, i64 58
  %12430 = load i8, i8* %scevgep34.49.8, align 1
  %call28.49.8 = call zeroext i8 @mult(i8 zeroext %12429, i8 zeroext %12430)
  %conv29.49.8 = zext i8 %call28.49.8 to i32
  %xor.49.8 = xor i32 %conv23.49.8, %conv29.49.8
  %scevgep35.49.8 = getelementptr i8, i8* %a, i64 58
  %12431 = load i8, i8* %scevgep35.49.8, align 1
  %12432 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.8 = call zeroext i8 @mult(i8 zeroext %12431, i8 zeroext %12432)
  %conv35.49.8 = zext i8 %call34.49.8 to i32
  %xor36.49.8 = xor i32 %xor.49.8, %conv35.49.8
  %conv37.49.8 = trunc i32 %xor36.49.8 to i8
  store i8 %conv37.49.8, i8* %scevgep41.49.7, align 1
  %scevgep28.49.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12426, i64 0, i64 0, i64 1
  %12433 = bitcast i8* %scevgep28.49.8 to [61 x [61 x i8]]*
  %scevgep41.49.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12427, i64 0, i64 1, i64 0
  %12434 = bitcast i8* %scevgep41.49.8 to [61 x [61 x i8]]*
  %call16.49.9 = call zeroext i8 (...) @rand()
  store i8 %call16.49.9, i8* %scevgep28.49.8, align 1
  %12435 = load i8, i8* %scevgep28.49.8, align 1
  %conv23.49.9 = zext i8 %12435 to i32
  %12436 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.9 = getelementptr i8, i8* %b, i64 59
  %12437 = load i8, i8* %scevgep34.49.9, align 1
  %call28.49.9 = call zeroext i8 @mult(i8 zeroext %12436, i8 zeroext %12437)
  %conv29.49.9 = zext i8 %call28.49.9 to i32
  %xor.49.9 = xor i32 %conv23.49.9, %conv29.49.9
  %scevgep35.49.9 = getelementptr i8, i8* %a, i64 59
  %12438 = load i8, i8* %scevgep35.49.9, align 1
  %12439 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.9 = call zeroext i8 @mult(i8 zeroext %12438, i8 zeroext %12439)
  %conv35.49.9 = zext i8 %call34.49.9 to i32
  %xor36.49.9 = xor i32 %xor.49.9, %conv35.49.9
  %conv37.49.9 = trunc i32 %xor36.49.9 to i8
  store i8 %conv37.49.9, i8* %scevgep41.49.8, align 1
  %scevgep28.49.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12433, i64 0, i64 0, i64 1
  %scevgep41.49.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12434, i64 0, i64 1, i64 0
  %call16.49.10 = call zeroext i8 (...) @rand()
  store i8 %call16.49.10, i8* %scevgep28.49.9, align 1
  %12440 = load i8, i8* %scevgep28.49.9, align 1
  %conv23.49.10 = zext i8 %12440 to i32
  %12441 = load i8, i8* %arrayidx25.49, align 1
  %scevgep34.49.10 = getelementptr i8, i8* %b, i64 60
  %12442 = load i8, i8* %scevgep34.49.10, align 1
  %call28.49.10 = call zeroext i8 @mult(i8 zeroext %12441, i8 zeroext %12442)
  %conv29.49.10 = zext i8 %call28.49.10 to i32
  %xor.49.10 = xor i32 %conv23.49.10, %conv29.49.10
  %scevgep35.49.10 = getelementptr i8, i8* %a, i64 60
  %12443 = load i8, i8* %scevgep35.49.10, align 1
  %12444 = load i8, i8* %arrayidx33.49, align 1
  %call34.49.10 = call zeroext i8 @mult(i8 zeroext %12443, i8 zeroext %12444)
  %conv35.49.10 = zext i8 %call34.49.10 to i32
  %xor36.49.10 = xor i32 %xor.49.10, %conv35.49.10
  %conv37.49.10 = trunc i32 %xor36.49.10 to i8
  store i8 %conv37.49.10, i8* %scevgep41.49.9, align 1
  %scevgep26.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12370, i64 0, i64 1, i64 1
  %12445 = bitcast i8* %scevgep26.49 to [61 x [61 x i8]]*
  %scevgep39.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12371, i64 0, i64 1, i64 1
  %12446 = bitcast i8* %scevgep39.49 to [61 x [61 x i8]]*
  %arrayidx25.50 = getelementptr inbounds i8, i8* %a, i64 50
  %arrayidx33.50 = getelementptr inbounds i8, i8* %b, i64 50
  %call16.50 = call zeroext i8 (...) @rand()
  store i8 %call16.50, i8* %scevgep26.49, align 1
  %12447 = load i8, i8* %scevgep26.49, align 1
  %conv23.50 = zext i8 %12447 to i32
  %12448 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50 = getelementptr i8, i8* %b, i64 51
  %12449 = load i8, i8* %scevgep34.50, align 1
  %call28.50 = call zeroext i8 @mult(i8 zeroext %12448, i8 zeroext %12449)
  %conv29.50 = zext i8 %call28.50 to i32
  %xor.50 = xor i32 %conv23.50, %conv29.50
  %scevgep35.50 = getelementptr i8, i8* %a, i64 51
  %12450 = load i8, i8* %scevgep35.50, align 1
  %12451 = load i8, i8* %arrayidx33.50, align 1
  %call34.50 = call zeroext i8 @mult(i8 zeroext %12450, i8 zeroext %12451)
  %conv35.50 = zext i8 %call34.50 to i32
  %xor36.50 = xor i32 %xor.50, %conv35.50
  %conv37.50 = trunc i32 %xor36.50 to i8
  store i8 %conv37.50, i8* %scevgep39.49, align 1
  %scevgep28.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12445, i64 0, i64 0, i64 1
  %12452 = bitcast i8* %scevgep28.50 to [61 x [61 x i8]]*
  %scevgep41.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12446, i64 0, i64 1, i64 0
  %12453 = bitcast i8* %scevgep41.50 to [61 x [61 x i8]]*
  %call16.50.1 = call zeroext i8 (...) @rand()
  store i8 %call16.50.1, i8* %scevgep28.50, align 1
  %12454 = load i8, i8* %scevgep28.50, align 1
  %conv23.50.1 = zext i8 %12454 to i32
  %12455 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50.1 = getelementptr i8, i8* %b, i64 52
  %12456 = load i8, i8* %scevgep34.50.1, align 1
  %call28.50.1 = call zeroext i8 @mult(i8 zeroext %12455, i8 zeroext %12456)
  %conv29.50.1 = zext i8 %call28.50.1 to i32
  %xor.50.1 = xor i32 %conv23.50.1, %conv29.50.1
  %scevgep35.50.1 = getelementptr i8, i8* %a, i64 52
  %12457 = load i8, i8* %scevgep35.50.1, align 1
  %12458 = load i8, i8* %arrayidx33.50, align 1
  %call34.50.1 = call zeroext i8 @mult(i8 zeroext %12457, i8 zeroext %12458)
  %conv35.50.1 = zext i8 %call34.50.1 to i32
  %xor36.50.1 = xor i32 %xor.50.1, %conv35.50.1
  %conv37.50.1 = trunc i32 %xor36.50.1 to i8
  store i8 %conv37.50.1, i8* %scevgep41.50, align 1
  %scevgep28.50.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12452, i64 0, i64 0, i64 1
  %12459 = bitcast i8* %scevgep28.50.1 to [61 x [61 x i8]]*
  %scevgep41.50.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12453, i64 0, i64 1, i64 0
  %12460 = bitcast i8* %scevgep41.50.1 to [61 x [61 x i8]]*
  %call16.50.2 = call zeroext i8 (...) @rand()
  store i8 %call16.50.2, i8* %scevgep28.50.1, align 1
  %12461 = load i8, i8* %scevgep28.50.1, align 1
  %conv23.50.2 = zext i8 %12461 to i32
  %12462 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50.2 = getelementptr i8, i8* %b, i64 53
  %12463 = load i8, i8* %scevgep34.50.2, align 1
  %call28.50.2 = call zeroext i8 @mult(i8 zeroext %12462, i8 zeroext %12463)
  %conv29.50.2 = zext i8 %call28.50.2 to i32
  %xor.50.2 = xor i32 %conv23.50.2, %conv29.50.2
  %scevgep35.50.2 = getelementptr i8, i8* %a, i64 53
  %12464 = load i8, i8* %scevgep35.50.2, align 1
  %12465 = load i8, i8* %arrayidx33.50, align 1
  %call34.50.2 = call zeroext i8 @mult(i8 zeroext %12464, i8 zeroext %12465)
  %conv35.50.2 = zext i8 %call34.50.2 to i32
  %xor36.50.2 = xor i32 %xor.50.2, %conv35.50.2
  %conv37.50.2 = trunc i32 %xor36.50.2 to i8
  store i8 %conv37.50.2, i8* %scevgep41.50.1, align 1
  %scevgep28.50.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12459, i64 0, i64 0, i64 1
  %12466 = bitcast i8* %scevgep28.50.2 to [61 x [61 x i8]]*
  %scevgep41.50.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12460, i64 0, i64 1, i64 0
  %12467 = bitcast i8* %scevgep41.50.2 to [61 x [61 x i8]]*
  %call16.50.3 = call zeroext i8 (...) @rand()
  store i8 %call16.50.3, i8* %scevgep28.50.2, align 1
  %12468 = load i8, i8* %scevgep28.50.2, align 1
  %conv23.50.3 = zext i8 %12468 to i32
  %12469 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50.3 = getelementptr i8, i8* %b, i64 54
  %12470 = load i8, i8* %scevgep34.50.3, align 1
  %call28.50.3 = call zeroext i8 @mult(i8 zeroext %12469, i8 zeroext %12470)
  %conv29.50.3 = zext i8 %call28.50.3 to i32
  %xor.50.3 = xor i32 %conv23.50.3, %conv29.50.3
  %scevgep35.50.3 = getelementptr i8, i8* %a, i64 54
  %12471 = load i8, i8* %scevgep35.50.3, align 1
  %12472 = load i8, i8* %arrayidx33.50, align 1
  %call34.50.3 = call zeroext i8 @mult(i8 zeroext %12471, i8 zeroext %12472)
  %conv35.50.3 = zext i8 %call34.50.3 to i32
  %xor36.50.3 = xor i32 %xor.50.3, %conv35.50.3
  %conv37.50.3 = trunc i32 %xor36.50.3 to i8
  store i8 %conv37.50.3, i8* %scevgep41.50.2, align 1
  %scevgep28.50.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12466, i64 0, i64 0, i64 1
  %12473 = bitcast i8* %scevgep28.50.3 to [61 x [61 x i8]]*
  %scevgep41.50.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12467, i64 0, i64 1, i64 0
  %12474 = bitcast i8* %scevgep41.50.3 to [61 x [61 x i8]]*
  %call16.50.4 = call zeroext i8 (...) @rand()
  store i8 %call16.50.4, i8* %scevgep28.50.3, align 1
  %12475 = load i8, i8* %scevgep28.50.3, align 1
  %conv23.50.4 = zext i8 %12475 to i32
  %12476 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50.4 = getelementptr i8, i8* %b, i64 55
  %12477 = load i8, i8* %scevgep34.50.4, align 1
  %call28.50.4 = call zeroext i8 @mult(i8 zeroext %12476, i8 zeroext %12477)
  %conv29.50.4 = zext i8 %call28.50.4 to i32
  %xor.50.4 = xor i32 %conv23.50.4, %conv29.50.4
  %scevgep35.50.4 = getelementptr i8, i8* %a, i64 55
  %12478 = load i8, i8* %scevgep35.50.4, align 1
  %12479 = load i8, i8* %arrayidx33.50, align 1
  %call34.50.4 = call zeroext i8 @mult(i8 zeroext %12478, i8 zeroext %12479)
  %conv35.50.4 = zext i8 %call34.50.4 to i32
  %xor36.50.4 = xor i32 %xor.50.4, %conv35.50.4
  %conv37.50.4 = trunc i32 %xor36.50.4 to i8
  store i8 %conv37.50.4, i8* %scevgep41.50.3, align 1
  %scevgep28.50.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12473, i64 0, i64 0, i64 1
  %12480 = bitcast i8* %scevgep28.50.4 to [61 x [61 x i8]]*
  %scevgep41.50.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12474, i64 0, i64 1, i64 0
  %12481 = bitcast i8* %scevgep41.50.4 to [61 x [61 x i8]]*
  %call16.50.5 = call zeroext i8 (...) @rand()
  store i8 %call16.50.5, i8* %scevgep28.50.4, align 1
  %12482 = load i8, i8* %scevgep28.50.4, align 1
  %conv23.50.5 = zext i8 %12482 to i32
  %12483 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50.5 = getelementptr i8, i8* %b, i64 56
  %12484 = load i8, i8* %scevgep34.50.5, align 1
  %call28.50.5 = call zeroext i8 @mult(i8 zeroext %12483, i8 zeroext %12484)
  %conv29.50.5 = zext i8 %call28.50.5 to i32
  %xor.50.5 = xor i32 %conv23.50.5, %conv29.50.5
  %scevgep35.50.5 = getelementptr i8, i8* %a, i64 56
  %12485 = load i8, i8* %scevgep35.50.5, align 1
  %12486 = load i8, i8* %arrayidx33.50, align 1
  %call34.50.5 = call zeroext i8 @mult(i8 zeroext %12485, i8 zeroext %12486)
  %conv35.50.5 = zext i8 %call34.50.5 to i32
  %xor36.50.5 = xor i32 %xor.50.5, %conv35.50.5
  %conv37.50.5 = trunc i32 %xor36.50.5 to i8
  store i8 %conv37.50.5, i8* %scevgep41.50.4, align 1
  %scevgep28.50.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12480, i64 0, i64 0, i64 1
  %12487 = bitcast i8* %scevgep28.50.5 to [61 x [61 x i8]]*
  %scevgep41.50.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12481, i64 0, i64 1, i64 0
  %12488 = bitcast i8* %scevgep41.50.5 to [61 x [61 x i8]]*
  %call16.50.6 = call zeroext i8 (...) @rand()
  store i8 %call16.50.6, i8* %scevgep28.50.5, align 1
  %12489 = load i8, i8* %scevgep28.50.5, align 1
  %conv23.50.6 = zext i8 %12489 to i32
  %12490 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50.6 = getelementptr i8, i8* %b, i64 57
  %12491 = load i8, i8* %scevgep34.50.6, align 1
  %call28.50.6 = call zeroext i8 @mult(i8 zeroext %12490, i8 zeroext %12491)
  %conv29.50.6 = zext i8 %call28.50.6 to i32
  %xor.50.6 = xor i32 %conv23.50.6, %conv29.50.6
  %scevgep35.50.6 = getelementptr i8, i8* %a, i64 57
  %12492 = load i8, i8* %scevgep35.50.6, align 1
  %12493 = load i8, i8* %arrayidx33.50, align 1
  %call34.50.6 = call zeroext i8 @mult(i8 zeroext %12492, i8 zeroext %12493)
  %conv35.50.6 = zext i8 %call34.50.6 to i32
  %xor36.50.6 = xor i32 %xor.50.6, %conv35.50.6
  %conv37.50.6 = trunc i32 %xor36.50.6 to i8
  store i8 %conv37.50.6, i8* %scevgep41.50.5, align 1
  %scevgep28.50.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12487, i64 0, i64 0, i64 1
  %12494 = bitcast i8* %scevgep28.50.6 to [61 x [61 x i8]]*
  %scevgep41.50.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12488, i64 0, i64 1, i64 0
  %12495 = bitcast i8* %scevgep41.50.6 to [61 x [61 x i8]]*
  %call16.50.7 = call zeroext i8 (...) @rand()
  store i8 %call16.50.7, i8* %scevgep28.50.6, align 1
  %12496 = load i8, i8* %scevgep28.50.6, align 1
  %conv23.50.7 = zext i8 %12496 to i32
  %12497 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50.7 = getelementptr i8, i8* %b, i64 58
  %12498 = load i8, i8* %scevgep34.50.7, align 1
  %call28.50.7 = call zeroext i8 @mult(i8 zeroext %12497, i8 zeroext %12498)
  %conv29.50.7 = zext i8 %call28.50.7 to i32
  %xor.50.7 = xor i32 %conv23.50.7, %conv29.50.7
  %scevgep35.50.7 = getelementptr i8, i8* %a, i64 58
  %12499 = load i8, i8* %scevgep35.50.7, align 1
  %12500 = load i8, i8* %arrayidx33.50, align 1
  %call34.50.7 = call zeroext i8 @mult(i8 zeroext %12499, i8 zeroext %12500)
  %conv35.50.7 = zext i8 %call34.50.7 to i32
  %xor36.50.7 = xor i32 %xor.50.7, %conv35.50.7
  %conv37.50.7 = trunc i32 %xor36.50.7 to i8
  store i8 %conv37.50.7, i8* %scevgep41.50.6, align 1
  %scevgep28.50.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12494, i64 0, i64 0, i64 1
  %12501 = bitcast i8* %scevgep28.50.7 to [61 x [61 x i8]]*
  %scevgep41.50.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12495, i64 0, i64 1, i64 0
  %12502 = bitcast i8* %scevgep41.50.7 to [61 x [61 x i8]]*
  %call16.50.8 = call zeroext i8 (...) @rand()
  store i8 %call16.50.8, i8* %scevgep28.50.7, align 1
  %12503 = load i8, i8* %scevgep28.50.7, align 1
  %conv23.50.8 = zext i8 %12503 to i32
  %12504 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50.8 = getelementptr i8, i8* %b, i64 59
  %12505 = load i8, i8* %scevgep34.50.8, align 1
  %call28.50.8 = call zeroext i8 @mult(i8 zeroext %12504, i8 zeroext %12505)
  %conv29.50.8 = zext i8 %call28.50.8 to i32
  %xor.50.8 = xor i32 %conv23.50.8, %conv29.50.8
  %scevgep35.50.8 = getelementptr i8, i8* %a, i64 59
  %12506 = load i8, i8* %scevgep35.50.8, align 1
  %12507 = load i8, i8* %arrayidx33.50, align 1
  %call34.50.8 = call zeroext i8 @mult(i8 zeroext %12506, i8 zeroext %12507)
  %conv35.50.8 = zext i8 %call34.50.8 to i32
  %xor36.50.8 = xor i32 %xor.50.8, %conv35.50.8
  %conv37.50.8 = trunc i32 %xor36.50.8 to i8
  store i8 %conv37.50.8, i8* %scevgep41.50.7, align 1
  %scevgep28.50.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12501, i64 0, i64 0, i64 1
  %scevgep41.50.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12502, i64 0, i64 1, i64 0
  %call16.50.9 = call zeroext i8 (...) @rand()
  store i8 %call16.50.9, i8* %scevgep28.50.8, align 1
  %12508 = load i8, i8* %scevgep28.50.8, align 1
  %conv23.50.9 = zext i8 %12508 to i32
  %12509 = load i8, i8* %arrayidx25.50, align 1
  %scevgep34.50.9 = getelementptr i8, i8* %b, i64 60
  %12510 = load i8, i8* %scevgep34.50.9, align 1
  %call28.50.9 = call zeroext i8 @mult(i8 zeroext %12509, i8 zeroext %12510)
  %conv29.50.9 = zext i8 %call28.50.9 to i32
  %xor.50.9 = xor i32 %conv23.50.9, %conv29.50.9
  %scevgep35.50.9 = getelementptr i8, i8* %a, i64 60
  %12511 = load i8, i8* %scevgep35.50.9, align 1
  %12512 = load i8, i8* %arrayidx33.50, align 1
  %call34.50.9 = call zeroext i8 @mult(i8 zeroext %12511, i8 zeroext %12512)
  %conv35.50.9 = zext i8 %call34.50.9 to i32
  %xor36.50.9 = xor i32 %xor.50.9, %conv35.50.9
  %conv37.50.9 = trunc i32 %xor36.50.9 to i8
  store i8 %conv37.50.9, i8* %scevgep41.50.8, align 1
  %scevgep26.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12445, i64 0, i64 1, i64 1
  %12513 = bitcast i8* %scevgep26.50 to [61 x [61 x i8]]*
  %scevgep39.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12446, i64 0, i64 1, i64 1
  %12514 = bitcast i8* %scevgep39.50 to [61 x [61 x i8]]*
  %arrayidx25.51 = getelementptr inbounds i8, i8* %a, i64 51
  %arrayidx33.51 = getelementptr inbounds i8, i8* %b, i64 51
  %call16.51 = call zeroext i8 (...) @rand()
  store i8 %call16.51, i8* %scevgep26.50, align 1
  %12515 = load i8, i8* %scevgep26.50, align 1
  %conv23.51 = zext i8 %12515 to i32
  %12516 = load i8, i8* %arrayidx25.51, align 1
  %scevgep34.51 = getelementptr i8, i8* %b, i64 52
  %12517 = load i8, i8* %scevgep34.51, align 1
  %call28.51 = call zeroext i8 @mult(i8 zeroext %12516, i8 zeroext %12517)
  %conv29.51 = zext i8 %call28.51 to i32
  %xor.51 = xor i32 %conv23.51, %conv29.51
  %scevgep35.51 = getelementptr i8, i8* %a, i64 52
  %12518 = load i8, i8* %scevgep35.51, align 1
  %12519 = load i8, i8* %arrayidx33.51, align 1
  %call34.51 = call zeroext i8 @mult(i8 zeroext %12518, i8 zeroext %12519)
  %conv35.51 = zext i8 %call34.51 to i32
  %xor36.51 = xor i32 %xor.51, %conv35.51
  %conv37.51 = trunc i32 %xor36.51 to i8
  store i8 %conv37.51, i8* %scevgep39.50, align 1
  %scevgep28.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12513, i64 0, i64 0, i64 1
  %12520 = bitcast i8* %scevgep28.51 to [61 x [61 x i8]]*
  %scevgep41.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12514, i64 0, i64 1, i64 0
  %12521 = bitcast i8* %scevgep41.51 to [61 x [61 x i8]]*
  %call16.51.1 = call zeroext i8 (...) @rand()
  store i8 %call16.51.1, i8* %scevgep28.51, align 1
  %12522 = load i8, i8* %scevgep28.51, align 1
  %conv23.51.1 = zext i8 %12522 to i32
  %12523 = load i8, i8* %arrayidx25.51, align 1
  %scevgep34.51.1 = getelementptr i8, i8* %b, i64 53
  %12524 = load i8, i8* %scevgep34.51.1, align 1
  %call28.51.1 = call zeroext i8 @mult(i8 zeroext %12523, i8 zeroext %12524)
  %conv29.51.1 = zext i8 %call28.51.1 to i32
  %xor.51.1 = xor i32 %conv23.51.1, %conv29.51.1
  %scevgep35.51.1 = getelementptr i8, i8* %a, i64 53
  %12525 = load i8, i8* %scevgep35.51.1, align 1
  %12526 = load i8, i8* %arrayidx33.51, align 1
  %call34.51.1 = call zeroext i8 @mult(i8 zeroext %12525, i8 zeroext %12526)
  %conv35.51.1 = zext i8 %call34.51.1 to i32
  %xor36.51.1 = xor i32 %xor.51.1, %conv35.51.1
  %conv37.51.1 = trunc i32 %xor36.51.1 to i8
  store i8 %conv37.51.1, i8* %scevgep41.51, align 1
  %scevgep28.51.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12520, i64 0, i64 0, i64 1
  %12527 = bitcast i8* %scevgep28.51.1 to [61 x [61 x i8]]*
  %scevgep41.51.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12521, i64 0, i64 1, i64 0
  %12528 = bitcast i8* %scevgep41.51.1 to [61 x [61 x i8]]*
  %call16.51.2 = call zeroext i8 (...) @rand()
  store i8 %call16.51.2, i8* %scevgep28.51.1, align 1
  %12529 = load i8, i8* %scevgep28.51.1, align 1
  %conv23.51.2 = zext i8 %12529 to i32
  %12530 = load i8, i8* %arrayidx25.51, align 1
  %scevgep34.51.2 = getelementptr i8, i8* %b, i64 54
  %12531 = load i8, i8* %scevgep34.51.2, align 1
  %call28.51.2 = call zeroext i8 @mult(i8 zeroext %12530, i8 zeroext %12531)
  %conv29.51.2 = zext i8 %call28.51.2 to i32
  %xor.51.2 = xor i32 %conv23.51.2, %conv29.51.2
  %scevgep35.51.2 = getelementptr i8, i8* %a, i64 54
  %12532 = load i8, i8* %scevgep35.51.2, align 1
  %12533 = load i8, i8* %arrayidx33.51, align 1
  %call34.51.2 = call zeroext i8 @mult(i8 zeroext %12532, i8 zeroext %12533)
  %conv35.51.2 = zext i8 %call34.51.2 to i32
  %xor36.51.2 = xor i32 %xor.51.2, %conv35.51.2
  %conv37.51.2 = trunc i32 %xor36.51.2 to i8
  store i8 %conv37.51.2, i8* %scevgep41.51.1, align 1
  %scevgep28.51.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12527, i64 0, i64 0, i64 1
  %12534 = bitcast i8* %scevgep28.51.2 to [61 x [61 x i8]]*
  %scevgep41.51.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12528, i64 0, i64 1, i64 0
  %12535 = bitcast i8* %scevgep41.51.2 to [61 x [61 x i8]]*
  %call16.51.3 = call zeroext i8 (...) @rand()
  store i8 %call16.51.3, i8* %scevgep28.51.2, align 1
  %12536 = load i8, i8* %scevgep28.51.2, align 1
  %conv23.51.3 = zext i8 %12536 to i32
  %12537 = load i8, i8* %arrayidx25.51, align 1
  %scevgep34.51.3 = getelementptr i8, i8* %b, i64 55
  %12538 = load i8, i8* %scevgep34.51.3, align 1
  %call28.51.3 = call zeroext i8 @mult(i8 zeroext %12537, i8 zeroext %12538)
  %conv29.51.3 = zext i8 %call28.51.3 to i32
  %xor.51.3 = xor i32 %conv23.51.3, %conv29.51.3
  %scevgep35.51.3 = getelementptr i8, i8* %a, i64 55
  %12539 = load i8, i8* %scevgep35.51.3, align 1
  %12540 = load i8, i8* %arrayidx33.51, align 1
  %call34.51.3 = call zeroext i8 @mult(i8 zeroext %12539, i8 zeroext %12540)
  %conv35.51.3 = zext i8 %call34.51.3 to i32
  %xor36.51.3 = xor i32 %xor.51.3, %conv35.51.3
  %conv37.51.3 = trunc i32 %xor36.51.3 to i8
  store i8 %conv37.51.3, i8* %scevgep41.51.2, align 1
  %scevgep28.51.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12534, i64 0, i64 0, i64 1
  %12541 = bitcast i8* %scevgep28.51.3 to [61 x [61 x i8]]*
  %scevgep41.51.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12535, i64 0, i64 1, i64 0
  %12542 = bitcast i8* %scevgep41.51.3 to [61 x [61 x i8]]*
  %call16.51.4 = call zeroext i8 (...) @rand()
  store i8 %call16.51.4, i8* %scevgep28.51.3, align 1
  %12543 = load i8, i8* %scevgep28.51.3, align 1
  %conv23.51.4 = zext i8 %12543 to i32
  %12544 = load i8, i8* %arrayidx25.51, align 1
  %scevgep34.51.4 = getelementptr i8, i8* %b, i64 56
  %12545 = load i8, i8* %scevgep34.51.4, align 1
  %call28.51.4 = call zeroext i8 @mult(i8 zeroext %12544, i8 zeroext %12545)
  %conv29.51.4 = zext i8 %call28.51.4 to i32
  %xor.51.4 = xor i32 %conv23.51.4, %conv29.51.4
  %scevgep35.51.4 = getelementptr i8, i8* %a, i64 56
  %12546 = load i8, i8* %scevgep35.51.4, align 1
  %12547 = load i8, i8* %arrayidx33.51, align 1
  %call34.51.4 = call zeroext i8 @mult(i8 zeroext %12546, i8 zeroext %12547)
  %conv35.51.4 = zext i8 %call34.51.4 to i32
  %xor36.51.4 = xor i32 %xor.51.4, %conv35.51.4
  %conv37.51.4 = trunc i32 %xor36.51.4 to i8
  store i8 %conv37.51.4, i8* %scevgep41.51.3, align 1
  %scevgep28.51.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12541, i64 0, i64 0, i64 1
  %12548 = bitcast i8* %scevgep28.51.4 to [61 x [61 x i8]]*
  %scevgep41.51.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12542, i64 0, i64 1, i64 0
  %12549 = bitcast i8* %scevgep41.51.4 to [61 x [61 x i8]]*
  %call16.51.5 = call zeroext i8 (...) @rand()
  store i8 %call16.51.5, i8* %scevgep28.51.4, align 1
  %12550 = load i8, i8* %scevgep28.51.4, align 1
  %conv23.51.5 = zext i8 %12550 to i32
  %12551 = load i8, i8* %arrayidx25.51, align 1
  %scevgep34.51.5 = getelementptr i8, i8* %b, i64 57
  %12552 = load i8, i8* %scevgep34.51.5, align 1
  %call28.51.5 = call zeroext i8 @mult(i8 zeroext %12551, i8 zeroext %12552)
  %conv29.51.5 = zext i8 %call28.51.5 to i32
  %xor.51.5 = xor i32 %conv23.51.5, %conv29.51.5
  %scevgep35.51.5 = getelementptr i8, i8* %a, i64 57
  %12553 = load i8, i8* %scevgep35.51.5, align 1
  %12554 = load i8, i8* %arrayidx33.51, align 1
  %call34.51.5 = call zeroext i8 @mult(i8 zeroext %12553, i8 zeroext %12554)
  %conv35.51.5 = zext i8 %call34.51.5 to i32
  %xor36.51.5 = xor i32 %xor.51.5, %conv35.51.5
  %conv37.51.5 = trunc i32 %xor36.51.5 to i8
  store i8 %conv37.51.5, i8* %scevgep41.51.4, align 1
  %scevgep28.51.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12548, i64 0, i64 0, i64 1
  %12555 = bitcast i8* %scevgep28.51.5 to [61 x [61 x i8]]*
  %scevgep41.51.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12549, i64 0, i64 1, i64 0
  %12556 = bitcast i8* %scevgep41.51.5 to [61 x [61 x i8]]*
  %call16.51.6 = call zeroext i8 (...) @rand()
  store i8 %call16.51.6, i8* %scevgep28.51.5, align 1
  %12557 = load i8, i8* %scevgep28.51.5, align 1
  %conv23.51.6 = zext i8 %12557 to i32
  %12558 = load i8, i8* %arrayidx25.51, align 1
  %scevgep34.51.6 = getelementptr i8, i8* %b, i64 58
  %12559 = load i8, i8* %scevgep34.51.6, align 1
  %call28.51.6 = call zeroext i8 @mult(i8 zeroext %12558, i8 zeroext %12559)
  %conv29.51.6 = zext i8 %call28.51.6 to i32
  %xor.51.6 = xor i32 %conv23.51.6, %conv29.51.6
  %scevgep35.51.6 = getelementptr i8, i8* %a, i64 58
  %12560 = load i8, i8* %scevgep35.51.6, align 1
  %12561 = load i8, i8* %arrayidx33.51, align 1
  %call34.51.6 = call zeroext i8 @mult(i8 zeroext %12560, i8 zeroext %12561)
  %conv35.51.6 = zext i8 %call34.51.6 to i32
  %xor36.51.6 = xor i32 %xor.51.6, %conv35.51.6
  %conv37.51.6 = trunc i32 %xor36.51.6 to i8
  store i8 %conv37.51.6, i8* %scevgep41.51.5, align 1
  %scevgep28.51.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12555, i64 0, i64 0, i64 1
  %12562 = bitcast i8* %scevgep28.51.6 to [61 x [61 x i8]]*
  %scevgep41.51.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12556, i64 0, i64 1, i64 0
  %12563 = bitcast i8* %scevgep41.51.6 to [61 x [61 x i8]]*
  %call16.51.7 = call zeroext i8 (...) @rand()
  store i8 %call16.51.7, i8* %scevgep28.51.6, align 1
  %12564 = load i8, i8* %scevgep28.51.6, align 1
  %conv23.51.7 = zext i8 %12564 to i32
  %12565 = load i8, i8* %arrayidx25.51, align 1
  %scevgep34.51.7 = getelementptr i8, i8* %b, i64 59
  %12566 = load i8, i8* %scevgep34.51.7, align 1
  %call28.51.7 = call zeroext i8 @mult(i8 zeroext %12565, i8 zeroext %12566)
  %conv29.51.7 = zext i8 %call28.51.7 to i32
  %xor.51.7 = xor i32 %conv23.51.7, %conv29.51.7
  %scevgep35.51.7 = getelementptr i8, i8* %a, i64 59
  %12567 = load i8, i8* %scevgep35.51.7, align 1
  %12568 = load i8, i8* %arrayidx33.51, align 1
  %call34.51.7 = call zeroext i8 @mult(i8 zeroext %12567, i8 zeroext %12568)
  %conv35.51.7 = zext i8 %call34.51.7 to i32
  %xor36.51.7 = xor i32 %xor.51.7, %conv35.51.7
  %conv37.51.7 = trunc i32 %xor36.51.7 to i8
  store i8 %conv37.51.7, i8* %scevgep41.51.6, align 1
  %scevgep28.51.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12562, i64 0, i64 0, i64 1
  %scevgep41.51.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12563, i64 0, i64 1, i64 0
  %call16.51.8 = call zeroext i8 (...) @rand()
  store i8 %call16.51.8, i8* %scevgep28.51.7, align 1
  %12569 = load i8, i8* %scevgep28.51.7, align 1
  %conv23.51.8 = zext i8 %12569 to i32
  %12570 = load i8, i8* %arrayidx25.51, align 1
  %scevgep34.51.8 = getelementptr i8, i8* %b, i64 60
  %12571 = load i8, i8* %scevgep34.51.8, align 1
  %call28.51.8 = call zeroext i8 @mult(i8 zeroext %12570, i8 zeroext %12571)
  %conv29.51.8 = zext i8 %call28.51.8 to i32
  %xor.51.8 = xor i32 %conv23.51.8, %conv29.51.8
  %scevgep35.51.8 = getelementptr i8, i8* %a, i64 60
  %12572 = load i8, i8* %scevgep35.51.8, align 1
  %12573 = load i8, i8* %arrayidx33.51, align 1
  %call34.51.8 = call zeroext i8 @mult(i8 zeroext %12572, i8 zeroext %12573)
  %conv35.51.8 = zext i8 %call34.51.8 to i32
  %xor36.51.8 = xor i32 %xor.51.8, %conv35.51.8
  %conv37.51.8 = trunc i32 %xor36.51.8 to i8
  store i8 %conv37.51.8, i8* %scevgep41.51.7, align 1
  %scevgep26.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12513, i64 0, i64 1, i64 1
  %12574 = bitcast i8* %scevgep26.51 to [61 x [61 x i8]]*
  %scevgep39.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12514, i64 0, i64 1, i64 1
  %12575 = bitcast i8* %scevgep39.51 to [61 x [61 x i8]]*
  %arrayidx25.52 = getelementptr inbounds i8, i8* %a, i64 52
  %arrayidx33.52 = getelementptr inbounds i8, i8* %b, i64 52
  %call16.52 = call zeroext i8 (...) @rand()
  store i8 %call16.52, i8* %scevgep26.51, align 1
  %12576 = load i8, i8* %scevgep26.51, align 1
  %conv23.52 = zext i8 %12576 to i32
  %12577 = load i8, i8* %arrayidx25.52, align 1
  %scevgep34.52 = getelementptr i8, i8* %b, i64 53
  %12578 = load i8, i8* %scevgep34.52, align 1
  %call28.52 = call zeroext i8 @mult(i8 zeroext %12577, i8 zeroext %12578)
  %conv29.52 = zext i8 %call28.52 to i32
  %xor.52 = xor i32 %conv23.52, %conv29.52
  %scevgep35.52 = getelementptr i8, i8* %a, i64 53
  %12579 = load i8, i8* %scevgep35.52, align 1
  %12580 = load i8, i8* %arrayidx33.52, align 1
  %call34.52 = call zeroext i8 @mult(i8 zeroext %12579, i8 zeroext %12580)
  %conv35.52 = zext i8 %call34.52 to i32
  %xor36.52 = xor i32 %xor.52, %conv35.52
  %conv37.52 = trunc i32 %xor36.52 to i8
  store i8 %conv37.52, i8* %scevgep39.51, align 1
  %scevgep28.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12574, i64 0, i64 0, i64 1
  %12581 = bitcast i8* %scevgep28.52 to [61 x [61 x i8]]*
  %scevgep41.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12575, i64 0, i64 1, i64 0
  %12582 = bitcast i8* %scevgep41.52 to [61 x [61 x i8]]*
  %call16.52.1 = call zeroext i8 (...) @rand()
  store i8 %call16.52.1, i8* %scevgep28.52, align 1
  %12583 = load i8, i8* %scevgep28.52, align 1
  %conv23.52.1 = zext i8 %12583 to i32
  %12584 = load i8, i8* %arrayidx25.52, align 1
  %scevgep34.52.1 = getelementptr i8, i8* %b, i64 54
  %12585 = load i8, i8* %scevgep34.52.1, align 1
  %call28.52.1 = call zeroext i8 @mult(i8 zeroext %12584, i8 zeroext %12585)
  %conv29.52.1 = zext i8 %call28.52.1 to i32
  %xor.52.1 = xor i32 %conv23.52.1, %conv29.52.1
  %scevgep35.52.1 = getelementptr i8, i8* %a, i64 54
  %12586 = load i8, i8* %scevgep35.52.1, align 1
  %12587 = load i8, i8* %arrayidx33.52, align 1
  %call34.52.1 = call zeroext i8 @mult(i8 zeroext %12586, i8 zeroext %12587)
  %conv35.52.1 = zext i8 %call34.52.1 to i32
  %xor36.52.1 = xor i32 %xor.52.1, %conv35.52.1
  %conv37.52.1 = trunc i32 %xor36.52.1 to i8
  store i8 %conv37.52.1, i8* %scevgep41.52, align 1
  %scevgep28.52.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12581, i64 0, i64 0, i64 1
  %12588 = bitcast i8* %scevgep28.52.1 to [61 x [61 x i8]]*
  %scevgep41.52.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12582, i64 0, i64 1, i64 0
  %12589 = bitcast i8* %scevgep41.52.1 to [61 x [61 x i8]]*
  %call16.52.2 = call zeroext i8 (...) @rand()
  store i8 %call16.52.2, i8* %scevgep28.52.1, align 1
  %12590 = load i8, i8* %scevgep28.52.1, align 1
  %conv23.52.2 = zext i8 %12590 to i32
  %12591 = load i8, i8* %arrayidx25.52, align 1
  %scevgep34.52.2 = getelementptr i8, i8* %b, i64 55
  %12592 = load i8, i8* %scevgep34.52.2, align 1
  %call28.52.2 = call zeroext i8 @mult(i8 zeroext %12591, i8 zeroext %12592)
  %conv29.52.2 = zext i8 %call28.52.2 to i32
  %xor.52.2 = xor i32 %conv23.52.2, %conv29.52.2
  %scevgep35.52.2 = getelementptr i8, i8* %a, i64 55
  %12593 = load i8, i8* %scevgep35.52.2, align 1
  %12594 = load i8, i8* %arrayidx33.52, align 1
  %call34.52.2 = call zeroext i8 @mult(i8 zeroext %12593, i8 zeroext %12594)
  %conv35.52.2 = zext i8 %call34.52.2 to i32
  %xor36.52.2 = xor i32 %xor.52.2, %conv35.52.2
  %conv37.52.2 = trunc i32 %xor36.52.2 to i8
  store i8 %conv37.52.2, i8* %scevgep41.52.1, align 1
  %scevgep28.52.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12588, i64 0, i64 0, i64 1
  %12595 = bitcast i8* %scevgep28.52.2 to [61 x [61 x i8]]*
  %scevgep41.52.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12589, i64 0, i64 1, i64 0
  %12596 = bitcast i8* %scevgep41.52.2 to [61 x [61 x i8]]*
  %call16.52.3 = call zeroext i8 (...) @rand()
  store i8 %call16.52.3, i8* %scevgep28.52.2, align 1
  %12597 = load i8, i8* %scevgep28.52.2, align 1
  %conv23.52.3 = zext i8 %12597 to i32
  %12598 = load i8, i8* %arrayidx25.52, align 1
  %scevgep34.52.3 = getelementptr i8, i8* %b, i64 56
  %12599 = load i8, i8* %scevgep34.52.3, align 1
  %call28.52.3 = call zeroext i8 @mult(i8 zeroext %12598, i8 zeroext %12599)
  %conv29.52.3 = zext i8 %call28.52.3 to i32
  %xor.52.3 = xor i32 %conv23.52.3, %conv29.52.3
  %scevgep35.52.3 = getelementptr i8, i8* %a, i64 56
  %12600 = load i8, i8* %scevgep35.52.3, align 1
  %12601 = load i8, i8* %arrayidx33.52, align 1
  %call34.52.3 = call zeroext i8 @mult(i8 zeroext %12600, i8 zeroext %12601)
  %conv35.52.3 = zext i8 %call34.52.3 to i32
  %xor36.52.3 = xor i32 %xor.52.3, %conv35.52.3
  %conv37.52.3 = trunc i32 %xor36.52.3 to i8
  store i8 %conv37.52.3, i8* %scevgep41.52.2, align 1
  %scevgep28.52.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12595, i64 0, i64 0, i64 1
  %12602 = bitcast i8* %scevgep28.52.3 to [61 x [61 x i8]]*
  %scevgep41.52.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12596, i64 0, i64 1, i64 0
  %12603 = bitcast i8* %scevgep41.52.3 to [61 x [61 x i8]]*
  %call16.52.4 = call zeroext i8 (...) @rand()
  store i8 %call16.52.4, i8* %scevgep28.52.3, align 1
  %12604 = load i8, i8* %scevgep28.52.3, align 1
  %conv23.52.4 = zext i8 %12604 to i32
  %12605 = load i8, i8* %arrayidx25.52, align 1
  %scevgep34.52.4 = getelementptr i8, i8* %b, i64 57
  %12606 = load i8, i8* %scevgep34.52.4, align 1
  %call28.52.4 = call zeroext i8 @mult(i8 zeroext %12605, i8 zeroext %12606)
  %conv29.52.4 = zext i8 %call28.52.4 to i32
  %xor.52.4 = xor i32 %conv23.52.4, %conv29.52.4
  %scevgep35.52.4 = getelementptr i8, i8* %a, i64 57
  %12607 = load i8, i8* %scevgep35.52.4, align 1
  %12608 = load i8, i8* %arrayidx33.52, align 1
  %call34.52.4 = call zeroext i8 @mult(i8 zeroext %12607, i8 zeroext %12608)
  %conv35.52.4 = zext i8 %call34.52.4 to i32
  %xor36.52.4 = xor i32 %xor.52.4, %conv35.52.4
  %conv37.52.4 = trunc i32 %xor36.52.4 to i8
  store i8 %conv37.52.4, i8* %scevgep41.52.3, align 1
  %scevgep28.52.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12602, i64 0, i64 0, i64 1
  %12609 = bitcast i8* %scevgep28.52.4 to [61 x [61 x i8]]*
  %scevgep41.52.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12603, i64 0, i64 1, i64 0
  %12610 = bitcast i8* %scevgep41.52.4 to [61 x [61 x i8]]*
  %call16.52.5 = call zeroext i8 (...) @rand()
  store i8 %call16.52.5, i8* %scevgep28.52.4, align 1
  %12611 = load i8, i8* %scevgep28.52.4, align 1
  %conv23.52.5 = zext i8 %12611 to i32
  %12612 = load i8, i8* %arrayidx25.52, align 1
  %scevgep34.52.5 = getelementptr i8, i8* %b, i64 58
  %12613 = load i8, i8* %scevgep34.52.5, align 1
  %call28.52.5 = call zeroext i8 @mult(i8 zeroext %12612, i8 zeroext %12613)
  %conv29.52.5 = zext i8 %call28.52.5 to i32
  %xor.52.5 = xor i32 %conv23.52.5, %conv29.52.5
  %scevgep35.52.5 = getelementptr i8, i8* %a, i64 58
  %12614 = load i8, i8* %scevgep35.52.5, align 1
  %12615 = load i8, i8* %arrayidx33.52, align 1
  %call34.52.5 = call zeroext i8 @mult(i8 zeroext %12614, i8 zeroext %12615)
  %conv35.52.5 = zext i8 %call34.52.5 to i32
  %xor36.52.5 = xor i32 %xor.52.5, %conv35.52.5
  %conv37.52.5 = trunc i32 %xor36.52.5 to i8
  store i8 %conv37.52.5, i8* %scevgep41.52.4, align 1
  %scevgep28.52.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12609, i64 0, i64 0, i64 1
  %12616 = bitcast i8* %scevgep28.52.5 to [61 x [61 x i8]]*
  %scevgep41.52.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12610, i64 0, i64 1, i64 0
  %12617 = bitcast i8* %scevgep41.52.5 to [61 x [61 x i8]]*
  %call16.52.6 = call zeroext i8 (...) @rand()
  store i8 %call16.52.6, i8* %scevgep28.52.5, align 1
  %12618 = load i8, i8* %scevgep28.52.5, align 1
  %conv23.52.6 = zext i8 %12618 to i32
  %12619 = load i8, i8* %arrayidx25.52, align 1
  %scevgep34.52.6 = getelementptr i8, i8* %b, i64 59
  %12620 = load i8, i8* %scevgep34.52.6, align 1
  %call28.52.6 = call zeroext i8 @mult(i8 zeroext %12619, i8 zeroext %12620)
  %conv29.52.6 = zext i8 %call28.52.6 to i32
  %xor.52.6 = xor i32 %conv23.52.6, %conv29.52.6
  %scevgep35.52.6 = getelementptr i8, i8* %a, i64 59
  %12621 = load i8, i8* %scevgep35.52.6, align 1
  %12622 = load i8, i8* %arrayidx33.52, align 1
  %call34.52.6 = call zeroext i8 @mult(i8 zeroext %12621, i8 zeroext %12622)
  %conv35.52.6 = zext i8 %call34.52.6 to i32
  %xor36.52.6 = xor i32 %xor.52.6, %conv35.52.6
  %conv37.52.6 = trunc i32 %xor36.52.6 to i8
  store i8 %conv37.52.6, i8* %scevgep41.52.5, align 1
  %scevgep28.52.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12616, i64 0, i64 0, i64 1
  %scevgep41.52.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12617, i64 0, i64 1, i64 0
  %call16.52.7 = call zeroext i8 (...) @rand()
  store i8 %call16.52.7, i8* %scevgep28.52.6, align 1
  %12623 = load i8, i8* %scevgep28.52.6, align 1
  %conv23.52.7 = zext i8 %12623 to i32
  %12624 = load i8, i8* %arrayidx25.52, align 1
  %scevgep34.52.7 = getelementptr i8, i8* %b, i64 60
  %12625 = load i8, i8* %scevgep34.52.7, align 1
  %call28.52.7 = call zeroext i8 @mult(i8 zeroext %12624, i8 zeroext %12625)
  %conv29.52.7 = zext i8 %call28.52.7 to i32
  %xor.52.7 = xor i32 %conv23.52.7, %conv29.52.7
  %scevgep35.52.7 = getelementptr i8, i8* %a, i64 60
  %12626 = load i8, i8* %scevgep35.52.7, align 1
  %12627 = load i8, i8* %arrayidx33.52, align 1
  %call34.52.7 = call zeroext i8 @mult(i8 zeroext %12626, i8 zeroext %12627)
  %conv35.52.7 = zext i8 %call34.52.7 to i32
  %xor36.52.7 = xor i32 %xor.52.7, %conv35.52.7
  %conv37.52.7 = trunc i32 %xor36.52.7 to i8
  store i8 %conv37.52.7, i8* %scevgep41.52.6, align 1
  %scevgep26.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12574, i64 0, i64 1, i64 1
  %12628 = bitcast i8* %scevgep26.52 to [61 x [61 x i8]]*
  %scevgep39.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12575, i64 0, i64 1, i64 1
  %12629 = bitcast i8* %scevgep39.52 to [61 x [61 x i8]]*
  %arrayidx25.53 = getelementptr inbounds i8, i8* %a, i64 53
  %arrayidx33.53 = getelementptr inbounds i8, i8* %b, i64 53
  %call16.53 = call zeroext i8 (...) @rand()
  store i8 %call16.53, i8* %scevgep26.52, align 1
  %12630 = load i8, i8* %scevgep26.52, align 1
  %conv23.53 = zext i8 %12630 to i32
  %12631 = load i8, i8* %arrayidx25.53, align 1
  %scevgep34.53 = getelementptr i8, i8* %b, i64 54
  %12632 = load i8, i8* %scevgep34.53, align 1
  %call28.53 = call zeroext i8 @mult(i8 zeroext %12631, i8 zeroext %12632)
  %conv29.53 = zext i8 %call28.53 to i32
  %xor.53 = xor i32 %conv23.53, %conv29.53
  %scevgep35.53 = getelementptr i8, i8* %a, i64 54
  %12633 = load i8, i8* %scevgep35.53, align 1
  %12634 = load i8, i8* %arrayidx33.53, align 1
  %call34.53 = call zeroext i8 @mult(i8 zeroext %12633, i8 zeroext %12634)
  %conv35.53 = zext i8 %call34.53 to i32
  %xor36.53 = xor i32 %xor.53, %conv35.53
  %conv37.53 = trunc i32 %xor36.53 to i8
  store i8 %conv37.53, i8* %scevgep39.52, align 1
  %scevgep28.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12628, i64 0, i64 0, i64 1
  %12635 = bitcast i8* %scevgep28.53 to [61 x [61 x i8]]*
  %scevgep41.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12629, i64 0, i64 1, i64 0
  %12636 = bitcast i8* %scevgep41.53 to [61 x [61 x i8]]*
  %call16.53.1 = call zeroext i8 (...) @rand()
  store i8 %call16.53.1, i8* %scevgep28.53, align 1
  %12637 = load i8, i8* %scevgep28.53, align 1
  %conv23.53.1 = zext i8 %12637 to i32
  %12638 = load i8, i8* %arrayidx25.53, align 1
  %scevgep34.53.1 = getelementptr i8, i8* %b, i64 55
  %12639 = load i8, i8* %scevgep34.53.1, align 1
  %call28.53.1 = call zeroext i8 @mult(i8 zeroext %12638, i8 zeroext %12639)
  %conv29.53.1 = zext i8 %call28.53.1 to i32
  %xor.53.1 = xor i32 %conv23.53.1, %conv29.53.1
  %scevgep35.53.1 = getelementptr i8, i8* %a, i64 55
  %12640 = load i8, i8* %scevgep35.53.1, align 1
  %12641 = load i8, i8* %arrayidx33.53, align 1
  %call34.53.1 = call zeroext i8 @mult(i8 zeroext %12640, i8 zeroext %12641)
  %conv35.53.1 = zext i8 %call34.53.1 to i32
  %xor36.53.1 = xor i32 %xor.53.1, %conv35.53.1
  %conv37.53.1 = trunc i32 %xor36.53.1 to i8
  store i8 %conv37.53.1, i8* %scevgep41.53, align 1
  %scevgep28.53.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12635, i64 0, i64 0, i64 1
  %12642 = bitcast i8* %scevgep28.53.1 to [61 x [61 x i8]]*
  %scevgep41.53.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12636, i64 0, i64 1, i64 0
  %12643 = bitcast i8* %scevgep41.53.1 to [61 x [61 x i8]]*
  %call16.53.2 = call zeroext i8 (...) @rand()
  store i8 %call16.53.2, i8* %scevgep28.53.1, align 1
  %12644 = load i8, i8* %scevgep28.53.1, align 1
  %conv23.53.2 = zext i8 %12644 to i32
  %12645 = load i8, i8* %arrayidx25.53, align 1
  %scevgep34.53.2 = getelementptr i8, i8* %b, i64 56
  %12646 = load i8, i8* %scevgep34.53.2, align 1
  %call28.53.2 = call zeroext i8 @mult(i8 zeroext %12645, i8 zeroext %12646)
  %conv29.53.2 = zext i8 %call28.53.2 to i32
  %xor.53.2 = xor i32 %conv23.53.2, %conv29.53.2
  %scevgep35.53.2 = getelementptr i8, i8* %a, i64 56
  %12647 = load i8, i8* %scevgep35.53.2, align 1
  %12648 = load i8, i8* %arrayidx33.53, align 1
  %call34.53.2 = call zeroext i8 @mult(i8 zeroext %12647, i8 zeroext %12648)
  %conv35.53.2 = zext i8 %call34.53.2 to i32
  %xor36.53.2 = xor i32 %xor.53.2, %conv35.53.2
  %conv37.53.2 = trunc i32 %xor36.53.2 to i8
  store i8 %conv37.53.2, i8* %scevgep41.53.1, align 1
  %scevgep28.53.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12642, i64 0, i64 0, i64 1
  %12649 = bitcast i8* %scevgep28.53.2 to [61 x [61 x i8]]*
  %scevgep41.53.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12643, i64 0, i64 1, i64 0
  %12650 = bitcast i8* %scevgep41.53.2 to [61 x [61 x i8]]*
  %call16.53.3 = call zeroext i8 (...) @rand()
  store i8 %call16.53.3, i8* %scevgep28.53.2, align 1
  %12651 = load i8, i8* %scevgep28.53.2, align 1
  %conv23.53.3 = zext i8 %12651 to i32
  %12652 = load i8, i8* %arrayidx25.53, align 1
  %scevgep34.53.3 = getelementptr i8, i8* %b, i64 57
  %12653 = load i8, i8* %scevgep34.53.3, align 1
  %call28.53.3 = call zeroext i8 @mult(i8 zeroext %12652, i8 zeroext %12653)
  %conv29.53.3 = zext i8 %call28.53.3 to i32
  %xor.53.3 = xor i32 %conv23.53.3, %conv29.53.3
  %scevgep35.53.3 = getelementptr i8, i8* %a, i64 57
  %12654 = load i8, i8* %scevgep35.53.3, align 1
  %12655 = load i8, i8* %arrayidx33.53, align 1
  %call34.53.3 = call zeroext i8 @mult(i8 zeroext %12654, i8 zeroext %12655)
  %conv35.53.3 = zext i8 %call34.53.3 to i32
  %xor36.53.3 = xor i32 %xor.53.3, %conv35.53.3
  %conv37.53.3 = trunc i32 %xor36.53.3 to i8
  store i8 %conv37.53.3, i8* %scevgep41.53.2, align 1
  %scevgep28.53.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12649, i64 0, i64 0, i64 1
  %12656 = bitcast i8* %scevgep28.53.3 to [61 x [61 x i8]]*
  %scevgep41.53.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12650, i64 0, i64 1, i64 0
  %12657 = bitcast i8* %scevgep41.53.3 to [61 x [61 x i8]]*
  %call16.53.4 = call zeroext i8 (...) @rand()
  store i8 %call16.53.4, i8* %scevgep28.53.3, align 1
  %12658 = load i8, i8* %scevgep28.53.3, align 1
  %conv23.53.4 = zext i8 %12658 to i32
  %12659 = load i8, i8* %arrayidx25.53, align 1
  %scevgep34.53.4 = getelementptr i8, i8* %b, i64 58
  %12660 = load i8, i8* %scevgep34.53.4, align 1
  %call28.53.4 = call zeroext i8 @mult(i8 zeroext %12659, i8 zeroext %12660)
  %conv29.53.4 = zext i8 %call28.53.4 to i32
  %xor.53.4 = xor i32 %conv23.53.4, %conv29.53.4
  %scevgep35.53.4 = getelementptr i8, i8* %a, i64 58
  %12661 = load i8, i8* %scevgep35.53.4, align 1
  %12662 = load i8, i8* %arrayidx33.53, align 1
  %call34.53.4 = call zeroext i8 @mult(i8 zeroext %12661, i8 zeroext %12662)
  %conv35.53.4 = zext i8 %call34.53.4 to i32
  %xor36.53.4 = xor i32 %xor.53.4, %conv35.53.4
  %conv37.53.4 = trunc i32 %xor36.53.4 to i8
  store i8 %conv37.53.4, i8* %scevgep41.53.3, align 1
  %scevgep28.53.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12656, i64 0, i64 0, i64 1
  %12663 = bitcast i8* %scevgep28.53.4 to [61 x [61 x i8]]*
  %scevgep41.53.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12657, i64 0, i64 1, i64 0
  %12664 = bitcast i8* %scevgep41.53.4 to [61 x [61 x i8]]*
  %call16.53.5 = call zeroext i8 (...) @rand()
  store i8 %call16.53.5, i8* %scevgep28.53.4, align 1
  %12665 = load i8, i8* %scevgep28.53.4, align 1
  %conv23.53.5 = zext i8 %12665 to i32
  %12666 = load i8, i8* %arrayidx25.53, align 1
  %scevgep34.53.5 = getelementptr i8, i8* %b, i64 59
  %12667 = load i8, i8* %scevgep34.53.5, align 1
  %call28.53.5 = call zeroext i8 @mult(i8 zeroext %12666, i8 zeroext %12667)
  %conv29.53.5 = zext i8 %call28.53.5 to i32
  %xor.53.5 = xor i32 %conv23.53.5, %conv29.53.5
  %scevgep35.53.5 = getelementptr i8, i8* %a, i64 59
  %12668 = load i8, i8* %scevgep35.53.5, align 1
  %12669 = load i8, i8* %arrayidx33.53, align 1
  %call34.53.5 = call zeroext i8 @mult(i8 zeroext %12668, i8 zeroext %12669)
  %conv35.53.5 = zext i8 %call34.53.5 to i32
  %xor36.53.5 = xor i32 %xor.53.5, %conv35.53.5
  %conv37.53.5 = trunc i32 %xor36.53.5 to i8
  store i8 %conv37.53.5, i8* %scevgep41.53.4, align 1
  %scevgep28.53.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12663, i64 0, i64 0, i64 1
  %scevgep41.53.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12664, i64 0, i64 1, i64 0
  %call16.53.6 = call zeroext i8 (...) @rand()
  store i8 %call16.53.6, i8* %scevgep28.53.5, align 1
  %12670 = load i8, i8* %scevgep28.53.5, align 1
  %conv23.53.6 = zext i8 %12670 to i32
  %12671 = load i8, i8* %arrayidx25.53, align 1
  %scevgep34.53.6 = getelementptr i8, i8* %b, i64 60
  %12672 = load i8, i8* %scevgep34.53.6, align 1
  %call28.53.6 = call zeroext i8 @mult(i8 zeroext %12671, i8 zeroext %12672)
  %conv29.53.6 = zext i8 %call28.53.6 to i32
  %xor.53.6 = xor i32 %conv23.53.6, %conv29.53.6
  %scevgep35.53.6 = getelementptr i8, i8* %a, i64 60
  %12673 = load i8, i8* %scevgep35.53.6, align 1
  %12674 = load i8, i8* %arrayidx33.53, align 1
  %call34.53.6 = call zeroext i8 @mult(i8 zeroext %12673, i8 zeroext %12674)
  %conv35.53.6 = zext i8 %call34.53.6 to i32
  %xor36.53.6 = xor i32 %xor.53.6, %conv35.53.6
  %conv37.53.6 = trunc i32 %xor36.53.6 to i8
  store i8 %conv37.53.6, i8* %scevgep41.53.5, align 1
  %scevgep26.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12628, i64 0, i64 1, i64 1
  %12675 = bitcast i8* %scevgep26.53 to [61 x [61 x i8]]*
  %scevgep39.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12629, i64 0, i64 1, i64 1
  %12676 = bitcast i8* %scevgep39.53 to [61 x [61 x i8]]*
  %arrayidx25.54 = getelementptr inbounds i8, i8* %a, i64 54
  %arrayidx33.54 = getelementptr inbounds i8, i8* %b, i64 54
  %call16.54 = call zeroext i8 (...) @rand()
  store i8 %call16.54, i8* %scevgep26.53, align 1
  %12677 = load i8, i8* %scevgep26.53, align 1
  %conv23.54 = zext i8 %12677 to i32
  %12678 = load i8, i8* %arrayidx25.54, align 1
  %scevgep34.54 = getelementptr i8, i8* %b, i64 55
  %12679 = load i8, i8* %scevgep34.54, align 1
  %call28.54 = call zeroext i8 @mult(i8 zeroext %12678, i8 zeroext %12679)
  %conv29.54 = zext i8 %call28.54 to i32
  %xor.54 = xor i32 %conv23.54, %conv29.54
  %scevgep35.54 = getelementptr i8, i8* %a, i64 55
  %12680 = load i8, i8* %scevgep35.54, align 1
  %12681 = load i8, i8* %arrayidx33.54, align 1
  %call34.54 = call zeroext i8 @mult(i8 zeroext %12680, i8 zeroext %12681)
  %conv35.54 = zext i8 %call34.54 to i32
  %xor36.54 = xor i32 %xor.54, %conv35.54
  %conv37.54 = trunc i32 %xor36.54 to i8
  store i8 %conv37.54, i8* %scevgep39.53, align 1
  %scevgep28.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12675, i64 0, i64 0, i64 1
  %12682 = bitcast i8* %scevgep28.54 to [61 x [61 x i8]]*
  %scevgep41.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12676, i64 0, i64 1, i64 0
  %12683 = bitcast i8* %scevgep41.54 to [61 x [61 x i8]]*
  %call16.54.1 = call zeroext i8 (...) @rand()
  store i8 %call16.54.1, i8* %scevgep28.54, align 1
  %12684 = load i8, i8* %scevgep28.54, align 1
  %conv23.54.1 = zext i8 %12684 to i32
  %12685 = load i8, i8* %arrayidx25.54, align 1
  %scevgep34.54.1 = getelementptr i8, i8* %b, i64 56
  %12686 = load i8, i8* %scevgep34.54.1, align 1
  %call28.54.1 = call zeroext i8 @mult(i8 zeroext %12685, i8 zeroext %12686)
  %conv29.54.1 = zext i8 %call28.54.1 to i32
  %xor.54.1 = xor i32 %conv23.54.1, %conv29.54.1
  %scevgep35.54.1 = getelementptr i8, i8* %a, i64 56
  %12687 = load i8, i8* %scevgep35.54.1, align 1
  %12688 = load i8, i8* %arrayidx33.54, align 1
  %call34.54.1 = call zeroext i8 @mult(i8 zeroext %12687, i8 zeroext %12688)
  %conv35.54.1 = zext i8 %call34.54.1 to i32
  %xor36.54.1 = xor i32 %xor.54.1, %conv35.54.1
  %conv37.54.1 = trunc i32 %xor36.54.1 to i8
  store i8 %conv37.54.1, i8* %scevgep41.54, align 1
  %scevgep28.54.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12682, i64 0, i64 0, i64 1
  %12689 = bitcast i8* %scevgep28.54.1 to [61 x [61 x i8]]*
  %scevgep41.54.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12683, i64 0, i64 1, i64 0
  %12690 = bitcast i8* %scevgep41.54.1 to [61 x [61 x i8]]*
  %call16.54.2 = call zeroext i8 (...) @rand()
  store i8 %call16.54.2, i8* %scevgep28.54.1, align 1
  %12691 = load i8, i8* %scevgep28.54.1, align 1
  %conv23.54.2 = zext i8 %12691 to i32
  %12692 = load i8, i8* %arrayidx25.54, align 1
  %scevgep34.54.2 = getelementptr i8, i8* %b, i64 57
  %12693 = load i8, i8* %scevgep34.54.2, align 1
  %call28.54.2 = call zeroext i8 @mult(i8 zeroext %12692, i8 zeroext %12693)
  %conv29.54.2 = zext i8 %call28.54.2 to i32
  %xor.54.2 = xor i32 %conv23.54.2, %conv29.54.2
  %scevgep35.54.2 = getelementptr i8, i8* %a, i64 57
  %12694 = load i8, i8* %scevgep35.54.2, align 1
  %12695 = load i8, i8* %arrayidx33.54, align 1
  %call34.54.2 = call zeroext i8 @mult(i8 zeroext %12694, i8 zeroext %12695)
  %conv35.54.2 = zext i8 %call34.54.2 to i32
  %xor36.54.2 = xor i32 %xor.54.2, %conv35.54.2
  %conv37.54.2 = trunc i32 %xor36.54.2 to i8
  store i8 %conv37.54.2, i8* %scevgep41.54.1, align 1
  %scevgep28.54.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12689, i64 0, i64 0, i64 1
  %12696 = bitcast i8* %scevgep28.54.2 to [61 x [61 x i8]]*
  %scevgep41.54.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12690, i64 0, i64 1, i64 0
  %12697 = bitcast i8* %scevgep41.54.2 to [61 x [61 x i8]]*
  %call16.54.3 = call zeroext i8 (...) @rand()
  store i8 %call16.54.3, i8* %scevgep28.54.2, align 1
  %12698 = load i8, i8* %scevgep28.54.2, align 1
  %conv23.54.3 = zext i8 %12698 to i32
  %12699 = load i8, i8* %arrayidx25.54, align 1
  %scevgep34.54.3 = getelementptr i8, i8* %b, i64 58
  %12700 = load i8, i8* %scevgep34.54.3, align 1
  %call28.54.3 = call zeroext i8 @mult(i8 zeroext %12699, i8 zeroext %12700)
  %conv29.54.3 = zext i8 %call28.54.3 to i32
  %xor.54.3 = xor i32 %conv23.54.3, %conv29.54.3
  %scevgep35.54.3 = getelementptr i8, i8* %a, i64 58
  %12701 = load i8, i8* %scevgep35.54.3, align 1
  %12702 = load i8, i8* %arrayidx33.54, align 1
  %call34.54.3 = call zeroext i8 @mult(i8 zeroext %12701, i8 zeroext %12702)
  %conv35.54.3 = zext i8 %call34.54.3 to i32
  %xor36.54.3 = xor i32 %xor.54.3, %conv35.54.3
  %conv37.54.3 = trunc i32 %xor36.54.3 to i8
  store i8 %conv37.54.3, i8* %scevgep41.54.2, align 1
  %scevgep28.54.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12696, i64 0, i64 0, i64 1
  %12703 = bitcast i8* %scevgep28.54.3 to [61 x [61 x i8]]*
  %scevgep41.54.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12697, i64 0, i64 1, i64 0
  %12704 = bitcast i8* %scevgep41.54.3 to [61 x [61 x i8]]*
  %call16.54.4 = call zeroext i8 (...) @rand()
  store i8 %call16.54.4, i8* %scevgep28.54.3, align 1
  %12705 = load i8, i8* %scevgep28.54.3, align 1
  %conv23.54.4 = zext i8 %12705 to i32
  %12706 = load i8, i8* %arrayidx25.54, align 1
  %scevgep34.54.4 = getelementptr i8, i8* %b, i64 59
  %12707 = load i8, i8* %scevgep34.54.4, align 1
  %call28.54.4 = call zeroext i8 @mult(i8 zeroext %12706, i8 zeroext %12707)
  %conv29.54.4 = zext i8 %call28.54.4 to i32
  %xor.54.4 = xor i32 %conv23.54.4, %conv29.54.4
  %scevgep35.54.4 = getelementptr i8, i8* %a, i64 59
  %12708 = load i8, i8* %scevgep35.54.4, align 1
  %12709 = load i8, i8* %arrayidx33.54, align 1
  %call34.54.4 = call zeroext i8 @mult(i8 zeroext %12708, i8 zeroext %12709)
  %conv35.54.4 = zext i8 %call34.54.4 to i32
  %xor36.54.4 = xor i32 %xor.54.4, %conv35.54.4
  %conv37.54.4 = trunc i32 %xor36.54.4 to i8
  store i8 %conv37.54.4, i8* %scevgep41.54.3, align 1
  %scevgep28.54.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12703, i64 0, i64 0, i64 1
  %scevgep41.54.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12704, i64 0, i64 1, i64 0
  %call16.54.5 = call zeroext i8 (...) @rand()
  store i8 %call16.54.5, i8* %scevgep28.54.4, align 1
  %12710 = load i8, i8* %scevgep28.54.4, align 1
  %conv23.54.5 = zext i8 %12710 to i32
  %12711 = load i8, i8* %arrayidx25.54, align 1
  %scevgep34.54.5 = getelementptr i8, i8* %b, i64 60
  %12712 = load i8, i8* %scevgep34.54.5, align 1
  %call28.54.5 = call zeroext i8 @mult(i8 zeroext %12711, i8 zeroext %12712)
  %conv29.54.5 = zext i8 %call28.54.5 to i32
  %xor.54.5 = xor i32 %conv23.54.5, %conv29.54.5
  %scevgep35.54.5 = getelementptr i8, i8* %a, i64 60
  %12713 = load i8, i8* %scevgep35.54.5, align 1
  %12714 = load i8, i8* %arrayidx33.54, align 1
  %call34.54.5 = call zeroext i8 @mult(i8 zeroext %12713, i8 zeroext %12714)
  %conv35.54.5 = zext i8 %call34.54.5 to i32
  %xor36.54.5 = xor i32 %xor.54.5, %conv35.54.5
  %conv37.54.5 = trunc i32 %xor36.54.5 to i8
  store i8 %conv37.54.5, i8* %scevgep41.54.4, align 1
  %scevgep26.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12675, i64 0, i64 1, i64 1
  %12715 = bitcast i8* %scevgep26.54 to [61 x [61 x i8]]*
  %scevgep39.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12676, i64 0, i64 1, i64 1
  %12716 = bitcast i8* %scevgep39.54 to [61 x [61 x i8]]*
  %arrayidx25.55 = getelementptr inbounds i8, i8* %a, i64 55
  %arrayidx33.55 = getelementptr inbounds i8, i8* %b, i64 55
  %call16.55 = call zeroext i8 (...) @rand()
  store i8 %call16.55, i8* %scevgep26.54, align 1
  %12717 = load i8, i8* %scevgep26.54, align 1
  %conv23.55 = zext i8 %12717 to i32
  %12718 = load i8, i8* %arrayidx25.55, align 1
  %scevgep34.55 = getelementptr i8, i8* %b, i64 56
  %12719 = load i8, i8* %scevgep34.55, align 1
  %call28.55 = call zeroext i8 @mult(i8 zeroext %12718, i8 zeroext %12719)
  %conv29.55 = zext i8 %call28.55 to i32
  %xor.55 = xor i32 %conv23.55, %conv29.55
  %scevgep35.55 = getelementptr i8, i8* %a, i64 56
  %12720 = load i8, i8* %scevgep35.55, align 1
  %12721 = load i8, i8* %arrayidx33.55, align 1
  %call34.55 = call zeroext i8 @mult(i8 zeroext %12720, i8 zeroext %12721)
  %conv35.55 = zext i8 %call34.55 to i32
  %xor36.55 = xor i32 %xor.55, %conv35.55
  %conv37.55 = trunc i32 %xor36.55 to i8
  store i8 %conv37.55, i8* %scevgep39.54, align 1
  %scevgep28.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12715, i64 0, i64 0, i64 1
  %12722 = bitcast i8* %scevgep28.55 to [61 x [61 x i8]]*
  %scevgep41.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12716, i64 0, i64 1, i64 0
  %12723 = bitcast i8* %scevgep41.55 to [61 x [61 x i8]]*
  %call16.55.1 = call zeroext i8 (...) @rand()
  store i8 %call16.55.1, i8* %scevgep28.55, align 1
  %12724 = load i8, i8* %scevgep28.55, align 1
  %conv23.55.1 = zext i8 %12724 to i32
  %12725 = load i8, i8* %arrayidx25.55, align 1
  %scevgep34.55.1 = getelementptr i8, i8* %b, i64 57
  %12726 = load i8, i8* %scevgep34.55.1, align 1
  %call28.55.1 = call zeroext i8 @mult(i8 zeroext %12725, i8 zeroext %12726)
  %conv29.55.1 = zext i8 %call28.55.1 to i32
  %xor.55.1 = xor i32 %conv23.55.1, %conv29.55.1
  %scevgep35.55.1 = getelementptr i8, i8* %a, i64 57
  %12727 = load i8, i8* %scevgep35.55.1, align 1
  %12728 = load i8, i8* %arrayidx33.55, align 1
  %call34.55.1 = call zeroext i8 @mult(i8 zeroext %12727, i8 zeroext %12728)
  %conv35.55.1 = zext i8 %call34.55.1 to i32
  %xor36.55.1 = xor i32 %xor.55.1, %conv35.55.1
  %conv37.55.1 = trunc i32 %xor36.55.1 to i8
  store i8 %conv37.55.1, i8* %scevgep41.55, align 1
  %scevgep28.55.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12722, i64 0, i64 0, i64 1
  %12729 = bitcast i8* %scevgep28.55.1 to [61 x [61 x i8]]*
  %scevgep41.55.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12723, i64 0, i64 1, i64 0
  %12730 = bitcast i8* %scevgep41.55.1 to [61 x [61 x i8]]*
  %call16.55.2 = call zeroext i8 (...) @rand()
  store i8 %call16.55.2, i8* %scevgep28.55.1, align 1
  %12731 = load i8, i8* %scevgep28.55.1, align 1
  %conv23.55.2 = zext i8 %12731 to i32
  %12732 = load i8, i8* %arrayidx25.55, align 1
  %scevgep34.55.2 = getelementptr i8, i8* %b, i64 58
  %12733 = load i8, i8* %scevgep34.55.2, align 1
  %call28.55.2 = call zeroext i8 @mult(i8 zeroext %12732, i8 zeroext %12733)
  %conv29.55.2 = zext i8 %call28.55.2 to i32
  %xor.55.2 = xor i32 %conv23.55.2, %conv29.55.2
  %scevgep35.55.2 = getelementptr i8, i8* %a, i64 58
  %12734 = load i8, i8* %scevgep35.55.2, align 1
  %12735 = load i8, i8* %arrayidx33.55, align 1
  %call34.55.2 = call zeroext i8 @mult(i8 zeroext %12734, i8 zeroext %12735)
  %conv35.55.2 = zext i8 %call34.55.2 to i32
  %xor36.55.2 = xor i32 %xor.55.2, %conv35.55.2
  %conv37.55.2 = trunc i32 %xor36.55.2 to i8
  store i8 %conv37.55.2, i8* %scevgep41.55.1, align 1
  %scevgep28.55.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12729, i64 0, i64 0, i64 1
  %12736 = bitcast i8* %scevgep28.55.2 to [61 x [61 x i8]]*
  %scevgep41.55.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12730, i64 0, i64 1, i64 0
  %12737 = bitcast i8* %scevgep41.55.2 to [61 x [61 x i8]]*
  %call16.55.3 = call zeroext i8 (...) @rand()
  store i8 %call16.55.3, i8* %scevgep28.55.2, align 1
  %12738 = load i8, i8* %scevgep28.55.2, align 1
  %conv23.55.3 = zext i8 %12738 to i32
  %12739 = load i8, i8* %arrayidx25.55, align 1
  %scevgep34.55.3 = getelementptr i8, i8* %b, i64 59
  %12740 = load i8, i8* %scevgep34.55.3, align 1
  %call28.55.3 = call zeroext i8 @mult(i8 zeroext %12739, i8 zeroext %12740)
  %conv29.55.3 = zext i8 %call28.55.3 to i32
  %xor.55.3 = xor i32 %conv23.55.3, %conv29.55.3
  %scevgep35.55.3 = getelementptr i8, i8* %a, i64 59
  %12741 = load i8, i8* %scevgep35.55.3, align 1
  %12742 = load i8, i8* %arrayidx33.55, align 1
  %call34.55.3 = call zeroext i8 @mult(i8 zeroext %12741, i8 zeroext %12742)
  %conv35.55.3 = zext i8 %call34.55.3 to i32
  %xor36.55.3 = xor i32 %xor.55.3, %conv35.55.3
  %conv37.55.3 = trunc i32 %xor36.55.3 to i8
  store i8 %conv37.55.3, i8* %scevgep41.55.2, align 1
  %scevgep28.55.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12736, i64 0, i64 0, i64 1
  %scevgep41.55.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12737, i64 0, i64 1, i64 0
  %call16.55.4 = call zeroext i8 (...) @rand()
  store i8 %call16.55.4, i8* %scevgep28.55.3, align 1
  %12743 = load i8, i8* %scevgep28.55.3, align 1
  %conv23.55.4 = zext i8 %12743 to i32
  %12744 = load i8, i8* %arrayidx25.55, align 1
  %scevgep34.55.4 = getelementptr i8, i8* %b, i64 60
  %12745 = load i8, i8* %scevgep34.55.4, align 1
  %call28.55.4 = call zeroext i8 @mult(i8 zeroext %12744, i8 zeroext %12745)
  %conv29.55.4 = zext i8 %call28.55.4 to i32
  %xor.55.4 = xor i32 %conv23.55.4, %conv29.55.4
  %scevgep35.55.4 = getelementptr i8, i8* %a, i64 60
  %12746 = load i8, i8* %scevgep35.55.4, align 1
  %12747 = load i8, i8* %arrayidx33.55, align 1
  %call34.55.4 = call zeroext i8 @mult(i8 zeroext %12746, i8 zeroext %12747)
  %conv35.55.4 = zext i8 %call34.55.4 to i32
  %xor36.55.4 = xor i32 %xor.55.4, %conv35.55.4
  %conv37.55.4 = trunc i32 %xor36.55.4 to i8
  store i8 %conv37.55.4, i8* %scevgep41.55.3, align 1
  %scevgep26.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12715, i64 0, i64 1, i64 1
  %12748 = bitcast i8* %scevgep26.55 to [61 x [61 x i8]]*
  %scevgep39.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12716, i64 0, i64 1, i64 1
  %12749 = bitcast i8* %scevgep39.55 to [61 x [61 x i8]]*
  %arrayidx25.56 = getelementptr inbounds i8, i8* %a, i64 56
  %arrayidx33.56 = getelementptr inbounds i8, i8* %b, i64 56
  %call16.56 = call zeroext i8 (...) @rand()
  store i8 %call16.56, i8* %scevgep26.55, align 1
  %12750 = load i8, i8* %scevgep26.55, align 1
  %conv23.56 = zext i8 %12750 to i32
  %12751 = load i8, i8* %arrayidx25.56, align 1
  %scevgep34.56 = getelementptr i8, i8* %b, i64 57
  %12752 = load i8, i8* %scevgep34.56, align 1
  %call28.56 = call zeroext i8 @mult(i8 zeroext %12751, i8 zeroext %12752)
  %conv29.56 = zext i8 %call28.56 to i32
  %xor.56 = xor i32 %conv23.56, %conv29.56
  %scevgep35.56 = getelementptr i8, i8* %a, i64 57
  %12753 = load i8, i8* %scevgep35.56, align 1
  %12754 = load i8, i8* %arrayidx33.56, align 1
  %call34.56 = call zeroext i8 @mult(i8 zeroext %12753, i8 zeroext %12754)
  %conv35.56 = zext i8 %call34.56 to i32
  %xor36.56 = xor i32 %xor.56, %conv35.56
  %conv37.56 = trunc i32 %xor36.56 to i8
  store i8 %conv37.56, i8* %scevgep39.55, align 1
  %scevgep28.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12748, i64 0, i64 0, i64 1
  %12755 = bitcast i8* %scevgep28.56 to [61 x [61 x i8]]*
  %scevgep41.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12749, i64 0, i64 1, i64 0
  %12756 = bitcast i8* %scevgep41.56 to [61 x [61 x i8]]*
  %call16.56.1 = call zeroext i8 (...) @rand()
  store i8 %call16.56.1, i8* %scevgep28.56, align 1
  %12757 = load i8, i8* %scevgep28.56, align 1
  %conv23.56.1 = zext i8 %12757 to i32
  %12758 = load i8, i8* %arrayidx25.56, align 1
  %scevgep34.56.1 = getelementptr i8, i8* %b, i64 58
  %12759 = load i8, i8* %scevgep34.56.1, align 1
  %call28.56.1 = call zeroext i8 @mult(i8 zeroext %12758, i8 zeroext %12759)
  %conv29.56.1 = zext i8 %call28.56.1 to i32
  %xor.56.1 = xor i32 %conv23.56.1, %conv29.56.1
  %scevgep35.56.1 = getelementptr i8, i8* %a, i64 58
  %12760 = load i8, i8* %scevgep35.56.1, align 1
  %12761 = load i8, i8* %arrayidx33.56, align 1
  %call34.56.1 = call zeroext i8 @mult(i8 zeroext %12760, i8 zeroext %12761)
  %conv35.56.1 = zext i8 %call34.56.1 to i32
  %xor36.56.1 = xor i32 %xor.56.1, %conv35.56.1
  %conv37.56.1 = trunc i32 %xor36.56.1 to i8
  store i8 %conv37.56.1, i8* %scevgep41.56, align 1
  %scevgep28.56.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12755, i64 0, i64 0, i64 1
  %12762 = bitcast i8* %scevgep28.56.1 to [61 x [61 x i8]]*
  %scevgep41.56.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12756, i64 0, i64 1, i64 0
  %12763 = bitcast i8* %scevgep41.56.1 to [61 x [61 x i8]]*
  %call16.56.2 = call zeroext i8 (...) @rand()
  store i8 %call16.56.2, i8* %scevgep28.56.1, align 1
  %12764 = load i8, i8* %scevgep28.56.1, align 1
  %conv23.56.2 = zext i8 %12764 to i32
  %12765 = load i8, i8* %arrayidx25.56, align 1
  %scevgep34.56.2 = getelementptr i8, i8* %b, i64 59
  %12766 = load i8, i8* %scevgep34.56.2, align 1
  %call28.56.2 = call zeroext i8 @mult(i8 zeroext %12765, i8 zeroext %12766)
  %conv29.56.2 = zext i8 %call28.56.2 to i32
  %xor.56.2 = xor i32 %conv23.56.2, %conv29.56.2
  %scevgep35.56.2 = getelementptr i8, i8* %a, i64 59
  %12767 = load i8, i8* %scevgep35.56.2, align 1
  %12768 = load i8, i8* %arrayidx33.56, align 1
  %call34.56.2 = call zeroext i8 @mult(i8 zeroext %12767, i8 zeroext %12768)
  %conv35.56.2 = zext i8 %call34.56.2 to i32
  %xor36.56.2 = xor i32 %xor.56.2, %conv35.56.2
  %conv37.56.2 = trunc i32 %xor36.56.2 to i8
  store i8 %conv37.56.2, i8* %scevgep41.56.1, align 1
  %scevgep28.56.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12762, i64 0, i64 0, i64 1
  %scevgep41.56.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12763, i64 0, i64 1, i64 0
  %call16.56.3 = call zeroext i8 (...) @rand()
  store i8 %call16.56.3, i8* %scevgep28.56.2, align 1
  %12769 = load i8, i8* %scevgep28.56.2, align 1
  %conv23.56.3 = zext i8 %12769 to i32
  %12770 = load i8, i8* %arrayidx25.56, align 1
  %scevgep34.56.3 = getelementptr i8, i8* %b, i64 60
  %12771 = load i8, i8* %scevgep34.56.3, align 1
  %call28.56.3 = call zeroext i8 @mult(i8 zeroext %12770, i8 zeroext %12771)
  %conv29.56.3 = zext i8 %call28.56.3 to i32
  %xor.56.3 = xor i32 %conv23.56.3, %conv29.56.3
  %scevgep35.56.3 = getelementptr i8, i8* %a, i64 60
  %12772 = load i8, i8* %scevgep35.56.3, align 1
  %12773 = load i8, i8* %arrayidx33.56, align 1
  %call34.56.3 = call zeroext i8 @mult(i8 zeroext %12772, i8 zeroext %12773)
  %conv35.56.3 = zext i8 %call34.56.3 to i32
  %xor36.56.3 = xor i32 %xor.56.3, %conv35.56.3
  %conv37.56.3 = trunc i32 %xor36.56.3 to i8
  store i8 %conv37.56.3, i8* %scevgep41.56.2, align 1
  %scevgep26.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12748, i64 0, i64 1, i64 1
  %12774 = bitcast i8* %scevgep26.56 to [61 x [61 x i8]]*
  %scevgep39.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12749, i64 0, i64 1, i64 1
  %12775 = bitcast i8* %scevgep39.56 to [61 x [61 x i8]]*
  %arrayidx25.57 = getelementptr inbounds i8, i8* %a, i64 57
  %arrayidx33.57 = getelementptr inbounds i8, i8* %b, i64 57
  %call16.57 = call zeroext i8 (...) @rand()
  store i8 %call16.57, i8* %scevgep26.56, align 1
  %12776 = load i8, i8* %scevgep26.56, align 1
  %conv23.57 = zext i8 %12776 to i32
  %12777 = load i8, i8* %arrayidx25.57, align 1
  %scevgep34.57 = getelementptr i8, i8* %b, i64 58
  %12778 = load i8, i8* %scevgep34.57, align 1
  %call28.57 = call zeroext i8 @mult(i8 zeroext %12777, i8 zeroext %12778)
  %conv29.57 = zext i8 %call28.57 to i32
  %xor.57 = xor i32 %conv23.57, %conv29.57
  %scevgep35.57 = getelementptr i8, i8* %a, i64 58
  %12779 = load i8, i8* %scevgep35.57, align 1
  %12780 = load i8, i8* %arrayidx33.57, align 1
  %call34.57 = call zeroext i8 @mult(i8 zeroext %12779, i8 zeroext %12780)
  %conv35.57 = zext i8 %call34.57 to i32
  %xor36.57 = xor i32 %xor.57, %conv35.57
  %conv37.57 = trunc i32 %xor36.57 to i8
  store i8 %conv37.57, i8* %scevgep39.56, align 1
  %scevgep28.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12774, i64 0, i64 0, i64 1
  %12781 = bitcast i8* %scevgep28.57 to [61 x [61 x i8]]*
  %scevgep41.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12775, i64 0, i64 1, i64 0
  %12782 = bitcast i8* %scevgep41.57 to [61 x [61 x i8]]*
  %call16.57.1 = call zeroext i8 (...) @rand()
  store i8 %call16.57.1, i8* %scevgep28.57, align 1
  %12783 = load i8, i8* %scevgep28.57, align 1
  %conv23.57.1 = zext i8 %12783 to i32
  %12784 = load i8, i8* %arrayidx25.57, align 1
  %scevgep34.57.1 = getelementptr i8, i8* %b, i64 59
  %12785 = load i8, i8* %scevgep34.57.1, align 1
  %call28.57.1 = call zeroext i8 @mult(i8 zeroext %12784, i8 zeroext %12785)
  %conv29.57.1 = zext i8 %call28.57.1 to i32
  %xor.57.1 = xor i32 %conv23.57.1, %conv29.57.1
  %scevgep35.57.1 = getelementptr i8, i8* %a, i64 59
  %12786 = load i8, i8* %scevgep35.57.1, align 1
  %12787 = load i8, i8* %arrayidx33.57, align 1
  %call34.57.1 = call zeroext i8 @mult(i8 zeroext %12786, i8 zeroext %12787)
  %conv35.57.1 = zext i8 %call34.57.1 to i32
  %xor36.57.1 = xor i32 %xor.57.1, %conv35.57.1
  %conv37.57.1 = trunc i32 %xor36.57.1 to i8
  store i8 %conv37.57.1, i8* %scevgep41.57, align 1
  %scevgep28.57.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12781, i64 0, i64 0, i64 1
  %scevgep41.57.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12782, i64 0, i64 1, i64 0
  %call16.57.2 = call zeroext i8 (...) @rand()
  store i8 %call16.57.2, i8* %scevgep28.57.1, align 1
  %12788 = load i8, i8* %scevgep28.57.1, align 1
  %conv23.57.2 = zext i8 %12788 to i32
  %12789 = load i8, i8* %arrayidx25.57, align 1
  %scevgep34.57.2 = getelementptr i8, i8* %b, i64 60
  %12790 = load i8, i8* %scevgep34.57.2, align 1
  %call28.57.2 = call zeroext i8 @mult(i8 zeroext %12789, i8 zeroext %12790)
  %conv29.57.2 = zext i8 %call28.57.2 to i32
  %xor.57.2 = xor i32 %conv23.57.2, %conv29.57.2
  %scevgep35.57.2 = getelementptr i8, i8* %a, i64 60
  %12791 = load i8, i8* %scevgep35.57.2, align 1
  %12792 = load i8, i8* %arrayidx33.57, align 1
  %call34.57.2 = call zeroext i8 @mult(i8 zeroext %12791, i8 zeroext %12792)
  %conv35.57.2 = zext i8 %call34.57.2 to i32
  %xor36.57.2 = xor i32 %xor.57.2, %conv35.57.2
  %conv37.57.2 = trunc i32 %xor36.57.2 to i8
  store i8 %conv37.57.2, i8* %scevgep41.57.1, align 1
  %scevgep26.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12774, i64 0, i64 1, i64 1
  %12793 = bitcast i8* %scevgep26.57 to [61 x [61 x i8]]*
  %scevgep39.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12775, i64 0, i64 1, i64 1
  %12794 = bitcast i8* %scevgep39.57 to [61 x [61 x i8]]*
  %arrayidx25.58 = getelementptr inbounds i8, i8* %a, i64 58
  %arrayidx33.58 = getelementptr inbounds i8, i8* %b, i64 58
  %call16.58 = call zeroext i8 (...) @rand()
  store i8 %call16.58, i8* %scevgep26.57, align 1
  %12795 = load i8, i8* %scevgep26.57, align 1
  %conv23.58 = zext i8 %12795 to i32
  %12796 = load i8, i8* %arrayidx25.58, align 1
  %scevgep34.58 = getelementptr i8, i8* %b, i64 59
  %12797 = load i8, i8* %scevgep34.58, align 1
  %call28.58 = call zeroext i8 @mult(i8 zeroext %12796, i8 zeroext %12797)
  %conv29.58 = zext i8 %call28.58 to i32
  %xor.58 = xor i32 %conv23.58, %conv29.58
  %scevgep35.58 = getelementptr i8, i8* %a, i64 59
  %12798 = load i8, i8* %scevgep35.58, align 1
  %12799 = load i8, i8* %arrayidx33.58, align 1
  %call34.58 = call zeroext i8 @mult(i8 zeroext %12798, i8 zeroext %12799)
  %conv35.58 = zext i8 %call34.58 to i32
  %xor36.58 = xor i32 %xor.58, %conv35.58
  %conv37.58 = trunc i32 %xor36.58 to i8
  store i8 %conv37.58, i8* %scevgep39.57, align 1
  %scevgep28.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12793, i64 0, i64 0, i64 1
  %scevgep41.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12794, i64 0, i64 1, i64 0
  %call16.58.1 = call zeroext i8 (...) @rand()
  store i8 %call16.58.1, i8* %scevgep28.58, align 1
  %12800 = load i8, i8* %scevgep28.58, align 1
  %conv23.58.1 = zext i8 %12800 to i32
  %12801 = load i8, i8* %arrayidx25.58, align 1
  %scevgep34.58.1 = getelementptr i8, i8* %b, i64 60
  %12802 = load i8, i8* %scevgep34.58.1, align 1
  %call28.58.1 = call zeroext i8 @mult(i8 zeroext %12801, i8 zeroext %12802)
  %conv29.58.1 = zext i8 %call28.58.1 to i32
  %xor.58.1 = xor i32 %conv23.58.1, %conv29.58.1
  %scevgep35.58.1 = getelementptr i8, i8* %a, i64 60
  %12803 = load i8, i8* %scevgep35.58.1, align 1
  %12804 = load i8, i8* %arrayidx33.58, align 1
  %call34.58.1 = call zeroext i8 @mult(i8 zeroext %12803, i8 zeroext %12804)
  %conv35.58.1 = zext i8 %call34.58.1 to i32
  %xor36.58.1 = xor i32 %xor.58.1, %conv35.58.1
  %conv37.58.1 = trunc i32 %xor36.58.1 to i8
  store i8 %conv37.58.1, i8* %scevgep41.58, align 1
  %scevgep26.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12793, i64 0, i64 1, i64 1
  %scevgep39.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12794, i64 0, i64 1, i64 1
  %arrayidx25.59 = getelementptr inbounds i8, i8* %a, i64 59
  %arrayidx33.59 = getelementptr inbounds i8, i8* %b, i64 59
  %call16.59 = call zeroext i8 (...) @rand()
  store i8 %call16.59, i8* %scevgep26.58, align 1
  %12805 = load i8, i8* %scevgep26.58, align 1
  %conv23.59 = zext i8 %12805 to i32
  %12806 = load i8, i8* %arrayidx25.59, align 1
  %scevgep34.59 = getelementptr i8, i8* %b, i64 60
  %12807 = load i8, i8* %scevgep34.59, align 1
  %call28.59 = call zeroext i8 @mult(i8 zeroext %12806, i8 zeroext %12807)
  %conv29.59 = zext i8 %call28.59 to i32
  %xor.59 = xor i32 %conv23.59, %conv29.59
  %scevgep35.59 = getelementptr i8, i8* %a, i64 60
  %12808 = load i8, i8* %scevgep35.59, align 1
  %12809 = load i8, i8* %arrayidx33.59, align 1
  %call34.59 = call zeroext i8 @mult(i8 zeroext %12808, i8 zeroext %12809)
  %conv35.59 = zext i8 %call34.59 to i32
  %xor36.59 = xor i32 %xor.59, %conv35.59
  %conv37.59 = trunc i32 %xor36.59 to i8
  store i8 %conv37.59, i8* %scevgep39.58, align 1
  %12810 = load i8, i8* %a, align 1
  %12811 = load i8, i8* %b, align 1
  %call54 = call zeroext i8 @mult(i8 zeroext %12810, i8 zeroext %12811)
  store i8 %call54, i8* %c, align 1
  %scevgep20.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 1
  %12812 = load i8, i8* %scevgep20.1, align 1
  %conv68.1 = zext i8 %12812 to i32
  %12813 = load i8, i8* %c, align 1
  %conv71.1 = zext i8 %12813 to i32
  %xor72.1 = xor i32 %conv71.1, %conv68.1
  %conv73.1 = trunc i32 %xor72.1 to i8
  store i8 %conv73.1, i8* %c, align 1
  %scevgep20.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 2
  %12814 = load i8, i8* %scevgep20.2, align 1
  %conv68.2 = zext i8 %12814 to i32
  %12815 = load i8, i8* %c, align 1
  %conv71.2 = zext i8 %12815 to i32
  %xor72.2 = xor i32 %conv71.2, %conv68.2
  %conv73.2 = trunc i32 %xor72.2 to i8
  store i8 %conv73.2, i8* %c, align 1
  %scevgep20.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 3
  %12816 = load i8, i8* %scevgep20.3, align 1
  %conv68.3 = zext i8 %12816 to i32
  %12817 = load i8, i8* %c, align 1
  %conv71.3 = zext i8 %12817 to i32
  %xor72.3 = xor i32 %conv71.3, %conv68.3
  %conv73.3 = trunc i32 %xor72.3 to i8
  store i8 %conv73.3, i8* %c, align 1
  %scevgep20.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 4
  %12818 = load i8, i8* %scevgep20.4, align 1
  %conv68.4 = zext i8 %12818 to i32
  %12819 = load i8, i8* %c, align 1
  %conv71.4 = zext i8 %12819 to i32
  %xor72.4 = xor i32 %conv71.4, %conv68.4
  %conv73.4 = trunc i32 %xor72.4 to i8
  store i8 %conv73.4, i8* %c, align 1
  %scevgep20.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 5
  %12820 = load i8, i8* %scevgep20.5, align 1
  %conv68.5 = zext i8 %12820 to i32
  %12821 = load i8, i8* %c, align 1
  %conv71.5 = zext i8 %12821 to i32
  %xor72.5 = xor i32 %conv71.5, %conv68.5
  %conv73.5 = trunc i32 %xor72.5 to i8
  store i8 %conv73.5, i8* %c, align 1
  %scevgep20.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 6
  %12822 = load i8, i8* %scevgep20.6, align 1
  %conv68.6 = zext i8 %12822 to i32
  %12823 = load i8, i8* %c, align 1
  %conv71.6 = zext i8 %12823 to i32
  %xor72.6 = xor i32 %conv71.6, %conv68.6
  %conv73.6 = trunc i32 %xor72.6 to i8
  store i8 %conv73.6, i8* %c, align 1
  %scevgep20.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 7
  %12824 = load i8, i8* %scevgep20.7, align 1
  %conv68.7 = zext i8 %12824 to i32
  %12825 = load i8, i8* %c, align 1
  %conv71.7 = zext i8 %12825 to i32
  %xor72.7 = xor i32 %conv71.7, %conv68.7
  %conv73.7 = trunc i32 %xor72.7 to i8
  store i8 %conv73.7, i8* %c, align 1
  %scevgep20.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 8
  %12826 = load i8, i8* %scevgep20.8, align 1
  %conv68.8 = zext i8 %12826 to i32
  %12827 = load i8, i8* %c, align 1
  %conv71.8 = zext i8 %12827 to i32
  %xor72.8 = xor i32 %conv71.8, %conv68.8
  %conv73.8 = trunc i32 %xor72.8 to i8
  store i8 %conv73.8, i8* %c, align 1
  %scevgep20.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 9
  %12828 = load i8, i8* %scevgep20.9, align 1
  %conv68.9 = zext i8 %12828 to i32
  %12829 = load i8, i8* %c, align 1
  %conv71.9 = zext i8 %12829 to i32
  %xor72.9 = xor i32 %conv71.9, %conv68.9
  %conv73.9 = trunc i32 %xor72.9 to i8
  store i8 %conv73.9, i8* %c, align 1
  %scevgep20.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 10
  %12830 = load i8, i8* %scevgep20.10, align 1
  %conv68.10 = zext i8 %12830 to i32
  %12831 = load i8, i8* %c, align 1
  %conv71.10 = zext i8 %12831 to i32
  %xor72.10 = xor i32 %conv71.10, %conv68.10
  %conv73.10 = trunc i32 %xor72.10 to i8
  store i8 %conv73.10, i8* %c, align 1
  %scevgep20.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 11
  %12832 = load i8, i8* %scevgep20.11, align 1
  %conv68.11 = zext i8 %12832 to i32
  %12833 = load i8, i8* %c, align 1
  %conv71.11 = zext i8 %12833 to i32
  %xor72.11 = xor i32 %conv71.11, %conv68.11
  %conv73.11 = trunc i32 %xor72.11 to i8
  store i8 %conv73.11, i8* %c, align 1
  %scevgep20.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 12
  %12834 = load i8, i8* %scevgep20.12, align 1
  %conv68.12 = zext i8 %12834 to i32
  %12835 = load i8, i8* %c, align 1
  %conv71.12 = zext i8 %12835 to i32
  %xor72.12 = xor i32 %conv71.12, %conv68.12
  %conv73.12 = trunc i32 %xor72.12 to i8
  store i8 %conv73.12, i8* %c, align 1
  %scevgep20.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 13
  %12836 = load i8, i8* %scevgep20.13, align 1
  %conv68.13 = zext i8 %12836 to i32
  %12837 = load i8, i8* %c, align 1
  %conv71.13 = zext i8 %12837 to i32
  %xor72.13 = xor i32 %conv71.13, %conv68.13
  %conv73.13 = trunc i32 %xor72.13 to i8
  store i8 %conv73.13, i8* %c, align 1
  %scevgep20.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 14
  %12838 = load i8, i8* %scevgep20.14, align 1
  %conv68.14 = zext i8 %12838 to i32
  %12839 = load i8, i8* %c, align 1
  %conv71.14 = zext i8 %12839 to i32
  %xor72.14 = xor i32 %conv71.14, %conv68.14
  %conv73.14 = trunc i32 %xor72.14 to i8
  store i8 %conv73.14, i8* %c, align 1
  %scevgep20.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 15
  %12840 = load i8, i8* %scevgep20.15, align 1
  %conv68.15 = zext i8 %12840 to i32
  %12841 = load i8, i8* %c, align 1
  %conv71.15 = zext i8 %12841 to i32
  %xor72.15 = xor i32 %conv71.15, %conv68.15
  %conv73.15 = trunc i32 %xor72.15 to i8
  store i8 %conv73.15, i8* %c, align 1
  %scevgep20.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 16
  %12842 = load i8, i8* %scevgep20.16, align 1
  %conv68.16 = zext i8 %12842 to i32
  %12843 = load i8, i8* %c, align 1
  %conv71.16 = zext i8 %12843 to i32
  %xor72.16 = xor i32 %conv71.16, %conv68.16
  %conv73.16 = trunc i32 %xor72.16 to i8
  store i8 %conv73.16, i8* %c, align 1
  %scevgep20.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 17
  %12844 = load i8, i8* %scevgep20.17, align 1
  %conv68.17 = zext i8 %12844 to i32
  %12845 = load i8, i8* %c, align 1
  %conv71.17 = zext i8 %12845 to i32
  %xor72.17 = xor i32 %conv71.17, %conv68.17
  %conv73.17 = trunc i32 %xor72.17 to i8
  store i8 %conv73.17, i8* %c, align 1
  %scevgep20.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 18
  %12846 = load i8, i8* %scevgep20.18, align 1
  %conv68.18 = zext i8 %12846 to i32
  %12847 = load i8, i8* %c, align 1
  %conv71.18 = zext i8 %12847 to i32
  %xor72.18 = xor i32 %conv71.18, %conv68.18
  %conv73.18 = trunc i32 %xor72.18 to i8
  store i8 %conv73.18, i8* %c, align 1
  %scevgep20.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 19
  %12848 = load i8, i8* %scevgep20.19, align 1
  %conv68.19 = zext i8 %12848 to i32
  %12849 = load i8, i8* %c, align 1
  %conv71.19 = zext i8 %12849 to i32
  %xor72.19 = xor i32 %conv71.19, %conv68.19
  %conv73.19 = trunc i32 %xor72.19 to i8
  store i8 %conv73.19, i8* %c, align 1
  %scevgep20.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 20
  %12850 = load i8, i8* %scevgep20.20, align 1
  %conv68.20 = zext i8 %12850 to i32
  %12851 = load i8, i8* %c, align 1
  %conv71.20 = zext i8 %12851 to i32
  %xor72.20 = xor i32 %conv71.20, %conv68.20
  %conv73.20 = trunc i32 %xor72.20 to i8
  store i8 %conv73.20, i8* %c, align 1
  %scevgep20.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 21
  %12852 = load i8, i8* %scevgep20.21, align 1
  %conv68.21 = zext i8 %12852 to i32
  %12853 = load i8, i8* %c, align 1
  %conv71.21 = zext i8 %12853 to i32
  %xor72.21 = xor i32 %conv71.21, %conv68.21
  %conv73.21 = trunc i32 %xor72.21 to i8
  store i8 %conv73.21, i8* %c, align 1
  %scevgep20.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 22
  %12854 = load i8, i8* %scevgep20.22, align 1
  %conv68.22 = zext i8 %12854 to i32
  %12855 = load i8, i8* %c, align 1
  %conv71.22 = zext i8 %12855 to i32
  %xor72.22 = xor i32 %conv71.22, %conv68.22
  %conv73.22 = trunc i32 %xor72.22 to i8
  store i8 %conv73.22, i8* %c, align 1
  %scevgep20.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 23
  %12856 = load i8, i8* %scevgep20.23, align 1
  %conv68.23 = zext i8 %12856 to i32
  %12857 = load i8, i8* %c, align 1
  %conv71.23 = zext i8 %12857 to i32
  %xor72.23 = xor i32 %conv71.23, %conv68.23
  %conv73.23 = trunc i32 %xor72.23 to i8
  store i8 %conv73.23, i8* %c, align 1
  %scevgep20.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 24
  %12858 = load i8, i8* %scevgep20.24, align 1
  %conv68.24 = zext i8 %12858 to i32
  %12859 = load i8, i8* %c, align 1
  %conv71.24 = zext i8 %12859 to i32
  %xor72.24 = xor i32 %conv71.24, %conv68.24
  %conv73.24 = trunc i32 %xor72.24 to i8
  store i8 %conv73.24, i8* %c, align 1
  %scevgep20.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 25
  %12860 = load i8, i8* %scevgep20.25, align 1
  %conv68.25 = zext i8 %12860 to i32
  %12861 = load i8, i8* %c, align 1
  %conv71.25 = zext i8 %12861 to i32
  %xor72.25 = xor i32 %conv71.25, %conv68.25
  %conv73.25 = trunc i32 %xor72.25 to i8
  store i8 %conv73.25, i8* %c, align 1
  %scevgep20.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 26
  %12862 = load i8, i8* %scevgep20.26, align 1
  %conv68.26 = zext i8 %12862 to i32
  %12863 = load i8, i8* %c, align 1
  %conv71.26 = zext i8 %12863 to i32
  %xor72.26 = xor i32 %conv71.26, %conv68.26
  %conv73.26 = trunc i32 %xor72.26 to i8
  store i8 %conv73.26, i8* %c, align 1
  %scevgep20.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 27
  %12864 = load i8, i8* %scevgep20.27, align 1
  %conv68.27 = zext i8 %12864 to i32
  %12865 = load i8, i8* %c, align 1
  %conv71.27 = zext i8 %12865 to i32
  %xor72.27 = xor i32 %conv71.27, %conv68.27
  %conv73.27 = trunc i32 %xor72.27 to i8
  store i8 %conv73.27, i8* %c, align 1
  %scevgep20.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 28
  %12866 = load i8, i8* %scevgep20.28, align 1
  %conv68.28 = zext i8 %12866 to i32
  %12867 = load i8, i8* %c, align 1
  %conv71.28 = zext i8 %12867 to i32
  %xor72.28 = xor i32 %conv71.28, %conv68.28
  %conv73.28 = trunc i32 %xor72.28 to i8
  store i8 %conv73.28, i8* %c, align 1
  %scevgep20.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 29
  %12868 = load i8, i8* %scevgep20.29, align 1
  %conv68.29 = zext i8 %12868 to i32
  %12869 = load i8, i8* %c, align 1
  %conv71.29 = zext i8 %12869 to i32
  %xor72.29 = xor i32 %conv71.29, %conv68.29
  %conv73.29 = trunc i32 %xor72.29 to i8
  store i8 %conv73.29, i8* %c, align 1
  %scevgep20.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 30
  %12870 = load i8, i8* %scevgep20.30, align 1
  %conv68.30 = zext i8 %12870 to i32
  %12871 = load i8, i8* %c, align 1
  %conv71.30 = zext i8 %12871 to i32
  %xor72.30 = xor i32 %conv71.30, %conv68.30
  %conv73.30 = trunc i32 %xor72.30 to i8
  store i8 %conv73.30, i8* %c, align 1
  %scevgep20.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 31
  %12872 = load i8, i8* %scevgep20.31, align 1
  %conv68.31 = zext i8 %12872 to i32
  %12873 = load i8, i8* %c, align 1
  %conv71.31 = zext i8 %12873 to i32
  %xor72.31 = xor i32 %conv71.31, %conv68.31
  %conv73.31 = trunc i32 %xor72.31 to i8
  store i8 %conv73.31, i8* %c, align 1
  %scevgep20.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 32
  %12874 = load i8, i8* %scevgep20.32, align 1
  %conv68.32 = zext i8 %12874 to i32
  %12875 = load i8, i8* %c, align 1
  %conv71.32 = zext i8 %12875 to i32
  %xor72.32 = xor i32 %conv71.32, %conv68.32
  %conv73.32 = trunc i32 %xor72.32 to i8
  store i8 %conv73.32, i8* %c, align 1
  %scevgep20.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 33
  %12876 = load i8, i8* %scevgep20.33, align 1
  %conv68.33 = zext i8 %12876 to i32
  %12877 = load i8, i8* %c, align 1
  %conv71.33 = zext i8 %12877 to i32
  %xor72.33 = xor i32 %conv71.33, %conv68.33
  %conv73.33 = trunc i32 %xor72.33 to i8
  store i8 %conv73.33, i8* %c, align 1
  %scevgep20.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 34
  %12878 = load i8, i8* %scevgep20.34, align 1
  %conv68.34 = zext i8 %12878 to i32
  %12879 = load i8, i8* %c, align 1
  %conv71.34 = zext i8 %12879 to i32
  %xor72.34 = xor i32 %conv71.34, %conv68.34
  %conv73.34 = trunc i32 %xor72.34 to i8
  store i8 %conv73.34, i8* %c, align 1
  %scevgep20.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 35
  %12880 = load i8, i8* %scevgep20.35, align 1
  %conv68.35 = zext i8 %12880 to i32
  %12881 = load i8, i8* %c, align 1
  %conv71.35 = zext i8 %12881 to i32
  %xor72.35 = xor i32 %conv71.35, %conv68.35
  %conv73.35 = trunc i32 %xor72.35 to i8
  store i8 %conv73.35, i8* %c, align 1
  %scevgep20.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 36
  %12882 = load i8, i8* %scevgep20.36, align 1
  %conv68.36 = zext i8 %12882 to i32
  %12883 = load i8, i8* %c, align 1
  %conv71.36 = zext i8 %12883 to i32
  %xor72.36 = xor i32 %conv71.36, %conv68.36
  %conv73.36 = trunc i32 %xor72.36 to i8
  store i8 %conv73.36, i8* %c, align 1
  %scevgep20.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 37
  %12884 = load i8, i8* %scevgep20.37, align 1
  %conv68.37 = zext i8 %12884 to i32
  %12885 = load i8, i8* %c, align 1
  %conv71.37 = zext i8 %12885 to i32
  %xor72.37 = xor i32 %conv71.37, %conv68.37
  %conv73.37 = trunc i32 %xor72.37 to i8
  store i8 %conv73.37, i8* %c, align 1
  %scevgep20.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 38
  %12886 = load i8, i8* %scevgep20.38, align 1
  %conv68.38 = zext i8 %12886 to i32
  %12887 = load i8, i8* %c, align 1
  %conv71.38 = zext i8 %12887 to i32
  %xor72.38 = xor i32 %conv71.38, %conv68.38
  %conv73.38 = trunc i32 %xor72.38 to i8
  store i8 %conv73.38, i8* %c, align 1
  %scevgep20.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 39
  %12888 = load i8, i8* %scevgep20.39, align 1
  %conv68.39 = zext i8 %12888 to i32
  %12889 = load i8, i8* %c, align 1
  %conv71.39 = zext i8 %12889 to i32
  %xor72.39 = xor i32 %conv71.39, %conv68.39
  %conv73.39 = trunc i32 %xor72.39 to i8
  store i8 %conv73.39, i8* %c, align 1
  %scevgep20.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 40
  %12890 = load i8, i8* %scevgep20.40, align 1
  %conv68.40 = zext i8 %12890 to i32
  %12891 = load i8, i8* %c, align 1
  %conv71.40 = zext i8 %12891 to i32
  %xor72.40 = xor i32 %conv71.40, %conv68.40
  %conv73.40 = trunc i32 %xor72.40 to i8
  store i8 %conv73.40, i8* %c, align 1
  %scevgep20.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 41
  %12892 = load i8, i8* %scevgep20.41, align 1
  %conv68.41 = zext i8 %12892 to i32
  %12893 = load i8, i8* %c, align 1
  %conv71.41 = zext i8 %12893 to i32
  %xor72.41 = xor i32 %conv71.41, %conv68.41
  %conv73.41 = trunc i32 %xor72.41 to i8
  store i8 %conv73.41, i8* %c, align 1
  %scevgep20.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 42
  %12894 = load i8, i8* %scevgep20.42, align 1
  %conv68.42 = zext i8 %12894 to i32
  %12895 = load i8, i8* %c, align 1
  %conv71.42 = zext i8 %12895 to i32
  %xor72.42 = xor i32 %conv71.42, %conv68.42
  %conv73.42 = trunc i32 %xor72.42 to i8
  store i8 %conv73.42, i8* %c, align 1
  %scevgep20.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 43
  %12896 = load i8, i8* %scevgep20.43, align 1
  %conv68.43 = zext i8 %12896 to i32
  %12897 = load i8, i8* %c, align 1
  %conv71.43 = zext i8 %12897 to i32
  %xor72.43 = xor i32 %conv71.43, %conv68.43
  %conv73.43 = trunc i32 %xor72.43 to i8
  store i8 %conv73.43, i8* %c, align 1
  %scevgep20.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 44
  %12898 = load i8, i8* %scevgep20.44, align 1
  %conv68.44 = zext i8 %12898 to i32
  %12899 = load i8, i8* %c, align 1
  %conv71.44 = zext i8 %12899 to i32
  %xor72.44 = xor i32 %conv71.44, %conv68.44
  %conv73.44 = trunc i32 %xor72.44 to i8
  store i8 %conv73.44, i8* %c, align 1
  %scevgep20.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 45
  %12900 = load i8, i8* %scevgep20.45, align 1
  %conv68.45 = zext i8 %12900 to i32
  %12901 = load i8, i8* %c, align 1
  %conv71.45 = zext i8 %12901 to i32
  %xor72.45 = xor i32 %conv71.45, %conv68.45
  %conv73.45 = trunc i32 %xor72.45 to i8
  store i8 %conv73.45, i8* %c, align 1
  %scevgep20.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 46
  %12902 = load i8, i8* %scevgep20.46, align 1
  %conv68.46 = zext i8 %12902 to i32
  %12903 = load i8, i8* %c, align 1
  %conv71.46 = zext i8 %12903 to i32
  %xor72.46 = xor i32 %conv71.46, %conv68.46
  %conv73.46 = trunc i32 %xor72.46 to i8
  store i8 %conv73.46, i8* %c, align 1
  %scevgep20.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 47
  %12904 = load i8, i8* %scevgep20.47, align 1
  %conv68.47 = zext i8 %12904 to i32
  %12905 = load i8, i8* %c, align 1
  %conv71.47 = zext i8 %12905 to i32
  %xor72.47 = xor i32 %conv71.47, %conv68.47
  %conv73.47 = trunc i32 %xor72.47 to i8
  store i8 %conv73.47, i8* %c, align 1
  %scevgep20.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 48
  %12906 = load i8, i8* %scevgep20.48, align 1
  %conv68.48 = zext i8 %12906 to i32
  %12907 = load i8, i8* %c, align 1
  %conv71.48 = zext i8 %12907 to i32
  %xor72.48 = xor i32 %conv71.48, %conv68.48
  %conv73.48 = trunc i32 %xor72.48 to i8
  store i8 %conv73.48, i8* %c, align 1
  %scevgep20.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 49
  %12908 = load i8, i8* %scevgep20.49, align 1
  %conv68.49 = zext i8 %12908 to i32
  %12909 = load i8, i8* %c, align 1
  %conv71.49 = zext i8 %12909 to i32
  %xor72.49 = xor i32 %conv71.49, %conv68.49
  %conv73.49 = trunc i32 %xor72.49 to i8
  store i8 %conv73.49, i8* %c, align 1
  %scevgep20.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 50
  %12910 = load i8, i8* %scevgep20.50, align 1
  %conv68.50 = zext i8 %12910 to i32
  %12911 = load i8, i8* %c, align 1
  %conv71.50 = zext i8 %12911 to i32
  %xor72.50 = xor i32 %conv71.50, %conv68.50
  %conv73.50 = trunc i32 %xor72.50 to i8
  store i8 %conv73.50, i8* %c, align 1
  %scevgep20.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 51
  %12912 = load i8, i8* %scevgep20.51, align 1
  %conv68.51 = zext i8 %12912 to i32
  %12913 = load i8, i8* %c, align 1
  %conv71.51 = zext i8 %12913 to i32
  %xor72.51 = xor i32 %conv71.51, %conv68.51
  %conv73.51 = trunc i32 %xor72.51 to i8
  store i8 %conv73.51, i8* %c, align 1
  %scevgep20.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 52
  %12914 = load i8, i8* %scevgep20.52, align 1
  %conv68.52 = zext i8 %12914 to i32
  %12915 = load i8, i8* %c, align 1
  %conv71.52 = zext i8 %12915 to i32
  %xor72.52 = xor i32 %conv71.52, %conv68.52
  %conv73.52 = trunc i32 %xor72.52 to i8
  store i8 %conv73.52, i8* %c, align 1
  %scevgep20.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 53
  %12916 = load i8, i8* %scevgep20.53, align 1
  %conv68.53 = zext i8 %12916 to i32
  %12917 = load i8, i8* %c, align 1
  %conv71.53 = zext i8 %12917 to i32
  %xor72.53 = xor i32 %conv71.53, %conv68.53
  %conv73.53 = trunc i32 %xor72.53 to i8
  store i8 %conv73.53, i8* %c, align 1
  %scevgep20.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 54
  %12918 = load i8, i8* %scevgep20.54, align 1
  %conv68.54 = zext i8 %12918 to i32
  %12919 = load i8, i8* %c, align 1
  %conv71.54 = zext i8 %12919 to i32
  %xor72.54 = xor i32 %conv71.54, %conv68.54
  %conv73.54 = trunc i32 %xor72.54 to i8
  store i8 %conv73.54, i8* %c, align 1
  %scevgep20.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 55
  %12920 = load i8, i8* %scevgep20.55, align 1
  %conv68.55 = zext i8 %12920 to i32
  %12921 = load i8, i8* %c, align 1
  %conv71.55 = zext i8 %12921 to i32
  %xor72.55 = xor i32 %conv71.55, %conv68.55
  %conv73.55 = trunc i32 %xor72.55 to i8
  store i8 %conv73.55, i8* %c, align 1
  %scevgep20.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 56
  %12922 = load i8, i8* %scevgep20.56, align 1
  %conv68.56 = zext i8 %12922 to i32
  %12923 = load i8, i8* %c, align 1
  %conv71.56 = zext i8 %12923 to i32
  %xor72.56 = xor i32 %conv71.56, %conv68.56
  %conv73.56 = trunc i32 %xor72.56 to i8
  store i8 %conv73.56, i8* %c, align 1
  %scevgep20.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 57
  %12924 = load i8, i8* %scevgep20.57, align 1
  %conv68.57 = zext i8 %12924 to i32
  %12925 = load i8, i8* %c, align 1
  %conv71.57 = zext i8 %12925 to i32
  %xor72.57 = xor i32 %conv71.57, %conv68.57
  %conv73.57 = trunc i32 %xor72.57 to i8
  store i8 %conv73.57, i8* %c, align 1
  %scevgep20.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 58
  %12926 = load i8, i8* %scevgep20.58, align 1
  %conv68.58 = zext i8 %12926 to i32
  %12927 = load i8, i8* %c, align 1
  %conv71.58 = zext i8 %12927 to i32
  %xor72.58 = xor i32 %conv71.58, %conv68.58
  %conv73.58 = trunc i32 %xor72.58 to i8
  store i8 %conv73.58, i8* %c, align 1
  %scevgep20.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 59
  %12928 = load i8, i8* %scevgep20.59, align 1
  %conv68.59 = zext i8 %12928 to i32
  %12929 = load i8, i8* %c, align 1
  %conv71.59 = zext i8 %12929 to i32
  %xor72.59 = xor i32 %conv71.59, %conv68.59
  %conv73.59 = trunc i32 %xor72.59 to i8
  store i8 %conv73.59, i8* %c, align 1
  %scevgep20.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 0, i64 60
  %12930 = load i8, i8* %scevgep20.60, align 1
  %conv68.60 = zext i8 %12930 to i32
  %12931 = load i8, i8* %c, align 1
  %conv71.60 = zext i8 %12931 to i32
  %xor72.60 = xor i32 %conv71.60, %conv68.60
  %conv73.60 = trunc i32 %xor72.60 to i8
  store i8 %conv73.60, i8* %c, align 1
  %scevgep19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %r, i64 0, i64 1, i64 0
  %12932 = bitcast i8* %scevgep19 to [61 x [61 x i8]]*
  %arrayidx51.1 = getelementptr inbounds i8, i8* %a, i64 1
  %12933 = load i8, i8* %arrayidx51.1, align 1
  %arrayidx53.1 = getelementptr inbounds i8, i8* %b, i64 1
  %12934 = load i8, i8* %arrayidx53.1, align 1
  %call54.1 = call zeroext i8 @mult(i8 zeroext %12933, i8 zeroext %12934)
  %arrayidx56.1 = getelementptr inbounds i8, i8* %c, i64 1
  store i8 %call54.1, i8* %arrayidx56.1, align 1
  %arrayidx70.1 = getelementptr inbounds i8, i8* %c, i64 1
  %scevgep20.154 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 0
  %12935 = load i8, i8* %scevgep20.154, align 1
  %conv68.155 = zext i8 %12935 to i32
  %12936 = load i8, i8* %arrayidx70.1, align 1
  %conv71.156 = zext i8 %12936 to i32
  %xor72.157 = xor i32 %conv71.156, %conv68.155
  %conv73.158 = trunc i32 %xor72.157 to i8
  store i8 %conv73.158, i8* %arrayidx70.1, align 1
  %scevgep20.2.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 2
  %12937 = load i8, i8* %scevgep20.2.1, align 1
  %conv68.2.1 = zext i8 %12937 to i32
  %12938 = load i8, i8* %arrayidx70.1, align 1
  %conv71.2.1 = zext i8 %12938 to i32
  %xor72.2.1 = xor i32 %conv71.2.1, %conv68.2.1
  %conv73.2.1 = trunc i32 %xor72.2.1 to i8
  store i8 %conv73.2.1, i8* %arrayidx70.1, align 1
  %scevgep20.3.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 3
  %12939 = load i8, i8* %scevgep20.3.1, align 1
  %conv68.3.1 = zext i8 %12939 to i32
  %12940 = load i8, i8* %arrayidx70.1, align 1
  %conv71.3.1 = zext i8 %12940 to i32
  %xor72.3.1 = xor i32 %conv71.3.1, %conv68.3.1
  %conv73.3.1 = trunc i32 %xor72.3.1 to i8
  store i8 %conv73.3.1, i8* %arrayidx70.1, align 1
  %scevgep20.4.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 4
  %12941 = load i8, i8* %scevgep20.4.1, align 1
  %conv68.4.1 = zext i8 %12941 to i32
  %12942 = load i8, i8* %arrayidx70.1, align 1
  %conv71.4.1 = zext i8 %12942 to i32
  %xor72.4.1 = xor i32 %conv71.4.1, %conv68.4.1
  %conv73.4.1 = trunc i32 %xor72.4.1 to i8
  store i8 %conv73.4.1, i8* %arrayidx70.1, align 1
  %scevgep20.5.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 5
  %12943 = load i8, i8* %scevgep20.5.1, align 1
  %conv68.5.1 = zext i8 %12943 to i32
  %12944 = load i8, i8* %arrayidx70.1, align 1
  %conv71.5.1 = zext i8 %12944 to i32
  %xor72.5.1 = xor i32 %conv71.5.1, %conv68.5.1
  %conv73.5.1 = trunc i32 %xor72.5.1 to i8
  store i8 %conv73.5.1, i8* %arrayidx70.1, align 1
  %scevgep20.6.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 6
  %12945 = load i8, i8* %scevgep20.6.1, align 1
  %conv68.6.1 = zext i8 %12945 to i32
  %12946 = load i8, i8* %arrayidx70.1, align 1
  %conv71.6.1 = zext i8 %12946 to i32
  %xor72.6.1 = xor i32 %conv71.6.1, %conv68.6.1
  %conv73.6.1 = trunc i32 %xor72.6.1 to i8
  store i8 %conv73.6.1, i8* %arrayidx70.1, align 1
  %scevgep20.7.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 7
  %12947 = load i8, i8* %scevgep20.7.1, align 1
  %conv68.7.1 = zext i8 %12947 to i32
  %12948 = load i8, i8* %arrayidx70.1, align 1
  %conv71.7.1 = zext i8 %12948 to i32
  %xor72.7.1 = xor i32 %conv71.7.1, %conv68.7.1
  %conv73.7.1 = trunc i32 %xor72.7.1 to i8
  store i8 %conv73.7.1, i8* %arrayidx70.1, align 1
  %scevgep20.8.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 8
  %12949 = load i8, i8* %scevgep20.8.1, align 1
  %conv68.8.1 = zext i8 %12949 to i32
  %12950 = load i8, i8* %arrayidx70.1, align 1
  %conv71.8.1 = zext i8 %12950 to i32
  %xor72.8.1 = xor i32 %conv71.8.1, %conv68.8.1
  %conv73.8.1 = trunc i32 %xor72.8.1 to i8
  store i8 %conv73.8.1, i8* %arrayidx70.1, align 1
  %scevgep20.9.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 9
  %12951 = load i8, i8* %scevgep20.9.1, align 1
  %conv68.9.1 = zext i8 %12951 to i32
  %12952 = load i8, i8* %arrayidx70.1, align 1
  %conv71.9.1 = zext i8 %12952 to i32
  %xor72.9.1 = xor i32 %conv71.9.1, %conv68.9.1
  %conv73.9.1 = trunc i32 %xor72.9.1 to i8
  store i8 %conv73.9.1, i8* %arrayidx70.1, align 1
  %scevgep20.10.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 10
  %12953 = load i8, i8* %scevgep20.10.1, align 1
  %conv68.10.1 = zext i8 %12953 to i32
  %12954 = load i8, i8* %arrayidx70.1, align 1
  %conv71.10.1 = zext i8 %12954 to i32
  %xor72.10.1 = xor i32 %conv71.10.1, %conv68.10.1
  %conv73.10.1 = trunc i32 %xor72.10.1 to i8
  store i8 %conv73.10.1, i8* %arrayidx70.1, align 1
  %scevgep20.11.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 11
  %12955 = load i8, i8* %scevgep20.11.1, align 1
  %conv68.11.1 = zext i8 %12955 to i32
  %12956 = load i8, i8* %arrayidx70.1, align 1
  %conv71.11.1 = zext i8 %12956 to i32
  %xor72.11.1 = xor i32 %conv71.11.1, %conv68.11.1
  %conv73.11.1 = trunc i32 %xor72.11.1 to i8
  store i8 %conv73.11.1, i8* %arrayidx70.1, align 1
  %scevgep20.12.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 12
  %12957 = load i8, i8* %scevgep20.12.1, align 1
  %conv68.12.1 = zext i8 %12957 to i32
  %12958 = load i8, i8* %arrayidx70.1, align 1
  %conv71.12.1 = zext i8 %12958 to i32
  %xor72.12.1 = xor i32 %conv71.12.1, %conv68.12.1
  %conv73.12.1 = trunc i32 %xor72.12.1 to i8
  store i8 %conv73.12.1, i8* %arrayidx70.1, align 1
  %scevgep20.13.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 13
  %12959 = load i8, i8* %scevgep20.13.1, align 1
  %conv68.13.1 = zext i8 %12959 to i32
  %12960 = load i8, i8* %arrayidx70.1, align 1
  %conv71.13.1 = zext i8 %12960 to i32
  %xor72.13.1 = xor i32 %conv71.13.1, %conv68.13.1
  %conv73.13.1 = trunc i32 %xor72.13.1 to i8
  store i8 %conv73.13.1, i8* %arrayidx70.1, align 1
  %scevgep20.14.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 14
  %12961 = load i8, i8* %scevgep20.14.1, align 1
  %conv68.14.1 = zext i8 %12961 to i32
  %12962 = load i8, i8* %arrayidx70.1, align 1
  %conv71.14.1 = zext i8 %12962 to i32
  %xor72.14.1 = xor i32 %conv71.14.1, %conv68.14.1
  %conv73.14.1 = trunc i32 %xor72.14.1 to i8
  store i8 %conv73.14.1, i8* %arrayidx70.1, align 1
  %scevgep20.15.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 15
  %12963 = load i8, i8* %scevgep20.15.1, align 1
  %conv68.15.1 = zext i8 %12963 to i32
  %12964 = load i8, i8* %arrayidx70.1, align 1
  %conv71.15.1 = zext i8 %12964 to i32
  %xor72.15.1 = xor i32 %conv71.15.1, %conv68.15.1
  %conv73.15.1 = trunc i32 %xor72.15.1 to i8
  store i8 %conv73.15.1, i8* %arrayidx70.1, align 1
  %scevgep20.16.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 16
  %12965 = load i8, i8* %scevgep20.16.1, align 1
  %conv68.16.1 = zext i8 %12965 to i32
  %12966 = load i8, i8* %arrayidx70.1, align 1
  %conv71.16.1 = zext i8 %12966 to i32
  %xor72.16.1 = xor i32 %conv71.16.1, %conv68.16.1
  %conv73.16.1 = trunc i32 %xor72.16.1 to i8
  store i8 %conv73.16.1, i8* %arrayidx70.1, align 1
  %scevgep20.17.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 17
  %12967 = load i8, i8* %scevgep20.17.1, align 1
  %conv68.17.1 = zext i8 %12967 to i32
  %12968 = load i8, i8* %arrayidx70.1, align 1
  %conv71.17.1 = zext i8 %12968 to i32
  %xor72.17.1 = xor i32 %conv71.17.1, %conv68.17.1
  %conv73.17.1 = trunc i32 %xor72.17.1 to i8
  store i8 %conv73.17.1, i8* %arrayidx70.1, align 1
  %scevgep20.18.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 18
  %12969 = load i8, i8* %scevgep20.18.1, align 1
  %conv68.18.1 = zext i8 %12969 to i32
  %12970 = load i8, i8* %arrayidx70.1, align 1
  %conv71.18.1 = zext i8 %12970 to i32
  %xor72.18.1 = xor i32 %conv71.18.1, %conv68.18.1
  %conv73.18.1 = trunc i32 %xor72.18.1 to i8
  store i8 %conv73.18.1, i8* %arrayidx70.1, align 1
  %scevgep20.19.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 19
  %12971 = load i8, i8* %scevgep20.19.1, align 1
  %conv68.19.1 = zext i8 %12971 to i32
  %12972 = load i8, i8* %arrayidx70.1, align 1
  %conv71.19.1 = zext i8 %12972 to i32
  %xor72.19.1 = xor i32 %conv71.19.1, %conv68.19.1
  %conv73.19.1 = trunc i32 %xor72.19.1 to i8
  store i8 %conv73.19.1, i8* %arrayidx70.1, align 1
  %scevgep20.20.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 20
  %12973 = load i8, i8* %scevgep20.20.1, align 1
  %conv68.20.1 = zext i8 %12973 to i32
  %12974 = load i8, i8* %arrayidx70.1, align 1
  %conv71.20.1 = zext i8 %12974 to i32
  %xor72.20.1 = xor i32 %conv71.20.1, %conv68.20.1
  %conv73.20.1 = trunc i32 %xor72.20.1 to i8
  store i8 %conv73.20.1, i8* %arrayidx70.1, align 1
  %scevgep20.21.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 21
  %12975 = load i8, i8* %scevgep20.21.1, align 1
  %conv68.21.1 = zext i8 %12975 to i32
  %12976 = load i8, i8* %arrayidx70.1, align 1
  %conv71.21.1 = zext i8 %12976 to i32
  %xor72.21.1 = xor i32 %conv71.21.1, %conv68.21.1
  %conv73.21.1 = trunc i32 %xor72.21.1 to i8
  store i8 %conv73.21.1, i8* %arrayidx70.1, align 1
  %scevgep20.22.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 22
  %12977 = load i8, i8* %scevgep20.22.1, align 1
  %conv68.22.1 = zext i8 %12977 to i32
  %12978 = load i8, i8* %arrayidx70.1, align 1
  %conv71.22.1 = zext i8 %12978 to i32
  %xor72.22.1 = xor i32 %conv71.22.1, %conv68.22.1
  %conv73.22.1 = trunc i32 %xor72.22.1 to i8
  store i8 %conv73.22.1, i8* %arrayidx70.1, align 1
  %scevgep20.23.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 23
  %12979 = load i8, i8* %scevgep20.23.1, align 1
  %conv68.23.1 = zext i8 %12979 to i32
  %12980 = load i8, i8* %arrayidx70.1, align 1
  %conv71.23.1 = zext i8 %12980 to i32
  %xor72.23.1 = xor i32 %conv71.23.1, %conv68.23.1
  %conv73.23.1 = trunc i32 %xor72.23.1 to i8
  store i8 %conv73.23.1, i8* %arrayidx70.1, align 1
  %scevgep20.24.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 24
  %12981 = load i8, i8* %scevgep20.24.1, align 1
  %conv68.24.1 = zext i8 %12981 to i32
  %12982 = load i8, i8* %arrayidx70.1, align 1
  %conv71.24.1 = zext i8 %12982 to i32
  %xor72.24.1 = xor i32 %conv71.24.1, %conv68.24.1
  %conv73.24.1 = trunc i32 %xor72.24.1 to i8
  store i8 %conv73.24.1, i8* %arrayidx70.1, align 1
  %scevgep20.25.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 25
  %12983 = load i8, i8* %scevgep20.25.1, align 1
  %conv68.25.1 = zext i8 %12983 to i32
  %12984 = load i8, i8* %arrayidx70.1, align 1
  %conv71.25.1 = zext i8 %12984 to i32
  %xor72.25.1 = xor i32 %conv71.25.1, %conv68.25.1
  %conv73.25.1 = trunc i32 %xor72.25.1 to i8
  store i8 %conv73.25.1, i8* %arrayidx70.1, align 1
  %scevgep20.26.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 26
  %12985 = load i8, i8* %scevgep20.26.1, align 1
  %conv68.26.1 = zext i8 %12985 to i32
  %12986 = load i8, i8* %arrayidx70.1, align 1
  %conv71.26.1 = zext i8 %12986 to i32
  %xor72.26.1 = xor i32 %conv71.26.1, %conv68.26.1
  %conv73.26.1 = trunc i32 %xor72.26.1 to i8
  store i8 %conv73.26.1, i8* %arrayidx70.1, align 1
  %scevgep20.27.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 27
  %12987 = load i8, i8* %scevgep20.27.1, align 1
  %conv68.27.1 = zext i8 %12987 to i32
  %12988 = load i8, i8* %arrayidx70.1, align 1
  %conv71.27.1 = zext i8 %12988 to i32
  %xor72.27.1 = xor i32 %conv71.27.1, %conv68.27.1
  %conv73.27.1 = trunc i32 %xor72.27.1 to i8
  store i8 %conv73.27.1, i8* %arrayidx70.1, align 1
  %scevgep20.28.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 28
  %12989 = load i8, i8* %scevgep20.28.1, align 1
  %conv68.28.1 = zext i8 %12989 to i32
  %12990 = load i8, i8* %arrayidx70.1, align 1
  %conv71.28.1 = zext i8 %12990 to i32
  %xor72.28.1 = xor i32 %conv71.28.1, %conv68.28.1
  %conv73.28.1 = trunc i32 %xor72.28.1 to i8
  store i8 %conv73.28.1, i8* %arrayidx70.1, align 1
  %scevgep20.29.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 29
  %12991 = load i8, i8* %scevgep20.29.1, align 1
  %conv68.29.1 = zext i8 %12991 to i32
  %12992 = load i8, i8* %arrayidx70.1, align 1
  %conv71.29.1 = zext i8 %12992 to i32
  %xor72.29.1 = xor i32 %conv71.29.1, %conv68.29.1
  %conv73.29.1 = trunc i32 %xor72.29.1 to i8
  store i8 %conv73.29.1, i8* %arrayidx70.1, align 1
  %scevgep20.30.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 30
  %12993 = load i8, i8* %scevgep20.30.1, align 1
  %conv68.30.1 = zext i8 %12993 to i32
  %12994 = load i8, i8* %arrayidx70.1, align 1
  %conv71.30.1 = zext i8 %12994 to i32
  %xor72.30.1 = xor i32 %conv71.30.1, %conv68.30.1
  %conv73.30.1 = trunc i32 %xor72.30.1 to i8
  store i8 %conv73.30.1, i8* %arrayidx70.1, align 1
  %scevgep20.31.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 31
  %12995 = load i8, i8* %scevgep20.31.1, align 1
  %conv68.31.1 = zext i8 %12995 to i32
  %12996 = load i8, i8* %arrayidx70.1, align 1
  %conv71.31.1 = zext i8 %12996 to i32
  %xor72.31.1 = xor i32 %conv71.31.1, %conv68.31.1
  %conv73.31.1 = trunc i32 %xor72.31.1 to i8
  store i8 %conv73.31.1, i8* %arrayidx70.1, align 1
  %scevgep20.32.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 32
  %12997 = load i8, i8* %scevgep20.32.1, align 1
  %conv68.32.1 = zext i8 %12997 to i32
  %12998 = load i8, i8* %arrayidx70.1, align 1
  %conv71.32.1 = zext i8 %12998 to i32
  %xor72.32.1 = xor i32 %conv71.32.1, %conv68.32.1
  %conv73.32.1 = trunc i32 %xor72.32.1 to i8
  store i8 %conv73.32.1, i8* %arrayidx70.1, align 1
  %scevgep20.33.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 33
  %12999 = load i8, i8* %scevgep20.33.1, align 1
  %conv68.33.1 = zext i8 %12999 to i32
  %13000 = load i8, i8* %arrayidx70.1, align 1
  %conv71.33.1 = zext i8 %13000 to i32
  %xor72.33.1 = xor i32 %conv71.33.1, %conv68.33.1
  %conv73.33.1 = trunc i32 %xor72.33.1 to i8
  store i8 %conv73.33.1, i8* %arrayidx70.1, align 1
  %scevgep20.34.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 34
  %13001 = load i8, i8* %scevgep20.34.1, align 1
  %conv68.34.1 = zext i8 %13001 to i32
  %13002 = load i8, i8* %arrayidx70.1, align 1
  %conv71.34.1 = zext i8 %13002 to i32
  %xor72.34.1 = xor i32 %conv71.34.1, %conv68.34.1
  %conv73.34.1 = trunc i32 %xor72.34.1 to i8
  store i8 %conv73.34.1, i8* %arrayidx70.1, align 1
  %scevgep20.35.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 35
  %13003 = load i8, i8* %scevgep20.35.1, align 1
  %conv68.35.1 = zext i8 %13003 to i32
  %13004 = load i8, i8* %arrayidx70.1, align 1
  %conv71.35.1 = zext i8 %13004 to i32
  %xor72.35.1 = xor i32 %conv71.35.1, %conv68.35.1
  %conv73.35.1 = trunc i32 %xor72.35.1 to i8
  store i8 %conv73.35.1, i8* %arrayidx70.1, align 1
  %scevgep20.36.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 36
  %13005 = load i8, i8* %scevgep20.36.1, align 1
  %conv68.36.1 = zext i8 %13005 to i32
  %13006 = load i8, i8* %arrayidx70.1, align 1
  %conv71.36.1 = zext i8 %13006 to i32
  %xor72.36.1 = xor i32 %conv71.36.1, %conv68.36.1
  %conv73.36.1 = trunc i32 %xor72.36.1 to i8
  store i8 %conv73.36.1, i8* %arrayidx70.1, align 1
  %scevgep20.37.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 37
  %13007 = load i8, i8* %scevgep20.37.1, align 1
  %conv68.37.1 = zext i8 %13007 to i32
  %13008 = load i8, i8* %arrayidx70.1, align 1
  %conv71.37.1 = zext i8 %13008 to i32
  %xor72.37.1 = xor i32 %conv71.37.1, %conv68.37.1
  %conv73.37.1 = trunc i32 %xor72.37.1 to i8
  store i8 %conv73.37.1, i8* %arrayidx70.1, align 1
  %scevgep20.38.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 38
  %13009 = load i8, i8* %scevgep20.38.1, align 1
  %conv68.38.1 = zext i8 %13009 to i32
  %13010 = load i8, i8* %arrayidx70.1, align 1
  %conv71.38.1 = zext i8 %13010 to i32
  %xor72.38.1 = xor i32 %conv71.38.1, %conv68.38.1
  %conv73.38.1 = trunc i32 %xor72.38.1 to i8
  store i8 %conv73.38.1, i8* %arrayidx70.1, align 1
  %scevgep20.39.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 39
  %13011 = load i8, i8* %scevgep20.39.1, align 1
  %conv68.39.1 = zext i8 %13011 to i32
  %13012 = load i8, i8* %arrayidx70.1, align 1
  %conv71.39.1 = zext i8 %13012 to i32
  %xor72.39.1 = xor i32 %conv71.39.1, %conv68.39.1
  %conv73.39.1 = trunc i32 %xor72.39.1 to i8
  store i8 %conv73.39.1, i8* %arrayidx70.1, align 1
  %scevgep20.40.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 40
  %13013 = load i8, i8* %scevgep20.40.1, align 1
  %conv68.40.1 = zext i8 %13013 to i32
  %13014 = load i8, i8* %arrayidx70.1, align 1
  %conv71.40.1 = zext i8 %13014 to i32
  %xor72.40.1 = xor i32 %conv71.40.1, %conv68.40.1
  %conv73.40.1 = trunc i32 %xor72.40.1 to i8
  store i8 %conv73.40.1, i8* %arrayidx70.1, align 1
  %scevgep20.41.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 41
  %13015 = load i8, i8* %scevgep20.41.1, align 1
  %conv68.41.1 = zext i8 %13015 to i32
  %13016 = load i8, i8* %arrayidx70.1, align 1
  %conv71.41.1 = zext i8 %13016 to i32
  %xor72.41.1 = xor i32 %conv71.41.1, %conv68.41.1
  %conv73.41.1 = trunc i32 %xor72.41.1 to i8
  store i8 %conv73.41.1, i8* %arrayidx70.1, align 1
  %scevgep20.42.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 42
  %13017 = load i8, i8* %scevgep20.42.1, align 1
  %conv68.42.1 = zext i8 %13017 to i32
  %13018 = load i8, i8* %arrayidx70.1, align 1
  %conv71.42.1 = zext i8 %13018 to i32
  %xor72.42.1 = xor i32 %conv71.42.1, %conv68.42.1
  %conv73.42.1 = trunc i32 %xor72.42.1 to i8
  store i8 %conv73.42.1, i8* %arrayidx70.1, align 1
  %scevgep20.43.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 43
  %13019 = load i8, i8* %scevgep20.43.1, align 1
  %conv68.43.1 = zext i8 %13019 to i32
  %13020 = load i8, i8* %arrayidx70.1, align 1
  %conv71.43.1 = zext i8 %13020 to i32
  %xor72.43.1 = xor i32 %conv71.43.1, %conv68.43.1
  %conv73.43.1 = trunc i32 %xor72.43.1 to i8
  store i8 %conv73.43.1, i8* %arrayidx70.1, align 1
  %scevgep20.44.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 44
  %13021 = load i8, i8* %scevgep20.44.1, align 1
  %conv68.44.1 = zext i8 %13021 to i32
  %13022 = load i8, i8* %arrayidx70.1, align 1
  %conv71.44.1 = zext i8 %13022 to i32
  %xor72.44.1 = xor i32 %conv71.44.1, %conv68.44.1
  %conv73.44.1 = trunc i32 %xor72.44.1 to i8
  store i8 %conv73.44.1, i8* %arrayidx70.1, align 1
  %scevgep20.45.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 45
  %13023 = load i8, i8* %scevgep20.45.1, align 1
  %conv68.45.1 = zext i8 %13023 to i32
  %13024 = load i8, i8* %arrayidx70.1, align 1
  %conv71.45.1 = zext i8 %13024 to i32
  %xor72.45.1 = xor i32 %conv71.45.1, %conv68.45.1
  %conv73.45.1 = trunc i32 %xor72.45.1 to i8
  store i8 %conv73.45.1, i8* %arrayidx70.1, align 1
  %scevgep20.46.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 46
  %13025 = load i8, i8* %scevgep20.46.1, align 1
  %conv68.46.1 = zext i8 %13025 to i32
  %13026 = load i8, i8* %arrayidx70.1, align 1
  %conv71.46.1 = zext i8 %13026 to i32
  %xor72.46.1 = xor i32 %conv71.46.1, %conv68.46.1
  %conv73.46.1 = trunc i32 %xor72.46.1 to i8
  store i8 %conv73.46.1, i8* %arrayidx70.1, align 1
  %scevgep20.47.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 47
  %13027 = load i8, i8* %scevgep20.47.1, align 1
  %conv68.47.1 = zext i8 %13027 to i32
  %13028 = load i8, i8* %arrayidx70.1, align 1
  %conv71.47.1 = zext i8 %13028 to i32
  %xor72.47.1 = xor i32 %conv71.47.1, %conv68.47.1
  %conv73.47.1 = trunc i32 %xor72.47.1 to i8
  store i8 %conv73.47.1, i8* %arrayidx70.1, align 1
  %scevgep20.48.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 48
  %13029 = load i8, i8* %scevgep20.48.1, align 1
  %conv68.48.1 = zext i8 %13029 to i32
  %13030 = load i8, i8* %arrayidx70.1, align 1
  %conv71.48.1 = zext i8 %13030 to i32
  %xor72.48.1 = xor i32 %conv71.48.1, %conv68.48.1
  %conv73.48.1 = trunc i32 %xor72.48.1 to i8
  store i8 %conv73.48.1, i8* %arrayidx70.1, align 1
  %scevgep20.49.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 49
  %13031 = load i8, i8* %scevgep20.49.1, align 1
  %conv68.49.1 = zext i8 %13031 to i32
  %13032 = load i8, i8* %arrayidx70.1, align 1
  %conv71.49.1 = zext i8 %13032 to i32
  %xor72.49.1 = xor i32 %conv71.49.1, %conv68.49.1
  %conv73.49.1 = trunc i32 %xor72.49.1 to i8
  store i8 %conv73.49.1, i8* %arrayidx70.1, align 1
  %scevgep20.50.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 50
  %13033 = load i8, i8* %scevgep20.50.1, align 1
  %conv68.50.1 = zext i8 %13033 to i32
  %13034 = load i8, i8* %arrayidx70.1, align 1
  %conv71.50.1 = zext i8 %13034 to i32
  %xor72.50.1 = xor i32 %conv71.50.1, %conv68.50.1
  %conv73.50.1 = trunc i32 %xor72.50.1 to i8
  store i8 %conv73.50.1, i8* %arrayidx70.1, align 1
  %scevgep20.51.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 51
  %13035 = load i8, i8* %scevgep20.51.1, align 1
  %conv68.51.1 = zext i8 %13035 to i32
  %13036 = load i8, i8* %arrayidx70.1, align 1
  %conv71.51.1 = zext i8 %13036 to i32
  %xor72.51.1 = xor i32 %conv71.51.1, %conv68.51.1
  %conv73.51.1 = trunc i32 %xor72.51.1 to i8
  store i8 %conv73.51.1, i8* %arrayidx70.1, align 1
  %scevgep20.52.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 52
  %13037 = load i8, i8* %scevgep20.52.1, align 1
  %conv68.52.1 = zext i8 %13037 to i32
  %13038 = load i8, i8* %arrayidx70.1, align 1
  %conv71.52.1 = zext i8 %13038 to i32
  %xor72.52.1 = xor i32 %conv71.52.1, %conv68.52.1
  %conv73.52.1 = trunc i32 %xor72.52.1 to i8
  store i8 %conv73.52.1, i8* %arrayidx70.1, align 1
  %scevgep20.53.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 53
  %13039 = load i8, i8* %scevgep20.53.1, align 1
  %conv68.53.1 = zext i8 %13039 to i32
  %13040 = load i8, i8* %arrayidx70.1, align 1
  %conv71.53.1 = zext i8 %13040 to i32
  %xor72.53.1 = xor i32 %conv71.53.1, %conv68.53.1
  %conv73.53.1 = trunc i32 %xor72.53.1 to i8
  store i8 %conv73.53.1, i8* %arrayidx70.1, align 1
  %scevgep20.54.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 54
  %13041 = load i8, i8* %scevgep20.54.1, align 1
  %conv68.54.1 = zext i8 %13041 to i32
  %13042 = load i8, i8* %arrayidx70.1, align 1
  %conv71.54.1 = zext i8 %13042 to i32
  %xor72.54.1 = xor i32 %conv71.54.1, %conv68.54.1
  %conv73.54.1 = trunc i32 %xor72.54.1 to i8
  store i8 %conv73.54.1, i8* %arrayidx70.1, align 1
  %scevgep20.55.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 55
  %13043 = load i8, i8* %scevgep20.55.1, align 1
  %conv68.55.1 = zext i8 %13043 to i32
  %13044 = load i8, i8* %arrayidx70.1, align 1
  %conv71.55.1 = zext i8 %13044 to i32
  %xor72.55.1 = xor i32 %conv71.55.1, %conv68.55.1
  %conv73.55.1 = trunc i32 %xor72.55.1 to i8
  store i8 %conv73.55.1, i8* %arrayidx70.1, align 1
  %scevgep20.56.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 56
  %13045 = load i8, i8* %scevgep20.56.1, align 1
  %conv68.56.1 = zext i8 %13045 to i32
  %13046 = load i8, i8* %arrayidx70.1, align 1
  %conv71.56.1 = zext i8 %13046 to i32
  %xor72.56.1 = xor i32 %conv71.56.1, %conv68.56.1
  %conv73.56.1 = trunc i32 %xor72.56.1 to i8
  store i8 %conv73.56.1, i8* %arrayidx70.1, align 1
  %scevgep20.57.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 57
  %13047 = load i8, i8* %scevgep20.57.1, align 1
  %conv68.57.1 = zext i8 %13047 to i32
  %13048 = load i8, i8* %arrayidx70.1, align 1
  %conv71.57.1 = zext i8 %13048 to i32
  %xor72.57.1 = xor i32 %conv71.57.1, %conv68.57.1
  %conv73.57.1 = trunc i32 %xor72.57.1 to i8
  store i8 %conv73.57.1, i8* %arrayidx70.1, align 1
  %scevgep20.58.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 58
  %13049 = load i8, i8* %scevgep20.58.1, align 1
  %conv68.58.1 = zext i8 %13049 to i32
  %13050 = load i8, i8* %arrayidx70.1, align 1
  %conv71.58.1 = zext i8 %13050 to i32
  %xor72.58.1 = xor i32 %conv71.58.1, %conv68.58.1
  %conv73.58.1 = trunc i32 %xor72.58.1 to i8
  store i8 %conv73.58.1, i8* %arrayidx70.1, align 1
  %scevgep20.59.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 59
  %13051 = load i8, i8* %scevgep20.59.1, align 1
  %conv68.59.1 = zext i8 %13051 to i32
  %13052 = load i8, i8* %arrayidx70.1, align 1
  %conv71.59.1 = zext i8 %13052 to i32
  %xor72.59.1 = xor i32 %conv71.59.1, %conv68.59.1
  %conv73.59.1 = trunc i32 %xor72.59.1 to i8
  store i8 %conv73.59.1, i8* %arrayidx70.1, align 1
  %scevgep20.60.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 0, i64 60
  %13053 = load i8, i8* %scevgep20.60.1, align 1
  %conv68.60.1 = zext i8 %13053 to i32
  %13054 = load i8, i8* %arrayidx70.1, align 1
  %conv71.60.1 = zext i8 %13054 to i32
  %xor72.60.1 = xor i32 %conv71.60.1, %conv68.60.1
  %conv73.60.1 = trunc i32 %xor72.60.1 to i8
  store i8 %conv73.60.1, i8* %arrayidx70.1, align 1
  %scevgep19.1 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %12932, i64 0, i64 1, i64 0
  %13055 = bitcast i8* %scevgep19.1 to [61 x [61 x i8]]*
  %arrayidx51.2 = getelementptr inbounds i8, i8* %a, i64 2
  %13056 = load i8, i8* %arrayidx51.2, align 1
  %arrayidx53.2 = getelementptr inbounds i8, i8* %b, i64 2
  %13057 = load i8, i8* %arrayidx53.2, align 1
  %call54.2 = call zeroext i8 @mult(i8 zeroext %13056, i8 zeroext %13057)
  %arrayidx56.2 = getelementptr inbounds i8, i8* %c, i64 2
  store i8 %call54.2, i8* %arrayidx56.2, align 1
  %arrayidx70.2 = getelementptr inbounds i8, i8* %c, i64 2
  %scevgep20.264 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 0
  %13058 = load i8, i8* %scevgep20.264, align 1
  %conv68.265 = zext i8 %13058 to i32
  %13059 = load i8, i8* %arrayidx70.2, align 1
  %conv71.266 = zext i8 %13059 to i32
  %xor72.267 = xor i32 %conv71.266, %conv68.265
  %conv73.268 = trunc i32 %xor72.267 to i8
  store i8 %conv73.268, i8* %arrayidx70.2, align 1
  %scevgep20.1.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 1
  %13060 = load i8, i8* %scevgep20.1.2, align 1
  %conv68.1.2 = zext i8 %13060 to i32
  %13061 = load i8, i8* %arrayidx70.2, align 1
  %conv71.1.2 = zext i8 %13061 to i32
  %xor72.1.2 = xor i32 %conv71.1.2, %conv68.1.2
  %conv73.1.2 = trunc i32 %xor72.1.2 to i8
  store i8 %conv73.1.2, i8* %arrayidx70.2, align 1
  %scevgep20.3.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 3
  %13062 = load i8, i8* %scevgep20.3.2, align 1
  %conv68.3.2 = zext i8 %13062 to i32
  %13063 = load i8, i8* %arrayidx70.2, align 1
  %conv71.3.2 = zext i8 %13063 to i32
  %xor72.3.2 = xor i32 %conv71.3.2, %conv68.3.2
  %conv73.3.2 = trunc i32 %xor72.3.2 to i8
  store i8 %conv73.3.2, i8* %arrayidx70.2, align 1
  %scevgep20.4.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 4
  %13064 = load i8, i8* %scevgep20.4.2, align 1
  %conv68.4.2 = zext i8 %13064 to i32
  %13065 = load i8, i8* %arrayidx70.2, align 1
  %conv71.4.2 = zext i8 %13065 to i32
  %xor72.4.2 = xor i32 %conv71.4.2, %conv68.4.2
  %conv73.4.2 = trunc i32 %xor72.4.2 to i8
  store i8 %conv73.4.2, i8* %arrayidx70.2, align 1
  %scevgep20.5.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 5
  %13066 = load i8, i8* %scevgep20.5.2, align 1
  %conv68.5.2 = zext i8 %13066 to i32
  %13067 = load i8, i8* %arrayidx70.2, align 1
  %conv71.5.2 = zext i8 %13067 to i32
  %xor72.5.2 = xor i32 %conv71.5.2, %conv68.5.2
  %conv73.5.2 = trunc i32 %xor72.5.2 to i8
  store i8 %conv73.5.2, i8* %arrayidx70.2, align 1
  %scevgep20.6.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 6
  %13068 = load i8, i8* %scevgep20.6.2, align 1
  %conv68.6.2 = zext i8 %13068 to i32
  %13069 = load i8, i8* %arrayidx70.2, align 1
  %conv71.6.2 = zext i8 %13069 to i32
  %xor72.6.2 = xor i32 %conv71.6.2, %conv68.6.2
  %conv73.6.2 = trunc i32 %xor72.6.2 to i8
  store i8 %conv73.6.2, i8* %arrayidx70.2, align 1
  %scevgep20.7.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 7
  %13070 = load i8, i8* %scevgep20.7.2, align 1
  %conv68.7.2 = zext i8 %13070 to i32
  %13071 = load i8, i8* %arrayidx70.2, align 1
  %conv71.7.2 = zext i8 %13071 to i32
  %xor72.7.2 = xor i32 %conv71.7.2, %conv68.7.2
  %conv73.7.2 = trunc i32 %xor72.7.2 to i8
  store i8 %conv73.7.2, i8* %arrayidx70.2, align 1
  %scevgep20.8.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 8
  %13072 = load i8, i8* %scevgep20.8.2, align 1
  %conv68.8.2 = zext i8 %13072 to i32
  %13073 = load i8, i8* %arrayidx70.2, align 1
  %conv71.8.2 = zext i8 %13073 to i32
  %xor72.8.2 = xor i32 %conv71.8.2, %conv68.8.2
  %conv73.8.2 = trunc i32 %xor72.8.2 to i8
  store i8 %conv73.8.2, i8* %arrayidx70.2, align 1
  %scevgep20.9.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 9
  %13074 = load i8, i8* %scevgep20.9.2, align 1
  %conv68.9.2 = zext i8 %13074 to i32
  %13075 = load i8, i8* %arrayidx70.2, align 1
  %conv71.9.2 = zext i8 %13075 to i32
  %xor72.9.2 = xor i32 %conv71.9.2, %conv68.9.2
  %conv73.9.2 = trunc i32 %xor72.9.2 to i8
  store i8 %conv73.9.2, i8* %arrayidx70.2, align 1
  %scevgep20.10.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 10
  %13076 = load i8, i8* %scevgep20.10.2, align 1
  %conv68.10.2 = zext i8 %13076 to i32
  %13077 = load i8, i8* %arrayidx70.2, align 1
  %conv71.10.2 = zext i8 %13077 to i32
  %xor72.10.2 = xor i32 %conv71.10.2, %conv68.10.2
  %conv73.10.2 = trunc i32 %xor72.10.2 to i8
  store i8 %conv73.10.2, i8* %arrayidx70.2, align 1
  %scevgep20.11.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 11
  %13078 = load i8, i8* %scevgep20.11.2, align 1
  %conv68.11.2 = zext i8 %13078 to i32
  %13079 = load i8, i8* %arrayidx70.2, align 1
  %conv71.11.2 = zext i8 %13079 to i32
  %xor72.11.2 = xor i32 %conv71.11.2, %conv68.11.2
  %conv73.11.2 = trunc i32 %xor72.11.2 to i8
  store i8 %conv73.11.2, i8* %arrayidx70.2, align 1
  %scevgep20.12.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 12
  %13080 = load i8, i8* %scevgep20.12.2, align 1
  %conv68.12.2 = zext i8 %13080 to i32
  %13081 = load i8, i8* %arrayidx70.2, align 1
  %conv71.12.2 = zext i8 %13081 to i32
  %xor72.12.2 = xor i32 %conv71.12.2, %conv68.12.2
  %conv73.12.2 = trunc i32 %xor72.12.2 to i8
  store i8 %conv73.12.2, i8* %arrayidx70.2, align 1
  %scevgep20.13.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 13
  %13082 = load i8, i8* %scevgep20.13.2, align 1
  %conv68.13.2 = zext i8 %13082 to i32
  %13083 = load i8, i8* %arrayidx70.2, align 1
  %conv71.13.2 = zext i8 %13083 to i32
  %xor72.13.2 = xor i32 %conv71.13.2, %conv68.13.2
  %conv73.13.2 = trunc i32 %xor72.13.2 to i8
  store i8 %conv73.13.2, i8* %arrayidx70.2, align 1
  %scevgep20.14.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 14
  %13084 = load i8, i8* %scevgep20.14.2, align 1
  %conv68.14.2 = zext i8 %13084 to i32
  %13085 = load i8, i8* %arrayidx70.2, align 1
  %conv71.14.2 = zext i8 %13085 to i32
  %xor72.14.2 = xor i32 %conv71.14.2, %conv68.14.2
  %conv73.14.2 = trunc i32 %xor72.14.2 to i8
  store i8 %conv73.14.2, i8* %arrayidx70.2, align 1
  %scevgep20.15.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 15
  %13086 = load i8, i8* %scevgep20.15.2, align 1
  %conv68.15.2 = zext i8 %13086 to i32
  %13087 = load i8, i8* %arrayidx70.2, align 1
  %conv71.15.2 = zext i8 %13087 to i32
  %xor72.15.2 = xor i32 %conv71.15.2, %conv68.15.2
  %conv73.15.2 = trunc i32 %xor72.15.2 to i8
  store i8 %conv73.15.2, i8* %arrayidx70.2, align 1
  %scevgep20.16.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 16
  %13088 = load i8, i8* %scevgep20.16.2, align 1
  %conv68.16.2 = zext i8 %13088 to i32
  %13089 = load i8, i8* %arrayidx70.2, align 1
  %conv71.16.2 = zext i8 %13089 to i32
  %xor72.16.2 = xor i32 %conv71.16.2, %conv68.16.2
  %conv73.16.2 = trunc i32 %xor72.16.2 to i8
  store i8 %conv73.16.2, i8* %arrayidx70.2, align 1
  %scevgep20.17.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 17
  %13090 = load i8, i8* %scevgep20.17.2, align 1
  %conv68.17.2 = zext i8 %13090 to i32
  %13091 = load i8, i8* %arrayidx70.2, align 1
  %conv71.17.2 = zext i8 %13091 to i32
  %xor72.17.2 = xor i32 %conv71.17.2, %conv68.17.2
  %conv73.17.2 = trunc i32 %xor72.17.2 to i8
  store i8 %conv73.17.2, i8* %arrayidx70.2, align 1
  %scevgep20.18.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 18
  %13092 = load i8, i8* %scevgep20.18.2, align 1
  %conv68.18.2 = zext i8 %13092 to i32
  %13093 = load i8, i8* %arrayidx70.2, align 1
  %conv71.18.2 = zext i8 %13093 to i32
  %xor72.18.2 = xor i32 %conv71.18.2, %conv68.18.2
  %conv73.18.2 = trunc i32 %xor72.18.2 to i8
  store i8 %conv73.18.2, i8* %arrayidx70.2, align 1
  %scevgep20.19.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 19
  %13094 = load i8, i8* %scevgep20.19.2, align 1
  %conv68.19.2 = zext i8 %13094 to i32
  %13095 = load i8, i8* %arrayidx70.2, align 1
  %conv71.19.2 = zext i8 %13095 to i32
  %xor72.19.2 = xor i32 %conv71.19.2, %conv68.19.2
  %conv73.19.2 = trunc i32 %xor72.19.2 to i8
  store i8 %conv73.19.2, i8* %arrayidx70.2, align 1
  %scevgep20.20.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 20
  %13096 = load i8, i8* %scevgep20.20.2, align 1
  %conv68.20.2 = zext i8 %13096 to i32
  %13097 = load i8, i8* %arrayidx70.2, align 1
  %conv71.20.2 = zext i8 %13097 to i32
  %xor72.20.2 = xor i32 %conv71.20.2, %conv68.20.2
  %conv73.20.2 = trunc i32 %xor72.20.2 to i8
  store i8 %conv73.20.2, i8* %arrayidx70.2, align 1
  %scevgep20.21.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 21
  %13098 = load i8, i8* %scevgep20.21.2, align 1
  %conv68.21.2 = zext i8 %13098 to i32
  %13099 = load i8, i8* %arrayidx70.2, align 1
  %conv71.21.2 = zext i8 %13099 to i32
  %xor72.21.2 = xor i32 %conv71.21.2, %conv68.21.2
  %conv73.21.2 = trunc i32 %xor72.21.2 to i8
  store i8 %conv73.21.2, i8* %arrayidx70.2, align 1
  %scevgep20.22.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 22
  %13100 = load i8, i8* %scevgep20.22.2, align 1
  %conv68.22.2 = zext i8 %13100 to i32
  %13101 = load i8, i8* %arrayidx70.2, align 1
  %conv71.22.2 = zext i8 %13101 to i32
  %xor72.22.2 = xor i32 %conv71.22.2, %conv68.22.2
  %conv73.22.2 = trunc i32 %xor72.22.2 to i8
  store i8 %conv73.22.2, i8* %arrayidx70.2, align 1
  %scevgep20.23.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 23
  %13102 = load i8, i8* %scevgep20.23.2, align 1
  %conv68.23.2 = zext i8 %13102 to i32
  %13103 = load i8, i8* %arrayidx70.2, align 1
  %conv71.23.2 = zext i8 %13103 to i32
  %xor72.23.2 = xor i32 %conv71.23.2, %conv68.23.2
  %conv73.23.2 = trunc i32 %xor72.23.2 to i8
  store i8 %conv73.23.2, i8* %arrayidx70.2, align 1
  %scevgep20.24.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 24
  %13104 = load i8, i8* %scevgep20.24.2, align 1
  %conv68.24.2 = zext i8 %13104 to i32
  %13105 = load i8, i8* %arrayidx70.2, align 1
  %conv71.24.2 = zext i8 %13105 to i32
  %xor72.24.2 = xor i32 %conv71.24.2, %conv68.24.2
  %conv73.24.2 = trunc i32 %xor72.24.2 to i8
  store i8 %conv73.24.2, i8* %arrayidx70.2, align 1
  %scevgep20.25.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 25
  %13106 = load i8, i8* %scevgep20.25.2, align 1
  %conv68.25.2 = zext i8 %13106 to i32
  %13107 = load i8, i8* %arrayidx70.2, align 1
  %conv71.25.2 = zext i8 %13107 to i32
  %xor72.25.2 = xor i32 %conv71.25.2, %conv68.25.2
  %conv73.25.2 = trunc i32 %xor72.25.2 to i8
  store i8 %conv73.25.2, i8* %arrayidx70.2, align 1
  %scevgep20.26.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 26
  %13108 = load i8, i8* %scevgep20.26.2, align 1
  %conv68.26.2 = zext i8 %13108 to i32
  %13109 = load i8, i8* %arrayidx70.2, align 1
  %conv71.26.2 = zext i8 %13109 to i32
  %xor72.26.2 = xor i32 %conv71.26.2, %conv68.26.2
  %conv73.26.2 = trunc i32 %xor72.26.2 to i8
  store i8 %conv73.26.2, i8* %arrayidx70.2, align 1
  %scevgep20.27.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 27
  %13110 = load i8, i8* %scevgep20.27.2, align 1
  %conv68.27.2 = zext i8 %13110 to i32
  %13111 = load i8, i8* %arrayidx70.2, align 1
  %conv71.27.2 = zext i8 %13111 to i32
  %xor72.27.2 = xor i32 %conv71.27.2, %conv68.27.2
  %conv73.27.2 = trunc i32 %xor72.27.2 to i8
  store i8 %conv73.27.2, i8* %arrayidx70.2, align 1
  %scevgep20.28.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 28
  %13112 = load i8, i8* %scevgep20.28.2, align 1
  %conv68.28.2 = zext i8 %13112 to i32
  %13113 = load i8, i8* %arrayidx70.2, align 1
  %conv71.28.2 = zext i8 %13113 to i32
  %xor72.28.2 = xor i32 %conv71.28.2, %conv68.28.2
  %conv73.28.2 = trunc i32 %xor72.28.2 to i8
  store i8 %conv73.28.2, i8* %arrayidx70.2, align 1
  %scevgep20.29.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 29
  %13114 = load i8, i8* %scevgep20.29.2, align 1
  %conv68.29.2 = zext i8 %13114 to i32
  %13115 = load i8, i8* %arrayidx70.2, align 1
  %conv71.29.2 = zext i8 %13115 to i32
  %xor72.29.2 = xor i32 %conv71.29.2, %conv68.29.2
  %conv73.29.2 = trunc i32 %xor72.29.2 to i8
  store i8 %conv73.29.2, i8* %arrayidx70.2, align 1
  %scevgep20.30.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 30
  %13116 = load i8, i8* %scevgep20.30.2, align 1
  %conv68.30.2 = zext i8 %13116 to i32
  %13117 = load i8, i8* %arrayidx70.2, align 1
  %conv71.30.2 = zext i8 %13117 to i32
  %xor72.30.2 = xor i32 %conv71.30.2, %conv68.30.2
  %conv73.30.2 = trunc i32 %xor72.30.2 to i8
  store i8 %conv73.30.2, i8* %arrayidx70.2, align 1
  %scevgep20.31.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 31
  %13118 = load i8, i8* %scevgep20.31.2, align 1
  %conv68.31.2 = zext i8 %13118 to i32
  %13119 = load i8, i8* %arrayidx70.2, align 1
  %conv71.31.2 = zext i8 %13119 to i32
  %xor72.31.2 = xor i32 %conv71.31.2, %conv68.31.2
  %conv73.31.2 = trunc i32 %xor72.31.2 to i8
  store i8 %conv73.31.2, i8* %arrayidx70.2, align 1
  %scevgep20.32.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 32
  %13120 = load i8, i8* %scevgep20.32.2, align 1
  %conv68.32.2 = zext i8 %13120 to i32
  %13121 = load i8, i8* %arrayidx70.2, align 1
  %conv71.32.2 = zext i8 %13121 to i32
  %xor72.32.2 = xor i32 %conv71.32.2, %conv68.32.2
  %conv73.32.2 = trunc i32 %xor72.32.2 to i8
  store i8 %conv73.32.2, i8* %arrayidx70.2, align 1
  %scevgep20.33.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 33
  %13122 = load i8, i8* %scevgep20.33.2, align 1
  %conv68.33.2 = zext i8 %13122 to i32
  %13123 = load i8, i8* %arrayidx70.2, align 1
  %conv71.33.2 = zext i8 %13123 to i32
  %xor72.33.2 = xor i32 %conv71.33.2, %conv68.33.2
  %conv73.33.2 = trunc i32 %xor72.33.2 to i8
  store i8 %conv73.33.2, i8* %arrayidx70.2, align 1
  %scevgep20.34.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 34
  %13124 = load i8, i8* %scevgep20.34.2, align 1
  %conv68.34.2 = zext i8 %13124 to i32
  %13125 = load i8, i8* %arrayidx70.2, align 1
  %conv71.34.2 = zext i8 %13125 to i32
  %xor72.34.2 = xor i32 %conv71.34.2, %conv68.34.2
  %conv73.34.2 = trunc i32 %xor72.34.2 to i8
  store i8 %conv73.34.2, i8* %arrayidx70.2, align 1
  %scevgep20.35.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 35
  %13126 = load i8, i8* %scevgep20.35.2, align 1
  %conv68.35.2 = zext i8 %13126 to i32
  %13127 = load i8, i8* %arrayidx70.2, align 1
  %conv71.35.2 = zext i8 %13127 to i32
  %xor72.35.2 = xor i32 %conv71.35.2, %conv68.35.2
  %conv73.35.2 = trunc i32 %xor72.35.2 to i8
  store i8 %conv73.35.2, i8* %arrayidx70.2, align 1
  %scevgep20.36.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 36
  %13128 = load i8, i8* %scevgep20.36.2, align 1
  %conv68.36.2 = zext i8 %13128 to i32
  %13129 = load i8, i8* %arrayidx70.2, align 1
  %conv71.36.2 = zext i8 %13129 to i32
  %xor72.36.2 = xor i32 %conv71.36.2, %conv68.36.2
  %conv73.36.2 = trunc i32 %xor72.36.2 to i8
  store i8 %conv73.36.2, i8* %arrayidx70.2, align 1
  %scevgep20.37.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 37
  %13130 = load i8, i8* %scevgep20.37.2, align 1
  %conv68.37.2 = zext i8 %13130 to i32
  %13131 = load i8, i8* %arrayidx70.2, align 1
  %conv71.37.2 = zext i8 %13131 to i32
  %xor72.37.2 = xor i32 %conv71.37.2, %conv68.37.2
  %conv73.37.2 = trunc i32 %xor72.37.2 to i8
  store i8 %conv73.37.2, i8* %arrayidx70.2, align 1
  %scevgep20.38.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 38
  %13132 = load i8, i8* %scevgep20.38.2, align 1
  %conv68.38.2 = zext i8 %13132 to i32
  %13133 = load i8, i8* %arrayidx70.2, align 1
  %conv71.38.2 = zext i8 %13133 to i32
  %xor72.38.2 = xor i32 %conv71.38.2, %conv68.38.2
  %conv73.38.2 = trunc i32 %xor72.38.2 to i8
  store i8 %conv73.38.2, i8* %arrayidx70.2, align 1
  %scevgep20.39.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 39
  %13134 = load i8, i8* %scevgep20.39.2, align 1
  %conv68.39.2 = zext i8 %13134 to i32
  %13135 = load i8, i8* %arrayidx70.2, align 1
  %conv71.39.2 = zext i8 %13135 to i32
  %xor72.39.2 = xor i32 %conv71.39.2, %conv68.39.2
  %conv73.39.2 = trunc i32 %xor72.39.2 to i8
  store i8 %conv73.39.2, i8* %arrayidx70.2, align 1
  %scevgep20.40.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 40
  %13136 = load i8, i8* %scevgep20.40.2, align 1
  %conv68.40.2 = zext i8 %13136 to i32
  %13137 = load i8, i8* %arrayidx70.2, align 1
  %conv71.40.2 = zext i8 %13137 to i32
  %xor72.40.2 = xor i32 %conv71.40.2, %conv68.40.2
  %conv73.40.2 = trunc i32 %xor72.40.2 to i8
  store i8 %conv73.40.2, i8* %arrayidx70.2, align 1
  %scevgep20.41.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 41
  %13138 = load i8, i8* %scevgep20.41.2, align 1
  %conv68.41.2 = zext i8 %13138 to i32
  %13139 = load i8, i8* %arrayidx70.2, align 1
  %conv71.41.2 = zext i8 %13139 to i32
  %xor72.41.2 = xor i32 %conv71.41.2, %conv68.41.2
  %conv73.41.2 = trunc i32 %xor72.41.2 to i8
  store i8 %conv73.41.2, i8* %arrayidx70.2, align 1
  %scevgep20.42.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 42
  %13140 = load i8, i8* %scevgep20.42.2, align 1
  %conv68.42.2 = zext i8 %13140 to i32
  %13141 = load i8, i8* %arrayidx70.2, align 1
  %conv71.42.2 = zext i8 %13141 to i32
  %xor72.42.2 = xor i32 %conv71.42.2, %conv68.42.2
  %conv73.42.2 = trunc i32 %xor72.42.2 to i8
  store i8 %conv73.42.2, i8* %arrayidx70.2, align 1
  %scevgep20.43.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 43
  %13142 = load i8, i8* %scevgep20.43.2, align 1
  %conv68.43.2 = zext i8 %13142 to i32
  %13143 = load i8, i8* %arrayidx70.2, align 1
  %conv71.43.2 = zext i8 %13143 to i32
  %xor72.43.2 = xor i32 %conv71.43.2, %conv68.43.2
  %conv73.43.2 = trunc i32 %xor72.43.2 to i8
  store i8 %conv73.43.2, i8* %arrayidx70.2, align 1
  %scevgep20.44.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 44
  %13144 = load i8, i8* %scevgep20.44.2, align 1
  %conv68.44.2 = zext i8 %13144 to i32
  %13145 = load i8, i8* %arrayidx70.2, align 1
  %conv71.44.2 = zext i8 %13145 to i32
  %xor72.44.2 = xor i32 %conv71.44.2, %conv68.44.2
  %conv73.44.2 = trunc i32 %xor72.44.2 to i8
  store i8 %conv73.44.2, i8* %arrayidx70.2, align 1
  %scevgep20.45.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 45
  %13146 = load i8, i8* %scevgep20.45.2, align 1
  %conv68.45.2 = zext i8 %13146 to i32
  %13147 = load i8, i8* %arrayidx70.2, align 1
  %conv71.45.2 = zext i8 %13147 to i32
  %xor72.45.2 = xor i32 %conv71.45.2, %conv68.45.2
  %conv73.45.2 = trunc i32 %xor72.45.2 to i8
  store i8 %conv73.45.2, i8* %arrayidx70.2, align 1
  %scevgep20.46.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 46
  %13148 = load i8, i8* %scevgep20.46.2, align 1
  %conv68.46.2 = zext i8 %13148 to i32
  %13149 = load i8, i8* %arrayidx70.2, align 1
  %conv71.46.2 = zext i8 %13149 to i32
  %xor72.46.2 = xor i32 %conv71.46.2, %conv68.46.2
  %conv73.46.2 = trunc i32 %xor72.46.2 to i8
  store i8 %conv73.46.2, i8* %arrayidx70.2, align 1
  %scevgep20.47.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 47
  %13150 = load i8, i8* %scevgep20.47.2, align 1
  %conv68.47.2 = zext i8 %13150 to i32
  %13151 = load i8, i8* %arrayidx70.2, align 1
  %conv71.47.2 = zext i8 %13151 to i32
  %xor72.47.2 = xor i32 %conv71.47.2, %conv68.47.2
  %conv73.47.2 = trunc i32 %xor72.47.2 to i8
  store i8 %conv73.47.2, i8* %arrayidx70.2, align 1
  %scevgep20.48.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 48
  %13152 = load i8, i8* %scevgep20.48.2, align 1
  %conv68.48.2 = zext i8 %13152 to i32
  %13153 = load i8, i8* %arrayidx70.2, align 1
  %conv71.48.2 = zext i8 %13153 to i32
  %xor72.48.2 = xor i32 %conv71.48.2, %conv68.48.2
  %conv73.48.2 = trunc i32 %xor72.48.2 to i8
  store i8 %conv73.48.2, i8* %arrayidx70.2, align 1
  %scevgep20.49.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 49
  %13154 = load i8, i8* %scevgep20.49.2, align 1
  %conv68.49.2 = zext i8 %13154 to i32
  %13155 = load i8, i8* %arrayidx70.2, align 1
  %conv71.49.2 = zext i8 %13155 to i32
  %xor72.49.2 = xor i32 %conv71.49.2, %conv68.49.2
  %conv73.49.2 = trunc i32 %xor72.49.2 to i8
  store i8 %conv73.49.2, i8* %arrayidx70.2, align 1
  %scevgep20.50.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 50
  %13156 = load i8, i8* %scevgep20.50.2, align 1
  %conv68.50.2 = zext i8 %13156 to i32
  %13157 = load i8, i8* %arrayidx70.2, align 1
  %conv71.50.2 = zext i8 %13157 to i32
  %xor72.50.2 = xor i32 %conv71.50.2, %conv68.50.2
  %conv73.50.2 = trunc i32 %xor72.50.2 to i8
  store i8 %conv73.50.2, i8* %arrayidx70.2, align 1
  %scevgep20.51.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 51
  %13158 = load i8, i8* %scevgep20.51.2, align 1
  %conv68.51.2 = zext i8 %13158 to i32
  %13159 = load i8, i8* %arrayidx70.2, align 1
  %conv71.51.2 = zext i8 %13159 to i32
  %xor72.51.2 = xor i32 %conv71.51.2, %conv68.51.2
  %conv73.51.2 = trunc i32 %xor72.51.2 to i8
  store i8 %conv73.51.2, i8* %arrayidx70.2, align 1
  %scevgep20.52.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 52
  %13160 = load i8, i8* %scevgep20.52.2, align 1
  %conv68.52.2 = zext i8 %13160 to i32
  %13161 = load i8, i8* %arrayidx70.2, align 1
  %conv71.52.2 = zext i8 %13161 to i32
  %xor72.52.2 = xor i32 %conv71.52.2, %conv68.52.2
  %conv73.52.2 = trunc i32 %xor72.52.2 to i8
  store i8 %conv73.52.2, i8* %arrayidx70.2, align 1
  %scevgep20.53.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 53
  %13162 = load i8, i8* %scevgep20.53.2, align 1
  %conv68.53.2 = zext i8 %13162 to i32
  %13163 = load i8, i8* %arrayidx70.2, align 1
  %conv71.53.2 = zext i8 %13163 to i32
  %xor72.53.2 = xor i32 %conv71.53.2, %conv68.53.2
  %conv73.53.2 = trunc i32 %xor72.53.2 to i8
  store i8 %conv73.53.2, i8* %arrayidx70.2, align 1
  %scevgep20.54.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 54
  %13164 = load i8, i8* %scevgep20.54.2, align 1
  %conv68.54.2 = zext i8 %13164 to i32
  %13165 = load i8, i8* %arrayidx70.2, align 1
  %conv71.54.2 = zext i8 %13165 to i32
  %xor72.54.2 = xor i32 %conv71.54.2, %conv68.54.2
  %conv73.54.2 = trunc i32 %xor72.54.2 to i8
  store i8 %conv73.54.2, i8* %arrayidx70.2, align 1
  %scevgep20.55.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 55
  %13166 = load i8, i8* %scevgep20.55.2, align 1
  %conv68.55.2 = zext i8 %13166 to i32
  %13167 = load i8, i8* %arrayidx70.2, align 1
  %conv71.55.2 = zext i8 %13167 to i32
  %xor72.55.2 = xor i32 %conv71.55.2, %conv68.55.2
  %conv73.55.2 = trunc i32 %xor72.55.2 to i8
  store i8 %conv73.55.2, i8* %arrayidx70.2, align 1
  %scevgep20.56.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 56
  %13168 = load i8, i8* %scevgep20.56.2, align 1
  %conv68.56.2 = zext i8 %13168 to i32
  %13169 = load i8, i8* %arrayidx70.2, align 1
  %conv71.56.2 = zext i8 %13169 to i32
  %xor72.56.2 = xor i32 %conv71.56.2, %conv68.56.2
  %conv73.56.2 = trunc i32 %xor72.56.2 to i8
  store i8 %conv73.56.2, i8* %arrayidx70.2, align 1
  %scevgep20.57.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 57
  %13170 = load i8, i8* %scevgep20.57.2, align 1
  %conv68.57.2 = zext i8 %13170 to i32
  %13171 = load i8, i8* %arrayidx70.2, align 1
  %conv71.57.2 = zext i8 %13171 to i32
  %xor72.57.2 = xor i32 %conv71.57.2, %conv68.57.2
  %conv73.57.2 = trunc i32 %xor72.57.2 to i8
  store i8 %conv73.57.2, i8* %arrayidx70.2, align 1
  %scevgep20.58.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 58
  %13172 = load i8, i8* %scevgep20.58.2, align 1
  %conv68.58.2 = zext i8 %13172 to i32
  %13173 = load i8, i8* %arrayidx70.2, align 1
  %conv71.58.2 = zext i8 %13173 to i32
  %xor72.58.2 = xor i32 %conv71.58.2, %conv68.58.2
  %conv73.58.2 = trunc i32 %xor72.58.2 to i8
  store i8 %conv73.58.2, i8* %arrayidx70.2, align 1
  %scevgep20.59.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 59
  %13174 = load i8, i8* %scevgep20.59.2, align 1
  %conv68.59.2 = zext i8 %13174 to i32
  %13175 = load i8, i8* %arrayidx70.2, align 1
  %conv71.59.2 = zext i8 %13175 to i32
  %xor72.59.2 = xor i32 %conv71.59.2, %conv68.59.2
  %conv73.59.2 = trunc i32 %xor72.59.2 to i8
  store i8 %conv73.59.2, i8* %arrayidx70.2, align 1
  %scevgep20.60.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 0, i64 60
  %13176 = load i8, i8* %scevgep20.60.2, align 1
  %conv68.60.2 = zext i8 %13176 to i32
  %13177 = load i8, i8* %arrayidx70.2, align 1
  %conv71.60.2 = zext i8 %13177 to i32
  %xor72.60.2 = xor i32 %conv71.60.2, %conv68.60.2
  %conv73.60.2 = trunc i32 %xor72.60.2 to i8
  store i8 %conv73.60.2, i8* %arrayidx70.2, align 1
  %scevgep19.2 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13055, i64 0, i64 1, i64 0
  %13178 = bitcast i8* %scevgep19.2 to [61 x [61 x i8]]*
  %arrayidx51.3 = getelementptr inbounds i8, i8* %a, i64 3
  %13179 = load i8, i8* %arrayidx51.3, align 1
  %arrayidx53.3 = getelementptr inbounds i8, i8* %b, i64 3
  %13180 = load i8, i8* %arrayidx53.3, align 1
  %call54.3 = call zeroext i8 @mult(i8 zeroext %13179, i8 zeroext %13180)
  %arrayidx56.3 = getelementptr inbounds i8, i8* %c, i64 3
  store i8 %call54.3, i8* %arrayidx56.3, align 1
  %arrayidx70.3 = getelementptr inbounds i8, i8* %c, i64 3
  %scevgep20.374 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 0
  %13181 = load i8, i8* %scevgep20.374, align 1
  %conv68.375 = zext i8 %13181 to i32
  %13182 = load i8, i8* %arrayidx70.3, align 1
  %conv71.376 = zext i8 %13182 to i32
  %xor72.377 = xor i32 %conv71.376, %conv68.375
  %conv73.378 = trunc i32 %xor72.377 to i8
  store i8 %conv73.378, i8* %arrayidx70.3, align 1
  %scevgep20.1.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 1
  %13183 = load i8, i8* %scevgep20.1.3, align 1
  %conv68.1.3 = zext i8 %13183 to i32
  %13184 = load i8, i8* %arrayidx70.3, align 1
  %conv71.1.3 = zext i8 %13184 to i32
  %xor72.1.3 = xor i32 %conv71.1.3, %conv68.1.3
  %conv73.1.3 = trunc i32 %xor72.1.3 to i8
  store i8 %conv73.1.3, i8* %arrayidx70.3, align 1
  %scevgep20.2.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 2
  %13185 = load i8, i8* %scevgep20.2.3, align 1
  %conv68.2.3 = zext i8 %13185 to i32
  %13186 = load i8, i8* %arrayidx70.3, align 1
  %conv71.2.3 = zext i8 %13186 to i32
  %xor72.2.3 = xor i32 %conv71.2.3, %conv68.2.3
  %conv73.2.3 = trunc i32 %xor72.2.3 to i8
  store i8 %conv73.2.3, i8* %arrayidx70.3, align 1
  %scevgep20.4.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 4
  %13187 = load i8, i8* %scevgep20.4.3, align 1
  %conv68.4.3 = zext i8 %13187 to i32
  %13188 = load i8, i8* %arrayidx70.3, align 1
  %conv71.4.3 = zext i8 %13188 to i32
  %xor72.4.3 = xor i32 %conv71.4.3, %conv68.4.3
  %conv73.4.3 = trunc i32 %xor72.4.3 to i8
  store i8 %conv73.4.3, i8* %arrayidx70.3, align 1
  %scevgep20.5.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 5
  %13189 = load i8, i8* %scevgep20.5.3, align 1
  %conv68.5.3 = zext i8 %13189 to i32
  %13190 = load i8, i8* %arrayidx70.3, align 1
  %conv71.5.3 = zext i8 %13190 to i32
  %xor72.5.3 = xor i32 %conv71.5.3, %conv68.5.3
  %conv73.5.3 = trunc i32 %xor72.5.3 to i8
  store i8 %conv73.5.3, i8* %arrayidx70.3, align 1
  %scevgep20.6.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 6
  %13191 = load i8, i8* %scevgep20.6.3, align 1
  %conv68.6.3 = zext i8 %13191 to i32
  %13192 = load i8, i8* %arrayidx70.3, align 1
  %conv71.6.3 = zext i8 %13192 to i32
  %xor72.6.3 = xor i32 %conv71.6.3, %conv68.6.3
  %conv73.6.3 = trunc i32 %xor72.6.3 to i8
  store i8 %conv73.6.3, i8* %arrayidx70.3, align 1
  %scevgep20.7.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 7
  %13193 = load i8, i8* %scevgep20.7.3, align 1
  %conv68.7.3 = zext i8 %13193 to i32
  %13194 = load i8, i8* %arrayidx70.3, align 1
  %conv71.7.3 = zext i8 %13194 to i32
  %xor72.7.3 = xor i32 %conv71.7.3, %conv68.7.3
  %conv73.7.3 = trunc i32 %xor72.7.3 to i8
  store i8 %conv73.7.3, i8* %arrayidx70.3, align 1
  %scevgep20.8.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 8
  %13195 = load i8, i8* %scevgep20.8.3, align 1
  %conv68.8.3 = zext i8 %13195 to i32
  %13196 = load i8, i8* %arrayidx70.3, align 1
  %conv71.8.3 = zext i8 %13196 to i32
  %xor72.8.3 = xor i32 %conv71.8.3, %conv68.8.3
  %conv73.8.3 = trunc i32 %xor72.8.3 to i8
  store i8 %conv73.8.3, i8* %arrayidx70.3, align 1
  %scevgep20.9.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 9
  %13197 = load i8, i8* %scevgep20.9.3, align 1
  %conv68.9.3 = zext i8 %13197 to i32
  %13198 = load i8, i8* %arrayidx70.3, align 1
  %conv71.9.3 = zext i8 %13198 to i32
  %xor72.9.3 = xor i32 %conv71.9.3, %conv68.9.3
  %conv73.9.3 = trunc i32 %xor72.9.3 to i8
  store i8 %conv73.9.3, i8* %arrayidx70.3, align 1
  %scevgep20.10.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 10
  %13199 = load i8, i8* %scevgep20.10.3, align 1
  %conv68.10.3 = zext i8 %13199 to i32
  %13200 = load i8, i8* %arrayidx70.3, align 1
  %conv71.10.3 = zext i8 %13200 to i32
  %xor72.10.3 = xor i32 %conv71.10.3, %conv68.10.3
  %conv73.10.3 = trunc i32 %xor72.10.3 to i8
  store i8 %conv73.10.3, i8* %arrayidx70.3, align 1
  %scevgep20.11.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 11
  %13201 = load i8, i8* %scevgep20.11.3, align 1
  %conv68.11.3 = zext i8 %13201 to i32
  %13202 = load i8, i8* %arrayidx70.3, align 1
  %conv71.11.3 = zext i8 %13202 to i32
  %xor72.11.3 = xor i32 %conv71.11.3, %conv68.11.3
  %conv73.11.3 = trunc i32 %xor72.11.3 to i8
  store i8 %conv73.11.3, i8* %arrayidx70.3, align 1
  %scevgep20.12.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 12
  %13203 = load i8, i8* %scevgep20.12.3, align 1
  %conv68.12.3 = zext i8 %13203 to i32
  %13204 = load i8, i8* %arrayidx70.3, align 1
  %conv71.12.3 = zext i8 %13204 to i32
  %xor72.12.3 = xor i32 %conv71.12.3, %conv68.12.3
  %conv73.12.3 = trunc i32 %xor72.12.3 to i8
  store i8 %conv73.12.3, i8* %arrayidx70.3, align 1
  %scevgep20.13.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 13
  %13205 = load i8, i8* %scevgep20.13.3, align 1
  %conv68.13.3 = zext i8 %13205 to i32
  %13206 = load i8, i8* %arrayidx70.3, align 1
  %conv71.13.3 = zext i8 %13206 to i32
  %xor72.13.3 = xor i32 %conv71.13.3, %conv68.13.3
  %conv73.13.3 = trunc i32 %xor72.13.3 to i8
  store i8 %conv73.13.3, i8* %arrayidx70.3, align 1
  %scevgep20.14.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 14
  %13207 = load i8, i8* %scevgep20.14.3, align 1
  %conv68.14.3 = zext i8 %13207 to i32
  %13208 = load i8, i8* %arrayidx70.3, align 1
  %conv71.14.3 = zext i8 %13208 to i32
  %xor72.14.3 = xor i32 %conv71.14.3, %conv68.14.3
  %conv73.14.3 = trunc i32 %xor72.14.3 to i8
  store i8 %conv73.14.3, i8* %arrayidx70.3, align 1
  %scevgep20.15.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 15
  %13209 = load i8, i8* %scevgep20.15.3, align 1
  %conv68.15.3 = zext i8 %13209 to i32
  %13210 = load i8, i8* %arrayidx70.3, align 1
  %conv71.15.3 = zext i8 %13210 to i32
  %xor72.15.3 = xor i32 %conv71.15.3, %conv68.15.3
  %conv73.15.3 = trunc i32 %xor72.15.3 to i8
  store i8 %conv73.15.3, i8* %arrayidx70.3, align 1
  %scevgep20.16.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 16
  %13211 = load i8, i8* %scevgep20.16.3, align 1
  %conv68.16.3 = zext i8 %13211 to i32
  %13212 = load i8, i8* %arrayidx70.3, align 1
  %conv71.16.3 = zext i8 %13212 to i32
  %xor72.16.3 = xor i32 %conv71.16.3, %conv68.16.3
  %conv73.16.3 = trunc i32 %xor72.16.3 to i8
  store i8 %conv73.16.3, i8* %arrayidx70.3, align 1
  %scevgep20.17.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 17
  %13213 = load i8, i8* %scevgep20.17.3, align 1
  %conv68.17.3 = zext i8 %13213 to i32
  %13214 = load i8, i8* %arrayidx70.3, align 1
  %conv71.17.3 = zext i8 %13214 to i32
  %xor72.17.3 = xor i32 %conv71.17.3, %conv68.17.3
  %conv73.17.3 = trunc i32 %xor72.17.3 to i8
  store i8 %conv73.17.3, i8* %arrayidx70.3, align 1
  %scevgep20.18.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 18
  %13215 = load i8, i8* %scevgep20.18.3, align 1
  %conv68.18.3 = zext i8 %13215 to i32
  %13216 = load i8, i8* %arrayidx70.3, align 1
  %conv71.18.3 = zext i8 %13216 to i32
  %xor72.18.3 = xor i32 %conv71.18.3, %conv68.18.3
  %conv73.18.3 = trunc i32 %xor72.18.3 to i8
  store i8 %conv73.18.3, i8* %arrayidx70.3, align 1
  %scevgep20.19.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 19
  %13217 = load i8, i8* %scevgep20.19.3, align 1
  %conv68.19.3 = zext i8 %13217 to i32
  %13218 = load i8, i8* %arrayidx70.3, align 1
  %conv71.19.3 = zext i8 %13218 to i32
  %xor72.19.3 = xor i32 %conv71.19.3, %conv68.19.3
  %conv73.19.3 = trunc i32 %xor72.19.3 to i8
  store i8 %conv73.19.3, i8* %arrayidx70.3, align 1
  %scevgep20.20.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 20
  %13219 = load i8, i8* %scevgep20.20.3, align 1
  %conv68.20.3 = zext i8 %13219 to i32
  %13220 = load i8, i8* %arrayidx70.3, align 1
  %conv71.20.3 = zext i8 %13220 to i32
  %xor72.20.3 = xor i32 %conv71.20.3, %conv68.20.3
  %conv73.20.3 = trunc i32 %xor72.20.3 to i8
  store i8 %conv73.20.3, i8* %arrayidx70.3, align 1
  %scevgep20.21.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 21
  %13221 = load i8, i8* %scevgep20.21.3, align 1
  %conv68.21.3 = zext i8 %13221 to i32
  %13222 = load i8, i8* %arrayidx70.3, align 1
  %conv71.21.3 = zext i8 %13222 to i32
  %xor72.21.3 = xor i32 %conv71.21.3, %conv68.21.3
  %conv73.21.3 = trunc i32 %xor72.21.3 to i8
  store i8 %conv73.21.3, i8* %arrayidx70.3, align 1
  %scevgep20.22.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 22
  %13223 = load i8, i8* %scevgep20.22.3, align 1
  %conv68.22.3 = zext i8 %13223 to i32
  %13224 = load i8, i8* %arrayidx70.3, align 1
  %conv71.22.3 = zext i8 %13224 to i32
  %xor72.22.3 = xor i32 %conv71.22.3, %conv68.22.3
  %conv73.22.3 = trunc i32 %xor72.22.3 to i8
  store i8 %conv73.22.3, i8* %arrayidx70.3, align 1
  %scevgep20.23.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 23
  %13225 = load i8, i8* %scevgep20.23.3, align 1
  %conv68.23.3 = zext i8 %13225 to i32
  %13226 = load i8, i8* %arrayidx70.3, align 1
  %conv71.23.3 = zext i8 %13226 to i32
  %xor72.23.3 = xor i32 %conv71.23.3, %conv68.23.3
  %conv73.23.3 = trunc i32 %xor72.23.3 to i8
  store i8 %conv73.23.3, i8* %arrayidx70.3, align 1
  %scevgep20.24.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 24
  %13227 = load i8, i8* %scevgep20.24.3, align 1
  %conv68.24.3 = zext i8 %13227 to i32
  %13228 = load i8, i8* %arrayidx70.3, align 1
  %conv71.24.3 = zext i8 %13228 to i32
  %xor72.24.3 = xor i32 %conv71.24.3, %conv68.24.3
  %conv73.24.3 = trunc i32 %xor72.24.3 to i8
  store i8 %conv73.24.3, i8* %arrayidx70.3, align 1
  %scevgep20.25.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 25
  %13229 = load i8, i8* %scevgep20.25.3, align 1
  %conv68.25.3 = zext i8 %13229 to i32
  %13230 = load i8, i8* %arrayidx70.3, align 1
  %conv71.25.3 = zext i8 %13230 to i32
  %xor72.25.3 = xor i32 %conv71.25.3, %conv68.25.3
  %conv73.25.3 = trunc i32 %xor72.25.3 to i8
  store i8 %conv73.25.3, i8* %arrayidx70.3, align 1
  %scevgep20.26.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 26
  %13231 = load i8, i8* %scevgep20.26.3, align 1
  %conv68.26.3 = zext i8 %13231 to i32
  %13232 = load i8, i8* %arrayidx70.3, align 1
  %conv71.26.3 = zext i8 %13232 to i32
  %xor72.26.3 = xor i32 %conv71.26.3, %conv68.26.3
  %conv73.26.3 = trunc i32 %xor72.26.3 to i8
  store i8 %conv73.26.3, i8* %arrayidx70.3, align 1
  %scevgep20.27.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 27
  %13233 = load i8, i8* %scevgep20.27.3, align 1
  %conv68.27.3 = zext i8 %13233 to i32
  %13234 = load i8, i8* %arrayidx70.3, align 1
  %conv71.27.3 = zext i8 %13234 to i32
  %xor72.27.3 = xor i32 %conv71.27.3, %conv68.27.3
  %conv73.27.3 = trunc i32 %xor72.27.3 to i8
  store i8 %conv73.27.3, i8* %arrayidx70.3, align 1
  %scevgep20.28.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 28
  %13235 = load i8, i8* %scevgep20.28.3, align 1
  %conv68.28.3 = zext i8 %13235 to i32
  %13236 = load i8, i8* %arrayidx70.3, align 1
  %conv71.28.3 = zext i8 %13236 to i32
  %xor72.28.3 = xor i32 %conv71.28.3, %conv68.28.3
  %conv73.28.3 = trunc i32 %xor72.28.3 to i8
  store i8 %conv73.28.3, i8* %arrayidx70.3, align 1
  %scevgep20.29.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 29
  %13237 = load i8, i8* %scevgep20.29.3, align 1
  %conv68.29.3 = zext i8 %13237 to i32
  %13238 = load i8, i8* %arrayidx70.3, align 1
  %conv71.29.3 = zext i8 %13238 to i32
  %xor72.29.3 = xor i32 %conv71.29.3, %conv68.29.3
  %conv73.29.3 = trunc i32 %xor72.29.3 to i8
  store i8 %conv73.29.3, i8* %arrayidx70.3, align 1
  %scevgep20.30.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 30
  %13239 = load i8, i8* %scevgep20.30.3, align 1
  %conv68.30.3 = zext i8 %13239 to i32
  %13240 = load i8, i8* %arrayidx70.3, align 1
  %conv71.30.3 = zext i8 %13240 to i32
  %xor72.30.3 = xor i32 %conv71.30.3, %conv68.30.3
  %conv73.30.3 = trunc i32 %xor72.30.3 to i8
  store i8 %conv73.30.3, i8* %arrayidx70.3, align 1
  %scevgep20.31.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 31
  %13241 = load i8, i8* %scevgep20.31.3, align 1
  %conv68.31.3 = zext i8 %13241 to i32
  %13242 = load i8, i8* %arrayidx70.3, align 1
  %conv71.31.3 = zext i8 %13242 to i32
  %xor72.31.3 = xor i32 %conv71.31.3, %conv68.31.3
  %conv73.31.3 = trunc i32 %xor72.31.3 to i8
  store i8 %conv73.31.3, i8* %arrayidx70.3, align 1
  %scevgep20.32.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 32
  %13243 = load i8, i8* %scevgep20.32.3, align 1
  %conv68.32.3 = zext i8 %13243 to i32
  %13244 = load i8, i8* %arrayidx70.3, align 1
  %conv71.32.3 = zext i8 %13244 to i32
  %xor72.32.3 = xor i32 %conv71.32.3, %conv68.32.3
  %conv73.32.3 = trunc i32 %xor72.32.3 to i8
  store i8 %conv73.32.3, i8* %arrayidx70.3, align 1
  %scevgep20.33.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 33
  %13245 = load i8, i8* %scevgep20.33.3, align 1
  %conv68.33.3 = zext i8 %13245 to i32
  %13246 = load i8, i8* %arrayidx70.3, align 1
  %conv71.33.3 = zext i8 %13246 to i32
  %xor72.33.3 = xor i32 %conv71.33.3, %conv68.33.3
  %conv73.33.3 = trunc i32 %xor72.33.3 to i8
  store i8 %conv73.33.3, i8* %arrayidx70.3, align 1
  %scevgep20.34.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 34
  %13247 = load i8, i8* %scevgep20.34.3, align 1
  %conv68.34.3 = zext i8 %13247 to i32
  %13248 = load i8, i8* %arrayidx70.3, align 1
  %conv71.34.3 = zext i8 %13248 to i32
  %xor72.34.3 = xor i32 %conv71.34.3, %conv68.34.3
  %conv73.34.3 = trunc i32 %xor72.34.3 to i8
  store i8 %conv73.34.3, i8* %arrayidx70.3, align 1
  %scevgep20.35.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 35
  %13249 = load i8, i8* %scevgep20.35.3, align 1
  %conv68.35.3 = zext i8 %13249 to i32
  %13250 = load i8, i8* %arrayidx70.3, align 1
  %conv71.35.3 = zext i8 %13250 to i32
  %xor72.35.3 = xor i32 %conv71.35.3, %conv68.35.3
  %conv73.35.3 = trunc i32 %xor72.35.3 to i8
  store i8 %conv73.35.3, i8* %arrayidx70.3, align 1
  %scevgep20.36.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 36
  %13251 = load i8, i8* %scevgep20.36.3, align 1
  %conv68.36.3 = zext i8 %13251 to i32
  %13252 = load i8, i8* %arrayidx70.3, align 1
  %conv71.36.3 = zext i8 %13252 to i32
  %xor72.36.3 = xor i32 %conv71.36.3, %conv68.36.3
  %conv73.36.3 = trunc i32 %xor72.36.3 to i8
  store i8 %conv73.36.3, i8* %arrayidx70.3, align 1
  %scevgep20.37.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 37
  %13253 = load i8, i8* %scevgep20.37.3, align 1
  %conv68.37.3 = zext i8 %13253 to i32
  %13254 = load i8, i8* %arrayidx70.3, align 1
  %conv71.37.3 = zext i8 %13254 to i32
  %xor72.37.3 = xor i32 %conv71.37.3, %conv68.37.3
  %conv73.37.3 = trunc i32 %xor72.37.3 to i8
  store i8 %conv73.37.3, i8* %arrayidx70.3, align 1
  %scevgep20.38.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 38
  %13255 = load i8, i8* %scevgep20.38.3, align 1
  %conv68.38.3 = zext i8 %13255 to i32
  %13256 = load i8, i8* %arrayidx70.3, align 1
  %conv71.38.3 = zext i8 %13256 to i32
  %xor72.38.3 = xor i32 %conv71.38.3, %conv68.38.3
  %conv73.38.3 = trunc i32 %xor72.38.3 to i8
  store i8 %conv73.38.3, i8* %arrayidx70.3, align 1
  %scevgep20.39.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 39
  %13257 = load i8, i8* %scevgep20.39.3, align 1
  %conv68.39.3 = zext i8 %13257 to i32
  %13258 = load i8, i8* %arrayidx70.3, align 1
  %conv71.39.3 = zext i8 %13258 to i32
  %xor72.39.3 = xor i32 %conv71.39.3, %conv68.39.3
  %conv73.39.3 = trunc i32 %xor72.39.3 to i8
  store i8 %conv73.39.3, i8* %arrayidx70.3, align 1
  %scevgep20.40.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 40
  %13259 = load i8, i8* %scevgep20.40.3, align 1
  %conv68.40.3 = zext i8 %13259 to i32
  %13260 = load i8, i8* %arrayidx70.3, align 1
  %conv71.40.3 = zext i8 %13260 to i32
  %xor72.40.3 = xor i32 %conv71.40.3, %conv68.40.3
  %conv73.40.3 = trunc i32 %xor72.40.3 to i8
  store i8 %conv73.40.3, i8* %arrayidx70.3, align 1
  %scevgep20.41.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 41
  %13261 = load i8, i8* %scevgep20.41.3, align 1
  %conv68.41.3 = zext i8 %13261 to i32
  %13262 = load i8, i8* %arrayidx70.3, align 1
  %conv71.41.3 = zext i8 %13262 to i32
  %xor72.41.3 = xor i32 %conv71.41.3, %conv68.41.3
  %conv73.41.3 = trunc i32 %xor72.41.3 to i8
  store i8 %conv73.41.3, i8* %arrayidx70.3, align 1
  %scevgep20.42.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 42
  %13263 = load i8, i8* %scevgep20.42.3, align 1
  %conv68.42.3 = zext i8 %13263 to i32
  %13264 = load i8, i8* %arrayidx70.3, align 1
  %conv71.42.3 = zext i8 %13264 to i32
  %xor72.42.3 = xor i32 %conv71.42.3, %conv68.42.3
  %conv73.42.3 = trunc i32 %xor72.42.3 to i8
  store i8 %conv73.42.3, i8* %arrayidx70.3, align 1
  %scevgep20.43.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 43
  %13265 = load i8, i8* %scevgep20.43.3, align 1
  %conv68.43.3 = zext i8 %13265 to i32
  %13266 = load i8, i8* %arrayidx70.3, align 1
  %conv71.43.3 = zext i8 %13266 to i32
  %xor72.43.3 = xor i32 %conv71.43.3, %conv68.43.3
  %conv73.43.3 = trunc i32 %xor72.43.3 to i8
  store i8 %conv73.43.3, i8* %arrayidx70.3, align 1
  %scevgep20.44.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 44
  %13267 = load i8, i8* %scevgep20.44.3, align 1
  %conv68.44.3 = zext i8 %13267 to i32
  %13268 = load i8, i8* %arrayidx70.3, align 1
  %conv71.44.3 = zext i8 %13268 to i32
  %xor72.44.3 = xor i32 %conv71.44.3, %conv68.44.3
  %conv73.44.3 = trunc i32 %xor72.44.3 to i8
  store i8 %conv73.44.3, i8* %arrayidx70.3, align 1
  %scevgep20.45.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 45
  %13269 = load i8, i8* %scevgep20.45.3, align 1
  %conv68.45.3 = zext i8 %13269 to i32
  %13270 = load i8, i8* %arrayidx70.3, align 1
  %conv71.45.3 = zext i8 %13270 to i32
  %xor72.45.3 = xor i32 %conv71.45.3, %conv68.45.3
  %conv73.45.3 = trunc i32 %xor72.45.3 to i8
  store i8 %conv73.45.3, i8* %arrayidx70.3, align 1
  %scevgep20.46.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 46
  %13271 = load i8, i8* %scevgep20.46.3, align 1
  %conv68.46.3 = zext i8 %13271 to i32
  %13272 = load i8, i8* %arrayidx70.3, align 1
  %conv71.46.3 = zext i8 %13272 to i32
  %xor72.46.3 = xor i32 %conv71.46.3, %conv68.46.3
  %conv73.46.3 = trunc i32 %xor72.46.3 to i8
  store i8 %conv73.46.3, i8* %arrayidx70.3, align 1
  %scevgep20.47.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 47
  %13273 = load i8, i8* %scevgep20.47.3, align 1
  %conv68.47.3 = zext i8 %13273 to i32
  %13274 = load i8, i8* %arrayidx70.3, align 1
  %conv71.47.3 = zext i8 %13274 to i32
  %xor72.47.3 = xor i32 %conv71.47.3, %conv68.47.3
  %conv73.47.3 = trunc i32 %xor72.47.3 to i8
  store i8 %conv73.47.3, i8* %arrayidx70.3, align 1
  %scevgep20.48.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 48
  %13275 = load i8, i8* %scevgep20.48.3, align 1
  %conv68.48.3 = zext i8 %13275 to i32
  %13276 = load i8, i8* %arrayidx70.3, align 1
  %conv71.48.3 = zext i8 %13276 to i32
  %xor72.48.3 = xor i32 %conv71.48.3, %conv68.48.3
  %conv73.48.3 = trunc i32 %xor72.48.3 to i8
  store i8 %conv73.48.3, i8* %arrayidx70.3, align 1
  %scevgep20.49.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 49
  %13277 = load i8, i8* %scevgep20.49.3, align 1
  %conv68.49.3 = zext i8 %13277 to i32
  %13278 = load i8, i8* %arrayidx70.3, align 1
  %conv71.49.3 = zext i8 %13278 to i32
  %xor72.49.3 = xor i32 %conv71.49.3, %conv68.49.3
  %conv73.49.3 = trunc i32 %xor72.49.3 to i8
  store i8 %conv73.49.3, i8* %arrayidx70.3, align 1
  %scevgep20.50.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 50
  %13279 = load i8, i8* %scevgep20.50.3, align 1
  %conv68.50.3 = zext i8 %13279 to i32
  %13280 = load i8, i8* %arrayidx70.3, align 1
  %conv71.50.3 = zext i8 %13280 to i32
  %xor72.50.3 = xor i32 %conv71.50.3, %conv68.50.3
  %conv73.50.3 = trunc i32 %xor72.50.3 to i8
  store i8 %conv73.50.3, i8* %arrayidx70.3, align 1
  %scevgep20.51.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 51
  %13281 = load i8, i8* %scevgep20.51.3, align 1
  %conv68.51.3 = zext i8 %13281 to i32
  %13282 = load i8, i8* %arrayidx70.3, align 1
  %conv71.51.3 = zext i8 %13282 to i32
  %xor72.51.3 = xor i32 %conv71.51.3, %conv68.51.3
  %conv73.51.3 = trunc i32 %xor72.51.3 to i8
  store i8 %conv73.51.3, i8* %arrayidx70.3, align 1
  %scevgep20.52.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 52
  %13283 = load i8, i8* %scevgep20.52.3, align 1
  %conv68.52.3 = zext i8 %13283 to i32
  %13284 = load i8, i8* %arrayidx70.3, align 1
  %conv71.52.3 = zext i8 %13284 to i32
  %xor72.52.3 = xor i32 %conv71.52.3, %conv68.52.3
  %conv73.52.3 = trunc i32 %xor72.52.3 to i8
  store i8 %conv73.52.3, i8* %arrayidx70.3, align 1
  %scevgep20.53.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 53
  %13285 = load i8, i8* %scevgep20.53.3, align 1
  %conv68.53.3 = zext i8 %13285 to i32
  %13286 = load i8, i8* %arrayidx70.3, align 1
  %conv71.53.3 = zext i8 %13286 to i32
  %xor72.53.3 = xor i32 %conv71.53.3, %conv68.53.3
  %conv73.53.3 = trunc i32 %xor72.53.3 to i8
  store i8 %conv73.53.3, i8* %arrayidx70.3, align 1
  %scevgep20.54.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 54
  %13287 = load i8, i8* %scevgep20.54.3, align 1
  %conv68.54.3 = zext i8 %13287 to i32
  %13288 = load i8, i8* %arrayidx70.3, align 1
  %conv71.54.3 = zext i8 %13288 to i32
  %xor72.54.3 = xor i32 %conv71.54.3, %conv68.54.3
  %conv73.54.3 = trunc i32 %xor72.54.3 to i8
  store i8 %conv73.54.3, i8* %arrayidx70.3, align 1
  %scevgep20.55.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 55
  %13289 = load i8, i8* %scevgep20.55.3, align 1
  %conv68.55.3 = zext i8 %13289 to i32
  %13290 = load i8, i8* %arrayidx70.3, align 1
  %conv71.55.3 = zext i8 %13290 to i32
  %xor72.55.3 = xor i32 %conv71.55.3, %conv68.55.3
  %conv73.55.3 = trunc i32 %xor72.55.3 to i8
  store i8 %conv73.55.3, i8* %arrayidx70.3, align 1
  %scevgep20.56.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 56
  %13291 = load i8, i8* %scevgep20.56.3, align 1
  %conv68.56.3 = zext i8 %13291 to i32
  %13292 = load i8, i8* %arrayidx70.3, align 1
  %conv71.56.3 = zext i8 %13292 to i32
  %xor72.56.3 = xor i32 %conv71.56.3, %conv68.56.3
  %conv73.56.3 = trunc i32 %xor72.56.3 to i8
  store i8 %conv73.56.3, i8* %arrayidx70.3, align 1
  %scevgep20.57.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 57
  %13293 = load i8, i8* %scevgep20.57.3, align 1
  %conv68.57.3 = zext i8 %13293 to i32
  %13294 = load i8, i8* %arrayidx70.3, align 1
  %conv71.57.3 = zext i8 %13294 to i32
  %xor72.57.3 = xor i32 %conv71.57.3, %conv68.57.3
  %conv73.57.3 = trunc i32 %xor72.57.3 to i8
  store i8 %conv73.57.3, i8* %arrayidx70.3, align 1
  %scevgep20.58.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 58
  %13295 = load i8, i8* %scevgep20.58.3, align 1
  %conv68.58.3 = zext i8 %13295 to i32
  %13296 = load i8, i8* %arrayidx70.3, align 1
  %conv71.58.3 = zext i8 %13296 to i32
  %xor72.58.3 = xor i32 %conv71.58.3, %conv68.58.3
  %conv73.58.3 = trunc i32 %xor72.58.3 to i8
  store i8 %conv73.58.3, i8* %arrayidx70.3, align 1
  %scevgep20.59.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 59
  %13297 = load i8, i8* %scevgep20.59.3, align 1
  %conv68.59.3 = zext i8 %13297 to i32
  %13298 = load i8, i8* %arrayidx70.3, align 1
  %conv71.59.3 = zext i8 %13298 to i32
  %xor72.59.3 = xor i32 %conv71.59.3, %conv68.59.3
  %conv73.59.3 = trunc i32 %xor72.59.3 to i8
  store i8 %conv73.59.3, i8* %arrayidx70.3, align 1
  %scevgep20.60.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 0, i64 60
  %13299 = load i8, i8* %scevgep20.60.3, align 1
  %conv68.60.3 = zext i8 %13299 to i32
  %13300 = load i8, i8* %arrayidx70.3, align 1
  %conv71.60.3 = zext i8 %13300 to i32
  %xor72.60.3 = xor i32 %conv71.60.3, %conv68.60.3
  %conv73.60.3 = trunc i32 %xor72.60.3 to i8
  store i8 %conv73.60.3, i8* %arrayidx70.3, align 1
  %scevgep19.3 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13178, i64 0, i64 1, i64 0
  %13301 = bitcast i8* %scevgep19.3 to [61 x [61 x i8]]*
  %arrayidx51.4 = getelementptr inbounds i8, i8* %a, i64 4
  %13302 = load i8, i8* %arrayidx51.4, align 1
  %arrayidx53.4 = getelementptr inbounds i8, i8* %b, i64 4
  %13303 = load i8, i8* %arrayidx53.4, align 1
  %call54.4 = call zeroext i8 @mult(i8 zeroext %13302, i8 zeroext %13303)
  %arrayidx56.4 = getelementptr inbounds i8, i8* %c, i64 4
  store i8 %call54.4, i8* %arrayidx56.4, align 1
  %arrayidx70.4 = getelementptr inbounds i8, i8* %c, i64 4
  %scevgep20.484 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 0
  %13304 = load i8, i8* %scevgep20.484, align 1
  %conv68.485 = zext i8 %13304 to i32
  %13305 = load i8, i8* %arrayidx70.4, align 1
  %conv71.486 = zext i8 %13305 to i32
  %xor72.487 = xor i32 %conv71.486, %conv68.485
  %conv73.488 = trunc i32 %xor72.487 to i8
  store i8 %conv73.488, i8* %arrayidx70.4, align 1
  %scevgep20.1.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 1
  %13306 = load i8, i8* %scevgep20.1.4, align 1
  %conv68.1.4 = zext i8 %13306 to i32
  %13307 = load i8, i8* %arrayidx70.4, align 1
  %conv71.1.4 = zext i8 %13307 to i32
  %xor72.1.4 = xor i32 %conv71.1.4, %conv68.1.4
  %conv73.1.4 = trunc i32 %xor72.1.4 to i8
  store i8 %conv73.1.4, i8* %arrayidx70.4, align 1
  %scevgep20.2.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 2
  %13308 = load i8, i8* %scevgep20.2.4, align 1
  %conv68.2.4 = zext i8 %13308 to i32
  %13309 = load i8, i8* %arrayidx70.4, align 1
  %conv71.2.4 = zext i8 %13309 to i32
  %xor72.2.4 = xor i32 %conv71.2.4, %conv68.2.4
  %conv73.2.4 = trunc i32 %xor72.2.4 to i8
  store i8 %conv73.2.4, i8* %arrayidx70.4, align 1
  %scevgep20.3.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 3
  %13310 = load i8, i8* %scevgep20.3.4, align 1
  %conv68.3.4 = zext i8 %13310 to i32
  %13311 = load i8, i8* %arrayidx70.4, align 1
  %conv71.3.4 = zext i8 %13311 to i32
  %xor72.3.4 = xor i32 %conv71.3.4, %conv68.3.4
  %conv73.3.4 = trunc i32 %xor72.3.4 to i8
  store i8 %conv73.3.4, i8* %arrayidx70.4, align 1
  %scevgep20.5.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 5
  %13312 = load i8, i8* %scevgep20.5.4, align 1
  %conv68.5.4 = zext i8 %13312 to i32
  %13313 = load i8, i8* %arrayidx70.4, align 1
  %conv71.5.4 = zext i8 %13313 to i32
  %xor72.5.4 = xor i32 %conv71.5.4, %conv68.5.4
  %conv73.5.4 = trunc i32 %xor72.5.4 to i8
  store i8 %conv73.5.4, i8* %arrayidx70.4, align 1
  %scevgep20.6.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 6
  %13314 = load i8, i8* %scevgep20.6.4, align 1
  %conv68.6.4 = zext i8 %13314 to i32
  %13315 = load i8, i8* %arrayidx70.4, align 1
  %conv71.6.4 = zext i8 %13315 to i32
  %xor72.6.4 = xor i32 %conv71.6.4, %conv68.6.4
  %conv73.6.4 = trunc i32 %xor72.6.4 to i8
  store i8 %conv73.6.4, i8* %arrayidx70.4, align 1
  %scevgep20.7.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 7
  %13316 = load i8, i8* %scevgep20.7.4, align 1
  %conv68.7.4 = zext i8 %13316 to i32
  %13317 = load i8, i8* %arrayidx70.4, align 1
  %conv71.7.4 = zext i8 %13317 to i32
  %xor72.7.4 = xor i32 %conv71.7.4, %conv68.7.4
  %conv73.7.4 = trunc i32 %xor72.7.4 to i8
  store i8 %conv73.7.4, i8* %arrayidx70.4, align 1
  %scevgep20.8.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 8
  %13318 = load i8, i8* %scevgep20.8.4, align 1
  %conv68.8.4 = zext i8 %13318 to i32
  %13319 = load i8, i8* %arrayidx70.4, align 1
  %conv71.8.4 = zext i8 %13319 to i32
  %xor72.8.4 = xor i32 %conv71.8.4, %conv68.8.4
  %conv73.8.4 = trunc i32 %xor72.8.4 to i8
  store i8 %conv73.8.4, i8* %arrayidx70.4, align 1
  %scevgep20.9.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 9
  %13320 = load i8, i8* %scevgep20.9.4, align 1
  %conv68.9.4 = zext i8 %13320 to i32
  %13321 = load i8, i8* %arrayidx70.4, align 1
  %conv71.9.4 = zext i8 %13321 to i32
  %xor72.9.4 = xor i32 %conv71.9.4, %conv68.9.4
  %conv73.9.4 = trunc i32 %xor72.9.4 to i8
  store i8 %conv73.9.4, i8* %arrayidx70.4, align 1
  %scevgep20.10.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 10
  %13322 = load i8, i8* %scevgep20.10.4, align 1
  %conv68.10.4 = zext i8 %13322 to i32
  %13323 = load i8, i8* %arrayidx70.4, align 1
  %conv71.10.4 = zext i8 %13323 to i32
  %xor72.10.4 = xor i32 %conv71.10.4, %conv68.10.4
  %conv73.10.4 = trunc i32 %xor72.10.4 to i8
  store i8 %conv73.10.4, i8* %arrayidx70.4, align 1
  %scevgep20.11.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 11
  %13324 = load i8, i8* %scevgep20.11.4, align 1
  %conv68.11.4 = zext i8 %13324 to i32
  %13325 = load i8, i8* %arrayidx70.4, align 1
  %conv71.11.4 = zext i8 %13325 to i32
  %xor72.11.4 = xor i32 %conv71.11.4, %conv68.11.4
  %conv73.11.4 = trunc i32 %xor72.11.4 to i8
  store i8 %conv73.11.4, i8* %arrayidx70.4, align 1
  %scevgep20.12.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 12
  %13326 = load i8, i8* %scevgep20.12.4, align 1
  %conv68.12.4 = zext i8 %13326 to i32
  %13327 = load i8, i8* %arrayidx70.4, align 1
  %conv71.12.4 = zext i8 %13327 to i32
  %xor72.12.4 = xor i32 %conv71.12.4, %conv68.12.4
  %conv73.12.4 = trunc i32 %xor72.12.4 to i8
  store i8 %conv73.12.4, i8* %arrayidx70.4, align 1
  %scevgep20.13.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 13
  %13328 = load i8, i8* %scevgep20.13.4, align 1
  %conv68.13.4 = zext i8 %13328 to i32
  %13329 = load i8, i8* %arrayidx70.4, align 1
  %conv71.13.4 = zext i8 %13329 to i32
  %xor72.13.4 = xor i32 %conv71.13.4, %conv68.13.4
  %conv73.13.4 = trunc i32 %xor72.13.4 to i8
  store i8 %conv73.13.4, i8* %arrayidx70.4, align 1
  %scevgep20.14.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 14
  %13330 = load i8, i8* %scevgep20.14.4, align 1
  %conv68.14.4 = zext i8 %13330 to i32
  %13331 = load i8, i8* %arrayidx70.4, align 1
  %conv71.14.4 = zext i8 %13331 to i32
  %xor72.14.4 = xor i32 %conv71.14.4, %conv68.14.4
  %conv73.14.4 = trunc i32 %xor72.14.4 to i8
  store i8 %conv73.14.4, i8* %arrayidx70.4, align 1
  %scevgep20.15.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 15
  %13332 = load i8, i8* %scevgep20.15.4, align 1
  %conv68.15.4 = zext i8 %13332 to i32
  %13333 = load i8, i8* %arrayidx70.4, align 1
  %conv71.15.4 = zext i8 %13333 to i32
  %xor72.15.4 = xor i32 %conv71.15.4, %conv68.15.4
  %conv73.15.4 = trunc i32 %xor72.15.4 to i8
  store i8 %conv73.15.4, i8* %arrayidx70.4, align 1
  %scevgep20.16.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 16
  %13334 = load i8, i8* %scevgep20.16.4, align 1
  %conv68.16.4 = zext i8 %13334 to i32
  %13335 = load i8, i8* %arrayidx70.4, align 1
  %conv71.16.4 = zext i8 %13335 to i32
  %xor72.16.4 = xor i32 %conv71.16.4, %conv68.16.4
  %conv73.16.4 = trunc i32 %xor72.16.4 to i8
  store i8 %conv73.16.4, i8* %arrayidx70.4, align 1
  %scevgep20.17.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 17
  %13336 = load i8, i8* %scevgep20.17.4, align 1
  %conv68.17.4 = zext i8 %13336 to i32
  %13337 = load i8, i8* %arrayidx70.4, align 1
  %conv71.17.4 = zext i8 %13337 to i32
  %xor72.17.4 = xor i32 %conv71.17.4, %conv68.17.4
  %conv73.17.4 = trunc i32 %xor72.17.4 to i8
  store i8 %conv73.17.4, i8* %arrayidx70.4, align 1
  %scevgep20.18.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 18
  %13338 = load i8, i8* %scevgep20.18.4, align 1
  %conv68.18.4 = zext i8 %13338 to i32
  %13339 = load i8, i8* %arrayidx70.4, align 1
  %conv71.18.4 = zext i8 %13339 to i32
  %xor72.18.4 = xor i32 %conv71.18.4, %conv68.18.4
  %conv73.18.4 = trunc i32 %xor72.18.4 to i8
  store i8 %conv73.18.4, i8* %arrayidx70.4, align 1
  %scevgep20.19.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 19
  %13340 = load i8, i8* %scevgep20.19.4, align 1
  %conv68.19.4 = zext i8 %13340 to i32
  %13341 = load i8, i8* %arrayidx70.4, align 1
  %conv71.19.4 = zext i8 %13341 to i32
  %xor72.19.4 = xor i32 %conv71.19.4, %conv68.19.4
  %conv73.19.4 = trunc i32 %xor72.19.4 to i8
  store i8 %conv73.19.4, i8* %arrayidx70.4, align 1
  %scevgep20.20.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 20
  %13342 = load i8, i8* %scevgep20.20.4, align 1
  %conv68.20.4 = zext i8 %13342 to i32
  %13343 = load i8, i8* %arrayidx70.4, align 1
  %conv71.20.4 = zext i8 %13343 to i32
  %xor72.20.4 = xor i32 %conv71.20.4, %conv68.20.4
  %conv73.20.4 = trunc i32 %xor72.20.4 to i8
  store i8 %conv73.20.4, i8* %arrayidx70.4, align 1
  %scevgep20.21.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 21
  %13344 = load i8, i8* %scevgep20.21.4, align 1
  %conv68.21.4 = zext i8 %13344 to i32
  %13345 = load i8, i8* %arrayidx70.4, align 1
  %conv71.21.4 = zext i8 %13345 to i32
  %xor72.21.4 = xor i32 %conv71.21.4, %conv68.21.4
  %conv73.21.4 = trunc i32 %xor72.21.4 to i8
  store i8 %conv73.21.4, i8* %arrayidx70.4, align 1
  %scevgep20.22.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 22
  %13346 = load i8, i8* %scevgep20.22.4, align 1
  %conv68.22.4 = zext i8 %13346 to i32
  %13347 = load i8, i8* %arrayidx70.4, align 1
  %conv71.22.4 = zext i8 %13347 to i32
  %xor72.22.4 = xor i32 %conv71.22.4, %conv68.22.4
  %conv73.22.4 = trunc i32 %xor72.22.4 to i8
  store i8 %conv73.22.4, i8* %arrayidx70.4, align 1
  %scevgep20.23.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 23
  %13348 = load i8, i8* %scevgep20.23.4, align 1
  %conv68.23.4 = zext i8 %13348 to i32
  %13349 = load i8, i8* %arrayidx70.4, align 1
  %conv71.23.4 = zext i8 %13349 to i32
  %xor72.23.4 = xor i32 %conv71.23.4, %conv68.23.4
  %conv73.23.4 = trunc i32 %xor72.23.4 to i8
  store i8 %conv73.23.4, i8* %arrayidx70.4, align 1
  %scevgep20.24.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 24
  %13350 = load i8, i8* %scevgep20.24.4, align 1
  %conv68.24.4 = zext i8 %13350 to i32
  %13351 = load i8, i8* %arrayidx70.4, align 1
  %conv71.24.4 = zext i8 %13351 to i32
  %xor72.24.4 = xor i32 %conv71.24.4, %conv68.24.4
  %conv73.24.4 = trunc i32 %xor72.24.4 to i8
  store i8 %conv73.24.4, i8* %arrayidx70.4, align 1
  %scevgep20.25.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 25
  %13352 = load i8, i8* %scevgep20.25.4, align 1
  %conv68.25.4 = zext i8 %13352 to i32
  %13353 = load i8, i8* %arrayidx70.4, align 1
  %conv71.25.4 = zext i8 %13353 to i32
  %xor72.25.4 = xor i32 %conv71.25.4, %conv68.25.4
  %conv73.25.4 = trunc i32 %xor72.25.4 to i8
  store i8 %conv73.25.4, i8* %arrayidx70.4, align 1
  %scevgep20.26.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 26
  %13354 = load i8, i8* %scevgep20.26.4, align 1
  %conv68.26.4 = zext i8 %13354 to i32
  %13355 = load i8, i8* %arrayidx70.4, align 1
  %conv71.26.4 = zext i8 %13355 to i32
  %xor72.26.4 = xor i32 %conv71.26.4, %conv68.26.4
  %conv73.26.4 = trunc i32 %xor72.26.4 to i8
  store i8 %conv73.26.4, i8* %arrayidx70.4, align 1
  %scevgep20.27.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 27
  %13356 = load i8, i8* %scevgep20.27.4, align 1
  %conv68.27.4 = zext i8 %13356 to i32
  %13357 = load i8, i8* %arrayidx70.4, align 1
  %conv71.27.4 = zext i8 %13357 to i32
  %xor72.27.4 = xor i32 %conv71.27.4, %conv68.27.4
  %conv73.27.4 = trunc i32 %xor72.27.4 to i8
  store i8 %conv73.27.4, i8* %arrayidx70.4, align 1
  %scevgep20.28.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 28
  %13358 = load i8, i8* %scevgep20.28.4, align 1
  %conv68.28.4 = zext i8 %13358 to i32
  %13359 = load i8, i8* %arrayidx70.4, align 1
  %conv71.28.4 = zext i8 %13359 to i32
  %xor72.28.4 = xor i32 %conv71.28.4, %conv68.28.4
  %conv73.28.4 = trunc i32 %xor72.28.4 to i8
  store i8 %conv73.28.4, i8* %arrayidx70.4, align 1
  %scevgep20.29.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 29
  %13360 = load i8, i8* %scevgep20.29.4, align 1
  %conv68.29.4 = zext i8 %13360 to i32
  %13361 = load i8, i8* %arrayidx70.4, align 1
  %conv71.29.4 = zext i8 %13361 to i32
  %xor72.29.4 = xor i32 %conv71.29.4, %conv68.29.4
  %conv73.29.4 = trunc i32 %xor72.29.4 to i8
  store i8 %conv73.29.4, i8* %arrayidx70.4, align 1
  %scevgep20.30.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 30
  %13362 = load i8, i8* %scevgep20.30.4, align 1
  %conv68.30.4 = zext i8 %13362 to i32
  %13363 = load i8, i8* %arrayidx70.4, align 1
  %conv71.30.4 = zext i8 %13363 to i32
  %xor72.30.4 = xor i32 %conv71.30.4, %conv68.30.4
  %conv73.30.4 = trunc i32 %xor72.30.4 to i8
  store i8 %conv73.30.4, i8* %arrayidx70.4, align 1
  %scevgep20.31.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 31
  %13364 = load i8, i8* %scevgep20.31.4, align 1
  %conv68.31.4 = zext i8 %13364 to i32
  %13365 = load i8, i8* %arrayidx70.4, align 1
  %conv71.31.4 = zext i8 %13365 to i32
  %xor72.31.4 = xor i32 %conv71.31.4, %conv68.31.4
  %conv73.31.4 = trunc i32 %xor72.31.4 to i8
  store i8 %conv73.31.4, i8* %arrayidx70.4, align 1
  %scevgep20.32.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 32
  %13366 = load i8, i8* %scevgep20.32.4, align 1
  %conv68.32.4 = zext i8 %13366 to i32
  %13367 = load i8, i8* %arrayidx70.4, align 1
  %conv71.32.4 = zext i8 %13367 to i32
  %xor72.32.4 = xor i32 %conv71.32.4, %conv68.32.4
  %conv73.32.4 = trunc i32 %xor72.32.4 to i8
  store i8 %conv73.32.4, i8* %arrayidx70.4, align 1
  %scevgep20.33.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 33
  %13368 = load i8, i8* %scevgep20.33.4, align 1
  %conv68.33.4 = zext i8 %13368 to i32
  %13369 = load i8, i8* %arrayidx70.4, align 1
  %conv71.33.4 = zext i8 %13369 to i32
  %xor72.33.4 = xor i32 %conv71.33.4, %conv68.33.4
  %conv73.33.4 = trunc i32 %xor72.33.4 to i8
  store i8 %conv73.33.4, i8* %arrayidx70.4, align 1
  %scevgep20.34.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 34
  %13370 = load i8, i8* %scevgep20.34.4, align 1
  %conv68.34.4 = zext i8 %13370 to i32
  %13371 = load i8, i8* %arrayidx70.4, align 1
  %conv71.34.4 = zext i8 %13371 to i32
  %xor72.34.4 = xor i32 %conv71.34.4, %conv68.34.4
  %conv73.34.4 = trunc i32 %xor72.34.4 to i8
  store i8 %conv73.34.4, i8* %arrayidx70.4, align 1
  %scevgep20.35.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 35
  %13372 = load i8, i8* %scevgep20.35.4, align 1
  %conv68.35.4 = zext i8 %13372 to i32
  %13373 = load i8, i8* %arrayidx70.4, align 1
  %conv71.35.4 = zext i8 %13373 to i32
  %xor72.35.4 = xor i32 %conv71.35.4, %conv68.35.4
  %conv73.35.4 = trunc i32 %xor72.35.4 to i8
  store i8 %conv73.35.4, i8* %arrayidx70.4, align 1
  %scevgep20.36.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 36
  %13374 = load i8, i8* %scevgep20.36.4, align 1
  %conv68.36.4 = zext i8 %13374 to i32
  %13375 = load i8, i8* %arrayidx70.4, align 1
  %conv71.36.4 = zext i8 %13375 to i32
  %xor72.36.4 = xor i32 %conv71.36.4, %conv68.36.4
  %conv73.36.4 = trunc i32 %xor72.36.4 to i8
  store i8 %conv73.36.4, i8* %arrayidx70.4, align 1
  %scevgep20.37.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 37
  %13376 = load i8, i8* %scevgep20.37.4, align 1
  %conv68.37.4 = zext i8 %13376 to i32
  %13377 = load i8, i8* %arrayidx70.4, align 1
  %conv71.37.4 = zext i8 %13377 to i32
  %xor72.37.4 = xor i32 %conv71.37.4, %conv68.37.4
  %conv73.37.4 = trunc i32 %xor72.37.4 to i8
  store i8 %conv73.37.4, i8* %arrayidx70.4, align 1
  %scevgep20.38.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 38
  %13378 = load i8, i8* %scevgep20.38.4, align 1
  %conv68.38.4 = zext i8 %13378 to i32
  %13379 = load i8, i8* %arrayidx70.4, align 1
  %conv71.38.4 = zext i8 %13379 to i32
  %xor72.38.4 = xor i32 %conv71.38.4, %conv68.38.4
  %conv73.38.4 = trunc i32 %xor72.38.4 to i8
  store i8 %conv73.38.4, i8* %arrayidx70.4, align 1
  %scevgep20.39.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 39
  %13380 = load i8, i8* %scevgep20.39.4, align 1
  %conv68.39.4 = zext i8 %13380 to i32
  %13381 = load i8, i8* %arrayidx70.4, align 1
  %conv71.39.4 = zext i8 %13381 to i32
  %xor72.39.4 = xor i32 %conv71.39.4, %conv68.39.4
  %conv73.39.4 = trunc i32 %xor72.39.4 to i8
  store i8 %conv73.39.4, i8* %arrayidx70.4, align 1
  %scevgep20.40.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 40
  %13382 = load i8, i8* %scevgep20.40.4, align 1
  %conv68.40.4 = zext i8 %13382 to i32
  %13383 = load i8, i8* %arrayidx70.4, align 1
  %conv71.40.4 = zext i8 %13383 to i32
  %xor72.40.4 = xor i32 %conv71.40.4, %conv68.40.4
  %conv73.40.4 = trunc i32 %xor72.40.4 to i8
  store i8 %conv73.40.4, i8* %arrayidx70.4, align 1
  %scevgep20.41.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 41
  %13384 = load i8, i8* %scevgep20.41.4, align 1
  %conv68.41.4 = zext i8 %13384 to i32
  %13385 = load i8, i8* %arrayidx70.4, align 1
  %conv71.41.4 = zext i8 %13385 to i32
  %xor72.41.4 = xor i32 %conv71.41.4, %conv68.41.4
  %conv73.41.4 = trunc i32 %xor72.41.4 to i8
  store i8 %conv73.41.4, i8* %arrayidx70.4, align 1
  %scevgep20.42.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 42
  %13386 = load i8, i8* %scevgep20.42.4, align 1
  %conv68.42.4 = zext i8 %13386 to i32
  %13387 = load i8, i8* %arrayidx70.4, align 1
  %conv71.42.4 = zext i8 %13387 to i32
  %xor72.42.4 = xor i32 %conv71.42.4, %conv68.42.4
  %conv73.42.4 = trunc i32 %xor72.42.4 to i8
  store i8 %conv73.42.4, i8* %arrayidx70.4, align 1
  %scevgep20.43.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 43
  %13388 = load i8, i8* %scevgep20.43.4, align 1
  %conv68.43.4 = zext i8 %13388 to i32
  %13389 = load i8, i8* %arrayidx70.4, align 1
  %conv71.43.4 = zext i8 %13389 to i32
  %xor72.43.4 = xor i32 %conv71.43.4, %conv68.43.4
  %conv73.43.4 = trunc i32 %xor72.43.4 to i8
  store i8 %conv73.43.4, i8* %arrayidx70.4, align 1
  %scevgep20.44.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 44
  %13390 = load i8, i8* %scevgep20.44.4, align 1
  %conv68.44.4 = zext i8 %13390 to i32
  %13391 = load i8, i8* %arrayidx70.4, align 1
  %conv71.44.4 = zext i8 %13391 to i32
  %xor72.44.4 = xor i32 %conv71.44.4, %conv68.44.4
  %conv73.44.4 = trunc i32 %xor72.44.4 to i8
  store i8 %conv73.44.4, i8* %arrayidx70.4, align 1
  %scevgep20.45.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 45
  %13392 = load i8, i8* %scevgep20.45.4, align 1
  %conv68.45.4 = zext i8 %13392 to i32
  %13393 = load i8, i8* %arrayidx70.4, align 1
  %conv71.45.4 = zext i8 %13393 to i32
  %xor72.45.4 = xor i32 %conv71.45.4, %conv68.45.4
  %conv73.45.4 = trunc i32 %xor72.45.4 to i8
  store i8 %conv73.45.4, i8* %arrayidx70.4, align 1
  %scevgep20.46.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 46
  %13394 = load i8, i8* %scevgep20.46.4, align 1
  %conv68.46.4 = zext i8 %13394 to i32
  %13395 = load i8, i8* %arrayidx70.4, align 1
  %conv71.46.4 = zext i8 %13395 to i32
  %xor72.46.4 = xor i32 %conv71.46.4, %conv68.46.4
  %conv73.46.4 = trunc i32 %xor72.46.4 to i8
  store i8 %conv73.46.4, i8* %arrayidx70.4, align 1
  %scevgep20.47.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 47
  %13396 = load i8, i8* %scevgep20.47.4, align 1
  %conv68.47.4 = zext i8 %13396 to i32
  %13397 = load i8, i8* %arrayidx70.4, align 1
  %conv71.47.4 = zext i8 %13397 to i32
  %xor72.47.4 = xor i32 %conv71.47.4, %conv68.47.4
  %conv73.47.4 = trunc i32 %xor72.47.4 to i8
  store i8 %conv73.47.4, i8* %arrayidx70.4, align 1
  %scevgep20.48.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 48
  %13398 = load i8, i8* %scevgep20.48.4, align 1
  %conv68.48.4 = zext i8 %13398 to i32
  %13399 = load i8, i8* %arrayidx70.4, align 1
  %conv71.48.4 = zext i8 %13399 to i32
  %xor72.48.4 = xor i32 %conv71.48.4, %conv68.48.4
  %conv73.48.4 = trunc i32 %xor72.48.4 to i8
  store i8 %conv73.48.4, i8* %arrayidx70.4, align 1
  %scevgep20.49.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 49
  %13400 = load i8, i8* %scevgep20.49.4, align 1
  %conv68.49.4 = zext i8 %13400 to i32
  %13401 = load i8, i8* %arrayidx70.4, align 1
  %conv71.49.4 = zext i8 %13401 to i32
  %xor72.49.4 = xor i32 %conv71.49.4, %conv68.49.4
  %conv73.49.4 = trunc i32 %xor72.49.4 to i8
  store i8 %conv73.49.4, i8* %arrayidx70.4, align 1
  %scevgep20.50.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 50
  %13402 = load i8, i8* %scevgep20.50.4, align 1
  %conv68.50.4 = zext i8 %13402 to i32
  %13403 = load i8, i8* %arrayidx70.4, align 1
  %conv71.50.4 = zext i8 %13403 to i32
  %xor72.50.4 = xor i32 %conv71.50.4, %conv68.50.4
  %conv73.50.4 = trunc i32 %xor72.50.4 to i8
  store i8 %conv73.50.4, i8* %arrayidx70.4, align 1
  %scevgep20.51.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 51
  %13404 = load i8, i8* %scevgep20.51.4, align 1
  %conv68.51.4 = zext i8 %13404 to i32
  %13405 = load i8, i8* %arrayidx70.4, align 1
  %conv71.51.4 = zext i8 %13405 to i32
  %xor72.51.4 = xor i32 %conv71.51.4, %conv68.51.4
  %conv73.51.4 = trunc i32 %xor72.51.4 to i8
  store i8 %conv73.51.4, i8* %arrayidx70.4, align 1
  %scevgep20.52.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 52
  %13406 = load i8, i8* %scevgep20.52.4, align 1
  %conv68.52.4 = zext i8 %13406 to i32
  %13407 = load i8, i8* %arrayidx70.4, align 1
  %conv71.52.4 = zext i8 %13407 to i32
  %xor72.52.4 = xor i32 %conv71.52.4, %conv68.52.4
  %conv73.52.4 = trunc i32 %xor72.52.4 to i8
  store i8 %conv73.52.4, i8* %arrayidx70.4, align 1
  %scevgep20.53.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 53
  %13408 = load i8, i8* %scevgep20.53.4, align 1
  %conv68.53.4 = zext i8 %13408 to i32
  %13409 = load i8, i8* %arrayidx70.4, align 1
  %conv71.53.4 = zext i8 %13409 to i32
  %xor72.53.4 = xor i32 %conv71.53.4, %conv68.53.4
  %conv73.53.4 = trunc i32 %xor72.53.4 to i8
  store i8 %conv73.53.4, i8* %arrayidx70.4, align 1
  %scevgep20.54.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 54
  %13410 = load i8, i8* %scevgep20.54.4, align 1
  %conv68.54.4 = zext i8 %13410 to i32
  %13411 = load i8, i8* %arrayidx70.4, align 1
  %conv71.54.4 = zext i8 %13411 to i32
  %xor72.54.4 = xor i32 %conv71.54.4, %conv68.54.4
  %conv73.54.4 = trunc i32 %xor72.54.4 to i8
  store i8 %conv73.54.4, i8* %arrayidx70.4, align 1
  %scevgep20.55.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 55
  %13412 = load i8, i8* %scevgep20.55.4, align 1
  %conv68.55.4 = zext i8 %13412 to i32
  %13413 = load i8, i8* %arrayidx70.4, align 1
  %conv71.55.4 = zext i8 %13413 to i32
  %xor72.55.4 = xor i32 %conv71.55.4, %conv68.55.4
  %conv73.55.4 = trunc i32 %xor72.55.4 to i8
  store i8 %conv73.55.4, i8* %arrayidx70.4, align 1
  %scevgep20.56.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 56
  %13414 = load i8, i8* %scevgep20.56.4, align 1
  %conv68.56.4 = zext i8 %13414 to i32
  %13415 = load i8, i8* %arrayidx70.4, align 1
  %conv71.56.4 = zext i8 %13415 to i32
  %xor72.56.4 = xor i32 %conv71.56.4, %conv68.56.4
  %conv73.56.4 = trunc i32 %xor72.56.4 to i8
  store i8 %conv73.56.4, i8* %arrayidx70.4, align 1
  %scevgep20.57.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 57
  %13416 = load i8, i8* %scevgep20.57.4, align 1
  %conv68.57.4 = zext i8 %13416 to i32
  %13417 = load i8, i8* %arrayidx70.4, align 1
  %conv71.57.4 = zext i8 %13417 to i32
  %xor72.57.4 = xor i32 %conv71.57.4, %conv68.57.4
  %conv73.57.4 = trunc i32 %xor72.57.4 to i8
  store i8 %conv73.57.4, i8* %arrayidx70.4, align 1
  %scevgep20.58.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 58
  %13418 = load i8, i8* %scevgep20.58.4, align 1
  %conv68.58.4 = zext i8 %13418 to i32
  %13419 = load i8, i8* %arrayidx70.4, align 1
  %conv71.58.4 = zext i8 %13419 to i32
  %xor72.58.4 = xor i32 %conv71.58.4, %conv68.58.4
  %conv73.58.4 = trunc i32 %xor72.58.4 to i8
  store i8 %conv73.58.4, i8* %arrayidx70.4, align 1
  %scevgep20.59.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 59
  %13420 = load i8, i8* %scevgep20.59.4, align 1
  %conv68.59.4 = zext i8 %13420 to i32
  %13421 = load i8, i8* %arrayidx70.4, align 1
  %conv71.59.4 = zext i8 %13421 to i32
  %xor72.59.4 = xor i32 %conv71.59.4, %conv68.59.4
  %conv73.59.4 = trunc i32 %xor72.59.4 to i8
  store i8 %conv73.59.4, i8* %arrayidx70.4, align 1
  %scevgep20.60.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 0, i64 60
  %13422 = load i8, i8* %scevgep20.60.4, align 1
  %conv68.60.4 = zext i8 %13422 to i32
  %13423 = load i8, i8* %arrayidx70.4, align 1
  %conv71.60.4 = zext i8 %13423 to i32
  %xor72.60.4 = xor i32 %conv71.60.4, %conv68.60.4
  %conv73.60.4 = trunc i32 %xor72.60.4 to i8
  store i8 %conv73.60.4, i8* %arrayidx70.4, align 1
  %scevgep19.4 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13301, i64 0, i64 1, i64 0
  %13424 = bitcast i8* %scevgep19.4 to [61 x [61 x i8]]*
  %arrayidx51.5 = getelementptr inbounds i8, i8* %a, i64 5
  %13425 = load i8, i8* %arrayidx51.5, align 1
  %arrayidx53.5 = getelementptr inbounds i8, i8* %b, i64 5
  %13426 = load i8, i8* %arrayidx53.5, align 1
  %call54.5 = call zeroext i8 @mult(i8 zeroext %13425, i8 zeroext %13426)
  %arrayidx56.5 = getelementptr inbounds i8, i8* %c, i64 5
  store i8 %call54.5, i8* %arrayidx56.5, align 1
  %arrayidx70.5 = getelementptr inbounds i8, i8* %c, i64 5
  %scevgep20.594 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 0
  %13427 = load i8, i8* %scevgep20.594, align 1
  %conv68.595 = zext i8 %13427 to i32
  %13428 = load i8, i8* %arrayidx70.5, align 1
  %conv71.596 = zext i8 %13428 to i32
  %xor72.597 = xor i32 %conv71.596, %conv68.595
  %conv73.598 = trunc i32 %xor72.597 to i8
  store i8 %conv73.598, i8* %arrayidx70.5, align 1
  %scevgep20.1.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 1
  %13429 = load i8, i8* %scevgep20.1.5, align 1
  %conv68.1.5 = zext i8 %13429 to i32
  %13430 = load i8, i8* %arrayidx70.5, align 1
  %conv71.1.5 = zext i8 %13430 to i32
  %xor72.1.5 = xor i32 %conv71.1.5, %conv68.1.5
  %conv73.1.5 = trunc i32 %xor72.1.5 to i8
  store i8 %conv73.1.5, i8* %arrayidx70.5, align 1
  %scevgep20.2.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 2
  %13431 = load i8, i8* %scevgep20.2.5, align 1
  %conv68.2.5 = zext i8 %13431 to i32
  %13432 = load i8, i8* %arrayidx70.5, align 1
  %conv71.2.5 = zext i8 %13432 to i32
  %xor72.2.5 = xor i32 %conv71.2.5, %conv68.2.5
  %conv73.2.5 = trunc i32 %xor72.2.5 to i8
  store i8 %conv73.2.5, i8* %arrayidx70.5, align 1
  %scevgep20.3.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 3
  %13433 = load i8, i8* %scevgep20.3.5, align 1
  %conv68.3.5 = zext i8 %13433 to i32
  %13434 = load i8, i8* %arrayidx70.5, align 1
  %conv71.3.5 = zext i8 %13434 to i32
  %xor72.3.5 = xor i32 %conv71.3.5, %conv68.3.5
  %conv73.3.5 = trunc i32 %xor72.3.5 to i8
  store i8 %conv73.3.5, i8* %arrayidx70.5, align 1
  %scevgep20.4.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 4
  %13435 = load i8, i8* %scevgep20.4.5, align 1
  %conv68.4.5 = zext i8 %13435 to i32
  %13436 = load i8, i8* %arrayidx70.5, align 1
  %conv71.4.5 = zext i8 %13436 to i32
  %xor72.4.5 = xor i32 %conv71.4.5, %conv68.4.5
  %conv73.4.5 = trunc i32 %xor72.4.5 to i8
  store i8 %conv73.4.5, i8* %arrayidx70.5, align 1
  %scevgep20.6.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 6
  %13437 = load i8, i8* %scevgep20.6.5, align 1
  %conv68.6.5 = zext i8 %13437 to i32
  %13438 = load i8, i8* %arrayidx70.5, align 1
  %conv71.6.5 = zext i8 %13438 to i32
  %xor72.6.5 = xor i32 %conv71.6.5, %conv68.6.5
  %conv73.6.5 = trunc i32 %xor72.6.5 to i8
  store i8 %conv73.6.5, i8* %arrayidx70.5, align 1
  %scevgep20.7.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 7
  %13439 = load i8, i8* %scevgep20.7.5, align 1
  %conv68.7.5 = zext i8 %13439 to i32
  %13440 = load i8, i8* %arrayidx70.5, align 1
  %conv71.7.5 = zext i8 %13440 to i32
  %xor72.7.5 = xor i32 %conv71.7.5, %conv68.7.5
  %conv73.7.5 = trunc i32 %xor72.7.5 to i8
  store i8 %conv73.7.5, i8* %arrayidx70.5, align 1
  %scevgep20.8.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 8
  %13441 = load i8, i8* %scevgep20.8.5, align 1
  %conv68.8.5 = zext i8 %13441 to i32
  %13442 = load i8, i8* %arrayidx70.5, align 1
  %conv71.8.5 = zext i8 %13442 to i32
  %xor72.8.5 = xor i32 %conv71.8.5, %conv68.8.5
  %conv73.8.5 = trunc i32 %xor72.8.5 to i8
  store i8 %conv73.8.5, i8* %arrayidx70.5, align 1
  %scevgep20.9.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 9
  %13443 = load i8, i8* %scevgep20.9.5, align 1
  %conv68.9.5 = zext i8 %13443 to i32
  %13444 = load i8, i8* %arrayidx70.5, align 1
  %conv71.9.5 = zext i8 %13444 to i32
  %xor72.9.5 = xor i32 %conv71.9.5, %conv68.9.5
  %conv73.9.5 = trunc i32 %xor72.9.5 to i8
  store i8 %conv73.9.5, i8* %arrayidx70.5, align 1
  %scevgep20.10.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 10
  %13445 = load i8, i8* %scevgep20.10.5, align 1
  %conv68.10.5 = zext i8 %13445 to i32
  %13446 = load i8, i8* %arrayidx70.5, align 1
  %conv71.10.5 = zext i8 %13446 to i32
  %xor72.10.5 = xor i32 %conv71.10.5, %conv68.10.5
  %conv73.10.5 = trunc i32 %xor72.10.5 to i8
  store i8 %conv73.10.5, i8* %arrayidx70.5, align 1
  %scevgep20.11.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 11
  %13447 = load i8, i8* %scevgep20.11.5, align 1
  %conv68.11.5 = zext i8 %13447 to i32
  %13448 = load i8, i8* %arrayidx70.5, align 1
  %conv71.11.5 = zext i8 %13448 to i32
  %xor72.11.5 = xor i32 %conv71.11.5, %conv68.11.5
  %conv73.11.5 = trunc i32 %xor72.11.5 to i8
  store i8 %conv73.11.5, i8* %arrayidx70.5, align 1
  %scevgep20.12.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 12
  %13449 = load i8, i8* %scevgep20.12.5, align 1
  %conv68.12.5 = zext i8 %13449 to i32
  %13450 = load i8, i8* %arrayidx70.5, align 1
  %conv71.12.5 = zext i8 %13450 to i32
  %xor72.12.5 = xor i32 %conv71.12.5, %conv68.12.5
  %conv73.12.5 = trunc i32 %xor72.12.5 to i8
  store i8 %conv73.12.5, i8* %arrayidx70.5, align 1
  %scevgep20.13.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 13
  %13451 = load i8, i8* %scevgep20.13.5, align 1
  %conv68.13.5 = zext i8 %13451 to i32
  %13452 = load i8, i8* %arrayidx70.5, align 1
  %conv71.13.5 = zext i8 %13452 to i32
  %xor72.13.5 = xor i32 %conv71.13.5, %conv68.13.5
  %conv73.13.5 = trunc i32 %xor72.13.5 to i8
  store i8 %conv73.13.5, i8* %arrayidx70.5, align 1
  %scevgep20.14.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 14
  %13453 = load i8, i8* %scevgep20.14.5, align 1
  %conv68.14.5 = zext i8 %13453 to i32
  %13454 = load i8, i8* %arrayidx70.5, align 1
  %conv71.14.5 = zext i8 %13454 to i32
  %xor72.14.5 = xor i32 %conv71.14.5, %conv68.14.5
  %conv73.14.5 = trunc i32 %xor72.14.5 to i8
  store i8 %conv73.14.5, i8* %arrayidx70.5, align 1
  %scevgep20.15.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 15
  %13455 = load i8, i8* %scevgep20.15.5, align 1
  %conv68.15.5 = zext i8 %13455 to i32
  %13456 = load i8, i8* %arrayidx70.5, align 1
  %conv71.15.5 = zext i8 %13456 to i32
  %xor72.15.5 = xor i32 %conv71.15.5, %conv68.15.5
  %conv73.15.5 = trunc i32 %xor72.15.5 to i8
  store i8 %conv73.15.5, i8* %arrayidx70.5, align 1
  %scevgep20.16.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 16
  %13457 = load i8, i8* %scevgep20.16.5, align 1
  %conv68.16.5 = zext i8 %13457 to i32
  %13458 = load i8, i8* %arrayidx70.5, align 1
  %conv71.16.5 = zext i8 %13458 to i32
  %xor72.16.5 = xor i32 %conv71.16.5, %conv68.16.5
  %conv73.16.5 = trunc i32 %xor72.16.5 to i8
  store i8 %conv73.16.5, i8* %arrayidx70.5, align 1
  %scevgep20.17.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 17
  %13459 = load i8, i8* %scevgep20.17.5, align 1
  %conv68.17.5 = zext i8 %13459 to i32
  %13460 = load i8, i8* %arrayidx70.5, align 1
  %conv71.17.5 = zext i8 %13460 to i32
  %xor72.17.5 = xor i32 %conv71.17.5, %conv68.17.5
  %conv73.17.5 = trunc i32 %xor72.17.5 to i8
  store i8 %conv73.17.5, i8* %arrayidx70.5, align 1
  %scevgep20.18.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 18
  %13461 = load i8, i8* %scevgep20.18.5, align 1
  %conv68.18.5 = zext i8 %13461 to i32
  %13462 = load i8, i8* %arrayidx70.5, align 1
  %conv71.18.5 = zext i8 %13462 to i32
  %xor72.18.5 = xor i32 %conv71.18.5, %conv68.18.5
  %conv73.18.5 = trunc i32 %xor72.18.5 to i8
  store i8 %conv73.18.5, i8* %arrayidx70.5, align 1
  %scevgep20.19.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 19
  %13463 = load i8, i8* %scevgep20.19.5, align 1
  %conv68.19.5 = zext i8 %13463 to i32
  %13464 = load i8, i8* %arrayidx70.5, align 1
  %conv71.19.5 = zext i8 %13464 to i32
  %xor72.19.5 = xor i32 %conv71.19.5, %conv68.19.5
  %conv73.19.5 = trunc i32 %xor72.19.5 to i8
  store i8 %conv73.19.5, i8* %arrayidx70.5, align 1
  %scevgep20.20.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 20
  %13465 = load i8, i8* %scevgep20.20.5, align 1
  %conv68.20.5 = zext i8 %13465 to i32
  %13466 = load i8, i8* %arrayidx70.5, align 1
  %conv71.20.5 = zext i8 %13466 to i32
  %xor72.20.5 = xor i32 %conv71.20.5, %conv68.20.5
  %conv73.20.5 = trunc i32 %xor72.20.5 to i8
  store i8 %conv73.20.5, i8* %arrayidx70.5, align 1
  %scevgep20.21.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 21
  %13467 = load i8, i8* %scevgep20.21.5, align 1
  %conv68.21.5 = zext i8 %13467 to i32
  %13468 = load i8, i8* %arrayidx70.5, align 1
  %conv71.21.5 = zext i8 %13468 to i32
  %xor72.21.5 = xor i32 %conv71.21.5, %conv68.21.5
  %conv73.21.5 = trunc i32 %xor72.21.5 to i8
  store i8 %conv73.21.5, i8* %arrayidx70.5, align 1
  %scevgep20.22.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 22
  %13469 = load i8, i8* %scevgep20.22.5, align 1
  %conv68.22.5 = zext i8 %13469 to i32
  %13470 = load i8, i8* %arrayidx70.5, align 1
  %conv71.22.5 = zext i8 %13470 to i32
  %xor72.22.5 = xor i32 %conv71.22.5, %conv68.22.5
  %conv73.22.5 = trunc i32 %xor72.22.5 to i8
  store i8 %conv73.22.5, i8* %arrayidx70.5, align 1
  %scevgep20.23.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 23
  %13471 = load i8, i8* %scevgep20.23.5, align 1
  %conv68.23.5 = zext i8 %13471 to i32
  %13472 = load i8, i8* %arrayidx70.5, align 1
  %conv71.23.5 = zext i8 %13472 to i32
  %xor72.23.5 = xor i32 %conv71.23.5, %conv68.23.5
  %conv73.23.5 = trunc i32 %xor72.23.5 to i8
  store i8 %conv73.23.5, i8* %arrayidx70.5, align 1
  %scevgep20.24.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 24
  %13473 = load i8, i8* %scevgep20.24.5, align 1
  %conv68.24.5 = zext i8 %13473 to i32
  %13474 = load i8, i8* %arrayidx70.5, align 1
  %conv71.24.5 = zext i8 %13474 to i32
  %xor72.24.5 = xor i32 %conv71.24.5, %conv68.24.5
  %conv73.24.5 = trunc i32 %xor72.24.5 to i8
  store i8 %conv73.24.5, i8* %arrayidx70.5, align 1
  %scevgep20.25.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 25
  %13475 = load i8, i8* %scevgep20.25.5, align 1
  %conv68.25.5 = zext i8 %13475 to i32
  %13476 = load i8, i8* %arrayidx70.5, align 1
  %conv71.25.5 = zext i8 %13476 to i32
  %xor72.25.5 = xor i32 %conv71.25.5, %conv68.25.5
  %conv73.25.5 = trunc i32 %xor72.25.5 to i8
  store i8 %conv73.25.5, i8* %arrayidx70.5, align 1
  %scevgep20.26.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 26
  %13477 = load i8, i8* %scevgep20.26.5, align 1
  %conv68.26.5 = zext i8 %13477 to i32
  %13478 = load i8, i8* %arrayidx70.5, align 1
  %conv71.26.5 = zext i8 %13478 to i32
  %xor72.26.5 = xor i32 %conv71.26.5, %conv68.26.5
  %conv73.26.5 = trunc i32 %xor72.26.5 to i8
  store i8 %conv73.26.5, i8* %arrayidx70.5, align 1
  %scevgep20.27.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 27
  %13479 = load i8, i8* %scevgep20.27.5, align 1
  %conv68.27.5 = zext i8 %13479 to i32
  %13480 = load i8, i8* %arrayidx70.5, align 1
  %conv71.27.5 = zext i8 %13480 to i32
  %xor72.27.5 = xor i32 %conv71.27.5, %conv68.27.5
  %conv73.27.5 = trunc i32 %xor72.27.5 to i8
  store i8 %conv73.27.5, i8* %arrayidx70.5, align 1
  %scevgep20.28.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 28
  %13481 = load i8, i8* %scevgep20.28.5, align 1
  %conv68.28.5 = zext i8 %13481 to i32
  %13482 = load i8, i8* %arrayidx70.5, align 1
  %conv71.28.5 = zext i8 %13482 to i32
  %xor72.28.5 = xor i32 %conv71.28.5, %conv68.28.5
  %conv73.28.5 = trunc i32 %xor72.28.5 to i8
  store i8 %conv73.28.5, i8* %arrayidx70.5, align 1
  %scevgep20.29.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 29
  %13483 = load i8, i8* %scevgep20.29.5, align 1
  %conv68.29.5 = zext i8 %13483 to i32
  %13484 = load i8, i8* %arrayidx70.5, align 1
  %conv71.29.5 = zext i8 %13484 to i32
  %xor72.29.5 = xor i32 %conv71.29.5, %conv68.29.5
  %conv73.29.5 = trunc i32 %xor72.29.5 to i8
  store i8 %conv73.29.5, i8* %arrayidx70.5, align 1
  %scevgep20.30.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 30
  %13485 = load i8, i8* %scevgep20.30.5, align 1
  %conv68.30.5 = zext i8 %13485 to i32
  %13486 = load i8, i8* %arrayidx70.5, align 1
  %conv71.30.5 = zext i8 %13486 to i32
  %xor72.30.5 = xor i32 %conv71.30.5, %conv68.30.5
  %conv73.30.5 = trunc i32 %xor72.30.5 to i8
  store i8 %conv73.30.5, i8* %arrayidx70.5, align 1
  %scevgep20.31.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 31
  %13487 = load i8, i8* %scevgep20.31.5, align 1
  %conv68.31.5 = zext i8 %13487 to i32
  %13488 = load i8, i8* %arrayidx70.5, align 1
  %conv71.31.5 = zext i8 %13488 to i32
  %xor72.31.5 = xor i32 %conv71.31.5, %conv68.31.5
  %conv73.31.5 = trunc i32 %xor72.31.5 to i8
  store i8 %conv73.31.5, i8* %arrayidx70.5, align 1
  %scevgep20.32.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 32
  %13489 = load i8, i8* %scevgep20.32.5, align 1
  %conv68.32.5 = zext i8 %13489 to i32
  %13490 = load i8, i8* %arrayidx70.5, align 1
  %conv71.32.5 = zext i8 %13490 to i32
  %xor72.32.5 = xor i32 %conv71.32.5, %conv68.32.5
  %conv73.32.5 = trunc i32 %xor72.32.5 to i8
  store i8 %conv73.32.5, i8* %arrayidx70.5, align 1
  %scevgep20.33.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 33
  %13491 = load i8, i8* %scevgep20.33.5, align 1
  %conv68.33.5 = zext i8 %13491 to i32
  %13492 = load i8, i8* %arrayidx70.5, align 1
  %conv71.33.5 = zext i8 %13492 to i32
  %xor72.33.5 = xor i32 %conv71.33.5, %conv68.33.5
  %conv73.33.5 = trunc i32 %xor72.33.5 to i8
  store i8 %conv73.33.5, i8* %arrayidx70.5, align 1
  %scevgep20.34.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 34
  %13493 = load i8, i8* %scevgep20.34.5, align 1
  %conv68.34.5 = zext i8 %13493 to i32
  %13494 = load i8, i8* %arrayidx70.5, align 1
  %conv71.34.5 = zext i8 %13494 to i32
  %xor72.34.5 = xor i32 %conv71.34.5, %conv68.34.5
  %conv73.34.5 = trunc i32 %xor72.34.5 to i8
  store i8 %conv73.34.5, i8* %arrayidx70.5, align 1
  %scevgep20.35.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 35
  %13495 = load i8, i8* %scevgep20.35.5, align 1
  %conv68.35.5 = zext i8 %13495 to i32
  %13496 = load i8, i8* %arrayidx70.5, align 1
  %conv71.35.5 = zext i8 %13496 to i32
  %xor72.35.5 = xor i32 %conv71.35.5, %conv68.35.5
  %conv73.35.5 = trunc i32 %xor72.35.5 to i8
  store i8 %conv73.35.5, i8* %arrayidx70.5, align 1
  %scevgep20.36.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 36
  %13497 = load i8, i8* %scevgep20.36.5, align 1
  %conv68.36.5 = zext i8 %13497 to i32
  %13498 = load i8, i8* %arrayidx70.5, align 1
  %conv71.36.5 = zext i8 %13498 to i32
  %xor72.36.5 = xor i32 %conv71.36.5, %conv68.36.5
  %conv73.36.5 = trunc i32 %xor72.36.5 to i8
  store i8 %conv73.36.5, i8* %arrayidx70.5, align 1
  %scevgep20.37.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 37
  %13499 = load i8, i8* %scevgep20.37.5, align 1
  %conv68.37.5 = zext i8 %13499 to i32
  %13500 = load i8, i8* %arrayidx70.5, align 1
  %conv71.37.5 = zext i8 %13500 to i32
  %xor72.37.5 = xor i32 %conv71.37.5, %conv68.37.5
  %conv73.37.5 = trunc i32 %xor72.37.5 to i8
  store i8 %conv73.37.5, i8* %arrayidx70.5, align 1
  %scevgep20.38.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 38
  %13501 = load i8, i8* %scevgep20.38.5, align 1
  %conv68.38.5 = zext i8 %13501 to i32
  %13502 = load i8, i8* %arrayidx70.5, align 1
  %conv71.38.5 = zext i8 %13502 to i32
  %xor72.38.5 = xor i32 %conv71.38.5, %conv68.38.5
  %conv73.38.5 = trunc i32 %xor72.38.5 to i8
  store i8 %conv73.38.5, i8* %arrayidx70.5, align 1
  %scevgep20.39.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 39
  %13503 = load i8, i8* %scevgep20.39.5, align 1
  %conv68.39.5 = zext i8 %13503 to i32
  %13504 = load i8, i8* %arrayidx70.5, align 1
  %conv71.39.5 = zext i8 %13504 to i32
  %xor72.39.5 = xor i32 %conv71.39.5, %conv68.39.5
  %conv73.39.5 = trunc i32 %xor72.39.5 to i8
  store i8 %conv73.39.5, i8* %arrayidx70.5, align 1
  %scevgep20.40.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 40
  %13505 = load i8, i8* %scevgep20.40.5, align 1
  %conv68.40.5 = zext i8 %13505 to i32
  %13506 = load i8, i8* %arrayidx70.5, align 1
  %conv71.40.5 = zext i8 %13506 to i32
  %xor72.40.5 = xor i32 %conv71.40.5, %conv68.40.5
  %conv73.40.5 = trunc i32 %xor72.40.5 to i8
  store i8 %conv73.40.5, i8* %arrayidx70.5, align 1
  %scevgep20.41.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 41
  %13507 = load i8, i8* %scevgep20.41.5, align 1
  %conv68.41.5 = zext i8 %13507 to i32
  %13508 = load i8, i8* %arrayidx70.5, align 1
  %conv71.41.5 = zext i8 %13508 to i32
  %xor72.41.5 = xor i32 %conv71.41.5, %conv68.41.5
  %conv73.41.5 = trunc i32 %xor72.41.5 to i8
  store i8 %conv73.41.5, i8* %arrayidx70.5, align 1
  %scevgep20.42.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 42
  %13509 = load i8, i8* %scevgep20.42.5, align 1
  %conv68.42.5 = zext i8 %13509 to i32
  %13510 = load i8, i8* %arrayidx70.5, align 1
  %conv71.42.5 = zext i8 %13510 to i32
  %xor72.42.5 = xor i32 %conv71.42.5, %conv68.42.5
  %conv73.42.5 = trunc i32 %xor72.42.5 to i8
  store i8 %conv73.42.5, i8* %arrayidx70.5, align 1
  %scevgep20.43.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 43
  %13511 = load i8, i8* %scevgep20.43.5, align 1
  %conv68.43.5 = zext i8 %13511 to i32
  %13512 = load i8, i8* %arrayidx70.5, align 1
  %conv71.43.5 = zext i8 %13512 to i32
  %xor72.43.5 = xor i32 %conv71.43.5, %conv68.43.5
  %conv73.43.5 = trunc i32 %xor72.43.5 to i8
  store i8 %conv73.43.5, i8* %arrayidx70.5, align 1
  %scevgep20.44.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 44
  %13513 = load i8, i8* %scevgep20.44.5, align 1
  %conv68.44.5 = zext i8 %13513 to i32
  %13514 = load i8, i8* %arrayidx70.5, align 1
  %conv71.44.5 = zext i8 %13514 to i32
  %xor72.44.5 = xor i32 %conv71.44.5, %conv68.44.5
  %conv73.44.5 = trunc i32 %xor72.44.5 to i8
  store i8 %conv73.44.5, i8* %arrayidx70.5, align 1
  %scevgep20.45.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 45
  %13515 = load i8, i8* %scevgep20.45.5, align 1
  %conv68.45.5 = zext i8 %13515 to i32
  %13516 = load i8, i8* %arrayidx70.5, align 1
  %conv71.45.5 = zext i8 %13516 to i32
  %xor72.45.5 = xor i32 %conv71.45.5, %conv68.45.5
  %conv73.45.5 = trunc i32 %xor72.45.5 to i8
  store i8 %conv73.45.5, i8* %arrayidx70.5, align 1
  %scevgep20.46.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 46
  %13517 = load i8, i8* %scevgep20.46.5, align 1
  %conv68.46.5 = zext i8 %13517 to i32
  %13518 = load i8, i8* %arrayidx70.5, align 1
  %conv71.46.5 = zext i8 %13518 to i32
  %xor72.46.5 = xor i32 %conv71.46.5, %conv68.46.5
  %conv73.46.5 = trunc i32 %xor72.46.5 to i8
  store i8 %conv73.46.5, i8* %arrayidx70.5, align 1
  %scevgep20.47.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 47
  %13519 = load i8, i8* %scevgep20.47.5, align 1
  %conv68.47.5 = zext i8 %13519 to i32
  %13520 = load i8, i8* %arrayidx70.5, align 1
  %conv71.47.5 = zext i8 %13520 to i32
  %xor72.47.5 = xor i32 %conv71.47.5, %conv68.47.5
  %conv73.47.5 = trunc i32 %xor72.47.5 to i8
  store i8 %conv73.47.5, i8* %arrayidx70.5, align 1
  %scevgep20.48.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 48
  %13521 = load i8, i8* %scevgep20.48.5, align 1
  %conv68.48.5 = zext i8 %13521 to i32
  %13522 = load i8, i8* %arrayidx70.5, align 1
  %conv71.48.5 = zext i8 %13522 to i32
  %xor72.48.5 = xor i32 %conv71.48.5, %conv68.48.5
  %conv73.48.5 = trunc i32 %xor72.48.5 to i8
  store i8 %conv73.48.5, i8* %arrayidx70.5, align 1
  %scevgep20.49.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 49
  %13523 = load i8, i8* %scevgep20.49.5, align 1
  %conv68.49.5 = zext i8 %13523 to i32
  %13524 = load i8, i8* %arrayidx70.5, align 1
  %conv71.49.5 = zext i8 %13524 to i32
  %xor72.49.5 = xor i32 %conv71.49.5, %conv68.49.5
  %conv73.49.5 = trunc i32 %xor72.49.5 to i8
  store i8 %conv73.49.5, i8* %arrayidx70.5, align 1
  %scevgep20.50.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 50
  %13525 = load i8, i8* %scevgep20.50.5, align 1
  %conv68.50.5 = zext i8 %13525 to i32
  %13526 = load i8, i8* %arrayidx70.5, align 1
  %conv71.50.5 = zext i8 %13526 to i32
  %xor72.50.5 = xor i32 %conv71.50.5, %conv68.50.5
  %conv73.50.5 = trunc i32 %xor72.50.5 to i8
  store i8 %conv73.50.5, i8* %arrayidx70.5, align 1
  %scevgep20.51.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 51
  %13527 = load i8, i8* %scevgep20.51.5, align 1
  %conv68.51.5 = zext i8 %13527 to i32
  %13528 = load i8, i8* %arrayidx70.5, align 1
  %conv71.51.5 = zext i8 %13528 to i32
  %xor72.51.5 = xor i32 %conv71.51.5, %conv68.51.5
  %conv73.51.5 = trunc i32 %xor72.51.5 to i8
  store i8 %conv73.51.5, i8* %arrayidx70.5, align 1
  %scevgep20.52.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 52
  %13529 = load i8, i8* %scevgep20.52.5, align 1
  %conv68.52.5 = zext i8 %13529 to i32
  %13530 = load i8, i8* %arrayidx70.5, align 1
  %conv71.52.5 = zext i8 %13530 to i32
  %xor72.52.5 = xor i32 %conv71.52.5, %conv68.52.5
  %conv73.52.5 = trunc i32 %xor72.52.5 to i8
  store i8 %conv73.52.5, i8* %arrayidx70.5, align 1
  %scevgep20.53.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 53
  %13531 = load i8, i8* %scevgep20.53.5, align 1
  %conv68.53.5 = zext i8 %13531 to i32
  %13532 = load i8, i8* %arrayidx70.5, align 1
  %conv71.53.5 = zext i8 %13532 to i32
  %xor72.53.5 = xor i32 %conv71.53.5, %conv68.53.5
  %conv73.53.5 = trunc i32 %xor72.53.5 to i8
  store i8 %conv73.53.5, i8* %arrayidx70.5, align 1
  %scevgep20.54.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 54
  %13533 = load i8, i8* %scevgep20.54.5, align 1
  %conv68.54.5 = zext i8 %13533 to i32
  %13534 = load i8, i8* %arrayidx70.5, align 1
  %conv71.54.5 = zext i8 %13534 to i32
  %xor72.54.5 = xor i32 %conv71.54.5, %conv68.54.5
  %conv73.54.5 = trunc i32 %xor72.54.5 to i8
  store i8 %conv73.54.5, i8* %arrayidx70.5, align 1
  %scevgep20.55.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 55
  %13535 = load i8, i8* %scevgep20.55.5, align 1
  %conv68.55.5 = zext i8 %13535 to i32
  %13536 = load i8, i8* %arrayidx70.5, align 1
  %conv71.55.5 = zext i8 %13536 to i32
  %xor72.55.5 = xor i32 %conv71.55.5, %conv68.55.5
  %conv73.55.5 = trunc i32 %xor72.55.5 to i8
  store i8 %conv73.55.5, i8* %arrayidx70.5, align 1
  %scevgep20.56.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 56
  %13537 = load i8, i8* %scevgep20.56.5, align 1
  %conv68.56.5 = zext i8 %13537 to i32
  %13538 = load i8, i8* %arrayidx70.5, align 1
  %conv71.56.5 = zext i8 %13538 to i32
  %xor72.56.5 = xor i32 %conv71.56.5, %conv68.56.5
  %conv73.56.5 = trunc i32 %xor72.56.5 to i8
  store i8 %conv73.56.5, i8* %arrayidx70.5, align 1
  %scevgep20.57.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 57
  %13539 = load i8, i8* %scevgep20.57.5, align 1
  %conv68.57.5 = zext i8 %13539 to i32
  %13540 = load i8, i8* %arrayidx70.5, align 1
  %conv71.57.5 = zext i8 %13540 to i32
  %xor72.57.5 = xor i32 %conv71.57.5, %conv68.57.5
  %conv73.57.5 = trunc i32 %xor72.57.5 to i8
  store i8 %conv73.57.5, i8* %arrayidx70.5, align 1
  %scevgep20.58.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 58
  %13541 = load i8, i8* %scevgep20.58.5, align 1
  %conv68.58.5 = zext i8 %13541 to i32
  %13542 = load i8, i8* %arrayidx70.5, align 1
  %conv71.58.5 = zext i8 %13542 to i32
  %xor72.58.5 = xor i32 %conv71.58.5, %conv68.58.5
  %conv73.58.5 = trunc i32 %xor72.58.5 to i8
  store i8 %conv73.58.5, i8* %arrayidx70.5, align 1
  %scevgep20.59.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 59
  %13543 = load i8, i8* %scevgep20.59.5, align 1
  %conv68.59.5 = zext i8 %13543 to i32
  %13544 = load i8, i8* %arrayidx70.5, align 1
  %conv71.59.5 = zext i8 %13544 to i32
  %xor72.59.5 = xor i32 %conv71.59.5, %conv68.59.5
  %conv73.59.5 = trunc i32 %xor72.59.5 to i8
  store i8 %conv73.59.5, i8* %arrayidx70.5, align 1
  %scevgep20.60.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 0, i64 60
  %13545 = load i8, i8* %scevgep20.60.5, align 1
  %conv68.60.5 = zext i8 %13545 to i32
  %13546 = load i8, i8* %arrayidx70.5, align 1
  %conv71.60.5 = zext i8 %13546 to i32
  %xor72.60.5 = xor i32 %conv71.60.5, %conv68.60.5
  %conv73.60.5 = trunc i32 %xor72.60.5 to i8
  store i8 %conv73.60.5, i8* %arrayidx70.5, align 1
  %scevgep19.5 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13424, i64 0, i64 1, i64 0
  %13547 = bitcast i8* %scevgep19.5 to [61 x [61 x i8]]*
  %arrayidx51.6 = getelementptr inbounds i8, i8* %a, i64 6
  %13548 = load i8, i8* %arrayidx51.6, align 1
  %arrayidx53.6 = getelementptr inbounds i8, i8* %b, i64 6
  %13549 = load i8, i8* %arrayidx53.6, align 1
  %call54.6 = call zeroext i8 @mult(i8 zeroext %13548, i8 zeroext %13549)
  %arrayidx56.6 = getelementptr inbounds i8, i8* %c, i64 6
  store i8 %call54.6, i8* %arrayidx56.6, align 1
  %arrayidx70.6 = getelementptr inbounds i8, i8* %c, i64 6
  %scevgep20.6104 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 0
  %13550 = load i8, i8* %scevgep20.6104, align 1
  %conv68.6105 = zext i8 %13550 to i32
  %13551 = load i8, i8* %arrayidx70.6, align 1
  %conv71.6106 = zext i8 %13551 to i32
  %xor72.6107 = xor i32 %conv71.6106, %conv68.6105
  %conv73.6108 = trunc i32 %xor72.6107 to i8
  store i8 %conv73.6108, i8* %arrayidx70.6, align 1
  %scevgep20.1.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 1
  %13552 = load i8, i8* %scevgep20.1.6, align 1
  %conv68.1.6 = zext i8 %13552 to i32
  %13553 = load i8, i8* %arrayidx70.6, align 1
  %conv71.1.6 = zext i8 %13553 to i32
  %xor72.1.6 = xor i32 %conv71.1.6, %conv68.1.6
  %conv73.1.6 = trunc i32 %xor72.1.6 to i8
  store i8 %conv73.1.6, i8* %arrayidx70.6, align 1
  %scevgep20.2.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 2
  %13554 = load i8, i8* %scevgep20.2.6, align 1
  %conv68.2.6 = zext i8 %13554 to i32
  %13555 = load i8, i8* %arrayidx70.6, align 1
  %conv71.2.6 = zext i8 %13555 to i32
  %xor72.2.6 = xor i32 %conv71.2.6, %conv68.2.6
  %conv73.2.6 = trunc i32 %xor72.2.6 to i8
  store i8 %conv73.2.6, i8* %arrayidx70.6, align 1
  %scevgep20.3.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 3
  %13556 = load i8, i8* %scevgep20.3.6, align 1
  %conv68.3.6 = zext i8 %13556 to i32
  %13557 = load i8, i8* %arrayidx70.6, align 1
  %conv71.3.6 = zext i8 %13557 to i32
  %xor72.3.6 = xor i32 %conv71.3.6, %conv68.3.6
  %conv73.3.6 = trunc i32 %xor72.3.6 to i8
  store i8 %conv73.3.6, i8* %arrayidx70.6, align 1
  %scevgep20.4.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 4
  %13558 = load i8, i8* %scevgep20.4.6, align 1
  %conv68.4.6 = zext i8 %13558 to i32
  %13559 = load i8, i8* %arrayidx70.6, align 1
  %conv71.4.6 = zext i8 %13559 to i32
  %xor72.4.6 = xor i32 %conv71.4.6, %conv68.4.6
  %conv73.4.6 = trunc i32 %xor72.4.6 to i8
  store i8 %conv73.4.6, i8* %arrayidx70.6, align 1
  %scevgep20.5.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 5
  %13560 = load i8, i8* %scevgep20.5.6, align 1
  %conv68.5.6 = zext i8 %13560 to i32
  %13561 = load i8, i8* %arrayidx70.6, align 1
  %conv71.5.6 = zext i8 %13561 to i32
  %xor72.5.6 = xor i32 %conv71.5.6, %conv68.5.6
  %conv73.5.6 = trunc i32 %xor72.5.6 to i8
  store i8 %conv73.5.6, i8* %arrayidx70.6, align 1
  %scevgep20.7.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 7
  %13562 = load i8, i8* %scevgep20.7.6, align 1
  %conv68.7.6 = zext i8 %13562 to i32
  %13563 = load i8, i8* %arrayidx70.6, align 1
  %conv71.7.6 = zext i8 %13563 to i32
  %xor72.7.6 = xor i32 %conv71.7.6, %conv68.7.6
  %conv73.7.6 = trunc i32 %xor72.7.6 to i8
  store i8 %conv73.7.6, i8* %arrayidx70.6, align 1
  %scevgep20.8.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 8
  %13564 = load i8, i8* %scevgep20.8.6, align 1
  %conv68.8.6 = zext i8 %13564 to i32
  %13565 = load i8, i8* %arrayidx70.6, align 1
  %conv71.8.6 = zext i8 %13565 to i32
  %xor72.8.6 = xor i32 %conv71.8.6, %conv68.8.6
  %conv73.8.6 = trunc i32 %xor72.8.6 to i8
  store i8 %conv73.8.6, i8* %arrayidx70.6, align 1
  %scevgep20.9.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 9
  %13566 = load i8, i8* %scevgep20.9.6, align 1
  %conv68.9.6 = zext i8 %13566 to i32
  %13567 = load i8, i8* %arrayidx70.6, align 1
  %conv71.9.6 = zext i8 %13567 to i32
  %xor72.9.6 = xor i32 %conv71.9.6, %conv68.9.6
  %conv73.9.6 = trunc i32 %xor72.9.6 to i8
  store i8 %conv73.9.6, i8* %arrayidx70.6, align 1
  %scevgep20.10.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 10
  %13568 = load i8, i8* %scevgep20.10.6, align 1
  %conv68.10.6 = zext i8 %13568 to i32
  %13569 = load i8, i8* %arrayidx70.6, align 1
  %conv71.10.6 = zext i8 %13569 to i32
  %xor72.10.6 = xor i32 %conv71.10.6, %conv68.10.6
  %conv73.10.6 = trunc i32 %xor72.10.6 to i8
  store i8 %conv73.10.6, i8* %arrayidx70.6, align 1
  %scevgep20.11.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 11
  %13570 = load i8, i8* %scevgep20.11.6, align 1
  %conv68.11.6 = zext i8 %13570 to i32
  %13571 = load i8, i8* %arrayidx70.6, align 1
  %conv71.11.6 = zext i8 %13571 to i32
  %xor72.11.6 = xor i32 %conv71.11.6, %conv68.11.6
  %conv73.11.6 = trunc i32 %xor72.11.6 to i8
  store i8 %conv73.11.6, i8* %arrayidx70.6, align 1
  %scevgep20.12.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 12
  %13572 = load i8, i8* %scevgep20.12.6, align 1
  %conv68.12.6 = zext i8 %13572 to i32
  %13573 = load i8, i8* %arrayidx70.6, align 1
  %conv71.12.6 = zext i8 %13573 to i32
  %xor72.12.6 = xor i32 %conv71.12.6, %conv68.12.6
  %conv73.12.6 = trunc i32 %xor72.12.6 to i8
  store i8 %conv73.12.6, i8* %arrayidx70.6, align 1
  %scevgep20.13.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 13
  %13574 = load i8, i8* %scevgep20.13.6, align 1
  %conv68.13.6 = zext i8 %13574 to i32
  %13575 = load i8, i8* %arrayidx70.6, align 1
  %conv71.13.6 = zext i8 %13575 to i32
  %xor72.13.6 = xor i32 %conv71.13.6, %conv68.13.6
  %conv73.13.6 = trunc i32 %xor72.13.6 to i8
  store i8 %conv73.13.6, i8* %arrayidx70.6, align 1
  %scevgep20.14.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 14
  %13576 = load i8, i8* %scevgep20.14.6, align 1
  %conv68.14.6 = zext i8 %13576 to i32
  %13577 = load i8, i8* %arrayidx70.6, align 1
  %conv71.14.6 = zext i8 %13577 to i32
  %xor72.14.6 = xor i32 %conv71.14.6, %conv68.14.6
  %conv73.14.6 = trunc i32 %xor72.14.6 to i8
  store i8 %conv73.14.6, i8* %arrayidx70.6, align 1
  %scevgep20.15.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 15
  %13578 = load i8, i8* %scevgep20.15.6, align 1
  %conv68.15.6 = zext i8 %13578 to i32
  %13579 = load i8, i8* %arrayidx70.6, align 1
  %conv71.15.6 = zext i8 %13579 to i32
  %xor72.15.6 = xor i32 %conv71.15.6, %conv68.15.6
  %conv73.15.6 = trunc i32 %xor72.15.6 to i8
  store i8 %conv73.15.6, i8* %arrayidx70.6, align 1
  %scevgep20.16.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 16
  %13580 = load i8, i8* %scevgep20.16.6, align 1
  %conv68.16.6 = zext i8 %13580 to i32
  %13581 = load i8, i8* %arrayidx70.6, align 1
  %conv71.16.6 = zext i8 %13581 to i32
  %xor72.16.6 = xor i32 %conv71.16.6, %conv68.16.6
  %conv73.16.6 = trunc i32 %xor72.16.6 to i8
  store i8 %conv73.16.6, i8* %arrayidx70.6, align 1
  %scevgep20.17.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 17
  %13582 = load i8, i8* %scevgep20.17.6, align 1
  %conv68.17.6 = zext i8 %13582 to i32
  %13583 = load i8, i8* %arrayidx70.6, align 1
  %conv71.17.6 = zext i8 %13583 to i32
  %xor72.17.6 = xor i32 %conv71.17.6, %conv68.17.6
  %conv73.17.6 = trunc i32 %xor72.17.6 to i8
  store i8 %conv73.17.6, i8* %arrayidx70.6, align 1
  %scevgep20.18.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 18
  %13584 = load i8, i8* %scevgep20.18.6, align 1
  %conv68.18.6 = zext i8 %13584 to i32
  %13585 = load i8, i8* %arrayidx70.6, align 1
  %conv71.18.6 = zext i8 %13585 to i32
  %xor72.18.6 = xor i32 %conv71.18.6, %conv68.18.6
  %conv73.18.6 = trunc i32 %xor72.18.6 to i8
  store i8 %conv73.18.6, i8* %arrayidx70.6, align 1
  %scevgep20.19.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 19
  %13586 = load i8, i8* %scevgep20.19.6, align 1
  %conv68.19.6 = zext i8 %13586 to i32
  %13587 = load i8, i8* %arrayidx70.6, align 1
  %conv71.19.6 = zext i8 %13587 to i32
  %xor72.19.6 = xor i32 %conv71.19.6, %conv68.19.6
  %conv73.19.6 = trunc i32 %xor72.19.6 to i8
  store i8 %conv73.19.6, i8* %arrayidx70.6, align 1
  %scevgep20.20.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 20
  %13588 = load i8, i8* %scevgep20.20.6, align 1
  %conv68.20.6 = zext i8 %13588 to i32
  %13589 = load i8, i8* %arrayidx70.6, align 1
  %conv71.20.6 = zext i8 %13589 to i32
  %xor72.20.6 = xor i32 %conv71.20.6, %conv68.20.6
  %conv73.20.6 = trunc i32 %xor72.20.6 to i8
  store i8 %conv73.20.6, i8* %arrayidx70.6, align 1
  %scevgep20.21.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 21
  %13590 = load i8, i8* %scevgep20.21.6, align 1
  %conv68.21.6 = zext i8 %13590 to i32
  %13591 = load i8, i8* %arrayidx70.6, align 1
  %conv71.21.6 = zext i8 %13591 to i32
  %xor72.21.6 = xor i32 %conv71.21.6, %conv68.21.6
  %conv73.21.6 = trunc i32 %xor72.21.6 to i8
  store i8 %conv73.21.6, i8* %arrayidx70.6, align 1
  %scevgep20.22.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 22
  %13592 = load i8, i8* %scevgep20.22.6, align 1
  %conv68.22.6 = zext i8 %13592 to i32
  %13593 = load i8, i8* %arrayidx70.6, align 1
  %conv71.22.6 = zext i8 %13593 to i32
  %xor72.22.6 = xor i32 %conv71.22.6, %conv68.22.6
  %conv73.22.6 = trunc i32 %xor72.22.6 to i8
  store i8 %conv73.22.6, i8* %arrayidx70.6, align 1
  %scevgep20.23.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 23
  %13594 = load i8, i8* %scevgep20.23.6, align 1
  %conv68.23.6 = zext i8 %13594 to i32
  %13595 = load i8, i8* %arrayidx70.6, align 1
  %conv71.23.6 = zext i8 %13595 to i32
  %xor72.23.6 = xor i32 %conv71.23.6, %conv68.23.6
  %conv73.23.6 = trunc i32 %xor72.23.6 to i8
  store i8 %conv73.23.6, i8* %arrayidx70.6, align 1
  %scevgep20.24.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 24
  %13596 = load i8, i8* %scevgep20.24.6, align 1
  %conv68.24.6 = zext i8 %13596 to i32
  %13597 = load i8, i8* %arrayidx70.6, align 1
  %conv71.24.6 = zext i8 %13597 to i32
  %xor72.24.6 = xor i32 %conv71.24.6, %conv68.24.6
  %conv73.24.6 = trunc i32 %xor72.24.6 to i8
  store i8 %conv73.24.6, i8* %arrayidx70.6, align 1
  %scevgep20.25.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 25
  %13598 = load i8, i8* %scevgep20.25.6, align 1
  %conv68.25.6 = zext i8 %13598 to i32
  %13599 = load i8, i8* %arrayidx70.6, align 1
  %conv71.25.6 = zext i8 %13599 to i32
  %xor72.25.6 = xor i32 %conv71.25.6, %conv68.25.6
  %conv73.25.6 = trunc i32 %xor72.25.6 to i8
  store i8 %conv73.25.6, i8* %arrayidx70.6, align 1
  %scevgep20.26.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 26
  %13600 = load i8, i8* %scevgep20.26.6, align 1
  %conv68.26.6 = zext i8 %13600 to i32
  %13601 = load i8, i8* %arrayidx70.6, align 1
  %conv71.26.6 = zext i8 %13601 to i32
  %xor72.26.6 = xor i32 %conv71.26.6, %conv68.26.6
  %conv73.26.6 = trunc i32 %xor72.26.6 to i8
  store i8 %conv73.26.6, i8* %arrayidx70.6, align 1
  %scevgep20.27.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 27
  %13602 = load i8, i8* %scevgep20.27.6, align 1
  %conv68.27.6 = zext i8 %13602 to i32
  %13603 = load i8, i8* %arrayidx70.6, align 1
  %conv71.27.6 = zext i8 %13603 to i32
  %xor72.27.6 = xor i32 %conv71.27.6, %conv68.27.6
  %conv73.27.6 = trunc i32 %xor72.27.6 to i8
  store i8 %conv73.27.6, i8* %arrayidx70.6, align 1
  %scevgep20.28.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 28
  %13604 = load i8, i8* %scevgep20.28.6, align 1
  %conv68.28.6 = zext i8 %13604 to i32
  %13605 = load i8, i8* %arrayidx70.6, align 1
  %conv71.28.6 = zext i8 %13605 to i32
  %xor72.28.6 = xor i32 %conv71.28.6, %conv68.28.6
  %conv73.28.6 = trunc i32 %xor72.28.6 to i8
  store i8 %conv73.28.6, i8* %arrayidx70.6, align 1
  %scevgep20.29.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 29
  %13606 = load i8, i8* %scevgep20.29.6, align 1
  %conv68.29.6 = zext i8 %13606 to i32
  %13607 = load i8, i8* %arrayidx70.6, align 1
  %conv71.29.6 = zext i8 %13607 to i32
  %xor72.29.6 = xor i32 %conv71.29.6, %conv68.29.6
  %conv73.29.6 = trunc i32 %xor72.29.6 to i8
  store i8 %conv73.29.6, i8* %arrayidx70.6, align 1
  %scevgep20.30.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 30
  %13608 = load i8, i8* %scevgep20.30.6, align 1
  %conv68.30.6 = zext i8 %13608 to i32
  %13609 = load i8, i8* %arrayidx70.6, align 1
  %conv71.30.6 = zext i8 %13609 to i32
  %xor72.30.6 = xor i32 %conv71.30.6, %conv68.30.6
  %conv73.30.6 = trunc i32 %xor72.30.6 to i8
  store i8 %conv73.30.6, i8* %arrayidx70.6, align 1
  %scevgep20.31.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 31
  %13610 = load i8, i8* %scevgep20.31.6, align 1
  %conv68.31.6 = zext i8 %13610 to i32
  %13611 = load i8, i8* %arrayidx70.6, align 1
  %conv71.31.6 = zext i8 %13611 to i32
  %xor72.31.6 = xor i32 %conv71.31.6, %conv68.31.6
  %conv73.31.6 = trunc i32 %xor72.31.6 to i8
  store i8 %conv73.31.6, i8* %arrayidx70.6, align 1
  %scevgep20.32.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 32
  %13612 = load i8, i8* %scevgep20.32.6, align 1
  %conv68.32.6 = zext i8 %13612 to i32
  %13613 = load i8, i8* %arrayidx70.6, align 1
  %conv71.32.6 = zext i8 %13613 to i32
  %xor72.32.6 = xor i32 %conv71.32.6, %conv68.32.6
  %conv73.32.6 = trunc i32 %xor72.32.6 to i8
  store i8 %conv73.32.6, i8* %arrayidx70.6, align 1
  %scevgep20.33.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 33
  %13614 = load i8, i8* %scevgep20.33.6, align 1
  %conv68.33.6 = zext i8 %13614 to i32
  %13615 = load i8, i8* %arrayidx70.6, align 1
  %conv71.33.6 = zext i8 %13615 to i32
  %xor72.33.6 = xor i32 %conv71.33.6, %conv68.33.6
  %conv73.33.6 = trunc i32 %xor72.33.6 to i8
  store i8 %conv73.33.6, i8* %arrayidx70.6, align 1
  %scevgep20.34.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 34
  %13616 = load i8, i8* %scevgep20.34.6, align 1
  %conv68.34.6 = zext i8 %13616 to i32
  %13617 = load i8, i8* %arrayidx70.6, align 1
  %conv71.34.6 = zext i8 %13617 to i32
  %xor72.34.6 = xor i32 %conv71.34.6, %conv68.34.6
  %conv73.34.6 = trunc i32 %xor72.34.6 to i8
  store i8 %conv73.34.6, i8* %arrayidx70.6, align 1
  %scevgep20.35.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 35
  %13618 = load i8, i8* %scevgep20.35.6, align 1
  %conv68.35.6 = zext i8 %13618 to i32
  %13619 = load i8, i8* %arrayidx70.6, align 1
  %conv71.35.6 = zext i8 %13619 to i32
  %xor72.35.6 = xor i32 %conv71.35.6, %conv68.35.6
  %conv73.35.6 = trunc i32 %xor72.35.6 to i8
  store i8 %conv73.35.6, i8* %arrayidx70.6, align 1
  %scevgep20.36.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 36
  %13620 = load i8, i8* %scevgep20.36.6, align 1
  %conv68.36.6 = zext i8 %13620 to i32
  %13621 = load i8, i8* %arrayidx70.6, align 1
  %conv71.36.6 = zext i8 %13621 to i32
  %xor72.36.6 = xor i32 %conv71.36.6, %conv68.36.6
  %conv73.36.6 = trunc i32 %xor72.36.6 to i8
  store i8 %conv73.36.6, i8* %arrayidx70.6, align 1
  %scevgep20.37.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 37
  %13622 = load i8, i8* %scevgep20.37.6, align 1
  %conv68.37.6 = zext i8 %13622 to i32
  %13623 = load i8, i8* %arrayidx70.6, align 1
  %conv71.37.6 = zext i8 %13623 to i32
  %xor72.37.6 = xor i32 %conv71.37.6, %conv68.37.6
  %conv73.37.6 = trunc i32 %xor72.37.6 to i8
  store i8 %conv73.37.6, i8* %arrayidx70.6, align 1
  %scevgep20.38.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 38
  %13624 = load i8, i8* %scevgep20.38.6, align 1
  %conv68.38.6 = zext i8 %13624 to i32
  %13625 = load i8, i8* %arrayidx70.6, align 1
  %conv71.38.6 = zext i8 %13625 to i32
  %xor72.38.6 = xor i32 %conv71.38.6, %conv68.38.6
  %conv73.38.6 = trunc i32 %xor72.38.6 to i8
  store i8 %conv73.38.6, i8* %arrayidx70.6, align 1
  %scevgep20.39.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 39
  %13626 = load i8, i8* %scevgep20.39.6, align 1
  %conv68.39.6 = zext i8 %13626 to i32
  %13627 = load i8, i8* %arrayidx70.6, align 1
  %conv71.39.6 = zext i8 %13627 to i32
  %xor72.39.6 = xor i32 %conv71.39.6, %conv68.39.6
  %conv73.39.6 = trunc i32 %xor72.39.6 to i8
  store i8 %conv73.39.6, i8* %arrayidx70.6, align 1
  %scevgep20.40.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 40
  %13628 = load i8, i8* %scevgep20.40.6, align 1
  %conv68.40.6 = zext i8 %13628 to i32
  %13629 = load i8, i8* %arrayidx70.6, align 1
  %conv71.40.6 = zext i8 %13629 to i32
  %xor72.40.6 = xor i32 %conv71.40.6, %conv68.40.6
  %conv73.40.6 = trunc i32 %xor72.40.6 to i8
  store i8 %conv73.40.6, i8* %arrayidx70.6, align 1
  %scevgep20.41.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 41
  %13630 = load i8, i8* %scevgep20.41.6, align 1
  %conv68.41.6 = zext i8 %13630 to i32
  %13631 = load i8, i8* %arrayidx70.6, align 1
  %conv71.41.6 = zext i8 %13631 to i32
  %xor72.41.6 = xor i32 %conv71.41.6, %conv68.41.6
  %conv73.41.6 = trunc i32 %xor72.41.6 to i8
  store i8 %conv73.41.6, i8* %arrayidx70.6, align 1
  %scevgep20.42.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 42
  %13632 = load i8, i8* %scevgep20.42.6, align 1
  %conv68.42.6 = zext i8 %13632 to i32
  %13633 = load i8, i8* %arrayidx70.6, align 1
  %conv71.42.6 = zext i8 %13633 to i32
  %xor72.42.6 = xor i32 %conv71.42.6, %conv68.42.6
  %conv73.42.6 = trunc i32 %xor72.42.6 to i8
  store i8 %conv73.42.6, i8* %arrayidx70.6, align 1
  %scevgep20.43.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 43
  %13634 = load i8, i8* %scevgep20.43.6, align 1
  %conv68.43.6 = zext i8 %13634 to i32
  %13635 = load i8, i8* %arrayidx70.6, align 1
  %conv71.43.6 = zext i8 %13635 to i32
  %xor72.43.6 = xor i32 %conv71.43.6, %conv68.43.6
  %conv73.43.6 = trunc i32 %xor72.43.6 to i8
  store i8 %conv73.43.6, i8* %arrayidx70.6, align 1
  %scevgep20.44.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 44
  %13636 = load i8, i8* %scevgep20.44.6, align 1
  %conv68.44.6 = zext i8 %13636 to i32
  %13637 = load i8, i8* %arrayidx70.6, align 1
  %conv71.44.6 = zext i8 %13637 to i32
  %xor72.44.6 = xor i32 %conv71.44.6, %conv68.44.6
  %conv73.44.6 = trunc i32 %xor72.44.6 to i8
  store i8 %conv73.44.6, i8* %arrayidx70.6, align 1
  %scevgep20.45.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 45
  %13638 = load i8, i8* %scevgep20.45.6, align 1
  %conv68.45.6 = zext i8 %13638 to i32
  %13639 = load i8, i8* %arrayidx70.6, align 1
  %conv71.45.6 = zext i8 %13639 to i32
  %xor72.45.6 = xor i32 %conv71.45.6, %conv68.45.6
  %conv73.45.6 = trunc i32 %xor72.45.6 to i8
  store i8 %conv73.45.6, i8* %arrayidx70.6, align 1
  %scevgep20.46.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 46
  %13640 = load i8, i8* %scevgep20.46.6, align 1
  %conv68.46.6 = zext i8 %13640 to i32
  %13641 = load i8, i8* %arrayidx70.6, align 1
  %conv71.46.6 = zext i8 %13641 to i32
  %xor72.46.6 = xor i32 %conv71.46.6, %conv68.46.6
  %conv73.46.6 = trunc i32 %xor72.46.6 to i8
  store i8 %conv73.46.6, i8* %arrayidx70.6, align 1
  %scevgep20.47.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 47
  %13642 = load i8, i8* %scevgep20.47.6, align 1
  %conv68.47.6 = zext i8 %13642 to i32
  %13643 = load i8, i8* %arrayidx70.6, align 1
  %conv71.47.6 = zext i8 %13643 to i32
  %xor72.47.6 = xor i32 %conv71.47.6, %conv68.47.6
  %conv73.47.6 = trunc i32 %xor72.47.6 to i8
  store i8 %conv73.47.6, i8* %arrayidx70.6, align 1
  %scevgep20.48.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 48
  %13644 = load i8, i8* %scevgep20.48.6, align 1
  %conv68.48.6 = zext i8 %13644 to i32
  %13645 = load i8, i8* %arrayidx70.6, align 1
  %conv71.48.6 = zext i8 %13645 to i32
  %xor72.48.6 = xor i32 %conv71.48.6, %conv68.48.6
  %conv73.48.6 = trunc i32 %xor72.48.6 to i8
  store i8 %conv73.48.6, i8* %arrayidx70.6, align 1
  %scevgep20.49.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 49
  %13646 = load i8, i8* %scevgep20.49.6, align 1
  %conv68.49.6 = zext i8 %13646 to i32
  %13647 = load i8, i8* %arrayidx70.6, align 1
  %conv71.49.6 = zext i8 %13647 to i32
  %xor72.49.6 = xor i32 %conv71.49.6, %conv68.49.6
  %conv73.49.6 = trunc i32 %xor72.49.6 to i8
  store i8 %conv73.49.6, i8* %arrayidx70.6, align 1
  %scevgep20.50.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 50
  %13648 = load i8, i8* %scevgep20.50.6, align 1
  %conv68.50.6 = zext i8 %13648 to i32
  %13649 = load i8, i8* %arrayidx70.6, align 1
  %conv71.50.6 = zext i8 %13649 to i32
  %xor72.50.6 = xor i32 %conv71.50.6, %conv68.50.6
  %conv73.50.6 = trunc i32 %xor72.50.6 to i8
  store i8 %conv73.50.6, i8* %arrayidx70.6, align 1
  %scevgep20.51.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 51
  %13650 = load i8, i8* %scevgep20.51.6, align 1
  %conv68.51.6 = zext i8 %13650 to i32
  %13651 = load i8, i8* %arrayidx70.6, align 1
  %conv71.51.6 = zext i8 %13651 to i32
  %xor72.51.6 = xor i32 %conv71.51.6, %conv68.51.6
  %conv73.51.6 = trunc i32 %xor72.51.6 to i8
  store i8 %conv73.51.6, i8* %arrayidx70.6, align 1
  %scevgep20.52.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 52
  %13652 = load i8, i8* %scevgep20.52.6, align 1
  %conv68.52.6 = zext i8 %13652 to i32
  %13653 = load i8, i8* %arrayidx70.6, align 1
  %conv71.52.6 = zext i8 %13653 to i32
  %xor72.52.6 = xor i32 %conv71.52.6, %conv68.52.6
  %conv73.52.6 = trunc i32 %xor72.52.6 to i8
  store i8 %conv73.52.6, i8* %arrayidx70.6, align 1
  %scevgep20.53.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 53
  %13654 = load i8, i8* %scevgep20.53.6, align 1
  %conv68.53.6 = zext i8 %13654 to i32
  %13655 = load i8, i8* %arrayidx70.6, align 1
  %conv71.53.6 = zext i8 %13655 to i32
  %xor72.53.6 = xor i32 %conv71.53.6, %conv68.53.6
  %conv73.53.6 = trunc i32 %xor72.53.6 to i8
  store i8 %conv73.53.6, i8* %arrayidx70.6, align 1
  %scevgep20.54.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 54
  %13656 = load i8, i8* %scevgep20.54.6, align 1
  %conv68.54.6 = zext i8 %13656 to i32
  %13657 = load i8, i8* %arrayidx70.6, align 1
  %conv71.54.6 = zext i8 %13657 to i32
  %xor72.54.6 = xor i32 %conv71.54.6, %conv68.54.6
  %conv73.54.6 = trunc i32 %xor72.54.6 to i8
  store i8 %conv73.54.6, i8* %arrayidx70.6, align 1
  %scevgep20.55.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 55
  %13658 = load i8, i8* %scevgep20.55.6, align 1
  %conv68.55.6 = zext i8 %13658 to i32
  %13659 = load i8, i8* %arrayidx70.6, align 1
  %conv71.55.6 = zext i8 %13659 to i32
  %xor72.55.6 = xor i32 %conv71.55.6, %conv68.55.6
  %conv73.55.6 = trunc i32 %xor72.55.6 to i8
  store i8 %conv73.55.6, i8* %arrayidx70.6, align 1
  %scevgep20.56.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 56
  %13660 = load i8, i8* %scevgep20.56.6, align 1
  %conv68.56.6 = zext i8 %13660 to i32
  %13661 = load i8, i8* %arrayidx70.6, align 1
  %conv71.56.6 = zext i8 %13661 to i32
  %xor72.56.6 = xor i32 %conv71.56.6, %conv68.56.6
  %conv73.56.6 = trunc i32 %xor72.56.6 to i8
  store i8 %conv73.56.6, i8* %arrayidx70.6, align 1
  %scevgep20.57.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 57
  %13662 = load i8, i8* %scevgep20.57.6, align 1
  %conv68.57.6 = zext i8 %13662 to i32
  %13663 = load i8, i8* %arrayidx70.6, align 1
  %conv71.57.6 = zext i8 %13663 to i32
  %xor72.57.6 = xor i32 %conv71.57.6, %conv68.57.6
  %conv73.57.6 = trunc i32 %xor72.57.6 to i8
  store i8 %conv73.57.6, i8* %arrayidx70.6, align 1
  %scevgep20.58.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 58
  %13664 = load i8, i8* %scevgep20.58.6, align 1
  %conv68.58.6 = zext i8 %13664 to i32
  %13665 = load i8, i8* %arrayidx70.6, align 1
  %conv71.58.6 = zext i8 %13665 to i32
  %xor72.58.6 = xor i32 %conv71.58.6, %conv68.58.6
  %conv73.58.6 = trunc i32 %xor72.58.6 to i8
  store i8 %conv73.58.6, i8* %arrayidx70.6, align 1
  %scevgep20.59.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 59
  %13666 = load i8, i8* %scevgep20.59.6, align 1
  %conv68.59.6 = zext i8 %13666 to i32
  %13667 = load i8, i8* %arrayidx70.6, align 1
  %conv71.59.6 = zext i8 %13667 to i32
  %xor72.59.6 = xor i32 %conv71.59.6, %conv68.59.6
  %conv73.59.6 = trunc i32 %xor72.59.6 to i8
  store i8 %conv73.59.6, i8* %arrayidx70.6, align 1
  %scevgep20.60.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 0, i64 60
  %13668 = load i8, i8* %scevgep20.60.6, align 1
  %conv68.60.6 = zext i8 %13668 to i32
  %13669 = load i8, i8* %arrayidx70.6, align 1
  %conv71.60.6 = zext i8 %13669 to i32
  %xor72.60.6 = xor i32 %conv71.60.6, %conv68.60.6
  %conv73.60.6 = trunc i32 %xor72.60.6 to i8
  store i8 %conv73.60.6, i8* %arrayidx70.6, align 1
  %scevgep19.6 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13547, i64 0, i64 1, i64 0
  %13670 = bitcast i8* %scevgep19.6 to [61 x [61 x i8]]*
  %arrayidx51.7 = getelementptr inbounds i8, i8* %a, i64 7
  %13671 = load i8, i8* %arrayidx51.7, align 1
  %arrayidx53.7 = getelementptr inbounds i8, i8* %b, i64 7
  %13672 = load i8, i8* %arrayidx53.7, align 1
  %call54.7 = call zeroext i8 @mult(i8 zeroext %13671, i8 zeroext %13672)
  %arrayidx56.7 = getelementptr inbounds i8, i8* %c, i64 7
  store i8 %call54.7, i8* %arrayidx56.7, align 1
  %arrayidx70.7 = getelementptr inbounds i8, i8* %c, i64 7
  %scevgep20.7114 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 0
  %13673 = load i8, i8* %scevgep20.7114, align 1
  %conv68.7115 = zext i8 %13673 to i32
  %13674 = load i8, i8* %arrayidx70.7, align 1
  %conv71.7116 = zext i8 %13674 to i32
  %xor72.7117 = xor i32 %conv71.7116, %conv68.7115
  %conv73.7118 = trunc i32 %xor72.7117 to i8
  store i8 %conv73.7118, i8* %arrayidx70.7, align 1
  %scevgep20.1.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 1
  %13675 = load i8, i8* %scevgep20.1.7, align 1
  %conv68.1.7 = zext i8 %13675 to i32
  %13676 = load i8, i8* %arrayidx70.7, align 1
  %conv71.1.7 = zext i8 %13676 to i32
  %xor72.1.7 = xor i32 %conv71.1.7, %conv68.1.7
  %conv73.1.7 = trunc i32 %xor72.1.7 to i8
  store i8 %conv73.1.7, i8* %arrayidx70.7, align 1
  %scevgep20.2.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 2
  %13677 = load i8, i8* %scevgep20.2.7, align 1
  %conv68.2.7 = zext i8 %13677 to i32
  %13678 = load i8, i8* %arrayidx70.7, align 1
  %conv71.2.7 = zext i8 %13678 to i32
  %xor72.2.7 = xor i32 %conv71.2.7, %conv68.2.7
  %conv73.2.7 = trunc i32 %xor72.2.7 to i8
  store i8 %conv73.2.7, i8* %arrayidx70.7, align 1
  %scevgep20.3.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 3
  %13679 = load i8, i8* %scevgep20.3.7, align 1
  %conv68.3.7 = zext i8 %13679 to i32
  %13680 = load i8, i8* %arrayidx70.7, align 1
  %conv71.3.7 = zext i8 %13680 to i32
  %xor72.3.7 = xor i32 %conv71.3.7, %conv68.3.7
  %conv73.3.7 = trunc i32 %xor72.3.7 to i8
  store i8 %conv73.3.7, i8* %arrayidx70.7, align 1
  %scevgep20.4.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 4
  %13681 = load i8, i8* %scevgep20.4.7, align 1
  %conv68.4.7 = zext i8 %13681 to i32
  %13682 = load i8, i8* %arrayidx70.7, align 1
  %conv71.4.7 = zext i8 %13682 to i32
  %xor72.4.7 = xor i32 %conv71.4.7, %conv68.4.7
  %conv73.4.7 = trunc i32 %xor72.4.7 to i8
  store i8 %conv73.4.7, i8* %arrayidx70.7, align 1
  %scevgep20.5.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 5
  %13683 = load i8, i8* %scevgep20.5.7, align 1
  %conv68.5.7 = zext i8 %13683 to i32
  %13684 = load i8, i8* %arrayidx70.7, align 1
  %conv71.5.7 = zext i8 %13684 to i32
  %xor72.5.7 = xor i32 %conv71.5.7, %conv68.5.7
  %conv73.5.7 = trunc i32 %xor72.5.7 to i8
  store i8 %conv73.5.7, i8* %arrayidx70.7, align 1
  %scevgep20.6.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 6
  %13685 = load i8, i8* %scevgep20.6.7, align 1
  %conv68.6.7 = zext i8 %13685 to i32
  %13686 = load i8, i8* %arrayidx70.7, align 1
  %conv71.6.7 = zext i8 %13686 to i32
  %xor72.6.7 = xor i32 %conv71.6.7, %conv68.6.7
  %conv73.6.7 = trunc i32 %xor72.6.7 to i8
  store i8 %conv73.6.7, i8* %arrayidx70.7, align 1
  %scevgep20.8.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 8
  %13687 = load i8, i8* %scevgep20.8.7, align 1
  %conv68.8.7 = zext i8 %13687 to i32
  %13688 = load i8, i8* %arrayidx70.7, align 1
  %conv71.8.7 = zext i8 %13688 to i32
  %xor72.8.7 = xor i32 %conv71.8.7, %conv68.8.7
  %conv73.8.7 = trunc i32 %xor72.8.7 to i8
  store i8 %conv73.8.7, i8* %arrayidx70.7, align 1
  %scevgep20.9.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 9
  %13689 = load i8, i8* %scevgep20.9.7, align 1
  %conv68.9.7 = zext i8 %13689 to i32
  %13690 = load i8, i8* %arrayidx70.7, align 1
  %conv71.9.7 = zext i8 %13690 to i32
  %xor72.9.7 = xor i32 %conv71.9.7, %conv68.9.7
  %conv73.9.7 = trunc i32 %xor72.9.7 to i8
  store i8 %conv73.9.7, i8* %arrayidx70.7, align 1
  %scevgep20.10.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 10
  %13691 = load i8, i8* %scevgep20.10.7, align 1
  %conv68.10.7 = zext i8 %13691 to i32
  %13692 = load i8, i8* %arrayidx70.7, align 1
  %conv71.10.7 = zext i8 %13692 to i32
  %xor72.10.7 = xor i32 %conv71.10.7, %conv68.10.7
  %conv73.10.7 = trunc i32 %xor72.10.7 to i8
  store i8 %conv73.10.7, i8* %arrayidx70.7, align 1
  %scevgep20.11.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 11
  %13693 = load i8, i8* %scevgep20.11.7, align 1
  %conv68.11.7 = zext i8 %13693 to i32
  %13694 = load i8, i8* %arrayidx70.7, align 1
  %conv71.11.7 = zext i8 %13694 to i32
  %xor72.11.7 = xor i32 %conv71.11.7, %conv68.11.7
  %conv73.11.7 = trunc i32 %xor72.11.7 to i8
  store i8 %conv73.11.7, i8* %arrayidx70.7, align 1
  %scevgep20.12.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 12
  %13695 = load i8, i8* %scevgep20.12.7, align 1
  %conv68.12.7 = zext i8 %13695 to i32
  %13696 = load i8, i8* %arrayidx70.7, align 1
  %conv71.12.7 = zext i8 %13696 to i32
  %xor72.12.7 = xor i32 %conv71.12.7, %conv68.12.7
  %conv73.12.7 = trunc i32 %xor72.12.7 to i8
  store i8 %conv73.12.7, i8* %arrayidx70.7, align 1
  %scevgep20.13.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 13
  %13697 = load i8, i8* %scevgep20.13.7, align 1
  %conv68.13.7 = zext i8 %13697 to i32
  %13698 = load i8, i8* %arrayidx70.7, align 1
  %conv71.13.7 = zext i8 %13698 to i32
  %xor72.13.7 = xor i32 %conv71.13.7, %conv68.13.7
  %conv73.13.7 = trunc i32 %xor72.13.7 to i8
  store i8 %conv73.13.7, i8* %arrayidx70.7, align 1
  %scevgep20.14.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 14
  %13699 = load i8, i8* %scevgep20.14.7, align 1
  %conv68.14.7 = zext i8 %13699 to i32
  %13700 = load i8, i8* %arrayidx70.7, align 1
  %conv71.14.7 = zext i8 %13700 to i32
  %xor72.14.7 = xor i32 %conv71.14.7, %conv68.14.7
  %conv73.14.7 = trunc i32 %xor72.14.7 to i8
  store i8 %conv73.14.7, i8* %arrayidx70.7, align 1
  %scevgep20.15.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 15
  %13701 = load i8, i8* %scevgep20.15.7, align 1
  %conv68.15.7 = zext i8 %13701 to i32
  %13702 = load i8, i8* %arrayidx70.7, align 1
  %conv71.15.7 = zext i8 %13702 to i32
  %xor72.15.7 = xor i32 %conv71.15.7, %conv68.15.7
  %conv73.15.7 = trunc i32 %xor72.15.7 to i8
  store i8 %conv73.15.7, i8* %arrayidx70.7, align 1
  %scevgep20.16.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 16
  %13703 = load i8, i8* %scevgep20.16.7, align 1
  %conv68.16.7 = zext i8 %13703 to i32
  %13704 = load i8, i8* %arrayidx70.7, align 1
  %conv71.16.7 = zext i8 %13704 to i32
  %xor72.16.7 = xor i32 %conv71.16.7, %conv68.16.7
  %conv73.16.7 = trunc i32 %xor72.16.7 to i8
  store i8 %conv73.16.7, i8* %arrayidx70.7, align 1
  %scevgep20.17.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 17
  %13705 = load i8, i8* %scevgep20.17.7, align 1
  %conv68.17.7 = zext i8 %13705 to i32
  %13706 = load i8, i8* %arrayidx70.7, align 1
  %conv71.17.7 = zext i8 %13706 to i32
  %xor72.17.7 = xor i32 %conv71.17.7, %conv68.17.7
  %conv73.17.7 = trunc i32 %xor72.17.7 to i8
  store i8 %conv73.17.7, i8* %arrayidx70.7, align 1
  %scevgep20.18.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 18
  %13707 = load i8, i8* %scevgep20.18.7, align 1
  %conv68.18.7 = zext i8 %13707 to i32
  %13708 = load i8, i8* %arrayidx70.7, align 1
  %conv71.18.7 = zext i8 %13708 to i32
  %xor72.18.7 = xor i32 %conv71.18.7, %conv68.18.7
  %conv73.18.7 = trunc i32 %xor72.18.7 to i8
  store i8 %conv73.18.7, i8* %arrayidx70.7, align 1
  %scevgep20.19.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 19
  %13709 = load i8, i8* %scevgep20.19.7, align 1
  %conv68.19.7 = zext i8 %13709 to i32
  %13710 = load i8, i8* %arrayidx70.7, align 1
  %conv71.19.7 = zext i8 %13710 to i32
  %xor72.19.7 = xor i32 %conv71.19.7, %conv68.19.7
  %conv73.19.7 = trunc i32 %xor72.19.7 to i8
  store i8 %conv73.19.7, i8* %arrayidx70.7, align 1
  %scevgep20.20.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 20
  %13711 = load i8, i8* %scevgep20.20.7, align 1
  %conv68.20.7 = zext i8 %13711 to i32
  %13712 = load i8, i8* %arrayidx70.7, align 1
  %conv71.20.7 = zext i8 %13712 to i32
  %xor72.20.7 = xor i32 %conv71.20.7, %conv68.20.7
  %conv73.20.7 = trunc i32 %xor72.20.7 to i8
  store i8 %conv73.20.7, i8* %arrayidx70.7, align 1
  %scevgep20.21.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 21
  %13713 = load i8, i8* %scevgep20.21.7, align 1
  %conv68.21.7 = zext i8 %13713 to i32
  %13714 = load i8, i8* %arrayidx70.7, align 1
  %conv71.21.7 = zext i8 %13714 to i32
  %xor72.21.7 = xor i32 %conv71.21.7, %conv68.21.7
  %conv73.21.7 = trunc i32 %xor72.21.7 to i8
  store i8 %conv73.21.7, i8* %arrayidx70.7, align 1
  %scevgep20.22.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 22
  %13715 = load i8, i8* %scevgep20.22.7, align 1
  %conv68.22.7 = zext i8 %13715 to i32
  %13716 = load i8, i8* %arrayidx70.7, align 1
  %conv71.22.7 = zext i8 %13716 to i32
  %xor72.22.7 = xor i32 %conv71.22.7, %conv68.22.7
  %conv73.22.7 = trunc i32 %xor72.22.7 to i8
  store i8 %conv73.22.7, i8* %arrayidx70.7, align 1
  %scevgep20.23.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 23
  %13717 = load i8, i8* %scevgep20.23.7, align 1
  %conv68.23.7 = zext i8 %13717 to i32
  %13718 = load i8, i8* %arrayidx70.7, align 1
  %conv71.23.7 = zext i8 %13718 to i32
  %xor72.23.7 = xor i32 %conv71.23.7, %conv68.23.7
  %conv73.23.7 = trunc i32 %xor72.23.7 to i8
  store i8 %conv73.23.7, i8* %arrayidx70.7, align 1
  %scevgep20.24.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 24
  %13719 = load i8, i8* %scevgep20.24.7, align 1
  %conv68.24.7 = zext i8 %13719 to i32
  %13720 = load i8, i8* %arrayidx70.7, align 1
  %conv71.24.7 = zext i8 %13720 to i32
  %xor72.24.7 = xor i32 %conv71.24.7, %conv68.24.7
  %conv73.24.7 = trunc i32 %xor72.24.7 to i8
  store i8 %conv73.24.7, i8* %arrayidx70.7, align 1
  %scevgep20.25.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 25
  %13721 = load i8, i8* %scevgep20.25.7, align 1
  %conv68.25.7 = zext i8 %13721 to i32
  %13722 = load i8, i8* %arrayidx70.7, align 1
  %conv71.25.7 = zext i8 %13722 to i32
  %xor72.25.7 = xor i32 %conv71.25.7, %conv68.25.7
  %conv73.25.7 = trunc i32 %xor72.25.7 to i8
  store i8 %conv73.25.7, i8* %arrayidx70.7, align 1
  %scevgep20.26.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 26
  %13723 = load i8, i8* %scevgep20.26.7, align 1
  %conv68.26.7 = zext i8 %13723 to i32
  %13724 = load i8, i8* %arrayidx70.7, align 1
  %conv71.26.7 = zext i8 %13724 to i32
  %xor72.26.7 = xor i32 %conv71.26.7, %conv68.26.7
  %conv73.26.7 = trunc i32 %xor72.26.7 to i8
  store i8 %conv73.26.7, i8* %arrayidx70.7, align 1
  %scevgep20.27.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 27
  %13725 = load i8, i8* %scevgep20.27.7, align 1
  %conv68.27.7 = zext i8 %13725 to i32
  %13726 = load i8, i8* %arrayidx70.7, align 1
  %conv71.27.7 = zext i8 %13726 to i32
  %xor72.27.7 = xor i32 %conv71.27.7, %conv68.27.7
  %conv73.27.7 = trunc i32 %xor72.27.7 to i8
  store i8 %conv73.27.7, i8* %arrayidx70.7, align 1
  %scevgep20.28.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 28
  %13727 = load i8, i8* %scevgep20.28.7, align 1
  %conv68.28.7 = zext i8 %13727 to i32
  %13728 = load i8, i8* %arrayidx70.7, align 1
  %conv71.28.7 = zext i8 %13728 to i32
  %xor72.28.7 = xor i32 %conv71.28.7, %conv68.28.7
  %conv73.28.7 = trunc i32 %xor72.28.7 to i8
  store i8 %conv73.28.7, i8* %arrayidx70.7, align 1
  %scevgep20.29.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 29
  %13729 = load i8, i8* %scevgep20.29.7, align 1
  %conv68.29.7 = zext i8 %13729 to i32
  %13730 = load i8, i8* %arrayidx70.7, align 1
  %conv71.29.7 = zext i8 %13730 to i32
  %xor72.29.7 = xor i32 %conv71.29.7, %conv68.29.7
  %conv73.29.7 = trunc i32 %xor72.29.7 to i8
  store i8 %conv73.29.7, i8* %arrayidx70.7, align 1
  %scevgep20.30.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 30
  %13731 = load i8, i8* %scevgep20.30.7, align 1
  %conv68.30.7 = zext i8 %13731 to i32
  %13732 = load i8, i8* %arrayidx70.7, align 1
  %conv71.30.7 = zext i8 %13732 to i32
  %xor72.30.7 = xor i32 %conv71.30.7, %conv68.30.7
  %conv73.30.7 = trunc i32 %xor72.30.7 to i8
  store i8 %conv73.30.7, i8* %arrayidx70.7, align 1
  %scevgep20.31.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 31
  %13733 = load i8, i8* %scevgep20.31.7, align 1
  %conv68.31.7 = zext i8 %13733 to i32
  %13734 = load i8, i8* %arrayidx70.7, align 1
  %conv71.31.7 = zext i8 %13734 to i32
  %xor72.31.7 = xor i32 %conv71.31.7, %conv68.31.7
  %conv73.31.7 = trunc i32 %xor72.31.7 to i8
  store i8 %conv73.31.7, i8* %arrayidx70.7, align 1
  %scevgep20.32.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 32
  %13735 = load i8, i8* %scevgep20.32.7, align 1
  %conv68.32.7 = zext i8 %13735 to i32
  %13736 = load i8, i8* %arrayidx70.7, align 1
  %conv71.32.7 = zext i8 %13736 to i32
  %xor72.32.7 = xor i32 %conv71.32.7, %conv68.32.7
  %conv73.32.7 = trunc i32 %xor72.32.7 to i8
  store i8 %conv73.32.7, i8* %arrayidx70.7, align 1
  %scevgep20.33.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 33
  %13737 = load i8, i8* %scevgep20.33.7, align 1
  %conv68.33.7 = zext i8 %13737 to i32
  %13738 = load i8, i8* %arrayidx70.7, align 1
  %conv71.33.7 = zext i8 %13738 to i32
  %xor72.33.7 = xor i32 %conv71.33.7, %conv68.33.7
  %conv73.33.7 = trunc i32 %xor72.33.7 to i8
  store i8 %conv73.33.7, i8* %arrayidx70.7, align 1
  %scevgep20.34.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 34
  %13739 = load i8, i8* %scevgep20.34.7, align 1
  %conv68.34.7 = zext i8 %13739 to i32
  %13740 = load i8, i8* %arrayidx70.7, align 1
  %conv71.34.7 = zext i8 %13740 to i32
  %xor72.34.7 = xor i32 %conv71.34.7, %conv68.34.7
  %conv73.34.7 = trunc i32 %xor72.34.7 to i8
  store i8 %conv73.34.7, i8* %arrayidx70.7, align 1
  %scevgep20.35.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 35
  %13741 = load i8, i8* %scevgep20.35.7, align 1
  %conv68.35.7 = zext i8 %13741 to i32
  %13742 = load i8, i8* %arrayidx70.7, align 1
  %conv71.35.7 = zext i8 %13742 to i32
  %xor72.35.7 = xor i32 %conv71.35.7, %conv68.35.7
  %conv73.35.7 = trunc i32 %xor72.35.7 to i8
  store i8 %conv73.35.7, i8* %arrayidx70.7, align 1
  %scevgep20.36.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 36
  %13743 = load i8, i8* %scevgep20.36.7, align 1
  %conv68.36.7 = zext i8 %13743 to i32
  %13744 = load i8, i8* %arrayidx70.7, align 1
  %conv71.36.7 = zext i8 %13744 to i32
  %xor72.36.7 = xor i32 %conv71.36.7, %conv68.36.7
  %conv73.36.7 = trunc i32 %xor72.36.7 to i8
  store i8 %conv73.36.7, i8* %arrayidx70.7, align 1
  %scevgep20.37.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 37
  %13745 = load i8, i8* %scevgep20.37.7, align 1
  %conv68.37.7 = zext i8 %13745 to i32
  %13746 = load i8, i8* %arrayidx70.7, align 1
  %conv71.37.7 = zext i8 %13746 to i32
  %xor72.37.7 = xor i32 %conv71.37.7, %conv68.37.7
  %conv73.37.7 = trunc i32 %xor72.37.7 to i8
  store i8 %conv73.37.7, i8* %arrayidx70.7, align 1
  %scevgep20.38.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 38
  %13747 = load i8, i8* %scevgep20.38.7, align 1
  %conv68.38.7 = zext i8 %13747 to i32
  %13748 = load i8, i8* %arrayidx70.7, align 1
  %conv71.38.7 = zext i8 %13748 to i32
  %xor72.38.7 = xor i32 %conv71.38.7, %conv68.38.7
  %conv73.38.7 = trunc i32 %xor72.38.7 to i8
  store i8 %conv73.38.7, i8* %arrayidx70.7, align 1
  %scevgep20.39.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 39
  %13749 = load i8, i8* %scevgep20.39.7, align 1
  %conv68.39.7 = zext i8 %13749 to i32
  %13750 = load i8, i8* %arrayidx70.7, align 1
  %conv71.39.7 = zext i8 %13750 to i32
  %xor72.39.7 = xor i32 %conv71.39.7, %conv68.39.7
  %conv73.39.7 = trunc i32 %xor72.39.7 to i8
  store i8 %conv73.39.7, i8* %arrayidx70.7, align 1
  %scevgep20.40.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 40
  %13751 = load i8, i8* %scevgep20.40.7, align 1
  %conv68.40.7 = zext i8 %13751 to i32
  %13752 = load i8, i8* %arrayidx70.7, align 1
  %conv71.40.7 = zext i8 %13752 to i32
  %xor72.40.7 = xor i32 %conv71.40.7, %conv68.40.7
  %conv73.40.7 = trunc i32 %xor72.40.7 to i8
  store i8 %conv73.40.7, i8* %arrayidx70.7, align 1
  %scevgep20.41.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 41
  %13753 = load i8, i8* %scevgep20.41.7, align 1
  %conv68.41.7 = zext i8 %13753 to i32
  %13754 = load i8, i8* %arrayidx70.7, align 1
  %conv71.41.7 = zext i8 %13754 to i32
  %xor72.41.7 = xor i32 %conv71.41.7, %conv68.41.7
  %conv73.41.7 = trunc i32 %xor72.41.7 to i8
  store i8 %conv73.41.7, i8* %arrayidx70.7, align 1
  %scevgep20.42.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 42
  %13755 = load i8, i8* %scevgep20.42.7, align 1
  %conv68.42.7 = zext i8 %13755 to i32
  %13756 = load i8, i8* %arrayidx70.7, align 1
  %conv71.42.7 = zext i8 %13756 to i32
  %xor72.42.7 = xor i32 %conv71.42.7, %conv68.42.7
  %conv73.42.7 = trunc i32 %xor72.42.7 to i8
  store i8 %conv73.42.7, i8* %arrayidx70.7, align 1
  %scevgep20.43.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 43
  %13757 = load i8, i8* %scevgep20.43.7, align 1
  %conv68.43.7 = zext i8 %13757 to i32
  %13758 = load i8, i8* %arrayidx70.7, align 1
  %conv71.43.7 = zext i8 %13758 to i32
  %xor72.43.7 = xor i32 %conv71.43.7, %conv68.43.7
  %conv73.43.7 = trunc i32 %xor72.43.7 to i8
  store i8 %conv73.43.7, i8* %arrayidx70.7, align 1
  %scevgep20.44.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 44
  %13759 = load i8, i8* %scevgep20.44.7, align 1
  %conv68.44.7 = zext i8 %13759 to i32
  %13760 = load i8, i8* %arrayidx70.7, align 1
  %conv71.44.7 = zext i8 %13760 to i32
  %xor72.44.7 = xor i32 %conv71.44.7, %conv68.44.7
  %conv73.44.7 = trunc i32 %xor72.44.7 to i8
  store i8 %conv73.44.7, i8* %arrayidx70.7, align 1
  %scevgep20.45.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 45
  %13761 = load i8, i8* %scevgep20.45.7, align 1
  %conv68.45.7 = zext i8 %13761 to i32
  %13762 = load i8, i8* %arrayidx70.7, align 1
  %conv71.45.7 = zext i8 %13762 to i32
  %xor72.45.7 = xor i32 %conv71.45.7, %conv68.45.7
  %conv73.45.7 = trunc i32 %xor72.45.7 to i8
  store i8 %conv73.45.7, i8* %arrayidx70.7, align 1
  %scevgep20.46.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 46
  %13763 = load i8, i8* %scevgep20.46.7, align 1
  %conv68.46.7 = zext i8 %13763 to i32
  %13764 = load i8, i8* %arrayidx70.7, align 1
  %conv71.46.7 = zext i8 %13764 to i32
  %xor72.46.7 = xor i32 %conv71.46.7, %conv68.46.7
  %conv73.46.7 = trunc i32 %xor72.46.7 to i8
  store i8 %conv73.46.7, i8* %arrayidx70.7, align 1
  %scevgep20.47.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 47
  %13765 = load i8, i8* %scevgep20.47.7, align 1
  %conv68.47.7 = zext i8 %13765 to i32
  %13766 = load i8, i8* %arrayidx70.7, align 1
  %conv71.47.7 = zext i8 %13766 to i32
  %xor72.47.7 = xor i32 %conv71.47.7, %conv68.47.7
  %conv73.47.7 = trunc i32 %xor72.47.7 to i8
  store i8 %conv73.47.7, i8* %arrayidx70.7, align 1
  %scevgep20.48.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 48
  %13767 = load i8, i8* %scevgep20.48.7, align 1
  %conv68.48.7 = zext i8 %13767 to i32
  %13768 = load i8, i8* %arrayidx70.7, align 1
  %conv71.48.7 = zext i8 %13768 to i32
  %xor72.48.7 = xor i32 %conv71.48.7, %conv68.48.7
  %conv73.48.7 = trunc i32 %xor72.48.7 to i8
  store i8 %conv73.48.7, i8* %arrayidx70.7, align 1
  %scevgep20.49.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 49
  %13769 = load i8, i8* %scevgep20.49.7, align 1
  %conv68.49.7 = zext i8 %13769 to i32
  %13770 = load i8, i8* %arrayidx70.7, align 1
  %conv71.49.7 = zext i8 %13770 to i32
  %xor72.49.7 = xor i32 %conv71.49.7, %conv68.49.7
  %conv73.49.7 = trunc i32 %xor72.49.7 to i8
  store i8 %conv73.49.7, i8* %arrayidx70.7, align 1
  %scevgep20.50.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 50
  %13771 = load i8, i8* %scevgep20.50.7, align 1
  %conv68.50.7 = zext i8 %13771 to i32
  %13772 = load i8, i8* %arrayidx70.7, align 1
  %conv71.50.7 = zext i8 %13772 to i32
  %xor72.50.7 = xor i32 %conv71.50.7, %conv68.50.7
  %conv73.50.7 = trunc i32 %xor72.50.7 to i8
  store i8 %conv73.50.7, i8* %arrayidx70.7, align 1
  %scevgep20.51.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 51
  %13773 = load i8, i8* %scevgep20.51.7, align 1
  %conv68.51.7 = zext i8 %13773 to i32
  %13774 = load i8, i8* %arrayidx70.7, align 1
  %conv71.51.7 = zext i8 %13774 to i32
  %xor72.51.7 = xor i32 %conv71.51.7, %conv68.51.7
  %conv73.51.7 = trunc i32 %xor72.51.7 to i8
  store i8 %conv73.51.7, i8* %arrayidx70.7, align 1
  %scevgep20.52.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 52
  %13775 = load i8, i8* %scevgep20.52.7, align 1
  %conv68.52.7 = zext i8 %13775 to i32
  %13776 = load i8, i8* %arrayidx70.7, align 1
  %conv71.52.7 = zext i8 %13776 to i32
  %xor72.52.7 = xor i32 %conv71.52.7, %conv68.52.7
  %conv73.52.7 = trunc i32 %xor72.52.7 to i8
  store i8 %conv73.52.7, i8* %arrayidx70.7, align 1
  %scevgep20.53.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 53
  %13777 = load i8, i8* %scevgep20.53.7, align 1
  %conv68.53.7 = zext i8 %13777 to i32
  %13778 = load i8, i8* %arrayidx70.7, align 1
  %conv71.53.7 = zext i8 %13778 to i32
  %xor72.53.7 = xor i32 %conv71.53.7, %conv68.53.7
  %conv73.53.7 = trunc i32 %xor72.53.7 to i8
  store i8 %conv73.53.7, i8* %arrayidx70.7, align 1
  %scevgep20.54.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 54
  %13779 = load i8, i8* %scevgep20.54.7, align 1
  %conv68.54.7 = zext i8 %13779 to i32
  %13780 = load i8, i8* %arrayidx70.7, align 1
  %conv71.54.7 = zext i8 %13780 to i32
  %xor72.54.7 = xor i32 %conv71.54.7, %conv68.54.7
  %conv73.54.7 = trunc i32 %xor72.54.7 to i8
  store i8 %conv73.54.7, i8* %arrayidx70.7, align 1
  %scevgep20.55.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 55
  %13781 = load i8, i8* %scevgep20.55.7, align 1
  %conv68.55.7 = zext i8 %13781 to i32
  %13782 = load i8, i8* %arrayidx70.7, align 1
  %conv71.55.7 = zext i8 %13782 to i32
  %xor72.55.7 = xor i32 %conv71.55.7, %conv68.55.7
  %conv73.55.7 = trunc i32 %xor72.55.7 to i8
  store i8 %conv73.55.7, i8* %arrayidx70.7, align 1
  %scevgep20.56.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 56
  %13783 = load i8, i8* %scevgep20.56.7, align 1
  %conv68.56.7 = zext i8 %13783 to i32
  %13784 = load i8, i8* %arrayidx70.7, align 1
  %conv71.56.7 = zext i8 %13784 to i32
  %xor72.56.7 = xor i32 %conv71.56.7, %conv68.56.7
  %conv73.56.7 = trunc i32 %xor72.56.7 to i8
  store i8 %conv73.56.7, i8* %arrayidx70.7, align 1
  %scevgep20.57.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 57
  %13785 = load i8, i8* %scevgep20.57.7, align 1
  %conv68.57.7 = zext i8 %13785 to i32
  %13786 = load i8, i8* %arrayidx70.7, align 1
  %conv71.57.7 = zext i8 %13786 to i32
  %xor72.57.7 = xor i32 %conv71.57.7, %conv68.57.7
  %conv73.57.7 = trunc i32 %xor72.57.7 to i8
  store i8 %conv73.57.7, i8* %arrayidx70.7, align 1
  %scevgep20.58.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 58
  %13787 = load i8, i8* %scevgep20.58.7, align 1
  %conv68.58.7 = zext i8 %13787 to i32
  %13788 = load i8, i8* %arrayidx70.7, align 1
  %conv71.58.7 = zext i8 %13788 to i32
  %xor72.58.7 = xor i32 %conv71.58.7, %conv68.58.7
  %conv73.58.7 = trunc i32 %xor72.58.7 to i8
  store i8 %conv73.58.7, i8* %arrayidx70.7, align 1
  %scevgep20.59.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 59
  %13789 = load i8, i8* %scevgep20.59.7, align 1
  %conv68.59.7 = zext i8 %13789 to i32
  %13790 = load i8, i8* %arrayidx70.7, align 1
  %conv71.59.7 = zext i8 %13790 to i32
  %xor72.59.7 = xor i32 %conv71.59.7, %conv68.59.7
  %conv73.59.7 = trunc i32 %xor72.59.7 to i8
  store i8 %conv73.59.7, i8* %arrayidx70.7, align 1
  %scevgep20.60.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 0, i64 60
  %13791 = load i8, i8* %scevgep20.60.7, align 1
  %conv68.60.7 = zext i8 %13791 to i32
  %13792 = load i8, i8* %arrayidx70.7, align 1
  %conv71.60.7 = zext i8 %13792 to i32
  %xor72.60.7 = xor i32 %conv71.60.7, %conv68.60.7
  %conv73.60.7 = trunc i32 %xor72.60.7 to i8
  store i8 %conv73.60.7, i8* %arrayidx70.7, align 1
  %scevgep19.7 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13670, i64 0, i64 1, i64 0
  %13793 = bitcast i8* %scevgep19.7 to [61 x [61 x i8]]*
  %arrayidx51.8 = getelementptr inbounds i8, i8* %a, i64 8
  %13794 = load i8, i8* %arrayidx51.8, align 1
  %arrayidx53.8 = getelementptr inbounds i8, i8* %b, i64 8
  %13795 = load i8, i8* %arrayidx53.8, align 1
  %call54.8 = call zeroext i8 @mult(i8 zeroext %13794, i8 zeroext %13795)
  %arrayidx56.8 = getelementptr inbounds i8, i8* %c, i64 8
  store i8 %call54.8, i8* %arrayidx56.8, align 1
  %arrayidx70.8 = getelementptr inbounds i8, i8* %c, i64 8
  %scevgep20.8124 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 0
  %13796 = load i8, i8* %scevgep20.8124, align 1
  %conv68.8125 = zext i8 %13796 to i32
  %13797 = load i8, i8* %arrayidx70.8, align 1
  %conv71.8126 = zext i8 %13797 to i32
  %xor72.8127 = xor i32 %conv71.8126, %conv68.8125
  %conv73.8128 = trunc i32 %xor72.8127 to i8
  store i8 %conv73.8128, i8* %arrayidx70.8, align 1
  %scevgep20.1.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 1
  %13798 = load i8, i8* %scevgep20.1.8, align 1
  %conv68.1.8 = zext i8 %13798 to i32
  %13799 = load i8, i8* %arrayidx70.8, align 1
  %conv71.1.8 = zext i8 %13799 to i32
  %xor72.1.8 = xor i32 %conv71.1.8, %conv68.1.8
  %conv73.1.8 = trunc i32 %xor72.1.8 to i8
  store i8 %conv73.1.8, i8* %arrayidx70.8, align 1
  %scevgep20.2.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 2
  %13800 = load i8, i8* %scevgep20.2.8, align 1
  %conv68.2.8 = zext i8 %13800 to i32
  %13801 = load i8, i8* %arrayidx70.8, align 1
  %conv71.2.8 = zext i8 %13801 to i32
  %xor72.2.8 = xor i32 %conv71.2.8, %conv68.2.8
  %conv73.2.8 = trunc i32 %xor72.2.8 to i8
  store i8 %conv73.2.8, i8* %arrayidx70.8, align 1
  %scevgep20.3.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 3
  %13802 = load i8, i8* %scevgep20.3.8, align 1
  %conv68.3.8 = zext i8 %13802 to i32
  %13803 = load i8, i8* %arrayidx70.8, align 1
  %conv71.3.8 = zext i8 %13803 to i32
  %xor72.3.8 = xor i32 %conv71.3.8, %conv68.3.8
  %conv73.3.8 = trunc i32 %xor72.3.8 to i8
  store i8 %conv73.3.8, i8* %arrayidx70.8, align 1
  %scevgep20.4.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 4
  %13804 = load i8, i8* %scevgep20.4.8, align 1
  %conv68.4.8 = zext i8 %13804 to i32
  %13805 = load i8, i8* %arrayidx70.8, align 1
  %conv71.4.8 = zext i8 %13805 to i32
  %xor72.4.8 = xor i32 %conv71.4.8, %conv68.4.8
  %conv73.4.8 = trunc i32 %xor72.4.8 to i8
  store i8 %conv73.4.8, i8* %arrayidx70.8, align 1
  %scevgep20.5.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 5
  %13806 = load i8, i8* %scevgep20.5.8, align 1
  %conv68.5.8 = zext i8 %13806 to i32
  %13807 = load i8, i8* %arrayidx70.8, align 1
  %conv71.5.8 = zext i8 %13807 to i32
  %xor72.5.8 = xor i32 %conv71.5.8, %conv68.5.8
  %conv73.5.8 = trunc i32 %xor72.5.8 to i8
  store i8 %conv73.5.8, i8* %arrayidx70.8, align 1
  %scevgep20.6.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 6
  %13808 = load i8, i8* %scevgep20.6.8, align 1
  %conv68.6.8 = zext i8 %13808 to i32
  %13809 = load i8, i8* %arrayidx70.8, align 1
  %conv71.6.8 = zext i8 %13809 to i32
  %xor72.6.8 = xor i32 %conv71.6.8, %conv68.6.8
  %conv73.6.8 = trunc i32 %xor72.6.8 to i8
  store i8 %conv73.6.8, i8* %arrayidx70.8, align 1
  %scevgep20.7.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 7
  %13810 = load i8, i8* %scevgep20.7.8, align 1
  %conv68.7.8 = zext i8 %13810 to i32
  %13811 = load i8, i8* %arrayidx70.8, align 1
  %conv71.7.8 = zext i8 %13811 to i32
  %xor72.7.8 = xor i32 %conv71.7.8, %conv68.7.8
  %conv73.7.8 = trunc i32 %xor72.7.8 to i8
  store i8 %conv73.7.8, i8* %arrayidx70.8, align 1
  %scevgep20.9.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 9
  %13812 = load i8, i8* %scevgep20.9.8, align 1
  %conv68.9.8 = zext i8 %13812 to i32
  %13813 = load i8, i8* %arrayidx70.8, align 1
  %conv71.9.8 = zext i8 %13813 to i32
  %xor72.9.8 = xor i32 %conv71.9.8, %conv68.9.8
  %conv73.9.8 = trunc i32 %xor72.9.8 to i8
  store i8 %conv73.9.8, i8* %arrayidx70.8, align 1
  %scevgep20.10.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 10
  %13814 = load i8, i8* %scevgep20.10.8, align 1
  %conv68.10.8 = zext i8 %13814 to i32
  %13815 = load i8, i8* %arrayidx70.8, align 1
  %conv71.10.8 = zext i8 %13815 to i32
  %xor72.10.8 = xor i32 %conv71.10.8, %conv68.10.8
  %conv73.10.8 = trunc i32 %xor72.10.8 to i8
  store i8 %conv73.10.8, i8* %arrayidx70.8, align 1
  %scevgep20.11.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 11
  %13816 = load i8, i8* %scevgep20.11.8, align 1
  %conv68.11.8 = zext i8 %13816 to i32
  %13817 = load i8, i8* %arrayidx70.8, align 1
  %conv71.11.8 = zext i8 %13817 to i32
  %xor72.11.8 = xor i32 %conv71.11.8, %conv68.11.8
  %conv73.11.8 = trunc i32 %xor72.11.8 to i8
  store i8 %conv73.11.8, i8* %arrayidx70.8, align 1
  %scevgep20.12.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 12
  %13818 = load i8, i8* %scevgep20.12.8, align 1
  %conv68.12.8 = zext i8 %13818 to i32
  %13819 = load i8, i8* %arrayidx70.8, align 1
  %conv71.12.8 = zext i8 %13819 to i32
  %xor72.12.8 = xor i32 %conv71.12.8, %conv68.12.8
  %conv73.12.8 = trunc i32 %xor72.12.8 to i8
  store i8 %conv73.12.8, i8* %arrayidx70.8, align 1
  %scevgep20.13.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 13
  %13820 = load i8, i8* %scevgep20.13.8, align 1
  %conv68.13.8 = zext i8 %13820 to i32
  %13821 = load i8, i8* %arrayidx70.8, align 1
  %conv71.13.8 = zext i8 %13821 to i32
  %xor72.13.8 = xor i32 %conv71.13.8, %conv68.13.8
  %conv73.13.8 = trunc i32 %xor72.13.8 to i8
  store i8 %conv73.13.8, i8* %arrayidx70.8, align 1
  %scevgep20.14.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 14
  %13822 = load i8, i8* %scevgep20.14.8, align 1
  %conv68.14.8 = zext i8 %13822 to i32
  %13823 = load i8, i8* %arrayidx70.8, align 1
  %conv71.14.8 = zext i8 %13823 to i32
  %xor72.14.8 = xor i32 %conv71.14.8, %conv68.14.8
  %conv73.14.8 = trunc i32 %xor72.14.8 to i8
  store i8 %conv73.14.8, i8* %arrayidx70.8, align 1
  %scevgep20.15.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 15
  %13824 = load i8, i8* %scevgep20.15.8, align 1
  %conv68.15.8 = zext i8 %13824 to i32
  %13825 = load i8, i8* %arrayidx70.8, align 1
  %conv71.15.8 = zext i8 %13825 to i32
  %xor72.15.8 = xor i32 %conv71.15.8, %conv68.15.8
  %conv73.15.8 = trunc i32 %xor72.15.8 to i8
  store i8 %conv73.15.8, i8* %arrayidx70.8, align 1
  %scevgep20.16.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 16
  %13826 = load i8, i8* %scevgep20.16.8, align 1
  %conv68.16.8 = zext i8 %13826 to i32
  %13827 = load i8, i8* %arrayidx70.8, align 1
  %conv71.16.8 = zext i8 %13827 to i32
  %xor72.16.8 = xor i32 %conv71.16.8, %conv68.16.8
  %conv73.16.8 = trunc i32 %xor72.16.8 to i8
  store i8 %conv73.16.8, i8* %arrayidx70.8, align 1
  %scevgep20.17.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 17
  %13828 = load i8, i8* %scevgep20.17.8, align 1
  %conv68.17.8 = zext i8 %13828 to i32
  %13829 = load i8, i8* %arrayidx70.8, align 1
  %conv71.17.8 = zext i8 %13829 to i32
  %xor72.17.8 = xor i32 %conv71.17.8, %conv68.17.8
  %conv73.17.8 = trunc i32 %xor72.17.8 to i8
  store i8 %conv73.17.8, i8* %arrayidx70.8, align 1
  %scevgep20.18.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 18
  %13830 = load i8, i8* %scevgep20.18.8, align 1
  %conv68.18.8 = zext i8 %13830 to i32
  %13831 = load i8, i8* %arrayidx70.8, align 1
  %conv71.18.8 = zext i8 %13831 to i32
  %xor72.18.8 = xor i32 %conv71.18.8, %conv68.18.8
  %conv73.18.8 = trunc i32 %xor72.18.8 to i8
  store i8 %conv73.18.8, i8* %arrayidx70.8, align 1
  %scevgep20.19.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 19
  %13832 = load i8, i8* %scevgep20.19.8, align 1
  %conv68.19.8 = zext i8 %13832 to i32
  %13833 = load i8, i8* %arrayidx70.8, align 1
  %conv71.19.8 = zext i8 %13833 to i32
  %xor72.19.8 = xor i32 %conv71.19.8, %conv68.19.8
  %conv73.19.8 = trunc i32 %xor72.19.8 to i8
  store i8 %conv73.19.8, i8* %arrayidx70.8, align 1
  %scevgep20.20.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 20
  %13834 = load i8, i8* %scevgep20.20.8, align 1
  %conv68.20.8 = zext i8 %13834 to i32
  %13835 = load i8, i8* %arrayidx70.8, align 1
  %conv71.20.8 = zext i8 %13835 to i32
  %xor72.20.8 = xor i32 %conv71.20.8, %conv68.20.8
  %conv73.20.8 = trunc i32 %xor72.20.8 to i8
  store i8 %conv73.20.8, i8* %arrayidx70.8, align 1
  %scevgep20.21.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 21
  %13836 = load i8, i8* %scevgep20.21.8, align 1
  %conv68.21.8 = zext i8 %13836 to i32
  %13837 = load i8, i8* %arrayidx70.8, align 1
  %conv71.21.8 = zext i8 %13837 to i32
  %xor72.21.8 = xor i32 %conv71.21.8, %conv68.21.8
  %conv73.21.8 = trunc i32 %xor72.21.8 to i8
  store i8 %conv73.21.8, i8* %arrayidx70.8, align 1
  %scevgep20.22.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 22
  %13838 = load i8, i8* %scevgep20.22.8, align 1
  %conv68.22.8 = zext i8 %13838 to i32
  %13839 = load i8, i8* %arrayidx70.8, align 1
  %conv71.22.8 = zext i8 %13839 to i32
  %xor72.22.8 = xor i32 %conv71.22.8, %conv68.22.8
  %conv73.22.8 = trunc i32 %xor72.22.8 to i8
  store i8 %conv73.22.8, i8* %arrayidx70.8, align 1
  %scevgep20.23.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 23
  %13840 = load i8, i8* %scevgep20.23.8, align 1
  %conv68.23.8 = zext i8 %13840 to i32
  %13841 = load i8, i8* %arrayidx70.8, align 1
  %conv71.23.8 = zext i8 %13841 to i32
  %xor72.23.8 = xor i32 %conv71.23.8, %conv68.23.8
  %conv73.23.8 = trunc i32 %xor72.23.8 to i8
  store i8 %conv73.23.8, i8* %arrayidx70.8, align 1
  %scevgep20.24.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 24
  %13842 = load i8, i8* %scevgep20.24.8, align 1
  %conv68.24.8 = zext i8 %13842 to i32
  %13843 = load i8, i8* %arrayidx70.8, align 1
  %conv71.24.8 = zext i8 %13843 to i32
  %xor72.24.8 = xor i32 %conv71.24.8, %conv68.24.8
  %conv73.24.8 = trunc i32 %xor72.24.8 to i8
  store i8 %conv73.24.8, i8* %arrayidx70.8, align 1
  %scevgep20.25.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 25
  %13844 = load i8, i8* %scevgep20.25.8, align 1
  %conv68.25.8 = zext i8 %13844 to i32
  %13845 = load i8, i8* %arrayidx70.8, align 1
  %conv71.25.8 = zext i8 %13845 to i32
  %xor72.25.8 = xor i32 %conv71.25.8, %conv68.25.8
  %conv73.25.8 = trunc i32 %xor72.25.8 to i8
  store i8 %conv73.25.8, i8* %arrayidx70.8, align 1
  %scevgep20.26.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 26
  %13846 = load i8, i8* %scevgep20.26.8, align 1
  %conv68.26.8 = zext i8 %13846 to i32
  %13847 = load i8, i8* %arrayidx70.8, align 1
  %conv71.26.8 = zext i8 %13847 to i32
  %xor72.26.8 = xor i32 %conv71.26.8, %conv68.26.8
  %conv73.26.8 = trunc i32 %xor72.26.8 to i8
  store i8 %conv73.26.8, i8* %arrayidx70.8, align 1
  %scevgep20.27.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 27
  %13848 = load i8, i8* %scevgep20.27.8, align 1
  %conv68.27.8 = zext i8 %13848 to i32
  %13849 = load i8, i8* %arrayidx70.8, align 1
  %conv71.27.8 = zext i8 %13849 to i32
  %xor72.27.8 = xor i32 %conv71.27.8, %conv68.27.8
  %conv73.27.8 = trunc i32 %xor72.27.8 to i8
  store i8 %conv73.27.8, i8* %arrayidx70.8, align 1
  %scevgep20.28.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 28
  %13850 = load i8, i8* %scevgep20.28.8, align 1
  %conv68.28.8 = zext i8 %13850 to i32
  %13851 = load i8, i8* %arrayidx70.8, align 1
  %conv71.28.8 = zext i8 %13851 to i32
  %xor72.28.8 = xor i32 %conv71.28.8, %conv68.28.8
  %conv73.28.8 = trunc i32 %xor72.28.8 to i8
  store i8 %conv73.28.8, i8* %arrayidx70.8, align 1
  %scevgep20.29.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 29
  %13852 = load i8, i8* %scevgep20.29.8, align 1
  %conv68.29.8 = zext i8 %13852 to i32
  %13853 = load i8, i8* %arrayidx70.8, align 1
  %conv71.29.8 = zext i8 %13853 to i32
  %xor72.29.8 = xor i32 %conv71.29.8, %conv68.29.8
  %conv73.29.8 = trunc i32 %xor72.29.8 to i8
  store i8 %conv73.29.8, i8* %arrayidx70.8, align 1
  %scevgep20.30.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 30
  %13854 = load i8, i8* %scevgep20.30.8, align 1
  %conv68.30.8 = zext i8 %13854 to i32
  %13855 = load i8, i8* %arrayidx70.8, align 1
  %conv71.30.8 = zext i8 %13855 to i32
  %xor72.30.8 = xor i32 %conv71.30.8, %conv68.30.8
  %conv73.30.8 = trunc i32 %xor72.30.8 to i8
  store i8 %conv73.30.8, i8* %arrayidx70.8, align 1
  %scevgep20.31.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 31
  %13856 = load i8, i8* %scevgep20.31.8, align 1
  %conv68.31.8 = zext i8 %13856 to i32
  %13857 = load i8, i8* %arrayidx70.8, align 1
  %conv71.31.8 = zext i8 %13857 to i32
  %xor72.31.8 = xor i32 %conv71.31.8, %conv68.31.8
  %conv73.31.8 = trunc i32 %xor72.31.8 to i8
  store i8 %conv73.31.8, i8* %arrayidx70.8, align 1
  %scevgep20.32.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 32
  %13858 = load i8, i8* %scevgep20.32.8, align 1
  %conv68.32.8 = zext i8 %13858 to i32
  %13859 = load i8, i8* %arrayidx70.8, align 1
  %conv71.32.8 = zext i8 %13859 to i32
  %xor72.32.8 = xor i32 %conv71.32.8, %conv68.32.8
  %conv73.32.8 = trunc i32 %xor72.32.8 to i8
  store i8 %conv73.32.8, i8* %arrayidx70.8, align 1
  %scevgep20.33.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 33
  %13860 = load i8, i8* %scevgep20.33.8, align 1
  %conv68.33.8 = zext i8 %13860 to i32
  %13861 = load i8, i8* %arrayidx70.8, align 1
  %conv71.33.8 = zext i8 %13861 to i32
  %xor72.33.8 = xor i32 %conv71.33.8, %conv68.33.8
  %conv73.33.8 = trunc i32 %xor72.33.8 to i8
  store i8 %conv73.33.8, i8* %arrayidx70.8, align 1
  %scevgep20.34.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 34
  %13862 = load i8, i8* %scevgep20.34.8, align 1
  %conv68.34.8 = zext i8 %13862 to i32
  %13863 = load i8, i8* %arrayidx70.8, align 1
  %conv71.34.8 = zext i8 %13863 to i32
  %xor72.34.8 = xor i32 %conv71.34.8, %conv68.34.8
  %conv73.34.8 = trunc i32 %xor72.34.8 to i8
  store i8 %conv73.34.8, i8* %arrayidx70.8, align 1
  %scevgep20.35.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 35
  %13864 = load i8, i8* %scevgep20.35.8, align 1
  %conv68.35.8 = zext i8 %13864 to i32
  %13865 = load i8, i8* %arrayidx70.8, align 1
  %conv71.35.8 = zext i8 %13865 to i32
  %xor72.35.8 = xor i32 %conv71.35.8, %conv68.35.8
  %conv73.35.8 = trunc i32 %xor72.35.8 to i8
  store i8 %conv73.35.8, i8* %arrayidx70.8, align 1
  %scevgep20.36.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 36
  %13866 = load i8, i8* %scevgep20.36.8, align 1
  %conv68.36.8 = zext i8 %13866 to i32
  %13867 = load i8, i8* %arrayidx70.8, align 1
  %conv71.36.8 = zext i8 %13867 to i32
  %xor72.36.8 = xor i32 %conv71.36.8, %conv68.36.8
  %conv73.36.8 = trunc i32 %xor72.36.8 to i8
  store i8 %conv73.36.8, i8* %arrayidx70.8, align 1
  %scevgep20.37.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 37
  %13868 = load i8, i8* %scevgep20.37.8, align 1
  %conv68.37.8 = zext i8 %13868 to i32
  %13869 = load i8, i8* %arrayidx70.8, align 1
  %conv71.37.8 = zext i8 %13869 to i32
  %xor72.37.8 = xor i32 %conv71.37.8, %conv68.37.8
  %conv73.37.8 = trunc i32 %xor72.37.8 to i8
  store i8 %conv73.37.8, i8* %arrayidx70.8, align 1
  %scevgep20.38.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 38
  %13870 = load i8, i8* %scevgep20.38.8, align 1
  %conv68.38.8 = zext i8 %13870 to i32
  %13871 = load i8, i8* %arrayidx70.8, align 1
  %conv71.38.8 = zext i8 %13871 to i32
  %xor72.38.8 = xor i32 %conv71.38.8, %conv68.38.8
  %conv73.38.8 = trunc i32 %xor72.38.8 to i8
  store i8 %conv73.38.8, i8* %arrayidx70.8, align 1
  %scevgep20.39.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 39
  %13872 = load i8, i8* %scevgep20.39.8, align 1
  %conv68.39.8 = zext i8 %13872 to i32
  %13873 = load i8, i8* %arrayidx70.8, align 1
  %conv71.39.8 = zext i8 %13873 to i32
  %xor72.39.8 = xor i32 %conv71.39.8, %conv68.39.8
  %conv73.39.8 = trunc i32 %xor72.39.8 to i8
  store i8 %conv73.39.8, i8* %arrayidx70.8, align 1
  %scevgep20.40.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 40
  %13874 = load i8, i8* %scevgep20.40.8, align 1
  %conv68.40.8 = zext i8 %13874 to i32
  %13875 = load i8, i8* %arrayidx70.8, align 1
  %conv71.40.8 = zext i8 %13875 to i32
  %xor72.40.8 = xor i32 %conv71.40.8, %conv68.40.8
  %conv73.40.8 = trunc i32 %xor72.40.8 to i8
  store i8 %conv73.40.8, i8* %arrayidx70.8, align 1
  %scevgep20.41.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 41
  %13876 = load i8, i8* %scevgep20.41.8, align 1
  %conv68.41.8 = zext i8 %13876 to i32
  %13877 = load i8, i8* %arrayidx70.8, align 1
  %conv71.41.8 = zext i8 %13877 to i32
  %xor72.41.8 = xor i32 %conv71.41.8, %conv68.41.8
  %conv73.41.8 = trunc i32 %xor72.41.8 to i8
  store i8 %conv73.41.8, i8* %arrayidx70.8, align 1
  %scevgep20.42.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 42
  %13878 = load i8, i8* %scevgep20.42.8, align 1
  %conv68.42.8 = zext i8 %13878 to i32
  %13879 = load i8, i8* %arrayidx70.8, align 1
  %conv71.42.8 = zext i8 %13879 to i32
  %xor72.42.8 = xor i32 %conv71.42.8, %conv68.42.8
  %conv73.42.8 = trunc i32 %xor72.42.8 to i8
  store i8 %conv73.42.8, i8* %arrayidx70.8, align 1
  %scevgep20.43.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 43
  %13880 = load i8, i8* %scevgep20.43.8, align 1
  %conv68.43.8 = zext i8 %13880 to i32
  %13881 = load i8, i8* %arrayidx70.8, align 1
  %conv71.43.8 = zext i8 %13881 to i32
  %xor72.43.8 = xor i32 %conv71.43.8, %conv68.43.8
  %conv73.43.8 = trunc i32 %xor72.43.8 to i8
  store i8 %conv73.43.8, i8* %arrayidx70.8, align 1
  %scevgep20.44.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 44
  %13882 = load i8, i8* %scevgep20.44.8, align 1
  %conv68.44.8 = zext i8 %13882 to i32
  %13883 = load i8, i8* %arrayidx70.8, align 1
  %conv71.44.8 = zext i8 %13883 to i32
  %xor72.44.8 = xor i32 %conv71.44.8, %conv68.44.8
  %conv73.44.8 = trunc i32 %xor72.44.8 to i8
  store i8 %conv73.44.8, i8* %arrayidx70.8, align 1
  %scevgep20.45.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 45
  %13884 = load i8, i8* %scevgep20.45.8, align 1
  %conv68.45.8 = zext i8 %13884 to i32
  %13885 = load i8, i8* %arrayidx70.8, align 1
  %conv71.45.8 = zext i8 %13885 to i32
  %xor72.45.8 = xor i32 %conv71.45.8, %conv68.45.8
  %conv73.45.8 = trunc i32 %xor72.45.8 to i8
  store i8 %conv73.45.8, i8* %arrayidx70.8, align 1
  %scevgep20.46.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 46
  %13886 = load i8, i8* %scevgep20.46.8, align 1
  %conv68.46.8 = zext i8 %13886 to i32
  %13887 = load i8, i8* %arrayidx70.8, align 1
  %conv71.46.8 = zext i8 %13887 to i32
  %xor72.46.8 = xor i32 %conv71.46.8, %conv68.46.8
  %conv73.46.8 = trunc i32 %xor72.46.8 to i8
  store i8 %conv73.46.8, i8* %arrayidx70.8, align 1
  %scevgep20.47.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 47
  %13888 = load i8, i8* %scevgep20.47.8, align 1
  %conv68.47.8 = zext i8 %13888 to i32
  %13889 = load i8, i8* %arrayidx70.8, align 1
  %conv71.47.8 = zext i8 %13889 to i32
  %xor72.47.8 = xor i32 %conv71.47.8, %conv68.47.8
  %conv73.47.8 = trunc i32 %xor72.47.8 to i8
  store i8 %conv73.47.8, i8* %arrayidx70.8, align 1
  %scevgep20.48.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 48
  %13890 = load i8, i8* %scevgep20.48.8, align 1
  %conv68.48.8 = zext i8 %13890 to i32
  %13891 = load i8, i8* %arrayidx70.8, align 1
  %conv71.48.8 = zext i8 %13891 to i32
  %xor72.48.8 = xor i32 %conv71.48.8, %conv68.48.8
  %conv73.48.8 = trunc i32 %xor72.48.8 to i8
  store i8 %conv73.48.8, i8* %arrayidx70.8, align 1
  %scevgep20.49.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 49
  %13892 = load i8, i8* %scevgep20.49.8, align 1
  %conv68.49.8 = zext i8 %13892 to i32
  %13893 = load i8, i8* %arrayidx70.8, align 1
  %conv71.49.8 = zext i8 %13893 to i32
  %xor72.49.8 = xor i32 %conv71.49.8, %conv68.49.8
  %conv73.49.8 = trunc i32 %xor72.49.8 to i8
  store i8 %conv73.49.8, i8* %arrayidx70.8, align 1
  %scevgep20.50.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 50
  %13894 = load i8, i8* %scevgep20.50.8, align 1
  %conv68.50.8 = zext i8 %13894 to i32
  %13895 = load i8, i8* %arrayidx70.8, align 1
  %conv71.50.8 = zext i8 %13895 to i32
  %xor72.50.8 = xor i32 %conv71.50.8, %conv68.50.8
  %conv73.50.8 = trunc i32 %xor72.50.8 to i8
  store i8 %conv73.50.8, i8* %arrayidx70.8, align 1
  %scevgep20.51.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 51
  %13896 = load i8, i8* %scevgep20.51.8, align 1
  %conv68.51.8 = zext i8 %13896 to i32
  %13897 = load i8, i8* %arrayidx70.8, align 1
  %conv71.51.8 = zext i8 %13897 to i32
  %xor72.51.8 = xor i32 %conv71.51.8, %conv68.51.8
  %conv73.51.8 = trunc i32 %xor72.51.8 to i8
  store i8 %conv73.51.8, i8* %arrayidx70.8, align 1
  %scevgep20.52.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 52
  %13898 = load i8, i8* %scevgep20.52.8, align 1
  %conv68.52.8 = zext i8 %13898 to i32
  %13899 = load i8, i8* %arrayidx70.8, align 1
  %conv71.52.8 = zext i8 %13899 to i32
  %xor72.52.8 = xor i32 %conv71.52.8, %conv68.52.8
  %conv73.52.8 = trunc i32 %xor72.52.8 to i8
  store i8 %conv73.52.8, i8* %arrayidx70.8, align 1
  %scevgep20.53.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 53
  %13900 = load i8, i8* %scevgep20.53.8, align 1
  %conv68.53.8 = zext i8 %13900 to i32
  %13901 = load i8, i8* %arrayidx70.8, align 1
  %conv71.53.8 = zext i8 %13901 to i32
  %xor72.53.8 = xor i32 %conv71.53.8, %conv68.53.8
  %conv73.53.8 = trunc i32 %xor72.53.8 to i8
  store i8 %conv73.53.8, i8* %arrayidx70.8, align 1
  %scevgep20.54.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 54
  %13902 = load i8, i8* %scevgep20.54.8, align 1
  %conv68.54.8 = zext i8 %13902 to i32
  %13903 = load i8, i8* %arrayidx70.8, align 1
  %conv71.54.8 = zext i8 %13903 to i32
  %xor72.54.8 = xor i32 %conv71.54.8, %conv68.54.8
  %conv73.54.8 = trunc i32 %xor72.54.8 to i8
  store i8 %conv73.54.8, i8* %arrayidx70.8, align 1
  %scevgep20.55.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 55
  %13904 = load i8, i8* %scevgep20.55.8, align 1
  %conv68.55.8 = zext i8 %13904 to i32
  %13905 = load i8, i8* %arrayidx70.8, align 1
  %conv71.55.8 = zext i8 %13905 to i32
  %xor72.55.8 = xor i32 %conv71.55.8, %conv68.55.8
  %conv73.55.8 = trunc i32 %xor72.55.8 to i8
  store i8 %conv73.55.8, i8* %arrayidx70.8, align 1
  %scevgep20.56.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 56
  %13906 = load i8, i8* %scevgep20.56.8, align 1
  %conv68.56.8 = zext i8 %13906 to i32
  %13907 = load i8, i8* %arrayidx70.8, align 1
  %conv71.56.8 = zext i8 %13907 to i32
  %xor72.56.8 = xor i32 %conv71.56.8, %conv68.56.8
  %conv73.56.8 = trunc i32 %xor72.56.8 to i8
  store i8 %conv73.56.8, i8* %arrayidx70.8, align 1
  %scevgep20.57.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 57
  %13908 = load i8, i8* %scevgep20.57.8, align 1
  %conv68.57.8 = zext i8 %13908 to i32
  %13909 = load i8, i8* %arrayidx70.8, align 1
  %conv71.57.8 = zext i8 %13909 to i32
  %xor72.57.8 = xor i32 %conv71.57.8, %conv68.57.8
  %conv73.57.8 = trunc i32 %xor72.57.8 to i8
  store i8 %conv73.57.8, i8* %arrayidx70.8, align 1
  %scevgep20.58.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 58
  %13910 = load i8, i8* %scevgep20.58.8, align 1
  %conv68.58.8 = zext i8 %13910 to i32
  %13911 = load i8, i8* %arrayidx70.8, align 1
  %conv71.58.8 = zext i8 %13911 to i32
  %xor72.58.8 = xor i32 %conv71.58.8, %conv68.58.8
  %conv73.58.8 = trunc i32 %xor72.58.8 to i8
  store i8 %conv73.58.8, i8* %arrayidx70.8, align 1
  %scevgep20.59.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 59
  %13912 = load i8, i8* %scevgep20.59.8, align 1
  %conv68.59.8 = zext i8 %13912 to i32
  %13913 = load i8, i8* %arrayidx70.8, align 1
  %conv71.59.8 = zext i8 %13913 to i32
  %xor72.59.8 = xor i32 %conv71.59.8, %conv68.59.8
  %conv73.59.8 = trunc i32 %xor72.59.8 to i8
  store i8 %conv73.59.8, i8* %arrayidx70.8, align 1
  %scevgep20.60.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 0, i64 60
  %13914 = load i8, i8* %scevgep20.60.8, align 1
  %conv68.60.8 = zext i8 %13914 to i32
  %13915 = load i8, i8* %arrayidx70.8, align 1
  %conv71.60.8 = zext i8 %13915 to i32
  %xor72.60.8 = xor i32 %conv71.60.8, %conv68.60.8
  %conv73.60.8 = trunc i32 %xor72.60.8 to i8
  store i8 %conv73.60.8, i8* %arrayidx70.8, align 1
  %scevgep19.8 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13793, i64 0, i64 1, i64 0
  %13916 = bitcast i8* %scevgep19.8 to [61 x [61 x i8]]*
  %arrayidx51.9 = getelementptr inbounds i8, i8* %a, i64 9
  %13917 = load i8, i8* %arrayidx51.9, align 1
  %arrayidx53.9 = getelementptr inbounds i8, i8* %b, i64 9
  %13918 = load i8, i8* %arrayidx53.9, align 1
  %call54.9 = call zeroext i8 @mult(i8 zeroext %13917, i8 zeroext %13918)
  %arrayidx56.9 = getelementptr inbounds i8, i8* %c, i64 9
  store i8 %call54.9, i8* %arrayidx56.9, align 1
  %arrayidx70.9 = getelementptr inbounds i8, i8* %c, i64 9
  %scevgep20.9134 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 0
  %13919 = load i8, i8* %scevgep20.9134, align 1
  %conv68.9135 = zext i8 %13919 to i32
  %13920 = load i8, i8* %arrayidx70.9, align 1
  %conv71.9136 = zext i8 %13920 to i32
  %xor72.9137 = xor i32 %conv71.9136, %conv68.9135
  %conv73.9138 = trunc i32 %xor72.9137 to i8
  store i8 %conv73.9138, i8* %arrayidx70.9, align 1
  %scevgep20.1.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 1
  %13921 = load i8, i8* %scevgep20.1.9, align 1
  %conv68.1.9 = zext i8 %13921 to i32
  %13922 = load i8, i8* %arrayidx70.9, align 1
  %conv71.1.9 = zext i8 %13922 to i32
  %xor72.1.9 = xor i32 %conv71.1.9, %conv68.1.9
  %conv73.1.9 = trunc i32 %xor72.1.9 to i8
  store i8 %conv73.1.9, i8* %arrayidx70.9, align 1
  %scevgep20.2.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 2
  %13923 = load i8, i8* %scevgep20.2.9, align 1
  %conv68.2.9 = zext i8 %13923 to i32
  %13924 = load i8, i8* %arrayidx70.9, align 1
  %conv71.2.9 = zext i8 %13924 to i32
  %xor72.2.9 = xor i32 %conv71.2.9, %conv68.2.9
  %conv73.2.9 = trunc i32 %xor72.2.9 to i8
  store i8 %conv73.2.9, i8* %arrayidx70.9, align 1
  %scevgep20.3.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 3
  %13925 = load i8, i8* %scevgep20.3.9, align 1
  %conv68.3.9 = zext i8 %13925 to i32
  %13926 = load i8, i8* %arrayidx70.9, align 1
  %conv71.3.9 = zext i8 %13926 to i32
  %xor72.3.9 = xor i32 %conv71.3.9, %conv68.3.9
  %conv73.3.9 = trunc i32 %xor72.3.9 to i8
  store i8 %conv73.3.9, i8* %arrayidx70.9, align 1
  %scevgep20.4.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 4
  %13927 = load i8, i8* %scevgep20.4.9, align 1
  %conv68.4.9 = zext i8 %13927 to i32
  %13928 = load i8, i8* %arrayidx70.9, align 1
  %conv71.4.9 = zext i8 %13928 to i32
  %xor72.4.9 = xor i32 %conv71.4.9, %conv68.4.9
  %conv73.4.9 = trunc i32 %xor72.4.9 to i8
  store i8 %conv73.4.9, i8* %arrayidx70.9, align 1
  %scevgep20.5.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 5
  %13929 = load i8, i8* %scevgep20.5.9, align 1
  %conv68.5.9 = zext i8 %13929 to i32
  %13930 = load i8, i8* %arrayidx70.9, align 1
  %conv71.5.9 = zext i8 %13930 to i32
  %xor72.5.9 = xor i32 %conv71.5.9, %conv68.5.9
  %conv73.5.9 = trunc i32 %xor72.5.9 to i8
  store i8 %conv73.5.9, i8* %arrayidx70.9, align 1
  %scevgep20.6.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 6
  %13931 = load i8, i8* %scevgep20.6.9, align 1
  %conv68.6.9 = zext i8 %13931 to i32
  %13932 = load i8, i8* %arrayidx70.9, align 1
  %conv71.6.9 = zext i8 %13932 to i32
  %xor72.6.9 = xor i32 %conv71.6.9, %conv68.6.9
  %conv73.6.9 = trunc i32 %xor72.6.9 to i8
  store i8 %conv73.6.9, i8* %arrayidx70.9, align 1
  %scevgep20.7.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 7
  %13933 = load i8, i8* %scevgep20.7.9, align 1
  %conv68.7.9 = zext i8 %13933 to i32
  %13934 = load i8, i8* %arrayidx70.9, align 1
  %conv71.7.9 = zext i8 %13934 to i32
  %xor72.7.9 = xor i32 %conv71.7.9, %conv68.7.9
  %conv73.7.9 = trunc i32 %xor72.7.9 to i8
  store i8 %conv73.7.9, i8* %arrayidx70.9, align 1
  %scevgep20.8.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 8
  %13935 = load i8, i8* %scevgep20.8.9, align 1
  %conv68.8.9 = zext i8 %13935 to i32
  %13936 = load i8, i8* %arrayidx70.9, align 1
  %conv71.8.9 = zext i8 %13936 to i32
  %xor72.8.9 = xor i32 %conv71.8.9, %conv68.8.9
  %conv73.8.9 = trunc i32 %xor72.8.9 to i8
  store i8 %conv73.8.9, i8* %arrayidx70.9, align 1
  %scevgep20.10.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 10
  %13937 = load i8, i8* %scevgep20.10.9, align 1
  %conv68.10.9 = zext i8 %13937 to i32
  %13938 = load i8, i8* %arrayidx70.9, align 1
  %conv71.10.9 = zext i8 %13938 to i32
  %xor72.10.9 = xor i32 %conv71.10.9, %conv68.10.9
  %conv73.10.9 = trunc i32 %xor72.10.9 to i8
  store i8 %conv73.10.9, i8* %arrayidx70.9, align 1
  %scevgep20.11.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 11
  %13939 = load i8, i8* %scevgep20.11.9, align 1
  %conv68.11.9 = zext i8 %13939 to i32
  %13940 = load i8, i8* %arrayidx70.9, align 1
  %conv71.11.9 = zext i8 %13940 to i32
  %xor72.11.9 = xor i32 %conv71.11.9, %conv68.11.9
  %conv73.11.9 = trunc i32 %xor72.11.9 to i8
  store i8 %conv73.11.9, i8* %arrayidx70.9, align 1
  %scevgep20.12.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 12
  %13941 = load i8, i8* %scevgep20.12.9, align 1
  %conv68.12.9 = zext i8 %13941 to i32
  %13942 = load i8, i8* %arrayidx70.9, align 1
  %conv71.12.9 = zext i8 %13942 to i32
  %xor72.12.9 = xor i32 %conv71.12.9, %conv68.12.9
  %conv73.12.9 = trunc i32 %xor72.12.9 to i8
  store i8 %conv73.12.9, i8* %arrayidx70.9, align 1
  %scevgep20.13.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 13
  %13943 = load i8, i8* %scevgep20.13.9, align 1
  %conv68.13.9 = zext i8 %13943 to i32
  %13944 = load i8, i8* %arrayidx70.9, align 1
  %conv71.13.9 = zext i8 %13944 to i32
  %xor72.13.9 = xor i32 %conv71.13.9, %conv68.13.9
  %conv73.13.9 = trunc i32 %xor72.13.9 to i8
  store i8 %conv73.13.9, i8* %arrayidx70.9, align 1
  %scevgep20.14.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 14
  %13945 = load i8, i8* %scevgep20.14.9, align 1
  %conv68.14.9 = zext i8 %13945 to i32
  %13946 = load i8, i8* %arrayidx70.9, align 1
  %conv71.14.9 = zext i8 %13946 to i32
  %xor72.14.9 = xor i32 %conv71.14.9, %conv68.14.9
  %conv73.14.9 = trunc i32 %xor72.14.9 to i8
  store i8 %conv73.14.9, i8* %arrayidx70.9, align 1
  %scevgep20.15.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 15
  %13947 = load i8, i8* %scevgep20.15.9, align 1
  %conv68.15.9 = zext i8 %13947 to i32
  %13948 = load i8, i8* %arrayidx70.9, align 1
  %conv71.15.9 = zext i8 %13948 to i32
  %xor72.15.9 = xor i32 %conv71.15.9, %conv68.15.9
  %conv73.15.9 = trunc i32 %xor72.15.9 to i8
  store i8 %conv73.15.9, i8* %arrayidx70.9, align 1
  %scevgep20.16.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 16
  %13949 = load i8, i8* %scevgep20.16.9, align 1
  %conv68.16.9 = zext i8 %13949 to i32
  %13950 = load i8, i8* %arrayidx70.9, align 1
  %conv71.16.9 = zext i8 %13950 to i32
  %xor72.16.9 = xor i32 %conv71.16.9, %conv68.16.9
  %conv73.16.9 = trunc i32 %xor72.16.9 to i8
  store i8 %conv73.16.9, i8* %arrayidx70.9, align 1
  %scevgep20.17.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 17
  %13951 = load i8, i8* %scevgep20.17.9, align 1
  %conv68.17.9 = zext i8 %13951 to i32
  %13952 = load i8, i8* %arrayidx70.9, align 1
  %conv71.17.9 = zext i8 %13952 to i32
  %xor72.17.9 = xor i32 %conv71.17.9, %conv68.17.9
  %conv73.17.9 = trunc i32 %xor72.17.9 to i8
  store i8 %conv73.17.9, i8* %arrayidx70.9, align 1
  %scevgep20.18.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 18
  %13953 = load i8, i8* %scevgep20.18.9, align 1
  %conv68.18.9 = zext i8 %13953 to i32
  %13954 = load i8, i8* %arrayidx70.9, align 1
  %conv71.18.9 = zext i8 %13954 to i32
  %xor72.18.9 = xor i32 %conv71.18.9, %conv68.18.9
  %conv73.18.9 = trunc i32 %xor72.18.9 to i8
  store i8 %conv73.18.9, i8* %arrayidx70.9, align 1
  %scevgep20.19.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 19
  %13955 = load i8, i8* %scevgep20.19.9, align 1
  %conv68.19.9 = zext i8 %13955 to i32
  %13956 = load i8, i8* %arrayidx70.9, align 1
  %conv71.19.9 = zext i8 %13956 to i32
  %xor72.19.9 = xor i32 %conv71.19.9, %conv68.19.9
  %conv73.19.9 = trunc i32 %xor72.19.9 to i8
  store i8 %conv73.19.9, i8* %arrayidx70.9, align 1
  %scevgep20.20.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 20
  %13957 = load i8, i8* %scevgep20.20.9, align 1
  %conv68.20.9 = zext i8 %13957 to i32
  %13958 = load i8, i8* %arrayidx70.9, align 1
  %conv71.20.9 = zext i8 %13958 to i32
  %xor72.20.9 = xor i32 %conv71.20.9, %conv68.20.9
  %conv73.20.9 = trunc i32 %xor72.20.9 to i8
  store i8 %conv73.20.9, i8* %arrayidx70.9, align 1
  %scevgep20.21.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 21
  %13959 = load i8, i8* %scevgep20.21.9, align 1
  %conv68.21.9 = zext i8 %13959 to i32
  %13960 = load i8, i8* %arrayidx70.9, align 1
  %conv71.21.9 = zext i8 %13960 to i32
  %xor72.21.9 = xor i32 %conv71.21.9, %conv68.21.9
  %conv73.21.9 = trunc i32 %xor72.21.9 to i8
  store i8 %conv73.21.9, i8* %arrayidx70.9, align 1
  %scevgep20.22.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 22
  %13961 = load i8, i8* %scevgep20.22.9, align 1
  %conv68.22.9 = zext i8 %13961 to i32
  %13962 = load i8, i8* %arrayidx70.9, align 1
  %conv71.22.9 = zext i8 %13962 to i32
  %xor72.22.9 = xor i32 %conv71.22.9, %conv68.22.9
  %conv73.22.9 = trunc i32 %xor72.22.9 to i8
  store i8 %conv73.22.9, i8* %arrayidx70.9, align 1
  %scevgep20.23.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 23
  %13963 = load i8, i8* %scevgep20.23.9, align 1
  %conv68.23.9 = zext i8 %13963 to i32
  %13964 = load i8, i8* %arrayidx70.9, align 1
  %conv71.23.9 = zext i8 %13964 to i32
  %xor72.23.9 = xor i32 %conv71.23.9, %conv68.23.9
  %conv73.23.9 = trunc i32 %xor72.23.9 to i8
  store i8 %conv73.23.9, i8* %arrayidx70.9, align 1
  %scevgep20.24.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 24
  %13965 = load i8, i8* %scevgep20.24.9, align 1
  %conv68.24.9 = zext i8 %13965 to i32
  %13966 = load i8, i8* %arrayidx70.9, align 1
  %conv71.24.9 = zext i8 %13966 to i32
  %xor72.24.9 = xor i32 %conv71.24.9, %conv68.24.9
  %conv73.24.9 = trunc i32 %xor72.24.9 to i8
  store i8 %conv73.24.9, i8* %arrayidx70.9, align 1
  %scevgep20.25.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 25
  %13967 = load i8, i8* %scevgep20.25.9, align 1
  %conv68.25.9 = zext i8 %13967 to i32
  %13968 = load i8, i8* %arrayidx70.9, align 1
  %conv71.25.9 = zext i8 %13968 to i32
  %xor72.25.9 = xor i32 %conv71.25.9, %conv68.25.9
  %conv73.25.9 = trunc i32 %xor72.25.9 to i8
  store i8 %conv73.25.9, i8* %arrayidx70.9, align 1
  %scevgep20.26.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 26
  %13969 = load i8, i8* %scevgep20.26.9, align 1
  %conv68.26.9 = zext i8 %13969 to i32
  %13970 = load i8, i8* %arrayidx70.9, align 1
  %conv71.26.9 = zext i8 %13970 to i32
  %xor72.26.9 = xor i32 %conv71.26.9, %conv68.26.9
  %conv73.26.9 = trunc i32 %xor72.26.9 to i8
  store i8 %conv73.26.9, i8* %arrayidx70.9, align 1
  %scevgep20.27.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 27
  %13971 = load i8, i8* %scevgep20.27.9, align 1
  %conv68.27.9 = zext i8 %13971 to i32
  %13972 = load i8, i8* %arrayidx70.9, align 1
  %conv71.27.9 = zext i8 %13972 to i32
  %xor72.27.9 = xor i32 %conv71.27.9, %conv68.27.9
  %conv73.27.9 = trunc i32 %xor72.27.9 to i8
  store i8 %conv73.27.9, i8* %arrayidx70.9, align 1
  %scevgep20.28.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 28
  %13973 = load i8, i8* %scevgep20.28.9, align 1
  %conv68.28.9 = zext i8 %13973 to i32
  %13974 = load i8, i8* %arrayidx70.9, align 1
  %conv71.28.9 = zext i8 %13974 to i32
  %xor72.28.9 = xor i32 %conv71.28.9, %conv68.28.9
  %conv73.28.9 = trunc i32 %xor72.28.9 to i8
  store i8 %conv73.28.9, i8* %arrayidx70.9, align 1
  %scevgep20.29.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 29
  %13975 = load i8, i8* %scevgep20.29.9, align 1
  %conv68.29.9 = zext i8 %13975 to i32
  %13976 = load i8, i8* %arrayidx70.9, align 1
  %conv71.29.9 = zext i8 %13976 to i32
  %xor72.29.9 = xor i32 %conv71.29.9, %conv68.29.9
  %conv73.29.9 = trunc i32 %xor72.29.9 to i8
  store i8 %conv73.29.9, i8* %arrayidx70.9, align 1
  %scevgep20.30.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 30
  %13977 = load i8, i8* %scevgep20.30.9, align 1
  %conv68.30.9 = zext i8 %13977 to i32
  %13978 = load i8, i8* %arrayidx70.9, align 1
  %conv71.30.9 = zext i8 %13978 to i32
  %xor72.30.9 = xor i32 %conv71.30.9, %conv68.30.9
  %conv73.30.9 = trunc i32 %xor72.30.9 to i8
  store i8 %conv73.30.9, i8* %arrayidx70.9, align 1
  %scevgep20.31.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 31
  %13979 = load i8, i8* %scevgep20.31.9, align 1
  %conv68.31.9 = zext i8 %13979 to i32
  %13980 = load i8, i8* %arrayidx70.9, align 1
  %conv71.31.9 = zext i8 %13980 to i32
  %xor72.31.9 = xor i32 %conv71.31.9, %conv68.31.9
  %conv73.31.9 = trunc i32 %xor72.31.9 to i8
  store i8 %conv73.31.9, i8* %arrayidx70.9, align 1
  %scevgep20.32.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 32
  %13981 = load i8, i8* %scevgep20.32.9, align 1
  %conv68.32.9 = zext i8 %13981 to i32
  %13982 = load i8, i8* %arrayidx70.9, align 1
  %conv71.32.9 = zext i8 %13982 to i32
  %xor72.32.9 = xor i32 %conv71.32.9, %conv68.32.9
  %conv73.32.9 = trunc i32 %xor72.32.9 to i8
  store i8 %conv73.32.9, i8* %arrayidx70.9, align 1
  %scevgep20.33.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 33
  %13983 = load i8, i8* %scevgep20.33.9, align 1
  %conv68.33.9 = zext i8 %13983 to i32
  %13984 = load i8, i8* %arrayidx70.9, align 1
  %conv71.33.9 = zext i8 %13984 to i32
  %xor72.33.9 = xor i32 %conv71.33.9, %conv68.33.9
  %conv73.33.9 = trunc i32 %xor72.33.9 to i8
  store i8 %conv73.33.9, i8* %arrayidx70.9, align 1
  %scevgep20.34.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 34
  %13985 = load i8, i8* %scevgep20.34.9, align 1
  %conv68.34.9 = zext i8 %13985 to i32
  %13986 = load i8, i8* %arrayidx70.9, align 1
  %conv71.34.9 = zext i8 %13986 to i32
  %xor72.34.9 = xor i32 %conv71.34.9, %conv68.34.9
  %conv73.34.9 = trunc i32 %xor72.34.9 to i8
  store i8 %conv73.34.9, i8* %arrayidx70.9, align 1
  %scevgep20.35.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 35
  %13987 = load i8, i8* %scevgep20.35.9, align 1
  %conv68.35.9 = zext i8 %13987 to i32
  %13988 = load i8, i8* %arrayidx70.9, align 1
  %conv71.35.9 = zext i8 %13988 to i32
  %xor72.35.9 = xor i32 %conv71.35.9, %conv68.35.9
  %conv73.35.9 = trunc i32 %xor72.35.9 to i8
  store i8 %conv73.35.9, i8* %arrayidx70.9, align 1
  %scevgep20.36.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 36
  %13989 = load i8, i8* %scevgep20.36.9, align 1
  %conv68.36.9 = zext i8 %13989 to i32
  %13990 = load i8, i8* %arrayidx70.9, align 1
  %conv71.36.9 = zext i8 %13990 to i32
  %xor72.36.9 = xor i32 %conv71.36.9, %conv68.36.9
  %conv73.36.9 = trunc i32 %xor72.36.9 to i8
  store i8 %conv73.36.9, i8* %arrayidx70.9, align 1
  %scevgep20.37.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 37
  %13991 = load i8, i8* %scevgep20.37.9, align 1
  %conv68.37.9 = zext i8 %13991 to i32
  %13992 = load i8, i8* %arrayidx70.9, align 1
  %conv71.37.9 = zext i8 %13992 to i32
  %xor72.37.9 = xor i32 %conv71.37.9, %conv68.37.9
  %conv73.37.9 = trunc i32 %xor72.37.9 to i8
  store i8 %conv73.37.9, i8* %arrayidx70.9, align 1
  %scevgep20.38.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 38
  %13993 = load i8, i8* %scevgep20.38.9, align 1
  %conv68.38.9 = zext i8 %13993 to i32
  %13994 = load i8, i8* %arrayidx70.9, align 1
  %conv71.38.9 = zext i8 %13994 to i32
  %xor72.38.9 = xor i32 %conv71.38.9, %conv68.38.9
  %conv73.38.9 = trunc i32 %xor72.38.9 to i8
  store i8 %conv73.38.9, i8* %arrayidx70.9, align 1
  %scevgep20.39.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 39
  %13995 = load i8, i8* %scevgep20.39.9, align 1
  %conv68.39.9 = zext i8 %13995 to i32
  %13996 = load i8, i8* %arrayidx70.9, align 1
  %conv71.39.9 = zext i8 %13996 to i32
  %xor72.39.9 = xor i32 %conv71.39.9, %conv68.39.9
  %conv73.39.9 = trunc i32 %xor72.39.9 to i8
  store i8 %conv73.39.9, i8* %arrayidx70.9, align 1
  %scevgep20.40.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 40
  %13997 = load i8, i8* %scevgep20.40.9, align 1
  %conv68.40.9 = zext i8 %13997 to i32
  %13998 = load i8, i8* %arrayidx70.9, align 1
  %conv71.40.9 = zext i8 %13998 to i32
  %xor72.40.9 = xor i32 %conv71.40.9, %conv68.40.9
  %conv73.40.9 = trunc i32 %xor72.40.9 to i8
  store i8 %conv73.40.9, i8* %arrayidx70.9, align 1
  %scevgep20.41.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 41
  %13999 = load i8, i8* %scevgep20.41.9, align 1
  %conv68.41.9 = zext i8 %13999 to i32
  %14000 = load i8, i8* %arrayidx70.9, align 1
  %conv71.41.9 = zext i8 %14000 to i32
  %xor72.41.9 = xor i32 %conv71.41.9, %conv68.41.9
  %conv73.41.9 = trunc i32 %xor72.41.9 to i8
  store i8 %conv73.41.9, i8* %arrayidx70.9, align 1
  %scevgep20.42.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 42
  %14001 = load i8, i8* %scevgep20.42.9, align 1
  %conv68.42.9 = zext i8 %14001 to i32
  %14002 = load i8, i8* %arrayidx70.9, align 1
  %conv71.42.9 = zext i8 %14002 to i32
  %xor72.42.9 = xor i32 %conv71.42.9, %conv68.42.9
  %conv73.42.9 = trunc i32 %xor72.42.9 to i8
  store i8 %conv73.42.9, i8* %arrayidx70.9, align 1
  %scevgep20.43.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 43
  %14003 = load i8, i8* %scevgep20.43.9, align 1
  %conv68.43.9 = zext i8 %14003 to i32
  %14004 = load i8, i8* %arrayidx70.9, align 1
  %conv71.43.9 = zext i8 %14004 to i32
  %xor72.43.9 = xor i32 %conv71.43.9, %conv68.43.9
  %conv73.43.9 = trunc i32 %xor72.43.9 to i8
  store i8 %conv73.43.9, i8* %arrayidx70.9, align 1
  %scevgep20.44.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 44
  %14005 = load i8, i8* %scevgep20.44.9, align 1
  %conv68.44.9 = zext i8 %14005 to i32
  %14006 = load i8, i8* %arrayidx70.9, align 1
  %conv71.44.9 = zext i8 %14006 to i32
  %xor72.44.9 = xor i32 %conv71.44.9, %conv68.44.9
  %conv73.44.9 = trunc i32 %xor72.44.9 to i8
  store i8 %conv73.44.9, i8* %arrayidx70.9, align 1
  %scevgep20.45.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 45
  %14007 = load i8, i8* %scevgep20.45.9, align 1
  %conv68.45.9 = zext i8 %14007 to i32
  %14008 = load i8, i8* %arrayidx70.9, align 1
  %conv71.45.9 = zext i8 %14008 to i32
  %xor72.45.9 = xor i32 %conv71.45.9, %conv68.45.9
  %conv73.45.9 = trunc i32 %xor72.45.9 to i8
  store i8 %conv73.45.9, i8* %arrayidx70.9, align 1
  %scevgep20.46.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 46
  %14009 = load i8, i8* %scevgep20.46.9, align 1
  %conv68.46.9 = zext i8 %14009 to i32
  %14010 = load i8, i8* %arrayidx70.9, align 1
  %conv71.46.9 = zext i8 %14010 to i32
  %xor72.46.9 = xor i32 %conv71.46.9, %conv68.46.9
  %conv73.46.9 = trunc i32 %xor72.46.9 to i8
  store i8 %conv73.46.9, i8* %arrayidx70.9, align 1
  %scevgep20.47.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 47
  %14011 = load i8, i8* %scevgep20.47.9, align 1
  %conv68.47.9 = zext i8 %14011 to i32
  %14012 = load i8, i8* %arrayidx70.9, align 1
  %conv71.47.9 = zext i8 %14012 to i32
  %xor72.47.9 = xor i32 %conv71.47.9, %conv68.47.9
  %conv73.47.9 = trunc i32 %xor72.47.9 to i8
  store i8 %conv73.47.9, i8* %arrayidx70.9, align 1
  %scevgep20.48.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 48
  %14013 = load i8, i8* %scevgep20.48.9, align 1
  %conv68.48.9 = zext i8 %14013 to i32
  %14014 = load i8, i8* %arrayidx70.9, align 1
  %conv71.48.9 = zext i8 %14014 to i32
  %xor72.48.9 = xor i32 %conv71.48.9, %conv68.48.9
  %conv73.48.9 = trunc i32 %xor72.48.9 to i8
  store i8 %conv73.48.9, i8* %arrayidx70.9, align 1
  %scevgep20.49.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 49
  %14015 = load i8, i8* %scevgep20.49.9, align 1
  %conv68.49.9 = zext i8 %14015 to i32
  %14016 = load i8, i8* %arrayidx70.9, align 1
  %conv71.49.9 = zext i8 %14016 to i32
  %xor72.49.9 = xor i32 %conv71.49.9, %conv68.49.9
  %conv73.49.9 = trunc i32 %xor72.49.9 to i8
  store i8 %conv73.49.9, i8* %arrayidx70.9, align 1
  %scevgep20.50.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 50
  %14017 = load i8, i8* %scevgep20.50.9, align 1
  %conv68.50.9 = zext i8 %14017 to i32
  %14018 = load i8, i8* %arrayidx70.9, align 1
  %conv71.50.9 = zext i8 %14018 to i32
  %xor72.50.9 = xor i32 %conv71.50.9, %conv68.50.9
  %conv73.50.9 = trunc i32 %xor72.50.9 to i8
  store i8 %conv73.50.9, i8* %arrayidx70.9, align 1
  %scevgep20.51.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 51
  %14019 = load i8, i8* %scevgep20.51.9, align 1
  %conv68.51.9 = zext i8 %14019 to i32
  %14020 = load i8, i8* %arrayidx70.9, align 1
  %conv71.51.9 = zext i8 %14020 to i32
  %xor72.51.9 = xor i32 %conv71.51.9, %conv68.51.9
  %conv73.51.9 = trunc i32 %xor72.51.9 to i8
  store i8 %conv73.51.9, i8* %arrayidx70.9, align 1
  %scevgep20.52.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 52
  %14021 = load i8, i8* %scevgep20.52.9, align 1
  %conv68.52.9 = zext i8 %14021 to i32
  %14022 = load i8, i8* %arrayidx70.9, align 1
  %conv71.52.9 = zext i8 %14022 to i32
  %xor72.52.9 = xor i32 %conv71.52.9, %conv68.52.9
  %conv73.52.9 = trunc i32 %xor72.52.9 to i8
  store i8 %conv73.52.9, i8* %arrayidx70.9, align 1
  %scevgep20.53.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 53
  %14023 = load i8, i8* %scevgep20.53.9, align 1
  %conv68.53.9 = zext i8 %14023 to i32
  %14024 = load i8, i8* %arrayidx70.9, align 1
  %conv71.53.9 = zext i8 %14024 to i32
  %xor72.53.9 = xor i32 %conv71.53.9, %conv68.53.9
  %conv73.53.9 = trunc i32 %xor72.53.9 to i8
  store i8 %conv73.53.9, i8* %arrayidx70.9, align 1
  %scevgep20.54.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 54
  %14025 = load i8, i8* %scevgep20.54.9, align 1
  %conv68.54.9 = zext i8 %14025 to i32
  %14026 = load i8, i8* %arrayidx70.9, align 1
  %conv71.54.9 = zext i8 %14026 to i32
  %xor72.54.9 = xor i32 %conv71.54.9, %conv68.54.9
  %conv73.54.9 = trunc i32 %xor72.54.9 to i8
  store i8 %conv73.54.9, i8* %arrayidx70.9, align 1
  %scevgep20.55.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 55
  %14027 = load i8, i8* %scevgep20.55.9, align 1
  %conv68.55.9 = zext i8 %14027 to i32
  %14028 = load i8, i8* %arrayidx70.9, align 1
  %conv71.55.9 = zext i8 %14028 to i32
  %xor72.55.9 = xor i32 %conv71.55.9, %conv68.55.9
  %conv73.55.9 = trunc i32 %xor72.55.9 to i8
  store i8 %conv73.55.9, i8* %arrayidx70.9, align 1
  %scevgep20.56.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 56
  %14029 = load i8, i8* %scevgep20.56.9, align 1
  %conv68.56.9 = zext i8 %14029 to i32
  %14030 = load i8, i8* %arrayidx70.9, align 1
  %conv71.56.9 = zext i8 %14030 to i32
  %xor72.56.9 = xor i32 %conv71.56.9, %conv68.56.9
  %conv73.56.9 = trunc i32 %xor72.56.9 to i8
  store i8 %conv73.56.9, i8* %arrayidx70.9, align 1
  %scevgep20.57.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 57
  %14031 = load i8, i8* %scevgep20.57.9, align 1
  %conv68.57.9 = zext i8 %14031 to i32
  %14032 = load i8, i8* %arrayidx70.9, align 1
  %conv71.57.9 = zext i8 %14032 to i32
  %xor72.57.9 = xor i32 %conv71.57.9, %conv68.57.9
  %conv73.57.9 = trunc i32 %xor72.57.9 to i8
  store i8 %conv73.57.9, i8* %arrayidx70.9, align 1
  %scevgep20.58.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 58
  %14033 = load i8, i8* %scevgep20.58.9, align 1
  %conv68.58.9 = zext i8 %14033 to i32
  %14034 = load i8, i8* %arrayidx70.9, align 1
  %conv71.58.9 = zext i8 %14034 to i32
  %xor72.58.9 = xor i32 %conv71.58.9, %conv68.58.9
  %conv73.58.9 = trunc i32 %xor72.58.9 to i8
  store i8 %conv73.58.9, i8* %arrayidx70.9, align 1
  %scevgep20.59.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 59
  %14035 = load i8, i8* %scevgep20.59.9, align 1
  %conv68.59.9 = zext i8 %14035 to i32
  %14036 = load i8, i8* %arrayidx70.9, align 1
  %conv71.59.9 = zext i8 %14036 to i32
  %xor72.59.9 = xor i32 %conv71.59.9, %conv68.59.9
  %conv73.59.9 = trunc i32 %xor72.59.9 to i8
  store i8 %conv73.59.9, i8* %arrayidx70.9, align 1
  %scevgep20.60.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 0, i64 60
  %14037 = load i8, i8* %scevgep20.60.9, align 1
  %conv68.60.9 = zext i8 %14037 to i32
  %14038 = load i8, i8* %arrayidx70.9, align 1
  %conv71.60.9 = zext i8 %14038 to i32
  %xor72.60.9 = xor i32 %conv71.60.9, %conv68.60.9
  %conv73.60.9 = trunc i32 %xor72.60.9 to i8
  store i8 %conv73.60.9, i8* %arrayidx70.9, align 1
  %scevgep19.9 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %13916, i64 0, i64 1, i64 0
  %14039 = bitcast i8* %scevgep19.9 to [61 x [61 x i8]]*
  %arrayidx51.10 = getelementptr inbounds i8, i8* %a, i64 10
  %14040 = load i8, i8* %arrayidx51.10, align 1
  %arrayidx53.10 = getelementptr inbounds i8, i8* %b, i64 10
  %14041 = load i8, i8* %arrayidx53.10, align 1
  %call54.10 = call zeroext i8 @mult(i8 zeroext %14040, i8 zeroext %14041)
  %arrayidx56.10 = getelementptr inbounds i8, i8* %c, i64 10
  store i8 %call54.10, i8* %arrayidx56.10, align 1
  %arrayidx70.10 = getelementptr inbounds i8, i8* %c, i64 10
  %scevgep20.10144 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 0
  %14042 = load i8, i8* %scevgep20.10144, align 1
  %conv68.10145 = zext i8 %14042 to i32
  %14043 = load i8, i8* %arrayidx70.10, align 1
  %conv71.10146 = zext i8 %14043 to i32
  %xor72.10147 = xor i32 %conv71.10146, %conv68.10145
  %conv73.10148 = trunc i32 %xor72.10147 to i8
  store i8 %conv73.10148, i8* %arrayidx70.10, align 1
  %scevgep20.1.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 1
  %14044 = load i8, i8* %scevgep20.1.10, align 1
  %conv68.1.10 = zext i8 %14044 to i32
  %14045 = load i8, i8* %arrayidx70.10, align 1
  %conv71.1.10 = zext i8 %14045 to i32
  %xor72.1.10 = xor i32 %conv71.1.10, %conv68.1.10
  %conv73.1.10 = trunc i32 %xor72.1.10 to i8
  store i8 %conv73.1.10, i8* %arrayidx70.10, align 1
  %scevgep20.2.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 2
  %14046 = load i8, i8* %scevgep20.2.10, align 1
  %conv68.2.10 = zext i8 %14046 to i32
  %14047 = load i8, i8* %arrayidx70.10, align 1
  %conv71.2.10 = zext i8 %14047 to i32
  %xor72.2.10 = xor i32 %conv71.2.10, %conv68.2.10
  %conv73.2.10 = trunc i32 %xor72.2.10 to i8
  store i8 %conv73.2.10, i8* %arrayidx70.10, align 1
  %scevgep20.3.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 3
  %14048 = load i8, i8* %scevgep20.3.10, align 1
  %conv68.3.10 = zext i8 %14048 to i32
  %14049 = load i8, i8* %arrayidx70.10, align 1
  %conv71.3.10 = zext i8 %14049 to i32
  %xor72.3.10 = xor i32 %conv71.3.10, %conv68.3.10
  %conv73.3.10 = trunc i32 %xor72.3.10 to i8
  store i8 %conv73.3.10, i8* %arrayidx70.10, align 1
  %scevgep20.4.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 4
  %14050 = load i8, i8* %scevgep20.4.10, align 1
  %conv68.4.10 = zext i8 %14050 to i32
  %14051 = load i8, i8* %arrayidx70.10, align 1
  %conv71.4.10 = zext i8 %14051 to i32
  %xor72.4.10 = xor i32 %conv71.4.10, %conv68.4.10
  %conv73.4.10 = trunc i32 %xor72.4.10 to i8
  store i8 %conv73.4.10, i8* %arrayidx70.10, align 1
  %scevgep20.5.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 5
  %14052 = load i8, i8* %scevgep20.5.10, align 1
  %conv68.5.10 = zext i8 %14052 to i32
  %14053 = load i8, i8* %arrayidx70.10, align 1
  %conv71.5.10 = zext i8 %14053 to i32
  %xor72.5.10 = xor i32 %conv71.5.10, %conv68.5.10
  %conv73.5.10 = trunc i32 %xor72.5.10 to i8
  store i8 %conv73.5.10, i8* %arrayidx70.10, align 1
  %scevgep20.6.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 6
  %14054 = load i8, i8* %scevgep20.6.10, align 1
  %conv68.6.10 = zext i8 %14054 to i32
  %14055 = load i8, i8* %arrayidx70.10, align 1
  %conv71.6.10 = zext i8 %14055 to i32
  %xor72.6.10 = xor i32 %conv71.6.10, %conv68.6.10
  %conv73.6.10 = trunc i32 %xor72.6.10 to i8
  store i8 %conv73.6.10, i8* %arrayidx70.10, align 1
  %scevgep20.7.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 7
  %14056 = load i8, i8* %scevgep20.7.10, align 1
  %conv68.7.10 = zext i8 %14056 to i32
  %14057 = load i8, i8* %arrayidx70.10, align 1
  %conv71.7.10 = zext i8 %14057 to i32
  %xor72.7.10 = xor i32 %conv71.7.10, %conv68.7.10
  %conv73.7.10 = trunc i32 %xor72.7.10 to i8
  store i8 %conv73.7.10, i8* %arrayidx70.10, align 1
  %scevgep20.8.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 8
  %14058 = load i8, i8* %scevgep20.8.10, align 1
  %conv68.8.10 = zext i8 %14058 to i32
  %14059 = load i8, i8* %arrayidx70.10, align 1
  %conv71.8.10 = zext i8 %14059 to i32
  %xor72.8.10 = xor i32 %conv71.8.10, %conv68.8.10
  %conv73.8.10 = trunc i32 %xor72.8.10 to i8
  store i8 %conv73.8.10, i8* %arrayidx70.10, align 1
  %scevgep20.9.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 9
  %14060 = load i8, i8* %scevgep20.9.10, align 1
  %conv68.9.10 = zext i8 %14060 to i32
  %14061 = load i8, i8* %arrayidx70.10, align 1
  %conv71.9.10 = zext i8 %14061 to i32
  %xor72.9.10 = xor i32 %conv71.9.10, %conv68.9.10
  %conv73.9.10 = trunc i32 %xor72.9.10 to i8
  store i8 %conv73.9.10, i8* %arrayidx70.10, align 1
  %scevgep20.11.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 11
  %14062 = load i8, i8* %scevgep20.11.10, align 1
  %conv68.11.10 = zext i8 %14062 to i32
  %14063 = load i8, i8* %arrayidx70.10, align 1
  %conv71.11.10 = zext i8 %14063 to i32
  %xor72.11.10 = xor i32 %conv71.11.10, %conv68.11.10
  %conv73.11.10 = trunc i32 %xor72.11.10 to i8
  store i8 %conv73.11.10, i8* %arrayidx70.10, align 1
  %scevgep20.12.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 12
  %14064 = load i8, i8* %scevgep20.12.10, align 1
  %conv68.12.10 = zext i8 %14064 to i32
  %14065 = load i8, i8* %arrayidx70.10, align 1
  %conv71.12.10 = zext i8 %14065 to i32
  %xor72.12.10 = xor i32 %conv71.12.10, %conv68.12.10
  %conv73.12.10 = trunc i32 %xor72.12.10 to i8
  store i8 %conv73.12.10, i8* %arrayidx70.10, align 1
  %scevgep20.13.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 13
  %14066 = load i8, i8* %scevgep20.13.10, align 1
  %conv68.13.10 = zext i8 %14066 to i32
  %14067 = load i8, i8* %arrayidx70.10, align 1
  %conv71.13.10 = zext i8 %14067 to i32
  %xor72.13.10 = xor i32 %conv71.13.10, %conv68.13.10
  %conv73.13.10 = trunc i32 %xor72.13.10 to i8
  store i8 %conv73.13.10, i8* %arrayidx70.10, align 1
  %scevgep20.14.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 14
  %14068 = load i8, i8* %scevgep20.14.10, align 1
  %conv68.14.10 = zext i8 %14068 to i32
  %14069 = load i8, i8* %arrayidx70.10, align 1
  %conv71.14.10 = zext i8 %14069 to i32
  %xor72.14.10 = xor i32 %conv71.14.10, %conv68.14.10
  %conv73.14.10 = trunc i32 %xor72.14.10 to i8
  store i8 %conv73.14.10, i8* %arrayidx70.10, align 1
  %scevgep20.15.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 15
  %14070 = load i8, i8* %scevgep20.15.10, align 1
  %conv68.15.10 = zext i8 %14070 to i32
  %14071 = load i8, i8* %arrayidx70.10, align 1
  %conv71.15.10 = zext i8 %14071 to i32
  %xor72.15.10 = xor i32 %conv71.15.10, %conv68.15.10
  %conv73.15.10 = trunc i32 %xor72.15.10 to i8
  store i8 %conv73.15.10, i8* %arrayidx70.10, align 1
  %scevgep20.16.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 16
  %14072 = load i8, i8* %scevgep20.16.10, align 1
  %conv68.16.10 = zext i8 %14072 to i32
  %14073 = load i8, i8* %arrayidx70.10, align 1
  %conv71.16.10 = zext i8 %14073 to i32
  %xor72.16.10 = xor i32 %conv71.16.10, %conv68.16.10
  %conv73.16.10 = trunc i32 %xor72.16.10 to i8
  store i8 %conv73.16.10, i8* %arrayidx70.10, align 1
  %scevgep20.17.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 17
  %14074 = load i8, i8* %scevgep20.17.10, align 1
  %conv68.17.10 = zext i8 %14074 to i32
  %14075 = load i8, i8* %arrayidx70.10, align 1
  %conv71.17.10 = zext i8 %14075 to i32
  %xor72.17.10 = xor i32 %conv71.17.10, %conv68.17.10
  %conv73.17.10 = trunc i32 %xor72.17.10 to i8
  store i8 %conv73.17.10, i8* %arrayidx70.10, align 1
  %scevgep20.18.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 18
  %14076 = load i8, i8* %scevgep20.18.10, align 1
  %conv68.18.10 = zext i8 %14076 to i32
  %14077 = load i8, i8* %arrayidx70.10, align 1
  %conv71.18.10 = zext i8 %14077 to i32
  %xor72.18.10 = xor i32 %conv71.18.10, %conv68.18.10
  %conv73.18.10 = trunc i32 %xor72.18.10 to i8
  store i8 %conv73.18.10, i8* %arrayidx70.10, align 1
  %scevgep20.19.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 19
  %14078 = load i8, i8* %scevgep20.19.10, align 1
  %conv68.19.10 = zext i8 %14078 to i32
  %14079 = load i8, i8* %arrayidx70.10, align 1
  %conv71.19.10 = zext i8 %14079 to i32
  %xor72.19.10 = xor i32 %conv71.19.10, %conv68.19.10
  %conv73.19.10 = trunc i32 %xor72.19.10 to i8
  store i8 %conv73.19.10, i8* %arrayidx70.10, align 1
  %scevgep20.20.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 20
  %14080 = load i8, i8* %scevgep20.20.10, align 1
  %conv68.20.10 = zext i8 %14080 to i32
  %14081 = load i8, i8* %arrayidx70.10, align 1
  %conv71.20.10 = zext i8 %14081 to i32
  %xor72.20.10 = xor i32 %conv71.20.10, %conv68.20.10
  %conv73.20.10 = trunc i32 %xor72.20.10 to i8
  store i8 %conv73.20.10, i8* %arrayidx70.10, align 1
  %scevgep20.21.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 21
  %14082 = load i8, i8* %scevgep20.21.10, align 1
  %conv68.21.10 = zext i8 %14082 to i32
  %14083 = load i8, i8* %arrayidx70.10, align 1
  %conv71.21.10 = zext i8 %14083 to i32
  %xor72.21.10 = xor i32 %conv71.21.10, %conv68.21.10
  %conv73.21.10 = trunc i32 %xor72.21.10 to i8
  store i8 %conv73.21.10, i8* %arrayidx70.10, align 1
  %scevgep20.22.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 22
  %14084 = load i8, i8* %scevgep20.22.10, align 1
  %conv68.22.10 = zext i8 %14084 to i32
  %14085 = load i8, i8* %arrayidx70.10, align 1
  %conv71.22.10 = zext i8 %14085 to i32
  %xor72.22.10 = xor i32 %conv71.22.10, %conv68.22.10
  %conv73.22.10 = trunc i32 %xor72.22.10 to i8
  store i8 %conv73.22.10, i8* %arrayidx70.10, align 1
  %scevgep20.23.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 23
  %14086 = load i8, i8* %scevgep20.23.10, align 1
  %conv68.23.10 = zext i8 %14086 to i32
  %14087 = load i8, i8* %arrayidx70.10, align 1
  %conv71.23.10 = zext i8 %14087 to i32
  %xor72.23.10 = xor i32 %conv71.23.10, %conv68.23.10
  %conv73.23.10 = trunc i32 %xor72.23.10 to i8
  store i8 %conv73.23.10, i8* %arrayidx70.10, align 1
  %scevgep20.24.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 24
  %14088 = load i8, i8* %scevgep20.24.10, align 1
  %conv68.24.10 = zext i8 %14088 to i32
  %14089 = load i8, i8* %arrayidx70.10, align 1
  %conv71.24.10 = zext i8 %14089 to i32
  %xor72.24.10 = xor i32 %conv71.24.10, %conv68.24.10
  %conv73.24.10 = trunc i32 %xor72.24.10 to i8
  store i8 %conv73.24.10, i8* %arrayidx70.10, align 1
  %scevgep20.25.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 25
  %14090 = load i8, i8* %scevgep20.25.10, align 1
  %conv68.25.10 = zext i8 %14090 to i32
  %14091 = load i8, i8* %arrayidx70.10, align 1
  %conv71.25.10 = zext i8 %14091 to i32
  %xor72.25.10 = xor i32 %conv71.25.10, %conv68.25.10
  %conv73.25.10 = trunc i32 %xor72.25.10 to i8
  store i8 %conv73.25.10, i8* %arrayidx70.10, align 1
  %scevgep20.26.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 26
  %14092 = load i8, i8* %scevgep20.26.10, align 1
  %conv68.26.10 = zext i8 %14092 to i32
  %14093 = load i8, i8* %arrayidx70.10, align 1
  %conv71.26.10 = zext i8 %14093 to i32
  %xor72.26.10 = xor i32 %conv71.26.10, %conv68.26.10
  %conv73.26.10 = trunc i32 %xor72.26.10 to i8
  store i8 %conv73.26.10, i8* %arrayidx70.10, align 1
  %scevgep20.27.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 27
  %14094 = load i8, i8* %scevgep20.27.10, align 1
  %conv68.27.10 = zext i8 %14094 to i32
  %14095 = load i8, i8* %arrayidx70.10, align 1
  %conv71.27.10 = zext i8 %14095 to i32
  %xor72.27.10 = xor i32 %conv71.27.10, %conv68.27.10
  %conv73.27.10 = trunc i32 %xor72.27.10 to i8
  store i8 %conv73.27.10, i8* %arrayidx70.10, align 1
  %scevgep20.28.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 28
  %14096 = load i8, i8* %scevgep20.28.10, align 1
  %conv68.28.10 = zext i8 %14096 to i32
  %14097 = load i8, i8* %arrayidx70.10, align 1
  %conv71.28.10 = zext i8 %14097 to i32
  %xor72.28.10 = xor i32 %conv71.28.10, %conv68.28.10
  %conv73.28.10 = trunc i32 %xor72.28.10 to i8
  store i8 %conv73.28.10, i8* %arrayidx70.10, align 1
  %scevgep20.29.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 29
  %14098 = load i8, i8* %scevgep20.29.10, align 1
  %conv68.29.10 = zext i8 %14098 to i32
  %14099 = load i8, i8* %arrayidx70.10, align 1
  %conv71.29.10 = zext i8 %14099 to i32
  %xor72.29.10 = xor i32 %conv71.29.10, %conv68.29.10
  %conv73.29.10 = trunc i32 %xor72.29.10 to i8
  store i8 %conv73.29.10, i8* %arrayidx70.10, align 1
  %scevgep20.30.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 30
  %14100 = load i8, i8* %scevgep20.30.10, align 1
  %conv68.30.10 = zext i8 %14100 to i32
  %14101 = load i8, i8* %arrayidx70.10, align 1
  %conv71.30.10 = zext i8 %14101 to i32
  %xor72.30.10 = xor i32 %conv71.30.10, %conv68.30.10
  %conv73.30.10 = trunc i32 %xor72.30.10 to i8
  store i8 %conv73.30.10, i8* %arrayidx70.10, align 1
  %scevgep20.31.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 31
  %14102 = load i8, i8* %scevgep20.31.10, align 1
  %conv68.31.10 = zext i8 %14102 to i32
  %14103 = load i8, i8* %arrayidx70.10, align 1
  %conv71.31.10 = zext i8 %14103 to i32
  %xor72.31.10 = xor i32 %conv71.31.10, %conv68.31.10
  %conv73.31.10 = trunc i32 %xor72.31.10 to i8
  store i8 %conv73.31.10, i8* %arrayidx70.10, align 1
  %scevgep20.32.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 32
  %14104 = load i8, i8* %scevgep20.32.10, align 1
  %conv68.32.10 = zext i8 %14104 to i32
  %14105 = load i8, i8* %arrayidx70.10, align 1
  %conv71.32.10 = zext i8 %14105 to i32
  %xor72.32.10 = xor i32 %conv71.32.10, %conv68.32.10
  %conv73.32.10 = trunc i32 %xor72.32.10 to i8
  store i8 %conv73.32.10, i8* %arrayidx70.10, align 1
  %scevgep20.33.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 33
  %14106 = load i8, i8* %scevgep20.33.10, align 1
  %conv68.33.10 = zext i8 %14106 to i32
  %14107 = load i8, i8* %arrayidx70.10, align 1
  %conv71.33.10 = zext i8 %14107 to i32
  %xor72.33.10 = xor i32 %conv71.33.10, %conv68.33.10
  %conv73.33.10 = trunc i32 %xor72.33.10 to i8
  store i8 %conv73.33.10, i8* %arrayidx70.10, align 1
  %scevgep20.34.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 34
  %14108 = load i8, i8* %scevgep20.34.10, align 1
  %conv68.34.10 = zext i8 %14108 to i32
  %14109 = load i8, i8* %arrayidx70.10, align 1
  %conv71.34.10 = zext i8 %14109 to i32
  %xor72.34.10 = xor i32 %conv71.34.10, %conv68.34.10
  %conv73.34.10 = trunc i32 %xor72.34.10 to i8
  store i8 %conv73.34.10, i8* %arrayidx70.10, align 1
  %scevgep20.35.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 35
  %14110 = load i8, i8* %scevgep20.35.10, align 1
  %conv68.35.10 = zext i8 %14110 to i32
  %14111 = load i8, i8* %arrayidx70.10, align 1
  %conv71.35.10 = zext i8 %14111 to i32
  %xor72.35.10 = xor i32 %conv71.35.10, %conv68.35.10
  %conv73.35.10 = trunc i32 %xor72.35.10 to i8
  store i8 %conv73.35.10, i8* %arrayidx70.10, align 1
  %scevgep20.36.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 36
  %14112 = load i8, i8* %scevgep20.36.10, align 1
  %conv68.36.10 = zext i8 %14112 to i32
  %14113 = load i8, i8* %arrayidx70.10, align 1
  %conv71.36.10 = zext i8 %14113 to i32
  %xor72.36.10 = xor i32 %conv71.36.10, %conv68.36.10
  %conv73.36.10 = trunc i32 %xor72.36.10 to i8
  store i8 %conv73.36.10, i8* %arrayidx70.10, align 1
  %scevgep20.37.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 37
  %14114 = load i8, i8* %scevgep20.37.10, align 1
  %conv68.37.10 = zext i8 %14114 to i32
  %14115 = load i8, i8* %arrayidx70.10, align 1
  %conv71.37.10 = zext i8 %14115 to i32
  %xor72.37.10 = xor i32 %conv71.37.10, %conv68.37.10
  %conv73.37.10 = trunc i32 %xor72.37.10 to i8
  store i8 %conv73.37.10, i8* %arrayidx70.10, align 1
  %scevgep20.38.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 38
  %14116 = load i8, i8* %scevgep20.38.10, align 1
  %conv68.38.10 = zext i8 %14116 to i32
  %14117 = load i8, i8* %arrayidx70.10, align 1
  %conv71.38.10 = zext i8 %14117 to i32
  %xor72.38.10 = xor i32 %conv71.38.10, %conv68.38.10
  %conv73.38.10 = trunc i32 %xor72.38.10 to i8
  store i8 %conv73.38.10, i8* %arrayidx70.10, align 1
  %scevgep20.39.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 39
  %14118 = load i8, i8* %scevgep20.39.10, align 1
  %conv68.39.10 = zext i8 %14118 to i32
  %14119 = load i8, i8* %arrayidx70.10, align 1
  %conv71.39.10 = zext i8 %14119 to i32
  %xor72.39.10 = xor i32 %conv71.39.10, %conv68.39.10
  %conv73.39.10 = trunc i32 %xor72.39.10 to i8
  store i8 %conv73.39.10, i8* %arrayidx70.10, align 1
  %scevgep20.40.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 40
  %14120 = load i8, i8* %scevgep20.40.10, align 1
  %conv68.40.10 = zext i8 %14120 to i32
  %14121 = load i8, i8* %arrayidx70.10, align 1
  %conv71.40.10 = zext i8 %14121 to i32
  %xor72.40.10 = xor i32 %conv71.40.10, %conv68.40.10
  %conv73.40.10 = trunc i32 %xor72.40.10 to i8
  store i8 %conv73.40.10, i8* %arrayidx70.10, align 1
  %scevgep20.41.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 41
  %14122 = load i8, i8* %scevgep20.41.10, align 1
  %conv68.41.10 = zext i8 %14122 to i32
  %14123 = load i8, i8* %arrayidx70.10, align 1
  %conv71.41.10 = zext i8 %14123 to i32
  %xor72.41.10 = xor i32 %conv71.41.10, %conv68.41.10
  %conv73.41.10 = trunc i32 %xor72.41.10 to i8
  store i8 %conv73.41.10, i8* %arrayidx70.10, align 1
  %scevgep20.42.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 42
  %14124 = load i8, i8* %scevgep20.42.10, align 1
  %conv68.42.10 = zext i8 %14124 to i32
  %14125 = load i8, i8* %arrayidx70.10, align 1
  %conv71.42.10 = zext i8 %14125 to i32
  %xor72.42.10 = xor i32 %conv71.42.10, %conv68.42.10
  %conv73.42.10 = trunc i32 %xor72.42.10 to i8
  store i8 %conv73.42.10, i8* %arrayidx70.10, align 1
  %scevgep20.43.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 43
  %14126 = load i8, i8* %scevgep20.43.10, align 1
  %conv68.43.10 = zext i8 %14126 to i32
  %14127 = load i8, i8* %arrayidx70.10, align 1
  %conv71.43.10 = zext i8 %14127 to i32
  %xor72.43.10 = xor i32 %conv71.43.10, %conv68.43.10
  %conv73.43.10 = trunc i32 %xor72.43.10 to i8
  store i8 %conv73.43.10, i8* %arrayidx70.10, align 1
  %scevgep20.44.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 44
  %14128 = load i8, i8* %scevgep20.44.10, align 1
  %conv68.44.10 = zext i8 %14128 to i32
  %14129 = load i8, i8* %arrayidx70.10, align 1
  %conv71.44.10 = zext i8 %14129 to i32
  %xor72.44.10 = xor i32 %conv71.44.10, %conv68.44.10
  %conv73.44.10 = trunc i32 %xor72.44.10 to i8
  store i8 %conv73.44.10, i8* %arrayidx70.10, align 1
  %scevgep20.45.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 45
  %14130 = load i8, i8* %scevgep20.45.10, align 1
  %conv68.45.10 = zext i8 %14130 to i32
  %14131 = load i8, i8* %arrayidx70.10, align 1
  %conv71.45.10 = zext i8 %14131 to i32
  %xor72.45.10 = xor i32 %conv71.45.10, %conv68.45.10
  %conv73.45.10 = trunc i32 %xor72.45.10 to i8
  store i8 %conv73.45.10, i8* %arrayidx70.10, align 1
  %scevgep20.46.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 46
  %14132 = load i8, i8* %scevgep20.46.10, align 1
  %conv68.46.10 = zext i8 %14132 to i32
  %14133 = load i8, i8* %arrayidx70.10, align 1
  %conv71.46.10 = zext i8 %14133 to i32
  %xor72.46.10 = xor i32 %conv71.46.10, %conv68.46.10
  %conv73.46.10 = trunc i32 %xor72.46.10 to i8
  store i8 %conv73.46.10, i8* %arrayidx70.10, align 1
  %scevgep20.47.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 47
  %14134 = load i8, i8* %scevgep20.47.10, align 1
  %conv68.47.10 = zext i8 %14134 to i32
  %14135 = load i8, i8* %arrayidx70.10, align 1
  %conv71.47.10 = zext i8 %14135 to i32
  %xor72.47.10 = xor i32 %conv71.47.10, %conv68.47.10
  %conv73.47.10 = trunc i32 %xor72.47.10 to i8
  store i8 %conv73.47.10, i8* %arrayidx70.10, align 1
  %scevgep20.48.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 48
  %14136 = load i8, i8* %scevgep20.48.10, align 1
  %conv68.48.10 = zext i8 %14136 to i32
  %14137 = load i8, i8* %arrayidx70.10, align 1
  %conv71.48.10 = zext i8 %14137 to i32
  %xor72.48.10 = xor i32 %conv71.48.10, %conv68.48.10
  %conv73.48.10 = trunc i32 %xor72.48.10 to i8
  store i8 %conv73.48.10, i8* %arrayidx70.10, align 1
  %scevgep20.49.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 49
  %14138 = load i8, i8* %scevgep20.49.10, align 1
  %conv68.49.10 = zext i8 %14138 to i32
  %14139 = load i8, i8* %arrayidx70.10, align 1
  %conv71.49.10 = zext i8 %14139 to i32
  %xor72.49.10 = xor i32 %conv71.49.10, %conv68.49.10
  %conv73.49.10 = trunc i32 %xor72.49.10 to i8
  store i8 %conv73.49.10, i8* %arrayidx70.10, align 1
  %scevgep20.50.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 50
  %14140 = load i8, i8* %scevgep20.50.10, align 1
  %conv68.50.10 = zext i8 %14140 to i32
  %14141 = load i8, i8* %arrayidx70.10, align 1
  %conv71.50.10 = zext i8 %14141 to i32
  %xor72.50.10 = xor i32 %conv71.50.10, %conv68.50.10
  %conv73.50.10 = trunc i32 %xor72.50.10 to i8
  store i8 %conv73.50.10, i8* %arrayidx70.10, align 1
  %scevgep20.51.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 51
  %14142 = load i8, i8* %scevgep20.51.10, align 1
  %conv68.51.10 = zext i8 %14142 to i32
  %14143 = load i8, i8* %arrayidx70.10, align 1
  %conv71.51.10 = zext i8 %14143 to i32
  %xor72.51.10 = xor i32 %conv71.51.10, %conv68.51.10
  %conv73.51.10 = trunc i32 %xor72.51.10 to i8
  store i8 %conv73.51.10, i8* %arrayidx70.10, align 1
  %scevgep20.52.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 52
  %14144 = load i8, i8* %scevgep20.52.10, align 1
  %conv68.52.10 = zext i8 %14144 to i32
  %14145 = load i8, i8* %arrayidx70.10, align 1
  %conv71.52.10 = zext i8 %14145 to i32
  %xor72.52.10 = xor i32 %conv71.52.10, %conv68.52.10
  %conv73.52.10 = trunc i32 %xor72.52.10 to i8
  store i8 %conv73.52.10, i8* %arrayidx70.10, align 1
  %scevgep20.53.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 53
  %14146 = load i8, i8* %scevgep20.53.10, align 1
  %conv68.53.10 = zext i8 %14146 to i32
  %14147 = load i8, i8* %arrayidx70.10, align 1
  %conv71.53.10 = zext i8 %14147 to i32
  %xor72.53.10 = xor i32 %conv71.53.10, %conv68.53.10
  %conv73.53.10 = trunc i32 %xor72.53.10 to i8
  store i8 %conv73.53.10, i8* %arrayidx70.10, align 1
  %scevgep20.54.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 54
  %14148 = load i8, i8* %scevgep20.54.10, align 1
  %conv68.54.10 = zext i8 %14148 to i32
  %14149 = load i8, i8* %arrayidx70.10, align 1
  %conv71.54.10 = zext i8 %14149 to i32
  %xor72.54.10 = xor i32 %conv71.54.10, %conv68.54.10
  %conv73.54.10 = trunc i32 %xor72.54.10 to i8
  store i8 %conv73.54.10, i8* %arrayidx70.10, align 1
  %scevgep20.55.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 55
  %14150 = load i8, i8* %scevgep20.55.10, align 1
  %conv68.55.10 = zext i8 %14150 to i32
  %14151 = load i8, i8* %arrayidx70.10, align 1
  %conv71.55.10 = zext i8 %14151 to i32
  %xor72.55.10 = xor i32 %conv71.55.10, %conv68.55.10
  %conv73.55.10 = trunc i32 %xor72.55.10 to i8
  store i8 %conv73.55.10, i8* %arrayidx70.10, align 1
  %scevgep20.56.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 56
  %14152 = load i8, i8* %scevgep20.56.10, align 1
  %conv68.56.10 = zext i8 %14152 to i32
  %14153 = load i8, i8* %arrayidx70.10, align 1
  %conv71.56.10 = zext i8 %14153 to i32
  %xor72.56.10 = xor i32 %conv71.56.10, %conv68.56.10
  %conv73.56.10 = trunc i32 %xor72.56.10 to i8
  store i8 %conv73.56.10, i8* %arrayidx70.10, align 1
  %scevgep20.57.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 57
  %14154 = load i8, i8* %scevgep20.57.10, align 1
  %conv68.57.10 = zext i8 %14154 to i32
  %14155 = load i8, i8* %arrayidx70.10, align 1
  %conv71.57.10 = zext i8 %14155 to i32
  %xor72.57.10 = xor i32 %conv71.57.10, %conv68.57.10
  %conv73.57.10 = trunc i32 %xor72.57.10 to i8
  store i8 %conv73.57.10, i8* %arrayidx70.10, align 1
  %scevgep20.58.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 58
  %14156 = load i8, i8* %scevgep20.58.10, align 1
  %conv68.58.10 = zext i8 %14156 to i32
  %14157 = load i8, i8* %arrayidx70.10, align 1
  %conv71.58.10 = zext i8 %14157 to i32
  %xor72.58.10 = xor i32 %conv71.58.10, %conv68.58.10
  %conv73.58.10 = trunc i32 %xor72.58.10 to i8
  store i8 %conv73.58.10, i8* %arrayidx70.10, align 1
  %scevgep20.59.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 59
  %14158 = load i8, i8* %scevgep20.59.10, align 1
  %conv68.59.10 = zext i8 %14158 to i32
  %14159 = load i8, i8* %arrayidx70.10, align 1
  %conv71.59.10 = zext i8 %14159 to i32
  %xor72.59.10 = xor i32 %conv71.59.10, %conv68.59.10
  %conv73.59.10 = trunc i32 %xor72.59.10 to i8
  store i8 %conv73.59.10, i8* %arrayidx70.10, align 1
  %scevgep20.60.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 0, i64 60
  %14160 = load i8, i8* %scevgep20.60.10, align 1
  %conv68.60.10 = zext i8 %14160 to i32
  %14161 = load i8, i8* %arrayidx70.10, align 1
  %conv71.60.10 = zext i8 %14161 to i32
  %xor72.60.10 = xor i32 %conv71.60.10, %conv68.60.10
  %conv73.60.10 = trunc i32 %xor72.60.10 to i8
  store i8 %conv73.60.10, i8* %arrayidx70.10, align 1
  %scevgep19.10 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14039, i64 0, i64 1, i64 0
  %14162 = bitcast i8* %scevgep19.10 to [61 x [61 x i8]]*
  %arrayidx51.11 = getelementptr inbounds i8, i8* %a, i64 11
  %14163 = load i8, i8* %arrayidx51.11, align 1
  %arrayidx53.11 = getelementptr inbounds i8, i8* %b, i64 11
  %14164 = load i8, i8* %arrayidx53.11, align 1
  %call54.11 = call zeroext i8 @mult(i8 zeroext %14163, i8 zeroext %14164)
  %arrayidx56.11 = getelementptr inbounds i8, i8* %c, i64 11
  store i8 %call54.11, i8* %arrayidx56.11, align 1
  %arrayidx70.11 = getelementptr inbounds i8, i8* %c, i64 11
  %scevgep20.11154 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 0
  %14165 = load i8, i8* %scevgep20.11154, align 1
  %conv68.11155 = zext i8 %14165 to i32
  %14166 = load i8, i8* %arrayidx70.11, align 1
  %conv71.11156 = zext i8 %14166 to i32
  %xor72.11157 = xor i32 %conv71.11156, %conv68.11155
  %conv73.11158 = trunc i32 %xor72.11157 to i8
  store i8 %conv73.11158, i8* %arrayidx70.11, align 1
  %scevgep20.1.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 1
  %14167 = load i8, i8* %scevgep20.1.11, align 1
  %conv68.1.11 = zext i8 %14167 to i32
  %14168 = load i8, i8* %arrayidx70.11, align 1
  %conv71.1.11 = zext i8 %14168 to i32
  %xor72.1.11 = xor i32 %conv71.1.11, %conv68.1.11
  %conv73.1.11 = trunc i32 %xor72.1.11 to i8
  store i8 %conv73.1.11, i8* %arrayidx70.11, align 1
  %scevgep20.2.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 2
  %14169 = load i8, i8* %scevgep20.2.11, align 1
  %conv68.2.11 = zext i8 %14169 to i32
  %14170 = load i8, i8* %arrayidx70.11, align 1
  %conv71.2.11 = zext i8 %14170 to i32
  %xor72.2.11 = xor i32 %conv71.2.11, %conv68.2.11
  %conv73.2.11 = trunc i32 %xor72.2.11 to i8
  store i8 %conv73.2.11, i8* %arrayidx70.11, align 1
  %scevgep20.3.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 3
  %14171 = load i8, i8* %scevgep20.3.11, align 1
  %conv68.3.11 = zext i8 %14171 to i32
  %14172 = load i8, i8* %arrayidx70.11, align 1
  %conv71.3.11 = zext i8 %14172 to i32
  %xor72.3.11 = xor i32 %conv71.3.11, %conv68.3.11
  %conv73.3.11 = trunc i32 %xor72.3.11 to i8
  store i8 %conv73.3.11, i8* %arrayidx70.11, align 1
  %scevgep20.4.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 4
  %14173 = load i8, i8* %scevgep20.4.11, align 1
  %conv68.4.11 = zext i8 %14173 to i32
  %14174 = load i8, i8* %arrayidx70.11, align 1
  %conv71.4.11 = zext i8 %14174 to i32
  %xor72.4.11 = xor i32 %conv71.4.11, %conv68.4.11
  %conv73.4.11 = trunc i32 %xor72.4.11 to i8
  store i8 %conv73.4.11, i8* %arrayidx70.11, align 1
  %scevgep20.5.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 5
  %14175 = load i8, i8* %scevgep20.5.11, align 1
  %conv68.5.11 = zext i8 %14175 to i32
  %14176 = load i8, i8* %arrayidx70.11, align 1
  %conv71.5.11 = zext i8 %14176 to i32
  %xor72.5.11 = xor i32 %conv71.5.11, %conv68.5.11
  %conv73.5.11 = trunc i32 %xor72.5.11 to i8
  store i8 %conv73.5.11, i8* %arrayidx70.11, align 1
  %scevgep20.6.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 6
  %14177 = load i8, i8* %scevgep20.6.11, align 1
  %conv68.6.11 = zext i8 %14177 to i32
  %14178 = load i8, i8* %arrayidx70.11, align 1
  %conv71.6.11 = zext i8 %14178 to i32
  %xor72.6.11 = xor i32 %conv71.6.11, %conv68.6.11
  %conv73.6.11 = trunc i32 %xor72.6.11 to i8
  store i8 %conv73.6.11, i8* %arrayidx70.11, align 1
  %scevgep20.7.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 7
  %14179 = load i8, i8* %scevgep20.7.11, align 1
  %conv68.7.11 = zext i8 %14179 to i32
  %14180 = load i8, i8* %arrayidx70.11, align 1
  %conv71.7.11 = zext i8 %14180 to i32
  %xor72.7.11 = xor i32 %conv71.7.11, %conv68.7.11
  %conv73.7.11 = trunc i32 %xor72.7.11 to i8
  store i8 %conv73.7.11, i8* %arrayidx70.11, align 1
  %scevgep20.8.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 8
  %14181 = load i8, i8* %scevgep20.8.11, align 1
  %conv68.8.11 = zext i8 %14181 to i32
  %14182 = load i8, i8* %arrayidx70.11, align 1
  %conv71.8.11 = zext i8 %14182 to i32
  %xor72.8.11 = xor i32 %conv71.8.11, %conv68.8.11
  %conv73.8.11 = trunc i32 %xor72.8.11 to i8
  store i8 %conv73.8.11, i8* %arrayidx70.11, align 1
  %scevgep20.9.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 9
  %14183 = load i8, i8* %scevgep20.9.11, align 1
  %conv68.9.11 = zext i8 %14183 to i32
  %14184 = load i8, i8* %arrayidx70.11, align 1
  %conv71.9.11 = zext i8 %14184 to i32
  %xor72.9.11 = xor i32 %conv71.9.11, %conv68.9.11
  %conv73.9.11 = trunc i32 %xor72.9.11 to i8
  store i8 %conv73.9.11, i8* %arrayidx70.11, align 1
  %scevgep20.10.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 10
  %14185 = load i8, i8* %scevgep20.10.11, align 1
  %conv68.10.11 = zext i8 %14185 to i32
  %14186 = load i8, i8* %arrayidx70.11, align 1
  %conv71.10.11 = zext i8 %14186 to i32
  %xor72.10.11 = xor i32 %conv71.10.11, %conv68.10.11
  %conv73.10.11 = trunc i32 %xor72.10.11 to i8
  store i8 %conv73.10.11, i8* %arrayidx70.11, align 1
  %scevgep20.12.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 12
  %14187 = load i8, i8* %scevgep20.12.11, align 1
  %conv68.12.11 = zext i8 %14187 to i32
  %14188 = load i8, i8* %arrayidx70.11, align 1
  %conv71.12.11 = zext i8 %14188 to i32
  %xor72.12.11 = xor i32 %conv71.12.11, %conv68.12.11
  %conv73.12.11 = trunc i32 %xor72.12.11 to i8
  store i8 %conv73.12.11, i8* %arrayidx70.11, align 1
  %scevgep20.13.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 13
  %14189 = load i8, i8* %scevgep20.13.11, align 1
  %conv68.13.11 = zext i8 %14189 to i32
  %14190 = load i8, i8* %arrayidx70.11, align 1
  %conv71.13.11 = zext i8 %14190 to i32
  %xor72.13.11 = xor i32 %conv71.13.11, %conv68.13.11
  %conv73.13.11 = trunc i32 %xor72.13.11 to i8
  store i8 %conv73.13.11, i8* %arrayidx70.11, align 1
  %scevgep20.14.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 14
  %14191 = load i8, i8* %scevgep20.14.11, align 1
  %conv68.14.11 = zext i8 %14191 to i32
  %14192 = load i8, i8* %arrayidx70.11, align 1
  %conv71.14.11 = zext i8 %14192 to i32
  %xor72.14.11 = xor i32 %conv71.14.11, %conv68.14.11
  %conv73.14.11 = trunc i32 %xor72.14.11 to i8
  store i8 %conv73.14.11, i8* %arrayidx70.11, align 1
  %scevgep20.15.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 15
  %14193 = load i8, i8* %scevgep20.15.11, align 1
  %conv68.15.11 = zext i8 %14193 to i32
  %14194 = load i8, i8* %arrayidx70.11, align 1
  %conv71.15.11 = zext i8 %14194 to i32
  %xor72.15.11 = xor i32 %conv71.15.11, %conv68.15.11
  %conv73.15.11 = trunc i32 %xor72.15.11 to i8
  store i8 %conv73.15.11, i8* %arrayidx70.11, align 1
  %scevgep20.16.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 16
  %14195 = load i8, i8* %scevgep20.16.11, align 1
  %conv68.16.11 = zext i8 %14195 to i32
  %14196 = load i8, i8* %arrayidx70.11, align 1
  %conv71.16.11 = zext i8 %14196 to i32
  %xor72.16.11 = xor i32 %conv71.16.11, %conv68.16.11
  %conv73.16.11 = trunc i32 %xor72.16.11 to i8
  store i8 %conv73.16.11, i8* %arrayidx70.11, align 1
  %scevgep20.17.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 17
  %14197 = load i8, i8* %scevgep20.17.11, align 1
  %conv68.17.11 = zext i8 %14197 to i32
  %14198 = load i8, i8* %arrayidx70.11, align 1
  %conv71.17.11 = zext i8 %14198 to i32
  %xor72.17.11 = xor i32 %conv71.17.11, %conv68.17.11
  %conv73.17.11 = trunc i32 %xor72.17.11 to i8
  store i8 %conv73.17.11, i8* %arrayidx70.11, align 1
  %scevgep20.18.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 18
  %14199 = load i8, i8* %scevgep20.18.11, align 1
  %conv68.18.11 = zext i8 %14199 to i32
  %14200 = load i8, i8* %arrayidx70.11, align 1
  %conv71.18.11 = zext i8 %14200 to i32
  %xor72.18.11 = xor i32 %conv71.18.11, %conv68.18.11
  %conv73.18.11 = trunc i32 %xor72.18.11 to i8
  store i8 %conv73.18.11, i8* %arrayidx70.11, align 1
  %scevgep20.19.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 19
  %14201 = load i8, i8* %scevgep20.19.11, align 1
  %conv68.19.11 = zext i8 %14201 to i32
  %14202 = load i8, i8* %arrayidx70.11, align 1
  %conv71.19.11 = zext i8 %14202 to i32
  %xor72.19.11 = xor i32 %conv71.19.11, %conv68.19.11
  %conv73.19.11 = trunc i32 %xor72.19.11 to i8
  store i8 %conv73.19.11, i8* %arrayidx70.11, align 1
  %scevgep20.20.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 20
  %14203 = load i8, i8* %scevgep20.20.11, align 1
  %conv68.20.11 = zext i8 %14203 to i32
  %14204 = load i8, i8* %arrayidx70.11, align 1
  %conv71.20.11 = zext i8 %14204 to i32
  %xor72.20.11 = xor i32 %conv71.20.11, %conv68.20.11
  %conv73.20.11 = trunc i32 %xor72.20.11 to i8
  store i8 %conv73.20.11, i8* %arrayidx70.11, align 1
  %scevgep20.21.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 21
  %14205 = load i8, i8* %scevgep20.21.11, align 1
  %conv68.21.11 = zext i8 %14205 to i32
  %14206 = load i8, i8* %arrayidx70.11, align 1
  %conv71.21.11 = zext i8 %14206 to i32
  %xor72.21.11 = xor i32 %conv71.21.11, %conv68.21.11
  %conv73.21.11 = trunc i32 %xor72.21.11 to i8
  store i8 %conv73.21.11, i8* %arrayidx70.11, align 1
  %scevgep20.22.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 22
  %14207 = load i8, i8* %scevgep20.22.11, align 1
  %conv68.22.11 = zext i8 %14207 to i32
  %14208 = load i8, i8* %arrayidx70.11, align 1
  %conv71.22.11 = zext i8 %14208 to i32
  %xor72.22.11 = xor i32 %conv71.22.11, %conv68.22.11
  %conv73.22.11 = trunc i32 %xor72.22.11 to i8
  store i8 %conv73.22.11, i8* %arrayidx70.11, align 1
  %scevgep20.23.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 23
  %14209 = load i8, i8* %scevgep20.23.11, align 1
  %conv68.23.11 = zext i8 %14209 to i32
  %14210 = load i8, i8* %arrayidx70.11, align 1
  %conv71.23.11 = zext i8 %14210 to i32
  %xor72.23.11 = xor i32 %conv71.23.11, %conv68.23.11
  %conv73.23.11 = trunc i32 %xor72.23.11 to i8
  store i8 %conv73.23.11, i8* %arrayidx70.11, align 1
  %scevgep20.24.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 24
  %14211 = load i8, i8* %scevgep20.24.11, align 1
  %conv68.24.11 = zext i8 %14211 to i32
  %14212 = load i8, i8* %arrayidx70.11, align 1
  %conv71.24.11 = zext i8 %14212 to i32
  %xor72.24.11 = xor i32 %conv71.24.11, %conv68.24.11
  %conv73.24.11 = trunc i32 %xor72.24.11 to i8
  store i8 %conv73.24.11, i8* %arrayidx70.11, align 1
  %scevgep20.25.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 25
  %14213 = load i8, i8* %scevgep20.25.11, align 1
  %conv68.25.11 = zext i8 %14213 to i32
  %14214 = load i8, i8* %arrayidx70.11, align 1
  %conv71.25.11 = zext i8 %14214 to i32
  %xor72.25.11 = xor i32 %conv71.25.11, %conv68.25.11
  %conv73.25.11 = trunc i32 %xor72.25.11 to i8
  store i8 %conv73.25.11, i8* %arrayidx70.11, align 1
  %scevgep20.26.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 26
  %14215 = load i8, i8* %scevgep20.26.11, align 1
  %conv68.26.11 = zext i8 %14215 to i32
  %14216 = load i8, i8* %arrayidx70.11, align 1
  %conv71.26.11 = zext i8 %14216 to i32
  %xor72.26.11 = xor i32 %conv71.26.11, %conv68.26.11
  %conv73.26.11 = trunc i32 %xor72.26.11 to i8
  store i8 %conv73.26.11, i8* %arrayidx70.11, align 1
  %scevgep20.27.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 27
  %14217 = load i8, i8* %scevgep20.27.11, align 1
  %conv68.27.11 = zext i8 %14217 to i32
  %14218 = load i8, i8* %arrayidx70.11, align 1
  %conv71.27.11 = zext i8 %14218 to i32
  %xor72.27.11 = xor i32 %conv71.27.11, %conv68.27.11
  %conv73.27.11 = trunc i32 %xor72.27.11 to i8
  store i8 %conv73.27.11, i8* %arrayidx70.11, align 1
  %scevgep20.28.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 28
  %14219 = load i8, i8* %scevgep20.28.11, align 1
  %conv68.28.11 = zext i8 %14219 to i32
  %14220 = load i8, i8* %arrayidx70.11, align 1
  %conv71.28.11 = zext i8 %14220 to i32
  %xor72.28.11 = xor i32 %conv71.28.11, %conv68.28.11
  %conv73.28.11 = trunc i32 %xor72.28.11 to i8
  store i8 %conv73.28.11, i8* %arrayidx70.11, align 1
  %scevgep20.29.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 29
  %14221 = load i8, i8* %scevgep20.29.11, align 1
  %conv68.29.11 = zext i8 %14221 to i32
  %14222 = load i8, i8* %arrayidx70.11, align 1
  %conv71.29.11 = zext i8 %14222 to i32
  %xor72.29.11 = xor i32 %conv71.29.11, %conv68.29.11
  %conv73.29.11 = trunc i32 %xor72.29.11 to i8
  store i8 %conv73.29.11, i8* %arrayidx70.11, align 1
  %scevgep20.30.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 30
  %14223 = load i8, i8* %scevgep20.30.11, align 1
  %conv68.30.11 = zext i8 %14223 to i32
  %14224 = load i8, i8* %arrayidx70.11, align 1
  %conv71.30.11 = zext i8 %14224 to i32
  %xor72.30.11 = xor i32 %conv71.30.11, %conv68.30.11
  %conv73.30.11 = trunc i32 %xor72.30.11 to i8
  store i8 %conv73.30.11, i8* %arrayidx70.11, align 1
  %scevgep20.31.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 31
  %14225 = load i8, i8* %scevgep20.31.11, align 1
  %conv68.31.11 = zext i8 %14225 to i32
  %14226 = load i8, i8* %arrayidx70.11, align 1
  %conv71.31.11 = zext i8 %14226 to i32
  %xor72.31.11 = xor i32 %conv71.31.11, %conv68.31.11
  %conv73.31.11 = trunc i32 %xor72.31.11 to i8
  store i8 %conv73.31.11, i8* %arrayidx70.11, align 1
  %scevgep20.32.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 32
  %14227 = load i8, i8* %scevgep20.32.11, align 1
  %conv68.32.11 = zext i8 %14227 to i32
  %14228 = load i8, i8* %arrayidx70.11, align 1
  %conv71.32.11 = zext i8 %14228 to i32
  %xor72.32.11 = xor i32 %conv71.32.11, %conv68.32.11
  %conv73.32.11 = trunc i32 %xor72.32.11 to i8
  store i8 %conv73.32.11, i8* %arrayidx70.11, align 1
  %scevgep20.33.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 33
  %14229 = load i8, i8* %scevgep20.33.11, align 1
  %conv68.33.11 = zext i8 %14229 to i32
  %14230 = load i8, i8* %arrayidx70.11, align 1
  %conv71.33.11 = zext i8 %14230 to i32
  %xor72.33.11 = xor i32 %conv71.33.11, %conv68.33.11
  %conv73.33.11 = trunc i32 %xor72.33.11 to i8
  store i8 %conv73.33.11, i8* %arrayidx70.11, align 1
  %scevgep20.34.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 34
  %14231 = load i8, i8* %scevgep20.34.11, align 1
  %conv68.34.11 = zext i8 %14231 to i32
  %14232 = load i8, i8* %arrayidx70.11, align 1
  %conv71.34.11 = zext i8 %14232 to i32
  %xor72.34.11 = xor i32 %conv71.34.11, %conv68.34.11
  %conv73.34.11 = trunc i32 %xor72.34.11 to i8
  store i8 %conv73.34.11, i8* %arrayidx70.11, align 1
  %scevgep20.35.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 35
  %14233 = load i8, i8* %scevgep20.35.11, align 1
  %conv68.35.11 = zext i8 %14233 to i32
  %14234 = load i8, i8* %arrayidx70.11, align 1
  %conv71.35.11 = zext i8 %14234 to i32
  %xor72.35.11 = xor i32 %conv71.35.11, %conv68.35.11
  %conv73.35.11 = trunc i32 %xor72.35.11 to i8
  store i8 %conv73.35.11, i8* %arrayidx70.11, align 1
  %scevgep20.36.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 36
  %14235 = load i8, i8* %scevgep20.36.11, align 1
  %conv68.36.11 = zext i8 %14235 to i32
  %14236 = load i8, i8* %arrayidx70.11, align 1
  %conv71.36.11 = zext i8 %14236 to i32
  %xor72.36.11 = xor i32 %conv71.36.11, %conv68.36.11
  %conv73.36.11 = trunc i32 %xor72.36.11 to i8
  store i8 %conv73.36.11, i8* %arrayidx70.11, align 1
  %scevgep20.37.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 37
  %14237 = load i8, i8* %scevgep20.37.11, align 1
  %conv68.37.11 = zext i8 %14237 to i32
  %14238 = load i8, i8* %arrayidx70.11, align 1
  %conv71.37.11 = zext i8 %14238 to i32
  %xor72.37.11 = xor i32 %conv71.37.11, %conv68.37.11
  %conv73.37.11 = trunc i32 %xor72.37.11 to i8
  store i8 %conv73.37.11, i8* %arrayidx70.11, align 1
  %scevgep20.38.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 38
  %14239 = load i8, i8* %scevgep20.38.11, align 1
  %conv68.38.11 = zext i8 %14239 to i32
  %14240 = load i8, i8* %arrayidx70.11, align 1
  %conv71.38.11 = zext i8 %14240 to i32
  %xor72.38.11 = xor i32 %conv71.38.11, %conv68.38.11
  %conv73.38.11 = trunc i32 %xor72.38.11 to i8
  store i8 %conv73.38.11, i8* %arrayidx70.11, align 1
  %scevgep20.39.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 39
  %14241 = load i8, i8* %scevgep20.39.11, align 1
  %conv68.39.11 = zext i8 %14241 to i32
  %14242 = load i8, i8* %arrayidx70.11, align 1
  %conv71.39.11 = zext i8 %14242 to i32
  %xor72.39.11 = xor i32 %conv71.39.11, %conv68.39.11
  %conv73.39.11 = trunc i32 %xor72.39.11 to i8
  store i8 %conv73.39.11, i8* %arrayidx70.11, align 1
  %scevgep20.40.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 40
  %14243 = load i8, i8* %scevgep20.40.11, align 1
  %conv68.40.11 = zext i8 %14243 to i32
  %14244 = load i8, i8* %arrayidx70.11, align 1
  %conv71.40.11 = zext i8 %14244 to i32
  %xor72.40.11 = xor i32 %conv71.40.11, %conv68.40.11
  %conv73.40.11 = trunc i32 %xor72.40.11 to i8
  store i8 %conv73.40.11, i8* %arrayidx70.11, align 1
  %scevgep20.41.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 41
  %14245 = load i8, i8* %scevgep20.41.11, align 1
  %conv68.41.11 = zext i8 %14245 to i32
  %14246 = load i8, i8* %arrayidx70.11, align 1
  %conv71.41.11 = zext i8 %14246 to i32
  %xor72.41.11 = xor i32 %conv71.41.11, %conv68.41.11
  %conv73.41.11 = trunc i32 %xor72.41.11 to i8
  store i8 %conv73.41.11, i8* %arrayidx70.11, align 1
  %scevgep20.42.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 42
  %14247 = load i8, i8* %scevgep20.42.11, align 1
  %conv68.42.11 = zext i8 %14247 to i32
  %14248 = load i8, i8* %arrayidx70.11, align 1
  %conv71.42.11 = zext i8 %14248 to i32
  %xor72.42.11 = xor i32 %conv71.42.11, %conv68.42.11
  %conv73.42.11 = trunc i32 %xor72.42.11 to i8
  store i8 %conv73.42.11, i8* %arrayidx70.11, align 1
  %scevgep20.43.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 43
  %14249 = load i8, i8* %scevgep20.43.11, align 1
  %conv68.43.11 = zext i8 %14249 to i32
  %14250 = load i8, i8* %arrayidx70.11, align 1
  %conv71.43.11 = zext i8 %14250 to i32
  %xor72.43.11 = xor i32 %conv71.43.11, %conv68.43.11
  %conv73.43.11 = trunc i32 %xor72.43.11 to i8
  store i8 %conv73.43.11, i8* %arrayidx70.11, align 1
  %scevgep20.44.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 44
  %14251 = load i8, i8* %scevgep20.44.11, align 1
  %conv68.44.11 = zext i8 %14251 to i32
  %14252 = load i8, i8* %arrayidx70.11, align 1
  %conv71.44.11 = zext i8 %14252 to i32
  %xor72.44.11 = xor i32 %conv71.44.11, %conv68.44.11
  %conv73.44.11 = trunc i32 %xor72.44.11 to i8
  store i8 %conv73.44.11, i8* %arrayidx70.11, align 1
  %scevgep20.45.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 45
  %14253 = load i8, i8* %scevgep20.45.11, align 1
  %conv68.45.11 = zext i8 %14253 to i32
  %14254 = load i8, i8* %arrayidx70.11, align 1
  %conv71.45.11 = zext i8 %14254 to i32
  %xor72.45.11 = xor i32 %conv71.45.11, %conv68.45.11
  %conv73.45.11 = trunc i32 %xor72.45.11 to i8
  store i8 %conv73.45.11, i8* %arrayidx70.11, align 1
  %scevgep20.46.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 46
  %14255 = load i8, i8* %scevgep20.46.11, align 1
  %conv68.46.11 = zext i8 %14255 to i32
  %14256 = load i8, i8* %arrayidx70.11, align 1
  %conv71.46.11 = zext i8 %14256 to i32
  %xor72.46.11 = xor i32 %conv71.46.11, %conv68.46.11
  %conv73.46.11 = trunc i32 %xor72.46.11 to i8
  store i8 %conv73.46.11, i8* %arrayidx70.11, align 1
  %scevgep20.47.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 47
  %14257 = load i8, i8* %scevgep20.47.11, align 1
  %conv68.47.11 = zext i8 %14257 to i32
  %14258 = load i8, i8* %arrayidx70.11, align 1
  %conv71.47.11 = zext i8 %14258 to i32
  %xor72.47.11 = xor i32 %conv71.47.11, %conv68.47.11
  %conv73.47.11 = trunc i32 %xor72.47.11 to i8
  store i8 %conv73.47.11, i8* %arrayidx70.11, align 1
  %scevgep20.48.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 48
  %14259 = load i8, i8* %scevgep20.48.11, align 1
  %conv68.48.11 = zext i8 %14259 to i32
  %14260 = load i8, i8* %arrayidx70.11, align 1
  %conv71.48.11 = zext i8 %14260 to i32
  %xor72.48.11 = xor i32 %conv71.48.11, %conv68.48.11
  %conv73.48.11 = trunc i32 %xor72.48.11 to i8
  store i8 %conv73.48.11, i8* %arrayidx70.11, align 1
  %scevgep20.49.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 49
  %14261 = load i8, i8* %scevgep20.49.11, align 1
  %conv68.49.11 = zext i8 %14261 to i32
  %14262 = load i8, i8* %arrayidx70.11, align 1
  %conv71.49.11 = zext i8 %14262 to i32
  %xor72.49.11 = xor i32 %conv71.49.11, %conv68.49.11
  %conv73.49.11 = trunc i32 %xor72.49.11 to i8
  store i8 %conv73.49.11, i8* %arrayidx70.11, align 1
  %scevgep20.50.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 50
  %14263 = load i8, i8* %scevgep20.50.11, align 1
  %conv68.50.11 = zext i8 %14263 to i32
  %14264 = load i8, i8* %arrayidx70.11, align 1
  %conv71.50.11 = zext i8 %14264 to i32
  %xor72.50.11 = xor i32 %conv71.50.11, %conv68.50.11
  %conv73.50.11 = trunc i32 %xor72.50.11 to i8
  store i8 %conv73.50.11, i8* %arrayidx70.11, align 1
  %scevgep20.51.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 51
  %14265 = load i8, i8* %scevgep20.51.11, align 1
  %conv68.51.11 = zext i8 %14265 to i32
  %14266 = load i8, i8* %arrayidx70.11, align 1
  %conv71.51.11 = zext i8 %14266 to i32
  %xor72.51.11 = xor i32 %conv71.51.11, %conv68.51.11
  %conv73.51.11 = trunc i32 %xor72.51.11 to i8
  store i8 %conv73.51.11, i8* %arrayidx70.11, align 1
  %scevgep20.52.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 52
  %14267 = load i8, i8* %scevgep20.52.11, align 1
  %conv68.52.11 = zext i8 %14267 to i32
  %14268 = load i8, i8* %arrayidx70.11, align 1
  %conv71.52.11 = zext i8 %14268 to i32
  %xor72.52.11 = xor i32 %conv71.52.11, %conv68.52.11
  %conv73.52.11 = trunc i32 %xor72.52.11 to i8
  store i8 %conv73.52.11, i8* %arrayidx70.11, align 1
  %scevgep20.53.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 53
  %14269 = load i8, i8* %scevgep20.53.11, align 1
  %conv68.53.11 = zext i8 %14269 to i32
  %14270 = load i8, i8* %arrayidx70.11, align 1
  %conv71.53.11 = zext i8 %14270 to i32
  %xor72.53.11 = xor i32 %conv71.53.11, %conv68.53.11
  %conv73.53.11 = trunc i32 %xor72.53.11 to i8
  store i8 %conv73.53.11, i8* %arrayidx70.11, align 1
  %scevgep20.54.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 54
  %14271 = load i8, i8* %scevgep20.54.11, align 1
  %conv68.54.11 = zext i8 %14271 to i32
  %14272 = load i8, i8* %arrayidx70.11, align 1
  %conv71.54.11 = zext i8 %14272 to i32
  %xor72.54.11 = xor i32 %conv71.54.11, %conv68.54.11
  %conv73.54.11 = trunc i32 %xor72.54.11 to i8
  store i8 %conv73.54.11, i8* %arrayidx70.11, align 1
  %scevgep20.55.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 55
  %14273 = load i8, i8* %scevgep20.55.11, align 1
  %conv68.55.11 = zext i8 %14273 to i32
  %14274 = load i8, i8* %arrayidx70.11, align 1
  %conv71.55.11 = zext i8 %14274 to i32
  %xor72.55.11 = xor i32 %conv71.55.11, %conv68.55.11
  %conv73.55.11 = trunc i32 %xor72.55.11 to i8
  store i8 %conv73.55.11, i8* %arrayidx70.11, align 1
  %scevgep20.56.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 56
  %14275 = load i8, i8* %scevgep20.56.11, align 1
  %conv68.56.11 = zext i8 %14275 to i32
  %14276 = load i8, i8* %arrayidx70.11, align 1
  %conv71.56.11 = zext i8 %14276 to i32
  %xor72.56.11 = xor i32 %conv71.56.11, %conv68.56.11
  %conv73.56.11 = trunc i32 %xor72.56.11 to i8
  store i8 %conv73.56.11, i8* %arrayidx70.11, align 1
  %scevgep20.57.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 57
  %14277 = load i8, i8* %scevgep20.57.11, align 1
  %conv68.57.11 = zext i8 %14277 to i32
  %14278 = load i8, i8* %arrayidx70.11, align 1
  %conv71.57.11 = zext i8 %14278 to i32
  %xor72.57.11 = xor i32 %conv71.57.11, %conv68.57.11
  %conv73.57.11 = trunc i32 %xor72.57.11 to i8
  store i8 %conv73.57.11, i8* %arrayidx70.11, align 1
  %scevgep20.58.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 58
  %14279 = load i8, i8* %scevgep20.58.11, align 1
  %conv68.58.11 = zext i8 %14279 to i32
  %14280 = load i8, i8* %arrayidx70.11, align 1
  %conv71.58.11 = zext i8 %14280 to i32
  %xor72.58.11 = xor i32 %conv71.58.11, %conv68.58.11
  %conv73.58.11 = trunc i32 %xor72.58.11 to i8
  store i8 %conv73.58.11, i8* %arrayidx70.11, align 1
  %scevgep20.59.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 59
  %14281 = load i8, i8* %scevgep20.59.11, align 1
  %conv68.59.11 = zext i8 %14281 to i32
  %14282 = load i8, i8* %arrayidx70.11, align 1
  %conv71.59.11 = zext i8 %14282 to i32
  %xor72.59.11 = xor i32 %conv71.59.11, %conv68.59.11
  %conv73.59.11 = trunc i32 %xor72.59.11 to i8
  store i8 %conv73.59.11, i8* %arrayidx70.11, align 1
  %scevgep20.60.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 0, i64 60
  %14283 = load i8, i8* %scevgep20.60.11, align 1
  %conv68.60.11 = zext i8 %14283 to i32
  %14284 = load i8, i8* %arrayidx70.11, align 1
  %conv71.60.11 = zext i8 %14284 to i32
  %xor72.60.11 = xor i32 %conv71.60.11, %conv68.60.11
  %conv73.60.11 = trunc i32 %xor72.60.11 to i8
  store i8 %conv73.60.11, i8* %arrayidx70.11, align 1
  %scevgep19.11 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14162, i64 0, i64 1, i64 0
  %14285 = bitcast i8* %scevgep19.11 to [61 x [61 x i8]]*
  %arrayidx51.12 = getelementptr inbounds i8, i8* %a, i64 12
  %14286 = load i8, i8* %arrayidx51.12, align 1
  %arrayidx53.12 = getelementptr inbounds i8, i8* %b, i64 12
  %14287 = load i8, i8* %arrayidx53.12, align 1
  %call54.12 = call zeroext i8 @mult(i8 zeroext %14286, i8 zeroext %14287)
  %arrayidx56.12 = getelementptr inbounds i8, i8* %c, i64 12
  store i8 %call54.12, i8* %arrayidx56.12, align 1
  %arrayidx70.12 = getelementptr inbounds i8, i8* %c, i64 12
  %scevgep20.12164 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 0
  %14288 = load i8, i8* %scevgep20.12164, align 1
  %conv68.12165 = zext i8 %14288 to i32
  %14289 = load i8, i8* %arrayidx70.12, align 1
  %conv71.12166 = zext i8 %14289 to i32
  %xor72.12167 = xor i32 %conv71.12166, %conv68.12165
  %conv73.12168 = trunc i32 %xor72.12167 to i8
  store i8 %conv73.12168, i8* %arrayidx70.12, align 1
  %scevgep20.1.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 1
  %14290 = load i8, i8* %scevgep20.1.12, align 1
  %conv68.1.12 = zext i8 %14290 to i32
  %14291 = load i8, i8* %arrayidx70.12, align 1
  %conv71.1.12 = zext i8 %14291 to i32
  %xor72.1.12 = xor i32 %conv71.1.12, %conv68.1.12
  %conv73.1.12 = trunc i32 %xor72.1.12 to i8
  store i8 %conv73.1.12, i8* %arrayidx70.12, align 1
  %scevgep20.2.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 2
  %14292 = load i8, i8* %scevgep20.2.12, align 1
  %conv68.2.12 = zext i8 %14292 to i32
  %14293 = load i8, i8* %arrayidx70.12, align 1
  %conv71.2.12 = zext i8 %14293 to i32
  %xor72.2.12 = xor i32 %conv71.2.12, %conv68.2.12
  %conv73.2.12 = trunc i32 %xor72.2.12 to i8
  store i8 %conv73.2.12, i8* %arrayidx70.12, align 1
  %scevgep20.3.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 3
  %14294 = load i8, i8* %scevgep20.3.12, align 1
  %conv68.3.12 = zext i8 %14294 to i32
  %14295 = load i8, i8* %arrayidx70.12, align 1
  %conv71.3.12 = zext i8 %14295 to i32
  %xor72.3.12 = xor i32 %conv71.3.12, %conv68.3.12
  %conv73.3.12 = trunc i32 %xor72.3.12 to i8
  store i8 %conv73.3.12, i8* %arrayidx70.12, align 1
  %scevgep20.4.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 4
  %14296 = load i8, i8* %scevgep20.4.12, align 1
  %conv68.4.12 = zext i8 %14296 to i32
  %14297 = load i8, i8* %arrayidx70.12, align 1
  %conv71.4.12 = zext i8 %14297 to i32
  %xor72.4.12 = xor i32 %conv71.4.12, %conv68.4.12
  %conv73.4.12 = trunc i32 %xor72.4.12 to i8
  store i8 %conv73.4.12, i8* %arrayidx70.12, align 1
  %scevgep20.5.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 5
  %14298 = load i8, i8* %scevgep20.5.12, align 1
  %conv68.5.12 = zext i8 %14298 to i32
  %14299 = load i8, i8* %arrayidx70.12, align 1
  %conv71.5.12 = zext i8 %14299 to i32
  %xor72.5.12 = xor i32 %conv71.5.12, %conv68.5.12
  %conv73.5.12 = trunc i32 %xor72.5.12 to i8
  store i8 %conv73.5.12, i8* %arrayidx70.12, align 1
  %scevgep20.6.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 6
  %14300 = load i8, i8* %scevgep20.6.12, align 1
  %conv68.6.12 = zext i8 %14300 to i32
  %14301 = load i8, i8* %arrayidx70.12, align 1
  %conv71.6.12 = zext i8 %14301 to i32
  %xor72.6.12 = xor i32 %conv71.6.12, %conv68.6.12
  %conv73.6.12 = trunc i32 %xor72.6.12 to i8
  store i8 %conv73.6.12, i8* %arrayidx70.12, align 1
  %scevgep20.7.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 7
  %14302 = load i8, i8* %scevgep20.7.12, align 1
  %conv68.7.12 = zext i8 %14302 to i32
  %14303 = load i8, i8* %arrayidx70.12, align 1
  %conv71.7.12 = zext i8 %14303 to i32
  %xor72.7.12 = xor i32 %conv71.7.12, %conv68.7.12
  %conv73.7.12 = trunc i32 %xor72.7.12 to i8
  store i8 %conv73.7.12, i8* %arrayidx70.12, align 1
  %scevgep20.8.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 8
  %14304 = load i8, i8* %scevgep20.8.12, align 1
  %conv68.8.12 = zext i8 %14304 to i32
  %14305 = load i8, i8* %arrayidx70.12, align 1
  %conv71.8.12 = zext i8 %14305 to i32
  %xor72.8.12 = xor i32 %conv71.8.12, %conv68.8.12
  %conv73.8.12 = trunc i32 %xor72.8.12 to i8
  store i8 %conv73.8.12, i8* %arrayidx70.12, align 1
  %scevgep20.9.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 9
  %14306 = load i8, i8* %scevgep20.9.12, align 1
  %conv68.9.12 = zext i8 %14306 to i32
  %14307 = load i8, i8* %arrayidx70.12, align 1
  %conv71.9.12 = zext i8 %14307 to i32
  %xor72.9.12 = xor i32 %conv71.9.12, %conv68.9.12
  %conv73.9.12 = trunc i32 %xor72.9.12 to i8
  store i8 %conv73.9.12, i8* %arrayidx70.12, align 1
  %scevgep20.10.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 10
  %14308 = load i8, i8* %scevgep20.10.12, align 1
  %conv68.10.12 = zext i8 %14308 to i32
  %14309 = load i8, i8* %arrayidx70.12, align 1
  %conv71.10.12 = zext i8 %14309 to i32
  %xor72.10.12 = xor i32 %conv71.10.12, %conv68.10.12
  %conv73.10.12 = trunc i32 %xor72.10.12 to i8
  store i8 %conv73.10.12, i8* %arrayidx70.12, align 1
  %scevgep20.11.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 11
  %14310 = load i8, i8* %scevgep20.11.12, align 1
  %conv68.11.12 = zext i8 %14310 to i32
  %14311 = load i8, i8* %arrayidx70.12, align 1
  %conv71.11.12 = zext i8 %14311 to i32
  %xor72.11.12 = xor i32 %conv71.11.12, %conv68.11.12
  %conv73.11.12 = trunc i32 %xor72.11.12 to i8
  store i8 %conv73.11.12, i8* %arrayidx70.12, align 1
  %scevgep20.13.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 13
  %14312 = load i8, i8* %scevgep20.13.12, align 1
  %conv68.13.12 = zext i8 %14312 to i32
  %14313 = load i8, i8* %arrayidx70.12, align 1
  %conv71.13.12 = zext i8 %14313 to i32
  %xor72.13.12 = xor i32 %conv71.13.12, %conv68.13.12
  %conv73.13.12 = trunc i32 %xor72.13.12 to i8
  store i8 %conv73.13.12, i8* %arrayidx70.12, align 1
  %scevgep20.14.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 14
  %14314 = load i8, i8* %scevgep20.14.12, align 1
  %conv68.14.12 = zext i8 %14314 to i32
  %14315 = load i8, i8* %arrayidx70.12, align 1
  %conv71.14.12 = zext i8 %14315 to i32
  %xor72.14.12 = xor i32 %conv71.14.12, %conv68.14.12
  %conv73.14.12 = trunc i32 %xor72.14.12 to i8
  store i8 %conv73.14.12, i8* %arrayidx70.12, align 1
  %scevgep20.15.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 15
  %14316 = load i8, i8* %scevgep20.15.12, align 1
  %conv68.15.12 = zext i8 %14316 to i32
  %14317 = load i8, i8* %arrayidx70.12, align 1
  %conv71.15.12 = zext i8 %14317 to i32
  %xor72.15.12 = xor i32 %conv71.15.12, %conv68.15.12
  %conv73.15.12 = trunc i32 %xor72.15.12 to i8
  store i8 %conv73.15.12, i8* %arrayidx70.12, align 1
  %scevgep20.16.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 16
  %14318 = load i8, i8* %scevgep20.16.12, align 1
  %conv68.16.12 = zext i8 %14318 to i32
  %14319 = load i8, i8* %arrayidx70.12, align 1
  %conv71.16.12 = zext i8 %14319 to i32
  %xor72.16.12 = xor i32 %conv71.16.12, %conv68.16.12
  %conv73.16.12 = trunc i32 %xor72.16.12 to i8
  store i8 %conv73.16.12, i8* %arrayidx70.12, align 1
  %scevgep20.17.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 17
  %14320 = load i8, i8* %scevgep20.17.12, align 1
  %conv68.17.12 = zext i8 %14320 to i32
  %14321 = load i8, i8* %arrayidx70.12, align 1
  %conv71.17.12 = zext i8 %14321 to i32
  %xor72.17.12 = xor i32 %conv71.17.12, %conv68.17.12
  %conv73.17.12 = trunc i32 %xor72.17.12 to i8
  store i8 %conv73.17.12, i8* %arrayidx70.12, align 1
  %scevgep20.18.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 18
  %14322 = load i8, i8* %scevgep20.18.12, align 1
  %conv68.18.12 = zext i8 %14322 to i32
  %14323 = load i8, i8* %arrayidx70.12, align 1
  %conv71.18.12 = zext i8 %14323 to i32
  %xor72.18.12 = xor i32 %conv71.18.12, %conv68.18.12
  %conv73.18.12 = trunc i32 %xor72.18.12 to i8
  store i8 %conv73.18.12, i8* %arrayidx70.12, align 1
  %scevgep20.19.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 19
  %14324 = load i8, i8* %scevgep20.19.12, align 1
  %conv68.19.12 = zext i8 %14324 to i32
  %14325 = load i8, i8* %arrayidx70.12, align 1
  %conv71.19.12 = zext i8 %14325 to i32
  %xor72.19.12 = xor i32 %conv71.19.12, %conv68.19.12
  %conv73.19.12 = trunc i32 %xor72.19.12 to i8
  store i8 %conv73.19.12, i8* %arrayidx70.12, align 1
  %scevgep20.20.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 20
  %14326 = load i8, i8* %scevgep20.20.12, align 1
  %conv68.20.12 = zext i8 %14326 to i32
  %14327 = load i8, i8* %arrayidx70.12, align 1
  %conv71.20.12 = zext i8 %14327 to i32
  %xor72.20.12 = xor i32 %conv71.20.12, %conv68.20.12
  %conv73.20.12 = trunc i32 %xor72.20.12 to i8
  store i8 %conv73.20.12, i8* %arrayidx70.12, align 1
  %scevgep20.21.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 21
  %14328 = load i8, i8* %scevgep20.21.12, align 1
  %conv68.21.12 = zext i8 %14328 to i32
  %14329 = load i8, i8* %arrayidx70.12, align 1
  %conv71.21.12 = zext i8 %14329 to i32
  %xor72.21.12 = xor i32 %conv71.21.12, %conv68.21.12
  %conv73.21.12 = trunc i32 %xor72.21.12 to i8
  store i8 %conv73.21.12, i8* %arrayidx70.12, align 1
  %scevgep20.22.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 22
  %14330 = load i8, i8* %scevgep20.22.12, align 1
  %conv68.22.12 = zext i8 %14330 to i32
  %14331 = load i8, i8* %arrayidx70.12, align 1
  %conv71.22.12 = zext i8 %14331 to i32
  %xor72.22.12 = xor i32 %conv71.22.12, %conv68.22.12
  %conv73.22.12 = trunc i32 %xor72.22.12 to i8
  store i8 %conv73.22.12, i8* %arrayidx70.12, align 1
  %scevgep20.23.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 23
  %14332 = load i8, i8* %scevgep20.23.12, align 1
  %conv68.23.12 = zext i8 %14332 to i32
  %14333 = load i8, i8* %arrayidx70.12, align 1
  %conv71.23.12 = zext i8 %14333 to i32
  %xor72.23.12 = xor i32 %conv71.23.12, %conv68.23.12
  %conv73.23.12 = trunc i32 %xor72.23.12 to i8
  store i8 %conv73.23.12, i8* %arrayidx70.12, align 1
  %scevgep20.24.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 24
  %14334 = load i8, i8* %scevgep20.24.12, align 1
  %conv68.24.12 = zext i8 %14334 to i32
  %14335 = load i8, i8* %arrayidx70.12, align 1
  %conv71.24.12 = zext i8 %14335 to i32
  %xor72.24.12 = xor i32 %conv71.24.12, %conv68.24.12
  %conv73.24.12 = trunc i32 %xor72.24.12 to i8
  store i8 %conv73.24.12, i8* %arrayidx70.12, align 1
  %scevgep20.25.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 25
  %14336 = load i8, i8* %scevgep20.25.12, align 1
  %conv68.25.12 = zext i8 %14336 to i32
  %14337 = load i8, i8* %arrayidx70.12, align 1
  %conv71.25.12 = zext i8 %14337 to i32
  %xor72.25.12 = xor i32 %conv71.25.12, %conv68.25.12
  %conv73.25.12 = trunc i32 %xor72.25.12 to i8
  store i8 %conv73.25.12, i8* %arrayidx70.12, align 1
  %scevgep20.26.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 26
  %14338 = load i8, i8* %scevgep20.26.12, align 1
  %conv68.26.12 = zext i8 %14338 to i32
  %14339 = load i8, i8* %arrayidx70.12, align 1
  %conv71.26.12 = zext i8 %14339 to i32
  %xor72.26.12 = xor i32 %conv71.26.12, %conv68.26.12
  %conv73.26.12 = trunc i32 %xor72.26.12 to i8
  store i8 %conv73.26.12, i8* %arrayidx70.12, align 1
  %scevgep20.27.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 27
  %14340 = load i8, i8* %scevgep20.27.12, align 1
  %conv68.27.12 = zext i8 %14340 to i32
  %14341 = load i8, i8* %arrayidx70.12, align 1
  %conv71.27.12 = zext i8 %14341 to i32
  %xor72.27.12 = xor i32 %conv71.27.12, %conv68.27.12
  %conv73.27.12 = trunc i32 %xor72.27.12 to i8
  store i8 %conv73.27.12, i8* %arrayidx70.12, align 1
  %scevgep20.28.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 28
  %14342 = load i8, i8* %scevgep20.28.12, align 1
  %conv68.28.12 = zext i8 %14342 to i32
  %14343 = load i8, i8* %arrayidx70.12, align 1
  %conv71.28.12 = zext i8 %14343 to i32
  %xor72.28.12 = xor i32 %conv71.28.12, %conv68.28.12
  %conv73.28.12 = trunc i32 %xor72.28.12 to i8
  store i8 %conv73.28.12, i8* %arrayidx70.12, align 1
  %scevgep20.29.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 29
  %14344 = load i8, i8* %scevgep20.29.12, align 1
  %conv68.29.12 = zext i8 %14344 to i32
  %14345 = load i8, i8* %arrayidx70.12, align 1
  %conv71.29.12 = zext i8 %14345 to i32
  %xor72.29.12 = xor i32 %conv71.29.12, %conv68.29.12
  %conv73.29.12 = trunc i32 %xor72.29.12 to i8
  store i8 %conv73.29.12, i8* %arrayidx70.12, align 1
  %scevgep20.30.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 30
  %14346 = load i8, i8* %scevgep20.30.12, align 1
  %conv68.30.12 = zext i8 %14346 to i32
  %14347 = load i8, i8* %arrayidx70.12, align 1
  %conv71.30.12 = zext i8 %14347 to i32
  %xor72.30.12 = xor i32 %conv71.30.12, %conv68.30.12
  %conv73.30.12 = trunc i32 %xor72.30.12 to i8
  store i8 %conv73.30.12, i8* %arrayidx70.12, align 1
  %scevgep20.31.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 31
  %14348 = load i8, i8* %scevgep20.31.12, align 1
  %conv68.31.12 = zext i8 %14348 to i32
  %14349 = load i8, i8* %arrayidx70.12, align 1
  %conv71.31.12 = zext i8 %14349 to i32
  %xor72.31.12 = xor i32 %conv71.31.12, %conv68.31.12
  %conv73.31.12 = trunc i32 %xor72.31.12 to i8
  store i8 %conv73.31.12, i8* %arrayidx70.12, align 1
  %scevgep20.32.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 32
  %14350 = load i8, i8* %scevgep20.32.12, align 1
  %conv68.32.12 = zext i8 %14350 to i32
  %14351 = load i8, i8* %arrayidx70.12, align 1
  %conv71.32.12 = zext i8 %14351 to i32
  %xor72.32.12 = xor i32 %conv71.32.12, %conv68.32.12
  %conv73.32.12 = trunc i32 %xor72.32.12 to i8
  store i8 %conv73.32.12, i8* %arrayidx70.12, align 1
  %scevgep20.33.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 33
  %14352 = load i8, i8* %scevgep20.33.12, align 1
  %conv68.33.12 = zext i8 %14352 to i32
  %14353 = load i8, i8* %arrayidx70.12, align 1
  %conv71.33.12 = zext i8 %14353 to i32
  %xor72.33.12 = xor i32 %conv71.33.12, %conv68.33.12
  %conv73.33.12 = trunc i32 %xor72.33.12 to i8
  store i8 %conv73.33.12, i8* %arrayidx70.12, align 1
  %scevgep20.34.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 34
  %14354 = load i8, i8* %scevgep20.34.12, align 1
  %conv68.34.12 = zext i8 %14354 to i32
  %14355 = load i8, i8* %arrayidx70.12, align 1
  %conv71.34.12 = zext i8 %14355 to i32
  %xor72.34.12 = xor i32 %conv71.34.12, %conv68.34.12
  %conv73.34.12 = trunc i32 %xor72.34.12 to i8
  store i8 %conv73.34.12, i8* %arrayidx70.12, align 1
  %scevgep20.35.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 35
  %14356 = load i8, i8* %scevgep20.35.12, align 1
  %conv68.35.12 = zext i8 %14356 to i32
  %14357 = load i8, i8* %arrayidx70.12, align 1
  %conv71.35.12 = zext i8 %14357 to i32
  %xor72.35.12 = xor i32 %conv71.35.12, %conv68.35.12
  %conv73.35.12 = trunc i32 %xor72.35.12 to i8
  store i8 %conv73.35.12, i8* %arrayidx70.12, align 1
  %scevgep20.36.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 36
  %14358 = load i8, i8* %scevgep20.36.12, align 1
  %conv68.36.12 = zext i8 %14358 to i32
  %14359 = load i8, i8* %arrayidx70.12, align 1
  %conv71.36.12 = zext i8 %14359 to i32
  %xor72.36.12 = xor i32 %conv71.36.12, %conv68.36.12
  %conv73.36.12 = trunc i32 %xor72.36.12 to i8
  store i8 %conv73.36.12, i8* %arrayidx70.12, align 1
  %scevgep20.37.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 37
  %14360 = load i8, i8* %scevgep20.37.12, align 1
  %conv68.37.12 = zext i8 %14360 to i32
  %14361 = load i8, i8* %arrayidx70.12, align 1
  %conv71.37.12 = zext i8 %14361 to i32
  %xor72.37.12 = xor i32 %conv71.37.12, %conv68.37.12
  %conv73.37.12 = trunc i32 %xor72.37.12 to i8
  store i8 %conv73.37.12, i8* %arrayidx70.12, align 1
  %scevgep20.38.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 38
  %14362 = load i8, i8* %scevgep20.38.12, align 1
  %conv68.38.12 = zext i8 %14362 to i32
  %14363 = load i8, i8* %arrayidx70.12, align 1
  %conv71.38.12 = zext i8 %14363 to i32
  %xor72.38.12 = xor i32 %conv71.38.12, %conv68.38.12
  %conv73.38.12 = trunc i32 %xor72.38.12 to i8
  store i8 %conv73.38.12, i8* %arrayidx70.12, align 1
  %scevgep20.39.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 39
  %14364 = load i8, i8* %scevgep20.39.12, align 1
  %conv68.39.12 = zext i8 %14364 to i32
  %14365 = load i8, i8* %arrayidx70.12, align 1
  %conv71.39.12 = zext i8 %14365 to i32
  %xor72.39.12 = xor i32 %conv71.39.12, %conv68.39.12
  %conv73.39.12 = trunc i32 %xor72.39.12 to i8
  store i8 %conv73.39.12, i8* %arrayidx70.12, align 1
  %scevgep20.40.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 40
  %14366 = load i8, i8* %scevgep20.40.12, align 1
  %conv68.40.12 = zext i8 %14366 to i32
  %14367 = load i8, i8* %arrayidx70.12, align 1
  %conv71.40.12 = zext i8 %14367 to i32
  %xor72.40.12 = xor i32 %conv71.40.12, %conv68.40.12
  %conv73.40.12 = trunc i32 %xor72.40.12 to i8
  store i8 %conv73.40.12, i8* %arrayidx70.12, align 1
  %scevgep20.41.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 41
  %14368 = load i8, i8* %scevgep20.41.12, align 1
  %conv68.41.12 = zext i8 %14368 to i32
  %14369 = load i8, i8* %arrayidx70.12, align 1
  %conv71.41.12 = zext i8 %14369 to i32
  %xor72.41.12 = xor i32 %conv71.41.12, %conv68.41.12
  %conv73.41.12 = trunc i32 %xor72.41.12 to i8
  store i8 %conv73.41.12, i8* %arrayidx70.12, align 1
  %scevgep20.42.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 42
  %14370 = load i8, i8* %scevgep20.42.12, align 1
  %conv68.42.12 = zext i8 %14370 to i32
  %14371 = load i8, i8* %arrayidx70.12, align 1
  %conv71.42.12 = zext i8 %14371 to i32
  %xor72.42.12 = xor i32 %conv71.42.12, %conv68.42.12
  %conv73.42.12 = trunc i32 %xor72.42.12 to i8
  store i8 %conv73.42.12, i8* %arrayidx70.12, align 1
  %scevgep20.43.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 43
  %14372 = load i8, i8* %scevgep20.43.12, align 1
  %conv68.43.12 = zext i8 %14372 to i32
  %14373 = load i8, i8* %arrayidx70.12, align 1
  %conv71.43.12 = zext i8 %14373 to i32
  %xor72.43.12 = xor i32 %conv71.43.12, %conv68.43.12
  %conv73.43.12 = trunc i32 %xor72.43.12 to i8
  store i8 %conv73.43.12, i8* %arrayidx70.12, align 1
  %scevgep20.44.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 44
  %14374 = load i8, i8* %scevgep20.44.12, align 1
  %conv68.44.12 = zext i8 %14374 to i32
  %14375 = load i8, i8* %arrayidx70.12, align 1
  %conv71.44.12 = zext i8 %14375 to i32
  %xor72.44.12 = xor i32 %conv71.44.12, %conv68.44.12
  %conv73.44.12 = trunc i32 %xor72.44.12 to i8
  store i8 %conv73.44.12, i8* %arrayidx70.12, align 1
  %scevgep20.45.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 45
  %14376 = load i8, i8* %scevgep20.45.12, align 1
  %conv68.45.12 = zext i8 %14376 to i32
  %14377 = load i8, i8* %arrayidx70.12, align 1
  %conv71.45.12 = zext i8 %14377 to i32
  %xor72.45.12 = xor i32 %conv71.45.12, %conv68.45.12
  %conv73.45.12 = trunc i32 %xor72.45.12 to i8
  store i8 %conv73.45.12, i8* %arrayidx70.12, align 1
  %scevgep20.46.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 46
  %14378 = load i8, i8* %scevgep20.46.12, align 1
  %conv68.46.12 = zext i8 %14378 to i32
  %14379 = load i8, i8* %arrayidx70.12, align 1
  %conv71.46.12 = zext i8 %14379 to i32
  %xor72.46.12 = xor i32 %conv71.46.12, %conv68.46.12
  %conv73.46.12 = trunc i32 %xor72.46.12 to i8
  store i8 %conv73.46.12, i8* %arrayidx70.12, align 1
  %scevgep20.47.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 47
  %14380 = load i8, i8* %scevgep20.47.12, align 1
  %conv68.47.12 = zext i8 %14380 to i32
  %14381 = load i8, i8* %arrayidx70.12, align 1
  %conv71.47.12 = zext i8 %14381 to i32
  %xor72.47.12 = xor i32 %conv71.47.12, %conv68.47.12
  %conv73.47.12 = trunc i32 %xor72.47.12 to i8
  store i8 %conv73.47.12, i8* %arrayidx70.12, align 1
  %scevgep20.48.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 48
  %14382 = load i8, i8* %scevgep20.48.12, align 1
  %conv68.48.12 = zext i8 %14382 to i32
  %14383 = load i8, i8* %arrayidx70.12, align 1
  %conv71.48.12 = zext i8 %14383 to i32
  %xor72.48.12 = xor i32 %conv71.48.12, %conv68.48.12
  %conv73.48.12 = trunc i32 %xor72.48.12 to i8
  store i8 %conv73.48.12, i8* %arrayidx70.12, align 1
  %scevgep20.49.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 49
  %14384 = load i8, i8* %scevgep20.49.12, align 1
  %conv68.49.12 = zext i8 %14384 to i32
  %14385 = load i8, i8* %arrayidx70.12, align 1
  %conv71.49.12 = zext i8 %14385 to i32
  %xor72.49.12 = xor i32 %conv71.49.12, %conv68.49.12
  %conv73.49.12 = trunc i32 %xor72.49.12 to i8
  store i8 %conv73.49.12, i8* %arrayidx70.12, align 1
  %scevgep20.50.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 50
  %14386 = load i8, i8* %scevgep20.50.12, align 1
  %conv68.50.12 = zext i8 %14386 to i32
  %14387 = load i8, i8* %arrayidx70.12, align 1
  %conv71.50.12 = zext i8 %14387 to i32
  %xor72.50.12 = xor i32 %conv71.50.12, %conv68.50.12
  %conv73.50.12 = trunc i32 %xor72.50.12 to i8
  store i8 %conv73.50.12, i8* %arrayidx70.12, align 1
  %scevgep20.51.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 51
  %14388 = load i8, i8* %scevgep20.51.12, align 1
  %conv68.51.12 = zext i8 %14388 to i32
  %14389 = load i8, i8* %arrayidx70.12, align 1
  %conv71.51.12 = zext i8 %14389 to i32
  %xor72.51.12 = xor i32 %conv71.51.12, %conv68.51.12
  %conv73.51.12 = trunc i32 %xor72.51.12 to i8
  store i8 %conv73.51.12, i8* %arrayidx70.12, align 1
  %scevgep20.52.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 52
  %14390 = load i8, i8* %scevgep20.52.12, align 1
  %conv68.52.12 = zext i8 %14390 to i32
  %14391 = load i8, i8* %arrayidx70.12, align 1
  %conv71.52.12 = zext i8 %14391 to i32
  %xor72.52.12 = xor i32 %conv71.52.12, %conv68.52.12
  %conv73.52.12 = trunc i32 %xor72.52.12 to i8
  store i8 %conv73.52.12, i8* %arrayidx70.12, align 1
  %scevgep20.53.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 53
  %14392 = load i8, i8* %scevgep20.53.12, align 1
  %conv68.53.12 = zext i8 %14392 to i32
  %14393 = load i8, i8* %arrayidx70.12, align 1
  %conv71.53.12 = zext i8 %14393 to i32
  %xor72.53.12 = xor i32 %conv71.53.12, %conv68.53.12
  %conv73.53.12 = trunc i32 %xor72.53.12 to i8
  store i8 %conv73.53.12, i8* %arrayidx70.12, align 1
  %scevgep20.54.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 54
  %14394 = load i8, i8* %scevgep20.54.12, align 1
  %conv68.54.12 = zext i8 %14394 to i32
  %14395 = load i8, i8* %arrayidx70.12, align 1
  %conv71.54.12 = zext i8 %14395 to i32
  %xor72.54.12 = xor i32 %conv71.54.12, %conv68.54.12
  %conv73.54.12 = trunc i32 %xor72.54.12 to i8
  store i8 %conv73.54.12, i8* %arrayidx70.12, align 1
  %scevgep20.55.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 55
  %14396 = load i8, i8* %scevgep20.55.12, align 1
  %conv68.55.12 = zext i8 %14396 to i32
  %14397 = load i8, i8* %arrayidx70.12, align 1
  %conv71.55.12 = zext i8 %14397 to i32
  %xor72.55.12 = xor i32 %conv71.55.12, %conv68.55.12
  %conv73.55.12 = trunc i32 %xor72.55.12 to i8
  store i8 %conv73.55.12, i8* %arrayidx70.12, align 1
  %scevgep20.56.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 56
  %14398 = load i8, i8* %scevgep20.56.12, align 1
  %conv68.56.12 = zext i8 %14398 to i32
  %14399 = load i8, i8* %arrayidx70.12, align 1
  %conv71.56.12 = zext i8 %14399 to i32
  %xor72.56.12 = xor i32 %conv71.56.12, %conv68.56.12
  %conv73.56.12 = trunc i32 %xor72.56.12 to i8
  store i8 %conv73.56.12, i8* %arrayidx70.12, align 1
  %scevgep20.57.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 57
  %14400 = load i8, i8* %scevgep20.57.12, align 1
  %conv68.57.12 = zext i8 %14400 to i32
  %14401 = load i8, i8* %arrayidx70.12, align 1
  %conv71.57.12 = zext i8 %14401 to i32
  %xor72.57.12 = xor i32 %conv71.57.12, %conv68.57.12
  %conv73.57.12 = trunc i32 %xor72.57.12 to i8
  store i8 %conv73.57.12, i8* %arrayidx70.12, align 1
  %scevgep20.58.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 58
  %14402 = load i8, i8* %scevgep20.58.12, align 1
  %conv68.58.12 = zext i8 %14402 to i32
  %14403 = load i8, i8* %arrayidx70.12, align 1
  %conv71.58.12 = zext i8 %14403 to i32
  %xor72.58.12 = xor i32 %conv71.58.12, %conv68.58.12
  %conv73.58.12 = trunc i32 %xor72.58.12 to i8
  store i8 %conv73.58.12, i8* %arrayidx70.12, align 1
  %scevgep20.59.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 59
  %14404 = load i8, i8* %scevgep20.59.12, align 1
  %conv68.59.12 = zext i8 %14404 to i32
  %14405 = load i8, i8* %arrayidx70.12, align 1
  %conv71.59.12 = zext i8 %14405 to i32
  %xor72.59.12 = xor i32 %conv71.59.12, %conv68.59.12
  %conv73.59.12 = trunc i32 %xor72.59.12 to i8
  store i8 %conv73.59.12, i8* %arrayidx70.12, align 1
  %scevgep20.60.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 0, i64 60
  %14406 = load i8, i8* %scevgep20.60.12, align 1
  %conv68.60.12 = zext i8 %14406 to i32
  %14407 = load i8, i8* %arrayidx70.12, align 1
  %conv71.60.12 = zext i8 %14407 to i32
  %xor72.60.12 = xor i32 %conv71.60.12, %conv68.60.12
  %conv73.60.12 = trunc i32 %xor72.60.12 to i8
  store i8 %conv73.60.12, i8* %arrayidx70.12, align 1
  %scevgep19.12 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14285, i64 0, i64 1, i64 0
  %14408 = bitcast i8* %scevgep19.12 to [61 x [61 x i8]]*
  %arrayidx51.13 = getelementptr inbounds i8, i8* %a, i64 13
  %14409 = load i8, i8* %arrayidx51.13, align 1
  %arrayidx53.13 = getelementptr inbounds i8, i8* %b, i64 13
  %14410 = load i8, i8* %arrayidx53.13, align 1
  %call54.13 = call zeroext i8 @mult(i8 zeroext %14409, i8 zeroext %14410)
  %arrayidx56.13 = getelementptr inbounds i8, i8* %c, i64 13
  store i8 %call54.13, i8* %arrayidx56.13, align 1
  %arrayidx70.13 = getelementptr inbounds i8, i8* %c, i64 13
  %scevgep20.13174 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 0
  %14411 = load i8, i8* %scevgep20.13174, align 1
  %conv68.13175 = zext i8 %14411 to i32
  %14412 = load i8, i8* %arrayidx70.13, align 1
  %conv71.13176 = zext i8 %14412 to i32
  %xor72.13177 = xor i32 %conv71.13176, %conv68.13175
  %conv73.13178 = trunc i32 %xor72.13177 to i8
  store i8 %conv73.13178, i8* %arrayidx70.13, align 1
  %scevgep20.1.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 1
  %14413 = load i8, i8* %scevgep20.1.13, align 1
  %conv68.1.13 = zext i8 %14413 to i32
  %14414 = load i8, i8* %arrayidx70.13, align 1
  %conv71.1.13 = zext i8 %14414 to i32
  %xor72.1.13 = xor i32 %conv71.1.13, %conv68.1.13
  %conv73.1.13 = trunc i32 %xor72.1.13 to i8
  store i8 %conv73.1.13, i8* %arrayidx70.13, align 1
  %scevgep20.2.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 2
  %14415 = load i8, i8* %scevgep20.2.13, align 1
  %conv68.2.13 = zext i8 %14415 to i32
  %14416 = load i8, i8* %arrayidx70.13, align 1
  %conv71.2.13 = zext i8 %14416 to i32
  %xor72.2.13 = xor i32 %conv71.2.13, %conv68.2.13
  %conv73.2.13 = trunc i32 %xor72.2.13 to i8
  store i8 %conv73.2.13, i8* %arrayidx70.13, align 1
  %scevgep20.3.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 3
  %14417 = load i8, i8* %scevgep20.3.13, align 1
  %conv68.3.13 = zext i8 %14417 to i32
  %14418 = load i8, i8* %arrayidx70.13, align 1
  %conv71.3.13 = zext i8 %14418 to i32
  %xor72.3.13 = xor i32 %conv71.3.13, %conv68.3.13
  %conv73.3.13 = trunc i32 %xor72.3.13 to i8
  store i8 %conv73.3.13, i8* %arrayidx70.13, align 1
  %scevgep20.4.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 4
  %14419 = load i8, i8* %scevgep20.4.13, align 1
  %conv68.4.13 = zext i8 %14419 to i32
  %14420 = load i8, i8* %arrayidx70.13, align 1
  %conv71.4.13 = zext i8 %14420 to i32
  %xor72.4.13 = xor i32 %conv71.4.13, %conv68.4.13
  %conv73.4.13 = trunc i32 %xor72.4.13 to i8
  store i8 %conv73.4.13, i8* %arrayidx70.13, align 1
  %scevgep20.5.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 5
  %14421 = load i8, i8* %scevgep20.5.13, align 1
  %conv68.5.13 = zext i8 %14421 to i32
  %14422 = load i8, i8* %arrayidx70.13, align 1
  %conv71.5.13 = zext i8 %14422 to i32
  %xor72.5.13 = xor i32 %conv71.5.13, %conv68.5.13
  %conv73.5.13 = trunc i32 %xor72.5.13 to i8
  store i8 %conv73.5.13, i8* %arrayidx70.13, align 1
  %scevgep20.6.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 6
  %14423 = load i8, i8* %scevgep20.6.13, align 1
  %conv68.6.13 = zext i8 %14423 to i32
  %14424 = load i8, i8* %arrayidx70.13, align 1
  %conv71.6.13 = zext i8 %14424 to i32
  %xor72.6.13 = xor i32 %conv71.6.13, %conv68.6.13
  %conv73.6.13 = trunc i32 %xor72.6.13 to i8
  store i8 %conv73.6.13, i8* %arrayidx70.13, align 1
  %scevgep20.7.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 7
  %14425 = load i8, i8* %scevgep20.7.13, align 1
  %conv68.7.13 = zext i8 %14425 to i32
  %14426 = load i8, i8* %arrayidx70.13, align 1
  %conv71.7.13 = zext i8 %14426 to i32
  %xor72.7.13 = xor i32 %conv71.7.13, %conv68.7.13
  %conv73.7.13 = trunc i32 %xor72.7.13 to i8
  store i8 %conv73.7.13, i8* %arrayidx70.13, align 1
  %scevgep20.8.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 8
  %14427 = load i8, i8* %scevgep20.8.13, align 1
  %conv68.8.13 = zext i8 %14427 to i32
  %14428 = load i8, i8* %arrayidx70.13, align 1
  %conv71.8.13 = zext i8 %14428 to i32
  %xor72.8.13 = xor i32 %conv71.8.13, %conv68.8.13
  %conv73.8.13 = trunc i32 %xor72.8.13 to i8
  store i8 %conv73.8.13, i8* %arrayidx70.13, align 1
  %scevgep20.9.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 9
  %14429 = load i8, i8* %scevgep20.9.13, align 1
  %conv68.9.13 = zext i8 %14429 to i32
  %14430 = load i8, i8* %arrayidx70.13, align 1
  %conv71.9.13 = zext i8 %14430 to i32
  %xor72.9.13 = xor i32 %conv71.9.13, %conv68.9.13
  %conv73.9.13 = trunc i32 %xor72.9.13 to i8
  store i8 %conv73.9.13, i8* %arrayidx70.13, align 1
  %scevgep20.10.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 10
  %14431 = load i8, i8* %scevgep20.10.13, align 1
  %conv68.10.13 = zext i8 %14431 to i32
  %14432 = load i8, i8* %arrayidx70.13, align 1
  %conv71.10.13 = zext i8 %14432 to i32
  %xor72.10.13 = xor i32 %conv71.10.13, %conv68.10.13
  %conv73.10.13 = trunc i32 %xor72.10.13 to i8
  store i8 %conv73.10.13, i8* %arrayidx70.13, align 1
  %scevgep20.11.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 11
  %14433 = load i8, i8* %scevgep20.11.13, align 1
  %conv68.11.13 = zext i8 %14433 to i32
  %14434 = load i8, i8* %arrayidx70.13, align 1
  %conv71.11.13 = zext i8 %14434 to i32
  %xor72.11.13 = xor i32 %conv71.11.13, %conv68.11.13
  %conv73.11.13 = trunc i32 %xor72.11.13 to i8
  store i8 %conv73.11.13, i8* %arrayidx70.13, align 1
  %scevgep20.12.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 12
  %14435 = load i8, i8* %scevgep20.12.13, align 1
  %conv68.12.13 = zext i8 %14435 to i32
  %14436 = load i8, i8* %arrayidx70.13, align 1
  %conv71.12.13 = zext i8 %14436 to i32
  %xor72.12.13 = xor i32 %conv71.12.13, %conv68.12.13
  %conv73.12.13 = trunc i32 %xor72.12.13 to i8
  store i8 %conv73.12.13, i8* %arrayidx70.13, align 1
  %scevgep20.14.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 14
  %14437 = load i8, i8* %scevgep20.14.13, align 1
  %conv68.14.13 = zext i8 %14437 to i32
  %14438 = load i8, i8* %arrayidx70.13, align 1
  %conv71.14.13 = zext i8 %14438 to i32
  %xor72.14.13 = xor i32 %conv71.14.13, %conv68.14.13
  %conv73.14.13 = trunc i32 %xor72.14.13 to i8
  store i8 %conv73.14.13, i8* %arrayidx70.13, align 1
  %scevgep20.15.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 15
  %14439 = load i8, i8* %scevgep20.15.13, align 1
  %conv68.15.13 = zext i8 %14439 to i32
  %14440 = load i8, i8* %arrayidx70.13, align 1
  %conv71.15.13 = zext i8 %14440 to i32
  %xor72.15.13 = xor i32 %conv71.15.13, %conv68.15.13
  %conv73.15.13 = trunc i32 %xor72.15.13 to i8
  store i8 %conv73.15.13, i8* %arrayidx70.13, align 1
  %scevgep20.16.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 16
  %14441 = load i8, i8* %scevgep20.16.13, align 1
  %conv68.16.13 = zext i8 %14441 to i32
  %14442 = load i8, i8* %arrayidx70.13, align 1
  %conv71.16.13 = zext i8 %14442 to i32
  %xor72.16.13 = xor i32 %conv71.16.13, %conv68.16.13
  %conv73.16.13 = trunc i32 %xor72.16.13 to i8
  store i8 %conv73.16.13, i8* %arrayidx70.13, align 1
  %scevgep20.17.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 17
  %14443 = load i8, i8* %scevgep20.17.13, align 1
  %conv68.17.13 = zext i8 %14443 to i32
  %14444 = load i8, i8* %arrayidx70.13, align 1
  %conv71.17.13 = zext i8 %14444 to i32
  %xor72.17.13 = xor i32 %conv71.17.13, %conv68.17.13
  %conv73.17.13 = trunc i32 %xor72.17.13 to i8
  store i8 %conv73.17.13, i8* %arrayidx70.13, align 1
  %scevgep20.18.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 18
  %14445 = load i8, i8* %scevgep20.18.13, align 1
  %conv68.18.13 = zext i8 %14445 to i32
  %14446 = load i8, i8* %arrayidx70.13, align 1
  %conv71.18.13 = zext i8 %14446 to i32
  %xor72.18.13 = xor i32 %conv71.18.13, %conv68.18.13
  %conv73.18.13 = trunc i32 %xor72.18.13 to i8
  store i8 %conv73.18.13, i8* %arrayidx70.13, align 1
  %scevgep20.19.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 19
  %14447 = load i8, i8* %scevgep20.19.13, align 1
  %conv68.19.13 = zext i8 %14447 to i32
  %14448 = load i8, i8* %arrayidx70.13, align 1
  %conv71.19.13 = zext i8 %14448 to i32
  %xor72.19.13 = xor i32 %conv71.19.13, %conv68.19.13
  %conv73.19.13 = trunc i32 %xor72.19.13 to i8
  store i8 %conv73.19.13, i8* %arrayidx70.13, align 1
  %scevgep20.20.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 20
  %14449 = load i8, i8* %scevgep20.20.13, align 1
  %conv68.20.13 = zext i8 %14449 to i32
  %14450 = load i8, i8* %arrayidx70.13, align 1
  %conv71.20.13 = zext i8 %14450 to i32
  %xor72.20.13 = xor i32 %conv71.20.13, %conv68.20.13
  %conv73.20.13 = trunc i32 %xor72.20.13 to i8
  store i8 %conv73.20.13, i8* %arrayidx70.13, align 1
  %scevgep20.21.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 21
  %14451 = load i8, i8* %scevgep20.21.13, align 1
  %conv68.21.13 = zext i8 %14451 to i32
  %14452 = load i8, i8* %arrayidx70.13, align 1
  %conv71.21.13 = zext i8 %14452 to i32
  %xor72.21.13 = xor i32 %conv71.21.13, %conv68.21.13
  %conv73.21.13 = trunc i32 %xor72.21.13 to i8
  store i8 %conv73.21.13, i8* %arrayidx70.13, align 1
  %scevgep20.22.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 22
  %14453 = load i8, i8* %scevgep20.22.13, align 1
  %conv68.22.13 = zext i8 %14453 to i32
  %14454 = load i8, i8* %arrayidx70.13, align 1
  %conv71.22.13 = zext i8 %14454 to i32
  %xor72.22.13 = xor i32 %conv71.22.13, %conv68.22.13
  %conv73.22.13 = trunc i32 %xor72.22.13 to i8
  store i8 %conv73.22.13, i8* %arrayidx70.13, align 1
  %scevgep20.23.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 23
  %14455 = load i8, i8* %scevgep20.23.13, align 1
  %conv68.23.13 = zext i8 %14455 to i32
  %14456 = load i8, i8* %arrayidx70.13, align 1
  %conv71.23.13 = zext i8 %14456 to i32
  %xor72.23.13 = xor i32 %conv71.23.13, %conv68.23.13
  %conv73.23.13 = trunc i32 %xor72.23.13 to i8
  store i8 %conv73.23.13, i8* %arrayidx70.13, align 1
  %scevgep20.24.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 24
  %14457 = load i8, i8* %scevgep20.24.13, align 1
  %conv68.24.13 = zext i8 %14457 to i32
  %14458 = load i8, i8* %arrayidx70.13, align 1
  %conv71.24.13 = zext i8 %14458 to i32
  %xor72.24.13 = xor i32 %conv71.24.13, %conv68.24.13
  %conv73.24.13 = trunc i32 %xor72.24.13 to i8
  store i8 %conv73.24.13, i8* %arrayidx70.13, align 1
  %scevgep20.25.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 25
  %14459 = load i8, i8* %scevgep20.25.13, align 1
  %conv68.25.13 = zext i8 %14459 to i32
  %14460 = load i8, i8* %arrayidx70.13, align 1
  %conv71.25.13 = zext i8 %14460 to i32
  %xor72.25.13 = xor i32 %conv71.25.13, %conv68.25.13
  %conv73.25.13 = trunc i32 %xor72.25.13 to i8
  store i8 %conv73.25.13, i8* %arrayidx70.13, align 1
  %scevgep20.26.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 26
  %14461 = load i8, i8* %scevgep20.26.13, align 1
  %conv68.26.13 = zext i8 %14461 to i32
  %14462 = load i8, i8* %arrayidx70.13, align 1
  %conv71.26.13 = zext i8 %14462 to i32
  %xor72.26.13 = xor i32 %conv71.26.13, %conv68.26.13
  %conv73.26.13 = trunc i32 %xor72.26.13 to i8
  store i8 %conv73.26.13, i8* %arrayidx70.13, align 1
  %scevgep20.27.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 27
  %14463 = load i8, i8* %scevgep20.27.13, align 1
  %conv68.27.13 = zext i8 %14463 to i32
  %14464 = load i8, i8* %arrayidx70.13, align 1
  %conv71.27.13 = zext i8 %14464 to i32
  %xor72.27.13 = xor i32 %conv71.27.13, %conv68.27.13
  %conv73.27.13 = trunc i32 %xor72.27.13 to i8
  store i8 %conv73.27.13, i8* %arrayidx70.13, align 1
  %scevgep20.28.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 28
  %14465 = load i8, i8* %scevgep20.28.13, align 1
  %conv68.28.13 = zext i8 %14465 to i32
  %14466 = load i8, i8* %arrayidx70.13, align 1
  %conv71.28.13 = zext i8 %14466 to i32
  %xor72.28.13 = xor i32 %conv71.28.13, %conv68.28.13
  %conv73.28.13 = trunc i32 %xor72.28.13 to i8
  store i8 %conv73.28.13, i8* %arrayidx70.13, align 1
  %scevgep20.29.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 29
  %14467 = load i8, i8* %scevgep20.29.13, align 1
  %conv68.29.13 = zext i8 %14467 to i32
  %14468 = load i8, i8* %arrayidx70.13, align 1
  %conv71.29.13 = zext i8 %14468 to i32
  %xor72.29.13 = xor i32 %conv71.29.13, %conv68.29.13
  %conv73.29.13 = trunc i32 %xor72.29.13 to i8
  store i8 %conv73.29.13, i8* %arrayidx70.13, align 1
  %scevgep20.30.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 30
  %14469 = load i8, i8* %scevgep20.30.13, align 1
  %conv68.30.13 = zext i8 %14469 to i32
  %14470 = load i8, i8* %arrayidx70.13, align 1
  %conv71.30.13 = zext i8 %14470 to i32
  %xor72.30.13 = xor i32 %conv71.30.13, %conv68.30.13
  %conv73.30.13 = trunc i32 %xor72.30.13 to i8
  store i8 %conv73.30.13, i8* %arrayidx70.13, align 1
  %scevgep20.31.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 31
  %14471 = load i8, i8* %scevgep20.31.13, align 1
  %conv68.31.13 = zext i8 %14471 to i32
  %14472 = load i8, i8* %arrayidx70.13, align 1
  %conv71.31.13 = zext i8 %14472 to i32
  %xor72.31.13 = xor i32 %conv71.31.13, %conv68.31.13
  %conv73.31.13 = trunc i32 %xor72.31.13 to i8
  store i8 %conv73.31.13, i8* %arrayidx70.13, align 1
  %scevgep20.32.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 32
  %14473 = load i8, i8* %scevgep20.32.13, align 1
  %conv68.32.13 = zext i8 %14473 to i32
  %14474 = load i8, i8* %arrayidx70.13, align 1
  %conv71.32.13 = zext i8 %14474 to i32
  %xor72.32.13 = xor i32 %conv71.32.13, %conv68.32.13
  %conv73.32.13 = trunc i32 %xor72.32.13 to i8
  store i8 %conv73.32.13, i8* %arrayidx70.13, align 1
  %scevgep20.33.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 33
  %14475 = load i8, i8* %scevgep20.33.13, align 1
  %conv68.33.13 = zext i8 %14475 to i32
  %14476 = load i8, i8* %arrayidx70.13, align 1
  %conv71.33.13 = zext i8 %14476 to i32
  %xor72.33.13 = xor i32 %conv71.33.13, %conv68.33.13
  %conv73.33.13 = trunc i32 %xor72.33.13 to i8
  store i8 %conv73.33.13, i8* %arrayidx70.13, align 1
  %scevgep20.34.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 34
  %14477 = load i8, i8* %scevgep20.34.13, align 1
  %conv68.34.13 = zext i8 %14477 to i32
  %14478 = load i8, i8* %arrayidx70.13, align 1
  %conv71.34.13 = zext i8 %14478 to i32
  %xor72.34.13 = xor i32 %conv71.34.13, %conv68.34.13
  %conv73.34.13 = trunc i32 %xor72.34.13 to i8
  store i8 %conv73.34.13, i8* %arrayidx70.13, align 1
  %scevgep20.35.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 35
  %14479 = load i8, i8* %scevgep20.35.13, align 1
  %conv68.35.13 = zext i8 %14479 to i32
  %14480 = load i8, i8* %arrayidx70.13, align 1
  %conv71.35.13 = zext i8 %14480 to i32
  %xor72.35.13 = xor i32 %conv71.35.13, %conv68.35.13
  %conv73.35.13 = trunc i32 %xor72.35.13 to i8
  store i8 %conv73.35.13, i8* %arrayidx70.13, align 1
  %scevgep20.36.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 36
  %14481 = load i8, i8* %scevgep20.36.13, align 1
  %conv68.36.13 = zext i8 %14481 to i32
  %14482 = load i8, i8* %arrayidx70.13, align 1
  %conv71.36.13 = zext i8 %14482 to i32
  %xor72.36.13 = xor i32 %conv71.36.13, %conv68.36.13
  %conv73.36.13 = trunc i32 %xor72.36.13 to i8
  store i8 %conv73.36.13, i8* %arrayidx70.13, align 1
  %scevgep20.37.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 37
  %14483 = load i8, i8* %scevgep20.37.13, align 1
  %conv68.37.13 = zext i8 %14483 to i32
  %14484 = load i8, i8* %arrayidx70.13, align 1
  %conv71.37.13 = zext i8 %14484 to i32
  %xor72.37.13 = xor i32 %conv71.37.13, %conv68.37.13
  %conv73.37.13 = trunc i32 %xor72.37.13 to i8
  store i8 %conv73.37.13, i8* %arrayidx70.13, align 1
  %scevgep20.38.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 38
  %14485 = load i8, i8* %scevgep20.38.13, align 1
  %conv68.38.13 = zext i8 %14485 to i32
  %14486 = load i8, i8* %arrayidx70.13, align 1
  %conv71.38.13 = zext i8 %14486 to i32
  %xor72.38.13 = xor i32 %conv71.38.13, %conv68.38.13
  %conv73.38.13 = trunc i32 %xor72.38.13 to i8
  store i8 %conv73.38.13, i8* %arrayidx70.13, align 1
  %scevgep20.39.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 39
  %14487 = load i8, i8* %scevgep20.39.13, align 1
  %conv68.39.13 = zext i8 %14487 to i32
  %14488 = load i8, i8* %arrayidx70.13, align 1
  %conv71.39.13 = zext i8 %14488 to i32
  %xor72.39.13 = xor i32 %conv71.39.13, %conv68.39.13
  %conv73.39.13 = trunc i32 %xor72.39.13 to i8
  store i8 %conv73.39.13, i8* %arrayidx70.13, align 1
  %scevgep20.40.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 40
  %14489 = load i8, i8* %scevgep20.40.13, align 1
  %conv68.40.13 = zext i8 %14489 to i32
  %14490 = load i8, i8* %arrayidx70.13, align 1
  %conv71.40.13 = zext i8 %14490 to i32
  %xor72.40.13 = xor i32 %conv71.40.13, %conv68.40.13
  %conv73.40.13 = trunc i32 %xor72.40.13 to i8
  store i8 %conv73.40.13, i8* %arrayidx70.13, align 1
  %scevgep20.41.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 41
  %14491 = load i8, i8* %scevgep20.41.13, align 1
  %conv68.41.13 = zext i8 %14491 to i32
  %14492 = load i8, i8* %arrayidx70.13, align 1
  %conv71.41.13 = zext i8 %14492 to i32
  %xor72.41.13 = xor i32 %conv71.41.13, %conv68.41.13
  %conv73.41.13 = trunc i32 %xor72.41.13 to i8
  store i8 %conv73.41.13, i8* %arrayidx70.13, align 1
  %scevgep20.42.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 42
  %14493 = load i8, i8* %scevgep20.42.13, align 1
  %conv68.42.13 = zext i8 %14493 to i32
  %14494 = load i8, i8* %arrayidx70.13, align 1
  %conv71.42.13 = zext i8 %14494 to i32
  %xor72.42.13 = xor i32 %conv71.42.13, %conv68.42.13
  %conv73.42.13 = trunc i32 %xor72.42.13 to i8
  store i8 %conv73.42.13, i8* %arrayidx70.13, align 1
  %scevgep20.43.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 43
  %14495 = load i8, i8* %scevgep20.43.13, align 1
  %conv68.43.13 = zext i8 %14495 to i32
  %14496 = load i8, i8* %arrayidx70.13, align 1
  %conv71.43.13 = zext i8 %14496 to i32
  %xor72.43.13 = xor i32 %conv71.43.13, %conv68.43.13
  %conv73.43.13 = trunc i32 %xor72.43.13 to i8
  store i8 %conv73.43.13, i8* %arrayidx70.13, align 1
  %scevgep20.44.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 44
  %14497 = load i8, i8* %scevgep20.44.13, align 1
  %conv68.44.13 = zext i8 %14497 to i32
  %14498 = load i8, i8* %arrayidx70.13, align 1
  %conv71.44.13 = zext i8 %14498 to i32
  %xor72.44.13 = xor i32 %conv71.44.13, %conv68.44.13
  %conv73.44.13 = trunc i32 %xor72.44.13 to i8
  store i8 %conv73.44.13, i8* %arrayidx70.13, align 1
  %scevgep20.45.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 45
  %14499 = load i8, i8* %scevgep20.45.13, align 1
  %conv68.45.13 = zext i8 %14499 to i32
  %14500 = load i8, i8* %arrayidx70.13, align 1
  %conv71.45.13 = zext i8 %14500 to i32
  %xor72.45.13 = xor i32 %conv71.45.13, %conv68.45.13
  %conv73.45.13 = trunc i32 %xor72.45.13 to i8
  store i8 %conv73.45.13, i8* %arrayidx70.13, align 1
  %scevgep20.46.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 46
  %14501 = load i8, i8* %scevgep20.46.13, align 1
  %conv68.46.13 = zext i8 %14501 to i32
  %14502 = load i8, i8* %arrayidx70.13, align 1
  %conv71.46.13 = zext i8 %14502 to i32
  %xor72.46.13 = xor i32 %conv71.46.13, %conv68.46.13
  %conv73.46.13 = trunc i32 %xor72.46.13 to i8
  store i8 %conv73.46.13, i8* %arrayidx70.13, align 1
  %scevgep20.47.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 47
  %14503 = load i8, i8* %scevgep20.47.13, align 1
  %conv68.47.13 = zext i8 %14503 to i32
  %14504 = load i8, i8* %arrayidx70.13, align 1
  %conv71.47.13 = zext i8 %14504 to i32
  %xor72.47.13 = xor i32 %conv71.47.13, %conv68.47.13
  %conv73.47.13 = trunc i32 %xor72.47.13 to i8
  store i8 %conv73.47.13, i8* %arrayidx70.13, align 1
  %scevgep20.48.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 48
  %14505 = load i8, i8* %scevgep20.48.13, align 1
  %conv68.48.13 = zext i8 %14505 to i32
  %14506 = load i8, i8* %arrayidx70.13, align 1
  %conv71.48.13 = zext i8 %14506 to i32
  %xor72.48.13 = xor i32 %conv71.48.13, %conv68.48.13
  %conv73.48.13 = trunc i32 %xor72.48.13 to i8
  store i8 %conv73.48.13, i8* %arrayidx70.13, align 1
  %scevgep20.49.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 49
  %14507 = load i8, i8* %scevgep20.49.13, align 1
  %conv68.49.13 = zext i8 %14507 to i32
  %14508 = load i8, i8* %arrayidx70.13, align 1
  %conv71.49.13 = zext i8 %14508 to i32
  %xor72.49.13 = xor i32 %conv71.49.13, %conv68.49.13
  %conv73.49.13 = trunc i32 %xor72.49.13 to i8
  store i8 %conv73.49.13, i8* %arrayidx70.13, align 1
  %scevgep20.50.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 50
  %14509 = load i8, i8* %scevgep20.50.13, align 1
  %conv68.50.13 = zext i8 %14509 to i32
  %14510 = load i8, i8* %arrayidx70.13, align 1
  %conv71.50.13 = zext i8 %14510 to i32
  %xor72.50.13 = xor i32 %conv71.50.13, %conv68.50.13
  %conv73.50.13 = trunc i32 %xor72.50.13 to i8
  store i8 %conv73.50.13, i8* %arrayidx70.13, align 1
  %scevgep20.51.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 51
  %14511 = load i8, i8* %scevgep20.51.13, align 1
  %conv68.51.13 = zext i8 %14511 to i32
  %14512 = load i8, i8* %arrayidx70.13, align 1
  %conv71.51.13 = zext i8 %14512 to i32
  %xor72.51.13 = xor i32 %conv71.51.13, %conv68.51.13
  %conv73.51.13 = trunc i32 %xor72.51.13 to i8
  store i8 %conv73.51.13, i8* %arrayidx70.13, align 1
  %scevgep20.52.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 52
  %14513 = load i8, i8* %scevgep20.52.13, align 1
  %conv68.52.13 = zext i8 %14513 to i32
  %14514 = load i8, i8* %arrayidx70.13, align 1
  %conv71.52.13 = zext i8 %14514 to i32
  %xor72.52.13 = xor i32 %conv71.52.13, %conv68.52.13
  %conv73.52.13 = trunc i32 %xor72.52.13 to i8
  store i8 %conv73.52.13, i8* %arrayidx70.13, align 1
  %scevgep20.53.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 53
  %14515 = load i8, i8* %scevgep20.53.13, align 1
  %conv68.53.13 = zext i8 %14515 to i32
  %14516 = load i8, i8* %arrayidx70.13, align 1
  %conv71.53.13 = zext i8 %14516 to i32
  %xor72.53.13 = xor i32 %conv71.53.13, %conv68.53.13
  %conv73.53.13 = trunc i32 %xor72.53.13 to i8
  store i8 %conv73.53.13, i8* %arrayidx70.13, align 1
  %scevgep20.54.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 54
  %14517 = load i8, i8* %scevgep20.54.13, align 1
  %conv68.54.13 = zext i8 %14517 to i32
  %14518 = load i8, i8* %arrayidx70.13, align 1
  %conv71.54.13 = zext i8 %14518 to i32
  %xor72.54.13 = xor i32 %conv71.54.13, %conv68.54.13
  %conv73.54.13 = trunc i32 %xor72.54.13 to i8
  store i8 %conv73.54.13, i8* %arrayidx70.13, align 1
  %scevgep20.55.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 55
  %14519 = load i8, i8* %scevgep20.55.13, align 1
  %conv68.55.13 = zext i8 %14519 to i32
  %14520 = load i8, i8* %arrayidx70.13, align 1
  %conv71.55.13 = zext i8 %14520 to i32
  %xor72.55.13 = xor i32 %conv71.55.13, %conv68.55.13
  %conv73.55.13 = trunc i32 %xor72.55.13 to i8
  store i8 %conv73.55.13, i8* %arrayidx70.13, align 1
  %scevgep20.56.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 56
  %14521 = load i8, i8* %scevgep20.56.13, align 1
  %conv68.56.13 = zext i8 %14521 to i32
  %14522 = load i8, i8* %arrayidx70.13, align 1
  %conv71.56.13 = zext i8 %14522 to i32
  %xor72.56.13 = xor i32 %conv71.56.13, %conv68.56.13
  %conv73.56.13 = trunc i32 %xor72.56.13 to i8
  store i8 %conv73.56.13, i8* %arrayidx70.13, align 1
  %scevgep20.57.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 57
  %14523 = load i8, i8* %scevgep20.57.13, align 1
  %conv68.57.13 = zext i8 %14523 to i32
  %14524 = load i8, i8* %arrayidx70.13, align 1
  %conv71.57.13 = zext i8 %14524 to i32
  %xor72.57.13 = xor i32 %conv71.57.13, %conv68.57.13
  %conv73.57.13 = trunc i32 %xor72.57.13 to i8
  store i8 %conv73.57.13, i8* %arrayidx70.13, align 1
  %scevgep20.58.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 58
  %14525 = load i8, i8* %scevgep20.58.13, align 1
  %conv68.58.13 = zext i8 %14525 to i32
  %14526 = load i8, i8* %arrayidx70.13, align 1
  %conv71.58.13 = zext i8 %14526 to i32
  %xor72.58.13 = xor i32 %conv71.58.13, %conv68.58.13
  %conv73.58.13 = trunc i32 %xor72.58.13 to i8
  store i8 %conv73.58.13, i8* %arrayidx70.13, align 1
  %scevgep20.59.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 59
  %14527 = load i8, i8* %scevgep20.59.13, align 1
  %conv68.59.13 = zext i8 %14527 to i32
  %14528 = load i8, i8* %arrayidx70.13, align 1
  %conv71.59.13 = zext i8 %14528 to i32
  %xor72.59.13 = xor i32 %conv71.59.13, %conv68.59.13
  %conv73.59.13 = trunc i32 %xor72.59.13 to i8
  store i8 %conv73.59.13, i8* %arrayidx70.13, align 1
  %scevgep20.60.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 0, i64 60
  %14529 = load i8, i8* %scevgep20.60.13, align 1
  %conv68.60.13 = zext i8 %14529 to i32
  %14530 = load i8, i8* %arrayidx70.13, align 1
  %conv71.60.13 = zext i8 %14530 to i32
  %xor72.60.13 = xor i32 %conv71.60.13, %conv68.60.13
  %conv73.60.13 = trunc i32 %xor72.60.13 to i8
  store i8 %conv73.60.13, i8* %arrayidx70.13, align 1
  %scevgep19.13 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14408, i64 0, i64 1, i64 0
  %14531 = bitcast i8* %scevgep19.13 to [61 x [61 x i8]]*
  %arrayidx51.14 = getelementptr inbounds i8, i8* %a, i64 14
  %14532 = load i8, i8* %arrayidx51.14, align 1
  %arrayidx53.14 = getelementptr inbounds i8, i8* %b, i64 14
  %14533 = load i8, i8* %arrayidx53.14, align 1
  %call54.14 = call zeroext i8 @mult(i8 zeroext %14532, i8 zeroext %14533)
  %arrayidx56.14 = getelementptr inbounds i8, i8* %c, i64 14
  store i8 %call54.14, i8* %arrayidx56.14, align 1
  %arrayidx70.14 = getelementptr inbounds i8, i8* %c, i64 14
  %scevgep20.14184 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 0
  %14534 = load i8, i8* %scevgep20.14184, align 1
  %conv68.14185 = zext i8 %14534 to i32
  %14535 = load i8, i8* %arrayidx70.14, align 1
  %conv71.14186 = zext i8 %14535 to i32
  %xor72.14187 = xor i32 %conv71.14186, %conv68.14185
  %conv73.14188 = trunc i32 %xor72.14187 to i8
  store i8 %conv73.14188, i8* %arrayidx70.14, align 1
  %scevgep20.1.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 1
  %14536 = load i8, i8* %scevgep20.1.14, align 1
  %conv68.1.14 = zext i8 %14536 to i32
  %14537 = load i8, i8* %arrayidx70.14, align 1
  %conv71.1.14 = zext i8 %14537 to i32
  %xor72.1.14 = xor i32 %conv71.1.14, %conv68.1.14
  %conv73.1.14 = trunc i32 %xor72.1.14 to i8
  store i8 %conv73.1.14, i8* %arrayidx70.14, align 1
  %scevgep20.2.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 2
  %14538 = load i8, i8* %scevgep20.2.14, align 1
  %conv68.2.14 = zext i8 %14538 to i32
  %14539 = load i8, i8* %arrayidx70.14, align 1
  %conv71.2.14 = zext i8 %14539 to i32
  %xor72.2.14 = xor i32 %conv71.2.14, %conv68.2.14
  %conv73.2.14 = trunc i32 %xor72.2.14 to i8
  store i8 %conv73.2.14, i8* %arrayidx70.14, align 1
  %scevgep20.3.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 3
  %14540 = load i8, i8* %scevgep20.3.14, align 1
  %conv68.3.14 = zext i8 %14540 to i32
  %14541 = load i8, i8* %arrayidx70.14, align 1
  %conv71.3.14 = zext i8 %14541 to i32
  %xor72.3.14 = xor i32 %conv71.3.14, %conv68.3.14
  %conv73.3.14 = trunc i32 %xor72.3.14 to i8
  store i8 %conv73.3.14, i8* %arrayidx70.14, align 1
  %scevgep20.4.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 4
  %14542 = load i8, i8* %scevgep20.4.14, align 1
  %conv68.4.14 = zext i8 %14542 to i32
  %14543 = load i8, i8* %arrayidx70.14, align 1
  %conv71.4.14 = zext i8 %14543 to i32
  %xor72.4.14 = xor i32 %conv71.4.14, %conv68.4.14
  %conv73.4.14 = trunc i32 %xor72.4.14 to i8
  store i8 %conv73.4.14, i8* %arrayidx70.14, align 1
  %scevgep20.5.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 5
  %14544 = load i8, i8* %scevgep20.5.14, align 1
  %conv68.5.14 = zext i8 %14544 to i32
  %14545 = load i8, i8* %arrayidx70.14, align 1
  %conv71.5.14 = zext i8 %14545 to i32
  %xor72.5.14 = xor i32 %conv71.5.14, %conv68.5.14
  %conv73.5.14 = trunc i32 %xor72.5.14 to i8
  store i8 %conv73.5.14, i8* %arrayidx70.14, align 1
  %scevgep20.6.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 6
  %14546 = load i8, i8* %scevgep20.6.14, align 1
  %conv68.6.14 = zext i8 %14546 to i32
  %14547 = load i8, i8* %arrayidx70.14, align 1
  %conv71.6.14 = zext i8 %14547 to i32
  %xor72.6.14 = xor i32 %conv71.6.14, %conv68.6.14
  %conv73.6.14 = trunc i32 %xor72.6.14 to i8
  store i8 %conv73.6.14, i8* %arrayidx70.14, align 1
  %scevgep20.7.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 7
  %14548 = load i8, i8* %scevgep20.7.14, align 1
  %conv68.7.14 = zext i8 %14548 to i32
  %14549 = load i8, i8* %arrayidx70.14, align 1
  %conv71.7.14 = zext i8 %14549 to i32
  %xor72.7.14 = xor i32 %conv71.7.14, %conv68.7.14
  %conv73.7.14 = trunc i32 %xor72.7.14 to i8
  store i8 %conv73.7.14, i8* %arrayidx70.14, align 1
  %scevgep20.8.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 8
  %14550 = load i8, i8* %scevgep20.8.14, align 1
  %conv68.8.14 = zext i8 %14550 to i32
  %14551 = load i8, i8* %arrayidx70.14, align 1
  %conv71.8.14 = zext i8 %14551 to i32
  %xor72.8.14 = xor i32 %conv71.8.14, %conv68.8.14
  %conv73.8.14 = trunc i32 %xor72.8.14 to i8
  store i8 %conv73.8.14, i8* %arrayidx70.14, align 1
  %scevgep20.9.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 9
  %14552 = load i8, i8* %scevgep20.9.14, align 1
  %conv68.9.14 = zext i8 %14552 to i32
  %14553 = load i8, i8* %arrayidx70.14, align 1
  %conv71.9.14 = zext i8 %14553 to i32
  %xor72.9.14 = xor i32 %conv71.9.14, %conv68.9.14
  %conv73.9.14 = trunc i32 %xor72.9.14 to i8
  store i8 %conv73.9.14, i8* %arrayidx70.14, align 1
  %scevgep20.10.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 10
  %14554 = load i8, i8* %scevgep20.10.14, align 1
  %conv68.10.14 = zext i8 %14554 to i32
  %14555 = load i8, i8* %arrayidx70.14, align 1
  %conv71.10.14 = zext i8 %14555 to i32
  %xor72.10.14 = xor i32 %conv71.10.14, %conv68.10.14
  %conv73.10.14 = trunc i32 %xor72.10.14 to i8
  store i8 %conv73.10.14, i8* %arrayidx70.14, align 1
  %scevgep20.11.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 11
  %14556 = load i8, i8* %scevgep20.11.14, align 1
  %conv68.11.14 = zext i8 %14556 to i32
  %14557 = load i8, i8* %arrayidx70.14, align 1
  %conv71.11.14 = zext i8 %14557 to i32
  %xor72.11.14 = xor i32 %conv71.11.14, %conv68.11.14
  %conv73.11.14 = trunc i32 %xor72.11.14 to i8
  store i8 %conv73.11.14, i8* %arrayidx70.14, align 1
  %scevgep20.12.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 12
  %14558 = load i8, i8* %scevgep20.12.14, align 1
  %conv68.12.14 = zext i8 %14558 to i32
  %14559 = load i8, i8* %arrayidx70.14, align 1
  %conv71.12.14 = zext i8 %14559 to i32
  %xor72.12.14 = xor i32 %conv71.12.14, %conv68.12.14
  %conv73.12.14 = trunc i32 %xor72.12.14 to i8
  store i8 %conv73.12.14, i8* %arrayidx70.14, align 1
  %scevgep20.13.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 13
  %14560 = load i8, i8* %scevgep20.13.14, align 1
  %conv68.13.14 = zext i8 %14560 to i32
  %14561 = load i8, i8* %arrayidx70.14, align 1
  %conv71.13.14 = zext i8 %14561 to i32
  %xor72.13.14 = xor i32 %conv71.13.14, %conv68.13.14
  %conv73.13.14 = trunc i32 %xor72.13.14 to i8
  store i8 %conv73.13.14, i8* %arrayidx70.14, align 1
  %scevgep20.15.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 15
  %14562 = load i8, i8* %scevgep20.15.14, align 1
  %conv68.15.14 = zext i8 %14562 to i32
  %14563 = load i8, i8* %arrayidx70.14, align 1
  %conv71.15.14 = zext i8 %14563 to i32
  %xor72.15.14 = xor i32 %conv71.15.14, %conv68.15.14
  %conv73.15.14 = trunc i32 %xor72.15.14 to i8
  store i8 %conv73.15.14, i8* %arrayidx70.14, align 1
  %scevgep20.16.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 16
  %14564 = load i8, i8* %scevgep20.16.14, align 1
  %conv68.16.14 = zext i8 %14564 to i32
  %14565 = load i8, i8* %arrayidx70.14, align 1
  %conv71.16.14 = zext i8 %14565 to i32
  %xor72.16.14 = xor i32 %conv71.16.14, %conv68.16.14
  %conv73.16.14 = trunc i32 %xor72.16.14 to i8
  store i8 %conv73.16.14, i8* %arrayidx70.14, align 1
  %scevgep20.17.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 17
  %14566 = load i8, i8* %scevgep20.17.14, align 1
  %conv68.17.14 = zext i8 %14566 to i32
  %14567 = load i8, i8* %arrayidx70.14, align 1
  %conv71.17.14 = zext i8 %14567 to i32
  %xor72.17.14 = xor i32 %conv71.17.14, %conv68.17.14
  %conv73.17.14 = trunc i32 %xor72.17.14 to i8
  store i8 %conv73.17.14, i8* %arrayidx70.14, align 1
  %scevgep20.18.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 18
  %14568 = load i8, i8* %scevgep20.18.14, align 1
  %conv68.18.14 = zext i8 %14568 to i32
  %14569 = load i8, i8* %arrayidx70.14, align 1
  %conv71.18.14 = zext i8 %14569 to i32
  %xor72.18.14 = xor i32 %conv71.18.14, %conv68.18.14
  %conv73.18.14 = trunc i32 %xor72.18.14 to i8
  store i8 %conv73.18.14, i8* %arrayidx70.14, align 1
  %scevgep20.19.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 19
  %14570 = load i8, i8* %scevgep20.19.14, align 1
  %conv68.19.14 = zext i8 %14570 to i32
  %14571 = load i8, i8* %arrayidx70.14, align 1
  %conv71.19.14 = zext i8 %14571 to i32
  %xor72.19.14 = xor i32 %conv71.19.14, %conv68.19.14
  %conv73.19.14 = trunc i32 %xor72.19.14 to i8
  store i8 %conv73.19.14, i8* %arrayidx70.14, align 1
  %scevgep20.20.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 20
  %14572 = load i8, i8* %scevgep20.20.14, align 1
  %conv68.20.14 = zext i8 %14572 to i32
  %14573 = load i8, i8* %arrayidx70.14, align 1
  %conv71.20.14 = zext i8 %14573 to i32
  %xor72.20.14 = xor i32 %conv71.20.14, %conv68.20.14
  %conv73.20.14 = trunc i32 %xor72.20.14 to i8
  store i8 %conv73.20.14, i8* %arrayidx70.14, align 1
  %scevgep20.21.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 21
  %14574 = load i8, i8* %scevgep20.21.14, align 1
  %conv68.21.14 = zext i8 %14574 to i32
  %14575 = load i8, i8* %arrayidx70.14, align 1
  %conv71.21.14 = zext i8 %14575 to i32
  %xor72.21.14 = xor i32 %conv71.21.14, %conv68.21.14
  %conv73.21.14 = trunc i32 %xor72.21.14 to i8
  store i8 %conv73.21.14, i8* %arrayidx70.14, align 1
  %scevgep20.22.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 22
  %14576 = load i8, i8* %scevgep20.22.14, align 1
  %conv68.22.14 = zext i8 %14576 to i32
  %14577 = load i8, i8* %arrayidx70.14, align 1
  %conv71.22.14 = zext i8 %14577 to i32
  %xor72.22.14 = xor i32 %conv71.22.14, %conv68.22.14
  %conv73.22.14 = trunc i32 %xor72.22.14 to i8
  store i8 %conv73.22.14, i8* %arrayidx70.14, align 1
  %scevgep20.23.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 23
  %14578 = load i8, i8* %scevgep20.23.14, align 1
  %conv68.23.14 = zext i8 %14578 to i32
  %14579 = load i8, i8* %arrayidx70.14, align 1
  %conv71.23.14 = zext i8 %14579 to i32
  %xor72.23.14 = xor i32 %conv71.23.14, %conv68.23.14
  %conv73.23.14 = trunc i32 %xor72.23.14 to i8
  store i8 %conv73.23.14, i8* %arrayidx70.14, align 1
  %scevgep20.24.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 24
  %14580 = load i8, i8* %scevgep20.24.14, align 1
  %conv68.24.14 = zext i8 %14580 to i32
  %14581 = load i8, i8* %arrayidx70.14, align 1
  %conv71.24.14 = zext i8 %14581 to i32
  %xor72.24.14 = xor i32 %conv71.24.14, %conv68.24.14
  %conv73.24.14 = trunc i32 %xor72.24.14 to i8
  store i8 %conv73.24.14, i8* %arrayidx70.14, align 1
  %scevgep20.25.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 25
  %14582 = load i8, i8* %scevgep20.25.14, align 1
  %conv68.25.14 = zext i8 %14582 to i32
  %14583 = load i8, i8* %arrayidx70.14, align 1
  %conv71.25.14 = zext i8 %14583 to i32
  %xor72.25.14 = xor i32 %conv71.25.14, %conv68.25.14
  %conv73.25.14 = trunc i32 %xor72.25.14 to i8
  store i8 %conv73.25.14, i8* %arrayidx70.14, align 1
  %scevgep20.26.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 26
  %14584 = load i8, i8* %scevgep20.26.14, align 1
  %conv68.26.14 = zext i8 %14584 to i32
  %14585 = load i8, i8* %arrayidx70.14, align 1
  %conv71.26.14 = zext i8 %14585 to i32
  %xor72.26.14 = xor i32 %conv71.26.14, %conv68.26.14
  %conv73.26.14 = trunc i32 %xor72.26.14 to i8
  store i8 %conv73.26.14, i8* %arrayidx70.14, align 1
  %scevgep20.27.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 27
  %14586 = load i8, i8* %scevgep20.27.14, align 1
  %conv68.27.14 = zext i8 %14586 to i32
  %14587 = load i8, i8* %arrayidx70.14, align 1
  %conv71.27.14 = zext i8 %14587 to i32
  %xor72.27.14 = xor i32 %conv71.27.14, %conv68.27.14
  %conv73.27.14 = trunc i32 %xor72.27.14 to i8
  store i8 %conv73.27.14, i8* %arrayidx70.14, align 1
  %scevgep20.28.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 28
  %14588 = load i8, i8* %scevgep20.28.14, align 1
  %conv68.28.14 = zext i8 %14588 to i32
  %14589 = load i8, i8* %arrayidx70.14, align 1
  %conv71.28.14 = zext i8 %14589 to i32
  %xor72.28.14 = xor i32 %conv71.28.14, %conv68.28.14
  %conv73.28.14 = trunc i32 %xor72.28.14 to i8
  store i8 %conv73.28.14, i8* %arrayidx70.14, align 1
  %scevgep20.29.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 29
  %14590 = load i8, i8* %scevgep20.29.14, align 1
  %conv68.29.14 = zext i8 %14590 to i32
  %14591 = load i8, i8* %arrayidx70.14, align 1
  %conv71.29.14 = zext i8 %14591 to i32
  %xor72.29.14 = xor i32 %conv71.29.14, %conv68.29.14
  %conv73.29.14 = trunc i32 %xor72.29.14 to i8
  store i8 %conv73.29.14, i8* %arrayidx70.14, align 1
  %scevgep20.30.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 30
  %14592 = load i8, i8* %scevgep20.30.14, align 1
  %conv68.30.14 = zext i8 %14592 to i32
  %14593 = load i8, i8* %arrayidx70.14, align 1
  %conv71.30.14 = zext i8 %14593 to i32
  %xor72.30.14 = xor i32 %conv71.30.14, %conv68.30.14
  %conv73.30.14 = trunc i32 %xor72.30.14 to i8
  store i8 %conv73.30.14, i8* %arrayidx70.14, align 1
  %scevgep20.31.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 31
  %14594 = load i8, i8* %scevgep20.31.14, align 1
  %conv68.31.14 = zext i8 %14594 to i32
  %14595 = load i8, i8* %arrayidx70.14, align 1
  %conv71.31.14 = zext i8 %14595 to i32
  %xor72.31.14 = xor i32 %conv71.31.14, %conv68.31.14
  %conv73.31.14 = trunc i32 %xor72.31.14 to i8
  store i8 %conv73.31.14, i8* %arrayidx70.14, align 1
  %scevgep20.32.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 32
  %14596 = load i8, i8* %scevgep20.32.14, align 1
  %conv68.32.14 = zext i8 %14596 to i32
  %14597 = load i8, i8* %arrayidx70.14, align 1
  %conv71.32.14 = zext i8 %14597 to i32
  %xor72.32.14 = xor i32 %conv71.32.14, %conv68.32.14
  %conv73.32.14 = trunc i32 %xor72.32.14 to i8
  store i8 %conv73.32.14, i8* %arrayidx70.14, align 1
  %scevgep20.33.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 33
  %14598 = load i8, i8* %scevgep20.33.14, align 1
  %conv68.33.14 = zext i8 %14598 to i32
  %14599 = load i8, i8* %arrayidx70.14, align 1
  %conv71.33.14 = zext i8 %14599 to i32
  %xor72.33.14 = xor i32 %conv71.33.14, %conv68.33.14
  %conv73.33.14 = trunc i32 %xor72.33.14 to i8
  store i8 %conv73.33.14, i8* %arrayidx70.14, align 1
  %scevgep20.34.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 34
  %14600 = load i8, i8* %scevgep20.34.14, align 1
  %conv68.34.14 = zext i8 %14600 to i32
  %14601 = load i8, i8* %arrayidx70.14, align 1
  %conv71.34.14 = zext i8 %14601 to i32
  %xor72.34.14 = xor i32 %conv71.34.14, %conv68.34.14
  %conv73.34.14 = trunc i32 %xor72.34.14 to i8
  store i8 %conv73.34.14, i8* %arrayidx70.14, align 1
  %scevgep20.35.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 35
  %14602 = load i8, i8* %scevgep20.35.14, align 1
  %conv68.35.14 = zext i8 %14602 to i32
  %14603 = load i8, i8* %arrayidx70.14, align 1
  %conv71.35.14 = zext i8 %14603 to i32
  %xor72.35.14 = xor i32 %conv71.35.14, %conv68.35.14
  %conv73.35.14 = trunc i32 %xor72.35.14 to i8
  store i8 %conv73.35.14, i8* %arrayidx70.14, align 1
  %scevgep20.36.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 36
  %14604 = load i8, i8* %scevgep20.36.14, align 1
  %conv68.36.14 = zext i8 %14604 to i32
  %14605 = load i8, i8* %arrayidx70.14, align 1
  %conv71.36.14 = zext i8 %14605 to i32
  %xor72.36.14 = xor i32 %conv71.36.14, %conv68.36.14
  %conv73.36.14 = trunc i32 %xor72.36.14 to i8
  store i8 %conv73.36.14, i8* %arrayidx70.14, align 1
  %scevgep20.37.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 37
  %14606 = load i8, i8* %scevgep20.37.14, align 1
  %conv68.37.14 = zext i8 %14606 to i32
  %14607 = load i8, i8* %arrayidx70.14, align 1
  %conv71.37.14 = zext i8 %14607 to i32
  %xor72.37.14 = xor i32 %conv71.37.14, %conv68.37.14
  %conv73.37.14 = trunc i32 %xor72.37.14 to i8
  store i8 %conv73.37.14, i8* %arrayidx70.14, align 1
  %scevgep20.38.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 38
  %14608 = load i8, i8* %scevgep20.38.14, align 1
  %conv68.38.14 = zext i8 %14608 to i32
  %14609 = load i8, i8* %arrayidx70.14, align 1
  %conv71.38.14 = zext i8 %14609 to i32
  %xor72.38.14 = xor i32 %conv71.38.14, %conv68.38.14
  %conv73.38.14 = trunc i32 %xor72.38.14 to i8
  store i8 %conv73.38.14, i8* %arrayidx70.14, align 1
  %scevgep20.39.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 39
  %14610 = load i8, i8* %scevgep20.39.14, align 1
  %conv68.39.14 = zext i8 %14610 to i32
  %14611 = load i8, i8* %arrayidx70.14, align 1
  %conv71.39.14 = zext i8 %14611 to i32
  %xor72.39.14 = xor i32 %conv71.39.14, %conv68.39.14
  %conv73.39.14 = trunc i32 %xor72.39.14 to i8
  store i8 %conv73.39.14, i8* %arrayidx70.14, align 1
  %scevgep20.40.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 40
  %14612 = load i8, i8* %scevgep20.40.14, align 1
  %conv68.40.14 = zext i8 %14612 to i32
  %14613 = load i8, i8* %arrayidx70.14, align 1
  %conv71.40.14 = zext i8 %14613 to i32
  %xor72.40.14 = xor i32 %conv71.40.14, %conv68.40.14
  %conv73.40.14 = trunc i32 %xor72.40.14 to i8
  store i8 %conv73.40.14, i8* %arrayidx70.14, align 1
  %scevgep20.41.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 41
  %14614 = load i8, i8* %scevgep20.41.14, align 1
  %conv68.41.14 = zext i8 %14614 to i32
  %14615 = load i8, i8* %arrayidx70.14, align 1
  %conv71.41.14 = zext i8 %14615 to i32
  %xor72.41.14 = xor i32 %conv71.41.14, %conv68.41.14
  %conv73.41.14 = trunc i32 %xor72.41.14 to i8
  store i8 %conv73.41.14, i8* %arrayidx70.14, align 1
  %scevgep20.42.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 42
  %14616 = load i8, i8* %scevgep20.42.14, align 1
  %conv68.42.14 = zext i8 %14616 to i32
  %14617 = load i8, i8* %arrayidx70.14, align 1
  %conv71.42.14 = zext i8 %14617 to i32
  %xor72.42.14 = xor i32 %conv71.42.14, %conv68.42.14
  %conv73.42.14 = trunc i32 %xor72.42.14 to i8
  store i8 %conv73.42.14, i8* %arrayidx70.14, align 1
  %scevgep20.43.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 43
  %14618 = load i8, i8* %scevgep20.43.14, align 1
  %conv68.43.14 = zext i8 %14618 to i32
  %14619 = load i8, i8* %arrayidx70.14, align 1
  %conv71.43.14 = zext i8 %14619 to i32
  %xor72.43.14 = xor i32 %conv71.43.14, %conv68.43.14
  %conv73.43.14 = trunc i32 %xor72.43.14 to i8
  store i8 %conv73.43.14, i8* %arrayidx70.14, align 1
  %scevgep20.44.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 44
  %14620 = load i8, i8* %scevgep20.44.14, align 1
  %conv68.44.14 = zext i8 %14620 to i32
  %14621 = load i8, i8* %arrayidx70.14, align 1
  %conv71.44.14 = zext i8 %14621 to i32
  %xor72.44.14 = xor i32 %conv71.44.14, %conv68.44.14
  %conv73.44.14 = trunc i32 %xor72.44.14 to i8
  store i8 %conv73.44.14, i8* %arrayidx70.14, align 1
  %scevgep20.45.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 45
  %14622 = load i8, i8* %scevgep20.45.14, align 1
  %conv68.45.14 = zext i8 %14622 to i32
  %14623 = load i8, i8* %arrayidx70.14, align 1
  %conv71.45.14 = zext i8 %14623 to i32
  %xor72.45.14 = xor i32 %conv71.45.14, %conv68.45.14
  %conv73.45.14 = trunc i32 %xor72.45.14 to i8
  store i8 %conv73.45.14, i8* %arrayidx70.14, align 1
  %scevgep20.46.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 46
  %14624 = load i8, i8* %scevgep20.46.14, align 1
  %conv68.46.14 = zext i8 %14624 to i32
  %14625 = load i8, i8* %arrayidx70.14, align 1
  %conv71.46.14 = zext i8 %14625 to i32
  %xor72.46.14 = xor i32 %conv71.46.14, %conv68.46.14
  %conv73.46.14 = trunc i32 %xor72.46.14 to i8
  store i8 %conv73.46.14, i8* %arrayidx70.14, align 1
  %scevgep20.47.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 47
  %14626 = load i8, i8* %scevgep20.47.14, align 1
  %conv68.47.14 = zext i8 %14626 to i32
  %14627 = load i8, i8* %arrayidx70.14, align 1
  %conv71.47.14 = zext i8 %14627 to i32
  %xor72.47.14 = xor i32 %conv71.47.14, %conv68.47.14
  %conv73.47.14 = trunc i32 %xor72.47.14 to i8
  store i8 %conv73.47.14, i8* %arrayidx70.14, align 1
  %scevgep20.48.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 48
  %14628 = load i8, i8* %scevgep20.48.14, align 1
  %conv68.48.14 = zext i8 %14628 to i32
  %14629 = load i8, i8* %arrayidx70.14, align 1
  %conv71.48.14 = zext i8 %14629 to i32
  %xor72.48.14 = xor i32 %conv71.48.14, %conv68.48.14
  %conv73.48.14 = trunc i32 %xor72.48.14 to i8
  store i8 %conv73.48.14, i8* %arrayidx70.14, align 1
  %scevgep20.49.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 49
  %14630 = load i8, i8* %scevgep20.49.14, align 1
  %conv68.49.14 = zext i8 %14630 to i32
  %14631 = load i8, i8* %arrayidx70.14, align 1
  %conv71.49.14 = zext i8 %14631 to i32
  %xor72.49.14 = xor i32 %conv71.49.14, %conv68.49.14
  %conv73.49.14 = trunc i32 %xor72.49.14 to i8
  store i8 %conv73.49.14, i8* %arrayidx70.14, align 1
  %scevgep20.50.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 50
  %14632 = load i8, i8* %scevgep20.50.14, align 1
  %conv68.50.14 = zext i8 %14632 to i32
  %14633 = load i8, i8* %arrayidx70.14, align 1
  %conv71.50.14 = zext i8 %14633 to i32
  %xor72.50.14 = xor i32 %conv71.50.14, %conv68.50.14
  %conv73.50.14 = trunc i32 %xor72.50.14 to i8
  store i8 %conv73.50.14, i8* %arrayidx70.14, align 1
  %scevgep20.51.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 51
  %14634 = load i8, i8* %scevgep20.51.14, align 1
  %conv68.51.14 = zext i8 %14634 to i32
  %14635 = load i8, i8* %arrayidx70.14, align 1
  %conv71.51.14 = zext i8 %14635 to i32
  %xor72.51.14 = xor i32 %conv71.51.14, %conv68.51.14
  %conv73.51.14 = trunc i32 %xor72.51.14 to i8
  store i8 %conv73.51.14, i8* %arrayidx70.14, align 1
  %scevgep20.52.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 52
  %14636 = load i8, i8* %scevgep20.52.14, align 1
  %conv68.52.14 = zext i8 %14636 to i32
  %14637 = load i8, i8* %arrayidx70.14, align 1
  %conv71.52.14 = zext i8 %14637 to i32
  %xor72.52.14 = xor i32 %conv71.52.14, %conv68.52.14
  %conv73.52.14 = trunc i32 %xor72.52.14 to i8
  store i8 %conv73.52.14, i8* %arrayidx70.14, align 1
  %scevgep20.53.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 53
  %14638 = load i8, i8* %scevgep20.53.14, align 1
  %conv68.53.14 = zext i8 %14638 to i32
  %14639 = load i8, i8* %arrayidx70.14, align 1
  %conv71.53.14 = zext i8 %14639 to i32
  %xor72.53.14 = xor i32 %conv71.53.14, %conv68.53.14
  %conv73.53.14 = trunc i32 %xor72.53.14 to i8
  store i8 %conv73.53.14, i8* %arrayidx70.14, align 1
  %scevgep20.54.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 54
  %14640 = load i8, i8* %scevgep20.54.14, align 1
  %conv68.54.14 = zext i8 %14640 to i32
  %14641 = load i8, i8* %arrayidx70.14, align 1
  %conv71.54.14 = zext i8 %14641 to i32
  %xor72.54.14 = xor i32 %conv71.54.14, %conv68.54.14
  %conv73.54.14 = trunc i32 %xor72.54.14 to i8
  store i8 %conv73.54.14, i8* %arrayidx70.14, align 1
  %scevgep20.55.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 55
  %14642 = load i8, i8* %scevgep20.55.14, align 1
  %conv68.55.14 = zext i8 %14642 to i32
  %14643 = load i8, i8* %arrayidx70.14, align 1
  %conv71.55.14 = zext i8 %14643 to i32
  %xor72.55.14 = xor i32 %conv71.55.14, %conv68.55.14
  %conv73.55.14 = trunc i32 %xor72.55.14 to i8
  store i8 %conv73.55.14, i8* %arrayidx70.14, align 1
  %scevgep20.56.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 56
  %14644 = load i8, i8* %scevgep20.56.14, align 1
  %conv68.56.14 = zext i8 %14644 to i32
  %14645 = load i8, i8* %arrayidx70.14, align 1
  %conv71.56.14 = zext i8 %14645 to i32
  %xor72.56.14 = xor i32 %conv71.56.14, %conv68.56.14
  %conv73.56.14 = trunc i32 %xor72.56.14 to i8
  store i8 %conv73.56.14, i8* %arrayidx70.14, align 1
  %scevgep20.57.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 57
  %14646 = load i8, i8* %scevgep20.57.14, align 1
  %conv68.57.14 = zext i8 %14646 to i32
  %14647 = load i8, i8* %arrayidx70.14, align 1
  %conv71.57.14 = zext i8 %14647 to i32
  %xor72.57.14 = xor i32 %conv71.57.14, %conv68.57.14
  %conv73.57.14 = trunc i32 %xor72.57.14 to i8
  store i8 %conv73.57.14, i8* %arrayidx70.14, align 1
  %scevgep20.58.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 58
  %14648 = load i8, i8* %scevgep20.58.14, align 1
  %conv68.58.14 = zext i8 %14648 to i32
  %14649 = load i8, i8* %arrayidx70.14, align 1
  %conv71.58.14 = zext i8 %14649 to i32
  %xor72.58.14 = xor i32 %conv71.58.14, %conv68.58.14
  %conv73.58.14 = trunc i32 %xor72.58.14 to i8
  store i8 %conv73.58.14, i8* %arrayidx70.14, align 1
  %scevgep20.59.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 59
  %14650 = load i8, i8* %scevgep20.59.14, align 1
  %conv68.59.14 = zext i8 %14650 to i32
  %14651 = load i8, i8* %arrayidx70.14, align 1
  %conv71.59.14 = zext i8 %14651 to i32
  %xor72.59.14 = xor i32 %conv71.59.14, %conv68.59.14
  %conv73.59.14 = trunc i32 %xor72.59.14 to i8
  store i8 %conv73.59.14, i8* %arrayidx70.14, align 1
  %scevgep20.60.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 0, i64 60
  %14652 = load i8, i8* %scevgep20.60.14, align 1
  %conv68.60.14 = zext i8 %14652 to i32
  %14653 = load i8, i8* %arrayidx70.14, align 1
  %conv71.60.14 = zext i8 %14653 to i32
  %xor72.60.14 = xor i32 %conv71.60.14, %conv68.60.14
  %conv73.60.14 = trunc i32 %xor72.60.14 to i8
  store i8 %conv73.60.14, i8* %arrayidx70.14, align 1
  %scevgep19.14 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14531, i64 0, i64 1, i64 0
  %14654 = bitcast i8* %scevgep19.14 to [61 x [61 x i8]]*
  %arrayidx51.15 = getelementptr inbounds i8, i8* %a, i64 15
  %14655 = load i8, i8* %arrayidx51.15, align 1
  %arrayidx53.15 = getelementptr inbounds i8, i8* %b, i64 15
  %14656 = load i8, i8* %arrayidx53.15, align 1
  %call54.15 = call zeroext i8 @mult(i8 zeroext %14655, i8 zeroext %14656)
  %arrayidx56.15 = getelementptr inbounds i8, i8* %c, i64 15
  store i8 %call54.15, i8* %arrayidx56.15, align 1
  %arrayidx70.15 = getelementptr inbounds i8, i8* %c, i64 15
  %scevgep20.15194 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 0
  %14657 = load i8, i8* %scevgep20.15194, align 1
  %conv68.15195 = zext i8 %14657 to i32
  %14658 = load i8, i8* %arrayidx70.15, align 1
  %conv71.15196 = zext i8 %14658 to i32
  %xor72.15197 = xor i32 %conv71.15196, %conv68.15195
  %conv73.15198 = trunc i32 %xor72.15197 to i8
  store i8 %conv73.15198, i8* %arrayidx70.15, align 1
  %scevgep20.1.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 1
  %14659 = load i8, i8* %scevgep20.1.15, align 1
  %conv68.1.15 = zext i8 %14659 to i32
  %14660 = load i8, i8* %arrayidx70.15, align 1
  %conv71.1.15 = zext i8 %14660 to i32
  %xor72.1.15 = xor i32 %conv71.1.15, %conv68.1.15
  %conv73.1.15 = trunc i32 %xor72.1.15 to i8
  store i8 %conv73.1.15, i8* %arrayidx70.15, align 1
  %scevgep20.2.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 2
  %14661 = load i8, i8* %scevgep20.2.15, align 1
  %conv68.2.15 = zext i8 %14661 to i32
  %14662 = load i8, i8* %arrayidx70.15, align 1
  %conv71.2.15 = zext i8 %14662 to i32
  %xor72.2.15 = xor i32 %conv71.2.15, %conv68.2.15
  %conv73.2.15 = trunc i32 %xor72.2.15 to i8
  store i8 %conv73.2.15, i8* %arrayidx70.15, align 1
  %scevgep20.3.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 3
  %14663 = load i8, i8* %scevgep20.3.15, align 1
  %conv68.3.15 = zext i8 %14663 to i32
  %14664 = load i8, i8* %arrayidx70.15, align 1
  %conv71.3.15 = zext i8 %14664 to i32
  %xor72.3.15 = xor i32 %conv71.3.15, %conv68.3.15
  %conv73.3.15 = trunc i32 %xor72.3.15 to i8
  store i8 %conv73.3.15, i8* %arrayidx70.15, align 1
  %scevgep20.4.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 4
  %14665 = load i8, i8* %scevgep20.4.15, align 1
  %conv68.4.15 = zext i8 %14665 to i32
  %14666 = load i8, i8* %arrayidx70.15, align 1
  %conv71.4.15 = zext i8 %14666 to i32
  %xor72.4.15 = xor i32 %conv71.4.15, %conv68.4.15
  %conv73.4.15 = trunc i32 %xor72.4.15 to i8
  store i8 %conv73.4.15, i8* %arrayidx70.15, align 1
  %scevgep20.5.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 5
  %14667 = load i8, i8* %scevgep20.5.15, align 1
  %conv68.5.15 = zext i8 %14667 to i32
  %14668 = load i8, i8* %arrayidx70.15, align 1
  %conv71.5.15 = zext i8 %14668 to i32
  %xor72.5.15 = xor i32 %conv71.5.15, %conv68.5.15
  %conv73.5.15 = trunc i32 %xor72.5.15 to i8
  store i8 %conv73.5.15, i8* %arrayidx70.15, align 1
  %scevgep20.6.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 6
  %14669 = load i8, i8* %scevgep20.6.15, align 1
  %conv68.6.15 = zext i8 %14669 to i32
  %14670 = load i8, i8* %arrayidx70.15, align 1
  %conv71.6.15 = zext i8 %14670 to i32
  %xor72.6.15 = xor i32 %conv71.6.15, %conv68.6.15
  %conv73.6.15 = trunc i32 %xor72.6.15 to i8
  store i8 %conv73.6.15, i8* %arrayidx70.15, align 1
  %scevgep20.7.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 7
  %14671 = load i8, i8* %scevgep20.7.15, align 1
  %conv68.7.15 = zext i8 %14671 to i32
  %14672 = load i8, i8* %arrayidx70.15, align 1
  %conv71.7.15 = zext i8 %14672 to i32
  %xor72.7.15 = xor i32 %conv71.7.15, %conv68.7.15
  %conv73.7.15 = trunc i32 %xor72.7.15 to i8
  store i8 %conv73.7.15, i8* %arrayidx70.15, align 1
  %scevgep20.8.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 8
  %14673 = load i8, i8* %scevgep20.8.15, align 1
  %conv68.8.15 = zext i8 %14673 to i32
  %14674 = load i8, i8* %arrayidx70.15, align 1
  %conv71.8.15 = zext i8 %14674 to i32
  %xor72.8.15 = xor i32 %conv71.8.15, %conv68.8.15
  %conv73.8.15 = trunc i32 %xor72.8.15 to i8
  store i8 %conv73.8.15, i8* %arrayidx70.15, align 1
  %scevgep20.9.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 9
  %14675 = load i8, i8* %scevgep20.9.15, align 1
  %conv68.9.15 = zext i8 %14675 to i32
  %14676 = load i8, i8* %arrayidx70.15, align 1
  %conv71.9.15 = zext i8 %14676 to i32
  %xor72.9.15 = xor i32 %conv71.9.15, %conv68.9.15
  %conv73.9.15 = trunc i32 %xor72.9.15 to i8
  store i8 %conv73.9.15, i8* %arrayidx70.15, align 1
  %scevgep20.10.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 10
  %14677 = load i8, i8* %scevgep20.10.15, align 1
  %conv68.10.15 = zext i8 %14677 to i32
  %14678 = load i8, i8* %arrayidx70.15, align 1
  %conv71.10.15 = zext i8 %14678 to i32
  %xor72.10.15 = xor i32 %conv71.10.15, %conv68.10.15
  %conv73.10.15 = trunc i32 %xor72.10.15 to i8
  store i8 %conv73.10.15, i8* %arrayidx70.15, align 1
  %scevgep20.11.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 11
  %14679 = load i8, i8* %scevgep20.11.15, align 1
  %conv68.11.15 = zext i8 %14679 to i32
  %14680 = load i8, i8* %arrayidx70.15, align 1
  %conv71.11.15 = zext i8 %14680 to i32
  %xor72.11.15 = xor i32 %conv71.11.15, %conv68.11.15
  %conv73.11.15 = trunc i32 %xor72.11.15 to i8
  store i8 %conv73.11.15, i8* %arrayidx70.15, align 1
  %scevgep20.12.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 12
  %14681 = load i8, i8* %scevgep20.12.15, align 1
  %conv68.12.15 = zext i8 %14681 to i32
  %14682 = load i8, i8* %arrayidx70.15, align 1
  %conv71.12.15 = zext i8 %14682 to i32
  %xor72.12.15 = xor i32 %conv71.12.15, %conv68.12.15
  %conv73.12.15 = trunc i32 %xor72.12.15 to i8
  store i8 %conv73.12.15, i8* %arrayidx70.15, align 1
  %scevgep20.13.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 13
  %14683 = load i8, i8* %scevgep20.13.15, align 1
  %conv68.13.15 = zext i8 %14683 to i32
  %14684 = load i8, i8* %arrayidx70.15, align 1
  %conv71.13.15 = zext i8 %14684 to i32
  %xor72.13.15 = xor i32 %conv71.13.15, %conv68.13.15
  %conv73.13.15 = trunc i32 %xor72.13.15 to i8
  store i8 %conv73.13.15, i8* %arrayidx70.15, align 1
  %scevgep20.14.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 14
  %14685 = load i8, i8* %scevgep20.14.15, align 1
  %conv68.14.15 = zext i8 %14685 to i32
  %14686 = load i8, i8* %arrayidx70.15, align 1
  %conv71.14.15 = zext i8 %14686 to i32
  %xor72.14.15 = xor i32 %conv71.14.15, %conv68.14.15
  %conv73.14.15 = trunc i32 %xor72.14.15 to i8
  store i8 %conv73.14.15, i8* %arrayidx70.15, align 1
  %scevgep20.16.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 16
  %14687 = load i8, i8* %scevgep20.16.15, align 1
  %conv68.16.15 = zext i8 %14687 to i32
  %14688 = load i8, i8* %arrayidx70.15, align 1
  %conv71.16.15 = zext i8 %14688 to i32
  %xor72.16.15 = xor i32 %conv71.16.15, %conv68.16.15
  %conv73.16.15 = trunc i32 %xor72.16.15 to i8
  store i8 %conv73.16.15, i8* %arrayidx70.15, align 1
  %scevgep20.17.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 17
  %14689 = load i8, i8* %scevgep20.17.15, align 1
  %conv68.17.15 = zext i8 %14689 to i32
  %14690 = load i8, i8* %arrayidx70.15, align 1
  %conv71.17.15 = zext i8 %14690 to i32
  %xor72.17.15 = xor i32 %conv71.17.15, %conv68.17.15
  %conv73.17.15 = trunc i32 %xor72.17.15 to i8
  store i8 %conv73.17.15, i8* %arrayidx70.15, align 1
  %scevgep20.18.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 18
  %14691 = load i8, i8* %scevgep20.18.15, align 1
  %conv68.18.15 = zext i8 %14691 to i32
  %14692 = load i8, i8* %arrayidx70.15, align 1
  %conv71.18.15 = zext i8 %14692 to i32
  %xor72.18.15 = xor i32 %conv71.18.15, %conv68.18.15
  %conv73.18.15 = trunc i32 %xor72.18.15 to i8
  store i8 %conv73.18.15, i8* %arrayidx70.15, align 1
  %scevgep20.19.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 19
  %14693 = load i8, i8* %scevgep20.19.15, align 1
  %conv68.19.15 = zext i8 %14693 to i32
  %14694 = load i8, i8* %arrayidx70.15, align 1
  %conv71.19.15 = zext i8 %14694 to i32
  %xor72.19.15 = xor i32 %conv71.19.15, %conv68.19.15
  %conv73.19.15 = trunc i32 %xor72.19.15 to i8
  store i8 %conv73.19.15, i8* %arrayidx70.15, align 1
  %scevgep20.20.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 20
  %14695 = load i8, i8* %scevgep20.20.15, align 1
  %conv68.20.15 = zext i8 %14695 to i32
  %14696 = load i8, i8* %arrayidx70.15, align 1
  %conv71.20.15 = zext i8 %14696 to i32
  %xor72.20.15 = xor i32 %conv71.20.15, %conv68.20.15
  %conv73.20.15 = trunc i32 %xor72.20.15 to i8
  store i8 %conv73.20.15, i8* %arrayidx70.15, align 1
  %scevgep20.21.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 21
  %14697 = load i8, i8* %scevgep20.21.15, align 1
  %conv68.21.15 = zext i8 %14697 to i32
  %14698 = load i8, i8* %arrayidx70.15, align 1
  %conv71.21.15 = zext i8 %14698 to i32
  %xor72.21.15 = xor i32 %conv71.21.15, %conv68.21.15
  %conv73.21.15 = trunc i32 %xor72.21.15 to i8
  store i8 %conv73.21.15, i8* %arrayidx70.15, align 1
  %scevgep20.22.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 22
  %14699 = load i8, i8* %scevgep20.22.15, align 1
  %conv68.22.15 = zext i8 %14699 to i32
  %14700 = load i8, i8* %arrayidx70.15, align 1
  %conv71.22.15 = zext i8 %14700 to i32
  %xor72.22.15 = xor i32 %conv71.22.15, %conv68.22.15
  %conv73.22.15 = trunc i32 %xor72.22.15 to i8
  store i8 %conv73.22.15, i8* %arrayidx70.15, align 1
  %scevgep20.23.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 23
  %14701 = load i8, i8* %scevgep20.23.15, align 1
  %conv68.23.15 = zext i8 %14701 to i32
  %14702 = load i8, i8* %arrayidx70.15, align 1
  %conv71.23.15 = zext i8 %14702 to i32
  %xor72.23.15 = xor i32 %conv71.23.15, %conv68.23.15
  %conv73.23.15 = trunc i32 %xor72.23.15 to i8
  store i8 %conv73.23.15, i8* %arrayidx70.15, align 1
  %scevgep20.24.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 24
  %14703 = load i8, i8* %scevgep20.24.15, align 1
  %conv68.24.15 = zext i8 %14703 to i32
  %14704 = load i8, i8* %arrayidx70.15, align 1
  %conv71.24.15 = zext i8 %14704 to i32
  %xor72.24.15 = xor i32 %conv71.24.15, %conv68.24.15
  %conv73.24.15 = trunc i32 %xor72.24.15 to i8
  store i8 %conv73.24.15, i8* %arrayidx70.15, align 1
  %scevgep20.25.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 25
  %14705 = load i8, i8* %scevgep20.25.15, align 1
  %conv68.25.15 = zext i8 %14705 to i32
  %14706 = load i8, i8* %arrayidx70.15, align 1
  %conv71.25.15 = zext i8 %14706 to i32
  %xor72.25.15 = xor i32 %conv71.25.15, %conv68.25.15
  %conv73.25.15 = trunc i32 %xor72.25.15 to i8
  store i8 %conv73.25.15, i8* %arrayidx70.15, align 1
  %scevgep20.26.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 26
  %14707 = load i8, i8* %scevgep20.26.15, align 1
  %conv68.26.15 = zext i8 %14707 to i32
  %14708 = load i8, i8* %arrayidx70.15, align 1
  %conv71.26.15 = zext i8 %14708 to i32
  %xor72.26.15 = xor i32 %conv71.26.15, %conv68.26.15
  %conv73.26.15 = trunc i32 %xor72.26.15 to i8
  store i8 %conv73.26.15, i8* %arrayidx70.15, align 1
  %scevgep20.27.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 27
  %14709 = load i8, i8* %scevgep20.27.15, align 1
  %conv68.27.15 = zext i8 %14709 to i32
  %14710 = load i8, i8* %arrayidx70.15, align 1
  %conv71.27.15 = zext i8 %14710 to i32
  %xor72.27.15 = xor i32 %conv71.27.15, %conv68.27.15
  %conv73.27.15 = trunc i32 %xor72.27.15 to i8
  store i8 %conv73.27.15, i8* %arrayidx70.15, align 1
  %scevgep20.28.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 28
  %14711 = load i8, i8* %scevgep20.28.15, align 1
  %conv68.28.15 = zext i8 %14711 to i32
  %14712 = load i8, i8* %arrayidx70.15, align 1
  %conv71.28.15 = zext i8 %14712 to i32
  %xor72.28.15 = xor i32 %conv71.28.15, %conv68.28.15
  %conv73.28.15 = trunc i32 %xor72.28.15 to i8
  store i8 %conv73.28.15, i8* %arrayidx70.15, align 1
  %scevgep20.29.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 29
  %14713 = load i8, i8* %scevgep20.29.15, align 1
  %conv68.29.15 = zext i8 %14713 to i32
  %14714 = load i8, i8* %arrayidx70.15, align 1
  %conv71.29.15 = zext i8 %14714 to i32
  %xor72.29.15 = xor i32 %conv71.29.15, %conv68.29.15
  %conv73.29.15 = trunc i32 %xor72.29.15 to i8
  store i8 %conv73.29.15, i8* %arrayidx70.15, align 1
  %scevgep20.30.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 30
  %14715 = load i8, i8* %scevgep20.30.15, align 1
  %conv68.30.15 = zext i8 %14715 to i32
  %14716 = load i8, i8* %arrayidx70.15, align 1
  %conv71.30.15 = zext i8 %14716 to i32
  %xor72.30.15 = xor i32 %conv71.30.15, %conv68.30.15
  %conv73.30.15 = trunc i32 %xor72.30.15 to i8
  store i8 %conv73.30.15, i8* %arrayidx70.15, align 1
  %scevgep20.31.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 31
  %14717 = load i8, i8* %scevgep20.31.15, align 1
  %conv68.31.15 = zext i8 %14717 to i32
  %14718 = load i8, i8* %arrayidx70.15, align 1
  %conv71.31.15 = zext i8 %14718 to i32
  %xor72.31.15 = xor i32 %conv71.31.15, %conv68.31.15
  %conv73.31.15 = trunc i32 %xor72.31.15 to i8
  store i8 %conv73.31.15, i8* %arrayidx70.15, align 1
  %scevgep20.32.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 32
  %14719 = load i8, i8* %scevgep20.32.15, align 1
  %conv68.32.15 = zext i8 %14719 to i32
  %14720 = load i8, i8* %arrayidx70.15, align 1
  %conv71.32.15 = zext i8 %14720 to i32
  %xor72.32.15 = xor i32 %conv71.32.15, %conv68.32.15
  %conv73.32.15 = trunc i32 %xor72.32.15 to i8
  store i8 %conv73.32.15, i8* %arrayidx70.15, align 1
  %scevgep20.33.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 33
  %14721 = load i8, i8* %scevgep20.33.15, align 1
  %conv68.33.15 = zext i8 %14721 to i32
  %14722 = load i8, i8* %arrayidx70.15, align 1
  %conv71.33.15 = zext i8 %14722 to i32
  %xor72.33.15 = xor i32 %conv71.33.15, %conv68.33.15
  %conv73.33.15 = trunc i32 %xor72.33.15 to i8
  store i8 %conv73.33.15, i8* %arrayidx70.15, align 1
  %scevgep20.34.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 34
  %14723 = load i8, i8* %scevgep20.34.15, align 1
  %conv68.34.15 = zext i8 %14723 to i32
  %14724 = load i8, i8* %arrayidx70.15, align 1
  %conv71.34.15 = zext i8 %14724 to i32
  %xor72.34.15 = xor i32 %conv71.34.15, %conv68.34.15
  %conv73.34.15 = trunc i32 %xor72.34.15 to i8
  store i8 %conv73.34.15, i8* %arrayidx70.15, align 1
  %scevgep20.35.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 35
  %14725 = load i8, i8* %scevgep20.35.15, align 1
  %conv68.35.15 = zext i8 %14725 to i32
  %14726 = load i8, i8* %arrayidx70.15, align 1
  %conv71.35.15 = zext i8 %14726 to i32
  %xor72.35.15 = xor i32 %conv71.35.15, %conv68.35.15
  %conv73.35.15 = trunc i32 %xor72.35.15 to i8
  store i8 %conv73.35.15, i8* %arrayidx70.15, align 1
  %scevgep20.36.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 36
  %14727 = load i8, i8* %scevgep20.36.15, align 1
  %conv68.36.15 = zext i8 %14727 to i32
  %14728 = load i8, i8* %arrayidx70.15, align 1
  %conv71.36.15 = zext i8 %14728 to i32
  %xor72.36.15 = xor i32 %conv71.36.15, %conv68.36.15
  %conv73.36.15 = trunc i32 %xor72.36.15 to i8
  store i8 %conv73.36.15, i8* %arrayidx70.15, align 1
  %scevgep20.37.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 37
  %14729 = load i8, i8* %scevgep20.37.15, align 1
  %conv68.37.15 = zext i8 %14729 to i32
  %14730 = load i8, i8* %arrayidx70.15, align 1
  %conv71.37.15 = zext i8 %14730 to i32
  %xor72.37.15 = xor i32 %conv71.37.15, %conv68.37.15
  %conv73.37.15 = trunc i32 %xor72.37.15 to i8
  store i8 %conv73.37.15, i8* %arrayidx70.15, align 1
  %scevgep20.38.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 38
  %14731 = load i8, i8* %scevgep20.38.15, align 1
  %conv68.38.15 = zext i8 %14731 to i32
  %14732 = load i8, i8* %arrayidx70.15, align 1
  %conv71.38.15 = zext i8 %14732 to i32
  %xor72.38.15 = xor i32 %conv71.38.15, %conv68.38.15
  %conv73.38.15 = trunc i32 %xor72.38.15 to i8
  store i8 %conv73.38.15, i8* %arrayidx70.15, align 1
  %scevgep20.39.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 39
  %14733 = load i8, i8* %scevgep20.39.15, align 1
  %conv68.39.15 = zext i8 %14733 to i32
  %14734 = load i8, i8* %arrayidx70.15, align 1
  %conv71.39.15 = zext i8 %14734 to i32
  %xor72.39.15 = xor i32 %conv71.39.15, %conv68.39.15
  %conv73.39.15 = trunc i32 %xor72.39.15 to i8
  store i8 %conv73.39.15, i8* %arrayidx70.15, align 1
  %scevgep20.40.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 40
  %14735 = load i8, i8* %scevgep20.40.15, align 1
  %conv68.40.15 = zext i8 %14735 to i32
  %14736 = load i8, i8* %arrayidx70.15, align 1
  %conv71.40.15 = zext i8 %14736 to i32
  %xor72.40.15 = xor i32 %conv71.40.15, %conv68.40.15
  %conv73.40.15 = trunc i32 %xor72.40.15 to i8
  store i8 %conv73.40.15, i8* %arrayidx70.15, align 1
  %scevgep20.41.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 41
  %14737 = load i8, i8* %scevgep20.41.15, align 1
  %conv68.41.15 = zext i8 %14737 to i32
  %14738 = load i8, i8* %arrayidx70.15, align 1
  %conv71.41.15 = zext i8 %14738 to i32
  %xor72.41.15 = xor i32 %conv71.41.15, %conv68.41.15
  %conv73.41.15 = trunc i32 %xor72.41.15 to i8
  store i8 %conv73.41.15, i8* %arrayidx70.15, align 1
  %scevgep20.42.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 42
  %14739 = load i8, i8* %scevgep20.42.15, align 1
  %conv68.42.15 = zext i8 %14739 to i32
  %14740 = load i8, i8* %arrayidx70.15, align 1
  %conv71.42.15 = zext i8 %14740 to i32
  %xor72.42.15 = xor i32 %conv71.42.15, %conv68.42.15
  %conv73.42.15 = trunc i32 %xor72.42.15 to i8
  store i8 %conv73.42.15, i8* %arrayidx70.15, align 1
  %scevgep20.43.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 43
  %14741 = load i8, i8* %scevgep20.43.15, align 1
  %conv68.43.15 = zext i8 %14741 to i32
  %14742 = load i8, i8* %arrayidx70.15, align 1
  %conv71.43.15 = zext i8 %14742 to i32
  %xor72.43.15 = xor i32 %conv71.43.15, %conv68.43.15
  %conv73.43.15 = trunc i32 %xor72.43.15 to i8
  store i8 %conv73.43.15, i8* %arrayidx70.15, align 1
  %scevgep20.44.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 44
  %14743 = load i8, i8* %scevgep20.44.15, align 1
  %conv68.44.15 = zext i8 %14743 to i32
  %14744 = load i8, i8* %arrayidx70.15, align 1
  %conv71.44.15 = zext i8 %14744 to i32
  %xor72.44.15 = xor i32 %conv71.44.15, %conv68.44.15
  %conv73.44.15 = trunc i32 %xor72.44.15 to i8
  store i8 %conv73.44.15, i8* %arrayidx70.15, align 1
  %scevgep20.45.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 45
  %14745 = load i8, i8* %scevgep20.45.15, align 1
  %conv68.45.15 = zext i8 %14745 to i32
  %14746 = load i8, i8* %arrayidx70.15, align 1
  %conv71.45.15 = zext i8 %14746 to i32
  %xor72.45.15 = xor i32 %conv71.45.15, %conv68.45.15
  %conv73.45.15 = trunc i32 %xor72.45.15 to i8
  store i8 %conv73.45.15, i8* %arrayidx70.15, align 1
  %scevgep20.46.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 46
  %14747 = load i8, i8* %scevgep20.46.15, align 1
  %conv68.46.15 = zext i8 %14747 to i32
  %14748 = load i8, i8* %arrayidx70.15, align 1
  %conv71.46.15 = zext i8 %14748 to i32
  %xor72.46.15 = xor i32 %conv71.46.15, %conv68.46.15
  %conv73.46.15 = trunc i32 %xor72.46.15 to i8
  store i8 %conv73.46.15, i8* %arrayidx70.15, align 1
  %scevgep20.47.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 47
  %14749 = load i8, i8* %scevgep20.47.15, align 1
  %conv68.47.15 = zext i8 %14749 to i32
  %14750 = load i8, i8* %arrayidx70.15, align 1
  %conv71.47.15 = zext i8 %14750 to i32
  %xor72.47.15 = xor i32 %conv71.47.15, %conv68.47.15
  %conv73.47.15 = trunc i32 %xor72.47.15 to i8
  store i8 %conv73.47.15, i8* %arrayidx70.15, align 1
  %scevgep20.48.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 48
  %14751 = load i8, i8* %scevgep20.48.15, align 1
  %conv68.48.15 = zext i8 %14751 to i32
  %14752 = load i8, i8* %arrayidx70.15, align 1
  %conv71.48.15 = zext i8 %14752 to i32
  %xor72.48.15 = xor i32 %conv71.48.15, %conv68.48.15
  %conv73.48.15 = trunc i32 %xor72.48.15 to i8
  store i8 %conv73.48.15, i8* %arrayidx70.15, align 1
  %scevgep20.49.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 49
  %14753 = load i8, i8* %scevgep20.49.15, align 1
  %conv68.49.15 = zext i8 %14753 to i32
  %14754 = load i8, i8* %arrayidx70.15, align 1
  %conv71.49.15 = zext i8 %14754 to i32
  %xor72.49.15 = xor i32 %conv71.49.15, %conv68.49.15
  %conv73.49.15 = trunc i32 %xor72.49.15 to i8
  store i8 %conv73.49.15, i8* %arrayidx70.15, align 1
  %scevgep20.50.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 50
  %14755 = load i8, i8* %scevgep20.50.15, align 1
  %conv68.50.15 = zext i8 %14755 to i32
  %14756 = load i8, i8* %arrayidx70.15, align 1
  %conv71.50.15 = zext i8 %14756 to i32
  %xor72.50.15 = xor i32 %conv71.50.15, %conv68.50.15
  %conv73.50.15 = trunc i32 %xor72.50.15 to i8
  store i8 %conv73.50.15, i8* %arrayidx70.15, align 1
  %scevgep20.51.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 51
  %14757 = load i8, i8* %scevgep20.51.15, align 1
  %conv68.51.15 = zext i8 %14757 to i32
  %14758 = load i8, i8* %arrayidx70.15, align 1
  %conv71.51.15 = zext i8 %14758 to i32
  %xor72.51.15 = xor i32 %conv71.51.15, %conv68.51.15
  %conv73.51.15 = trunc i32 %xor72.51.15 to i8
  store i8 %conv73.51.15, i8* %arrayidx70.15, align 1
  %scevgep20.52.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 52
  %14759 = load i8, i8* %scevgep20.52.15, align 1
  %conv68.52.15 = zext i8 %14759 to i32
  %14760 = load i8, i8* %arrayidx70.15, align 1
  %conv71.52.15 = zext i8 %14760 to i32
  %xor72.52.15 = xor i32 %conv71.52.15, %conv68.52.15
  %conv73.52.15 = trunc i32 %xor72.52.15 to i8
  store i8 %conv73.52.15, i8* %arrayidx70.15, align 1
  %scevgep20.53.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 53
  %14761 = load i8, i8* %scevgep20.53.15, align 1
  %conv68.53.15 = zext i8 %14761 to i32
  %14762 = load i8, i8* %arrayidx70.15, align 1
  %conv71.53.15 = zext i8 %14762 to i32
  %xor72.53.15 = xor i32 %conv71.53.15, %conv68.53.15
  %conv73.53.15 = trunc i32 %xor72.53.15 to i8
  store i8 %conv73.53.15, i8* %arrayidx70.15, align 1
  %scevgep20.54.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 54
  %14763 = load i8, i8* %scevgep20.54.15, align 1
  %conv68.54.15 = zext i8 %14763 to i32
  %14764 = load i8, i8* %arrayidx70.15, align 1
  %conv71.54.15 = zext i8 %14764 to i32
  %xor72.54.15 = xor i32 %conv71.54.15, %conv68.54.15
  %conv73.54.15 = trunc i32 %xor72.54.15 to i8
  store i8 %conv73.54.15, i8* %arrayidx70.15, align 1
  %scevgep20.55.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 55
  %14765 = load i8, i8* %scevgep20.55.15, align 1
  %conv68.55.15 = zext i8 %14765 to i32
  %14766 = load i8, i8* %arrayidx70.15, align 1
  %conv71.55.15 = zext i8 %14766 to i32
  %xor72.55.15 = xor i32 %conv71.55.15, %conv68.55.15
  %conv73.55.15 = trunc i32 %xor72.55.15 to i8
  store i8 %conv73.55.15, i8* %arrayidx70.15, align 1
  %scevgep20.56.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 56
  %14767 = load i8, i8* %scevgep20.56.15, align 1
  %conv68.56.15 = zext i8 %14767 to i32
  %14768 = load i8, i8* %arrayidx70.15, align 1
  %conv71.56.15 = zext i8 %14768 to i32
  %xor72.56.15 = xor i32 %conv71.56.15, %conv68.56.15
  %conv73.56.15 = trunc i32 %xor72.56.15 to i8
  store i8 %conv73.56.15, i8* %arrayidx70.15, align 1
  %scevgep20.57.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 57
  %14769 = load i8, i8* %scevgep20.57.15, align 1
  %conv68.57.15 = zext i8 %14769 to i32
  %14770 = load i8, i8* %arrayidx70.15, align 1
  %conv71.57.15 = zext i8 %14770 to i32
  %xor72.57.15 = xor i32 %conv71.57.15, %conv68.57.15
  %conv73.57.15 = trunc i32 %xor72.57.15 to i8
  store i8 %conv73.57.15, i8* %arrayidx70.15, align 1
  %scevgep20.58.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 58
  %14771 = load i8, i8* %scevgep20.58.15, align 1
  %conv68.58.15 = zext i8 %14771 to i32
  %14772 = load i8, i8* %arrayidx70.15, align 1
  %conv71.58.15 = zext i8 %14772 to i32
  %xor72.58.15 = xor i32 %conv71.58.15, %conv68.58.15
  %conv73.58.15 = trunc i32 %xor72.58.15 to i8
  store i8 %conv73.58.15, i8* %arrayidx70.15, align 1
  %scevgep20.59.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 59
  %14773 = load i8, i8* %scevgep20.59.15, align 1
  %conv68.59.15 = zext i8 %14773 to i32
  %14774 = load i8, i8* %arrayidx70.15, align 1
  %conv71.59.15 = zext i8 %14774 to i32
  %xor72.59.15 = xor i32 %conv71.59.15, %conv68.59.15
  %conv73.59.15 = trunc i32 %xor72.59.15 to i8
  store i8 %conv73.59.15, i8* %arrayidx70.15, align 1
  %scevgep20.60.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 0, i64 60
  %14775 = load i8, i8* %scevgep20.60.15, align 1
  %conv68.60.15 = zext i8 %14775 to i32
  %14776 = load i8, i8* %arrayidx70.15, align 1
  %conv71.60.15 = zext i8 %14776 to i32
  %xor72.60.15 = xor i32 %conv71.60.15, %conv68.60.15
  %conv73.60.15 = trunc i32 %xor72.60.15 to i8
  store i8 %conv73.60.15, i8* %arrayidx70.15, align 1
  %scevgep19.15 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14654, i64 0, i64 1, i64 0
  %14777 = bitcast i8* %scevgep19.15 to [61 x [61 x i8]]*
  %arrayidx51.16 = getelementptr inbounds i8, i8* %a, i64 16
  %14778 = load i8, i8* %arrayidx51.16, align 1
  %arrayidx53.16 = getelementptr inbounds i8, i8* %b, i64 16
  %14779 = load i8, i8* %arrayidx53.16, align 1
  %call54.16 = call zeroext i8 @mult(i8 zeroext %14778, i8 zeroext %14779)
  %arrayidx56.16 = getelementptr inbounds i8, i8* %c, i64 16
  store i8 %call54.16, i8* %arrayidx56.16, align 1
  %arrayidx70.16 = getelementptr inbounds i8, i8* %c, i64 16
  %scevgep20.16204 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 0
  %14780 = load i8, i8* %scevgep20.16204, align 1
  %conv68.16205 = zext i8 %14780 to i32
  %14781 = load i8, i8* %arrayidx70.16, align 1
  %conv71.16206 = zext i8 %14781 to i32
  %xor72.16207 = xor i32 %conv71.16206, %conv68.16205
  %conv73.16208 = trunc i32 %xor72.16207 to i8
  store i8 %conv73.16208, i8* %arrayidx70.16, align 1
  %scevgep20.1.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 1
  %14782 = load i8, i8* %scevgep20.1.16, align 1
  %conv68.1.16 = zext i8 %14782 to i32
  %14783 = load i8, i8* %arrayidx70.16, align 1
  %conv71.1.16 = zext i8 %14783 to i32
  %xor72.1.16 = xor i32 %conv71.1.16, %conv68.1.16
  %conv73.1.16 = trunc i32 %xor72.1.16 to i8
  store i8 %conv73.1.16, i8* %arrayidx70.16, align 1
  %scevgep20.2.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 2
  %14784 = load i8, i8* %scevgep20.2.16, align 1
  %conv68.2.16 = zext i8 %14784 to i32
  %14785 = load i8, i8* %arrayidx70.16, align 1
  %conv71.2.16 = zext i8 %14785 to i32
  %xor72.2.16 = xor i32 %conv71.2.16, %conv68.2.16
  %conv73.2.16 = trunc i32 %xor72.2.16 to i8
  store i8 %conv73.2.16, i8* %arrayidx70.16, align 1
  %scevgep20.3.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 3
  %14786 = load i8, i8* %scevgep20.3.16, align 1
  %conv68.3.16 = zext i8 %14786 to i32
  %14787 = load i8, i8* %arrayidx70.16, align 1
  %conv71.3.16 = zext i8 %14787 to i32
  %xor72.3.16 = xor i32 %conv71.3.16, %conv68.3.16
  %conv73.3.16 = trunc i32 %xor72.3.16 to i8
  store i8 %conv73.3.16, i8* %arrayidx70.16, align 1
  %scevgep20.4.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 4
  %14788 = load i8, i8* %scevgep20.4.16, align 1
  %conv68.4.16 = zext i8 %14788 to i32
  %14789 = load i8, i8* %arrayidx70.16, align 1
  %conv71.4.16 = zext i8 %14789 to i32
  %xor72.4.16 = xor i32 %conv71.4.16, %conv68.4.16
  %conv73.4.16 = trunc i32 %xor72.4.16 to i8
  store i8 %conv73.4.16, i8* %arrayidx70.16, align 1
  %scevgep20.5.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 5
  %14790 = load i8, i8* %scevgep20.5.16, align 1
  %conv68.5.16 = zext i8 %14790 to i32
  %14791 = load i8, i8* %arrayidx70.16, align 1
  %conv71.5.16 = zext i8 %14791 to i32
  %xor72.5.16 = xor i32 %conv71.5.16, %conv68.5.16
  %conv73.5.16 = trunc i32 %xor72.5.16 to i8
  store i8 %conv73.5.16, i8* %arrayidx70.16, align 1
  %scevgep20.6.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 6
  %14792 = load i8, i8* %scevgep20.6.16, align 1
  %conv68.6.16 = zext i8 %14792 to i32
  %14793 = load i8, i8* %arrayidx70.16, align 1
  %conv71.6.16 = zext i8 %14793 to i32
  %xor72.6.16 = xor i32 %conv71.6.16, %conv68.6.16
  %conv73.6.16 = trunc i32 %xor72.6.16 to i8
  store i8 %conv73.6.16, i8* %arrayidx70.16, align 1
  %scevgep20.7.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 7
  %14794 = load i8, i8* %scevgep20.7.16, align 1
  %conv68.7.16 = zext i8 %14794 to i32
  %14795 = load i8, i8* %arrayidx70.16, align 1
  %conv71.7.16 = zext i8 %14795 to i32
  %xor72.7.16 = xor i32 %conv71.7.16, %conv68.7.16
  %conv73.7.16 = trunc i32 %xor72.7.16 to i8
  store i8 %conv73.7.16, i8* %arrayidx70.16, align 1
  %scevgep20.8.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 8
  %14796 = load i8, i8* %scevgep20.8.16, align 1
  %conv68.8.16 = zext i8 %14796 to i32
  %14797 = load i8, i8* %arrayidx70.16, align 1
  %conv71.8.16 = zext i8 %14797 to i32
  %xor72.8.16 = xor i32 %conv71.8.16, %conv68.8.16
  %conv73.8.16 = trunc i32 %xor72.8.16 to i8
  store i8 %conv73.8.16, i8* %arrayidx70.16, align 1
  %scevgep20.9.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 9
  %14798 = load i8, i8* %scevgep20.9.16, align 1
  %conv68.9.16 = zext i8 %14798 to i32
  %14799 = load i8, i8* %arrayidx70.16, align 1
  %conv71.9.16 = zext i8 %14799 to i32
  %xor72.9.16 = xor i32 %conv71.9.16, %conv68.9.16
  %conv73.9.16 = trunc i32 %xor72.9.16 to i8
  store i8 %conv73.9.16, i8* %arrayidx70.16, align 1
  %scevgep20.10.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 10
  %14800 = load i8, i8* %scevgep20.10.16, align 1
  %conv68.10.16 = zext i8 %14800 to i32
  %14801 = load i8, i8* %arrayidx70.16, align 1
  %conv71.10.16 = zext i8 %14801 to i32
  %xor72.10.16 = xor i32 %conv71.10.16, %conv68.10.16
  %conv73.10.16 = trunc i32 %xor72.10.16 to i8
  store i8 %conv73.10.16, i8* %arrayidx70.16, align 1
  %scevgep20.11.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 11
  %14802 = load i8, i8* %scevgep20.11.16, align 1
  %conv68.11.16 = zext i8 %14802 to i32
  %14803 = load i8, i8* %arrayidx70.16, align 1
  %conv71.11.16 = zext i8 %14803 to i32
  %xor72.11.16 = xor i32 %conv71.11.16, %conv68.11.16
  %conv73.11.16 = trunc i32 %xor72.11.16 to i8
  store i8 %conv73.11.16, i8* %arrayidx70.16, align 1
  %scevgep20.12.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 12
  %14804 = load i8, i8* %scevgep20.12.16, align 1
  %conv68.12.16 = zext i8 %14804 to i32
  %14805 = load i8, i8* %arrayidx70.16, align 1
  %conv71.12.16 = zext i8 %14805 to i32
  %xor72.12.16 = xor i32 %conv71.12.16, %conv68.12.16
  %conv73.12.16 = trunc i32 %xor72.12.16 to i8
  store i8 %conv73.12.16, i8* %arrayidx70.16, align 1
  %scevgep20.13.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 13
  %14806 = load i8, i8* %scevgep20.13.16, align 1
  %conv68.13.16 = zext i8 %14806 to i32
  %14807 = load i8, i8* %arrayidx70.16, align 1
  %conv71.13.16 = zext i8 %14807 to i32
  %xor72.13.16 = xor i32 %conv71.13.16, %conv68.13.16
  %conv73.13.16 = trunc i32 %xor72.13.16 to i8
  store i8 %conv73.13.16, i8* %arrayidx70.16, align 1
  %scevgep20.14.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 14
  %14808 = load i8, i8* %scevgep20.14.16, align 1
  %conv68.14.16 = zext i8 %14808 to i32
  %14809 = load i8, i8* %arrayidx70.16, align 1
  %conv71.14.16 = zext i8 %14809 to i32
  %xor72.14.16 = xor i32 %conv71.14.16, %conv68.14.16
  %conv73.14.16 = trunc i32 %xor72.14.16 to i8
  store i8 %conv73.14.16, i8* %arrayidx70.16, align 1
  %scevgep20.15.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 15
  %14810 = load i8, i8* %scevgep20.15.16, align 1
  %conv68.15.16 = zext i8 %14810 to i32
  %14811 = load i8, i8* %arrayidx70.16, align 1
  %conv71.15.16 = zext i8 %14811 to i32
  %xor72.15.16 = xor i32 %conv71.15.16, %conv68.15.16
  %conv73.15.16 = trunc i32 %xor72.15.16 to i8
  store i8 %conv73.15.16, i8* %arrayidx70.16, align 1
  %scevgep20.17.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 17
  %14812 = load i8, i8* %scevgep20.17.16, align 1
  %conv68.17.16 = zext i8 %14812 to i32
  %14813 = load i8, i8* %arrayidx70.16, align 1
  %conv71.17.16 = zext i8 %14813 to i32
  %xor72.17.16 = xor i32 %conv71.17.16, %conv68.17.16
  %conv73.17.16 = trunc i32 %xor72.17.16 to i8
  store i8 %conv73.17.16, i8* %arrayidx70.16, align 1
  %scevgep20.18.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 18
  %14814 = load i8, i8* %scevgep20.18.16, align 1
  %conv68.18.16 = zext i8 %14814 to i32
  %14815 = load i8, i8* %arrayidx70.16, align 1
  %conv71.18.16 = zext i8 %14815 to i32
  %xor72.18.16 = xor i32 %conv71.18.16, %conv68.18.16
  %conv73.18.16 = trunc i32 %xor72.18.16 to i8
  store i8 %conv73.18.16, i8* %arrayidx70.16, align 1
  %scevgep20.19.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 19
  %14816 = load i8, i8* %scevgep20.19.16, align 1
  %conv68.19.16 = zext i8 %14816 to i32
  %14817 = load i8, i8* %arrayidx70.16, align 1
  %conv71.19.16 = zext i8 %14817 to i32
  %xor72.19.16 = xor i32 %conv71.19.16, %conv68.19.16
  %conv73.19.16 = trunc i32 %xor72.19.16 to i8
  store i8 %conv73.19.16, i8* %arrayidx70.16, align 1
  %scevgep20.20.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 20
  %14818 = load i8, i8* %scevgep20.20.16, align 1
  %conv68.20.16 = zext i8 %14818 to i32
  %14819 = load i8, i8* %arrayidx70.16, align 1
  %conv71.20.16 = zext i8 %14819 to i32
  %xor72.20.16 = xor i32 %conv71.20.16, %conv68.20.16
  %conv73.20.16 = trunc i32 %xor72.20.16 to i8
  store i8 %conv73.20.16, i8* %arrayidx70.16, align 1
  %scevgep20.21.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 21
  %14820 = load i8, i8* %scevgep20.21.16, align 1
  %conv68.21.16 = zext i8 %14820 to i32
  %14821 = load i8, i8* %arrayidx70.16, align 1
  %conv71.21.16 = zext i8 %14821 to i32
  %xor72.21.16 = xor i32 %conv71.21.16, %conv68.21.16
  %conv73.21.16 = trunc i32 %xor72.21.16 to i8
  store i8 %conv73.21.16, i8* %arrayidx70.16, align 1
  %scevgep20.22.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 22
  %14822 = load i8, i8* %scevgep20.22.16, align 1
  %conv68.22.16 = zext i8 %14822 to i32
  %14823 = load i8, i8* %arrayidx70.16, align 1
  %conv71.22.16 = zext i8 %14823 to i32
  %xor72.22.16 = xor i32 %conv71.22.16, %conv68.22.16
  %conv73.22.16 = trunc i32 %xor72.22.16 to i8
  store i8 %conv73.22.16, i8* %arrayidx70.16, align 1
  %scevgep20.23.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 23
  %14824 = load i8, i8* %scevgep20.23.16, align 1
  %conv68.23.16 = zext i8 %14824 to i32
  %14825 = load i8, i8* %arrayidx70.16, align 1
  %conv71.23.16 = zext i8 %14825 to i32
  %xor72.23.16 = xor i32 %conv71.23.16, %conv68.23.16
  %conv73.23.16 = trunc i32 %xor72.23.16 to i8
  store i8 %conv73.23.16, i8* %arrayidx70.16, align 1
  %scevgep20.24.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 24
  %14826 = load i8, i8* %scevgep20.24.16, align 1
  %conv68.24.16 = zext i8 %14826 to i32
  %14827 = load i8, i8* %arrayidx70.16, align 1
  %conv71.24.16 = zext i8 %14827 to i32
  %xor72.24.16 = xor i32 %conv71.24.16, %conv68.24.16
  %conv73.24.16 = trunc i32 %xor72.24.16 to i8
  store i8 %conv73.24.16, i8* %arrayidx70.16, align 1
  %scevgep20.25.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 25
  %14828 = load i8, i8* %scevgep20.25.16, align 1
  %conv68.25.16 = zext i8 %14828 to i32
  %14829 = load i8, i8* %arrayidx70.16, align 1
  %conv71.25.16 = zext i8 %14829 to i32
  %xor72.25.16 = xor i32 %conv71.25.16, %conv68.25.16
  %conv73.25.16 = trunc i32 %xor72.25.16 to i8
  store i8 %conv73.25.16, i8* %arrayidx70.16, align 1
  %scevgep20.26.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 26
  %14830 = load i8, i8* %scevgep20.26.16, align 1
  %conv68.26.16 = zext i8 %14830 to i32
  %14831 = load i8, i8* %arrayidx70.16, align 1
  %conv71.26.16 = zext i8 %14831 to i32
  %xor72.26.16 = xor i32 %conv71.26.16, %conv68.26.16
  %conv73.26.16 = trunc i32 %xor72.26.16 to i8
  store i8 %conv73.26.16, i8* %arrayidx70.16, align 1
  %scevgep20.27.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 27
  %14832 = load i8, i8* %scevgep20.27.16, align 1
  %conv68.27.16 = zext i8 %14832 to i32
  %14833 = load i8, i8* %arrayidx70.16, align 1
  %conv71.27.16 = zext i8 %14833 to i32
  %xor72.27.16 = xor i32 %conv71.27.16, %conv68.27.16
  %conv73.27.16 = trunc i32 %xor72.27.16 to i8
  store i8 %conv73.27.16, i8* %arrayidx70.16, align 1
  %scevgep20.28.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 28
  %14834 = load i8, i8* %scevgep20.28.16, align 1
  %conv68.28.16 = zext i8 %14834 to i32
  %14835 = load i8, i8* %arrayidx70.16, align 1
  %conv71.28.16 = zext i8 %14835 to i32
  %xor72.28.16 = xor i32 %conv71.28.16, %conv68.28.16
  %conv73.28.16 = trunc i32 %xor72.28.16 to i8
  store i8 %conv73.28.16, i8* %arrayidx70.16, align 1
  %scevgep20.29.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 29
  %14836 = load i8, i8* %scevgep20.29.16, align 1
  %conv68.29.16 = zext i8 %14836 to i32
  %14837 = load i8, i8* %arrayidx70.16, align 1
  %conv71.29.16 = zext i8 %14837 to i32
  %xor72.29.16 = xor i32 %conv71.29.16, %conv68.29.16
  %conv73.29.16 = trunc i32 %xor72.29.16 to i8
  store i8 %conv73.29.16, i8* %arrayidx70.16, align 1
  %scevgep20.30.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 30
  %14838 = load i8, i8* %scevgep20.30.16, align 1
  %conv68.30.16 = zext i8 %14838 to i32
  %14839 = load i8, i8* %arrayidx70.16, align 1
  %conv71.30.16 = zext i8 %14839 to i32
  %xor72.30.16 = xor i32 %conv71.30.16, %conv68.30.16
  %conv73.30.16 = trunc i32 %xor72.30.16 to i8
  store i8 %conv73.30.16, i8* %arrayidx70.16, align 1
  %scevgep20.31.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 31
  %14840 = load i8, i8* %scevgep20.31.16, align 1
  %conv68.31.16 = zext i8 %14840 to i32
  %14841 = load i8, i8* %arrayidx70.16, align 1
  %conv71.31.16 = zext i8 %14841 to i32
  %xor72.31.16 = xor i32 %conv71.31.16, %conv68.31.16
  %conv73.31.16 = trunc i32 %xor72.31.16 to i8
  store i8 %conv73.31.16, i8* %arrayidx70.16, align 1
  %scevgep20.32.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 32
  %14842 = load i8, i8* %scevgep20.32.16, align 1
  %conv68.32.16 = zext i8 %14842 to i32
  %14843 = load i8, i8* %arrayidx70.16, align 1
  %conv71.32.16 = zext i8 %14843 to i32
  %xor72.32.16 = xor i32 %conv71.32.16, %conv68.32.16
  %conv73.32.16 = trunc i32 %xor72.32.16 to i8
  store i8 %conv73.32.16, i8* %arrayidx70.16, align 1
  %scevgep20.33.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 33
  %14844 = load i8, i8* %scevgep20.33.16, align 1
  %conv68.33.16 = zext i8 %14844 to i32
  %14845 = load i8, i8* %arrayidx70.16, align 1
  %conv71.33.16 = zext i8 %14845 to i32
  %xor72.33.16 = xor i32 %conv71.33.16, %conv68.33.16
  %conv73.33.16 = trunc i32 %xor72.33.16 to i8
  store i8 %conv73.33.16, i8* %arrayidx70.16, align 1
  %scevgep20.34.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 34
  %14846 = load i8, i8* %scevgep20.34.16, align 1
  %conv68.34.16 = zext i8 %14846 to i32
  %14847 = load i8, i8* %arrayidx70.16, align 1
  %conv71.34.16 = zext i8 %14847 to i32
  %xor72.34.16 = xor i32 %conv71.34.16, %conv68.34.16
  %conv73.34.16 = trunc i32 %xor72.34.16 to i8
  store i8 %conv73.34.16, i8* %arrayidx70.16, align 1
  %scevgep20.35.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 35
  %14848 = load i8, i8* %scevgep20.35.16, align 1
  %conv68.35.16 = zext i8 %14848 to i32
  %14849 = load i8, i8* %arrayidx70.16, align 1
  %conv71.35.16 = zext i8 %14849 to i32
  %xor72.35.16 = xor i32 %conv71.35.16, %conv68.35.16
  %conv73.35.16 = trunc i32 %xor72.35.16 to i8
  store i8 %conv73.35.16, i8* %arrayidx70.16, align 1
  %scevgep20.36.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 36
  %14850 = load i8, i8* %scevgep20.36.16, align 1
  %conv68.36.16 = zext i8 %14850 to i32
  %14851 = load i8, i8* %arrayidx70.16, align 1
  %conv71.36.16 = zext i8 %14851 to i32
  %xor72.36.16 = xor i32 %conv71.36.16, %conv68.36.16
  %conv73.36.16 = trunc i32 %xor72.36.16 to i8
  store i8 %conv73.36.16, i8* %arrayidx70.16, align 1
  %scevgep20.37.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 37
  %14852 = load i8, i8* %scevgep20.37.16, align 1
  %conv68.37.16 = zext i8 %14852 to i32
  %14853 = load i8, i8* %arrayidx70.16, align 1
  %conv71.37.16 = zext i8 %14853 to i32
  %xor72.37.16 = xor i32 %conv71.37.16, %conv68.37.16
  %conv73.37.16 = trunc i32 %xor72.37.16 to i8
  store i8 %conv73.37.16, i8* %arrayidx70.16, align 1
  %scevgep20.38.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 38
  %14854 = load i8, i8* %scevgep20.38.16, align 1
  %conv68.38.16 = zext i8 %14854 to i32
  %14855 = load i8, i8* %arrayidx70.16, align 1
  %conv71.38.16 = zext i8 %14855 to i32
  %xor72.38.16 = xor i32 %conv71.38.16, %conv68.38.16
  %conv73.38.16 = trunc i32 %xor72.38.16 to i8
  store i8 %conv73.38.16, i8* %arrayidx70.16, align 1
  %scevgep20.39.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 39
  %14856 = load i8, i8* %scevgep20.39.16, align 1
  %conv68.39.16 = zext i8 %14856 to i32
  %14857 = load i8, i8* %arrayidx70.16, align 1
  %conv71.39.16 = zext i8 %14857 to i32
  %xor72.39.16 = xor i32 %conv71.39.16, %conv68.39.16
  %conv73.39.16 = trunc i32 %xor72.39.16 to i8
  store i8 %conv73.39.16, i8* %arrayidx70.16, align 1
  %scevgep20.40.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 40
  %14858 = load i8, i8* %scevgep20.40.16, align 1
  %conv68.40.16 = zext i8 %14858 to i32
  %14859 = load i8, i8* %arrayidx70.16, align 1
  %conv71.40.16 = zext i8 %14859 to i32
  %xor72.40.16 = xor i32 %conv71.40.16, %conv68.40.16
  %conv73.40.16 = trunc i32 %xor72.40.16 to i8
  store i8 %conv73.40.16, i8* %arrayidx70.16, align 1
  %scevgep20.41.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 41
  %14860 = load i8, i8* %scevgep20.41.16, align 1
  %conv68.41.16 = zext i8 %14860 to i32
  %14861 = load i8, i8* %arrayidx70.16, align 1
  %conv71.41.16 = zext i8 %14861 to i32
  %xor72.41.16 = xor i32 %conv71.41.16, %conv68.41.16
  %conv73.41.16 = trunc i32 %xor72.41.16 to i8
  store i8 %conv73.41.16, i8* %arrayidx70.16, align 1
  %scevgep20.42.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 42
  %14862 = load i8, i8* %scevgep20.42.16, align 1
  %conv68.42.16 = zext i8 %14862 to i32
  %14863 = load i8, i8* %arrayidx70.16, align 1
  %conv71.42.16 = zext i8 %14863 to i32
  %xor72.42.16 = xor i32 %conv71.42.16, %conv68.42.16
  %conv73.42.16 = trunc i32 %xor72.42.16 to i8
  store i8 %conv73.42.16, i8* %arrayidx70.16, align 1
  %scevgep20.43.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 43
  %14864 = load i8, i8* %scevgep20.43.16, align 1
  %conv68.43.16 = zext i8 %14864 to i32
  %14865 = load i8, i8* %arrayidx70.16, align 1
  %conv71.43.16 = zext i8 %14865 to i32
  %xor72.43.16 = xor i32 %conv71.43.16, %conv68.43.16
  %conv73.43.16 = trunc i32 %xor72.43.16 to i8
  store i8 %conv73.43.16, i8* %arrayidx70.16, align 1
  %scevgep20.44.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 44
  %14866 = load i8, i8* %scevgep20.44.16, align 1
  %conv68.44.16 = zext i8 %14866 to i32
  %14867 = load i8, i8* %arrayidx70.16, align 1
  %conv71.44.16 = zext i8 %14867 to i32
  %xor72.44.16 = xor i32 %conv71.44.16, %conv68.44.16
  %conv73.44.16 = trunc i32 %xor72.44.16 to i8
  store i8 %conv73.44.16, i8* %arrayidx70.16, align 1
  %scevgep20.45.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 45
  %14868 = load i8, i8* %scevgep20.45.16, align 1
  %conv68.45.16 = zext i8 %14868 to i32
  %14869 = load i8, i8* %arrayidx70.16, align 1
  %conv71.45.16 = zext i8 %14869 to i32
  %xor72.45.16 = xor i32 %conv71.45.16, %conv68.45.16
  %conv73.45.16 = trunc i32 %xor72.45.16 to i8
  store i8 %conv73.45.16, i8* %arrayidx70.16, align 1
  %scevgep20.46.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 46
  %14870 = load i8, i8* %scevgep20.46.16, align 1
  %conv68.46.16 = zext i8 %14870 to i32
  %14871 = load i8, i8* %arrayidx70.16, align 1
  %conv71.46.16 = zext i8 %14871 to i32
  %xor72.46.16 = xor i32 %conv71.46.16, %conv68.46.16
  %conv73.46.16 = trunc i32 %xor72.46.16 to i8
  store i8 %conv73.46.16, i8* %arrayidx70.16, align 1
  %scevgep20.47.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 47
  %14872 = load i8, i8* %scevgep20.47.16, align 1
  %conv68.47.16 = zext i8 %14872 to i32
  %14873 = load i8, i8* %arrayidx70.16, align 1
  %conv71.47.16 = zext i8 %14873 to i32
  %xor72.47.16 = xor i32 %conv71.47.16, %conv68.47.16
  %conv73.47.16 = trunc i32 %xor72.47.16 to i8
  store i8 %conv73.47.16, i8* %arrayidx70.16, align 1
  %scevgep20.48.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 48
  %14874 = load i8, i8* %scevgep20.48.16, align 1
  %conv68.48.16 = zext i8 %14874 to i32
  %14875 = load i8, i8* %arrayidx70.16, align 1
  %conv71.48.16 = zext i8 %14875 to i32
  %xor72.48.16 = xor i32 %conv71.48.16, %conv68.48.16
  %conv73.48.16 = trunc i32 %xor72.48.16 to i8
  store i8 %conv73.48.16, i8* %arrayidx70.16, align 1
  %scevgep20.49.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 49
  %14876 = load i8, i8* %scevgep20.49.16, align 1
  %conv68.49.16 = zext i8 %14876 to i32
  %14877 = load i8, i8* %arrayidx70.16, align 1
  %conv71.49.16 = zext i8 %14877 to i32
  %xor72.49.16 = xor i32 %conv71.49.16, %conv68.49.16
  %conv73.49.16 = trunc i32 %xor72.49.16 to i8
  store i8 %conv73.49.16, i8* %arrayidx70.16, align 1
  %scevgep20.50.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 50
  %14878 = load i8, i8* %scevgep20.50.16, align 1
  %conv68.50.16 = zext i8 %14878 to i32
  %14879 = load i8, i8* %arrayidx70.16, align 1
  %conv71.50.16 = zext i8 %14879 to i32
  %xor72.50.16 = xor i32 %conv71.50.16, %conv68.50.16
  %conv73.50.16 = trunc i32 %xor72.50.16 to i8
  store i8 %conv73.50.16, i8* %arrayidx70.16, align 1
  %scevgep20.51.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 51
  %14880 = load i8, i8* %scevgep20.51.16, align 1
  %conv68.51.16 = zext i8 %14880 to i32
  %14881 = load i8, i8* %arrayidx70.16, align 1
  %conv71.51.16 = zext i8 %14881 to i32
  %xor72.51.16 = xor i32 %conv71.51.16, %conv68.51.16
  %conv73.51.16 = trunc i32 %xor72.51.16 to i8
  store i8 %conv73.51.16, i8* %arrayidx70.16, align 1
  %scevgep20.52.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 52
  %14882 = load i8, i8* %scevgep20.52.16, align 1
  %conv68.52.16 = zext i8 %14882 to i32
  %14883 = load i8, i8* %arrayidx70.16, align 1
  %conv71.52.16 = zext i8 %14883 to i32
  %xor72.52.16 = xor i32 %conv71.52.16, %conv68.52.16
  %conv73.52.16 = trunc i32 %xor72.52.16 to i8
  store i8 %conv73.52.16, i8* %arrayidx70.16, align 1
  %scevgep20.53.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 53
  %14884 = load i8, i8* %scevgep20.53.16, align 1
  %conv68.53.16 = zext i8 %14884 to i32
  %14885 = load i8, i8* %arrayidx70.16, align 1
  %conv71.53.16 = zext i8 %14885 to i32
  %xor72.53.16 = xor i32 %conv71.53.16, %conv68.53.16
  %conv73.53.16 = trunc i32 %xor72.53.16 to i8
  store i8 %conv73.53.16, i8* %arrayidx70.16, align 1
  %scevgep20.54.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 54
  %14886 = load i8, i8* %scevgep20.54.16, align 1
  %conv68.54.16 = zext i8 %14886 to i32
  %14887 = load i8, i8* %arrayidx70.16, align 1
  %conv71.54.16 = zext i8 %14887 to i32
  %xor72.54.16 = xor i32 %conv71.54.16, %conv68.54.16
  %conv73.54.16 = trunc i32 %xor72.54.16 to i8
  store i8 %conv73.54.16, i8* %arrayidx70.16, align 1
  %scevgep20.55.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 55
  %14888 = load i8, i8* %scevgep20.55.16, align 1
  %conv68.55.16 = zext i8 %14888 to i32
  %14889 = load i8, i8* %arrayidx70.16, align 1
  %conv71.55.16 = zext i8 %14889 to i32
  %xor72.55.16 = xor i32 %conv71.55.16, %conv68.55.16
  %conv73.55.16 = trunc i32 %xor72.55.16 to i8
  store i8 %conv73.55.16, i8* %arrayidx70.16, align 1
  %scevgep20.56.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 56
  %14890 = load i8, i8* %scevgep20.56.16, align 1
  %conv68.56.16 = zext i8 %14890 to i32
  %14891 = load i8, i8* %arrayidx70.16, align 1
  %conv71.56.16 = zext i8 %14891 to i32
  %xor72.56.16 = xor i32 %conv71.56.16, %conv68.56.16
  %conv73.56.16 = trunc i32 %xor72.56.16 to i8
  store i8 %conv73.56.16, i8* %arrayidx70.16, align 1
  %scevgep20.57.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 57
  %14892 = load i8, i8* %scevgep20.57.16, align 1
  %conv68.57.16 = zext i8 %14892 to i32
  %14893 = load i8, i8* %arrayidx70.16, align 1
  %conv71.57.16 = zext i8 %14893 to i32
  %xor72.57.16 = xor i32 %conv71.57.16, %conv68.57.16
  %conv73.57.16 = trunc i32 %xor72.57.16 to i8
  store i8 %conv73.57.16, i8* %arrayidx70.16, align 1
  %scevgep20.58.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 58
  %14894 = load i8, i8* %scevgep20.58.16, align 1
  %conv68.58.16 = zext i8 %14894 to i32
  %14895 = load i8, i8* %arrayidx70.16, align 1
  %conv71.58.16 = zext i8 %14895 to i32
  %xor72.58.16 = xor i32 %conv71.58.16, %conv68.58.16
  %conv73.58.16 = trunc i32 %xor72.58.16 to i8
  store i8 %conv73.58.16, i8* %arrayidx70.16, align 1
  %scevgep20.59.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 59
  %14896 = load i8, i8* %scevgep20.59.16, align 1
  %conv68.59.16 = zext i8 %14896 to i32
  %14897 = load i8, i8* %arrayidx70.16, align 1
  %conv71.59.16 = zext i8 %14897 to i32
  %xor72.59.16 = xor i32 %conv71.59.16, %conv68.59.16
  %conv73.59.16 = trunc i32 %xor72.59.16 to i8
  store i8 %conv73.59.16, i8* %arrayidx70.16, align 1
  %scevgep20.60.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 0, i64 60
  %14898 = load i8, i8* %scevgep20.60.16, align 1
  %conv68.60.16 = zext i8 %14898 to i32
  %14899 = load i8, i8* %arrayidx70.16, align 1
  %conv71.60.16 = zext i8 %14899 to i32
  %xor72.60.16 = xor i32 %conv71.60.16, %conv68.60.16
  %conv73.60.16 = trunc i32 %xor72.60.16 to i8
  store i8 %conv73.60.16, i8* %arrayidx70.16, align 1
  %scevgep19.16 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14777, i64 0, i64 1, i64 0
  %14900 = bitcast i8* %scevgep19.16 to [61 x [61 x i8]]*
  %arrayidx51.17 = getelementptr inbounds i8, i8* %a, i64 17
  %14901 = load i8, i8* %arrayidx51.17, align 1
  %arrayidx53.17 = getelementptr inbounds i8, i8* %b, i64 17
  %14902 = load i8, i8* %arrayidx53.17, align 1
  %call54.17 = call zeroext i8 @mult(i8 zeroext %14901, i8 zeroext %14902)
  %arrayidx56.17 = getelementptr inbounds i8, i8* %c, i64 17
  store i8 %call54.17, i8* %arrayidx56.17, align 1
  %arrayidx70.17 = getelementptr inbounds i8, i8* %c, i64 17
  %scevgep20.17214 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 0
  %14903 = load i8, i8* %scevgep20.17214, align 1
  %conv68.17215 = zext i8 %14903 to i32
  %14904 = load i8, i8* %arrayidx70.17, align 1
  %conv71.17216 = zext i8 %14904 to i32
  %xor72.17217 = xor i32 %conv71.17216, %conv68.17215
  %conv73.17218 = trunc i32 %xor72.17217 to i8
  store i8 %conv73.17218, i8* %arrayidx70.17, align 1
  %scevgep20.1.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 1
  %14905 = load i8, i8* %scevgep20.1.17, align 1
  %conv68.1.17 = zext i8 %14905 to i32
  %14906 = load i8, i8* %arrayidx70.17, align 1
  %conv71.1.17 = zext i8 %14906 to i32
  %xor72.1.17 = xor i32 %conv71.1.17, %conv68.1.17
  %conv73.1.17 = trunc i32 %xor72.1.17 to i8
  store i8 %conv73.1.17, i8* %arrayidx70.17, align 1
  %scevgep20.2.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 2
  %14907 = load i8, i8* %scevgep20.2.17, align 1
  %conv68.2.17 = zext i8 %14907 to i32
  %14908 = load i8, i8* %arrayidx70.17, align 1
  %conv71.2.17 = zext i8 %14908 to i32
  %xor72.2.17 = xor i32 %conv71.2.17, %conv68.2.17
  %conv73.2.17 = trunc i32 %xor72.2.17 to i8
  store i8 %conv73.2.17, i8* %arrayidx70.17, align 1
  %scevgep20.3.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 3
  %14909 = load i8, i8* %scevgep20.3.17, align 1
  %conv68.3.17 = zext i8 %14909 to i32
  %14910 = load i8, i8* %arrayidx70.17, align 1
  %conv71.3.17 = zext i8 %14910 to i32
  %xor72.3.17 = xor i32 %conv71.3.17, %conv68.3.17
  %conv73.3.17 = trunc i32 %xor72.3.17 to i8
  store i8 %conv73.3.17, i8* %arrayidx70.17, align 1
  %scevgep20.4.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 4
  %14911 = load i8, i8* %scevgep20.4.17, align 1
  %conv68.4.17 = zext i8 %14911 to i32
  %14912 = load i8, i8* %arrayidx70.17, align 1
  %conv71.4.17 = zext i8 %14912 to i32
  %xor72.4.17 = xor i32 %conv71.4.17, %conv68.4.17
  %conv73.4.17 = trunc i32 %xor72.4.17 to i8
  store i8 %conv73.4.17, i8* %arrayidx70.17, align 1
  %scevgep20.5.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 5
  %14913 = load i8, i8* %scevgep20.5.17, align 1
  %conv68.5.17 = zext i8 %14913 to i32
  %14914 = load i8, i8* %arrayidx70.17, align 1
  %conv71.5.17 = zext i8 %14914 to i32
  %xor72.5.17 = xor i32 %conv71.5.17, %conv68.5.17
  %conv73.5.17 = trunc i32 %xor72.5.17 to i8
  store i8 %conv73.5.17, i8* %arrayidx70.17, align 1
  %scevgep20.6.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 6
  %14915 = load i8, i8* %scevgep20.6.17, align 1
  %conv68.6.17 = zext i8 %14915 to i32
  %14916 = load i8, i8* %arrayidx70.17, align 1
  %conv71.6.17 = zext i8 %14916 to i32
  %xor72.6.17 = xor i32 %conv71.6.17, %conv68.6.17
  %conv73.6.17 = trunc i32 %xor72.6.17 to i8
  store i8 %conv73.6.17, i8* %arrayidx70.17, align 1
  %scevgep20.7.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 7
  %14917 = load i8, i8* %scevgep20.7.17, align 1
  %conv68.7.17 = zext i8 %14917 to i32
  %14918 = load i8, i8* %arrayidx70.17, align 1
  %conv71.7.17 = zext i8 %14918 to i32
  %xor72.7.17 = xor i32 %conv71.7.17, %conv68.7.17
  %conv73.7.17 = trunc i32 %xor72.7.17 to i8
  store i8 %conv73.7.17, i8* %arrayidx70.17, align 1
  %scevgep20.8.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 8
  %14919 = load i8, i8* %scevgep20.8.17, align 1
  %conv68.8.17 = zext i8 %14919 to i32
  %14920 = load i8, i8* %arrayidx70.17, align 1
  %conv71.8.17 = zext i8 %14920 to i32
  %xor72.8.17 = xor i32 %conv71.8.17, %conv68.8.17
  %conv73.8.17 = trunc i32 %xor72.8.17 to i8
  store i8 %conv73.8.17, i8* %arrayidx70.17, align 1
  %scevgep20.9.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 9
  %14921 = load i8, i8* %scevgep20.9.17, align 1
  %conv68.9.17 = zext i8 %14921 to i32
  %14922 = load i8, i8* %arrayidx70.17, align 1
  %conv71.9.17 = zext i8 %14922 to i32
  %xor72.9.17 = xor i32 %conv71.9.17, %conv68.9.17
  %conv73.9.17 = trunc i32 %xor72.9.17 to i8
  store i8 %conv73.9.17, i8* %arrayidx70.17, align 1
  %scevgep20.10.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 10
  %14923 = load i8, i8* %scevgep20.10.17, align 1
  %conv68.10.17 = zext i8 %14923 to i32
  %14924 = load i8, i8* %arrayidx70.17, align 1
  %conv71.10.17 = zext i8 %14924 to i32
  %xor72.10.17 = xor i32 %conv71.10.17, %conv68.10.17
  %conv73.10.17 = trunc i32 %xor72.10.17 to i8
  store i8 %conv73.10.17, i8* %arrayidx70.17, align 1
  %scevgep20.11.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 11
  %14925 = load i8, i8* %scevgep20.11.17, align 1
  %conv68.11.17 = zext i8 %14925 to i32
  %14926 = load i8, i8* %arrayidx70.17, align 1
  %conv71.11.17 = zext i8 %14926 to i32
  %xor72.11.17 = xor i32 %conv71.11.17, %conv68.11.17
  %conv73.11.17 = trunc i32 %xor72.11.17 to i8
  store i8 %conv73.11.17, i8* %arrayidx70.17, align 1
  %scevgep20.12.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 12
  %14927 = load i8, i8* %scevgep20.12.17, align 1
  %conv68.12.17 = zext i8 %14927 to i32
  %14928 = load i8, i8* %arrayidx70.17, align 1
  %conv71.12.17 = zext i8 %14928 to i32
  %xor72.12.17 = xor i32 %conv71.12.17, %conv68.12.17
  %conv73.12.17 = trunc i32 %xor72.12.17 to i8
  store i8 %conv73.12.17, i8* %arrayidx70.17, align 1
  %scevgep20.13.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 13
  %14929 = load i8, i8* %scevgep20.13.17, align 1
  %conv68.13.17 = zext i8 %14929 to i32
  %14930 = load i8, i8* %arrayidx70.17, align 1
  %conv71.13.17 = zext i8 %14930 to i32
  %xor72.13.17 = xor i32 %conv71.13.17, %conv68.13.17
  %conv73.13.17 = trunc i32 %xor72.13.17 to i8
  store i8 %conv73.13.17, i8* %arrayidx70.17, align 1
  %scevgep20.14.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 14
  %14931 = load i8, i8* %scevgep20.14.17, align 1
  %conv68.14.17 = zext i8 %14931 to i32
  %14932 = load i8, i8* %arrayidx70.17, align 1
  %conv71.14.17 = zext i8 %14932 to i32
  %xor72.14.17 = xor i32 %conv71.14.17, %conv68.14.17
  %conv73.14.17 = trunc i32 %xor72.14.17 to i8
  store i8 %conv73.14.17, i8* %arrayidx70.17, align 1
  %scevgep20.15.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 15
  %14933 = load i8, i8* %scevgep20.15.17, align 1
  %conv68.15.17 = zext i8 %14933 to i32
  %14934 = load i8, i8* %arrayidx70.17, align 1
  %conv71.15.17 = zext i8 %14934 to i32
  %xor72.15.17 = xor i32 %conv71.15.17, %conv68.15.17
  %conv73.15.17 = trunc i32 %xor72.15.17 to i8
  store i8 %conv73.15.17, i8* %arrayidx70.17, align 1
  %scevgep20.16.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 16
  %14935 = load i8, i8* %scevgep20.16.17, align 1
  %conv68.16.17 = zext i8 %14935 to i32
  %14936 = load i8, i8* %arrayidx70.17, align 1
  %conv71.16.17 = zext i8 %14936 to i32
  %xor72.16.17 = xor i32 %conv71.16.17, %conv68.16.17
  %conv73.16.17 = trunc i32 %xor72.16.17 to i8
  store i8 %conv73.16.17, i8* %arrayidx70.17, align 1
  %scevgep20.18.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 18
  %14937 = load i8, i8* %scevgep20.18.17, align 1
  %conv68.18.17 = zext i8 %14937 to i32
  %14938 = load i8, i8* %arrayidx70.17, align 1
  %conv71.18.17 = zext i8 %14938 to i32
  %xor72.18.17 = xor i32 %conv71.18.17, %conv68.18.17
  %conv73.18.17 = trunc i32 %xor72.18.17 to i8
  store i8 %conv73.18.17, i8* %arrayidx70.17, align 1
  %scevgep20.19.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 19
  %14939 = load i8, i8* %scevgep20.19.17, align 1
  %conv68.19.17 = zext i8 %14939 to i32
  %14940 = load i8, i8* %arrayidx70.17, align 1
  %conv71.19.17 = zext i8 %14940 to i32
  %xor72.19.17 = xor i32 %conv71.19.17, %conv68.19.17
  %conv73.19.17 = trunc i32 %xor72.19.17 to i8
  store i8 %conv73.19.17, i8* %arrayidx70.17, align 1
  %scevgep20.20.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 20
  %14941 = load i8, i8* %scevgep20.20.17, align 1
  %conv68.20.17 = zext i8 %14941 to i32
  %14942 = load i8, i8* %arrayidx70.17, align 1
  %conv71.20.17 = zext i8 %14942 to i32
  %xor72.20.17 = xor i32 %conv71.20.17, %conv68.20.17
  %conv73.20.17 = trunc i32 %xor72.20.17 to i8
  store i8 %conv73.20.17, i8* %arrayidx70.17, align 1
  %scevgep20.21.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 21
  %14943 = load i8, i8* %scevgep20.21.17, align 1
  %conv68.21.17 = zext i8 %14943 to i32
  %14944 = load i8, i8* %arrayidx70.17, align 1
  %conv71.21.17 = zext i8 %14944 to i32
  %xor72.21.17 = xor i32 %conv71.21.17, %conv68.21.17
  %conv73.21.17 = trunc i32 %xor72.21.17 to i8
  store i8 %conv73.21.17, i8* %arrayidx70.17, align 1
  %scevgep20.22.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 22
  %14945 = load i8, i8* %scevgep20.22.17, align 1
  %conv68.22.17 = zext i8 %14945 to i32
  %14946 = load i8, i8* %arrayidx70.17, align 1
  %conv71.22.17 = zext i8 %14946 to i32
  %xor72.22.17 = xor i32 %conv71.22.17, %conv68.22.17
  %conv73.22.17 = trunc i32 %xor72.22.17 to i8
  store i8 %conv73.22.17, i8* %arrayidx70.17, align 1
  %scevgep20.23.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 23
  %14947 = load i8, i8* %scevgep20.23.17, align 1
  %conv68.23.17 = zext i8 %14947 to i32
  %14948 = load i8, i8* %arrayidx70.17, align 1
  %conv71.23.17 = zext i8 %14948 to i32
  %xor72.23.17 = xor i32 %conv71.23.17, %conv68.23.17
  %conv73.23.17 = trunc i32 %xor72.23.17 to i8
  store i8 %conv73.23.17, i8* %arrayidx70.17, align 1
  %scevgep20.24.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 24
  %14949 = load i8, i8* %scevgep20.24.17, align 1
  %conv68.24.17 = zext i8 %14949 to i32
  %14950 = load i8, i8* %arrayidx70.17, align 1
  %conv71.24.17 = zext i8 %14950 to i32
  %xor72.24.17 = xor i32 %conv71.24.17, %conv68.24.17
  %conv73.24.17 = trunc i32 %xor72.24.17 to i8
  store i8 %conv73.24.17, i8* %arrayidx70.17, align 1
  %scevgep20.25.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 25
  %14951 = load i8, i8* %scevgep20.25.17, align 1
  %conv68.25.17 = zext i8 %14951 to i32
  %14952 = load i8, i8* %arrayidx70.17, align 1
  %conv71.25.17 = zext i8 %14952 to i32
  %xor72.25.17 = xor i32 %conv71.25.17, %conv68.25.17
  %conv73.25.17 = trunc i32 %xor72.25.17 to i8
  store i8 %conv73.25.17, i8* %arrayidx70.17, align 1
  %scevgep20.26.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 26
  %14953 = load i8, i8* %scevgep20.26.17, align 1
  %conv68.26.17 = zext i8 %14953 to i32
  %14954 = load i8, i8* %arrayidx70.17, align 1
  %conv71.26.17 = zext i8 %14954 to i32
  %xor72.26.17 = xor i32 %conv71.26.17, %conv68.26.17
  %conv73.26.17 = trunc i32 %xor72.26.17 to i8
  store i8 %conv73.26.17, i8* %arrayidx70.17, align 1
  %scevgep20.27.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 27
  %14955 = load i8, i8* %scevgep20.27.17, align 1
  %conv68.27.17 = zext i8 %14955 to i32
  %14956 = load i8, i8* %arrayidx70.17, align 1
  %conv71.27.17 = zext i8 %14956 to i32
  %xor72.27.17 = xor i32 %conv71.27.17, %conv68.27.17
  %conv73.27.17 = trunc i32 %xor72.27.17 to i8
  store i8 %conv73.27.17, i8* %arrayidx70.17, align 1
  %scevgep20.28.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 28
  %14957 = load i8, i8* %scevgep20.28.17, align 1
  %conv68.28.17 = zext i8 %14957 to i32
  %14958 = load i8, i8* %arrayidx70.17, align 1
  %conv71.28.17 = zext i8 %14958 to i32
  %xor72.28.17 = xor i32 %conv71.28.17, %conv68.28.17
  %conv73.28.17 = trunc i32 %xor72.28.17 to i8
  store i8 %conv73.28.17, i8* %arrayidx70.17, align 1
  %scevgep20.29.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 29
  %14959 = load i8, i8* %scevgep20.29.17, align 1
  %conv68.29.17 = zext i8 %14959 to i32
  %14960 = load i8, i8* %arrayidx70.17, align 1
  %conv71.29.17 = zext i8 %14960 to i32
  %xor72.29.17 = xor i32 %conv71.29.17, %conv68.29.17
  %conv73.29.17 = trunc i32 %xor72.29.17 to i8
  store i8 %conv73.29.17, i8* %arrayidx70.17, align 1
  %scevgep20.30.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 30
  %14961 = load i8, i8* %scevgep20.30.17, align 1
  %conv68.30.17 = zext i8 %14961 to i32
  %14962 = load i8, i8* %arrayidx70.17, align 1
  %conv71.30.17 = zext i8 %14962 to i32
  %xor72.30.17 = xor i32 %conv71.30.17, %conv68.30.17
  %conv73.30.17 = trunc i32 %xor72.30.17 to i8
  store i8 %conv73.30.17, i8* %arrayidx70.17, align 1
  %scevgep20.31.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 31
  %14963 = load i8, i8* %scevgep20.31.17, align 1
  %conv68.31.17 = zext i8 %14963 to i32
  %14964 = load i8, i8* %arrayidx70.17, align 1
  %conv71.31.17 = zext i8 %14964 to i32
  %xor72.31.17 = xor i32 %conv71.31.17, %conv68.31.17
  %conv73.31.17 = trunc i32 %xor72.31.17 to i8
  store i8 %conv73.31.17, i8* %arrayidx70.17, align 1
  %scevgep20.32.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 32
  %14965 = load i8, i8* %scevgep20.32.17, align 1
  %conv68.32.17 = zext i8 %14965 to i32
  %14966 = load i8, i8* %arrayidx70.17, align 1
  %conv71.32.17 = zext i8 %14966 to i32
  %xor72.32.17 = xor i32 %conv71.32.17, %conv68.32.17
  %conv73.32.17 = trunc i32 %xor72.32.17 to i8
  store i8 %conv73.32.17, i8* %arrayidx70.17, align 1
  %scevgep20.33.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 33
  %14967 = load i8, i8* %scevgep20.33.17, align 1
  %conv68.33.17 = zext i8 %14967 to i32
  %14968 = load i8, i8* %arrayidx70.17, align 1
  %conv71.33.17 = zext i8 %14968 to i32
  %xor72.33.17 = xor i32 %conv71.33.17, %conv68.33.17
  %conv73.33.17 = trunc i32 %xor72.33.17 to i8
  store i8 %conv73.33.17, i8* %arrayidx70.17, align 1
  %scevgep20.34.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 34
  %14969 = load i8, i8* %scevgep20.34.17, align 1
  %conv68.34.17 = zext i8 %14969 to i32
  %14970 = load i8, i8* %arrayidx70.17, align 1
  %conv71.34.17 = zext i8 %14970 to i32
  %xor72.34.17 = xor i32 %conv71.34.17, %conv68.34.17
  %conv73.34.17 = trunc i32 %xor72.34.17 to i8
  store i8 %conv73.34.17, i8* %arrayidx70.17, align 1
  %scevgep20.35.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 35
  %14971 = load i8, i8* %scevgep20.35.17, align 1
  %conv68.35.17 = zext i8 %14971 to i32
  %14972 = load i8, i8* %arrayidx70.17, align 1
  %conv71.35.17 = zext i8 %14972 to i32
  %xor72.35.17 = xor i32 %conv71.35.17, %conv68.35.17
  %conv73.35.17 = trunc i32 %xor72.35.17 to i8
  store i8 %conv73.35.17, i8* %arrayidx70.17, align 1
  %scevgep20.36.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 36
  %14973 = load i8, i8* %scevgep20.36.17, align 1
  %conv68.36.17 = zext i8 %14973 to i32
  %14974 = load i8, i8* %arrayidx70.17, align 1
  %conv71.36.17 = zext i8 %14974 to i32
  %xor72.36.17 = xor i32 %conv71.36.17, %conv68.36.17
  %conv73.36.17 = trunc i32 %xor72.36.17 to i8
  store i8 %conv73.36.17, i8* %arrayidx70.17, align 1
  %scevgep20.37.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 37
  %14975 = load i8, i8* %scevgep20.37.17, align 1
  %conv68.37.17 = zext i8 %14975 to i32
  %14976 = load i8, i8* %arrayidx70.17, align 1
  %conv71.37.17 = zext i8 %14976 to i32
  %xor72.37.17 = xor i32 %conv71.37.17, %conv68.37.17
  %conv73.37.17 = trunc i32 %xor72.37.17 to i8
  store i8 %conv73.37.17, i8* %arrayidx70.17, align 1
  %scevgep20.38.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 38
  %14977 = load i8, i8* %scevgep20.38.17, align 1
  %conv68.38.17 = zext i8 %14977 to i32
  %14978 = load i8, i8* %arrayidx70.17, align 1
  %conv71.38.17 = zext i8 %14978 to i32
  %xor72.38.17 = xor i32 %conv71.38.17, %conv68.38.17
  %conv73.38.17 = trunc i32 %xor72.38.17 to i8
  store i8 %conv73.38.17, i8* %arrayidx70.17, align 1
  %scevgep20.39.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 39
  %14979 = load i8, i8* %scevgep20.39.17, align 1
  %conv68.39.17 = zext i8 %14979 to i32
  %14980 = load i8, i8* %arrayidx70.17, align 1
  %conv71.39.17 = zext i8 %14980 to i32
  %xor72.39.17 = xor i32 %conv71.39.17, %conv68.39.17
  %conv73.39.17 = trunc i32 %xor72.39.17 to i8
  store i8 %conv73.39.17, i8* %arrayidx70.17, align 1
  %scevgep20.40.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 40
  %14981 = load i8, i8* %scevgep20.40.17, align 1
  %conv68.40.17 = zext i8 %14981 to i32
  %14982 = load i8, i8* %arrayidx70.17, align 1
  %conv71.40.17 = zext i8 %14982 to i32
  %xor72.40.17 = xor i32 %conv71.40.17, %conv68.40.17
  %conv73.40.17 = trunc i32 %xor72.40.17 to i8
  store i8 %conv73.40.17, i8* %arrayidx70.17, align 1
  %scevgep20.41.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 41
  %14983 = load i8, i8* %scevgep20.41.17, align 1
  %conv68.41.17 = zext i8 %14983 to i32
  %14984 = load i8, i8* %arrayidx70.17, align 1
  %conv71.41.17 = zext i8 %14984 to i32
  %xor72.41.17 = xor i32 %conv71.41.17, %conv68.41.17
  %conv73.41.17 = trunc i32 %xor72.41.17 to i8
  store i8 %conv73.41.17, i8* %arrayidx70.17, align 1
  %scevgep20.42.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 42
  %14985 = load i8, i8* %scevgep20.42.17, align 1
  %conv68.42.17 = zext i8 %14985 to i32
  %14986 = load i8, i8* %arrayidx70.17, align 1
  %conv71.42.17 = zext i8 %14986 to i32
  %xor72.42.17 = xor i32 %conv71.42.17, %conv68.42.17
  %conv73.42.17 = trunc i32 %xor72.42.17 to i8
  store i8 %conv73.42.17, i8* %arrayidx70.17, align 1
  %scevgep20.43.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 43
  %14987 = load i8, i8* %scevgep20.43.17, align 1
  %conv68.43.17 = zext i8 %14987 to i32
  %14988 = load i8, i8* %arrayidx70.17, align 1
  %conv71.43.17 = zext i8 %14988 to i32
  %xor72.43.17 = xor i32 %conv71.43.17, %conv68.43.17
  %conv73.43.17 = trunc i32 %xor72.43.17 to i8
  store i8 %conv73.43.17, i8* %arrayidx70.17, align 1
  %scevgep20.44.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 44
  %14989 = load i8, i8* %scevgep20.44.17, align 1
  %conv68.44.17 = zext i8 %14989 to i32
  %14990 = load i8, i8* %arrayidx70.17, align 1
  %conv71.44.17 = zext i8 %14990 to i32
  %xor72.44.17 = xor i32 %conv71.44.17, %conv68.44.17
  %conv73.44.17 = trunc i32 %xor72.44.17 to i8
  store i8 %conv73.44.17, i8* %arrayidx70.17, align 1
  %scevgep20.45.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 45
  %14991 = load i8, i8* %scevgep20.45.17, align 1
  %conv68.45.17 = zext i8 %14991 to i32
  %14992 = load i8, i8* %arrayidx70.17, align 1
  %conv71.45.17 = zext i8 %14992 to i32
  %xor72.45.17 = xor i32 %conv71.45.17, %conv68.45.17
  %conv73.45.17 = trunc i32 %xor72.45.17 to i8
  store i8 %conv73.45.17, i8* %arrayidx70.17, align 1
  %scevgep20.46.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 46
  %14993 = load i8, i8* %scevgep20.46.17, align 1
  %conv68.46.17 = zext i8 %14993 to i32
  %14994 = load i8, i8* %arrayidx70.17, align 1
  %conv71.46.17 = zext i8 %14994 to i32
  %xor72.46.17 = xor i32 %conv71.46.17, %conv68.46.17
  %conv73.46.17 = trunc i32 %xor72.46.17 to i8
  store i8 %conv73.46.17, i8* %arrayidx70.17, align 1
  %scevgep20.47.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 47
  %14995 = load i8, i8* %scevgep20.47.17, align 1
  %conv68.47.17 = zext i8 %14995 to i32
  %14996 = load i8, i8* %arrayidx70.17, align 1
  %conv71.47.17 = zext i8 %14996 to i32
  %xor72.47.17 = xor i32 %conv71.47.17, %conv68.47.17
  %conv73.47.17 = trunc i32 %xor72.47.17 to i8
  store i8 %conv73.47.17, i8* %arrayidx70.17, align 1
  %scevgep20.48.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 48
  %14997 = load i8, i8* %scevgep20.48.17, align 1
  %conv68.48.17 = zext i8 %14997 to i32
  %14998 = load i8, i8* %arrayidx70.17, align 1
  %conv71.48.17 = zext i8 %14998 to i32
  %xor72.48.17 = xor i32 %conv71.48.17, %conv68.48.17
  %conv73.48.17 = trunc i32 %xor72.48.17 to i8
  store i8 %conv73.48.17, i8* %arrayidx70.17, align 1
  %scevgep20.49.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 49
  %14999 = load i8, i8* %scevgep20.49.17, align 1
  %conv68.49.17 = zext i8 %14999 to i32
  %15000 = load i8, i8* %arrayidx70.17, align 1
  %conv71.49.17 = zext i8 %15000 to i32
  %xor72.49.17 = xor i32 %conv71.49.17, %conv68.49.17
  %conv73.49.17 = trunc i32 %xor72.49.17 to i8
  store i8 %conv73.49.17, i8* %arrayidx70.17, align 1
  %scevgep20.50.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 50
  %15001 = load i8, i8* %scevgep20.50.17, align 1
  %conv68.50.17 = zext i8 %15001 to i32
  %15002 = load i8, i8* %arrayidx70.17, align 1
  %conv71.50.17 = zext i8 %15002 to i32
  %xor72.50.17 = xor i32 %conv71.50.17, %conv68.50.17
  %conv73.50.17 = trunc i32 %xor72.50.17 to i8
  store i8 %conv73.50.17, i8* %arrayidx70.17, align 1
  %scevgep20.51.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 51
  %15003 = load i8, i8* %scevgep20.51.17, align 1
  %conv68.51.17 = zext i8 %15003 to i32
  %15004 = load i8, i8* %arrayidx70.17, align 1
  %conv71.51.17 = zext i8 %15004 to i32
  %xor72.51.17 = xor i32 %conv71.51.17, %conv68.51.17
  %conv73.51.17 = trunc i32 %xor72.51.17 to i8
  store i8 %conv73.51.17, i8* %arrayidx70.17, align 1
  %scevgep20.52.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 52
  %15005 = load i8, i8* %scevgep20.52.17, align 1
  %conv68.52.17 = zext i8 %15005 to i32
  %15006 = load i8, i8* %arrayidx70.17, align 1
  %conv71.52.17 = zext i8 %15006 to i32
  %xor72.52.17 = xor i32 %conv71.52.17, %conv68.52.17
  %conv73.52.17 = trunc i32 %xor72.52.17 to i8
  store i8 %conv73.52.17, i8* %arrayidx70.17, align 1
  %scevgep20.53.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 53
  %15007 = load i8, i8* %scevgep20.53.17, align 1
  %conv68.53.17 = zext i8 %15007 to i32
  %15008 = load i8, i8* %arrayidx70.17, align 1
  %conv71.53.17 = zext i8 %15008 to i32
  %xor72.53.17 = xor i32 %conv71.53.17, %conv68.53.17
  %conv73.53.17 = trunc i32 %xor72.53.17 to i8
  store i8 %conv73.53.17, i8* %arrayidx70.17, align 1
  %scevgep20.54.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 54
  %15009 = load i8, i8* %scevgep20.54.17, align 1
  %conv68.54.17 = zext i8 %15009 to i32
  %15010 = load i8, i8* %arrayidx70.17, align 1
  %conv71.54.17 = zext i8 %15010 to i32
  %xor72.54.17 = xor i32 %conv71.54.17, %conv68.54.17
  %conv73.54.17 = trunc i32 %xor72.54.17 to i8
  store i8 %conv73.54.17, i8* %arrayidx70.17, align 1
  %scevgep20.55.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 55
  %15011 = load i8, i8* %scevgep20.55.17, align 1
  %conv68.55.17 = zext i8 %15011 to i32
  %15012 = load i8, i8* %arrayidx70.17, align 1
  %conv71.55.17 = zext i8 %15012 to i32
  %xor72.55.17 = xor i32 %conv71.55.17, %conv68.55.17
  %conv73.55.17 = trunc i32 %xor72.55.17 to i8
  store i8 %conv73.55.17, i8* %arrayidx70.17, align 1
  %scevgep20.56.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 56
  %15013 = load i8, i8* %scevgep20.56.17, align 1
  %conv68.56.17 = zext i8 %15013 to i32
  %15014 = load i8, i8* %arrayidx70.17, align 1
  %conv71.56.17 = zext i8 %15014 to i32
  %xor72.56.17 = xor i32 %conv71.56.17, %conv68.56.17
  %conv73.56.17 = trunc i32 %xor72.56.17 to i8
  store i8 %conv73.56.17, i8* %arrayidx70.17, align 1
  %scevgep20.57.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 57
  %15015 = load i8, i8* %scevgep20.57.17, align 1
  %conv68.57.17 = zext i8 %15015 to i32
  %15016 = load i8, i8* %arrayidx70.17, align 1
  %conv71.57.17 = zext i8 %15016 to i32
  %xor72.57.17 = xor i32 %conv71.57.17, %conv68.57.17
  %conv73.57.17 = trunc i32 %xor72.57.17 to i8
  store i8 %conv73.57.17, i8* %arrayidx70.17, align 1
  %scevgep20.58.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 58
  %15017 = load i8, i8* %scevgep20.58.17, align 1
  %conv68.58.17 = zext i8 %15017 to i32
  %15018 = load i8, i8* %arrayidx70.17, align 1
  %conv71.58.17 = zext i8 %15018 to i32
  %xor72.58.17 = xor i32 %conv71.58.17, %conv68.58.17
  %conv73.58.17 = trunc i32 %xor72.58.17 to i8
  store i8 %conv73.58.17, i8* %arrayidx70.17, align 1
  %scevgep20.59.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 59
  %15019 = load i8, i8* %scevgep20.59.17, align 1
  %conv68.59.17 = zext i8 %15019 to i32
  %15020 = load i8, i8* %arrayidx70.17, align 1
  %conv71.59.17 = zext i8 %15020 to i32
  %xor72.59.17 = xor i32 %conv71.59.17, %conv68.59.17
  %conv73.59.17 = trunc i32 %xor72.59.17 to i8
  store i8 %conv73.59.17, i8* %arrayidx70.17, align 1
  %scevgep20.60.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 0, i64 60
  %15021 = load i8, i8* %scevgep20.60.17, align 1
  %conv68.60.17 = zext i8 %15021 to i32
  %15022 = load i8, i8* %arrayidx70.17, align 1
  %conv71.60.17 = zext i8 %15022 to i32
  %xor72.60.17 = xor i32 %conv71.60.17, %conv68.60.17
  %conv73.60.17 = trunc i32 %xor72.60.17 to i8
  store i8 %conv73.60.17, i8* %arrayidx70.17, align 1
  %scevgep19.17 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %14900, i64 0, i64 1, i64 0
  %15023 = bitcast i8* %scevgep19.17 to [61 x [61 x i8]]*
  %arrayidx51.18 = getelementptr inbounds i8, i8* %a, i64 18
  %15024 = load i8, i8* %arrayidx51.18, align 1
  %arrayidx53.18 = getelementptr inbounds i8, i8* %b, i64 18
  %15025 = load i8, i8* %arrayidx53.18, align 1
  %call54.18 = call zeroext i8 @mult(i8 zeroext %15024, i8 zeroext %15025)
  %arrayidx56.18 = getelementptr inbounds i8, i8* %c, i64 18
  store i8 %call54.18, i8* %arrayidx56.18, align 1
  %arrayidx70.18 = getelementptr inbounds i8, i8* %c, i64 18
  %scevgep20.18224 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 0
  %15026 = load i8, i8* %scevgep20.18224, align 1
  %conv68.18225 = zext i8 %15026 to i32
  %15027 = load i8, i8* %arrayidx70.18, align 1
  %conv71.18226 = zext i8 %15027 to i32
  %xor72.18227 = xor i32 %conv71.18226, %conv68.18225
  %conv73.18228 = trunc i32 %xor72.18227 to i8
  store i8 %conv73.18228, i8* %arrayidx70.18, align 1
  %scevgep20.1.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 1
  %15028 = load i8, i8* %scevgep20.1.18, align 1
  %conv68.1.18 = zext i8 %15028 to i32
  %15029 = load i8, i8* %arrayidx70.18, align 1
  %conv71.1.18 = zext i8 %15029 to i32
  %xor72.1.18 = xor i32 %conv71.1.18, %conv68.1.18
  %conv73.1.18 = trunc i32 %xor72.1.18 to i8
  store i8 %conv73.1.18, i8* %arrayidx70.18, align 1
  %scevgep20.2.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 2
  %15030 = load i8, i8* %scevgep20.2.18, align 1
  %conv68.2.18 = zext i8 %15030 to i32
  %15031 = load i8, i8* %arrayidx70.18, align 1
  %conv71.2.18 = zext i8 %15031 to i32
  %xor72.2.18 = xor i32 %conv71.2.18, %conv68.2.18
  %conv73.2.18 = trunc i32 %xor72.2.18 to i8
  store i8 %conv73.2.18, i8* %arrayidx70.18, align 1
  %scevgep20.3.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 3
  %15032 = load i8, i8* %scevgep20.3.18, align 1
  %conv68.3.18 = zext i8 %15032 to i32
  %15033 = load i8, i8* %arrayidx70.18, align 1
  %conv71.3.18 = zext i8 %15033 to i32
  %xor72.3.18 = xor i32 %conv71.3.18, %conv68.3.18
  %conv73.3.18 = trunc i32 %xor72.3.18 to i8
  store i8 %conv73.3.18, i8* %arrayidx70.18, align 1
  %scevgep20.4.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 4
  %15034 = load i8, i8* %scevgep20.4.18, align 1
  %conv68.4.18 = zext i8 %15034 to i32
  %15035 = load i8, i8* %arrayidx70.18, align 1
  %conv71.4.18 = zext i8 %15035 to i32
  %xor72.4.18 = xor i32 %conv71.4.18, %conv68.4.18
  %conv73.4.18 = trunc i32 %xor72.4.18 to i8
  store i8 %conv73.4.18, i8* %arrayidx70.18, align 1
  %scevgep20.5.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 5
  %15036 = load i8, i8* %scevgep20.5.18, align 1
  %conv68.5.18 = zext i8 %15036 to i32
  %15037 = load i8, i8* %arrayidx70.18, align 1
  %conv71.5.18 = zext i8 %15037 to i32
  %xor72.5.18 = xor i32 %conv71.5.18, %conv68.5.18
  %conv73.5.18 = trunc i32 %xor72.5.18 to i8
  store i8 %conv73.5.18, i8* %arrayidx70.18, align 1
  %scevgep20.6.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 6
  %15038 = load i8, i8* %scevgep20.6.18, align 1
  %conv68.6.18 = zext i8 %15038 to i32
  %15039 = load i8, i8* %arrayidx70.18, align 1
  %conv71.6.18 = zext i8 %15039 to i32
  %xor72.6.18 = xor i32 %conv71.6.18, %conv68.6.18
  %conv73.6.18 = trunc i32 %xor72.6.18 to i8
  store i8 %conv73.6.18, i8* %arrayidx70.18, align 1
  %scevgep20.7.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 7
  %15040 = load i8, i8* %scevgep20.7.18, align 1
  %conv68.7.18 = zext i8 %15040 to i32
  %15041 = load i8, i8* %arrayidx70.18, align 1
  %conv71.7.18 = zext i8 %15041 to i32
  %xor72.7.18 = xor i32 %conv71.7.18, %conv68.7.18
  %conv73.7.18 = trunc i32 %xor72.7.18 to i8
  store i8 %conv73.7.18, i8* %arrayidx70.18, align 1
  %scevgep20.8.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 8
  %15042 = load i8, i8* %scevgep20.8.18, align 1
  %conv68.8.18 = zext i8 %15042 to i32
  %15043 = load i8, i8* %arrayidx70.18, align 1
  %conv71.8.18 = zext i8 %15043 to i32
  %xor72.8.18 = xor i32 %conv71.8.18, %conv68.8.18
  %conv73.8.18 = trunc i32 %xor72.8.18 to i8
  store i8 %conv73.8.18, i8* %arrayidx70.18, align 1
  %scevgep20.9.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 9
  %15044 = load i8, i8* %scevgep20.9.18, align 1
  %conv68.9.18 = zext i8 %15044 to i32
  %15045 = load i8, i8* %arrayidx70.18, align 1
  %conv71.9.18 = zext i8 %15045 to i32
  %xor72.9.18 = xor i32 %conv71.9.18, %conv68.9.18
  %conv73.9.18 = trunc i32 %xor72.9.18 to i8
  store i8 %conv73.9.18, i8* %arrayidx70.18, align 1
  %scevgep20.10.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 10
  %15046 = load i8, i8* %scevgep20.10.18, align 1
  %conv68.10.18 = zext i8 %15046 to i32
  %15047 = load i8, i8* %arrayidx70.18, align 1
  %conv71.10.18 = zext i8 %15047 to i32
  %xor72.10.18 = xor i32 %conv71.10.18, %conv68.10.18
  %conv73.10.18 = trunc i32 %xor72.10.18 to i8
  store i8 %conv73.10.18, i8* %arrayidx70.18, align 1
  %scevgep20.11.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 11
  %15048 = load i8, i8* %scevgep20.11.18, align 1
  %conv68.11.18 = zext i8 %15048 to i32
  %15049 = load i8, i8* %arrayidx70.18, align 1
  %conv71.11.18 = zext i8 %15049 to i32
  %xor72.11.18 = xor i32 %conv71.11.18, %conv68.11.18
  %conv73.11.18 = trunc i32 %xor72.11.18 to i8
  store i8 %conv73.11.18, i8* %arrayidx70.18, align 1
  %scevgep20.12.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 12
  %15050 = load i8, i8* %scevgep20.12.18, align 1
  %conv68.12.18 = zext i8 %15050 to i32
  %15051 = load i8, i8* %arrayidx70.18, align 1
  %conv71.12.18 = zext i8 %15051 to i32
  %xor72.12.18 = xor i32 %conv71.12.18, %conv68.12.18
  %conv73.12.18 = trunc i32 %xor72.12.18 to i8
  store i8 %conv73.12.18, i8* %arrayidx70.18, align 1
  %scevgep20.13.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 13
  %15052 = load i8, i8* %scevgep20.13.18, align 1
  %conv68.13.18 = zext i8 %15052 to i32
  %15053 = load i8, i8* %arrayidx70.18, align 1
  %conv71.13.18 = zext i8 %15053 to i32
  %xor72.13.18 = xor i32 %conv71.13.18, %conv68.13.18
  %conv73.13.18 = trunc i32 %xor72.13.18 to i8
  store i8 %conv73.13.18, i8* %arrayidx70.18, align 1
  %scevgep20.14.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 14
  %15054 = load i8, i8* %scevgep20.14.18, align 1
  %conv68.14.18 = zext i8 %15054 to i32
  %15055 = load i8, i8* %arrayidx70.18, align 1
  %conv71.14.18 = zext i8 %15055 to i32
  %xor72.14.18 = xor i32 %conv71.14.18, %conv68.14.18
  %conv73.14.18 = trunc i32 %xor72.14.18 to i8
  store i8 %conv73.14.18, i8* %arrayidx70.18, align 1
  %scevgep20.15.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 15
  %15056 = load i8, i8* %scevgep20.15.18, align 1
  %conv68.15.18 = zext i8 %15056 to i32
  %15057 = load i8, i8* %arrayidx70.18, align 1
  %conv71.15.18 = zext i8 %15057 to i32
  %xor72.15.18 = xor i32 %conv71.15.18, %conv68.15.18
  %conv73.15.18 = trunc i32 %xor72.15.18 to i8
  store i8 %conv73.15.18, i8* %arrayidx70.18, align 1
  %scevgep20.16.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 16
  %15058 = load i8, i8* %scevgep20.16.18, align 1
  %conv68.16.18 = zext i8 %15058 to i32
  %15059 = load i8, i8* %arrayidx70.18, align 1
  %conv71.16.18 = zext i8 %15059 to i32
  %xor72.16.18 = xor i32 %conv71.16.18, %conv68.16.18
  %conv73.16.18 = trunc i32 %xor72.16.18 to i8
  store i8 %conv73.16.18, i8* %arrayidx70.18, align 1
  %scevgep20.17.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 17
  %15060 = load i8, i8* %scevgep20.17.18, align 1
  %conv68.17.18 = zext i8 %15060 to i32
  %15061 = load i8, i8* %arrayidx70.18, align 1
  %conv71.17.18 = zext i8 %15061 to i32
  %xor72.17.18 = xor i32 %conv71.17.18, %conv68.17.18
  %conv73.17.18 = trunc i32 %xor72.17.18 to i8
  store i8 %conv73.17.18, i8* %arrayidx70.18, align 1
  %scevgep20.19.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 19
  %15062 = load i8, i8* %scevgep20.19.18, align 1
  %conv68.19.18 = zext i8 %15062 to i32
  %15063 = load i8, i8* %arrayidx70.18, align 1
  %conv71.19.18 = zext i8 %15063 to i32
  %xor72.19.18 = xor i32 %conv71.19.18, %conv68.19.18
  %conv73.19.18 = trunc i32 %xor72.19.18 to i8
  store i8 %conv73.19.18, i8* %arrayidx70.18, align 1
  %scevgep20.20.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 20
  %15064 = load i8, i8* %scevgep20.20.18, align 1
  %conv68.20.18 = zext i8 %15064 to i32
  %15065 = load i8, i8* %arrayidx70.18, align 1
  %conv71.20.18 = zext i8 %15065 to i32
  %xor72.20.18 = xor i32 %conv71.20.18, %conv68.20.18
  %conv73.20.18 = trunc i32 %xor72.20.18 to i8
  store i8 %conv73.20.18, i8* %arrayidx70.18, align 1
  %scevgep20.21.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 21
  %15066 = load i8, i8* %scevgep20.21.18, align 1
  %conv68.21.18 = zext i8 %15066 to i32
  %15067 = load i8, i8* %arrayidx70.18, align 1
  %conv71.21.18 = zext i8 %15067 to i32
  %xor72.21.18 = xor i32 %conv71.21.18, %conv68.21.18
  %conv73.21.18 = trunc i32 %xor72.21.18 to i8
  store i8 %conv73.21.18, i8* %arrayidx70.18, align 1
  %scevgep20.22.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 22
  %15068 = load i8, i8* %scevgep20.22.18, align 1
  %conv68.22.18 = zext i8 %15068 to i32
  %15069 = load i8, i8* %arrayidx70.18, align 1
  %conv71.22.18 = zext i8 %15069 to i32
  %xor72.22.18 = xor i32 %conv71.22.18, %conv68.22.18
  %conv73.22.18 = trunc i32 %xor72.22.18 to i8
  store i8 %conv73.22.18, i8* %arrayidx70.18, align 1
  %scevgep20.23.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 23
  %15070 = load i8, i8* %scevgep20.23.18, align 1
  %conv68.23.18 = zext i8 %15070 to i32
  %15071 = load i8, i8* %arrayidx70.18, align 1
  %conv71.23.18 = zext i8 %15071 to i32
  %xor72.23.18 = xor i32 %conv71.23.18, %conv68.23.18
  %conv73.23.18 = trunc i32 %xor72.23.18 to i8
  store i8 %conv73.23.18, i8* %arrayidx70.18, align 1
  %scevgep20.24.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 24
  %15072 = load i8, i8* %scevgep20.24.18, align 1
  %conv68.24.18 = zext i8 %15072 to i32
  %15073 = load i8, i8* %arrayidx70.18, align 1
  %conv71.24.18 = zext i8 %15073 to i32
  %xor72.24.18 = xor i32 %conv71.24.18, %conv68.24.18
  %conv73.24.18 = trunc i32 %xor72.24.18 to i8
  store i8 %conv73.24.18, i8* %arrayidx70.18, align 1
  %scevgep20.25.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 25
  %15074 = load i8, i8* %scevgep20.25.18, align 1
  %conv68.25.18 = zext i8 %15074 to i32
  %15075 = load i8, i8* %arrayidx70.18, align 1
  %conv71.25.18 = zext i8 %15075 to i32
  %xor72.25.18 = xor i32 %conv71.25.18, %conv68.25.18
  %conv73.25.18 = trunc i32 %xor72.25.18 to i8
  store i8 %conv73.25.18, i8* %arrayidx70.18, align 1
  %scevgep20.26.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 26
  %15076 = load i8, i8* %scevgep20.26.18, align 1
  %conv68.26.18 = zext i8 %15076 to i32
  %15077 = load i8, i8* %arrayidx70.18, align 1
  %conv71.26.18 = zext i8 %15077 to i32
  %xor72.26.18 = xor i32 %conv71.26.18, %conv68.26.18
  %conv73.26.18 = trunc i32 %xor72.26.18 to i8
  store i8 %conv73.26.18, i8* %arrayidx70.18, align 1
  %scevgep20.27.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 27
  %15078 = load i8, i8* %scevgep20.27.18, align 1
  %conv68.27.18 = zext i8 %15078 to i32
  %15079 = load i8, i8* %arrayidx70.18, align 1
  %conv71.27.18 = zext i8 %15079 to i32
  %xor72.27.18 = xor i32 %conv71.27.18, %conv68.27.18
  %conv73.27.18 = trunc i32 %xor72.27.18 to i8
  store i8 %conv73.27.18, i8* %arrayidx70.18, align 1
  %scevgep20.28.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 28
  %15080 = load i8, i8* %scevgep20.28.18, align 1
  %conv68.28.18 = zext i8 %15080 to i32
  %15081 = load i8, i8* %arrayidx70.18, align 1
  %conv71.28.18 = zext i8 %15081 to i32
  %xor72.28.18 = xor i32 %conv71.28.18, %conv68.28.18
  %conv73.28.18 = trunc i32 %xor72.28.18 to i8
  store i8 %conv73.28.18, i8* %arrayidx70.18, align 1
  %scevgep20.29.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 29
  %15082 = load i8, i8* %scevgep20.29.18, align 1
  %conv68.29.18 = zext i8 %15082 to i32
  %15083 = load i8, i8* %arrayidx70.18, align 1
  %conv71.29.18 = zext i8 %15083 to i32
  %xor72.29.18 = xor i32 %conv71.29.18, %conv68.29.18
  %conv73.29.18 = trunc i32 %xor72.29.18 to i8
  store i8 %conv73.29.18, i8* %arrayidx70.18, align 1
  %scevgep20.30.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 30
  %15084 = load i8, i8* %scevgep20.30.18, align 1
  %conv68.30.18 = zext i8 %15084 to i32
  %15085 = load i8, i8* %arrayidx70.18, align 1
  %conv71.30.18 = zext i8 %15085 to i32
  %xor72.30.18 = xor i32 %conv71.30.18, %conv68.30.18
  %conv73.30.18 = trunc i32 %xor72.30.18 to i8
  store i8 %conv73.30.18, i8* %arrayidx70.18, align 1
  %scevgep20.31.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 31
  %15086 = load i8, i8* %scevgep20.31.18, align 1
  %conv68.31.18 = zext i8 %15086 to i32
  %15087 = load i8, i8* %arrayidx70.18, align 1
  %conv71.31.18 = zext i8 %15087 to i32
  %xor72.31.18 = xor i32 %conv71.31.18, %conv68.31.18
  %conv73.31.18 = trunc i32 %xor72.31.18 to i8
  store i8 %conv73.31.18, i8* %arrayidx70.18, align 1
  %scevgep20.32.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 32
  %15088 = load i8, i8* %scevgep20.32.18, align 1
  %conv68.32.18 = zext i8 %15088 to i32
  %15089 = load i8, i8* %arrayidx70.18, align 1
  %conv71.32.18 = zext i8 %15089 to i32
  %xor72.32.18 = xor i32 %conv71.32.18, %conv68.32.18
  %conv73.32.18 = trunc i32 %xor72.32.18 to i8
  store i8 %conv73.32.18, i8* %arrayidx70.18, align 1
  %scevgep20.33.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 33
  %15090 = load i8, i8* %scevgep20.33.18, align 1
  %conv68.33.18 = zext i8 %15090 to i32
  %15091 = load i8, i8* %arrayidx70.18, align 1
  %conv71.33.18 = zext i8 %15091 to i32
  %xor72.33.18 = xor i32 %conv71.33.18, %conv68.33.18
  %conv73.33.18 = trunc i32 %xor72.33.18 to i8
  store i8 %conv73.33.18, i8* %arrayidx70.18, align 1
  %scevgep20.34.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 34
  %15092 = load i8, i8* %scevgep20.34.18, align 1
  %conv68.34.18 = zext i8 %15092 to i32
  %15093 = load i8, i8* %arrayidx70.18, align 1
  %conv71.34.18 = zext i8 %15093 to i32
  %xor72.34.18 = xor i32 %conv71.34.18, %conv68.34.18
  %conv73.34.18 = trunc i32 %xor72.34.18 to i8
  store i8 %conv73.34.18, i8* %arrayidx70.18, align 1
  %scevgep20.35.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 35
  %15094 = load i8, i8* %scevgep20.35.18, align 1
  %conv68.35.18 = zext i8 %15094 to i32
  %15095 = load i8, i8* %arrayidx70.18, align 1
  %conv71.35.18 = zext i8 %15095 to i32
  %xor72.35.18 = xor i32 %conv71.35.18, %conv68.35.18
  %conv73.35.18 = trunc i32 %xor72.35.18 to i8
  store i8 %conv73.35.18, i8* %arrayidx70.18, align 1
  %scevgep20.36.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 36
  %15096 = load i8, i8* %scevgep20.36.18, align 1
  %conv68.36.18 = zext i8 %15096 to i32
  %15097 = load i8, i8* %arrayidx70.18, align 1
  %conv71.36.18 = zext i8 %15097 to i32
  %xor72.36.18 = xor i32 %conv71.36.18, %conv68.36.18
  %conv73.36.18 = trunc i32 %xor72.36.18 to i8
  store i8 %conv73.36.18, i8* %arrayidx70.18, align 1
  %scevgep20.37.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 37
  %15098 = load i8, i8* %scevgep20.37.18, align 1
  %conv68.37.18 = zext i8 %15098 to i32
  %15099 = load i8, i8* %arrayidx70.18, align 1
  %conv71.37.18 = zext i8 %15099 to i32
  %xor72.37.18 = xor i32 %conv71.37.18, %conv68.37.18
  %conv73.37.18 = trunc i32 %xor72.37.18 to i8
  store i8 %conv73.37.18, i8* %arrayidx70.18, align 1
  %scevgep20.38.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 38
  %15100 = load i8, i8* %scevgep20.38.18, align 1
  %conv68.38.18 = zext i8 %15100 to i32
  %15101 = load i8, i8* %arrayidx70.18, align 1
  %conv71.38.18 = zext i8 %15101 to i32
  %xor72.38.18 = xor i32 %conv71.38.18, %conv68.38.18
  %conv73.38.18 = trunc i32 %xor72.38.18 to i8
  store i8 %conv73.38.18, i8* %arrayidx70.18, align 1
  %scevgep20.39.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 39
  %15102 = load i8, i8* %scevgep20.39.18, align 1
  %conv68.39.18 = zext i8 %15102 to i32
  %15103 = load i8, i8* %arrayidx70.18, align 1
  %conv71.39.18 = zext i8 %15103 to i32
  %xor72.39.18 = xor i32 %conv71.39.18, %conv68.39.18
  %conv73.39.18 = trunc i32 %xor72.39.18 to i8
  store i8 %conv73.39.18, i8* %arrayidx70.18, align 1
  %scevgep20.40.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 40
  %15104 = load i8, i8* %scevgep20.40.18, align 1
  %conv68.40.18 = zext i8 %15104 to i32
  %15105 = load i8, i8* %arrayidx70.18, align 1
  %conv71.40.18 = zext i8 %15105 to i32
  %xor72.40.18 = xor i32 %conv71.40.18, %conv68.40.18
  %conv73.40.18 = trunc i32 %xor72.40.18 to i8
  store i8 %conv73.40.18, i8* %arrayidx70.18, align 1
  %scevgep20.41.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 41
  %15106 = load i8, i8* %scevgep20.41.18, align 1
  %conv68.41.18 = zext i8 %15106 to i32
  %15107 = load i8, i8* %arrayidx70.18, align 1
  %conv71.41.18 = zext i8 %15107 to i32
  %xor72.41.18 = xor i32 %conv71.41.18, %conv68.41.18
  %conv73.41.18 = trunc i32 %xor72.41.18 to i8
  store i8 %conv73.41.18, i8* %arrayidx70.18, align 1
  %scevgep20.42.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 42
  %15108 = load i8, i8* %scevgep20.42.18, align 1
  %conv68.42.18 = zext i8 %15108 to i32
  %15109 = load i8, i8* %arrayidx70.18, align 1
  %conv71.42.18 = zext i8 %15109 to i32
  %xor72.42.18 = xor i32 %conv71.42.18, %conv68.42.18
  %conv73.42.18 = trunc i32 %xor72.42.18 to i8
  store i8 %conv73.42.18, i8* %arrayidx70.18, align 1
  %scevgep20.43.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 43
  %15110 = load i8, i8* %scevgep20.43.18, align 1
  %conv68.43.18 = zext i8 %15110 to i32
  %15111 = load i8, i8* %arrayidx70.18, align 1
  %conv71.43.18 = zext i8 %15111 to i32
  %xor72.43.18 = xor i32 %conv71.43.18, %conv68.43.18
  %conv73.43.18 = trunc i32 %xor72.43.18 to i8
  store i8 %conv73.43.18, i8* %arrayidx70.18, align 1
  %scevgep20.44.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 44
  %15112 = load i8, i8* %scevgep20.44.18, align 1
  %conv68.44.18 = zext i8 %15112 to i32
  %15113 = load i8, i8* %arrayidx70.18, align 1
  %conv71.44.18 = zext i8 %15113 to i32
  %xor72.44.18 = xor i32 %conv71.44.18, %conv68.44.18
  %conv73.44.18 = trunc i32 %xor72.44.18 to i8
  store i8 %conv73.44.18, i8* %arrayidx70.18, align 1
  %scevgep20.45.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 45
  %15114 = load i8, i8* %scevgep20.45.18, align 1
  %conv68.45.18 = zext i8 %15114 to i32
  %15115 = load i8, i8* %arrayidx70.18, align 1
  %conv71.45.18 = zext i8 %15115 to i32
  %xor72.45.18 = xor i32 %conv71.45.18, %conv68.45.18
  %conv73.45.18 = trunc i32 %xor72.45.18 to i8
  store i8 %conv73.45.18, i8* %arrayidx70.18, align 1
  %scevgep20.46.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 46
  %15116 = load i8, i8* %scevgep20.46.18, align 1
  %conv68.46.18 = zext i8 %15116 to i32
  %15117 = load i8, i8* %arrayidx70.18, align 1
  %conv71.46.18 = zext i8 %15117 to i32
  %xor72.46.18 = xor i32 %conv71.46.18, %conv68.46.18
  %conv73.46.18 = trunc i32 %xor72.46.18 to i8
  store i8 %conv73.46.18, i8* %arrayidx70.18, align 1
  %scevgep20.47.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 47
  %15118 = load i8, i8* %scevgep20.47.18, align 1
  %conv68.47.18 = zext i8 %15118 to i32
  %15119 = load i8, i8* %arrayidx70.18, align 1
  %conv71.47.18 = zext i8 %15119 to i32
  %xor72.47.18 = xor i32 %conv71.47.18, %conv68.47.18
  %conv73.47.18 = trunc i32 %xor72.47.18 to i8
  store i8 %conv73.47.18, i8* %arrayidx70.18, align 1
  %scevgep20.48.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 48
  %15120 = load i8, i8* %scevgep20.48.18, align 1
  %conv68.48.18 = zext i8 %15120 to i32
  %15121 = load i8, i8* %arrayidx70.18, align 1
  %conv71.48.18 = zext i8 %15121 to i32
  %xor72.48.18 = xor i32 %conv71.48.18, %conv68.48.18
  %conv73.48.18 = trunc i32 %xor72.48.18 to i8
  store i8 %conv73.48.18, i8* %arrayidx70.18, align 1
  %scevgep20.49.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 49
  %15122 = load i8, i8* %scevgep20.49.18, align 1
  %conv68.49.18 = zext i8 %15122 to i32
  %15123 = load i8, i8* %arrayidx70.18, align 1
  %conv71.49.18 = zext i8 %15123 to i32
  %xor72.49.18 = xor i32 %conv71.49.18, %conv68.49.18
  %conv73.49.18 = trunc i32 %xor72.49.18 to i8
  store i8 %conv73.49.18, i8* %arrayidx70.18, align 1
  %scevgep20.50.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 50
  %15124 = load i8, i8* %scevgep20.50.18, align 1
  %conv68.50.18 = zext i8 %15124 to i32
  %15125 = load i8, i8* %arrayidx70.18, align 1
  %conv71.50.18 = zext i8 %15125 to i32
  %xor72.50.18 = xor i32 %conv71.50.18, %conv68.50.18
  %conv73.50.18 = trunc i32 %xor72.50.18 to i8
  store i8 %conv73.50.18, i8* %arrayidx70.18, align 1
  %scevgep20.51.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 51
  %15126 = load i8, i8* %scevgep20.51.18, align 1
  %conv68.51.18 = zext i8 %15126 to i32
  %15127 = load i8, i8* %arrayidx70.18, align 1
  %conv71.51.18 = zext i8 %15127 to i32
  %xor72.51.18 = xor i32 %conv71.51.18, %conv68.51.18
  %conv73.51.18 = trunc i32 %xor72.51.18 to i8
  store i8 %conv73.51.18, i8* %arrayidx70.18, align 1
  %scevgep20.52.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 52
  %15128 = load i8, i8* %scevgep20.52.18, align 1
  %conv68.52.18 = zext i8 %15128 to i32
  %15129 = load i8, i8* %arrayidx70.18, align 1
  %conv71.52.18 = zext i8 %15129 to i32
  %xor72.52.18 = xor i32 %conv71.52.18, %conv68.52.18
  %conv73.52.18 = trunc i32 %xor72.52.18 to i8
  store i8 %conv73.52.18, i8* %arrayidx70.18, align 1
  %scevgep20.53.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 53
  %15130 = load i8, i8* %scevgep20.53.18, align 1
  %conv68.53.18 = zext i8 %15130 to i32
  %15131 = load i8, i8* %arrayidx70.18, align 1
  %conv71.53.18 = zext i8 %15131 to i32
  %xor72.53.18 = xor i32 %conv71.53.18, %conv68.53.18
  %conv73.53.18 = trunc i32 %xor72.53.18 to i8
  store i8 %conv73.53.18, i8* %arrayidx70.18, align 1
  %scevgep20.54.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 54
  %15132 = load i8, i8* %scevgep20.54.18, align 1
  %conv68.54.18 = zext i8 %15132 to i32
  %15133 = load i8, i8* %arrayidx70.18, align 1
  %conv71.54.18 = zext i8 %15133 to i32
  %xor72.54.18 = xor i32 %conv71.54.18, %conv68.54.18
  %conv73.54.18 = trunc i32 %xor72.54.18 to i8
  store i8 %conv73.54.18, i8* %arrayidx70.18, align 1
  %scevgep20.55.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 55
  %15134 = load i8, i8* %scevgep20.55.18, align 1
  %conv68.55.18 = zext i8 %15134 to i32
  %15135 = load i8, i8* %arrayidx70.18, align 1
  %conv71.55.18 = zext i8 %15135 to i32
  %xor72.55.18 = xor i32 %conv71.55.18, %conv68.55.18
  %conv73.55.18 = trunc i32 %xor72.55.18 to i8
  store i8 %conv73.55.18, i8* %arrayidx70.18, align 1
  %scevgep20.56.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 56
  %15136 = load i8, i8* %scevgep20.56.18, align 1
  %conv68.56.18 = zext i8 %15136 to i32
  %15137 = load i8, i8* %arrayidx70.18, align 1
  %conv71.56.18 = zext i8 %15137 to i32
  %xor72.56.18 = xor i32 %conv71.56.18, %conv68.56.18
  %conv73.56.18 = trunc i32 %xor72.56.18 to i8
  store i8 %conv73.56.18, i8* %arrayidx70.18, align 1
  %scevgep20.57.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 57
  %15138 = load i8, i8* %scevgep20.57.18, align 1
  %conv68.57.18 = zext i8 %15138 to i32
  %15139 = load i8, i8* %arrayidx70.18, align 1
  %conv71.57.18 = zext i8 %15139 to i32
  %xor72.57.18 = xor i32 %conv71.57.18, %conv68.57.18
  %conv73.57.18 = trunc i32 %xor72.57.18 to i8
  store i8 %conv73.57.18, i8* %arrayidx70.18, align 1
  %scevgep20.58.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 58
  %15140 = load i8, i8* %scevgep20.58.18, align 1
  %conv68.58.18 = zext i8 %15140 to i32
  %15141 = load i8, i8* %arrayidx70.18, align 1
  %conv71.58.18 = zext i8 %15141 to i32
  %xor72.58.18 = xor i32 %conv71.58.18, %conv68.58.18
  %conv73.58.18 = trunc i32 %xor72.58.18 to i8
  store i8 %conv73.58.18, i8* %arrayidx70.18, align 1
  %scevgep20.59.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 59
  %15142 = load i8, i8* %scevgep20.59.18, align 1
  %conv68.59.18 = zext i8 %15142 to i32
  %15143 = load i8, i8* %arrayidx70.18, align 1
  %conv71.59.18 = zext i8 %15143 to i32
  %xor72.59.18 = xor i32 %conv71.59.18, %conv68.59.18
  %conv73.59.18 = trunc i32 %xor72.59.18 to i8
  store i8 %conv73.59.18, i8* %arrayidx70.18, align 1
  %scevgep20.60.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 0, i64 60
  %15144 = load i8, i8* %scevgep20.60.18, align 1
  %conv68.60.18 = zext i8 %15144 to i32
  %15145 = load i8, i8* %arrayidx70.18, align 1
  %conv71.60.18 = zext i8 %15145 to i32
  %xor72.60.18 = xor i32 %conv71.60.18, %conv68.60.18
  %conv73.60.18 = trunc i32 %xor72.60.18 to i8
  store i8 %conv73.60.18, i8* %arrayidx70.18, align 1
  %scevgep19.18 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15023, i64 0, i64 1, i64 0
  %15146 = bitcast i8* %scevgep19.18 to [61 x [61 x i8]]*
  %arrayidx51.19 = getelementptr inbounds i8, i8* %a, i64 19
  %15147 = load i8, i8* %arrayidx51.19, align 1
  %arrayidx53.19 = getelementptr inbounds i8, i8* %b, i64 19
  %15148 = load i8, i8* %arrayidx53.19, align 1
  %call54.19 = call zeroext i8 @mult(i8 zeroext %15147, i8 zeroext %15148)
  %arrayidx56.19 = getelementptr inbounds i8, i8* %c, i64 19
  store i8 %call54.19, i8* %arrayidx56.19, align 1
  %arrayidx70.19 = getelementptr inbounds i8, i8* %c, i64 19
  %scevgep20.19234 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 0
  %15149 = load i8, i8* %scevgep20.19234, align 1
  %conv68.19235 = zext i8 %15149 to i32
  %15150 = load i8, i8* %arrayidx70.19, align 1
  %conv71.19236 = zext i8 %15150 to i32
  %xor72.19237 = xor i32 %conv71.19236, %conv68.19235
  %conv73.19238 = trunc i32 %xor72.19237 to i8
  store i8 %conv73.19238, i8* %arrayidx70.19, align 1
  %scevgep20.1.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 1
  %15151 = load i8, i8* %scevgep20.1.19, align 1
  %conv68.1.19 = zext i8 %15151 to i32
  %15152 = load i8, i8* %arrayidx70.19, align 1
  %conv71.1.19 = zext i8 %15152 to i32
  %xor72.1.19 = xor i32 %conv71.1.19, %conv68.1.19
  %conv73.1.19 = trunc i32 %xor72.1.19 to i8
  store i8 %conv73.1.19, i8* %arrayidx70.19, align 1
  %scevgep20.2.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 2
  %15153 = load i8, i8* %scevgep20.2.19, align 1
  %conv68.2.19 = zext i8 %15153 to i32
  %15154 = load i8, i8* %arrayidx70.19, align 1
  %conv71.2.19 = zext i8 %15154 to i32
  %xor72.2.19 = xor i32 %conv71.2.19, %conv68.2.19
  %conv73.2.19 = trunc i32 %xor72.2.19 to i8
  store i8 %conv73.2.19, i8* %arrayidx70.19, align 1
  %scevgep20.3.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 3
  %15155 = load i8, i8* %scevgep20.3.19, align 1
  %conv68.3.19 = zext i8 %15155 to i32
  %15156 = load i8, i8* %arrayidx70.19, align 1
  %conv71.3.19 = zext i8 %15156 to i32
  %xor72.3.19 = xor i32 %conv71.3.19, %conv68.3.19
  %conv73.3.19 = trunc i32 %xor72.3.19 to i8
  store i8 %conv73.3.19, i8* %arrayidx70.19, align 1
  %scevgep20.4.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 4
  %15157 = load i8, i8* %scevgep20.4.19, align 1
  %conv68.4.19 = zext i8 %15157 to i32
  %15158 = load i8, i8* %arrayidx70.19, align 1
  %conv71.4.19 = zext i8 %15158 to i32
  %xor72.4.19 = xor i32 %conv71.4.19, %conv68.4.19
  %conv73.4.19 = trunc i32 %xor72.4.19 to i8
  store i8 %conv73.4.19, i8* %arrayidx70.19, align 1
  %scevgep20.5.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 5
  %15159 = load i8, i8* %scevgep20.5.19, align 1
  %conv68.5.19 = zext i8 %15159 to i32
  %15160 = load i8, i8* %arrayidx70.19, align 1
  %conv71.5.19 = zext i8 %15160 to i32
  %xor72.5.19 = xor i32 %conv71.5.19, %conv68.5.19
  %conv73.5.19 = trunc i32 %xor72.5.19 to i8
  store i8 %conv73.5.19, i8* %arrayidx70.19, align 1
  %scevgep20.6.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 6
  %15161 = load i8, i8* %scevgep20.6.19, align 1
  %conv68.6.19 = zext i8 %15161 to i32
  %15162 = load i8, i8* %arrayidx70.19, align 1
  %conv71.6.19 = zext i8 %15162 to i32
  %xor72.6.19 = xor i32 %conv71.6.19, %conv68.6.19
  %conv73.6.19 = trunc i32 %xor72.6.19 to i8
  store i8 %conv73.6.19, i8* %arrayidx70.19, align 1
  %scevgep20.7.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 7
  %15163 = load i8, i8* %scevgep20.7.19, align 1
  %conv68.7.19 = zext i8 %15163 to i32
  %15164 = load i8, i8* %arrayidx70.19, align 1
  %conv71.7.19 = zext i8 %15164 to i32
  %xor72.7.19 = xor i32 %conv71.7.19, %conv68.7.19
  %conv73.7.19 = trunc i32 %xor72.7.19 to i8
  store i8 %conv73.7.19, i8* %arrayidx70.19, align 1
  %scevgep20.8.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 8
  %15165 = load i8, i8* %scevgep20.8.19, align 1
  %conv68.8.19 = zext i8 %15165 to i32
  %15166 = load i8, i8* %arrayidx70.19, align 1
  %conv71.8.19 = zext i8 %15166 to i32
  %xor72.8.19 = xor i32 %conv71.8.19, %conv68.8.19
  %conv73.8.19 = trunc i32 %xor72.8.19 to i8
  store i8 %conv73.8.19, i8* %arrayidx70.19, align 1
  %scevgep20.9.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 9
  %15167 = load i8, i8* %scevgep20.9.19, align 1
  %conv68.9.19 = zext i8 %15167 to i32
  %15168 = load i8, i8* %arrayidx70.19, align 1
  %conv71.9.19 = zext i8 %15168 to i32
  %xor72.9.19 = xor i32 %conv71.9.19, %conv68.9.19
  %conv73.9.19 = trunc i32 %xor72.9.19 to i8
  store i8 %conv73.9.19, i8* %arrayidx70.19, align 1
  %scevgep20.10.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 10
  %15169 = load i8, i8* %scevgep20.10.19, align 1
  %conv68.10.19 = zext i8 %15169 to i32
  %15170 = load i8, i8* %arrayidx70.19, align 1
  %conv71.10.19 = zext i8 %15170 to i32
  %xor72.10.19 = xor i32 %conv71.10.19, %conv68.10.19
  %conv73.10.19 = trunc i32 %xor72.10.19 to i8
  store i8 %conv73.10.19, i8* %arrayidx70.19, align 1
  %scevgep20.11.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 11
  %15171 = load i8, i8* %scevgep20.11.19, align 1
  %conv68.11.19 = zext i8 %15171 to i32
  %15172 = load i8, i8* %arrayidx70.19, align 1
  %conv71.11.19 = zext i8 %15172 to i32
  %xor72.11.19 = xor i32 %conv71.11.19, %conv68.11.19
  %conv73.11.19 = trunc i32 %xor72.11.19 to i8
  store i8 %conv73.11.19, i8* %arrayidx70.19, align 1
  %scevgep20.12.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 12
  %15173 = load i8, i8* %scevgep20.12.19, align 1
  %conv68.12.19 = zext i8 %15173 to i32
  %15174 = load i8, i8* %arrayidx70.19, align 1
  %conv71.12.19 = zext i8 %15174 to i32
  %xor72.12.19 = xor i32 %conv71.12.19, %conv68.12.19
  %conv73.12.19 = trunc i32 %xor72.12.19 to i8
  store i8 %conv73.12.19, i8* %arrayidx70.19, align 1
  %scevgep20.13.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 13
  %15175 = load i8, i8* %scevgep20.13.19, align 1
  %conv68.13.19 = zext i8 %15175 to i32
  %15176 = load i8, i8* %arrayidx70.19, align 1
  %conv71.13.19 = zext i8 %15176 to i32
  %xor72.13.19 = xor i32 %conv71.13.19, %conv68.13.19
  %conv73.13.19 = trunc i32 %xor72.13.19 to i8
  store i8 %conv73.13.19, i8* %arrayidx70.19, align 1
  %scevgep20.14.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 14
  %15177 = load i8, i8* %scevgep20.14.19, align 1
  %conv68.14.19 = zext i8 %15177 to i32
  %15178 = load i8, i8* %arrayidx70.19, align 1
  %conv71.14.19 = zext i8 %15178 to i32
  %xor72.14.19 = xor i32 %conv71.14.19, %conv68.14.19
  %conv73.14.19 = trunc i32 %xor72.14.19 to i8
  store i8 %conv73.14.19, i8* %arrayidx70.19, align 1
  %scevgep20.15.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 15
  %15179 = load i8, i8* %scevgep20.15.19, align 1
  %conv68.15.19 = zext i8 %15179 to i32
  %15180 = load i8, i8* %arrayidx70.19, align 1
  %conv71.15.19 = zext i8 %15180 to i32
  %xor72.15.19 = xor i32 %conv71.15.19, %conv68.15.19
  %conv73.15.19 = trunc i32 %xor72.15.19 to i8
  store i8 %conv73.15.19, i8* %arrayidx70.19, align 1
  %scevgep20.16.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 16
  %15181 = load i8, i8* %scevgep20.16.19, align 1
  %conv68.16.19 = zext i8 %15181 to i32
  %15182 = load i8, i8* %arrayidx70.19, align 1
  %conv71.16.19 = zext i8 %15182 to i32
  %xor72.16.19 = xor i32 %conv71.16.19, %conv68.16.19
  %conv73.16.19 = trunc i32 %xor72.16.19 to i8
  store i8 %conv73.16.19, i8* %arrayidx70.19, align 1
  %scevgep20.17.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 17
  %15183 = load i8, i8* %scevgep20.17.19, align 1
  %conv68.17.19 = zext i8 %15183 to i32
  %15184 = load i8, i8* %arrayidx70.19, align 1
  %conv71.17.19 = zext i8 %15184 to i32
  %xor72.17.19 = xor i32 %conv71.17.19, %conv68.17.19
  %conv73.17.19 = trunc i32 %xor72.17.19 to i8
  store i8 %conv73.17.19, i8* %arrayidx70.19, align 1
  %scevgep20.18.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 18
  %15185 = load i8, i8* %scevgep20.18.19, align 1
  %conv68.18.19 = zext i8 %15185 to i32
  %15186 = load i8, i8* %arrayidx70.19, align 1
  %conv71.18.19 = zext i8 %15186 to i32
  %xor72.18.19 = xor i32 %conv71.18.19, %conv68.18.19
  %conv73.18.19 = trunc i32 %xor72.18.19 to i8
  store i8 %conv73.18.19, i8* %arrayidx70.19, align 1
  %scevgep20.20.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 20
  %15187 = load i8, i8* %scevgep20.20.19, align 1
  %conv68.20.19 = zext i8 %15187 to i32
  %15188 = load i8, i8* %arrayidx70.19, align 1
  %conv71.20.19 = zext i8 %15188 to i32
  %xor72.20.19 = xor i32 %conv71.20.19, %conv68.20.19
  %conv73.20.19 = trunc i32 %xor72.20.19 to i8
  store i8 %conv73.20.19, i8* %arrayidx70.19, align 1
  %scevgep20.21.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 21
  %15189 = load i8, i8* %scevgep20.21.19, align 1
  %conv68.21.19 = zext i8 %15189 to i32
  %15190 = load i8, i8* %arrayidx70.19, align 1
  %conv71.21.19 = zext i8 %15190 to i32
  %xor72.21.19 = xor i32 %conv71.21.19, %conv68.21.19
  %conv73.21.19 = trunc i32 %xor72.21.19 to i8
  store i8 %conv73.21.19, i8* %arrayidx70.19, align 1
  %scevgep20.22.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 22
  %15191 = load i8, i8* %scevgep20.22.19, align 1
  %conv68.22.19 = zext i8 %15191 to i32
  %15192 = load i8, i8* %arrayidx70.19, align 1
  %conv71.22.19 = zext i8 %15192 to i32
  %xor72.22.19 = xor i32 %conv71.22.19, %conv68.22.19
  %conv73.22.19 = trunc i32 %xor72.22.19 to i8
  store i8 %conv73.22.19, i8* %arrayidx70.19, align 1
  %scevgep20.23.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 23
  %15193 = load i8, i8* %scevgep20.23.19, align 1
  %conv68.23.19 = zext i8 %15193 to i32
  %15194 = load i8, i8* %arrayidx70.19, align 1
  %conv71.23.19 = zext i8 %15194 to i32
  %xor72.23.19 = xor i32 %conv71.23.19, %conv68.23.19
  %conv73.23.19 = trunc i32 %xor72.23.19 to i8
  store i8 %conv73.23.19, i8* %arrayidx70.19, align 1
  %scevgep20.24.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 24
  %15195 = load i8, i8* %scevgep20.24.19, align 1
  %conv68.24.19 = zext i8 %15195 to i32
  %15196 = load i8, i8* %arrayidx70.19, align 1
  %conv71.24.19 = zext i8 %15196 to i32
  %xor72.24.19 = xor i32 %conv71.24.19, %conv68.24.19
  %conv73.24.19 = trunc i32 %xor72.24.19 to i8
  store i8 %conv73.24.19, i8* %arrayidx70.19, align 1
  %scevgep20.25.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 25
  %15197 = load i8, i8* %scevgep20.25.19, align 1
  %conv68.25.19 = zext i8 %15197 to i32
  %15198 = load i8, i8* %arrayidx70.19, align 1
  %conv71.25.19 = zext i8 %15198 to i32
  %xor72.25.19 = xor i32 %conv71.25.19, %conv68.25.19
  %conv73.25.19 = trunc i32 %xor72.25.19 to i8
  store i8 %conv73.25.19, i8* %arrayidx70.19, align 1
  %scevgep20.26.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 26
  %15199 = load i8, i8* %scevgep20.26.19, align 1
  %conv68.26.19 = zext i8 %15199 to i32
  %15200 = load i8, i8* %arrayidx70.19, align 1
  %conv71.26.19 = zext i8 %15200 to i32
  %xor72.26.19 = xor i32 %conv71.26.19, %conv68.26.19
  %conv73.26.19 = trunc i32 %xor72.26.19 to i8
  store i8 %conv73.26.19, i8* %arrayidx70.19, align 1
  %scevgep20.27.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 27
  %15201 = load i8, i8* %scevgep20.27.19, align 1
  %conv68.27.19 = zext i8 %15201 to i32
  %15202 = load i8, i8* %arrayidx70.19, align 1
  %conv71.27.19 = zext i8 %15202 to i32
  %xor72.27.19 = xor i32 %conv71.27.19, %conv68.27.19
  %conv73.27.19 = trunc i32 %xor72.27.19 to i8
  store i8 %conv73.27.19, i8* %arrayidx70.19, align 1
  %scevgep20.28.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 28
  %15203 = load i8, i8* %scevgep20.28.19, align 1
  %conv68.28.19 = zext i8 %15203 to i32
  %15204 = load i8, i8* %arrayidx70.19, align 1
  %conv71.28.19 = zext i8 %15204 to i32
  %xor72.28.19 = xor i32 %conv71.28.19, %conv68.28.19
  %conv73.28.19 = trunc i32 %xor72.28.19 to i8
  store i8 %conv73.28.19, i8* %arrayidx70.19, align 1
  %scevgep20.29.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 29
  %15205 = load i8, i8* %scevgep20.29.19, align 1
  %conv68.29.19 = zext i8 %15205 to i32
  %15206 = load i8, i8* %arrayidx70.19, align 1
  %conv71.29.19 = zext i8 %15206 to i32
  %xor72.29.19 = xor i32 %conv71.29.19, %conv68.29.19
  %conv73.29.19 = trunc i32 %xor72.29.19 to i8
  store i8 %conv73.29.19, i8* %arrayidx70.19, align 1
  %scevgep20.30.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 30
  %15207 = load i8, i8* %scevgep20.30.19, align 1
  %conv68.30.19 = zext i8 %15207 to i32
  %15208 = load i8, i8* %arrayidx70.19, align 1
  %conv71.30.19 = zext i8 %15208 to i32
  %xor72.30.19 = xor i32 %conv71.30.19, %conv68.30.19
  %conv73.30.19 = trunc i32 %xor72.30.19 to i8
  store i8 %conv73.30.19, i8* %arrayidx70.19, align 1
  %scevgep20.31.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 31
  %15209 = load i8, i8* %scevgep20.31.19, align 1
  %conv68.31.19 = zext i8 %15209 to i32
  %15210 = load i8, i8* %arrayidx70.19, align 1
  %conv71.31.19 = zext i8 %15210 to i32
  %xor72.31.19 = xor i32 %conv71.31.19, %conv68.31.19
  %conv73.31.19 = trunc i32 %xor72.31.19 to i8
  store i8 %conv73.31.19, i8* %arrayidx70.19, align 1
  %scevgep20.32.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 32
  %15211 = load i8, i8* %scevgep20.32.19, align 1
  %conv68.32.19 = zext i8 %15211 to i32
  %15212 = load i8, i8* %arrayidx70.19, align 1
  %conv71.32.19 = zext i8 %15212 to i32
  %xor72.32.19 = xor i32 %conv71.32.19, %conv68.32.19
  %conv73.32.19 = trunc i32 %xor72.32.19 to i8
  store i8 %conv73.32.19, i8* %arrayidx70.19, align 1
  %scevgep20.33.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 33
  %15213 = load i8, i8* %scevgep20.33.19, align 1
  %conv68.33.19 = zext i8 %15213 to i32
  %15214 = load i8, i8* %arrayidx70.19, align 1
  %conv71.33.19 = zext i8 %15214 to i32
  %xor72.33.19 = xor i32 %conv71.33.19, %conv68.33.19
  %conv73.33.19 = trunc i32 %xor72.33.19 to i8
  store i8 %conv73.33.19, i8* %arrayidx70.19, align 1
  %scevgep20.34.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 34
  %15215 = load i8, i8* %scevgep20.34.19, align 1
  %conv68.34.19 = zext i8 %15215 to i32
  %15216 = load i8, i8* %arrayidx70.19, align 1
  %conv71.34.19 = zext i8 %15216 to i32
  %xor72.34.19 = xor i32 %conv71.34.19, %conv68.34.19
  %conv73.34.19 = trunc i32 %xor72.34.19 to i8
  store i8 %conv73.34.19, i8* %arrayidx70.19, align 1
  %scevgep20.35.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 35
  %15217 = load i8, i8* %scevgep20.35.19, align 1
  %conv68.35.19 = zext i8 %15217 to i32
  %15218 = load i8, i8* %arrayidx70.19, align 1
  %conv71.35.19 = zext i8 %15218 to i32
  %xor72.35.19 = xor i32 %conv71.35.19, %conv68.35.19
  %conv73.35.19 = trunc i32 %xor72.35.19 to i8
  store i8 %conv73.35.19, i8* %arrayidx70.19, align 1
  %scevgep20.36.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 36
  %15219 = load i8, i8* %scevgep20.36.19, align 1
  %conv68.36.19 = zext i8 %15219 to i32
  %15220 = load i8, i8* %arrayidx70.19, align 1
  %conv71.36.19 = zext i8 %15220 to i32
  %xor72.36.19 = xor i32 %conv71.36.19, %conv68.36.19
  %conv73.36.19 = trunc i32 %xor72.36.19 to i8
  store i8 %conv73.36.19, i8* %arrayidx70.19, align 1
  %scevgep20.37.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 37
  %15221 = load i8, i8* %scevgep20.37.19, align 1
  %conv68.37.19 = zext i8 %15221 to i32
  %15222 = load i8, i8* %arrayidx70.19, align 1
  %conv71.37.19 = zext i8 %15222 to i32
  %xor72.37.19 = xor i32 %conv71.37.19, %conv68.37.19
  %conv73.37.19 = trunc i32 %xor72.37.19 to i8
  store i8 %conv73.37.19, i8* %arrayidx70.19, align 1
  %scevgep20.38.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 38
  %15223 = load i8, i8* %scevgep20.38.19, align 1
  %conv68.38.19 = zext i8 %15223 to i32
  %15224 = load i8, i8* %arrayidx70.19, align 1
  %conv71.38.19 = zext i8 %15224 to i32
  %xor72.38.19 = xor i32 %conv71.38.19, %conv68.38.19
  %conv73.38.19 = trunc i32 %xor72.38.19 to i8
  store i8 %conv73.38.19, i8* %arrayidx70.19, align 1
  %scevgep20.39.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 39
  %15225 = load i8, i8* %scevgep20.39.19, align 1
  %conv68.39.19 = zext i8 %15225 to i32
  %15226 = load i8, i8* %arrayidx70.19, align 1
  %conv71.39.19 = zext i8 %15226 to i32
  %xor72.39.19 = xor i32 %conv71.39.19, %conv68.39.19
  %conv73.39.19 = trunc i32 %xor72.39.19 to i8
  store i8 %conv73.39.19, i8* %arrayidx70.19, align 1
  %scevgep20.40.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 40
  %15227 = load i8, i8* %scevgep20.40.19, align 1
  %conv68.40.19 = zext i8 %15227 to i32
  %15228 = load i8, i8* %arrayidx70.19, align 1
  %conv71.40.19 = zext i8 %15228 to i32
  %xor72.40.19 = xor i32 %conv71.40.19, %conv68.40.19
  %conv73.40.19 = trunc i32 %xor72.40.19 to i8
  store i8 %conv73.40.19, i8* %arrayidx70.19, align 1
  %scevgep20.41.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 41
  %15229 = load i8, i8* %scevgep20.41.19, align 1
  %conv68.41.19 = zext i8 %15229 to i32
  %15230 = load i8, i8* %arrayidx70.19, align 1
  %conv71.41.19 = zext i8 %15230 to i32
  %xor72.41.19 = xor i32 %conv71.41.19, %conv68.41.19
  %conv73.41.19 = trunc i32 %xor72.41.19 to i8
  store i8 %conv73.41.19, i8* %arrayidx70.19, align 1
  %scevgep20.42.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 42
  %15231 = load i8, i8* %scevgep20.42.19, align 1
  %conv68.42.19 = zext i8 %15231 to i32
  %15232 = load i8, i8* %arrayidx70.19, align 1
  %conv71.42.19 = zext i8 %15232 to i32
  %xor72.42.19 = xor i32 %conv71.42.19, %conv68.42.19
  %conv73.42.19 = trunc i32 %xor72.42.19 to i8
  store i8 %conv73.42.19, i8* %arrayidx70.19, align 1
  %scevgep20.43.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 43
  %15233 = load i8, i8* %scevgep20.43.19, align 1
  %conv68.43.19 = zext i8 %15233 to i32
  %15234 = load i8, i8* %arrayidx70.19, align 1
  %conv71.43.19 = zext i8 %15234 to i32
  %xor72.43.19 = xor i32 %conv71.43.19, %conv68.43.19
  %conv73.43.19 = trunc i32 %xor72.43.19 to i8
  store i8 %conv73.43.19, i8* %arrayidx70.19, align 1
  %scevgep20.44.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 44
  %15235 = load i8, i8* %scevgep20.44.19, align 1
  %conv68.44.19 = zext i8 %15235 to i32
  %15236 = load i8, i8* %arrayidx70.19, align 1
  %conv71.44.19 = zext i8 %15236 to i32
  %xor72.44.19 = xor i32 %conv71.44.19, %conv68.44.19
  %conv73.44.19 = trunc i32 %xor72.44.19 to i8
  store i8 %conv73.44.19, i8* %arrayidx70.19, align 1
  %scevgep20.45.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 45
  %15237 = load i8, i8* %scevgep20.45.19, align 1
  %conv68.45.19 = zext i8 %15237 to i32
  %15238 = load i8, i8* %arrayidx70.19, align 1
  %conv71.45.19 = zext i8 %15238 to i32
  %xor72.45.19 = xor i32 %conv71.45.19, %conv68.45.19
  %conv73.45.19 = trunc i32 %xor72.45.19 to i8
  store i8 %conv73.45.19, i8* %arrayidx70.19, align 1
  %scevgep20.46.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 46
  %15239 = load i8, i8* %scevgep20.46.19, align 1
  %conv68.46.19 = zext i8 %15239 to i32
  %15240 = load i8, i8* %arrayidx70.19, align 1
  %conv71.46.19 = zext i8 %15240 to i32
  %xor72.46.19 = xor i32 %conv71.46.19, %conv68.46.19
  %conv73.46.19 = trunc i32 %xor72.46.19 to i8
  store i8 %conv73.46.19, i8* %arrayidx70.19, align 1
  %scevgep20.47.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 47
  %15241 = load i8, i8* %scevgep20.47.19, align 1
  %conv68.47.19 = zext i8 %15241 to i32
  %15242 = load i8, i8* %arrayidx70.19, align 1
  %conv71.47.19 = zext i8 %15242 to i32
  %xor72.47.19 = xor i32 %conv71.47.19, %conv68.47.19
  %conv73.47.19 = trunc i32 %xor72.47.19 to i8
  store i8 %conv73.47.19, i8* %arrayidx70.19, align 1
  %scevgep20.48.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 48
  %15243 = load i8, i8* %scevgep20.48.19, align 1
  %conv68.48.19 = zext i8 %15243 to i32
  %15244 = load i8, i8* %arrayidx70.19, align 1
  %conv71.48.19 = zext i8 %15244 to i32
  %xor72.48.19 = xor i32 %conv71.48.19, %conv68.48.19
  %conv73.48.19 = trunc i32 %xor72.48.19 to i8
  store i8 %conv73.48.19, i8* %arrayidx70.19, align 1
  %scevgep20.49.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 49
  %15245 = load i8, i8* %scevgep20.49.19, align 1
  %conv68.49.19 = zext i8 %15245 to i32
  %15246 = load i8, i8* %arrayidx70.19, align 1
  %conv71.49.19 = zext i8 %15246 to i32
  %xor72.49.19 = xor i32 %conv71.49.19, %conv68.49.19
  %conv73.49.19 = trunc i32 %xor72.49.19 to i8
  store i8 %conv73.49.19, i8* %arrayidx70.19, align 1
  %scevgep20.50.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 50
  %15247 = load i8, i8* %scevgep20.50.19, align 1
  %conv68.50.19 = zext i8 %15247 to i32
  %15248 = load i8, i8* %arrayidx70.19, align 1
  %conv71.50.19 = zext i8 %15248 to i32
  %xor72.50.19 = xor i32 %conv71.50.19, %conv68.50.19
  %conv73.50.19 = trunc i32 %xor72.50.19 to i8
  store i8 %conv73.50.19, i8* %arrayidx70.19, align 1
  %scevgep20.51.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 51
  %15249 = load i8, i8* %scevgep20.51.19, align 1
  %conv68.51.19 = zext i8 %15249 to i32
  %15250 = load i8, i8* %arrayidx70.19, align 1
  %conv71.51.19 = zext i8 %15250 to i32
  %xor72.51.19 = xor i32 %conv71.51.19, %conv68.51.19
  %conv73.51.19 = trunc i32 %xor72.51.19 to i8
  store i8 %conv73.51.19, i8* %arrayidx70.19, align 1
  %scevgep20.52.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 52
  %15251 = load i8, i8* %scevgep20.52.19, align 1
  %conv68.52.19 = zext i8 %15251 to i32
  %15252 = load i8, i8* %arrayidx70.19, align 1
  %conv71.52.19 = zext i8 %15252 to i32
  %xor72.52.19 = xor i32 %conv71.52.19, %conv68.52.19
  %conv73.52.19 = trunc i32 %xor72.52.19 to i8
  store i8 %conv73.52.19, i8* %arrayidx70.19, align 1
  %scevgep20.53.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 53
  %15253 = load i8, i8* %scevgep20.53.19, align 1
  %conv68.53.19 = zext i8 %15253 to i32
  %15254 = load i8, i8* %arrayidx70.19, align 1
  %conv71.53.19 = zext i8 %15254 to i32
  %xor72.53.19 = xor i32 %conv71.53.19, %conv68.53.19
  %conv73.53.19 = trunc i32 %xor72.53.19 to i8
  store i8 %conv73.53.19, i8* %arrayidx70.19, align 1
  %scevgep20.54.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 54
  %15255 = load i8, i8* %scevgep20.54.19, align 1
  %conv68.54.19 = zext i8 %15255 to i32
  %15256 = load i8, i8* %arrayidx70.19, align 1
  %conv71.54.19 = zext i8 %15256 to i32
  %xor72.54.19 = xor i32 %conv71.54.19, %conv68.54.19
  %conv73.54.19 = trunc i32 %xor72.54.19 to i8
  store i8 %conv73.54.19, i8* %arrayidx70.19, align 1
  %scevgep20.55.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 55
  %15257 = load i8, i8* %scevgep20.55.19, align 1
  %conv68.55.19 = zext i8 %15257 to i32
  %15258 = load i8, i8* %arrayidx70.19, align 1
  %conv71.55.19 = zext i8 %15258 to i32
  %xor72.55.19 = xor i32 %conv71.55.19, %conv68.55.19
  %conv73.55.19 = trunc i32 %xor72.55.19 to i8
  store i8 %conv73.55.19, i8* %arrayidx70.19, align 1
  %scevgep20.56.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 56
  %15259 = load i8, i8* %scevgep20.56.19, align 1
  %conv68.56.19 = zext i8 %15259 to i32
  %15260 = load i8, i8* %arrayidx70.19, align 1
  %conv71.56.19 = zext i8 %15260 to i32
  %xor72.56.19 = xor i32 %conv71.56.19, %conv68.56.19
  %conv73.56.19 = trunc i32 %xor72.56.19 to i8
  store i8 %conv73.56.19, i8* %arrayidx70.19, align 1
  %scevgep20.57.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 57
  %15261 = load i8, i8* %scevgep20.57.19, align 1
  %conv68.57.19 = zext i8 %15261 to i32
  %15262 = load i8, i8* %arrayidx70.19, align 1
  %conv71.57.19 = zext i8 %15262 to i32
  %xor72.57.19 = xor i32 %conv71.57.19, %conv68.57.19
  %conv73.57.19 = trunc i32 %xor72.57.19 to i8
  store i8 %conv73.57.19, i8* %arrayidx70.19, align 1
  %scevgep20.58.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 58
  %15263 = load i8, i8* %scevgep20.58.19, align 1
  %conv68.58.19 = zext i8 %15263 to i32
  %15264 = load i8, i8* %arrayidx70.19, align 1
  %conv71.58.19 = zext i8 %15264 to i32
  %xor72.58.19 = xor i32 %conv71.58.19, %conv68.58.19
  %conv73.58.19 = trunc i32 %xor72.58.19 to i8
  store i8 %conv73.58.19, i8* %arrayidx70.19, align 1
  %scevgep20.59.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 59
  %15265 = load i8, i8* %scevgep20.59.19, align 1
  %conv68.59.19 = zext i8 %15265 to i32
  %15266 = load i8, i8* %arrayidx70.19, align 1
  %conv71.59.19 = zext i8 %15266 to i32
  %xor72.59.19 = xor i32 %conv71.59.19, %conv68.59.19
  %conv73.59.19 = trunc i32 %xor72.59.19 to i8
  store i8 %conv73.59.19, i8* %arrayidx70.19, align 1
  %scevgep20.60.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 0, i64 60
  %15267 = load i8, i8* %scevgep20.60.19, align 1
  %conv68.60.19 = zext i8 %15267 to i32
  %15268 = load i8, i8* %arrayidx70.19, align 1
  %conv71.60.19 = zext i8 %15268 to i32
  %xor72.60.19 = xor i32 %conv71.60.19, %conv68.60.19
  %conv73.60.19 = trunc i32 %xor72.60.19 to i8
  store i8 %conv73.60.19, i8* %arrayidx70.19, align 1
  %scevgep19.19 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15146, i64 0, i64 1, i64 0
  %15269 = bitcast i8* %scevgep19.19 to [61 x [61 x i8]]*
  %arrayidx51.20 = getelementptr inbounds i8, i8* %a, i64 20
  %15270 = load i8, i8* %arrayidx51.20, align 1
  %arrayidx53.20 = getelementptr inbounds i8, i8* %b, i64 20
  %15271 = load i8, i8* %arrayidx53.20, align 1
  %call54.20 = call zeroext i8 @mult(i8 zeroext %15270, i8 zeroext %15271)
  %arrayidx56.20 = getelementptr inbounds i8, i8* %c, i64 20
  store i8 %call54.20, i8* %arrayidx56.20, align 1
  %arrayidx70.20 = getelementptr inbounds i8, i8* %c, i64 20
  %scevgep20.20244 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 0
  %15272 = load i8, i8* %scevgep20.20244, align 1
  %conv68.20245 = zext i8 %15272 to i32
  %15273 = load i8, i8* %arrayidx70.20, align 1
  %conv71.20246 = zext i8 %15273 to i32
  %xor72.20247 = xor i32 %conv71.20246, %conv68.20245
  %conv73.20248 = trunc i32 %xor72.20247 to i8
  store i8 %conv73.20248, i8* %arrayidx70.20, align 1
  %scevgep20.1.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 1
  %15274 = load i8, i8* %scevgep20.1.20, align 1
  %conv68.1.20 = zext i8 %15274 to i32
  %15275 = load i8, i8* %arrayidx70.20, align 1
  %conv71.1.20 = zext i8 %15275 to i32
  %xor72.1.20 = xor i32 %conv71.1.20, %conv68.1.20
  %conv73.1.20 = trunc i32 %xor72.1.20 to i8
  store i8 %conv73.1.20, i8* %arrayidx70.20, align 1
  %scevgep20.2.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 2
  %15276 = load i8, i8* %scevgep20.2.20, align 1
  %conv68.2.20 = zext i8 %15276 to i32
  %15277 = load i8, i8* %arrayidx70.20, align 1
  %conv71.2.20 = zext i8 %15277 to i32
  %xor72.2.20 = xor i32 %conv71.2.20, %conv68.2.20
  %conv73.2.20 = trunc i32 %xor72.2.20 to i8
  store i8 %conv73.2.20, i8* %arrayidx70.20, align 1
  %scevgep20.3.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 3
  %15278 = load i8, i8* %scevgep20.3.20, align 1
  %conv68.3.20 = zext i8 %15278 to i32
  %15279 = load i8, i8* %arrayidx70.20, align 1
  %conv71.3.20 = zext i8 %15279 to i32
  %xor72.3.20 = xor i32 %conv71.3.20, %conv68.3.20
  %conv73.3.20 = trunc i32 %xor72.3.20 to i8
  store i8 %conv73.3.20, i8* %arrayidx70.20, align 1
  %scevgep20.4.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 4
  %15280 = load i8, i8* %scevgep20.4.20, align 1
  %conv68.4.20 = zext i8 %15280 to i32
  %15281 = load i8, i8* %arrayidx70.20, align 1
  %conv71.4.20 = zext i8 %15281 to i32
  %xor72.4.20 = xor i32 %conv71.4.20, %conv68.4.20
  %conv73.4.20 = trunc i32 %xor72.4.20 to i8
  store i8 %conv73.4.20, i8* %arrayidx70.20, align 1
  %scevgep20.5.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 5
  %15282 = load i8, i8* %scevgep20.5.20, align 1
  %conv68.5.20 = zext i8 %15282 to i32
  %15283 = load i8, i8* %arrayidx70.20, align 1
  %conv71.5.20 = zext i8 %15283 to i32
  %xor72.5.20 = xor i32 %conv71.5.20, %conv68.5.20
  %conv73.5.20 = trunc i32 %xor72.5.20 to i8
  store i8 %conv73.5.20, i8* %arrayidx70.20, align 1
  %scevgep20.6.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 6
  %15284 = load i8, i8* %scevgep20.6.20, align 1
  %conv68.6.20 = zext i8 %15284 to i32
  %15285 = load i8, i8* %arrayidx70.20, align 1
  %conv71.6.20 = zext i8 %15285 to i32
  %xor72.6.20 = xor i32 %conv71.6.20, %conv68.6.20
  %conv73.6.20 = trunc i32 %xor72.6.20 to i8
  store i8 %conv73.6.20, i8* %arrayidx70.20, align 1
  %scevgep20.7.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 7
  %15286 = load i8, i8* %scevgep20.7.20, align 1
  %conv68.7.20 = zext i8 %15286 to i32
  %15287 = load i8, i8* %arrayidx70.20, align 1
  %conv71.7.20 = zext i8 %15287 to i32
  %xor72.7.20 = xor i32 %conv71.7.20, %conv68.7.20
  %conv73.7.20 = trunc i32 %xor72.7.20 to i8
  store i8 %conv73.7.20, i8* %arrayidx70.20, align 1
  %scevgep20.8.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 8
  %15288 = load i8, i8* %scevgep20.8.20, align 1
  %conv68.8.20 = zext i8 %15288 to i32
  %15289 = load i8, i8* %arrayidx70.20, align 1
  %conv71.8.20 = zext i8 %15289 to i32
  %xor72.8.20 = xor i32 %conv71.8.20, %conv68.8.20
  %conv73.8.20 = trunc i32 %xor72.8.20 to i8
  store i8 %conv73.8.20, i8* %arrayidx70.20, align 1
  %scevgep20.9.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 9
  %15290 = load i8, i8* %scevgep20.9.20, align 1
  %conv68.9.20 = zext i8 %15290 to i32
  %15291 = load i8, i8* %arrayidx70.20, align 1
  %conv71.9.20 = zext i8 %15291 to i32
  %xor72.9.20 = xor i32 %conv71.9.20, %conv68.9.20
  %conv73.9.20 = trunc i32 %xor72.9.20 to i8
  store i8 %conv73.9.20, i8* %arrayidx70.20, align 1
  %scevgep20.10.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 10
  %15292 = load i8, i8* %scevgep20.10.20, align 1
  %conv68.10.20 = zext i8 %15292 to i32
  %15293 = load i8, i8* %arrayidx70.20, align 1
  %conv71.10.20 = zext i8 %15293 to i32
  %xor72.10.20 = xor i32 %conv71.10.20, %conv68.10.20
  %conv73.10.20 = trunc i32 %xor72.10.20 to i8
  store i8 %conv73.10.20, i8* %arrayidx70.20, align 1
  %scevgep20.11.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 11
  %15294 = load i8, i8* %scevgep20.11.20, align 1
  %conv68.11.20 = zext i8 %15294 to i32
  %15295 = load i8, i8* %arrayidx70.20, align 1
  %conv71.11.20 = zext i8 %15295 to i32
  %xor72.11.20 = xor i32 %conv71.11.20, %conv68.11.20
  %conv73.11.20 = trunc i32 %xor72.11.20 to i8
  store i8 %conv73.11.20, i8* %arrayidx70.20, align 1
  %scevgep20.12.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 12
  %15296 = load i8, i8* %scevgep20.12.20, align 1
  %conv68.12.20 = zext i8 %15296 to i32
  %15297 = load i8, i8* %arrayidx70.20, align 1
  %conv71.12.20 = zext i8 %15297 to i32
  %xor72.12.20 = xor i32 %conv71.12.20, %conv68.12.20
  %conv73.12.20 = trunc i32 %xor72.12.20 to i8
  store i8 %conv73.12.20, i8* %arrayidx70.20, align 1
  %scevgep20.13.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 13
  %15298 = load i8, i8* %scevgep20.13.20, align 1
  %conv68.13.20 = zext i8 %15298 to i32
  %15299 = load i8, i8* %arrayidx70.20, align 1
  %conv71.13.20 = zext i8 %15299 to i32
  %xor72.13.20 = xor i32 %conv71.13.20, %conv68.13.20
  %conv73.13.20 = trunc i32 %xor72.13.20 to i8
  store i8 %conv73.13.20, i8* %arrayidx70.20, align 1
  %scevgep20.14.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 14
  %15300 = load i8, i8* %scevgep20.14.20, align 1
  %conv68.14.20 = zext i8 %15300 to i32
  %15301 = load i8, i8* %arrayidx70.20, align 1
  %conv71.14.20 = zext i8 %15301 to i32
  %xor72.14.20 = xor i32 %conv71.14.20, %conv68.14.20
  %conv73.14.20 = trunc i32 %xor72.14.20 to i8
  store i8 %conv73.14.20, i8* %arrayidx70.20, align 1
  %scevgep20.15.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 15
  %15302 = load i8, i8* %scevgep20.15.20, align 1
  %conv68.15.20 = zext i8 %15302 to i32
  %15303 = load i8, i8* %arrayidx70.20, align 1
  %conv71.15.20 = zext i8 %15303 to i32
  %xor72.15.20 = xor i32 %conv71.15.20, %conv68.15.20
  %conv73.15.20 = trunc i32 %xor72.15.20 to i8
  store i8 %conv73.15.20, i8* %arrayidx70.20, align 1
  %scevgep20.16.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 16
  %15304 = load i8, i8* %scevgep20.16.20, align 1
  %conv68.16.20 = zext i8 %15304 to i32
  %15305 = load i8, i8* %arrayidx70.20, align 1
  %conv71.16.20 = zext i8 %15305 to i32
  %xor72.16.20 = xor i32 %conv71.16.20, %conv68.16.20
  %conv73.16.20 = trunc i32 %xor72.16.20 to i8
  store i8 %conv73.16.20, i8* %arrayidx70.20, align 1
  %scevgep20.17.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 17
  %15306 = load i8, i8* %scevgep20.17.20, align 1
  %conv68.17.20 = zext i8 %15306 to i32
  %15307 = load i8, i8* %arrayidx70.20, align 1
  %conv71.17.20 = zext i8 %15307 to i32
  %xor72.17.20 = xor i32 %conv71.17.20, %conv68.17.20
  %conv73.17.20 = trunc i32 %xor72.17.20 to i8
  store i8 %conv73.17.20, i8* %arrayidx70.20, align 1
  %scevgep20.18.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 18
  %15308 = load i8, i8* %scevgep20.18.20, align 1
  %conv68.18.20 = zext i8 %15308 to i32
  %15309 = load i8, i8* %arrayidx70.20, align 1
  %conv71.18.20 = zext i8 %15309 to i32
  %xor72.18.20 = xor i32 %conv71.18.20, %conv68.18.20
  %conv73.18.20 = trunc i32 %xor72.18.20 to i8
  store i8 %conv73.18.20, i8* %arrayidx70.20, align 1
  %scevgep20.19.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 19
  %15310 = load i8, i8* %scevgep20.19.20, align 1
  %conv68.19.20 = zext i8 %15310 to i32
  %15311 = load i8, i8* %arrayidx70.20, align 1
  %conv71.19.20 = zext i8 %15311 to i32
  %xor72.19.20 = xor i32 %conv71.19.20, %conv68.19.20
  %conv73.19.20 = trunc i32 %xor72.19.20 to i8
  store i8 %conv73.19.20, i8* %arrayidx70.20, align 1
  %scevgep20.21.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 21
  %15312 = load i8, i8* %scevgep20.21.20, align 1
  %conv68.21.20 = zext i8 %15312 to i32
  %15313 = load i8, i8* %arrayidx70.20, align 1
  %conv71.21.20 = zext i8 %15313 to i32
  %xor72.21.20 = xor i32 %conv71.21.20, %conv68.21.20
  %conv73.21.20 = trunc i32 %xor72.21.20 to i8
  store i8 %conv73.21.20, i8* %arrayidx70.20, align 1
  %scevgep20.22.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 22
  %15314 = load i8, i8* %scevgep20.22.20, align 1
  %conv68.22.20 = zext i8 %15314 to i32
  %15315 = load i8, i8* %arrayidx70.20, align 1
  %conv71.22.20 = zext i8 %15315 to i32
  %xor72.22.20 = xor i32 %conv71.22.20, %conv68.22.20
  %conv73.22.20 = trunc i32 %xor72.22.20 to i8
  store i8 %conv73.22.20, i8* %arrayidx70.20, align 1
  %scevgep20.23.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 23
  %15316 = load i8, i8* %scevgep20.23.20, align 1
  %conv68.23.20 = zext i8 %15316 to i32
  %15317 = load i8, i8* %arrayidx70.20, align 1
  %conv71.23.20 = zext i8 %15317 to i32
  %xor72.23.20 = xor i32 %conv71.23.20, %conv68.23.20
  %conv73.23.20 = trunc i32 %xor72.23.20 to i8
  store i8 %conv73.23.20, i8* %arrayidx70.20, align 1
  %scevgep20.24.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 24
  %15318 = load i8, i8* %scevgep20.24.20, align 1
  %conv68.24.20 = zext i8 %15318 to i32
  %15319 = load i8, i8* %arrayidx70.20, align 1
  %conv71.24.20 = zext i8 %15319 to i32
  %xor72.24.20 = xor i32 %conv71.24.20, %conv68.24.20
  %conv73.24.20 = trunc i32 %xor72.24.20 to i8
  store i8 %conv73.24.20, i8* %arrayidx70.20, align 1
  %scevgep20.25.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 25
  %15320 = load i8, i8* %scevgep20.25.20, align 1
  %conv68.25.20 = zext i8 %15320 to i32
  %15321 = load i8, i8* %arrayidx70.20, align 1
  %conv71.25.20 = zext i8 %15321 to i32
  %xor72.25.20 = xor i32 %conv71.25.20, %conv68.25.20
  %conv73.25.20 = trunc i32 %xor72.25.20 to i8
  store i8 %conv73.25.20, i8* %arrayidx70.20, align 1
  %scevgep20.26.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 26
  %15322 = load i8, i8* %scevgep20.26.20, align 1
  %conv68.26.20 = zext i8 %15322 to i32
  %15323 = load i8, i8* %arrayidx70.20, align 1
  %conv71.26.20 = zext i8 %15323 to i32
  %xor72.26.20 = xor i32 %conv71.26.20, %conv68.26.20
  %conv73.26.20 = trunc i32 %xor72.26.20 to i8
  store i8 %conv73.26.20, i8* %arrayidx70.20, align 1
  %scevgep20.27.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 27
  %15324 = load i8, i8* %scevgep20.27.20, align 1
  %conv68.27.20 = zext i8 %15324 to i32
  %15325 = load i8, i8* %arrayidx70.20, align 1
  %conv71.27.20 = zext i8 %15325 to i32
  %xor72.27.20 = xor i32 %conv71.27.20, %conv68.27.20
  %conv73.27.20 = trunc i32 %xor72.27.20 to i8
  store i8 %conv73.27.20, i8* %arrayidx70.20, align 1
  %scevgep20.28.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 28
  %15326 = load i8, i8* %scevgep20.28.20, align 1
  %conv68.28.20 = zext i8 %15326 to i32
  %15327 = load i8, i8* %arrayidx70.20, align 1
  %conv71.28.20 = zext i8 %15327 to i32
  %xor72.28.20 = xor i32 %conv71.28.20, %conv68.28.20
  %conv73.28.20 = trunc i32 %xor72.28.20 to i8
  store i8 %conv73.28.20, i8* %arrayidx70.20, align 1
  %scevgep20.29.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 29
  %15328 = load i8, i8* %scevgep20.29.20, align 1
  %conv68.29.20 = zext i8 %15328 to i32
  %15329 = load i8, i8* %arrayidx70.20, align 1
  %conv71.29.20 = zext i8 %15329 to i32
  %xor72.29.20 = xor i32 %conv71.29.20, %conv68.29.20
  %conv73.29.20 = trunc i32 %xor72.29.20 to i8
  store i8 %conv73.29.20, i8* %arrayidx70.20, align 1
  %scevgep20.30.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 30
  %15330 = load i8, i8* %scevgep20.30.20, align 1
  %conv68.30.20 = zext i8 %15330 to i32
  %15331 = load i8, i8* %arrayidx70.20, align 1
  %conv71.30.20 = zext i8 %15331 to i32
  %xor72.30.20 = xor i32 %conv71.30.20, %conv68.30.20
  %conv73.30.20 = trunc i32 %xor72.30.20 to i8
  store i8 %conv73.30.20, i8* %arrayidx70.20, align 1
  %scevgep20.31.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 31
  %15332 = load i8, i8* %scevgep20.31.20, align 1
  %conv68.31.20 = zext i8 %15332 to i32
  %15333 = load i8, i8* %arrayidx70.20, align 1
  %conv71.31.20 = zext i8 %15333 to i32
  %xor72.31.20 = xor i32 %conv71.31.20, %conv68.31.20
  %conv73.31.20 = trunc i32 %xor72.31.20 to i8
  store i8 %conv73.31.20, i8* %arrayidx70.20, align 1
  %scevgep20.32.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 32
  %15334 = load i8, i8* %scevgep20.32.20, align 1
  %conv68.32.20 = zext i8 %15334 to i32
  %15335 = load i8, i8* %arrayidx70.20, align 1
  %conv71.32.20 = zext i8 %15335 to i32
  %xor72.32.20 = xor i32 %conv71.32.20, %conv68.32.20
  %conv73.32.20 = trunc i32 %xor72.32.20 to i8
  store i8 %conv73.32.20, i8* %arrayidx70.20, align 1
  %scevgep20.33.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 33
  %15336 = load i8, i8* %scevgep20.33.20, align 1
  %conv68.33.20 = zext i8 %15336 to i32
  %15337 = load i8, i8* %arrayidx70.20, align 1
  %conv71.33.20 = zext i8 %15337 to i32
  %xor72.33.20 = xor i32 %conv71.33.20, %conv68.33.20
  %conv73.33.20 = trunc i32 %xor72.33.20 to i8
  store i8 %conv73.33.20, i8* %arrayidx70.20, align 1
  %scevgep20.34.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 34
  %15338 = load i8, i8* %scevgep20.34.20, align 1
  %conv68.34.20 = zext i8 %15338 to i32
  %15339 = load i8, i8* %arrayidx70.20, align 1
  %conv71.34.20 = zext i8 %15339 to i32
  %xor72.34.20 = xor i32 %conv71.34.20, %conv68.34.20
  %conv73.34.20 = trunc i32 %xor72.34.20 to i8
  store i8 %conv73.34.20, i8* %arrayidx70.20, align 1
  %scevgep20.35.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 35
  %15340 = load i8, i8* %scevgep20.35.20, align 1
  %conv68.35.20 = zext i8 %15340 to i32
  %15341 = load i8, i8* %arrayidx70.20, align 1
  %conv71.35.20 = zext i8 %15341 to i32
  %xor72.35.20 = xor i32 %conv71.35.20, %conv68.35.20
  %conv73.35.20 = trunc i32 %xor72.35.20 to i8
  store i8 %conv73.35.20, i8* %arrayidx70.20, align 1
  %scevgep20.36.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 36
  %15342 = load i8, i8* %scevgep20.36.20, align 1
  %conv68.36.20 = zext i8 %15342 to i32
  %15343 = load i8, i8* %arrayidx70.20, align 1
  %conv71.36.20 = zext i8 %15343 to i32
  %xor72.36.20 = xor i32 %conv71.36.20, %conv68.36.20
  %conv73.36.20 = trunc i32 %xor72.36.20 to i8
  store i8 %conv73.36.20, i8* %arrayidx70.20, align 1
  %scevgep20.37.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 37
  %15344 = load i8, i8* %scevgep20.37.20, align 1
  %conv68.37.20 = zext i8 %15344 to i32
  %15345 = load i8, i8* %arrayidx70.20, align 1
  %conv71.37.20 = zext i8 %15345 to i32
  %xor72.37.20 = xor i32 %conv71.37.20, %conv68.37.20
  %conv73.37.20 = trunc i32 %xor72.37.20 to i8
  store i8 %conv73.37.20, i8* %arrayidx70.20, align 1
  %scevgep20.38.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 38
  %15346 = load i8, i8* %scevgep20.38.20, align 1
  %conv68.38.20 = zext i8 %15346 to i32
  %15347 = load i8, i8* %arrayidx70.20, align 1
  %conv71.38.20 = zext i8 %15347 to i32
  %xor72.38.20 = xor i32 %conv71.38.20, %conv68.38.20
  %conv73.38.20 = trunc i32 %xor72.38.20 to i8
  store i8 %conv73.38.20, i8* %arrayidx70.20, align 1
  %scevgep20.39.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 39
  %15348 = load i8, i8* %scevgep20.39.20, align 1
  %conv68.39.20 = zext i8 %15348 to i32
  %15349 = load i8, i8* %arrayidx70.20, align 1
  %conv71.39.20 = zext i8 %15349 to i32
  %xor72.39.20 = xor i32 %conv71.39.20, %conv68.39.20
  %conv73.39.20 = trunc i32 %xor72.39.20 to i8
  store i8 %conv73.39.20, i8* %arrayidx70.20, align 1
  %scevgep20.40.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 40
  %15350 = load i8, i8* %scevgep20.40.20, align 1
  %conv68.40.20 = zext i8 %15350 to i32
  %15351 = load i8, i8* %arrayidx70.20, align 1
  %conv71.40.20 = zext i8 %15351 to i32
  %xor72.40.20 = xor i32 %conv71.40.20, %conv68.40.20
  %conv73.40.20 = trunc i32 %xor72.40.20 to i8
  store i8 %conv73.40.20, i8* %arrayidx70.20, align 1
  %scevgep20.41.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 41
  %15352 = load i8, i8* %scevgep20.41.20, align 1
  %conv68.41.20 = zext i8 %15352 to i32
  %15353 = load i8, i8* %arrayidx70.20, align 1
  %conv71.41.20 = zext i8 %15353 to i32
  %xor72.41.20 = xor i32 %conv71.41.20, %conv68.41.20
  %conv73.41.20 = trunc i32 %xor72.41.20 to i8
  store i8 %conv73.41.20, i8* %arrayidx70.20, align 1
  %scevgep20.42.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 42
  %15354 = load i8, i8* %scevgep20.42.20, align 1
  %conv68.42.20 = zext i8 %15354 to i32
  %15355 = load i8, i8* %arrayidx70.20, align 1
  %conv71.42.20 = zext i8 %15355 to i32
  %xor72.42.20 = xor i32 %conv71.42.20, %conv68.42.20
  %conv73.42.20 = trunc i32 %xor72.42.20 to i8
  store i8 %conv73.42.20, i8* %arrayidx70.20, align 1
  %scevgep20.43.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 43
  %15356 = load i8, i8* %scevgep20.43.20, align 1
  %conv68.43.20 = zext i8 %15356 to i32
  %15357 = load i8, i8* %arrayidx70.20, align 1
  %conv71.43.20 = zext i8 %15357 to i32
  %xor72.43.20 = xor i32 %conv71.43.20, %conv68.43.20
  %conv73.43.20 = trunc i32 %xor72.43.20 to i8
  store i8 %conv73.43.20, i8* %arrayidx70.20, align 1
  %scevgep20.44.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 44
  %15358 = load i8, i8* %scevgep20.44.20, align 1
  %conv68.44.20 = zext i8 %15358 to i32
  %15359 = load i8, i8* %arrayidx70.20, align 1
  %conv71.44.20 = zext i8 %15359 to i32
  %xor72.44.20 = xor i32 %conv71.44.20, %conv68.44.20
  %conv73.44.20 = trunc i32 %xor72.44.20 to i8
  store i8 %conv73.44.20, i8* %arrayidx70.20, align 1
  %scevgep20.45.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 45
  %15360 = load i8, i8* %scevgep20.45.20, align 1
  %conv68.45.20 = zext i8 %15360 to i32
  %15361 = load i8, i8* %arrayidx70.20, align 1
  %conv71.45.20 = zext i8 %15361 to i32
  %xor72.45.20 = xor i32 %conv71.45.20, %conv68.45.20
  %conv73.45.20 = trunc i32 %xor72.45.20 to i8
  store i8 %conv73.45.20, i8* %arrayidx70.20, align 1
  %scevgep20.46.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 46
  %15362 = load i8, i8* %scevgep20.46.20, align 1
  %conv68.46.20 = zext i8 %15362 to i32
  %15363 = load i8, i8* %arrayidx70.20, align 1
  %conv71.46.20 = zext i8 %15363 to i32
  %xor72.46.20 = xor i32 %conv71.46.20, %conv68.46.20
  %conv73.46.20 = trunc i32 %xor72.46.20 to i8
  store i8 %conv73.46.20, i8* %arrayidx70.20, align 1
  %scevgep20.47.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 47
  %15364 = load i8, i8* %scevgep20.47.20, align 1
  %conv68.47.20 = zext i8 %15364 to i32
  %15365 = load i8, i8* %arrayidx70.20, align 1
  %conv71.47.20 = zext i8 %15365 to i32
  %xor72.47.20 = xor i32 %conv71.47.20, %conv68.47.20
  %conv73.47.20 = trunc i32 %xor72.47.20 to i8
  store i8 %conv73.47.20, i8* %arrayidx70.20, align 1
  %scevgep20.48.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 48
  %15366 = load i8, i8* %scevgep20.48.20, align 1
  %conv68.48.20 = zext i8 %15366 to i32
  %15367 = load i8, i8* %arrayidx70.20, align 1
  %conv71.48.20 = zext i8 %15367 to i32
  %xor72.48.20 = xor i32 %conv71.48.20, %conv68.48.20
  %conv73.48.20 = trunc i32 %xor72.48.20 to i8
  store i8 %conv73.48.20, i8* %arrayidx70.20, align 1
  %scevgep20.49.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 49
  %15368 = load i8, i8* %scevgep20.49.20, align 1
  %conv68.49.20 = zext i8 %15368 to i32
  %15369 = load i8, i8* %arrayidx70.20, align 1
  %conv71.49.20 = zext i8 %15369 to i32
  %xor72.49.20 = xor i32 %conv71.49.20, %conv68.49.20
  %conv73.49.20 = trunc i32 %xor72.49.20 to i8
  store i8 %conv73.49.20, i8* %arrayidx70.20, align 1
  %scevgep20.50.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 50
  %15370 = load i8, i8* %scevgep20.50.20, align 1
  %conv68.50.20 = zext i8 %15370 to i32
  %15371 = load i8, i8* %arrayidx70.20, align 1
  %conv71.50.20 = zext i8 %15371 to i32
  %xor72.50.20 = xor i32 %conv71.50.20, %conv68.50.20
  %conv73.50.20 = trunc i32 %xor72.50.20 to i8
  store i8 %conv73.50.20, i8* %arrayidx70.20, align 1
  %scevgep20.51.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 51
  %15372 = load i8, i8* %scevgep20.51.20, align 1
  %conv68.51.20 = zext i8 %15372 to i32
  %15373 = load i8, i8* %arrayidx70.20, align 1
  %conv71.51.20 = zext i8 %15373 to i32
  %xor72.51.20 = xor i32 %conv71.51.20, %conv68.51.20
  %conv73.51.20 = trunc i32 %xor72.51.20 to i8
  store i8 %conv73.51.20, i8* %arrayidx70.20, align 1
  %scevgep20.52.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 52
  %15374 = load i8, i8* %scevgep20.52.20, align 1
  %conv68.52.20 = zext i8 %15374 to i32
  %15375 = load i8, i8* %arrayidx70.20, align 1
  %conv71.52.20 = zext i8 %15375 to i32
  %xor72.52.20 = xor i32 %conv71.52.20, %conv68.52.20
  %conv73.52.20 = trunc i32 %xor72.52.20 to i8
  store i8 %conv73.52.20, i8* %arrayidx70.20, align 1
  %scevgep20.53.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 53
  %15376 = load i8, i8* %scevgep20.53.20, align 1
  %conv68.53.20 = zext i8 %15376 to i32
  %15377 = load i8, i8* %arrayidx70.20, align 1
  %conv71.53.20 = zext i8 %15377 to i32
  %xor72.53.20 = xor i32 %conv71.53.20, %conv68.53.20
  %conv73.53.20 = trunc i32 %xor72.53.20 to i8
  store i8 %conv73.53.20, i8* %arrayidx70.20, align 1
  %scevgep20.54.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 54
  %15378 = load i8, i8* %scevgep20.54.20, align 1
  %conv68.54.20 = zext i8 %15378 to i32
  %15379 = load i8, i8* %arrayidx70.20, align 1
  %conv71.54.20 = zext i8 %15379 to i32
  %xor72.54.20 = xor i32 %conv71.54.20, %conv68.54.20
  %conv73.54.20 = trunc i32 %xor72.54.20 to i8
  store i8 %conv73.54.20, i8* %arrayidx70.20, align 1
  %scevgep20.55.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 55
  %15380 = load i8, i8* %scevgep20.55.20, align 1
  %conv68.55.20 = zext i8 %15380 to i32
  %15381 = load i8, i8* %arrayidx70.20, align 1
  %conv71.55.20 = zext i8 %15381 to i32
  %xor72.55.20 = xor i32 %conv71.55.20, %conv68.55.20
  %conv73.55.20 = trunc i32 %xor72.55.20 to i8
  store i8 %conv73.55.20, i8* %arrayidx70.20, align 1
  %scevgep20.56.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 56
  %15382 = load i8, i8* %scevgep20.56.20, align 1
  %conv68.56.20 = zext i8 %15382 to i32
  %15383 = load i8, i8* %arrayidx70.20, align 1
  %conv71.56.20 = zext i8 %15383 to i32
  %xor72.56.20 = xor i32 %conv71.56.20, %conv68.56.20
  %conv73.56.20 = trunc i32 %xor72.56.20 to i8
  store i8 %conv73.56.20, i8* %arrayidx70.20, align 1
  %scevgep20.57.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 57
  %15384 = load i8, i8* %scevgep20.57.20, align 1
  %conv68.57.20 = zext i8 %15384 to i32
  %15385 = load i8, i8* %arrayidx70.20, align 1
  %conv71.57.20 = zext i8 %15385 to i32
  %xor72.57.20 = xor i32 %conv71.57.20, %conv68.57.20
  %conv73.57.20 = trunc i32 %xor72.57.20 to i8
  store i8 %conv73.57.20, i8* %arrayidx70.20, align 1
  %scevgep20.58.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 58
  %15386 = load i8, i8* %scevgep20.58.20, align 1
  %conv68.58.20 = zext i8 %15386 to i32
  %15387 = load i8, i8* %arrayidx70.20, align 1
  %conv71.58.20 = zext i8 %15387 to i32
  %xor72.58.20 = xor i32 %conv71.58.20, %conv68.58.20
  %conv73.58.20 = trunc i32 %xor72.58.20 to i8
  store i8 %conv73.58.20, i8* %arrayidx70.20, align 1
  %scevgep20.59.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 59
  %15388 = load i8, i8* %scevgep20.59.20, align 1
  %conv68.59.20 = zext i8 %15388 to i32
  %15389 = load i8, i8* %arrayidx70.20, align 1
  %conv71.59.20 = zext i8 %15389 to i32
  %xor72.59.20 = xor i32 %conv71.59.20, %conv68.59.20
  %conv73.59.20 = trunc i32 %xor72.59.20 to i8
  store i8 %conv73.59.20, i8* %arrayidx70.20, align 1
  %scevgep20.60.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 0, i64 60
  %15390 = load i8, i8* %scevgep20.60.20, align 1
  %conv68.60.20 = zext i8 %15390 to i32
  %15391 = load i8, i8* %arrayidx70.20, align 1
  %conv71.60.20 = zext i8 %15391 to i32
  %xor72.60.20 = xor i32 %conv71.60.20, %conv68.60.20
  %conv73.60.20 = trunc i32 %xor72.60.20 to i8
  store i8 %conv73.60.20, i8* %arrayidx70.20, align 1
  %scevgep19.20 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15269, i64 0, i64 1, i64 0
  %15392 = bitcast i8* %scevgep19.20 to [61 x [61 x i8]]*
  %arrayidx51.21 = getelementptr inbounds i8, i8* %a, i64 21
  %15393 = load i8, i8* %arrayidx51.21, align 1
  %arrayidx53.21 = getelementptr inbounds i8, i8* %b, i64 21
  %15394 = load i8, i8* %arrayidx53.21, align 1
  %call54.21 = call zeroext i8 @mult(i8 zeroext %15393, i8 zeroext %15394)
  %arrayidx56.21 = getelementptr inbounds i8, i8* %c, i64 21
  store i8 %call54.21, i8* %arrayidx56.21, align 1
  %arrayidx70.21 = getelementptr inbounds i8, i8* %c, i64 21
  %scevgep20.21254 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 0
  %15395 = load i8, i8* %scevgep20.21254, align 1
  %conv68.21255 = zext i8 %15395 to i32
  %15396 = load i8, i8* %arrayidx70.21, align 1
  %conv71.21256 = zext i8 %15396 to i32
  %xor72.21257 = xor i32 %conv71.21256, %conv68.21255
  %conv73.21258 = trunc i32 %xor72.21257 to i8
  store i8 %conv73.21258, i8* %arrayidx70.21, align 1
  %scevgep20.1.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 1
  %15397 = load i8, i8* %scevgep20.1.21, align 1
  %conv68.1.21 = zext i8 %15397 to i32
  %15398 = load i8, i8* %arrayidx70.21, align 1
  %conv71.1.21 = zext i8 %15398 to i32
  %xor72.1.21 = xor i32 %conv71.1.21, %conv68.1.21
  %conv73.1.21 = trunc i32 %xor72.1.21 to i8
  store i8 %conv73.1.21, i8* %arrayidx70.21, align 1
  %scevgep20.2.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 2
  %15399 = load i8, i8* %scevgep20.2.21, align 1
  %conv68.2.21 = zext i8 %15399 to i32
  %15400 = load i8, i8* %arrayidx70.21, align 1
  %conv71.2.21 = zext i8 %15400 to i32
  %xor72.2.21 = xor i32 %conv71.2.21, %conv68.2.21
  %conv73.2.21 = trunc i32 %xor72.2.21 to i8
  store i8 %conv73.2.21, i8* %arrayidx70.21, align 1
  %scevgep20.3.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 3
  %15401 = load i8, i8* %scevgep20.3.21, align 1
  %conv68.3.21 = zext i8 %15401 to i32
  %15402 = load i8, i8* %arrayidx70.21, align 1
  %conv71.3.21 = zext i8 %15402 to i32
  %xor72.3.21 = xor i32 %conv71.3.21, %conv68.3.21
  %conv73.3.21 = trunc i32 %xor72.3.21 to i8
  store i8 %conv73.3.21, i8* %arrayidx70.21, align 1
  %scevgep20.4.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 4
  %15403 = load i8, i8* %scevgep20.4.21, align 1
  %conv68.4.21 = zext i8 %15403 to i32
  %15404 = load i8, i8* %arrayidx70.21, align 1
  %conv71.4.21 = zext i8 %15404 to i32
  %xor72.4.21 = xor i32 %conv71.4.21, %conv68.4.21
  %conv73.4.21 = trunc i32 %xor72.4.21 to i8
  store i8 %conv73.4.21, i8* %arrayidx70.21, align 1
  %scevgep20.5.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 5
  %15405 = load i8, i8* %scevgep20.5.21, align 1
  %conv68.5.21 = zext i8 %15405 to i32
  %15406 = load i8, i8* %arrayidx70.21, align 1
  %conv71.5.21 = zext i8 %15406 to i32
  %xor72.5.21 = xor i32 %conv71.5.21, %conv68.5.21
  %conv73.5.21 = trunc i32 %xor72.5.21 to i8
  store i8 %conv73.5.21, i8* %arrayidx70.21, align 1
  %scevgep20.6.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 6
  %15407 = load i8, i8* %scevgep20.6.21, align 1
  %conv68.6.21 = zext i8 %15407 to i32
  %15408 = load i8, i8* %arrayidx70.21, align 1
  %conv71.6.21 = zext i8 %15408 to i32
  %xor72.6.21 = xor i32 %conv71.6.21, %conv68.6.21
  %conv73.6.21 = trunc i32 %xor72.6.21 to i8
  store i8 %conv73.6.21, i8* %arrayidx70.21, align 1
  %scevgep20.7.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 7
  %15409 = load i8, i8* %scevgep20.7.21, align 1
  %conv68.7.21 = zext i8 %15409 to i32
  %15410 = load i8, i8* %arrayidx70.21, align 1
  %conv71.7.21 = zext i8 %15410 to i32
  %xor72.7.21 = xor i32 %conv71.7.21, %conv68.7.21
  %conv73.7.21 = trunc i32 %xor72.7.21 to i8
  store i8 %conv73.7.21, i8* %arrayidx70.21, align 1
  %scevgep20.8.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 8
  %15411 = load i8, i8* %scevgep20.8.21, align 1
  %conv68.8.21 = zext i8 %15411 to i32
  %15412 = load i8, i8* %arrayidx70.21, align 1
  %conv71.8.21 = zext i8 %15412 to i32
  %xor72.8.21 = xor i32 %conv71.8.21, %conv68.8.21
  %conv73.8.21 = trunc i32 %xor72.8.21 to i8
  store i8 %conv73.8.21, i8* %arrayidx70.21, align 1
  %scevgep20.9.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 9
  %15413 = load i8, i8* %scevgep20.9.21, align 1
  %conv68.9.21 = zext i8 %15413 to i32
  %15414 = load i8, i8* %arrayidx70.21, align 1
  %conv71.9.21 = zext i8 %15414 to i32
  %xor72.9.21 = xor i32 %conv71.9.21, %conv68.9.21
  %conv73.9.21 = trunc i32 %xor72.9.21 to i8
  store i8 %conv73.9.21, i8* %arrayidx70.21, align 1
  %scevgep20.10.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 10
  %15415 = load i8, i8* %scevgep20.10.21, align 1
  %conv68.10.21 = zext i8 %15415 to i32
  %15416 = load i8, i8* %arrayidx70.21, align 1
  %conv71.10.21 = zext i8 %15416 to i32
  %xor72.10.21 = xor i32 %conv71.10.21, %conv68.10.21
  %conv73.10.21 = trunc i32 %xor72.10.21 to i8
  store i8 %conv73.10.21, i8* %arrayidx70.21, align 1
  %scevgep20.11.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 11
  %15417 = load i8, i8* %scevgep20.11.21, align 1
  %conv68.11.21 = zext i8 %15417 to i32
  %15418 = load i8, i8* %arrayidx70.21, align 1
  %conv71.11.21 = zext i8 %15418 to i32
  %xor72.11.21 = xor i32 %conv71.11.21, %conv68.11.21
  %conv73.11.21 = trunc i32 %xor72.11.21 to i8
  store i8 %conv73.11.21, i8* %arrayidx70.21, align 1
  %scevgep20.12.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 12
  %15419 = load i8, i8* %scevgep20.12.21, align 1
  %conv68.12.21 = zext i8 %15419 to i32
  %15420 = load i8, i8* %arrayidx70.21, align 1
  %conv71.12.21 = zext i8 %15420 to i32
  %xor72.12.21 = xor i32 %conv71.12.21, %conv68.12.21
  %conv73.12.21 = trunc i32 %xor72.12.21 to i8
  store i8 %conv73.12.21, i8* %arrayidx70.21, align 1
  %scevgep20.13.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 13
  %15421 = load i8, i8* %scevgep20.13.21, align 1
  %conv68.13.21 = zext i8 %15421 to i32
  %15422 = load i8, i8* %arrayidx70.21, align 1
  %conv71.13.21 = zext i8 %15422 to i32
  %xor72.13.21 = xor i32 %conv71.13.21, %conv68.13.21
  %conv73.13.21 = trunc i32 %xor72.13.21 to i8
  store i8 %conv73.13.21, i8* %arrayidx70.21, align 1
  %scevgep20.14.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 14
  %15423 = load i8, i8* %scevgep20.14.21, align 1
  %conv68.14.21 = zext i8 %15423 to i32
  %15424 = load i8, i8* %arrayidx70.21, align 1
  %conv71.14.21 = zext i8 %15424 to i32
  %xor72.14.21 = xor i32 %conv71.14.21, %conv68.14.21
  %conv73.14.21 = trunc i32 %xor72.14.21 to i8
  store i8 %conv73.14.21, i8* %arrayidx70.21, align 1
  %scevgep20.15.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 15
  %15425 = load i8, i8* %scevgep20.15.21, align 1
  %conv68.15.21 = zext i8 %15425 to i32
  %15426 = load i8, i8* %arrayidx70.21, align 1
  %conv71.15.21 = zext i8 %15426 to i32
  %xor72.15.21 = xor i32 %conv71.15.21, %conv68.15.21
  %conv73.15.21 = trunc i32 %xor72.15.21 to i8
  store i8 %conv73.15.21, i8* %arrayidx70.21, align 1
  %scevgep20.16.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 16
  %15427 = load i8, i8* %scevgep20.16.21, align 1
  %conv68.16.21 = zext i8 %15427 to i32
  %15428 = load i8, i8* %arrayidx70.21, align 1
  %conv71.16.21 = zext i8 %15428 to i32
  %xor72.16.21 = xor i32 %conv71.16.21, %conv68.16.21
  %conv73.16.21 = trunc i32 %xor72.16.21 to i8
  store i8 %conv73.16.21, i8* %arrayidx70.21, align 1
  %scevgep20.17.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 17
  %15429 = load i8, i8* %scevgep20.17.21, align 1
  %conv68.17.21 = zext i8 %15429 to i32
  %15430 = load i8, i8* %arrayidx70.21, align 1
  %conv71.17.21 = zext i8 %15430 to i32
  %xor72.17.21 = xor i32 %conv71.17.21, %conv68.17.21
  %conv73.17.21 = trunc i32 %xor72.17.21 to i8
  store i8 %conv73.17.21, i8* %arrayidx70.21, align 1
  %scevgep20.18.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 18
  %15431 = load i8, i8* %scevgep20.18.21, align 1
  %conv68.18.21 = zext i8 %15431 to i32
  %15432 = load i8, i8* %arrayidx70.21, align 1
  %conv71.18.21 = zext i8 %15432 to i32
  %xor72.18.21 = xor i32 %conv71.18.21, %conv68.18.21
  %conv73.18.21 = trunc i32 %xor72.18.21 to i8
  store i8 %conv73.18.21, i8* %arrayidx70.21, align 1
  %scevgep20.19.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 19
  %15433 = load i8, i8* %scevgep20.19.21, align 1
  %conv68.19.21 = zext i8 %15433 to i32
  %15434 = load i8, i8* %arrayidx70.21, align 1
  %conv71.19.21 = zext i8 %15434 to i32
  %xor72.19.21 = xor i32 %conv71.19.21, %conv68.19.21
  %conv73.19.21 = trunc i32 %xor72.19.21 to i8
  store i8 %conv73.19.21, i8* %arrayidx70.21, align 1
  %scevgep20.20.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 20
  %15435 = load i8, i8* %scevgep20.20.21, align 1
  %conv68.20.21 = zext i8 %15435 to i32
  %15436 = load i8, i8* %arrayidx70.21, align 1
  %conv71.20.21 = zext i8 %15436 to i32
  %xor72.20.21 = xor i32 %conv71.20.21, %conv68.20.21
  %conv73.20.21 = trunc i32 %xor72.20.21 to i8
  store i8 %conv73.20.21, i8* %arrayidx70.21, align 1
  %scevgep20.22.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 22
  %15437 = load i8, i8* %scevgep20.22.21, align 1
  %conv68.22.21 = zext i8 %15437 to i32
  %15438 = load i8, i8* %arrayidx70.21, align 1
  %conv71.22.21 = zext i8 %15438 to i32
  %xor72.22.21 = xor i32 %conv71.22.21, %conv68.22.21
  %conv73.22.21 = trunc i32 %xor72.22.21 to i8
  store i8 %conv73.22.21, i8* %arrayidx70.21, align 1
  %scevgep20.23.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 23
  %15439 = load i8, i8* %scevgep20.23.21, align 1
  %conv68.23.21 = zext i8 %15439 to i32
  %15440 = load i8, i8* %arrayidx70.21, align 1
  %conv71.23.21 = zext i8 %15440 to i32
  %xor72.23.21 = xor i32 %conv71.23.21, %conv68.23.21
  %conv73.23.21 = trunc i32 %xor72.23.21 to i8
  store i8 %conv73.23.21, i8* %arrayidx70.21, align 1
  %scevgep20.24.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 24
  %15441 = load i8, i8* %scevgep20.24.21, align 1
  %conv68.24.21 = zext i8 %15441 to i32
  %15442 = load i8, i8* %arrayidx70.21, align 1
  %conv71.24.21 = zext i8 %15442 to i32
  %xor72.24.21 = xor i32 %conv71.24.21, %conv68.24.21
  %conv73.24.21 = trunc i32 %xor72.24.21 to i8
  store i8 %conv73.24.21, i8* %arrayidx70.21, align 1
  %scevgep20.25.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 25
  %15443 = load i8, i8* %scevgep20.25.21, align 1
  %conv68.25.21 = zext i8 %15443 to i32
  %15444 = load i8, i8* %arrayidx70.21, align 1
  %conv71.25.21 = zext i8 %15444 to i32
  %xor72.25.21 = xor i32 %conv71.25.21, %conv68.25.21
  %conv73.25.21 = trunc i32 %xor72.25.21 to i8
  store i8 %conv73.25.21, i8* %arrayidx70.21, align 1
  %scevgep20.26.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 26
  %15445 = load i8, i8* %scevgep20.26.21, align 1
  %conv68.26.21 = zext i8 %15445 to i32
  %15446 = load i8, i8* %arrayidx70.21, align 1
  %conv71.26.21 = zext i8 %15446 to i32
  %xor72.26.21 = xor i32 %conv71.26.21, %conv68.26.21
  %conv73.26.21 = trunc i32 %xor72.26.21 to i8
  store i8 %conv73.26.21, i8* %arrayidx70.21, align 1
  %scevgep20.27.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 27
  %15447 = load i8, i8* %scevgep20.27.21, align 1
  %conv68.27.21 = zext i8 %15447 to i32
  %15448 = load i8, i8* %arrayidx70.21, align 1
  %conv71.27.21 = zext i8 %15448 to i32
  %xor72.27.21 = xor i32 %conv71.27.21, %conv68.27.21
  %conv73.27.21 = trunc i32 %xor72.27.21 to i8
  store i8 %conv73.27.21, i8* %arrayidx70.21, align 1
  %scevgep20.28.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 28
  %15449 = load i8, i8* %scevgep20.28.21, align 1
  %conv68.28.21 = zext i8 %15449 to i32
  %15450 = load i8, i8* %arrayidx70.21, align 1
  %conv71.28.21 = zext i8 %15450 to i32
  %xor72.28.21 = xor i32 %conv71.28.21, %conv68.28.21
  %conv73.28.21 = trunc i32 %xor72.28.21 to i8
  store i8 %conv73.28.21, i8* %arrayidx70.21, align 1
  %scevgep20.29.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 29
  %15451 = load i8, i8* %scevgep20.29.21, align 1
  %conv68.29.21 = zext i8 %15451 to i32
  %15452 = load i8, i8* %arrayidx70.21, align 1
  %conv71.29.21 = zext i8 %15452 to i32
  %xor72.29.21 = xor i32 %conv71.29.21, %conv68.29.21
  %conv73.29.21 = trunc i32 %xor72.29.21 to i8
  store i8 %conv73.29.21, i8* %arrayidx70.21, align 1
  %scevgep20.30.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 30
  %15453 = load i8, i8* %scevgep20.30.21, align 1
  %conv68.30.21 = zext i8 %15453 to i32
  %15454 = load i8, i8* %arrayidx70.21, align 1
  %conv71.30.21 = zext i8 %15454 to i32
  %xor72.30.21 = xor i32 %conv71.30.21, %conv68.30.21
  %conv73.30.21 = trunc i32 %xor72.30.21 to i8
  store i8 %conv73.30.21, i8* %arrayidx70.21, align 1
  %scevgep20.31.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 31
  %15455 = load i8, i8* %scevgep20.31.21, align 1
  %conv68.31.21 = zext i8 %15455 to i32
  %15456 = load i8, i8* %arrayidx70.21, align 1
  %conv71.31.21 = zext i8 %15456 to i32
  %xor72.31.21 = xor i32 %conv71.31.21, %conv68.31.21
  %conv73.31.21 = trunc i32 %xor72.31.21 to i8
  store i8 %conv73.31.21, i8* %arrayidx70.21, align 1
  %scevgep20.32.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 32
  %15457 = load i8, i8* %scevgep20.32.21, align 1
  %conv68.32.21 = zext i8 %15457 to i32
  %15458 = load i8, i8* %arrayidx70.21, align 1
  %conv71.32.21 = zext i8 %15458 to i32
  %xor72.32.21 = xor i32 %conv71.32.21, %conv68.32.21
  %conv73.32.21 = trunc i32 %xor72.32.21 to i8
  store i8 %conv73.32.21, i8* %arrayidx70.21, align 1
  %scevgep20.33.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 33
  %15459 = load i8, i8* %scevgep20.33.21, align 1
  %conv68.33.21 = zext i8 %15459 to i32
  %15460 = load i8, i8* %arrayidx70.21, align 1
  %conv71.33.21 = zext i8 %15460 to i32
  %xor72.33.21 = xor i32 %conv71.33.21, %conv68.33.21
  %conv73.33.21 = trunc i32 %xor72.33.21 to i8
  store i8 %conv73.33.21, i8* %arrayidx70.21, align 1
  %scevgep20.34.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 34
  %15461 = load i8, i8* %scevgep20.34.21, align 1
  %conv68.34.21 = zext i8 %15461 to i32
  %15462 = load i8, i8* %arrayidx70.21, align 1
  %conv71.34.21 = zext i8 %15462 to i32
  %xor72.34.21 = xor i32 %conv71.34.21, %conv68.34.21
  %conv73.34.21 = trunc i32 %xor72.34.21 to i8
  store i8 %conv73.34.21, i8* %arrayidx70.21, align 1
  %scevgep20.35.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 35
  %15463 = load i8, i8* %scevgep20.35.21, align 1
  %conv68.35.21 = zext i8 %15463 to i32
  %15464 = load i8, i8* %arrayidx70.21, align 1
  %conv71.35.21 = zext i8 %15464 to i32
  %xor72.35.21 = xor i32 %conv71.35.21, %conv68.35.21
  %conv73.35.21 = trunc i32 %xor72.35.21 to i8
  store i8 %conv73.35.21, i8* %arrayidx70.21, align 1
  %scevgep20.36.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 36
  %15465 = load i8, i8* %scevgep20.36.21, align 1
  %conv68.36.21 = zext i8 %15465 to i32
  %15466 = load i8, i8* %arrayidx70.21, align 1
  %conv71.36.21 = zext i8 %15466 to i32
  %xor72.36.21 = xor i32 %conv71.36.21, %conv68.36.21
  %conv73.36.21 = trunc i32 %xor72.36.21 to i8
  store i8 %conv73.36.21, i8* %arrayidx70.21, align 1
  %scevgep20.37.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 37
  %15467 = load i8, i8* %scevgep20.37.21, align 1
  %conv68.37.21 = zext i8 %15467 to i32
  %15468 = load i8, i8* %arrayidx70.21, align 1
  %conv71.37.21 = zext i8 %15468 to i32
  %xor72.37.21 = xor i32 %conv71.37.21, %conv68.37.21
  %conv73.37.21 = trunc i32 %xor72.37.21 to i8
  store i8 %conv73.37.21, i8* %arrayidx70.21, align 1
  %scevgep20.38.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 38
  %15469 = load i8, i8* %scevgep20.38.21, align 1
  %conv68.38.21 = zext i8 %15469 to i32
  %15470 = load i8, i8* %arrayidx70.21, align 1
  %conv71.38.21 = zext i8 %15470 to i32
  %xor72.38.21 = xor i32 %conv71.38.21, %conv68.38.21
  %conv73.38.21 = trunc i32 %xor72.38.21 to i8
  store i8 %conv73.38.21, i8* %arrayidx70.21, align 1
  %scevgep20.39.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 39
  %15471 = load i8, i8* %scevgep20.39.21, align 1
  %conv68.39.21 = zext i8 %15471 to i32
  %15472 = load i8, i8* %arrayidx70.21, align 1
  %conv71.39.21 = zext i8 %15472 to i32
  %xor72.39.21 = xor i32 %conv71.39.21, %conv68.39.21
  %conv73.39.21 = trunc i32 %xor72.39.21 to i8
  store i8 %conv73.39.21, i8* %arrayidx70.21, align 1
  %scevgep20.40.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 40
  %15473 = load i8, i8* %scevgep20.40.21, align 1
  %conv68.40.21 = zext i8 %15473 to i32
  %15474 = load i8, i8* %arrayidx70.21, align 1
  %conv71.40.21 = zext i8 %15474 to i32
  %xor72.40.21 = xor i32 %conv71.40.21, %conv68.40.21
  %conv73.40.21 = trunc i32 %xor72.40.21 to i8
  store i8 %conv73.40.21, i8* %arrayidx70.21, align 1
  %scevgep20.41.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 41
  %15475 = load i8, i8* %scevgep20.41.21, align 1
  %conv68.41.21 = zext i8 %15475 to i32
  %15476 = load i8, i8* %arrayidx70.21, align 1
  %conv71.41.21 = zext i8 %15476 to i32
  %xor72.41.21 = xor i32 %conv71.41.21, %conv68.41.21
  %conv73.41.21 = trunc i32 %xor72.41.21 to i8
  store i8 %conv73.41.21, i8* %arrayidx70.21, align 1
  %scevgep20.42.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 42
  %15477 = load i8, i8* %scevgep20.42.21, align 1
  %conv68.42.21 = zext i8 %15477 to i32
  %15478 = load i8, i8* %arrayidx70.21, align 1
  %conv71.42.21 = zext i8 %15478 to i32
  %xor72.42.21 = xor i32 %conv71.42.21, %conv68.42.21
  %conv73.42.21 = trunc i32 %xor72.42.21 to i8
  store i8 %conv73.42.21, i8* %arrayidx70.21, align 1
  %scevgep20.43.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 43
  %15479 = load i8, i8* %scevgep20.43.21, align 1
  %conv68.43.21 = zext i8 %15479 to i32
  %15480 = load i8, i8* %arrayidx70.21, align 1
  %conv71.43.21 = zext i8 %15480 to i32
  %xor72.43.21 = xor i32 %conv71.43.21, %conv68.43.21
  %conv73.43.21 = trunc i32 %xor72.43.21 to i8
  store i8 %conv73.43.21, i8* %arrayidx70.21, align 1
  %scevgep20.44.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 44
  %15481 = load i8, i8* %scevgep20.44.21, align 1
  %conv68.44.21 = zext i8 %15481 to i32
  %15482 = load i8, i8* %arrayidx70.21, align 1
  %conv71.44.21 = zext i8 %15482 to i32
  %xor72.44.21 = xor i32 %conv71.44.21, %conv68.44.21
  %conv73.44.21 = trunc i32 %xor72.44.21 to i8
  store i8 %conv73.44.21, i8* %arrayidx70.21, align 1
  %scevgep20.45.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 45
  %15483 = load i8, i8* %scevgep20.45.21, align 1
  %conv68.45.21 = zext i8 %15483 to i32
  %15484 = load i8, i8* %arrayidx70.21, align 1
  %conv71.45.21 = zext i8 %15484 to i32
  %xor72.45.21 = xor i32 %conv71.45.21, %conv68.45.21
  %conv73.45.21 = trunc i32 %xor72.45.21 to i8
  store i8 %conv73.45.21, i8* %arrayidx70.21, align 1
  %scevgep20.46.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 46
  %15485 = load i8, i8* %scevgep20.46.21, align 1
  %conv68.46.21 = zext i8 %15485 to i32
  %15486 = load i8, i8* %arrayidx70.21, align 1
  %conv71.46.21 = zext i8 %15486 to i32
  %xor72.46.21 = xor i32 %conv71.46.21, %conv68.46.21
  %conv73.46.21 = trunc i32 %xor72.46.21 to i8
  store i8 %conv73.46.21, i8* %arrayidx70.21, align 1
  %scevgep20.47.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 47
  %15487 = load i8, i8* %scevgep20.47.21, align 1
  %conv68.47.21 = zext i8 %15487 to i32
  %15488 = load i8, i8* %arrayidx70.21, align 1
  %conv71.47.21 = zext i8 %15488 to i32
  %xor72.47.21 = xor i32 %conv71.47.21, %conv68.47.21
  %conv73.47.21 = trunc i32 %xor72.47.21 to i8
  store i8 %conv73.47.21, i8* %arrayidx70.21, align 1
  %scevgep20.48.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 48
  %15489 = load i8, i8* %scevgep20.48.21, align 1
  %conv68.48.21 = zext i8 %15489 to i32
  %15490 = load i8, i8* %arrayidx70.21, align 1
  %conv71.48.21 = zext i8 %15490 to i32
  %xor72.48.21 = xor i32 %conv71.48.21, %conv68.48.21
  %conv73.48.21 = trunc i32 %xor72.48.21 to i8
  store i8 %conv73.48.21, i8* %arrayidx70.21, align 1
  %scevgep20.49.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 49
  %15491 = load i8, i8* %scevgep20.49.21, align 1
  %conv68.49.21 = zext i8 %15491 to i32
  %15492 = load i8, i8* %arrayidx70.21, align 1
  %conv71.49.21 = zext i8 %15492 to i32
  %xor72.49.21 = xor i32 %conv71.49.21, %conv68.49.21
  %conv73.49.21 = trunc i32 %xor72.49.21 to i8
  store i8 %conv73.49.21, i8* %arrayidx70.21, align 1
  %scevgep20.50.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 50
  %15493 = load i8, i8* %scevgep20.50.21, align 1
  %conv68.50.21 = zext i8 %15493 to i32
  %15494 = load i8, i8* %arrayidx70.21, align 1
  %conv71.50.21 = zext i8 %15494 to i32
  %xor72.50.21 = xor i32 %conv71.50.21, %conv68.50.21
  %conv73.50.21 = trunc i32 %xor72.50.21 to i8
  store i8 %conv73.50.21, i8* %arrayidx70.21, align 1
  %scevgep20.51.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 51
  %15495 = load i8, i8* %scevgep20.51.21, align 1
  %conv68.51.21 = zext i8 %15495 to i32
  %15496 = load i8, i8* %arrayidx70.21, align 1
  %conv71.51.21 = zext i8 %15496 to i32
  %xor72.51.21 = xor i32 %conv71.51.21, %conv68.51.21
  %conv73.51.21 = trunc i32 %xor72.51.21 to i8
  store i8 %conv73.51.21, i8* %arrayidx70.21, align 1
  %scevgep20.52.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 52
  %15497 = load i8, i8* %scevgep20.52.21, align 1
  %conv68.52.21 = zext i8 %15497 to i32
  %15498 = load i8, i8* %arrayidx70.21, align 1
  %conv71.52.21 = zext i8 %15498 to i32
  %xor72.52.21 = xor i32 %conv71.52.21, %conv68.52.21
  %conv73.52.21 = trunc i32 %xor72.52.21 to i8
  store i8 %conv73.52.21, i8* %arrayidx70.21, align 1
  %scevgep20.53.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 53
  %15499 = load i8, i8* %scevgep20.53.21, align 1
  %conv68.53.21 = zext i8 %15499 to i32
  %15500 = load i8, i8* %arrayidx70.21, align 1
  %conv71.53.21 = zext i8 %15500 to i32
  %xor72.53.21 = xor i32 %conv71.53.21, %conv68.53.21
  %conv73.53.21 = trunc i32 %xor72.53.21 to i8
  store i8 %conv73.53.21, i8* %arrayidx70.21, align 1
  %scevgep20.54.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 54
  %15501 = load i8, i8* %scevgep20.54.21, align 1
  %conv68.54.21 = zext i8 %15501 to i32
  %15502 = load i8, i8* %arrayidx70.21, align 1
  %conv71.54.21 = zext i8 %15502 to i32
  %xor72.54.21 = xor i32 %conv71.54.21, %conv68.54.21
  %conv73.54.21 = trunc i32 %xor72.54.21 to i8
  store i8 %conv73.54.21, i8* %arrayidx70.21, align 1
  %scevgep20.55.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 55
  %15503 = load i8, i8* %scevgep20.55.21, align 1
  %conv68.55.21 = zext i8 %15503 to i32
  %15504 = load i8, i8* %arrayidx70.21, align 1
  %conv71.55.21 = zext i8 %15504 to i32
  %xor72.55.21 = xor i32 %conv71.55.21, %conv68.55.21
  %conv73.55.21 = trunc i32 %xor72.55.21 to i8
  store i8 %conv73.55.21, i8* %arrayidx70.21, align 1
  %scevgep20.56.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 56
  %15505 = load i8, i8* %scevgep20.56.21, align 1
  %conv68.56.21 = zext i8 %15505 to i32
  %15506 = load i8, i8* %arrayidx70.21, align 1
  %conv71.56.21 = zext i8 %15506 to i32
  %xor72.56.21 = xor i32 %conv71.56.21, %conv68.56.21
  %conv73.56.21 = trunc i32 %xor72.56.21 to i8
  store i8 %conv73.56.21, i8* %arrayidx70.21, align 1
  %scevgep20.57.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 57
  %15507 = load i8, i8* %scevgep20.57.21, align 1
  %conv68.57.21 = zext i8 %15507 to i32
  %15508 = load i8, i8* %arrayidx70.21, align 1
  %conv71.57.21 = zext i8 %15508 to i32
  %xor72.57.21 = xor i32 %conv71.57.21, %conv68.57.21
  %conv73.57.21 = trunc i32 %xor72.57.21 to i8
  store i8 %conv73.57.21, i8* %arrayidx70.21, align 1
  %scevgep20.58.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 58
  %15509 = load i8, i8* %scevgep20.58.21, align 1
  %conv68.58.21 = zext i8 %15509 to i32
  %15510 = load i8, i8* %arrayidx70.21, align 1
  %conv71.58.21 = zext i8 %15510 to i32
  %xor72.58.21 = xor i32 %conv71.58.21, %conv68.58.21
  %conv73.58.21 = trunc i32 %xor72.58.21 to i8
  store i8 %conv73.58.21, i8* %arrayidx70.21, align 1
  %scevgep20.59.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 59
  %15511 = load i8, i8* %scevgep20.59.21, align 1
  %conv68.59.21 = zext i8 %15511 to i32
  %15512 = load i8, i8* %arrayidx70.21, align 1
  %conv71.59.21 = zext i8 %15512 to i32
  %xor72.59.21 = xor i32 %conv71.59.21, %conv68.59.21
  %conv73.59.21 = trunc i32 %xor72.59.21 to i8
  store i8 %conv73.59.21, i8* %arrayidx70.21, align 1
  %scevgep20.60.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 0, i64 60
  %15513 = load i8, i8* %scevgep20.60.21, align 1
  %conv68.60.21 = zext i8 %15513 to i32
  %15514 = load i8, i8* %arrayidx70.21, align 1
  %conv71.60.21 = zext i8 %15514 to i32
  %xor72.60.21 = xor i32 %conv71.60.21, %conv68.60.21
  %conv73.60.21 = trunc i32 %xor72.60.21 to i8
  store i8 %conv73.60.21, i8* %arrayidx70.21, align 1
  %scevgep19.21 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15392, i64 0, i64 1, i64 0
  %15515 = bitcast i8* %scevgep19.21 to [61 x [61 x i8]]*
  %arrayidx51.22 = getelementptr inbounds i8, i8* %a, i64 22
  %15516 = load i8, i8* %arrayidx51.22, align 1
  %arrayidx53.22 = getelementptr inbounds i8, i8* %b, i64 22
  %15517 = load i8, i8* %arrayidx53.22, align 1
  %call54.22 = call zeroext i8 @mult(i8 zeroext %15516, i8 zeroext %15517)
  %arrayidx56.22 = getelementptr inbounds i8, i8* %c, i64 22
  store i8 %call54.22, i8* %arrayidx56.22, align 1
  %arrayidx70.22 = getelementptr inbounds i8, i8* %c, i64 22
  %scevgep20.22264 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 0
  %15518 = load i8, i8* %scevgep20.22264, align 1
  %conv68.22265 = zext i8 %15518 to i32
  %15519 = load i8, i8* %arrayidx70.22, align 1
  %conv71.22266 = zext i8 %15519 to i32
  %xor72.22267 = xor i32 %conv71.22266, %conv68.22265
  %conv73.22268 = trunc i32 %xor72.22267 to i8
  store i8 %conv73.22268, i8* %arrayidx70.22, align 1
  %scevgep20.1.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 1
  %15520 = load i8, i8* %scevgep20.1.22, align 1
  %conv68.1.22 = zext i8 %15520 to i32
  %15521 = load i8, i8* %arrayidx70.22, align 1
  %conv71.1.22 = zext i8 %15521 to i32
  %xor72.1.22 = xor i32 %conv71.1.22, %conv68.1.22
  %conv73.1.22 = trunc i32 %xor72.1.22 to i8
  store i8 %conv73.1.22, i8* %arrayidx70.22, align 1
  %scevgep20.2.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 2
  %15522 = load i8, i8* %scevgep20.2.22, align 1
  %conv68.2.22 = zext i8 %15522 to i32
  %15523 = load i8, i8* %arrayidx70.22, align 1
  %conv71.2.22 = zext i8 %15523 to i32
  %xor72.2.22 = xor i32 %conv71.2.22, %conv68.2.22
  %conv73.2.22 = trunc i32 %xor72.2.22 to i8
  store i8 %conv73.2.22, i8* %arrayidx70.22, align 1
  %scevgep20.3.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 3
  %15524 = load i8, i8* %scevgep20.3.22, align 1
  %conv68.3.22 = zext i8 %15524 to i32
  %15525 = load i8, i8* %arrayidx70.22, align 1
  %conv71.3.22 = zext i8 %15525 to i32
  %xor72.3.22 = xor i32 %conv71.3.22, %conv68.3.22
  %conv73.3.22 = trunc i32 %xor72.3.22 to i8
  store i8 %conv73.3.22, i8* %arrayidx70.22, align 1
  %scevgep20.4.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 4
  %15526 = load i8, i8* %scevgep20.4.22, align 1
  %conv68.4.22 = zext i8 %15526 to i32
  %15527 = load i8, i8* %arrayidx70.22, align 1
  %conv71.4.22 = zext i8 %15527 to i32
  %xor72.4.22 = xor i32 %conv71.4.22, %conv68.4.22
  %conv73.4.22 = trunc i32 %xor72.4.22 to i8
  store i8 %conv73.4.22, i8* %arrayidx70.22, align 1
  %scevgep20.5.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 5
  %15528 = load i8, i8* %scevgep20.5.22, align 1
  %conv68.5.22 = zext i8 %15528 to i32
  %15529 = load i8, i8* %arrayidx70.22, align 1
  %conv71.5.22 = zext i8 %15529 to i32
  %xor72.5.22 = xor i32 %conv71.5.22, %conv68.5.22
  %conv73.5.22 = trunc i32 %xor72.5.22 to i8
  store i8 %conv73.5.22, i8* %arrayidx70.22, align 1
  %scevgep20.6.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 6
  %15530 = load i8, i8* %scevgep20.6.22, align 1
  %conv68.6.22 = zext i8 %15530 to i32
  %15531 = load i8, i8* %arrayidx70.22, align 1
  %conv71.6.22 = zext i8 %15531 to i32
  %xor72.6.22 = xor i32 %conv71.6.22, %conv68.6.22
  %conv73.6.22 = trunc i32 %xor72.6.22 to i8
  store i8 %conv73.6.22, i8* %arrayidx70.22, align 1
  %scevgep20.7.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 7
  %15532 = load i8, i8* %scevgep20.7.22, align 1
  %conv68.7.22 = zext i8 %15532 to i32
  %15533 = load i8, i8* %arrayidx70.22, align 1
  %conv71.7.22 = zext i8 %15533 to i32
  %xor72.7.22 = xor i32 %conv71.7.22, %conv68.7.22
  %conv73.7.22 = trunc i32 %xor72.7.22 to i8
  store i8 %conv73.7.22, i8* %arrayidx70.22, align 1
  %scevgep20.8.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 8
  %15534 = load i8, i8* %scevgep20.8.22, align 1
  %conv68.8.22 = zext i8 %15534 to i32
  %15535 = load i8, i8* %arrayidx70.22, align 1
  %conv71.8.22 = zext i8 %15535 to i32
  %xor72.8.22 = xor i32 %conv71.8.22, %conv68.8.22
  %conv73.8.22 = trunc i32 %xor72.8.22 to i8
  store i8 %conv73.8.22, i8* %arrayidx70.22, align 1
  %scevgep20.9.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 9
  %15536 = load i8, i8* %scevgep20.9.22, align 1
  %conv68.9.22 = zext i8 %15536 to i32
  %15537 = load i8, i8* %arrayidx70.22, align 1
  %conv71.9.22 = zext i8 %15537 to i32
  %xor72.9.22 = xor i32 %conv71.9.22, %conv68.9.22
  %conv73.9.22 = trunc i32 %xor72.9.22 to i8
  store i8 %conv73.9.22, i8* %arrayidx70.22, align 1
  %scevgep20.10.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 10
  %15538 = load i8, i8* %scevgep20.10.22, align 1
  %conv68.10.22 = zext i8 %15538 to i32
  %15539 = load i8, i8* %arrayidx70.22, align 1
  %conv71.10.22 = zext i8 %15539 to i32
  %xor72.10.22 = xor i32 %conv71.10.22, %conv68.10.22
  %conv73.10.22 = trunc i32 %xor72.10.22 to i8
  store i8 %conv73.10.22, i8* %arrayidx70.22, align 1
  %scevgep20.11.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 11
  %15540 = load i8, i8* %scevgep20.11.22, align 1
  %conv68.11.22 = zext i8 %15540 to i32
  %15541 = load i8, i8* %arrayidx70.22, align 1
  %conv71.11.22 = zext i8 %15541 to i32
  %xor72.11.22 = xor i32 %conv71.11.22, %conv68.11.22
  %conv73.11.22 = trunc i32 %xor72.11.22 to i8
  store i8 %conv73.11.22, i8* %arrayidx70.22, align 1
  %scevgep20.12.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 12
  %15542 = load i8, i8* %scevgep20.12.22, align 1
  %conv68.12.22 = zext i8 %15542 to i32
  %15543 = load i8, i8* %arrayidx70.22, align 1
  %conv71.12.22 = zext i8 %15543 to i32
  %xor72.12.22 = xor i32 %conv71.12.22, %conv68.12.22
  %conv73.12.22 = trunc i32 %xor72.12.22 to i8
  store i8 %conv73.12.22, i8* %arrayidx70.22, align 1
  %scevgep20.13.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 13
  %15544 = load i8, i8* %scevgep20.13.22, align 1
  %conv68.13.22 = zext i8 %15544 to i32
  %15545 = load i8, i8* %arrayidx70.22, align 1
  %conv71.13.22 = zext i8 %15545 to i32
  %xor72.13.22 = xor i32 %conv71.13.22, %conv68.13.22
  %conv73.13.22 = trunc i32 %xor72.13.22 to i8
  store i8 %conv73.13.22, i8* %arrayidx70.22, align 1
  %scevgep20.14.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 14
  %15546 = load i8, i8* %scevgep20.14.22, align 1
  %conv68.14.22 = zext i8 %15546 to i32
  %15547 = load i8, i8* %arrayidx70.22, align 1
  %conv71.14.22 = zext i8 %15547 to i32
  %xor72.14.22 = xor i32 %conv71.14.22, %conv68.14.22
  %conv73.14.22 = trunc i32 %xor72.14.22 to i8
  store i8 %conv73.14.22, i8* %arrayidx70.22, align 1
  %scevgep20.15.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 15
  %15548 = load i8, i8* %scevgep20.15.22, align 1
  %conv68.15.22 = zext i8 %15548 to i32
  %15549 = load i8, i8* %arrayidx70.22, align 1
  %conv71.15.22 = zext i8 %15549 to i32
  %xor72.15.22 = xor i32 %conv71.15.22, %conv68.15.22
  %conv73.15.22 = trunc i32 %xor72.15.22 to i8
  store i8 %conv73.15.22, i8* %arrayidx70.22, align 1
  %scevgep20.16.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 16
  %15550 = load i8, i8* %scevgep20.16.22, align 1
  %conv68.16.22 = zext i8 %15550 to i32
  %15551 = load i8, i8* %arrayidx70.22, align 1
  %conv71.16.22 = zext i8 %15551 to i32
  %xor72.16.22 = xor i32 %conv71.16.22, %conv68.16.22
  %conv73.16.22 = trunc i32 %xor72.16.22 to i8
  store i8 %conv73.16.22, i8* %arrayidx70.22, align 1
  %scevgep20.17.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 17
  %15552 = load i8, i8* %scevgep20.17.22, align 1
  %conv68.17.22 = zext i8 %15552 to i32
  %15553 = load i8, i8* %arrayidx70.22, align 1
  %conv71.17.22 = zext i8 %15553 to i32
  %xor72.17.22 = xor i32 %conv71.17.22, %conv68.17.22
  %conv73.17.22 = trunc i32 %xor72.17.22 to i8
  store i8 %conv73.17.22, i8* %arrayidx70.22, align 1
  %scevgep20.18.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 18
  %15554 = load i8, i8* %scevgep20.18.22, align 1
  %conv68.18.22 = zext i8 %15554 to i32
  %15555 = load i8, i8* %arrayidx70.22, align 1
  %conv71.18.22 = zext i8 %15555 to i32
  %xor72.18.22 = xor i32 %conv71.18.22, %conv68.18.22
  %conv73.18.22 = trunc i32 %xor72.18.22 to i8
  store i8 %conv73.18.22, i8* %arrayidx70.22, align 1
  %scevgep20.19.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 19
  %15556 = load i8, i8* %scevgep20.19.22, align 1
  %conv68.19.22 = zext i8 %15556 to i32
  %15557 = load i8, i8* %arrayidx70.22, align 1
  %conv71.19.22 = zext i8 %15557 to i32
  %xor72.19.22 = xor i32 %conv71.19.22, %conv68.19.22
  %conv73.19.22 = trunc i32 %xor72.19.22 to i8
  store i8 %conv73.19.22, i8* %arrayidx70.22, align 1
  %scevgep20.20.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 20
  %15558 = load i8, i8* %scevgep20.20.22, align 1
  %conv68.20.22 = zext i8 %15558 to i32
  %15559 = load i8, i8* %arrayidx70.22, align 1
  %conv71.20.22 = zext i8 %15559 to i32
  %xor72.20.22 = xor i32 %conv71.20.22, %conv68.20.22
  %conv73.20.22 = trunc i32 %xor72.20.22 to i8
  store i8 %conv73.20.22, i8* %arrayidx70.22, align 1
  %scevgep20.21.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 21
  %15560 = load i8, i8* %scevgep20.21.22, align 1
  %conv68.21.22 = zext i8 %15560 to i32
  %15561 = load i8, i8* %arrayidx70.22, align 1
  %conv71.21.22 = zext i8 %15561 to i32
  %xor72.21.22 = xor i32 %conv71.21.22, %conv68.21.22
  %conv73.21.22 = trunc i32 %xor72.21.22 to i8
  store i8 %conv73.21.22, i8* %arrayidx70.22, align 1
  %scevgep20.23.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 23
  %15562 = load i8, i8* %scevgep20.23.22, align 1
  %conv68.23.22 = zext i8 %15562 to i32
  %15563 = load i8, i8* %arrayidx70.22, align 1
  %conv71.23.22 = zext i8 %15563 to i32
  %xor72.23.22 = xor i32 %conv71.23.22, %conv68.23.22
  %conv73.23.22 = trunc i32 %xor72.23.22 to i8
  store i8 %conv73.23.22, i8* %arrayidx70.22, align 1
  %scevgep20.24.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 24
  %15564 = load i8, i8* %scevgep20.24.22, align 1
  %conv68.24.22 = zext i8 %15564 to i32
  %15565 = load i8, i8* %arrayidx70.22, align 1
  %conv71.24.22 = zext i8 %15565 to i32
  %xor72.24.22 = xor i32 %conv71.24.22, %conv68.24.22
  %conv73.24.22 = trunc i32 %xor72.24.22 to i8
  store i8 %conv73.24.22, i8* %arrayidx70.22, align 1
  %scevgep20.25.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 25
  %15566 = load i8, i8* %scevgep20.25.22, align 1
  %conv68.25.22 = zext i8 %15566 to i32
  %15567 = load i8, i8* %arrayidx70.22, align 1
  %conv71.25.22 = zext i8 %15567 to i32
  %xor72.25.22 = xor i32 %conv71.25.22, %conv68.25.22
  %conv73.25.22 = trunc i32 %xor72.25.22 to i8
  store i8 %conv73.25.22, i8* %arrayidx70.22, align 1
  %scevgep20.26.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 26
  %15568 = load i8, i8* %scevgep20.26.22, align 1
  %conv68.26.22 = zext i8 %15568 to i32
  %15569 = load i8, i8* %arrayidx70.22, align 1
  %conv71.26.22 = zext i8 %15569 to i32
  %xor72.26.22 = xor i32 %conv71.26.22, %conv68.26.22
  %conv73.26.22 = trunc i32 %xor72.26.22 to i8
  store i8 %conv73.26.22, i8* %arrayidx70.22, align 1
  %scevgep20.27.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 27
  %15570 = load i8, i8* %scevgep20.27.22, align 1
  %conv68.27.22 = zext i8 %15570 to i32
  %15571 = load i8, i8* %arrayidx70.22, align 1
  %conv71.27.22 = zext i8 %15571 to i32
  %xor72.27.22 = xor i32 %conv71.27.22, %conv68.27.22
  %conv73.27.22 = trunc i32 %xor72.27.22 to i8
  store i8 %conv73.27.22, i8* %arrayidx70.22, align 1
  %scevgep20.28.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 28
  %15572 = load i8, i8* %scevgep20.28.22, align 1
  %conv68.28.22 = zext i8 %15572 to i32
  %15573 = load i8, i8* %arrayidx70.22, align 1
  %conv71.28.22 = zext i8 %15573 to i32
  %xor72.28.22 = xor i32 %conv71.28.22, %conv68.28.22
  %conv73.28.22 = trunc i32 %xor72.28.22 to i8
  store i8 %conv73.28.22, i8* %arrayidx70.22, align 1
  %scevgep20.29.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 29
  %15574 = load i8, i8* %scevgep20.29.22, align 1
  %conv68.29.22 = zext i8 %15574 to i32
  %15575 = load i8, i8* %arrayidx70.22, align 1
  %conv71.29.22 = zext i8 %15575 to i32
  %xor72.29.22 = xor i32 %conv71.29.22, %conv68.29.22
  %conv73.29.22 = trunc i32 %xor72.29.22 to i8
  store i8 %conv73.29.22, i8* %arrayidx70.22, align 1
  %scevgep20.30.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 30
  %15576 = load i8, i8* %scevgep20.30.22, align 1
  %conv68.30.22 = zext i8 %15576 to i32
  %15577 = load i8, i8* %arrayidx70.22, align 1
  %conv71.30.22 = zext i8 %15577 to i32
  %xor72.30.22 = xor i32 %conv71.30.22, %conv68.30.22
  %conv73.30.22 = trunc i32 %xor72.30.22 to i8
  store i8 %conv73.30.22, i8* %arrayidx70.22, align 1
  %scevgep20.31.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 31
  %15578 = load i8, i8* %scevgep20.31.22, align 1
  %conv68.31.22 = zext i8 %15578 to i32
  %15579 = load i8, i8* %arrayidx70.22, align 1
  %conv71.31.22 = zext i8 %15579 to i32
  %xor72.31.22 = xor i32 %conv71.31.22, %conv68.31.22
  %conv73.31.22 = trunc i32 %xor72.31.22 to i8
  store i8 %conv73.31.22, i8* %arrayidx70.22, align 1
  %scevgep20.32.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 32
  %15580 = load i8, i8* %scevgep20.32.22, align 1
  %conv68.32.22 = zext i8 %15580 to i32
  %15581 = load i8, i8* %arrayidx70.22, align 1
  %conv71.32.22 = zext i8 %15581 to i32
  %xor72.32.22 = xor i32 %conv71.32.22, %conv68.32.22
  %conv73.32.22 = trunc i32 %xor72.32.22 to i8
  store i8 %conv73.32.22, i8* %arrayidx70.22, align 1
  %scevgep20.33.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 33
  %15582 = load i8, i8* %scevgep20.33.22, align 1
  %conv68.33.22 = zext i8 %15582 to i32
  %15583 = load i8, i8* %arrayidx70.22, align 1
  %conv71.33.22 = zext i8 %15583 to i32
  %xor72.33.22 = xor i32 %conv71.33.22, %conv68.33.22
  %conv73.33.22 = trunc i32 %xor72.33.22 to i8
  store i8 %conv73.33.22, i8* %arrayidx70.22, align 1
  %scevgep20.34.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 34
  %15584 = load i8, i8* %scevgep20.34.22, align 1
  %conv68.34.22 = zext i8 %15584 to i32
  %15585 = load i8, i8* %arrayidx70.22, align 1
  %conv71.34.22 = zext i8 %15585 to i32
  %xor72.34.22 = xor i32 %conv71.34.22, %conv68.34.22
  %conv73.34.22 = trunc i32 %xor72.34.22 to i8
  store i8 %conv73.34.22, i8* %arrayidx70.22, align 1
  %scevgep20.35.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 35
  %15586 = load i8, i8* %scevgep20.35.22, align 1
  %conv68.35.22 = zext i8 %15586 to i32
  %15587 = load i8, i8* %arrayidx70.22, align 1
  %conv71.35.22 = zext i8 %15587 to i32
  %xor72.35.22 = xor i32 %conv71.35.22, %conv68.35.22
  %conv73.35.22 = trunc i32 %xor72.35.22 to i8
  store i8 %conv73.35.22, i8* %arrayidx70.22, align 1
  %scevgep20.36.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 36
  %15588 = load i8, i8* %scevgep20.36.22, align 1
  %conv68.36.22 = zext i8 %15588 to i32
  %15589 = load i8, i8* %arrayidx70.22, align 1
  %conv71.36.22 = zext i8 %15589 to i32
  %xor72.36.22 = xor i32 %conv71.36.22, %conv68.36.22
  %conv73.36.22 = trunc i32 %xor72.36.22 to i8
  store i8 %conv73.36.22, i8* %arrayidx70.22, align 1
  %scevgep20.37.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 37
  %15590 = load i8, i8* %scevgep20.37.22, align 1
  %conv68.37.22 = zext i8 %15590 to i32
  %15591 = load i8, i8* %arrayidx70.22, align 1
  %conv71.37.22 = zext i8 %15591 to i32
  %xor72.37.22 = xor i32 %conv71.37.22, %conv68.37.22
  %conv73.37.22 = trunc i32 %xor72.37.22 to i8
  store i8 %conv73.37.22, i8* %arrayidx70.22, align 1
  %scevgep20.38.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 38
  %15592 = load i8, i8* %scevgep20.38.22, align 1
  %conv68.38.22 = zext i8 %15592 to i32
  %15593 = load i8, i8* %arrayidx70.22, align 1
  %conv71.38.22 = zext i8 %15593 to i32
  %xor72.38.22 = xor i32 %conv71.38.22, %conv68.38.22
  %conv73.38.22 = trunc i32 %xor72.38.22 to i8
  store i8 %conv73.38.22, i8* %arrayidx70.22, align 1
  %scevgep20.39.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 39
  %15594 = load i8, i8* %scevgep20.39.22, align 1
  %conv68.39.22 = zext i8 %15594 to i32
  %15595 = load i8, i8* %arrayidx70.22, align 1
  %conv71.39.22 = zext i8 %15595 to i32
  %xor72.39.22 = xor i32 %conv71.39.22, %conv68.39.22
  %conv73.39.22 = trunc i32 %xor72.39.22 to i8
  store i8 %conv73.39.22, i8* %arrayidx70.22, align 1
  %scevgep20.40.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 40
  %15596 = load i8, i8* %scevgep20.40.22, align 1
  %conv68.40.22 = zext i8 %15596 to i32
  %15597 = load i8, i8* %arrayidx70.22, align 1
  %conv71.40.22 = zext i8 %15597 to i32
  %xor72.40.22 = xor i32 %conv71.40.22, %conv68.40.22
  %conv73.40.22 = trunc i32 %xor72.40.22 to i8
  store i8 %conv73.40.22, i8* %arrayidx70.22, align 1
  %scevgep20.41.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 41
  %15598 = load i8, i8* %scevgep20.41.22, align 1
  %conv68.41.22 = zext i8 %15598 to i32
  %15599 = load i8, i8* %arrayidx70.22, align 1
  %conv71.41.22 = zext i8 %15599 to i32
  %xor72.41.22 = xor i32 %conv71.41.22, %conv68.41.22
  %conv73.41.22 = trunc i32 %xor72.41.22 to i8
  store i8 %conv73.41.22, i8* %arrayidx70.22, align 1
  %scevgep20.42.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 42
  %15600 = load i8, i8* %scevgep20.42.22, align 1
  %conv68.42.22 = zext i8 %15600 to i32
  %15601 = load i8, i8* %arrayidx70.22, align 1
  %conv71.42.22 = zext i8 %15601 to i32
  %xor72.42.22 = xor i32 %conv71.42.22, %conv68.42.22
  %conv73.42.22 = trunc i32 %xor72.42.22 to i8
  store i8 %conv73.42.22, i8* %arrayidx70.22, align 1
  %scevgep20.43.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 43
  %15602 = load i8, i8* %scevgep20.43.22, align 1
  %conv68.43.22 = zext i8 %15602 to i32
  %15603 = load i8, i8* %arrayidx70.22, align 1
  %conv71.43.22 = zext i8 %15603 to i32
  %xor72.43.22 = xor i32 %conv71.43.22, %conv68.43.22
  %conv73.43.22 = trunc i32 %xor72.43.22 to i8
  store i8 %conv73.43.22, i8* %arrayidx70.22, align 1
  %scevgep20.44.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 44
  %15604 = load i8, i8* %scevgep20.44.22, align 1
  %conv68.44.22 = zext i8 %15604 to i32
  %15605 = load i8, i8* %arrayidx70.22, align 1
  %conv71.44.22 = zext i8 %15605 to i32
  %xor72.44.22 = xor i32 %conv71.44.22, %conv68.44.22
  %conv73.44.22 = trunc i32 %xor72.44.22 to i8
  store i8 %conv73.44.22, i8* %arrayidx70.22, align 1
  %scevgep20.45.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 45
  %15606 = load i8, i8* %scevgep20.45.22, align 1
  %conv68.45.22 = zext i8 %15606 to i32
  %15607 = load i8, i8* %arrayidx70.22, align 1
  %conv71.45.22 = zext i8 %15607 to i32
  %xor72.45.22 = xor i32 %conv71.45.22, %conv68.45.22
  %conv73.45.22 = trunc i32 %xor72.45.22 to i8
  store i8 %conv73.45.22, i8* %arrayidx70.22, align 1
  %scevgep20.46.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 46
  %15608 = load i8, i8* %scevgep20.46.22, align 1
  %conv68.46.22 = zext i8 %15608 to i32
  %15609 = load i8, i8* %arrayidx70.22, align 1
  %conv71.46.22 = zext i8 %15609 to i32
  %xor72.46.22 = xor i32 %conv71.46.22, %conv68.46.22
  %conv73.46.22 = trunc i32 %xor72.46.22 to i8
  store i8 %conv73.46.22, i8* %arrayidx70.22, align 1
  %scevgep20.47.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 47
  %15610 = load i8, i8* %scevgep20.47.22, align 1
  %conv68.47.22 = zext i8 %15610 to i32
  %15611 = load i8, i8* %arrayidx70.22, align 1
  %conv71.47.22 = zext i8 %15611 to i32
  %xor72.47.22 = xor i32 %conv71.47.22, %conv68.47.22
  %conv73.47.22 = trunc i32 %xor72.47.22 to i8
  store i8 %conv73.47.22, i8* %arrayidx70.22, align 1
  %scevgep20.48.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 48
  %15612 = load i8, i8* %scevgep20.48.22, align 1
  %conv68.48.22 = zext i8 %15612 to i32
  %15613 = load i8, i8* %arrayidx70.22, align 1
  %conv71.48.22 = zext i8 %15613 to i32
  %xor72.48.22 = xor i32 %conv71.48.22, %conv68.48.22
  %conv73.48.22 = trunc i32 %xor72.48.22 to i8
  store i8 %conv73.48.22, i8* %arrayidx70.22, align 1
  %scevgep20.49.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 49
  %15614 = load i8, i8* %scevgep20.49.22, align 1
  %conv68.49.22 = zext i8 %15614 to i32
  %15615 = load i8, i8* %arrayidx70.22, align 1
  %conv71.49.22 = zext i8 %15615 to i32
  %xor72.49.22 = xor i32 %conv71.49.22, %conv68.49.22
  %conv73.49.22 = trunc i32 %xor72.49.22 to i8
  store i8 %conv73.49.22, i8* %arrayidx70.22, align 1
  %scevgep20.50.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 50
  %15616 = load i8, i8* %scevgep20.50.22, align 1
  %conv68.50.22 = zext i8 %15616 to i32
  %15617 = load i8, i8* %arrayidx70.22, align 1
  %conv71.50.22 = zext i8 %15617 to i32
  %xor72.50.22 = xor i32 %conv71.50.22, %conv68.50.22
  %conv73.50.22 = trunc i32 %xor72.50.22 to i8
  store i8 %conv73.50.22, i8* %arrayidx70.22, align 1
  %scevgep20.51.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 51
  %15618 = load i8, i8* %scevgep20.51.22, align 1
  %conv68.51.22 = zext i8 %15618 to i32
  %15619 = load i8, i8* %arrayidx70.22, align 1
  %conv71.51.22 = zext i8 %15619 to i32
  %xor72.51.22 = xor i32 %conv71.51.22, %conv68.51.22
  %conv73.51.22 = trunc i32 %xor72.51.22 to i8
  store i8 %conv73.51.22, i8* %arrayidx70.22, align 1
  %scevgep20.52.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 52
  %15620 = load i8, i8* %scevgep20.52.22, align 1
  %conv68.52.22 = zext i8 %15620 to i32
  %15621 = load i8, i8* %arrayidx70.22, align 1
  %conv71.52.22 = zext i8 %15621 to i32
  %xor72.52.22 = xor i32 %conv71.52.22, %conv68.52.22
  %conv73.52.22 = trunc i32 %xor72.52.22 to i8
  store i8 %conv73.52.22, i8* %arrayidx70.22, align 1
  %scevgep20.53.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 53
  %15622 = load i8, i8* %scevgep20.53.22, align 1
  %conv68.53.22 = zext i8 %15622 to i32
  %15623 = load i8, i8* %arrayidx70.22, align 1
  %conv71.53.22 = zext i8 %15623 to i32
  %xor72.53.22 = xor i32 %conv71.53.22, %conv68.53.22
  %conv73.53.22 = trunc i32 %xor72.53.22 to i8
  store i8 %conv73.53.22, i8* %arrayidx70.22, align 1
  %scevgep20.54.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 54
  %15624 = load i8, i8* %scevgep20.54.22, align 1
  %conv68.54.22 = zext i8 %15624 to i32
  %15625 = load i8, i8* %arrayidx70.22, align 1
  %conv71.54.22 = zext i8 %15625 to i32
  %xor72.54.22 = xor i32 %conv71.54.22, %conv68.54.22
  %conv73.54.22 = trunc i32 %xor72.54.22 to i8
  store i8 %conv73.54.22, i8* %arrayidx70.22, align 1
  %scevgep20.55.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 55
  %15626 = load i8, i8* %scevgep20.55.22, align 1
  %conv68.55.22 = zext i8 %15626 to i32
  %15627 = load i8, i8* %arrayidx70.22, align 1
  %conv71.55.22 = zext i8 %15627 to i32
  %xor72.55.22 = xor i32 %conv71.55.22, %conv68.55.22
  %conv73.55.22 = trunc i32 %xor72.55.22 to i8
  store i8 %conv73.55.22, i8* %arrayidx70.22, align 1
  %scevgep20.56.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 56
  %15628 = load i8, i8* %scevgep20.56.22, align 1
  %conv68.56.22 = zext i8 %15628 to i32
  %15629 = load i8, i8* %arrayidx70.22, align 1
  %conv71.56.22 = zext i8 %15629 to i32
  %xor72.56.22 = xor i32 %conv71.56.22, %conv68.56.22
  %conv73.56.22 = trunc i32 %xor72.56.22 to i8
  store i8 %conv73.56.22, i8* %arrayidx70.22, align 1
  %scevgep20.57.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 57
  %15630 = load i8, i8* %scevgep20.57.22, align 1
  %conv68.57.22 = zext i8 %15630 to i32
  %15631 = load i8, i8* %arrayidx70.22, align 1
  %conv71.57.22 = zext i8 %15631 to i32
  %xor72.57.22 = xor i32 %conv71.57.22, %conv68.57.22
  %conv73.57.22 = trunc i32 %xor72.57.22 to i8
  store i8 %conv73.57.22, i8* %arrayidx70.22, align 1
  %scevgep20.58.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 58
  %15632 = load i8, i8* %scevgep20.58.22, align 1
  %conv68.58.22 = zext i8 %15632 to i32
  %15633 = load i8, i8* %arrayidx70.22, align 1
  %conv71.58.22 = zext i8 %15633 to i32
  %xor72.58.22 = xor i32 %conv71.58.22, %conv68.58.22
  %conv73.58.22 = trunc i32 %xor72.58.22 to i8
  store i8 %conv73.58.22, i8* %arrayidx70.22, align 1
  %scevgep20.59.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 59
  %15634 = load i8, i8* %scevgep20.59.22, align 1
  %conv68.59.22 = zext i8 %15634 to i32
  %15635 = load i8, i8* %arrayidx70.22, align 1
  %conv71.59.22 = zext i8 %15635 to i32
  %xor72.59.22 = xor i32 %conv71.59.22, %conv68.59.22
  %conv73.59.22 = trunc i32 %xor72.59.22 to i8
  store i8 %conv73.59.22, i8* %arrayidx70.22, align 1
  %scevgep20.60.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 0, i64 60
  %15636 = load i8, i8* %scevgep20.60.22, align 1
  %conv68.60.22 = zext i8 %15636 to i32
  %15637 = load i8, i8* %arrayidx70.22, align 1
  %conv71.60.22 = zext i8 %15637 to i32
  %xor72.60.22 = xor i32 %conv71.60.22, %conv68.60.22
  %conv73.60.22 = trunc i32 %xor72.60.22 to i8
  store i8 %conv73.60.22, i8* %arrayidx70.22, align 1
  %scevgep19.22 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15515, i64 0, i64 1, i64 0
  %15638 = bitcast i8* %scevgep19.22 to [61 x [61 x i8]]*
  %arrayidx51.23 = getelementptr inbounds i8, i8* %a, i64 23
  %15639 = load i8, i8* %arrayidx51.23, align 1
  %arrayidx53.23 = getelementptr inbounds i8, i8* %b, i64 23
  %15640 = load i8, i8* %arrayidx53.23, align 1
  %call54.23 = call zeroext i8 @mult(i8 zeroext %15639, i8 zeroext %15640)
  %arrayidx56.23 = getelementptr inbounds i8, i8* %c, i64 23
  store i8 %call54.23, i8* %arrayidx56.23, align 1
  %arrayidx70.23 = getelementptr inbounds i8, i8* %c, i64 23
  %scevgep20.23274 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 0
  %15641 = load i8, i8* %scevgep20.23274, align 1
  %conv68.23275 = zext i8 %15641 to i32
  %15642 = load i8, i8* %arrayidx70.23, align 1
  %conv71.23276 = zext i8 %15642 to i32
  %xor72.23277 = xor i32 %conv71.23276, %conv68.23275
  %conv73.23278 = trunc i32 %xor72.23277 to i8
  store i8 %conv73.23278, i8* %arrayidx70.23, align 1
  %scevgep20.1.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 1
  %15643 = load i8, i8* %scevgep20.1.23, align 1
  %conv68.1.23 = zext i8 %15643 to i32
  %15644 = load i8, i8* %arrayidx70.23, align 1
  %conv71.1.23 = zext i8 %15644 to i32
  %xor72.1.23 = xor i32 %conv71.1.23, %conv68.1.23
  %conv73.1.23 = trunc i32 %xor72.1.23 to i8
  store i8 %conv73.1.23, i8* %arrayidx70.23, align 1
  %scevgep20.2.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 2
  %15645 = load i8, i8* %scevgep20.2.23, align 1
  %conv68.2.23 = zext i8 %15645 to i32
  %15646 = load i8, i8* %arrayidx70.23, align 1
  %conv71.2.23 = zext i8 %15646 to i32
  %xor72.2.23 = xor i32 %conv71.2.23, %conv68.2.23
  %conv73.2.23 = trunc i32 %xor72.2.23 to i8
  store i8 %conv73.2.23, i8* %arrayidx70.23, align 1
  %scevgep20.3.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 3
  %15647 = load i8, i8* %scevgep20.3.23, align 1
  %conv68.3.23 = zext i8 %15647 to i32
  %15648 = load i8, i8* %arrayidx70.23, align 1
  %conv71.3.23 = zext i8 %15648 to i32
  %xor72.3.23 = xor i32 %conv71.3.23, %conv68.3.23
  %conv73.3.23 = trunc i32 %xor72.3.23 to i8
  store i8 %conv73.3.23, i8* %arrayidx70.23, align 1
  %scevgep20.4.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 4
  %15649 = load i8, i8* %scevgep20.4.23, align 1
  %conv68.4.23 = zext i8 %15649 to i32
  %15650 = load i8, i8* %arrayidx70.23, align 1
  %conv71.4.23 = zext i8 %15650 to i32
  %xor72.4.23 = xor i32 %conv71.4.23, %conv68.4.23
  %conv73.4.23 = trunc i32 %xor72.4.23 to i8
  store i8 %conv73.4.23, i8* %arrayidx70.23, align 1
  %scevgep20.5.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 5
  %15651 = load i8, i8* %scevgep20.5.23, align 1
  %conv68.5.23 = zext i8 %15651 to i32
  %15652 = load i8, i8* %arrayidx70.23, align 1
  %conv71.5.23 = zext i8 %15652 to i32
  %xor72.5.23 = xor i32 %conv71.5.23, %conv68.5.23
  %conv73.5.23 = trunc i32 %xor72.5.23 to i8
  store i8 %conv73.5.23, i8* %arrayidx70.23, align 1
  %scevgep20.6.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 6
  %15653 = load i8, i8* %scevgep20.6.23, align 1
  %conv68.6.23 = zext i8 %15653 to i32
  %15654 = load i8, i8* %arrayidx70.23, align 1
  %conv71.6.23 = zext i8 %15654 to i32
  %xor72.6.23 = xor i32 %conv71.6.23, %conv68.6.23
  %conv73.6.23 = trunc i32 %xor72.6.23 to i8
  store i8 %conv73.6.23, i8* %arrayidx70.23, align 1
  %scevgep20.7.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 7
  %15655 = load i8, i8* %scevgep20.7.23, align 1
  %conv68.7.23 = zext i8 %15655 to i32
  %15656 = load i8, i8* %arrayidx70.23, align 1
  %conv71.7.23 = zext i8 %15656 to i32
  %xor72.7.23 = xor i32 %conv71.7.23, %conv68.7.23
  %conv73.7.23 = trunc i32 %xor72.7.23 to i8
  store i8 %conv73.7.23, i8* %arrayidx70.23, align 1
  %scevgep20.8.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 8
  %15657 = load i8, i8* %scevgep20.8.23, align 1
  %conv68.8.23 = zext i8 %15657 to i32
  %15658 = load i8, i8* %arrayidx70.23, align 1
  %conv71.8.23 = zext i8 %15658 to i32
  %xor72.8.23 = xor i32 %conv71.8.23, %conv68.8.23
  %conv73.8.23 = trunc i32 %xor72.8.23 to i8
  store i8 %conv73.8.23, i8* %arrayidx70.23, align 1
  %scevgep20.9.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 9
  %15659 = load i8, i8* %scevgep20.9.23, align 1
  %conv68.9.23 = zext i8 %15659 to i32
  %15660 = load i8, i8* %arrayidx70.23, align 1
  %conv71.9.23 = zext i8 %15660 to i32
  %xor72.9.23 = xor i32 %conv71.9.23, %conv68.9.23
  %conv73.9.23 = trunc i32 %xor72.9.23 to i8
  store i8 %conv73.9.23, i8* %arrayidx70.23, align 1
  %scevgep20.10.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 10
  %15661 = load i8, i8* %scevgep20.10.23, align 1
  %conv68.10.23 = zext i8 %15661 to i32
  %15662 = load i8, i8* %arrayidx70.23, align 1
  %conv71.10.23 = zext i8 %15662 to i32
  %xor72.10.23 = xor i32 %conv71.10.23, %conv68.10.23
  %conv73.10.23 = trunc i32 %xor72.10.23 to i8
  store i8 %conv73.10.23, i8* %arrayidx70.23, align 1
  %scevgep20.11.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 11
  %15663 = load i8, i8* %scevgep20.11.23, align 1
  %conv68.11.23 = zext i8 %15663 to i32
  %15664 = load i8, i8* %arrayidx70.23, align 1
  %conv71.11.23 = zext i8 %15664 to i32
  %xor72.11.23 = xor i32 %conv71.11.23, %conv68.11.23
  %conv73.11.23 = trunc i32 %xor72.11.23 to i8
  store i8 %conv73.11.23, i8* %arrayidx70.23, align 1
  %scevgep20.12.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 12
  %15665 = load i8, i8* %scevgep20.12.23, align 1
  %conv68.12.23 = zext i8 %15665 to i32
  %15666 = load i8, i8* %arrayidx70.23, align 1
  %conv71.12.23 = zext i8 %15666 to i32
  %xor72.12.23 = xor i32 %conv71.12.23, %conv68.12.23
  %conv73.12.23 = trunc i32 %xor72.12.23 to i8
  store i8 %conv73.12.23, i8* %arrayidx70.23, align 1
  %scevgep20.13.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 13
  %15667 = load i8, i8* %scevgep20.13.23, align 1
  %conv68.13.23 = zext i8 %15667 to i32
  %15668 = load i8, i8* %arrayidx70.23, align 1
  %conv71.13.23 = zext i8 %15668 to i32
  %xor72.13.23 = xor i32 %conv71.13.23, %conv68.13.23
  %conv73.13.23 = trunc i32 %xor72.13.23 to i8
  store i8 %conv73.13.23, i8* %arrayidx70.23, align 1
  %scevgep20.14.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 14
  %15669 = load i8, i8* %scevgep20.14.23, align 1
  %conv68.14.23 = zext i8 %15669 to i32
  %15670 = load i8, i8* %arrayidx70.23, align 1
  %conv71.14.23 = zext i8 %15670 to i32
  %xor72.14.23 = xor i32 %conv71.14.23, %conv68.14.23
  %conv73.14.23 = trunc i32 %xor72.14.23 to i8
  store i8 %conv73.14.23, i8* %arrayidx70.23, align 1
  %scevgep20.15.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 15
  %15671 = load i8, i8* %scevgep20.15.23, align 1
  %conv68.15.23 = zext i8 %15671 to i32
  %15672 = load i8, i8* %arrayidx70.23, align 1
  %conv71.15.23 = zext i8 %15672 to i32
  %xor72.15.23 = xor i32 %conv71.15.23, %conv68.15.23
  %conv73.15.23 = trunc i32 %xor72.15.23 to i8
  store i8 %conv73.15.23, i8* %arrayidx70.23, align 1
  %scevgep20.16.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 16
  %15673 = load i8, i8* %scevgep20.16.23, align 1
  %conv68.16.23 = zext i8 %15673 to i32
  %15674 = load i8, i8* %arrayidx70.23, align 1
  %conv71.16.23 = zext i8 %15674 to i32
  %xor72.16.23 = xor i32 %conv71.16.23, %conv68.16.23
  %conv73.16.23 = trunc i32 %xor72.16.23 to i8
  store i8 %conv73.16.23, i8* %arrayidx70.23, align 1
  %scevgep20.17.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 17
  %15675 = load i8, i8* %scevgep20.17.23, align 1
  %conv68.17.23 = zext i8 %15675 to i32
  %15676 = load i8, i8* %arrayidx70.23, align 1
  %conv71.17.23 = zext i8 %15676 to i32
  %xor72.17.23 = xor i32 %conv71.17.23, %conv68.17.23
  %conv73.17.23 = trunc i32 %xor72.17.23 to i8
  store i8 %conv73.17.23, i8* %arrayidx70.23, align 1
  %scevgep20.18.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 18
  %15677 = load i8, i8* %scevgep20.18.23, align 1
  %conv68.18.23 = zext i8 %15677 to i32
  %15678 = load i8, i8* %arrayidx70.23, align 1
  %conv71.18.23 = zext i8 %15678 to i32
  %xor72.18.23 = xor i32 %conv71.18.23, %conv68.18.23
  %conv73.18.23 = trunc i32 %xor72.18.23 to i8
  store i8 %conv73.18.23, i8* %arrayidx70.23, align 1
  %scevgep20.19.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 19
  %15679 = load i8, i8* %scevgep20.19.23, align 1
  %conv68.19.23 = zext i8 %15679 to i32
  %15680 = load i8, i8* %arrayidx70.23, align 1
  %conv71.19.23 = zext i8 %15680 to i32
  %xor72.19.23 = xor i32 %conv71.19.23, %conv68.19.23
  %conv73.19.23 = trunc i32 %xor72.19.23 to i8
  store i8 %conv73.19.23, i8* %arrayidx70.23, align 1
  %scevgep20.20.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 20
  %15681 = load i8, i8* %scevgep20.20.23, align 1
  %conv68.20.23 = zext i8 %15681 to i32
  %15682 = load i8, i8* %arrayidx70.23, align 1
  %conv71.20.23 = zext i8 %15682 to i32
  %xor72.20.23 = xor i32 %conv71.20.23, %conv68.20.23
  %conv73.20.23 = trunc i32 %xor72.20.23 to i8
  store i8 %conv73.20.23, i8* %arrayidx70.23, align 1
  %scevgep20.21.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 21
  %15683 = load i8, i8* %scevgep20.21.23, align 1
  %conv68.21.23 = zext i8 %15683 to i32
  %15684 = load i8, i8* %arrayidx70.23, align 1
  %conv71.21.23 = zext i8 %15684 to i32
  %xor72.21.23 = xor i32 %conv71.21.23, %conv68.21.23
  %conv73.21.23 = trunc i32 %xor72.21.23 to i8
  store i8 %conv73.21.23, i8* %arrayidx70.23, align 1
  %scevgep20.22.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 22
  %15685 = load i8, i8* %scevgep20.22.23, align 1
  %conv68.22.23 = zext i8 %15685 to i32
  %15686 = load i8, i8* %arrayidx70.23, align 1
  %conv71.22.23 = zext i8 %15686 to i32
  %xor72.22.23 = xor i32 %conv71.22.23, %conv68.22.23
  %conv73.22.23 = trunc i32 %xor72.22.23 to i8
  store i8 %conv73.22.23, i8* %arrayidx70.23, align 1
  %scevgep20.24.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 24
  %15687 = load i8, i8* %scevgep20.24.23, align 1
  %conv68.24.23 = zext i8 %15687 to i32
  %15688 = load i8, i8* %arrayidx70.23, align 1
  %conv71.24.23 = zext i8 %15688 to i32
  %xor72.24.23 = xor i32 %conv71.24.23, %conv68.24.23
  %conv73.24.23 = trunc i32 %xor72.24.23 to i8
  store i8 %conv73.24.23, i8* %arrayidx70.23, align 1
  %scevgep20.25.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 25
  %15689 = load i8, i8* %scevgep20.25.23, align 1
  %conv68.25.23 = zext i8 %15689 to i32
  %15690 = load i8, i8* %arrayidx70.23, align 1
  %conv71.25.23 = zext i8 %15690 to i32
  %xor72.25.23 = xor i32 %conv71.25.23, %conv68.25.23
  %conv73.25.23 = trunc i32 %xor72.25.23 to i8
  store i8 %conv73.25.23, i8* %arrayidx70.23, align 1
  %scevgep20.26.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 26
  %15691 = load i8, i8* %scevgep20.26.23, align 1
  %conv68.26.23 = zext i8 %15691 to i32
  %15692 = load i8, i8* %arrayidx70.23, align 1
  %conv71.26.23 = zext i8 %15692 to i32
  %xor72.26.23 = xor i32 %conv71.26.23, %conv68.26.23
  %conv73.26.23 = trunc i32 %xor72.26.23 to i8
  store i8 %conv73.26.23, i8* %arrayidx70.23, align 1
  %scevgep20.27.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 27
  %15693 = load i8, i8* %scevgep20.27.23, align 1
  %conv68.27.23 = zext i8 %15693 to i32
  %15694 = load i8, i8* %arrayidx70.23, align 1
  %conv71.27.23 = zext i8 %15694 to i32
  %xor72.27.23 = xor i32 %conv71.27.23, %conv68.27.23
  %conv73.27.23 = trunc i32 %xor72.27.23 to i8
  store i8 %conv73.27.23, i8* %arrayidx70.23, align 1
  %scevgep20.28.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 28
  %15695 = load i8, i8* %scevgep20.28.23, align 1
  %conv68.28.23 = zext i8 %15695 to i32
  %15696 = load i8, i8* %arrayidx70.23, align 1
  %conv71.28.23 = zext i8 %15696 to i32
  %xor72.28.23 = xor i32 %conv71.28.23, %conv68.28.23
  %conv73.28.23 = trunc i32 %xor72.28.23 to i8
  store i8 %conv73.28.23, i8* %arrayidx70.23, align 1
  %scevgep20.29.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 29
  %15697 = load i8, i8* %scevgep20.29.23, align 1
  %conv68.29.23 = zext i8 %15697 to i32
  %15698 = load i8, i8* %arrayidx70.23, align 1
  %conv71.29.23 = zext i8 %15698 to i32
  %xor72.29.23 = xor i32 %conv71.29.23, %conv68.29.23
  %conv73.29.23 = trunc i32 %xor72.29.23 to i8
  store i8 %conv73.29.23, i8* %arrayidx70.23, align 1
  %scevgep20.30.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 30
  %15699 = load i8, i8* %scevgep20.30.23, align 1
  %conv68.30.23 = zext i8 %15699 to i32
  %15700 = load i8, i8* %arrayidx70.23, align 1
  %conv71.30.23 = zext i8 %15700 to i32
  %xor72.30.23 = xor i32 %conv71.30.23, %conv68.30.23
  %conv73.30.23 = trunc i32 %xor72.30.23 to i8
  store i8 %conv73.30.23, i8* %arrayidx70.23, align 1
  %scevgep20.31.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 31
  %15701 = load i8, i8* %scevgep20.31.23, align 1
  %conv68.31.23 = zext i8 %15701 to i32
  %15702 = load i8, i8* %arrayidx70.23, align 1
  %conv71.31.23 = zext i8 %15702 to i32
  %xor72.31.23 = xor i32 %conv71.31.23, %conv68.31.23
  %conv73.31.23 = trunc i32 %xor72.31.23 to i8
  store i8 %conv73.31.23, i8* %arrayidx70.23, align 1
  %scevgep20.32.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 32
  %15703 = load i8, i8* %scevgep20.32.23, align 1
  %conv68.32.23 = zext i8 %15703 to i32
  %15704 = load i8, i8* %arrayidx70.23, align 1
  %conv71.32.23 = zext i8 %15704 to i32
  %xor72.32.23 = xor i32 %conv71.32.23, %conv68.32.23
  %conv73.32.23 = trunc i32 %xor72.32.23 to i8
  store i8 %conv73.32.23, i8* %arrayidx70.23, align 1
  %scevgep20.33.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 33
  %15705 = load i8, i8* %scevgep20.33.23, align 1
  %conv68.33.23 = zext i8 %15705 to i32
  %15706 = load i8, i8* %arrayidx70.23, align 1
  %conv71.33.23 = zext i8 %15706 to i32
  %xor72.33.23 = xor i32 %conv71.33.23, %conv68.33.23
  %conv73.33.23 = trunc i32 %xor72.33.23 to i8
  store i8 %conv73.33.23, i8* %arrayidx70.23, align 1
  %scevgep20.34.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 34
  %15707 = load i8, i8* %scevgep20.34.23, align 1
  %conv68.34.23 = zext i8 %15707 to i32
  %15708 = load i8, i8* %arrayidx70.23, align 1
  %conv71.34.23 = zext i8 %15708 to i32
  %xor72.34.23 = xor i32 %conv71.34.23, %conv68.34.23
  %conv73.34.23 = trunc i32 %xor72.34.23 to i8
  store i8 %conv73.34.23, i8* %arrayidx70.23, align 1
  %scevgep20.35.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 35
  %15709 = load i8, i8* %scevgep20.35.23, align 1
  %conv68.35.23 = zext i8 %15709 to i32
  %15710 = load i8, i8* %arrayidx70.23, align 1
  %conv71.35.23 = zext i8 %15710 to i32
  %xor72.35.23 = xor i32 %conv71.35.23, %conv68.35.23
  %conv73.35.23 = trunc i32 %xor72.35.23 to i8
  store i8 %conv73.35.23, i8* %arrayidx70.23, align 1
  %scevgep20.36.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 36
  %15711 = load i8, i8* %scevgep20.36.23, align 1
  %conv68.36.23 = zext i8 %15711 to i32
  %15712 = load i8, i8* %arrayidx70.23, align 1
  %conv71.36.23 = zext i8 %15712 to i32
  %xor72.36.23 = xor i32 %conv71.36.23, %conv68.36.23
  %conv73.36.23 = trunc i32 %xor72.36.23 to i8
  store i8 %conv73.36.23, i8* %arrayidx70.23, align 1
  %scevgep20.37.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 37
  %15713 = load i8, i8* %scevgep20.37.23, align 1
  %conv68.37.23 = zext i8 %15713 to i32
  %15714 = load i8, i8* %arrayidx70.23, align 1
  %conv71.37.23 = zext i8 %15714 to i32
  %xor72.37.23 = xor i32 %conv71.37.23, %conv68.37.23
  %conv73.37.23 = trunc i32 %xor72.37.23 to i8
  store i8 %conv73.37.23, i8* %arrayidx70.23, align 1
  %scevgep20.38.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 38
  %15715 = load i8, i8* %scevgep20.38.23, align 1
  %conv68.38.23 = zext i8 %15715 to i32
  %15716 = load i8, i8* %arrayidx70.23, align 1
  %conv71.38.23 = zext i8 %15716 to i32
  %xor72.38.23 = xor i32 %conv71.38.23, %conv68.38.23
  %conv73.38.23 = trunc i32 %xor72.38.23 to i8
  store i8 %conv73.38.23, i8* %arrayidx70.23, align 1
  %scevgep20.39.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 39
  %15717 = load i8, i8* %scevgep20.39.23, align 1
  %conv68.39.23 = zext i8 %15717 to i32
  %15718 = load i8, i8* %arrayidx70.23, align 1
  %conv71.39.23 = zext i8 %15718 to i32
  %xor72.39.23 = xor i32 %conv71.39.23, %conv68.39.23
  %conv73.39.23 = trunc i32 %xor72.39.23 to i8
  store i8 %conv73.39.23, i8* %arrayidx70.23, align 1
  %scevgep20.40.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 40
  %15719 = load i8, i8* %scevgep20.40.23, align 1
  %conv68.40.23 = zext i8 %15719 to i32
  %15720 = load i8, i8* %arrayidx70.23, align 1
  %conv71.40.23 = zext i8 %15720 to i32
  %xor72.40.23 = xor i32 %conv71.40.23, %conv68.40.23
  %conv73.40.23 = trunc i32 %xor72.40.23 to i8
  store i8 %conv73.40.23, i8* %arrayidx70.23, align 1
  %scevgep20.41.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 41
  %15721 = load i8, i8* %scevgep20.41.23, align 1
  %conv68.41.23 = zext i8 %15721 to i32
  %15722 = load i8, i8* %arrayidx70.23, align 1
  %conv71.41.23 = zext i8 %15722 to i32
  %xor72.41.23 = xor i32 %conv71.41.23, %conv68.41.23
  %conv73.41.23 = trunc i32 %xor72.41.23 to i8
  store i8 %conv73.41.23, i8* %arrayidx70.23, align 1
  %scevgep20.42.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 42
  %15723 = load i8, i8* %scevgep20.42.23, align 1
  %conv68.42.23 = zext i8 %15723 to i32
  %15724 = load i8, i8* %arrayidx70.23, align 1
  %conv71.42.23 = zext i8 %15724 to i32
  %xor72.42.23 = xor i32 %conv71.42.23, %conv68.42.23
  %conv73.42.23 = trunc i32 %xor72.42.23 to i8
  store i8 %conv73.42.23, i8* %arrayidx70.23, align 1
  %scevgep20.43.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 43
  %15725 = load i8, i8* %scevgep20.43.23, align 1
  %conv68.43.23 = zext i8 %15725 to i32
  %15726 = load i8, i8* %arrayidx70.23, align 1
  %conv71.43.23 = zext i8 %15726 to i32
  %xor72.43.23 = xor i32 %conv71.43.23, %conv68.43.23
  %conv73.43.23 = trunc i32 %xor72.43.23 to i8
  store i8 %conv73.43.23, i8* %arrayidx70.23, align 1
  %scevgep20.44.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 44
  %15727 = load i8, i8* %scevgep20.44.23, align 1
  %conv68.44.23 = zext i8 %15727 to i32
  %15728 = load i8, i8* %arrayidx70.23, align 1
  %conv71.44.23 = zext i8 %15728 to i32
  %xor72.44.23 = xor i32 %conv71.44.23, %conv68.44.23
  %conv73.44.23 = trunc i32 %xor72.44.23 to i8
  store i8 %conv73.44.23, i8* %arrayidx70.23, align 1
  %scevgep20.45.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 45
  %15729 = load i8, i8* %scevgep20.45.23, align 1
  %conv68.45.23 = zext i8 %15729 to i32
  %15730 = load i8, i8* %arrayidx70.23, align 1
  %conv71.45.23 = zext i8 %15730 to i32
  %xor72.45.23 = xor i32 %conv71.45.23, %conv68.45.23
  %conv73.45.23 = trunc i32 %xor72.45.23 to i8
  store i8 %conv73.45.23, i8* %arrayidx70.23, align 1
  %scevgep20.46.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 46
  %15731 = load i8, i8* %scevgep20.46.23, align 1
  %conv68.46.23 = zext i8 %15731 to i32
  %15732 = load i8, i8* %arrayidx70.23, align 1
  %conv71.46.23 = zext i8 %15732 to i32
  %xor72.46.23 = xor i32 %conv71.46.23, %conv68.46.23
  %conv73.46.23 = trunc i32 %xor72.46.23 to i8
  store i8 %conv73.46.23, i8* %arrayidx70.23, align 1
  %scevgep20.47.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 47
  %15733 = load i8, i8* %scevgep20.47.23, align 1
  %conv68.47.23 = zext i8 %15733 to i32
  %15734 = load i8, i8* %arrayidx70.23, align 1
  %conv71.47.23 = zext i8 %15734 to i32
  %xor72.47.23 = xor i32 %conv71.47.23, %conv68.47.23
  %conv73.47.23 = trunc i32 %xor72.47.23 to i8
  store i8 %conv73.47.23, i8* %arrayidx70.23, align 1
  %scevgep20.48.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 48
  %15735 = load i8, i8* %scevgep20.48.23, align 1
  %conv68.48.23 = zext i8 %15735 to i32
  %15736 = load i8, i8* %arrayidx70.23, align 1
  %conv71.48.23 = zext i8 %15736 to i32
  %xor72.48.23 = xor i32 %conv71.48.23, %conv68.48.23
  %conv73.48.23 = trunc i32 %xor72.48.23 to i8
  store i8 %conv73.48.23, i8* %arrayidx70.23, align 1
  %scevgep20.49.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 49
  %15737 = load i8, i8* %scevgep20.49.23, align 1
  %conv68.49.23 = zext i8 %15737 to i32
  %15738 = load i8, i8* %arrayidx70.23, align 1
  %conv71.49.23 = zext i8 %15738 to i32
  %xor72.49.23 = xor i32 %conv71.49.23, %conv68.49.23
  %conv73.49.23 = trunc i32 %xor72.49.23 to i8
  store i8 %conv73.49.23, i8* %arrayidx70.23, align 1
  %scevgep20.50.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 50
  %15739 = load i8, i8* %scevgep20.50.23, align 1
  %conv68.50.23 = zext i8 %15739 to i32
  %15740 = load i8, i8* %arrayidx70.23, align 1
  %conv71.50.23 = zext i8 %15740 to i32
  %xor72.50.23 = xor i32 %conv71.50.23, %conv68.50.23
  %conv73.50.23 = trunc i32 %xor72.50.23 to i8
  store i8 %conv73.50.23, i8* %arrayidx70.23, align 1
  %scevgep20.51.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 51
  %15741 = load i8, i8* %scevgep20.51.23, align 1
  %conv68.51.23 = zext i8 %15741 to i32
  %15742 = load i8, i8* %arrayidx70.23, align 1
  %conv71.51.23 = zext i8 %15742 to i32
  %xor72.51.23 = xor i32 %conv71.51.23, %conv68.51.23
  %conv73.51.23 = trunc i32 %xor72.51.23 to i8
  store i8 %conv73.51.23, i8* %arrayidx70.23, align 1
  %scevgep20.52.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 52
  %15743 = load i8, i8* %scevgep20.52.23, align 1
  %conv68.52.23 = zext i8 %15743 to i32
  %15744 = load i8, i8* %arrayidx70.23, align 1
  %conv71.52.23 = zext i8 %15744 to i32
  %xor72.52.23 = xor i32 %conv71.52.23, %conv68.52.23
  %conv73.52.23 = trunc i32 %xor72.52.23 to i8
  store i8 %conv73.52.23, i8* %arrayidx70.23, align 1
  %scevgep20.53.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 53
  %15745 = load i8, i8* %scevgep20.53.23, align 1
  %conv68.53.23 = zext i8 %15745 to i32
  %15746 = load i8, i8* %arrayidx70.23, align 1
  %conv71.53.23 = zext i8 %15746 to i32
  %xor72.53.23 = xor i32 %conv71.53.23, %conv68.53.23
  %conv73.53.23 = trunc i32 %xor72.53.23 to i8
  store i8 %conv73.53.23, i8* %arrayidx70.23, align 1
  %scevgep20.54.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 54
  %15747 = load i8, i8* %scevgep20.54.23, align 1
  %conv68.54.23 = zext i8 %15747 to i32
  %15748 = load i8, i8* %arrayidx70.23, align 1
  %conv71.54.23 = zext i8 %15748 to i32
  %xor72.54.23 = xor i32 %conv71.54.23, %conv68.54.23
  %conv73.54.23 = trunc i32 %xor72.54.23 to i8
  store i8 %conv73.54.23, i8* %arrayidx70.23, align 1
  %scevgep20.55.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 55
  %15749 = load i8, i8* %scevgep20.55.23, align 1
  %conv68.55.23 = zext i8 %15749 to i32
  %15750 = load i8, i8* %arrayidx70.23, align 1
  %conv71.55.23 = zext i8 %15750 to i32
  %xor72.55.23 = xor i32 %conv71.55.23, %conv68.55.23
  %conv73.55.23 = trunc i32 %xor72.55.23 to i8
  store i8 %conv73.55.23, i8* %arrayidx70.23, align 1
  %scevgep20.56.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 56
  %15751 = load i8, i8* %scevgep20.56.23, align 1
  %conv68.56.23 = zext i8 %15751 to i32
  %15752 = load i8, i8* %arrayidx70.23, align 1
  %conv71.56.23 = zext i8 %15752 to i32
  %xor72.56.23 = xor i32 %conv71.56.23, %conv68.56.23
  %conv73.56.23 = trunc i32 %xor72.56.23 to i8
  store i8 %conv73.56.23, i8* %arrayidx70.23, align 1
  %scevgep20.57.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 57
  %15753 = load i8, i8* %scevgep20.57.23, align 1
  %conv68.57.23 = zext i8 %15753 to i32
  %15754 = load i8, i8* %arrayidx70.23, align 1
  %conv71.57.23 = zext i8 %15754 to i32
  %xor72.57.23 = xor i32 %conv71.57.23, %conv68.57.23
  %conv73.57.23 = trunc i32 %xor72.57.23 to i8
  store i8 %conv73.57.23, i8* %arrayidx70.23, align 1
  %scevgep20.58.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 58
  %15755 = load i8, i8* %scevgep20.58.23, align 1
  %conv68.58.23 = zext i8 %15755 to i32
  %15756 = load i8, i8* %arrayidx70.23, align 1
  %conv71.58.23 = zext i8 %15756 to i32
  %xor72.58.23 = xor i32 %conv71.58.23, %conv68.58.23
  %conv73.58.23 = trunc i32 %xor72.58.23 to i8
  store i8 %conv73.58.23, i8* %arrayidx70.23, align 1
  %scevgep20.59.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 59
  %15757 = load i8, i8* %scevgep20.59.23, align 1
  %conv68.59.23 = zext i8 %15757 to i32
  %15758 = load i8, i8* %arrayidx70.23, align 1
  %conv71.59.23 = zext i8 %15758 to i32
  %xor72.59.23 = xor i32 %conv71.59.23, %conv68.59.23
  %conv73.59.23 = trunc i32 %xor72.59.23 to i8
  store i8 %conv73.59.23, i8* %arrayidx70.23, align 1
  %scevgep20.60.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 0, i64 60
  %15759 = load i8, i8* %scevgep20.60.23, align 1
  %conv68.60.23 = zext i8 %15759 to i32
  %15760 = load i8, i8* %arrayidx70.23, align 1
  %conv71.60.23 = zext i8 %15760 to i32
  %xor72.60.23 = xor i32 %conv71.60.23, %conv68.60.23
  %conv73.60.23 = trunc i32 %xor72.60.23 to i8
  store i8 %conv73.60.23, i8* %arrayidx70.23, align 1
  %scevgep19.23 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15638, i64 0, i64 1, i64 0
  %15761 = bitcast i8* %scevgep19.23 to [61 x [61 x i8]]*
  %arrayidx51.24 = getelementptr inbounds i8, i8* %a, i64 24
  %15762 = load i8, i8* %arrayidx51.24, align 1
  %arrayidx53.24 = getelementptr inbounds i8, i8* %b, i64 24
  %15763 = load i8, i8* %arrayidx53.24, align 1
  %call54.24 = call zeroext i8 @mult(i8 zeroext %15762, i8 zeroext %15763)
  %arrayidx56.24 = getelementptr inbounds i8, i8* %c, i64 24
  store i8 %call54.24, i8* %arrayidx56.24, align 1
  %arrayidx70.24 = getelementptr inbounds i8, i8* %c, i64 24
  %scevgep20.24284 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 0
  %15764 = load i8, i8* %scevgep20.24284, align 1
  %conv68.24285 = zext i8 %15764 to i32
  %15765 = load i8, i8* %arrayidx70.24, align 1
  %conv71.24286 = zext i8 %15765 to i32
  %xor72.24287 = xor i32 %conv71.24286, %conv68.24285
  %conv73.24288 = trunc i32 %xor72.24287 to i8
  store i8 %conv73.24288, i8* %arrayidx70.24, align 1
  %scevgep20.1.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 1
  %15766 = load i8, i8* %scevgep20.1.24, align 1
  %conv68.1.24 = zext i8 %15766 to i32
  %15767 = load i8, i8* %arrayidx70.24, align 1
  %conv71.1.24 = zext i8 %15767 to i32
  %xor72.1.24 = xor i32 %conv71.1.24, %conv68.1.24
  %conv73.1.24 = trunc i32 %xor72.1.24 to i8
  store i8 %conv73.1.24, i8* %arrayidx70.24, align 1
  %scevgep20.2.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 2
  %15768 = load i8, i8* %scevgep20.2.24, align 1
  %conv68.2.24 = zext i8 %15768 to i32
  %15769 = load i8, i8* %arrayidx70.24, align 1
  %conv71.2.24 = zext i8 %15769 to i32
  %xor72.2.24 = xor i32 %conv71.2.24, %conv68.2.24
  %conv73.2.24 = trunc i32 %xor72.2.24 to i8
  store i8 %conv73.2.24, i8* %arrayidx70.24, align 1
  %scevgep20.3.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 3
  %15770 = load i8, i8* %scevgep20.3.24, align 1
  %conv68.3.24 = zext i8 %15770 to i32
  %15771 = load i8, i8* %arrayidx70.24, align 1
  %conv71.3.24 = zext i8 %15771 to i32
  %xor72.3.24 = xor i32 %conv71.3.24, %conv68.3.24
  %conv73.3.24 = trunc i32 %xor72.3.24 to i8
  store i8 %conv73.3.24, i8* %arrayidx70.24, align 1
  %scevgep20.4.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 4
  %15772 = load i8, i8* %scevgep20.4.24, align 1
  %conv68.4.24 = zext i8 %15772 to i32
  %15773 = load i8, i8* %arrayidx70.24, align 1
  %conv71.4.24 = zext i8 %15773 to i32
  %xor72.4.24 = xor i32 %conv71.4.24, %conv68.4.24
  %conv73.4.24 = trunc i32 %xor72.4.24 to i8
  store i8 %conv73.4.24, i8* %arrayidx70.24, align 1
  %scevgep20.5.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 5
  %15774 = load i8, i8* %scevgep20.5.24, align 1
  %conv68.5.24 = zext i8 %15774 to i32
  %15775 = load i8, i8* %arrayidx70.24, align 1
  %conv71.5.24 = zext i8 %15775 to i32
  %xor72.5.24 = xor i32 %conv71.5.24, %conv68.5.24
  %conv73.5.24 = trunc i32 %xor72.5.24 to i8
  store i8 %conv73.5.24, i8* %arrayidx70.24, align 1
  %scevgep20.6.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 6
  %15776 = load i8, i8* %scevgep20.6.24, align 1
  %conv68.6.24 = zext i8 %15776 to i32
  %15777 = load i8, i8* %arrayidx70.24, align 1
  %conv71.6.24 = zext i8 %15777 to i32
  %xor72.6.24 = xor i32 %conv71.6.24, %conv68.6.24
  %conv73.6.24 = trunc i32 %xor72.6.24 to i8
  store i8 %conv73.6.24, i8* %arrayidx70.24, align 1
  %scevgep20.7.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 7
  %15778 = load i8, i8* %scevgep20.7.24, align 1
  %conv68.7.24 = zext i8 %15778 to i32
  %15779 = load i8, i8* %arrayidx70.24, align 1
  %conv71.7.24 = zext i8 %15779 to i32
  %xor72.7.24 = xor i32 %conv71.7.24, %conv68.7.24
  %conv73.7.24 = trunc i32 %xor72.7.24 to i8
  store i8 %conv73.7.24, i8* %arrayidx70.24, align 1
  %scevgep20.8.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 8
  %15780 = load i8, i8* %scevgep20.8.24, align 1
  %conv68.8.24 = zext i8 %15780 to i32
  %15781 = load i8, i8* %arrayidx70.24, align 1
  %conv71.8.24 = zext i8 %15781 to i32
  %xor72.8.24 = xor i32 %conv71.8.24, %conv68.8.24
  %conv73.8.24 = trunc i32 %xor72.8.24 to i8
  store i8 %conv73.8.24, i8* %arrayidx70.24, align 1
  %scevgep20.9.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 9
  %15782 = load i8, i8* %scevgep20.9.24, align 1
  %conv68.9.24 = zext i8 %15782 to i32
  %15783 = load i8, i8* %arrayidx70.24, align 1
  %conv71.9.24 = zext i8 %15783 to i32
  %xor72.9.24 = xor i32 %conv71.9.24, %conv68.9.24
  %conv73.9.24 = trunc i32 %xor72.9.24 to i8
  store i8 %conv73.9.24, i8* %arrayidx70.24, align 1
  %scevgep20.10.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 10
  %15784 = load i8, i8* %scevgep20.10.24, align 1
  %conv68.10.24 = zext i8 %15784 to i32
  %15785 = load i8, i8* %arrayidx70.24, align 1
  %conv71.10.24 = zext i8 %15785 to i32
  %xor72.10.24 = xor i32 %conv71.10.24, %conv68.10.24
  %conv73.10.24 = trunc i32 %xor72.10.24 to i8
  store i8 %conv73.10.24, i8* %arrayidx70.24, align 1
  %scevgep20.11.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 11
  %15786 = load i8, i8* %scevgep20.11.24, align 1
  %conv68.11.24 = zext i8 %15786 to i32
  %15787 = load i8, i8* %arrayidx70.24, align 1
  %conv71.11.24 = zext i8 %15787 to i32
  %xor72.11.24 = xor i32 %conv71.11.24, %conv68.11.24
  %conv73.11.24 = trunc i32 %xor72.11.24 to i8
  store i8 %conv73.11.24, i8* %arrayidx70.24, align 1
  %scevgep20.12.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 12
  %15788 = load i8, i8* %scevgep20.12.24, align 1
  %conv68.12.24 = zext i8 %15788 to i32
  %15789 = load i8, i8* %arrayidx70.24, align 1
  %conv71.12.24 = zext i8 %15789 to i32
  %xor72.12.24 = xor i32 %conv71.12.24, %conv68.12.24
  %conv73.12.24 = trunc i32 %xor72.12.24 to i8
  store i8 %conv73.12.24, i8* %arrayidx70.24, align 1
  %scevgep20.13.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 13
  %15790 = load i8, i8* %scevgep20.13.24, align 1
  %conv68.13.24 = zext i8 %15790 to i32
  %15791 = load i8, i8* %arrayidx70.24, align 1
  %conv71.13.24 = zext i8 %15791 to i32
  %xor72.13.24 = xor i32 %conv71.13.24, %conv68.13.24
  %conv73.13.24 = trunc i32 %xor72.13.24 to i8
  store i8 %conv73.13.24, i8* %arrayidx70.24, align 1
  %scevgep20.14.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 14
  %15792 = load i8, i8* %scevgep20.14.24, align 1
  %conv68.14.24 = zext i8 %15792 to i32
  %15793 = load i8, i8* %arrayidx70.24, align 1
  %conv71.14.24 = zext i8 %15793 to i32
  %xor72.14.24 = xor i32 %conv71.14.24, %conv68.14.24
  %conv73.14.24 = trunc i32 %xor72.14.24 to i8
  store i8 %conv73.14.24, i8* %arrayidx70.24, align 1
  %scevgep20.15.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 15
  %15794 = load i8, i8* %scevgep20.15.24, align 1
  %conv68.15.24 = zext i8 %15794 to i32
  %15795 = load i8, i8* %arrayidx70.24, align 1
  %conv71.15.24 = zext i8 %15795 to i32
  %xor72.15.24 = xor i32 %conv71.15.24, %conv68.15.24
  %conv73.15.24 = trunc i32 %xor72.15.24 to i8
  store i8 %conv73.15.24, i8* %arrayidx70.24, align 1
  %scevgep20.16.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 16
  %15796 = load i8, i8* %scevgep20.16.24, align 1
  %conv68.16.24 = zext i8 %15796 to i32
  %15797 = load i8, i8* %arrayidx70.24, align 1
  %conv71.16.24 = zext i8 %15797 to i32
  %xor72.16.24 = xor i32 %conv71.16.24, %conv68.16.24
  %conv73.16.24 = trunc i32 %xor72.16.24 to i8
  store i8 %conv73.16.24, i8* %arrayidx70.24, align 1
  %scevgep20.17.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 17
  %15798 = load i8, i8* %scevgep20.17.24, align 1
  %conv68.17.24 = zext i8 %15798 to i32
  %15799 = load i8, i8* %arrayidx70.24, align 1
  %conv71.17.24 = zext i8 %15799 to i32
  %xor72.17.24 = xor i32 %conv71.17.24, %conv68.17.24
  %conv73.17.24 = trunc i32 %xor72.17.24 to i8
  store i8 %conv73.17.24, i8* %arrayidx70.24, align 1
  %scevgep20.18.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 18
  %15800 = load i8, i8* %scevgep20.18.24, align 1
  %conv68.18.24 = zext i8 %15800 to i32
  %15801 = load i8, i8* %arrayidx70.24, align 1
  %conv71.18.24 = zext i8 %15801 to i32
  %xor72.18.24 = xor i32 %conv71.18.24, %conv68.18.24
  %conv73.18.24 = trunc i32 %xor72.18.24 to i8
  store i8 %conv73.18.24, i8* %arrayidx70.24, align 1
  %scevgep20.19.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 19
  %15802 = load i8, i8* %scevgep20.19.24, align 1
  %conv68.19.24 = zext i8 %15802 to i32
  %15803 = load i8, i8* %arrayidx70.24, align 1
  %conv71.19.24 = zext i8 %15803 to i32
  %xor72.19.24 = xor i32 %conv71.19.24, %conv68.19.24
  %conv73.19.24 = trunc i32 %xor72.19.24 to i8
  store i8 %conv73.19.24, i8* %arrayidx70.24, align 1
  %scevgep20.20.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 20
  %15804 = load i8, i8* %scevgep20.20.24, align 1
  %conv68.20.24 = zext i8 %15804 to i32
  %15805 = load i8, i8* %arrayidx70.24, align 1
  %conv71.20.24 = zext i8 %15805 to i32
  %xor72.20.24 = xor i32 %conv71.20.24, %conv68.20.24
  %conv73.20.24 = trunc i32 %xor72.20.24 to i8
  store i8 %conv73.20.24, i8* %arrayidx70.24, align 1
  %scevgep20.21.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 21
  %15806 = load i8, i8* %scevgep20.21.24, align 1
  %conv68.21.24 = zext i8 %15806 to i32
  %15807 = load i8, i8* %arrayidx70.24, align 1
  %conv71.21.24 = zext i8 %15807 to i32
  %xor72.21.24 = xor i32 %conv71.21.24, %conv68.21.24
  %conv73.21.24 = trunc i32 %xor72.21.24 to i8
  store i8 %conv73.21.24, i8* %arrayidx70.24, align 1
  %scevgep20.22.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 22
  %15808 = load i8, i8* %scevgep20.22.24, align 1
  %conv68.22.24 = zext i8 %15808 to i32
  %15809 = load i8, i8* %arrayidx70.24, align 1
  %conv71.22.24 = zext i8 %15809 to i32
  %xor72.22.24 = xor i32 %conv71.22.24, %conv68.22.24
  %conv73.22.24 = trunc i32 %xor72.22.24 to i8
  store i8 %conv73.22.24, i8* %arrayidx70.24, align 1
  %scevgep20.23.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 23
  %15810 = load i8, i8* %scevgep20.23.24, align 1
  %conv68.23.24 = zext i8 %15810 to i32
  %15811 = load i8, i8* %arrayidx70.24, align 1
  %conv71.23.24 = zext i8 %15811 to i32
  %xor72.23.24 = xor i32 %conv71.23.24, %conv68.23.24
  %conv73.23.24 = trunc i32 %xor72.23.24 to i8
  store i8 %conv73.23.24, i8* %arrayidx70.24, align 1
  %scevgep20.25.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 25
  %15812 = load i8, i8* %scevgep20.25.24, align 1
  %conv68.25.24 = zext i8 %15812 to i32
  %15813 = load i8, i8* %arrayidx70.24, align 1
  %conv71.25.24 = zext i8 %15813 to i32
  %xor72.25.24 = xor i32 %conv71.25.24, %conv68.25.24
  %conv73.25.24 = trunc i32 %xor72.25.24 to i8
  store i8 %conv73.25.24, i8* %arrayidx70.24, align 1
  %scevgep20.26.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 26
  %15814 = load i8, i8* %scevgep20.26.24, align 1
  %conv68.26.24 = zext i8 %15814 to i32
  %15815 = load i8, i8* %arrayidx70.24, align 1
  %conv71.26.24 = zext i8 %15815 to i32
  %xor72.26.24 = xor i32 %conv71.26.24, %conv68.26.24
  %conv73.26.24 = trunc i32 %xor72.26.24 to i8
  store i8 %conv73.26.24, i8* %arrayidx70.24, align 1
  %scevgep20.27.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 27
  %15816 = load i8, i8* %scevgep20.27.24, align 1
  %conv68.27.24 = zext i8 %15816 to i32
  %15817 = load i8, i8* %arrayidx70.24, align 1
  %conv71.27.24 = zext i8 %15817 to i32
  %xor72.27.24 = xor i32 %conv71.27.24, %conv68.27.24
  %conv73.27.24 = trunc i32 %xor72.27.24 to i8
  store i8 %conv73.27.24, i8* %arrayidx70.24, align 1
  %scevgep20.28.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 28
  %15818 = load i8, i8* %scevgep20.28.24, align 1
  %conv68.28.24 = zext i8 %15818 to i32
  %15819 = load i8, i8* %arrayidx70.24, align 1
  %conv71.28.24 = zext i8 %15819 to i32
  %xor72.28.24 = xor i32 %conv71.28.24, %conv68.28.24
  %conv73.28.24 = trunc i32 %xor72.28.24 to i8
  store i8 %conv73.28.24, i8* %arrayidx70.24, align 1
  %scevgep20.29.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 29
  %15820 = load i8, i8* %scevgep20.29.24, align 1
  %conv68.29.24 = zext i8 %15820 to i32
  %15821 = load i8, i8* %arrayidx70.24, align 1
  %conv71.29.24 = zext i8 %15821 to i32
  %xor72.29.24 = xor i32 %conv71.29.24, %conv68.29.24
  %conv73.29.24 = trunc i32 %xor72.29.24 to i8
  store i8 %conv73.29.24, i8* %arrayidx70.24, align 1
  %scevgep20.30.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 30
  %15822 = load i8, i8* %scevgep20.30.24, align 1
  %conv68.30.24 = zext i8 %15822 to i32
  %15823 = load i8, i8* %arrayidx70.24, align 1
  %conv71.30.24 = zext i8 %15823 to i32
  %xor72.30.24 = xor i32 %conv71.30.24, %conv68.30.24
  %conv73.30.24 = trunc i32 %xor72.30.24 to i8
  store i8 %conv73.30.24, i8* %arrayidx70.24, align 1
  %scevgep20.31.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 31
  %15824 = load i8, i8* %scevgep20.31.24, align 1
  %conv68.31.24 = zext i8 %15824 to i32
  %15825 = load i8, i8* %arrayidx70.24, align 1
  %conv71.31.24 = zext i8 %15825 to i32
  %xor72.31.24 = xor i32 %conv71.31.24, %conv68.31.24
  %conv73.31.24 = trunc i32 %xor72.31.24 to i8
  store i8 %conv73.31.24, i8* %arrayidx70.24, align 1
  %scevgep20.32.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 32
  %15826 = load i8, i8* %scevgep20.32.24, align 1
  %conv68.32.24 = zext i8 %15826 to i32
  %15827 = load i8, i8* %arrayidx70.24, align 1
  %conv71.32.24 = zext i8 %15827 to i32
  %xor72.32.24 = xor i32 %conv71.32.24, %conv68.32.24
  %conv73.32.24 = trunc i32 %xor72.32.24 to i8
  store i8 %conv73.32.24, i8* %arrayidx70.24, align 1
  %scevgep20.33.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 33
  %15828 = load i8, i8* %scevgep20.33.24, align 1
  %conv68.33.24 = zext i8 %15828 to i32
  %15829 = load i8, i8* %arrayidx70.24, align 1
  %conv71.33.24 = zext i8 %15829 to i32
  %xor72.33.24 = xor i32 %conv71.33.24, %conv68.33.24
  %conv73.33.24 = trunc i32 %xor72.33.24 to i8
  store i8 %conv73.33.24, i8* %arrayidx70.24, align 1
  %scevgep20.34.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 34
  %15830 = load i8, i8* %scevgep20.34.24, align 1
  %conv68.34.24 = zext i8 %15830 to i32
  %15831 = load i8, i8* %arrayidx70.24, align 1
  %conv71.34.24 = zext i8 %15831 to i32
  %xor72.34.24 = xor i32 %conv71.34.24, %conv68.34.24
  %conv73.34.24 = trunc i32 %xor72.34.24 to i8
  store i8 %conv73.34.24, i8* %arrayidx70.24, align 1
  %scevgep20.35.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 35
  %15832 = load i8, i8* %scevgep20.35.24, align 1
  %conv68.35.24 = zext i8 %15832 to i32
  %15833 = load i8, i8* %arrayidx70.24, align 1
  %conv71.35.24 = zext i8 %15833 to i32
  %xor72.35.24 = xor i32 %conv71.35.24, %conv68.35.24
  %conv73.35.24 = trunc i32 %xor72.35.24 to i8
  store i8 %conv73.35.24, i8* %arrayidx70.24, align 1
  %scevgep20.36.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 36
  %15834 = load i8, i8* %scevgep20.36.24, align 1
  %conv68.36.24 = zext i8 %15834 to i32
  %15835 = load i8, i8* %arrayidx70.24, align 1
  %conv71.36.24 = zext i8 %15835 to i32
  %xor72.36.24 = xor i32 %conv71.36.24, %conv68.36.24
  %conv73.36.24 = trunc i32 %xor72.36.24 to i8
  store i8 %conv73.36.24, i8* %arrayidx70.24, align 1
  %scevgep20.37.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 37
  %15836 = load i8, i8* %scevgep20.37.24, align 1
  %conv68.37.24 = zext i8 %15836 to i32
  %15837 = load i8, i8* %arrayidx70.24, align 1
  %conv71.37.24 = zext i8 %15837 to i32
  %xor72.37.24 = xor i32 %conv71.37.24, %conv68.37.24
  %conv73.37.24 = trunc i32 %xor72.37.24 to i8
  store i8 %conv73.37.24, i8* %arrayidx70.24, align 1
  %scevgep20.38.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 38
  %15838 = load i8, i8* %scevgep20.38.24, align 1
  %conv68.38.24 = zext i8 %15838 to i32
  %15839 = load i8, i8* %arrayidx70.24, align 1
  %conv71.38.24 = zext i8 %15839 to i32
  %xor72.38.24 = xor i32 %conv71.38.24, %conv68.38.24
  %conv73.38.24 = trunc i32 %xor72.38.24 to i8
  store i8 %conv73.38.24, i8* %arrayidx70.24, align 1
  %scevgep20.39.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 39
  %15840 = load i8, i8* %scevgep20.39.24, align 1
  %conv68.39.24 = zext i8 %15840 to i32
  %15841 = load i8, i8* %arrayidx70.24, align 1
  %conv71.39.24 = zext i8 %15841 to i32
  %xor72.39.24 = xor i32 %conv71.39.24, %conv68.39.24
  %conv73.39.24 = trunc i32 %xor72.39.24 to i8
  store i8 %conv73.39.24, i8* %arrayidx70.24, align 1
  %scevgep20.40.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 40
  %15842 = load i8, i8* %scevgep20.40.24, align 1
  %conv68.40.24 = zext i8 %15842 to i32
  %15843 = load i8, i8* %arrayidx70.24, align 1
  %conv71.40.24 = zext i8 %15843 to i32
  %xor72.40.24 = xor i32 %conv71.40.24, %conv68.40.24
  %conv73.40.24 = trunc i32 %xor72.40.24 to i8
  store i8 %conv73.40.24, i8* %arrayidx70.24, align 1
  %scevgep20.41.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 41
  %15844 = load i8, i8* %scevgep20.41.24, align 1
  %conv68.41.24 = zext i8 %15844 to i32
  %15845 = load i8, i8* %arrayidx70.24, align 1
  %conv71.41.24 = zext i8 %15845 to i32
  %xor72.41.24 = xor i32 %conv71.41.24, %conv68.41.24
  %conv73.41.24 = trunc i32 %xor72.41.24 to i8
  store i8 %conv73.41.24, i8* %arrayidx70.24, align 1
  %scevgep20.42.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 42
  %15846 = load i8, i8* %scevgep20.42.24, align 1
  %conv68.42.24 = zext i8 %15846 to i32
  %15847 = load i8, i8* %arrayidx70.24, align 1
  %conv71.42.24 = zext i8 %15847 to i32
  %xor72.42.24 = xor i32 %conv71.42.24, %conv68.42.24
  %conv73.42.24 = trunc i32 %xor72.42.24 to i8
  store i8 %conv73.42.24, i8* %arrayidx70.24, align 1
  %scevgep20.43.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 43
  %15848 = load i8, i8* %scevgep20.43.24, align 1
  %conv68.43.24 = zext i8 %15848 to i32
  %15849 = load i8, i8* %arrayidx70.24, align 1
  %conv71.43.24 = zext i8 %15849 to i32
  %xor72.43.24 = xor i32 %conv71.43.24, %conv68.43.24
  %conv73.43.24 = trunc i32 %xor72.43.24 to i8
  store i8 %conv73.43.24, i8* %arrayidx70.24, align 1
  %scevgep20.44.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 44
  %15850 = load i8, i8* %scevgep20.44.24, align 1
  %conv68.44.24 = zext i8 %15850 to i32
  %15851 = load i8, i8* %arrayidx70.24, align 1
  %conv71.44.24 = zext i8 %15851 to i32
  %xor72.44.24 = xor i32 %conv71.44.24, %conv68.44.24
  %conv73.44.24 = trunc i32 %xor72.44.24 to i8
  store i8 %conv73.44.24, i8* %arrayidx70.24, align 1
  %scevgep20.45.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 45
  %15852 = load i8, i8* %scevgep20.45.24, align 1
  %conv68.45.24 = zext i8 %15852 to i32
  %15853 = load i8, i8* %arrayidx70.24, align 1
  %conv71.45.24 = zext i8 %15853 to i32
  %xor72.45.24 = xor i32 %conv71.45.24, %conv68.45.24
  %conv73.45.24 = trunc i32 %xor72.45.24 to i8
  store i8 %conv73.45.24, i8* %arrayidx70.24, align 1
  %scevgep20.46.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 46
  %15854 = load i8, i8* %scevgep20.46.24, align 1
  %conv68.46.24 = zext i8 %15854 to i32
  %15855 = load i8, i8* %arrayidx70.24, align 1
  %conv71.46.24 = zext i8 %15855 to i32
  %xor72.46.24 = xor i32 %conv71.46.24, %conv68.46.24
  %conv73.46.24 = trunc i32 %xor72.46.24 to i8
  store i8 %conv73.46.24, i8* %arrayidx70.24, align 1
  %scevgep20.47.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 47
  %15856 = load i8, i8* %scevgep20.47.24, align 1
  %conv68.47.24 = zext i8 %15856 to i32
  %15857 = load i8, i8* %arrayidx70.24, align 1
  %conv71.47.24 = zext i8 %15857 to i32
  %xor72.47.24 = xor i32 %conv71.47.24, %conv68.47.24
  %conv73.47.24 = trunc i32 %xor72.47.24 to i8
  store i8 %conv73.47.24, i8* %arrayidx70.24, align 1
  %scevgep20.48.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 48
  %15858 = load i8, i8* %scevgep20.48.24, align 1
  %conv68.48.24 = zext i8 %15858 to i32
  %15859 = load i8, i8* %arrayidx70.24, align 1
  %conv71.48.24 = zext i8 %15859 to i32
  %xor72.48.24 = xor i32 %conv71.48.24, %conv68.48.24
  %conv73.48.24 = trunc i32 %xor72.48.24 to i8
  store i8 %conv73.48.24, i8* %arrayidx70.24, align 1
  %scevgep20.49.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 49
  %15860 = load i8, i8* %scevgep20.49.24, align 1
  %conv68.49.24 = zext i8 %15860 to i32
  %15861 = load i8, i8* %arrayidx70.24, align 1
  %conv71.49.24 = zext i8 %15861 to i32
  %xor72.49.24 = xor i32 %conv71.49.24, %conv68.49.24
  %conv73.49.24 = trunc i32 %xor72.49.24 to i8
  store i8 %conv73.49.24, i8* %arrayidx70.24, align 1
  %scevgep20.50.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 50
  %15862 = load i8, i8* %scevgep20.50.24, align 1
  %conv68.50.24 = zext i8 %15862 to i32
  %15863 = load i8, i8* %arrayidx70.24, align 1
  %conv71.50.24 = zext i8 %15863 to i32
  %xor72.50.24 = xor i32 %conv71.50.24, %conv68.50.24
  %conv73.50.24 = trunc i32 %xor72.50.24 to i8
  store i8 %conv73.50.24, i8* %arrayidx70.24, align 1
  %scevgep20.51.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 51
  %15864 = load i8, i8* %scevgep20.51.24, align 1
  %conv68.51.24 = zext i8 %15864 to i32
  %15865 = load i8, i8* %arrayidx70.24, align 1
  %conv71.51.24 = zext i8 %15865 to i32
  %xor72.51.24 = xor i32 %conv71.51.24, %conv68.51.24
  %conv73.51.24 = trunc i32 %xor72.51.24 to i8
  store i8 %conv73.51.24, i8* %arrayidx70.24, align 1
  %scevgep20.52.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 52
  %15866 = load i8, i8* %scevgep20.52.24, align 1
  %conv68.52.24 = zext i8 %15866 to i32
  %15867 = load i8, i8* %arrayidx70.24, align 1
  %conv71.52.24 = zext i8 %15867 to i32
  %xor72.52.24 = xor i32 %conv71.52.24, %conv68.52.24
  %conv73.52.24 = trunc i32 %xor72.52.24 to i8
  store i8 %conv73.52.24, i8* %arrayidx70.24, align 1
  %scevgep20.53.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 53
  %15868 = load i8, i8* %scevgep20.53.24, align 1
  %conv68.53.24 = zext i8 %15868 to i32
  %15869 = load i8, i8* %arrayidx70.24, align 1
  %conv71.53.24 = zext i8 %15869 to i32
  %xor72.53.24 = xor i32 %conv71.53.24, %conv68.53.24
  %conv73.53.24 = trunc i32 %xor72.53.24 to i8
  store i8 %conv73.53.24, i8* %arrayidx70.24, align 1
  %scevgep20.54.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 54
  %15870 = load i8, i8* %scevgep20.54.24, align 1
  %conv68.54.24 = zext i8 %15870 to i32
  %15871 = load i8, i8* %arrayidx70.24, align 1
  %conv71.54.24 = zext i8 %15871 to i32
  %xor72.54.24 = xor i32 %conv71.54.24, %conv68.54.24
  %conv73.54.24 = trunc i32 %xor72.54.24 to i8
  store i8 %conv73.54.24, i8* %arrayidx70.24, align 1
  %scevgep20.55.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 55
  %15872 = load i8, i8* %scevgep20.55.24, align 1
  %conv68.55.24 = zext i8 %15872 to i32
  %15873 = load i8, i8* %arrayidx70.24, align 1
  %conv71.55.24 = zext i8 %15873 to i32
  %xor72.55.24 = xor i32 %conv71.55.24, %conv68.55.24
  %conv73.55.24 = trunc i32 %xor72.55.24 to i8
  store i8 %conv73.55.24, i8* %arrayidx70.24, align 1
  %scevgep20.56.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 56
  %15874 = load i8, i8* %scevgep20.56.24, align 1
  %conv68.56.24 = zext i8 %15874 to i32
  %15875 = load i8, i8* %arrayidx70.24, align 1
  %conv71.56.24 = zext i8 %15875 to i32
  %xor72.56.24 = xor i32 %conv71.56.24, %conv68.56.24
  %conv73.56.24 = trunc i32 %xor72.56.24 to i8
  store i8 %conv73.56.24, i8* %arrayidx70.24, align 1
  %scevgep20.57.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 57
  %15876 = load i8, i8* %scevgep20.57.24, align 1
  %conv68.57.24 = zext i8 %15876 to i32
  %15877 = load i8, i8* %arrayidx70.24, align 1
  %conv71.57.24 = zext i8 %15877 to i32
  %xor72.57.24 = xor i32 %conv71.57.24, %conv68.57.24
  %conv73.57.24 = trunc i32 %xor72.57.24 to i8
  store i8 %conv73.57.24, i8* %arrayidx70.24, align 1
  %scevgep20.58.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 58
  %15878 = load i8, i8* %scevgep20.58.24, align 1
  %conv68.58.24 = zext i8 %15878 to i32
  %15879 = load i8, i8* %arrayidx70.24, align 1
  %conv71.58.24 = zext i8 %15879 to i32
  %xor72.58.24 = xor i32 %conv71.58.24, %conv68.58.24
  %conv73.58.24 = trunc i32 %xor72.58.24 to i8
  store i8 %conv73.58.24, i8* %arrayidx70.24, align 1
  %scevgep20.59.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 59
  %15880 = load i8, i8* %scevgep20.59.24, align 1
  %conv68.59.24 = zext i8 %15880 to i32
  %15881 = load i8, i8* %arrayidx70.24, align 1
  %conv71.59.24 = zext i8 %15881 to i32
  %xor72.59.24 = xor i32 %conv71.59.24, %conv68.59.24
  %conv73.59.24 = trunc i32 %xor72.59.24 to i8
  store i8 %conv73.59.24, i8* %arrayidx70.24, align 1
  %scevgep20.60.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 0, i64 60
  %15882 = load i8, i8* %scevgep20.60.24, align 1
  %conv68.60.24 = zext i8 %15882 to i32
  %15883 = load i8, i8* %arrayidx70.24, align 1
  %conv71.60.24 = zext i8 %15883 to i32
  %xor72.60.24 = xor i32 %conv71.60.24, %conv68.60.24
  %conv73.60.24 = trunc i32 %xor72.60.24 to i8
  store i8 %conv73.60.24, i8* %arrayidx70.24, align 1
  %scevgep19.24 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15761, i64 0, i64 1, i64 0
  %15884 = bitcast i8* %scevgep19.24 to [61 x [61 x i8]]*
  %arrayidx51.25 = getelementptr inbounds i8, i8* %a, i64 25
  %15885 = load i8, i8* %arrayidx51.25, align 1
  %arrayidx53.25 = getelementptr inbounds i8, i8* %b, i64 25
  %15886 = load i8, i8* %arrayidx53.25, align 1
  %call54.25 = call zeroext i8 @mult(i8 zeroext %15885, i8 zeroext %15886)
  %arrayidx56.25 = getelementptr inbounds i8, i8* %c, i64 25
  store i8 %call54.25, i8* %arrayidx56.25, align 1
  %arrayidx70.25 = getelementptr inbounds i8, i8* %c, i64 25
  %scevgep20.25294 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 0
  %15887 = load i8, i8* %scevgep20.25294, align 1
  %conv68.25295 = zext i8 %15887 to i32
  %15888 = load i8, i8* %arrayidx70.25, align 1
  %conv71.25296 = zext i8 %15888 to i32
  %xor72.25297 = xor i32 %conv71.25296, %conv68.25295
  %conv73.25298 = trunc i32 %xor72.25297 to i8
  store i8 %conv73.25298, i8* %arrayidx70.25, align 1
  %scevgep20.1.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 1
  %15889 = load i8, i8* %scevgep20.1.25, align 1
  %conv68.1.25 = zext i8 %15889 to i32
  %15890 = load i8, i8* %arrayidx70.25, align 1
  %conv71.1.25 = zext i8 %15890 to i32
  %xor72.1.25 = xor i32 %conv71.1.25, %conv68.1.25
  %conv73.1.25 = trunc i32 %xor72.1.25 to i8
  store i8 %conv73.1.25, i8* %arrayidx70.25, align 1
  %scevgep20.2.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 2
  %15891 = load i8, i8* %scevgep20.2.25, align 1
  %conv68.2.25 = zext i8 %15891 to i32
  %15892 = load i8, i8* %arrayidx70.25, align 1
  %conv71.2.25 = zext i8 %15892 to i32
  %xor72.2.25 = xor i32 %conv71.2.25, %conv68.2.25
  %conv73.2.25 = trunc i32 %xor72.2.25 to i8
  store i8 %conv73.2.25, i8* %arrayidx70.25, align 1
  %scevgep20.3.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 3
  %15893 = load i8, i8* %scevgep20.3.25, align 1
  %conv68.3.25 = zext i8 %15893 to i32
  %15894 = load i8, i8* %arrayidx70.25, align 1
  %conv71.3.25 = zext i8 %15894 to i32
  %xor72.3.25 = xor i32 %conv71.3.25, %conv68.3.25
  %conv73.3.25 = trunc i32 %xor72.3.25 to i8
  store i8 %conv73.3.25, i8* %arrayidx70.25, align 1
  %scevgep20.4.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 4
  %15895 = load i8, i8* %scevgep20.4.25, align 1
  %conv68.4.25 = zext i8 %15895 to i32
  %15896 = load i8, i8* %arrayidx70.25, align 1
  %conv71.4.25 = zext i8 %15896 to i32
  %xor72.4.25 = xor i32 %conv71.4.25, %conv68.4.25
  %conv73.4.25 = trunc i32 %xor72.4.25 to i8
  store i8 %conv73.4.25, i8* %arrayidx70.25, align 1
  %scevgep20.5.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 5
  %15897 = load i8, i8* %scevgep20.5.25, align 1
  %conv68.5.25 = zext i8 %15897 to i32
  %15898 = load i8, i8* %arrayidx70.25, align 1
  %conv71.5.25 = zext i8 %15898 to i32
  %xor72.5.25 = xor i32 %conv71.5.25, %conv68.5.25
  %conv73.5.25 = trunc i32 %xor72.5.25 to i8
  store i8 %conv73.5.25, i8* %arrayidx70.25, align 1
  %scevgep20.6.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 6
  %15899 = load i8, i8* %scevgep20.6.25, align 1
  %conv68.6.25 = zext i8 %15899 to i32
  %15900 = load i8, i8* %arrayidx70.25, align 1
  %conv71.6.25 = zext i8 %15900 to i32
  %xor72.6.25 = xor i32 %conv71.6.25, %conv68.6.25
  %conv73.6.25 = trunc i32 %xor72.6.25 to i8
  store i8 %conv73.6.25, i8* %arrayidx70.25, align 1
  %scevgep20.7.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 7
  %15901 = load i8, i8* %scevgep20.7.25, align 1
  %conv68.7.25 = zext i8 %15901 to i32
  %15902 = load i8, i8* %arrayidx70.25, align 1
  %conv71.7.25 = zext i8 %15902 to i32
  %xor72.7.25 = xor i32 %conv71.7.25, %conv68.7.25
  %conv73.7.25 = trunc i32 %xor72.7.25 to i8
  store i8 %conv73.7.25, i8* %arrayidx70.25, align 1
  %scevgep20.8.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 8
  %15903 = load i8, i8* %scevgep20.8.25, align 1
  %conv68.8.25 = zext i8 %15903 to i32
  %15904 = load i8, i8* %arrayidx70.25, align 1
  %conv71.8.25 = zext i8 %15904 to i32
  %xor72.8.25 = xor i32 %conv71.8.25, %conv68.8.25
  %conv73.8.25 = trunc i32 %xor72.8.25 to i8
  store i8 %conv73.8.25, i8* %arrayidx70.25, align 1
  %scevgep20.9.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 9
  %15905 = load i8, i8* %scevgep20.9.25, align 1
  %conv68.9.25 = zext i8 %15905 to i32
  %15906 = load i8, i8* %arrayidx70.25, align 1
  %conv71.9.25 = zext i8 %15906 to i32
  %xor72.9.25 = xor i32 %conv71.9.25, %conv68.9.25
  %conv73.9.25 = trunc i32 %xor72.9.25 to i8
  store i8 %conv73.9.25, i8* %arrayidx70.25, align 1
  %scevgep20.10.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 10
  %15907 = load i8, i8* %scevgep20.10.25, align 1
  %conv68.10.25 = zext i8 %15907 to i32
  %15908 = load i8, i8* %arrayidx70.25, align 1
  %conv71.10.25 = zext i8 %15908 to i32
  %xor72.10.25 = xor i32 %conv71.10.25, %conv68.10.25
  %conv73.10.25 = trunc i32 %xor72.10.25 to i8
  store i8 %conv73.10.25, i8* %arrayidx70.25, align 1
  %scevgep20.11.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 11
  %15909 = load i8, i8* %scevgep20.11.25, align 1
  %conv68.11.25 = zext i8 %15909 to i32
  %15910 = load i8, i8* %arrayidx70.25, align 1
  %conv71.11.25 = zext i8 %15910 to i32
  %xor72.11.25 = xor i32 %conv71.11.25, %conv68.11.25
  %conv73.11.25 = trunc i32 %xor72.11.25 to i8
  store i8 %conv73.11.25, i8* %arrayidx70.25, align 1
  %scevgep20.12.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 12
  %15911 = load i8, i8* %scevgep20.12.25, align 1
  %conv68.12.25 = zext i8 %15911 to i32
  %15912 = load i8, i8* %arrayidx70.25, align 1
  %conv71.12.25 = zext i8 %15912 to i32
  %xor72.12.25 = xor i32 %conv71.12.25, %conv68.12.25
  %conv73.12.25 = trunc i32 %xor72.12.25 to i8
  store i8 %conv73.12.25, i8* %arrayidx70.25, align 1
  %scevgep20.13.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 13
  %15913 = load i8, i8* %scevgep20.13.25, align 1
  %conv68.13.25 = zext i8 %15913 to i32
  %15914 = load i8, i8* %arrayidx70.25, align 1
  %conv71.13.25 = zext i8 %15914 to i32
  %xor72.13.25 = xor i32 %conv71.13.25, %conv68.13.25
  %conv73.13.25 = trunc i32 %xor72.13.25 to i8
  store i8 %conv73.13.25, i8* %arrayidx70.25, align 1
  %scevgep20.14.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 14
  %15915 = load i8, i8* %scevgep20.14.25, align 1
  %conv68.14.25 = zext i8 %15915 to i32
  %15916 = load i8, i8* %arrayidx70.25, align 1
  %conv71.14.25 = zext i8 %15916 to i32
  %xor72.14.25 = xor i32 %conv71.14.25, %conv68.14.25
  %conv73.14.25 = trunc i32 %xor72.14.25 to i8
  store i8 %conv73.14.25, i8* %arrayidx70.25, align 1
  %scevgep20.15.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 15
  %15917 = load i8, i8* %scevgep20.15.25, align 1
  %conv68.15.25 = zext i8 %15917 to i32
  %15918 = load i8, i8* %arrayidx70.25, align 1
  %conv71.15.25 = zext i8 %15918 to i32
  %xor72.15.25 = xor i32 %conv71.15.25, %conv68.15.25
  %conv73.15.25 = trunc i32 %xor72.15.25 to i8
  store i8 %conv73.15.25, i8* %arrayidx70.25, align 1
  %scevgep20.16.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 16
  %15919 = load i8, i8* %scevgep20.16.25, align 1
  %conv68.16.25 = zext i8 %15919 to i32
  %15920 = load i8, i8* %arrayidx70.25, align 1
  %conv71.16.25 = zext i8 %15920 to i32
  %xor72.16.25 = xor i32 %conv71.16.25, %conv68.16.25
  %conv73.16.25 = trunc i32 %xor72.16.25 to i8
  store i8 %conv73.16.25, i8* %arrayidx70.25, align 1
  %scevgep20.17.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 17
  %15921 = load i8, i8* %scevgep20.17.25, align 1
  %conv68.17.25 = zext i8 %15921 to i32
  %15922 = load i8, i8* %arrayidx70.25, align 1
  %conv71.17.25 = zext i8 %15922 to i32
  %xor72.17.25 = xor i32 %conv71.17.25, %conv68.17.25
  %conv73.17.25 = trunc i32 %xor72.17.25 to i8
  store i8 %conv73.17.25, i8* %arrayidx70.25, align 1
  %scevgep20.18.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 18
  %15923 = load i8, i8* %scevgep20.18.25, align 1
  %conv68.18.25 = zext i8 %15923 to i32
  %15924 = load i8, i8* %arrayidx70.25, align 1
  %conv71.18.25 = zext i8 %15924 to i32
  %xor72.18.25 = xor i32 %conv71.18.25, %conv68.18.25
  %conv73.18.25 = trunc i32 %xor72.18.25 to i8
  store i8 %conv73.18.25, i8* %arrayidx70.25, align 1
  %scevgep20.19.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 19
  %15925 = load i8, i8* %scevgep20.19.25, align 1
  %conv68.19.25 = zext i8 %15925 to i32
  %15926 = load i8, i8* %arrayidx70.25, align 1
  %conv71.19.25 = zext i8 %15926 to i32
  %xor72.19.25 = xor i32 %conv71.19.25, %conv68.19.25
  %conv73.19.25 = trunc i32 %xor72.19.25 to i8
  store i8 %conv73.19.25, i8* %arrayidx70.25, align 1
  %scevgep20.20.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 20
  %15927 = load i8, i8* %scevgep20.20.25, align 1
  %conv68.20.25 = zext i8 %15927 to i32
  %15928 = load i8, i8* %arrayidx70.25, align 1
  %conv71.20.25 = zext i8 %15928 to i32
  %xor72.20.25 = xor i32 %conv71.20.25, %conv68.20.25
  %conv73.20.25 = trunc i32 %xor72.20.25 to i8
  store i8 %conv73.20.25, i8* %arrayidx70.25, align 1
  %scevgep20.21.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 21
  %15929 = load i8, i8* %scevgep20.21.25, align 1
  %conv68.21.25 = zext i8 %15929 to i32
  %15930 = load i8, i8* %arrayidx70.25, align 1
  %conv71.21.25 = zext i8 %15930 to i32
  %xor72.21.25 = xor i32 %conv71.21.25, %conv68.21.25
  %conv73.21.25 = trunc i32 %xor72.21.25 to i8
  store i8 %conv73.21.25, i8* %arrayidx70.25, align 1
  %scevgep20.22.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 22
  %15931 = load i8, i8* %scevgep20.22.25, align 1
  %conv68.22.25 = zext i8 %15931 to i32
  %15932 = load i8, i8* %arrayidx70.25, align 1
  %conv71.22.25 = zext i8 %15932 to i32
  %xor72.22.25 = xor i32 %conv71.22.25, %conv68.22.25
  %conv73.22.25 = trunc i32 %xor72.22.25 to i8
  store i8 %conv73.22.25, i8* %arrayidx70.25, align 1
  %scevgep20.23.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 23
  %15933 = load i8, i8* %scevgep20.23.25, align 1
  %conv68.23.25 = zext i8 %15933 to i32
  %15934 = load i8, i8* %arrayidx70.25, align 1
  %conv71.23.25 = zext i8 %15934 to i32
  %xor72.23.25 = xor i32 %conv71.23.25, %conv68.23.25
  %conv73.23.25 = trunc i32 %xor72.23.25 to i8
  store i8 %conv73.23.25, i8* %arrayidx70.25, align 1
  %scevgep20.24.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 24
  %15935 = load i8, i8* %scevgep20.24.25, align 1
  %conv68.24.25 = zext i8 %15935 to i32
  %15936 = load i8, i8* %arrayidx70.25, align 1
  %conv71.24.25 = zext i8 %15936 to i32
  %xor72.24.25 = xor i32 %conv71.24.25, %conv68.24.25
  %conv73.24.25 = trunc i32 %xor72.24.25 to i8
  store i8 %conv73.24.25, i8* %arrayidx70.25, align 1
  %scevgep20.26.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 26
  %15937 = load i8, i8* %scevgep20.26.25, align 1
  %conv68.26.25 = zext i8 %15937 to i32
  %15938 = load i8, i8* %arrayidx70.25, align 1
  %conv71.26.25 = zext i8 %15938 to i32
  %xor72.26.25 = xor i32 %conv71.26.25, %conv68.26.25
  %conv73.26.25 = trunc i32 %xor72.26.25 to i8
  store i8 %conv73.26.25, i8* %arrayidx70.25, align 1
  %scevgep20.27.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 27
  %15939 = load i8, i8* %scevgep20.27.25, align 1
  %conv68.27.25 = zext i8 %15939 to i32
  %15940 = load i8, i8* %arrayidx70.25, align 1
  %conv71.27.25 = zext i8 %15940 to i32
  %xor72.27.25 = xor i32 %conv71.27.25, %conv68.27.25
  %conv73.27.25 = trunc i32 %xor72.27.25 to i8
  store i8 %conv73.27.25, i8* %arrayidx70.25, align 1
  %scevgep20.28.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 28
  %15941 = load i8, i8* %scevgep20.28.25, align 1
  %conv68.28.25 = zext i8 %15941 to i32
  %15942 = load i8, i8* %arrayidx70.25, align 1
  %conv71.28.25 = zext i8 %15942 to i32
  %xor72.28.25 = xor i32 %conv71.28.25, %conv68.28.25
  %conv73.28.25 = trunc i32 %xor72.28.25 to i8
  store i8 %conv73.28.25, i8* %arrayidx70.25, align 1
  %scevgep20.29.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 29
  %15943 = load i8, i8* %scevgep20.29.25, align 1
  %conv68.29.25 = zext i8 %15943 to i32
  %15944 = load i8, i8* %arrayidx70.25, align 1
  %conv71.29.25 = zext i8 %15944 to i32
  %xor72.29.25 = xor i32 %conv71.29.25, %conv68.29.25
  %conv73.29.25 = trunc i32 %xor72.29.25 to i8
  store i8 %conv73.29.25, i8* %arrayidx70.25, align 1
  %scevgep20.30.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 30
  %15945 = load i8, i8* %scevgep20.30.25, align 1
  %conv68.30.25 = zext i8 %15945 to i32
  %15946 = load i8, i8* %arrayidx70.25, align 1
  %conv71.30.25 = zext i8 %15946 to i32
  %xor72.30.25 = xor i32 %conv71.30.25, %conv68.30.25
  %conv73.30.25 = trunc i32 %xor72.30.25 to i8
  store i8 %conv73.30.25, i8* %arrayidx70.25, align 1
  %scevgep20.31.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 31
  %15947 = load i8, i8* %scevgep20.31.25, align 1
  %conv68.31.25 = zext i8 %15947 to i32
  %15948 = load i8, i8* %arrayidx70.25, align 1
  %conv71.31.25 = zext i8 %15948 to i32
  %xor72.31.25 = xor i32 %conv71.31.25, %conv68.31.25
  %conv73.31.25 = trunc i32 %xor72.31.25 to i8
  store i8 %conv73.31.25, i8* %arrayidx70.25, align 1
  %scevgep20.32.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 32
  %15949 = load i8, i8* %scevgep20.32.25, align 1
  %conv68.32.25 = zext i8 %15949 to i32
  %15950 = load i8, i8* %arrayidx70.25, align 1
  %conv71.32.25 = zext i8 %15950 to i32
  %xor72.32.25 = xor i32 %conv71.32.25, %conv68.32.25
  %conv73.32.25 = trunc i32 %xor72.32.25 to i8
  store i8 %conv73.32.25, i8* %arrayidx70.25, align 1
  %scevgep20.33.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 33
  %15951 = load i8, i8* %scevgep20.33.25, align 1
  %conv68.33.25 = zext i8 %15951 to i32
  %15952 = load i8, i8* %arrayidx70.25, align 1
  %conv71.33.25 = zext i8 %15952 to i32
  %xor72.33.25 = xor i32 %conv71.33.25, %conv68.33.25
  %conv73.33.25 = trunc i32 %xor72.33.25 to i8
  store i8 %conv73.33.25, i8* %arrayidx70.25, align 1
  %scevgep20.34.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 34
  %15953 = load i8, i8* %scevgep20.34.25, align 1
  %conv68.34.25 = zext i8 %15953 to i32
  %15954 = load i8, i8* %arrayidx70.25, align 1
  %conv71.34.25 = zext i8 %15954 to i32
  %xor72.34.25 = xor i32 %conv71.34.25, %conv68.34.25
  %conv73.34.25 = trunc i32 %xor72.34.25 to i8
  store i8 %conv73.34.25, i8* %arrayidx70.25, align 1
  %scevgep20.35.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 35
  %15955 = load i8, i8* %scevgep20.35.25, align 1
  %conv68.35.25 = zext i8 %15955 to i32
  %15956 = load i8, i8* %arrayidx70.25, align 1
  %conv71.35.25 = zext i8 %15956 to i32
  %xor72.35.25 = xor i32 %conv71.35.25, %conv68.35.25
  %conv73.35.25 = trunc i32 %xor72.35.25 to i8
  store i8 %conv73.35.25, i8* %arrayidx70.25, align 1
  %scevgep20.36.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 36
  %15957 = load i8, i8* %scevgep20.36.25, align 1
  %conv68.36.25 = zext i8 %15957 to i32
  %15958 = load i8, i8* %arrayidx70.25, align 1
  %conv71.36.25 = zext i8 %15958 to i32
  %xor72.36.25 = xor i32 %conv71.36.25, %conv68.36.25
  %conv73.36.25 = trunc i32 %xor72.36.25 to i8
  store i8 %conv73.36.25, i8* %arrayidx70.25, align 1
  %scevgep20.37.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 37
  %15959 = load i8, i8* %scevgep20.37.25, align 1
  %conv68.37.25 = zext i8 %15959 to i32
  %15960 = load i8, i8* %arrayidx70.25, align 1
  %conv71.37.25 = zext i8 %15960 to i32
  %xor72.37.25 = xor i32 %conv71.37.25, %conv68.37.25
  %conv73.37.25 = trunc i32 %xor72.37.25 to i8
  store i8 %conv73.37.25, i8* %arrayidx70.25, align 1
  %scevgep20.38.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 38
  %15961 = load i8, i8* %scevgep20.38.25, align 1
  %conv68.38.25 = zext i8 %15961 to i32
  %15962 = load i8, i8* %arrayidx70.25, align 1
  %conv71.38.25 = zext i8 %15962 to i32
  %xor72.38.25 = xor i32 %conv71.38.25, %conv68.38.25
  %conv73.38.25 = trunc i32 %xor72.38.25 to i8
  store i8 %conv73.38.25, i8* %arrayidx70.25, align 1
  %scevgep20.39.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 39
  %15963 = load i8, i8* %scevgep20.39.25, align 1
  %conv68.39.25 = zext i8 %15963 to i32
  %15964 = load i8, i8* %arrayidx70.25, align 1
  %conv71.39.25 = zext i8 %15964 to i32
  %xor72.39.25 = xor i32 %conv71.39.25, %conv68.39.25
  %conv73.39.25 = trunc i32 %xor72.39.25 to i8
  store i8 %conv73.39.25, i8* %arrayidx70.25, align 1
  %scevgep20.40.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 40
  %15965 = load i8, i8* %scevgep20.40.25, align 1
  %conv68.40.25 = zext i8 %15965 to i32
  %15966 = load i8, i8* %arrayidx70.25, align 1
  %conv71.40.25 = zext i8 %15966 to i32
  %xor72.40.25 = xor i32 %conv71.40.25, %conv68.40.25
  %conv73.40.25 = trunc i32 %xor72.40.25 to i8
  store i8 %conv73.40.25, i8* %arrayidx70.25, align 1
  %scevgep20.41.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 41
  %15967 = load i8, i8* %scevgep20.41.25, align 1
  %conv68.41.25 = zext i8 %15967 to i32
  %15968 = load i8, i8* %arrayidx70.25, align 1
  %conv71.41.25 = zext i8 %15968 to i32
  %xor72.41.25 = xor i32 %conv71.41.25, %conv68.41.25
  %conv73.41.25 = trunc i32 %xor72.41.25 to i8
  store i8 %conv73.41.25, i8* %arrayidx70.25, align 1
  %scevgep20.42.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 42
  %15969 = load i8, i8* %scevgep20.42.25, align 1
  %conv68.42.25 = zext i8 %15969 to i32
  %15970 = load i8, i8* %arrayidx70.25, align 1
  %conv71.42.25 = zext i8 %15970 to i32
  %xor72.42.25 = xor i32 %conv71.42.25, %conv68.42.25
  %conv73.42.25 = trunc i32 %xor72.42.25 to i8
  store i8 %conv73.42.25, i8* %arrayidx70.25, align 1
  %scevgep20.43.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 43
  %15971 = load i8, i8* %scevgep20.43.25, align 1
  %conv68.43.25 = zext i8 %15971 to i32
  %15972 = load i8, i8* %arrayidx70.25, align 1
  %conv71.43.25 = zext i8 %15972 to i32
  %xor72.43.25 = xor i32 %conv71.43.25, %conv68.43.25
  %conv73.43.25 = trunc i32 %xor72.43.25 to i8
  store i8 %conv73.43.25, i8* %arrayidx70.25, align 1
  %scevgep20.44.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 44
  %15973 = load i8, i8* %scevgep20.44.25, align 1
  %conv68.44.25 = zext i8 %15973 to i32
  %15974 = load i8, i8* %arrayidx70.25, align 1
  %conv71.44.25 = zext i8 %15974 to i32
  %xor72.44.25 = xor i32 %conv71.44.25, %conv68.44.25
  %conv73.44.25 = trunc i32 %xor72.44.25 to i8
  store i8 %conv73.44.25, i8* %arrayidx70.25, align 1
  %scevgep20.45.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 45
  %15975 = load i8, i8* %scevgep20.45.25, align 1
  %conv68.45.25 = zext i8 %15975 to i32
  %15976 = load i8, i8* %arrayidx70.25, align 1
  %conv71.45.25 = zext i8 %15976 to i32
  %xor72.45.25 = xor i32 %conv71.45.25, %conv68.45.25
  %conv73.45.25 = trunc i32 %xor72.45.25 to i8
  store i8 %conv73.45.25, i8* %arrayidx70.25, align 1
  %scevgep20.46.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 46
  %15977 = load i8, i8* %scevgep20.46.25, align 1
  %conv68.46.25 = zext i8 %15977 to i32
  %15978 = load i8, i8* %arrayidx70.25, align 1
  %conv71.46.25 = zext i8 %15978 to i32
  %xor72.46.25 = xor i32 %conv71.46.25, %conv68.46.25
  %conv73.46.25 = trunc i32 %xor72.46.25 to i8
  store i8 %conv73.46.25, i8* %arrayidx70.25, align 1
  %scevgep20.47.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 47
  %15979 = load i8, i8* %scevgep20.47.25, align 1
  %conv68.47.25 = zext i8 %15979 to i32
  %15980 = load i8, i8* %arrayidx70.25, align 1
  %conv71.47.25 = zext i8 %15980 to i32
  %xor72.47.25 = xor i32 %conv71.47.25, %conv68.47.25
  %conv73.47.25 = trunc i32 %xor72.47.25 to i8
  store i8 %conv73.47.25, i8* %arrayidx70.25, align 1
  %scevgep20.48.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 48
  %15981 = load i8, i8* %scevgep20.48.25, align 1
  %conv68.48.25 = zext i8 %15981 to i32
  %15982 = load i8, i8* %arrayidx70.25, align 1
  %conv71.48.25 = zext i8 %15982 to i32
  %xor72.48.25 = xor i32 %conv71.48.25, %conv68.48.25
  %conv73.48.25 = trunc i32 %xor72.48.25 to i8
  store i8 %conv73.48.25, i8* %arrayidx70.25, align 1
  %scevgep20.49.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 49
  %15983 = load i8, i8* %scevgep20.49.25, align 1
  %conv68.49.25 = zext i8 %15983 to i32
  %15984 = load i8, i8* %arrayidx70.25, align 1
  %conv71.49.25 = zext i8 %15984 to i32
  %xor72.49.25 = xor i32 %conv71.49.25, %conv68.49.25
  %conv73.49.25 = trunc i32 %xor72.49.25 to i8
  store i8 %conv73.49.25, i8* %arrayidx70.25, align 1
  %scevgep20.50.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 50
  %15985 = load i8, i8* %scevgep20.50.25, align 1
  %conv68.50.25 = zext i8 %15985 to i32
  %15986 = load i8, i8* %arrayidx70.25, align 1
  %conv71.50.25 = zext i8 %15986 to i32
  %xor72.50.25 = xor i32 %conv71.50.25, %conv68.50.25
  %conv73.50.25 = trunc i32 %xor72.50.25 to i8
  store i8 %conv73.50.25, i8* %arrayidx70.25, align 1
  %scevgep20.51.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 51
  %15987 = load i8, i8* %scevgep20.51.25, align 1
  %conv68.51.25 = zext i8 %15987 to i32
  %15988 = load i8, i8* %arrayidx70.25, align 1
  %conv71.51.25 = zext i8 %15988 to i32
  %xor72.51.25 = xor i32 %conv71.51.25, %conv68.51.25
  %conv73.51.25 = trunc i32 %xor72.51.25 to i8
  store i8 %conv73.51.25, i8* %arrayidx70.25, align 1
  %scevgep20.52.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 52
  %15989 = load i8, i8* %scevgep20.52.25, align 1
  %conv68.52.25 = zext i8 %15989 to i32
  %15990 = load i8, i8* %arrayidx70.25, align 1
  %conv71.52.25 = zext i8 %15990 to i32
  %xor72.52.25 = xor i32 %conv71.52.25, %conv68.52.25
  %conv73.52.25 = trunc i32 %xor72.52.25 to i8
  store i8 %conv73.52.25, i8* %arrayidx70.25, align 1
  %scevgep20.53.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 53
  %15991 = load i8, i8* %scevgep20.53.25, align 1
  %conv68.53.25 = zext i8 %15991 to i32
  %15992 = load i8, i8* %arrayidx70.25, align 1
  %conv71.53.25 = zext i8 %15992 to i32
  %xor72.53.25 = xor i32 %conv71.53.25, %conv68.53.25
  %conv73.53.25 = trunc i32 %xor72.53.25 to i8
  store i8 %conv73.53.25, i8* %arrayidx70.25, align 1
  %scevgep20.54.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 54
  %15993 = load i8, i8* %scevgep20.54.25, align 1
  %conv68.54.25 = zext i8 %15993 to i32
  %15994 = load i8, i8* %arrayidx70.25, align 1
  %conv71.54.25 = zext i8 %15994 to i32
  %xor72.54.25 = xor i32 %conv71.54.25, %conv68.54.25
  %conv73.54.25 = trunc i32 %xor72.54.25 to i8
  store i8 %conv73.54.25, i8* %arrayidx70.25, align 1
  %scevgep20.55.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 55
  %15995 = load i8, i8* %scevgep20.55.25, align 1
  %conv68.55.25 = zext i8 %15995 to i32
  %15996 = load i8, i8* %arrayidx70.25, align 1
  %conv71.55.25 = zext i8 %15996 to i32
  %xor72.55.25 = xor i32 %conv71.55.25, %conv68.55.25
  %conv73.55.25 = trunc i32 %xor72.55.25 to i8
  store i8 %conv73.55.25, i8* %arrayidx70.25, align 1
  %scevgep20.56.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 56
  %15997 = load i8, i8* %scevgep20.56.25, align 1
  %conv68.56.25 = zext i8 %15997 to i32
  %15998 = load i8, i8* %arrayidx70.25, align 1
  %conv71.56.25 = zext i8 %15998 to i32
  %xor72.56.25 = xor i32 %conv71.56.25, %conv68.56.25
  %conv73.56.25 = trunc i32 %xor72.56.25 to i8
  store i8 %conv73.56.25, i8* %arrayidx70.25, align 1
  %scevgep20.57.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 57
  %15999 = load i8, i8* %scevgep20.57.25, align 1
  %conv68.57.25 = zext i8 %15999 to i32
  %16000 = load i8, i8* %arrayidx70.25, align 1
  %conv71.57.25 = zext i8 %16000 to i32
  %xor72.57.25 = xor i32 %conv71.57.25, %conv68.57.25
  %conv73.57.25 = trunc i32 %xor72.57.25 to i8
  store i8 %conv73.57.25, i8* %arrayidx70.25, align 1
  %scevgep20.58.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 58
  %16001 = load i8, i8* %scevgep20.58.25, align 1
  %conv68.58.25 = zext i8 %16001 to i32
  %16002 = load i8, i8* %arrayidx70.25, align 1
  %conv71.58.25 = zext i8 %16002 to i32
  %xor72.58.25 = xor i32 %conv71.58.25, %conv68.58.25
  %conv73.58.25 = trunc i32 %xor72.58.25 to i8
  store i8 %conv73.58.25, i8* %arrayidx70.25, align 1
  %scevgep20.59.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 59
  %16003 = load i8, i8* %scevgep20.59.25, align 1
  %conv68.59.25 = zext i8 %16003 to i32
  %16004 = load i8, i8* %arrayidx70.25, align 1
  %conv71.59.25 = zext i8 %16004 to i32
  %xor72.59.25 = xor i32 %conv71.59.25, %conv68.59.25
  %conv73.59.25 = trunc i32 %xor72.59.25 to i8
  store i8 %conv73.59.25, i8* %arrayidx70.25, align 1
  %scevgep20.60.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 0, i64 60
  %16005 = load i8, i8* %scevgep20.60.25, align 1
  %conv68.60.25 = zext i8 %16005 to i32
  %16006 = load i8, i8* %arrayidx70.25, align 1
  %conv71.60.25 = zext i8 %16006 to i32
  %xor72.60.25 = xor i32 %conv71.60.25, %conv68.60.25
  %conv73.60.25 = trunc i32 %xor72.60.25 to i8
  store i8 %conv73.60.25, i8* %arrayidx70.25, align 1
  %scevgep19.25 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %15884, i64 0, i64 1, i64 0
  %16007 = bitcast i8* %scevgep19.25 to [61 x [61 x i8]]*
  %arrayidx51.26 = getelementptr inbounds i8, i8* %a, i64 26
  %16008 = load i8, i8* %arrayidx51.26, align 1
  %arrayidx53.26 = getelementptr inbounds i8, i8* %b, i64 26
  %16009 = load i8, i8* %arrayidx53.26, align 1
  %call54.26 = call zeroext i8 @mult(i8 zeroext %16008, i8 zeroext %16009)
  %arrayidx56.26 = getelementptr inbounds i8, i8* %c, i64 26
  store i8 %call54.26, i8* %arrayidx56.26, align 1
  %arrayidx70.26 = getelementptr inbounds i8, i8* %c, i64 26
  %scevgep20.26304 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 0
  %16010 = load i8, i8* %scevgep20.26304, align 1
  %conv68.26305 = zext i8 %16010 to i32
  %16011 = load i8, i8* %arrayidx70.26, align 1
  %conv71.26306 = zext i8 %16011 to i32
  %xor72.26307 = xor i32 %conv71.26306, %conv68.26305
  %conv73.26308 = trunc i32 %xor72.26307 to i8
  store i8 %conv73.26308, i8* %arrayidx70.26, align 1
  %scevgep20.1.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 1
  %16012 = load i8, i8* %scevgep20.1.26, align 1
  %conv68.1.26 = zext i8 %16012 to i32
  %16013 = load i8, i8* %arrayidx70.26, align 1
  %conv71.1.26 = zext i8 %16013 to i32
  %xor72.1.26 = xor i32 %conv71.1.26, %conv68.1.26
  %conv73.1.26 = trunc i32 %xor72.1.26 to i8
  store i8 %conv73.1.26, i8* %arrayidx70.26, align 1
  %scevgep20.2.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 2
  %16014 = load i8, i8* %scevgep20.2.26, align 1
  %conv68.2.26 = zext i8 %16014 to i32
  %16015 = load i8, i8* %arrayidx70.26, align 1
  %conv71.2.26 = zext i8 %16015 to i32
  %xor72.2.26 = xor i32 %conv71.2.26, %conv68.2.26
  %conv73.2.26 = trunc i32 %xor72.2.26 to i8
  store i8 %conv73.2.26, i8* %arrayidx70.26, align 1
  %scevgep20.3.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 3
  %16016 = load i8, i8* %scevgep20.3.26, align 1
  %conv68.3.26 = zext i8 %16016 to i32
  %16017 = load i8, i8* %arrayidx70.26, align 1
  %conv71.3.26 = zext i8 %16017 to i32
  %xor72.3.26 = xor i32 %conv71.3.26, %conv68.3.26
  %conv73.3.26 = trunc i32 %xor72.3.26 to i8
  store i8 %conv73.3.26, i8* %arrayidx70.26, align 1
  %scevgep20.4.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 4
  %16018 = load i8, i8* %scevgep20.4.26, align 1
  %conv68.4.26 = zext i8 %16018 to i32
  %16019 = load i8, i8* %arrayidx70.26, align 1
  %conv71.4.26 = zext i8 %16019 to i32
  %xor72.4.26 = xor i32 %conv71.4.26, %conv68.4.26
  %conv73.4.26 = trunc i32 %xor72.4.26 to i8
  store i8 %conv73.4.26, i8* %arrayidx70.26, align 1
  %scevgep20.5.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 5
  %16020 = load i8, i8* %scevgep20.5.26, align 1
  %conv68.5.26 = zext i8 %16020 to i32
  %16021 = load i8, i8* %arrayidx70.26, align 1
  %conv71.5.26 = zext i8 %16021 to i32
  %xor72.5.26 = xor i32 %conv71.5.26, %conv68.5.26
  %conv73.5.26 = trunc i32 %xor72.5.26 to i8
  store i8 %conv73.5.26, i8* %arrayidx70.26, align 1
  %scevgep20.6.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 6
  %16022 = load i8, i8* %scevgep20.6.26, align 1
  %conv68.6.26 = zext i8 %16022 to i32
  %16023 = load i8, i8* %arrayidx70.26, align 1
  %conv71.6.26 = zext i8 %16023 to i32
  %xor72.6.26 = xor i32 %conv71.6.26, %conv68.6.26
  %conv73.6.26 = trunc i32 %xor72.6.26 to i8
  store i8 %conv73.6.26, i8* %arrayidx70.26, align 1
  %scevgep20.7.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 7
  %16024 = load i8, i8* %scevgep20.7.26, align 1
  %conv68.7.26 = zext i8 %16024 to i32
  %16025 = load i8, i8* %arrayidx70.26, align 1
  %conv71.7.26 = zext i8 %16025 to i32
  %xor72.7.26 = xor i32 %conv71.7.26, %conv68.7.26
  %conv73.7.26 = trunc i32 %xor72.7.26 to i8
  store i8 %conv73.7.26, i8* %arrayidx70.26, align 1
  %scevgep20.8.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 8
  %16026 = load i8, i8* %scevgep20.8.26, align 1
  %conv68.8.26 = zext i8 %16026 to i32
  %16027 = load i8, i8* %arrayidx70.26, align 1
  %conv71.8.26 = zext i8 %16027 to i32
  %xor72.8.26 = xor i32 %conv71.8.26, %conv68.8.26
  %conv73.8.26 = trunc i32 %xor72.8.26 to i8
  store i8 %conv73.8.26, i8* %arrayidx70.26, align 1
  %scevgep20.9.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 9
  %16028 = load i8, i8* %scevgep20.9.26, align 1
  %conv68.9.26 = zext i8 %16028 to i32
  %16029 = load i8, i8* %arrayidx70.26, align 1
  %conv71.9.26 = zext i8 %16029 to i32
  %xor72.9.26 = xor i32 %conv71.9.26, %conv68.9.26
  %conv73.9.26 = trunc i32 %xor72.9.26 to i8
  store i8 %conv73.9.26, i8* %arrayidx70.26, align 1
  %scevgep20.10.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 10
  %16030 = load i8, i8* %scevgep20.10.26, align 1
  %conv68.10.26 = zext i8 %16030 to i32
  %16031 = load i8, i8* %arrayidx70.26, align 1
  %conv71.10.26 = zext i8 %16031 to i32
  %xor72.10.26 = xor i32 %conv71.10.26, %conv68.10.26
  %conv73.10.26 = trunc i32 %xor72.10.26 to i8
  store i8 %conv73.10.26, i8* %arrayidx70.26, align 1
  %scevgep20.11.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 11
  %16032 = load i8, i8* %scevgep20.11.26, align 1
  %conv68.11.26 = zext i8 %16032 to i32
  %16033 = load i8, i8* %arrayidx70.26, align 1
  %conv71.11.26 = zext i8 %16033 to i32
  %xor72.11.26 = xor i32 %conv71.11.26, %conv68.11.26
  %conv73.11.26 = trunc i32 %xor72.11.26 to i8
  store i8 %conv73.11.26, i8* %arrayidx70.26, align 1
  %scevgep20.12.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 12
  %16034 = load i8, i8* %scevgep20.12.26, align 1
  %conv68.12.26 = zext i8 %16034 to i32
  %16035 = load i8, i8* %arrayidx70.26, align 1
  %conv71.12.26 = zext i8 %16035 to i32
  %xor72.12.26 = xor i32 %conv71.12.26, %conv68.12.26
  %conv73.12.26 = trunc i32 %xor72.12.26 to i8
  store i8 %conv73.12.26, i8* %arrayidx70.26, align 1
  %scevgep20.13.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 13
  %16036 = load i8, i8* %scevgep20.13.26, align 1
  %conv68.13.26 = zext i8 %16036 to i32
  %16037 = load i8, i8* %arrayidx70.26, align 1
  %conv71.13.26 = zext i8 %16037 to i32
  %xor72.13.26 = xor i32 %conv71.13.26, %conv68.13.26
  %conv73.13.26 = trunc i32 %xor72.13.26 to i8
  store i8 %conv73.13.26, i8* %arrayidx70.26, align 1
  %scevgep20.14.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 14
  %16038 = load i8, i8* %scevgep20.14.26, align 1
  %conv68.14.26 = zext i8 %16038 to i32
  %16039 = load i8, i8* %arrayidx70.26, align 1
  %conv71.14.26 = zext i8 %16039 to i32
  %xor72.14.26 = xor i32 %conv71.14.26, %conv68.14.26
  %conv73.14.26 = trunc i32 %xor72.14.26 to i8
  store i8 %conv73.14.26, i8* %arrayidx70.26, align 1
  %scevgep20.15.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 15
  %16040 = load i8, i8* %scevgep20.15.26, align 1
  %conv68.15.26 = zext i8 %16040 to i32
  %16041 = load i8, i8* %arrayidx70.26, align 1
  %conv71.15.26 = zext i8 %16041 to i32
  %xor72.15.26 = xor i32 %conv71.15.26, %conv68.15.26
  %conv73.15.26 = trunc i32 %xor72.15.26 to i8
  store i8 %conv73.15.26, i8* %arrayidx70.26, align 1
  %scevgep20.16.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 16
  %16042 = load i8, i8* %scevgep20.16.26, align 1
  %conv68.16.26 = zext i8 %16042 to i32
  %16043 = load i8, i8* %arrayidx70.26, align 1
  %conv71.16.26 = zext i8 %16043 to i32
  %xor72.16.26 = xor i32 %conv71.16.26, %conv68.16.26
  %conv73.16.26 = trunc i32 %xor72.16.26 to i8
  store i8 %conv73.16.26, i8* %arrayidx70.26, align 1
  %scevgep20.17.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 17
  %16044 = load i8, i8* %scevgep20.17.26, align 1
  %conv68.17.26 = zext i8 %16044 to i32
  %16045 = load i8, i8* %arrayidx70.26, align 1
  %conv71.17.26 = zext i8 %16045 to i32
  %xor72.17.26 = xor i32 %conv71.17.26, %conv68.17.26
  %conv73.17.26 = trunc i32 %xor72.17.26 to i8
  store i8 %conv73.17.26, i8* %arrayidx70.26, align 1
  %scevgep20.18.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 18
  %16046 = load i8, i8* %scevgep20.18.26, align 1
  %conv68.18.26 = zext i8 %16046 to i32
  %16047 = load i8, i8* %arrayidx70.26, align 1
  %conv71.18.26 = zext i8 %16047 to i32
  %xor72.18.26 = xor i32 %conv71.18.26, %conv68.18.26
  %conv73.18.26 = trunc i32 %xor72.18.26 to i8
  store i8 %conv73.18.26, i8* %arrayidx70.26, align 1
  %scevgep20.19.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 19
  %16048 = load i8, i8* %scevgep20.19.26, align 1
  %conv68.19.26 = zext i8 %16048 to i32
  %16049 = load i8, i8* %arrayidx70.26, align 1
  %conv71.19.26 = zext i8 %16049 to i32
  %xor72.19.26 = xor i32 %conv71.19.26, %conv68.19.26
  %conv73.19.26 = trunc i32 %xor72.19.26 to i8
  store i8 %conv73.19.26, i8* %arrayidx70.26, align 1
  %scevgep20.20.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 20
  %16050 = load i8, i8* %scevgep20.20.26, align 1
  %conv68.20.26 = zext i8 %16050 to i32
  %16051 = load i8, i8* %arrayidx70.26, align 1
  %conv71.20.26 = zext i8 %16051 to i32
  %xor72.20.26 = xor i32 %conv71.20.26, %conv68.20.26
  %conv73.20.26 = trunc i32 %xor72.20.26 to i8
  store i8 %conv73.20.26, i8* %arrayidx70.26, align 1
  %scevgep20.21.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 21
  %16052 = load i8, i8* %scevgep20.21.26, align 1
  %conv68.21.26 = zext i8 %16052 to i32
  %16053 = load i8, i8* %arrayidx70.26, align 1
  %conv71.21.26 = zext i8 %16053 to i32
  %xor72.21.26 = xor i32 %conv71.21.26, %conv68.21.26
  %conv73.21.26 = trunc i32 %xor72.21.26 to i8
  store i8 %conv73.21.26, i8* %arrayidx70.26, align 1
  %scevgep20.22.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 22
  %16054 = load i8, i8* %scevgep20.22.26, align 1
  %conv68.22.26 = zext i8 %16054 to i32
  %16055 = load i8, i8* %arrayidx70.26, align 1
  %conv71.22.26 = zext i8 %16055 to i32
  %xor72.22.26 = xor i32 %conv71.22.26, %conv68.22.26
  %conv73.22.26 = trunc i32 %xor72.22.26 to i8
  store i8 %conv73.22.26, i8* %arrayidx70.26, align 1
  %scevgep20.23.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 23
  %16056 = load i8, i8* %scevgep20.23.26, align 1
  %conv68.23.26 = zext i8 %16056 to i32
  %16057 = load i8, i8* %arrayidx70.26, align 1
  %conv71.23.26 = zext i8 %16057 to i32
  %xor72.23.26 = xor i32 %conv71.23.26, %conv68.23.26
  %conv73.23.26 = trunc i32 %xor72.23.26 to i8
  store i8 %conv73.23.26, i8* %arrayidx70.26, align 1
  %scevgep20.24.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 24
  %16058 = load i8, i8* %scevgep20.24.26, align 1
  %conv68.24.26 = zext i8 %16058 to i32
  %16059 = load i8, i8* %arrayidx70.26, align 1
  %conv71.24.26 = zext i8 %16059 to i32
  %xor72.24.26 = xor i32 %conv71.24.26, %conv68.24.26
  %conv73.24.26 = trunc i32 %xor72.24.26 to i8
  store i8 %conv73.24.26, i8* %arrayidx70.26, align 1
  %scevgep20.25.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 25
  %16060 = load i8, i8* %scevgep20.25.26, align 1
  %conv68.25.26 = zext i8 %16060 to i32
  %16061 = load i8, i8* %arrayidx70.26, align 1
  %conv71.25.26 = zext i8 %16061 to i32
  %xor72.25.26 = xor i32 %conv71.25.26, %conv68.25.26
  %conv73.25.26 = trunc i32 %xor72.25.26 to i8
  store i8 %conv73.25.26, i8* %arrayidx70.26, align 1
  %scevgep20.27.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 27
  %16062 = load i8, i8* %scevgep20.27.26, align 1
  %conv68.27.26 = zext i8 %16062 to i32
  %16063 = load i8, i8* %arrayidx70.26, align 1
  %conv71.27.26 = zext i8 %16063 to i32
  %xor72.27.26 = xor i32 %conv71.27.26, %conv68.27.26
  %conv73.27.26 = trunc i32 %xor72.27.26 to i8
  store i8 %conv73.27.26, i8* %arrayidx70.26, align 1
  %scevgep20.28.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 28
  %16064 = load i8, i8* %scevgep20.28.26, align 1
  %conv68.28.26 = zext i8 %16064 to i32
  %16065 = load i8, i8* %arrayidx70.26, align 1
  %conv71.28.26 = zext i8 %16065 to i32
  %xor72.28.26 = xor i32 %conv71.28.26, %conv68.28.26
  %conv73.28.26 = trunc i32 %xor72.28.26 to i8
  store i8 %conv73.28.26, i8* %arrayidx70.26, align 1
  %scevgep20.29.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 29
  %16066 = load i8, i8* %scevgep20.29.26, align 1
  %conv68.29.26 = zext i8 %16066 to i32
  %16067 = load i8, i8* %arrayidx70.26, align 1
  %conv71.29.26 = zext i8 %16067 to i32
  %xor72.29.26 = xor i32 %conv71.29.26, %conv68.29.26
  %conv73.29.26 = trunc i32 %xor72.29.26 to i8
  store i8 %conv73.29.26, i8* %arrayidx70.26, align 1
  %scevgep20.30.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 30
  %16068 = load i8, i8* %scevgep20.30.26, align 1
  %conv68.30.26 = zext i8 %16068 to i32
  %16069 = load i8, i8* %arrayidx70.26, align 1
  %conv71.30.26 = zext i8 %16069 to i32
  %xor72.30.26 = xor i32 %conv71.30.26, %conv68.30.26
  %conv73.30.26 = trunc i32 %xor72.30.26 to i8
  store i8 %conv73.30.26, i8* %arrayidx70.26, align 1
  %scevgep20.31.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 31
  %16070 = load i8, i8* %scevgep20.31.26, align 1
  %conv68.31.26 = zext i8 %16070 to i32
  %16071 = load i8, i8* %arrayidx70.26, align 1
  %conv71.31.26 = zext i8 %16071 to i32
  %xor72.31.26 = xor i32 %conv71.31.26, %conv68.31.26
  %conv73.31.26 = trunc i32 %xor72.31.26 to i8
  store i8 %conv73.31.26, i8* %arrayidx70.26, align 1
  %scevgep20.32.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 32
  %16072 = load i8, i8* %scevgep20.32.26, align 1
  %conv68.32.26 = zext i8 %16072 to i32
  %16073 = load i8, i8* %arrayidx70.26, align 1
  %conv71.32.26 = zext i8 %16073 to i32
  %xor72.32.26 = xor i32 %conv71.32.26, %conv68.32.26
  %conv73.32.26 = trunc i32 %xor72.32.26 to i8
  store i8 %conv73.32.26, i8* %arrayidx70.26, align 1
  %scevgep20.33.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 33
  %16074 = load i8, i8* %scevgep20.33.26, align 1
  %conv68.33.26 = zext i8 %16074 to i32
  %16075 = load i8, i8* %arrayidx70.26, align 1
  %conv71.33.26 = zext i8 %16075 to i32
  %xor72.33.26 = xor i32 %conv71.33.26, %conv68.33.26
  %conv73.33.26 = trunc i32 %xor72.33.26 to i8
  store i8 %conv73.33.26, i8* %arrayidx70.26, align 1
  %scevgep20.34.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 34
  %16076 = load i8, i8* %scevgep20.34.26, align 1
  %conv68.34.26 = zext i8 %16076 to i32
  %16077 = load i8, i8* %arrayidx70.26, align 1
  %conv71.34.26 = zext i8 %16077 to i32
  %xor72.34.26 = xor i32 %conv71.34.26, %conv68.34.26
  %conv73.34.26 = trunc i32 %xor72.34.26 to i8
  store i8 %conv73.34.26, i8* %arrayidx70.26, align 1
  %scevgep20.35.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 35
  %16078 = load i8, i8* %scevgep20.35.26, align 1
  %conv68.35.26 = zext i8 %16078 to i32
  %16079 = load i8, i8* %arrayidx70.26, align 1
  %conv71.35.26 = zext i8 %16079 to i32
  %xor72.35.26 = xor i32 %conv71.35.26, %conv68.35.26
  %conv73.35.26 = trunc i32 %xor72.35.26 to i8
  store i8 %conv73.35.26, i8* %arrayidx70.26, align 1
  %scevgep20.36.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 36
  %16080 = load i8, i8* %scevgep20.36.26, align 1
  %conv68.36.26 = zext i8 %16080 to i32
  %16081 = load i8, i8* %arrayidx70.26, align 1
  %conv71.36.26 = zext i8 %16081 to i32
  %xor72.36.26 = xor i32 %conv71.36.26, %conv68.36.26
  %conv73.36.26 = trunc i32 %xor72.36.26 to i8
  store i8 %conv73.36.26, i8* %arrayidx70.26, align 1
  %scevgep20.37.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 37
  %16082 = load i8, i8* %scevgep20.37.26, align 1
  %conv68.37.26 = zext i8 %16082 to i32
  %16083 = load i8, i8* %arrayidx70.26, align 1
  %conv71.37.26 = zext i8 %16083 to i32
  %xor72.37.26 = xor i32 %conv71.37.26, %conv68.37.26
  %conv73.37.26 = trunc i32 %xor72.37.26 to i8
  store i8 %conv73.37.26, i8* %arrayidx70.26, align 1
  %scevgep20.38.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 38
  %16084 = load i8, i8* %scevgep20.38.26, align 1
  %conv68.38.26 = zext i8 %16084 to i32
  %16085 = load i8, i8* %arrayidx70.26, align 1
  %conv71.38.26 = zext i8 %16085 to i32
  %xor72.38.26 = xor i32 %conv71.38.26, %conv68.38.26
  %conv73.38.26 = trunc i32 %xor72.38.26 to i8
  store i8 %conv73.38.26, i8* %arrayidx70.26, align 1
  %scevgep20.39.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 39
  %16086 = load i8, i8* %scevgep20.39.26, align 1
  %conv68.39.26 = zext i8 %16086 to i32
  %16087 = load i8, i8* %arrayidx70.26, align 1
  %conv71.39.26 = zext i8 %16087 to i32
  %xor72.39.26 = xor i32 %conv71.39.26, %conv68.39.26
  %conv73.39.26 = trunc i32 %xor72.39.26 to i8
  store i8 %conv73.39.26, i8* %arrayidx70.26, align 1
  %scevgep20.40.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 40
  %16088 = load i8, i8* %scevgep20.40.26, align 1
  %conv68.40.26 = zext i8 %16088 to i32
  %16089 = load i8, i8* %arrayidx70.26, align 1
  %conv71.40.26 = zext i8 %16089 to i32
  %xor72.40.26 = xor i32 %conv71.40.26, %conv68.40.26
  %conv73.40.26 = trunc i32 %xor72.40.26 to i8
  store i8 %conv73.40.26, i8* %arrayidx70.26, align 1
  %scevgep20.41.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 41
  %16090 = load i8, i8* %scevgep20.41.26, align 1
  %conv68.41.26 = zext i8 %16090 to i32
  %16091 = load i8, i8* %arrayidx70.26, align 1
  %conv71.41.26 = zext i8 %16091 to i32
  %xor72.41.26 = xor i32 %conv71.41.26, %conv68.41.26
  %conv73.41.26 = trunc i32 %xor72.41.26 to i8
  store i8 %conv73.41.26, i8* %arrayidx70.26, align 1
  %scevgep20.42.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 42
  %16092 = load i8, i8* %scevgep20.42.26, align 1
  %conv68.42.26 = zext i8 %16092 to i32
  %16093 = load i8, i8* %arrayidx70.26, align 1
  %conv71.42.26 = zext i8 %16093 to i32
  %xor72.42.26 = xor i32 %conv71.42.26, %conv68.42.26
  %conv73.42.26 = trunc i32 %xor72.42.26 to i8
  store i8 %conv73.42.26, i8* %arrayidx70.26, align 1
  %scevgep20.43.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 43
  %16094 = load i8, i8* %scevgep20.43.26, align 1
  %conv68.43.26 = zext i8 %16094 to i32
  %16095 = load i8, i8* %arrayidx70.26, align 1
  %conv71.43.26 = zext i8 %16095 to i32
  %xor72.43.26 = xor i32 %conv71.43.26, %conv68.43.26
  %conv73.43.26 = trunc i32 %xor72.43.26 to i8
  store i8 %conv73.43.26, i8* %arrayidx70.26, align 1
  %scevgep20.44.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 44
  %16096 = load i8, i8* %scevgep20.44.26, align 1
  %conv68.44.26 = zext i8 %16096 to i32
  %16097 = load i8, i8* %arrayidx70.26, align 1
  %conv71.44.26 = zext i8 %16097 to i32
  %xor72.44.26 = xor i32 %conv71.44.26, %conv68.44.26
  %conv73.44.26 = trunc i32 %xor72.44.26 to i8
  store i8 %conv73.44.26, i8* %arrayidx70.26, align 1
  %scevgep20.45.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 45
  %16098 = load i8, i8* %scevgep20.45.26, align 1
  %conv68.45.26 = zext i8 %16098 to i32
  %16099 = load i8, i8* %arrayidx70.26, align 1
  %conv71.45.26 = zext i8 %16099 to i32
  %xor72.45.26 = xor i32 %conv71.45.26, %conv68.45.26
  %conv73.45.26 = trunc i32 %xor72.45.26 to i8
  store i8 %conv73.45.26, i8* %arrayidx70.26, align 1
  %scevgep20.46.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 46
  %16100 = load i8, i8* %scevgep20.46.26, align 1
  %conv68.46.26 = zext i8 %16100 to i32
  %16101 = load i8, i8* %arrayidx70.26, align 1
  %conv71.46.26 = zext i8 %16101 to i32
  %xor72.46.26 = xor i32 %conv71.46.26, %conv68.46.26
  %conv73.46.26 = trunc i32 %xor72.46.26 to i8
  store i8 %conv73.46.26, i8* %arrayidx70.26, align 1
  %scevgep20.47.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 47
  %16102 = load i8, i8* %scevgep20.47.26, align 1
  %conv68.47.26 = zext i8 %16102 to i32
  %16103 = load i8, i8* %arrayidx70.26, align 1
  %conv71.47.26 = zext i8 %16103 to i32
  %xor72.47.26 = xor i32 %conv71.47.26, %conv68.47.26
  %conv73.47.26 = trunc i32 %xor72.47.26 to i8
  store i8 %conv73.47.26, i8* %arrayidx70.26, align 1
  %scevgep20.48.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 48
  %16104 = load i8, i8* %scevgep20.48.26, align 1
  %conv68.48.26 = zext i8 %16104 to i32
  %16105 = load i8, i8* %arrayidx70.26, align 1
  %conv71.48.26 = zext i8 %16105 to i32
  %xor72.48.26 = xor i32 %conv71.48.26, %conv68.48.26
  %conv73.48.26 = trunc i32 %xor72.48.26 to i8
  store i8 %conv73.48.26, i8* %arrayidx70.26, align 1
  %scevgep20.49.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 49
  %16106 = load i8, i8* %scevgep20.49.26, align 1
  %conv68.49.26 = zext i8 %16106 to i32
  %16107 = load i8, i8* %arrayidx70.26, align 1
  %conv71.49.26 = zext i8 %16107 to i32
  %xor72.49.26 = xor i32 %conv71.49.26, %conv68.49.26
  %conv73.49.26 = trunc i32 %xor72.49.26 to i8
  store i8 %conv73.49.26, i8* %arrayidx70.26, align 1
  %scevgep20.50.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 50
  %16108 = load i8, i8* %scevgep20.50.26, align 1
  %conv68.50.26 = zext i8 %16108 to i32
  %16109 = load i8, i8* %arrayidx70.26, align 1
  %conv71.50.26 = zext i8 %16109 to i32
  %xor72.50.26 = xor i32 %conv71.50.26, %conv68.50.26
  %conv73.50.26 = trunc i32 %xor72.50.26 to i8
  store i8 %conv73.50.26, i8* %arrayidx70.26, align 1
  %scevgep20.51.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 51
  %16110 = load i8, i8* %scevgep20.51.26, align 1
  %conv68.51.26 = zext i8 %16110 to i32
  %16111 = load i8, i8* %arrayidx70.26, align 1
  %conv71.51.26 = zext i8 %16111 to i32
  %xor72.51.26 = xor i32 %conv71.51.26, %conv68.51.26
  %conv73.51.26 = trunc i32 %xor72.51.26 to i8
  store i8 %conv73.51.26, i8* %arrayidx70.26, align 1
  %scevgep20.52.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 52
  %16112 = load i8, i8* %scevgep20.52.26, align 1
  %conv68.52.26 = zext i8 %16112 to i32
  %16113 = load i8, i8* %arrayidx70.26, align 1
  %conv71.52.26 = zext i8 %16113 to i32
  %xor72.52.26 = xor i32 %conv71.52.26, %conv68.52.26
  %conv73.52.26 = trunc i32 %xor72.52.26 to i8
  store i8 %conv73.52.26, i8* %arrayidx70.26, align 1
  %scevgep20.53.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 53
  %16114 = load i8, i8* %scevgep20.53.26, align 1
  %conv68.53.26 = zext i8 %16114 to i32
  %16115 = load i8, i8* %arrayidx70.26, align 1
  %conv71.53.26 = zext i8 %16115 to i32
  %xor72.53.26 = xor i32 %conv71.53.26, %conv68.53.26
  %conv73.53.26 = trunc i32 %xor72.53.26 to i8
  store i8 %conv73.53.26, i8* %arrayidx70.26, align 1
  %scevgep20.54.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 54
  %16116 = load i8, i8* %scevgep20.54.26, align 1
  %conv68.54.26 = zext i8 %16116 to i32
  %16117 = load i8, i8* %arrayidx70.26, align 1
  %conv71.54.26 = zext i8 %16117 to i32
  %xor72.54.26 = xor i32 %conv71.54.26, %conv68.54.26
  %conv73.54.26 = trunc i32 %xor72.54.26 to i8
  store i8 %conv73.54.26, i8* %arrayidx70.26, align 1
  %scevgep20.55.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 55
  %16118 = load i8, i8* %scevgep20.55.26, align 1
  %conv68.55.26 = zext i8 %16118 to i32
  %16119 = load i8, i8* %arrayidx70.26, align 1
  %conv71.55.26 = zext i8 %16119 to i32
  %xor72.55.26 = xor i32 %conv71.55.26, %conv68.55.26
  %conv73.55.26 = trunc i32 %xor72.55.26 to i8
  store i8 %conv73.55.26, i8* %arrayidx70.26, align 1
  %scevgep20.56.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 56
  %16120 = load i8, i8* %scevgep20.56.26, align 1
  %conv68.56.26 = zext i8 %16120 to i32
  %16121 = load i8, i8* %arrayidx70.26, align 1
  %conv71.56.26 = zext i8 %16121 to i32
  %xor72.56.26 = xor i32 %conv71.56.26, %conv68.56.26
  %conv73.56.26 = trunc i32 %xor72.56.26 to i8
  store i8 %conv73.56.26, i8* %arrayidx70.26, align 1
  %scevgep20.57.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 57
  %16122 = load i8, i8* %scevgep20.57.26, align 1
  %conv68.57.26 = zext i8 %16122 to i32
  %16123 = load i8, i8* %arrayidx70.26, align 1
  %conv71.57.26 = zext i8 %16123 to i32
  %xor72.57.26 = xor i32 %conv71.57.26, %conv68.57.26
  %conv73.57.26 = trunc i32 %xor72.57.26 to i8
  store i8 %conv73.57.26, i8* %arrayidx70.26, align 1
  %scevgep20.58.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 58
  %16124 = load i8, i8* %scevgep20.58.26, align 1
  %conv68.58.26 = zext i8 %16124 to i32
  %16125 = load i8, i8* %arrayidx70.26, align 1
  %conv71.58.26 = zext i8 %16125 to i32
  %xor72.58.26 = xor i32 %conv71.58.26, %conv68.58.26
  %conv73.58.26 = trunc i32 %xor72.58.26 to i8
  store i8 %conv73.58.26, i8* %arrayidx70.26, align 1
  %scevgep20.59.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 59
  %16126 = load i8, i8* %scevgep20.59.26, align 1
  %conv68.59.26 = zext i8 %16126 to i32
  %16127 = load i8, i8* %arrayidx70.26, align 1
  %conv71.59.26 = zext i8 %16127 to i32
  %xor72.59.26 = xor i32 %conv71.59.26, %conv68.59.26
  %conv73.59.26 = trunc i32 %xor72.59.26 to i8
  store i8 %conv73.59.26, i8* %arrayidx70.26, align 1
  %scevgep20.60.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 0, i64 60
  %16128 = load i8, i8* %scevgep20.60.26, align 1
  %conv68.60.26 = zext i8 %16128 to i32
  %16129 = load i8, i8* %arrayidx70.26, align 1
  %conv71.60.26 = zext i8 %16129 to i32
  %xor72.60.26 = xor i32 %conv71.60.26, %conv68.60.26
  %conv73.60.26 = trunc i32 %xor72.60.26 to i8
  store i8 %conv73.60.26, i8* %arrayidx70.26, align 1
  %scevgep19.26 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16007, i64 0, i64 1, i64 0
  %16130 = bitcast i8* %scevgep19.26 to [61 x [61 x i8]]*
  %arrayidx51.27 = getelementptr inbounds i8, i8* %a, i64 27
  %16131 = load i8, i8* %arrayidx51.27, align 1
  %arrayidx53.27 = getelementptr inbounds i8, i8* %b, i64 27
  %16132 = load i8, i8* %arrayidx53.27, align 1
  %call54.27 = call zeroext i8 @mult(i8 zeroext %16131, i8 zeroext %16132)
  %arrayidx56.27 = getelementptr inbounds i8, i8* %c, i64 27
  store i8 %call54.27, i8* %arrayidx56.27, align 1
  %arrayidx70.27 = getelementptr inbounds i8, i8* %c, i64 27
  %scevgep20.27314 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 0
  %16133 = load i8, i8* %scevgep20.27314, align 1
  %conv68.27315 = zext i8 %16133 to i32
  %16134 = load i8, i8* %arrayidx70.27, align 1
  %conv71.27316 = zext i8 %16134 to i32
  %xor72.27317 = xor i32 %conv71.27316, %conv68.27315
  %conv73.27318 = trunc i32 %xor72.27317 to i8
  store i8 %conv73.27318, i8* %arrayidx70.27, align 1
  %scevgep20.1.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 1
  %16135 = load i8, i8* %scevgep20.1.27, align 1
  %conv68.1.27 = zext i8 %16135 to i32
  %16136 = load i8, i8* %arrayidx70.27, align 1
  %conv71.1.27 = zext i8 %16136 to i32
  %xor72.1.27 = xor i32 %conv71.1.27, %conv68.1.27
  %conv73.1.27 = trunc i32 %xor72.1.27 to i8
  store i8 %conv73.1.27, i8* %arrayidx70.27, align 1
  %scevgep20.2.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 2
  %16137 = load i8, i8* %scevgep20.2.27, align 1
  %conv68.2.27 = zext i8 %16137 to i32
  %16138 = load i8, i8* %arrayidx70.27, align 1
  %conv71.2.27 = zext i8 %16138 to i32
  %xor72.2.27 = xor i32 %conv71.2.27, %conv68.2.27
  %conv73.2.27 = trunc i32 %xor72.2.27 to i8
  store i8 %conv73.2.27, i8* %arrayidx70.27, align 1
  %scevgep20.3.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 3
  %16139 = load i8, i8* %scevgep20.3.27, align 1
  %conv68.3.27 = zext i8 %16139 to i32
  %16140 = load i8, i8* %arrayidx70.27, align 1
  %conv71.3.27 = zext i8 %16140 to i32
  %xor72.3.27 = xor i32 %conv71.3.27, %conv68.3.27
  %conv73.3.27 = trunc i32 %xor72.3.27 to i8
  store i8 %conv73.3.27, i8* %arrayidx70.27, align 1
  %scevgep20.4.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 4
  %16141 = load i8, i8* %scevgep20.4.27, align 1
  %conv68.4.27 = zext i8 %16141 to i32
  %16142 = load i8, i8* %arrayidx70.27, align 1
  %conv71.4.27 = zext i8 %16142 to i32
  %xor72.4.27 = xor i32 %conv71.4.27, %conv68.4.27
  %conv73.4.27 = trunc i32 %xor72.4.27 to i8
  store i8 %conv73.4.27, i8* %arrayidx70.27, align 1
  %scevgep20.5.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 5
  %16143 = load i8, i8* %scevgep20.5.27, align 1
  %conv68.5.27 = zext i8 %16143 to i32
  %16144 = load i8, i8* %arrayidx70.27, align 1
  %conv71.5.27 = zext i8 %16144 to i32
  %xor72.5.27 = xor i32 %conv71.5.27, %conv68.5.27
  %conv73.5.27 = trunc i32 %xor72.5.27 to i8
  store i8 %conv73.5.27, i8* %arrayidx70.27, align 1
  %scevgep20.6.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 6
  %16145 = load i8, i8* %scevgep20.6.27, align 1
  %conv68.6.27 = zext i8 %16145 to i32
  %16146 = load i8, i8* %arrayidx70.27, align 1
  %conv71.6.27 = zext i8 %16146 to i32
  %xor72.6.27 = xor i32 %conv71.6.27, %conv68.6.27
  %conv73.6.27 = trunc i32 %xor72.6.27 to i8
  store i8 %conv73.6.27, i8* %arrayidx70.27, align 1
  %scevgep20.7.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 7
  %16147 = load i8, i8* %scevgep20.7.27, align 1
  %conv68.7.27 = zext i8 %16147 to i32
  %16148 = load i8, i8* %arrayidx70.27, align 1
  %conv71.7.27 = zext i8 %16148 to i32
  %xor72.7.27 = xor i32 %conv71.7.27, %conv68.7.27
  %conv73.7.27 = trunc i32 %xor72.7.27 to i8
  store i8 %conv73.7.27, i8* %arrayidx70.27, align 1
  %scevgep20.8.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 8
  %16149 = load i8, i8* %scevgep20.8.27, align 1
  %conv68.8.27 = zext i8 %16149 to i32
  %16150 = load i8, i8* %arrayidx70.27, align 1
  %conv71.8.27 = zext i8 %16150 to i32
  %xor72.8.27 = xor i32 %conv71.8.27, %conv68.8.27
  %conv73.8.27 = trunc i32 %xor72.8.27 to i8
  store i8 %conv73.8.27, i8* %arrayidx70.27, align 1
  %scevgep20.9.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 9
  %16151 = load i8, i8* %scevgep20.9.27, align 1
  %conv68.9.27 = zext i8 %16151 to i32
  %16152 = load i8, i8* %arrayidx70.27, align 1
  %conv71.9.27 = zext i8 %16152 to i32
  %xor72.9.27 = xor i32 %conv71.9.27, %conv68.9.27
  %conv73.9.27 = trunc i32 %xor72.9.27 to i8
  store i8 %conv73.9.27, i8* %arrayidx70.27, align 1
  %scevgep20.10.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 10
  %16153 = load i8, i8* %scevgep20.10.27, align 1
  %conv68.10.27 = zext i8 %16153 to i32
  %16154 = load i8, i8* %arrayidx70.27, align 1
  %conv71.10.27 = zext i8 %16154 to i32
  %xor72.10.27 = xor i32 %conv71.10.27, %conv68.10.27
  %conv73.10.27 = trunc i32 %xor72.10.27 to i8
  store i8 %conv73.10.27, i8* %arrayidx70.27, align 1
  %scevgep20.11.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 11
  %16155 = load i8, i8* %scevgep20.11.27, align 1
  %conv68.11.27 = zext i8 %16155 to i32
  %16156 = load i8, i8* %arrayidx70.27, align 1
  %conv71.11.27 = zext i8 %16156 to i32
  %xor72.11.27 = xor i32 %conv71.11.27, %conv68.11.27
  %conv73.11.27 = trunc i32 %xor72.11.27 to i8
  store i8 %conv73.11.27, i8* %arrayidx70.27, align 1
  %scevgep20.12.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 12
  %16157 = load i8, i8* %scevgep20.12.27, align 1
  %conv68.12.27 = zext i8 %16157 to i32
  %16158 = load i8, i8* %arrayidx70.27, align 1
  %conv71.12.27 = zext i8 %16158 to i32
  %xor72.12.27 = xor i32 %conv71.12.27, %conv68.12.27
  %conv73.12.27 = trunc i32 %xor72.12.27 to i8
  store i8 %conv73.12.27, i8* %arrayidx70.27, align 1
  %scevgep20.13.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 13
  %16159 = load i8, i8* %scevgep20.13.27, align 1
  %conv68.13.27 = zext i8 %16159 to i32
  %16160 = load i8, i8* %arrayidx70.27, align 1
  %conv71.13.27 = zext i8 %16160 to i32
  %xor72.13.27 = xor i32 %conv71.13.27, %conv68.13.27
  %conv73.13.27 = trunc i32 %xor72.13.27 to i8
  store i8 %conv73.13.27, i8* %arrayidx70.27, align 1
  %scevgep20.14.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 14
  %16161 = load i8, i8* %scevgep20.14.27, align 1
  %conv68.14.27 = zext i8 %16161 to i32
  %16162 = load i8, i8* %arrayidx70.27, align 1
  %conv71.14.27 = zext i8 %16162 to i32
  %xor72.14.27 = xor i32 %conv71.14.27, %conv68.14.27
  %conv73.14.27 = trunc i32 %xor72.14.27 to i8
  store i8 %conv73.14.27, i8* %arrayidx70.27, align 1
  %scevgep20.15.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 15
  %16163 = load i8, i8* %scevgep20.15.27, align 1
  %conv68.15.27 = zext i8 %16163 to i32
  %16164 = load i8, i8* %arrayidx70.27, align 1
  %conv71.15.27 = zext i8 %16164 to i32
  %xor72.15.27 = xor i32 %conv71.15.27, %conv68.15.27
  %conv73.15.27 = trunc i32 %xor72.15.27 to i8
  store i8 %conv73.15.27, i8* %arrayidx70.27, align 1
  %scevgep20.16.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 16
  %16165 = load i8, i8* %scevgep20.16.27, align 1
  %conv68.16.27 = zext i8 %16165 to i32
  %16166 = load i8, i8* %arrayidx70.27, align 1
  %conv71.16.27 = zext i8 %16166 to i32
  %xor72.16.27 = xor i32 %conv71.16.27, %conv68.16.27
  %conv73.16.27 = trunc i32 %xor72.16.27 to i8
  store i8 %conv73.16.27, i8* %arrayidx70.27, align 1
  %scevgep20.17.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 17
  %16167 = load i8, i8* %scevgep20.17.27, align 1
  %conv68.17.27 = zext i8 %16167 to i32
  %16168 = load i8, i8* %arrayidx70.27, align 1
  %conv71.17.27 = zext i8 %16168 to i32
  %xor72.17.27 = xor i32 %conv71.17.27, %conv68.17.27
  %conv73.17.27 = trunc i32 %xor72.17.27 to i8
  store i8 %conv73.17.27, i8* %arrayidx70.27, align 1
  %scevgep20.18.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 18
  %16169 = load i8, i8* %scevgep20.18.27, align 1
  %conv68.18.27 = zext i8 %16169 to i32
  %16170 = load i8, i8* %arrayidx70.27, align 1
  %conv71.18.27 = zext i8 %16170 to i32
  %xor72.18.27 = xor i32 %conv71.18.27, %conv68.18.27
  %conv73.18.27 = trunc i32 %xor72.18.27 to i8
  store i8 %conv73.18.27, i8* %arrayidx70.27, align 1
  %scevgep20.19.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 19
  %16171 = load i8, i8* %scevgep20.19.27, align 1
  %conv68.19.27 = zext i8 %16171 to i32
  %16172 = load i8, i8* %arrayidx70.27, align 1
  %conv71.19.27 = zext i8 %16172 to i32
  %xor72.19.27 = xor i32 %conv71.19.27, %conv68.19.27
  %conv73.19.27 = trunc i32 %xor72.19.27 to i8
  store i8 %conv73.19.27, i8* %arrayidx70.27, align 1
  %scevgep20.20.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 20
  %16173 = load i8, i8* %scevgep20.20.27, align 1
  %conv68.20.27 = zext i8 %16173 to i32
  %16174 = load i8, i8* %arrayidx70.27, align 1
  %conv71.20.27 = zext i8 %16174 to i32
  %xor72.20.27 = xor i32 %conv71.20.27, %conv68.20.27
  %conv73.20.27 = trunc i32 %xor72.20.27 to i8
  store i8 %conv73.20.27, i8* %arrayidx70.27, align 1
  %scevgep20.21.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 21
  %16175 = load i8, i8* %scevgep20.21.27, align 1
  %conv68.21.27 = zext i8 %16175 to i32
  %16176 = load i8, i8* %arrayidx70.27, align 1
  %conv71.21.27 = zext i8 %16176 to i32
  %xor72.21.27 = xor i32 %conv71.21.27, %conv68.21.27
  %conv73.21.27 = trunc i32 %xor72.21.27 to i8
  store i8 %conv73.21.27, i8* %arrayidx70.27, align 1
  %scevgep20.22.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 22
  %16177 = load i8, i8* %scevgep20.22.27, align 1
  %conv68.22.27 = zext i8 %16177 to i32
  %16178 = load i8, i8* %arrayidx70.27, align 1
  %conv71.22.27 = zext i8 %16178 to i32
  %xor72.22.27 = xor i32 %conv71.22.27, %conv68.22.27
  %conv73.22.27 = trunc i32 %xor72.22.27 to i8
  store i8 %conv73.22.27, i8* %arrayidx70.27, align 1
  %scevgep20.23.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 23
  %16179 = load i8, i8* %scevgep20.23.27, align 1
  %conv68.23.27 = zext i8 %16179 to i32
  %16180 = load i8, i8* %arrayidx70.27, align 1
  %conv71.23.27 = zext i8 %16180 to i32
  %xor72.23.27 = xor i32 %conv71.23.27, %conv68.23.27
  %conv73.23.27 = trunc i32 %xor72.23.27 to i8
  store i8 %conv73.23.27, i8* %arrayidx70.27, align 1
  %scevgep20.24.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 24
  %16181 = load i8, i8* %scevgep20.24.27, align 1
  %conv68.24.27 = zext i8 %16181 to i32
  %16182 = load i8, i8* %arrayidx70.27, align 1
  %conv71.24.27 = zext i8 %16182 to i32
  %xor72.24.27 = xor i32 %conv71.24.27, %conv68.24.27
  %conv73.24.27 = trunc i32 %xor72.24.27 to i8
  store i8 %conv73.24.27, i8* %arrayidx70.27, align 1
  %scevgep20.25.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 25
  %16183 = load i8, i8* %scevgep20.25.27, align 1
  %conv68.25.27 = zext i8 %16183 to i32
  %16184 = load i8, i8* %arrayidx70.27, align 1
  %conv71.25.27 = zext i8 %16184 to i32
  %xor72.25.27 = xor i32 %conv71.25.27, %conv68.25.27
  %conv73.25.27 = trunc i32 %xor72.25.27 to i8
  store i8 %conv73.25.27, i8* %arrayidx70.27, align 1
  %scevgep20.26.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 26
  %16185 = load i8, i8* %scevgep20.26.27, align 1
  %conv68.26.27 = zext i8 %16185 to i32
  %16186 = load i8, i8* %arrayidx70.27, align 1
  %conv71.26.27 = zext i8 %16186 to i32
  %xor72.26.27 = xor i32 %conv71.26.27, %conv68.26.27
  %conv73.26.27 = trunc i32 %xor72.26.27 to i8
  store i8 %conv73.26.27, i8* %arrayidx70.27, align 1
  %scevgep20.28.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 28
  %16187 = load i8, i8* %scevgep20.28.27, align 1
  %conv68.28.27 = zext i8 %16187 to i32
  %16188 = load i8, i8* %arrayidx70.27, align 1
  %conv71.28.27 = zext i8 %16188 to i32
  %xor72.28.27 = xor i32 %conv71.28.27, %conv68.28.27
  %conv73.28.27 = trunc i32 %xor72.28.27 to i8
  store i8 %conv73.28.27, i8* %arrayidx70.27, align 1
  %scevgep20.29.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 29
  %16189 = load i8, i8* %scevgep20.29.27, align 1
  %conv68.29.27 = zext i8 %16189 to i32
  %16190 = load i8, i8* %arrayidx70.27, align 1
  %conv71.29.27 = zext i8 %16190 to i32
  %xor72.29.27 = xor i32 %conv71.29.27, %conv68.29.27
  %conv73.29.27 = trunc i32 %xor72.29.27 to i8
  store i8 %conv73.29.27, i8* %arrayidx70.27, align 1
  %scevgep20.30.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 30
  %16191 = load i8, i8* %scevgep20.30.27, align 1
  %conv68.30.27 = zext i8 %16191 to i32
  %16192 = load i8, i8* %arrayidx70.27, align 1
  %conv71.30.27 = zext i8 %16192 to i32
  %xor72.30.27 = xor i32 %conv71.30.27, %conv68.30.27
  %conv73.30.27 = trunc i32 %xor72.30.27 to i8
  store i8 %conv73.30.27, i8* %arrayidx70.27, align 1
  %scevgep20.31.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 31
  %16193 = load i8, i8* %scevgep20.31.27, align 1
  %conv68.31.27 = zext i8 %16193 to i32
  %16194 = load i8, i8* %arrayidx70.27, align 1
  %conv71.31.27 = zext i8 %16194 to i32
  %xor72.31.27 = xor i32 %conv71.31.27, %conv68.31.27
  %conv73.31.27 = trunc i32 %xor72.31.27 to i8
  store i8 %conv73.31.27, i8* %arrayidx70.27, align 1
  %scevgep20.32.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 32
  %16195 = load i8, i8* %scevgep20.32.27, align 1
  %conv68.32.27 = zext i8 %16195 to i32
  %16196 = load i8, i8* %arrayidx70.27, align 1
  %conv71.32.27 = zext i8 %16196 to i32
  %xor72.32.27 = xor i32 %conv71.32.27, %conv68.32.27
  %conv73.32.27 = trunc i32 %xor72.32.27 to i8
  store i8 %conv73.32.27, i8* %arrayidx70.27, align 1
  %scevgep20.33.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 33
  %16197 = load i8, i8* %scevgep20.33.27, align 1
  %conv68.33.27 = zext i8 %16197 to i32
  %16198 = load i8, i8* %arrayidx70.27, align 1
  %conv71.33.27 = zext i8 %16198 to i32
  %xor72.33.27 = xor i32 %conv71.33.27, %conv68.33.27
  %conv73.33.27 = trunc i32 %xor72.33.27 to i8
  store i8 %conv73.33.27, i8* %arrayidx70.27, align 1
  %scevgep20.34.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 34
  %16199 = load i8, i8* %scevgep20.34.27, align 1
  %conv68.34.27 = zext i8 %16199 to i32
  %16200 = load i8, i8* %arrayidx70.27, align 1
  %conv71.34.27 = zext i8 %16200 to i32
  %xor72.34.27 = xor i32 %conv71.34.27, %conv68.34.27
  %conv73.34.27 = trunc i32 %xor72.34.27 to i8
  store i8 %conv73.34.27, i8* %arrayidx70.27, align 1
  %scevgep20.35.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 35
  %16201 = load i8, i8* %scevgep20.35.27, align 1
  %conv68.35.27 = zext i8 %16201 to i32
  %16202 = load i8, i8* %arrayidx70.27, align 1
  %conv71.35.27 = zext i8 %16202 to i32
  %xor72.35.27 = xor i32 %conv71.35.27, %conv68.35.27
  %conv73.35.27 = trunc i32 %xor72.35.27 to i8
  store i8 %conv73.35.27, i8* %arrayidx70.27, align 1
  %scevgep20.36.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 36
  %16203 = load i8, i8* %scevgep20.36.27, align 1
  %conv68.36.27 = zext i8 %16203 to i32
  %16204 = load i8, i8* %arrayidx70.27, align 1
  %conv71.36.27 = zext i8 %16204 to i32
  %xor72.36.27 = xor i32 %conv71.36.27, %conv68.36.27
  %conv73.36.27 = trunc i32 %xor72.36.27 to i8
  store i8 %conv73.36.27, i8* %arrayidx70.27, align 1
  %scevgep20.37.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 37
  %16205 = load i8, i8* %scevgep20.37.27, align 1
  %conv68.37.27 = zext i8 %16205 to i32
  %16206 = load i8, i8* %arrayidx70.27, align 1
  %conv71.37.27 = zext i8 %16206 to i32
  %xor72.37.27 = xor i32 %conv71.37.27, %conv68.37.27
  %conv73.37.27 = trunc i32 %xor72.37.27 to i8
  store i8 %conv73.37.27, i8* %arrayidx70.27, align 1
  %scevgep20.38.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 38
  %16207 = load i8, i8* %scevgep20.38.27, align 1
  %conv68.38.27 = zext i8 %16207 to i32
  %16208 = load i8, i8* %arrayidx70.27, align 1
  %conv71.38.27 = zext i8 %16208 to i32
  %xor72.38.27 = xor i32 %conv71.38.27, %conv68.38.27
  %conv73.38.27 = trunc i32 %xor72.38.27 to i8
  store i8 %conv73.38.27, i8* %arrayidx70.27, align 1
  %scevgep20.39.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 39
  %16209 = load i8, i8* %scevgep20.39.27, align 1
  %conv68.39.27 = zext i8 %16209 to i32
  %16210 = load i8, i8* %arrayidx70.27, align 1
  %conv71.39.27 = zext i8 %16210 to i32
  %xor72.39.27 = xor i32 %conv71.39.27, %conv68.39.27
  %conv73.39.27 = trunc i32 %xor72.39.27 to i8
  store i8 %conv73.39.27, i8* %arrayidx70.27, align 1
  %scevgep20.40.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 40
  %16211 = load i8, i8* %scevgep20.40.27, align 1
  %conv68.40.27 = zext i8 %16211 to i32
  %16212 = load i8, i8* %arrayidx70.27, align 1
  %conv71.40.27 = zext i8 %16212 to i32
  %xor72.40.27 = xor i32 %conv71.40.27, %conv68.40.27
  %conv73.40.27 = trunc i32 %xor72.40.27 to i8
  store i8 %conv73.40.27, i8* %arrayidx70.27, align 1
  %scevgep20.41.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 41
  %16213 = load i8, i8* %scevgep20.41.27, align 1
  %conv68.41.27 = zext i8 %16213 to i32
  %16214 = load i8, i8* %arrayidx70.27, align 1
  %conv71.41.27 = zext i8 %16214 to i32
  %xor72.41.27 = xor i32 %conv71.41.27, %conv68.41.27
  %conv73.41.27 = trunc i32 %xor72.41.27 to i8
  store i8 %conv73.41.27, i8* %arrayidx70.27, align 1
  %scevgep20.42.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 42
  %16215 = load i8, i8* %scevgep20.42.27, align 1
  %conv68.42.27 = zext i8 %16215 to i32
  %16216 = load i8, i8* %arrayidx70.27, align 1
  %conv71.42.27 = zext i8 %16216 to i32
  %xor72.42.27 = xor i32 %conv71.42.27, %conv68.42.27
  %conv73.42.27 = trunc i32 %xor72.42.27 to i8
  store i8 %conv73.42.27, i8* %arrayidx70.27, align 1
  %scevgep20.43.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 43
  %16217 = load i8, i8* %scevgep20.43.27, align 1
  %conv68.43.27 = zext i8 %16217 to i32
  %16218 = load i8, i8* %arrayidx70.27, align 1
  %conv71.43.27 = zext i8 %16218 to i32
  %xor72.43.27 = xor i32 %conv71.43.27, %conv68.43.27
  %conv73.43.27 = trunc i32 %xor72.43.27 to i8
  store i8 %conv73.43.27, i8* %arrayidx70.27, align 1
  %scevgep20.44.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 44
  %16219 = load i8, i8* %scevgep20.44.27, align 1
  %conv68.44.27 = zext i8 %16219 to i32
  %16220 = load i8, i8* %arrayidx70.27, align 1
  %conv71.44.27 = zext i8 %16220 to i32
  %xor72.44.27 = xor i32 %conv71.44.27, %conv68.44.27
  %conv73.44.27 = trunc i32 %xor72.44.27 to i8
  store i8 %conv73.44.27, i8* %arrayidx70.27, align 1
  %scevgep20.45.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 45
  %16221 = load i8, i8* %scevgep20.45.27, align 1
  %conv68.45.27 = zext i8 %16221 to i32
  %16222 = load i8, i8* %arrayidx70.27, align 1
  %conv71.45.27 = zext i8 %16222 to i32
  %xor72.45.27 = xor i32 %conv71.45.27, %conv68.45.27
  %conv73.45.27 = trunc i32 %xor72.45.27 to i8
  store i8 %conv73.45.27, i8* %arrayidx70.27, align 1
  %scevgep20.46.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 46
  %16223 = load i8, i8* %scevgep20.46.27, align 1
  %conv68.46.27 = zext i8 %16223 to i32
  %16224 = load i8, i8* %arrayidx70.27, align 1
  %conv71.46.27 = zext i8 %16224 to i32
  %xor72.46.27 = xor i32 %conv71.46.27, %conv68.46.27
  %conv73.46.27 = trunc i32 %xor72.46.27 to i8
  store i8 %conv73.46.27, i8* %arrayidx70.27, align 1
  %scevgep20.47.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 47
  %16225 = load i8, i8* %scevgep20.47.27, align 1
  %conv68.47.27 = zext i8 %16225 to i32
  %16226 = load i8, i8* %arrayidx70.27, align 1
  %conv71.47.27 = zext i8 %16226 to i32
  %xor72.47.27 = xor i32 %conv71.47.27, %conv68.47.27
  %conv73.47.27 = trunc i32 %xor72.47.27 to i8
  store i8 %conv73.47.27, i8* %arrayidx70.27, align 1
  %scevgep20.48.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 48
  %16227 = load i8, i8* %scevgep20.48.27, align 1
  %conv68.48.27 = zext i8 %16227 to i32
  %16228 = load i8, i8* %arrayidx70.27, align 1
  %conv71.48.27 = zext i8 %16228 to i32
  %xor72.48.27 = xor i32 %conv71.48.27, %conv68.48.27
  %conv73.48.27 = trunc i32 %xor72.48.27 to i8
  store i8 %conv73.48.27, i8* %arrayidx70.27, align 1
  %scevgep20.49.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 49
  %16229 = load i8, i8* %scevgep20.49.27, align 1
  %conv68.49.27 = zext i8 %16229 to i32
  %16230 = load i8, i8* %arrayidx70.27, align 1
  %conv71.49.27 = zext i8 %16230 to i32
  %xor72.49.27 = xor i32 %conv71.49.27, %conv68.49.27
  %conv73.49.27 = trunc i32 %xor72.49.27 to i8
  store i8 %conv73.49.27, i8* %arrayidx70.27, align 1
  %scevgep20.50.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 50
  %16231 = load i8, i8* %scevgep20.50.27, align 1
  %conv68.50.27 = zext i8 %16231 to i32
  %16232 = load i8, i8* %arrayidx70.27, align 1
  %conv71.50.27 = zext i8 %16232 to i32
  %xor72.50.27 = xor i32 %conv71.50.27, %conv68.50.27
  %conv73.50.27 = trunc i32 %xor72.50.27 to i8
  store i8 %conv73.50.27, i8* %arrayidx70.27, align 1
  %scevgep20.51.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 51
  %16233 = load i8, i8* %scevgep20.51.27, align 1
  %conv68.51.27 = zext i8 %16233 to i32
  %16234 = load i8, i8* %arrayidx70.27, align 1
  %conv71.51.27 = zext i8 %16234 to i32
  %xor72.51.27 = xor i32 %conv71.51.27, %conv68.51.27
  %conv73.51.27 = trunc i32 %xor72.51.27 to i8
  store i8 %conv73.51.27, i8* %arrayidx70.27, align 1
  %scevgep20.52.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 52
  %16235 = load i8, i8* %scevgep20.52.27, align 1
  %conv68.52.27 = zext i8 %16235 to i32
  %16236 = load i8, i8* %arrayidx70.27, align 1
  %conv71.52.27 = zext i8 %16236 to i32
  %xor72.52.27 = xor i32 %conv71.52.27, %conv68.52.27
  %conv73.52.27 = trunc i32 %xor72.52.27 to i8
  store i8 %conv73.52.27, i8* %arrayidx70.27, align 1
  %scevgep20.53.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 53
  %16237 = load i8, i8* %scevgep20.53.27, align 1
  %conv68.53.27 = zext i8 %16237 to i32
  %16238 = load i8, i8* %arrayidx70.27, align 1
  %conv71.53.27 = zext i8 %16238 to i32
  %xor72.53.27 = xor i32 %conv71.53.27, %conv68.53.27
  %conv73.53.27 = trunc i32 %xor72.53.27 to i8
  store i8 %conv73.53.27, i8* %arrayidx70.27, align 1
  %scevgep20.54.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 54
  %16239 = load i8, i8* %scevgep20.54.27, align 1
  %conv68.54.27 = zext i8 %16239 to i32
  %16240 = load i8, i8* %arrayidx70.27, align 1
  %conv71.54.27 = zext i8 %16240 to i32
  %xor72.54.27 = xor i32 %conv71.54.27, %conv68.54.27
  %conv73.54.27 = trunc i32 %xor72.54.27 to i8
  store i8 %conv73.54.27, i8* %arrayidx70.27, align 1
  %scevgep20.55.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 55
  %16241 = load i8, i8* %scevgep20.55.27, align 1
  %conv68.55.27 = zext i8 %16241 to i32
  %16242 = load i8, i8* %arrayidx70.27, align 1
  %conv71.55.27 = zext i8 %16242 to i32
  %xor72.55.27 = xor i32 %conv71.55.27, %conv68.55.27
  %conv73.55.27 = trunc i32 %xor72.55.27 to i8
  store i8 %conv73.55.27, i8* %arrayidx70.27, align 1
  %scevgep20.56.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 56
  %16243 = load i8, i8* %scevgep20.56.27, align 1
  %conv68.56.27 = zext i8 %16243 to i32
  %16244 = load i8, i8* %arrayidx70.27, align 1
  %conv71.56.27 = zext i8 %16244 to i32
  %xor72.56.27 = xor i32 %conv71.56.27, %conv68.56.27
  %conv73.56.27 = trunc i32 %xor72.56.27 to i8
  store i8 %conv73.56.27, i8* %arrayidx70.27, align 1
  %scevgep20.57.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 57
  %16245 = load i8, i8* %scevgep20.57.27, align 1
  %conv68.57.27 = zext i8 %16245 to i32
  %16246 = load i8, i8* %arrayidx70.27, align 1
  %conv71.57.27 = zext i8 %16246 to i32
  %xor72.57.27 = xor i32 %conv71.57.27, %conv68.57.27
  %conv73.57.27 = trunc i32 %xor72.57.27 to i8
  store i8 %conv73.57.27, i8* %arrayidx70.27, align 1
  %scevgep20.58.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 58
  %16247 = load i8, i8* %scevgep20.58.27, align 1
  %conv68.58.27 = zext i8 %16247 to i32
  %16248 = load i8, i8* %arrayidx70.27, align 1
  %conv71.58.27 = zext i8 %16248 to i32
  %xor72.58.27 = xor i32 %conv71.58.27, %conv68.58.27
  %conv73.58.27 = trunc i32 %xor72.58.27 to i8
  store i8 %conv73.58.27, i8* %arrayidx70.27, align 1
  %scevgep20.59.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 59
  %16249 = load i8, i8* %scevgep20.59.27, align 1
  %conv68.59.27 = zext i8 %16249 to i32
  %16250 = load i8, i8* %arrayidx70.27, align 1
  %conv71.59.27 = zext i8 %16250 to i32
  %xor72.59.27 = xor i32 %conv71.59.27, %conv68.59.27
  %conv73.59.27 = trunc i32 %xor72.59.27 to i8
  store i8 %conv73.59.27, i8* %arrayidx70.27, align 1
  %scevgep20.60.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 0, i64 60
  %16251 = load i8, i8* %scevgep20.60.27, align 1
  %conv68.60.27 = zext i8 %16251 to i32
  %16252 = load i8, i8* %arrayidx70.27, align 1
  %conv71.60.27 = zext i8 %16252 to i32
  %xor72.60.27 = xor i32 %conv71.60.27, %conv68.60.27
  %conv73.60.27 = trunc i32 %xor72.60.27 to i8
  store i8 %conv73.60.27, i8* %arrayidx70.27, align 1
  %scevgep19.27 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16130, i64 0, i64 1, i64 0
  %16253 = bitcast i8* %scevgep19.27 to [61 x [61 x i8]]*
  %arrayidx51.28 = getelementptr inbounds i8, i8* %a, i64 28
  %16254 = load i8, i8* %arrayidx51.28, align 1
  %arrayidx53.28 = getelementptr inbounds i8, i8* %b, i64 28
  %16255 = load i8, i8* %arrayidx53.28, align 1
  %call54.28 = call zeroext i8 @mult(i8 zeroext %16254, i8 zeroext %16255)
  %arrayidx56.28 = getelementptr inbounds i8, i8* %c, i64 28
  store i8 %call54.28, i8* %arrayidx56.28, align 1
  %arrayidx70.28 = getelementptr inbounds i8, i8* %c, i64 28
  %scevgep20.28324 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 0
  %16256 = load i8, i8* %scevgep20.28324, align 1
  %conv68.28325 = zext i8 %16256 to i32
  %16257 = load i8, i8* %arrayidx70.28, align 1
  %conv71.28326 = zext i8 %16257 to i32
  %xor72.28327 = xor i32 %conv71.28326, %conv68.28325
  %conv73.28328 = trunc i32 %xor72.28327 to i8
  store i8 %conv73.28328, i8* %arrayidx70.28, align 1
  %scevgep20.1.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 1
  %16258 = load i8, i8* %scevgep20.1.28, align 1
  %conv68.1.28 = zext i8 %16258 to i32
  %16259 = load i8, i8* %arrayidx70.28, align 1
  %conv71.1.28 = zext i8 %16259 to i32
  %xor72.1.28 = xor i32 %conv71.1.28, %conv68.1.28
  %conv73.1.28 = trunc i32 %xor72.1.28 to i8
  store i8 %conv73.1.28, i8* %arrayidx70.28, align 1
  %scevgep20.2.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 2
  %16260 = load i8, i8* %scevgep20.2.28, align 1
  %conv68.2.28 = zext i8 %16260 to i32
  %16261 = load i8, i8* %arrayidx70.28, align 1
  %conv71.2.28 = zext i8 %16261 to i32
  %xor72.2.28 = xor i32 %conv71.2.28, %conv68.2.28
  %conv73.2.28 = trunc i32 %xor72.2.28 to i8
  store i8 %conv73.2.28, i8* %arrayidx70.28, align 1
  %scevgep20.3.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 3
  %16262 = load i8, i8* %scevgep20.3.28, align 1
  %conv68.3.28 = zext i8 %16262 to i32
  %16263 = load i8, i8* %arrayidx70.28, align 1
  %conv71.3.28 = zext i8 %16263 to i32
  %xor72.3.28 = xor i32 %conv71.3.28, %conv68.3.28
  %conv73.3.28 = trunc i32 %xor72.3.28 to i8
  store i8 %conv73.3.28, i8* %arrayidx70.28, align 1
  %scevgep20.4.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 4
  %16264 = load i8, i8* %scevgep20.4.28, align 1
  %conv68.4.28 = zext i8 %16264 to i32
  %16265 = load i8, i8* %arrayidx70.28, align 1
  %conv71.4.28 = zext i8 %16265 to i32
  %xor72.4.28 = xor i32 %conv71.4.28, %conv68.4.28
  %conv73.4.28 = trunc i32 %xor72.4.28 to i8
  store i8 %conv73.4.28, i8* %arrayidx70.28, align 1
  %scevgep20.5.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 5
  %16266 = load i8, i8* %scevgep20.5.28, align 1
  %conv68.5.28 = zext i8 %16266 to i32
  %16267 = load i8, i8* %arrayidx70.28, align 1
  %conv71.5.28 = zext i8 %16267 to i32
  %xor72.5.28 = xor i32 %conv71.5.28, %conv68.5.28
  %conv73.5.28 = trunc i32 %xor72.5.28 to i8
  store i8 %conv73.5.28, i8* %arrayidx70.28, align 1
  %scevgep20.6.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 6
  %16268 = load i8, i8* %scevgep20.6.28, align 1
  %conv68.6.28 = zext i8 %16268 to i32
  %16269 = load i8, i8* %arrayidx70.28, align 1
  %conv71.6.28 = zext i8 %16269 to i32
  %xor72.6.28 = xor i32 %conv71.6.28, %conv68.6.28
  %conv73.6.28 = trunc i32 %xor72.6.28 to i8
  store i8 %conv73.6.28, i8* %arrayidx70.28, align 1
  %scevgep20.7.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 7
  %16270 = load i8, i8* %scevgep20.7.28, align 1
  %conv68.7.28 = zext i8 %16270 to i32
  %16271 = load i8, i8* %arrayidx70.28, align 1
  %conv71.7.28 = zext i8 %16271 to i32
  %xor72.7.28 = xor i32 %conv71.7.28, %conv68.7.28
  %conv73.7.28 = trunc i32 %xor72.7.28 to i8
  store i8 %conv73.7.28, i8* %arrayidx70.28, align 1
  %scevgep20.8.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 8
  %16272 = load i8, i8* %scevgep20.8.28, align 1
  %conv68.8.28 = zext i8 %16272 to i32
  %16273 = load i8, i8* %arrayidx70.28, align 1
  %conv71.8.28 = zext i8 %16273 to i32
  %xor72.8.28 = xor i32 %conv71.8.28, %conv68.8.28
  %conv73.8.28 = trunc i32 %xor72.8.28 to i8
  store i8 %conv73.8.28, i8* %arrayidx70.28, align 1
  %scevgep20.9.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 9
  %16274 = load i8, i8* %scevgep20.9.28, align 1
  %conv68.9.28 = zext i8 %16274 to i32
  %16275 = load i8, i8* %arrayidx70.28, align 1
  %conv71.9.28 = zext i8 %16275 to i32
  %xor72.9.28 = xor i32 %conv71.9.28, %conv68.9.28
  %conv73.9.28 = trunc i32 %xor72.9.28 to i8
  store i8 %conv73.9.28, i8* %arrayidx70.28, align 1
  %scevgep20.10.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 10
  %16276 = load i8, i8* %scevgep20.10.28, align 1
  %conv68.10.28 = zext i8 %16276 to i32
  %16277 = load i8, i8* %arrayidx70.28, align 1
  %conv71.10.28 = zext i8 %16277 to i32
  %xor72.10.28 = xor i32 %conv71.10.28, %conv68.10.28
  %conv73.10.28 = trunc i32 %xor72.10.28 to i8
  store i8 %conv73.10.28, i8* %arrayidx70.28, align 1
  %scevgep20.11.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 11
  %16278 = load i8, i8* %scevgep20.11.28, align 1
  %conv68.11.28 = zext i8 %16278 to i32
  %16279 = load i8, i8* %arrayidx70.28, align 1
  %conv71.11.28 = zext i8 %16279 to i32
  %xor72.11.28 = xor i32 %conv71.11.28, %conv68.11.28
  %conv73.11.28 = trunc i32 %xor72.11.28 to i8
  store i8 %conv73.11.28, i8* %arrayidx70.28, align 1
  %scevgep20.12.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 12
  %16280 = load i8, i8* %scevgep20.12.28, align 1
  %conv68.12.28 = zext i8 %16280 to i32
  %16281 = load i8, i8* %arrayidx70.28, align 1
  %conv71.12.28 = zext i8 %16281 to i32
  %xor72.12.28 = xor i32 %conv71.12.28, %conv68.12.28
  %conv73.12.28 = trunc i32 %xor72.12.28 to i8
  store i8 %conv73.12.28, i8* %arrayidx70.28, align 1
  %scevgep20.13.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 13
  %16282 = load i8, i8* %scevgep20.13.28, align 1
  %conv68.13.28 = zext i8 %16282 to i32
  %16283 = load i8, i8* %arrayidx70.28, align 1
  %conv71.13.28 = zext i8 %16283 to i32
  %xor72.13.28 = xor i32 %conv71.13.28, %conv68.13.28
  %conv73.13.28 = trunc i32 %xor72.13.28 to i8
  store i8 %conv73.13.28, i8* %arrayidx70.28, align 1
  %scevgep20.14.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 14
  %16284 = load i8, i8* %scevgep20.14.28, align 1
  %conv68.14.28 = zext i8 %16284 to i32
  %16285 = load i8, i8* %arrayidx70.28, align 1
  %conv71.14.28 = zext i8 %16285 to i32
  %xor72.14.28 = xor i32 %conv71.14.28, %conv68.14.28
  %conv73.14.28 = trunc i32 %xor72.14.28 to i8
  store i8 %conv73.14.28, i8* %arrayidx70.28, align 1
  %scevgep20.15.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 15
  %16286 = load i8, i8* %scevgep20.15.28, align 1
  %conv68.15.28 = zext i8 %16286 to i32
  %16287 = load i8, i8* %arrayidx70.28, align 1
  %conv71.15.28 = zext i8 %16287 to i32
  %xor72.15.28 = xor i32 %conv71.15.28, %conv68.15.28
  %conv73.15.28 = trunc i32 %xor72.15.28 to i8
  store i8 %conv73.15.28, i8* %arrayidx70.28, align 1
  %scevgep20.16.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 16
  %16288 = load i8, i8* %scevgep20.16.28, align 1
  %conv68.16.28 = zext i8 %16288 to i32
  %16289 = load i8, i8* %arrayidx70.28, align 1
  %conv71.16.28 = zext i8 %16289 to i32
  %xor72.16.28 = xor i32 %conv71.16.28, %conv68.16.28
  %conv73.16.28 = trunc i32 %xor72.16.28 to i8
  store i8 %conv73.16.28, i8* %arrayidx70.28, align 1
  %scevgep20.17.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 17
  %16290 = load i8, i8* %scevgep20.17.28, align 1
  %conv68.17.28 = zext i8 %16290 to i32
  %16291 = load i8, i8* %arrayidx70.28, align 1
  %conv71.17.28 = zext i8 %16291 to i32
  %xor72.17.28 = xor i32 %conv71.17.28, %conv68.17.28
  %conv73.17.28 = trunc i32 %xor72.17.28 to i8
  store i8 %conv73.17.28, i8* %arrayidx70.28, align 1
  %scevgep20.18.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 18
  %16292 = load i8, i8* %scevgep20.18.28, align 1
  %conv68.18.28 = zext i8 %16292 to i32
  %16293 = load i8, i8* %arrayidx70.28, align 1
  %conv71.18.28 = zext i8 %16293 to i32
  %xor72.18.28 = xor i32 %conv71.18.28, %conv68.18.28
  %conv73.18.28 = trunc i32 %xor72.18.28 to i8
  store i8 %conv73.18.28, i8* %arrayidx70.28, align 1
  %scevgep20.19.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 19
  %16294 = load i8, i8* %scevgep20.19.28, align 1
  %conv68.19.28 = zext i8 %16294 to i32
  %16295 = load i8, i8* %arrayidx70.28, align 1
  %conv71.19.28 = zext i8 %16295 to i32
  %xor72.19.28 = xor i32 %conv71.19.28, %conv68.19.28
  %conv73.19.28 = trunc i32 %xor72.19.28 to i8
  store i8 %conv73.19.28, i8* %arrayidx70.28, align 1
  %scevgep20.20.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 20
  %16296 = load i8, i8* %scevgep20.20.28, align 1
  %conv68.20.28 = zext i8 %16296 to i32
  %16297 = load i8, i8* %arrayidx70.28, align 1
  %conv71.20.28 = zext i8 %16297 to i32
  %xor72.20.28 = xor i32 %conv71.20.28, %conv68.20.28
  %conv73.20.28 = trunc i32 %xor72.20.28 to i8
  store i8 %conv73.20.28, i8* %arrayidx70.28, align 1
  %scevgep20.21.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 21
  %16298 = load i8, i8* %scevgep20.21.28, align 1
  %conv68.21.28 = zext i8 %16298 to i32
  %16299 = load i8, i8* %arrayidx70.28, align 1
  %conv71.21.28 = zext i8 %16299 to i32
  %xor72.21.28 = xor i32 %conv71.21.28, %conv68.21.28
  %conv73.21.28 = trunc i32 %xor72.21.28 to i8
  store i8 %conv73.21.28, i8* %arrayidx70.28, align 1
  %scevgep20.22.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 22
  %16300 = load i8, i8* %scevgep20.22.28, align 1
  %conv68.22.28 = zext i8 %16300 to i32
  %16301 = load i8, i8* %arrayidx70.28, align 1
  %conv71.22.28 = zext i8 %16301 to i32
  %xor72.22.28 = xor i32 %conv71.22.28, %conv68.22.28
  %conv73.22.28 = trunc i32 %xor72.22.28 to i8
  store i8 %conv73.22.28, i8* %arrayidx70.28, align 1
  %scevgep20.23.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 23
  %16302 = load i8, i8* %scevgep20.23.28, align 1
  %conv68.23.28 = zext i8 %16302 to i32
  %16303 = load i8, i8* %arrayidx70.28, align 1
  %conv71.23.28 = zext i8 %16303 to i32
  %xor72.23.28 = xor i32 %conv71.23.28, %conv68.23.28
  %conv73.23.28 = trunc i32 %xor72.23.28 to i8
  store i8 %conv73.23.28, i8* %arrayidx70.28, align 1
  %scevgep20.24.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 24
  %16304 = load i8, i8* %scevgep20.24.28, align 1
  %conv68.24.28 = zext i8 %16304 to i32
  %16305 = load i8, i8* %arrayidx70.28, align 1
  %conv71.24.28 = zext i8 %16305 to i32
  %xor72.24.28 = xor i32 %conv71.24.28, %conv68.24.28
  %conv73.24.28 = trunc i32 %xor72.24.28 to i8
  store i8 %conv73.24.28, i8* %arrayidx70.28, align 1
  %scevgep20.25.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 25
  %16306 = load i8, i8* %scevgep20.25.28, align 1
  %conv68.25.28 = zext i8 %16306 to i32
  %16307 = load i8, i8* %arrayidx70.28, align 1
  %conv71.25.28 = zext i8 %16307 to i32
  %xor72.25.28 = xor i32 %conv71.25.28, %conv68.25.28
  %conv73.25.28 = trunc i32 %xor72.25.28 to i8
  store i8 %conv73.25.28, i8* %arrayidx70.28, align 1
  %scevgep20.26.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 26
  %16308 = load i8, i8* %scevgep20.26.28, align 1
  %conv68.26.28 = zext i8 %16308 to i32
  %16309 = load i8, i8* %arrayidx70.28, align 1
  %conv71.26.28 = zext i8 %16309 to i32
  %xor72.26.28 = xor i32 %conv71.26.28, %conv68.26.28
  %conv73.26.28 = trunc i32 %xor72.26.28 to i8
  store i8 %conv73.26.28, i8* %arrayidx70.28, align 1
  %scevgep20.27.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 27
  %16310 = load i8, i8* %scevgep20.27.28, align 1
  %conv68.27.28 = zext i8 %16310 to i32
  %16311 = load i8, i8* %arrayidx70.28, align 1
  %conv71.27.28 = zext i8 %16311 to i32
  %xor72.27.28 = xor i32 %conv71.27.28, %conv68.27.28
  %conv73.27.28 = trunc i32 %xor72.27.28 to i8
  store i8 %conv73.27.28, i8* %arrayidx70.28, align 1
  %scevgep20.29.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 29
  %16312 = load i8, i8* %scevgep20.29.28, align 1
  %conv68.29.28 = zext i8 %16312 to i32
  %16313 = load i8, i8* %arrayidx70.28, align 1
  %conv71.29.28 = zext i8 %16313 to i32
  %xor72.29.28 = xor i32 %conv71.29.28, %conv68.29.28
  %conv73.29.28 = trunc i32 %xor72.29.28 to i8
  store i8 %conv73.29.28, i8* %arrayidx70.28, align 1
  %scevgep20.30.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 30
  %16314 = load i8, i8* %scevgep20.30.28, align 1
  %conv68.30.28 = zext i8 %16314 to i32
  %16315 = load i8, i8* %arrayidx70.28, align 1
  %conv71.30.28 = zext i8 %16315 to i32
  %xor72.30.28 = xor i32 %conv71.30.28, %conv68.30.28
  %conv73.30.28 = trunc i32 %xor72.30.28 to i8
  store i8 %conv73.30.28, i8* %arrayidx70.28, align 1
  %scevgep20.31.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 31
  %16316 = load i8, i8* %scevgep20.31.28, align 1
  %conv68.31.28 = zext i8 %16316 to i32
  %16317 = load i8, i8* %arrayidx70.28, align 1
  %conv71.31.28 = zext i8 %16317 to i32
  %xor72.31.28 = xor i32 %conv71.31.28, %conv68.31.28
  %conv73.31.28 = trunc i32 %xor72.31.28 to i8
  store i8 %conv73.31.28, i8* %arrayidx70.28, align 1
  %scevgep20.32.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 32
  %16318 = load i8, i8* %scevgep20.32.28, align 1
  %conv68.32.28 = zext i8 %16318 to i32
  %16319 = load i8, i8* %arrayidx70.28, align 1
  %conv71.32.28 = zext i8 %16319 to i32
  %xor72.32.28 = xor i32 %conv71.32.28, %conv68.32.28
  %conv73.32.28 = trunc i32 %xor72.32.28 to i8
  store i8 %conv73.32.28, i8* %arrayidx70.28, align 1
  %scevgep20.33.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 33
  %16320 = load i8, i8* %scevgep20.33.28, align 1
  %conv68.33.28 = zext i8 %16320 to i32
  %16321 = load i8, i8* %arrayidx70.28, align 1
  %conv71.33.28 = zext i8 %16321 to i32
  %xor72.33.28 = xor i32 %conv71.33.28, %conv68.33.28
  %conv73.33.28 = trunc i32 %xor72.33.28 to i8
  store i8 %conv73.33.28, i8* %arrayidx70.28, align 1
  %scevgep20.34.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 34
  %16322 = load i8, i8* %scevgep20.34.28, align 1
  %conv68.34.28 = zext i8 %16322 to i32
  %16323 = load i8, i8* %arrayidx70.28, align 1
  %conv71.34.28 = zext i8 %16323 to i32
  %xor72.34.28 = xor i32 %conv71.34.28, %conv68.34.28
  %conv73.34.28 = trunc i32 %xor72.34.28 to i8
  store i8 %conv73.34.28, i8* %arrayidx70.28, align 1
  %scevgep20.35.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 35
  %16324 = load i8, i8* %scevgep20.35.28, align 1
  %conv68.35.28 = zext i8 %16324 to i32
  %16325 = load i8, i8* %arrayidx70.28, align 1
  %conv71.35.28 = zext i8 %16325 to i32
  %xor72.35.28 = xor i32 %conv71.35.28, %conv68.35.28
  %conv73.35.28 = trunc i32 %xor72.35.28 to i8
  store i8 %conv73.35.28, i8* %arrayidx70.28, align 1
  %scevgep20.36.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 36
  %16326 = load i8, i8* %scevgep20.36.28, align 1
  %conv68.36.28 = zext i8 %16326 to i32
  %16327 = load i8, i8* %arrayidx70.28, align 1
  %conv71.36.28 = zext i8 %16327 to i32
  %xor72.36.28 = xor i32 %conv71.36.28, %conv68.36.28
  %conv73.36.28 = trunc i32 %xor72.36.28 to i8
  store i8 %conv73.36.28, i8* %arrayidx70.28, align 1
  %scevgep20.37.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 37
  %16328 = load i8, i8* %scevgep20.37.28, align 1
  %conv68.37.28 = zext i8 %16328 to i32
  %16329 = load i8, i8* %arrayidx70.28, align 1
  %conv71.37.28 = zext i8 %16329 to i32
  %xor72.37.28 = xor i32 %conv71.37.28, %conv68.37.28
  %conv73.37.28 = trunc i32 %xor72.37.28 to i8
  store i8 %conv73.37.28, i8* %arrayidx70.28, align 1
  %scevgep20.38.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 38
  %16330 = load i8, i8* %scevgep20.38.28, align 1
  %conv68.38.28 = zext i8 %16330 to i32
  %16331 = load i8, i8* %arrayidx70.28, align 1
  %conv71.38.28 = zext i8 %16331 to i32
  %xor72.38.28 = xor i32 %conv71.38.28, %conv68.38.28
  %conv73.38.28 = trunc i32 %xor72.38.28 to i8
  store i8 %conv73.38.28, i8* %arrayidx70.28, align 1
  %scevgep20.39.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 39
  %16332 = load i8, i8* %scevgep20.39.28, align 1
  %conv68.39.28 = zext i8 %16332 to i32
  %16333 = load i8, i8* %arrayidx70.28, align 1
  %conv71.39.28 = zext i8 %16333 to i32
  %xor72.39.28 = xor i32 %conv71.39.28, %conv68.39.28
  %conv73.39.28 = trunc i32 %xor72.39.28 to i8
  store i8 %conv73.39.28, i8* %arrayidx70.28, align 1
  %scevgep20.40.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 40
  %16334 = load i8, i8* %scevgep20.40.28, align 1
  %conv68.40.28 = zext i8 %16334 to i32
  %16335 = load i8, i8* %arrayidx70.28, align 1
  %conv71.40.28 = zext i8 %16335 to i32
  %xor72.40.28 = xor i32 %conv71.40.28, %conv68.40.28
  %conv73.40.28 = trunc i32 %xor72.40.28 to i8
  store i8 %conv73.40.28, i8* %arrayidx70.28, align 1
  %scevgep20.41.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 41
  %16336 = load i8, i8* %scevgep20.41.28, align 1
  %conv68.41.28 = zext i8 %16336 to i32
  %16337 = load i8, i8* %arrayidx70.28, align 1
  %conv71.41.28 = zext i8 %16337 to i32
  %xor72.41.28 = xor i32 %conv71.41.28, %conv68.41.28
  %conv73.41.28 = trunc i32 %xor72.41.28 to i8
  store i8 %conv73.41.28, i8* %arrayidx70.28, align 1
  %scevgep20.42.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 42
  %16338 = load i8, i8* %scevgep20.42.28, align 1
  %conv68.42.28 = zext i8 %16338 to i32
  %16339 = load i8, i8* %arrayidx70.28, align 1
  %conv71.42.28 = zext i8 %16339 to i32
  %xor72.42.28 = xor i32 %conv71.42.28, %conv68.42.28
  %conv73.42.28 = trunc i32 %xor72.42.28 to i8
  store i8 %conv73.42.28, i8* %arrayidx70.28, align 1
  %scevgep20.43.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 43
  %16340 = load i8, i8* %scevgep20.43.28, align 1
  %conv68.43.28 = zext i8 %16340 to i32
  %16341 = load i8, i8* %arrayidx70.28, align 1
  %conv71.43.28 = zext i8 %16341 to i32
  %xor72.43.28 = xor i32 %conv71.43.28, %conv68.43.28
  %conv73.43.28 = trunc i32 %xor72.43.28 to i8
  store i8 %conv73.43.28, i8* %arrayidx70.28, align 1
  %scevgep20.44.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 44
  %16342 = load i8, i8* %scevgep20.44.28, align 1
  %conv68.44.28 = zext i8 %16342 to i32
  %16343 = load i8, i8* %arrayidx70.28, align 1
  %conv71.44.28 = zext i8 %16343 to i32
  %xor72.44.28 = xor i32 %conv71.44.28, %conv68.44.28
  %conv73.44.28 = trunc i32 %xor72.44.28 to i8
  store i8 %conv73.44.28, i8* %arrayidx70.28, align 1
  %scevgep20.45.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 45
  %16344 = load i8, i8* %scevgep20.45.28, align 1
  %conv68.45.28 = zext i8 %16344 to i32
  %16345 = load i8, i8* %arrayidx70.28, align 1
  %conv71.45.28 = zext i8 %16345 to i32
  %xor72.45.28 = xor i32 %conv71.45.28, %conv68.45.28
  %conv73.45.28 = trunc i32 %xor72.45.28 to i8
  store i8 %conv73.45.28, i8* %arrayidx70.28, align 1
  %scevgep20.46.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 46
  %16346 = load i8, i8* %scevgep20.46.28, align 1
  %conv68.46.28 = zext i8 %16346 to i32
  %16347 = load i8, i8* %arrayidx70.28, align 1
  %conv71.46.28 = zext i8 %16347 to i32
  %xor72.46.28 = xor i32 %conv71.46.28, %conv68.46.28
  %conv73.46.28 = trunc i32 %xor72.46.28 to i8
  store i8 %conv73.46.28, i8* %arrayidx70.28, align 1
  %scevgep20.47.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 47
  %16348 = load i8, i8* %scevgep20.47.28, align 1
  %conv68.47.28 = zext i8 %16348 to i32
  %16349 = load i8, i8* %arrayidx70.28, align 1
  %conv71.47.28 = zext i8 %16349 to i32
  %xor72.47.28 = xor i32 %conv71.47.28, %conv68.47.28
  %conv73.47.28 = trunc i32 %xor72.47.28 to i8
  store i8 %conv73.47.28, i8* %arrayidx70.28, align 1
  %scevgep20.48.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 48
  %16350 = load i8, i8* %scevgep20.48.28, align 1
  %conv68.48.28 = zext i8 %16350 to i32
  %16351 = load i8, i8* %arrayidx70.28, align 1
  %conv71.48.28 = zext i8 %16351 to i32
  %xor72.48.28 = xor i32 %conv71.48.28, %conv68.48.28
  %conv73.48.28 = trunc i32 %xor72.48.28 to i8
  store i8 %conv73.48.28, i8* %arrayidx70.28, align 1
  %scevgep20.49.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 49
  %16352 = load i8, i8* %scevgep20.49.28, align 1
  %conv68.49.28 = zext i8 %16352 to i32
  %16353 = load i8, i8* %arrayidx70.28, align 1
  %conv71.49.28 = zext i8 %16353 to i32
  %xor72.49.28 = xor i32 %conv71.49.28, %conv68.49.28
  %conv73.49.28 = trunc i32 %xor72.49.28 to i8
  store i8 %conv73.49.28, i8* %arrayidx70.28, align 1
  %scevgep20.50.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 50
  %16354 = load i8, i8* %scevgep20.50.28, align 1
  %conv68.50.28 = zext i8 %16354 to i32
  %16355 = load i8, i8* %arrayidx70.28, align 1
  %conv71.50.28 = zext i8 %16355 to i32
  %xor72.50.28 = xor i32 %conv71.50.28, %conv68.50.28
  %conv73.50.28 = trunc i32 %xor72.50.28 to i8
  store i8 %conv73.50.28, i8* %arrayidx70.28, align 1
  %scevgep20.51.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 51
  %16356 = load i8, i8* %scevgep20.51.28, align 1
  %conv68.51.28 = zext i8 %16356 to i32
  %16357 = load i8, i8* %arrayidx70.28, align 1
  %conv71.51.28 = zext i8 %16357 to i32
  %xor72.51.28 = xor i32 %conv71.51.28, %conv68.51.28
  %conv73.51.28 = trunc i32 %xor72.51.28 to i8
  store i8 %conv73.51.28, i8* %arrayidx70.28, align 1
  %scevgep20.52.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 52
  %16358 = load i8, i8* %scevgep20.52.28, align 1
  %conv68.52.28 = zext i8 %16358 to i32
  %16359 = load i8, i8* %arrayidx70.28, align 1
  %conv71.52.28 = zext i8 %16359 to i32
  %xor72.52.28 = xor i32 %conv71.52.28, %conv68.52.28
  %conv73.52.28 = trunc i32 %xor72.52.28 to i8
  store i8 %conv73.52.28, i8* %arrayidx70.28, align 1
  %scevgep20.53.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 53
  %16360 = load i8, i8* %scevgep20.53.28, align 1
  %conv68.53.28 = zext i8 %16360 to i32
  %16361 = load i8, i8* %arrayidx70.28, align 1
  %conv71.53.28 = zext i8 %16361 to i32
  %xor72.53.28 = xor i32 %conv71.53.28, %conv68.53.28
  %conv73.53.28 = trunc i32 %xor72.53.28 to i8
  store i8 %conv73.53.28, i8* %arrayidx70.28, align 1
  %scevgep20.54.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 54
  %16362 = load i8, i8* %scevgep20.54.28, align 1
  %conv68.54.28 = zext i8 %16362 to i32
  %16363 = load i8, i8* %arrayidx70.28, align 1
  %conv71.54.28 = zext i8 %16363 to i32
  %xor72.54.28 = xor i32 %conv71.54.28, %conv68.54.28
  %conv73.54.28 = trunc i32 %xor72.54.28 to i8
  store i8 %conv73.54.28, i8* %arrayidx70.28, align 1
  %scevgep20.55.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 55
  %16364 = load i8, i8* %scevgep20.55.28, align 1
  %conv68.55.28 = zext i8 %16364 to i32
  %16365 = load i8, i8* %arrayidx70.28, align 1
  %conv71.55.28 = zext i8 %16365 to i32
  %xor72.55.28 = xor i32 %conv71.55.28, %conv68.55.28
  %conv73.55.28 = trunc i32 %xor72.55.28 to i8
  store i8 %conv73.55.28, i8* %arrayidx70.28, align 1
  %scevgep20.56.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 56
  %16366 = load i8, i8* %scevgep20.56.28, align 1
  %conv68.56.28 = zext i8 %16366 to i32
  %16367 = load i8, i8* %arrayidx70.28, align 1
  %conv71.56.28 = zext i8 %16367 to i32
  %xor72.56.28 = xor i32 %conv71.56.28, %conv68.56.28
  %conv73.56.28 = trunc i32 %xor72.56.28 to i8
  store i8 %conv73.56.28, i8* %arrayidx70.28, align 1
  %scevgep20.57.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 57
  %16368 = load i8, i8* %scevgep20.57.28, align 1
  %conv68.57.28 = zext i8 %16368 to i32
  %16369 = load i8, i8* %arrayidx70.28, align 1
  %conv71.57.28 = zext i8 %16369 to i32
  %xor72.57.28 = xor i32 %conv71.57.28, %conv68.57.28
  %conv73.57.28 = trunc i32 %xor72.57.28 to i8
  store i8 %conv73.57.28, i8* %arrayidx70.28, align 1
  %scevgep20.58.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 58
  %16370 = load i8, i8* %scevgep20.58.28, align 1
  %conv68.58.28 = zext i8 %16370 to i32
  %16371 = load i8, i8* %arrayidx70.28, align 1
  %conv71.58.28 = zext i8 %16371 to i32
  %xor72.58.28 = xor i32 %conv71.58.28, %conv68.58.28
  %conv73.58.28 = trunc i32 %xor72.58.28 to i8
  store i8 %conv73.58.28, i8* %arrayidx70.28, align 1
  %scevgep20.59.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 59
  %16372 = load i8, i8* %scevgep20.59.28, align 1
  %conv68.59.28 = zext i8 %16372 to i32
  %16373 = load i8, i8* %arrayidx70.28, align 1
  %conv71.59.28 = zext i8 %16373 to i32
  %xor72.59.28 = xor i32 %conv71.59.28, %conv68.59.28
  %conv73.59.28 = trunc i32 %xor72.59.28 to i8
  store i8 %conv73.59.28, i8* %arrayidx70.28, align 1
  %scevgep20.60.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 0, i64 60
  %16374 = load i8, i8* %scevgep20.60.28, align 1
  %conv68.60.28 = zext i8 %16374 to i32
  %16375 = load i8, i8* %arrayidx70.28, align 1
  %conv71.60.28 = zext i8 %16375 to i32
  %xor72.60.28 = xor i32 %conv71.60.28, %conv68.60.28
  %conv73.60.28 = trunc i32 %xor72.60.28 to i8
  store i8 %conv73.60.28, i8* %arrayidx70.28, align 1
  %scevgep19.28 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16253, i64 0, i64 1, i64 0
  %16376 = bitcast i8* %scevgep19.28 to [61 x [61 x i8]]*
  %arrayidx51.29 = getelementptr inbounds i8, i8* %a, i64 29
  %16377 = load i8, i8* %arrayidx51.29, align 1
  %arrayidx53.29 = getelementptr inbounds i8, i8* %b, i64 29
  %16378 = load i8, i8* %arrayidx53.29, align 1
  %call54.29 = call zeroext i8 @mult(i8 zeroext %16377, i8 zeroext %16378)
  %arrayidx56.29 = getelementptr inbounds i8, i8* %c, i64 29
  store i8 %call54.29, i8* %arrayidx56.29, align 1
  %arrayidx70.29 = getelementptr inbounds i8, i8* %c, i64 29
  %scevgep20.29334 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 0
  %16379 = load i8, i8* %scevgep20.29334, align 1
  %conv68.29335 = zext i8 %16379 to i32
  %16380 = load i8, i8* %arrayidx70.29, align 1
  %conv71.29336 = zext i8 %16380 to i32
  %xor72.29337 = xor i32 %conv71.29336, %conv68.29335
  %conv73.29338 = trunc i32 %xor72.29337 to i8
  store i8 %conv73.29338, i8* %arrayidx70.29, align 1
  %scevgep20.1.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 1
  %16381 = load i8, i8* %scevgep20.1.29, align 1
  %conv68.1.29 = zext i8 %16381 to i32
  %16382 = load i8, i8* %arrayidx70.29, align 1
  %conv71.1.29 = zext i8 %16382 to i32
  %xor72.1.29 = xor i32 %conv71.1.29, %conv68.1.29
  %conv73.1.29 = trunc i32 %xor72.1.29 to i8
  store i8 %conv73.1.29, i8* %arrayidx70.29, align 1
  %scevgep20.2.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 2
  %16383 = load i8, i8* %scevgep20.2.29, align 1
  %conv68.2.29 = zext i8 %16383 to i32
  %16384 = load i8, i8* %arrayidx70.29, align 1
  %conv71.2.29 = zext i8 %16384 to i32
  %xor72.2.29 = xor i32 %conv71.2.29, %conv68.2.29
  %conv73.2.29 = trunc i32 %xor72.2.29 to i8
  store i8 %conv73.2.29, i8* %arrayidx70.29, align 1
  %scevgep20.3.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 3
  %16385 = load i8, i8* %scevgep20.3.29, align 1
  %conv68.3.29 = zext i8 %16385 to i32
  %16386 = load i8, i8* %arrayidx70.29, align 1
  %conv71.3.29 = zext i8 %16386 to i32
  %xor72.3.29 = xor i32 %conv71.3.29, %conv68.3.29
  %conv73.3.29 = trunc i32 %xor72.3.29 to i8
  store i8 %conv73.3.29, i8* %arrayidx70.29, align 1
  %scevgep20.4.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 4
  %16387 = load i8, i8* %scevgep20.4.29, align 1
  %conv68.4.29 = zext i8 %16387 to i32
  %16388 = load i8, i8* %arrayidx70.29, align 1
  %conv71.4.29 = zext i8 %16388 to i32
  %xor72.4.29 = xor i32 %conv71.4.29, %conv68.4.29
  %conv73.4.29 = trunc i32 %xor72.4.29 to i8
  store i8 %conv73.4.29, i8* %arrayidx70.29, align 1
  %scevgep20.5.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 5
  %16389 = load i8, i8* %scevgep20.5.29, align 1
  %conv68.5.29 = zext i8 %16389 to i32
  %16390 = load i8, i8* %arrayidx70.29, align 1
  %conv71.5.29 = zext i8 %16390 to i32
  %xor72.5.29 = xor i32 %conv71.5.29, %conv68.5.29
  %conv73.5.29 = trunc i32 %xor72.5.29 to i8
  store i8 %conv73.5.29, i8* %arrayidx70.29, align 1
  %scevgep20.6.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 6
  %16391 = load i8, i8* %scevgep20.6.29, align 1
  %conv68.6.29 = zext i8 %16391 to i32
  %16392 = load i8, i8* %arrayidx70.29, align 1
  %conv71.6.29 = zext i8 %16392 to i32
  %xor72.6.29 = xor i32 %conv71.6.29, %conv68.6.29
  %conv73.6.29 = trunc i32 %xor72.6.29 to i8
  store i8 %conv73.6.29, i8* %arrayidx70.29, align 1
  %scevgep20.7.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 7
  %16393 = load i8, i8* %scevgep20.7.29, align 1
  %conv68.7.29 = zext i8 %16393 to i32
  %16394 = load i8, i8* %arrayidx70.29, align 1
  %conv71.7.29 = zext i8 %16394 to i32
  %xor72.7.29 = xor i32 %conv71.7.29, %conv68.7.29
  %conv73.7.29 = trunc i32 %xor72.7.29 to i8
  store i8 %conv73.7.29, i8* %arrayidx70.29, align 1
  %scevgep20.8.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 8
  %16395 = load i8, i8* %scevgep20.8.29, align 1
  %conv68.8.29 = zext i8 %16395 to i32
  %16396 = load i8, i8* %arrayidx70.29, align 1
  %conv71.8.29 = zext i8 %16396 to i32
  %xor72.8.29 = xor i32 %conv71.8.29, %conv68.8.29
  %conv73.8.29 = trunc i32 %xor72.8.29 to i8
  store i8 %conv73.8.29, i8* %arrayidx70.29, align 1
  %scevgep20.9.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 9
  %16397 = load i8, i8* %scevgep20.9.29, align 1
  %conv68.9.29 = zext i8 %16397 to i32
  %16398 = load i8, i8* %arrayidx70.29, align 1
  %conv71.9.29 = zext i8 %16398 to i32
  %xor72.9.29 = xor i32 %conv71.9.29, %conv68.9.29
  %conv73.9.29 = trunc i32 %xor72.9.29 to i8
  store i8 %conv73.9.29, i8* %arrayidx70.29, align 1
  %scevgep20.10.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 10
  %16399 = load i8, i8* %scevgep20.10.29, align 1
  %conv68.10.29 = zext i8 %16399 to i32
  %16400 = load i8, i8* %arrayidx70.29, align 1
  %conv71.10.29 = zext i8 %16400 to i32
  %xor72.10.29 = xor i32 %conv71.10.29, %conv68.10.29
  %conv73.10.29 = trunc i32 %xor72.10.29 to i8
  store i8 %conv73.10.29, i8* %arrayidx70.29, align 1
  %scevgep20.11.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 11
  %16401 = load i8, i8* %scevgep20.11.29, align 1
  %conv68.11.29 = zext i8 %16401 to i32
  %16402 = load i8, i8* %arrayidx70.29, align 1
  %conv71.11.29 = zext i8 %16402 to i32
  %xor72.11.29 = xor i32 %conv71.11.29, %conv68.11.29
  %conv73.11.29 = trunc i32 %xor72.11.29 to i8
  store i8 %conv73.11.29, i8* %arrayidx70.29, align 1
  %scevgep20.12.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 12
  %16403 = load i8, i8* %scevgep20.12.29, align 1
  %conv68.12.29 = zext i8 %16403 to i32
  %16404 = load i8, i8* %arrayidx70.29, align 1
  %conv71.12.29 = zext i8 %16404 to i32
  %xor72.12.29 = xor i32 %conv71.12.29, %conv68.12.29
  %conv73.12.29 = trunc i32 %xor72.12.29 to i8
  store i8 %conv73.12.29, i8* %arrayidx70.29, align 1
  %scevgep20.13.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 13
  %16405 = load i8, i8* %scevgep20.13.29, align 1
  %conv68.13.29 = zext i8 %16405 to i32
  %16406 = load i8, i8* %arrayidx70.29, align 1
  %conv71.13.29 = zext i8 %16406 to i32
  %xor72.13.29 = xor i32 %conv71.13.29, %conv68.13.29
  %conv73.13.29 = trunc i32 %xor72.13.29 to i8
  store i8 %conv73.13.29, i8* %arrayidx70.29, align 1
  %scevgep20.14.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 14
  %16407 = load i8, i8* %scevgep20.14.29, align 1
  %conv68.14.29 = zext i8 %16407 to i32
  %16408 = load i8, i8* %arrayidx70.29, align 1
  %conv71.14.29 = zext i8 %16408 to i32
  %xor72.14.29 = xor i32 %conv71.14.29, %conv68.14.29
  %conv73.14.29 = trunc i32 %xor72.14.29 to i8
  store i8 %conv73.14.29, i8* %arrayidx70.29, align 1
  %scevgep20.15.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 15
  %16409 = load i8, i8* %scevgep20.15.29, align 1
  %conv68.15.29 = zext i8 %16409 to i32
  %16410 = load i8, i8* %arrayidx70.29, align 1
  %conv71.15.29 = zext i8 %16410 to i32
  %xor72.15.29 = xor i32 %conv71.15.29, %conv68.15.29
  %conv73.15.29 = trunc i32 %xor72.15.29 to i8
  store i8 %conv73.15.29, i8* %arrayidx70.29, align 1
  %scevgep20.16.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 16
  %16411 = load i8, i8* %scevgep20.16.29, align 1
  %conv68.16.29 = zext i8 %16411 to i32
  %16412 = load i8, i8* %arrayidx70.29, align 1
  %conv71.16.29 = zext i8 %16412 to i32
  %xor72.16.29 = xor i32 %conv71.16.29, %conv68.16.29
  %conv73.16.29 = trunc i32 %xor72.16.29 to i8
  store i8 %conv73.16.29, i8* %arrayidx70.29, align 1
  %scevgep20.17.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 17
  %16413 = load i8, i8* %scevgep20.17.29, align 1
  %conv68.17.29 = zext i8 %16413 to i32
  %16414 = load i8, i8* %arrayidx70.29, align 1
  %conv71.17.29 = zext i8 %16414 to i32
  %xor72.17.29 = xor i32 %conv71.17.29, %conv68.17.29
  %conv73.17.29 = trunc i32 %xor72.17.29 to i8
  store i8 %conv73.17.29, i8* %arrayidx70.29, align 1
  %scevgep20.18.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 18
  %16415 = load i8, i8* %scevgep20.18.29, align 1
  %conv68.18.29 = zext i8 %16415 to i32
  %16416 = load i8, i8* %arrayidx70.29, align 1
  %conv71.18.29 = zext i8 %16416 to i32
  %xor72.18.29 = xor i32 %conv71.18.29, %conv68.18.29
  %conv73.18.29 = trunc i32 %xor72.18.29 to i8
  store i8 %conv73.18.29, i8* %arrayidx70.29, align 1
  %scevgep20.19.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 19
  %16417 = load i8, i8* %scevgep20.19.29, align 1
  %conv68.19.29 = zext i8 %16417 to i32
  %16418 = load i8, i8* %arrayidx70.29, align 1
  %conv71.19.29 = zext i8 %16418 to i32
  %xor72.19.29 = xor i32 %conv71.19.29, %conv68.19.29
  %conv73.19.29 = trunc i32 %xor72.19.29 to i8
  store i8 %conv73.19.29, i8* %arrayidx70.29, align 1
  %scevgep20.20.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 20
  %16419 = load i8, i8* %scevgep20.20.29, align 1
  %conv68.20.29 = zext i8 %16419 to i32
  %16420 = load i8, i8* %arrayidx70.29, align 1
  %conv71.20.29 = zext i8 %16420 to i32
  %xor72.20.29 = xor i32 %conv71.20.29, %conv68.20.29
  %conv73.20.29 = trunc i32 %xor72.20.29 to i8
  store i8 %conv73.20.29, i8* %arrayidx70.29, align 1
  %scevgep20.21.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 21
  %16421 = load i8, i8* %scevgep20.21.29, align 1
  %conv68.21.29 = zext i8 %16421 to i32
  %16422 = load i8, i8* %arrayidx70.29, align 1
  %conv71.21.29 = zext i8 %16422 to i32
  %xor72.21.29 = xor i32 %conv71.21.29, %conv68.21.29
  %conv73.21.29 = trunc i32 %xor72.21.29 to i8
  store i8 %conv73.21.29, i8* %arrayidx70.29, align 1
  %scevgep20.22.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 22
  %16423 = load i8, i8* %scevgep20.22.29, align 1
  %conv68.22.29 = zext i8 %16423 to i32
  %16424 = load i8, i8* %arrayidx70.29, align 1
  %conv71.22.29 = zext i8 %16424 to i32
  %xor72.22.29 = xor i32 %conv71.22.29, %conv68.22.29
  %conv73.22.29 = trunc i32 %xor72.22.29 to i8
  store i8 %conv73.22.29, i8* %arrayidx70.29, align 1
  %scevgep20.23.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 23
  %16425 = load i8, i8* %scevgep20.23.29, align 1
  %conv68.23.29 = zext i8 %16425 to i32
  %16426 = load i8, i8* %arrayidx70.29, align 1
  %conv71.23.29 = zext i8 %16426 to i32
  %xor72.23.29 = xor i32 %conv71.23.29, %conv68.23.29
  %conv73.23.29 = trunc i32 %xor72.23.29 to i8
  store i8 %conv73.23.29, i8* %arrayidx70.29, align 1
  %scevgep20.24.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 24
  %16427 = load i8, i8* %scevgep20.24.29, align 1
  %conv68.24.29 = zext i8 %16427 to i32
  %16428 = load i8, i8* %arrayidx70.29, align 1
  %conv71.24.29 = zext i8 %16428 to i32
  %xor72.24.29 = xor i32 %conv71.24.29, %conv68.24.29
  %conv73.24.29 = trunc i32 %xor72.24.29 to i8
  store i8 %conv73.24.29, i8* %arrayidx70.29, align 1
  %scevgep20.25.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 25
  %16429 = load i8, i8* %scevgep20.25.29, align 1
  %conv68.25.29 = zext i8 %16429 to i32
  %16430 = load i8, i8* %arrayidx70.29, align 1
  %conv71.25.29 = zext i8 %16430 to i32
  %xor72.25.29 = xor i32 %conv71.25.29, %conv68.25.29
  %conv73.25.29 = trunc i32 %xor72.25.29 to i8
  store i8 %conv73.25.29, i8* %arrayidx70.29, align 1
  %scevgep20.26.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 26
  %16431 = load i8, i8* %scevgep20.26.29, align 1
  %conv68.26.29 = zext i8 %16431 to i32
  %16432 = load i8, i8* %arrayidx70.29, align 1
  %conv71.26.29 = zext i8 %16432 to i32
  %xor72.26.29 = xor i32 %conv71.26.29, %conv68.26.29
  %conv73.26.29 = trunc i32 %xor72.26.29 to i8
  store i8 %conv73.26.29, i8* %arrayidx70.29, align 1
  %scevgep20.27.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 27
  %16433 = load i8, i8* %scevgep20.27.29, align 1
  %conv68.27.29 = zext i8 %16433 to i32
  %16434 = load i8, i8* %arrayidx70.29, align 1
  %conv71.27.29 = zext i8 %16434 to i32
  %xor72.27.29 = xor i32 %conv71.27.29, %conv68.27.29
  %conv73.27.29 = trunc i32 %xor72.27.29 to i8
  store i8 %conv73.27.29, i8* %arrayidx70.29, align 1
  %scevgep20.28.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 28
  %16435 = load i8, i8* %scevgep20.28.29, align 1
  %conv68.28.29 = zext i8 %16435 to i32
  %16436 = load i8, i8* %arrayidx70.29, align 1
  %conv71.28.29 = zext i8 %16436 to i32
  %xor72.28.29 = xor i32 %conv71.28.29, %conv68.28.29
  %conv73.28.29 = trunc i32 %xor72.28.29 to i8
  store i8 %conv73.28.29, i8* %arrayidx70.29, align 1
  %scevgep20.30.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 30
  %16437 = load i8, i8* %scevgep20.30.29, align 1
  %conv68.30.29 = zext i8 %16437 to i32
  %16438 = load i8, i8* %arrayidx70.29, align 1
  %conv71.30.29 = zext i8 %16438 to i32
  %xor72.30.29 = xor i32 %conv71.30.29, %conv68.30.29
  %conv73.30.29 = trunc i32 %xor72.30.29 to i8
  store i8 %conv73.30.29, i8* %arrayidx70.29, align 1
  %scevgep20.31.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 31
  %16439 = load i8, i8* %scevgep20.31.29, align 1
  %conv68.31.29 = zext i8 %16439 to i32
  %16440 = load i8, i8* %arrayidx70.29, align 1
  %conv71.31.29 = zext i8 %16440 to i32
  %xor72.31.29 = xor i32 %conv71.31.29, %conv68.31.29
  %conv73.31.29 = trunc i32 %xor72.31.29 to i8
  store i8 %conv73.31.29, i8* %arrayidx70.29, align 1
  %scevgep20.32.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 32
  %16441 = load i8, i8* %scevgep20.32.29, align 1
  %conv68.32.29 = zext i8 %16441 to i32
  %16442 = load i8, i8* %arrayidx70.29, align 1
  %conv71.32.29 = zext i8 %16442 to i32
  %xor72.32.29 = xor i32 %conv71.32.29, %conv68.32.29
  %conv73.32.29 = trunc i32 %xor72.32.29 to i8
  store i8 %conv73.32.29, i8* %arrayidx70.29, align 1
  %scevgep20.33.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 33
  %16443 = load i8, i8* %scevgep20.33.29, align 1
  %conv68.33.29 = zext i8 %16443 to i32
  %16444 = load i8, i8* %arrayidx70.29, align 1
  %conv71.33.29 = zext i8 %16444 to i32
  %xor72.33.29 = xor i32 %conv71.33.29, %conv68.33.29
  %conv73.33.29 = trunc i32 %xor72.33.29 to i8
  store i8 %conv73.33.29, i8* %arrayidx70.29, align 1
  %scevgep20.34.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 34
  %16445 = load i8, i8* %scevgep20.34.29, align 1
  %conv68.34.29 = zext i8 %16445 to i32
  %16446 = load i8, i8* %arrayidx70.29, align 1
  %conv71.34.29 = zext i8 %16446 to i32
  %xor72.34.29 = xor i32 %conv71.34.29, %conv68.34.29
  %conv73.34.29 = trunc i32 %xor72.34.29 to i8
  store i8 %conv73.34.29, i8* %arrayidx70.29, align 1
  %scevgep20.35.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 35
  %16447 = load i8, i8* %scevgep20.35.29, align 1
  %conv68.35.29 = zext i8 %16447 to i32
  %16448 = load i8, i8* %arrayidx70.29, align 1
  %conv71.35.29 = zext i8 %16448 to i32
  %xor72.35.29 = xor i32 %conv71.35.29, %conv68.35.29
  %conv73.35.29 = trunc i32 %xor72.35.29 to i8
  store i8 %conv73.35.29, i8* %arrayidx70.29, align 1
  %scevgep20.36.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 36
  %16449 = load i8, i8* %scevgep20.36.29, align 1
  %conv68.36.29 = zext i8 %16449 to i32
  %16450 = load i8, i8* %arrayidx70.29, align 1
  %conv71.36.29 = zext i8 %16450 to i32
  %xor72.36.29 = xor i32 %conv71.36.29, %conv68.36.29
  %conv73.36.29 = trunc i32 %xor72.36.29 to i8
  store i8 %conv73.36.29, i8* %arrayidx70.29, align 1
  %scevgep20.37.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 37
  %16451 = load i8, i8* %scevgep20.37.29, align 1
  %conv68.37.29 = zext i8 %16451 to i32
  %16452 = load i8, i8* %arrayidx70.29, align 1
  %conv71.37.29 = zext i8 %16452 to i32
  %xor72.37.29 = xor i32 %conv71.37.29, %conv68.37.29
  %conv73.37.29 = trunc i32 %xor72.37.29 to i8
  store i8 %conv73.37.29, i8* %arrayidx70.29, align 1
  %scevgep20.38.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 38
  %16453 = load i8, i8* %scevgep20.38.29, align 1
  %conv68.38.29 = zext i8 %16453 to i32
  %16454 = load i8, i8* %arrayidx70.29, align 1
  %conv71.38.29 = zext i8 %16454 to i32
  %xor72.38.29 = xor i32 %conv71.38.29, %conv68.38.29
  %conv73.38.29 = trunc i32 %xor72.38.29 to i8
  store i8 %conv73.38.29, i8* %arrayidx70.29, align 1
  %scevgep20.39.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 39
  %16455 = load i8, i8* %scevgep20.39.29, align 1
  %conv68.39.29 = zext i8 %16455 to i32
  %16456 = load i8, i8* %arrayidx70.29, align 1
  %conv71.39.29 = zext i8 %16456 to i32
  %xor72.39.29 = xor i32 %conv71.39.29, %conv68.39.29
  %conv73.39.29 = trunc i32 %xor72.39.29 to i8
  store i8 %conv73.39.29, i8* %arrayidx70.29, align 1
  %scevgep20.40.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 40
  %16457 = load i8, i8* %scevgep20.40.29, align 1
  %conv68.40.29 = zext i8 %16457 to i32
  %16458 = load i8, i8* %arrayidx70.29, align 1
  %conv71.40.29 = zext i8 %16458 to i32
  %xor72.40.29 = xor i32 %conv71.40.29, %conv68.40.29
  %conv73.40.29 = trunc i32 %xor72.40.29 to i8
  store i8 %conv73.40.29, i8* %arrayidx70.29, align 1
  %scevgep20.41.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 41
  %16459 = load i8, i8* %scevgep20.41.29, align 1
  %conv68.41.29 = zext i8 %16459 to i32
  %16460 = load i8, i8* %arrayidx70.29, align 1
  %conv71.41.29 = zext i8 %16460 to i32
  %xor72.41.29 = xor i32 %conv71.41.29, %conv68.41.29
  %conv73.41.29 = trunc i32 %xor72.41.29 to i8
  store i8 %conv73.41.29, i8* %arrayidx70.29, align 1
  %scevgep20.42.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 42
  %16461 = load i8, i8* %scevgep20.42.29, align 1
  %conv68.42.29 = zext i8 %16461 to i32
  %16462 = load i8, i8* %arrayidx70.29, align 1
  %conv71.42.29 = zext i8 %16462 to i32
  %xor72.42.29 = xor i32 %conv71.42.29, %conv68.42.29
  %conv73.42.29 = trunc i32 %xor72.42.29 to i8
  store i8 %conv73.42.29, i8* %arrayidx70.29, align 1
  %scevgep20.43.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 43
  %16463 = load i8, i8* %scevgep20.43.29, align 1
  %conv68.43.29 = zext i8 %16463 to i32
  %16464 = load i8, i8* %arrayidx70.29, align 1
  %conv71.43.29 = zext i8 %16464 to i32
  %xor72.43.29 = xor i32 %conv71.43.29, %conv68.43.29
  %conv73.43.29 = trunc i32 %xor72.43.29 to i8
  store i8 %conv73.43.29, i8* %arrayidx70.29, align 1
  %scevgep20.44.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 44
  %16465 = load i8, i8* %scevgep20.44.29, align 1
  %conv68.44.29 = zext i8 %16465 to i32
  %16466 = load i8, i8* %arrayidx70.29, align 1
  %conv71.44.29 = zext i8 %16466 to i32
  %xor72.44.29 = xor i32 %conv71.44.29, %conv68.44.29
  %conv73.44.29 = trunc i32 %xor72.44.29 to i8
  store i8 %conv73.44.29, i8* %arrayidx70.29, align 1
  %scevgep20.45.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 45
  %16467 = load i8, i8* %scevgep20.45.29, align 1
  %conv68.45.29 = zext i8 %16467 to i32
  %16468 = load i8, i8* %arrayidx70.29, align 1
  %conv71.45.29 = zext i8 %16468 to i32
  %xor72.45.29 = xor i32 %conv71.45.29, %conv68.45.29
  %conv73.45.29 = trunc i32 %xor72.45.29 to i8
  store i8 %conv73.45.29, i8* %arrayidx70.29, align 1
  %scevgep20.46.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 46
  %16469 = load i8, i8* %scevgep20.46.29, align 1
  %conv68.46.29 = zext i8 %16469 to i32
  %16470 = load i8, i8* %arrayidx70.29, align 1
  %conv71.46.29 = zext i8 %16470 to i32
  %xor72.46.29 = xor i32 %conv71.46.29, %conv68.46.29
  %conv73.46.29 = trunc i32 %xor72.46.29 to i8
  store i8 %conv73.46.29, i8* %arrayidx70.29, align 1
  %scevgep20.47.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 47
  %16471 = load i8, i8* %scevgep20.47.29, align 1
  %conv68.47.29 = zext i8 %16471 to i32
  %16472 = load i8, i8* %arrayidx70.29, align 1
  %conv71.47.29 = zext i8 %16472 to i32
  %xor72.47.29 = xor i32 %conv71.47.29, %conv68.47.29
  %conv73.47.29 = trunc i32 %xor72.47.29 to i8
  store i8 %conv73.47.29, i8* %arrayidx70.29, align 1
  %scevgep20.48.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 48
  %16473 = load i8, i8* %scevgep20.48.29, align 1
  %conv68.48.29 = zext i8 %16473 to i32
  %16474 = load i8, i8* %arrayidx70.29, align 1
  %conv71.48.29 = zext i8 %16474 to i32
  %xor72.48.29 = xor i32 %conv71.48.29, %conv68.48.29
  %conv73.48.29 = trunc i32 %xor72.48.29 to i8
  store i8 %conv73.48.29, i8* %arrayidx70.29, align 1
  %scevgep20.49.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 49
  %16475 = load i8, i8* %scevgep20.49.29, align 1
  %conv68.49.29 = zext i8 %16475 to i32
  %16476 = load i8, i8* %arrayidx70.29, align 1
  %conv71.49.29 = zext i8 %16476 to i32
  %xor72.49.29 = xor i32 %conv71.49.29, %conv68.49.29
  %conv73.49.29 = trunc i32 %xor72.49.29 to i8
  store i8 %conv73.49.29, i8* %arrayidx70.29, align 1
  %scevgep20.50.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 50
  %16477 = load i8, i8* %scevgep20.50.29, align 1
  %conv68.50.29 = zext i8 %16477 to i32
  %16478 = load i8, i8* %arrayidx70.29, align 1
  %conv71.50.29 = zext i8 %16478 to i32
  %xor72.50.29 = xor i32 %conv71.50.29, %conv68.50.29
  %conv73.50.29 = trunc i32 %xor72.50.29 to i8
  store i8 %conv73.50.29, i8* %arrayidx70.29, align 1
  %scevgep20.51.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 51
  %16479 = load i8, i8* %scevgep20.51.29, align 1
  %conv68.51.29 = zext i8 %16479 to i32
  %16480 = load i8, i8* %arrayidx70.29, align 1
  %conv71.51.29 = zext i8 %16480 to i32
  %xor72.51.29 = xor i32 %conv71.51.29, %conv68.51.29
  %conv73.51.29 = trunc i32 %xor72.51.29 to i8
  store i8 %conv73.51.29, i8* %arrayidx70.29, align 1
  %scevgep20.52.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 52
  %16481 = load i8, i8* %scevgep20.52.29, align 1
  %conv68.52.29 = zext i8 %16481 to i32
  %16482 = load i8, i8* %arrayidx70.29, align 1
  %conv71.52.29 = zext i8 %16482 to i32
  %xor72.52.29 = xor i32 %conv71.52.29, %conv68.52.29
  %conv73.52.29 = trunc i32 %xor72.52.29 to i8
  store i8 %conv73.52.29, i8* %arrayidx70.29, align 1
  %scevgep20.53.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 53
  %16483 = load i8, i8* %scevgep20.53.29, align 1
  %conv68.53.29 = zext i8 %16483 to i32
  %16484 = load i8, i8* %arrayidx70.29, align 1
  %conv71.53.29 = zext i8 %16484 to i32
  %xor72.53.29 = xor i32 %conv71.53.29, %conv68.53.29
  %conv73.53.29 = trunc i32 %xor72.53.29 to i8
  store i8 %conv73.53.29, i8* %arrayidx70.29, align 1
  %scevgep20.54.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 54
  %16485 = load i8, i8* %scevgep20.54.29, align 1
  %conv68.54.29 = zext i8 %16485 to i32
  %16486 = load i8, i8* %arrayidx70.29, align 1
  %conv71.54.29 = zext i8 %16486 to i32
  %xor72.54.29 = xor i32 %conv71.54.29, %conv68.54.29
  %conv73.54.29 = trunc i32 %xor72.54.29 to i8
  store i8 %conv73.54.29, i8* %arrayidx70.29, align 1
  %scevgep20.55.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 55
  %16487 = load i8, i8* %scevgep20.55.29, align 1
  %conv68.55.29 = zext i8 %16487 to i32
  %16488 = load i8, i8* %arrayidx70.29, align 1
  %conv71.55.29 = zext i8 %16488 to i32
  %xor72.55.29 = xor i32 %conv71.55.29, %conv68.55.29
  %conv73.55.29 = trunc i32 %xor72.55.29 to i8
  store i8 %conv73.55.29, i8* %arrayidx70.29, align 1
  %scevgep20.56.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 56
  %16489 = load i8, i8* %scevgep20.56.29, align 1
  %conv68.56.29 = zext i8 %16489 to i32
  %16490 = load i8, i8* %arrayidx70.29, align 1
  %conv71.56.29 = zext i8 %16490 to i32
  %xor72.56.29 = xor i32 %conv71.56.29, %conv68.56.29
  %conv73.56.29 = trunc i32 %xor72.56.29 to i8
  store i8 %conv73.56.29, i8* %arrayidx70.29, align 1
  %scevgep20.57.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 57
  %16491 = load i8, i8* %scevgep20.57.29, align 1
  %conv68.57.29 = zext i8 %16491 to i32
  %16492 = load i8, i8* %arrayidx70.29, align 1
  %conv71.57.29 = zext i8 %16492 to i32
  %xor72.57.29 = xor i32 %conv71.57.29, %conv68.57.29
  %conv73.57.29 = trunc i32 %xor72.57.29 to i8
  store i8 %conv73.57.29, i8* %arrayidx70.29, align 1
  %scevgep20.58.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 58
  %16493 = load i8, i8* %scevgep20.58.29, align 1
  %conv68.58.29 = zext i8 %16493 to i32
  %16494 = load i8, i8* %arrayidx70.29, align 1
  %conv71.58.29 = zext i8 %16494 to i32
  %xor72.58.29 = xor i32 %conv71.58.29, %conv68.58.29
  %conv73.58.29 = trunc i32 %xor72.58.29 to i8
  store i8 %conv73.58.29, i8* %arrayidx70.29, align 1
  %scevgep20.59.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 59
  %16495 = load i8, i8* %scevgep20.59.29, align 1
  %conv68.59.29 = zext i8 %16495 to i32
  %16496 = load i8, i8* %arrayidx70.29, align 1
  %conv71.59.29 = zext i8 %16496 to i32
  %xor72.59.29 = xor i32 %conv71.59.29, %conv68.59.29
  %conv73.59.29 = trunc i32 %xor72.59.29 to i8
  store i8 %conv73.59.29, i8* %arrayidx70.29, align 1
  %scevgep20.60.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 0, i64 60
  %16497 = load i8, i8* %scevgep20.60.29, align 1
  %conv68.60.29 = zext i8 %16497 to i32
  %16498 = load i8, i8* %arrayidx70.29, align 1
  %conv71.60.29 = zext i8 %16498 to i32
  %xor72.60.29 = xor i32 %conv71.60.29, %conv68.60.29
  %conv73.60.29 = trunc i32 %xor72.60.29 to i8
  store i8 %conv73.60.29, i8* %arrayidx70.29, align 1
  %scevgep19.29 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16376, i64 0, i64 1, i64 0
  %16499 = bitcast i8* %scevgep19.29 to [61 x [61 x i8]]*
  %arrayidx51.30 = getelementptr inbounds i8, i8* %a, i64 30
  %16500 = load i8, i8* %arrayidx51.30, align 1
  %arrayidx53.30 = getelementptr inbounds i8, i8* %b, i64 30
  %16501 = load i8, i8* %arrayidx53.30, align 1
  %call54.30 = call zeroext i8 @mult(i8 zeroext %16500, i8 zeroext %16501)
  %arrayidx56.30 = getelementptr inbounds i8, i8* %c, i64 30
  store i8 %call54.30, i8* %arrayidx56.30, align 1
  %arrayidx70.30 = getelementptr inbounds i8, i8* %c, i64 30
  %scevgep20.30344 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 0
  %16502 = load i8, i8* %scevgep20.30344, align 1
  %conv68.30345 = zext i8 %16502 to i32
  %16503 = load i8, i8* %arrayidx70.30, align 1
  %conv71.30346 = zext i8 %16503 to i32
  %xor72.30347 = xor i32 %conv71.30346, %conv68.30345
  %conv73.30348 = trunc i32 %xor72.30347 to i8
  store i8 %conv73.30348, i8* %arrayidx70.30, align 1
  %scevgep20.1.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 1
  %16504 = load i8, i8* %scevgep20.1.30, align 1
  %conv68.1.30 = zext i8 %16504 to i32
  %16505 = load i8, i8* %arrayidx70.30, align 1
  %conv71.1.30 = zext i8 %16505 to i32
  %xor72.1.30 = xor i32 %conv71.1.30, %conv68.1.30
  %conv73.1.30 = trunc i32 %xor72.1.30 to i8
  store i8 %conv73.1.30, i8* %arrayidx70.30, align 1
  %scevgep20.2.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 2
  %16506 = load i8, i8* %scevgep20.2.30, align 1
  %conv68.2.30 = zext i8 %16506 to i32
  %16507 = load i8, i8* %arrayidx70.30, align 1
  %conv71.2.30 = zext i8 %16507 to i32
  %xor72.2.30 = xor i32 %conv71.2.30, %conv68.2.30
  %conv73.2.30 = trunc i32 %xor72.2.30 to i8
  store i8 %conv73.2.30, i8* %arrayidx70.30, align 1
  %scevgep20.3.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 3
  %16508 = load i8, i8* %scevgep20.3.30, align 1
  %conv68.3.30 = zext i8 %16508 to i32
  %16509 = load i8, i8* %arrayidx70.30, align 1
  %conv71.3.30 = zext i8 %16509 to i32
  %xor72.3.30 = xor i32 %conv71.3.30, %conv68.3.30
  %conv73.3.30 = trunc i32 %xor72.3.30 to i8
  store i8 %conv73.3.30, i8* %arrayidx70.30, align 1
  %scevgep20.4.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 4
  %16510 = load i8, i8* %scevgep20.4.30, align 1
  %conv68.4.30 = zext i8 %16510 to i32
  %16511 = load i8, i8* %arrayidx70.30, align 1
  %conv71.4.30 = zext i8 %16511 to i32
  %xor72.4.30 = xor i32 %conv71.4.30, %conv68.4.30
  %conv73.4.30 = trunc i32 %xor72.4.30 to i8
  store i8 %conv73.4.30, i8* %arrayidx70.30, align 1
  %scevgep20.5.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 5
  %16512 = load i8, i8* %scevgep20.5.30, align 1
  %conv68.5.30 = zext i8 %16512 to i32
  %16513 = load i8, i8* %arrayidx70.30, align 1
  %conv71.5.30 = zext i8 %16513 to i32
  %xor72.5.30 = xor i32 %conv71.5.30, %conv68.5.30
  %conv73.5.30 = trunc i32 %xor72.5.30 to i8
  store i8 %conv73.5.30, i8* %arrayidx70.30, align 1
  %scevgep20.6.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 6
  %16514 = load i8, i8* %scevgep20.6.30, align 1
  %conv68.6.30 = zext i8 %16514 to i32
  %16515 = load i8, i8* %arrayidx70.30, align 1
  %conv71.6.30 = zext i8 %16515 to i32
  %xor72.6.30 = xor i32 %conv71.6.30, %conv68.6.30
  %conv73.6.30 = trunc i32 %xor72.6.30 to i8
  store i8 %conv73.6.30, i8* %arrayidx70.30, align 1
  %scevgep20.7.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 7
  %16516 = load i8, i8* %scevgep20.7.30, align 1
  %conv68.7.30 = zext i8 %16516 to i32
  %16517 = load i8, i8* %arrayidx70.30, align 1
  %conv71.7.30 = zext i8 %16517 to i32
  %xor72.7.30 = xor i32 %conv71.7.30, %conv68.7.30
  %conv73.7.30 = trunc i32 %xor72.7.30 to i8
  store i8 %conv73.7.30, i8* %arrayidx70.30, align 1
  %scevgep20.8.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 8
  %16518 = load i8, i8* %scevgep20.8.30, align 1
  %conv68.8.30 = zext i8 %16518 to i32
  %16519 = load i8, i8* %arrayidx70.30, align 1
  %conv71.8.30 = zext i8 %16519 to i32
  %xor72.8.30 = xor i32 %conv71.8.30, %conv68.8.30
  %conv73.8.30 = trunc i32 %xor72.8.30 to i8
  store i8 %conv73.8.30, i8* %arrayidx70.30, align 1
  %scevgep20.9.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 9
  %16520 = load i8, i8* %scevgep20.9.30, align 1
  %conv68.9.30 = zext i8 %16520 to i32
  %16521 = load i8, i8* %arrayidx70.30, align 1
  %conv71.9.30 = zext i8 %16521 to i32
  %xor72.9.30 = xor i32 %conv71.9.30, %conv68.9.30
  %conv73.9.30 = trunc i32 %xor72.9.30 to i8
  store i8 %conv73.9.30, i8* %arrayidx70.30, align 1
  %scevgep20.10.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 10
  %16522 = load i8, i8* %scevgep20.10.30, align 1
  %conv68.10.30 = zext i8 %16522 to i32
  %16523 = load i8, i8* %arrayidx70.30, align 1
  %conv71.10.30 = zext i8 %16523 to i32
  %xor72.10.30 = xor i32 %conv71.10.30, %conv68.10.30
  %conv73.10.30 = trunc i32 %xor72.10.30 to i8
  store i8 %conv73.10.30, i8* %arrayidx70.30, align 1
  %scevgep20.11.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 11
  %16524 = load i8, i8* %scevgep20.11.30, align 1
  %conv68.11.30 = zext i8 %16524 to i32
  %16525 = load i8, i8* %arrayidx70.30, align 1
  %conv71.11.30 = zext i8 %16525 to i32
  %xor72.11.30 = xor i32 %conv71.11.30, %conv68.11.30
  %conv73.11.30 = trunc i32 %xor72.11.30 to i8
  store i8 %conv73.11.30, i8* %arrayidx70.30, align 1
  %scevgep20.12.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 12
  %16526 = load i8, i8* %scevgep20.12.30, align 1
  %conv68.12.30 = zext i8 %16526 to i32
  %16527 = load i8, i8* %arrayidx70.30, align 1
  %conv71.12.30 = zext i8 %16527 to i32
  %xor72.12.30 = xor i32 %conv71.12.30, %conv68.12.30
  %conv73.12.30 = trunc i32 %xor72.12.30 to i8
  store i8 %conv73.12.30, i8* %arrayidx70.30, align 1
  %scevgep20.13.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 13
  %16528 = load i8, i8* %scevgep20.13.30, align 1
  %conv68.13.30 = zext i8 %16528 to i32
  %16529 = load i8, i8* %arrayidx70.30, align 1
  %conv71.13.30 = zext i8 %16529 to i32
  %xor72.13.30 = xor i32 %conv71.13.30, %conv68.13.30
  %conv73.13.30 = trunc i32 %xor72.13.30 to i8
  store i8 %conv73.13.30, i8* %arrayidx70.30, align 1
  %scevgep20.14.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 14
  %16530 = load i8, i8* %scevgep20.14.30, align 1
  %conv68.14.30 = zext i8 %16530 to i32
  %16531 = load i8, i8* %arrayidx70.30, align 1
  %conv71.14.30 = zext i8 %16531 to i32
  %xor72.14.30 = xor i32 %conv71.14.30, %conv68.14.30
  %conv73.14.30 = trunc i32 %xor72.14.30 to i8
  store i8 %conv73.14.30, i8* %arrayidx70.30, align 1
  %scevgep20.15.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 15
  %16532 = load i8, i8* %scevgep20.15.30, align 1
  %conv68.15.30 = zext i8 %16532 to i32
  %16533 = load i8, i8* %arrayidx70.30, align 1
  %conv71.15.30 = zext i8 %16533 to i32
  %xor72.15.30 = xor i32 %conv71.15.30, %conv68.15.30
  %conv73.15.30 = trunc i32 %xor72.15.30 to i8
  store i8 %conv73.15.30, i8* %arrayidx70.30, align 1
  %scevgep20.16.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 16
  %16534 = load i8, i8* %scevgep20.16.30, align 1
  %conv68.16.30 = zext i8 %16534 to i32
  %16535 = load i8, i8* %arrayidx70.30, align 1
  %conv71.16.30 = zext i8 %16535 to i32
  %xor72.16.30 = xor i32 %conv71.16.30, %conv68.16.30
  %conv73.16.30 = trunc i32 %xor72.16.30 to i8
  store i8 %conv73.16.30, i8* %arrayidx70.30, align 1
  %scevgep20.17.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 17
  %16536 = load i8, i8* %scevgep20.17.30, align 1
  %conv68.17.30 = zext i8 %16536 to i32
  %16537 = load i8, i8* %arrayidx70.30, align 1
  %conv71.17.30 = zext i8 %16537 to i32
  %xor72.17.30 = xor i32 %conv71.17.30, %conv68.17.30
  %conv73.17.30 = trunc i32 %xor72.17.30 to i8
  store i8 %conv73.17.30, i8* %arrayidx70.30, align 1
  %scevgep20.18.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 18
  %16538 = load i8, i8* %scevgep20.18.30, align 1
  %conv68.18.30 = zext i8 %16538 to i32
  %16539 = load i8, i8* %arrayidx70.30, align 1
  %conv71.18.30 = zext i8 %16539 to i32
  %xor72.18.30 = xor i32 %conv71.18.30, %conv68.18.30
  %conv73.18.30 = trunc i32 %xor72.18.30 to i8
  store i8 %conv73.18.30, i8* %arrayidx70.30, align 1
  %scevgep20.19.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 19
  %16540 = load i8, i8* %scevgep20.19.30, align 1
  %conv68.19.30 = zext i8 %16540 to i32
  %16541 = load i8, i8* %arrayidx70.30, align 1
  %conv71.19.30 = zext i8 %16541 to i32
  %xor72.19.30 = xor i32 %conv71.19.30, %conv68.19.30
  %conv73.19.30 = trunc i32 %xor72.19.30 to i8
  store i8 %conv73.19.30, i8* %arrayidx70.30, align 1
  %scevgep20.20.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 20
  %16542 = load i8, i8* %scevgep20.20.30, align 1
  %conv68.20.30 = zext i8 %16542 to i32
  %16543 = load i8, i8* %arrayidx70.30, align 1
  %conv71.20.30 = zext i8 %16543 to i32
  %xor72.20.30 = xor i32 %conv71.20.30, %conv68.20.30
  %conv73.20.30 = trunc i32 %xor72.20.30 to i8
  store i8 %conv73.20.30, i8* %arrayidx70.30, align 1
  %scevgep20.21.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 21
  %16544 = load i8, i8* %scevgep20.21.30, align 1
  %conv68.21.30 = zext i8 %16544 to i32
  %16545 = load i8, i8* %arrayidx70.30, align 1
  %conv71.21.30 = zext i8 %16545 to i32
  %xor72.21.30 = xor i32 %conv71.21.30, %conv68.21.30
  %conv73.21.30 = trunc i32 %xor72.21.30 to i8
  store i8 %conv73.21.30, i8* %arrayidx70.30, align 1
  %scevgep20.22.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 22
  %16546 = load i8, i8* %scevgep20.22.30, align 1
  %conv68.22.30 = zext i8 %16546 to i32
  %16547 = load i8, i8* %arrayidx70.30, align 1
  %conv71.22.30 = zext i8 %16547 to i32
  %xor72.22.30 = xor i32 %conv71.22.30, %conv68.22.30
  %conv73.22.30 = trunc i32 %xor72.22.30 to i8
  store i8 %conv73.22.30, i8* %arrayidx70.30, align 1
  %scevgep20.23.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 23
  %16548 = load i8, i8* %scevgep20.23.30, align 1
  %conv68.23.30 = zext i8 %16548 to i32
  %16549 = load i8, i8* %arrayidx70.30, align 1
  %conv71.23.30 = zext i8 %16549 to i32
  %xor72.23.30 = xor i32 %conv71.23.30, %conv68.23.30
  %conv73.23.30 = trunc i32 %xor72.23.30 to i8
  store i8 %conv73.23.30, i8* %arrayidx70.30, align 1
  %scevgep20.24.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 24
  %16550 = load i8, i8* %scevgep20.24.30, align 1
  %conv68.24.30 = zext i8 %16550 to i32
  %16551 = load i8, i8* %arrayidx70.30, align 1
  %conv71.24.30 = zext i8 %16551 to i32
  %xor72.24.30 = xor i32 %conv71.24.30, %conv68.24.30
  %conv73.24.30 = trunc i32 %xor72.24.30 to i8
  store i8 %conv73.24.30, i8* %arrayidx70.30, align 1
  %scevgep20.25.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 25
  %16552 = load i8, i8* %scevgep20.25.30, align 1
  %conv68.25.30 = zext i8 %16552 to i32
  %16553 = load i8, i8* %arrayidx70.30, align 1
  %conv71.25.30 = zext i8 %16553 to i32
  %xor72.25.30 = xor i32 %conv71.25.30, %conv68.25.30
  %conv73.25.30 = trunc i32 %xor72.25.30 to i8
  store i8 %conv73.25.30, i8* %arrayidx70.30, align 1
  %scevgep20.26.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 26
  %16554 = load i8, i8* %scevgep20.26.30, align 1
  %conv68.26.30 = zext i8 %16554 to i32
  %16555 = load i8, i8* %arrayidx70.30, align 1
  %conv71.26.30 = zext i8 %16555 to i32
  %xor72.26.30 = xor i32 %conv71.26.30, %conv68.26.30
  %conv73.26.30 = trunc i32 %xor72.26.30 to i8
  store i8 %conv73.26.30, i8* %arrayidx70.30, align 1
  %scevgep20.27.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 27
  %16556 = load i8, i8* %scevgep20.27.30, align 1
  %conv68.27.30 = zext i8 %16556 to i32
  %16557 = load i8, i8* %arrayidx70.30, align 1
  %conv71.27.30 = zext i8 %16557 to i32
  %xor72.27.30 = xor i32 %conv71.27.30, %conv68.27.30
  %conv73.27.30 = trunc i32 %xor72.27.30 to i8
  store i8 %conv73.27.30, i8* %arrayidx70.30, align 1
  %scevgep20.28.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 28
  %16558 = load i8, i8* %scevgep20.28.30, align 1
  %conv68.28.30 = zext i8 %16558 to i32
  %16559 = load i8, i8* %arrayidx70.30, align 1
  %conv71.28.30 = zext i8 %16559 to i32
  %xor72.28.30 = xor i32 %conv71.28.30, %conv68.28.30
  %conv73.28.30 = trunc i32 %xor72.28.30 to i8
  store i8 %conv73.28.30, i8* %arrayidx70.30, align 1
  %scevgep20.29.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 29
  %16560 = load i8, i8* %scevgep20.29.30, align 1
  %conv68.29.30 = zext i8 %16560 to i32
  %16561 = load i8, i8* %arrayidx70.30, align 1
  %conv71.29.30 = zext i8 %16561 to i32
  %xor72.29.30 = xor i32 %conv71.29.30, %conv68.29.30
  %conv73.29.30 = trunc i32 %xor72.29.30 to i8
  store i8 %conv73.29.30, i8* %arrayidx70.30, align 1
  %scevgep20.31.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 31
  %16562 = load i8, i8* %scevgep20.31.30, align 1
  %conv68.31.30 = zext i8 %16562 to i32
  %16563 = load i8, i8* %arrayidx70.30, align 1
  %conv71.31.30 = zext i8 %16563 to i32
  %xor72.31.30 = xor i32 %conv71.31.30, %conv68.31.30
  %conv73.31.30 = trunc i32 %xor72.31.30 to i8
  store i8 %conv73.31.30, i8* %arrayidx70.30, align 1
  %scevgep20.32.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 32
  %16564 = load i8, i8* %scevgep20.32.30, align 1
  %conv68.32.30 = zext i8 %16564 to i32
  %16565 = load i8, i8* %arrayidx70.30, align 1
  %conv71.32.30 = zext i8 %16565 to i32
  %xor72.32.30 = xor i32 %conv71.32.30, %conv68.32.30
  %conv73.32.30 = trunc i32 %xor72.32.30 to i8
  store i8 %conv73.32.30, i8* %arrayidx70.30, align 1
  %scevgep20.33.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 33
  %16566 = load i8, i8* %scevgep20.33.30, align 1
  %conv68.33.30 = zext i8 %16566 to i32
  %16567 = load i8, i8* %arrayidx70.30, align 1
  %conv71.33.30 = zext i8 %16567 to i32
  %xor72.33.30 = xor i32 %conv71.33.30, %conv68.33.30
  %conv73.33.30 = trunc i32 %xor72.33.30 to i8
  store i8 %conv73.33.30, i8* %arrayidx70.30, align 1
  %scevgep20.34.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 34
  %16568 = load i8, i8* %scevgep20.34.30, align 1
  %conv68.34.30 = zext i8 %16568 to i32
  %16569 = load i8, i8* %arrayidx70.30, align 1
  %conv71.34.30 = zext i8 %16569 to i32
  %xor72.34.30 = xor i32 %conv71.34.30, %conv68.34.30
  %conv73.34.30 = trunc i32 %xor72.34.30 to i8
  store i8 %conv73.34.30, i8* %arrayidx70.30, align 1
  %scevgep20.35.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 35
  %16570 = load i8, i8* %scevgep20.35.30, align 1
  %conv68.35.30 = zext i8 %16570 to i32
  %16571 = load i8, i8* %arrayidx70.30, align 1
  %conv71.35.30 = zext i8 %16571 to i32
  %xor72.35.30 = xor i32 %conv71.35.30, %conv68.35.30
  %conv73.35.30 = trunc i32 %xor72.35.30 to i8
  store i8 %conv73.35.30, i8* %arrayidx70.30, align 1
  %scevgep20.36.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 36
  %16572 = load i8, i8* %scevgep20.36.30, align 1
  %conv68.36.30 = zext i8 %16572 to i32
  %16573 = load i8, i8* %arrayidx70.30, align 1
  %conv71.36.30 = zext i8 %16573 to i32
  %xor72.36.30 = xor i32 %conv71.36.30, %conv68.36.30
  %conv73.36.30 = trunc i32 %xor72.36.30 to i8
  store i8 %conv73.36.30, i8* %arrayidx70.30, align 1
  %scevgep20.37.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 37
  %16574 = load i8, i8* %scevgep20.37.30, align 1
  %conv68.37.30 = zext i8 %16574 to i32
  %16575 = load i8, i8* %arrayidx70.30, align 1
  %conv71.37.30 = zext i8 %16575 to i32
  %xor72.37.30 = xor i32 %conv71.37.30, %conv68.37.30
  %conv73.37.30 = trunc i32 %xor72.37.30 to i8
  store i8 %conv73.37.30, i8* %arrayidx70.30, align 1
  %scevgep20.38.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 38
  %16576 = load i8, i8* %scevgep20.38.30, align 1
  %conv68.38.30 = zext i8 %16576 to i32
  %16577 = load i8, i8* %arrayidx70.30, align 1
  %conv71.38.30 = zext i8 %16577 to i32
  %xor72.38.30 = xor i32 %conv71.38.30, %conv68.38.30
  %conv73.38.30 = trunc i32 %xor72.38.30 to i8
  store i8 %conv73.38.30, i8* %arrayidx70.30, align 1
  %scevgep20.39.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 39
  %16578 = load i8, i8* %scevgep20.39.30, align 1
  %conv68.39.30 = zext i8 %16578 to i32
  %16579 = load i8, i8* %arrayidx70.30, align 1
  %conv71.39.30 = zext i8 %16579 to i32
  %xor72.39.30 = xor i32 %conv71.39.30, %conv68.39.30
  %conv73.39.30 = trunc i32 %xor72.39.30 to i8
  store i8 %conv73.39.30, i8* %arrayidx70.30, align 1
  %scevgep20.40.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 40
  %16580 = load i8, i8* %scevgep20.40.30, align 1
  %conv68.40.30 = zext i8 %16580 to i32
  %16581 = load i8, i8* %arrayidx70.30, align 1
  %conv71.40.30 = zext i8 %16581 to i32
  %xor72.40.30 = xor i32 %conv71.40.30, %conv68.40.30
  %conv73.40.30 = trunc i32 %xor72.40.30 to i8
  store i8 %conv73.40.30, i8* %arrayidx70.30, align 1
  %scevgep20.41.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 41
  %16582 = load i8, i8* %scevgep20.41.30, align 1
  %conv68.41.30 = zext i8 %16582 to i32
  %16583 = load i8, i8* %arrayidx70.30, align 1
  %conv71.41.30 = zext i8 %16583 to i32
  %xor72.41.30 = xor i32 %conv71.41.30, %conv68.41.30
  %conv73.41.30 = trunc i32 %xor72.41.30 to i8
  store i8 %conv73.41.30, i8* %arrayidx70.30, align 1
  %scevgep20.42.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 42
  %16584 = load i8, i8* %scevgep20.42.30, align 1
  %conv68.42.30 = zext i8 %16584 to i32
  %16585 = load i8, i8* %arrayidx70.30, align 1
  %conv71.42.30 = zext i8 %16585 to i32
  %xor72.42.30 = xor i32 %conv71.42.30, %conv68.42.30
  %conv73.42.30 = trunc i32 %xor72.42.30 to i8
  store i8 %conv73.42.30, i8* %arrayidx70.30, align 1
  %scevgep20.43.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 43
  %16586 = load i8, i8* %scevgep20.43.30, align 1
  %conv68.43.30 = zext i8 %16586 to i32
  %16587 = load i8, i8* %arrayidx70.30, align 1
  %conv71.43.30 = zext i8 %16587 to i32
  %xor72.43.30 = xor i32 %conv71.43.30, %conv68.43.30
  %conv73.43.30 = trunc i32 %xor72.43.30 to i8
  store i8 %conv73.43.30, i8* %arrayidx70.30, align 1
  %scevgep20.44.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 44
  %16588 = load i8, i8* %scevgep20.44.30, align 1
  %conv68.44.30 = zext i8 %16588 to i32
  %16589 = load i8, i8* %arrayidx70.30, align 1
  %conv71.44.30 = zext i8 %16589 to i32
  %xor72.44.30 = xor i32 %conv71.44.30, %conv68.44.30
  %conv73.44.30 = trunc i32 %xor72.44.30 to i8
  store i8 %conv73.44.30, i8* %arrayidx70.30, align 1
  %scevgep20.45.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 45
  %16590 = load i8, i8* %scevgep20.45.30, align 1
  %conv68.45.30 = zext i8 %16590 to i32
  %16591 = load i8, i8* %arrayidx70.30, align 1
  %conv71.45.30 = zext i8 %16591 to i32
  %xor72.45.30 = xor i32 %conv71.45.30, %conv68.45.30
  %conv73.45.30 = trunc i32 %xor72.45.30 to i8
  store i8 %conv73.45.30, i8* %arrayidx70.30, align 1
  %scevgep20.46.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 46
  %16592 = load i8, i8* %scevgep20.46.30, align 1
  %conv68.46.30 = zext i8 %16592 to i32
  %16593 = load i8, i8* %arrayidx70.30, align 1
  %conv71.46.30 = zext i8 %16593 to i32
  %xor72.46.30 = xor i32 %conv71.46.30, %conv68.46.30
  %conv73.46.30 = trunc i32 %xor72.46.30 to i8
  store i8 %conv73.46.30, i8* %arrayidx70.30, align 1
  %scevgep20.47.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 47
  %16594 = load i8, i8* %scevgep20.47.30, align 1
  %conv68.47.30 = zext i8 %16594 to i32
  %16595 = load i8, i8* %arrayidx70.30, align 1
  %conv71.47.30 = zext i8 %16595 to i32
  %xor72.47.30 = xor i32 %conv71.47.30, %conv68.47.30
  %conv73.47.30 = trunc i32 %xor72.47.30 to i8
  store i8 %conv73.47.30, i8* %arrayidx70.30, align 1
  %scevgep20.48.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 48
  %16596 = load i8, i8* %scevgep20.48.30, align 1
  %conv68.48.30 = zext i8 %16596 to i32
  %16597 = load i8, i8* %arrayidx70.30, align 1
  %conv71.48.30 = zext i8 %16597 to i32
  %xor72.48.30 = xor i32 %conv71.48.30, %conv68.48.30
  %conv73.48.30 = trunc i32 %xor72.48.30 to i8
  store i8 %conv73.48.30, i8* %arrayidx70.30, align 1
  %scevgep20.49.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 49
  %16598 = load i8, i8* %scevgep20.49.30, align 1
  %conv68.49.30 = zext i8 %16598 to i32
  %16599 = load i8, i8* %arrayidx70.30, align 1
  %conv71.49.30 = zext i8 %16599 to i32
  %xor72.49.30 = xor i32 %conv71.49.30, %conv68.49.30
  %conv73.49.30 = trunc i32 %xor72.49.30 to i8
  store i8 %conv73.49.30, i8* %arrayidx70.30, align 1
  %scevgep20.50.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 50
  %16600 = load i8, i8* %scevgep20.50.30, align 1
  %conv68.50.30 = zext i8 %16600 to i32
  %16601 = load i8, i8* %arrayidx70.30, align 1
  %conv71.50.30 = zext i8 %16601 to i32
  %xor72.50.30 = xor i32 %conv71.50.30, %conv68.50.30
  %conv73.50.30 = trunc i32 %xor72.50.30 to i8
  store i8 %conv73.50.30, i8* %arrayidx70.30, align 1
  %scevgep20.51.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 51
  %16602 = load i8, i8* %scevgep20.51.30, align 1
  %conv68.51.30 = zext i8 %16602 to i32
  %16603 = load i8, i8* %arrayidx70.30, align 1
  %conv71.51.30 = zext i8 %16603 to i32
  %xor72.51.30 = xor i32 %conv71.51.30, %conv68.51.30
  %conv73.51.30 = trunc i32 %xor72.51.30 to i8
  store i8 %conv73.51.30, i8* %arrayidx70.30, align 1
  %scevgep20.52.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 52
  %16604 = load i8, i8* %scevgep20.52.30, align 1
  %conv68.52.30 = zext i8 %16604 to i32
  %16605 = load i8, i8* %arrayidx70.30, align 1
  %conv71.52.30 = zext i8 %16605 to i32
  %xor72.52.30 = xor i32 %conv71.52.30, %conv68.52.30
  %conv73.52.30 = trunc i32 %xor72.52.30 to i8
  store i8 %conv73.52.30, i8* %arrayidx70.30, align 1
  %scevgep20.53.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 53
  %16606 = load i8, i8* %scevgep20.53.30, align 1
  %conv68.53.30 = zext i8 %16606 to i32
  %16607 = load i8, i8* %arrayidx70.30, align 1
  %conv71.53.30 = zext i8 %16607 to i32
  %xor72.53.30 = xor i32 %conv71.53.30, %conv68.53.30
  %conv73.53.30 = trunc i32 %xor72.53.30 to i8
  store i8 %conv73.53.30, i8* %arrayidx70.30, align 1
  %scevgep20.54.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 54
  %16608 = load i8, i8* %scevgep20.54.30, align 1
  %conv68.54.30 = zext i8 %16608 to i32
  %16609 = load i8, i8* %arrayidx70.30, align 1
  %conv71.54.30 = zext i8 %16609 to i32
  %xor72.54.30 = xor i32 %conv71.54.30, %conv68.54.30
  %conv73.54.30 = trunc i32 %xor72.54.30 to i8
  store i8 %conv73.54.30, i8* %arrayidx70.30, align 1
  %scevgep20.55.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 55
  %16610 = load i8, i8* %scevgep20.55.30, align 1
  %conv68.55.30 = zext i8 %16610 to i32
  %16611 = load i8, i8* %arrayidx70.30, align 1
  %conv71.55.30 = zext i8 %16611 to i32
  %xor72.55.30 = xor i32 %conv71.55.30, %conv68.55.30
  %conv73.55.30 = trunc i32 %xor72.55.30 to i8
  store i8 %conv73.55.30, i8* %arrayidx70.30, align 1
  %scevgep20.56.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 56
  %16612 = load i8, i8* %scevgep20.56.30, align 1
  %conv68.56.30 = zext i8 %16612 to i32
  %16613 = load i8, i8* %arrayidx70.30, align 1
  %conv71.56.30 = zext i8 %16613 to i32
  %xor72.56.30 = xor i32 %conv71.56.30, %conv68.56.30
  %conv73.56.30 = trunc i32 %xor72.56.30 to i8
  store i8 %conv73.56.30, i8* %arrayidx70.30, align 1
  %scevgep20.57.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 57
  %16614 = load i8, i8* %scevgep20.57.30, align 1
  %conv68.57.30 = zext i8 %16614 to i32
  %16615 = load i8, i8* %arrayidx70.30, align 1
  %conv71.57.30 = zext i8 %16615 to i32
  %xor72.57.30 = xor i32 %conv71.57.30, %conv68.57.30
  %conv73.57.30 = trunc i32 %xor72.57.30 to i8
  store i8 %conv73.57.30, i8* %arrayidx70.30, align 1
  %scevgep20.58.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 58
  %16616 = load i8, i8* %scevgep20.58.30, align 1
  %conv68.58.30 = zext i8 %16616 to i32
  %16617 = load i8, i8* %arrayidx70.30, align 1
  %conv71.58.30 = zext i8 %16617 to i32
  %xor72.58.30 = xor i32 %conv71.58.30, %conv68.58.30
  %conv73.58.30 = trunc i32 %xor72.58.30 to i8
  store i8 %conv73.58.30, i8* %arrayidx70.30, align 1
  %scevgep20.59.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 59
  %16618 = load i8, i8* %scevgep20.59.30, align 1
  %conv68.59.30 = zext i8 %16618 to i32
  %16619 = load i8, i8* %arrayidx70.30, align 1
  %conv71.59.30 = zext i8 %16619 to i32
  %xor72.59.30 = xor i32 %conv71.59.30, %conv68.59.30
  %conv73.59.30 = trunc i32 %xor72.59.30 to i8
  store i8 %conv73.59.30, i8* %arrayidx70.30, align 1
  %scevgep20.60.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 0, i64 60
  %16620 = load i8, i8* %scevgep20.60.30, align 1
  %conv68.60.30 = zext i8 %16620 to i32
  %16621 = load i8, i8* %arrayidx70.30, align 1
  %conv71.60.30 = zext i8 %16621 to i32
  %xor72.60.30 = xor i32 %conv71.60.30, %conv68.60.30
  %conv73.60.30 = trunc i32 %xor72.60.30 to i8
  store i8 %conv73.60.30, i8* %arrayidx70.30, align 1
  %scevgep19.30 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16499, i64 0, i64 1, i64 0
  %16622 = bitcast i8* %scevgep19.30 to [61 x [61 x i8]]*
  %arrayidx51.31 = getelementptr inbounds i8, i8* %a, i64 31
  %16623 = load i8, i8* %arrayidx51.31, align 1
  %arrayidx53.31 = getelementptr inbounds i8, i8* %b, i64 31
  %16624 = load i8, i8* %arrayidx53.31, align 1
  %call54.31 = call zeroext i8 @mult(i8 zeroext %16623, i8 zeroext %16624)
  %arrayidx56.31 = getelementptr inbounds i8, i8* %c, i64 31
  store i8 %call54.31, i8* %arrayidx56.31, align 1
  %arrayidx70.31 = getelementptr inbounds i8, i8* %c, i64 31
  %scevgep20.31354 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 0
  %16625 = load i8, i8* %scevgep20.31354, align 1
  %conv68.31355 = zext i8 %16625 to i32
  %16626 = load i8, i8* %arrayidx70.31, align 1
  %conv71.31356 = zext i8 %16626 to i32
  %xor72.31357 = xor i32 %conv71.31356, %conv68.31355
  %conv73.31358 = trunc i32 %xor72.31357 to i8
  store i8 %conv73.31358, i8* %arrayidx70.31, align 1
  %scevgep20.1.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 1
  %16627 = load i8, i8* %scevgep20.1.31, align 1
  %conv68.1.31 = zext i8 %16627 to i32
  %16628 = load i8, i8* %arrayidx70.31, align 1
  %conv71.1.31 = zext i8 %16628 to i32
  %xor72.1.31 = xor i32 %conv71.1.31, %conv68.1.31
  %conv73.1.31 = trunc i32 %xor72.1.31 to i8
  store i8 %conv73.1.31, i8* %arrayidx70.31, align 1
  %scevgep20.2.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 2
  %16629 = load i8, i8* %scevgep20.2.31, align 1
  %conv68.2.31 = zext i8 %16629 to i32
  %16630 = load i8, i8* %arrayidx70.31, align 1
  %conv71.2.31 = zext i8 %16630 to i32
  %xor72.2.31 = xor i32 %conv71.2.31, %conv68.2.31
  %conv73.2.31 = trunc i32 %xor72.2.31 to i8
  store i8 %conv73.2.31, i8* %arrayidx70.31, align 1
  %scevgep20.3.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 3
  %16631 = load i8, i8* %scevgep20.3.31, align 1
  %conv68.3.31 = zext i8 %16631 to i32
  %16632 = load i8, i8* %arrayidx70.31, align 1
  %conv71.3.31 = zext i8 %16632 to i32
  %xor72.3.31 = xor i32 %conv71.3.31, %conv68.3.31
  %conv73.3.31 = trunc i32 %xor72.3.31 to i8
  store i8 %conv73.3.31, i8* %arrayidx70.31, align 1
  %scevgep20.4.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 4
  %16633 = load i8, i8* %scevgep20.4.31, align 1
  %conv68.4.31 = zext i8 %16633 to i32
  %16634 = load i8, i8* %arrayidx70.31, align 1
  %conv71.4.31 = zext i8 %16634 to i32
  %xor72.4.31 = xor i32 %conv71.4.31, %conv68.4.31
  %conv73.4.31 = trunc i32 %xor72.4.31 to i8
  store i8 %conv73.4.31, i8* %arrayidx70.31, align 1
  %scevgep20.5.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 5
  %16635 = load i8, i8* %scevgep20.5.31, align 1
  %conv68.5.31 = zext i8 %16635 to i32
  %16636 = load i8, i8* %arrayidx70.31, align 1
  %conv71.5.31 = zext i8 %16636 to i32
  %xor72.5.31 = xor i32 %conv71.5.31, %conv68.5.31
  %conv73.5.31 = trunc i32 %xor72.5.31 to i8
  store i8 %conv73.5.31, i8* %arrayidx70.31, align 1
  %scevgep20.6.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 6
  %16637 = load i8, i8* %scevgep20.6.31, align 1
  %conv68.6.31 = zext i8 %16637 to i32
  %16638 = load i8, i8* %arrayidx70.31, align 1
  %conv71.6.31 = zext i8 %16638 to i32
  %xor72.6.31 = xor i32 %conv71.6.31, %conv68.6.31
  %conv73.6.31 = trunc i32 %xor72.6.31 to i8
  store i8 %conv73.6.31, i8* %arrayidx70.31, align 1
  %scevgep20.7.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 7
  %16639 = load i8, i8* %scevgep20.7.31, align 1
  %conv68.7.31 = zext i8 %16639 to i32
  %16640 = load i8, i8* %arrayidx70.31, align 1
  %conv71.7.31 = zext i8 %16640 to i32
  %xor72.7.31 = xor i32 %conv71.7.31, %conv68.7.31
  %conv73.7.31 = trunc i32 %xor72.7.31 to i8
  store i8 %conv73.7.31, i8* %arrayidx70.31, align 1
  %scevgep20.8.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 8
  %16641 = load i8, i8* %scevgep20.8.31, align 1
  %conv68.8.31 = zext i8 %16641 to i32
  %16642 = load i8, i8* %arrayidx70.31, align 1
  %conv71.8.31 = zext i8 %16642 to i32
  %xor72.8.31 = xor i32 %conv71.8.31, %conv68.8.31
  %conv73.8.31 = trunc i32 %xor72.8.31 to i8
  store i8 %conv73.8.31, i8* %arrayidx70.31, align 1
  %scevgep20.9.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 9
  %16643 = load i8, i8* %scevgep20.9.31, align 1
  %conv68.9.31 = zext i8 %16643 to i32
  %16644 = load i8, i8* %arrayidx70.31, align 1
  %conv71.9.31 = zext i8 %16644 to i32
  %xor72.9.31 = xor i32 %conv71.9.31, %conv68.9.31
  %conv73.9.31 = trunc i32 %xor72.9.31 to i8
  store i8 %conv73.9.31, i8* %arrayidx70.31, align 1
  %scevgep20.10.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 10
  %16645 = load i8, i8* %scevgep20.10.31, align 1
  %conv68.10.31 = zext i8 %16645 to i32
  %16646 = load i8, i8* %arrayidx70.31, align 1
  %conv71.10.31 = zext i8 %16646 to i32
  %xor72.10.31 = xor i32 %conv71.10.31, %conv68.10.31
  %conv73.10.31 = trunc i32 %xor72.10.31 to i8
  store i8 %conv73.10.31, i8* %arrayidx70.31, align 1
  %scevgep20.11.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 11
  %16647 = load i8, i8* %scevgep20.11.31, align 1
  %conv68.11.31 = zext i8 %16647 to i32
  %16648 = load i8, i8* %arrayidx70.31, align 1
  %conv71.11.31 = zext i8 %16648 to i32
  %xor72.11.31 = xor i32 %conv71.11.31, %conv68.11.31
  %conv73.11.31 = trunc i32 %xor72.11.31 to i8
  store i8 %conv73.11.31, i8* %arrayidx70.31, align 1
  %scevgep20.12.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 12
  %16649 = load i8, i8* %scevgep20.12.31, align 1
  %conv68.12.31 = zext i8 %16649 to i32
  %16650 = load i8, i8* %arrayidx70.31, align 1
  %conv71.12.31 = zext i8 %16650 to i32
  %xor72.12.31 = xor i32 %conv71.12.31, %conv68.12.31
  %conv73.12.31 = trunc i32 %xor72.12.31 to i8
  store i8 %conv73.12.31, i8* %arrayidx70.31, align 1
  %scevgep20.13.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 13
  %16651 = load i8, i8* %scevgep20.13.31, align 1
  %conv68.13.31 = zext i8 %16651 to i32
  %16652 = load i8, i8* %arrayidx70.31, align 1
  %conv71.13.31 = zext i8 %16652 to i32
  %xor72.13.31 = xor i32 %conv71.13.31, %conv68.13.31
  %conv73.13.31 = trunc i32 %xor72.13.31 to i8
  store i8 %conv73.13.31, i8* %arrayidx70.31, align 1
  %scevgep20.14.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 14
  %16653 = load i8, i8* %scevgep20.14.31, align 1
  %conv68.14.31 = zext i8 %16653 to i32
  %16654 = load i8, i8* %arrayidx70.31, align 1
  %conv71.14.31 = zext i8 %16654 to i32
  %xor72.14.31 = xor i32 %conv71.14.31, %conv68.14.31
  %conv73.14.31 = trunc i32 %xor72.14.31 to i8
  store i8 %conv73.14.31, i8* %arrayidx70.31, align 1
  %scevgep20.15.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 15
  %16655 = load i8, i8* %scevgep20.15.31, align 1
  %conv68.15.31 = zext i8 %16655 to i32
  %16656 = load i8, i8* %arrayidx70.31, align 1
  %conv71.15.31 = zext i8 %16656 to i32
  %xor72.15.31 = xor i32 %conv71.15.31, %conv68.15.31
  %conv73.15.31 = trunc i32 %xor72.15.31 to i8
  store i8 %conv73.15.31, i8* %arrayidx70.31, align 1
  %scevgep20.16.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 16
  %16657 = load i8, i8* %scevgep20.16.31, align 1
  %conv68.16.31 = zext i8 %16657 to i32
  %16658 = load i8, i8* %arrayidx70.31, align 1
  %conv71.16.31 = zext i8 %16658 to i32
  %xor72.16.31 = xor i32 %conv71.16.31, %conv68.16.31
  %conv73.16.31 = trunc i32 %xor72.16.31 to i8
  store i8 %conv73.16.31, i8* %arrayidx70.31, align 1
  %scevgep20.17.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 17
  %16659 = load i8, i8* %scevgep20.17.31, align 1
  %conv68.17.31 = zext i8 %16659 to i32
  %16660 = load i8, i8* %arrayidx70.31, align 1
  %conv71.17.31 = zext i8 %16660 to i32
  %xor72.17.31 = xor i32 %conv71.17.31, %conv68.17.31
  %conv73.17.31 = trunc i32 %xor72.17.31 to i8
  store i8 %conv73.17.31, i8* %arrayidx70.31, align 1
  %scevgep20.18.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 18
  %16661 = load i8, i8* %scevgep20.18.31, align 1
  %conv68.18.31 = zext i8 %16661 to i32
  %16662 = load i8, i8* %arrayidx70.31, align 1
  %conv71.18.31 = zext i8 %16662 to i32
  %xor72.18.31 = xor i32 %conv71.18.31, %conv68.18.31
  %conv73.18.31 = trunc i32 %xor72.18.31 to i8
  store i8 %conv73.18.31, i8* %arrayidx70.31, align 1
  %scevgep20.19.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 19
  %16663 = load i8, i8* %scevgep20.19.31, align 1
  %conv68.19.31 = zext i8 %16663 to i32
  %16664 = load i8, i8* %arrayidx70.31, align 1
  %conv71.19.31 = zext i8 %16664 to i32
  %xor72.19.31 = xor i32 %conv71.19.31, %conv68.19.31
  %conv73.19.31 = trunc i32 %xor72.19.31 to i8
  store i8 %conv73.19.31, i8* %arrayidx70.31, align 1
  %scevgep20.20.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 20
  %16665 = load i8, i8* %scevgep20.20.31, align 1
  %conv68.20.31 = zext i8 %16665 to i32
  %16666 = load i8, i8* %arrayidx70.31, align 1
  %conv71.20.31 = zext i8 %16666 to i32
  %xor72.20.31 = xor i32 %conv71.20.31, %conv68.20.31
  %conv73.20.31 = trunc i32 %xor72.20.31 to i8
  store i8 %conv73.20.31, i8* %arrayidx70.31, align 1
  %scevgep20.21.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 21
  %16667 = load i8, i8* %scevgep20.21.31, align 1
  %conv68.21.31 = zext i8 %16667 to i32
  %16668 = load i8, i8* %arrayidx70.31, align 1
  %conv71.21.31 = zext i8 %16668 to i32
  %xor72.21.31 = xor i32 %conv71.21.31, %conv68.21.31
  %conv73.21.31 = trunc i32 %xor72.21.31 to i8
  store i8 %conv73.21.31, i8* %arrayidx70.31, align 1
  %scevgep20.22.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 22
  %16669 = load i8, i8* %scevgep20.22.31, align 1
  %conv68.22.31 = zext i8 %16669 to i32
  %16670 = load i8, i8* %arrayidx70.31, align 1
  %conv71.22.31 = zext i8 %16670 to i32
  %xor72.22.31 = xor i32 %conv71.22.31, %conv68.22.31
  %conv73.22.31 = trunc i32 %xor72.22.31 to i8
  store i8 %conv73.22.31, i8* %arrayidx70.31, align 1
  %scevgep20.23.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 23
  %16671 = load i8, i8* %scevgep20.23.31, align 1
  %conv68.23.31 = zext i8 %16671 to i32
  %16672 = load i8, i8* %arrayidx70.31, align 1
  %conv71.23.31 = zext i8 %16672 to i32
  %xor72.23.31 = xor i32 %conv71.23.31, %conv68.23.31
  %conv73.23.31 = trunc i32 %xor72.23.31 to i8
  store i8 %conv73.23.31, i8* %arrayidx70.31, align 1
  %scevgep20.24.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 24
  %16673 = load i8, i8* %scevgep20.24.31, align 1
  %conv68.24.31 = zext i8 %16673 to i32
  %16674 = load i8, i8* %arrayidx70.31, align 1
  %conv71.24.31 = zext i8 %16674 to i32
  %xor72.24.31 = xor i32 %conv71.24.31, %conv68.24.31
  %conv73.24.31 = trunc i32 %xor72.24.31 to i8
  store i8 %conv73.24.31, i8* %arrayidx70.31, align 1
  %scevgep20.25.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 25
  %16675 = load i8, i8* %scevgep20.25.31, align 1
  %conv68.25.31 = zext i8 %16675 to i32
  %16676 = load i8, i8* %arrayidx70.31, align 1
  %conv71.25.31 = zext i8 %16676 to i32
  %xor72.25.31 = xor i32 %conv71.25.31, %conv68.25.31
  %conv73.25.31 = trunc i32 %xor72.25.31 to i8
  store i8 %conv73.25.31, i8* %arrayidx70.31, align 1
  %scevgep20.26.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 26
  %16677 = load i8, i8* %scevgep20.26.31, align 1
  %conv68.26.31 = zext i8 %16677 to i32
  %16678 = load i8, i8* %arrayidx70.31, align 1
  %conv71.26.31 = zext i8 %16678 to i32
  %xor72.26.31 = xor i32 %conv71.26.31, %conv68.26.31
  %conv73.26.31 = trunc i32 %xor72.26.31 to i8
  store i8 %conv73.26.31, i8* %arrayidx70.31, align 1
  %scevgep20.27.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 27
  %16679 = load i8, i8* %scevgep20.27.31, align 1
  %conv68.27.31 = zext i8 %16679 to i32
  %16680 = load i8, i8* %arrayidx70.31, align 1
  %conv71.27.31 = zext i8 %16680 to i32
  %xor72.27.31 = xor i32 %conv71.27.31, %conv68.27.31
  %conv73.27.31 = trunc i32 %xor72.27.31 to i8
  store i8 %conv73.27.31, i8* %arrayidx70.31, align 1
  %scevgep20.28.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 28
  %16681 = load i8, i8* %scevgep20.28.31, align 1
  %conv68.28.31 = zext i8 %16681 to i32
  %16682 = load i8, i8* %arrayidx70.31, align 1
  %conv71.28.31 = zext i8 %16682 to i32
  %xor72.28.31 = xor i32 %conv71.28.31, %conv68.28.31
  %conv73.28.31 = trunc i32 %xor72.28.31 to i8
  store i8 %conv73.28.31, i8* %arrayidx70.31, align 1
  %scevgep20.29.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 29
  %16683 = load i8, i8* %scevgep20.29.31, align 1
  %conv68.29.31 = zext i8 %16683 to i32
  %16684 = load i8, i8* %arrayidx70.31, align 1
  %conv71.29.31 = zext i8 %16684 to i32
  %xor72.29.31 = xor i32 %conv71.29.31, %conv68.29.31
  %conv73.29.31 = trunc i32 %xor72.29.31 to i8
  store i8 %conv73.29.31, i8* %arrayidx70.31, align 1
  %scevgep20.30.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 30
  %16685 = load i8, i8* %scevgep20.30.31, align 1
  %conv68.30.31 = zext i8 %16685 to i32
  %16686 = load i8, i8* %arrayidx70.31, align 1
  %conv71.30.31 = zext i8 %16686 to i32
  %xor72.30.31 = xor i32 %conv71.30.31, %conv68.30.31
  %conv73.30.31 = trunc i32 %xor72.30.31 to i8
  store i8 %conv73.30.31, i8* %arrayidx70.31, align 1
  %scevgep20.32.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 32
  %16687 = load i8, i8* %scevgep20.32.31, align 1
  %conv68.32.31 = zext i8 %16687 to i32
  %16688 = load i8, i8* %arrayidx70.31, align 1
  %conv71.32.31 = zext i8 %16688 to i32
  %xor72.32.31 = xor i32 %conv71.32.31, %conv68.32.31
  %conv73.32.31 = trunc i32 %xor72.32.31 to i8
  store i8 %conv73.32.31, i8* %arrayidx70.31, align 1
  %scevgep20.33.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 33
  %16689 = load i8, i8* %scevgep20.33.31, align 1
  %conv68.33.31 = zext i8 %16689 to i32
  %16690 = load i8, i8* %arrayidx70.31, align 1
  %conv71.33.31 = zext i8 %16690 to i32
  %xor72.33.31 = xor i32 %conv71.33.31, %conv68.33.31
  %conv73.33.31 = trunc i32 %xor72.33.31 to i8
  store i8 %conv73.33.31, i8* %arrayidx70.31, align 1
  %scevgep20.34.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 34
  %16691 = load i8, i8* %scevgep20.34.31, align 1
  %conv68.34.31 = zext i8 %16691 to i32
  %16692 = load i8, i8* %arrayidx70.31, align 1
  %conv71.34.31 = zext i8 %16692 to i32
  %xor72.34.31 = xor i32 %conv71.34.31, %conv68.34.31
  %conv73.34.31 = trunc i32 %xor72.34.31 to i8
  store i8 %conv73.34.31, i8* %arrayidx70.31, align 1
  %scevgep20.35.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 35
  %16693 = load i8, i8* %scevgep20.35.31, align 1
  %conv68.35.31 = zext i8 %16693 to i32
  %16694 = load i8, i8* %arrayidx70.31, align 1
  %conv71.35.31 = zext i8 %16694 to i32
  %xor72.35.31 = xor i32 %conv71.35.31, %conv68.35.31
  %conv73.35.31 = trunc i32 %xor72.35.31 to i8
  store i8 %conv73.35.31, i8* %arrayidx70.31, align 1
  %scevgep20.36.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 36
  %16695 = load i8, i8* %scevgep20.36.31, align 1
  %conv68.36.31 = zext i8 %16695 to i32
  %16696 = load i8, i8* %arrayidx70.31, align 1
  %conv71.36.31 = zext i8 %16696 to i32
  %xor72.36.31 = xor i32 %conv71.36.31, %conv68.36.31
  %conv73.36.31 = trunc i32 %xor72.36.31 to i8
  store i8 %conv73.36.31, i8* %arrayidx70.31, align 1
  %scevgep20.37.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 37
  %16697 = load i8, i8* %scevgep20.37.31, align 1
  %conv68.37.31 = zext i8 %16697 to i32
  %16698 = load i8, i8* %arrayidx70.31, align 1
  %conv71.37.31 = zext i8 %16698 to i32
  %xor72.37.31 = xor i32 %conv71.37.31, %conv68.37.31
  %conv73.37.31 = trunc i32 %xor72.37.31 to i8
  store i8 %conv73.37.31, i8* %arrayidx70.31, align 1
  %scevgep20.38.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 38
  %16699 = load i8, i8* %scevgep20.38.31, align 1
  %conv68.38.31 = zext i8 %16699 to i32
  %16700 = load i8, i8* %arrayidx70.31, align 1
  %conv71.38.31 = zext i8 %16700 to i32
  %xor72.38.31 = xor i32 %conv71.38.31, %conv68.38.31
  %conv73.38.31 = trunc i32 %xor72.38.31 to i8
  store i8 %conv73.38.31, i8* %arrayidx70.31, align 1
  %scevgep20.39.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 39
  %16701 = load i8, i8* %scevgep20.39.31, align 1
  %conv68.39.31 = zext i8 %16701 to i32
  %16702 = load i8, i8* %arrayidx70.31, align 1
  %conv71.39.31 = zext i8 %16702 to i32
  %xor72.39.31 = xor i32 %conv71.39.31, %conv68.39.31
  %conv73.39.31 = trunc i32 %xor72.39.31 to i8
  store i8 %conv73.39.31, i8* %arrayidx70.31, align 1
  %scevgep20.40.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 40
  %16703 = load i8, i8* %scevgep20.40.31, align 1
  %conv68.40.31 = zext i8 %16703 to i32
  %16704 = load i8, i8* %arrayidx70.31, align 1
  %conv71.40.31 = zext i8 %16704 to i32
  %xor72.40.31 = xor i32 %conv71.40.31, %conv68.40.31
  %conv73.40.31 = trunc i32 %xor72.40.31 to i8
  store i8 %conv73.40.31, i8* %arrayidx70.31, align 1
  %scevgep20.41.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 41
  %16705 = load i8, i8* %scevgep20.41.31, align 1
  %conv68.41.31 = zext i8 %16705 to i32
  %16706 = load i8, i8* %arrayidx70.31, align 1
  %conv71.41.31 = zext i8 %16706 to i32
  %xor72.41.31 = xor i32 %conv71.41.31, %conv68.41.31
  %conv73.41.31 = trunc i32 %xor72.41.31 to i8
  store i8 %conv73.41.31, i8* %arrayidx70.31, align 1
  %scevgep20.42.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 42
  %16707 = load i8, i8* %scevgep20.42.31, align 1
  %conv68.42.31 = zext i8 %16707 to i32
  %16708 = load i8, i8* %arrayidx70.31, align 1
  %conv71.42.31 = zext i8 %16708 to i32
  %xor72.42.31 = xor i32 %conv71.42.31, %conv68.42.31
  %conv73.42.31 = trunc i32 %xor72.42.31 to i8
  store i8 %conv73.42.31, i8* %arrayidx70.31, align 1
  %scevgep20.43.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 43
  %16709 = load i8, i8* %scevgep20.43.31, align 1
  %conv68.43.31 = zext i8 %16709 to i32
  %16710 = load i8, i8* %arrayidx70.31, align 1
  %conv71.43.31 = zext i8 %16710 to i32
  %xor72.43.31 = xor i32 %conv71.43.31, %conv68.43.31
  %conv73.43.31 = trunc i32 %xor72.43.31 to i8
  store i8 %conv73.43.31, i8* %arrayidx70.31, align 1
  %scevgep20.44.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 44
  %16711 = load i8, i8* %scevgep20.44.31, align 1
  %conv68.44.31 = zext i8 %16711 to i32
  %16712 = load i8, i8* %arrayidx70.31, align 1
  %conv71.44.31 = zext i8 %16712 to i32
  %xor72.44.31 = xor i32 %conv71.44.31, %conv68.44.31
  %conv73.44.31 = trunc i32 %xor72.44.31 to i8
  store i8 %conv73.44.31, i8* %arrayidx70.31, align 1
  %scevgep20.45.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 45
  %16713 = load i8, i8* %scevgep20.45.31, align 1
  %conv68.45.31 = zext i8 %16713 to i32
  %16714 = load i8, i8* %arrayidx70.31, align 1
  %conv71.45.31 = zext i8 %16714 to i32
  %xor72.45.31 = xor i32 %conv71.45.31, %conv68.45.31
  %conv73.45.31 = trunc i32 %xor72.45.31 to i8
  store i8 %conv73.45.31, i8* %arrayidx70.31, align 1
  %scevgep20.46.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 46
  %16715 = load i8, i8* %scevgep20.46.31, align 1
  %conv68.46.31 = zext i8 %16715 to i32
  %16716 = load i8, i8* %arrayidx70.31, align 1
  %conv71.46.31 = zext i8 %16716 to i32
  %xor72.46.31 = xor i32 %conv71.46.31, %conv68.46.31
  %conv73.46.31 = trunc i32 %xor72.46.31 to i8
  store i8 %conv73.46.31, i8* %arrayidx70.31, align 1
  %scevgep20.47.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 47
  %16717 = load i8, i8* %scevgep20.47.31, align 1
  %conv68.47.31 = zext i8 %16717 to i32
  %16718 = load i8, i8* %arrayidx70.31, align 1
  %conv71.47.31 = zext i8 %16718 to i32
  %xor72.47.31 = xor i32 %conv71.47.31, %conv68.47.31
  %conv73.47.31 = trunc i32 %xor72.47.31 to i8
  store i8 %conv73.47.31, i8* %arrayidx70.31, align 1
  %scevgep20.48.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 48
  %16719 = load i8, i8* %scevgep20.48.31, align 1
  %conv68.48.31 = zext i8 %16719 to i32
  %16720 = load i8, i8* %arrayidx70.31, align 1
  %conv71.48.31 = zext i8 %16720 to i32
  %xor72.48.31 = xor i32 %conv71.48.31, %conv68.48.31
  %conv73.48.31 = trunc i32 %xor72.48.31 to i8
  store i8 %conv73.48.31, i8* %arrayidx70.31, align 1
  %scevgep20.49.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 49
  %16721 = load i8, i8* %scevgep20.49.31, align 1
  %conv68.49.31 = zext i8 %16721 to i32
  %16722 = load i8, i8* %arrayidx70.31, align 1
  %conv71.49.31 = zext i8 %16722 to i32
  %xor72.49.31 = xor i32 %conv71.49.31, %conv68.49.31
  %conv73.49.31 = trunc i32 %xor72.49.31 to i8
  store i8 %conv73.49.31, i8* %arrayidx70.31, align 1
  %scevgep20.50.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 50
  %16723 = load i8, i8* %scevgep20.50.31, align 1
  %conv68.50.31 = zext i8 %16723 to i32
  %16724 = load i8, i8* %arrayidx70.31, align 1
  %conv71.50.31 = zext i8 %16724 to i32
  %xor72.50.31 = xor i32 %conv71.50.31, %conv68.50.31
  %conv73.50.31 = trunc i32 %xor72.50.31 to i8
  store i8 %conv73.50.31, i8* %arrayidx70.31, align 1
  %scevgep20.51.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 51
  %16725 = load i8, i8* %scevgep20.51.31, align 1
  %conv68.51.31 = zext i8 %16725 to i32
  %16726 = load i8, i8* %arrayidx70.31, align 1
  %conv71.51.31 = zext i8 %16726 to i32
  %xor72.51.31 = xor i32 %conv71.51.31, %conv68.51.31
  %conv73.51.31 = trunc i32 %xor72.51.31 to i8
  store i8 %conv73.51.31, i8* %arrayidx70.31, align 1
  %scevgep20.52.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 52
  %16727 = load i8, i8* %scevgep20.52.31, align 1
  %conv68.52.31 = zext i8 %16727 to i32
  %16728 = load i8, i8* %arrayidx70.31, align 1
  %conv71.52.31 = zext i8 %16728 to i32
  %xor72.52.31 = xor i32 %conv71.52.31, %conv68.52.31
  %conv73.52.31 = trunc i32 %xor72.52.31 to i8
  store i8 %conv73.52.31, i8* %arrayidx70.31, align 1
  %scevgep20.53.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 53
  %16729 = load i8, i8* %scevgep20.53.31, align 1
  %conv68.53.31 = zext i8 %16729 to i32
  %16730 = load i8, i8* %arrayidx70.31, align 1
  %conv71.53.31 = zext i8 %16730 to i32
  %xor72.53.31 = xor i32 %conv71.53.31, %conv68.53.31
  %conv73.53.31 = trunc i32 %xor72.53.31 to i8
  store i8 %conv73.53.31, i8* %arrayidx70.31, align 1
  %scevgep20.54.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 54
  %16731 = load i8, i8* %scevgep20.54.31, align 1
  %conv68.54.31 = zext i8 %16731 to i32
  %16732 = load i8, i8* %arrayidx70.31, align 1
  %conv71.54.31 = zext i8 %16732 to i32
  %xor72.54.31 = xor i32 %conv71.54.31, %conv68.54.31
  %conv73.54.31 = trunc i32 %xor72.54.31 to i8
  store i8 %conv73.54.31, i8* %arrayidx70.31, align 1
  %scevgep20.55.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 55
  %16733 = load i8, i8* %scevgep20.55.31, align 1
  %conv68.55.31 = zext i8 %16733 to i32
  %16734 = load i8, i8* %arrayidx70.31, align 1
  %conv71.55.31 = zext i8 %16734 to i32
  %xor72.55.31 = xor i32 %conv71.55.31, %conv68.55.31
  %conv73.55.31 = trunc i32 %xor72.55.31 to i8
  store i8 %conv73.55.31, i8* %arrayidx70.31, align 1
  %scevgep20.56.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 56
  %16735 = load i8, i8* %scevgep20.56.31, align 1
  %conv68.56.31 = zext i8 %16735 to i32
  %16736 = load i8, i8* %arrayidx70.31, align 1
  %conv71.56.31 = zext i8 %16736 to i32
  %xor72.56.31 = xor i32 %conv71.56.31, %conv68.56.31
  %conv73.56.31 = trunc i32 %xor72.56.31 to i8
  store i8 %conv73.56.31, i8* %arrayidx70.31, align 1
  %scevgep20.57.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 57
  %16737 = load i8, i8* %scevgep20.57.31, align 1
  %conv68.57.31 = zext i8 %16737 to i32
  %16738 = load i8, i8* %arrayidx70.31, align 1
  %conv71.57.31 = zext i8 %16738 to i32
  %xor72.57.31 = xor i32 %conv71.57.31, %conv68.57.31
  %conv73.57.31 = trunc i32 %xor72.57.31 to i8
  store i8 %conv73.57.31, i8* %arrayidx70.31, align 1
  %scevgep20.58.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 58
  %16739 = load i8, i8* %scevgep20.58.31, align 1
  %conv68.58.31 = zext i8 %16739 to i32
  %16740 = load i8, i8* %arrayidx70.31, align 1
  %conv71.58.31 = zext i8 %16740 to i32
  %xor72.58.31 = xor i32 %conv71.58.31, %conv68.58.31
  %conv73.58.31 = trunc i32 %xor72.58.31 to i8
  store i8 %conv73.58.31, i8* %arrayidx70.31, align 1
  %scevgep20.59.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 59
  %16741 = load i8, i8* %scevgep20.59.31, align 1
  %conv68.59.31 = zext i8 %16741 to i32
  %16742 = load i8, i8* %arrayidx70.31, align 1
  %conv71.59.31 = zext i8 %16742 to i32
  %xor72.59.31 = xor i32 %conv71.59.31, %conv68.59.31
  %conv73.59.31 = trunc i32 %xor72.59.31 to i8
  store i8 %conv73.59.31, i8* %arrayidx70.31, align 1
  %scevgep20.60.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 0, i64 60
  %16743 = load i8, i8* %scevgep20.60.31, align 1
  %conv68.60.31 = zext i8 %16743 to i32
  %16744 = load i8, i8* %arrayidx70.31, align 1
  %conv71.60.31 = zext i8 %16744 to i32
  %xor72.60.31 = xor i32 %conv71.60.31, %conv68.60.31
  %conv73.60.31 = trunc i32 %xor72.60.31 to i8
  store i8 %conv73.60.31, i8* %arrayidx70.31, align 1
  %scevgep19.31 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16622, i64 0, i64 1, i64 0
  %16745 = bitcast i8* %scevgep19.31 to [61 x [61 x i8]]*
  %arrayidx51.32 = getelementptr inbounds i8, i8* %a, i64 32
  %16746 = load i8, i8* %arrayidx51.32, align 1
  %arrayidx53.32 = getelementptr inbounds i8, i8* %b, i64 32
  %16747 = load i8, i8* %arrayidx53.32, align 1
  %call54.32 = call zeroext i8 @mult(i8 zeroext %16746, i8 zeroext %16747)
  %arrayidx56.32 = getelementptr inbounds i8, i8* %c, i64 32
  store i8 %call54.32, i8* %arrayidx56.32, align 1
  %arrayidx70.32 = getelementptr inbounds i8, i8* %c, i64 32
  %scevgep20.32364 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 0
  %16748 = load i8, i8* %scevgep20.32364, align 1
  %conv68.32365 = zext i8 %16748 to i32
  %16749 = load i8, i8* %arrayidx70.32, align 1
  %conv71.32366 = zext i8 %16749 to i32
  %xor72.32367 = xor i32 %conv71.32366, %conv68.32365
  %conv73.32368 = trunc i32 %xor72.32367 to i8
  store i8 %conv73.32368, i8* %arrayidx70.32, align 1
  %scevgep20.1.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 1
  %16750 = load i8, i8* %scevgep20.1.32, align 1
  %conv68.1.32 = zext i8 %16750 to i32
  %16751 = load i8, i8* %arrayidx70.32, align 1
  %conv71.1.32 = zext i8 %16751 to i32
  %xor72.1.32 = xor i32 %conv71.1.32, %conv68.1.32
  %conv73.1.32 = trunc i32 %xor72.1.32 to i8
  store i8 %conv73.1.32, i8* %arrayidx70.32, align 1
  %scevgep20.2.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 2
  %16752 = load i8, i8* %scevgep20.2.32, align 1
  %conv68.2.32 = zext i8 %16752 to i32
  %16753 = load i8, i8* %arrayidx70.32, align 1
  %conv71.2.32 = zext i8 %16753 to i32
  %xor72.2.32 = xor i32 %conv71.2.32, %conv68.2.32
  %conv73.2.32 = trunc i32 %xor72.2.32 to i8
  store i8 %conv73.2.32, i8* %arrayidx70.32, align 1
  %scevgep20.3.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 3
  %16754 = load i8, i8* %scevgep20.3.32, align 1
  %conv68.3.32 = zext i8 %16754 to i32
  %16755 = load i8, i8* %arrayidx70.32, align 1
  %conv71.3.32 = zext i8 %16755 to i32
  %xor72.3.32 = xor i32 %conv71.3.32, %conv68.3.32
  %conv73.3.32 = trunc i32 %xor72.3.32 to i8
  store i8 %conv73.3.32, i8* %arrayidx70.32, align 1
  %scevgep20.4.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 4
  %16756 = load i8, i8* %scevgep20.4.32, align 1
  %conv68.4.32 = zext i8 %16756 to i32
  %16757 = load i8, i8* %arrayidx70.32, align 1
  %conv71.4.32 = zext i8 %16757 to i32
  %xor72.4.32 = xor i32 %conv71.4.32, %conv68.4.32
  %conv73.4.32 = trunc i32 %xor72.4.32 to i8
  store i8 %conv73.4.32, i8* %arrayidx70.32, align 1
  %scevgep20.5.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 5
  %16758 = load i8, i8* %scevgep20.5.32, align 1
  %conv68.5.32 = zext i8 %16758 to i32
  %16759 = load i8, i8* %arrayidx70.32, align 1
  %conv71.5.32 = zext i8 %16759 to i32
  %xor72.5.32 = xor i32 %conv71.5.32, %conv68.5.32
  %conv73.5.32 = trunc i32 %xor72.5.32 to i8
  store i8 %conv73.5.32, i8* %arrayidx70.32, align 1
  %scevgep20.6.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 6
  %16760 = load i8, i8* %scevgep20.6.32, align 1
  %conv68.6.32 = zext i8 %16760 to i32
  %16761 = load i8, i8* %arrayidx70.32, align 1
  %conv71.6.32 = zext i8 %16761 to i32
  %xor72.6.32 = xor i32 %conv71.6.32, %conv68.6.32
  %conv73.6.32 = trunc i32 %xor72.6.32 to i8
  store i8 %conv73.6.32, i8* %arrayidx70.32, align 1
  %scevgep20.7.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 7
  %16762 = load i8, i8* %scevgep20.7.32, align 1
  %conv68.7.32 = zext i8 %16762 to i32
  %16763 = load i8, i8* %arrayidx70.32, align 1
  %conv71.7.32 = zext i8 %16763 to i32
  %xor72.7.32 = xor i32 %conv71.7.32, %conv68.7.32
  %conv73.7.32 = trunc i32 %xor72.7.32 to i8
  store i8 %conv73.7.32, i8* %arrayidx70.32, align 1
  %scevgep20.8.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 8
  %16764 = load i8, i8* %scevgep20.8.32, align 1
  %conv68.8.32 = zext i8 %16764 to i32
  %16765 = load i8, i8* %arrayidx70.32, align 1
  %conv71.8.32 = zext i8 %16765 to i32
  %xor72.8.32 = xor i32 %conv71.8.32, %conv68.8.32
  %conv73.8.32 = trunc i32 %xor72.8.32 to i8
  store i8 %conv73.8.32, i8* %arrayidx70.32, align 1
  %scevgep20.9.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 9
  %16766 = load i8, i8* %scevgep20.9.32, align 1
  %conv68.9.32 = zext i8 %16766 to i32
  %16767 = load i8, i8* %arrayidx70.32, align 1
  %conv71.9.32 = zext i8 %16767 to i32
  %xor72.9.32 = xor i32 %conv71.9.32, %conv68.9.32
  %conv73.9.32 = trunc i32 %xor72.9.32 to i8
  store i8 %conv73.9.32, i8* %arrayidx70.32, align 1
  %scevgep20.10.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 10
  %16768 = load i8, i8* %scevgep20.10.32, align 1
  %conv68.10.32 = zext i8 %16768 to i32
  %16769 = load i8, i8* %arrayidx70.32, align 1
  %conv71.10.32 = zext i8 %16769 to i32
  %xor72.10.32 = xor i32 %conv71.10.32, %conv68.10.32
  %conv73.10.32 = trunc i32 %xor72.10.32 to i8
  store i8 %conv73.10.32, i8* %arrayidx70.32, align 1
  %scevgep20.11.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 11
  %16770 = load i8, i8* %scevgep20.11.32, align 1
  %conv68.11.32 = zext i8 %16770 to i32
  %16771 = load i8, i8* %arrayidx70.32, align 1
  %conv71.11.32 = zext i8 %16771 to i32
  %xor72.11.32 = xor i32 %conv71.11.32, %conv68.11.32
  %conv73.11.32 = trunc i32 %xor72.11.32 to i8
  store i8 %conv73.11.32, i8* %arrayidx70.32, align 1
  %scevgep20.12.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 12
  %16772 = load i8, i8* %scevgep20.12.32, align 1
  %conv68.12.32 = zext i8 %16772 to i32
  %16773 = load i8, i8* %arrayidx70.32, align 1
  %conv71.12.32 = zext i8 %16773 to i32
  %xor72.12.32 = xor i32 %conv71.12.32, %conv68.12.32
  %conv73.12.32 = trunc i32 %xor72.12.32 to i8
  store i8 %conv73.12.32, i8* %arrayidx70.32, align 1
  %scevgep20.13.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 13
  %16774 = load i8, i8* %scevgep20.13.32, align 1
  %conv68.13.32 = zext i8 %16774 to i32
  %16775 = load i8, i8* %arrayidx70.32, align 1
  %conv71.13.32 = zext i8 %16775 to i32
  %xor72.13.32 = xor i32 %conv71.13.32, %conv68.13.32
  %conv73.13.32 = trunc i32 %xor72.13.32 to i8
  store i8 %conv73.13.32, i8* %arrayidx70.32, align 1
  %scevgep20.14.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 14
  %16776 = load i8, i8* %scevgep20.14.32, align 1
  %conv68.14.32 = zext i8 %16776 to i32
  %16777 = load i8, i8* %arrayidx70.32, align 1
  %conv71.14.32 = zext i8 %16777 to i32
  %xor72.14.32 = xor i32 %conv71.14.32, %conv68.14.32
  %conv73.14.32 = trunc i32 %xor72.14.32 to i8
  store i8 %conv73.14.32, i8* %arrayidx70.32, align 1
  %scevgep20.15.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 15
  %16778 = load i8, i8* %scevgep20.15.32, align 1
  %conv68.15.32 = zext i8 %16778 to i32
  %16779 = load i8, i8* %arrayidx70.32, align 1
  %conv71.15.32 = zext i8 %16779 to i32
  %xor72.15.32 = xor i32 %conv71.15.32, %conv68.15.32
  %conv73.15.32 = trunc i32 %xor72.15.32 to i8
  store i8 %conv73.15.32, i8* %arrayidx70.32, align 1
  %scevgep20.16.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 16
  %16780 = load i8, i8* %scevgep20.16.32, align 1
  %conv68.16.32 = zext i8 %16780 to i32
  %16781 = load i8, i8* %arrayidx70.32, align 1
  %conv71.16.32 = zext i8 %16781 to i32
  %xor72.16.32 = xor i32 %conv71.16.32, %conv68.16.32
  %conv73.16.32 = trunc i32 %xor72.16.32 to i8
  store i8 %conv73.16.32, i8* %arrayidx70.32, align 1
  %scevgep20.17.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 17
  %16782 = load i8, i8* %scevgep20.17.32, align 1
  %conv68.17.32 = zext i8 %16782 to i32
  %16783 = load i8, i8* %arrayidx70.32, align 1
  %conv71.17.32 = zext i8 %16783 to i32
  %xor72.17.32 = xor i32 %conv71.17.32, %conv68.17.32
  %conv73.17.32 = trunc i32 %xor72.17.32 to i8
  store i8 %conv73.17.32, i8* %arrayidx70.32, align 1
  %scevgep20.18.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 18
  %16784 = load i8, i8* %scevgep20.18.32, align 1
  %conv68.18.32 = zext i8 %16784 to i32
  %16785 = load i8, i8* %arrayidx70.32, align 1
  %conv71.18.32 = zext i8 %16785 to i32
  %xor72.18.32 = xor i32 %conv71.18.32, %conv68.18.32
  %conv73.18.32 = trunc i32 %xor72.18.32 to i8
  store i8 %conv73.18.32, i8* %arrayidx70.32, align 1
  %scevgep20.19.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 19
  %16786 = load i8, i8* %scevgep20.19.32, align 1
  %conv68.19.32 = zext i8 %16786 to i32
  %16787 = load i8, i8* %arrayidx70.32, align 1
  %conv71.19.32 = zext i8 %16787 to i32
  %xor72.19.32 = xor i32 %conv71.19.32, %conv68.19.32
  %conv73.19.32 = trunc i32 %xor72.19.32 to i8
  store i8 %conv73.19.32, i8* %arrayidx70.32, align 1
  %scevgep20.20.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 20
  %16788 = load i8, i8* %scevgep20.20.32, align 1
  %conv68.20.32 = zext i8 %16788 to i32
  %16789 = load i8, i8* %arrayidx70.32, align 1
  %conv71.20.32 = zext i8 %16789 to i32
  %xor72.20.32 = xor i32 %conv71.20.32, %conv68.20.32
  %conv73.20.32 = trunc i32 %xor72.20.32 to i8
  store i8 %conv73.20.32, i8* %arrayidx70.32, align 1
  %scevgep20.21.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 21
  %16790 = load i8, i8* %scevgep20.21.32, align 1
  %conv68.21.32 = zext i8 %16790 to i32
  %16791 = load i8, i8* %arrayidx70.32, align 1
  %conv71.21.32 = zext i8 %16791 to i32
  %xor72.21.32 = xor i32 %conv71.21.32, %conv68.21.32
  %conv73.21.32 = trunc i32 %xor72.21.32 to i8
  store i8 %conv73.21.32, i8* %arrayidx70.32, align 1
  %scevgep20.22.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 22
  %16792 = load i8, i8* %scevgep20.22.32, align 1
  %conv68.22.32 = zext i8 %16792 to i32
  %16793 = load i8, i8* %arrayidx70.32, align 1
  %conv71.22.32 = zext i8 %16793 to i32
  %xor72.22.32 = xor i32 %conv71.22.32, %conv68.22.32
  %conv73.22.32 = trunc i32 %xor72.22.32 to i8
  store i8 %conv73.22.32, i8* %arrayidx70.32, align 1
  %scevgep20.23.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 23
  %16794 = load i8, i8* %scevgep20.23.32, align 1
  %conv68.23.32 = zext i8 %16794 to i32
  %16795 = load i8, i8* %arrayidx70.32, align 1
  %conv71.23.32 = zext i8 %16795 to i32
  %xor72.23.32 = xor i32 %conv71.23.32, %conv68.23.32
  %conv73.23.32 = trunc i32 %xor72.23.32 to i8
  store i8 %conv73.23.32, i8* %arrayidx70.32, align 1
  %scevgep20.24.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 24
  %16796 = load i8, i8* %scevgep20.24.32, align 1
  %conv68.24.32 = zext i8 %16796 to i32
  %16797 = load i8, i8* %arrayidx70.32, align 1
  %conv71.24.32 = zext i8 %16797 to i32
  %xor72.24.32 = xor i32 %conv71.24.32, %conv68.24.32
  %conv73.24.32 = trunc i32 %xor72.24.32 to i8
  store i8 %conv73.24.32, i8* %arrayidx70.32, align 1
  %scevgep20.25.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 25
  %16798 = load i8, i8* %scevgep20.25.32, align 1
  %conv68.25.32 = zext i8 %16798 to i32
  %16799 = load i8, i8* %arrayidx70.32, align 1
  %conv71.25.32 = zext i8 %16799 to i32
  %xor72.25.32 = xor i32 %conv71.25.32, %conv68.25.32
  %conv73.25.32 = trunc i32 %xor72.25.32 to i8
  store i8 %conv73.25.32, i8* %arrayidx70.32, align 1
  %scevgep20.26.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 26
  %16800 = load i8, i8* %scevgep20.26.32, align 1
  %conv68.26.32 = zext i8 %16800 to i32
  %16801 = load i8, i8* %arrayidx70.32, align 1
  %conv71.26.32 = zext i8 %16801 to i32
  %xor72.26.32 = xor i32 %conv71.26.32, %conv68.26.32
  %conv73.26.32 = trunc i32 %xor72.26.32 to i8
  store i8 %conv73.26.32, i8* %arrayidx70.32, align 1
  %scevgep20.27.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 27
  %16802 = load i8, i8* %scevgep20.27.32, align 1
  %conv68.27.32 = zext i8 %16802 to i32
  %16803 = load i8, i8* %arrayidx70.32, align 1
  %conv71.27.32 = zext i8 %16803 to i32
  %xor72.27.32 = xor i32 %conv71.27.32, %conv68.27.32
  %conv73.27.32 = trunc i32 %xor72.27.32 to i8
  store i8 %conv73.27.32, i8* %arrayidx70.32, align 1
  %scevgep20.28.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 28
  %16804 = load i8, i8* %scevgep20.28.32, align 1
  %conv68.28.32 = zext i8 %16804 to i32
  %16805 = load i8, i8* %arrayidx70.32, align 1
  %conv71.28.32 = zext i8 %16805 to i32
  %xor72.28.32 = xor i32 %conv71.28.32, %conv68.28.32
  %conv73.28.32 = trunc i32 %xor72.28.32 to i8
  store i8 %conv73.28.32, i8* %arrayidx70.32, align 1
  %scevgep20.29.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 29
  %16806 = load i8, i8* %scevgep20.29.32, align 1
  %conv68.29.32 = zext i8 %16806 to i32
  %16807 = load i8, i8* %arrayidx70.32, align 1
  %conv71.29.32 = zext i8 %16807 to i32
  %xor72.29.32 = xor i32 %conv71.29.32, %conv68.29.32
  %conv73.29.32 = trunc i32 %xor72.29.32 to i8
  store i8 %conv73.29.32, i8* %arrayidx70.32, align 1
  %scevgep20.30.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 30
  %16808 = load i8, i8* %scevgep20.30.32, align 1
  %conv68.30.32 = zext i8 %16808 to i32
  %16809 = load i8, i8* %arrayidx70.32, align 1
  %conv71.30.32 = zext i8 %16809 to i32
  %xor72.30.32 = xor i32 %conv71.30.32, %conv68.30.32
  %conv73.30.32 = trunc i32 %xor72.30.32 to i8
  store i8 %conv73.30.32, i8* %arrayidx70.32, align 1
  %scevgep20.31.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 31
  %16810 = load i8, i8* %scevgep20.31.32, align 1
  %conv68.31.32 = zext i8 %16810 to i32
  %16811 = load i8, i8* %arrayidx70.32, align 1
  %conv71.31.32 = zext i8 %16811 to i32
  %xor72.31.32 = xor i32 %conv71.31.32, %conv68.31.32
  %conv73.31.32 = trunc i32 %xor72.31.32 to i8
  store i8 %conv73.31.32, i8* %arrayidx70.32, align 1
  %scevgep20.33.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 33
  %16812 = load i8, i8* %scevgep20.33.32, align 1
  %conv68.33.32 = zext i8 %16812 to i32
  %16813 = load i8, i8* %arrayidx70.32, align 1
  %conv71.33.32 = zext i8 %16813 to i32
  %xor72.33.32 = xor i32 %conv71.33.32, %conv68.33.32
  %conv73.33.32 = trunc i32 %xor72.33.32 to i8
  store i8 %conv73.33.32, i8* %arrayidx70.32, align 1
  %scevgep20.34.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 34
  %16814 = load i8, i8* %scevgep20.34.32, align 1
  %conv68.34.32 = zext i8 %16814 to i32
  %16815 = load i8, i8* %arrayidx70.32, align 1
  %conv71.34.32 = zext i8 %16815 to i32
  %xor72.34.32 = xor i32 %conv71.34.32, %conv68.34.32
  %conv73.34.32 = trunc i32 %xor72.34.32 to i8
  store i8 %conv73.34.32, i8* %arrayidx70.32, align 1
  %scevgep20.35.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 35
  %16816 = load i8, i8* %scevgep20.35.32, align 1
  %conv68.35.32 = zext i8 %16816 to i32
  %16817 = load i8, i8* %arrayidx70.32, align 1
  %conv71.35.32 = zext i8 %16817 to i32
  %xor72.35.32 = xor i32 %conv71.35.32, %conv68.35.32
  %conv73.35.32 = trunc i32 %xor72.35.32 to i8
  store i8 %conv73.35.32, i8* %arrayidx70.32, align 1
  %scevgep20.36.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 36
  %16818 = load i8, i8* %scevgep20.36.32, align 1
  %conv68.36.32 = zext i8 %16818 to i32
  %16819 = load i8, i8* %arrayidx70.32, align 1
  %conv71.36.32 = zext i8 %16819 to i32
  %xor72.36.32 = xor i32 %conv71.36.32, %conv68.36.32
  %conv73.36.32 = trunc i32 %xor72.36.32 to i8
  store i8 %conv73.36.32, i8* %arrayidx70.32, align 1
  %scevgep20.37.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 37
  %16820 = load i8, i8* %scevgep20.37.32, align 1
  %conv68.37.32 = zext i8 %16820 to i32
  %16821 = load i8, i8* %arrayidx70.32, align 1
  %conv71.37.32 = zext i8 %16821 to i32
  %xor72.37.32 = xor i32 %conv71.37.32, %conv68.37.32
  %conv73.37.32 = trunc i32 %xor72.37.32 to i8
  store i8 %conv73.37.32, i8* %arrayidx70.32, align 1
  %scevgep20.38.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 38
  %16822 = load i8, i8* %scevgep20.38.32, align 1
  %conv68.38.32 = zext i8 %16822 to i32
  %16823 = load i8, i8* %arrayidx70.32, align 1
  %conv71.38.32 = zext i8 %16823 to i32
  %xor72.38.32 = xor i32 %conv71.38.32, %conv68.38.32
  %conv73.38.32 = trunc i32 %xor72.38.32 to i8
  store i8 %conv73.38.32, i8* %arrayidx70.32, align 1
  %scevgep20.39.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 39
  %16824 = load i8, i8* %scevgep20.39.32, align 1
  %conv68.39.32 = zext i8 %16824 to i32
  %16825 = load i8, i8* %arrayidx70.32, align 1
  %conv71.39.32 = zext i8 %16825 to i32
  %xor72.39.32 = xor i32 %conv71.39.32, %conv68.39.32
  %conv73.39.32 = trunc i32 %xor72.39.32 to i8
  store i8 %conv73.39.32, i8* %arrayidx70.32, align 1
  %scevgep20.40.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 40
  %16826 = load i8, i8* %scevgep20.40.32, align 1
  %conv68.40.32 = zext i8 %16826 to i32
  %16827 = load i8, i8* %arrayidx70.32, align 1
  %conv71.40.32 = zext i8 %16827 to i32
  %xor72.40.32 = xor i32 %conv71.40.32, %conv68.40.32
  %conv73.40.32 = trunc i32 %xor72.40.32 to i8
  store i8 %conv73.40.32, i8* %arrayidx70.32, align 1
  %scevgep20.41.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 41
  %16828 = load i8, i8* %scevgep20.41.32, align 1
  %conv68.41.32 = zext i8 %16828 to i32
  %16829 = load i8, i8* %arrayidx70.32, align 1
  %conv71.41.32 = zext i8 %16829 to i32
  %xor72.41.32 = xor i32 %conv71.41.32, %conv68.41.32
  %conv73.41.32 = trunc i32 %xor72.41.32 to i8
  store i8 %conv73.41.32, i8* %arrayidx70.32, align 1
  %scevgep20.42.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 42
  %16830 = load i8, i8* %scevgep20.42.32, align 1
  %conv68.42.32 = zext i8 %16830 to i32
  %16831 = load i8, i8* %arrayidx70.32, align 1
  %conv71.42.32 = zext i8 %16831 to i32
  %xor72.42.32 = xor i32 %conv71.42.32, %conv68.42.32
  %conv73.42.32 = trunc i32 %xor72.42.32 to i8
  store i8 %conv73.42.32, i8* %arrayidx70.32, align 1
  %scevgep20.43.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 43
  %16832 = load i8, i8* %scevgep20.43.32, align 1
  %conv68.43.32 = zext i8 %16832 to i32
  %16833 = load i8, i8* %arrayidx70.32, align 1
  %conv71.43.32 = zext i8 %16833 to i32
  %xor72.43.32 = xor i32 %conv71.43.32, %conv68.43.32
  %conv73.43.32 = trunc i32 %xor72.43.32 to i8
  store i8 %conv73.43.32, i8* %arrayidx70.32, align 1
  %scevgep20.44.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 44
  %16834 = load i8, i8* %scevgep20.44.32, align 1
  %conv68.44.32 = zext i8 %16834 to i32
  %16835 = load i8, i8* %arrayidx70.32, align 1
  %conv71.44.32 = zext i8 %16835 to i32
  %xor72.44.32 = xor i32 %conv71.44.32, %conv68.44.32
  %conv73.44.32 = trunc i32 %xor72.44.32 to i8
  store i8 %conv73.44.32, i8* %arrayidx70.32, align 1
  %scevgep20.45.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 45
  %16836 = load i8, i8* %scevgep20.45.32, align 1
  %conv68.45.32 = zext i8 %16836 to i32
  %16837 = load i8, i8* %arrayidx70.32, align 1
  %conv71.45.32 = zext i8 %16837 to i32
  %xor72.45.32 = xor i32 %conv71.45.32, %conv68.45.32
  %conv73.45.32 = trunc i32 %xor72.45.32 to i8
  store i8 %conv73.45.32, i8* %arrayidx70.32, align 1
  %scevgep20.46.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 46
  %16838 = load i8, i8* %scevgep20.46.32, align 1
  %conv68.46.32 = zext i8 %16838 to i32
  %16839 = load i8, i8* %arrayidx70.32, align 1
  %conv71.46.32 = zext i8 %16839 to i32
  %xor72.46.32 = xor i32 %conv71.46.32, %conv68.46.32
  %conv73.46.32 = trunc i32 %xor72.46.32 to i8
  store i8 %conv73.46.32, i8* %arrayidx70.32, align 1
  %scevgep20.47.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 47
  %16840 = load i8, i8* %scevgep20.47.32, align 1
  %conv68.47.32 = zext i8 %16840 to i32
  %16841 = load i8, i8* %arrayidx70.32, align 1
  %conv71.47.32 = zext i8 %16841 to i32
  %xor72.47.32 = xor i32 %conv71.47.32, %conv68.47.32
  %conv73.47.32 = trunc i32 %xor72.47.32 to i8
  store i8 %conv73.47.32, i8* %arrayidx70.32, align 1
  %scevgep20.48.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 48
  %16842 = load i8, i8* %scevgep20.48.32, align 1
  %conv68.48.32 = zext i8 %16842 to i32
  %16843 = load i8, i8* %arrayidx70.32, align 1
  %conv71.48.32 = zext i8 %16843 to i32
  %xor72.48.32 = xor i32 %conv71.48.32, %conv68.48.32
  %conv73.48.32 = trunc i32 %xor72.48.32 to i8
  store i8 %conv73.48.32, i8* %arrayidx70.32, align 1
  %scevgep20.49.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 49
  %16844 = load i8, i8* %scevgep20.49.32, align 1
  %conv68.49.32 = zext i8 %16844 to i32
  %16845 = load i8, i8* %arrayidx70.32, align 1
  %conv71.49.32 = zext i8 %16845 to i32
  %xor72.49.32 = xor i32 %conv71.49.32, %conv68.49.32
  %conv73.49.32 = trunc i32 %xor72.49.32 to i8
  store i8 %conv73.49.32, i8* %arrayidx70.32, align 1
  %scevgep20.50.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 50
  %16846 = load i8, i8* %scevgep20.50.32, align 1
  %conv68.50.32 = zext i8 %16846 to i32
  %16847 = load i8, i8* %arrayidx70.32, align 1
  %conv71.50.32 = zext i8 %16847 to i32
  %xor72.50.32 = xor i32 %conv71.50.32, %conv68.50.32
  %conv73.50.32 = trunc i32 %xor72.50.32 to i8
  store i8 %conv73.50.32, i8* %arrayidx70.32, align 1
  %scevgep20.51.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 51
  %16848 = load i8, i8* %scevgep20.51.32, align 1
  %conv68.51.32 = zext i8 %16848 to i32
  %16849 = load i8, i8* %arrayidx70.32, align 1
  %conv71.51.32 = zext i8 %16849 to i32
  %xor72.51.32 = xor i32 %conv71.51.32, %conv68.51.32
  %conv73.51.32 = trunc i32 %xor72.51.32 to i8
  store i8 %conv73.51.32, i8* %arrayidx70.32, align 1
  %scevgep20.52.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 52
  %16850 = load i8, i8* %scevgep20.52.32, align 1
  %conv68.52.32 = zext i8 %16850 to i32
  %16851 = load i8, i8* %arrayidx70.32, align 1
  %conv71.52.32 = zext i8 %16851 to i32
  %xor72.52.32 = xor i32 %conv71.52.32, %conv68.52.32
  %conv73.52.32 = trunc i32 %xor72.52.32 to i8
  store i8 %conv73.52.32, i8* %arrayidx70.32, align 1
  %scevgep20.53.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 53
  %16852 = load i8, i8* %scevgep20.53.32, align 1
  %conv68.53.32 = zext i8 %16852 to i32
  %16853 = load i8, i8* %arrayidx70.32, align 1
  %conv71.53.32 = zext i8 %16853 to i32
  %xor72.53.32 = xor i32 %conv71.53.32, %conv68.53.32
  %conv73.53.32 = trunc i32 %xor72.53.32 to i8
  store i8 %conv73.53.32, i8* %arrayidx70.32, align 1
  %scevgep20.54.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 54
  %16854 = load i8, i8* %scevgep20.54.32, align 1
  %conv68.54.32 = zext i8 %16854 to i32
  %16855 = load i8, i8* %arrayidx70.32, align 1
  %conv71.54.32 = zext i8 %16855 to i32
  %xor72.54.32 = xor i32 %conv71.54.32, %conv68.54.32
  %conv73.54.32 = trunc i32 %xor72.54.32 to i8
  store i8 %conv73.54.32, i8* %arrayidx70.32, align 1
  %scevgep20.55.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 55
  %16856 = load i8, i8* %scevgep20.55.32, align 1
  %conv68.55.32 = zext i8 %16856 to i32
  %16857 = load i8, i8* %arrayidx70.32, align 1
  %conv71.55.32 = zext i8 %16857 to i32
  %xor72.55.32 = xor i32 %conv71.55.32, %conv68.55.32
  %conv73.55.32 = trunc i32 %xor72.55.32 to i8
  store i8 %conv73.55.32, i8* %arrayidx70.32, align 1
  %scevgep20.56.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 56
  %16858 = load i8, i8* %scevgep20.56.32, align 1
  %conv68.56.32 = zext i8 %16858 to i32
  %16859 = load i8, i8* %arrayidx70.32, align 1
  %conv71.56.32 = zext i8 %16859 to i32
  %xor72.56.32 = xor i32 %conv71.56.32, %conv68.56.32
  %conv73.56.32 = trunc i32 %xor72.56.32 to i8
  store i8 %conv73.56.32, i8* %arrayidx70.32, align 1
  %scevgep20.57.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 57
  %16860 = load i8, i8* %scevgep20.57.32, align 1
  %conv68.57.32 = zext i8 %16860 to i32
  %16861 = load i8, i8* %arrayidx70.32, align 1
  %conv71.57.32 = zext i8 %16861 to i32
  %xor72.57.32 = xor i32 %conv71.57.32, %conv68.57.32
  %conv73.57.32 = trunc i32 %xor72.57.32 to i8
  store i8 %conv73.57.32, i8* %arrayidx70.32, align 1
  %scevgep20.58.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 58
  %16862 = load i8, i8* %scevgep20.58.32, align 1
  %conv68.58.32 = zext i8 %16862 to i32
  %16863 = load i8, i8* %arrayidx70.32, align 1
  %conv71.58.32 = zext i8 %16863 to i32
  %xor72.58.32 = xor i32 %conv71.58.32, %conv68.58.32
  %conv73.58.32 = trunc i32 %xor72.58.32 to i8
  store i8 %conv73.58.32, i8* %arrayidx70.32, align 1
  %scevgep20.59.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 59
  %16864 = load i8, i8* %scevgep20.59.32, align 1
  %conv68.59.32 = zext i8 %16864 to i32
  %16865 = load i8, i8* %arrayidx70.32, align 1
  %conv71.59.32 = zext i8 %16865 to i32
  %xor72.59.32 = xor i32 %conv71.59.32, %conv68.59.32
  %conv73.59.32 = trunc i32 %xor72.59.32 to i8
  store i8 %conv73.59.32, i8* %arrayidx70.32, align 1
  %scevgep20.60.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 0, i64 60
  %16866 = load i8, i8* %scevgep20.60.32, align 1
  %conv68.60.32 = zext i8 %16866 to i32
  %16867 = load i8, i8* %arrayidx70.32, align 1
  %conv71.60.32 = zext i8 %16867 to i32
  %xor72.60.32 = xor i32 %conv71.60.32, %conv68.60.32
  %conv73.60.32 = trunc i32 %xor72.60.32 to i8
  store i8 %conv73.60.32, i8* %arrayidx70.32, align 1
  %scevgep19.32 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16745, i64 0, i64 1, i64 0
  %16868 = bitcast i8* %scevgep19.32 to [61 x [61 x i8]]*
  %arrayidx51.33 = getelementptr inbounds i8, i8* %a, i64 33
  %16869 = load i8, i8* %arrayidx51.33, align 1
  %arrayidx53.33 = getelementptr inbounds i8, i8* %b, i64 33
  %16870 = load i8, i8* %arrayidx53.33, align 1
  %call54.33 = call zeroext i8 @mult(i8 zeroext %16869, i8 zeroext %16870)
  %arrayidx56.33 = getelementptr inbounds i8, i8* %c, i64 33
  store i8 %call54.33, i8* %arrayidx56.33, align 1
  %arrayidx70.33 = getelementptr inbounds i8, i8* %c, i64 33
  %scevgep20.33374 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 0
  %16871 = load i8, i8* %scevgep20.33374, align 1
  %conv68.33375 = zext i8 %16871 to i32
  %16872 = load i8, i8* %arrayidx70.33, align 1
  %conv71.33376 = zext i8 %16872 to i32
  %xor72.33377 = xor i32 %conv71.33376, %conv68.33375
  %conv73.33378 = trunc i32 %xor72.33377 to i8
  store i8 %conv73.33378, i8* %arrayidx70.33, align 1
  %scevgep20.1.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 1
  %16873 = load i8, i8* %scevgep20.1.33, align 1
  %conv68.1.33 = zext i8 %16873 to i32
  %16874 = load i8, i8* %arrayidx70.33, align 1
  %conv71.1.33 = zext i8 %16874 to i32
  %xor72.1.33 = xor i32 %conv71.1.33, %conv68.1.33
  %conv73.1.33 = trunc i32 %xor72.1.33 to i8
  store i8 %conv73.1.33, i8* %arrayidx70.33, align 1
  %scevgep20.2.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 2
  %16875 = load i8, i8* %scevgep20.2.33, align 1
  %conv68.2.33 = zext i8 %16875 to i32
  %16876 = load i8, i8* %arrayidx70.33, align 1
  %conv71.2.33 = zext i8 %16876 to i32
  %xor72.2.33 = xor i32 %conv71.2.33, %conv68.2.33
  %conv73.2.33 = trunc i32 %xor72.2.33 to i8
  store i8 %conv73.2.33, i8* %arrayidx70.33, align 1
  %scevgep20.3.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 3
  %16877 = load i8, i8* %scevgep20.3.33, align 1
  %conv68.3.33 = zext i8 %16877 to i32
  %16878 = load i8, i8* %arrayidx70.33, align 1
  %conv71.3.33 = zext i8 %16878 to i32
  %xor72.3.33 = xor i32 %conv71.3.33, %conv68.3.33
  %conv73.3.33 = trunc i32 %xor72.3.33 to i8
  store i8 %conv73.3.33, i8* %arrayidx70.33, align 1
  %scevgep20.4.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 4
  %16879 = load i8, i8* %scevgep20.4.33, align 1
  %conv68.4.33 = zext i8 %16879 to i32
  %16880 = load i8, i8* %arrayidx70.33, align 1
  %conv71.4.33 = zext i8 %16880 to i32
  %xor72.4.33 = xor i32 %conv71.4.33, %conv68.4.33
  %conv73.4.33 = trunc i32 %xor72.4.33 to i8
  store i8 %conv73.4.33, i8* %arrayidx70.33, align 1
  %scevgep20.5.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 5
  %16881 = load i8, i8* %scevgep20.5.33, align 1
  %conv68.5.33 = zext i8 %16881 to i32
  %16882 = load i8, i8* %arrayidx70.33, align 1
  %conv71.5.33 = zext i8 %16882 to i32
  %xor72.5.33 = xor i32 %conv71.5.33, %conv68.5.33
  %conv73.5.33 = trunc i32 %xor72.5.33 to i8
  store i8 %conv73.5.33, i8* %arrayidx70.33, align 1
  %scevgep20.6.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 6
  %16883 = load i8, i8* %scevgep20.6.33, align 1
  %conv68.6.33 = zext i8 %16883 to i32
  %16884 = load i8, i8* %arrayidx70.33, align 1
  %conv71.6.33 = zext i8 %16884 to i32
  %xor72.6.33 = xor i32 %conv71.6.33, %conv68.6.33
  %conv73.6.33 = trunc i32 %xor72.6.33 to i8
  store i8 %conv73.6.33, i8* %arrayidx70.33, align 1
  %scevgep20.7.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 7
  %16885 = load i8, i8* %scevgep20.7.33, align 1
  %conv68.7.33 = zext i8 %16885 to i32
  %16886 = load i8, i8* %arrayidx70.33, align 1
  %conv71.7.33 = zext i8 %16886 to i32
  %xor72.7.33 = xor i32 %conv71.7.33, %conv68.7.33
  %conv73.7.33 = trunc i32 %xor72.7.33 to i8
  store i8 %conv73.7.33, i8* %arrayidx70.33, align 1
  %scevgep20.8.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 8
  %16887 = load i8, i8* %scevgep20.8.33, align 1
  %conv68.8.33 = zext i8 %16887 to i32
  %16888 = load i8, i8* %arrayidx70.33, align 1
  %conv71.8.33 = zext i8 %16888 to i32
  %xor72.8.33 = xor i32 %conv71.8.33, %conv68.8.33
  %conv73.8.33 = trunc i32 %xor72.8.33 to i8
  store i8 %conv73.8.33, i8* %arrayidx70.33, align 1
  %scevgep20.9.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 9
  %16889 = load i8, i8* %scevgep20.9.33, align 1
  %conv68.9.33 = zext i8 %16889 to i32
  %16890 = load i8, i8* %arrayidx70.33, align 1
  %conv71.9.33 = zext i8 %16890 to i32
  %xor72.9.33 = xor i32 %conv71.9.33, %conv68.9.33
  %conv73.9.33 = trunc i32 %xor72.9.33 to i8
  store i8 %conv73.9.33, i8* %arrayidx70.33, align 1
  %scevgep20.10.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 10
  %16891 = load i8, i8* %scevgep20.10.33, align 1
  %conv68.10.33 = zext i8 %16891 to i32
  %16892 = load i8, i8* %arrayidx70.33, align 1
  %conv71.10.33 = zext i8 %16892 to i32
  %xor72.10.33 = xor i32 %conv71.10.33, %conv68.10.33
  %conv73.10.33 = trunc i32 %xor72.10.33 to i8
  store i8 %conv73.10.33, i8* %arrayidx70.33, align 1
  %scevgep20.11.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 11
  %16893 = load i8, i8* %scevgep20.11.33, align 1
  %conv68.11.33 = zext i8 %16893 to i32
  %16894 = load i8, i8* %arrayidx70.33, align 1
  %conv71.11.33 = zext i8 %16894 to i32
  %xor72.11.33 = xor i32 %conv71.11.33, %conv68.11.33
  %conv73.11.33 = trunc i32 %xor72.11.33 to i8
  store i8 %conv73.11.33, i8* %arrayidx70.33, align 1
  %scevgep20.12.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 12
  %16895 = load i8, i8* %scevgep20.12.33, align 1
  %conv68.12.33 = zext i8 %16895 to i32
  %16896 = load i8, i8* %arrayidx70.33, align 1
  %conv71.12.33 = zext i8 %16896 to i32
  %xor72.12.33 = xor i32 %conv71.12.33, %conv68.12.33
  %conv73.12.33 = trunc i32 %xor72.12.33 to i8
  store i8 %conv73.12.33, i8* %arrayidx70.33, align 1
  %scevgep20.13.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 13
  %16897 = load i8, i8* %scevgep20.13.33, align 1
  %conv68.13.33 = zext i8 %16897 to i32
  %16898 = load i8, i8* %arrayidx70.33, align 1
  %conv71.13.33 = zext i8 %16898 to i32
  %xor72.13.33 = xor i32 %conv71.13.33, %conv68.13.33
  %conv73.13.33 = trunc i32 %xor72.13.33 to i8
  store i8 %conv73.13.33, i8* %arrayidx70.33, align 1
  %scevgep20.14.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 14
  %16899 = load i8, i8* %scevgep20.14.33, align 1
  %conv68.14.33 = zext i8 %16899 to i32
  %16900 = load i8, i8* %arrayidx70.33, align 1
  %conv71.14.33 = zext i8 %16900 to i32
  %xor72.14.33 = xor i32 %conv71.14.33, %conv68.14.33
  %conv73.14.33 = trunc i32 %xor72.14.33 to i8
  store i8 %conv73.14.33, i8* %arrayidx70.33, align 1
  %scevgep20.15.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 15
  %16901 = load i8, i8* %scevgep20.15.33, align 1
  %conv68.15.33 = zext i8 %16901 to i32
  %16902 = load i8, i8* %arrayidx70.33, align 1
  %conv71.15.33 = zext i8 %16902 to i32
  %xor72.15.33 = xor i32 %conv71.15.33, %conv68.15.33
  %conv73.15.33 = trunc i32 %xor72.15.33 to i8
  store i8 %conv73.15.33, i8* %arrayidx70.33, align 1
  %scevgep20.16.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 16
  %16903 = load i8, i8* %scevgep20.16.33, align 1
  %conv68.16.33 = zext i8 %16903 to i32
  %16904 = load i8, i8* %arrayidx70.33, align 1
  %conv71.16.33 = zext i8 %16904 to i32
  %xor72.16.33 = xor i32 %conv71.16.33, %conv68.16.33
  %conv73.16.33 = trunc i32 %xor72.16.33 to i8
  store i8 %conv73.16.33, i8* %arrayidx70.33, align 1
  %scevgep20.17.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 17
  %16905 = load i8, i8* %scevgep20.17.33, align 1
  %conv68.17.33 = zext i8 %16905 to i32
  %16906 = load i8, i8* %arrayidx70.33, align 1
  %conv71.17.33 = zext i8 %16906 to i32
  %xor72.17.33 = xor i32 %conv71.17.33, %conv68.17.33
  %conv73.17.33 = trunc i32 %xor72.17.33 to i8
  store i8 %conv73.17.33, i8* %arrayidx70.33, align 1
  %scevgep20.18.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 18
  %16907 = load i8, i8* %scevgep20.18.33, align 1
  %conv68.18.33 = zext i8 %16907 to i32
  %16908 = load i8, i8* %arrayidx70.33, align 1
  %conv71.18.33 = zext i8 %16908 to i32
  %xor72.18.33 = xor i32 %conv71.18.33, %conv68.18.33
  %conv73.18.33 = trunc i32 %xor72.18.33 to i8
  store i8 %conv73.18.33, i8* %arrayidx70.33, align 1
  %scevgep20.19.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 19
  %16909 = load i8, i8* %scevgep20.19.33, align 1
  %conv68.19.33 = zext i8 %16909 to i32
  %16910 = load i8, i8* %arrayidx70.33, align 1
  %conv71.19.33 = zext i8 %16910 to i32
  %xor72.19.33 = xor i32 %conv71.19.33, %conv68.19.33
  %conv73.19.33 = trunc i32 %xor72.19.33 to i8
  store i8 %conv73.19.33, i8* %arrayidx70.33, align 1
  %scevgep20.20.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 20
  %16911 = load i8, i8* %scevgep20.20.33, align 1
  %conv68.20.33 = zext i8 %16911 to i32
  %16912 = load i8, i8* %arrayidx70.33, align 1
  %conv71.20.33 = zext i8 %16912 to i32
  %xor72.20.33 = xor i32 %conv71.20.33, %conv68.20.33
  %conv73.20.33 = trunc i32 %xor72.20.33 to i8
  store i8 %conv73.20.33, i8* %arrayidx70.33, align 1
  %scevgep20.21.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 21
  %16913 = load i8, i8* %scevgep20.21.33, align 1
  %conv68.21.33 = zext i8 %16913 to i32
  %16914 = load i8, i8* %arrayidx70.33, align 1
  %conv71.21.33 = zext i8 %16914 to i32
  %xor72.21.33 = xor i32 %conv71.21.33, %conv68.21.33
  %conv73.21.33 = trunc i32 %xor72.21.33 to i8
  store i8 %conv73.21.33, i8* %arrayidx70.33, align 1
  %scevgep20.22.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 22
  %16915 = load i8, i8* %scevgep20.22.33, align 1
  %conv68.22.33 = zext i8 %16915 to i32
  %16916 = load i8, i8* %arrayidx70.33, align 1
  %conv71.22.33 = zext i8 %16916 to i32
  %xor72.22.33 = xor i32 %conv71.22.33, %conv68.22.33
  %conv73.22.33 = trunc i32 %xor72.22.33 to i8
  store i8 %conv73.22.33, i8* %arrayidx70.33, align 1
  %scevgep20.23.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 23
  %16917 = load i8, i8* %scevgep20.23.33, align 1
  %conv68.23.33 = zext i8 %16917 to i32
  %16918 = load i8, i8* %arrayidx70.33, align 1
  %conv71.23.33 = zext i8 %16918 to i32
  %xor72.23.33 = xor i32 %conv71.23.33, %conv68.23.33
  %conv73.23.33 = trunc i32 %xor72.23.33 to i8
  store i8 %conv73.23.33, i8* %arrayidx70.33, align 1
  %scevgep20.24.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 24
  %16919 = load i8, i8* %scevgep20.24.33, align 1
  %conv68.24.33 = zext i8 %16919 to i32
  %16920 = load i8, i8* %arrayidx70.33, align 1
  %conv71.24.33 = zext i8 %16920 to i32
  %xor72.24.33 = xor i32 %conv71.24.33, %conv68.24.33
  %conv73.24.33 = trunc i32 %xor72.24.33 to i8
  store i8 %conv73.24.33, i8* %arrayidx70.33, align 1
  %scevgep20.25.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 25
  %16921 = load i8, i8* %scevgep20.25.33, align 1
  %conv68.25.33 = zext i8 %16921 to i32
  %16922 = load i8, i8* %arrayidx70.33, align 1
  %conv71.25.33 = zext i8 %16922 to i32
  %xor72.25.33 = xor i32 %conv71.25.33, %conv68.25.33
  %conv73.25.33 = trunc i32 %xor72.25.33 to i8
  store i8 %conv73.25.33, i8* %arrayidx70.33, align 1
  %scevgep20.26.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 26
  %16923 = load i8, i8* %scevgep20.26.33, align 1
  %conv68.26.33 = zext i8 %16923 to i32
  %16924 = load i8, i8* %arrayidx70.33, align 1
  %conv71.26.33 = zext i8 %16924 to i32
  %xor72.26.33 = xor i32 %conv71.26.33, %conv68.26.33
  %conv73.26.33 = trunc i32 %xor72.26.33 to i8
  store i8 %conv73.26.33, i8* %arrayidx70.33, align 1
  %scevgep20.27.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 27
  %16925 = load i8, i8* %scevgep20.27.33, align 1
  %conv68.27.33 = zext i8 %16925 to i32
  %16926 = load i8, i8* %arrayidx70.33, align 1
  %conv71.27.33 = zext i8 %16926 to i32
  %xor72.27.33 = xor i32 %conv71.27.33, %conv68.27.33
  %conv73.27.33 = trunc i32 %xor72.27.33 to i8
  store i8 %conv73.27.33, i8* %arrayidx70.33, align 1
  %scevgep20.28.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 28
  %16927 = load i8, i8* %scevgep20.28.33, align 1
  %conv68.28.33 = zext i8 %16927 to i32
  %16928 = load i8, i8* %arrayidx70.33, align 1
  %conv71.28.33 = zext i8 %16928 to i32
  %xor72.28.33 = xor i32 %conv71.28.33, %conv68.28.33
  %conv73.28.33 = trunc i32 %xor72.28.33 to i8
  store i8 %conv73.28.33, i8* %arrayidx70.33, align 1
  %scevgep20.29.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 29
  %16929 = load i8, i8* %scevgep20.29.33, align 1
  %conv68.29.33 = zext i8 %16929 to i32
  %16930 = load i8, i8* %arrayidx70.33, align 1
  %conv71.29.33 = zext i8 %16930 to i32
  %xor72.29.33 = xor i32 %conv71.29.33, %conv68.29.33
  %conv73.29.33 = trunc i32 %xor72.29.33 to i8
  store i8 %conv73.29.33, i8* %arrayidx70.33, align 1
  %scevgep20.30.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 30
  %16931 = load i8, i8* %scevgep20.30.33, align 1
  %conv68.30.33 = zext i8 %16931 to i32
  %16932 = load i8, i8* %arrayidx70.33, align 1
  %conv71.30.33 = zext i8 %16932 to i32
  %xor72.30.33 = xor i32 %conv71.30.33, %conv68.30.33
  %conv73.30.33 = trunc i32 %xor72.30.33 to i8
  store i8 %conv73.30.33, i8* %arrayidx70.33, align 1
  %scevgep20.31.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 31
  %16933 = load i8, i8* %scevgep20.31.33, align 1
  %conv68.31.33 = zext i8 %16933 to i32
  %16934 = load i8, i8* %arrayidx70.33, align 1
  %conv71.31.33 = zext i8 %16934 to i32
  %xor72.31.33 = xor i32 %conv71.31.33, %conv68.31.33
  %conv73.31.33 = trunc i32 %xor72.31.33 to i8
  store i8 %conv73.31.33, i8* %arrayidx70.33, align 1
  %scevgep20.32.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 32
  %16935 = load i8, i8* %scevgep20.32.33, align 1
  %conv68.32.33 = zext i8 %16935 to i32
  %16936 = load i8, i8* %arrayidx70.33, align 1
  %conv71.32.33 = zext i8 %16936 to i32
  %xor72.32.33 = xor i32 %conv71.32.33, %conv68.32.33
  %conv73.32.33 = trunc i32 %xor72.32.33 to i8
  store i8 %conv73.32.33, i8* %arrayidx70.33, align 1
  %scevgep20.34.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 34
  %16937 = load i8, i8* %scevgep20.34.33, align 1
  %conv68.34.33 = zext i8 %16937 to i32
  %16938 = load i8, i8* %arrayidx70.33, align 1
  %conv71.34.33 = zext i8 %16938 to i32
  %xor72.34.33 = xor i32 %conv71.34.33, %conv68.34.33
  %conv73.34.33 = trunc i32 %xor72.34.33 to i8
  store i8 %conv73.34.33, i8* %arrayidx70.33, align 1
  %scevgep20.35.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 35
  %16939 = load i8, i8* %scevgep20.35.33, align 1
  %conv68.35.33 = zext i8 %16939 to i32
  %16940 = load i8, i8* %arrayidx70.33, align 1
  %conv71.35.33 = zext i8 %16940 to i32
  %xor72.35.33 = xor i32 %conv71.35.33, %conv68.35.33
  %conv73.35.33 = trunc i32 %xor72.35.33 to i8
  store i8 %conv73.35.33, i8* %arrayidx70.33, align 1
  %scevgep20.36.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 36
  %16941 = load i8, i8* %scevgep20.36.33, align 1
  %conv68.36.33 = zext i8 %16941 to i32
  %16942 = load i8, i8* %arrayidx70.33, align 1
  %conv71.36.33 = zext i8 %16942 to i32
  %xor72.36.33 = xor i32 %conv71.36.33, %conv68.36.33
  %conv73.36.33 = trunc i32 %xor72.36.33 to i8
  store i8 %conv73.36.33, i8* %arrayidx70.33, align 1
  %scevgep20.37.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 37
  %16943 = load i8, i8* %scevgep20.37.33, align 1
  %conv68.37.33 = zext i8 %16943 to i32
  %16944 = load i8, i8* %arrayidx70.33, align 1
  %conv71.37.33 = zext i8 %16944 to i32
  %xor72.37.33 = xor i32 %conv71.37.33, %conv68.37.33
  %conv73.37.33 = trunc i32 %xor72.37.33 to i8
  store i8 %conv73.37.33, i8* %arrayidx70.33, align 1
  %scevgep20.38.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 38
  %16945 = load i8, i8* %scevgep20.38.33, align 1
  %conv68.38.33 = zext i8 %16945 to i32
  %16946 = load i8, i8* %arrayidx70.33, align 1
  %conv71.38.33 = zext i8 %16946 to i32
  %xor72.38.33 = xor i32 %conv71.38.33, %conv68.38.33
  %conv73.38.33 = trunc i32 %xor72.38.33 to i8
  store i8 %conv73.38.33, i8* %arrayidx70.33, align 1
  %scevgep20.39.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 39
  %16947 = load i8, i8* %scevgep20.39.33, align 1
  %conv68.39.33 = zext i8 %16947 to i32
  %16948 = load i8, i8* %arrayidx70.33, align 1
  %conv71.39.33 = zext i8 %16948 to i32
  %xor72.39.33 = xor i32 %conv71.39.33, %conv68.39.33
  %conv73.39.33 = trunc i32 %xor72.39.33 to i8
  store i8 %conv73.39.33, i8* %arrayidx70.33, align 1
  %scevgep20.40.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 40
  %16949 = load i8, i8* %scevgep20.40.33, align 1
  %conv68.40.33 = zext i8 %16949 to i32
  %16950 = load i8, i8* %arrayidx70.33, align 1
  %conv71.40.33 = zext i8 %16950 to i32
  %xor72.40.33 = xor i32 %conv71.40.33, %conv68.40.33
  %conv73.40.33 = trunc i32 %xor72.40.33 to i8
  store i8 %conv73.40.33, i8* %arrayidx70.33, align 1
  %scevgep20.41.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 41
  %16951 = load i8, i8* %scevgep20.41.33, align 1
  %conv68.41.33 = zext i8 %16951 to i32
  %16952 = load i8, i8* %arrayidx70.33, align 1
  %conv71.41.33 = zext i8 %16952 to i32
  %xor72.41.33 = xor i32 %conv71.41.33, %conv68.41.33
  %conv73.41.33 = trunc i32 %xor72.41.33 to i8
  store i8 %conv73.41.33, i8* %arrayidx70.33, align 1
  %scevgep20.42.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 42
  %16953 = load i8, i8* %scevgep20.42.33, align 1
  %conv68.42.33 = zext i8 %16953 to i32
  %16954 = load i8, i8* %arrayidx70.33, align 1
  %conv71.42.33 = zext i8 %16954 to i32
  %xor72.42.33 = xor i32 %conv71.42.33, %conv68.42.33
  %conv73.42.33 = trunc i32 %xor72.42.33 to i8
  store i8 %conv73.42.33, i8* %arrayidx70.33, align 1
  %scevgep20.43.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 43
  %16955 = load i8, i8* %scevgep20.43.33, align 1
  %conv68.43.33 = zext i8 %16955 to i32
  %16956 = load i8, i8* %arrayidx70.33, align 1
  %conv71.43.33 = zext i8 %16956 to i32
  %xor72.43.33 = xor i32 %conv71.43.33, %conv68.43.33
  %conv73.43.33 = trunc i32 %xor72.43.33 to i8
  store i8 %conv73.43.33, i8* %arrayidx70.33, align 1
  %scevgep20.44.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 44
  %16957 = load i8, i8* %scevgep20.44.33, align 1
  %conv68.44.33 = zext i8 %16957 to i32
  %16958 = load i8, i8* %arrayidx70.33, align 1
  %conv71.44.33 = zext i8 %16958 to i32
  %xor72.44.33 = xor i32 %conv71.44.33, %conv68.44.33
  %conv73.44.33 = trunc i32 %xor72.44.33 to i8
  store i8 %conv73.44.33, i8* %arrayidx70.33, align 1
  %scevgep20.45.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 45
  %16959 = load i8, i8* %scevgep20.45.33, align 1
  %conv68.45.33 = zext i8 %16959 to i32
  %16960 = load i8, i8* %arrayidx70.33, align 1
  %conv71.45.33 = zext i8 %16960 to i32
  %xor72.45.33 = xor i32 %conv71.45.33, %conv68.45.33
  %conv73.45.33 = trunc i32 %xor72.45.33 to i8
  store i8 %conv73.45.33, i8* %arrayidx70.33, align 1
  %scevgep20.46.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 46
  %16961 = load i8, i8* %scevgep20.46.33, align 1
  %conv68.46.33 = zext i8 %16961 to i32
  %16962 = load i8, i8* %arrayidx70.33, align 1
  %conv71.46.33 = zext i8 %16962 to i32
  %xor72.46.33 = xor i32 %conv71.46.33, %conv68.46.33
  %conv73.46.33 = trunc i32 %xor72.46.33 to i8
  store i8 %conv73.46.33, i8* %arrayidx70.33, align 1
  %scevgep20.47.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 47
  %16963 = load i8, i8* %scevgep20.47.33, align 1
  %conv68.47.33 = zext i8 %16963 to i32
  %16964 = load i8, i8* %arrayidx70.33, align 1
  %conv71.47.33 = zext i8 %16964 to i32
  %xor72.47.33 = xor i32 %conv71.47.33, %conv68.47.33
  %conv73.47.33 = trunc i32 %xor72.47.33 to i8
  store i8 %conv73.47.33, i8* %arrayidx70.33, align 1
  %scevgep20.48.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 48
  %16965 = load i8, i8* %scevgep20.48.33, align 1
  %conv68.48.33 = zext i8 %16965 to i32
  %16966 = load i8, i8* %arrayidx70.33, align 1
  %conv71.48.33 = zext i8 %16966 to i32
  %xor72.48.33 = xor i32 %conv71.48.33, %conv68.48.33
  %conv73.48.33 = trunc i32 %xor72.48.33 to i8
  store i8 %conv73.48.33, i8* %arrayidx70.33, align 1
  %scevgep20.49.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 49
  %16967 = load i8, i8* %scevgep20.49.33, align 1
  %conv68.49.33 = zext i8 %16967 to i32
  %16968 = load i8, i8* %arrayidx70.33, align 1
  %conv71.49.33 = zext i8 %16968 to i32
  %xor72.49.33 = xor i32 %conv71.49.33, %conv68.49.33
  %conv73.49.33 = trunc i32 %xor72.49.33 to i8
  store i8 %conv73.49.33, i8* %arrayidx70.33, align 1
  %scevgep20.50.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 50
  %16969 = load i8, i8* %scevgep20.50.33, align 1
  %conv68.50.33 = zext i8 %16969 to i32
  %16970 = load i8, i8* %arrayidx70.33, align 1
  %conv71.50.33 = zext i8 %16970 to i32
  %xor72.50.33 = xor i32 %conv71.50.33, %conv68.50.33
  %conv73.50.33 = trunc i32 %xor72.50.33 to i8
  store i8 %conv73.50.33, i8* %arrayidx70.33, align 1
  %scevgep20.51.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 51
  %16971 = load i8, i8* %scevgep20.51.33, align 1
  %conv68.51.33 = zext i8 %16971 to i32
  %16972 = load i8, i8* %arrayidx70.33, align 1
  %conv71.51.33 = zext i8 %16972 to i32
  %xor72.51.33 = xor i32 %conv71.51.33, %conv68.51.33
  %conv73.51.33 = trunc i32 %xor72.51.33 to i8
  store i8 %conv73.51.33, i8* %arrayidx70.33, align 1
  %scevgep20.52.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 52
  %16973 = load i8, i8* %scevgep20.52.33, align 1
  %conv68.52.33 = zext i8 %16973 to i32
  %16974 = load i8, i8* %arrayidx70.33, align 1
  %conv71.52.33 = zext i8 %16974 to i32
  %xor72.52.33 = xor i32 %conv71.52.33, %conv68.52.33
  %conv73.52.33 = trunc i32 %xor72.52.33 to i8
  store i8 %conv73.52.33, i8* %arrayidx70.33, align 1
  %scevgep20.53.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 53
  %16975 = load i8, i8* %scevgep20.53.33, align 1
  %conv68.53.33 = zext i8 %16975 to i32
  %16976 = load i8, i8* %arrayidx70.33, align 1
  %conv71.53.33 = zext i8 %16976 to i32
  %xor72.53.33 = xor i32 %conv71.53.33, %conv68.53.33
  %conv73.53.33 = trunc i32 %xor72.53.33 to i8
  store i8 %conv73.53.33, i8* %arrayidx70.33, align 1
  %scevgep20.54.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 54
  %16977 = load i8, i8* %scevgep20.54.33, align 1
  %conv68.54.33 = zext i8 %16977 to i32
  %16978 = load i8, i8* %arrayidx70.33, align 1
  %conv71.54.33 = zext i8 %16978 to i32
  %xor72.54.33 = xor i32 %conv71.54.33, %conv68.54.33
  %conv73.54.33 = trunc i32 %xor72.54.33 to i8
  store i8 %conv73.54.33, i8* %arrayidx70.33, align 1
  %scevgep20.55.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 55
  %16979 = load i8, i8* %scevgep20.55.33, align 1
  %conv68.55.33 = zext i8 %16979 to i32
  %16980 = load i8, i8* %arrayidx70.33, align 1
  %conv71.55.33 = zext i8 %16980 to i32
  %xor72.55.33 = xor i32 %conv71.55.33, %conv68.55.33
  %conv73.55.33 = trunc i32 %xor72.55.33 to i8
  store i8 %conv73.55.33, i8* %arrayidx70.33, align 1
  %scevgep20.56.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 56
  %16981 = load i8, i8* %scevgep20.56.33, align 1
  %conv68.56.33 = zext i8 %16981 to i32
  %16982 = load i8, i8* %arrayidx70.33, align 1
  %conv71.56.33 = zext i8 %16982 to i32
  %xor72.56.33 = xor i32 %conv71.56.33, %conv68.56.33
  %conv73.56.33 = trunc i32 %xor72.56.33 to i8
  store i8 %conv73.56.33, i8* %arrayidx70.33, align 1
  %scevgep20.57.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 57
  %16983 = load i8, i8* %scevgep20.57.33, align 1
  %conv68.57.33 = zext i8 %16983 to i32
  %16984 = load i8, i8* %arrayidx70.33, align 1
  %conv71.57.33 = zext i8 %16984 to i32
  %xor72.57.33 = xor i32 %conv71.57.33, %conv68.57.33
  %conv73.57.33 = trunc i32 %xor72.57.33 to i8
  store i8 %conv73.57.33, i8* %arrayidx70.33, align 1
  %scevgep20.58.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 58
  %16985 = load i8, i8* %scevgep20.58.33, align 1
  %conv68.58.33 = zext i8 %16985 to i32
  %16986 = load i8, i8* %arrayidx70.33, align 1
  %conv71.58.33 = zext i8 %16986 to i32
  %xor72.58.33 = xor i32 %conv71.58.33, %conv68.58.33
  %conv73.58.33 = trunc i32 %xor72.58.33 to i8
  store i8 %conv73.58.33, i8* %arrayidx70.33, align 1
  %scevgep20.59.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 59
  %16987 = load i8, i8* %scevgep20.59.33, align 1
  %conv68.59.33 = zext i8 %16987 to i32
  %16988 = load i8, i8* %arrayidx70.33, align 1
  %conv71.59.33 = zext i8 %16988 to i32
  %xor72.59.33 = xor i32 %conv71.59.33, %conv68.59.33
  %conv73.59.33 = trunc i32 %xor72.59.33 to i8
  store i8 %conv73.59.33, i8* %arrayidx70.33, align 1
  %scevgep20.60.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 0, i64 60
  %16989 = load i8, i8* %scevgep20.60.33, align 1
  %conv68.60.33 = zext i8 %16989 to i32
  %16990 = load i8, i8* %arrayidx70.33, align 1
  %conv71.60.33 = zext i8 %16990 to i32
  %xor72.60.33 = xor i32 %conv71.60.33, %conv68.60.33
  %conv73.60.33 = trunc i32 %xor72.60.33 to i8
  store i8 %conv73.60.33, i8* %arrayidx70.33, align 1
  %scevgep19.33 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16868, i64 0, i64 1, i64 0
  %16991 = bitcast i8* %scevgep19.33 to [61 x [61 x i8]]*
  %arrayidx51.34 = getelementptr inbounds i8, i8* %a, i64 34
  %16992 = load i8, i8* %arrayidx51.34, align 1
  %arrayidx53.34 = getelementptr inbounds i8, i8* %b, i64 34
  %16993 = load i8, i8* %arrayidx53.34, align 1
  %call54.34 = call zeroext i8 @mult(i8 zeroext %16992, i8 zeroext %16993)
  %arrayidx56.34 = getelementptr inbounds i8, i8* %c, i64 34
  store i8 %call54.34, i8* %arrayidx56.34, align 1
  %arrayidx70.34 = getelementptr inbounds i8, i8* %c, i64 34
  %scevgep20.34384 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 0
  %16994 = load i8, i8* %scevgep20.34384, align 1
  %conv68.34385 = zext i8 %16994 to i32
  %16995 = load i8, i8* %arrayidx70.34, align 1
  %conv71.34386 = zext i8 %16995 to i32
  %xor72.34387 = xor i32 %conv71.34386, %conv68.34385
  %conv73.34388 = trunc i32 %xor72.34387 to i8
  store i8 %conv73.34388, i8* %arrayidx70.34, align 1
  %scevgep20.1.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 1
  %16996 = load i8, i8* %scevgep20.1.34, align 1
  %conv68.1.34 = zext i8 %16996 to i32
  %16997 = load i8, i8* %arrayidx70.34, align 1
  %conv71.1.34 = zext i8 %16997 to i32
  %xor72.1.34 = xor i32 %conv71.1.34, %conv68.1.34
  %conv73.1.34 = trunc i32 %xor72.1.34 to i8
  store i8 %conv73.1.34, i8* %arrayidx70.34, align 1
  %scevgep20.2.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 2
  %16998 = load i8, i8* %scevgep20.2.34, align 1
  %conv68.2.34 = zext i8 %16998 to i32
  %16999 = load i8, i8* %arrayidx70.34, align 1
  %conv71.2.34 = zext i8 %16999 to i32
  %xor72.2.34 = xor i32 %conv71.2.34, %conv68.2.34
  %conv73.2.34 = trunc i32 %xor72.2.34 to i8
  store i8 %conv73.2.34, i8* %arrayidx70.34, align 1
  %scevgep20.3.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 3
  %17000 = load i8, i8* %scevgep20.3.34, align 1
  %conv68.3.34 = zext i8 %17000 to i32
  %17001 = load i8, i8* %arrayidx70.34, align 1
  %conv71.3.34 = zext i8 %17001 to i32
  %xor72.3.34 = xor i32 %conv71.3.34, %conv68.3.34
  %conv73.3.34 = trunc i32 %xor72.3.34 to i8
  store i8 %conv73.3.34, i8* %arrayidx70.34, align 1
  %scevgep20.4.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 4
  %17002 = load i8, i8* %scevgep20.4.34, align 1
  %conv68.4.34 = zext i8 %17002 to i32
  %17003 = load i8, i8* %arrayidx70.34, align 1
  %conv71.4.34 = zext i8 %17003 to i32
  %xor72.4.34 = xor i32 %conv71.4.34, %conv68.4.34
  %conv73.4.34 = trunc i32 %xor72.4.34 to i8
  store i8 %conv73.4.34, i8* %arrayidx70.34, align 1
  %scevgep20.5.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 5
  %17004 = load i8, i8* %scevgep20.5.34, align 1
  %conv68.5.34 = zext i8 %17004 to i32
  %17005 = load i8, i8* %arrayidx70.34, align 1
  %conv71.5.34 = zext i8 %17005 to i32
  %xor72.5.34 = xor i32 %conv71.5.34, %conv68.5.34
  %conv73.5.34 = trunc i32 %xor72.5.34 to i8
  store i8 %conv73.5.34, i8* %arrayidx70.34, align 1
  %scevgep20.6.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 6
  %17006 = load i8, i8* %scevgep20.6.34, align 1
  %conv68.6.34 = zext i8 %17006 to i32
  %17007 = load i8, i8* %arrayidx70.34, align 1
  %conv71.6.34 = zext i8 %17007 to i32
  %xor72.6.34 = xor i32 %conv71.6.34, %conv68.6.34
  %conv73.6.34 = trunc i32 %xor72.6.34 to i8
  store i8 %conv73.6.34, i8* %arrayidx70.34, align 1
  %scevgep20.7.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 7
  %17008 = load i8, i8* %scevgep20.7.34, align 1
  %conv68.7.34 = zext i8 %17008 to i32
  %17009 = load i8, i8* %arrayidx70.34, align 1
  %conv71.7.34 = zext i8 %17009 to i32
  %xor72.7.34 = xor i32 %conv71.7.34, %conv68.7.34
  %conv73.7.34 = trunc i32 %xor72.7.34 to i8
  store i8 %conv73.7.34, i8* %arrayidx70.34, align 1
  %scevgep20.8.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 8
  %17010 = load i8, i8* %scevgep20.8.34, align 1
  %conv68.8.34 = zext i8 %17010 to i32
  %17011 = load i8, i8* %arrayidx70.34, align 1
  %conv71.8.34 = zext i8 %17011 to i32
  %xor72.8.34 = xor i32 %conv71.8.34, %conv68.8.34
  %conv73.8.34 = trunc i32 %xor72.8.34 to i8
  store i8 %conv73.8.34, i8* %arrayidx70.34, align 1
  %scevgep20.9.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 9
  %17012 = load i8, i8* %scevgep20.9.34, align 1
  %conv68.9.34 = zext i8 %17012 to i32
  %17013 = load i8, i8* %arrayidx70.34, align 1
  %conv71.9.34 = zext i8 %17013 to i32
  %xor72.9.34 = xor i32 %conv71.9.34, %conv68.9.34
  %conv73.9.34 = trunc i32 %xor72.9.34 to i8
  store i8 %conv73.9.34, i8* %arrayidx70.34, align 1
  %scevgep20.10.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 10
  %17014 = load i8, i8* %scevgep20.10.34, align 1
  %conv68.10.34 = zext i8 %17014 to i32
  %17015 = load i8, i8* %arrayidx70.34, align 1
  %conv71.10.34 = zext i8 %17015 to i32
  %xor72.10.34 = xor i32 %conv71.10.34, %conv68.10.34
  %conv73.10.34 = trunc i32 %xor72.10.34 to i8
  store i8 %conv73.10.34, i8* %arrayidx70.34, align 1
  %scevgep20.11.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 11
  %17016 = load i8, i8* %scevgep20.11.34, align 1
  %conv68.11.34 = zext i8 %17016 to i32
  %17017 = load i8, i8* %arrayidx70.34, align 1
  %conv71.11.34 = zext i8 %17017 to i32
  %xor72.11.34 = xor i32 %conv71.11.34, %conv68.11.34
  %conv73.11.34 = trunc i32 %xor72.11.34 to i8
  store i8 %conv73.11.34, i8* %arrayidx70.34, align 1
  %scevgep20.12.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 12
  %17018 = load i8, i8* %scevgep20.12.34, align 1
  %conv68.12.34 = zext i8 %17018 to i32
  %17019 = load i8, i8* %arrayidx70.34, align 1
  %conv71.12.34 = zext i8 %17019 to i32
  %xor72.12.34 = xor i32 %conv71.12.34, %conv68.12.34
  %conv73.12.34 = trunc i32 %xor72.12.34 to i8
  store i8 %conv73.12.34, i8* %arrayidx70.34, align 1
  %scevgep20.13.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 13
  %17020 = load i8, i8* %scevgep20.13.34, align 1
  %conv68.13.34 = zext i8 %17020 to i32
  %17021 = load i8, i8* %arrayidx70.34, align 1
  %conv71.13.34 = zext i8 %17021 to i32
  %xor72.13.34 = xor i32 %conv71.13.34, %conv68.13.34
  %conv73.13.34 = trunc i32 %xor72.13.34 to i8
  store i8 %conv73.13.34, i8* %arrayidx70.34, align 1
  %scevgep20.14.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 14
  %17022 = load i8, i8* %scevgep20.14.34, align 1
  %conv68.14.34 = zext i8 %17022 to i32
  %17023 = load i8, i8* %arrayidx70.34, align 1
  %conv71.14.34 = zext i8 %17023 to i32
  %xor72.14.34 = xor i32 %conv71.14.34, %conv68.14.34
  %conv73.14.34 = trunc i32 %xor72.14.34 to i8
  store i8 %conv73.14.34, i8* %arrayidx70.34, align 1
  %scevgep20.15.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 15
  %17024 = load i8, i8* %scevgep20.15.34, align 1
  %conv68.15.34 = zext i8 %17024 to i32
  %17025 = load i8, i8* %arrayidx70.34, align 1
  %conv71.15.34 = zext i8 %17025 to i32
  %xor72.15.34 = xor i32 %conv71.15.34, %conv68.15.34
  %conv73.15.34 = trunc i32 %xor72.15.34 to i8
  store i8 %conv73.15.34, i8* %arrayidx70.34, align 1
  %scevgep20.16.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 16
  %17026 = load i8, i8* %scevgep20.16.34, align 1
  %conv68.16.34 = zext i8 %17026 to i32
  %17027 = load i8, i8* %arrayidx70.34, align 1
  %conv71.16.34 = zext i8 %17027 to i32
  %xor72.16.34 = xor i32 %conv71.16.34, %conv68.16.34
  %conv73.16.34 = trunc i32 %xor72.16.34 to i8
  store i8 %conv73.16.34, i8* %arrayidx70.34, align 1
  %scevgep20.17.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 17
  %17028 = load i8, i8* %scevgep20.17.34, align 1
  %conv68.17.34 = zext i8 %17028 to i32
  %17029 = load i8, i8* %arrayidx70.34, align 1
  %conv71.17.34 = zext i8 %17029 to i32
  %xor72.17.34 = xor i32 %conv71.17.34, %conv68.17.34
  %conv73.17.34 = trunc i32 %xor72.17.34 to i8
  store i8 %conv73.17.34, i8* %arrayidx70.34, align 1
  %scevgep20.18.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 18
  %17030 = load i8, i8* %scevgep20.18.34, align 1
  %conv68.18.34 = zext i8 %17030 to i32
  %17031 = load i8, i8* %arrayidx70.34, align 1
  %conv71.18.34 = zext i8 %17031 to i32
  %xor72.18.34 = xor i32 %conv71.18.34, %conv68.18.34
  %conv73.18.34 = trunc i32 %xor72.18.34 to i8
  store i8 %conv73.18.34, i8* %arrayidx70.34, align 1
  %scevgep20.19.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 19
  %17032 = load i8, i8* %scevgep20.19.34, align 1
  %conv68.19.34 = zext i8 %17032 to i32
  %17033 = load i8, i8* %arrayidx70.34, align 1
  %conv71.19.34 = zext i8 %17033 to i32
  %xor72.19.34 = xor i32 %conv71.19.34, %conv68.19.34
  %conv73.19.34 = trunc i32 %xor72.19.34 to i8
  store i8 %conv73.19.34, i8* %arrayidx70.34, align 1
  %scevgep20.20.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 20
  %17034 = load i8, i8* %scevgep20.20.34, align 1
  %conv68.20.34 = zext i8 %17034 to i32
  %17035 = load i8, i8* %arrayidx70.34, align 1
  %conv71.20.34 = zext i8 %17035 to i32
  %xor72.20.34 = xor i32 %conv71.20.34, %conv68.20.34
  %conv73.20.34 = trunc i32 %xor72.20.34 to i8
  store i8 %conv73.20.34, i8* %arrayidx70.34, align 1
  %scevgep20.21.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 21
  %17036 = load i8, i8* %scevgep20.21.34, align 1
  %conv68.21.34 = zext i8 %17036 to i32
  %17037 = load i8, i8* %arrayidx70.34, align 1
  %conv71.21.34 = zext i8 %17037 to i32
  %xor72.21.34 = xor i32 %conv71.21.34, %conv68.21.34
  %conv73.21.34 = trunc i32 %xor72.21.34 to i8
  store i8 %conv73.21.34, i8* %arrayidx70.34, align 1
  %scevgep20.22.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 22
  %17038 = load i8, i8* %scevgep20.22.34, align 1
  %conv68.22.34 = zext i8 %17038 to i32
  %17039 = load i8, i8* %arrayidx70.34, align 1
  %conv71.22.34 = zext i8 %17039 to i32
  %xor72.22.34 = xor i32 %conv71.22.34, %conv68.22.34
  %conv73.22.34 = trunc i32 %xor72.22.34 to i8
  store i8 %conv73.22.34, i8* %arrayidx70.34, align 1
  %scevgep20.23.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 23
  %17040 = load i8, i8* %scevgep20.23.34, align 1
  %conv68.23.34 = zext i8 %17040 to i32
  %17041 = load i8, i8* %arrayidx70.34, align 1
  %conv71.23.34 = zext i8 %17041 to i32
  %xor72.23.34 = xor i32 %conv71.23.34, %conv68.23.34
  %conv73.23.34 = trunc i32 %xor72.23.34 to i8
  store i8 %conv73.23.34, i8* %arrayidx70.34, align 1
  %scevgep20.24.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 24
  %17042 = load i8, i8* %scevgep20.24.34, align 1
  %conv68.24.34 = zext i8 %17042 to i32
  %17043 = load i8, i8* %arrayidx70.34, align 1
  %conv71.24.34 = zext i8 %17043 to i32
  %xor72.24.34 = xor i32 %conv71.24.34, %conv68.24.34
  %conv73.24.34 = trunc i32 %xor72.24.34 to i8
  store i8 %conv73.24.34, i8* %arrayidx70.34, align 1
  %scevgep20.25.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 25
  %17044 = load i8, i8* %scevgep20.25.34, align 1
  %conv68.25.34 = zext i8 %17044 to i32
  %17045 = load i8, i8* %arrayidx70.34, align 1
  %conv71.25.34 = zext i8 %17045 to i32
  %xor72.25.34 = xor i32 %conv71.25.34, %conv68.25.34
  %conv73.25.34 = trunc i32 %xor72.25.34 to i8
  store i8 %conv73.25.34, i8* %arrayidx70.34, align 1
  %scevgep20.26.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 26
  %17046 = load i8, i8* %scevgep20.26.34, align 1
  %conv68.26.34 = zext i8 %17046 to i32
  %17047 = load i8, i8* %arrayidx70.34, align 1
  %conv71.26.34 = zext i8 %17047 to i32
  %xor72.26.34 = xor i32 %conv71.26.34, %conv68.26.34
  %conv73.26.34 = trunc i32 %xor72.26.34 to i8
  store i8 %conv73.26.34, i8* %arrayidx70.34, align 1
  %scevgep20.27.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 27
  %17048 = load i8, i8* %scevgep20.27.34, align 1
  %conv68.27.34 = zext i8 %17048 to i32
  %17049 = load i8, i8* %arrayidx70.34, align 1
  %conv71.27.34 = zext i8 %17049 to i32
  %xor72.27.34 = xor i32 %conv71.27.34, %conv68.27.34
  %conv73.27.34 = trunc i32 %xor72.27.34 to i8
  store i8 %conv73.27.34, i8* %arrayidx70.34, align 1
  %scevgep20.28.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 28
  %17050 = load i8, i8* %scevgep20.28.34, align 1
  %conv68.28.34 = zext i8 %17050 to i32
  %17051 = load i8, i8* %arrayidx70.34, align 1
  %conv71.28.34 = zext i8 %17051 to i32
  %xor72.28.34 = xor i32 %conv71.28.34, %conv68.28.34
  %conv73.28.34 = trunc i32 %xor72.28.34 to i8
  store i8 %conv73.28.34, i8* %arrayidx70.34, align 1
  %scevgep20.29.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 29
  %17052 = load i8, i8* %scevgep20.29.34, align 1
  %conv68.29.34 = zext i8 %17052 to i32
  %17053 = load i8, i8* %arrayidx70.34, align 1
  %conv71.29.34 = zext i8 %17053 to i32
  %xor72.29.34 = xor i32 %conv71.29.34, %conv68.29.34
  %conv73.29.34 = trunc i32 %xor72.29.34 to i8
  store i8 %conv73.29.34, i8* %arrayidx70.34, align 1
  %scevgep20.30.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 30
  %17054 = load i8, i8* %scevgep20.30.34, align 1
  %conv68.30.34 = zext i8 %17054 to i32
  %17055 = load i8, i8* %arrayidx70.34, align 1
  %conv71.30.34 = zext i8 %17055 to i32
  %xor72.30.34 = xor i32 %conv71.30.34, %conv68.30.34
  %conv73.30.34 = trunc i32 %xor72.30.34 to i8
  store i8 %conv73.30.34, i8* %arrayidx70.34, align 1
  %scevgep20.31.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 31
  %17056 = load i8, i8* %scevgep20.31.34, align 1
  %conv68.31.34 = zext i8 %17056 to i32
  %17057 = load i8, i8* %arrayidx70.34, align 1
  %conv71.31.34 = zext i8 %17057 to i32
  %xor72.31.34 = xor i32 %conv71.31.34, %conv68.31.34
  %conv73.31.34 = trunc i32 %xor72.31.34 to i8
  store i8 %conv73.31.34, i8* %arrayidx70.34, align 1
  %scevgep20.32.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 32
  %17058 = load i8, i8* %scevgep20.32.34, align 1
  %conv68.32.34 = zext i8 %17058 to i32
  %17059 = load i8, i8* %arrayidx70.34, align 1
  %conv71.32.34 = zext i8 %17059 to i32
  %xor72.32.34 = xor i32 %conv71.32.34, %conv68.32.34
  %conv73.32.34 = trunc i32 %xor72.32.34 to i8
  store i8 %conv73.32.34, i8* %arrayidx70.34, align 1
  %scevgep20.33.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 33
  %17060 = load i8, i8* %scevgep20.33.34, align 1
  %conv68.33.34 = zext i8 %17060 to i32
  %17061 = load i8, i8* %arrayidx70.34, align 1
  %conv71.33.34 = zext i8 %17061 to i32
  %xor72.33.34 = xor i32 %conv71.33.34, %conv68.33.34
  %conv73.33.34 = trunc i32 %xor72.33.34 to i8
  store i8 %conv73.33.34, i8* %arrayidx70.34, align 1
  %scevgep20.35.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 35
  %17062 = load i8, i8* %scevgep20.35.34, align 1
  %conv68.35.34 = zext i8 %17062 to i32
  %17063 = load i8, i8* %arrayidx70.34, align 1
  %conv71.35.34 = zext i8 %17063 to i32
  %xor72.35.34 = xor i32 %conv71.35.34, %conv68.35.34
  %conv73.35.34 = trunc i32 %xor72.35.34 to i8
  store i8 %conv73.35.34, i8* %arrayidx70.34, align 1
  %scevgep20.36.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 36
  %17064 = load i8, i8* %scevgep20.36.34, align 1
  %conv68.36.34 = zext i8 %17064 to i32
  %17065 = load i8, i8* %arrayidx70.34, align 1
  %conv71.36.34 = zext i8 %17065 to i32
  %xor72.36.34 = xor i32 %conv71.36.34, %conv68.36.34
  %conv73.36.34 = trunc i32 %xor72.36.34 to i8
  store i8 %conv73.36.34, i8* %arrayidx70.34, align 1
  %scevgep20.37.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 37
  %17066 = load i8, i8* %scevgep20.37.34, align 1
  %conv68.37.34 = zext i8 %17066 to i32
  %17067 = load i8, i8* %arrayidx70.34, align 1
  %conv71.37.34 = zext i8 %17067 to i32
  %xor72.37.34 = xor i32 %conv71.37.34, %conv68.37.34
  %conv73.37.34 = trunc i32 %xor72.37.34 to i8
  store i8 %conv73.37.34, i8* %arrayidx70.34, align 1
  %scevgep20.38.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 38
  %17068 = load i8, i8* %scevgep20.38.34, align 1
  %conv68.38.34 = zext i8 %17068 to i32
  %17069 = load i8, i8* %arrayidx70.34, align 1
  %conv71.38.34 = zext i8 %17069 to i32
  %xor72.38.34 = xor i32 %conv71.38.34, %conv68.38.34
  %conv73.38.34 = trunc i32 %xor72.38.34 to i8
  store i8 %conv73.38.34, i8* %arrayidx70.34, align 1
  %scevgep20.39.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 39
  %17070 = load i8, i8* %scevgep20.39.34, align 1
  %conv68.39.34 = zext i8 %17070 to i32
  %17071 = load i8, i8* %arrayidx70.34, align 1
  %conv71.39.34 = zext i8 %17071 to i32
  %xor72.39.34 = xor i32 %conv71.39.34, %conv68.39.34
  %conv73.39.34 = trunc i32 %xor72.39.34 to i8
  store i8 %conv73.39.34, i8* %arrayidx70.34, align 1
  %scevgep20.40.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 40
  %17072 = load i8, i8* %scevgep20.40.34, align 1
  %conv68.40.34 = zext i8 %17072 to i32
  %17073 = load i8, i8* %arrayidx70.34, align 1
  %conv71.40.34 = zext i8 %17073 to i32
  %xor72.40.34 = xor i32 %conv71.40.34, %conv68.40.34
  %conv73.40.34 = trunc i32 %xor72.40.34 to i8
  store i8 %conv73.40.34, i8* %arrayidx70.34, align 1
  %scevgep20.41.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 41
  %17074 = load i8, i8* %scevgep20.41.34, align 1
  %conv68.41.34 = zext i8 %17074 to i32
  %17075 = load i8, i8* %arrayidx70.34, align 1
  %conv71.41.34 = zext i8 %17075 to i32
  %xor72.41.34 = xor i32 %conv71.41.34, %conv68.41.34
  %conv73.41.34 = trunc i32 %xor72.41.34 to i8
  store i8 %conv73.41.34, i8* %arrayidx70.34, align 1
  %scevgep20.42.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 42
  %17076 = load i8, i8* %scevgep20.42.34, align 1
  %conv68.42.34 = zext i8 %17076 to i32
  %17077 = load i8, i8* %arrayidx70.34, align 1
  %conv71.42.34 = zext i8 %17077 to i32
  %xor72.42.34 = xor i32 %conv71.42.34, %conv68.42.34
  %conv73.42.34 = trunc i32 %xor72.42.34 to i8
  store i8 %conv73.42.34, i8* %arrayidx70.34, align 1
  %scevgep20.43.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 43
  %17078 = load i8, i8* %scevgep20.43.34, align 1
  %conv68.43.34 = zext i8 %17078 to i32
  %17079 = load i8, i8* %arrayidx70.34, align 1
  %conv71.43.34 = zext i8 %17079 to i32
  %xor72.43.34 = xor i32 %conv71.43.34, %conv68.43.34
  %conv73.43.34 = trunc i32 %xor72.43.34 to i8
  store i8 %conv73.43.34, i8* %arrayidx70.34, align 1
  %scevgep20.44.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 44
  %17080 = load i8, i8* %scevgep20.44.34, align 1
  %conv68.44.34 = zext i8 %17080 to i32
  %17081 = load i8, i8* %arrayidx70.34, align 1
  %conv71.44.34 = zext i8 %17081 to i32
  %xor72.44.34 = xor i32 %conv71.44.34, %conv68.44.34
  %conv73.44.34 = trunc i32 %xor72.44.34 to i8
  store i8 %conv73.44.34, i8* %arrayidx70.34, align 1
  %scevgep20.45.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 45
  %17082 = load i8, i8* %scevgep20.45.34, align 1
  %conv68.45.34 = zext i8 %17082 to i32
  %17083 = load i8, i8* %arrayidx70.34, align 1
  %conv71.45.34 = zext i8 %17083 to i32
  %xor72.45.34 = xor i32 %conv71.45.34, %conv68.45.34
  %conv73.45.34 = trunc i32 %xor72.45.34 to i8
  store i8 %conv73.45.34, i8* %arrayidx70.34, align 1
  %scevgep20.46.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 46
  %17084 = load i8, i8* %scevgep20.46.34, align 1
  %conv68.46.34 = zext i8 %17084 to i32
  %17085 = load i8, i8* %arrayidx70.34, align 1
  %conv71.46.34 = zext i8 %17085 to i32
  %xor72.46.34 = xor i32 %conv71.46.34, %conv68.46.34
  %conv73.46.34 = trunc i32 %xor72.46.34 to i8
  store i8 %conv73.46.34, i8* %arrayidx70.34, align 1
  %scevgep20.47.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 47
  %17086 = load i8, i8* %scevgep20.47.34, align 1
  %conv68.47.34 = zext i8 %17086 to i32
  %17087 = load i8, i8* %arrayidx70.34, align 1
  %conv71.47.34 = zext i8 %17087 to i32
  %xor72.47.34 = xor i32 %conv71.47.34, %conv68.47.34
  %conv73.47.34 = trunc i32 %xor72.47.34 to i8
  store i8 %conv73.47.34, i8* %arrayidx70.34, align 1
  %scevgep20.48.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 48
  %17088 = load i8, i8* %scevgep20.48.34, align 1
  %conv68.48.34 = zext i8 %17088 to i32
  %17089 = load i8, i8* %arrayidx70.34, align 1
  %conv71.48.34 = zext i8 %17089 to i32
  %xor72.48.34 = xor i32 %conv71.48.34, %conv68.48.34
  %conv73.48.34 = trunc i32 %xor72.48.34 to i8
  store i8 %conv73.48.34, i8* %arrayidx70.34, align 1
  %scevgep20.49.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 49
  %17090 = load i8, i8* %scevgep20.49.34, align 1
  %conv68.49.34 = zext i8 %17090 to i32
  %17091 = load i8, i8* %arrayidx70.34, align 1
  %conv71.49.34 = zext i8 %17091 to i32
  %xor72.49.34 = xor i32 %conv71.49.34, %conv68.49.34
  %conv73.49.34 = trunc i32 %xor72.49.34 to i8
  store i8 %conv73.49.34, i8* %arrayidx70.34, align 1
  %scevgep20.50.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 50
  %17092 = load i8, i8* %scevgep20.50.34, align 1
  %conv68.50.34 = zext i8 %17092 to i32
  %17093 = load i8, i8* %arrayidx70.34, align 1
  %conv71.50.34 = zext i8 %17093 to i32
  %xor72.50.34 = xor i32 %conv71.50.34, %conv68.50.34
  %conv73.50.34 = trunc i32 %xor72.50.34 to i8
  store i8 %conv73.50.34, i8* %arrayidx70.34, align 1
  %scevgep20.51.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 51
  %17094 = load i8, i8* %scevgep20.51.34, align 1
  %conv68.51.34 = zext i8 %17094 to i32
  %17095 = load i8, i8* %arrayidx70.34, align 1
  %conv71.51.34 = zext i8 %17095 to i32
  %xor72.51.34 = xor i32 %conv71.51.34, %conv68.51.34
  %conv73.51.34 = trunc i32 %xor72.51.34 to i8
  store i8 %conv73.51.34, i8* %arrayidx70.34, align 1
  %scevgep20.52.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 52
  %17096 = load i8, i8* %scevgep20.52.34, align 1
  %conv68.52.34 = zext i8 %17096 to i32
  %17097 = load i8, i8* %arrayidx70.34, align 1
  %conv71.52.34 = zext i8 %17097 to i32
  %xor72.52.34 = xor i32 %conv71.52.34, %conv68.52.34
  %conv73.52.34 = trunc i32 %xor72.52.34 to i8
  store i8 %conv73.52.34, i8* %arrayidx70.34, align 1
  %scevgep20.53.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 53
  %17098 = load i8, i8* %scevgep20.53.34, align 1
  %conv68.53.34 = zext i8 %17098 to i32
  %17099 = load i8, i8* %arrayidx70.34, align 1
  %conv71.53.34 = zext i8 %17099 to i32
  %xor72.53.34 = xor i32 %conv71.53.34, %conv68.53.34
  %conv73.53.34 = trunc i32 %xor72.53.34 to i8
  store i8 %conv73.53.34, i8* %arrayidx70.34, align 1
  %scevgep20.54.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 54
  %17100 = load i8, i8* %scevgep20.54.34, align 1
  %conv68.54.34 = zext i8 %17100 to i32
  %17101 = load i8, i8* %arrayidx70.34, align 1
  %conv71.54.34 = zext i8 %17101 to i32
  %xor72.54.34 = xor i32 %conv71.54.34, %conv68.54.34
  %conv73.54.34 = trunc i32 %xor72.54.34 to i8
  store i8 %conv73.54.34, i8* %arrayidx70.34, align 1
  %scevgep20.55.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 55
  %17102 = load i8, i8* %scevgep20.55.34, align 1
  %conv68.55.34 = zext i8 %17102 to i32
  %17103 = load i8, i8* %arrayidx70.34, align 1
  %conv71.55.34 = zext i8 %17103 to i32
  %xor72.55.34 = xor i32 %conv71.55.34, %conv68.55.34
  %conv73.55.34 = trunc i32 %xor72.55.34 to i8
  store i8 %conv73.55.34, i8* %arrayidx70.34, align 1
  %scevgep20.56.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 56
  %17104 = load i8, i8* %scevgep20.56.34, align 1
  %conv68.56.34 = zext i8 %17104 to i32
  %17105 = load i8, i8* %arrayidx70.34, align 1
  %conv71.56.34 = zext i8 %17105 to i32
  %xor72.56.34 = xor i32 %conv71.56.34, %conv68.56.34
  %conv73.56.34 = trunc i32 %xor72.56.34 to i8
  store i8 %conv73.56.34, i8* %arrayidx70.34, align 1
  %scevgep20.57.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 57
  %17106 = load i8, i8* %scevgep20.57.34, align 1
  %conv68.57.34 = zext i8 %17106 to i32
  %17107 = load i8, i8* %arrayidx70.34, align 1
  %conv71.57.34 = zext i8 %17107 to i32
  %xor72.57.34 = xor i32 %conv71.57.34, %conv68.57.34
  %conv73.57.34 = trunc i32 %xor72.57.34 to i8
  store i8 %conv73.57.34, i8* %arrayidx70.34, align 1
  %scevgep20.58.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 58
  %17108 = load i8, i8* %scevgep20.58.34, align 1
  %conv68.58.34 = zext i8 %17108 to i32
  %17109 = load i8, i8* %arrayidx70.34, align 1
  %conv71.58.34 = zext i8 %17109 to i32
  %xor72.58.34 = xor i32 %conv71.58.34, %conv68.58.34
  %conv73.58.34 = trunc i32 %xor72.58.34 to i8
  store i8 %conv73.58.34, i8* %arrayidx70.34, align 1
  %scevgep20.59.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 59
  %17110 = load i8, i8* %scevgep20.59.34, align 1
  %conv68.59.34 = zext i8 %17110 to i32
  %17111 = load i8, i8* %arrayidx70.34, align 1
  %conv71.59.34 = zext i8 %17111 to i32
  %xor72.59.34 = xor i32 %conv71.59.34, %conv68.59.34
  %conv73.59.34 = trunc i32 %xor72.59.34 to i8
  store i8 %conv73.59.34, i8* %arrayidx70.34, align 1
  %scevgep20.60.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 0, i64 60
  %17112 = load i8, i8* %scevgep20.60.34, align 1
  %conv68.60.34 = zext i8 %17112 to i32
  %17113 = load i8, i8* %arrayidx70.34, align 1
  %conv71.60.34 = zext i8 %17113 to i32
  %xor72.60.34 = xor i32 %conv71.60.34, %conv68.60.34
  %conv73.60.34 = trunc i32 %xor72.60.34 to i8
  store i8 %conv73.60.34, i8* %arrayidx70.34, align 1
  %scevgep19.34 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %16991, i64 0, i64 1, i64 0
  %17114 = bitcast i8* %scevgep19.34 to [61 x [61 x i8]]*
  %arrayidx51.35 = getelementptr inbounds i8, i8* %a, i64 35
  %17115 = load i8, i8* %arrayidx51.35, align 1
  %arrayidx53.35 = getelementptr inbounds i8, i8* %b, i64 35
  %17116 = load i8, i8* %arrayidx53.35, align 1
  %call54.35 = call zeroext i8 @mult(i8 zeroext %17115, i8 zeroext %17116)
  %arrayidx56.35 = getelementptr inbounds i8, i8* %c, i64 35
  store i8 %call54.35, i8* %arrayidx56.35, align 1
  %arrayidx70.35 = getelementptr inbounds i8, i8* %c, i64 35
  %scevgep20.35394 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 0
  %17117 = load i8, i8* %scevgep20.35394, align 1
  %conv68.35395 = zext i8 %17117 to i32
  %17118 = load i8, i8* %arrayidx70.35, align 1
  %conv71.35396 = zext i8 %17118 to i32
  %xor72.35397 = xor i32 %conv71.35396, %conv68.35395
  %conv73.35398 = trunc i32 %xor72.35397 to i8
  store i8 %conv73.35398, i8* %arrayidx70.35, align 1
  %scevgep20.1.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 1
  %17119 = load i8, i8* %scevgep20.1.35, align 1
  %conv68.1.35 = zext i8 %17119 to i32
  %17120 = load i8, i8* %arrayidx70.35, align 1
  %conv71.1.35 = zext i8 %17120 to i32
  %xor72.1.35 = xor i32 %conv71.1.35, %conv68.1.35
  %conv73.1.35 = trunc i32 %xor72.1.35 to i8
  store i8 %conv73.1.35, i8* %arrayidx70.35, align 1
  %scevgep20.2.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 2
  %17121 = load i8, i8* %scevgep20.2.35, align 1
  %conv68.2.35 = zext i8 %17121 to i32
  %17122 = load i8, i8* %arrayidx70.35, align 1
  %conv71.2.35 = zext i8 %17122 to i32
  %xor72.2.35 = xor i32 %conv71.2.35, %conv68.2.35
  %conv73.2.35 = trunc i32 %xor72.2.35 to i8
  store i8 %conv73.2.35, i8* %arrayidx70.35, align 1
  %scevgep20.3.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 3
  %17123 = load i8, i8* %scevgep20.3.35, align 1
  %conv68.3.35 = zext i8 %17123 to i32
  %17124 = load i8, i8* %arrayidx70.35, align 1
  %conv71.3.35 = zext i8 %17124 to i32
  %xor72.3.35 = xor i32 %conv71.3.35, %conv68.3.35
  %conv73.3.35 = trunc i32 %xor72.3.35 to i8
  store i8 %conv73.3.35, i8* %arrayidx70.35, align 1
  %scevgep20.4.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 4
  %17125 = load i8, i8* %scevgep20.4.35, align 1
  %conv68.4.35 = zext i8 %17125 to i32
  %17126 = load i8, i8* %arrayidx70.35, align 1
  %conv71.4.35 = zext i8 %17126 to i32
  %xor72.4.35 = xor i32 %conv71.4.35, %conv68.4.35
  %conv73.4.35 = trunc i32 %xor72.4.35 to i8
  store i8 %conv73.4.35, i8* %arrayidx70.35, align 1
  %scevgep20.5.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 5
  %17127 = load i8, i8* %scevgep20.5.35, align 1
  %conv68.5.35 = zext i8 %17127 to i32
  %17128 = load i8, i8* %arrayidx70.35, align 1
  %conv71.5.35 = zext i8 %17128 to i32
  %xor72.5.35 = xor i32 %conv71.5.35, %conv68.5.35
  %conv73.5.35 = trunc i32 %xor72.5.35 to i8
  store i8 %conv73.5.35, i8* %arrayidx70.35, align 1
  %scevgep20.6.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 6
  %17129 = load i8, i8* %scevgep20.6.35, align 1
  %conv68.6.35 = zext i8 %17129 to i32
  %17130 = load i8, i8* %arrayidx70.35, align 1
  %conv71.6.35 = zext i8 %17130 to i32
  %xor72.6.35 = xor i32 %conv71.6.35, %conv68.6.35
  %conv73.6.35 = trunc i32 %xor72.6.35 to i8
  store i8 %conv73.6.35, i8* %arrayidx70.35, align 1
  %scevgep20.7.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 7
  %17131 = load i8, i8* %scevgep20.7.35, align 1
  %conv68.7.35 = zext i8 %17131 to i32
  %17132 = load i8, i8* %arrayidx70.35, align 1
  %conv71.7.35 = zext i8 %17132 to i32
  %xor72.7.35 = xor i32 %conv71.7.35, %conv68.7.35
  %conv73.7.35 = trunc i32 %xor72.7.35 to i8
  store i8 %conv73.7.35, i8* %arrayidx70.35, align 1
  %scevgep20.8.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 8
  %17133 = load i8, i8* %scevgep20.8.35, align 1
  %conv68.8.35 = zext i8 %17133 to i32
  %17134 = load i8, i8* %arrayidx70.35, align 1
  %conv71.8.35 = zext i8 %17134 to i32
  %xor72.8.35 = xor i32 %conv71.8.35, %conv68.8.35
  %conv73.8.35 = trunc i32 %xor72.8.35 to i8
  store i8 %conv73.8.35, i8* %arrayidx70.35, align 1
  %scevgep20.9.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 9
  %17135 = load i8, i8* %scevgep20.9.35, align 1
  %conv68.9.35 = zext i8 %17135 to i32
  %17136 = load i8, i8* %arrayidx70.35, align 1
  %conv71.9.35 = zext i8 %17136 to i32
  %xor72.9.35 = xor i32 %conv71.9.35, %conv68.9.35
  %conv73.9.35 = trunc i32 %xor72.9.35 to i8
  store i8 %conv73.9.35, i8* %arrayidx70.35, align 1
  %scevgep20.10.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 10
  %17137 = load i8, i8* %scevgep20.10.35, align 1
  %conv68.10.35 = zext i8 %17137 to i32
  %17138 = load i8, i8* %arrayidx70.35, align 1
  %conv71.10.35 = zext i8 %17138 to i32
  %xor72.10.35 = xor i32 %conv71.10.35, %conv68.10.35
  %conv73.10.35 = trunc i32 %xor72.10.35 to i8
  store i8 %conv73.10.35, i8* %arrayidx70.35, align 1
  %scevgep20.11.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 11
  %17139 = load i8, i8* %scevgep20.11.35, align 1
  %conv68.11.35 = zext i8 %17139 to i32
  %17140 = load i8, i8* %arrayidx70.35, align 1
  %conv71.11.35 = zext i8 %17140 to i32
  %xor72.11.35 = xor i32 %conv71.11.35, %conv68.11.35
  %conv73.11.35 = trunc i32 %xor72.11.35 to i8
  store i8 %conv73.11.35, i8* %arrayidx70.35, align 1
  %scevgep20.12.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 12
  %17141 = load i8, i8* %scevgep20.12.35, align 1
  %conv68.12.35 = zext i8 %17141 to i32
  %17142 = load i8, i8* %arrayidx70.35, align 1
  %conv71.12.35 = zext i8 %17142 to i32
  %xor72.12.35 = xor i32 %conv71.12.35, %conv68.12.35
  %conv73.12.35 = trunc i32 %xor72.12.35 to i8
  store i8 %conv73.12.35, i8* %arrayidx70.35, align 1
  %scevgep20.13.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 13
  %17143 = load i8, i8* %scevgep20.13.35, align 1
  %conv68.13.35 = zext i8 %17143 to i32
  %17144 = load i8, i8* %arrayidx70.35, align 1
  %conv71.13.35 = zext i8 %17144 to i32
  %xor72.13.35 = xor i32 %conv71.13.35, %conv68.13.35
  %conv73.13.35 = trunc i32 %xor72.13.35 to i8
  store i8 %conv73.13.35, i8* %arrayidx70.35, align 1
  %scevgep20.14.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 14
  %17145 = load i8, i8* %scevgep20.14.35, align 1
  %conv68.14.35 = zext i8 %17145 to i32
  %17146 = load i8, i8* %arrayidx70.35, align 1
  %conv71.14.35 = zext i8 %17146 to i32
  %xor72.14.35 = xor i32 %conv71.14.35, %conv68.14.35
  %conv73.14.35 = trunc i32 %xor72.14.35 to i8
  store i8 %conv73.14.35, i8* %arrayidx70.35, align 1
  %scevgep20.15.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 15
  %17147 = load i8, i8* %scevgep20.15.35, align 1
  %conv68.15.35 = zext i8 %17147 to i32
  %17148 = load i8, i8* %arrayidx70.35, align 1
  %conv71.15.35 = zext i8 %17148 to i32
  %xor72.15.35 = xor i32 %conv71.15.35, %conv68.15.35
  %conv73.15.35 = trunc i32 %xor72.15.35 to i8
  store i8 %conv73.15.35, i8* %arrayidx70.35, align 1
  %scevgep20.16.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 16
  %17149 = load i8, i8* %scevgep20.16.35, align 1
  %conv68.16.35 = zext i8 %17149 to i32
  %17150 = load i8, i8* %arrayidx70.35, align 1
  %conv71.16.35 = zext i8 %17150 to i32
  %xor72.16.35 = xor i32 %conv71.16.35, %conv68.16.35
  %conv73.16.35 = trunc i32 %xor72.16.35 to i8
  store i8 %conv73.16.35, i8* %arrayidx70.35, align 1
  %scevgep20.17.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 17
  %17151 = load i8, i8* %scevgep20.17.35, align 1
  %conv68.17.35 = zext i8 %17151 to i32
  %17152 = load i8, i8* %arrayidx70.35, align 1
  %conv71.17.35 = zext i8 %17152 to i32
  %xor72.17.35 = xor i32 %conv71.17.35, %conv68.17.35
  %conv73.17.35 = trunc i32 %xor72.17.35 to i8
  store i8 %conv73.17.35, i8* %arrayidx70.35, align 1
  %scevgep20.18.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 18
  %17153 = load i8, i8* %scevgep20.18.35, align 1
  %conv68.18.35 = zext i8 %17153 to i32
  %17154 = load i8, i8* %arrayidx70.35, align 1
  %conv71.18.35 = zext i8 %17154 to i32
  %xor72.18.35 = xor i32 %conv71.18.35, %conv68.18.35
  %conv73.18.35 = trunc i32 %xor72.18.35 to i8
  store i8 %conv73.18.35, i8* %arrayidx70.35, align 1
  %scevgep20.19.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 19
  %17155 = load i8, i8* %scevgep20.19.35, align 1
  %conv68.19.35 = zext i8 %17155 to i32
  %17156 = load i8, i8* %arrayidx70.35, align 1
  %conv71.19.35 = zext i8 %17156 to i32
  %xor72.19.35 = xor i32 %conv71.19.35, %conv68.19.35
  %conv73.19.35 = trunc i32 %xor72.19.35 to i8
  store i8 %conv73.19.35, i8* %arrayidx70.35, align 1
  %scevgep20.20.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 20
  %17157 = load i8, i8* %scevgep20.20.35, align 1
  %conv68.20.35 = zext i8 %17157 to i32
  %17158 = load i8, i8* %arrayidx70.35, align 1
  %conv71.20.35 = zext i8 %17158 to i32
  %xor72.20.35 = xor i32 %conv71.20.35, %conv68.20.35
  %conv73.20.35 = trunc i32 %xor72.20.35 to i8
  store i8 %conv73.20.35, i8* %arrayidx70.35, align 1
  %scevgep20.21.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 21
  %17159 = load i8, i8* %scevgep20.21.35, align 1
  %conv68.21.35 = zext i8 %17159 to i32
  %17160 = load i8, i8* %arrayidx70.35, align 1
  %conv71.21.35 = zext i8 %17160 to i32
  %xor72.21.35 = xor i32 %conv71.21.35, %conv68.21.35
  %conv73.21.35 = trunc i32 %xor72.21.35 to i8
  store i8 %conv73.21.35, i8* %arrayidx70.35, align 1
  %scevgep20.22.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 22
  %17161 = load i8, i8* %scevgep20.22.35, align 1
  %conv68.22.35 = zext i8 %17161 to i32
  %17162 = load i8, i8* %arrayidx70.35, align 1
  %conv71.22.35 = zext i8 %17162 to i32
  %xor72.22.35 = xor i32 %conv71.22.35, %conv68.22.35
  %conv73.22.35 = trunc i32 %xor72.22.35 to i8
  store i8 %conv73.22.35, i8* %arrayidx70.35, align 1
  %scevgep20.23.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 23
  %17163 = load i8, i8* %scevgep20.23.35, align 1
  %conv68.23.35 = zext i8 %17163 to i32
  %17164 = load i8, i8* %arrayidx70.35, align 1
  %conv71.23.35 = zext i8 %17164 to i32
  %xor72.23.35 = xor i32 %conv71.23.35, %conv68.23.35
  %conv73.23.35 = trunc i32 %xor72.23.35 to i8
  store i8 %conv73.23.35, i8* %arrayidx70.35, align 1
  %scevgep20.24.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 24
  %17165 = load i8, i8* %scevgep20.24.35, align 1
  %conv68.24.35 = zext i8 %17165 to i32
  %17166 = load i8, i8* %arrayidx70.35, align 1
  %conv71.24.35 = zext i8 %17166 to i32
  %xor72.24.35 = xor i32 %conv71.24.35, %conv68.24.35
  %conv73.24.35 = trunc i32 %xor72.24.35 to i8
  store i8 %conv73.24.35, i8* %arrayidx70.35, align 1
  %scevgep20.25.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 25
  %17167 = load i8, i8* %scevgep20.25.35, align 1
  %conv68.25.35 = zext i8 %17167 to i32
  %17168 = load i8, i8* %arrayidx70.35, align 1
  %conv71.25.35 = zext i8 %17168 to i32
  %xor72.25.35 = xor i32 %conv71.25.35, %conv68.25.35
  %conv73.25.35 = trunc i32 %xor72.25.35 to i8
  store i8 %conv73.25.35, i8* %arrayidx70.35, align 1
  %scevgep20.26.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 26
  %17169 = load i8, i8* %scevgep20.26.35, align 1
  %conv68.26.35 = zext i8 %17169 to i32
  %17170 = load i8, i8* %arrayidx70.35, align 1
  %conv71.26.35 = zext i8 %17170 to i32
  %xor72.26.35 = xor i32 %conv71.26.35, %conv68.26.35
  %conv73.26.35 = trunc i32 %xor72.26.35 to i8
  store i8 %conv73.26.35, i8* %arrayidx70.35, align 1
  %scevgep20.27.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 27
  %17171 = load i8, i8* %scevgep20.27.35, align 1
  %conv68.27.35 = zext i8 %17171 to i32
  %17172 = load i8, i8* %arrayidx70.35, align 1
  %conv71.27.35 = zext i8 %17172 to i32
  %xor72.27.35 = xor i32 %conv71.27.35, %conv68.27.35
  %conv73.27.35 = trunc i32 %xor72.27.35 to i8
  store i8 %conv73.27.35, i8* %arrayidx70.35, align 1
  %scevgep20.28.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 28
  %17173 = load i8, i8* %scevgep20.28.35, align 1
  %conv68.28.35 = zext i8 %17173 to i32
  %17174 = load i8, i8* %arrayidx70.35, align 1
  %conv71.28.35 = zext i8 %17174 to i32
  %xor72.28.35 = xor i32 %conv71.28.35, %conv68.28.35
  %conv73.28.35 = trunc i32 %xor72.28.35 to i8
  store i8 %conv73.28.35, i8* %arrayidx70.35, align 1
  %scevgep20.29.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 29
  %17175 = load i8, i8* %scevgep20.29.35, align 1
  %conv68.29.35 = zext i8 %17175 to i32
  %17176 = load i8, i8* %arrayidx70.35, align 1
  %conv71.29.35 = zext i8 %17176 to i32
  %xor72.29.35 = xor i32 %conv71.29.35, %conv68.29.35
  %conv73.29.35 = trunc i32 %xor72.29.35 to i8
  store i8 %conv73.29.35, i8* %arrayidx70.35, align 1
  %scevgep20.30.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 30
  %17177 = load i8, i8* %scevgep20.30.35, align 1
  %conv68.30.35 = zext i8 %17177 to i32
  %17178 = load i8, i8* %arrayidx70.35, align 1
  %conv71.30.35 = zext i8 %17178 to i32
  %xor72.30.35 = xor i32 %conv71.30.35, %conv68.30.35
  %conv73.30.35 = trunc i32 %xor72.30.35 to i8
  store i8 %conv73.30.35, i8* %arrayidx70.35, align 1
  %scevgep20.31.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 31
  %17179 = load i8, i8* %scevgep20.31.35, align 1
  %conv68.31.35 = zext i8 %17179 to i32
  %17180 = load i8, i8* %arrayidx70.35, align 1
  %conv71.31.35 = zext i8 %17180 to i32
  %xor72.31.35 = xor i32 %conv71.31.35, %conv68.31.35
  %conv73.31.35 = trunc i32 %xor72.31.35 to i8
  store i8 %conv73.31.35, i8* %arrayidx70.35, align 1
  %scevgep20.32.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 32
  %17181 = load i8, i8* %scevgep20.32.35, align 1
  %conv68.32.35 = zext i8 %17181 to i32
  %17182 = load i8, i8* %arrayidx70.35, align 1
  %conv71.32.35 = zext i8 %17182 to i32
  %xor72.32.35 = xor i32 %conv71.32.35, %conv68.32.35
  %conv73.32.35 = trunc i32 %xor72.32.35 to i8
  store i8 %conv73.32.35, i8* %arrayidx70.35, align 1
  %scevgep20.33.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 33
  %17183 = load i8, i8* %scevgep20.33.35, align 1
  %conv68.33.35 = zext i8 %17183 to i32
  %17184 = load i8, i8* %arrayidx70.35, align 1
  %conv71.33.35 = zext i8 %17184 to i32
  %xor72.33.35 = xor i32 %conv71.33.35, %conv68.33.35
  %conv73.33.35 = trunc i32 %xor72.33.35 to i8
  store i8 %conv73.33.35, i8* %arrayidx70.35, align 1
  %scevgep20.34.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 34
  %17185 = load i8, i8* %scevgep20.34.35, align 1
  %conv68.34.35 = zext i8 %17185 to i32
  %17186 = load i8, i8* %arrayidx70.35, align 1
  %conv71.34.35 = zext i8 %17186 to i32
  %xor72.34.35 = xor i32 %conv71.34.35, %conv68.34.35
  %conv73.34.35 = trunc i32 %xor72.34.35 to i8
  store i8 %conv73.34.35, i8* %arrayidx70.35, align 1
  %scevgep20.36.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 36
  %17187 = load i8, i8* %scevgep20.36.35, align 1
  %conv68.36.35 = zext i8 %17187 to i32
  %17188 = load i8, i8* %arrayidx70.35, align 1
  %conv71.36.35 = zext i8 %17188 to i32
  %xor72.36.35 = xor i32 %conv71.36.35, %conv68.36.35
  %conv73.36.35 = trunc i32 %xor72.36.35 to i8
  store i8 %conv73.36.35, i8* %arrayidx70.35, align 1
  %scevgep20.37.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 37
  %17189 = load i8, i8* %scevgep20.37.35, align 1
  %conv68.37.35 = zext i8 %17189 to i32
  %17190 = load i8, i8* %arrayidx70.35, align 1
  %conv71.37.35 = zext i8 %17190 to i32
  %xor72.37.35 = xor i32 %conv71.37.35, %conv68.37.35
  %conv73.37.35 = trunc i32 %xor72.37.35 to i8
  store i8 %conv73.37.35, i8* %arrayidx70.35, align 1
  %scevgep20.38.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 38
  %17191 = load i8, i8* %scevgep20.38.35, align 1
  %conv68.38.35 = zext i8 %17191 to i32
  %17192 = load i8, i8* %arrayidx70.35, align 1
  %conv71.38.35 = zext i8 %17192 to i32
  %xor72.38.35 = xor i32 %conv71.38.35, %conv68.38.35
  %conv73.38.35 = trunc i32 %xor72.38.35 to i8
  store i8 %conv73.38.35, i8* %arrayidx70.35, align 1
  %scevgep20.39.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 39
  %17193 = load i8, i8* %scevgep20.39.35, align 1
  %conv68.39.35 = zext i8 %17193 to i32
  %17194 = load i8, i8* %arrayidx70.35, align 1
  %conv71.39.35 = zext i8 %17194 to i32
  %xor72.39.35 = xor i32 %conv71.39.35, %conv68.39.35
  %conv73.39.35 = trunc i32 %xor72.39.35 to i8
  store i8 %conv73.39.35, i8* %arrayidx70.35, align 1
  %scevgep20.40.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 40
  %17195 = load i8, i8* %scevgep20.40.35, align 1
  %conv68.40.35 = zext i8 %17195 to i32
  %17196 = load i8, i8* %arrayidx70.35, align 1
  %conv71.40.35 = zext i8 %17196 to i32
  %xor72.40.35 = xor i32 %conv71.40.35, %conv68.40.35
  %conv73.40.35 = trunc i32 %xor72.40.35 to i8
  store i8 %conv73.40.35, i8* %arrayidx70.35, align 1
  %scevgep20.41.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 41
  %17197 = load i8, i8* %scevgep20.41.35, align 1
  %conv68.41.35 = zext i8 %17197 to i32
  %17198 = load i8, i8* %arrayidx70.35, align 1
  %conv71.41.35 = zext i8 %17198 to i32
  %xor72.41.35 = xor i32 %conv71.41.35, %conv68.41.35
  %conv73.41.35 = trunc i32 %xor72.41.35 to i8
  store i8 %conv73.41.35, i8* %arrayidx70.35, align 1
  %scevgep20.42.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 42
  %17199 = load i8, i8* %scevgep20.42.35, align 1
  %conv68.42.35 = zext i8 %17199 to i32
  %17200 = load i8, i8* %arrayidx70.35, align 1
  %conv71.42.35 = zext i8 %17200 to i32
  %xor72.42.35 = xor i32 %conv71.42.35, %conv68.42.35
  %conv73.42.35 = trunc i32 %xor72.42.35 to i8
  store i8 %conv73.42.35, i8* %arrayidx70.35, align 1
  %scevgep20.43.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 43
  %17201 = load i8, i8* %scevgep20.43.35, align 1
  %conv68.43.35 = zext i8 %17201 to i32
  %17202 = load i8, i8* %arrayidx70.35, align 1
  %conv71.43.35 = zext i8 %17202 to i32
  %xor72.43.35 = xor i32 %conv71.43.35, %conv68.43.35
  %conv73.43.35 = trunc i32 %xor72.43.35 to i8
  store i8 %conv73.43.35, i8* %arrayidx70.35, align 1
  %scevgep20.44.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 44
  %17203 = load i8, i8* %scevgep20.44.35, align 1
  %conv68.44.35 = zext i8 %17203 to i32
  %17204 = load i8, i8* %arrayidx70.35, align 1
  %conv71.44.35 = zext i8 %17204 to i32
  %xor72.44.35 = xor i32 %conv71.44.35, %conv68.44.35
  %conv73.44.35 = trunc i32 %xor72.44.35 to i8
  store i8 %conv73.44.35, i8* %arrayidx70.35, align 1
  %scevgep20.45.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 45
  %17205 = load i8, i8* %scevgep20.45.35, align 1
  %conv68.45.35 = zext i8 %17205 to i32
  %17206 = load i8, i8* %arrayidx70.35, align 1
  %conv71.45.35 = zext i8 %17206 to i32
  %xor72.45.35 = xor i32 %conv71.45.35, %conv68.45.35
  %conv73.45.35 = trunc i32 %xor72.45.35 to i8
  store i8 %conv73.45.35, i8* %arrayidx70.35, align 1
  %scevgep20.46.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 46
  %17207 = load i8, i8* %scevgep20.46.35, align 1
  %conv68.46.35 = zext i8 %17207 to i32
  %17208 = load i8, i8* %arrayidx70.35, align 1
  %conv71.46.35 = zext i8 %17208 to i32
  %xor72.46.35 = xor i32 %conv71.46.35, %conv68.46.35
  %conv73.46.35 = trunc i32 %xor72.46.35 to i8
  store i8 %conv73.46.35, i8* %arrayidx70.35, align 1
  %scevgep20.47.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 47
  %17209 = load i8, i8* %scevgep20.47.35, align 1
  %conv68.47.35 = zext i8 %17209 to i32
  %17210 = load i8, i8* %arrayidx70.35, align 1
  %conv71.47.35 = zext i8 %17210 to i32
  %xor72.47.35 = xor i32 %conv71.47.35, %conv68.47.35
  %conv73.47.35 = trunc i32 %xor72.47.35 to i8
  store i8 %conv73.47.35, i8* %arrayidx70.35, align 1
  %scevgep20.48.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 48
  %17211 = load i8, i8* %scevgep20.48.35, align 1
  %conv68.48.35 = zext i8 %17211 to i32
  %17212 = load i8, i8* %arrayidx70.35, align 1
  %conv71.48.35 = zext i8 %17212 to i32
  %xor72.48.35 = xor i32 %conv71.48.35, %conv68.48.35
  %conv73.48.35 = trunc i32 %xor72.48.35 to i8
  store i8 %conv73.48.35, i8* %arrayidx70.35, align 1
  %scevgep20.49.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 49
  %17213 = load i8, i8* %scevgep20.49.35, align 1
  %conv68.49.35 = zext i8 %17213 to i32
  %17214 = load i8, i8* %arrayidx70.35, align 1
  %conv71.49.35 = zext i8 %17214 to i32
  %xor72.49.35 = xor i32 %conv71.49.35, %conv68.49.35
  %conv73.49.35 = trunc i32 %xor72.49.35 to i8
  store i8 %conv73.49.35, i8* %arrayidx70.35, align 1
  %scevgep20.50.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 50
  %17215 = load i8, i8* %scevgep20.50.35, align 1
  %conv68.50.35 = zext i8 %17215 to i32
  %17216 = load i8, i8* %arrayidx70.35, align 1
  %conv71.50.35 = zext i8 %17216 to i32
  %xor72.50.35 = xor i32 %conv71.50.35, %conv68.50.35
  %conv73.50.35 = trunc i32 %xor72.50.35 to i8
  store i8 %conv73.50.35, i8* %arrayidx70.35, align 1
  %scevgep20.51.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 51
  %17217 = load i8, i8* %scevgep20.51.35, align 1
  %conv68.51.35 = zext i8 %17217 to i32
  %17218 = load i8, i8* %arrayidx70.35, align 1
  %conv71.51.35 = zext i8 %17218 to i32
  %xor72.51.35 = xor i32 %conv71.51.35, %conv68.51.35
  %conv73.51.35 = trunc i32 %xor72.51.35 to i8
  store i8 %conv73.51.35, i8* %arrayidx70.35, align 1
  %scevgep20.52.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 52
  %17219 = load i8, i8* %scevgep20.52.35, align 1
  %conv68.52.35 = zext i8 %17219 to i32
  %17220 = load i8, i8* %arrayidx70.35, align 1
  %conv71.52.35 = zext i8 %17220 to i32
  %xor72.52.35 = xor i32 %conv71.52.35, %conv68.52.35
  %conv73.52.35 = trunc i32 %xor72.52.35 to i8
  store i8 %conv73.52.35, i8* %arrayidx70.35, align 1
  %scevgep20.53.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 53
  %17221 = load i8, i8* %scevgep20.53.35, align 1
  %conv68.53.35 = zext i8 %17221 to i32
  %17222 = load i8, i8* %arrayidx70.35, align 1
  %conv71.53.35 = zext i8 %17222 to i32
  %xor72.53.35 = xor i32 %conv71.53.35, %conv68.53.35
  %conv73.53.35 = trunc i32 %xor72.53.35 to i8
  store i8 %conv73.53.35, i8* %arrayidx70.35, align 1
  %scevgep20.54.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 54
  %17223 = load i8, i8* %scevgep20.54.35, align 1
  %conv68.54.35 = zext i8 %17223 to i32
  %17224 = load i8, i8* %arrayidx70.35, align 1
  %conv71.54.35 = zext i8 %17224 to i32
  %xor72.54.35 = xor i32 %conv71.54.35, %conv68.54.35
  %conv73.54.35 = trunc i32 %xor72.54.35 to i8
  store i8 %conv73.54.35, i8* %arrayidx70.35, align 1
  %scevgep20.55.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 55
  %17225 = load i8, i8* %scevgep20.55.35, align 1
  %conv68.55.35 = zext i8 %17225 to i32
  %17226 = load i8, i8* %arrayidx70.35, align 1
  %conv71.55.35 = zext i8 %17226 to i32
  %xor72.55.35 = xor i32 %conv71.55.35, %conv68.55.35
  %conv73.55.35 = trunc i32 %xor72.55.35 to i8
  store i8 %conv73.55.35, i8* %arrayidx70.35, align 1
  %scevgep20.56.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 56
  %17227 = load i8, i8* %scevgep20.56.35, align 1
  %conv68.56.35 = zext i8 %17227 to i32
  %17228 = load i8, i8* %arrayidx70.35, align 1
  %conv71.56.35 = zext i8 %17228 to i32
  %xor72.56.35 = xor i32 %conv71.56.35, %conv68.56.35
  %conv73.56.35 = trunc i32 %xor72.56.35 to i8
  store i8 %conv73.56.35, i8* %arrayidx70.35, align 1
  %scevgep20.57.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 57
  %17229 = load i8, i8* %scevgep20.57.35, align 1
  %conv68.57.35 = zext i8 %17229 to i32
  %17230 = load i8, i8* %arrayidx70.35, align 1
  %conv71.57.35 = zext i8 %17230 to i32
  %xor72.57.35 = xor i32 %conv71.57.35, %conv68.57.35
  %conv73.57.35 = trunc i32 %xor72.57.35 to i8
  store i8 %conv73.57.35, i8* %arrayidx70.35, align 1
  %scevgep20.58.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 58
  %17231 = load i8, i8* %scevgep20.58.35, align 1
  %conv68.58.35 = zext i8 %17231 to i32
  %17232 = load i8, i8* %arrayidx70.35, align 1
  %conv71.58.35 = zext i8 %17232 to i32
  %xor72.58.35 = xor i32 %conv71.58.35, %conv68.58.35
  %conv73.58.35 = trunc i32 %xor72.58.35 to i8
  store i8 %conv73.58.35, i8* %arrayidx70.35, align 1
  %scevgep20.59.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 59
  %17233 = load i8, i8* %scevgep20.59.35, align 1
  %conv68.59.35 = zext i8 %17233 to i32
  %17234 = load i8, i8* %arrayidx70.35, align 1
  %conv71.59.35 = zext i8 %17234 to i32
  %xor72.59.35 = xor i32 %conv71.59.35, %conv68.59.35
  %conv73.59.35 = trunc i32 %xor72.59.35 to i8
  store i8 %conv73.59.35, i8* %arrayidx70.35, align 1
  %scevgep20.60.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 0, i64 60
  %17235 = load i8, i8* %scevgep20.60.35, align 1
  %conv68.60.35 = zext i8 %17235 to i32
  %17236 = load i8, i8* %arrayidx70.35, align 1
  %conv71.60.35 = zext i8 %17236 to i32
  %xor72.60.35 = xor i32 %conv71.60.35, %conv68.60.35
  %conv73.60.35 = trunc i32 %xor72.60.35 to i8
  store i8 %conv73.60.35, i8* %arrayidx70.35, align 1
  %scevgep19.35 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17114, i64 0, i64 1, i64 0
  %17237 = bitcast i8* %scevgep19.35 to [61 x [61 x i8]]*
  %arrayidx51.36 = getelementptr inbounds i8, i8* %a, i64 36
  %17238 = load i8, i8* %arrayidx51.36, align 1
  %arrayidx53.36 = getelementptr inbounds i8, i8* %b, i64 36
  %17239 = load i8, i8* %arrayidx53.36, align 1
  %call54.36 = call zeroext i8 @mult(i8 zeroext %17238, i8 zeroext %17239)
  %arrayidx56.36 = getelementptr inbounds i8, i8* %c, i64 36
  store i8 %call54.36, i8* %arrayidx56.36, align 1
  %arrayidx70.36 = getelementptr inbounds i8, i8* %c, i64 36
  %scevgep20.36404 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 0
  %17240 = load i8, i8* %scevgep20.36404, align 1
  %conv68.36405 = zext i8 %17240 to i32
  %17241 = load i8, i8* %arrayidx70.36, align 1
  %conv71.36406 = zext i8 %17241 to i32
  %xor72.36407 = xor i32 %conv71.36406, %conv68.36405
  %conv73.36408 = trunc i32 %xor72.36407 to i8
  store i8 %conv73.36408, i8* %arrayidx70.36, align 1
  %scevgep20.1.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 1
  %17242 = load i8, i8* %scevgep20.1.36, align 1
  %conv68.1.36 = zext i8 %17242 to i32
  %17243 = load i8, i8* %arrayidx70.36, align 1
  %conv71.1.36 = zext i8 %17243 to i32
  %xor72.1.36 = xor i32 %conv71.1.36, %conv68.1.36
  %conv73.1.36 = trunc i32 %xor72.1.36 to i8
  store i8 %conv73.1.36, i8* %arrayidx70.36, align 1
  %scevgep20.2.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 2
  %17244 = load i8, i8* %scevgep20.2.36, align 1
  %conv68.2.36 = zext i8 %17244 to i32
  %17245 = load i8, i8* %arrayidx70.36, align 1
  %conv71.2.36 = zext i8 %17245 to i32
  %xor72.2.36 = xor i32 %conv71.2.36, %conv68.2.36
  %conv73.2.36 = trunc i32 %xor72.2.36 to i8
  store i8 %conv73.2.36, i8* %arrayidx70.36, align 1
  %scevgep20.3.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 3
  %17246 = load i8, i8* %scevgep20.3.36, align 1
  %conv68.3.36 = zext i8 %17246 to i32
  %17247 = load i8, i8* %arrayidx70.36, align 1
  %conv71.3.36 = zext i8 %17247 to i32
  %xor72.3.36 = xor i32 %conv71.3.36, %conv68.3.36
  %conv73.3.36 = trunc i32 %xor72.3.36 to i8
  store i8 %conv73.3.36, i8* %arrayidx70.36, align 1
  %scevgep20.4.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 4
  %17248 = load i8, i8* %scevgep20.4.36, align 1
  %conv68.4.36 = zext i8 %17248 to i32
  %17249 = load i8, i8* %arrayidx70.36, align 1
  %conv71.4.36 = zext i8 %17249 to i32
  %xor72.4.36 = xor i32 %conv71.4.36, %conv68.4.36
  %conv73.4.36 = trunc i32 %xor72.4.36 to i8
  store i8 %conv73.4.36, i8* %arrayidx70.36, align 1
  %scevgep20.5.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 5
  %17250 = load i8, i8* %scevgep20.5.36, align 1
  %conv68.5.36 = zext i8 %17250 to i32
  %17251 = load i8, i8* %arrayidx70.36, align 1
  %conv71.5.36 = zext i8 %17251 to i32
  %xor72.5.36 = xor i32 %conv71.5.36, %conv68.5.36
  %conv73.5.36 = trunc i32 %xor72.5.36 to i8
  store i8 %conv73.5.36, i8* %arrayidx70.36, align 1
  %scevgep20.6.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 6
  %17252 = load i8, i8* %scevgep20.6.36, align 1
  %conv68.6.36 = zext i8 %17252 to i32
  %17253 = load i8, i8* %arrayidx70.36, align 1
  %conv71.6.36 = zext i8 %17253 to i32
  %xor72.6.36 = xor i32 %conv71.6.36, %conv68.6.36
  %conv73.6.36 = trunc i32 %xor72.6.36 to i8
  store i8 %conv73.6.36, i8* %arrayidx70.36, align 1
  %scevgep20.7.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 7
  %17254 = load i8, i8* %scevgep20.7.36, align 1
  %conv68.7.36 = zext i8 %17254 to i32
  %17255 = load i8, i8* %arrayidx70.36, align 1
  %conv71.7.36 = zext i8 %17255 to i32
  %xor72.7.36 = xor i32 %conv71.7.36, %conv68.7.36
  %conv73.7.36 = trunc i32 %xor72.7.36 to i8
  store i8 %conv73.7.36, i8* %arrayidx70.36, align 1
  %scevgep20.8.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 8
  %17256 = load i8, i8* %scevgep20.8.36, align 1
  %conv68.8.36 = zext i8 %17256 to i32
  %17257 = load i8, i8* %arrayidx70.36, align 1
  %conv71.8.36 = zext i8 %17257 to i32
  %xor72.8.36 = xor i32 %conv71.8.36, %conv68.8.36
  %conv73.8.36 = trunc i32 %xor72.8.36 to i8
  store i8 %conv73.8.36, i8* %arrayidx70.36, align 1
  %scevgep20.9.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 9
  %17258 = load i8, i8* %scevgep20.9.36, align 1
  %conv68.9.36 = zext i8 %17258 to i32
  %17259 = load i8, i8* %arrayidx70.36, align 1
  %conv71.9.36 = zext i8 %17259 to i32
  %xor72.9.36 = xor i32 %conv71.9.36, %conv68.9.36
  %conv73.9.36 = trunc i32 %xor72.9.36 to i8
  store i8 %conv73.9.36, i8* %arrayidx70.36, align 1
  %scevgep20.10.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 10
  %17260 = load i8, i8* %scevgep20.10.36, align 1
  %conv68.10.36 = zext i8 %17260 to i32
  %17261 = load i8, i8* %arrayidx70.36, align 1
  %conv71.10.36 = zext i8 %17261 to i32
  %xor72.10.36 = xor i32 %conv71.10.36, %conv68.10.36
  %conv73.10.36 = trunc i32 %xor72.10.36 to i8
  store i8 %conv73.10.36, i8* %arrayidx70.36, align 1
  %scevgep20.11.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 11
  %17262 = load i8, i8* %scevgep20.11.36, align 1
  %conv68.11.36 = zext i8 %17262 to i32
  %17263 = load i8, i8* %arrayidx70.36, align 1
  %conv71.11.36 = zext i8 %17263 to i32
  %xor72.11.36 = xor i32 %conv71.11.36, %conv68.11.36
  %conv73.11.36 = trunc i32 %xor72.11.36 to i8
  store i8 %conv73.11.36, i8* %arrayidx70.36, align 1
  %scevgep20.12.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 12
  %17264 = load i8, i8* %scevgep20.12.36, align 1
  %conv68.12.36 = zext i8 %17264 to i32
  %17265 = load i8, i8* %arrayidx70.36, align 1
  %conv71.12.36 = zext i8 %17265 to i32
  %xor72.12.36 = xor i32 %conv71.12.36, %conv68.12.36
  %conv73.12.36 = trunc i32 %xor72.12.36 to i8
  store i8 %conv73.12.36, i8* %arrayidx70.36, align 1
  %scevgep20.13.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 13
  %17266 = load i8, i8* %scevgep20.13.36, align 1
  %conv68.13.36 = zext i8 %17266 to i32
  %17267 = load i8, i8* %arrayidx70.36, align 1
  %conv71.13.36 = zext i8 %17267 to i32
  %xor72.13.36 = xor i32 %conv71.13.36, %conv68.13.36
  %conv73.13.36 = trunc i32 %xor72.13.36 to i8
  store i8 %conv73.13.36, i8* %arrayidx70.36, align 1
  %scevgep20.14.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 14
  %17268 = load i8, i8* %scevgep20.14.36, align 1
  %conv68.14.36 = zext i8 %17268 to i32
  %17269 = load i8, i8* %arrayidx70.36, align 1
  %conv71.14.36 = zext i8 %17269 to i32
  %xor72.14.36 = xor i32 %conv71.14.36, %conv68.14.36
  %conv73.14.36 = trunc i32 %xor72.14.36 to i8
  store i8 %conv73.14.36, i8* %arrayidx70.36, align 1
  %scevgep20.15.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 15
  %17270 = load i8, i8* %scevgep20.15.36, align 1
  %conv68.15.36 = zext i8 %17270 to i32
  %17271 = load i8, i8* %arrayidx70.36, align 1
  %conv71.15.36 = zext i8 %17271 to i32
  %xor72.15.36 = xor i32 %conv71.15.36, %conv68.15.36
  %conv73.15.36 = trunc i32 %xor72.15.36 to i8
  store i8 %conv73.15.36, i8* %arrayidx70.36, align 1
  %scevgep20.16.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 16
  %17272 = load i8, i8* %scevgep20.16.36, align 1
  %conv68.16.36 = zext i8 %17272 to i32
  %17273 = load i8, i8* %arrayidx70.36, align 1
  %conv71.16.36 = zext i8 %17273 to i32
  %xor72.16.36 = xor i32 %conv71.16.36, %conv68.16.36
  %conv73.16.36 = trunc i32 %xor72.16.36 to i8
  store i8 %conv73.16.36, i8* %arrayidx70.36, align 1
  %scevgep20.17.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 17
  %17274 = load i8, i8* %scevgep20.17.36, align 1
  %conv68.17.36 = zext i8 %17274 to i32
  %17275 = load i8, i8* %arrayidx70.36, align 1
  %conv71.17.36 = zext i8 %17275 to i32
  %xor72.17.36 = xor i32 %conv71.17.36, %conv68.17.36
  %conv73.17.36 = trunc i32 %xor72.17.36 to i8
  store i8 %conv73.17.36, i8* %arrayidx70.36, align 1
  %scevgep20.18.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 18
  %17276 = load i8, i8* %scevgep20.18.36, align 1
  %conv68.18.36 = zext i8 %17276 to i32
  %17277 = load i8, i8* %arrayidx70.36, align 1
  %conv71.18.36 = zext i8 %17277 to i32
  %xor72.18.36 = xor i32 %conv71.18.36, %conv68.18.36
  %conv73.18.36 = trunc i32 %xor72.18.36 to i8
  store i8 %conv73.18.36, i8* %arrayidx70.36, align 1
  %scevgep20.19.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 19
  %17278 = load i8, i8* %scevgep20.19.36, align 1
  %conv68.19.36 = zext i8 %17278 to i32
  %17279 = load i8, i8* %arrayidx70.36, align 1
  %conv71.19.36 = zext i8 %17279 to i32
  %xor72.19.36 = xor i32 %conv71.19.36, %conv68.19.36
  %conv73.19.36 = trunc i32 %xor72.19.36 to i8
  store i8 %conv73.19.36, i8* %arrayidx70.36, align 1
  %scevgep20.20.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 20
  %17280 = load i8, i8* %scevgep20.20.36, align 1
  %conv68.20.36 = zext i8 %17280 to i32
  %17281 = load i8, i8* %arrayidx70.36, align 1
  %conv71.20.36 = zext i8 %17281 to i32
  %xor72.20.36 = xor i32 %conv71.20.36, %conv68.20.36
  %conv73.20.36 = trunc i32 %xor72.20.36 to i8
  store i8 %conv73.20.36, i8* %arrayidx70.36, align 1
  %scevgep20.21.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 21
  %17282 = load i8, i8* %scevgep20.21.36, align 1
  %conv68.21.36 = zext i8 %17282 to i32
  %17283 = load i8, i8* %arrayidx70.36, align 1
  %conv71.21.36 = zext i8 %17283 to i32
  %xor72.21.36 = xor i32 %conv71.21.36, %conv68.21.36
  %conv73.21.36 = trunc i32 %xor72.21.36 to i8
  store i8 %conv73.21.36, i8* %arrayidx70.36, align 1
  %scevgep20.22.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 22
  %17284 = load i8, i8* %scevgep20.22.36, align 1
  %conv68.22.36 = zext i8 %17284 to i32
  %17285 = load i8, i8* %arrayidx70.36, align 1
  %conv71.22.36 = zext i8 %17285 to i32
  %xor72.22.36 = xor i32 %conv71.22.36, %conv68.22.36
  %conv73.22.36 = trunc i32 %xor72.22.36 to i8
  store i8 %conv73.22.36, i8* %arrayidx70.36, align 1
  %scevgep20.23.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 23
  %17286 = load i8, i8* %scevgep20.23.36, align 1
  %conv68.23.36 = zext i8 %17286 to i32
  %17287 = load i8, i8* %arrayidx70.36, align 1
  %conv71.23.36 = zext i8 %17287 to i32
  %xor72.23.36 = xor i32 %conv71.23.36, %conv68.23.36
  %conv73.23.36 = trunc i32 %xor72.23.36 to i8
  store i8 %conv73.23.36, i8* %arrayidx70.36, align 1
  %scevgep20.24.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 24
  %17288 = load i8, i8* %scevgep20.24.36, align 1
  %conv68.24.36 = zext i8 %17288 to i32
  %17289 = load i8, i8* %arrayidx70.36, align 1
  %conv71.24.36 = zext i8 %17289 to i32
  %xor72.24.36 = xor i32 %conv71.24.36, %conv68.24.36
  %conv73.24.36 = trunc i32 %xor72.24.36 to i8
  store i8 %conv73.24.36, i8* %arrayidx70.36, align 1
  %scevgep20.25.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 25
  %17290 = load i8, i8* %scevgep20.25.36, align 1
  %conv68.25.36 = zext i8 %17290 to i32
  %17291 = load i8, i8* %arrayidx70.36, align 1
  %conv71.25.36 = zext i8 %17291 to i32
  %xor72.25.36 = xor i32 %conv71.25.36, %conv68.25.36
  %conv73.25.36 = trunc i32 %xor72.25.36 to i8
  store i8 %conv73.25.36, i8* %arrayidx70.36, align 1
  %scevgep20.26.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 26
  %17292 = load i8, i8* %scevgep20.26.36, align 1
  %conv68.26.36 = zext i8 %17292 to i32
  %17293 = load i8, i8* %arrayidx70.36, align 1
  %conv71.26.36 = zext i8 %17293 to i32
  %xor72.26.36 = xor i32 %conv71.26.36, %conv68.26.36
  %conv73.26.36 = trunc i32 %xor72.26.36 to i8
  store i8 %conv73.26.36, i8* %arrayidx70.36, align 1
  %scevgep20.27.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 27
  %17294 = load i8, i8* %scevgep20.27.36, align 1
  %conv68.27.36 = zext i8 %17294 to i32
  %17295 = load i8, i8* %arrayidx70.36, align 1
  %conv71.27.36 = zext i8 %17295 to i32
  %xor72.27.36 = xor i32 %conv71.27.36, %conv68.27.36
  %conv73.27.36 = trunc i32 %xor72.27.36 to i8
  store i8 %conv73.27.36, i8* %arrayidx70.36, align 1
  %scevgep20.28.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 28
  %17296 = load i8, i8* %scevgep20.28.36, align 1
  %conv68.28.36 = zext i8 %17296 to i32
  %17297 = load i8, i8* %arrayidx70.36, align 1
  %conv71.28.36 = zext i8 %17297 to i32
  %xor72.28.36 = xor i32 %conv71.28.36, %conv68.28.36
  %conv73.28.36 = trunc i32 %xor72.28.36 to i8
  store i8 %conv73.28.36, i8* %arrayidx70.36, align 1
  %scevgep20.29.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 29
  %17298 = load i8, i8* %scevgep20.29.36, align 1
  %conv68.29.36 = zext i8 %17298 to i32
  %17299 = load i8, i8* %arrayidx70.36, align 1
  %conv71.29.36 = zext i8 %17299 to i32
  %xor72.29.36 = xor i32 %conv71.29.36, %conv68.29.36
  %conv73.29.36 = trunc i32 %xor72.29.36 to i8
  store i8 %conv73.29.36, i8* %arrayidx70.36, align 1
  %scevgep20.30.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 30
  %17300 = load i8, i8* %scevgep20.30.36, align 1
  %conv68.30.36 = zext i8 %17300 to i32
  %17301 = load i8, i8* %arrayidx70.36, align 1
  %conv71.30.36 = zext i8 %17301 to i32
  %xor72.30.36 = xor i32 %conv71.30.36, %conv68.30.36
  %conv73.30.36 = trunc i32 %xor72.30.36 to i8
  store i8 %conv73.30.36, i8* %arrayidx70.36, align 1
  %scevgep20.31.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 31
  %17302 = load i8, i8* %scevgep20.31.36, align 1
  %conv68.31.36 = zext i8 %17302 to i32
  %17303 = load i8, i8* %arrayidx70.36, align 1
  %conv71.31.36 = zext i8 %17303 to i32
  %xor72.31.36 = xor i32 %conv71.31.36, %conv68.31.36
  %conv73.31.36 = trunc i32 %xor72.31.36 to i8
  store i8 %conv73.31.36, i8* %arrayidx70.36, align 1
  %scevgep20.32.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 32
  %17304 = load i8, i8* %scevgep20.32.36, align 1
  %conv68.32.36 = zext i8 %17304 to i32
  %17305 = load i8, i8* %arrayidx70.36, align 1
  %conv71.32.36 = zext i8 %17305 to i32
  %xor72.32.36 = xor i32 %conv71.32.36, %conv68.32.36
  %conv73.32.36 = trunc i32 %xor72.32.36 to i8
  store i8 %conv73.32.36, i8* %arrayidx70.36, align 1
  %scevgep20.33.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 33
  %17306 = load i8, i8* %scevgep20.33.36, align 1
  %conv68.33.36 = zext i8 %17306 to i32
  %17307 = load i8, i8* %arrayidx70.36, align 1
  %conv71.33.36 = zext i8 %17307 to i32
  %xor72.33.36 = xor i32 %conv71.33.36, %conv68.33.36
  %conv73.33.36 = trunc i32 %xor72.33.36 to i8
  store i8 %conv73.33.36, i8* %arrayidx70.36, align 1
  %scevgep20.34.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 34
  %17308 = load i8, i8* %scevgep20.34.36, align 1
  %conv68.34.36 = zext i8 %17308 to i32
  %17309 = load i8, i8* %arrayidx70.36, align 1
  %conv71.34.36 = zext i8 %17309 to i32
  %xor72.34.36 = xor i32 %conv71.34.36, %conv68.34.36
  %conv73.34.36 = trunc i32 %xor72.34.36 to i8
  store i8 %conv73.34.36, i8* %arrayidx70.36, align 1
  %scevgep20.35.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 35
  %17310 = load i8, i8* %scevgep20.35.36, align 1
  %conv68.35.36 = zext i8 %17310 to i32
  %17311 = load i8, i8* %arrayidx70.36, align 1
  %conv71.35.36 = zext i8 %17311 to i32
  %xor72.35.36 = xor i32 %conv71.35.36, %conv68.35.36
  %conv73.35.36 = trunc i32 %xor72.35.36 to i8
  store i8 %conv73.35.36, i8* %arrayidx70.36, align 1
  %scevgep20.37.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 37
  %17312 = load i8, i8* %scevgep20.37.36, align 1
  %conv68.37.36 = zext i8 %17312 to i32
  %17313 = load i8, i8* %arrayidx70.36, align 1
  %conv71.37.36 = zext i8 %17313 to i32
  %xor72.37.36 = xor i32 %conv71.37.36, %conv68.37.36
  %conv73.37.36 = trunc i32 %xor72.37.36 to i8
  store i8 %conv73.37.36, i8* %arrayidx70.36, align 1
  %scevgep20.38.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 38
  %17314 = load i8, i8* %scevgep20.38.36, align 1
  %conv68.38.36 = zext i8 %17314 to i32
  %17315 = load i8, i8* %arrayidx70.36, align 1
  %conv71.38.36 = zext i8 %17315 to i32
  %xor72.38.36 = xor i32 %conv71.38.36, %conv68.38.36
  %conv73.38.36 = trunc i32 %xor72.38.36 to i8
  store i8 %conv73.38.36, i8* %arrayidx70.36, align 1
  %scevgep20.39.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 39
  %17316 = load i8, i8* %scevgep20.39.36, align 1
  %conv68.39.36 = zext i8 %17316 to i32
  %17317 = load i8, i8* %arrayidx70.36, align 1
  %conv71.39.36 = zext i8 %17317 to i32
  %xor72.39.36 = xor i32 %conv71.39.36, %conv68.39.36
  %conv73.39.36 = trunc i32 %xor72.39.36 to i8
  store i8 %conv73.39.36, i8* %arrayidx70.36, align 1
  %scevgep20.40.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 40
  %17318 = load i8, i8* %scevgep20.40.36, align 1
  %conv68.40.36 = zext i8 %17318 to i32
  %17319 = load i8, i8* %arrayidx70.36, align 1
  %conv71.40.36 = zext i8 %17319 to i32
  %xor72.40.36 = xor i32 %conv71.40.36, %conv68.40.36
  %conv73.40.36 = trunc i32 %xor72.40.36 to i8
  store i8 %conv73.40.36, i8* %arrayidx70.36, align 1
  %scevgep20.41.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 41
  %17320 = load i8, i8* %scevgep20.41.36, align 1
  %conv68.41.36 = zext i8 %17320 to i32
  %17321 = load i8, i8* %arrayidx70.36, align 1
  %conv71.41.36 = zext i8 %17321 to i32
  %xor72.41.36 = xor i32 %conv71.41.36, %conv68.41.36
  %conv73.41.36 = trunc i32 %xor72.41.36 to i8
  store i8 %conv73.41.36, i8* %arrayidx70.36, align 1
  %scevgep20.42.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 42
  %17322 = load i8, i8* %scevgep20.42.36, align 1
  %conv68.42.36 = zext i8 %17322 to i32
  %17323 = load i8, i8* %arrayidx70.36, align 1
  %conv71.42.36 = zext i8 %17323 to i32
  %xor72.42.36 = xor i32 %conv71.42.36, %conv68.42.36
  %conv73.42.36 = trunc i32 %xor72.42.36 to i8
  store i8 %conv73.42.36, i8* %arrayidx70.36, align 1
  %scevgep20.43.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 43
  %17324 = load i8, i8* %scevgep20.43.36, align 1
  %conv68.43.36 = zext i8 %17324 to i32
  %17325 = load i8, i8* %arrayidx70.36, align 1
  %conv71.43.36 = zext i8 %17325 to i32
  %xor72.43.36 = xor i32 %conv71.43.36, %conv68.43.36
  %conv73.43.36 = trunc i32 %xor72.43.36 to i8
  store i8 %conv73.43.36, i8* %arrayidx70.36, align 1
  %scevgep20.44.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 44
  %17326 = load i8, i8* %scevgep20.44.36, align 1
  %conv68.44.36 = zext i8 %17326 to i32
  %17327 = load i8, i8* %arrayidx70.36, align 1
  %conv71.44.36 = zext i8 %17327 to i32
  %xor72.44.36 = xor i32 %conv71.44.36, %conv68.44.36
  %conv73.44.36 = trunc i32 %xor72.44.36 to i8
  store i8 %conv73.44.36, i8* %arrayidx70.36, align 1
  %scevgep20.45.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 45
  %17328 = load i8, i8* %scevgep20.45.36, align 1
  %conv68.45.36 = zext i8 %17328 to i32
  %17329 = load i8, i8* %arrayidx70.36, align 1
  %conv71.45.36 = zext i8 %17329 to i32
  %xor72.45.36 = xor i32 %conv71.45.36, %conv68.45.36
  %conv73.45.36 = trunc i32 %xor72.45.36 to i8
  store i8 %conv73.45.36, i8* %arrayidx70.36, align 1
  %scevgep20.46.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 46
  %17330 = load i8, i8* %scevgep20.46.36, align 1
  %conv68.46.36 = zext i8 %17330 to i32
  %17331 = load i8, i8* %arrayidx70.36, align 1
  %conv71.46.36 = zext i8 %17331 to i32
  %xor72.46.36 = xor i32 %conv71.46.36, %conv68.46.36
  %conv73.46.36 = trunc i32 %xor72.46.36 to i8
  store i8 %conv73.46.36, i8* %arrayidx70.36, align 1
  %scevgep20.47.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 47
  %17332 = load i8, i8* %scevgep20.47.36, align 1
  %conv68.47.36 = zext i8 %17332 to i32
  %17333 = load i8, i8* %arrayidx70.36, align 1
  %conv71.47.36 = zext i8 %17333 to i32
  %xor72.47.36 = xor i32 %conv71.47.36, %conv68.47.36
  %conv73.47.36 = trunc i32 %xor72.47.36 to i8
  store i8 %conv73.47.36, i8* %arrayidx70.36, align 1
  %scevgep20.48.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 48
  %17334 = load i8, i8* %scevgep20.48.36, align 1
  %conv68.48.36 = zext i8 %17334 to i32
  %17335 = load i8, i8* %arrayidx70.36, align 1
  %conv71.48.36 = zext i8 %17335 to i32
  %xor72.48.36 = xor i32 %conv71.48.36, %conv68.48.36
  %conv73.48.36 = trunc i32 %xor72.48.36 to i8
  store i8 %conv73.48.36, i8* %arrayidx70.36, align 1
  %scevgep20.49.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 49
  %17336 = load i8, i8* %scevgep20.49.36, align 1
  %conv68.49.36 = zext i8 %17336 to i32
  %17337 = load i8, i8* %arrayidx70.36, align 1
  %conv71.49.36 = zext i8 %17337 to i32
  %xor72.49.36 = xor i32 %conv71.49.36, %conv68.49.36
  %conv73.49.36 = trunc i32 %xor72.49.36 to i8
  store i8 %conv73.49.36, i8* %arrayidx70.36, align 1
  %scevgep20.50.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 50
  %17338 = load i8, i8* %scevgep20.50.36, align 1
  %conv68.50.36 = zext i8 %17338 to i32
  %17339 = load i8, i8* %arrayidx70.36, align 1
  %conv71.50.36 = zext i8 %17339 to i32
  %xor72.50.36 = xor i32 %conv71.50.36, %conv68.50.36
  %conv73.50.36 = trunc i32 %xor72.50.36 to i8
  store i8 %conv73.50.36, i8* %arrayidx70.36, align 1
  %scevgep20.51.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 51
  %17340 = load i8, i8* %scevgep20.51.36, align 1
  %conv68.51.36 = zext i8 %17340 to i32
  %17341 = load i8, i8* %arrayidx70.36, align 1
  %conv71.51.36 = zext i8 %17341 to i32
  %xor72.51.36 = xor i32 %conv71.51.36, %conv68.51.36
  %conv73.51.36 = trunc i32 %xor72.51.36 to i8
  store i8 %conv73.51.36, i8* %arrayidx70.36, align 1
  %scevgep20.52.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 52
  %17342 = load i8, i8* %scevgep20.52.36, align 1
  %conv68.52.36 = zext i8 %17342 to i32
  %17343 = load i8, i8* %arrayidx70.36, align 1
  %conv71.52.36 = zext i8 %17343 to i32
  %xor72.52.36 = xor i32 %conv71.52.36, %conv68.52.36
  %conv73.52.36 = trunc i32 %xor72.52.36 to i8
  store i8 %conv73.52.36, i8* %arrayidx70.36, align 1
  %scevgep20.53.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 53
  %17344 = load i8, i8* %scevgep20.53.36, align 1
  %conv68.53.36 = zext i8 %17344 to i32
  %17345 = load i8, i8* %arrayidx70.36, align 1
  %conv71.53.36 = zext i8 %17345 to i32
  %xor72.53.36 = xor i32 %conv71.53.36, %conv68.53.36
  %conv73.53.36 = trunc i32 %xor72.53.36 to i8
  store i8 %conv73.53.36, i8* %arrayidx70.36, align 1
  %scevgep20.54.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 54
  %17346 = load i8, i8* %scevgep20.54.36, align 1
  %conv68.54.36 = zext i8 %17346 to i32
  %17347 = load i8, i8* %arrayidx70.36, align 1
  %conv71.54.36 = zext i8 %17347 to i32
  %xor72.54.36 = xor i32 %conv71.54.36, %conv68.54.36
  %conv73.54.36 = trunc i32 %xor72.54.36 to i8
  store i8 %conv73.54.36, i8* %arrayidx70.36, align 1
  %scevgep20.55.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 55
  %17348 = load i8, i8* %scevgep20.55.36, align 1
  %conv68.55.36 = zext i8 %17348 to i32
  %17349 = load i8, i8* %arrayidx70.36, align 1
  %conv71.55.36 = zext i8 %17349 to i32
  %xor72.55.36 = xor i32 %conv71.55.36, %conv68.55.36
  %conv73.55.36 = trunc i32 %xor72.55.36 to i8
  store i8 %conv73.55.36, i8* %arrayidx70.36, align 1
  %scevgep20.56.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 56
  %17350 = load i8, i8* %scevgep20.56.36, align 1
  %conv68.56.36 = zext i8 %17350 to i32
  %17351 = load i8, i8* %arrayidx70.36, align 1
  %conv71.56.36 = zext i8 %17351 to i32
  %xor72.56.36 = xor i32 %conv71.56.36, %conv68.56.36
  %conv73.56.36 = trunc i32 %xor72.56.36 to i8
  store i8 %conv73.56.36, i8* %arrayidx70.36, align 1
  %scevgep20.57.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 57
  %17352 = load i8, i8* %scevgep20.57.36, align 1
  %conv68.57.36 = zext i8 %17352 to i32
  %17353 = load i8, i8* %arrayidx70.36, align 1
  %conv71.57.36 = zext i8 %17353 to i32
  %xor72.57.36 = xor i32 %conv71.57.36, %conv68.57.36
  %conv73.57.36 = trunc i32 %xor72.57.36 to i8
  store i8 %conv73.57.36, i8* %arrayidx70.36, align 1
  %scevgep20.58.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 58
  %17354 = load i8, i8* %scevgep20.58.36, align 1
  %conv68.58.36 = zext i8 %17354 to i32
  %17355 = load i8, i8* %arrayidx70.36, align 1
  %conv71.58.36 = zext i8 %17355 to i32
  %xor72.58.36 = xor i32 %conv71.58.36, %conv68.58.36
  %conv73.58.36 = trunc i32 %xor72.58.36 to i8
  store i8 %conv73.58.36, i8* %arrayidx70.36, align 1
  %scevgep20.59.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 59
  %17356 = load i8, i8* %scevgep20.59.36, align 1
  %conv68.59.36 = zext i8 %17356 to i32
  %17357 = load i8, i8* %arrayidx70.36, align 1
  %conv71.59.36 = zext i8 %17357 to i32
  %xor72.59.36 = xor i32 %conv71.59.36, %conv68.59.36
  %conv73.59.36 = trunc i32 %xor72.59.36 to i8
  store i8 %conv73.59.36, i8* %arrayidx70.36, align 1
  %scevgep20.60.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 0, i64 60
  %17358 = load i8, i8* %scevgep20.60.36, align 1
  %conv68.60.36 = zext i8 %17358 to i32
  %17359 = load i8, i8* %arrayidx70.36, align 1
  %conv71.60.36 = zext i8 %17359 to i32
  %xor72.60.36 = xor i32 %conv71.60.36, %conv68.60.36
  %conv73.60.36 = trunc i32 %xor72.60.36 to i8
  store i8 %conv73.60.36, i8* %arrayidx70.36, align 1
  %scevgep19.36 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17237, i64 0, i64 1, i64 0
  %17360 = bitcast i8* %scevgep19.36 to [61 x [61 x i8]]*
  %arrayidx51.37 = getelementptr inbounds i8, i8* %a, i64 37
  %17361 = load i8, i8* %arrayidx51.37, align 1
  %arrayidx53.37 = getelementptr inbounds i8, i8* %b, i64 37
  %17362 = load i8, i8* %arrayidx53.37, align 1
  %call54.37 = call zeroext i8 @mult(i8 zeroext %17361, i8 zeroext %17362)
  %arrayidx56.37 = getelementptr inbounds i8, i8* %c, i64 37
  store i8 %call54.37, i8* %arrayidx56.37, align 1
  %arrayidx70.37 = getelementptr inbounds i8, i8* %c, i64 37
  %scevgep20.37414 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 0
  %17363 = load i8, i8* %scevgep20.37414, align 1
  %conv68.37415 = zext i8 %17363 to i32
  %17364 = load i8, i8* %arrayidx70.37, align 1
  %conv71.37416 = zext i8 %17364 to i32
  %xor72.37417 = xor i32 %conv71.37416, %conv68.37415
  %conv73.37418 = trunc i32 %xor72.37417 to i8
  store i8 %conv73.37418, i8* %arrayidx70.37, align 1
  %scevgep20.1.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 1
  %17365 = load i8, i8* %scevgep20.1.37, align 1
  %conv68.1.37 = zext i8 %17365 to i32
  %17366 = load i8, i8* %arrayidx70.37, align 1
  %conv71.1.37 = zext i8 %17366 to i32
  %xor72.1.37 = xor i32 %conv71.1.37, %conv68.1.37
  %conv73.1.37 = trunc i32 %xor72.1.37 to i8
  store i8 %conv73.1.37, i8* %arrayidx70.37, align 1
  %scevgep20.2.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 2
  %17367 = load i8, i8* %scevgep20.2.37, align 1
  %conv68.2.37 = zext i8 %17367 to i32
  %17368 = load i8, i8* %arrayidx70.37, align 1
  %conv71.2.37 = zext i8 %17368 to i32
  %xor72.2.37 = xor i32 %conv71.2.37, %conv68.2.37
  %conv73.2.37 = trunc i32 %xor72.2.37 to i8
  store i8 %conv73.2.37, i8* %arrayidx70.37, align 1
  %scevgep20.3.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 3
  %17369 = load i8, i8* %scevgep20.3.37, align 1
  %conv68.3.37 = zext i8 %17369 to i32
  %17370 = load i8, i8* %arrayidx70.37, align 1
  %conv71.3.37 = zext i8 %17370 to i32
  %xor72.3.37 = xor i32 %conv71.3.37, %conv68.3.37
  %conv73.3.37 = trunc i32 %xor72.3.37 to i8
  store i8 %conv73.3.37, i8* %arrayidx70.37, align 1
  %scevgep20.4.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 4
  %17371 = load i8, i8* %scevgep20.4.37, align 1
  %conv68.4.37 = zext i8 %17371 to i32
  %17372 = load i8, i8* %arrayidx70.37, align 1
  %conv71.4.37 = zext i8 %17372 to i32
  %xor72.4.37 = xor i32 %conv71.4.37, %conv68.4.37
  %conv73.4.37 = trunc i32 %xor72.4.37 to i8
  store i8 %conv73.4.37, i8* %arrayidx70.37, align 1
  %scevgep20.5.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 5
  %17373 = load i8, i8* %scevgep20.5.37, align 1
  %conv68.5.37 = zext i8 %17373 to i32
  %17374 = load i8, i8* %arrayidx70.37, align 1
  %conv71.5.37 = zext i8 %17374 to i32
  %xor72.5.37 = xor i32 %conv71.5.37, %conv68.5.37
  %conv73.5.37 = trunc i32 %xor72.5.37 to i8
  store i8 %conv73.5.37, i8* %arrayidx70.37, align 1
  %scevgep20.6.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 6
  %17375 = load i8, i8* %scevgep20.6.37, align 1
  %conv68.6.37 = zext i8 %17375 to i32
  %17376 = load i8, i8* %arrayidx70.37, align 1
  %conv71.6.37 = zext i8 %17376 to i32
  %xor72.6.37 = xor i32 %conv71.6.37, %conv68.6.37
  %conv73.6.37 = trunc i32 %xor72.6.37 to i8
  store i8 %conv73.6.37, i8* %arrayidx70.37, align 1
  %scevgep20.7.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 7
  %17377 = load i8, i8* %scevgep20.7.37, align 1
  %conv68.7.37 = zext i8 %17377 to i32
  %17378 = load i8, i8* %arrayidx70.37, align 1
  %conv71.7.37 = zext i8 %17378 to i32
  %xor72.7.37 = xor i32 %conv71.7.37, %conv68.7.37
  %conv73.7.37 = trunc i32 %xor72.7.37 to i8
  store i8 %conv73.7.37, i8* %arrayidx70.37, align 1
  %scevgep20.8.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 8
  %17379 = load i8, i8* %scevgep20.8.37, align 1
  %conv68.8.37 = zext i8 %17379 to i32
  %17380 = load i8, i8* %arrayidx70.37, align 1
  %conv71.8.37 = zext i8 %17380 to i32
  %xor72.8.37 = xor i32 %conv71.8.37, %conv68.8.37
  %conv73.8.37 = trunc i32 %xor72.8.37 to i8
  store i8 %conv73.8.37, i8* %arrayidx70.37, align 1
  %scevgep20.9.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 9
  %17381 = load i8, i8* %scevgep20.9.37, align 1
  %conv68.9.37 = zext i8 %17381 to i32
  %17382 = load i8, i8* %arrayidx70.37, align 1
  %conv71.9.37 = zext i8 %17382 to i32
  %xor72.9.37 = xor i32 %conv71.9.37, %conv68.9.37
  %conv73.9.37 = trunc i32 %xor72.9.37 to i8
  store i8 %conv73.9.37, i8* %arrayidx70.37, align 1
  %scevgep20.10.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 10
  %17383 = load i8, i8* %scevgep20.10.37, align 1
  %conv68.10.37 = zext i8 %17383 to i32
  %17384 = load i8, i8* %arrayidx70.37, align 1
  %conv71.10.37 = zext i8 %17384 to i32
  %xor72.10.37 = xor i32 %conv71.10.37, %conv68.10.37
  %conv73.10.37 = trunc i32 %xor72.10.37 to i8
  store i8 %conv73.10.37, i8* %arrayidx70.37, align 1
  %scevgep20.11.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 11
  %17385 = load i8, i8* %scevgep20.11.37, align 1
  %conv68.11.37 = zext i8 %17385 to i32
  %17386 = load i8, i8* %arrayidx70.37, align 1
  %conv71.11.37 = zext i8 %17386 to i32
  %xor72.11.37 = xor i32 %conv71.11.37, %conv68.11.37
  %conv73.11.37 = trunc i32 %xor72.11.37 to i8
  store i8 %conv73.11.37, i8* %arrayidx70.37, align 1
  %scevgep20.12.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 12
  %17387 = load i8, i8* %scevgep20.12.37, align 1
  %conv68.12.37 = zext i8 %17387 to i32
  %17388 = load i8, i8* %arrayidx70.37, align 1
  %conv71.12.37 = zext i8 %17388 to i32
  %xor72.12.37 = xor i32 %conv71.12.37, %conv68.12.37
  %conv73.12.37 = trunc i32 %xor72.12.37 to i8
  store i8 %conv73.12.37, i8* %arrayidx70.37, align 1
  %scevgep20.13.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 13
  %17389 = load i8, i8* %scevgep20.13.37, align 1
  %conv68.13.37 = zext i8 %17389 to i32
  %17390 = load i8, i8* %arrayidx70.37, align 1
  %conv71.13.37 = zext i8 %17390 to i32
  %xor72.13.37 = xor i32 %conv71.13.37, %conv68.13.37
  %conv73.13.37 = trunc i32 %xor72.13.37 to i8
  store i8 %conv73.13.37, i8* %arrayidx70.37, align 1
  %scevgep20.14.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 14
  %17391 = load i8, i8* %scevgep20.14.37, align 1
  %conv68.14.37 = zext i8 %17391 to i32
  %17392 = load i8, i8* %arrayidx70.37, align 1
  %conv71.14.37 = zext i8 %17392 to i32
  %xor72.14.37 = xor i32 %conv71.14.37, %conv68.14.37
  %conv73.14.37 = trunc i32 %xor72.14.37 to i8
  store i8 %conv73.14.37, i8* %arrayidx70.37, align 1
  %scevgep20.15.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 15
  %17393 = load i8, i8* %scevgep20.15.37, align 1
  %conv68.15.37 = zext i8 %17393 to i32
  %17394 = load i8, i8* %arrayidx70.37, align 1
  %conv71.15.37 = zext i8 %17394 to i32
  %xor72.15.37 = xor i32 %conv71.15.37, %conv68.15.37
  %conv73.15.37 = trunc i32 %xor72.15.37 to i8
  store i8 %conv73.15.37, i8* %arrayidx70.37, align 1
  %scevgep20.16.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 16
  %17395 = load i8, i8* %scevgep20.16.37, align 1
  %conv68.16.37 = zext i8 %17395 to i32
  %17396 = load i8, i8* %arrayidx70.37, align 1
  %conv71.16.37 = zext i8 %17396 to i32
  %xor72.16.37 = xor i32 %conv71.16.37, %conv68.16.37
  %conv73.16.37 = trunc i32 %xor72.16.37 to i8
  store i8 %conv73.16.37, i8* %arrayidx70.37, align 1
  %scevgep20.17.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 17
  %17397 = load i8, i8* %scevgep20.17.37, align 1
  %conv68.17.37 = zext i8 %17397 to i32
  %17398 = load i8, i8* %arrayidx70.37, align 1
  %conv71.17.37 = zext i8 %17398 to i32
  %xor72.17.37 = xor i32 %conv71.17.37, %conv68.17.37
  %conv73.17.37 = trunc i32 %xor72.17.37 to i8
  store i8 %conv73.17.37, i8* %arrayidx70.37, align 1
  %scevgep20.18.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 18
  %17399 = load i8, i8* %scevgep20.18.37, align 1
  %conv68.18.37 = zext i8 %17399 to i32
  %17400 = load i8, i8* %arrayidx70.37, align 1
  %conv71.18.37 = zext i8 %17400 to i32
  %xor72.18.37 = xor i32 %conv71.18.37, %conv68.18.37
  %conv73.18.37 = trunc i32 %xor72.18.37 to i8
  store i8 %conv73.18.37, i8* %arrayidx70.37, align 1
  %scevgep20.19.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 19
  %17401 = load i8, i8* %scevgep20.19.37, align 1
  %conv68.19.37 = zext i8 %17401 to i32
  %17402 = load i8, i8* %arrayidx70.37, align 1
  %conv71.19.37 = zext i8 %17402 to i32
  %xor72.19.37 = xor i32 %conv71.19.37, %conv68.19.37
  %conv73.19.37 = trunc i32 %xor72.19.37 to i8
  store i8 %conv73.19.37, i8* %arrayidx70.37, align 1
  %scevgep20.20.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 20
  %17403 = load i8, i8* %scevgep20.20.37, align 1
  %conv68.20.37 = zext i8 %17403 to i32
  %17404 = load i8, i8* %arrayidx70.37, align 1
  %conv71.20.37 = zext i8 %17404 to i32
  %xor72.20.37 = xor i32 %conv71.20.37, %conv68.20.37
  %conv73.20.37 = trunc i32 %xor72.20.37 to i8
  store i8 %conv73.20.37, i8* %arrayidx70.37, align 1
  %scevgep20.21.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 21
  %17405 = load i8, i8* %scevgep20.21.37, align 1
  %conv68.21.37 = zext i8 %17405 to i32
  %17406 = load i8, i8* %arrayidx70.37, align 1
  %conv71.21.37 = zext i8 %17406 to i32
  %xor72.21.37 = xor i32 %conv71.21.37, %conv68.21.37
  %conv73.21.37 = trunc i32 %xor72.21.37 to i8
  store i8 %conv73.21.37, i8* %arrayidx70.37, align 1
  %scevgep20.22.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 22
  %17407 = load i8, i8* %scevgep20.22.37, align 1
  %conv68.22.37 = zext i8 %17407 to i32
  %17408 = load i8, i8* %arrayidx70.37, align 1
  %conv71.22.37 = zext i8 %17408 to i32
  %xor72.22.37 = xor i32 %conv71.22.37, %conv68.22.37
  %conv73.22.37 = trunc i32 %xor72.22.37 to i8
  store i8 %conv73.22.37, i8* %arrayidx70.37, align 1
  %scevgep20.23.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 23
  %17409 = load i8, i8* %scevgep20.23.37, align 1
  %conv68.23.37 = zext i8 %17409 to i32
  %17410 = load i8, i8* %arrayidx70.37, align 1
  %conv71.23.37 = zext i8 %17410 to i32
  %xor72.23.37 = xor i32 %conv71.23.37, %conv68.23.37
  %conv73.23.37 = trunc i32 %xor72.23.37 to i8
  store i8 %conv73.23.37, i8* %arrayidx70.37, align 1
  %scevgep20.24.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 24
  %17411 = load i8, i8* %scevgep20.24.37, align 1
  %conv68.24.37 = zext i8 %17411 to i32
  %17412 = load i8, i8* %arrayidx70.37, align 1
  %conv71.24.37 = zext i8 %17412 to i32
  %xor72.24.37 = xor i32 %conv71.24.37, %conv68.24.37
  %conv73.24.37 = trunc i32 %xor72.24.37 to i8
  store i8 %conv73.24.37, i8* %arrayidx70.37, align 1
  %scevgep20.25.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 25
  %17413 = load i8, i8* %scevgep20.25.37, align 1
  %conv68.25.37 = zext i8 %17413 to i32
  %17414 = load i8, i8* %arrayidx70.37, align 1
  %conv71.25.37 = zext i8 %17414 to i32
  %xor72.25.37 = xor i32 %conv71.25.37, %conv68.25.37
  %conv73.25.37 = trunc i32 %xor72.25.37 to i8
  store i8 %conv73.25.37, i8* %arrayidx70.37, align 1
  %scevgep20.26.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 26
  %17415 = load i8, i8* %scevgep20.26.37, align 1
  %conv68.26.37 = zext i8 %17415 to i32
  %17416 = load i8, i8* %arrayidx70.37, align 1
  %conv71.26.37 = zext i8 %17416 to i32
  %xor72.26.37 = xor i32 %conv71.26.37, %conv68.26.37
  %conv73.26.37 = trunc i32 %xor72.26.37 to i8
  store i8 %conv73.26.37, i8* %arrayidx70.37, align 1
  %scevgep20.27.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 27
  %17417 = load i8, i8* %scevgep20.27.37, align 1
  %conv68.27.37 = zext i8 %17417 to i32
  %17418 = load i8, i8* %arrayidx70.37, align 1
  %conv71.27.37 = zext i8 %17418 to i32
  %xor72.27.37 = xor i32 %conv71.27.37, %conv68.27.37
  %conv73.27.37 = trunc i32 %xor72.27.37 to i8
  store i8 %conv73.27.37, i8* %arrayidx70.37, align 1
  %scevgep20.28.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 28
  %17419 = load i8, i8* %scevgep20.28.37, align 1
  %conv68.28.37 = zext i8 %17419 to i32
  %17420 = load i8, i8* %arrayidx70.37, align 1
  %conv71.28.37 = zext i8 %17420 to i32
  %xor72.28.37 = xor i32 %conv71.28.37, %conv68.28.37
  %conv73.28.37 = trunc i32 %xor72.28.37 to i8
  store i8 %conv73.28.37, i8* %arrayidx70.37, align 1
  %scevgep20.29.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 29
  %17421 = load i8, i8* %scevgep20.29.37, align 1
  %conv68.29.37 = zext i8 %17421 to i32
  %17422 = load i8, i8* %arrayidx70.37, align 1
  %conv71.29.37 = zext i8 %17422 to i32
  %xor72.29.37 = xor i32 %conv71.29.37, %conv68.29.37
  %conv73.29.37 = trunc i32 %xor72.29.37 to i8
  store i8 %conv73.29.37, i8* %arrayidx70.37, align 1
  %scevgep20.30.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 30
  %17423 = load i8, i8* %scevgep20.30.37, align 1
  %conv68.30.37 = zext i8 %17423 to i32
  %17424 = load i8, i8* %arrayidx70.37, align 1
  %conv71.30.37 = zext i8 %17424 to i32
  %xor72.30.37 = xor i32 %conv71.30.37, %conv68.30.37
  %conv73.30.37 = trunc i32 %xor72.30.37 to i8
  store i8 %conv73.30.37, i8* %arrayidx70.37, align 1
  %scevgep20.31.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 31
  %17425 = load i8, i8* %scevgep20.31.37, align 1
  %conv68.31.37 = zext i8 %17425 to i32
  %17426 = load i8, i8* %arrayidx70.37, align 1
  %conv71.31.37 = zext i8 %17426 to i32
  %xor72.31.37 = xor i32 %conv71.31.37, %conv68.31.37
  %conv73.31.37 = trunc i32 %xor72.31.37 to i8
  store i8 %conv73.31.37, i8* %arrayidx70.37, align 1
  %scevgep20.32.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 32
  %17427 = load i8, i8* %scevgep20.32.37, align 1
  %conv68.32.37 = zext i8 %17427 to i32
  %17428 = load i8, i8* %arrayidx70.37, align 1
  %conv71.32.37 = zext i8 %17428 to i32
  %xor72.32.37 = xor i32 %conv71.32.37, %conv68.32.37
  %conv73.32.37 = trunc i32 %xor72.32.37 to i8
  store i8 %conv73.32.37, i8* %arrayidx70.37, align 1
  %scevgep20.33.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 33
  %17429 = load i8, i8* %scevgep20.33.37, align 1
  %conv68.33.37 = zext i8 %17429 to i32
  %17430 = load i8, i8* %arrayidx70.37, align 1
  %conv71.33.37 = zext i8 %17430 to i32
  %xor72.33.37 = xor i32 %conv71.33.37, %conv68.33.37
  %conv73.33.37 = trunc i32 %xor72.33.37 to i8
  store i8 %conv73.33.37, i8* %arrayidx70.37, align 1
  %scevgep20.34.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 34
  %17431 = load i8, i8* %scevgep20.34.37, align 1
  %conv68.34.37 = zext i8 %17431 to i32
  %17432 = load i8, i8* %arrayidx70.37, align 1
  %conv71.34.37 = zext i8 %17432 to i32
  %xor72.34.37 = xor i32 %conv71.34.37, %conv68.34.37
  %conv73.34.37 = trunc i32 %xor72.34.37 to i8
  store i8 %conv73.34.37, i8* %arrayidx70.37, align 1
  %scevgep20.35.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 35
  %17433 = load i8, i8* %scevgep20.35.37, align 1
  %conv68.35.37 = zext i8 %17433 to i32
  %17434 = load i8, i8* %arrayidx70.37, align 1
  %conv71.35.37 = zext i8 %17434 to i32
  %xor72.35.37 = xor i32 %conv71.35.37, %conv68.35.37
  %conv73.35.37 = trunc i32 %xor72.35.37 to i8
  store i8 %conv73.35.37, i8* %arrayidx70.37, align 1
  %scevgep20.36.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 36
  %17435 = load i8, i8* %scevgep20.36.37, align 1
  %conv68.36.37 = zext i8 %17435 to i32
  %17436 = load i8, i8* %arrayidx70.37, align 1
  %conv71.36.37 = zext i8 %17436 to i32
  %xor72.36.37 = xor i32 %conv71.36.37, %conv68.36.37
  %conv73.36.37 = trunc i32 %xor72.36.37 to i8
  store i8 %conv73.36.37, i8* %arrayidx70.37, align 1
  %scevgep20.38.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 38
  %17437 = load i8, i8* %scevgep20.38.37, align 1
  %conv68.38.37 = zext i8 %17437 to i32
  %17438 = load i8, i8* %arrayidx70.37, align 1
  %conv71.38.37 = zext i8 %17438 to i32
  %xor72.38.37 = xor i32 %conv71.38.37, %conv68.38.37
  %conv73.38.37 = trunc i32 %xor72.38.37 to i8
  store i8 %conv73.38.37, i8* %arrayidx70.37, align 1
  %scevgep20.39.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 39
  %17439 = load i8, i8* %scevgep20.39.37, align 1
  %conv68.39.37 = zext i8 %17439 to i32
  %17440 = load i8, i8* %arrayidx70.37, align 1
  %conv71.39.37 = zext i8 %17440 to i32
  %xor72.39.37 = xor i32 %conv71.39.37, %conv68.39.37
  %conv73.39.37 = trunc i32 %xor72.39.37 to i8
  store i8 %conv73.39.37, i8* %arrayidx70.37, align 1
  %scevgep20.40.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 40
  %17441 = load i8, i8* %scevgep20.40.37, align 1
  %conv68.40.37 = zext i8 %17441 to i32
  %17442 = load i8, i8* %arrayidx70.37, align 1
  %conv71.40.37 = zext i8 %17442 to i32
  %xor72.40.37 = xor i32 %conv71.40.37, %conv68.40.37
  %conv73.40.37 = trunc i32 %xor72.40.37 to i8
  store i8 %conv73.40.37, i8* %arrayidx70.37, align 1
  %scevgep20.41.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 41
  %17443 = load i8, i8* %scevgep20.41.37, align 1
  %conv68.41.37 = zext i8 %17443 to i32
  %17444 = load i8, i8* %arrayidx70.37, align 1
  %conv71.41.37 = zext i8 %17444 to i32
  %xor72.41.37 = xor i32 %conv71.41.37, %conv68.41.37
  %conv73.41.37 = trunc i32 %xor72.41.37 to i8
  store i8 %conv73.41.37, i8* %arrayidx70.37, align 1
  %scevgep20.42.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 42
  %17445 = load i8, i8* %scevgep20.42.37, align 1
  %conv68.42.37 = zext i8 %17445 to i32
  %17446 = load i8, i8* %arrayidx70.37, align 1
  %conv71.42.37 = zext i8 %17446 to i32
  %xor72.42.37 = xor i32 %conv71.42.37, %conv68.42.37
  %conv73.42.37 = trunc i32 %xor72.42.37 to i8
  store i8 %conv73.42.37, i8* %arrayidx70.37, align 1
  %scevgep20.43.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 43
  %17447 = load i8, i8* %scevgep20.43.37, align 1
  %conv68.43.37 = zext i8 %17447 to i32
  %17448 = load i8, i8* %arrayidx70.37, align 1
  %conv71.43.37 = zext i8 %17448 to i32
  %xor72.43.37 = xor i32 %conv71.43.37, %conv68.43.37
  %conv73.43.37 = trunc i32 %xor72.43.37 to i8
  store i8 %conv73.43.37, i8* %arrayidx70.37, align 1
  %scevgep20.44.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 44
  %17449 = load i8, i8* %scevgep20.44.37, align 1
  %conv68.44.37 = zext i8 %17449 to i32
  %17450 = load i8, i8* %arrayidx70.37, align 1
  %conv71.44.37 = zext i8 %17450 to i32
  %xor72.44.37 = xor i32 %conv71.44.37, %conv68.44.37
  %conv73.44.37 = trunc i32 %xor72.44.37 to i8
  store i8 %conv73.44.37, i8* %arrayidx70.37, align 1
  %scevgep20.45.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 45
  %17451 = load i8, i8* %scevgep20.45.37, align 1
  %conv68.45.37 = zext i8 %17451 to i32
  %17452 = load i8, i8* %arrayidx70.37, align 1
  %conv71.45.37 = zext i8 %17452 to i32
  %xor72.45.37 = xor i32 %conv71.45.37, %conv68.45.37
  %conv73.45.37 = trunc i32 %xor72.45.37 to i8
  store i8 %conv73.45.37, i8* %arrayidx70.37, align 1
  %scevgep20.46.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 46
  %17453 = load i8, i8* %scevgep20.46.37, align 1
  %conv68.46.37 = zext i8 %17453 to i32
  %17454 = load i8, i8* %arrayidx70.37, align 1
  %conv71.46.37 = zext i8 %17454 to i32
  %xor72.46.37 = xor i32 %conv71.46.37, %conv68.46.37
  %conv73.46.37 = trunc i32 %xor72.46.37 to i8
  store i8 %conv73.46.37, i8* %arrayidx70.37, align 1
  %scevgep20.47.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 47
  %17455 = load i8, i8* %scevgep20.47.37, align 1
  %conv68.47.37 = zext i8 %17455 to i32
  %17456 = load i8, i8* %arrayidx70.37, align 1
  %conv71.47.37 = zext i8 %17456 to i32
  %xor72.47.37 = xor i32 %conv71.47.37, %conv68.47.37
  %conv73.47.37 = trunc i32 %xor72.47.37 to i8
  store i8 %conv73.47.37, i8* %arrayidx70.37, align 1
  %scevgep20.48.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 48
  %17457 = load i8, i8* %scevgep20.48.37, align 1
  %conv68.48.37 = zext i8 %17457 to i32
  %17458 = load i8, i8* %arrayidx70.37, align 1
  %conv71.48.37 = zext i8 %17458 to i32
  %xor72.48.37 = xor i32 %conv71.48.37, %conv68.48.37
  %conv73.48.37 = trunc i32 %xor72.48.37 to i8
  store i8 %conv73.48.37, i8* %arrayidx70.37, align 1
  %scevgep20.49.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 49
  %17459 = load i8, i8* %scevgep20.49.37, align 1
  %conv68.49.37 = zext i8 %17459 to i32
  %17460 = load i8, i8* %arrayidx70.37, align 1
  %conv71.49.37 = zext i8 %17460 to i32
  %xor72.49.37 = xor i32 %conv71.49.37, %conv68.49.37
  %conv73.49.37 = trunc i32 %xor72.49.37 to i8
  store i8 %conv73.49.37, i8* %arrayidx70.37, align 1
  %scevgep20.50.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 50
  %17461 = load i8, i8* %scevgep20.50.37, align 1
  %conv68.50.37 = zext i8 %17461 to i32
  %17462 = load i8, i8* %arrayidx70.37, align 1
  %conv71.50.37 = zext i8 %17462 to i32
  %xor72.50.37 = xor i32 %conv71.50.37, %conv68.50.37
  %conv73.50.37 = trunc i32 %xor72.50.37 to i8
  store i8 %conv73.50.37, i8* %arrayidx70.37, align 1
  %scevgep20.51.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 51
  %17463 = load i8, i8* %scevgep20.51.37, align 1
  %conv68.51.37 = zext i8 %17463 to i32
  %17464 = load i8, i8* %arrayidx70.37, align 1
  %conv71.51.37 = zext i8 %17464 to i32
  %xor72.51.37 = xor i32 %conv71.51.37, %conv68.51.37
  %conv73.51.37 = trunc i32 %xor72.51.37 to i8
  store i8 %conv73.51.37, i8* %arrayidx70.37, align 1
  %scevgep20.52.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 52
  %17465 = load i8, i8* %scevgep20.52.37, align 1
  %conv68.52.37 = zext i8 %17465 to i32
  %17466 = load i8, i8* %arrayidx70.37, align 1
  %conv71.52.37 = zext i8 %17466 to i32
  %xor72.52.37 = xor i32 %conv71.52.37, %conv68.52.37
  %conv73.52.37 = trunc i32 %xor72.52.37 to i8
  store i8 %conv73.52.37, i8* %arrayidx70.37, align 1
  %scevgep20.53.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 53
  %17467 = load i8, i8* %scevgep20.53.37, align 1
  %conv68.53.37 = zext i8 %17467 to i32
  %17468 = load i8, i8* %arrayidx70.37, align 1
  %conv71.53.37 = zext i8 %17468 to i32
  %xor72.53.37 = xor i32 %conv71.53.37, %conv68.53.37
  %conv73.53.37 = trunc i32 %xor72.53.37 to i8
  store i8 %conv73.53.37, i8* %arrayidx70.37, align 1
  %scevgep20.54.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 54
  %17469 = load i8, i8* %scevgep20.54.37, align 1
  %conv68.54.37 = zext i8 %17469 to i32
  %17470 = load i8, i8* %arrayidx70.37, align 1
  %conv71.54.37 = zext i8 %17470 to i32
  %xor72.54.37 = xor i32 %conv71.54.37, %conv68.54.37
  %conv73.54.37 = trunc i32 %xor72.54.37 to i8
  store i8 %conv73.54.37, i8* %arrayidx70.37, align 1
  %scevgep20.55.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 55
  %17471 = load i8, i8* %scevgep20.55.37, align 1
  %conv68.55.37 = zext i8 %17471 to i32
  %17472 = load i8, i8* %arrayidx70.37, align 1
  %conv71.55.37 = zext i8 %17472 to i32
  %xor72.55.37 = xor i32 %conv71.55.37, %conv68.55.37
  %conv73.55.37 = trunc i32 %xor72.55.37 to i8
  store i8 %conv73.55.37, i8* %arrayidx70.37, align 1
  %scevgep20.56.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 56
  %17473 = load i8, i8* %scevgep20.56.37, align 1
  %conv68.56.37 = zext i8 %17473 to i32
  %17474 = load i8, i8* %arrayidx70.37, align 1
  %conv71.56.37 = zext i8 %17474 to i32
  %xor72.56.37 = xor i32 %conv71.56.37, %conv68.56.37
  %conv73.56.37 = trunc i32 %xor72.56.37 to i8
  store i8 %conv73.56.37, i8* %arrayidx70.37, align 1
  %scevgep20.57.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 57
  %17475 = load i8, i8* %scevgep20.57.37, align 1
  %conv68.57.37 = zext i8 %17475 to i32
  %17476 = load i8, i8* %arrayidx70.37, align 1
  %conv71.57.37 = zext i8 %17476 to i32
  %xor72.57.37 = xor i32 %conv71.57.37, %conv68.57.37
  %conv73.57.37 = trunc i32 %xor72.57.37 to i8
  store i8 %conv73.57.37, i8* %arrayidx70.37, align 1
  %scevgep20.58.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 58
  %17477 = load i8, i8* %scevgep20.58.37, align 1
  %conv68.58.37 = zext i8 %17477 to i32
  %17478 = load i8, i8* %arrayidx70.37, align 1
  %conv71.58.37 = zext i8 %17478 to i32
  %xor72.58.37 = xor i32 %conv71.58.37, %conv68.58.37
  %conv73.58.37 = trunc i32 %xor72.58.37 to i8
  store i8 %conv73.58.37, i8* %arrayidx70.37, align 1
  %scevgep20.59.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 59
  %17479 = load i8, i8* %scevgep20.59.37, align 1
  %conv68.59.37 = zext i8 %17479 to i32
  %17480 = load i8, i8* %arrayidx70.37, align 1
  %conv71.59.37 = zext i8 %17480 to i32
  %xor72.59.37 = xor i32 %conv71.59.37, %conv68.59.37
  %conv73.59.37 = trunc i32 %xor72.59.37 to i8
  store i8 %conv73.59.37, i8* %arrayidx70.37, align 1
  %scevgep20.60.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 0, i64 60
  %17481 = load i8, i8* %scevgep20.60.37, align 1
  %conv68.60.37 = zext i8 %17481 to i32
  %17482 = load i8, i8* %arrayidx70.37, align 1
  %conv71.60.37 = zext i8 %17482 to i32
  %xor72.60.37 = xor i32 %conv71.60.37, %conv68.60.37
  %conv73.60.37 = trunc i32 %xor72.60.37 to i8
  store i8 %conv73.60.37, i8* %arrayidx70.37, align 1
  %scevgep19.37 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17360, i64 0, i64 1, i64 0
  %17483 = bitcast i8* %scevgep19.37 to [61 x [61 x i8]]*
  %arrayidx51.38 = getelementptr inbounds i8, i8* %a, i64 38
  %17484 = load i8, i8* %arrayidx51.38, align 1
  %arrayidx53.38 = getelementptr inbounds i8, i8* %b, i64 38
  %17485 = load i8, i8* %arrayidx53.38, align 1
  %call54.38 = call zeroext i8 @mult(i8 zeroext %17484, i8 zeroext %17485)
  %arrayidx56.38 = getelementptr inbounds i8, i8* %c, i64 38
  store i8 %call54.38, i8* %arrayidx56.38, align 1
  %arrayidx70.38 = getelementptr inbounds i8, i8* %c, i64 38
  %scevgep20.38424 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 0
  %17486 = load i8, i8* %scevgep20.38424, align 1
  %conv68.38425 = zext i8 %17486 to i32
  %17487 = load i8, i8* %arrayidx70.38, align 1
  %conv71.38426 = zext i8 %17487 to i32
  %xor72.38427 = xor i32 %conv71.38426, %conv68.38425
  %conv73.38428 = trunc i32 %xor72.38427 to i8
  store i8 %conv73.38428, i8* %arrayidx70.38, align 1
  %scevgep20.1.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 1
  %17488 = load i8, i8* %scevgep20.1.38, align 1
  %conv68.1.38 = zext i8 %17488 to i32
  %17489 = load i8, i8* %arrayidx70.38, align 1
  %conv71.1.38 = zext i8 %17489 to i32
  %xor72.1.38 = xor i32 %conv71.1.38, %conv68.1.38
  %conv73.1.38 = trunc i32 %xor72.1.38 to i8
  store i8 %conv73.1.38, i8* %arrayidx70.38, align 1
  %scevgep20.2.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 2
  %17490 = load i8, i8* %scevgep20.2.38, align 1
  %conv68.2.38 = zext i8 %17490 to i32
  %17491 = load i8, i8* %arrayidx70.38, align 1
  %conv71.2.38 = zext i8 %17491 to i32
  %xor72.2.38 = xor i32 %conv71.2.38, %conv68.2.38
  %conv73.2.38 = trunc i32 %xor72.2.38 to i8
  store i8 %conv73.2.38, i8* %arrayidx70.38, align 1
  %scevgep20.3.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 3
  %17492 = load i8, i8* %scevgep20.3.38, align 1
  %conv68.3.38 = zext i8 %17492 to i32
  %17493 = load i8, i8* %arrayidx70.38, align 1
  %conv71.3.38 = zext i8 %17493 to i32
  %xor72.3.38 = xor i32 %conv71.3.38, %conv68.3.38
  %conv73.3.38 = trunc i32 %xor72.3.38 to i8
  store i8 %conv73.3.38, i8* %arrayidx70.38, align 1
  %scevgep20.4.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 4
  %17494 = load i8, i8* %scevgep20.4.38, align 1
  %conv68.4.38 = zext i8 %17494 to i32
  %17495 = load i8, i8* %arrayidx70.38, align 1
  %conv71.4.38 = zext i8 %17495 to i32
  %xor72.4.38 = xor i32 %conv71.4.38, %conv68.4.38
  %conv73.4.38 = trunc i32 %xor72.4.38 to i8
  store i8 %conv73.4.38, i8* %arrayidx70.38, align 1
  %scevgep20.5.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 5
  %17496 = load i8, i8* %scevgep20.5.38, align 1
  %conv68.5.38 = zext i8 %17496 to i32
  %17497 = load i8, i8* %arrayidx70.38, align 1
  %conv71.5.38 = zext i8 %17497 to i32
  %xor72.5.38 = xor i32 %conv71.5.38, %conv68.5.38
  %conv73.5.38 = trunc i32 %xor72.5.38 to i8
  store i8 %conv73.5.38, i8* %arrayidx70.38, align 1
  %scevgep20.6.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 6
  %17498 = load i8, i8* %scevgep20.6.38, align 1
  %conv68.6.38 = zext i8 %17498 to i32
  %17499 = load i8, i8* %arrayidx70.38, align 1
  %conv71.6.38 = zext i8 %17499 to i32
  %xor72.6.38 = xor i32 %conv71.6.38, %conv68.6.38
  %conv73.6.38 = trunc i32 %xor72.6.38 to i8
  store i8 %conv73.6.38, i8* %arrayidx70.38, align 1
  %scevgep20.7.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 7
  %17500 = load i8, i8* %scevgep20.7.38, align 1
  %conv68.7.38 = zext i8 %17500 to i32
  %17501 = load i8, i8* %arrayidx70.38, align 1
  %conv71.7.38 = zext i8 %17501 to i32
  %xor72.7.38 = xor i32 %conv71.7.38, %conv68.7.38
  %conv73.7.38 = trunc i32 %xor72.7.38 to i8
  store i8 %conv73.7.38, i8* %arrayidx70.38, align 1
  %scevgep20.8.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 8
  %17502 = load i8, i8* %scevgep20.8.38, align 1
  %conv68.8.38 = zext i8 %17502 to i32
  %17503 = load i8, i8* %arrayidx70.38, align 1
  %conv71.8.38 = zext i8 %17503 to i32
  %xor72.8.38 = xor i32 %conv71.8.38, %conv68.8.38
  %conv73.8.38 = trunc i32 %xor72.8.38 to i8
  store i8 %conv73.8.38, i8* %arrayidx70.38, align 1
  %scevgep20.9.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 9
  %17504 = load i8, i8* %scevgep20.9.38, align 1
  %conv68.9.38 = zext i8 %17504 to i32
  %17505 = load i8, i8* %arrayidx70.38, align 1
  %conv71.9.38 = zext i8 %17505 to i32
  %xor72.9.38 = xor i32 %conv71.9.38, %conv68.9.38
  %conv73.9.38 = trunc i32 %xor72.9.38 to i8
  store i8 %conv73.9.38, i8* %arrayidx70.38, align 1
  %scevgep20.10.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 10
  %17506 = load i8, i8* %scevgep20.10.38, align 1
  %conv68.10.38 = zext i8 %17506 to i32
  %17507 = load i8, i8* %arrayidx70.38, align 1
  %conv71.10.38 = zext i8 %17507 to i32
  %xor72.10.38 = xor i32 %conv71.10.38, %conv68.10.38
  %conv73.10.38 = trunc i32 %xor72.10.38 to i8
  store i8 %conv73.10.38, i8* %arrayidx70.38, align 1
  %scevgep20.11.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 11
  %17508 = load i8, i8* %scevgep20.11.38, align 1
  %conv68.11.38 = zext i8 %17508 to i32
  %17509 = load i8, i8* %arrayidx70.38, align 1
  %conv71.11.38 = zext i8 %17509 to i32
  %xor72.11.38 = xor i32 %conv71.11.38, %conv68.11.38
  %conv73.11.38 = trunc i32 %xor72.11.38 to i8
  store i8 %conv73.11.38, i8* %arrayidx70.38, align 1
  %scevgep20.12.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 12
  %17510 = load i8, i8* %scevgep20.12.38, align 1
  %conv68.12.38 = zext i8 %17510 to i32
  %17511 = load i8, i8* %arrayidx70.38, align 1
  %conv71.12.38 = zext i8 %17511 to i32
  %xor72.12.38 = xor i32 %conv71.12.38, %conv68.12.38
  %conv73.12.38 = trunc i32 %xor72.12.38 to i8
  store i8 %conv73.12.38, i8* %arrayidx70.38, align 1
  %scevgep20.13.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 13
  %17512 = load i8, i8* %scevgep20.13.38, align 1
  %conv68.13.38 = zext i8 %17512 to i32
  %17513 = load i8, i8* %arrayidx70.38, align 1
  %conv71.13.38 = zext i8 %17513 to i32
  %xor72.13.38 = xor i32 %conv71.13.38, %conv68.13.38
  %conv73.13.38 = trunc i32 %xor72.13.38 to i8
  store i8 %conv73.13.38, i8* %arrayidx70.38, align 1
  %scevgep20.14.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 14
  %17514 = load i8, i8* %scevgep20.14.38, align 1
  %conv68.14.38 = zext i8 %17514 to i32
  %17515 = load i8, i8* %arrayidx70.38, align 1
  %conv71.14.38 = zext i8 %17515 to i32
  %xor72.14.38 = xor i32 %conv71.14.38, %conv68.14.38
  %conv73.14.38 = trunc i32 %xor72.14.38 to i8
  store i8 %conv73.14.38, i8* %arrayidx70.38, align 1
  %scevgep20.15.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 15
  %17516 = load i8, i8* %scevgep20.15.38, align 1
  %conv68.15.38 = zext i8 %17516 to i32
  %17517 = load i8, i8* %arrayidx70.38, align 1
  %conv71.15.38 = zext i8 %17517 to i32
  %xor72.15.38 = xor i32 %conv71.15.38, %conv68.15.38
  %conv73.15.38 = trunc i32 %xor72.15.38 to i8
  store i8 %conv73.15.38, i8* %arrayidx70.38, align 1
  %scevgep20.16.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 16
  %17518 = load i8, i8* %scevgep20.16.38, align 1
  %conv68.16.38 = zext i8 %17518 to i32
  %17519 = load i8, i8* %arrayidx70.38, align 1
  %conv71.16.38 = zext i8 %17519 to i32
  %xor72.16.38 = xor i32 %conv71.16.38, %conv68.16.38
  %conv73.16.38 = trunc i32 %xor72.16.38 to i8
  store i8 %conv73.16.38, i8* %arrayidx70.38, align 1
  %scevgep20.17.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 17
  %17520 = load i8, i8* %scevgep20.17.38, align 1
  %conv68.17.38 = zext i8 %17520 to i32
  %17521 = load i8, i8* %arrayidx70.38, align 1
  %conv71.17.38 = zext i8 %17521 to i32
  %xor72.17.38 = xor i32 %conv71.17.38, %conv68.17.38
  %conv73.17.38 = trunc i32 %xor72.17.38 to i8
  store i8 %conv73.17.38, i8* %arrayidx70.38, align 1
  %scevgep20.18.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 18
  %17522 = load i8, i8* %scevgep20.18.38, align 1
  %conv68.18.38 = zext i8 %17522 to i32
  %17523 = load i8, i8* %arrayidx70.38, align 1
  %conv71.18.38 = zext i8 %17523 to i32
  %xor72.18.38 = xor i32 %conv71.18.38, %conv68.18.38
  %conv73.18.38 = trunc i32 %xor72.18.38 to i8
  store i8 %conv73.18.38, i8* %arrayidx70.38, align 1
  %scevgep20.19.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 19
  %17524 = load i8, i8* %scevgep20.19.38, align 1
  %conv68.19.38 = zext i8 %17524 to i32
  %17525 = load i8, i8* %arrayidx70.38, align 1
  %conv71.19.38 = zext i8 %17525 to i32
  %xor72.19.38 = xor i32 %conv71.19.38, %conv68.19.38
  %conv73.19.38 = trunc i32 %xor72.19.38 to i8
  store i8 %conv73.19.38, i8* %arrayidx70.38, align 1
  %scevgep20.20.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 20
  %17526 = load i8, i8* %scevgep20.20.38, align 1
  %conv68.20.38 = zext i8 %17526 to i32
  %17527 = load i8, i8* %arrayidx70.38, align 1
  %conv71.20.38 = zext i8 %17527 to i32
  %xor72.20.38 = xor i32 %conv71.20.38, %conv68.20.38
  %conv73.20.38 = trunc i32 %xor72.20.38 to i8
  store i8 %conv73.20.38, i8* %arrayidx70.38, align 1
  %scevgep20.21.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 21
  %17528 = load i8, i8* %scevgep20.21.38, align 1
  %conv68.21.38 = zext i8 %17528 to i32
  %17529 = load i8, i8* %arrayidx70.38, align 1
  %conv71.21.38 = zext i8 %17529 to i32
  %xor72.21.38 = xor i32 %conv71.21.38, %conv68.21.38
  %conv73.21.38 = trunc i32 %xor72.21.38 to i8
  store i8 %conv73.21.38, i8* %arrayidx70.38, align 1
  %scevgep20.22.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 22
  %17530 = load i8, i8* %scevgep20.22.38, align 1
  %conv68.22.38 = zext i8 %17530 to i32
  %17531 = load i8, i8* %arrayidx70.38, align 1
  %conv71.22.38 = zext i8 %17531 to i32
  %xor72.22.38 = xor i32 %conv71.22.38, %conv68.22.38
  %conv73.22.38 = trunc i32 %xor72.22.38 to i8
  store i8 %conv73.22.38, i8* %arrayidx70.38, align 1
  %scevgep20.23.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 23
  %17532 = load i8, i8* %scevgep20.23.38, align 1
  %conv68.23.38 = zext i8 %17532 to i32
  %17533 = load i8, i8* %arrayidx70.38, align 1
  %conv71.23.38 = zext i8 %17533 to i32
  %xor72.23.38 = xor i32 %conv71.23.38, %conv68.23.38
  %conv73.23.38 = trunc i32 %xor72.23.38 to i8
  store i8 %conv73.23.38, i8* %arrayidx70.38, align 1
  %scevgep20.24.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 24
  %17534 = load i8, i8* %scevgep20.24.38, align 1
  %conv68.24.38 = zext i8 %17534 to i32
  %17535 = load i8, i8* %arrayidx70.38, align 1
  %conv71.24.38 = zext i8 %17535 to i32
  %xor72.24.38 = xor i32 %conv71.24.38, %conv68.24.38
  %conv73.24.38 = trunc i32 %xor72.24.38 to i8
  store i8 %conv73.24.38, i8* %arrayidx70.38, align 1
  %scevgep20.25.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 25
  %17536 = load i8, i8* %scevgep20.25.38, align 1
  %conv68.25.38 = zext i8 %17536 to i32
  %17537 = load i8, i8* %arrayidx70.38, align 1
  %conv71.25.38 = zext i8 %17537 to i32
  %xor72.25.38 = xor i32 %conv71.25.38, %conv68.25.38
  %conv73.25.38 = trunc i32 %xor72.25.38 to i8
  store i8 %conv73.25.38, i8* %arrayidx70.38, align 1
  %scevgep20.26.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 26
  %17538 = load i8, i8* %scevgep20.26.38, align 1
  %conv68.26.38 = zext i8 %17538 to i32
  %17539 = load i8, i8* %arrayidx70.38, align 1
  %conv71.26.38 = zext i8 %17539 to i32
  %xor72.26.38 = xor i32 %conv71.26.38, %conv68.26.38
  %conv73.26.38 = trunc i32 %xor72.26.38 to i8
  store i8 %conv73.26.38, i8* %arrayidx70.38, align 1
  %scevgep20.27.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 27
  %17540 = load i8, i8* %scevgep20.27.38, align 1
  %conv68.27.38 = zext i8 %17540 to i32
  %17541 = load i8, i8* %arrayidx70.38, align 1
  %conv71.27.38 = zext i8 %17541 to i32
  %xor72.27.38 = xor i32 %conv71.27.38, %conv68.27.38
  %conv73.27.38 = trunc i32 %xor72.27.38 to i8
  store i8 %conv73.27.38, i8* %arrayidx70.38, align 1
  %scevgep20.28.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 28
  %17542 = load i8, i8* %scevgep20.28.38, align 1
  %conv68.28.38 = zext i8 %17542 to i32
  %17543 = load i8, i8* %arrayidx70.38, align 1
  %conv71.28.38 = zext i8 %17543 to i32
  %xor72.28.38 = xor i32 %conv71.28.38, %conv68.28.38
  %conv73.28.38 = trunc i32 %xor72.28.38 to i8
  store i8 %conv73.28.38, i8* %arrayidx70.38, align 1
  %scevgep20.29.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 29
  %17544 = load i8, i8* %scevgep20.29.38, align 1
  %conv68.29.38 = zext i8 %17544 to i32
  %17545 = load i8, i8* %arrayidx70.38, align 1
  %conv71.29.38 = zext i8 %17545 to i32
  %xor72.29.38 = xor i32 %conv71.29.38, %conv68.29.38
  %conv73.29.38 = trunc i32 %xor72.29.38 to i8
  store i8 %conv73.29.38, i8* %arrayidx70.38, align 1
  %scevgep20.30.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 30
  %17546 = load i8, i8* %scevgep20.30.38, align 1
  %conv68.30.38 = zext i8 %17546 to i32
  %17547 = load i8, i8* %arrayidx70.38, align 1
  %conv71.30.38 = zext i8 %17547 to i32
  %xor72.30.38 = xor i32 %conv71.30.38, %conv68.30.38
  %conv73.30.38 = trunc i32 %xor72.30.38 to i8
  store i8 %conv73.30.38, i8* %arrayidx70.38, align 1
  %scevgep20.31.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 31
  %17548 = load i8, i8* %scevgep20.31.38, align 1
  %conv68.31.38 = zext i8 %17548 to i32
  %17549 = load i8, i8* %arrayidx70.38, align 1
  %conv71.31.38 = zext i8 %17549 to i32
  %xor72.31.38 = xor i32 %conv71.31.38, %conv68.31.38
  %conv73.31.38 = trunc i32 %xor72.31.38 to i8
  store i8 %conv73.31.38, i8* %arrayidx70.38, align 1
  %scevgep20.32.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 32
  %17550 = load i8, i8* %scevgep20.32.38, align 1
  %conv68.32.38 = zext i8 %17550 to i32
  %17551 = load i8, i8* %arrayidx70.38, align 1
  %conv71.32.38 = zext i8 %17551 to i32
  %xor72.32.38 = xor i32 %conv71.32.38, %conv68.32.38
  %conv73.32.38 = trunc i32 %xor72.32.38 to i8
  store i8 %conv73.32.38, i8* %arrayidx70.38, align 1
  %scevgep20.33.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 33
  %17552 = load i8, i8* %scevgep20.33.38, align 1
  %conv68.33.38 = zext i8 %17552 to i32
  %17553 = load i8, i8* %arrayidx70.38, align 1
  %conv71.33.38 = zext i8 %17553 to i32
  %xor72.33.38 = xor i32 %conv71.33.38, %conv68.33.38
  %conv73.33.38 = trunc i32 %xor72.33.38 to i8
  store i8 %conv73.33.38, i8* %arrayidx70.38, align 1
  %scevgep20.34.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 34
  %17554 = load i8, i8* %scevgep20.34.38, align 1
  %conv68.34.38 = zext i8 %17554 to i32
  %17555 = load i8, i8* %arrayidx70.38, align 1
  %conv71.34.38 = zext i8 %17555 to i32
  %xor72.34.38 = xor i32 %conv71.34.38, %conv68.34.38
  %conv73.34.38 = trunc i32 %xor72.34.38 to i8
  store i8 %conv73.34.38, i8* %arrayidx70.38, align 1
  %scevgep20.35.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 35
  %17556 = load i8, i8* %scevgep20.35.38, align 1
  %conv68.35.38 = zext i8 %17556 to i32
  %17557 = load i8, i8* %arrayidx70.38, align 1
  %conv71.35.38 = zext i8 %17557 to i32
  %xor72.35.38 = xor i32 %conv71.35.38, %conv68.35.38
  %conv73.35.38 = trunc i32 %xor72.35.38 to i8
  store i8 %conv73.35.38, i8* %arrayidx70.38, align 1
  %scevgep20.36.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 36
  %17558 = load i8, i8* %scevgep20.36.38, align 1
  %conv68.36.38 = zext i8 %17558 to i32
  %17559 = load i8, i8* %arrayidx70.38, align 1
  %conv71.36.38 = zext i8 %17559 to i32
  %xor72.36.38 = xor i32 %conv71.36.38, %conv68.36.38
  %conv73.36.38 = trunc i32 %xor72.36.38 to i8
  store i8 %conv73.36.38, i8* %arrayidx70.38, align 1
  %scevgep20.37.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 37
  %17560 = load i8, i8* %scevgep20.37.38, align 1
  %conv68.37.38 = zext i8 %17560 to i32
  %17561 = load i8, i8* %arrayidx70.38, align 1
  %conv71.37.38 = zext i8 %17561 to i32
  %xor72.37.38 = xor i32 %conv71.37.38, %conv68.37.38
  %conv73.37.38 = trunc i32 %xor72.37.38 to i8
  store i8 %conv73.37.38, i8* %arrayidx70.38, align 1
  %scevgep20.39.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 39
  %17562 = load i8, i8* %scevgep20.39.38, align 1
  %conv68.39.38 = zext i8 %17562 to i32
  %17563 = load i8, i8* %arrayidx70.38, align 1
  %conv71.39.38 = zext i8 %17563 to i32
  %xor72.39.38 = xor i32 %conv71.39.38, %conv68.39.38
  %conv73.39.38 = trunc i32 %xor72.39.38 to i8
  store i8 %conv73.39.38, i8* %arrayidx70.38, align 1
  %scevgep20.40.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 40
  %17564 = load i8, i8* %scevgep20.40.38, align 1
  %conv68.40.38 = zext i8 %17564 to i32
  %17565 = load i8, i8* %arrayidx70.38, align 1
  %conv71.40.38 = zext i8 %17565 to i32
  %xor72.40.38 = xor i32 %conv71.40.38, %conv68.40.38
  %conv73.40.38 = trunc i32 %xor72.40.38 to i8
  store i8 %conv73.40.38, i8* %arrayidx70.38, align 1
  %scevgep20.41.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 41
  %17566 = load i8, i8* %scevgep20.41.38, align 1
  %conv68.41.38 = zext i8 %17566 to i32
  %17567 = load i8, i8* %arrayidx70.38, align 1
  %conv71.41.38 = zext i8 %17567 to i32
  %xor72.41.38 = xor i32 %conv71.41.38, %conv68.41.38
  %conv73.41.38 = trunc i32 %xor72.41.38 to i8
  store i8 %conv73.41.38, i8* %arrayidx70.38, align 1
  %scevgep20.42.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 42
  %17568 = load i8, i8* %scevgep20.42.38, align 1
  %conv68.42.38 = zext i8 %17568 to i32
  %17569 = load i8, i8* %arrayidx70.38, align 1
  %conv71.42.38 = zext i8 %17569 to i32
  %xor72.42.38 = xor i32 %conv71.42.38, %conv68.42.38
  %conv73.42.38 = trunc i32 %xor72.42.38 to i8
  store i8 %conv73.42.38, i8* %arrayidx70.38, align 1
  %scevgep20.43.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 43
  %17570 = load i8, i8* %scevgep20.43.38, align 1
  %conv68.43.38 = zext i8 %17570 to i32
  %17571 = load i8, i8* %arrayidx70.38, align 1
  %conv71.43.38 = zext i8 %17571 to i32
  %xor72.43.38 = xor i32 %conv71.43.38, %conv68.43.38
  %conv73.43.38 = trunc i32 %xor72.43.38 to i8
  store i8 %conv73.43.38, i8* %arrayidx70.38, align 1
  %scevgep20.44.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 44
  %17572 = load i8, i8* %scevgep20.44.38, align 1
  %conv68.44.38 = zext i8 %17572 to i32
  %17573 = load i8, i8* %arrayidx70.38, align 1
  %conv71.44.38 = zext i8 %17573 to i32
  %xor72.44.38 = xor i32 %conv71.44.38, %conv68.44.38
  %conv73.44.38 = trunc i32 %xor72.44.38 to i8
  store i8 %conv73.44.38, i8* %arrayidx70.38, align 1
  %scevgep20.45.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 45
  %17574 = load i8, i8* %scevgep20.45.38, align 1
  %conv68.45.38 = zext i8 %17574 to i32
  %17575 = load i8, i8* %arrayidx70.38, align 1
  %conv71.45.38 = zext i8 %17575 to i32
  %xor72.45.38 = xor i32 %conv71.45.38, %conv68.45.38
  %conv73.45.38 = trunc i32 %xor72.45.38 to i8
  store i8 %conv73.45.38, i8* %arrayidx70.38, align 1
  %scevgep20.46.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 46
  %17576 = load i8, i8* %scevgep20.46.38, align 1
  %conv68.46.38 = zext i8 %17576 to i32
  %17577 = load i8, i8* %arrayidx70.38, align 1
  %conv71.46.38 = zext i8 %17577 to i32
  %xor72.46.38 = xor i32 %conv71.46.38, %conv68.46.38
  %conv73.46.38 = trunc i32 %xor72.46.38 to i8
  store i8 %conv73.46.38, i8* %arrayidx70.38, align 1
  %scevgep20.47.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 47
  %17578 = load i8, i8* %scevgep20.47.38, align 1
  %conv68.47.38 = zext i8 %17578 to i32
  %17579 = load i8, i8* %arrayidx70.38, align 1
  %conv71.47.38 = zext i8 %17579 to i32
  %xor72.47.38 = xor i32 %conv71.47.38, %conv68.47.38
  %conv73.47.38 = trunc i32 %xor72.47.38 to i8
  store i8 %conv73.47.38, i8* %arrayidx70.38, align 1
  %scevgep20.48.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 48
  %17580 = load i8, i8* %scevgep20.48.38, align 1
  %conv68.48.38 = zext i8 %17580 to i32
  %17581 = load i8, i8* %arrayidx70.38, align 1
  %conv71.48.38 = zext i8 %17581 to i32
  %xor72.48.38 = xor i32 %conv71.48.38, %conv68.48.38
  %conv73.48.38 = trunc i32 %xor72.48.38 to i8
  store i8 %conv73.48.38, i8* %arrayidx70.38, align 1
  %scevgep20.49.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 49
  %17582 = load i8, i8* %scevgep20.49.38, align 1
  %conv68.49.38 = zext i8 %17582 to i32
  %17583 = load i8, i8* %arrayidx70.38, align 1
  %conv71.49.38 = zext i8 %17583 to i32
  %xor72.49.38 = xor i32 %conv71.49.38, %conv68.49.38
  %conv73.49.38 = trunc i32 %xor72.49.38 to i8
  store i8 %conv73.49.38, i8* %arrayidx70.38, align 1
  %scevgep20.50.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 50
  %17584 = load i8, i8* %scevgep20.50.38, align 1
  %conv68.50.38 = zext i8 %17584 to i32
  %17585 = load i8, i8* %arrayidx70.38, align 1
  %conv71.50.38 = zext i8 %17585 to i32
  %xor72.50.38 = xor i32 %conv71.50.38, %conv68.50.38
  %conv73.50.38 = trunc i32 %xor72.50.38 to i8
  store i8 %conv73.50.38, i8* %arrayidx70.38, align 1
  %scevgep20.51.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 51
  %17586 = load i8, i8* %scevgep20.51.38, align 1
  %conv68.51.38 = zext i8 %17586 to i32
  %17587 = load i8, i8* %arrayidx70.38, align 1
  %conv71.51.38 = zext i8 %17587 to i32
  %xor72.51.38 = xor i32 %conv71.51.38, %conv68.51.38
  %conv73.51.38 = trunc i32 %xor72.51.38 to i8
  store i8 %conv73.51.38, i8* %arrayidx70.38, align 1
  %scevgep20.52.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 52
  %17588 = load i8, i8* %scevgep20.52.38, align 1
  %conv68.52.38 = zext i8 %17588 to i32
  %17589 = load i8, i8* %arrayidx70.38, align 1
  %conv71.52.38 = zext i8 %17589 to i32
  %xor72.52.38 = xor i32 %conv71.52.38, %conv68.52.38
  %conv73.52.38 = trunc i32 %xor72.52.38 to i8
  store i8 %conv73.52.38, i8* %arrayidx70.38, align 1
  %scevgep20.53.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 53
  %17590 = load i8, i8* %scevgep20.53.38, align 1
  %conv68.53.38 = zext i8 %17590 to i32
  %17591 = load i8, i8* %arrayidx70.38, align 1
  %conv71.53.38 = zext i8 %17591 to i32
  %xor72.53.38 = xor i32 %conv71.53.38, %conv68.53.38
  %conv73.53.38 = trunc i32 %xor72.53.38 to i8
  store i8 %conv73.53.38, i8* %arrayidx70.38, align 1
  %scevgep20.54.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 54
  %17592 = load i8, i8* %scevgep20.54.38, align 1
  %conv68.54.38 = zext i8 %17592 to i32
  %17593 = load i8, i8* %arrayidx70.38, align 1
  %conv71.54.38 = zext i8 %17593 to i32
  %xor72.54.38 = xor i32 %conv71.54.38, %conv68.54.38
  %conv73.54.38 = trunc i32 %xor72.54.38 to i8
  store i8 %conv73.54.38, i8* %arrayidx70.38, align 1
  %scevgep20.55.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 55
  %17594 = load i8, i8* %scevgep20.55.38, align 1
  %conv68.55.38 = zext i8 %17594 to i32
  %17595 = load i8, i8* %arrayidx70.38, align 1
  %conv71.55.38 = zext i8 %17595 to i32
  %xor72.55.38 = xor i32 %conv71.55.38, %conv68.55.38
  %conv73.55.38 = trunc i32 %xor72.55.38 to i8
  store i8 %conv73.55.38, i8* %arrayidx70.38, align 1
  %scevgep20.56.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 56
  %17596 = load i8, i8* %scevgep20.56.38, align 1
  %conv68.56.38 = zext i8 %17596 to i32
  %17597 = load i8, i8* %arrayidx70.38, align 1
  %conv71.56.38 = zext i8 %17597 to i32
  %xor72.56.38 = xor i32 %conv71.56.38, %conv68.56.38
  %conv73.56.38 = trunc i32 %xor72.56.38 to i8
  store i8 %conv73.56.38, i8* %arrayidx70.38, align 1
  %scevgep20.57.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 57
  %17598 = load i8, i8* %scevgep20.57.38, align 1
  %conv68.57.38 = zext i8 %17598 to i32
  %17599 = load i8, i8* %arrayidx70.38, align 1
  %conv71.57.38 = zext i8 %17599 to i32
  %xor72.57.38 = xor i32 %conv71.57.38, %conv68.57.38
  %conv73.57.38 = trunc i32 %xor72.57.38 to i8
  store i8 %conv73.57.38, i8* %arrayidx70.38, align 1
  %scevgep20.58.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 58
  %17600 = load i8, i8* %scevgep20.58.38, align 1
  %conv68.58.38 = zext i8 %17600 to i32
  %17601 = load i8, i8* %arrayidx70.38, align 1
  %conv71.58.38 = zext i8 %17601 to i32
  %xor72.58.38 = xor i32 %conv71.58.38, %conv68.58.38
  %conv73.58.38 = trunc i32 %xor72.58.38 to i8
  store i8 %conv73.58.38, i8* %arrayidx70.38, align 1
  %scevgep20.59.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 59
  %17602 = load i8, i8* %scevgep20.59.38, align 1
  %conv68.59.38 = zext i8 %17602 to i32
  %17603 = load i8, i8* %arrayidx70.38, align 1
  %conv71.59.38 = zext i8 %17603 to i32
  %xor72.59.38 = xor i32 %conv71.59.38, %conv68.59.38
  %conv73.59.38 = trunc i32 %xor72.59.38 to i8
  store i8 %conv73.59.38, i8* %arrayidx70.38, align 1
  %scevgep20.60.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 0, i64 60
  %17604 = load i8, i8* %scevgep20.60.38, align 1
  %conv68.60.38 = zext i8 %17604 to i32
  %17605 = load i8, i8* %arrayidx70.38, align 1
  %conv71.60.38 = zext i8 %17605 to i32
  %xor72.60.38 = xor i32 %conv71.60.38, %conv68.60.38
  %conv73.60.38 = trunc i32 %xor72.60.38 to i8
  store i8 %conv73.60.38, i8* %arrayidx70.38, align 1
  %scevgep19.38 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17483, i64 0, i64 1, i64 0
  %17606 = bitcast i8* %scevgep19.38 to [61 x [61 x i8]]*
  %arrayidx51.39 = getelementptr inbounds i8, i8* %a, i64 39
  %17607 = load i8, i8* %arrayidx51.39, align 1
  %arrayidx53.39 = getelementptr inbounds i8, i8* %b, i64 39
  %17608 = load i8, i8* %arrayidx53.39, align 1
  %call54.39 = call zeroext i8 @mult(i8 zeroext %17607, i8 zeroext %17608)
  %arrayidx56.39 = getelementptr inbounds i8, i8* %c, i64 39
  store i8 %call54.39, i8* %arrayidx56.39, align 1
  %arrayidx70.39 = getelementptr inbounds i8, i8* %c, i64 39
  %scevgep20.39434 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 0
  %17609 = load i8, i8* %scevgep20.39434, align 1
  %conv68.39435 = zext i8 %17609 to i32
  %17610 = load i8, i8* %arrayidx70.39, align 1
  %conv71.39436 = zext i8 %17610 to i32
  %xor72.39437 = xor i32 %conv71.39436, %conv68.39435
  %conv73.39438 = trunc i32 %xor72.39437 to i8
  store i8 %conv73.39438, i8* %arrayidx70.39, align 1
  %scevgep20.1.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 1
  %17611 = load i8, i8* %scevgep20.1.39, align 1
  %conv68.1.39 = zext i8 %17611 to i32
  %17612 = load i8, i8* %arrayidx70.39, align 1
  %conv71.1.39 = zext i8 %17612 to i32
  %xor72.1.39 = xor i32 %conv71.1.39, %conv68.1.39
  %conv73.1.39 = trunc i32 %xor72.1.39 to i8
  store i8 %conv73.1.39, i8* %arrayidx70.39, align 1
  %scevgep20.2.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 2
  %17613 = load i8, i8* %scevgep20.2.39, align 1
  %conv68.2.39 = zext i8 %17613 to i32
  %17614 = load i8, i8* %arrayidx70.39, align 1
  %conv71.2.39 = zext i8 %17614 to i32
  %xor72.2.39 = xor i32 %conv71.2.39, %conv68.2.39
  %conv73.2.39 = trunc i32 %xor72.2.39 to i8
  store i8 %conv73.2.39, i8* %arrayidx70.39, align 1
  %scevgep20.3.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 3
  %17615 = load i8, i8* %scevgep20.3.39, align 1
  %conv68.3.39 = zext i8 %17615 to i32
  %17616 = load i8, i8* %arrayidx70.39, align 1
  %conv71.3.39 = zext i8 %17616 to i32
  %xor72.3.39 = xor i32 %conv71.3.39, %conv68.3.39
  %conv73.3.39 = trunc i32 %xor72.3.39 to i8
  store i8 %conv73.3.39, i8* %arrayidx70.39, align 1
  %scevgep20.4.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 4
  %17617 = load i8, i8* %scevgep20.4.39, align 1
  %conv68.4.39 = zext i8 %17617 to i32
  %17618 = load i8, i8* %arrayidx70.39, align 1
  %conv71.4.39 = zext i8 %17618 to i32
  %xor72.4.39 = xor i32 %conv71.4.39, %conv68.4.39
  %conv73.4.39 = trunc i32 %xor72.4.39 to i8
  store i8 %conv73.4.39, i8* %arrayidx70.39, align 1
  %scevgep20.5.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 5
  %17619 = load i8, i8* %scevgep20.5.39, align 1
  %conv68.5.39 = zext i8 %17619 to i32
  %17620 = load i8, i8* %arrayidx70.39, align 1
  %conv71.5.39 = zext i8 %17620 to i32
  %xor72.5.39 = xor i32 %conv71.5.39, %conv68.5.39
  %conv73.5.39 = trunc i32 %xor72.5.39 to i8
  store i8 %conv73.5.39, i8* %arrayidx70.39, align 1
  %scevgep20.6.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 6
  %17621 = load i8, i8* %scevgep20.6.39, align 1
  %conv68.6.39 = zext i8 %17621 to i32
  %17622 = load i8, i8* %arrayidx70.39, align 1
  %conv71.6.39 = zext i8 %17622 to i32
  %xor72.6.39 = xor i32 %conv71.6.39, %conv68.6.39
  %conv73.6.39 = trunc i32 %xor72.6.39 to i8
  store i8 %conv73.6.39, i8* %arrayidx70.39, align 1
  %scevgep20.7.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 7
  %17623 = load i8, i8* %scevgep20.7.39, align 1
  %conv68.7.39 = zext i8 %17623 to i32
  %17624 = load i8, i8* %arrayidx70.39, align 1
  %conv71.7.39 = zext i8 %17624 to i32
  %xor72.7.39 = xor i32 %conv71.7.39, %conv68.7.39
  %conv73.7.39 = trunc i32 %xor72.7.39 to i8
  store i8 %conv73.7.39, i8* %arrayidx70.39, align 1
  %scevgep20.8.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 8
  %17625 = load i8, i8* %scevgep20.8.39, align 1
  %conv68.8.39 = zext i8 %17625 to i32
  %17626 = load i8, i8* %arrayidx70.39, align 1
  %conv71.8.39 = zext i8 %17626 to i32
  %xor72.8.39 = xor i32 %conv71.8.39, %conv68.8.39
  %conv73.8.39 = trunc i32 %xor72.8.39 to i8
  store i8 %conv73.8.39, i8* %arrayidx70.39, align 1
  %scevgep20.9.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 9
  %17627 = load i8, i8* %scevgep20.9.39, align 1
  %conv68.9.39 = zext i8 %17627 to i32
  %17628 = load i8, i8* %arrayidx70.39, align 1
  %conv71.9.39 = zext i8 %17628 to i32
  %xor72.9.39 = xor i32 %conv71.9.39, %conv68.9.39
  %conv73.9.39 = trunc i32 %xor72.9.39 to i8
  store i8 %conv73.9.39, i8* %arrayidx70.39, align 1
  %scevgep20.10.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 10
  %17629 = load i8, i8* %scevgep20.10.39, align 1
  %conv68.10.39 = zext i8 %17629 to i32
  %17630 = load i8, i8* %arrayidx70.39, align 1
  %conv71.10.39 = zext i8 %17630 to i32
  %xor72.10.39 = xor i32 %conv71.10.39, %conv68.10.39
  %conv73.10.39 = trunc i32 %xor72.10.39 to i8
  store i8 %conv73.10.39, i8* %arrayidx70.39, align 1
  %scevgep20.11.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 11
  %17631 = load i8, i8* %scevgep20.11.39, align 1
  %conv68.11.39 = zext i8 %17631 to i32
  %17632 = load i8, i8* %arrayidx70.39, align 1
  %conv71.11.39 = zext i8 %17632 to i32
  %xor72.11.39 = xor i32 %conv71.11.39, %conv68.11.39
  %conv73.11.39 = trunc i32 %xor72.11.39 to i8
  store i8 %conv73.11.39, i8* %arrayidx70.39, align 1
  %scevgep20.12.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 12
  %17633 = load i8, i8* %scevgep20.12.39, align 1
  %conv68.12.39 = zext i8 %17633 to i32
  %17634 = load i8, i8* %arrayidx70.39, align 1
  %conv71.12.39 = zext i8 %17634 to i32
  %xor72.12.39 = xor i32 %conv71.12.39, %conv68.12.39
  %conv73.12.39 = trunc i32 %xor72.12.39 to i8
  store i8 %conv73.12.39, i8* %arrayidx70.39, align 1
  %scevgep20.13.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 13
  %17635 = load i8, i8* %scevgep20.13.39, align 1
  %conv68.13.39 = zext i8 %17635 to i32
  %17636 = load i8, i8* %arrayidx70.39, align 1
  %conv71.13.39 = zext i8 %17636 to i32
  %xor72.13.39 = xor i32 %conv71.13.39, %conv68.13.39
  %conv73.13.39 = trunc i32 %xor72.13.39 to i8
  store i8 %conv73.13.39, i8* %arrayidx70.39, align 1
  %scevgep20.14.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 14
  %17637 = load i8, i8* %scevgep20.14.39, align 1
  %conv68.14.39 = zext i8 %17637 to i32
  %17638 = load i8, i8* %arrayidx70.39, align 1
  %conv71.14.39 = zext i8 %17638 to i32
  %xor72.14.39 = xor i32 %conv71.14.39, %conv68.14.39
  %conv73.14.39 = trunc i32 %xor72.14.39 to i8
  store i8 %conv73.14.39, i8* %arrayidx70.39, align 1
  %scevgep20.15.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 15
  %17639 = load i8, i8* %scevgep20.15.39, align 1
  %conv68.15.39 = zext i8 %17639 to i32
  %17640 = load i8, i8* %arrayidx70.39, align 1
  %conv71.15.39 = zext i8 %17640 to i32
  %xor72.15.39 = xor i32 %conv71.15.39, %conv68.15.39
  %conv73.15.39 = trunc i32 %xor72.15.39 to i8
  store i8 %conv73.15.39, i8* %arrayidx70.39, align 1
  %scevgep20.16.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 16
  %17641 = load i8, i8* %scevgep20.16.39, align 1
  %conv68.16.39 = zext i8 %17641 to i32
  %17642 = load i8, i8* %arrayidx70.39, align 1
  %conv71.16.39 = zext i8 %17642 to i32
  %xor72.16.39 = xor i32 %conv71.16.39, %conv68.16.39
  %conv73.16.39 = trunc i32 %xor72.16.39 to i8
  store i8 %conv73.16.39, i8* %arrayidx70.39, align 1
  %scevgep20.17.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 17
  %17643 = load i8, i8* %scevgep20.17.39, align 1
  %conv68.17.39 = zext i8 %17643 to i32
  %17644 = load i8, i8* %arrayidx70.39, align 1
  %conv71.17.39 = zext i8 %17644 to i32
  %xor72.17.39 = xor i32 %conv71.17.39, %conv68.17.39
  %conv73.17.39 = trunc i32 %xor72.17.39 to i8
  store i8 %conv73.17.39, i8* %arrayidx70.39, align 1
  %scevgep20.18.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 18
  %17645 = load i8, i8* %scevgep20.18.39, align 1
  %conv68.18.39 = zext i8 %17645 to i32
  %17646 = load i8, i8* %arrayidx70.39, align 1
  %conv71.18.39 = zext i8 %17646 to i32
  %xor72.18.39 = xor i32 %conv71.18.39, %conv68.18.39
  %conv73.18.39 = trunc i32 %xor72.18.39 to i8
  store i8 %conv73.18.39, i8* %arrayidx70.39, align 1
  %scevgep20.19.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 19
  %17647 = load i8, i8* %scevgep20.19.39, align 1
  %conv68.19.39 = zext i8 %17647 to i32
  %17648 = load i8, i8* %arrayidx70.39, align 1
  %conv71.19.39 = zext i8 %17648 to i32
  %xor72.19.39 = xor i32 %conv71.19.39, %conv68.19.39
  %conv73.19.39 = trunc i32 %xor72.19.39 to i8
  store i8 %conv73.19.39, i8* %arrayidx70.39, align 1
  %scevgep20.20.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 20
  %17649 = load i8, i8* %scevgep20.20.39, align 1
  %conv68.20.39 = zext i8 %17649 to i32
  %17650 = load i8, i8* %arrayidx70.39, align 1
  %conv71.20.39 = zext i8 %17650 to i32
  %xor72.20.39 = xor i32 %conv71.20.39, %conv68.20.39
  %conv73.20.39 = trunc i32 %xor72.20.39 to i8
  store i8 %conv73.20.39, i8* %arrayidx70.39, align 1
  %scevgep20.21.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 21
  %17651 = load i8, i8* %scevgep20.21.39, align 1
  %conv68.21.39 = zext i8 %17651 to i32
  %17652 = load i8, i8* %arrayidx70.39, align 1
  %conv71.21.39 = zext i8 %17652 to i32
  %xor72.21.39 = xor i32 %conv71.21.39, %conv68.21.39
  %conv73.21.39 = trunc i32 %xor72.21.39 to i8
  store i8 %conv73.21.39, i8* %arrayidx70.39, align 1
  %scevgep20.22.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 22
  %17653 = load i8, i8* %scevgep20.22.39, align 1
  %conv68.22.39 = zext i8 %17653 to i32
  %17654 = load i8, i8* %arrayidx70.39, align 1
  %conv71.22.39 = zext i8 %17654 to i32
  %xor72.22.39 = xor i32 %conv71.22.39, %conv68.22.39
  %conv73.22.39 = trunc i32 %xor72.22.39 to i8
  store i8 %conv73.22.39, i8* %arrayidx70.39, align 1
  %scevgep20.23.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 23
  %17655 = load i8, i8* %scevgep20.23.39, align 1
  %conv68.23.39 = zext i8 %17655 to i32
  %17656 = load i8, i8* %arrayidx70.39, align 1
  %conv71.23.39 = zext i8 %17656 to i32
  %xor72.23.39 = xor i32 %conv71.23.39, %conv68.23.39
  %conv73.23.39 = trunc i32 %xor72.23.39 to i8
  store i8 %conv73.23.39, i8* %arrayidx70.39, align 1
  %scevgep20.24.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 24
  %17657 = load i8, i8* %scevgep20.24.39, align 1
  %conv68.24.39 = zext i8 %17657 to i32
  %17658 = load i8, i8* %arrayidx70.39, align 1
  %conv71.24.39 = zext i8 %17658 to i32
  %xor72.24.39 = xor i32 %conv71.24.39, %conv68.24.39
  %conv73.24.39 = trunc i32 %xor72.24.39 to i8
  store i8 %conv73.24.39, i8* %arrayidx70.39, align 1
  %scevgep20.25.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 25
  %17659 = load i8, i8* %scevgep20.25.39, align 1
  %conv68.25.39 = zext i8 %17659 to i32
  %17660 = load i8, i8* %arrayidx70.39, align 1
  %conv71.25.39 = zext i8 %17660 to i32
  %xor72.25.39 = xor i32 %conv71.25.39, %conv68.25.39
  %conv73.25.39 = trunc i32 %xor72.25.39 to i8
  store i8 %conv73.25.39, i8* %arrayidx70.39, align 1
  %scevgep20.26.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 26
  %17661 = load i8, i8* %scevgep20.26.39, align 1
  %conv68.26.39 = zext i8 %17661 to i32
  %17662 = load i8, i8* %arrayidx70.39, align 1
  %conv71.26.39 = zext i8 %17662 to i32
  %xor72.26.39 = xor i32 %conv71.26.39, %conv68.26.39
  %conv73.26.39 = trunc i32 %xor72.26.39 to i8
  store i8 %conv73.26.39, i8* %arrayidx70.39, align 1
  %scevgep20.27.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 27
  %17663 = load i8, i8* %scevgep20.27.39, align 1
  %conv68.27.39 = zext i8 %17663 to i32
  %17664 = load i8, i8* %arrayidx70.39, align 1
  %conv71.27.39 = zext i8 %17664 to i32
  %xor72.27.39 = xor i32 %conv71.27.39, %conv68.27.39
  %conv73.27.39 = trunc i32 %xor72.27.39 to i8
  store i8 %conv73.27.39, i8* %arrayidx70.39, align 1
  %scevgep20.28.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 28
  %17665 = load i8, i8* %scevgep20.28.39, align 1
  %conv68.28.39 = zext i8 %17665 to i32
  %17666 = load i8, i8* %arrayidx70.39, align 1
  %conv71.28.39 = zext i8 %17666 to i32
  %xor72.28.39 = xor i32 %conv71.28.39, %conv68.28.39
  %conv73.28.39 = trunc i32 %xor72.28.39 to i8
  store i8 %conv73.28.39, i8* %arrayidx70.39, align 1
  %scevgep20.29.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 29
  %17667 = load i8, i8* %scevgep20.29.39, align 1
  %conv68.29.39 = zext i8 %17667 to i32
  %17668 = load i8, i8* %arrayidx70.39, align 1
  %conv71.29.39 = zext i8 %17668 to i32
  %xor72.29.39 = xor i32 %conv71.29.39, %conv68.29.39
  %conv73.29.39 = trunc i32 %xor72.29.39 to i8
  store i8 %conv73.29.39, i8* %arrayidx70.39, align 1
  %scevgep20.30.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 30
  %17669 = load i8, i8* %scevgep20.30.39, align 1
  %conv68.30.39 = zext i8 %17669 to i32
  %17670 = load i8, i8* %arrayidx70.39, align 1
  %conv71.30.39 = zext i8 %17670 to i32
  %xor72.30.39 = xor i32 %conv71.30.39, %conv68.30.39
  %conv73.30.39 = trunc i32 %xor72.30.39 to i8
  store i8 %conv73.30.39, i8* %arrayidx70.39, align 1
  %scevgep20.31.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 31
  %17671 = load i8, i8* %scevgep20.31.39, align 1
  %conv68.31.39 = zext i8 %17671 to i32
  %17672 = load i8, i8* %arrayidx70.39, align 1
  %conv71.31.39 = zext i8 %17672 to i32
  %xor72.31.39 = xor i32 %conv71.31.39, %conv68.31.39
  %conv73.31.39 = trunc i32 %xor72.31.39 to i8
  store i8 %conv73.31.39, i8* %arrayidx70.39, align 1
  %scevgep20.32.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 32
  %17673 = load i8, i8* %scevgep20.32.39, align 1
  %conv68.32.39 = zext i8 %17673 to i32
  %17674 = load i8, i8* %arrayidx70.39, align 1
  %conv71.32.39 = zext i8 %17674 to i32
  %xor72.32.39 = xor i32 %conv71.32.39, %conv68.32.39
  %conv73.32.39 = trunc i32 %xor72.32.39 to i8
  store i8 %conv73.32.39, i8* %arrayidx70.39, align 1
  %scevgep20.33.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 33
  %17675 = load i8, i8* %scevgep20.33.39, align 1
  %conv68.33.39 = zext i8 %17675 to i32
  %17676 = load i8, i8* %arrayidx70.39, align 1
  %conv71.33.39 = zext i8 %17676 to i32
  %xor72.33.39 = xor i32 %conv71.33.39, %conv68.33.39
  %conv73.33.39 = trunc i32 %xor72.33.39 to i8
  store i8 %conv73.33.39, i8* %arrayidx70.39, align 1
  %scevgep20.34.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 34
  %17677 = load i8, i8* %scevgep20.34.39, align 1
  %conv68.34.39 = zext i8 %17677 to i32
  %17678 = load i8, i8* %arrayidx70.39, align 1
  %conv71.34.39 = zext i8 %17678 to i32
  %xor72.34.39 = xor i32 %conv71.34.39, %conv68.34.39
  %conv73.34.39 = trunc i32 %xor72.34.39 to i8
  store i8 %conv73.34.39, i8* %arrayidx70.39, align 1
  %scevgep20.35.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 35
  %17679 = load i8, i8* %scevgep20.35.39, align 1
  %conv68.35.39 = zext i8 %17679 to i32
  %17680 = load i8, i8* %arrayidx70.39, align 1
  %conv71.35.39 = zext i8 %17680 to i32
  %xor72.35.39 = xor i32 %conv71.35.39, %conv68.35.39
  %conv73.35.39 = trunc i32 %xor72.35.39 to i8
  store i8 %conv73.35.39, i8* %arrayidx70.39, align 1
  %scevgep20.36.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 36
  %17681 = load i8, i8* %scevgep20.36.39, align 1
  %conv68.36.39 = zext i8 %17681 to i32
  %17682 = load i8, i8* %arrayidx70.39, align 1
  %conv71.36.39 = zext i8 %17682 to i32
  %xor72.36.39 = xor i32 %conv71.36.39, %conv68.36.39
  %conv73.36.39 = trunc i32 %xor72.36.39 to i8
  store i8 %conv73.36.39, i8* %arrayidx70.39, align 1
  %scevgep20.37.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 37
  %17683 = load i8, i8* %scevgep20.37.39, align 1
  %conv68.37.39 = zext i8 %17683 to i32
  %17684 = load i8, i8* %arrayidx70.39, align 1
  %conv71.37.39 = zext i8 %17684 to i32
  %xor72.37.39 = xor i32 %conv71.37.39, %conv68.37.39
  %conv73.37.39 = trunc i32 %xor72.37.39 to i8
  store i8 %conv73.37.39, i8* %arrayidx70.39, align 1
  %scevgep20.38.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 38
  %17685 = load i8, i8* %scevgep20.38.39, align 1
  %conv68.38.39 = zext i8 %17685 to i32
  %17686 = load i8, i8* %arrayidx70.39, align 1
  %conv71.38.39 = zext i8 %17686 to i32
  %xor72.38.39 = xor i32 %conv71.38.39, %conv68.38.39
  %conv73.38.39 = trunc i32 %xor72.38.39 to i8
  store i8 %conv73.38.39, i8* %arrayidx70.39, align 1
  %scevgep20.40.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 40
  %17687 = load i8, i8* %scevgep20.40.39, align 1
  %conv68.40.39 = zext i8 %17687 to i32
  %17688 = load i8, i8* %arrayidx70.39, align 1
  %conv71.40.39 = zext i8 %17688 to i32
  %xor72.40.39 = xor i32 %conv71.40.39, %conv68.40.39
  %conv73.40.39 = trunc i32 %xor72.40.39 to i8
  store i8 %conv73.40.39, i8* %arrayidx70.39, align 1
  %scevgep20.41.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 41
  %17689 = load i8, i8* %scevgep20.41.39, align 1
  %conv68.41.39 = zext i8 %17689 to i32
  %17690 = load i8, i8* %arrayidx70.39, align 1
  %conv71.41.39 = zext i8 %17690 to i32
  %xor72.41.39 = xor i32 %conv71.41.39, %conv68.41.39
  %conv73.41.39 = trunc i32 %xor72.41.39 to i8
  store i8 %conv73.41.39, i8* %arrayidx70.39, align 1
  %scevgep20.42.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 42
  %17691 = load i8, i8* %scevgep20.42.39, align 1
  %conv68.42.39 = zext i8 %17691 to i32
  %17692 = load i8, i8* %arrayidx70.39, align 1
  %conv71.42.39 = zext i8 %17692 to i32
  %xor72.42.39 = xor i32 %conv71.42.39, %conv68.42.39
  %conv73.42.39 = trunc i32 %xor72.42.39 to i8
  store i8 %conv73.42.39, i8* %arrayidx70.39, align 1
  %scevgep20.43.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 43
  %17693 = load i8, i8* %scevgep20.43.39, align 1
  %conv68.43.39 = zext i8 %17693 to i32
  %17694 = load i8, i8* %arrayidx70.39, align 1
  %conv71.43.39 = zext i8 %17694 to i32
  %xor72.43.39 = xor i32 %conv71.43.39, %conv68.43.39
  %conv73.43.39 = trunc i32 %xor72.43.39 to i8
  store i8 %conv73.43.39, i8* %arrayidx70.39, align 1
  %scevgep20.44.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 44
  %17695 = load i8, i8* %scevgep20.44.39, align 1
  %conv68.44.39 = zext i8 %17695 to i32
  %17696 = load i8, i8* %arrayidx70.39, align 1
  %conv71.44.39 = zext i8 %17696 to i32
  %xor72.44.39 = xor i32 %conv71.44.39, %conv68.44.39
  %conv73.44.39 = trunc i32 %xor72.44.39 to i8
  store i8 %conv73.44.39, i8* %arrayidx70.39, align 1
  %scevgep20.45.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 45
  %17697 = load i8, i8* %scevgep20.45.39, align 1
  %conv68.45.39 = zext i8 %17697 to i32
  %17698 = load i8, i8* %arrayidx70.39, align 1
  %conv71.45.39 = zext i8 %17698 to i32
  %xor72.45.39 = xor i32 %conv71.45.39, %conv68.45.39
  %conv73.45.39 = trunc i32 %xor72.45.39 to i8
  store i8 %conv73.45.39, i8* %arrayidx70.39, align 1
  %scevgep20.46.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 46
  %17699 = load i8, i8* %scevgep20.46.39, align 1
  %conv68.46.39 = zext i8 %17699 to i32
  %17700 = load i8, i8* %arrayidx70.39, align 1
  %conv71.46.39 = zext i8 %17700 to i32
  %xor72.46.39 = xor i32 %conv71.46.39, %conv68.46.39
  %conv73.46.39 = trunc i32 %xor72.46.39 to i8
  store i8 %conv73.46.39, i8* %arrayidx70.39, align 1
  %scevgep20.47.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 47
  %17701 = load i8, i8* %scevgep20.47.39, align 1
  %conv68.47.39 = zext i8 %17701 to i32
  %17702 = load i8, i8* %arrayidx70.39, align 1
  %conv71.47.39 = zext i8 %17702 to i32
  %xor72.47.39 = xor i32 %conv71.47.39, %conv68.47.39
  %conv73.47.39 = trunc i32 %xor72.47.39 to i8
  store i8 %conv73.47.39, i8* %arrayidx70.39, align 1
  %scevgep20.48.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 48
  %17703 = load i8, i8* %scevgep20.48.39, align 1
  %conv68.48.39 = zext i8 %17703 to i32
  %17704 = load i8, i8* %arrayidx70.39, align 1
  %conv71.48.39 = zext i8 %17704 to i32
  %xor72.48.39 = xor i32 %conv71.48.39, %conv68.48.39
  %conv73.48.39 = trunc i32 %xor72.48.39 to i8
  store i8 %conv73.48.39, i8* %arrayidx70.39, align 1
  %scevgep20.49.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 49
  %17705 = load i8, i8* %scevgep20.49.39, align 1
  %conv68.49.39 = zext i8 %17705 to i32
  %17706 = load i8, i8* %arrayidx70.39, align 1
  %conv71.49.39 = zext i8 %17706 to i32
  %xor72.49.39 = xor i32 %conv71.49.39, %conv68.49.39
  %conv73.49.39 = trunc i32 %xor72.49.39 to i8
  store i8 %conv73.49.39, i8* %arrayidx70.39, align 1
  %scevgep20.50.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 50
  %17707 = load i8, i8* %scevgep20.50.39, align 1
  %conv68.50.39 = zext i8 %17707 to i32
  %17708 = load i8, i8* %arrayidx70.39, align 1
  %conv71.50.39 = zext i8 %17708 to i32
  %xor72.50.39 = xor i32 %conv71.50.39, %conv68.50.39
  %conv73.50.39 = trunc i32 %xor72.50.39 to i8
  store i8 %conv73.50.39, i8* %arrayidx70.39, align 1
  %scevgep20.51.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 51
  %17709 = load i8, i8* %scevgep20.51.39, align 1
  %conv68.51.39 = zext i8 %17709 to i32
  %17710 = load i8, i8* %arrayidx70.39, align 1
  %conv71.51.39 = zext i8 %17710 to i32
  %xor72.51.39 = xor i32 %conv71.51.39, %conv68.51.39
  %conv73.51.39 = trunc i32 %xor72.51.39 to i8
  store i8 %conv73.51.39, i8* %arrayidx70.39, align 1
  %scevgep20.52.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 52
  %17711 = load i8, i8* %scevgep20.52.39, align 1
  %conv68.52.39 = zext i8 %17711 to i32
  %17712 = load i8, i8* %arrayidx70.39, align 1
  %conv71.52.39 = zext i8 %17712 to i32
  %xor72.52.39 = xor i32 %conv71.52.39, %conv68.52.39
  %conv73.52.39 = trunc i32 %xor72.52.39 to i8
  store i8 %conv73.52.39, i8* %arrayidx70.39, align 1
  %scevgep20.53.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 53
  %17713 = load i8, i8* %scevgep20.53.39, align 1
  %conv68.53.39 = zext i8 %17713 to i32
  %17714 = load i8, i8* %arrayidx70.39, align 1
  %conv71.53.39 = zext i8 %17714 to i32
  %xor72.53.39 = xor i32 %conv71.53.39, %conv68.53.39
  %conv73.53.39 = trunc i32 %xor72.53.39 to i8
  store i8 %conv73.53.39, i8* %arrayidx70.39, align 1
  %scevgep20.54.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 54
  %17715 = load i8, i8* %scevgep20.54.39, align 1
  %conv68.54.39 = zext i8 %17715 to i32
  %17716 = load i8, i8* %arrayidx70.39, align 1
  %conv71.54.39 = zext i8 %17716 to i32
  %xor72.54.39 = xor i32 %conv71.54.39, %conv68.54.39
  %conv73.54.39 = trunc i32 %xor72.54.39 to i8
  store i8 %conv73.54.39, i8* %arrayidx70.39, align 1
  %scevgep20.55.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 55
  %17717 = load i8, i8* %scevgep20.55.39, align 1
  %conv68.55.39 = zext i8 %17717 to i32
  %17718 = load i8, i8* %arrayidx70.39, align 1
  %conv71.55.39 = zext i8 %17718 to i32
  %xor72.55.39 = xor i32 %conv71.55.39, %conv68.55.39
  %conv73.55.39 = trunc i32 %xor72.55.39 to i8
  store i8 %conv73.55.39, i8* %arrayidx70.39, align 1
  %scevgep20.56.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 56
  %17719 = load i8, i8* %scevgep20.56.39, align 1
  %conv68.56.39 = zext i8 %17719 to i32
  %17720 = load i8, i8* %arrayidx70.39, align 1
  %conv71.56.39 = zext i8 %17720 to i32
  %xor72.56.39 = xor i32 %conv71.56.39, %conv68.56.39
  %conv73.56.39 = trunc i32 %xor72.56.39 to i8
  store i8 %conv73.56.39, i8* %arrayidx70.39, align 1
  %scevgep20.57.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 57
  %17721 = load i8, i8* %scevgep20.57.39, align 1
  %conv68.57.39 = zext i8 %17721 to i32
  %17722 = load i8, i8* %arrayidx70.39, align 1
  %conv71.57.39 = zext i8 %17722 to i32
  %xor72.57.39 = xor i32 %conv71.57.39, %conv68.57.39
  %conv73.57.39 = trunc i32 %xor72.57.39 to i8
  store i8 %conv73.57.39, i8* %arrayidx70.39, align 1
  %scevgep20.58.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 58
  %17723 = load i8, i8* %scevgep20.58.39, align 1
  %conv68.58.39 = zext i8 %17723 to i32
  %17724 = load i8, i8* %arrayidx70.39, align 1
  %conv71.58.39 = zext i8 %17724 to i32
  %xor72.58.39 = xor i32 %conv71.58.39, %conv68.58.39
  %conv73.58.39 = trunc i32 %xor72.58.39 to i8
  store i8 %conv73.58.39, i8* %arrayidx70.39, align 1
  %scevgep20.59.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 59
  %17725 = load i8, i8* %scevgep20.59.39, align 1
  %conv68.59.39 = zext i8 %17725 to i32
  %17726 = load i8, i8* %arrayidx70.39, align 1
  %conv71.59.39 = zext i8 %17726 to i32
  %xor72.59.39 = xor i32 %conv71.59.39, %conv68.59.39
  %conv73.59.39 = trunc i32 %xor72.59.39 to i8
  store i8 %conv73.59.39, i8* %arrayidx70.39, align 1
  %scevgep20.60.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 0, i64 60
  %17727 = load i8, i8* %scevgep20.60.39, align 1
  %conv68.60.39 = zext i8 %17727 to i32
  %17728 = load i8, i8* %arrayidx70.39, align 1
  %conv71.60.39 = zext i8 %17728 to i32
  %xor72.60.39 = xor i32 %conv71.60.39, %conv68.60.39
  %conv73.60.39 = trunc i32 %xor72.60.39 to i8
  store i8 %conv73.60.39, i8* %arrayidx70.39, align 1
  %scevgep19.39 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17606, i64 0, i64 1, i64 0
  %17729 = bitcast i8* %scevgep19.39 to [61 x [61 x i8]]*
  %arrayidx51.40 = getelementptr inbounds i8, i8* %a, i64 40
  %17730 = load i8, i8* %arrayidx51.40, align 1
  %arrayidx53.40 = getelementptr inbounds i8, i8* %b, i64 40
  %17731 = load i8, i8* %arrayidx53.40, align 1
  %call54.40 = call zeroext i8 @mult(i8 zeroext %17730, i8 zeroext %17731)
  %arrayidx56.40 = getelementptr inbounds i8, i8* %c, i64 40
  store i8 %call54.40, i8* %arrayidx56.40, align 1
  %arrayidx70.40 = getelementptr inbounds i8, i8* %c, i64 40
  %scevgep20.40444 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 0
  %17732 = load i8, i8* %scevgep20.40444, align 1
  %conv68.40445 = zext i8 %17732 to i32
  %17733 = load i8, i8* %arrayidx70.40, align 1
  %conv71.40446 = zext i8 %17733 to i32
  %xor72.40447 = xor i32 %conv71.40446, %conv68.40445
  %conv73.40448 = trunc i32 %xor72.40447 to i8
  store i8 %conv73.40448, i8* %arrayidx70.40, align 1
  %scevgep20.1.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 1
  %17734 = load i8, i8* %scevgep20.1.40, align 1
  %conv68.1.40 = zext i8 %17734 to i32
  %17735 = load i8, i8* %arrayidx70.40, align 1
  %conv71.1.40 = zext i8 %17735 to i32
  %xor72.1.40 = xor i32 %conv71.1.40, %conv68.1.40
  %conv73.1.40 = trunc i32 %xor72.1.40 to i8
  store i8 %conv73.1.40, i8* %arrayidx70.40, align 1
  %scevgep20.2.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 2
  %17736 = load i8, i8* %scevgep20.2.40, align 1
  %conv68.2.40 = zext i8 %17736 to i32
  %17737 = load i8, i8* %arrayidx70.40, align 1
  %conv71.2.40 = zext i8 %17737 to i32
  %xor72.2.40 = xor i32 %conv71.2.40, %conv68.2.40
  %conv73.2.40 = trunc i32 %xor72.2.40 to i8
  store i8 %conv73.2.40, i8* %arrayidx70.40, align 1
  %scevgep20.3.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 3
  %17738 = load i8, i8* %scevgep20.3.40, align 1
  %conv68.3.40 = zext i8 %17738 to i32
  %17739 = load i8, i8* %arrayidx70.40, align 1
  %conv71.3.40 = zext i8 %17739 to i32
  %xor72.3.40 = xor i32 %conv71.3.40, %conv68.3.40
  %conv73.3.40 = trunc i32 %xor72.3.40 to i8
  store i8 %conv73.3.40, i8* %arrayidx70.40, align 1
  %scevgep20.4.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 4
  %17740 = load i8, i8* %scevgep20.4.40, align 1
  %conv68.4.40 = zext i8 %17740 to i32
  %17741 = load i8, i8* %arrayidx70.40, align 1
  %conv71.4.40 = zext i8 %17741 to i32
  %xor72.4.40 = xor i32 %conv71.4.40, %conv68.4.40
  %conv73.4.40 = trunc i32 %xor72.4.40 to i8
  store i8 %conv73.4.40, i8* %arrayidx70.40, align 1
  %scevgep20.5.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 5
  %17742 = load i8, i8* %scevgep20.5.40, align 1
  %conv68.5.40 = zext i8 %17742 to i32
  %17743 = load i8, i8* %arrayidx70.40, align 1
  %conv71.5.40 = zext i8 %17743 to i32
  %xor72.5.40 = xor i32 %conv71.5.40, %conv68.5.40
  %conv73.5.40 = trunc i32 %xor72.5.40 to i8
  store i8 %conv73.5.40, i8* %arrayidx70.40, align 1
  %scevgep20.6.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 6
  %17744 = load i8, i8* %scevgep20.6.40, align 1
  %conv68.6.40 = zext i8 %17744 to i32
  %17745 = load i8, i8* %arrayidx70.40, align 1
  %conv71.6.40 = zext i8 %17745 to i32
  %xor72.6.40 = xor i32 %conv71.6.40, %conv68.6.40
  %conv73.6.40 = trunc i32 %xor72.6.40 to i8
  store i8 %conv73.6.40, i8* %arrayidx70.40, align 1
  %scevgep20.7.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 7
  %17746 = load i8, i8* %scevgep20.7.40, align 1
  %conv68.7.40 = zext i8 %17746 to i32
  %17747 = load i8, i8* %arrayidx70.40, align 1
  %conv71.7.40 = zext i8 %17747 to i32
  %xor72.7.40 = xor i32 %conv71.7.40, %conv68.7.40
  %conv73.7.40 = trunc i32 %xor72.7.40 to i8
  store i8 %conv73.7.40, i8* %arrayidx70.40, align 1
  %scevgep20.8.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 8
  %17748 = load i8, i8* %scevgep20.8.40, align 1
  %conv68.8.40 = zext i8 %17748 to i32
  %17749 = load i8, i8* %arrayidx70.40, align 1
  %conv71.8.40 = zext i8 %17749 to i32
  %xor72.8.40 = xor i32 %conv71.8.40, %conv68.8.40
  %conv73.8.40 = trunc i32 %xor72.8.40 to i8
  store i8 %conv73.8.40, i8* %arrayidx70.40, align 1
  %scevgep20.9.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 9
  %17750 = load i8, i8* %scevgep20.9.40, align 1
  %conv68.9.40 = zext i8 %17750 to i32
  %17751 = load i8, i8* %arrayidx70.40, align 1
  %conv71.9.40 = zext i8 %17751 to i32
  %xor72.9.40 = xor i32 %conv71.9.40, %conv68.9.40
  %conv73.9.40 = trunc i32 %xor72.9.40 to i8
  store i8 %conv73.9.40, i8* %arrayidx70.40, align 1
  %scevgep20.10.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 10
  %17752 = load i8, i8* %scevgep20.10.40, align 1
  %conv68.10.40 = zext i8 %17752 to i32
  %17753 = load i8, i8* %arrayidx70.40, align 1
  %conv71.10.40 = zext i8 %17753 to i32
  %xor72.10.40 = xor i32 %conv71.10.40, %conv68.10.40
  %conv73.10.40 = trunc i32 %xor72.10.40 to i8
  store i8 %conv73.10.40, i8* %arrayidx70.40, align 1
  %scevgep20.11.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 11
  %17754 = load i8, i8* %scevgep20.11.40, align 1
  %conv68.11.40 = zext i8 %17754 to i32
  %17755 = load i8, i8* %arrayidx70.40, align 1
  %conv71.11.40 = zext i8 %17755 to i32
  %xor72.11.40 = xor i32 %conv71.11.40, %conv68.11.40
  %conv73.11.40 = trunc i32 %xor72.11.40 to i8
  store i8 %conv73.11.40, i8* %arrayidx70.40, align 1
  %scevgep20.12.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 12
  %17756 = load i8, i8* %scevgep20.12.40, align 1
  %conv68.12.40 = zext i8 %17756 to i32
  %17757 = load i8, i8* %arrayidx70.40, align 1
  %conv71.12.40 = zext i8 %17757 to i32
  %xor72.12.40 = xor i32 %conv71.12.40, %conv68.12.40
  %conv73.12.40 = trunc i32 %xor72.12.40 to i8
  store i8 %conv73.12.40, i8* %arrayidx70.40, align 1
  %scevgep20.13.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 13
  %17758 = load i8, i8* %scevgep20.13.40, align 1
  %conv68.13.40 = zext i8 %17758 to i32
  %17759 = load i8, i8* %arrayidx70.40, align 1
  %conv71.13.40 = zext i8 %17759 to i32
  %xor72.13.40 = xor i32 %conv71.13.40, %conv68.13.40
  %conv73.13.40 = trunc i32 %xor72.13.40 to i8
  store i8 %conv73.13.40, i8* %arrayidx70.40, align 1
  %scevgep20.14.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 14
  %17760 = load i8, i8* %scevgep20.14.40, align 1
  %conv68.14.40 = zext i8 %17760 to i32
  %17761 = load i8, i8* %arrayidx70.40, align 1
  %conv71.14.40 = zext i8 %17761 to i32
  %xor72.14.40 = xor i32 %conv71.14.40, %conv68.14.40
  %conv73.14.40 = trunc i32 %xor72.14.40 to i8
  store i8 %conv73.14.40, i8* %arrayidx70.40, align 1
  %scevgep20.15.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 15
  %17762 = load i8, i8* %scevgep20.15.40, align 1
  %conv68.15.40 = zext i8 %17762 to i32
  %17763 = load i8, i8* %arrayidx70.40, align 1
  %conv71.15.40 = zext i8 %17763 to i32
  %xor72.15.40 = xor i32 %conv71.15.40, %conv68.15.40
  %conv73.15.40 = trunc i32 %xor72.15.40 to i8
  store i8 %conv73.15.40, i8* %arrayidx70.40, align 1
  %scevgep20.16.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 16
  %17764 = load i8, i8* %scevgep20.16.40, align 1
  %conv68.16.40 = zext i8 %17764 to i32
  %17765 = load i8, i8* %arrayidx70.40, align 1
  %conv71.16.40 = zext i8 %17765 to i32
  %xor72.16.40 = xor i32 %conv71.16.40, %conv68.16.40
  %conv73.16.40 = trunc i32 %xor72.16.40 to i8
  store i8 %conv73.16.40, i8* %arrayidx70.40, align 1
  %scevgep20.17.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 17
  %17766 = load i8, i8* %scevgep20.17.40, align 1
  %conv68.17.40 = zext i8 %17766 to i32
  %17767 = load i8, i8* %arrayidx70.40, align 1
  %conv71.17.40 = zext i8 %17767 to i32
  %xor72.17.40 = xor i32 %conv71.17.40, %conv68.17.40
  %conv73.17.40 = trunc i32 %xor72.17.40 to i8
  store i8 %conv73.17.40, i8* %arrayidx70.40, align 1
  %scevgep20.18.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 18
  %17768 = load i8, i8* %scevgep20.18.40, align 1
  %conv68.18.40 = zext i8 %17768 to i32
  %17769 = load i8, i8* %arrayidx70.40, align 1
  %conv71.18.40 = zext i8 %17769 to i32
  %xor72.18.40 = xor i32 %conv71.18.40, %conv68.18.40
  %conv73.18.40 = trunc i32 %xor72.18.40 to i8
  store i8 %conv73.18.40, i8* %arrayidx70.40, align 1
  %scevgep20.19.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 19
  %17770 = load i8, i8* %scevgep20.19.40, align 1
  %conv68.19.40 = zext i8 %17770 to i32
  %17771 = load i8, i8* %arrayidx70.40, align 1
  %conv71.19.40 = zext i8 %17771 to i32
  %xor72.19.40 = xor i32 %conv71.19.40, %conv68.19.40
  %conv73.19.40 = trunc i32 %xor72.19.40 to i8
  store i8 %conv73.19.40, i8* %arrayidx70.40, align 1
  %scevgep20.20.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 20
  %17772 = load i8, i8* %scevgep20.20.40, align 1
  %conv68.20.40 = zext i8 %17772 to i32
  %17773 = load i8, i8* %arrayidx70.40, align 1
  %conv71.20.40 = zext i8 %17773 to i32
  %xor72.20.40 = xor i32 %conv71.20.40, %conv68.20.40
  %conv73.20.40 = trunc i32 %xor72.20.40 to i8
  store i8 %conv73.20.40, i8* %arrayidx70.40, align 1
  %scevgep20.21.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 21
  %17774 = load i8, i8* %scevgep20.21.40, align 1
  %conv68.21.40 = zext i8 %17774 to i32
  %17775 = load i8, i8* %arrayidx70.40, align 1
  %conv71.21.40 = zext i8 %17775 to i32
  %xor72.21.40 = xor i32 %conv71.21.40, %conv68.21.40
  %conv73.21.40 = trunc i32 %xor72.21.40 to i8
  store i8 %conv73.21.40, i8* %arrayidx70.40, align 1
  %scevgep20.22.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 22
  %17776 = load i8, i8* %scevgep20.22.40, align 1
  %conv68.22.40 = zext i8 %17776 to i32
  %17777 = load i8, i8* %arrayidx70.40, align 1
  %conv71.22.40 = zext i8 %17777 to i32
  %xor72.22.40 = xor i32 %conv71.22.40, %conv68.22.40
  %conv73.22.40 = trunc i32 %xor72.22.40 to i8
  store i8 %conv73.22.40, i8* %arrayidx70.40, align 1
  %scevgep20.23.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 23
  %17778 = load i8, i8* %scevgep20.23.40, align 1
  %conv68.23.40 = zext i8 %17778 to i32
  %17779 = load i8, i8* %arrayidx70.40, align 1
  %conv71.23.40 = zext i8 %17779 to i32
  %xor72.23.40 = xor i32 %conv71.23.40, %conv68.23.40
  %conv73.23.40 = trunc i32 %xor72.23.40 to i8
  store i8 %conv73.23.40, i8* %arrayidx70.40, align 1
  %scevgep20.24.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 24
  %17780 = load i8, i8* %scevgep20.24.40, align 1
  %conv68.24.40 = zext i8 %17780 to i32
  %17781 = load i8, i8* %arrayidx70.40, align 1
  %conv71.24.40 = zext i8 %17781 to i32
  %xor72.24.40 = xor i32 %conv71.24.40, %conv68.24.40
  %conv73.24.40 = trunc i32 %xor72.24.40 to i8
  store i8 %conv73.24.40, i8* %arrayidx70.40, align 1
  %scevgep20.25.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 25
  %17782 = load i8, i8* %scevgep20.25.40, align 1
  %conv68.25.40 = zext i8 %17782 to i32
  %17783 = load i8, i8* %arrayidx70.40, align 1
  %conv71.25.40 = zext i8 %17783 to i32
  %xor72.25.40 = xor i32 %conv71.25.40, %conv68.25.40
  %conv73.25.40 = trunc i32 %xor72.25.40 to i8
  store i8 %conv73.25.40, i8* %arrayidx70.40, align 1
  %scevgep20.26.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 26
  %17784 = load i8, i8* %scevgep20.26.40, align 1
  %conv68.26.40 = zext i8 %17784 to i32
  %17785 = load i8, i8* %arrayidx70.40, align 1
  %conv71.26.40 = zext i8 %17785 to i32
  %xor72.26.40 = xor i32 %conv71.26.40, %conv68.26.40
  %conv73.26.40 = trunc i32 %xor72.26.40 to i8
  store i8 %conv73.26.40, i8* %arrayidx70.40, align 1
  %scevgep20.27.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 27
  %17786 = load i8, i8* %scevgep20.27.40, align 1
  %conv68.27.40 = zext i8 %17786 to i32
  %17787 = load i8, i8* %arrayidx70.40, align 1
  %conv71.27.40 = zext i8 %17787 to i32
  %xor72.27.40 = xor i32 %conv71.27.40, %conv68.27.40
  %conv73.27.40 = trunc i32 %xor72.27.40 to i8
  store i8 %conv73.27.40, i8* %arrayidx70.40, align 1
  %scevgep20.28.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 28
  %17788 = load i8, i8* %scevgep20.28.40, align 1
  %conv68.28.40 = zext i8 %17788 to i32
  %17789 = load i8, i8* %arrayidx70.40, align 1
  %conv71.28.40 = zext i8 %17789 to i32
  %xor72.28.40 = xor i32 %conv71.28.40, %conv68.28.40
  %conv73.28.40 = trunc i32 %xor72.28.40 to i8
  store i8 %conv73.28.40, i8* %arrayidx70.40, align 1
  %scevgep20.29.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 29
  %17790 = load i8, i8* %scevgep20.29.40, align 1
  %conv68.29.40 = zext i8 %17790 to i32
  %17791 = load i8, i8* %arrayidx70.40, align 1
  %conv71.29.40 = zext i8 %17791 to i32
  %xor72.29.40 = xor i32 %conv71.29.40, %conv68.29.40
  %conv73.29.40 = trunc i32 %xor72.29.40 to i8
  store i8 %conv73.29.40, i8* %arrayidx70.40, align 1
  %scevgep20.30.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 30
  %17792 = load i8, i8* %scevgep20.30.40, align 1
  %conv68.30.40 = zext i8 %17792 to i32
  %17793 = load i8, i8* %arrayidx70.40, align 1
  %conv71.30.40 = zext i8 %17793 to i32
  %xor72.30.40 = xor i32 %conv71.30.40, %conv68.30.40
  %conv73.30.40 = trunc i32 %xor72.30.40 to i8
  store i8 %conv73.30.40, i8* %arrayidx70.40, align 1
  %scevgep20.31.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 31
  %17794 = load i8, i8* %scevgep20.31.40, align 1
  %conv68.31.40 = zext i8 %17794 to i32
  %17795 = load i8, i8* %arrayidx70.40, align 1
  %conv71.31.40 = zext i8 %17795 to i32
  %xor72.31.40 = xor i32 %conv71.31.40, %conv68.31.40
  %conv73.31.40 = trunc i32 %xor72.31.40 to i8
  store i8 %conv73.31.40, i8* %arrayidx70.40, align 1
  %scevgep20.32.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 32
  %17796 = load i8, i8* %scevgep20.32.40, align 1
  %conv68.32.40 = zext i8 %17796 to i32
  %17797 = load i8, i8* %arrayidx70.40, align 1
  %conv71.32.40 = zext i8 %17797 to i32
  %xor72.32.40 = xor i32 %conv71.32.40, %conv68.32.40
  %conv73.32.40 = trunc i32 %xor72.32.40 to i8
  store i8 %conv73.32.40, i8* %arrayidx70.40, align 1
  %scevgep20.33.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 33
  %17798 = load i8, i8* %scevgep20.33.40, align 1
  %conv68.33.40 = zext i8 %17798 to i32
  %17799 = load i8, i8* %arrayidx70.40, align 1
  %conv71.33.40 = zext i8 %17799 to i32
  %xor72.33.40 = xor i32 %conv71.33.40, %conv68.33.40
  %conv73.33.40 = trunc i32 %xor72.33.40 to i8
  store i8 %conv73.33.40, i8* %arrayidx70.40, align 1
  %scevgep20.34.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 34
  %17800 = load i8, i8* %scevgep20.34.40, align 1
  %conv68.34.40 = zext i8 %17800 to i32
  %17801 = load i8, i8* %arrayidx70.40, align 1
  %conv71.34.40 = zext i8 %17801 to i32
  %xor72.34.40 = xor i32 %conv71.34.40, %conv68.34.40
  %conv73.34.40 = trunc i32 %xor72.34.40 to i8
  store i8 %conv73.34.40, i8* %arrayidx70.40, align 1
  %scevgep20.35.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 35
  %17802 = load i8, i8* %scevgep20.35.40, align 1
  %conv68.35.40 = zext i8 %17802 to i32
  %17803 = load i8, i8* %arrayidx70.40, align 1
  %conv71.35.40 = zext i8 %17803 to i32
  %xor72.35.40 = xor i32 %conv71.35.40, %conv68.35.40
  %conv73.35.40 = trunc i32 %xor72.35.40 to i8
  store i8 %conv73.35.40, i8* %arrayidx70.40, align 1
  %scevgep20.36.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 36
  %17804 = load i8, i8* %scevgep20.36.40, align 1
  %conv68.36.40 = zext i8 %17804 to i32
  %17805 = load i8, i8* %arrayidx70.40, align 1
  %conv71.36.40 = zext i8 %17805 to i32
  %xor72.36.40 = xor i32 %conv71.36.40, %conv68.36.40
  %conv73.36.40 = trunc i32 %xor72.36.40 to i8
  store i8 %conv73.36.40, i8* %arrayidx70.40, align 1
  %scevgep20.37.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 37
  %17806 = load i8, i8* %scevgep20.37.40, align 1
  %conv68.37.40 = zext i8 %17806 to i32
  %17807 = load i8, i8* %arrayidx70.40, align 1
  %conv71.37.40 = zext i8 %17807 to i32
  %xor72.37.40 = xor i32 %conv71.37.40, %conv68.37.40
  %conv73.37.40 = trunc i32 %xor72.37.40 to i8
  store i8 %conv73.37.40, i8* %arrayidx70.40, align 1
  %scevgep20.38.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 38
  %17808 = load i8, i8* %scevgep20.38.40, align 1
  %conv68.38.40 = zext i8 %17808 to i32
  %17809 = load i8, i8* %arrayidx70.40, align 1
  %conv71.38.40 = zext i8 %17809 to i32
  %xor72.38.40 = xor i32 %conv71.38.40, %conv68.38.40
  %conv73.38.40 = trunc i32 %xor72.38.40 to i8
  store i8 %conv73.38.40, i8* %arrayidx70.40, align 1
  %scevgep20.39.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 39
  %17810 = load i8, i8* %scevgep20.39.40, align 1
  %conv68.39.40 = zext i8 %17810 to i32
  %17811 = load i8, i8* %arrayidx70.40, align 1
  %conv71.39.40 = zext i8 %17811 to i32
  %xor72.39.40 = xor i32 %conv71.39.40, %conv68.39.40
  %conv73.39.40 = trunc i32 %xor72.39.40 to i8
  store i8 %conv73.39.40, i8* %arrayidx70.40, align 1
  %scevgep20.41.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 41
  %17812 = load i8, i8* %scevgep20.41.40, align 1
  %conv68.41.40 = zext i8 %17812 to i32
  %17813 = load i8, i8* %arrayidx70.40, align 1
  %conv71.41.40 = zext i8 %17813 to i32
  %xor72.41.40 = xor i32 %conv71.41.40, %conv68.41.40
  %conv73.41.40 = trunc i32 %xor72.41.40 to i8
  store i8 %conv73.41.40, i8* %arrayidx70.40, align 1
  %scevgep20.42.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 42
  %17814 = load i8, i8* %scevgep20.42.40, align 1
  %conv68.42.40 = zext i8 %17814 to i32
  %17815 = load i8, i8* %arrayidx70.40, align 1
  %conv71.42.40 = zext i8 %17815 to i32
  %xor72.42.40 = xor i32 %conv71.42.40, %conv68.42.40
  %conv73.42.40 = trunc i32 %xor72.42.40 to i8
  store i8 %conv73.42.40, i8* %arrayidx70.40, align 1
  %scevgep20.43.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 43
  %17816 = load i8, i8* %scevgep20.43.40, align 1
  %conv68.43.40 = zext i8 %17816 to i32
  %17817 = load i8, i8* %arrayidx70.40, align 1
  %conv71.43.40 = zext i8 %17817 to i32
  %xor72.43.40 = xor i32 %conv71.43.40, %conv68.43.40
  %conv73.43.40 = trunc i32 %xor72.43.40 to i8
  store i8 %conv73.43.40, i8* %arrayidx70.40, align 1
  %scevgep20.44.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 44
  %17818 = load i8, i8* %scevgep20.44.40, align 1
  %conv68.44.40 = zext i8 %17818 to i32
  %17819 = load i8, i8* %arrayidx70.40, align 1
  %conv71.44.40 = zext i8 %17819 to i32
  %xor72.44.40 = xor i32 %conv71.44.40, %conv68.44.40
  %conv73.44.40 = trunc i32 %xor72.44.40 to i8
  store i8 %conv73.44.40, i8* %arrayidx70.40, align 1
  %scevgep20.45.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 45
  %17820 = load i8, i8* %scevgep20.45.40, align 1
  %conv68.45.40 = zext i8 %17820 to i32
  %17821 = load i8, i8* %arrayidx70.40, align 1
  %conv71.45.40 = zext i8 %17821 to i32
  %xor72.45.40 = xor i32 %conv71.45.40, %conv68.45.40
  %conv73.45.40 = trunc i32 %xor72.45.40 to i8
  store i8 %conv73.45.40, i8* %arrayidx70.40, align 1
  %scevgep20.46.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 46
  %17822 = load i8, i8* %scevgep20.46.40, align 1
  %conv68.46.40 = zext i8 %17822 to i32
  %17823 = load i8, i8* %arrayidx70.40, align 1
  %conv71.46.40 = zext i8 %17823 to i32
  %xor72.46.40 = xor i32 %conv71.46.40, %conv68.46.40
  %conv73.46.40 = trunc i32 %xor72.46.40 to i8
  store i8 %conv73.46.40, i8* %arrayidx70.40, align 1
  %scevgep20.47.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 47
  %17824 = load i8, i8* %scevgep20.47.40, align 1
  %conv68.47.40 = zext i8 %17824 to i32
  %17825 = load i8, i8* %arrayidx70.40, align 1
  %conv71.47.40 = zext i8 %17825 to i32
  %xor72.47.40 = xor i32 %conv71.47.40, %conv68.47.40
  %conv73.47.40 = trunc i32 %xor72.47.40 to i8
  store i8 %conv73.47.40, i8* %arrayidx70.40, align 1
  %scevgep20.48.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 48
  %17826 = load i8, i8* %scevgep20.48.40, align 1
  %conv68.48.40 = zext i8 %17826 to i32
  %17827 = load i8, i8* %arrayidx70.40, align 1
  %conv71.48.40 = zext i8 %17827 to i32
  %xor72.48.40 = xor i32 %conv71.48.40, %conv68.48.40
  %conv73.48.40 = trunc i32 %xor72.48.40 to i8
  store i8 %conv73.48.40, i8* %arrayidx70.40, align 1
  %scevgep20.49.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 49
  %17828 = load i8, i8* %scevgep20.49.40, align 1
  %conv68.49.40 = zext i8 %17828 to i32
  %17829 = load i8, i8* %arrayidx70.40, align 1
  %conv71.49.40 = zext i8 %17829 to i32
  %xor72.49.40 = xor i32 %conv71.49.40, %conv68.49.40
  %conv73.49.40 = trunc i32 %xor72.49.40 to i8
  store i8 %conv73.49.40, i8* %arrayidx70.40, align 1
  %scevgep20.50.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 50
  %17830 = load i8, i8* %scevgep20.50.40, align 1
  %conv68.50.40 = zext i8 %17830 to i32
  %17831 = load i8, i8* %arrayidx70.40, align 1
  %conv71.50.40 = zext i8 %17831 to i32
  %xor72.50.40 = xor i32 %conv71.50.40, %conv68.50.40
  %conv73.50.40 = trunc i32 %xor72.50.40 to i8
  store i8 %conv73.50.40, i8* %arrayidx70.40, align 1
  %scevgep20.51.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 51
  %17832 = load i8, i8* %scevgep20.51.40, align 1
  %conv68.51.40 = zext i8 %17832 to i32
  %17833 = load i8, i8* %arrayidx70.40, align 1
  %conv71.51.40 = zext i8 %17833 to i32
  %xor72.51.40 = xor i32 %conv71.51.40, %conv68.51.40
  %conv73.51.40 = trunc i32 %xor72.51.40 to i8
  store i8 %conv73.51.40, i8* %arrayidx70.40, align 1
  %scevgep20.52.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 52
  %17834 = load i8, i8* %scevgep20.52.40, align 1
  %conv68.52.40 = zext i8 %17834 to i32
  %17835 = load i8, i8* %arrayidx70.40, align 1
  %conv71.52.40 = zext i8 %17835 to i32
  %xor72.52.40 = xor i32 %conv71.52.40, %conv68.52.40
  %conv73.52.40 = trunc i32 %xor72.52.40 to i8
  store i8 %conv73.52.40, i8* %arrayidx70.40, align 1
  %scevgep20.53.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 53
  %17836 = load i8, i8* %scevgep20.53.40, align 1
  %conv68.53.40 = zext i8 %17836 to i32
  %17837 = load i8, i8* %arrayidx70.40, align 1
  %conv71.53.40 = zext i8 %17837 to i32
  %xor72.53.40 = xor i32 %conv71.53.40, %conv68.53.40
  %conv73.53.40 = trunc i32 %xor72.53.40 to i8
  store i8 %conv73.53.40, i8* %arrayidx70.40, align 1
  %scevgep20.54.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 54
  %17838 = load i8, i8* %scevgep20.54.40, align 1
  %conv68.54.40 = zext i8 %17838 to i32
  %17839 = load i8, i8* %arrayidx70.40, align 1
  %conv71.54.40 = zext i8 %17839 to i32
  %xor72.54.40 = xor i32 %conv71.54.40, %conv68.54.40
  %conv73.54.40 = trunc i32 %xor72.54.40 to i8
  store i8 %conv73.54.40, i8* %arrayidx70.40, align 1
  %scevgep20.55.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 55
  %17840 = load i8, i8* %scevgep20.55.40, align 1
  %conv68.55.40 = zext i8 %17840 to i32
  %17841 = load i8, i8* %arrayidx70.40, align 1
  %conv71.55.40 = zext i8 %17841 to i32
  %xor72.55.40 = xor i32 %conv71.55.40, %conv68.55.40
  %conv73.55.40 = trunc i32 %xor72.55.40 to i8
  store i8 %conv73.55.40, i8* %arrayidx70.40, align 1
  %scevgep20.56.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 56
  %17842 = load i8, i8* %scevgep20.56.40, align 1
  %conv68.56.40 = zext i8 %17842 to i32
  %17843 = load i8, i8* %arrayidx70.40, align 1
  %conv71.56.40 = zext i8 %17843 to i32
  %xor72.56.40 = xor i32 %conv71.56.40, %conv68.56.40
  %conv73.56.40 = trunc i32 %xor72.56.40 to i8
  store i8 %conv73.56.40, i8* %arrayidx70.40, align 1
  %scevgep20.57.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 57
  %17844 = load i8, i8* %scevgep20.57.40, align 1
  %conv68.57.40 = zext i8 %17844 to i32
  %17845 = load i8, i8* %arrayidx70.40, align 1
  %conv71.57.40 = zext i8 %17845 to i32
  %xor72.57.40 = xor i32 %conv71.57.40, %conv68.57.40
  %conv73.57.40 = trunc i32 %xor72.57.40 to i8
  store i8 %conv73.57.40, i8* %arrayidx70.40, align 1
  %scevgep20.58.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 58
  %17846 = load i8, i8* %scevgep20.58.40, align 1
  %conv68.58.40 = zext i8 %17846 to i32
  %17847 = load i8, i8* %arrayidx70.40, align 1
  %conv71.58.40 = zext i8 %17847 to i32
  %xor72.58.40 = xor i32 %conv71.58.40, %conv68.58.40
  %conv73.58.40 = trunc i32 %xor72.58.40 to i8
  store i8 %conv73.58.40, i8* %arrayidx70.40, align 1
  %scevgep20.59.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 59
  %17848 = load i8, i8* %scevgep20.59.40, align 1
  %conv68.59.40 = zext i8 %17848 to i32
  %17849 = load i8, i8* %arrayidx70.40, align 1
  %conv71.59.40 = zext i8 %17849 to i32
  %xor72.59.40 = xor i32 %conv71.59.40, %conv68.59.40
  %conv73.59.40 = trunc i32 %xor72.59.40 to i8
  store i8 %conv73.59.40, i8* %arrayidx70.40, align 1
  %scevgep20.60.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 0, i64 60
  %17850 = load i8, i8* %scevgep20.60.40, align 1
  %conv68.60.40 = zext i8 %17850 to i32
  %17851 = load i8, i8* %arrayidx70.40, align 1
  %conv71.60.40 = zext i8 %17851 to i32
  %xor72.60.40 = xor i32 %conv71.60.40, %conv68.60.40
  %conv73.60.40 = trunc i32 %xor72.60.40 to i8
  store i8 %conv73.60.40, i8* %arrayidx70.40, align 1
  %scevgep19.40 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17729, i64 0, i64 1, i64 0
  %17852 = bitcast i8* %scevgep19.40 to [61 x [61 x i8]]*
  %arrayidx51.41 = getelementptr inbounds i8, i8* %a, i64 41
  %17853 = load i8, i8* %arrayidx51.41, align 1
  %arrayidx53.41 = getelementptr inbounds i8, i8* %b, i64 41
  %17854 = load i8, i8* %arrayidx53.41, align 1
  %call54.41 = call zeroext i8 @mult(i8 zeroext %17853, i8 zeroext %17854)
  %arrayidx56.41 = getelementptr inbounds i8, i8* %c, i64 41
  store i8 %call54.41, i8* %arrayidx56.41, align 1
  %arrayidx70.41 = getelementptr inbounds i8, i8* %c, i64 41
  %scevgep20.41454 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 0
  %17855 = load i8, i8* %scevgep20.41454, align 1
  %conv68.41455 = zext i8 %17855 to i32
  %17856 = load i8, i8* %arrayidx70.41, align 1
  %conv71.41456 = zext i8 %17856 to i32
  %xor72.41457 = xor i32 %conv71.41456, %conv68.41455
  %conv73.41458 = trunc i32 %xor72.41457 to i8
  store i8 %conv73.41458, i8* %arrayidx70.41, align 1
  %scevgep20.1.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 1
  %17857 = load i8, i8* %scevgep20.1.41, align 1
  %conv68.1.41 = zext i8 %17857 to i32
  %17858 = load i8, i8* %arrayidx70.41, align 1
  %conv71.1.41 = zext i8 %17858 to i32
  %xor72.1.41 = xor i32 %conv71.1.41, %conv68.1.41
  %conv73.1.41 = trunc i32 %xor72.1.41 to i8
  store i8 %conv73.1.41, i8* %arrayidx70.41, align 1
  %scevgep20.2.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 2
  %17859 = load i8, i8* %scevgep20.2.41, align 1
  %conv68.2.41 = zext i8 %17859 to i32
  %17860 = load i8, i8* %arrayidx70.41, align 1
  %conv71.2.41 = zext i8 %17860 to i32
  %xor72.2.41 = xor i32 %conv71.2.41, %conv68.2.41
  %conv73.2.41 = trunc i32 %xor72.2.41 to i8
  store i8 %conv73.2.41, i8* %arrayidx70.41, align 1
  %scevgep20.3.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 3
  %17861 = load i8, i8* %scevgep20.3.41, align 1
  %conv68.3.41 = zext i8 %17861 to i32
  %17862 = load i8, i8* %arrayidx70.41, align 1
  %conv71.3.41 = zext i8 %17862 to i32
  %xor72.3.41 = xor i32 %conv71.3.41, %conv68.3.41
  %conv73.3.41 = trunc i32 %xor72.3.41 to i8
  store i8 %conv73.3.41, i8* %arrayidx70.41, align 1
  %scevgep20.4.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 4
  %17863 = load i8, i8* %scevgep20.4.41, align 1
  %conv68.4.41 = zext i8 %17863 to i32
  %17864 = load i8, i8* %arrayidx70.41, align 1
  %conv71.4.41 = zext i8 %17864 to i32
  %xor72.4.41 = xor i32 %conv71.4.41, %conv68.4.41
  %conv73.4.41 = trunc i32 %xor72.4.41 to i8
  store i8 %conv73.4.41, i8* %arrayidx70.41, align 1
  %scevgep20.5.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 5
  %17865 = load i8, i8* %scevgep20.5.41, align 1
  %conv68.5.41 = zext i8 %17865 to i32
  %17866 = load i8, i8* %arrayidx70.41, align 1
  %conv71.5.41 = zext i8 %17866 to i32
  %xor72.5.41 = xor i32 %conv71.5.41, %conv68.5.41
  %conv73.5.41 = trunc i32 %xor72.5.41 to i8
  store i8 %conv73.5.41, i8* %arrayidx70.41, align 1
  %scevgep20.6.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 6
  %17867 = load i8, i8* %scevgep20.6.41, align 1
  %conv68.6.41 = zext i8 %17867 to i32
  %17868 = load i8, i8* %arrayidx70.41, align 1
  %conv71.6.41 = zext i8 %17868 to i32
  %xor72.6.41 = xor i32 %conv71.6.41, %conv68.6.41
  %conv73.6.41 = trunc i32 %xor72.6.41 to i8
  store i8 %conv73.6.41, i8* %arrayidx70.41, align 1
  %scevgep20.7.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 7
  %17869 = load i8, i8* %scevgep20.7.41, align 1
  %conv68.7.41 = zext i8 %17869 to i32
  %17870 = load i8, i8* %arrayidx70.41, align 1
  %conv71.7.41 = zext i8 %17870 to i32
  %xor72.7.41 = xor i32 %conv71.7.41, %conv68.7.41
  %conv73.7.41 = trunc i32 %xor72.7.41 to i8
  store i8 %conv73.7.41, i8* %arrayidx70.41, align 1
  %scevgep20.8.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 8
  %17871 = load i8, i8* %scevgep20.8.41, align 1
  %conv68.8.41 = zext i8 %17871 to i32
  %17872 = load i8, i8* %arrayidx70.41, align 1
  %conv71.8.41 = zext i8 %17872 to i32
  %xor72.8.41 = xor i32 %conv71.8.41, %conv68.8.41
  %conv73.8.41 = trunc i32 %xor72.8.41 to i8
  store i8 %conv73.8.41, i8* %arrayidx70.41, align 1
  %scevgep20.9.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 9
  %17873 = load i8, i8* %scevgep20.9.41, align 1
  %conv68.9.41 = zext i8 %17873 to i32
  %17874 = load i8, i8* %arrayidx70.41, align 1
  %conv71.9.41 = zext i8 %17874 to i32
  %xor72.9.41 = xor i32 %conv71.9.41, %conv68.9.41
  %conv73.9.41 = trunc i32 %xor72.9.41 to i8
  store i8 %conv73.9.41, i8* %arrayidx70.41, align 1
  %scevgep20.10.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 10
  %17875 = load i8, i8* %scevgep20.10.41, align 1
  %conv68.10.41 = zext i8 %17875 to i32
  %17876 = load i8, i8* %arrayidx70.41, align 1
  %conv71.10.41 = zext i8 %17876 to i32
  %xor72.10.41 = xor i32 %conv71.10.41, %conv68.10.41
  %conv73.10.41 = trunc i32 %xor72.10.41 to i8
  store i8 %conv73.10.41, i8* %arrayidx70.41, align 1
  %scevgep20.11.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 11
  %17877 = load i8, i8* %scevgep20.11.41, align 1
  %conv68.11.41 = zext i8 %17877 to i32
  %17878 = load i8, i8* %arrayidx70.41, align 1
  %conv71.11.41 = zext i8 %17878 to i32
  %xor72.11.41 = xor i32 %conv71.11.41, %conv68.11.41
  %conv73.11.41 = trunc i32 %xor72.11.41 to i8
  store i8 %conv73.11.41, i8* %arrayidx70.41, align 1
  %scevgep20.12.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 12
  %17879 = load i8, i8* %scevgep20.12.41, align 1
  %conv68.12.41 = zext i8 %17879 to i32
  %17880 = load i8, i8* %arrayidx70.41, align 1
  %conv71.12.41 = zext i8 %17880 to i32
  %xor72.12.41 = xor i32 %conv71.12.41, %conv68.12.41
  %conv73.12.41 = trunc i32 %xor72.12.41 to i8
  store i8 %conv73.12.41, i8* %arrayidx70.41, align 1
  %scevgep20.13.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 13
  %17881 = load i8, i8* %scevgep20.13.41, align 1
  %conv68.13.41 = zext i8 %17881 to i32
  %17882 = load i8, i8* %arrayidx70.41, align 1
  %conv71.13.41 = zext i8 %17882 to i32
  %xor72.13.41 = xor i32 %conv71.13.41, %conv68.13.41
  %conv73.13.41 = trunc i32 %xor72.13.41 to i8
  store i8 %conv73.13.41, i8* %arrayidx70.41, align 1
  %scevgep20.14.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 14
  %17883 = load i8, i8* %scevgep20.14.41, align 1
  %conv68.14.41 = zext i8 %17883 to i32
  %17884 = load i8, i8* %arrayidx70.41, align 1
  %conv71.14.41 = zext i8 %17884 to i32
  %xor72.14.41 = xor i32 %conv71.14.41, %conv68.14.41
  %conv73.14.41 = trunc i32 %xor72.14.41 to i8
  store i8 %conv73.14.41, i8* %arrayidx70.41, align 1
  %scevgep20.15.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 15
  %17885 = load i8, i8* %scevgep20.15.41, align 1
  %conv68.15.41 = zext i8 %17885 to i32
  %17886 = load i8, i8* %arrayidx70.41, align 1
  %conv71.15.41 = zext i8 %17886 to i32
  %xor72.15.41 = xor i32 %conv71.15.41, %conv68.15.41
  %conv73.15.41 = trunc i32 %xor72.15.41 to i8
  store i8 %conv73.15.41, i8* %arrayidx70.41, align 1
  %scevgep20.16.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 16
  %17887 = load i8, i8* %scevgep20.16.41, align 1
  %conv68.16.41 = zext i8 %17887 to i32
  %17888 = load i8, i8* %arrayidx70.41, align 1
  %conv71.16.41 = zext i8 %17888 to i32
  %xor72.16.41 = xor i32 %conv71.16.41, %conv68.16.41
  %conv73.16.41 = trunc i32 %xor72.16.41 to i8
  store i8 %conv73.16.41, i8* %arrayidx70.41, align 1
  %scevgep20.17.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 17
  %17889 = load i8, i8* %scevgep20.17.41, align 1
  %conv68.17.41 = zext i8 %17889 to i32
  %17890 = load i8, i8* %arrayidx70.41, align 1
  %conv71.17.41 = zext i8 %17890 to i32
  %xor72.17.41 = xor i32 %conv71.17.41, %conv68.17.41
  %conv73.17.41 = trunc i32 %xor72.17.41 to i8
  store i8 %conv73.17.41, i8* %arrayidx70.41, align 1
  %scevgep20.18.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 18
  %17891 = load i8, i8* %scevgep20.18.41, align 1
  %conv68.18.41 = zext i8 %17891 to i32
  %17892 = load i8, i8* %arrayidx70.41, align 1
  %conv71.18.41 = zext i8 %17892 to i32
  %xor72.18.41 = xor i32 %conv71.18.41, %conv68.18.41
  %conv73.18.41 = trunc i32 %xor72.18.41 to i8
  store i8 %conv73.18.41, i8* %arrayidx70.41, align 1
  %scevgep20.19.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 19
  %17893 = load i8, i8* %scevgep20.19.41, align 1
  %conv68.19.41 = zext i8 %17893 to i32
  %17894 = load i8, i8* %arrayidx70.41, align 1
  %conv71.19.41 = zext i8 %17894 to i32
  %xor72.19.41 = xor i32 %conv71.19.41, %conv68.19.41
  %conv73.19.41 = trunc i32 %xor72.19.41 to i8
  store i8 %conv73.19.41, i8* %arrayidx70.41, align 1
  %scevgep20.20.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 20
  %17895 = load i8, i8* %scevgep20.20.41, align 1
  %conv68.20.41 = zext i8 %17895 to i32
  %17896 = load i8, i8* %arrayidx70.41, align 1
  %conv71.20.41 = zext i8 %17896 to i32
  %xor72.20.41 = xor i32 %conv71.20.41, %conv68.20.41
  %conv73.20.41 = trunc i32 %xor72.20.41 to i8
  store i8 %conv73.20.41, i8* %arrayidx70.41, align 1
  %scevgep20.21.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 21
  %17897 = load i8, i8* %scevgep20.21.41, align 1
  %conv68.21.41 = zext i8 %17897 to i32
  %17898 = load i8, i8* %arrayidx70.41, align 1
  %conv71.21.41 = zext i8 %17898 to i32
  %xor72.21.41 = xor i32 %conv71.21.41, %conv68.21.41
  %conv73.21.41 = trunc i32 %xor72.21.41 to i8
  store i8 %conv73.21.41, i8* %arrayidx70.41, align 1
  %scevgep20.22.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 22
  %17899 = load i8, i8* %scevgep20.22.41, align 1
  %conv68.22.41 = zext i8 %17899 to i32
  %17900 = load i8, i8* %arrayidx70.41, align 1
  %conv71.22.41 = zext i8 %17900 to i32
  %xor72.22.41 = xor i32 %conv71.22.41, %conv68.22.41
  %conv73.22.41 = trunc i32 %xor72.22.41 to i8
  store i8 %conv73.22.41, i8* %arrayidx70.41, align 1
  %scevgep20.23.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 23
  %17901 = load i8, i8* %scevgep20.23.41, align 1
  %conv68.23.41 = zext i8 %17901 to i32
  %17902 = load i8, i8* %arrayidx70.41, align 1
  %conv71.23.41 = zext i8 %17902 to i32
  %xor72.23.41 = xor i32 %conv71.23.41, %conv68.23.41
  %conv73.23.41 = trunc i32 %xor72.23.41 to i8
  store i8 %conv73.23.41, i8* %arrayidx70.41, align 1
  %scevgep20.24.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 24
  %17903 = load i8, i8* %scevgep20.24.41, align 1
  %conv68.24.41 = zext i8 %17903 to i32
  %17904 = load i8, i8* %arrayidx70.41, align 1
  %conv71.24.41 = zext i8 %17904 to i32
  %xor72.24.41 = xor i32 %conv71.24.41, %conv68.24.41
  %conv73.24.41 = trunc i32 %xor72.24.41 to i8
  store i8 %conv73.24.41, i8* %arrayidx70.41, align 1
  %scevgep20.25.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 25
  %17905 = load i8, i8* %scevgep20.25.41, align 1
  %conv68.25.41 = zext i8 %17905 to i32
  %17906 = load i8, i8* %arrayidx70.41, align 1
  %conv71.25.41 = zext i8 %17906 to i32
  %xor72.25.41 = xor i32 %conv71.25.41, %conv68.25.41
  %conv73.25.41 = trunc i32 %xor72.25.41 to i8
  store i8 %conv73.25.41, i8* %arrayidx70.41, align 1
  %scevgep20.26.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 26
  %17907 = load i8, i8* %scevgep20.26.41, align 1
  %conv68.26.41 = zext i8 %17907 to i32
  %17908 = load i8, i8* %arrayidx70.41, align 1
  %conv71.26.41 = zext i8 %17908 to i32
  %xor72.26.41 = xor i32 %conv71.26.41, %conv68.26.41
  %conv73.26.41 = trunc i32 %xor72.26.41 to i8
  store i8 %conv73.26.41, i8* %arrayidx70.41, align 1
  %scevgep20.27.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 27
  %17909 = load i8, i8* %scevgep20.27.41, align 1
  %conv68.27.41 = zext i8 %17909 to i32
  %17910 = load i8, i8* %arrayidx70.41, align 1
  %conv71.27.41 = zext i8 %17910 to i32
  %xor72.27.41 = xor i32 %conv71.27.41, %conv68.27.41
  %conv73.27.41 = trunc i32 %xor72.27.41 to i8
  store i8 %conv73.27.41, i8* %arrayidx70.41, align 1
  %scevgep20.28.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 28
  %17911 = load i8, i8* %scevgep20.28.41, align 1
  %conv68.28.41 = zext i8 %17911 to i32
  %17912 = load i8, i8* %arrayidx70.41, align 1
  %conv71.28.41 = zext i8 %17912 to i32
  %xor72.28.41 = xor i32 %conv71.28.41, %conv68.28.41
  %conv73.28.41 = trunc i32 %xor72.28.41 to i8
  store i8 %conv73.28.41, i8* %arrayidx70.41, align 1
  %scevgep20.29.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 29
  %17913 = load i8, i8* %scevgep20.29.41, align 1
  %conv68.29.41 = zext i8 %17913 to i32
  %17914 = load i8, i8* %arrayidx70.41, align 1
  %conv71.29.41 = zext i8 %17914 to i32
  %xor72.29.41 = xor i32 %conv71.29.41, %conv68.29.41
  %conv73.29.41 = trunc i32 %xor72.29.41 to i8
  store i8 %conv73.29.41, i8* %arrayidx70.41, align 1
  %scevgep20.30.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 30
  %17915 = load i8, i8* %scevgep20.30.41, align 1
  %conv68.30.41 = zext i8 %17915 to i32
  %17916 = load i8, i8* %arrayidx70.41, align 1
  %conv71.30.41 = zext i8 %17916 to i32
  %xor72.30.41 = xor i32 %conv71.30.41, %conv68.30.41
  %conv73.30.41 = trunc i32 %xor72.30.41 to i8
  store i8 %conv73.30.41, i8* %arrayidx70.41, align 1
  %scevgep20.31.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 31
  %17917 = load i8, i8* %scevgep20.31.41, align 1
  %conv68.31.41 = zext i8 %17917 to i32
  %17918 = load i8, i8* %arrayidx70.41, align 1
  %conv71.31.41 = zext i8 %17918 to i32
  %xor72.31.41 = xor i32 %conv71.31.41, %conv68.31.41
  %conv73.31.41 = trunc i32 %xor72.31.41 to i8
  store i8 %conv73.31.41, i8* %arrayidx70.41, align 1
  %scevgep20.32.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 32
  %17919 = load i8, i8* %scevgep20.32.41, align 1
  %conv68.32.41 = zext i8 %17919 to i32
  %17920 = load i8, i8* %arrayidx70.41, align 1
  %conv71.32.41 = zext i8 %17920 to i32
  %xor72.32.41 = xor i32 %conv71.32.41, %conv68.32.41
  %conv73.32.41 = trunc i32 %xor72.32.41 to i8
  store i8 %conv73.32.41, i8* %arrayidx70.41, align 1
  %scevgep20.33.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 33
  %17921 = load i8, i8* %scevgep20.33.41, align 1
  %conv68.33.41 = zext i8 %17921 to i32
  %17922 = load i8, i8* %arrayidx70.41, align 1
  %conv71.33.41 = zext i8 %17922 to i32
  %xor72.33.41 = xor i32 %conv71.33.41, %conv68.33.41
  %conv73.33.41 = trunc i32 %xor72.33.41 to i8
  store i8 %conv73.33.41, i8* %arrayidx70.41, align 1
  %scevgep20.34.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 34
  %17923 = load i8, i8* %scevgep20.34.41, align 1
  %conv68.34.41 = zext i8 %17923 to i32
  %17924 = load i8, i8* %arrayidx70.41, align 1
  %conv71.34.41 = zext i8 %17924 to i32
  %xor72.34.41 = xor i32 %conv71.34.41, %conv68.34.41
  %conv73.34.41 = trunc i32 %xor72.34.41 to i8
  store i8 %conv73.34.41, i8* %arrayidx70.41, align 1
  %scevgep20.35.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 35
  %17925 = load i8, i8* %scevgep20.35.41, align 1
  %conv68.35.41 = zext i8 %17925 to i32
  %17926 = load i8, i8* %arrayidx70.41, align 1
  %conv71.35.41 = zext i8 %17926 to i32
  %xor72.35.41 = xor i32 %conv71.35.41, %conv68.35.41
  %conv73.35.41 = trunc i32 %xor72.35.41 to i8
  store i8 %conv73.35.41, i8* %arrayidx70.41, align 1
  %scevgep20.36.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 36
  %17927 = load i8, i8* %scevgep20.36.41, align 1
  %conv68.36.41 = zext i8 %17927 to i32
  %17928 = load i8, i8* %arrayidx70.41, align 1
  %conv71.36.41 = zext i8 %17928 to i32
  %xor72.36.41 = xor i32 %conv71.36.41, %conv68.36.41
  %conv73.36.41 = trunc i32 %xor72.36.41 to i8
  store i8 %conv73.36.41, i8* %arrayidx70.41, align 1
  %scevgep20.37.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 37
  %17929 = load i8, i8* %scevgep20.37.41, align 1
  %conv68.37.41 = zext i8 %17929 to i32
  %17930 = load i8, i8* %arrayidx70.41, align 1
  %conv71.37.41 = zext i8 %17930 to i32
  %xor72.37.41 = xor i32 %conv71.37.41, %conv68.37.41
  %conv73.37.41 = trunc i32 %xor72.37.41 to i8
  store i8 %conv73.37.41, i8* %arrayidx70.41, align 1
  %scevgep20.38.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 38
  %17931 = load i8, i8* %scevgep20.38.41, align 1
  %conv68.38.41 = zext i8 %17931 to i32
  %17932 = load i8, i8* %arrayidx70.41, align 1
  %conv71.38.41 = zext i8 %17932 to i32
  %xor72.38.41 = xor i32 %conv71.38.41, %conv68.38.41
  %conv73.38.41 = trunc i32 %xor72.38.41 to i8
  store i8 %conv73.38.41, i8* %arrayidx70.41, align 1
  %scevgep20.39.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 39
  %17933 = load i8, i8* %scevgep20.39.41, align 1
  %conv68.39.41 = zext i8 %17933 to i32
  %17934 = load i8, i8* %arrayidx70.41, align 1
  %conv71.39.41 = zext i8 %17934 to i32
  %xor72.39.41 = xor i32 %conv71.39.41, %conv68.39.41
  %conv73.39.41 = trunc i32 %xor72.39.41 to i8
  store i8 %conv73.39.41, i8* %arrayidx70.41, align 1
  %scevgep20.40.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 40
  %17935 = load i8, i8* %scevgep20.40.41, align 1
  %conv68.40.41 = zext i8 %17935 to i32
  %17936 = load i8, i8* %arrayidx70.41, align 1
  %conv71.40.41 = zext i8 %17936 to i32
  %xor72.40.41 = xor i32 %conv71.40.41, %conv68.40.41
  %conv73.40.41 = trunc i32 %xor72.40.41 to i8
  store i8 %conv73.40.41, i8* %arrayidx70.41, align 1
  %scevgep20.42.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 42
  %17937 = load i8, i8* %scevgep20.42.41, align 1
  %conv68.42.41 = zext i8 %17937 to i32
  %17938 = load i8, i8* %arrayidx70.41, align 1
  %conv71.42.41 = zext i8 %17938 to i32
  %xor72.42.41 = xor i32 %conv71.42.41, %conv68.42.41
  %conv73.42.41 = trunc i32 %xor72.42.41 to i8
  store i8 %conv73.42.41, i8* %arrayidx70.41, align 1
  %scevgep20.43.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 43
  %17939 = load i8, i8* %scevgep20.43.41, align 1
  %conv68.43.41 = zext i8 %17939 to i32
  %17940 = load i8, i8* %arrayidx70.41, align 1
  %conv71.43.41 = zext i8 %17940 to i32
  %xor72.43.41 = xor i32 %conv71.43.41, %conv68.43.41
  %conv73.43.41 = trunc i32 %xor72.43.41 to i8
  store i8 %conv73.43.41, i8* %arrayidx70.41, align 1
  %scevgep20.44.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 44
  %17941 = load i8, i8* %scevgep20.44.41, align 1
  %conv68.44.41 = zext i8 %17941 to i32
  %17942 = load i8, i8* %arrayidx70.41, align 1
  %conv71.44.41 = zext i8 %17942 to i32
  %xor72.44.41 = xor i32 %conv71.44.41, %conv68.44.41
  %conv73.44.41 = trunc i32 %xor72.44.41 to i8
  store i8 %conv73.44.41, i8* %arrayidx70.41, align 1
  %scevgep20.45.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 45
  %17943 = load i8, i8* %scevgep20.45.41, align 1
  %conv68.45.41 = zext i8 %17943 to i32
  %17944 = load i8, i8* %arrayidx70.41, align 1
  %conv71.45.41 = zext i8 %17944 to i32
  %xor72.45.41 = xor i32 %conv71.45.41, %conv68.45.41
  %conv73.45.41 = trunc i32 %xor72.45.41 to i8
  store i8 %conv73.45.41, i8* %arrayidx70.41, align 1
  %scevgep20.46.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 46
  %17945 = load i8, i8* %scevgep20.46.41, align 1
  %conv68.46.41 = zext i8 %17945 to i32
  %17946 = load i8, i8* %arrayidx70.41, align 1
  %conv71.46.41 = zext i8 %17946 to i32
  %xor72.46.41 = xor i32 %conv71.46.41, %conv68.46.41
  %conv73.46.41 = trunc i32 %xor72.46.41 to i8
  store i8 %conv73.46.41, i8* %arrayidx70.41, align 1
  %scevgep20.47.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 47
  %17947 = load i8, i8* %scevgep20.47.41, align 1
  %conv68.47.41 = zext i8 %17947 to i32
  %17948 = load i8, i8* %arrayidx70.41, align 1
  %conv71.47.41 = zext i8 %17948 to i32
  %xor72.47.41 = xor i32 %conv71.47.41, %conv68.47.41
  %conv73.47.41 = trunc i32 %xor72.47.41 to i8
  store i8 %conv73.47.41, i8* %arrayidx70.41, align 1
  %scevgep20.48.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 48
  %17949 = load i8, i8* %scevgep20.48.41, align 1
  %conv68.48.41 = zext i8 %17949 to i32
  %17950 = load i8, i8* %arrayidx70.41, align 1
  %conv71.48.41 = zext i8 %17950 to i32
  %xor72.48.41 = xor i32 %conv71.48.41, %conv68.48.41
  %conv73.48.41 = trunc i32 %xor72.48.41 to i8
  store i8 %conv73.48.41, i8* %arrayidx70.41, align 1
  %scevgep20.49.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 49
  %17951 = load i8, i8* %scevgep20.49.41, align 1
  %conv68.49.41 = zext i8 %17951 to i32
  %17952 = load i8, i8* %arrayidx70.41, align 1
  %conv71.49.41 = zext i8 %17952 to i32
  %xor72.49.41 = xor i32 %conv71.49.41, %conv68.49.41
  %conv73.49.41 = trunc i32 %xor72.49.41 to i8
  store i8 %conv73.49.41, i8* %arrayidx70.41, align 1
  %scevgep20.50.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 50
  %17953 = load i8, i8* %scevgep20.50.41, align 1
  %conv68.50.41 = zext i8 %17953 to i32
  %17954 = load i8, i8* %arrayidx70.41, align 1
  %conv71.50.41 = zext i8 %17954 to i32
  %xor72.50.41 = xor i32 %conv71.50.41, %conv68.50.41
  %conv73.50.41 = trunc i32 %xor72.50.41 to i8
  store i8 %conv73.50.41, i8* %arrayidx70.41, align 1
  %scevgep20.51.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 51
  %17955 = load i8, i8* %scevgep20.51.41, align 1
  %conv68.51.41 = zext i8 %17955 to i32
  %17956 = load i8, i8* %arrayidx70.41, align 1
  %conv71.51.41 = zext i8 %17956 to i32
  %xor72.51.41 = xor i32 %conv71.51.41, %conv68.51.41
  %conv73.51.41 = trunc i32 %xor72.51.41 to i8
  store i8 %conv73.51.41, i8* %arrayidx70.41, align 1
  %scevgep20.52.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 52
  %17957 = load i8, i8* %scevgep20.52.41, align 1
  %conv68.52.41 = zext i8 %17957 to i32
  %17958 = load i8, i8* %arrayidx70.41, align 1
  %conv71.52.41 = zext i8 %17958 to i32
  %xor72.52.41 = xor i32 %conv71.52.41, %conv68.52.41
  %conv73.52.41 = trunc i32 %xor72.52.41 to i8
  store i8 %conv73.52.41, i8* %arrayidx70.41, align 1
  %scevgep20.53.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 53
  %17959 = load i8, i8* %scevgep20.53.41, align 1
  %conv68.53.41 = zext i8 %17959 to i32
  %17960 = load i8, i8* %arrayidx70.41, align 1
  %conv71.53.41 = zext i8 %17960 to i32
  %xor72.53.41 = xor i32 %conv71.53.41, %conv68.53.41
  %conv73.53.41 = trunc i32 %xor72.53.41 to i8
  store i8 %conv73.53.41, i8* %arrayidx70.41, align 1
  %scevgep20.54.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 54
  %17961 = load i8, i8* %scevgep20.54.41, align 1
  %conv68.54.41 = zext i8 %17961 to i32
  %17962 = load i8, i8* %arrayidx70.41, align 1
  %conv71.54.41 = zext i8 %17962 to i32
  %xor72.54.41 = xor i32 %conv71.54.41, %conv68.54.41
  %conv73.54.41 = trunc i32 %xor72.54.41 to i8
  store i8 %conv73.54.41, i8* %arrayidx70.41, align 1
  %scevgep20.55.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 55
  %17963 = load i8, i8* %scevgep20.55.41, align 1
  %conv68.55.41 = zext i8 %17963 to i32
  %17964 = load i8, i8* %arrayidx70.41, align 1
  %conv71.55.41 = zext i8 %17964 to i32
  %xor72.55.41 = xor i32 %conv71.55.41, %conv68.55.41
  %conv73.55.41 = trunc i32 %xor72.55.41 to i8
  store i8 %conv73.55.41, i8* %arrayidx70.41, align 1
  %scevgep20.56.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 56
  %17965 = load i8, i8* %scevgep20.56.41, align 1
  %conv68.56.41 = zext i8 %17965 to i32
  %17966 = load i8, i8* %arrayidx70.41, align 1
  %conv71.56.41 = zext i8 %17966 to i32
  %xor72.56.41 = xor i32 %conv71.56.41, %conv68.56.41
  %conv73.56.41 = trunc i32 %xor72.56.41 to i8
  store i8 %conv73.56.41, i8* %arrayidx70.41, align 1
  %scevgep20.57.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 57
  %17967 = load i8, i8* %scevgep20.57.41, align 1
  %conv68.57.41 = zext i8 %17967 to i32
  %17968 = load i8, i8* %arrayidx70.41, align 1
  %conv71.57.41 = zext i8 %17968 to i32
  %xor72.57.41 = xor i32 %conv71.57.41, %conv68.57.41
  %conv73.57.41 = trunc i32 %xor72.57.41 to i8
  store i8 %conv73.57.41, i8* %arrayidx70.41, align 1
  %scevgep20.58.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 58
  %17969 = load i8, i8* %scevgep20.58.41, align 1
  %conv68.58.41 = zext i8 %17969 to i32
  %17970 = load i8, i8* %arrayidx70.41, align 1
  %conv71.58.41 = zext i8 %17970 to i32
  %xor72.58.41 = xor i32 %conv71.58.41, %conv68.58.41
  %conv73.58.41 = trunc i32 %xor72.58.41 to i8
  store i8 %conv73.58.41, i8* %arrayidx70.41, align 1
  %scevgep20.59.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 59
  %17971 = load i8, i8* %scevgep20.59.41, align 1
  %conv68.59.41 = zext i8 %17971 to i32
  %17972 = load i8, i8* %arrayidx70.41, align 1
  %conv71.59.41 = zext i8 %17972 to i32
  %xor72.59.41 = xor i32 %conv71.59.41, %conv68.59.41
  %conv73.59.41 = trunc i32 %xor72.59.41 to i8
  store i8 %conv73.59.41, i8* %arrayidx70.41, align 1
  %scevgep20.60.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 0, i64 60
  %17973 = load i8, i8* %scevgep20.60.41, align 1
  %conv68.60.41 = zext i8 %17973 to i32
  %17974 = load i8, i8* %arrayidx70.41, align 1
  %conv71.60.41 = zext i8 %17974 to i32
  %xor72.60.41 = xor i32 %conv71.60.41, %conv68.60.41
  %conv73.60.41 = trunc i32 %xor72.60.41 to i8
  store i8 %conv73.60.41, i8* %arrayidx70.41, align 1
  %scevgep19.41 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17852, i64 0, i64 1, i64 0
  %17975 = bitcast i8* %scevgep19.41 to [61 x [61 x i8]]*
  %arrayidx51.42 = getelementptr inbounds i8, i8* %a, i64 42
  %17976 = load i8, i8* %arrayidx51.42, align 1
  %arrayidx53.42 = getelementptr inbounds i8, i8* %b, i64 42
  %17977 = load i8, i8* %arrayidx53.42, align 1
  %call54.42 = call zeroext i8 @mult(i8 zeroext %17976, i8 zeroext %17977)
  %arrayidx56.42 = getelementptr inbounds i8, i8* %c, i64 42
  store i8 %call54.42, i8* %arrayidx56.42, align 1
  %arrayidx70.42 = getelementptr inbounds i8, i8* %c, i64 42
  %scevgep20.42464 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 0
  %17978 = load i8, i8* %scevgep20.42464, align 1
  %conv68.42465 = zext i8 %17978 to i32
  %17979 = load i8, i8* %arrayidx70.42, align 1
  %conv71.42466 = zext i8 %17979 to i32
  %xor72.42467 = xor i32 %conv71.42466, %conv68.42465
  %conv73.42468 = trunc i32 %xor72.42467 to i8
  store i8 %conv73.42468, i8* %arrayidx70.42, align 1
  %scevgep20.1.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 1
  %17980 = load i8, i8* %scevgep20.1.42, align 1
  %conv68.1.42 = zext i8 %17980 to i32
  %17981 = load i8, i8* %arrayidx70.42, align 1
  %conv71.1.42 = zext i8 %17981 to i32
  %xor72.1.42 = xor i32 %conv71.1.42, %conv68.1.42
  %conv73.1.42 = trunc i32 %xor72.1.42 to i8
  store i8 %conv73.1.42, i8* %arrayidx70.42, align 1
  %scevgep20.2.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 2
  %17982 = load i8, i8* %scevgep20.2.42, align 1
  %conv68.2.42 = zext i8 %17982 to i32
  %17983 = load i8, i8* %arrayidx70.42, align 1
  %conv71.2.42 = zext i8 %17983 to i32
  %xor72.2.42 = xor i32 %conv71.2.42, %conv68.2.42
  %conv73.2.42 = trunc i32 %xor72.2.42 to i8
  store i8 %conv73.2.42, i8* %arrayidx70.42, align 1
  %scevgep20.3.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 3
  %17984 = load i8, i8* %scevgep20.3.42, align 1
  %conv68.3.42 = zext i8 %17984 to i32
  %17985 = load i8, i8* %arrayidx70.42, align 1
  %conv71.3.42 = zext i8 %17985 to i32
  %xor72.3.42 = xor i32 %conv71.3.42, %conv68.3.42
  %conv73.3.42 = trunc i32 %xor72.3.42 to i8
  store i8 %conv73.3.42, i8* %arrayidx70.42, align 1
  %scevgep20.4.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 4
  %17986 = load i8, i8* %scevgep20.4.42, align 1
  %conv68.4.42 = zext i8 %17986 to i32
  %17987 = load i8, i8* %arrayidx70.42, align 1
  %conv71.4.42 = zext i8 %17987 to i32
  %xor72.4.42 = xor i32 %conv71.4.42, %conv68.4.42
  %conv73.4.42 = trunc i32 %xor72.4.42 to i8
  store i8 %conv73.4.42, i8* %arrayidx70.42, align 1
  %scevgep20.5.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 5
  %17988 = load i8, i8* %scevgep20.5.42, align 1
  %conv68.5.42 = zext i8 %17988 to i32
  %17989 = load i8, i8* %arrayidx70.42, align 1
  %conv71.5.42 = zext i8 %17989 to i32
  %xor72.5.42 = xor i32 %conv71.5.42, %conv68.5.42
  %conv73.5.42 = trunc i32 %xor72.5.42 to i8
  store i8 %conv73.5.42, i8* %arrayidx70.42, align 1
  %scevgep20.6.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 6
  %17990 = load i8, i8* %scevgep20.6.42, align 1
  %conv68.6.42 = zext i8 %17990 to i32
  %17991 = load i8, i8* %arrayidx70.42, align 1
  %conv71.6.42 = zext i8 %17991 to i32
  %xor72.6.42 = xor i32 %conv71.6.42, %conv68.6.42
  %conv73.6.42 = trunc i32 %xor72.6.42 to i8
  store i8 %conv73.6.42, i8* %arrayidx70.42, align 1
  %scevgep20.7.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 7
  %17992 = load i8, i8* %scevgep20.7.42, align 1
  %conv68.7.42 = zext i8 %17992 to i32
  %17993 = load i8, i8* %arrayidx70.42, align 1
  %conv71.7.42 = zext i8 %17993 to i32
  %xor72.7.42 = xor i32 %conv71.7.42, %conv68.7.42
  %conv73.7.42 = trunc i32 %xor72.7.42 to i8
  store i8 %conv73.7.42, i8* %arrayidx70.42, align 1
  %scevgep20.8.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 8
  %17994 = load i8, i8* %scevgep20.8.42, align 1
  %conv68.8.42 = zext i8 %17994 to i32
  %17995 = load i8, i8* %arrayidx70.42, align 1
  %conv71.8.42 = zext i8 %17995 to i32
  %xor72.8.42 = xor i32 %conv71.8.42, %conv68.8.42
  %conv73.8.42 = trunc i32 %xor72.8.42 to i8
  store i8 %conv73.8.42, i8* %arrayidx70.42, align 1
  %scevgep20.9.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 9
  %17996 = load i8, i8* %scevgep20.9.42, align 1
  %conv68.9.42 = zext i8 %17996 to i32
  %17997 = load i8, i8* %arrayidx70.42, align 1
  %conv71.9.42 = zext i8 %17997 to i32
  %xor72.9.42 = xor i32 %conv71.9.42, %conv68.9.42
  %conv73.9.42 = trunc i32 %xor72.9.42 to i8
  store i8 %conv73.9.42, i8* %arrayidx70.42, align 1
  %scevgep20.10.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 10
  %17998 = load i8, i8* %scevgep20.10.42, align 1
  %conv68.10.42 = zext i8 %17998 to i32
  %17999 = load i8, i8* %arrayidx70.42, align 1
  %conv71.10.42 = zext i8 %17999 to i32
  %xor72.10.42 = xor i32 %conv71.10.42, %conv68.10.42
  %conv73.10.42 = trunc i32 %xor72.10.42 to i8
  store i8 %conv73.10.42, i8* %arrayidx70.42, align 1
  %scevgep20.11.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 11
  %18000 = load i8, i8* %scevgep20.11.42, align 1
  %conv68.11.42 = zext i8 %18000 to i32
  %18001 = load i8, i8* %arrayidx70.42, align 1
  %conv71.11.42 = zext i8 %18001 to i32
  %xor72.11.42 = xor i32 %conv71.11.42, %conv68.11.42
  %conv73.11.42 = trunc i32 %xor72.11.42 to i8
  store i8 %conv73.11.42, i8* %arrayidx70.42, align 1
  %scevgep20.12.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 12
  %18002 = load i8, i8* %scevgep20.12.42, align 1
  %conv68.12.42 = zext i8 %18002 to i32
  %18003 = load i8, i8* %arrayidx70.42, align 1
  %conv71.12.42 = zext i8 %18003 to i32
  %xor72.12.42 = xor i32 %conv71.12.42, %conv68.12.42
  %conv73.12.42 = trunc i32 %xor72.12.42 to i8
  store i8 %conv73.12.42, i8* %arrayidx70.42, align 1
  %scevgep20.13.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 13
  %18004 = load i8, i8* %scevgep20.13.42, align 1
  %conv68.13.42 = zext i8 %18004 to i32
  %18005 = load i8, i8* %arrayidx70.42, align 1
  %conv71.13.42 = zext i8 %18005 to i32
  %xor72.13.42 = xor i32 %conv71.13.42, %conv68.13.42
  %conv73.13.42 = trunc i32 %xor72.13.42 to i8
  store i8 %conv73.13.42, i8* %arrayidx70.42, align 1
  %scevgep20.14.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 14
  %18006 = load i8, i8* %scevgep20.14.42, align 1
  %conv68.14.42 = zext i8 %18006 to i32
  %18007 = load i8, i8* %arrayidx70.42, align 1
  %conv71.14.42 = zext i8 %18007 to i32
  %xor72.14.42 = xor i32 %conv71.14.42, %conv68.14.42
  %conv73.14.42 = trunc i32 %xor72.14.42 to i8
  store i8 %conv73.14.42, i8* %arrayidx70.42, align 1
  %scevgep20.15.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 15
  %18008 = load i8, i8* %scevgep20.15.42, align 1
  %conv68.15.42 = zext i8 %18008 to i32
  %18009 = load i8, i8* %arrayidx70.42, align 1
  %conv71.15.42 = zext i8 %18009 to i32
  %xor72.15.42 = xor i32 %conv71.15.42, %conv68.15.42
  %conv73.15.42 = trunc i32 %xor72.15.42 to i8
  store i8 %conv73.15.42, i8* %arrayidx70.42, align 1
  %scevgep20.16.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 16
  %18010 = load i8, i8* %scevgep20.16.42, align 1
  %conv68.16.42 = zext i8 %18010 to i32
  %18011 = load i8, i8* %arrayidx70.42, align 1
  %conv71.16.42 = zext i8 %18011 to i32
  %xor72.16.42 = xor i32 %conv71.16.42, %conv68.16.42
  %conv73.16.42 = trunc i32 %xor72.16.42 to i8
  store i8 %conv73.16.42, i8* %arrayidx70.42, align 1
  %scevgep20.17.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 17
  %18012 = load i8, i8* %scevgep20.17.42, align 1
  %conv68.17.42 = zext i8 %18012 to i32
  %18013 = load i8, i8* %arrayidx70.42, align 1
  %conv71.17.42 = zext i8 %18013 to i32
  %xor72.17.42 = xor i32 %conv71.17.42, %conv68.17.42
  %conv73.17.42 = trunc i32 %xor72.17.42 to i8
  store i8 %conv73.17.42, i8* %arrayidx70.42, align 1
  %scevgep20.18.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 18
  %18014 = load i8, i8* %scevgep20.18.42, align 1
  %conv68.18.42 = zext i8 %18014 to i32
  %18015 = load i8, i8* %arrayidx70.42, align 1
  %conv71.18.42 = zext i8 %18015 to i32
  %xor72.18.42 = xor i32 %conv71.18.42, %conv68.18.42
  %conv73.18.42 = trunc i32 %xor72.18.42 to i8
  store i8 %conv73.18.42, i8* %arrayidx70.42, align 1
  %scevgep20.19.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 19
  %18016 = load i8, i8* %scevgep20.19.42, align 1
  %conv68.19.42 = zext i8 %18016 to i32
  %18017 = load i8, i8* %arrayidx70.42, align 1
  %conv71.19.42 = zext i8 %18017 to i32
  %xor72.19.42 = xor i32 %conv71.19.42, %conv68.19.42
  %conv73.19.42 = trunc i32 %xor72.19.42 to i8
  store i8 %conv73.19.42, i8* %arrayidx70.42, align 1
  %scevgep20.20.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 20
  %18018 = load i8, i8* %scevgep20.20.42, align 1
  %conv68.20.42 = zext i8 %18018 to i32
  %18019 = load i8, i8* %arrayidx70.42, align 1
  %conv71.20.42 = zext i8 %18019 to i32
  %xor72.20.42 = xor i32 %conv71.20.42, %conv68.20.42
  %conv73.20.42 = trunc i32 %xor72.20.42 to i8
  store i8 %conv73.20.42, i8* %arrayidx70.42, align 1
  %scevgep20.21.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 21
  %18020 = load i8, i8* %scevgep20.21.42, align 1
  %conv68.21.42 = zext i8 %18020 to i32
  %18021 = load i8, i8* %arrayidx70.42, align 1
  %conv71.21.42 = zext i8 %18021 to i32
  %xor72.21.42 = xor i32 %conv71.21.42, %conv68.21.42
  %conv73.21.42 = trunc i32 %xor72.21.42 to i8
  store i8 %conv73.21.42, i8* %arrayidx70.42, align 1
  %scevgep20.22.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 22
  %18022 = load i8, i8* %scevgep20.22.42, align 1
  %conv68.22.42 = zext i8 %18022 to i32
  %18023 = load i8, i8* %arrayidx70.42, align 1
  %conv71.22.42 = zext i8 %18023 to i32
  %xor72.22.42 = xor i32 %conv71.22.42, %conv68.22.42
  %conv73.22.42 = trunc i32 %xor72.22.42 to i8
  store i8 %conv73.22.42, i8* %arrayidx70.42, align 1
  %scevgep20.23.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 23
  %18024 = load i8, i8* %scevgep20.23.42, align 1
  %conv68.23.42 = zext i8 %18024 to i32
  %18025 = load i8, i8* %arrayidx70.42, align 1
  %conv71.23.42 = zext i8 %18025 to i32
  %xor72.23.42 = xor i32 %conv71.23.42, %conv68.23.42
  %conv73.23.42 = trunc i32 %xor72.23.42 to i8
  store i8 %conv73.23.42, i8* %arrayidx70.42, align 1
  %scevgep20.24.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 24
  %18026 = load i8, i8* %scevgep20.24.42, align 1
  %conv68.24.42 = zext i8 %18026 to i32
  %18027 = load i8, i8* %arrayidx70.42, align 1
  %conv71.24.42 = zext i8 %18027 to i32
  %xor72.24.42 = xor i32 %conv71.24.42, %conv68.24.42
  %conv73.24.42 = trunc i32 %xor72.24.42 to i8
  store i8 %conv73.24.42, i8* %arrayidx70.42, align 1
  %scevgep20.25.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 25
  %18028 = load i8, i8* %scevgep20.25.42, align 1
  %conv68.25.42 = zext i8 %18028 to i32
  %18029 = load i8, i8* %arrayidx70.42, align 1
  %conv71.25.42 = zext i8 %18029 to i32
  %xor72.25.42 = xor i32 %conv71.25.42, %conv68.25.42
  %conv73.25.42 = trunc i32 %xor72.25.42 to i8
  store i8 %conv73.25.42, i8* %arrayidx70.42, align 1
  %scevgep20.26.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 26
  %18030 = load i8, i8* %scevgep20.26.42, align 1
  %conv68.26.42 = zext i8 %18030 to i32
  %18031 = load i8, i8* %arrayidx70.42, align 1
  %conv71.26.42 = zext i8 %18031 to i32
  %xor72.26.42 = xor i32 %conv71.26.42, %conv68.26.42
  %conv73.26.42 = trunc i32 %xor72.26.42 to i8
  store i8 %conv73.26.42, i8* %arrayidx70.42, align 1
  %scevgep20.27.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 27
  %18032 = load i8, i8* %scevgep20.27.42, align 1
  %conv68.27.42 = zext i8 %18032 to i32
  %18033 = load i8, i8* %arrayidx70.42, align 1
  %conv71.27.42 = zext i8 %18033 to i32
  %xor72.27.42 = xor i32 %conv71.27.42, %conv68.27.42
  %conv73.27.42 = trunc i32 %xor72.27.42 to i8
  store i8 %conv73.27.42, i8* %arrayidx70.42, align 1
  %scevgep20.28.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 28
  %18034 = load i8, i8* %scevgep20.28.42, align 1
  %conv68.28.42 = zext i8 %18034 to i32
  %18035 = load i8, i8* %arrayidx70.42, align 1
  %conv71.28.42 = zext i8 %18035 to i32
  %xor72.28.42 = xor i32 %conv71.28.42, %conv68.28.42
  %conv73.28.42 = trunc i32 %xor72.28.42 to i8
  store i8 %conv73.28.42, i8* %arrayidx70.42, align 1
  %scevgep20.29.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 29
  %18036 = load i8, i8* %scevgep20.29.42, align 1
  %conv68.29.42 = zext i8 %18036 to i32
  %18037 = load i8, i8* %arrayidx70.42, align 1
  %conv71.29.42 = zext i8 %18037 to i32
  %xor72.29.42 = xor i32 %conv71.29.42, %conv68.29.42
  %conv73.29.42 = trunc i32 %xor72.29.42 to i8
  store i8 %conv73.29.42, i8* %arrayidx70.42, align 1
  %scevgep20.30.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 30
  %18038 = load i8, i8* %scevgep20.30.42, align 1
  %conv68.30.42 = zext i8 %18038 to i32
  %18039 = load i8, i8* %arrayidx70.42, align 1
  %conv71.30.42 = zext i8 %18039 to i32
  %xor72.30.42 = xor i32 %conv71.30.42, %conv68.30.42
  %conv73.30.42 = trunc i32 %xor72.30.42 to i8
  store i8 %conv73.30.42, i8* %arrayidx70.42, align 1
  %scevgep20.31.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 31
  %18040 = load i8, i8* %scevgep20.31.42, align 1
  %conv68.31.42 = zext i8 %18040 to i32
  %18041 = load i8, i8* %arrayidx70.42, align 1
  %conv71.31.42 = zext i8 %18041 to i32
  %xor72.31.42 = xor i32 %conv71.31.42, %conv68.31.42
  %conv73.31.42 = trunc i32 %xor72.31.42 to i8
  store i8 %conv73.31.42, i8* %arrayidx70.42, align 1
  %scevgep20.32.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 32
  %18042 = load i8, i8* %scevgep20.32.42, align 1
  %conv68.32.42 = zext i8 %18042 to i32
  %18043 = load i8, i8* %arrayidx70.42, align 1
  %conv71.32.42 = zext i8 %18043 to i32
  %xor72.32.42 = xor i32 %conv71.32.42, %conv68.32.42
  %conv73.32.42 = trunc i32 %xor72.32.42 to i8
  store i8 %conv73.32.42, i8* %arrayidx70.42, align 1
  %scevgep20.33.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 33
  %18044 = load i8, i8* %scevgep20.33.42, align 1
  %conv68.33.42 = zext i8 %18044 to i32
  %18045 = load i8, i8* %arrayidx70.42, align 1
  %conv71.33.42 = zext i8 %18045 to i32
  %xor72.33.42 = xor i32 %conv71.33.42, %conv68.33.42
  %conv73.33.42 = trunc i32 %xor72.33.42 to i8
  store i8 %conv73.33.42, i8* %arrayidx70.42, align 1
  %scevgep20.34.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 34
  %18046 = load i8, i8* %scevgep20.34.42, align 1
  %conv68.34.42 = zext i8 %18046 to i32
  %18047 = load i8, i8* %arrayidx70.42, align 1
  %conv71.34.42 = zext i8 %18047 to i32
  %xor72.34.42 = xor i32 %conv71.34.42, %conv68.34.42
  %conv73.34.42 = trunc i32 %xor72.34.42 to i8
  store i8 %conv73.34.42, i8* %arrayidx70.42, align 1
  %scevgep20.35.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 35
  %18048 = load i8, i8* %scevgep20.35.42, align 1
  %conv68.35.42 = zext i8 %18048 to i32
  %18049 = load i8, i8* %arrayidx70.42, align 1
  %conv71.35.42 = zext i8 %18049 to i32
  %xor72.35.42 = xor i32 %conv71.35.42, %conv68.35.42
  %conv73.35.42 = trunc i32 %xor72.35.42 to i8
  store i8 %conv73.35.42, i8* %arrayidx70.42, align 1
  %scevgep20.36.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 36
  %18050 = load i8, i8* %scevgep20.36.42, align 1
  %conv68.36.42 = zext i8 %18050 to i32
  %18051 = load i8, i8* %arrayidx70.42, align 1
  %conv71.36.42 = zext i8 %18051 to i32
  %xor72.36.42 = xor i32 %conv71.36.42, %conv68.36.42
  %conv73.36.42 = trunc i32 %xor72.36.42 to i8
  store i8 %conv73.36.42, i8* %arrayidx70.42, align 1
  %scevgep20.37.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 37
  %18052 = load i8, i8* %scevgep20.37.42, align 1
  %conv68.37.42 = zext i8 %18052 to i32
  %18053 = load i8, i8* %arrayidx70.42, align 1
  %conv71.37.42 = zext i8 %18053 to i32
  %xor72.37.42 = xor i32 %conv71.37.42, %conv68.37.42
  %conv73.37.42 = trunc i32 %xor72.37.42 to i8
  store i8 %conv73.37.42, i8* %arrayidx70.42, align 1
  %scevgep20.38.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 38
  %18054 = load i8, i8* %scevgep20.38.42, align 1
  %conv68.38.42 = zext i8 %18054 to i32
  %18055 = load i8, i8* %arrayidx70.42, align 1
  %conv71.38.42 = zext i8 %18055 to i32
  %xor72.38.42 = xor i32 %conv71.38.42, %conv68.38.42
  %conv73.38.42 = trunc i32 %xor72.38.42 to i8
  store i8 %conv73.38.42, i8* %arrayidx70.42, align 1
  %scevgep20.39.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 39
  %18056 = load i8, i8* %scevgep20.39.42, align 1
  %conv68.39.42 = zext i8 %18056 to i32
  %18057 = load i8, i8* %arrayidx70.42, align 1
  %conv71.39.42 = zext i8 %18057 to i32
  %xor72.39.42 = xor i32 %conv71.39.42, %conv68.39.42
  %conv73.39.42 = trunc i32 %xor72.39.42 to i8
  store i8 %conv73.39.42, i8* %arrayidx70.42, align 1
  %scevgep20.40.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 40
  %18058 = load i8, i8* %scevgep20.40.42, align 1
  %conv68.40.42 = zext i8 %18058 to i32
  %18059 = load i8, i8* %arrayidx70.42, align 1
  %conv71.40.42 = zext i8 %18059 to i32
  %xor72.40.42 = xor i32 %conv71.40.42, %conv68.40.42
  %conv73.40.42 = trunc i32 %xor72.40.42 to i8
  store i8 %conv73.40.42, i8* %arrayidx70.42, align 1
  %scevgep20.41.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 41
  %18060 = load i8, i8* %scevgep20.41.42, align 1
  %conv68.41.42 = zext i8 %18060 to i32
  %18061 = load i8, i8* %arrayidx70.42, align 1
  %conv71.41.42 = zext i8 %18061 to i32
  %xor72.41.42 = xor i32 %conv71.41.42, %conv68.41.42
  %conv73.41.42 = trunc i32 %xor72.41.42 to i8
  store i8 %conv73.41.42, i8* %arrayidx70.42, align 1
  %scevgep20.43.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 43
  %18062 = load i8, i8* %scevgep20.43.42, align 1
  %conv68.43.42 = zext i8 %18062 to i32
  %18063 = load i8, i8* %arrayidx70.42, align 1
  %conv71.43.42 = zext i8 %18063 to i32
  %xor72.43.42 = xor i32 %conv71.43.42, %conv68.43.42
  %conv73.43.42 = trunc i32 %xor72.43.42 to i8
  store i8 %conv73.43.42, i8* %arrayidx70.42, align 1
  %scevgep20.44.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 44
  %18064 = load i8, i8* %scevgep20.44.42, align 1
  %conv68.44.42 = zext i8 %18064 to i32
  %18065 = load i8, i8* %arrayidx70.42, align 1
  %conv71.44.42 = zext i8 %18065 to i32
  %xor72.44.42 = xor i32 %conv71.44.42, %conv68.44.42
  %conv73.44.42 = trunc i32 %xor72.44.42 to i8
  store i8 %conv73.44.42, i8* %arrayidx70.42, align 1
  %scevgep20.45.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 45
  %18066 = load i8, i8* %scevgep20.45.42, align 1
  %conv68.45.42 = zext i8 %18066 to i32
  %18067 = load i8, i8* %arrayidx70.42, align 1
  %conv71.45.42 = zext i8 %18067 to i32
  %xor72.45.42 = xor i32 %conv71.45.42, %conv68.45.42
  %conv73.45.42 = trunc i32 %xor72.45.42 to i8
  store i8 %conv73.45.42, i8* %arrayidx70.42, align 1
  %scevgep20.46.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 46
  %18068 = load i8, i8* %scevgep20.46.42, align 1
  %conv68.46.42 = zext i8 %18068 to i32
  %18069 = load i8, i8* %arrayidx70.42, align 1
  %conv71.46.42 = zext i8 %18069 to i32
  %xor72.46.42 = xor i32 %conv71.46.42, %conv68.46.42
  %conv73.46.42 = trunc i32 %xor72.46.42 to i8
  store i8 %conv73.46.42, i8* %arrayidx70.42, align 1
  %scevgep20.47.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 47
  %18070 = load i8, i8* %scevgep20.47.42, align 1
  %conv68.47.42 = zext i8 %18070 to i32
  %18071 = load i8, i8* %arrayidx70.42, align 1
  %conv71.47.42 = zext i8 %18071 to i32
  %xor72.47.42 = xor i32 %conv71.47.42, %conv68.47.42
  %conv73.47.42 = trunc i32 %xor72.47.42 to i8
  store i8 %conv73.47.42, i8* %arrayidx70.42, align 1
  %scevgep20.48.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 48
  %18072 = load i8, i8* %scevgep20.48.42, align 1
  %conv68.48.42 = zext i8 %18072 to i32
  %18073 = load i8, i8* %arrayidx70.42, align 1
  %conv71.48.42 = zext i8 %18073 to i32
  %xor72.48.42 = xor i32 %conv71.48.42, %conv68.48.42
  %conv73.48.42 = trunc i32 %xor72.48.42 to i8
  store i8 %conv73.48.42, i8* %arrayidx70.42, align 1
  %scevgep20.49.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 49
  %18074 = load i8, i8* %scevgep20.49.42, align 1
  %conv68.49.42 = zext i8 %18074 to i32
  %18075 = load i8, i8* %arrayidx70.42, align 1
  %conv71.49.42 = zext i8 %18075 to i32
  %xor72.49.42 = xor i32 %conv71.49.42, %conv68.49.42
  %conv73.49.42 = trunc i32 %xor72.49.42 to i8
  store i8 %conv73.49.42, i8* %arrayidx70.42, align 1
  %scevgep20.50.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 50
  %18076 = load i8, i8* %scevgep20.50.42, align 1
  %conv68.50.42 = zext i8 %18076 to i32
  %18077 = load i8, i8* %arrayidx70.42, align 1
  %conv71.50.42 = zext i8 %18077 to i32
  %xor72.50.42 = xor i32 %conv71.50.42, %conv68.50.42
  %conv73.50.42 = trunc i32 %xor72.50.42 to i8
  store i8 %conv73.50.42, i8* %arrayidx70.42, align 1
  %scevgep20.51.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 51
  %18078 = load i8, i8* %scevgep20.51.42, align 1
  %conv68.51.42 = zext i8 %18078 to i32
  %18079 = load i8, i8* %arrayidx70.42, align 1
  %conv71.51.42 = zext i8 %18079 to i32
  %xor72.51.42 = xor i32 %conv71.51.42, %conv68.51.42
  %conv73.51.42 = trunc i32 %xor72.51.42 to i8
  store i8 %conv73.51.42, i8* %arrayidx70.42, align 1
  %scevgep20.52.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 52
  %18080 = load i8, i8* %scevgep20.52.42, align 1
  %conv68.52.42 = zext i8 %18080 to i32
  %18081 = load i8, i8* %arrayidx70.42, align 1
  %conv71.52.42 = zext i8 %18081 to i32
  %xor72.52.42 = xor i32 %conv71.52.42, %conv68.52.42
  %conv73.52.42 = trunc i32 %xor72.52.42 to i8
  store i8 %conv73.52.42, i8* %arrayidx70.42, align 1
  %scevgep20.53.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 53
  %18082 = load i8, i8* %scevgep20.53.42, align 1
  %conv68.53.42 = zext i8 %18082 to i32
  %18083 = load i8, i8* %arrayidx70.42, align 1
  %conv71.53.42 = zext i8 %18083 to i32
  %xor72.53.42 = xor i32 %conv71.53.42, %conv68.53.42
  %conv73.53.42 = trunc i32 %xor72.53.42 to i8
  store i8 %conv73.53.42, i8* %arrayidx70.42, align 1
  %scevgep20.54.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 54
  %18084 = load i8, i8* %scevgep20.54.42, align 1
  %conv68.54.42 = zext i8 %18084 to i32
  %18085 = load i8, i8* %arrayidx70.42, align 1
  %conv71.54.42 = zext i8 %18085 to i32
  %xor72.54.42 = xor i32 %conv71.54.42, %conv68.54.42
  %conv73.54.42 = trunc i32 %xor72.54.42 to i8
  store i8 %conv73.54.42, i8* %arrayidx70.42, align 1
  %scevgep20.55.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 55
  %18086 = load i8, i8* %scevgep20.55.42, align 1
  %conv68.55.42 = zext i8 %18086 to i32
  %18087 = load i8, i8* %arrayidx70.42, align 1
  %conv71.55.42 = zext i8 %18087 to i32
  %xor72.55.42 = xor i32 %conv71.55.42, %conv68.55.42
  %conv73.55.42 = trunc i32 %xor72.55.42 to i8
  store i8 %conv73.55.42, i8* %arrayidx70.42, align 1
  %scevgep20.56.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 56
  %18088 = load i8, i8* %scevgep20.56.42, align 1
  %conv68.56.42 = zext i8 %18088 to i32
  %18089 = load i8, i8* %arrayidx70.42, align 1
  %conv71.56.42 = zext i8 %18089 to i32
  %xor72.56.42 = xor i32 %conv71.56.42, %conv68.56.42
  %conv73.56.42 = trunc i32 %xor72.56.42 to i8
  store i8 %conv73.56.42, i8* %arrayidx70.42, align 1
  %scevgep20.57.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 57
  %18090 = load i8, i8* %scevgep20.57.42, align 1
  %conv68.57.42 = zext i8 %18090 to i32
  %18091 = load i8, i8* %arrayidx70.42, align 1
  %conv71.57.42 = zext i8 %18091 to i32
  %xor72.57.42 = xor i32 %conv71.57.42, %conv68.57.42
  %conv73.57.42 = trunc i32 %xor72.57.42 to i8
  store i8 %conv73.57.42, i8* %arrayidx70.42, align 1
  %scevgep20.58.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 58
  %18092 = load i8, i8* %scevgep20.58.42, align 1
  %conv68.58.42 = zext i8 %18092 to i32
  %18093 = load i8, i8* %arrayidx70.42, align 1
  %conv71.58.42 = zext i8 %18093 to i32
  %xor72.58.42 = xor i32 %conv71.58.42, %conv68.58.42
  %conv73.58.42 = trunc i32 %xor72.58.42 to i8
  store i8 %conv73.58.42, i8* %arrayidx70.42, align 1
  %scevgep20.59.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 59
  %18094 = load i8, i8* %scevgep20.59.42, align 1
  %conv68.59.42 = zext i8 %18094 to i32
  %18095 = load i8, i8* %arrayidx70.42, align 1
  %conv71.59.42 = zext i8 %18095 to i32
  %xor72.59.42 = xor i32 %conv71.59.42, %conv68.59.42
  %conv73.59.42 = trunc i32 %xor72.59.42 to i8
  store i8 %conv73.59.42, i8* %arrayidx70.42, align 1
  %scevgep20.60.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 0, i64 60
  %18096 = load i8, i8* %scevgep20.60.42, align 1
  %conv68.60.42 = zext i8 %18096 to i32
  %18097 = load i8, i8* %arrayidx70.42, align 1
  %conv71.60.42 = zext i8 %18097 to i32
  %xor72.60.42 = xor i32 %conv71.60.42, %conv68.60.42
  %conv73.60.42 = trunc i32 %xor72.60.42 to i8
  store i8 %conv73.60.42, i8* %arrayidx70.42, align 1
  %scevgep19.42 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %17975, i64 0, i64 1, i64 0
  %18098 = bitcast i8* %scevgep19.42 to [61 x [61 x i8]]*
  %arrayidx51.43 = getelementptr inbounds i8, i8* %a, i64 43
  %18099 = load i8, i8* %arrayidx51.43, align 1
  %arrayidx53.43 = getelementptr inbounds i8, i8* %b, i64 43
  %18100 = load i8, i8* %arrayidx53.43, align 1
  %call54.43 = call zeroext i8 @mult(i8 zeroext %18099, i8 zeroext %18100)
  %arrayidx56.43 = getelementptr inbounds i8, i8* %c, i64 43
  store i8 %call54.43, i8* %arrayidx56.43, align 1
  %arrayidx70.43 = getelementptr inbounds i8, i8* %c, i64 43
  %scevgep20.43474 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 0
  %18101 = load i8, i8* %scevgep20.43474, align 1
  %conv68.43475 = zext i8 %18101 to i32
  %18102 = load i8, i8* %arrayidx70.43, align 1
  %conv71.43476 = zext i8 %18102 to i32
  %xor72.43477 = xor i32 %conv71.43476, %conv68.43475
  %conv73.43478 = trunc i32 %xor72.43477 to i8
  store i8 %conv73.43478, i8* %arrayidx70.43, align 1
  %scevgep20.1.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 1
  %18103 = load i8, i8* %scevgep20.1.43, align 1
  %conv68.1.43 = zext i8 %18103 to i32
  %18104 = load i8, i8* %arrayidx70.43, align 1
  %conv71.1.43 = zext i8 %18104 to i32
  %xor72.1.43 = xor i32 %conv71.1.43, %conv68.1.43
  %conv73.1.43 = trunc i32 %xor72.1.43 to i8
  store i8 %conv73.1.43, i8* %arrayidx70.43, align 1
  %scevgep20.2.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 2
  %18105 = load i8, i8* %scevgep20.2.43, align 1
  %conv68.2.43 = zext i8 %18105 to i32
  %18106 = load i8, i8* %arrayidx70.43, align 1
  %conv71.2.43 = zext i8 %18106 to i32
  %xor72.2.43 = xor i32 %conv71.2.43, %conv68.2.43
  %conv73.2.43 = trunc i32 %xor72.2.43 to i8
  store i8 %conv73.2.43, i8* %arrayidx70.43, align 1
  %scevgep20.3.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 3
  %18107 = load i8, i8* %scevgep20.3.43, align 1
  %conv68.3.43 = zext i8 %18107 to i32
  %18108 = load i8, i8* %arrayidx70.43, align 1
  %conv71.3.43 = zext i8 %18108 to i32
  %xor72.3.43 = xor i32 %conv71.3.43, %conv68.3.43
  %conv73.3.43 = trunc i32 %xor72.3.43 to i8
  store i8 %conv73.3.43, i8* %arrayidx70.43, align 1
  %scevgep20.4.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 4
  %18109 = load i8, i8* %scevgep20.4.43, align 1
  %conv68.4.43 = zext i8 %18109 to i32
  %18110 = load i8, i8* %arrayidx70.43, align 1
  %conv71.4.43 = zext i8 %18110 to i32
  %xor72.4.43 = xor i32 %conv71.4.43, %conv68.4.43
  %conv73.4.43 = trunc i32 %xor72.4.43 to i8
  store i8 %conv73.4.43, i8* %arrayidx70.43, align 1
  %scevgep20.5.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 5
  %18111 = load i8, i8* %scevgep20.5.43, align 1
  %conv68.5.43 = zext i8 %18111 to i32
  %18112 = load i8, i8* %arrayidx70.43, align 1
  %conv71.5.43 = zext i8 %18112 to i32
  %xor72.5.43 = xor i32 %conv71.5.43, %conv68.5.43
  %conv73.5.43 = trunc i32 %xor72.5.43 to i8
  store i8 %conv73.5.43, i8* %arrayidx70.43, align 1
  %scevgep20.6.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 6
  %18113 = load i8, i8* %scevgep20.6.43, align 1
  %conv68.6.43 = zext i8 %18113 to i32
  %18114 = load i8, i8* %arrayidx70.43, align 1
  %conv71.6.43 = zext i8 %18114 to i32
  %xor72.6.43 = xor i32 %conv71.6.43, %conv68.6.43
  %conv73.6.43 = trunc i32 %xor72.6.43 to i8
  store i8 %conv73.6.43, i8* %arrayidx70.43, align 1
  %scevgep20.7.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 7
  %18115 = load i8, i8* %scevgep20.7.43, align 1
  %conv68.7.43 = zext i8 %18115 to i32
  %18116 = load i8, i8* %arrayidx70.43, align 1
  %conv71.7.43 = zext i8 %18116 to i32
  %xor72.7.43 = xor i32 %conv71.7.43, %conv68.7.43
  %conv73.7.43 = trunc i32 %xor72.7.43 to i8
  store i8 %conv73.7.43, i8* %arrayidx70.43, align 1
  %scevgep20.8.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 8
  %18117 = load i8, i8* %scevgep20.8.43, align 1
  %conv68.8.43 = zext i8 %18117 to i32
  %18118 = load i8, i8* %arrayidx70.43, align 1
  %conv71.8.43 = zext i8 %18118 to i32
  %xor72.8.43 = xor i32 %conv71.8.43, %conv68.8.43
  %conv73.8.43 = trunc i32 %xor72.8.43 to i8
  store i8 %conv73.8.43, i8* %arrayidx70.43, align 1
  %scevgep20.9.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 9
  %18119 = load i8, i8* %scevgep20.9.43, align 1
  %conv68.9.43 = zext i8 %18119 to i32
  %18120 = load i8, i8* %arrayidx70.43, align 1
  %conv71.9.43 = zext i8 %18120 to i32
  %xor72.9.43 = xor i32 %conv71.9.43, %conv68.9.43
  %conv73.9.43 = trunc i32 %xor72.9.43 to i8
  store i8 %conv73.9.43, i8* %arrayidx70.43, align 1
  %scevgep20.10.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 10
  %18121 = load i8, i8* %scevgep20.10.43, align 1
  %conv68.10.43 = zext i8 %18121 to i32
  %18122 = load i8, i8* %arrayidx70.43, align 1
  %conv71.10.43 = zext i8 %18122 to i32
  %xor72.10.43 = xor i32 %conv71.10.43, %conv68.10.43
  %conv73.10.43 = trunc i32 %xor72.10.43 to i8
  store i8 %conv73.10.43, i8* %arrayidx70.43, align 1
  %scevgep20.11.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 11
  %18123 = load i8, i8* %scevgep20.11.43, align 1
  %conv68.11.43 = zext i8 %18123 to i32
  %18124 = load i8, i8* %arrayidx70.43, align 1
  %conv71.11.43 = zext i8 %18124 to i32
  %xor72.11.43 = xor i32 %conv71.11.43, %conv68.11.43
  %conv73.11.43 = trunc i32 %xor72.11.43 to i8
  store i8 %conv73.11.43, i8* %arrayidx70.43, align 1
  %scevgep20.12.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 12
  %18125 = load i8, i8* %scevgep20.12.43, align 1
  %conv68.12.43 = zext i8 %18125 to i32
  %18126 = load i8, i8* %arrayidx70.43, align 1
  %conv71.12.43 = zext i8 %18126 to i32
  %xor72.12.43 = xor i32 %conv71.12.43, %conv68.12.43
  %conv73.12.43 = trunc i32 %xor72.12.43 to i8
  store i8 %conv73.12.43, i8* %arrayidx70.43, align 1
  %scevgep20.13.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 13
  %18127 = load i8, i8* %scevgep20.13.43, align 1
  %conv68.13.43 = zext i8 %18127 to i32
  %18128 = load i8, i8* %arrayidx70.43, align 1
  %conv71.13.43 = zext i8 %18128 to i32
  %xor72.13.43 = xor i32 %conv71.13.43, %conv68.13.43
  %conv73.13.43 = trunc i32 %xor72.13.43 to i8
  store i8 %conv73.13.43, i8* %arrayidx70.43, align 1
  %scevgep20.14.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 14
  %18129 = load i8, i8* %scevgep20.14.43, align 1
  %conv68.14.43 = zext i8 %18129 to i32
  %18130 = load i8, i8* %arrayidx70.43, align 1
  %conv71.14.43 = zext i8 %18130 to i32
  %xor72.14.43 = xor i32 %conv71.14.43, %conv68.14.43
  %conv73.14.43 = trunc i32 %xor72.14.43 to i8
  store i8 %conv73.14.43, i8* %arrayidx70.43, align 1
  %scevgep20.15.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 15
  %18131 = load i8, i8* %scevgep20.15.43, align 1
  %conv68.15.43 = zext i8 %18131 to i32
  %18132 = load i8, i8* %arrayidx70.43, align 1
  %conv71.15.43 = zext i8 %18132 to i32
  %xor72.15.43 = xor i32 %conv71.15.43, %conv68.15.43
  %conv73.15.43 = trunc i32 %xor72.15.43 to i8
  store i8 %conv73.15.43, i8* %arrayidx70.43, align 1
  %scevgep20.16.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 16
  %18133 = load i8, i8* %scevgep20.16.43, align 1
  %conv68.16.43 = zext i8 %18133 to i32
  %18134 = load i8, i8* %arrayidx70.43, align 1
  %conv71.16.43 = zext i8 %18134 to i32
  %xor72.16.43 = xor i32 %conv71.16.43, %conv68.16.43
  %conv73.16.43 = trunc i32 %xor72.16.43 to i8
  store i8 %conv73.16.43, i8* %arrayidx70.43, align 1
  %scevgep20.17.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 17
  %18135 = load i8, i8* %scevgep20.17.43, align 1
  %conv68.17.43 = zext i8 %18135 to i32
  %18136 = load i8, i8* %arrayidx70.43, align 1
  %conv71.17.43 = zext i8 %18136 to i32
  %xor72.17.43 = xor i32 %conv71.17.43, %conv68.17.43
  %conv73.17.43 = trunc i32 %xor72.17.43 to i8
  store i8 %conv73.17.43, i8* %arrayidx70.43, align 1
  %scevgep20.18.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 18
  %18137 = load i8, i8* %scevgep20.18.43, align 1
  %conv68.18.43 = zext i8 %18137 to i32
  %18138 = load i8, i8* %arrayidx70.43, align 1
  %conv71.18.43 = zext i8 %18138 to i32
  %xor72.18.43 = xor i32 %conv71.18.43, %conv68.18.43
  %conv73.18.43 = trunc i32 %xor72.18.43 to i8
  store i8 %conv73.18.43, i8* %arrayidx70.43, align 1
  %scevgep20.19.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 19
  %18139 = load i8, i8* %scevgep20.19.43, align 1
  %conv68.19.43 = zext i8 %18139 to i32
  %18140 = load i8, i8* %arrayidx70.43, align 1
  %conv71.19.43 = zext i8 %18140 to i32
  %xor72.19.43 = xor i32 %conv71.19.43, %conv68.19.43
  %conv73.19.43 = trunc i32 %xor72.19.43 to i8
  store i8 %conv73.19.43, i8* %arrayidx70.43, align 1
  %scevgep20.20.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 20
  %18141 = load i8, i8* %scevgep20.20.43, align 1
  %conv68.20.43 = zext i8 %18141 to i32
  %18142 = load i8, i8* %arrayidx70.43, align 1
  %conv71.20.43 = zext i8 %18142 to i32
  %xor72.20.43 = xor i32 %conv71.20.43, %conv68.20.43
  %conv73.20.43 = trunc i32 %xor72.20.43 to i8
  store i8 %conv73.20.43, i8* %arrayidx70.43, align 1
  %scevgep20.21.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 21
  %18143 = load i8, i8* %scevgep20.21.43, align 1
  %conv68.21.43 = zext i8 %18143 to i32
  %18144 = load i8, i8* %arrayidx70.43, align 1
  %conv71.21.43 = zext i8 %18144 to i32
  %xor72.21.43 = xor i32 %conv71.21.43, %conv68.21.43
  %conv73.21.43 = trunc i32 %xor72.21.43 to i8
  store i8 %conv73.21.43, i8* %arrayidx70.43, align 1
  %scevgep20.22.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 22
  %18145 = load i8, i8* %scevgep20.22.43, align 1
  %conv68.22.43 = zext i8 %18145 to i32
  %18146 = load i8, i8* %arrayidx70.43, align 1
  %conv71.22.43 = zext i8 %18146 to i32
  %xor72.22.43 = xor i32 %conv71.22.43, %conv68.22.43
  %conv73.22.43 = trunc i32 %xor72.22.43 to i8
  store i8 %conv73.22.43, i8* %arrayidx70.43, align 1
  %scevgep20.23.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 23
  %18147 = load i8, i8* %scevgep20.23.43, align 1
  %conv68.23.43 = zext i8 %18147 to i32
  %18148 = load i8, i8* %arrayidx70.43, align 1
  %conv71.23.43 = zext i8 %18148 to i32
  %xor72.23.43 = xor i32 %conv71.23.43, %conv68.23.43
  %conv73.23.43 = trunc i32 %xor72.23.43 to i8
  store i8 %conv73.23.43, i8* %arrayidx70.43, align 1
  %scevgep20.24.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 24
  %18149 = load i8, i8* %scevgep20.24.43, align 1
  %conv68.24.43 = zext i8 %18149 to i32
  %18150 = load i8, i8* %arrayidx70.43, align 1
  %conv71.24.43 = zext i8 %18150 to i32
  %xor72.24.43 = xor i32 %conv71.24.43, %conv68.24.43
  %conv73.24.43 = trunc i32 %xor72.24.43 to i8
  store i8 %conv73.24.43, i8* %arrayidx70.43, align 1
  %scevgep20.25.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 25
  %18151 = load i8, i8* %scevgep20.25.43, align 1
  %conv68.25.43 = zext i8 %18151 to i32
  %18152 = load i8, i8* %arrayidx70.43, align 1
  %conv71.25.43 = zext i8 %18152 to i32
  %xor72.25.43 = xor i32 %conv71.25.43, %conv68.25.43
  %conv73.25.43 = trunc i32 %xor72.25.43 to i8
  store i8 %conv73.25.43, i8* %arrayidx70.43, align 1
  %scevgep20.26.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 26
  %18153 = load i8, i8* %scevgep20.26.43, align 1
  %conv68.26.43 = zext i8 %18153 to i32
  %18154 = load i8, i8* %arrayidx70.43, align 1
  %conv71.26.43 = zext i8 %18154 to i32
  %xor72.26.43 = xor i32 %conv71.26.43, %conv68.26.43
  %conv73.26.43 = trunc i32 %xor72.26.43 to i8
  store i8 %conv73.26.43, i8* %arrayidx70.43, align 1
  %scevgep20.27.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 27
  %18155 = load i8, i8* %scevgep20.27.43, align 1
  %conv68.27.43 = zext i8 %18155 to i32
  %18156 = load i8, i8* %arrayidx70.43, align 1
  %conv71.27.43 = zext i8 %18156 to i32
  %xor72.27.43 = xor i32 %conv71.27.43, %conv68.27.43
  %conv73.27.43 = trunc i32 %xor72.27.43 to i8
  store i8 %conv73.27.43, i8* %arrayidx70.43, align 1
  %scevgep20.28.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 28
  %18157 = load i8, i8* %scevgep20.28.43, align 1
  %conv68.28.43 = zext i8 %18157 to i32
  %18158 = load i8, i8* %arrayidx70.43, align 1
  %conv71.28.43 = zext i8 %18158 to i32
  %xor72.28.43 = xor i32 %conv71.28.43, %conv68.28.43
  %conv73.28.43 = trunc i32 %xor72.28.43 to i8
  store i8 %conv73.28.43, i8* %arrayidx70.43, align 1
  %scevgep20.29.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 29
  %18159 = load i8, i8* %scevgep20.29.43, align 1
  %conv68.29.43 = zext i8 %18159 to i32
  %18160 = load i8, i8* %arrayidx70.43, align 1
  %conv71.29.43 = zext i8 %18160 to i32
  %xor72.29.43 = xor i32 %conv71.29.43, %conv68.29.43
  %conv73.29.43 = trunc i32 %xor72.29.43 to i8
  store i8 %conv73.29.43, i8* %arrayidx70.43, align 1
  %scevgep20.30.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 30
  %18161 = load i8, i8* %scevgep20.30.43, align 1
  %conv68.30.43 = zext i8 %18161 to i32
  %18162 = load i8, i8* %arrayidx70.43, align 1
  %conv71.30.43 = zext i8 %18162 to i32
  %xor72.30.43 = xor i32 %conv71.30.43, %conv68.30.43
  %conv73.30.43 = trunc i32 %xor72.30.43 to i8
  store i8 %conv73.30.43, i8* %arrayidx70.43, align 1
  %scevgep20.31.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 31
  %18163 = load i8, i8* %scevgep20.31.43, align 1
  %conv68.31.43 = zext i8 %18163 to i32
  %18164 = load i8, i8* %arrayidx70.43, align 1
  %conv71.31.43 = zext i8 %18164 to i32
  %xor72.31.43 = xor i32 %conv71.31.43, %conv68.31.43
  %conv73.31.43 = trunc i32 %xor72.31.43 to i8
  store i8 %conv73.31.43, i8* %arrayidx70.43, align 1
  %scevgep20.32.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 32
  %18165 = load i8, i8* %scevgep20.32.43, align 1
  %conv68.32.43 = zext i8 %18165 to i32
  %18166 = load i8, i8* %arrayidx70.43, align 1
  %conv71.32.43 = zext i8 %18166 to i32
  %xor72.32.43 = xor i32 %conv71.32.43, %conv68.32.43
  %conv73.32.43 = trunc i32 %xor72.32.43 to i8
  store i8 %conv73.32.43, i8* %arrayidx70.43, align 1
  %scevgep20.33.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 33
  %18167 = load i8, i8* %scevgep20.33.43, align 1
  %conv68.33.43 = zext i8 %18167 to i32
  %18168 = load i8, i8* %arrayidx70.43, align 1
  %conv71.33.43 = zext i8 %18168 to i32
  %xor72.33.43 = xor i32 %conv71.33.43, %conv68.33.43
  %conv73.33.43 = trunc i32 %xor72.33.43 to i8
  store i8 %conv73.33.43, i8* %arrayidx70.43, align 1
  %scevgep20.34.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 34
  %18169 = load i8, i8* %scevgep20.34.43, align 1
  %conv68.34.43 = zext i8 %18169 to i32
  %18170 = load i8, i8* %arrayidx70.43, align 1
  %conv71.34.43 = zext i8 %18170 to i32
  %xor72.34.43 = xor i32 %conv71.34.43, %conv68.34.43
  %conv73.34.43 = trunc i32 %xor72.34.43 to i8
  store i8 %conv73.34.43, i8* %arrayidx70.43, align 1
  %scevgep20.35.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 35
  %18171 = load i8, i8* %scevgep20.35.43, align 1
  %conv68.35.43 = zext i8 %18171 to i32
  %18172 = load i8, i8* %arrayidx70.43, align 1
  %conv71.35.43 = zext i8 %18172 to i32
  %xor72.35.43 = xor i32 %conv71.35.43, %conv68.35.43
  %conv73.35.43 = trunc i32 %xor72.35.43 to i8
  store i8 %conv73.35.43, i8* %arrayidx70.43, align 1
  %scevgep20.36.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 36
  %18173 = load i8, i8* %scevgep20.36.43, align 1
  %conv68.36.43 = zext i8 %18173 to i32
  %18174 = load i8, i8* %arrayidx70.43, align 1
  %conv71.36.43 = zext i8 %18174 to i32
  %xor72.36.43 = xor i32 %conv71.36.43, %conv68.36.43
  %conv73.36.43 = trunc i32 %xor72.36.43 to i8
  store i8 %conv73.36.43, i8* %arrayidx70.43, align 1
  %scevgep20.37.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 37
  %18175 = load i8, i8* %scevgep20.37.43, align 1
  %conv68.37.43 = zext i8 %18175 to i32
  %18176 = load i8, i8* %arrayidx70.43, align 1
  %conv71.37.43 = zext i8 %18176 to i32
  %xor72.37.43 = xor i32 %conv71.37.43, %conv68.37.43
  %conv73.37.43 = trunc i32 %xor72.37.43 to i8
  store i8 %conv73.37.43, i8* %arrayidx70.43, align 1
  %scevgep20.38.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 38
  %18177 = load i8, i8* %scevgep20.38.43, align 1
  %conv68.38.43 = zext i8 %18177 to i32
  %18178 = load i8, i8* %arrayidx70.43, align 1
  %conv71.38.43 = zext i8 %18178 to i32
  %xor72.38.43 = xor i32 %conv71.38.43, %conv68.38.43
  %conv73.38.43 = trunc i32 %xor72.38.43 to i8
  store i8 %conv73.38.43, i8* %arrayidx70.43, align 1
  %scevgep20.39.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 39
  %18179 = load i8, i8* %scevgep20.39.43, align 1
  %conv68.39.43 = zext i8 %18179 to i32
  %18180 = load i8, i8* %arrayidx70.43, align 1
  %conv71.39.43 = zext i8 %18180 to i32
  %xor72.39.43 = xor i32 %conv71.39.43, %conv68.39.43
  %conv73.39.43 = trunc i32 %xor72.39.43 to i8
  store i8 %conv73.39.43, i8* %arrayidx70.43, align 1
  %scevgep20.40.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 40
  %18181 = load i8, i8* %scevgep20.40.43, align 1
  %conv68.40.43 = zext i8 %18181 to i32
  %18182 = load i8, i8* %arrayidx70.43, align 1
  %conv71.40.43 = zext i8 %18182 to i32
  %xor72.40.43 = xor i32 %conv71.40.43, %conv68.40.43
  %conv73.40.43 = trunc i32 %xor72.40.43 to i8
  store i8 %conv73.40.43, i8* %arrayidx70.43, align 1
  %scevgep20.41.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 41
  %18183 = load i8, i8* %scevgep20.41.43, align 1
  %conv68.41.43 = zext i8 %18183 to i32
  %18184 = load i8, i8* %arrayidx70.43, align 1
  %conv71.41.43 = zext i8 %18184 to i32
  %xor72.41.43 = xor i32 %conv71.41.43, %conv68.41.43
  %conv73.41.43 = trunc i32 %xor72.41.43 to i8
  store i8 %conv73.41.43, i8* %arrayidx70.43, align 1
  %scevgep20.42.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 42
  %18185 = load i8, i8* %scevgep20.42.43, align 1
  %conv68.42.43 = zext i8 %18185 to i32
  %18186 = load i8, i8* %arrayidx70.43, align 1
  %conv71.42.43 = zext i8 %18186 to i32
  %xor72.42.43 = xor i32 %conv71.42.43, %conv68.42.43
  %conv73.42.43 = trunc i32 %xor72.42.43 to i8
  store i8 %conv73.42.43, i8* %arrayidx70.43, align 1
  %scevgep20.44.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 44
  %18187 = load i8, i8* %scevgep20.44.43, align 1
  %conv68.44.43 = zext i8 %18187 to i32
  %18188 = load i8, i8* %arrayidx70.43, align 1
  %conv71.44.43 = zext i8 %18188 to i32
  %xor72.44.43 = xor i32 %conv71.44.43, %conv68.44.43
  %conv73.44.43 = trunc i32 %xor72.44.43 to i8
  store i8 %conv73.44.43, i8* %arrayidx70.43, align 1
  %scevgep20.45.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 45
  %18189 = load i8, i8* %scevgep20.45.43, align 1
  %conv68.45.43 = zext i8 %18189 to i32
  %18190 = load i8, i8* %arrayidx70.43, align 1
  %conv71.45.43 = zext i8 %18190 to i32
  %xor72.45.43 = xor i32 %conv71.45.43, %conv68.45.43
  %conv73.45.43 = trunc i32 %xor72.45.43 to i8
  store i8 %conv73.45.43, i8* %arrayidx70.43, align 1
  %scevgep20.46.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 46
  %18191 = load i8, i8* %scevgep20.46.43, align 1
  %conv68.46.43 = zext i8 %18191 to i32
  %18192 = load i8, i8* %arrayidx70.43, align 1
  %conv71.46.43 = zext i8 %18192 to i32
  %xor72.46.43 = xor i32 %conv71.46.43, %conv68.46.43
  %conv73.46.43 = trunc i32 %xor72.46.43 to i8
  store i8 %conv73.46.43, i8* %arrayidx70.43, align 1
  %scevgep20.47.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 47
  %18193 = load i8, i8* %scevgep20.47.43, align 1
  %conv68.47.43 = zext i8 %18193 to i32
  %18194 = load i8, i8* %arrayidx70.43, align 1
  %conv71.47.43 = zext i8 %18194 to i32
  %xor72.47.43 = xor i32 %conv71.47.43, %conv68.47.43
  %conv73.47.43 = trunc i32 %xor72.47.43 to i8
  store i8 %conv73.47.43, i8* %arrayidx70.43, align 1
  %scevgep20.48.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 48
  %18195 = load i8, i8* %scevgep20.48.43, align 1
  %conv68.48.43 = zext i8 %18195 to i32
  %18196 = load i8, i8* %arrayidx70.43, align 1
  %conv71.48.43 = zext i8 %18196 to i32
  %xor72.48.43 = xor i32 %conv71.48.43, %conv68.48.43
  %conv73.48.43 = trunc i32 %xor72.48.43 to i8
  store i8 %conv73.48.43, i8* %arrayidx70.43, align 1
  %scevgep20.49.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 49
  %18197 = load i8, i8* %scevgep20.49.43, align 1
  %conv68.49.43 = zext i8 %18197 to i32
  %18198 = load i8, i8* %arrayidx70.43, align 1
  %conv71.49.43 = zext i8 %18198 to i32
  %xor72.49.43 = xor i32 %conv71.49.43, %conv68.49.43
  %conv73.49.43 = trunc i32 %xor72.49.43 to i8
  store i8 %conv73.49.43, i8* %arrayidx70.43, align 1
  %scevgep20.50.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 50
  %18199 = load i8, i8* %scevgep20.50.43, align 1
  %conv68.50.43 = zext i8 %18199 to i32
  %18200 = load i8, i8* %arrayidx70.43, align 1
  %conv71.50.43 = zext i8 %18200 to i32
  %xor72.50.43 = xor i32 %conv71.50.43, %conv68.50.43
  %conv73.50.43 = trunc i32 %xor72.50.43 to i8
  store i8 %conv73.50.43, i8* %arrayidx70.43, align 1
  %scevgep20.51.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 51
  %18201 = load i8, i8* %scevgep20.51.43, align 1
  %conv68.51.43 = zext i8 %18201 to i32
  %18202 = load i8, i8* %arrayidx70.43, align 1
  %conv71.51.43 = zext i8 %18202 to i32
  %xor72.51.43 = xor i32 %conv71.51.43, %conv68.51.43
  %conv73.51.43 = trunc i32 %xor72.51.43 to i8
  store i8 %conv73.51.43, i8* %arrayidx70.43, align 1
  %scevgep20.52.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 52
  %18203 = load i8, i8* %scevgep20.52.43, align 1
  %conv68.52.43 = zext i8 %18203 to i32
  %18204 = load i8, i8* %arrayidx70.43, align 1
  %conv71.52.43 = zext i8 %18204 to i32
  %xor72.52.43 = xor i32 %conv71.52.43, %conv68.52.43
  %conv73.52.43 = trunc i32 %xor72.52.43 to i8
  store i8 %conv73.52.43, i8* %arrayidx70.43, align 1
  %scevgep20.53.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 53
  %18205 = load i8, i8* %scevgep20.53.43, align 1
  %conv68.53.43 = zext i8 %18205 to i32
  %18206 = load i8, i8* %arrayidx70.43, align 1
  %conv71.53.43 = zext i8 %18206 to i32
  %xor72.53.43 = xor i32 %conv71.53.43, %conv68.53.43
  %conv73.53.43 = trunc i32 %xor72.53.43 to i8
  store i8 %conv73.53.43, i8* %arrayidx70.43, align 1
  %scevgep20.54.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 54
  %18207 = load i8, i8* %scevgep20.54.43, align 1
  %conv68.54.43 = zext i8 %18207 to i32
  %18208 = load i8, i8* %arrayidx70.43, align 1
  %conv71.54.43 = zext i8 %18208 to i32
  %xor72.54.43 = xor i32 %conv71.54.43, %conv68.54.43
  %conv73.54.43 = trunc i32 %xor72.54.43 to i8
  store i8 %conv73.54.43, i8* %arrayidx70.43, align 1
  %scevgep20.55.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 55
  %18209 = load i8, i8* %scevgep20.55.43, align 1
  %conv68.55.43 = zext i8 %18209 to i32
  %18210 = load i8, i8* %arrayidx70.43, align 1
  %conv71.55.43 = zext i8 %18210 to i32
  %xor72.55.43 = xor i32 %conv71.55.43, %conv68.55.43
  %conv73.55.43 = trunc i32 %xor72.55.43 to i8
  store i8 %conv73.55.43, i8* %arrayidx70.43, align 1
  %scevgep20.56.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 56
  %18211 = load i8, i8* %scevgep20.56.43, align 1
  %conv68.56.43 = zext i8 %18211 to i32
  %18212 = load i8, i8* %arrayidx70.43, align 1
  %conv71.56.43 = zext i8 %18212 to i32
  %xor72.56.43 = xor i32 %conv71.56.43, %conv68.56.43
  %conv73.56.43 = trunc i32 %xor72.56.43 to i8
  store i8 %conv73.56.43, i8* %arrayidx70.43, align 1
  %scevgep20.57.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 57
  %18213 = load i8, i8* %scevgep20.57.43, align 1
  %conv68.57.43 = zext i8 %18213 to i32
  %18214 = load i8, i8* %arrayidx70.43, align 1
  %conv71.57.43 = zext i8 %18214 to i32
  %xor72.57.43 = xor i32 %conv71.57.43, %conv68.57.43
  %conv73.57.43 = trunc i32 %xor72.57.43 to i8
  store i8 %conv73.57.43, i8* %arrayidx70.43, align 1
  %scevgep20.58.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 58
  %18215 = load i8, i8* %scevgep20.58.43, align 1
  %conv68.58.43 = zext i8 %18215 to i32
  %18216 = load i8, i8* %arrayidx70.43, align 1
  %conv71.58.43 = zext i8 %18216 to i32
  %xor72.58.43 = xor i32 %conv71.58.43, %conv68.58.43
  %conv73.58.43 = trunc i32 %xor72.58.43 to i8
  store i8 %conv73.58.43, i8* %arrayidx70.43, align 1
  %scevgep20.59.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 59
  %18217 = load i8, i8* %scevgep20.59.43, align 1
  %conv68.59.43 = zext i8 %18217 to i32
  %18218 = load i8, i8* %arrayidx70.43, align 1
  %conv71.59.43 = zext i8 %18218 to i32
  %xor72.59.43 = xor i32 %conv71.59.43, %conv68.59.43
  %conv73.59.43 = trunc i32 %xor72.59.43 to i8
  store i8 %conv73.59.43, i8* %arrayidx70.43, align 1
  %scevgep20.60.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 0, i64 60
  %18219 = load i8, i8* %scevgep20.60.43, align 1
  %conv68.60.43 = zext i8 %18219 to i32
  %18220 = load i8, i8* %arrayidx70.43, align 1
  %conv71.60.43 = zext i8 %18220 to i32
  %xor72.60.43 = xor i32 %conv71.60.43, %conv68.60.43
  %conv73.60.43 = trunc i32 %xor72.60.43 to i8
  store i8 %conv73.60.43, i8* %arrayidx70.43, align 1
  %scevgep19.43 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18098, i64 0, i64 1, i64 0
  %18221 = bitcast i8* %scevgep19.43 to [61 x [61 x i8]]*
  %arrayidx51.44 = getelementptr inbounds i8, i8* %a, i64 44
  %18222 = load i8, i8* %arrayidx51.44, align 1
  %arrayidx53.44 = getelementptr inbounds i8, i8* %b, i64 44
  %18223 = load i8, i8* %arrayidx53.44, align 1
  %call54.44 = call zeroext i8 @mult(i8 zeroext %18222, i8 zeroext %18223)
  %arrayidx56.44 = getelementptr inbounds i8, i8* %c, i64 44
  store i8 %call54.44, i8* %arrayidx56.44, align 1
  %arrayidx70.44 = getelementptr inbounds i8, i8* %c, i64 44
  %scevgep20.44484 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 0
  %18224 = load i8, i8* %scevgep20.44484, align 1
  %conv68.44485 = zext i8 %18224 to i32
  %18225 = load i8, i8* %arrayidx70.44, align 1
  %conv71.44486 = zext i8 %18225 to i32
  %xor72.44487 = xor i32 %conv71.44486, %conv68.44485
  %conv73.44488 = trunc i32 %xor72.44487 to i8
  store i8 %conv73.44488, i8* %arrayidx70.44, align 1
  %scevgep20.1.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 1
  %18226 = load i8, i8* %scevgep20.1.44, align 1
  %conv68.1.44 = zext i8 %18226 to i32
  %18227 = load i8, i8* %arrayidx70.44, align 1
  %conv71.1.44 = zext i8 %18227 to i32
  %xor72.1.44 = xor i32 %conv71.1.44, %conv68.1.44
  %conv73.1.44 = trunc i32 %xor72.1.44 to i8
  store i8 %conv73.1.44, i8* %arrayidx70.44, align 1
  %scevgep20.2.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 2
  %18228 = load i8, i8* %scevgep20.2.44, align 1
  %conv68.2.44 = zext i8 %18228 to i32
  %18229 = load i8, i8* %arrayidx70.44, align 1
  %conv71.2.44 = zext i8 %18229 to i32
  %xor72.2.44 = xor i32 %conv71.2.44, %conv68.2.44
  %conv73.2.44 = trunc i32 %xor72.2.44 to i8
  store i8 %conv73.2.44, i8* %arrayidx70.44, align 1
  %scevgep20.3.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 3
  %18230 = load i8, i8* %scevgep20.3.44, align 1
  %conv68.3.44 = zext i8 %18230 to i32
  %18231 = load i8, i8* %arrayidx70.44, align 1
  %conv71.3.44 = zext i8 %18231 to i32
  %xor72.3.44 = xor i32 %conv71.3.44, %conv68.3.44
  %conv73.3.44 = trunc i32 %xor72.3.44 to i8
  store i8 %conv73.3.44, i8* %arrayidx70.44, align 1
  %scevgep20.4.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 4
  %18232 = load i8, i8* %scevgep20.4.44, align 1
  %conv68.4.44 = zext i8 %18232 to i32
  %18233 = load i8, i8* %arrayidx70.44, align 1
  %conv71.4.44 = zext i8 %18233 to i32
  %xor72.4.44 = xor i32 %conv71.4.44, %conv68.4.44
  %conv73.4.44 = trunc i32 %xor72.4.44 to i8
  store i8 %conv73.4.44, i8* %arrayidx70.44, align 1
  %scevgep20.5.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 5
  %18234 = load i8, i8* %scevgep20.5.44, align 1
  %conv68.5.44 = zext i8 %18234 to i32
  %18235 = load i8, i8* %arrayidx70.44, align 1
  %conv71.5.44 = zext i8 %18235 to i32
  %xor72.5.44 = xor i32 %conv71.5.44, %conv68.5.44
  %conv73.5.44 = trunc i32 %xor72.5.44 to i8
  store i8 %conv73.5.44, i8* %arrayidx70.44, align 1
  %scevgep20.6.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 6
  %18236 = load i8, i8* %scevgep20.6.44, align 1
  %conv68.6.44 = zext i8 %18236 to i32
  %18237 = load i8, i8* %arrayidx70.44, align 1
  %conv71.6.44 = zext i8 %18237 to i32
  %xor72.6.44 = xor i32 %conv71.6.44, %conv68.6.44
  %conv73.6.44 = trunc i32 %xor72.6.44 to i8
  store i8 %conv73.6.44, i8* %arrayidx70.44, align 1
  %scevgep20.7.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 7
  %18238 = load i8, i8* %scevgep20.7.44, align 1
  %conv68.7.44 = zext i8 %18238 to i32
  %18239 = load i8, i8* %arrayidx70.44, align 1
  %conv71.7.44 = zext i8 %18239 to i32
  %xor72.7.44 = xor i32 %conv71.7.44, %conv68.7.44
  %conv73.7.44 = trunc i32 %xor72.7.44 to i8
  store i8 %conv73.7.44, i8* %arrayidx70.44, align 1
  %scevgep20.8.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 8
  %18240 = load i8, i8* %scevgep20.8.44, align 1
  %conv68.8.44 = zext i8 %18240 to i32
  %18241 = load i8, i8* %arrayidx70.44, align 1
  %conv71.8.44 = zext i8 %18241 to i32
  %xor72.8.44 = xor i32 %conv71.8.44, %conv68.8.44
  %conv73.8.44 = trunc i32 %xor72.8.44 to i8
  store i8 %conv73.8.44, i8* %arrayidx70.44, align 1
  %scevgep20.9.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 9
  %18242 = load i8, i8* %scevgep20.9.44, align 1
  %conv68.9.44 = zext i8 %18242 to i32
  %18243 = load i8, i8* %arrayidx70.44, align 1
  %conv71.9.44 = zext i8 %18243 to i32
  %xor72.9.44 = xor i32 %conv71.9.44, %conv68.9.44
  %conv73.9.44 = trunc i32 %xor72.9.44 to i8
  store i8 %conv73.9.44, i8* %arrayidx70.44, align 1
  %scevgep20.10.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 10
  %18244 = load i8, i8* %scevgep20.10.44, align 1
  %conv68.10.44 = zext i8 %18244 to i32
  %18245 = load i8, i8* %arrayidx70.44, align 1
  %conv71.10.44 = zext i8 %18245 to i32
  %xor72.10.44 = xor i32 %conv71.10.44, %conv68.10.44
  %conv73.10.44 = trunc i32 %xor72.10.44 to i8
  store i8 %conv73.10.44, i8* %arrayidx70.44, align 1
  %scevgep20.11.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 11
  %18246 = load i8, i8* %scevgep20.11.44, align 1
  %conv68.11.44 = zext i8 %18246 to i32
  %18247 = load i8, i8* %arrayidx70.44, align 1
  %conv71.11.44 = zext i8 %18247 to i32
  %xor72.11.44 = xor i32 %conv71.11.44, %conv68.11.44
  %conv73.11.44 = trunc i32 %xor72.11.44 to i8
  store i8 %conv73.11.44, i8* %arrayidx70.44, align 1
  %scevgep20.12.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 12
  %18248 = load i8, i8* %scevgep20.12.44, align 1
  %conv68.12.44 = zext i8 %18248 to i32
  %18249 = load i8, i8* %arrayidx70.44, align 1
  %conv71.12.44 = zext i8 %18249 to i32
  %xor72.12.44 = xor i32 %conv71.12.44, %conv68.12.44
  %conv73.12.44 = trunc i32 %xor72.12.44 to i8
  store i8 %conv73.12.44, i8* %arrayidx70.44, align 1
  %scevgep20.13.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 13
  %18250 = load i8, i8* %scevgep20.13.44, align 1
  %conv68.13.44 = zext i8 %18250 to i32
  %18251 = load i8, i8* %arrayidx70.44, align 1
  %conv71.13.44 = zext i8 %18251 to i32
  %xor72.13.44 = xor i32 %conv71.13.44, %conv68.13.44
  %conv73.13.44 = trunc i32 %xor72.13.44 to i8
  store i8 %conv73.13.44, i8* %arrayidx70.44, align 1
  %scevgep20.14.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 14
  %18252 = load i8, i8* %scevgep20.14.44, align 1
  %conv68.14.44 = zext i8 %18252 to i32
  %18253 = load i8, i8* %arrayidx70.44, align 1
  %conv71.14.44 = zext i8 %18253 to i32
  %xor72.14.44 = xor i32 %conv71.14.44, %conv68.14.44
  %conv73.14.44 = trunc i32 %xor72.14.44 to i8
  store i8 %conv73.14.44, i8* %arrayidx70.44, align 1
  %scevgep20.15.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 15
  %18254 = load i8, i8* %scevgep20.15.44, align 1
  %conv68.15.44 = zext i8 %18254 to i32
  %18255 = load i8, i8* %arrayidx70.44, align 1
  %conv71.15.44 = zext i8 %18255 to i32
  %xor72.15.44 = xor i32 %conv71.15.44, %conv68.15.44
  %conv73.15.44 = trunc i32 %xor72.15.44 to i8
  store i8 %conv73.15.44, i8* %arrayidx70.44, align 1
  %scevgep20.16.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 16
  %18256 = load i8, i8* %scevgep20.16.44, align 1
  %conv68.16.44 = zext i8 %18256 to i32
  %18257 = load i8, i8* %arrayidx70.44, align 1
  %conv71.16.44 = zext i8 %18257 to i32
  %xor72.16.44 = xor i32 %conv71.16.44, %conv68.16.44
  %conv73.16.44 = trunc i32 %xor72.16.44 to i8
  store i8 %conv73.16.44, i8* %arrayidx70.44, align 1
  %scevgep20.17.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 17
  %18258 = load i8, i8* %scevgep20.17.44, align 1
  %conv68.17.44 = zext i8 %18258 to i32
  %18259 = load i8, i8* %arrayidx70.44, align 1
  %conv71.17.44 = zext i8 %18259 to i32
  %xor72.17.44 = xor i32 %conv71.17.44, %conv68.17.44
  %conv73.17.44 = trunc i32 %xor72.17.44 to i8
  store i8 %conv73.17.44, i8* %arrayidx70.44, align 1
  %scevgep20.18.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 18
  %18260 = load i8, i8* %scevgep20.18.44, align 1
  %conv68.18.44 = zext i8 %18260 to i32
  %18261 = load i8, i8* %arrayidx70.44, align 1
  %conv71.18.44 = zext i8 %18261 to i32
  %xor72.18.44 = xor i32 %conv71.18.44, %conv68.18.44
  %conv73.18.44 = trunc i32 %xor72.18.44 to i8
  store i8 %conv73.18.44, i8* %arrayidx70.44, align 1
  %scevgep20.19.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 19
  %18262 = load i8, i8* %scevgep20.19.44, align 1
  %conv68.19.44 = zext i8 %18262 to i32
  %18263 = load i8, i8* %arrayidx70.44, align 1
  %conv71.19.44 = zext i8 %18263 to i32
  %xor72.19.44 = xor i32 %conv71.19.44, %conv68.19.44
  %conv73.19.44 = trunc i32 %xor72.19.44 to i8
  store i8 %conv73.19.44, i8* %arrayidx70.44, align 1
  %scevgep20.20.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 20
  %18264 = load i8, i8* %scevgep20.20.44, align 1
  %conv68.20.44 = zext i8 %18264 to i32
  %18265 = load i8, i8* %arrayidx70.44, align 1
  %conv71.20.44 = zext i8 %18265 to i32
  %xor72.20.44 = xor i32 %conv71.20.44, %conv68.20.44
  %conv73.20.44 = trunc i32 %xor72.20.44 to i8
  store i8 %conv73.20.44, i8* %arrayidx70.44, align 1
  %scevgep20.21.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 21
  %18266 = load i8, i8* %scevgep20.21.44, align 1
  %conv68.21.44 = zext i8 %18266 to i32
  %18267 = load i8, i8* %arrayidx70.44, align 1
  %conv71.21.44 = zext i8 %18267 to i32
  %xor72.21.44 = xor i32 %conv71.21.44, %conv68.21.44
  %conv73.21.44 = trunc i32 %xor72.21.44 to i8
  store i8 %conv73.21.44, i8* %arrayidx70.44, align 1
  %scevgep20.22.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 22
  %18268 = load i8, i8* %scevgep20.22.44, align 1
  %conv68.22.44 = zext i8 %18268 to i32
  %18269 = load i8, i8* %arrayidx70.44, align 1
  %conv71.22.44 = zext i8 %18269 to i32
  %xor72.22.44 = xor i32 %conv71.22.44, %conv68.22.44
  %conv73.22.44 = trunc i32 %xor72.22.44 to i8
  store i8 %conv73.22.44, i8* %arrayidx70.44, align 1
  %scevgep20.23.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 23
  %18270 = load i8, i8* %scevgep20.23.44, align 1
  %conv68.23.44 = zext i8 %18270 to i32
  %18271 = load i8, i8* %arrayidx70.44, align 1
  %conv71.23.44 = zext i8 %18271 to i32
  %xor72.23.44 = xor i32 %conv71.23.44, %conv68.23.44
  %conv73.23.44 = trunc i32 %xor72.23.44 to i8
  store i8 %conv73.23.44, i8* %arrayidx70.44, align 1
  %scevgep20.24.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 24
  %18272 = load i8, i8* %scevgep20.24.44, align 1
  %conv68.24.44 = zext i8 %18272 to i32
  %18273 = load i8, i8* %arrayidx70.44, align 1
  %conv71.24.44 = zext i8 %18273 to i32
  %xor72.24.44 = xor i32 %conv71.24.44, %conv68.24.44
  %conv73.24.44 = trunc i32 %xor72.24.44 to i8
  store i8 %conv73.24.44, i8* %arrayidx70.44, align 1
  %scevgep20.25.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 25
  %18274 = load i8, i8* %scevgep20.25.44, align 1
  %conv68.25.44 = zext i8 %18274 to i32
  %18275 = load i8, i8* %arrayidx70.44, align 1
  %conv71.25.44 = zext i8 %18275 to i32
  %xor72.25.44 = xor i32 %conv71.25.44, %conv68.25.44
  %conv73.25.44 = trunc i32 %xor72.25.44 to i8
  store i8 %conv73.25.44, i8* %arrayidx70.44, align 1
  %scevgep20.26.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 26
  %18276 = load i8, i8* %scevgep20.26.44, align 1
  %conv68.26.44 = zext i8 %18276 to i32
  %18277 = load i8, i8* %arrayidx70.44, align 1
  %conv71.26.44 = zext i8 %18277 to i32
  %xor72.26.44 = xor i32 %conv71.26.44, %conv68.26.44
  %conv73.26.44 = trunc i32 %xor72.26.44 to i8
  store i8 %conv73.26.44, i8* %arrayidx70.44, align 1
  %scevgep20.27.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 27
  %18278 = load i8, i8* %scevgep20.27.44, align 1
  %conv68.27.44 = zext i8 %18278 to i32
  %18279 = load i8, i8* %arrayidx70.44, align 1
  %conv71.27.44 = zext i8 %18279 to i32
  %xor72.27.44 = xor i32 %conv71.27.44, %conv68.27.44
  %conv73.27.44 = trunc i32 %xor72.27.44 to i8
  store i8 %conv73.27.44, i8* %arrayidx70.44, align 1
  %scevgep20.28.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 28
  %18280 = load i8, i8* %scevgep20.28.44, align 1
  %conv68.28.44 = zext i8 %18280 to i32
  %18281 = load i8, i8* %arrayidx70.44, align 1
  %conv71.28.44 = zext i8 %18281 to i32
  %xor72.28.44 = xor i32 %conv71.28.44, %conv68.28.44
  %conv73.28.44 = trunc i32 %xor72.28.44 to i8
  store i8 %conv73.28.44, i8* %arrayidx70.44, align 1
  %scevgep20.29.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 29
  %18282 = load i8, i8* %scevgep20.29.44, align 1
  %conv68.29.44 = zext i8 %18282 to i32
  %18283 = load i8, i8* %arrayidx70.44, align 1
  %conv71.29.44 = zext i8 %18283 to i32
  %xor72.29.44 = xor i32 %conv71.29.44, %conv68.29.44
  %conv73.29.44 = trunc i32 %xor72.29.44 to i8
  store i8 %conv73.29.44, i8* %arrayidx70.44, align 1
  %scevgep20.30.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 30
  %18284 = load i8, i8* %scevgep20.30.44, align 1
  %conv68.30.44 = zext i8 %18284 to i32
  %18285 = load i8, i8* %arrayidx70.44, align 1
  %conv71.30.44 = zext i8 %18285 to i32
  %xor72.30.44 = xor i32 %conv71.30.44, %conv68.30.44
  %conv73.30.44 = trunc i32 %xor72.30.44 to i8
  store i8 %conv73.30.44, i8* %arrayidx70.44, align 1
  %scevgep20.31.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 31
  %18286 = load i8, i8* %scevgep20.31.44, align 1
  %conv68.31.44 = zext i8 %18286 to i32
  %18287 = load i8, i8* %arrayidx70.44, align 1
  %conv71.31.44 = zext i8 %18287 to i32
  %xor72.31.44 = xor i32 %conv71.31.44, %conv68.31.44
  %conv73.31.44 = trunc i32 %xor72.31.44 to i8
  store i8 %conv73.31.44, i8* %arrayidx70.44, align 1
  %scevgep20.32.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 32
  %18288 = load i8, i8* %scevgep20.32.44, align 1
  %conv68.32.44 = zext i8 %18288 to i32
  %18289 = load i8, i8* %arrayidx70.44, align 1
  %conv71.32.44 = zext i8 %18289 to i32
  %xor72.32.44 = xor i32 %conv71.32.44, %conv68.32.44
  %conv73.32.44 = trunc i32 %xor72.32.44 to i8
  store i8 %conv73.32.44, i8* %arrayidx70.44, align 1
  %scevgep20.33.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 33
  %18290 = load i8, i8* %scevgep20.33.44, align 1
  %conv68.33.44 = zext i8 %18290 to i32
  %18291 = load i8, i8* %arrayidx70.44, align 1
  %conv71.33.44 = zext i8 %18291 to i32
  %xor72.33.44 = xor i32 %conv71.33.44, %conv68.33.44
  %conv73.33.44 = trunc i32 %xor72.33.44 to i8
  store i8 %conv73.33.44, i8* %arrayidx70.44, align 1
  %scevgep20.34.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 34
  %18292 = load i8, i8* %scevgep20.34.44, align 1
  %conv68.34.44 = zext i8 %18292 to i32
  %18293 = load i8, i8* %arrayidx70.44, align 1
  %conv71.34.44 = zext i8 %18293 to i32
  %xor72.34.44 = xor i32 %conv71.34.44, %conv68.34.44
  %conv73.34.44 = trunc i32 %xor72.34.44 to i8
  store i8 %conv73.34.44, i8* %arrayidx70.44, align 1
  %scevgep20.35.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 35
  %18294 = load i8, i8* %scevgep20.35.44, align 1
  %conv68.35.44 = zext i8 %18294 to i32
  %18295 = load i8, i8* %arrayidx70.44, align 1
  %conv71.35.44 = zext i8 %18295 to i32
  %xor72.35.44 = xor i32 %conv71.35.44, %conv68.35.44
  %conv73.35.44 = trunc i32 %xor72.35.44 to i8
  store i8 %conv73.35.44, i8* %arrayidx70.44, align 1
  %scevgep20.36.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 36
  %18296 = load i8, i8* %scevgep20.36.44, align 1
  %conv68.36.44 = zext i8 %18296 to i32
  %18297 = load i8, i8* %arrayidx70.44, align 1
  %conv71.36.44 = zext i8 %18297 to i32
  %xor72.36.44 = xor i32 %conv71.36.44, %conv68.36.44
  %conv73.36.44 = trunc i32 %xor72.36.44 to i8
  store i8 %conv73.36.44, i8* %arrayidx70.44, align 1
  %scevgep20.37.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 37
  %18298 = load i8, i8* %scevgep20.37.44, align 1
  %conv68.37.44 = zext i8 %18298 to i32
  %18299 = load i8, i8* %arrayidx70.44, align 1
  %conv71.37.44 = zext i8 %18299 to i32
  %xor72.37.44 = xor i32 %conv71.37.44, %conv68.37.44
  %conv73.37.44 = trunc i32 %xor72.37.44 to i8
  store i8 %conv73.37.44, i8* %arrayidx70.44, align 1
  %scevgep20.38.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 38
  %18300 = load i8, i8* %scevgep20.38.44, align 1
  %conv68.38.44 = zext i8 %18300 to i32
  %18301 = load i8, i8* %arrayidx70.44, align 1
  %conv71.38.44 = zext i8 %18301 to i32
  %xor72.38.44 = xor i32 %conv71.38.44, %conv68.38.44
  %conv73.38.44 = trunc i32 %xor72.38.44 to i8
  store i8 %conv73.38.44, i8* %arrayidx70.44, align 1
  %scevgep20.39.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 39
  %18302 = load i8, i8* %scevgep20.39.44, align 1
  %conv68.39.44 = zext i8 %18302 to i32
  %18303 = load i8, i8* %arrayidx70.44, align 1
  %conv71.39.44 = zext i8 %18303 to i32
  %xor72.39.44 = xor i32 %conv71.39.44, %conv68.39.44
  %conv73.39.44 = trunc i32 %xor72.39.44 to i8
  store i8 %conv73.39.44, i8* %arrayidx70.44, align 1
  %scevgep20.40.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 40
  %18304 = load i8, i8* %scevgep20.40.44, align 1
  %conv68.40.44 = zext i8 %18304 to i32
  %18305 = load i8, i8* %arrayidx70.44, align 1
  %conv71.40.44 = zext i8 %18305 to i32
  %xor72.40.44 = xor i32 %conv71.40.44, %conv68.40.44
  %conv73.40.44 = trunc i32 %xor72.40.44 to i8
  store i8 %conv73.40.44, i8* %arrayidx70.44, align 1
  %scevgep20.41.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 41
  %18306 = load i8, i8* %scevgep20.41.44, align 1
  %conv68.41.44 = zext i8 %18306 to i32
  %18307 = load i8, i8* %arrayidx70.44, align 1
  %conv71.41.44 = zext i8 %18307 to i32
  %xor72.41.44 = xor i32 %conv71.41.44, %conv68.41.44
  %conv73.41.44 = trunc i32 %xor72.41.44 to i8
  store i8 %conv73.41.44, i8* %arrayidx70.44, align 1
  %scevgep20.42.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 42
  %18308 = load i8, i8* %scevgep20.42.44, align 1
  %conv68.42.44 = zext i8 %18308 to i32
  %18309 = load i8, i8* %arrayidx70.44, align 1
  %conv71.42.44 = zext i8 %18309 to i32
  %xor72.42.44 = xor i32 %conv71.42.44, %conv68.42.44
  %conv73.42.44 = trunc i32 %xor72.42.44 to i8
  store i8 %conv73.42.44, i8* %arrayidx70.44, align 1
  %scevgep20.43.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 43
  %18310 = load i8, i8* %scevgep20.43.44, align 1
  %conv68.43.44 = zext i8 %18310 to i32
  %18311 = load i8, i8* %arrayidx70.44, align 1
  %conv71.43.44 = zext i8 %18311 to i32
  %xor72.43.44 = xor i32 %conv71.43.44, %conv68.43.44
  %conv73.43.44 = trunc i32 %xor72.43.44 to i8
  store i8 %conv73.43.44, i8* %arrayidx70.44, align 1
  %scevgep20.45.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 45
  %18312 = load i8, i8* %scevgep20.45.44, align 1
  %conv68.45.44 = zext i8 %18312 to i32
  %18313 = load i8, i8* %arrayidx70.44, align 1
  %conv71.45.44 = zext i8 %18313 to i32
  %xor72.45.44 = xor i32 %conv71.45.44, %conv68.45.44
  %conv73.45.44 = trunc i32 %xor72.45.44 to i8
  store i8 %conv73.45.44, i8* %arrayidx70.44, align 1
  %scevgep20.46.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 46
  %18314 = load i8, i8* %scevgep20.46.44, align 1
  %conv68.46.44 = zext i8 %18314 to i32
  %18315 = load i8, i8* %arrayidx70.44, align 1
  %conv71.46.44 = zext i8 %18315 to i32
  %xor72.46.44 = xor i32 %conv71.46.44, %conv68.46.44
  %conv73.46.44 = trunc i32 %xor72.46.44 to i8
  store i8 %conv73.46.44, i8* %arrayidx70.44, align 1
  %scevgep20.47.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 47
  %18316 = load i8, i8* %scevgep20.47.44, align 1
  %conv68.47.44 = zext i8 %18316 to i32
  %18317 = load i8, i8* %arrayidx70.44, align 1
  %conv71.47.44 = zext i8 %18317 to i32
  %xor72.47.44 = xor i32 %conv71.47.44, %conv68.47.44
  %conv73.47.44 = trunc i32 %xor72.47.44 to i8
  store i8 %conv73.47.44, i8* %arrayidx70.44, align 1
  %scevgep20.48.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 48
  %18318 = load i8, i8* %scevgep20.48.44, align 1
  %conv68.48.44 = zext i8 %18318 to i32
  %18319 = load i8, i8* %arrayidx70.44, align 1
  %conv71.48.44 = zext i8 %18319 to i32
  %xor72.48.44 = xor i32 %conv71.48.44, %conv68.48.44
  %conv73.48.44 = trunc i32 %xor72.48.44 to i8
  store i8 %conv73.48.44, i8* %arrayidx70.44, align 1
  %scevgep20.49.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 49
  %18320 = load i8, i8* %scevgep20.49.44, align 1
  %conv68.49.44 = zext i8 %18320 to i32
  %18321 = load i8, i8* %arrayidx70.44, align 1
  %conv71.49.44 = zext i8 %18321 to i32
  %xor72.49.44 = xor i32 %conv71.49.44, %conv68.49.44
  %conv73.49.44 = trunc i32 %xor72.49.44 to i8
  store i8 %conv73.49.44, i8* %arrayidx70.44, align 1
  %scevgep20.50.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 50
  %18322 = load i8, i8* %scevgep20.50.44, align 1
  %conv68.50.44 = zext i8 %18322 to i32
  %18323 = load i8, i8* %arrayidx70.44, align 1
  %conv71.50.44 = zext i8 %18323 to i32
  %xor72.50.44 = xor i32 %conv71.50.44, %conv68.50.44
  %conv73.50.44 = trunc i32 %xor72.50.44 to i8
  store i8 %conv73.50.44, i8* %arrayidx70.44, align 1
  %scevgep20.51.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 51
  %18324 = load i8, i8* %scevgep20.51.44, align 1
  %conv68.51.44 = zext i8 %18324 to i32
  %18325 = load i8, i8* %arrayidx70.44, align 1
  %conv71.51.44 = zext i8 %18325 to i32
  %xor72.51.44 = xor i32 %conv71.51.44, %conv68.51.44
  %conv73.51.44 = trunc i32 %xor72.51.44 to i8
  store i8 %conv73.51.44, i8* %arrayidx70.44, align 1
  %scevgep20.52.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 52
  %18326 = load i8, i8* %scevgep20.52.44, align 1
  %conv68.52.44 = zext i8 %18326 to i32
  %18327 = load i8, i8* %arrayidx70.44, align 1
  %conv71.52.44 = zext i8 %18327 to i32
  %xor72.52.44 = xor i32 %conv71.52.44, %conv68.52.44
  %conv73.52.44 = trunc i32 %xor72.52.44 to i8
  store i8 %conv73.52.44, i8* %arrayidx70.44, align 1
  %scevgep20.53.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 53
  %18328 = load i8, i8* %scevgep20.53.44, align 1
  %conv68.53.44 = zext i8 %18328 to i32
  %18329 = load i8, i8* %arrayidx70.44, align 1
  %conv71.53.44 = zext i8 %18329 to i32
  %xor72.53.44 = xor i32 %conv71.53.44, %conv68.53.44
  %conv73.53.44 = trunc i32 %xor72.53.44 to i8
  store i8 %conv73.53.44, i8* %arrayidx70.44, align 1
  %scevgep20.54.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 54
  %18330 = load i8, i8* %scevgep20.54.44, align 1
  %conv68.54.44 = zext i8 %18330 to i32
  %18331 = load i8, i8* %arrayidx70.44, align 1
  %conv71.54.44 = zext i8 %18331 to i32
  %xor72.54.44 = xor i32 %conv71.54.44, %conv68.54.44
  %conv73.54.44 = trunc i32 %xor72.54.44 to i8
  store i8 %conv73.54.44, i8* %arrayidx70.44, align 1
  %scevgep20.55.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 55
  %18332 = load i8, i8* %scevgep20.55.44, align 1
  %conv68.55.44 = zext i8 %18332 to i32
  %18333 = load i8, i8* %arrayidx70.44, align 1
  %conv71.55.44 = zext i8 %18333 to i32
  %xor72.55.44 = xor i32 %conv71.55.44, %conv68.55.44
  %conv73.55.44 = trunc i32 %xor72.55.44 to i8
  store i8 %conv73.55.44, i8* %arrayidx70.44, align 1
  %scevgep20.56.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 56
  %18334 = load i8, i8* %scevgep20.56.44, align 1
  %conv68.56.44 = zext i8 %18334 to i32
  %18335 = load i8, i8* %arrayidx70.44, align 1
  %conv71.56.44 = zext i8 %18335 to i32
  %xor72.56.44 = xor i32 %conv71.56.44, %conv68.56.44
  %conv73.56.44 = trunc i32 %xor72.56.44 to i8
  store i8 %conv73.56.44, i8* %arrayidx70.44, align 1
  %scevgep20.57.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 57
  %18336 = load i8, i8* %scevgep20.57.44, align 1
  %conv68.57.44 = zext i8 %18336 to i32
  %18337 = load i8, i8* %arrayidx70.44, align 1
  %conv71.57.44 = zext i8 %18337 to i32
  %xor72.57.44 = xor i32 %conv71.57.44, %conv68.57.44
  %conv73.57.44 = trunc i32 %xor72.57.44 to i8
  store i8 %conv73.57.44, i8* %arrayidx70.44, align 1
  %scevgep20.58.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 58
  %18338 = load i8, i8* %scevgep20.58.44, align 1
  %conv68.58.44 = zext i8 %18338 to i32
  %18339 = load i8, i8* %arrayidx70.44, align 1
  %conv71.58.44 = zext i8 %18339 to i32
  %xor72.58.44 = xor i32 %conv71.58.44, %conv68.58.44
  %conv73.58.44 = trunc i32 %xor72.58.44 to i8
  store i8 %conv73.58.44, i8* %arrayidx70.44, align 1
  %scevgep20.59.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 59
  %18340 = load i8, i8* %scevgep20.59.44, align 1
  %conv68.59.44 = zext i8 %18340 to i32
  %18341 = load i8, i8* %arrayidx70.44, align 1
  %conv71.59.44 = zext i8 %18341 to i32
  %xor72.59.44 = xor i32 %conv71.59.44, %conv68.59.44
  %conv73.59.44 = trunc i32 %xor72.59.44 to i8
  store i8 %conv73.59.44, i8* %arrayidx70.44, align 1
  %scevgep20.60.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 0, i64 60
  %18342 = load i8, i8* %scevgep20.60.44, align 1
  %conv68.60.44 = zext i8 %18342 to i32
  %18343 = load i8, i8* %arrayidx70.44, align 1
  %conv71.60.44 = zext i8 %18343 to i32
  %xor72.60.44 = xor i32 %conv71.60.44, %conv68.60.44
  %conv73.60.44 = trunc i32 %xor72.60.44 to i8
  store i8 %conv73.60.44, i8* %arrayidx70.44, align 1
  %scevgep19.44 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18221, i64 0, i64 1, i64 0
  %18344 = bitcast i8* %scevgep19.44 to [61 x [61 x i8]]*
  %arrayidx51.45 = getelementptr inbounds i8, i8* %a, i64 45
  %18345 = load i8, i8* %arrayidx51.45, align 1
  %arrayidx53.45 = getelementptr inbounds i8, i8* %b, i64 45
  %18346 = load i8, i8* %arrayidx53.45, align 1
  %call54.45 = call zeroext i8 @mult(i8 zeroext %18345, i8 zeroext %18346)
  %arrayidx56.45 = getelementptr inbounds i8, i8* %c, i64 45
  store i8 %call54.45, i8* %arrayidx56.45, align 1
  %arrayidx70.45 = getelementptr inbounds i8, i8* %c, i64 45
  %scevgep20.45494 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 0
  %18347 = load i8, i8* %scevgep20.45494, align 1
  %conv68.45495 = zext i8 %18347 to i32
  %18348 = load i8, i8* %arrayidx70.45, align 1
  %conv71.45496 = zext i8 %18348 to i32
  %xor72.45497 = xor i32 %conv71.45496, %conv68.45495
  %conv73.45498 = trunc i32 %xor72.45497 to i8
  store i8 %conv73.45498, i8* %arrayidx70.45, align 1
  %scevgep20.1.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 1
  %18349 = load i8, i8* %scevgep20.1.45, align 1
  %conv68.1.45 = zext i8 %18349 to i32
  %18350 = load i8, i8* %arrayidx70.45, align 1
  %conv71.1.45 = zext i8 %18350 to i32
  %xor72.1.45 = xor i32 %conv71.1.45, %conv68.1.45
  %conv73.1.45 = trunc i32 %xor72.1.45 to i8
  store i8 %conv73.1.45, i8* %arrayidx70.45, align 1
  %scevgep20.2.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 2
  %18351 = load i8, i8* %scevgep20.2.45, align 1
  %conv68.2.45 = zext i8 %18351 to i32
  %18352 = load i8, i8* %arrayidx70.45, align 1
  %conv71.2.45 = zext i8 %18352 to i32
  %xor72.2.45 = xor i32 %conv71.2.45, %conv68.2.45
  %conv73.2.45 = trunc i32 %xor72.2.45 to i8
  store i8 %conv73.2.45, i8* %arrayidx70.45, align 1
  %scevgep20.3.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 3
  %18353 = load i8, i8* %scevgep20.3.45, align 1
  %conv68.3.45 = zext i8 %18353 to i32
  %18354 = load i8, i8* %arrayidx70.45, align 1
  %conv71.3.45 = zext i8 %18354 to i32
  %xor72.3.45 = xor i32 %conv71.3.45, %conv68.3.45
  %conv73.3.45 = trunc i32 %xor72.3.45 to i8
  store i8 %conv73.3.45, i8* %arrayidx70.45, align 1
  %scevgep20.4.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 4
  %18355 = load i8, i8* %scevgep20.4.45, align 1
  %conv68.4.45 = zext i8 %18355 to i32
  %18356 = load i8, i8* %arrayidx70.45, align 1
  %conv71.4.45 = zext i8 %18356 to i32
  %xor72.4.45 = xor i32 %conv71.4.45, %conv68.4.45
  %conv73.4.45 = trunc i32 %xor72.4.45 to i8
  store i8 %conv73.4.45, i8* %arrayidx70.45, align 1
  %scevgep20.5.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 5
  %18357 = load i8, i8* %scevgep20.5.45, align 1
  %conv68.5.45 = zext i8 %18357 to i32
  %18358 = load i8, i8* %arrayidx70.45, align 1
  %conv71.5.45 = zext i8 %18358 to i32
  %xor72.5.45 = xor i32 %conv71.5.45, %conv68.5.45
  %conv73.5.45 = trunc i32 %xor72.5.45 to i8
  store i8 %conv73.5.45, i8* %arrayidx70.45, align 1
  %scevgep20.6.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 6
  %18359 = load i8, i8* %scevgep20.6.45, align 1
  %conv68.6.45 = zext i8 %18359 to i32
  %18360 = load i8, i8* %arrayidx70.45, align 1
  %conv71.6.45 = zext i8 %18360 to i32
  %xor72.6.45 = xor i32 %conv71.6.45, %conv68.6.45
  %conv73.6.45 = trunc i32 %xor72.6.45 to i8
  store i8 %conv73.6.45, i8* %arrayidx70.45, align 1
  %scevgep20.7.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 7
  %18361 = load i8, i8* %scevgep20.7.45, align 1
  %conv68.7.45 = zext i8 %18361 to i32
  %18362 = load i8, i8* %arrayidx70.45, align 1
  %conv71.7.45 = zext i8 %18362 to i32
  %xor72.7.45 = xor i32 %conv71.7.45, %conv68.7.45
  %conv73.7.45 = trunc i32 %xor72.7.45 to i8
  store i8 %conv73.7.45, i8* %arrayidx70.45, align 1
  %scevgep20.8.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 8
  %18363 = load i8, i8* %scevgep20.8.45, align 1
  %conv68.8.45 = zext i8 %18363 to i32
  %18364 = load i8, i8* %arrayidx70.45, align 1
  %conv71.8.45 = zext i8 %18364 to i32
  %xor72.8.45 = xor i32 %conv71.8.45, %conv68.8.45
  %conv73.8.45 = trunc i32 %xor72.8.45 to i8
  store i8 %conv73.8.45, i8* %arrayidx70.45, align 1
  %scevgep20.9.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 9
  %18365 = load i8, i8* %scevgep20.9.45, align 1
  %conv68.9.45 = zext i8 %18365 to i32
  %18366 = load i8, i8* %arrayidx70.45, align 1
  %conv71.9.45 = zext i8 %18366 to i32
  %xor72.9.45 = xor i32 %conv71.9.45, %conv68.9.45
  %conv73.9.45 = trunc i32 %xor72.9.45 to i8
  store i8 %conv73.9.45, i8* %arrayidx70.45, align 1
  %scevgep20.10.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 10
  %18367 = load i8, i8* %scevgep20.10.45, align 1
  %conv68.10.45 = zext i8 %18367 to i32
  %18368 = load i8, i8* %arrayidx70.45, align 1
  %conv71.10.45 = zext i8 %18368 to i32
  %xor72.10.45 = xor i32 %conv71.10.45, %conv68.10.45
  %conv73.10.45 = trunc i32 %xor72.10.45 to i8
  store i8 %conv73.10.45, i8* %arrayidx70.45, align 1
  %scevgep20.11.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 11
  %18369 = load i8, i8* %scevgep20.11.45, align 1
  %conv68.11.45 = zext i8 %18369 to i32
  %18370 = load i8, i8* %arrayidx70.45, align 1
  %conv71.11.45 = zext i8 %18370 to i32
  %xor72.11.45 = xor i32 %conv71.11.45, %conv68.11.45
  %conv73.11.45 = trunc i32 %xor72.11.45 to i8
  store i8 %conv73.11.45, i8* %arrayidx70.45, align 1
  %scevgep20.12.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 12
  %18371 = load i8, i8* %scevgep20.12.45, align 1
  %conv68.12.45 = zext i8 %18371 to i32
  %18372 = load i8, i8* %arrayidx70.45, align 1
  %conv71.12.45 = zext i8 %18372 to i32
  %xor72.12.45 = xor i32 %conv71.12.45, %conv68.12.45
  %conv73.12.45 = trunc i32 %xor72.12.45 to i8
  store i8 %conv73.12.45, i8* %arrayidx70.45, align 1
  %scevgep20.13.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 13
  %18373 = load i8, i8* %scevgep20.13.45, align 1
  %conv68.13.45 = zext i8 %18373 to i32
  %18374 = load i8, i8* %arrayidx70.45, align 1
  %conv71.13.45 = zext i8 %18374 to i32
  %xor72.13.45 = xor i32 %conv71.13.45, %conv68.13.45
  %conv73.13.45 = trunc i32 %xor72.13.45 to i8
  store i8 %conv73.13.45, i8* %arrayidx70.45, align 1
  %scevgep20.14.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 14
  %18375 = load i8, i8* %scevgep20.14.45, align 1
  %conv68.14.45 = zext i8 %18375 to i32
  %18376 = load i8, i8* %arrayidx70.45, align 1
  %conv71.14.45 = zext i8 %18376 to i32
  %xor72.14.45 = xor i32 %conv71.14.45, %conv68.14.45
  %conv73.14.45 = trunc i32 %xor72.14.45 to i8
  store i8 %conv73.14.45, i8* %arrayidx70.45, align 1
  %scevgep20.15.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 15
  %18377 = load i8, i8* %scevgep20.15.45, align 1
  %conv68.15.45 = zext i8 %18377 to i32
  %18378 = load i8, i8* %arrayidx70.45, align 1
  %conv71.15.45 = zext i8 %18378 to i32
  %xor72.15.45 = xor i32 %conv71.15.45, %conv68.15.45
  %conv73.15.45 = trunc i32 %xor72.15.45 to i8
  store i8 %conv73.15.45, i8* %arrayidx70.45, align 1
  %scevgep20.16.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 16
  %18379 = load i8, i8* %scevgep20.16.45, align 1
  %conv68.16.45 = zext i8 %18379 to i32
  %18380 = load i8, i8* %arrayidx70.45, align 1
  %conv71.16.45 = zext i8 %18380 to i32
  %xor72.16.45 = xor i32 %conv71.16.45, %conv68.16.45
  %conv73.16.45 = trunc i32 %xor72.16.45 to i8
  store i8 %conv73.16.45, i8* %arrayidx70.45, align 1
  %scevgep20.17.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 17
  %18381 = load i8, i8* %scevgep20.17.45, align 1
  %conv68.17.45 = zext i8 %18381 to i32
  %18382 = load i8, i8* %arrayidx70.45, align 1
  %conv71.17.45 = zext i8 %18382 to i32
  %xor72.17.45 = xor i32 %conv71.17.45, %conv68.17.45
  %conv73.17.45 = trunc i32 %xor72.17.45 to i8
  store i8 %conv73.17.45, i8* %arrayidx70.45, align 1
  %scevgep20.18.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 18
  %18383 = load i8, i8* %scevgep20.18.45, align 1
  %conv68.18.45 = zext i8 %18383 to i32
  %18384 = load i8, i8* %arrayidx70.45, align 1
  %conv71.18.45 = zext i8 %18384 to i32
  %xor72.18.45 = xor i32 %conv71.18.45, %conv68.18.45
  %conv73.18.45 = trunc i32 %xor72.18.45 to i8
  store i8 %conv73.18.45, i8* %arrayidx70.45, align 1
  %scevgep20.19.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 19
  %18385 = load i8, i8* %scevgep20.19.45, align 1
  %conv68.19.45 = zext i8 %18385 to i32
  %18386 = load i8, i8* %arrayidx70.45, align 1
  %conv71.19.45 = zext i8 %18386 to i32
  %xor72.19.45 = xor i32 %conv71.19.45, %conv68.19.45
  %conv73.19.45 = trunc i32 %xor72.19.45 to i8
  store i8 %conv73.19.45, i8* %arrayidx70.45, align 1
  %scevgep20.20.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 20
  %18387 = load i8, i8* %scevgep20.20.45, align 1
  %conv68.20.45 = zext i8 %18387 to i32
  %18388 = load i8, i8* %arrayidx70.45, align 1
  %conv71.20.45 = zext i8 %18388 to i32
  %xor72.20.45 = xor i32 %conv71.20.45, %conv68.20.45
  %conv73.20.45 = trunc i32 %xor72.20.45 to i8
  store i8 %conv73.20.45, i8* %arrayidx70.45, align 1
  %scevgep20.21.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 21
  %18389 = load i8, i8* %scevgep20.21.45, align 1
  %conv68.21.45 = zext i8 %18389 to i32
  %18390 = load i8, i8* %arrayidx70.45, align 1
  %conv71.21.45 = zext i8 %18390 to i32
  %xor72.21.45 = xor i32 %conv71.21.45, %conv68.21.45
  %conv73.21.45 = trunc i32 %xor72.21.45 to i8
  store i8 %conv73.21.45, i8* %arrayidx70.45, align 1
  %scevgep20.22.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 22
  %18391 = load i8, i8* %scevgep20.22.45, align 1
  %conv68.22.45 = zext i8 %18391 to i32
  %18392 = load i8, i8* %arrayidx70.45, align 1
  %conv71.22.45 = zext i8 %18392 to i32
  %xor72.22.45 = xor i32 %conv71.22.45, %conv68.22.45
  %conv73.22.45 = trunc i32 %xor72.22.45 to i8
  store i8 %conv73.22.45, i8* %arrayidx70.45, align 1
  %scevgep20.23.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 23
  %18393 = load i8, i8* %scevgep20.23.45, align 1
  %conv68.23.45 = zext i8 %18393 to i32
  %18394 = load i8, i8* %arrayidx70.45, align 1
  %conv71.23.45 = zext i8 %18394 to i32
  %xor72.23.45 = xor i32 %conv71.23.45, %conv68.23.45
  %conv73.23.45 = trunc i32 %xor72.23.45 to i8
  store i8 %conv73.23.45, i8* %arrayidx70.45, align 1
  %scevgep20.24.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 24
  %18395 = load i8, i8* %scevgep20.24.45, align 1
  %conv68.24.45 = zext i8 %18395 to i32
  %18396 = load i8, i8* %arrayidx70.45, align 1
  %conv71.24.45 = zext i8 %18396 to i32
  %xor72.24.45 = xor i32 %conv71.24.45, %conv68.24.45
  %conv73.24.45 = trunc i32 %xor72.24.45 to i8
  store i8 %conv73.24.45, i8* %arrayidx70.45, align 1
  %scevgep20.25.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 25
  %18397 = load i8, i8* %scevgep20.25.45, align 1
  %conv68.25.45 = zext i8 %18397 to i32
  %18398 = load i8, i8* %arrayidx70.45, align 1
  %conv71.25.45 = zext i8 %18398 to i32
  %xor72.25.45 = xor i32 %conv71.25.45, %conv68.25.45
  %conv73.25.45 = trunc i32 %xor72.25.45 to i8
  store i8 %conv73.25.45, i8* %arrayidx70.45, align 1
  %scevgep20.26.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 26
  %18399 = load i8, i8* %scevgep20.26.45, align 1
  %conv68.26.45 = zext i8 %18399 to i32
  %18400 = load i8, i8* %arrayidx70.45, align 1
  %conv71.26.45 = zext i8 %18400 to i32
  %xor72.26.45 = xor i32 %conv71.26.45, %conv68.26.45
  %conv73.26.45 = trunc i32 %xor72.26.45 to i8
  store i8 %conv73.26.45, i8* %arrayidx70.45, align 1
  %scevgep20.27.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 27
  %18401 = load i8, i8* %scevgep20.27.45, align 1
  %conv68.27.45 = zext i8 %18401 to i32
  %18402 = load i8, i8* %arrayidx70.45, align 1
  %conv71.27.45 = zext i8 %18402 to i32
  %xor72.27.45 = xor i32 %conv71.27.45, %conv68.27.45
  %conv73.27.45 = trunc i32 %xor72.27.45 to i8
  store i8 %conv73.27.45, i8* %arrayidx70.45, align 1
  %scevgep20.28.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 28
  %18403 = load i8, i8* %scevgep20.28.45, align 1
  %conv68.28.45 = zext i8 %18403 to i32
  %18404 = load i8, i8* %arrayidx70.45, align 1
  %conv71.28.45 = zext i8 %18404 to i32
  %xor72.28.45 = xor i32 %conv71.28.45, %conv68.28.45
  %conv73.28.45 = trunc i32 %xor72.28.45 to i8
  store i8 %conv73.28.45, i8* %arrayidx70.45, align 1
  %scevgep20.29.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 29
  %18405 = load i8, i8* %scevgep20.29.45, align 1
  %conv68.29.45 = zext i8 %18405 to i32
  %18406 = load i8, i8* %arrayidx70.45, align 1
  %conv71.29.45 = zext i8 %18406 to i32
  %xor72.29.45 = xor i32 %conv71.29.45, %conv68.29.45
  %conv73.29.45 = trunc i32 %xor72.29.45 to i8
  store i8 %conv73.29.45, i8* %arrayidx70.45, align 1
  %scevgep20.30.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 30
  %18407 = load i8, i8* %scevgep20.30.45, align 1
  %conv68.30.45 = zext i8 %18407 to i32
  %18408 = load i8, i8* %arrayidx70.45, align 1
  %conv71.30.45 = zext i8 %18408 to i32
  %xor72.30.45 = xor i32 %conv71.30.45, %conv68.30.45
  %conv73.30.45 = trunc i32 %xor72.30.45 to i8
  store i8 %conv73.30.45, i8* %arrayidx70.45, align 1
  %scevgep20.31.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 31
  %18409 = load i8, i8* %scevgep20.31.45, align 1
  %conv68.31.45 = zext i8 %18409 to i32
  %18410 = load i8, i8* %arrayidx70.45, align 1
  %conv71.31.45 = zext i8 %18410 to i32
  %xor72.31.45 = xor i32 %conv71.31.45, %conv68.31.45
  %conv73.31.45 = trunc i32 %xor72.31.45 to i8
  store i8 %conv73.31.45, i8* %arrayidx70.45, align 1
  %scevgep20.32.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 32
  %18411 = load i8, i8* %scevgep20.32.45, align 1
  %conv68.32.45 = zext i8 %18411 to i32
  %18412 = load i8, i8* %arrayidx70.45, align 1
  %conv71.32.45 = zext i8 %18412 to i32
  %xor72.32.45 = xor i32 %conv71.32.45, %conv68.32.45
  %conv73.32.45 = trunc i32 %xor72.32.45 to i8
  store i8 %conv73.32.45, i8* %arrayidx70.45, align 1
  %scevgep20.33.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 33
  %18413 = load i8, i8* %scevgep20.33.45, align 1
  %conv68.33.45 = zext i8 %18413 to i32
  %18414 = load i8, i8* %arrayidx70.45, align 1
  %conv71.33.45 = zext i8 %18414 to i32
  %xor72.33.45 = xor i32 %conv71.33.45, %conv68.33.45
  %conv73.33.45 = trunc i32 %xor72.33.45 to i8
  store i8 %conv73.33.45, i8* %arrayidx70.45, align 1
  %scevgep20.34.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 34
  %18415 = load i8, i8* %scevgep20.34.45, align 1
  %conv68.34.45 = zext i8 %18415 to i32
  %18416 = load i8, i8* %arrayidx70.45, align 1
  %conv71.34.45 = zext i8 %18416 to i32
  %xor72.34.45 = xor i32 %conv71.34.45, %conv68.34.45
  %conv73.34.45 = trunc i32 %xor72.34.45 to i8
  store i8 %conv73.34.45, i8* %arrayidx70.45, align 1
  %scevgep20.35.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 35
  %18417 = load i8, i8* %scevgep20.35.45, align 1
  %conv68.35.45 = zext i8 %18417 to i32
  %18418 = load i8, i8* %arrayidx70.45, align 1
  %conv71.35.45 = zext i8 %18418 to i32
  %xor72.35.45 = xor i32 %conv71.35.45, %conv68.35.45
  %conv73.35.45 = trunc i32 %xor72.35.45 to i8
  store i8 %conv73.35.45, i8* %arrayidx70.45, align 1
  %scevgep20.36.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 36
  %18419 = load i8, i8* %scevgep20.36.45, align 1
  %conv68.36.45 = zext i8 %18419 to i32
  %18420 = load i8, i8* %arrayidx70.45, align 1
  %conv71.36.45 = zext i8 %18420 to i32
  %xor72.36.45 = xor i32 %conv71.36.45, %conv68.36.45
  %conv73.36.45 = trunc i32 %xor72.36.45 to i8
  store i8 %conv73.36.45, i8* %arrayidx70.45, align 1
  %scevgep20.37.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 37
  %18421 = load i8, i8* %scevgep20.37.45, align 1
  %conv68.37.45 = zext i8 %18421 to i32
  %18422 = load i8, i8* %arrayidx70.45, align 1
  %conv71.37.45 = zext i8 %18422 to i32
  %xor72.37.45 = xor i32 %conv71.37.45, %conv68.37.45
  %conv73.37.45 = trunc i32 %xor72.37.45 to i8
  store i8 %conv73.37.45, i8* %arrayidx70.45, align 1
  %scevgep20.38.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 38
  %18423 = load i8, i8* %scevgep20.38.45, align 1
  %conv68.38.45 = zext i8 %18423 to i32
  %18424 = load i8, i8* %arrayidx70.45, align 1
  %conv71.38.45 = zext i8 %18424 to i32
  %xor72.38.45 = xor i32 %conv71.38.45, %conv68.38.45
  %conv73.38.45 = trunc i32 %xor72.38.45 to i8
  store i8 %conv73.38.45, i8* %arrayidx70.45, align 1
  %scevgep20.39.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 39
  %18425 = load i8, i8* %scevgep20.39.45, align 1
  %conv68.39.45 = zext i8 %18425 to i32
  %18426 = load i8, i8* %arrayidx70.45, align 1
  %conv71.39.45 = zext i8 %18426 to i32
  %xor72.39.45 = xor i32 %conv71.39.45, %conv68.39.45
  %conv73.39.45 = trunc i32 %xor72.39.45 to i8
  store i8 %conv73.39.45, i8* %arrayidx70.45, align 1
  %scevgep20.40.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 40
  %18427 = load i8, i8* %scevgep20.40.45, align 1
  %conv68.40.45 = zext i8 %18427 to i32
  %18428 = load i8, i8* %arrayidx70.45, align 1
  %conv71.40.45 = zext i8 %18428 to i32
  %xor72.40.45 = xor i32 %conv71.40.45, %conv68.40.45
  %conv73.40.45 = trunc i32 %xor72.40.45 to i8
  store i8 %conv73.40.45, i8* %arrayidx70.45, align 1
  %scevgep20.41.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 41
  %18429 = load i8, i8* %scevgep20.41.45, align 1
  %conv68.41.45 = zext i8 %18429 to i32
  %18430 = load i8, i8* %arrayidx70.45, align 1
  %conv71.41.45 = zext i8 %18430 to i32
  %xor72.41.45 = xor i32 %conv71.41.45, %conv68.41.45
  %conv73.41.45 = trunc i32 %xor72.41.45 to i8
  store i8 %conv73.41.45, i8* %arrayidx70.45, align 1
  %scevgep20.42.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 42
  %18431 = load i8, i8* %scevgep20.42.45, align 1
  %conv68.42.45 = zext i8 %18431 to i32
  %18432 = load i8, i8* %arrayidx70.45, align 1
  %conv71.42.45 = zext i8 %18432 to i32
  %xor72.42.45 = xor i32 %conv71.42.45, %conv68.42.45
  %conv73.42.45 = trunc i32 %xor72.42.45 to i8
  store i8 %conv73.42.45, i8* %arrayidx70.45, align 1
  %scevgep20.43.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 43
  %18433 = load i8, i8* %scevgep20.43.45, align 1
  %conv68.43.45 = zext i8 %18433 to i32
  %18434 = load i8, i8* %arrayidx70.45, align 1
  %conv71.43.45 = zext i8 %18434 to i32
  %xor72.43.45 = xor i32 %conv71.43.45, %conv68.43.45
  %conv73.43.45 = trunc i32 %xor72.43.45 to i8
  store i8 %conv73.43.45, i8* %arrayidx70.45, align 1
  %scevgep20.44.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 44
  %18435 = load i8, i8* %scevgep20.44.45, align 1
  %conv68.44.45 = zext i8 %18435 to i32
  %18436 = load i8, i8* %arrayidx70.45, align 1
  %conv71.44.45 = zext i8 %18436 to i32
  %xor72.44.45 = xor i32 %conv71.44.45, %conv68.44.45
  %conv73.44.45 = trunc i32 %xor72.44.45 to i8
  store i8 %conv73.44.45, i8* %arrayidx70.45, align 1
  %scevgep20.46.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 46
  %18437 = load i8, i8* %scevgep20.46.45, align 1
  %conv68.46.45 = zext i8 %18437 to i32
  %18438 = load i8, i8* %arrayidx70.45, align 1
  %conv71.46.45 = zext i8 %18438 to i32
  %xor72.46.45 = xor i32 %conv71.46.45, %conv68.46.45
  %conv73.46.45 = trunc i32 %xor72.46.45 to i8
  store i8 %conv73.46.45, i8* %arrayidx70.45, align 1
  %scevgep20.47.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 47
  %18439 = load i8, i8* %scevgep20.47.45, align 1
  %conv68.47.45 = zext i8 %18439 to i32
  %18440 = load i8, i8* %arrayidx70.45, align 1
  %conv71.47.45 = zext i8 %18440 to i32
  %xor72.47.45 = xor i32 %conv71.47.45, %conv68.47.45
  %conv73.47.45 = trunc i32 %xor72.47.45 to i8
  store i8 %conv73.47.45, i8* %arrayidx70.45, align 1
  %scevgep20.48.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 48
  %18441 = load i8, i8* %scevgep20.48.45, align 1
  %conv68.48.45 = zext i8 %18441 to i32
  %18442 = load i8, i8* %arrayidx70.45, align 1
  %conv71.48.45 = zext i8 %18442 to i32
  %xor72.48.45 = xor i32 %conv71.48.45, %conv68.48.45
  %conv73.48.45 = trunc i32 %xor72.48.45 to i8
  store i8 %conv73.48.45, i8* %arrayidx70.45, align 1
  %scevgep20.49.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 49
  %18443 = load i8, i8* %scevgep20.49.45, align 1
  %conv68.49.45 = zext i8 %18443 to i32
  %18444 = load i8, i8* %arrayidx70.45, align 1
  %conv71.49.45 = zext i8 %18444 to i32
  %xor72.49.45 = xor i32 %conv71.49.45, %conv68.49.45
  %conv73.49.45 = trunc i32 %xor72.49.45 to i8
  store i8 %conv73.49.45, i8* %arrayidx70.45, align 1
  %scevgep20.50.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 50
  %18445 = load i8, i8* %scevgep20.50.45, align 1
  %conv68.50.45 = zext i8 %18445 to i32
  %18446 = load i8, i8* %arrayidx70.45, align 1
  %conv71.50.45 = zext i8 %18446 to i32
  %xor72.50.45 = xor i32 %conv71.50.45, %conv68.50.45
  %conv73.50.45 = trunc i32 %xor72.50.45 to i8
  store i8 %conv73.50.45, i8* %arrayidx70.45, align 1
  %scevgep20.51.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 51
  %18447 = load i8, i8* %scevgep20.51.45, align 1
  %conv68.51.45 = zext i8 %18447 to i32
  %18448 = load i8, i8* %arrayidx70.45, align 1
  %conv71.51.45 = zext i8 %18448 to i32
  %xor72.51.45 = xor i32 %conv71.51.45, %conv68.51.45
  %conv73.51.45 = trunc i32 %xor72.51.45 to i8
  store i8 %conv73.51.45, i8* %arrayidx70.45, align 1
  %scevgep20.52.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 52
  %18449 = load i8, i8* %scevgep20.52.45, align 1
  %conv68.52.45 = zext i8 %18449 to i32
  %18450 = load i8, i8* %arrayidx70.45, align 1
  %conv71.52.45 = zext i8 %18450 to i32
  %xor72.52.45 = xor i32 %conv71.52.45, %conv68.52.45
  %conv73.52.45 = trunc i32 %xor72.52.45 to i8
  store i8 %conv73.52.45, i8* %arrayidx70.45, align 1
  %scevgep20.53.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 53
  %18451 = load i8, i8* %scevgep20.53.45, align 1
  %conv68.53.45 = zext i8 %18451 to i32
  %18452 = load i8, i8* %arrayidx70.45, align 1
  %conv71.53.45 = zext i8 %18452 to i32
  %xor72.53.45 = xor i32 %conv71.53.45, %conv68.53.45
  %conv73.53.45 = trunc i32 %xor72.53.45 to i8
  store i8 %conv73.53.45, i8* %arrayidx70.45, align 1
  %scevgep20.54.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 54
  %18453 = load i8, i8* %scevgep20.54.45, align 1
  %conv68.54.45 = zext i8 %18453 to i32
  %18454 = load i8, i8* %arrayidx70.45, align 1
  %conv71.54.45 = zext i8 %18454 to i32
  %xor72.54.45 = xor i32 %conv71.54.45, %conv68.54.45
  %conv73.54.45 = trunc i32 %xor72.54.45 to i8
  store i8 %conv73.54.45, i8* %arrayidx70.45, align 1
  %scevgep20.55.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 55
  %18455 = load i8, i8* %scevgep20.55.45, align 1
  %conv68.55.45 = zext i8 %18455 to i32
  %18456 = load i8, i8* %arrayidx70.45, align 1
  %conv71.55.45 = zext i8 %18456 to i32
  %xor72.55.45 = xor i32 %conv71.55.45, %conv68.55.45
  %conv73.55.45 = trunc i32 %xor72.55.45 to i8
  store i8 %conv73.55.45, i8* %arrayidx70.45, align 1
  %scevgep20.56.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 56
  %18457 = load i8, i8* %scevgep20.56.45, align 1
  %conv68.56.45 = zext i8 %18457 to i32
  %18458 = load i8, i8* %arrayidx70.45, align 1
  %conv71.56.45 = zext i8 %18458 to i32
  %xor72.56.45 = xor i32 %conv71.56.45, %conv68.56.45
  %conv73.56.45 = trunc i32 %xor72.56.45 to i8
  store i8 %conv73.56.45, i8* %arrayidx70.45, align 1
  %scevgep20.57.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 57
  %18459 = load i8, i8* %scevgep20.57.45, align 1
  %conv68.57.45 = zext i8 %18459 to i32
  %18460 = load i8, i8* %arrayidx70.45, align 1
  %conv71.57.45 = zext i8 %18460 to i32
  %xor72.57.45 = xor i32 %conv71.57.45, %conv68.57.45
  %conv73.57.45 = trunc i32 %xor72.57.45 to i8
  store i8 %conv73.57.45, i8* %arrayidx70.45, align 1
  %scevgep20.58.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 58
  %18461 = load i8, i8* %scevgep20.58.45, align 1
  %conv68.58.45 = zext i8 %18461 to i32
  %18462 = load i8, i8* %arrayidx70.45, align 1
  %conv71.58.45 = zext i8 %18462 to i32
  %xor72.58.45 = xor i32 %conv71.58.45, %conv68.58.45
  %conv73.58.45 = trunc i32 %xor72.58.45 to i8
  store i8 %conv73.58.45, i8* %arrayidx70.45, align 1
  %scevgep20.59.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 59
  %18463 = load i8, i8* %scevgep20.59.45, align 1
  %conv68.59.45 = zext i8 %18463 to i32
  %18464 = load i8, i8* %arrayidx70.45, align 1
  %conv71.59.45 = zext i8 %18464 to i32
  %xor72.59.45 = xor i32 %conv71.59.45, %conv68.59.45
  %conv73.59.45 = trunc i32 %xor72.59.45 to i8
  store i8 %conv73.59.45, i8* %arrayidx70.45, align 1
  %scevgep20.60.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 0, i64 60
  %18465 = load i8, i8* %scevgep20.60.45, align 1
  %conv68.60.45 = zext i8 %18465 to i32
  %18466 = load i8, i8* %arrayidx70.45, align 1
  %conv71.60.45 = zext i8 %18466 to i32
  %xor72.60.45 = xor i32 %conv71.60.45, %conv68.60.45
  %conv73.60.45 = trunc i32 %xor72.60.45 to i8
  store i8 %conv73.60.45, i8* %arrayidx70.45, align 1
  %scevgep19.45 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18344, i64 0, i64 1, i64 0
  %18467 = bitcast i8* %scevgep19.45 to [61 x [61 x i8]]*
  %arrayidx51.46 = getelementptr inbounds i8, i8* %a, i64 46
  %18468 = load i8, i8* %arrayidx51.46, align 1
  %arrayidx53.46 = getelementptr inbounds i8, i8* %b, i64 46
  %18469 = load i8, i8* %arrayidx53.46, align 1
  %call54.46 = call zeroext i8 @mult(i8 zeroext %18468, i8 zeroext %18469)
  %arrayidx56.46 = getelementptr inbounds i8, i8* %c, i64 46
  store i8 %call54.46, i8* %arrayidx56.46, align 1
  %arrayidx70.46 = getelementptr inbounds i8, i8* %c, i64 46
  %scevgep20.46504 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 0
  %18470 = load i8, i8* %scevgep20.46504, align 1
  %conv68.46505 = zext i8 %18470 to i32
  %18471 = load i8, i8* %arrayidx70.46, align 1
  %conv71.46506 = zext i8 %18471 to i32
  %xor72.46507 = xor i32 %conv71.46506, %conv68.46505
  %conv73.46508 = trunc i32 %xor72.46507 to i8
  store i8 %conv73.46508, i8* %arrayidx70.46, align 1
  %scevgep20.1.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 1
  %18472 = load i8, i8* %scevgep20.1.46, align 1
  %conv68.1.46 = zext i8 %18472 to i32
  %18473 = load i8, i8* %arrayidx70.46, align 1
  %conv71.1.46 = zext i8 %18473 to i32
  %xor72.1.46 = xor i32 %conv71.1.46, %conv68.1.46
  %conv73.1.46 = trunc i32 %xor72.1.46 to i8
  store i8 %conv73.1.46, i8* %arrayidx70.46, align 1
  %scevgep20.2.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 2
  %18474 = load i8, i8* %scevgep20.2.46, align 1
  %conv68.2.46 = zext i8 %18474 to i32
  %18475 = load i8, i8* %arrayidx70.46, align 1
  %conv71.2.46 = zext i8 %18475 to i32
  %xor72.2.46 = xor i32 %conv71.2.46, %conv68.2.46
  %conv73.2.46 = trunc i32 %xor72.2.46 to i8
  store i8 %conv73.2.46, i8* %arrayidx70.46, align 1
  %scevgep20.3.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 3
  %18476 = load i8, i8* %scevgep20.3.46, align 1
  %conv68.3.46 = zext i8 %18476 to i32
  %18477 = load i8, i8* %arrayidx70.46, align 1
  %conv71.3.46 = zext i8 %18477 to i32
  %xor72.3.46 = xor i32 %conv71.3.46, %conv68.3.46
  %conv73.3.46 = trunc i32 %xor72.3.46 to i8
  store i8 %conv73.3.46, i8* %arrayidx70.46, align 1
  %scevgep20.4.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 4
  %18478 = load i8, i8* %scevgep20.4.46, align 1
  %conv68.4.46 = zext i8 %18478 to i32
  %18479 = load i8, i8* %arrayidx70.46, align 1
  %conv71.4.46 = zext i8 %18479 to i32
  %xor72.4.46 = xor i32 %conv71.4.46, %conv68.4.46
  %conv73.4.46 = trunc i32 %xor72.4.46 to i8
  store i8 %conv73.4.46, i8* %arrayidx70.46, align 1
  %scevgep20.5.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 5
  %18480 = load i8, i8* %scevgep20.5.46, align 1
  %conv68.5.46 = zext i8 %18480 to i32
  %18481 = load i8, i8* %arrayidx70.46, align 1
  %conv71.5.46 = zext i8 %18481 to i32
  %xor72.5.46 = xor i32 %conv71.5.46, %conv68.5.46
  %conv73.5.46 = trunc i32 %xor72.5.46 to i8
  store i8 %conv73.5.46, i8* %arrayidx70.46, align 1
  %scevgep20.6.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 6
  %18482 = load i8, i8* %scevgep20.6.46, align 1
  %conv68.6.46 = zext i8 %18482 to i32
  %18483 = load i8, i8* %arrayidx70.46, align 1
  %conv71.6.46 = zext i8 %18483 to i32
  %xor72.6.46 = xor i32 %conv71.6.46, %conv68.6.46
  %conv73.6.46 = trunc i32 %xor72.6.46 to i8
  store i8 %conv73.6.46, i8* %arrayidx70.46, align 1
  %scevgep20.7.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 7
  %18484 = load i8, i8* %scevgep20.7.46, align 1
  %conv68.7.46 = zext i8 %18484 to i32
  %18485 = load i8, i8* %arrayidx70.46, align 1
  %conv71.7.46 = zext i8 %18485 to i32
  %xor72.7.46 = xor i32 %conv71.7.46, %conv68.7.46
  %conv73.7.46 = trunc i32 %xor72.7.46 to i8
  store i8 %conv73.7.46, i8* %arrayidx70.46, align 1
  %scevgep20.8.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 8
  %18486 = load i8, i8* %scevgep20.8.46, align 1
  %conv68.8.46 = zext i8 %18486 to i32
  %18487 = load i8, i8* %arrayidx70.46, align 1
  %conv71.8.46 = zext i8 %18487 to i32
  %xor72.8.46 = xor i32 %conv71.8.46, %conv68.8.46
  %conv73.8.46 = trunc i32 %xor72.8.46 to i8
  store i8 %conv73.8.46, i8* %arrayidx70.46, align 1
  %scevgep20.9.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 9
  %18488 = load i8, i8* %scevgep20.9.46, align 1
  %conv68.9.46 = zext i8 %18488 to i32
  %18489 = load i8, i8* %arrayidx70.46, align 1
  %conv71.9.46 = zext i8 %18489 to i32
  %xor72.9.46 = xor i32 %conv71.9.46, %conv68.9.46
  %conv73.9.46 = trunc i32 %xor72.9.46 to i8
  store i8 %conv73.9.46, i8* %arrayidx70.46, align 1
  %scevgep20.10.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 10
  %18490 = load i8, i8* %scevgep20.10.46, align 1
  %conv68.10.46 = zext i8 %18490 to i32
  %18491 = load i8, i8* %arrayidx70.46, align 1
  %conv71.10.46 = zext i8 %18491 to i32
  %xor72.10.46 = xor i32 %conv71.10.46, %conv68.10.46
  %conv73.10.46 = trunc i32 %xor72.10.46 to i8
  store i8 %conv73.10.46, i8* %arrayidx70.46, align 1
  %scevgep20.11.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 11
  %18492 = load i8, i8* %scevgep20.11.46, align 1
  %conv68.11.46 = zext i8 %18492 to i32
  %18493 = load i8, i8* %arrayidx70.46, align 1
  %conv71.11.46 = zext i8 %18493 to i32
  %xor72.11.46 = xor i32 %conv71.11.46, %conv68.11.46
  %conv73.11.46 = trunc i32 %xor72.11.46 to i8
  store i8 %conv73.11.46, i8* %arrayidx70.46, align 1
  %scevgep20.12.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 12
  %18494 = load i8, i8* %scevgep20.12.46, align 1
  %conv68.12.46 = zext i8 %18494 to i32
  %18495 = load i8, i8* %arrayidx70.46, align 1
  %conv71.12.46 = zext i8 %18495 to i32
  %xor72.12.46 = xor i32 %conv71.12.46, %conv68.12.46
  %conv73.12.46 = trunc i32 %xor72.12.46 to i8
  store i8 %conv73.12.46, i8* %arrayidx70.46, align 1
  %scevgep20.13.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 13
  %18496 = load i8, i8* %scevgep20.13.46, align 1
  %conv68.13.46 = zext i8 %18496 to i32
  %18497 = load i8, i8* %arrayidx70.46, align 1
  %conv71.13.46 = zext i8 %18497 to i32
  %xor72.13.46 = xor i32 %conv71.13.46, %conv68.13.46
  %conv73.13.46 = trunc i32 %xor72.13.46 to i8
  store i8 %conv73.13.46, i8* %arrayidx70.46, align 1
  %scevgep20.14.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 14
  %18498 = load i8, i8* %scevgep20.14.46, align 1
  %conv68.14.46 = zext i8 %18498 to i32
  %18499 = load i8, i8* %arrayidx70.46, align 1
  %conv71.14.46 = zext i8 %18499 to i32
  %xor72.14.46 = xor i32 %conv71.14.46, %conv68.14.46
  %conv73.14.46 = trunc i32 %xor72.14.46 to i8
  store i8 %conv73.14.46, i8* %arrayidx70.46, align 1
  %scevgep20.15.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 15
  %18500 = load i8, i8* %scevgep20.15.46, align 1
  %conv68.15.46 = zext i8 %18500 to i32
  %18501 = load i8, i8* %arrayidx70.46, align 1
  %conv71.15.46 = zext i8 %18501 to i32
  %xor72.15.46 = xor i32 %conv71.15.46, %conv68.15.46
  %conv73.15.46 = trunc i32 %xor72.15.46 to i8
  store i8 %conv73.15.46, i8* %arrayidx70.46, align 1
  %scevgep20.16.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 16
  %18502 = load i8, i8* %scevgep20.16.46, align 1
  %conv68.16.46 = zext i8 %18502 to i32
  %18503 = load i8, i8* %arrayidx70.46, align 1
  %conv71.16.46 = zext i8 %18503 to i32
  %xor72.16.46 = xor i32 %conv71.16.46, %conv68.16.46
  %conv73.16.46 = trunc i32 %xor72.16.46 to i8
  store i8 %conv73.16.46, i8* %arrayidx70.46, align 1
  %scevgep20.17.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 17
  %18504 = load i8, i8* %scevgep20.17.46, align 1
  %conv68.17.46 = zext i8 %18504 to i32
  %18505 = load i8, i8* %arrayidx70.46, align 1
  %conv71.17.46 = zext i8 %18505 to i32
  %xor72.17.46 = xor i32 %conv71.17.46, %conv68.17.46
  %conv73.17.46 = trunc i32 %xor72.17.46 to i8
  store i8 %conv73.17.46, i8* %arrayidx70.46, align 1
  %scevgep20.18.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 18
  %18506 = load i8, i8* %scevgep20.18.46, align 1
  %conv68.18.46 = zext i8 %18506 to i32
  %18507 = load i8, i8* %arrayidx70.46, align 1
  %conv71.18.46 = zext i8 %18507 to i32
  %xor72.18.46 = xor i32 %conv71.18.46, %conv68.18.46
  %conv73.18.46 = trunc i32 %xor72.18.46 to i8
  store i8 %conv73.18.46, i8* %arrayidx70.46, align 1
  %scevgep20.19.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 19
  %18508 = load i8, i8* %scevgep20.19.46, align 1
  %conv68.19.46 = zext i8 %18508 to i32
  %18509 = load i8, i8* %arrayidx70.46, align 1
  %conv71.19.46 = zext i8 %18509 to i32
  %xor72.19.46 = xor i32 %conv71.19.46, %conv68.19.46
  %conv73.19.46 = trunc i32 %xor72.19.46 to i8
  store i8 %conv73.19.46, i8* %arrayidx70.46, align 1
  %scevgep20.20.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 20
  %18510 = load i8, i8* %scevgep20.20.46, align 1
  %conv68.20.46 = zext i8 %18510 to i32
  %18511 = load i8, i8* %arrayidx70.46, align 1
  %conv71.20.46 = zext i8 %18511 to i32
  %xor72.20.46 = xor i32 %conv71.20.46, %conv68.20.46
  %conv73.20.46 = trunc i32 %xor72.20.46 to i8
  store i8 %conv73.20.46, i8* %arrayidx70.46, align 1
  %scevgep20.21.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 21
  %18512 = load i8, i8* %scevgep20.21.46, align 1
  %conv68.21.46 = zext i8 %18512 to i32
  %18513 = load i8, i8* %arrayidx70.46, align 1
  %conv71.21.46 = zext i8 %18513 to i32
  %xor72.21.46 = xor i32 %conv71.21.46, %conv68.21.46
  %conv73.21.46 = trunc i32 %xor72.21.46 to i8
  store i8 %conv73.21.46, i8* %arrayidx70.46, align 1
  %scevgep20.22.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 22
  %18514 = load i8, i8* %scevgep20.22.46, align 1
  %conv68.22.46 = zext i8 %18514 to i32
  %18515 = load i8, i8* %arrayidx70.46, align 1
  %conv71.22.46 = zext i8 %18515 to i32
  %xor72.22.46 = xor i32 %conv71.22.46, %conv68.22.46
  %conv73.22.46 = trunc i32 %xor72.22.46 to i8
  store i8 %conv73.22.46, i8* %arrayidx70.46, align 1
  %scevgep20.23.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 23
  %18516 = load i8, i8* %scevgep20.23.46, align 1
  %conv68.23.46 = zext i8 %18516 to i32
  %18517 = load i8, i8* %arrayidx70.46, align 1
  %conv71.23.46 = zext i8 %18517 to i32
  %xor72.23.46 = xor i32 %conv71.23.46, %conv68.23.46
  %conv73.23.46 = trunc i32 %xor72.23.46 to i8
  store i8 %conv73.23.46, i8* %arrayidx70.46, align 1
  %scevgep20.24.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 24
  %18518 = load i8, i8* %scevgep20.24.46, align 1
  %conv68.24.46 = zext i8 %18518 to i32
  %18519 = load i8, i8* %arrayidx70.46, align 1
  %conv71.24.46 = zext i8 %18519 to i32
  %xor72.24.46 = xor i32 %conv71.24.46, %conv68.24.46
  %conv73.24.46 = trunc i32 %xor72.24.46 to i8
  store i8 %conv73.24.46, i8* %arrayidx70.46, align 1
  %scevgep20.25.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 25
  %18520 = load i8, i8* %scevgep20.25.46, align 1
  %conv68.25.46 = zext i8 %18520 to i32
  %18521 = load i8, i8* %arrayidx70.46, align 1
  %conv71.25.46 = zext i8 %18521 to i32
  %xor72.25.46 = xor i32 %conv71.25.46, %conv68.25.46
  %conv73.25.46 = trunc i32 %xor72.25.46 to i8
  store i8 %conv73.25.46, i8* %arrayidx70.46, align 1
  %scevgep20.26.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 26
  %18522 = load i8, i8* %scevgep20.26.46, align 1
  %conv68.26.46 = zext i8 %18522 to i32
  %18523 = load i8, i8* %arrayidx70.46, align 1
  %conv71.26.46 = zext i8 %18523 to i32
  %xor72.26.46 = xor i32 %conv71.26.46, %conv68.26.46
  %conv73.26.46 = trunc i32 %xor72.26.46 to i8
  store i8 %conv73.26.46, i8* %arrayidx70.46, align 1
  %scevgep20.27.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 27
  %18524 = load i8, i8* %scevgep20.27.46, align 1
  %conv68.27.46 = zext i8 %18524 to i32
  %18525 = load i8, i8* %arrayidx70.46, align 1
  %conv71.27.46 = zext i8 %18525 to i32
  %xor72.27.46 = xor i32 %conv71.27.46, %conv68.27.46
  %conv73.27.46 = trunc i32 %xor72.27.46 to i8
  store i8 %conv73.27.46, i8* %arrayidx70.46, align 1
  %scevgep20.28.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 28
  %18526 = load i8, i8* %scevgep20.28.46, align 1
  %conv68.28.46 = zext i8 %18526 to i32
  %18527 = load i8, i8* %arrayidx70.46, align 1
  %conv71.28.46 = zext i8 %18527 to i32
  %xor72.28.46 = xor i32 %conv71.28.46, %conv68.28.46
  %conv73.28.46 = trunc i32 %xor72.28.46 to i8
  store i8 %conv73.28.46, i8* %arrayidx70.46, align 1
  %scevgep20.29.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 29
  %18528 = load i8, i8* %scevgep20.29.46, align 1
  %conv68.29.46 = zext i8 %18528 to i32
  %18529 = load i8, i8* %arrayidx70.46, align 1
  %conv71.29.46 = zext i8 %18529 to i32
  %xor72.29.46 = xor i32 %conv71.29.46, %conv68.29.46
  %conv73.29.46 = trunc i32 %xor72.29.46 to i8
  store i8 %conv73.29.46, i8* %arrayidx70.46, align 1
  %scevgep20.30.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 30
  %18530 = load i8, i8* %scevgep20.30.46, align 1
  %conv68.30.46 = zext i8 %18530 to i32
  %18531 = load i8, i8* %arrayidx70.46, align 1
  %conv71.30.46 = zext i8 %18531 to i32
  %xor72.30.46 = xor i32 %conv71.30.46, %conv68.30.46
  %conv73.30.46 = trunc i32 %xor72.30.46 to i8
  store i8 %conv73.30.46, i8* %arrayidx70.46, align 1
  %scevgep20.31.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 31
  %18532 = load i8, i8* %scevgep20.31.46, align 1
  %conv68.31.46 = zext i8 %18532 to i32
  %18533 = load i8, i8* %arrayidx70.46, align 1
  %conv71.31.46 = zext i8 %18533 to i32
  %xor72.31.46 = xor i32 %conv71.31.46, %conv68.31.46
  %conv73.31.46 = trunc i32 %xor72.31.46 to i8
  store i8 %conv73.31.46, i8* %arrayidx70.46, align 1
  %scevgep20.32.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 32
  %18534 = load i8, i8* %scevgep20.32.46, align 1
  %conv68.32.46 = zext i8 %18534 to i32
  %18535 = load i8, i8* %arrayidx70.46, align 1
  %conv71.32.46 = zext i8 %18535 to i32
  %xor72.32.46 = xor i32 %conv71.32.46, %conv68.32.46
  %conv73.32.46 = trunc i32 %xor72.32.46 to i8
  store i8 %conv73.32.46, i8* %arrayidx70.46, align 1
  %scevgep20.33.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 33
  %18536 = load i8, i8* %scevgep20.33.46, align 1
  %conv68.33.46 = zext i8 %18536 to i32
  %18537 = load i8, i8* %arrayidx70.46, align 1
  %conv71.33.46 = zext i8 %18537 to i32
  %xor72.33.46 = xor i32 %conv71.33.46, %conv68.33.46
  %conv73.33.46 = trunc i32 %xor72.33.46 to i8
  store i8 %conv73.33.46, i8* %arrayidx70.46, align 1
  %scevgep20.34.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 34
  %18538 = load i8, i8* %scevgep20.34.46, align 1
  %conv68.34.46 = zext i8 %18538 to i32
  %18539 = load i8, i8* %arrayidx70.46, align 1
  %conv71.34.46 = zext i8 %18539 to i32
  %xor72.34.46 = xor i32 %conv71.34.46, %conv68.34.46
  %conv73.34.46 = trunc i32 %xor72.34.46 to i8
  store i8 %conv73.34.46, i8* %arrayidx70.46, align 1
  %scevgep20.35.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 35
  %18540 = load i8, i8* %scevgep20.35.46, align 1
  %conv68.35.46 = zext i8 %18540 to i32
  %18541 = load i8, i8* %arrayidx70.46, align 1
  %conv71.35.46 = zext i8 %18541 to i32
  %xor72.35.46 = xor i32 %conv71.35.46, %conv68.35.46
  %conv73.35.46 = trunc i32 %xor72.35.46 to i8
  store i8 %conv73.35.46, i8* %arrayidx70.46, align 1
  %scevgep20.36.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 36
  %18542 = load i8, i8* %scevgep20.36.46, align 1
  %conv68.36.46 = zext i8 %18542 to i32
  %18543 = load i8, i8* %arrayidx70.46, align 1
  %conv71.36.46 = zext i8 %18543 to i32
  %xor72.36.46 = xor i32 %conv71.36.46, %conv68.36.46
  %conv73.36.46 = trunc i32 %xor72.36.46 to i8
  store i8 %conv73.36.46, i8* %arrayidx70.46, align 1
  %scevgep20.37.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 37
  %18544 = load i8, i8* %scevgep20.37.46, align 1
  %conv68.37.46 = zext i8 %18544 to i32
  %18545 = load i8, i8* %arrayidx70.46, align 1
  %conv71.37.46 = zext i8 %18545 to i32
  %xor72.37.46 = xor i32 %conv71.37.46, %conv68.37.46
  %conv73.37.46 = trunc i32 %xor72.37.46 to i8
  store i8 %conv73.37.46, i8* %arrayidx70.46, align 1
  %scevgep20.38.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 38
  %18546 = load i8, i8* %scevgep20.38.46, align 1
  %conv68.38.46 = zext i8 %18546 to i32
  %18547 = load i8, i8* %arrayidx70.46, align 1
  %conv71.38.46 = zext i8 %18547 to i32
  %xor72.38.46 = xor i32 %conv71.38.46, %conv68.38.46
  %conv73.38.46 = trunc i32 %xor72.38.46 to i8
  store i8 %conv73.38.46, i8* %arrayidx70.46, align 1
  %scevgep20.39.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 39
  %18548 = load i8, i8* %scevgep20.39.46, align 1
  %conv68.39.46 = zext i8 %18548 to i32
  %18549 = load i8, i8* %arrayidx70.46, align 1
  %conv71.39.46 = zext i8 %18549 to i32
  %xor72.39.46 = xor i32 %conv71.39.46, %conv68.39.46
  %conv73.39.46 = trunc i32 %xor72.39.46 to i8
  store i8 %conv73.39.46, i8* %arrayidx70.46, align 1
  %scevgep20.40.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 40
  %18550 = load i8, i8* %scevgep20.40.46, align 1
  %conv68.40.46 = zext i8 %18550 to i32
  %18551 = load i8, i8* %arrayidx70.46, align 1
  %conv71.40.46 = zext i8 %18551 to i32
  %xor72.40.46 = xor i32 %conv71.40.46, %conv68.40.46
  %conv73.40.46 = trunc i32 %xor72.40.46 to i8
  store i8 %conv73.40.46, i8* %arrayidx70.46, align 1
  %scevgep20.41.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 41
  %18552 = load i8, i8* %scevgep20.41.46, align 1
  %conv68.41.46 = zext i8 %18552 to i32
  %18553 = load i8, i8* %arrayidx70.46, align 1
  %conv71.41.46 = zext i8 %18553 to i32
  %xor72.41.46 = xor i32 %conv71.41.46, %conv68.41.46
  %conv73.41.46 = trunc i32 %xor72.41.46 to i8
  store i8 %conv73.41.46, i8* %arrayidx70.46, align 1
  %scevgep20.42.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 42
  %18554 = load i8, i8* %scevgep20.42.46, align 1
  %conv68.42.46 = zext i8 %18554 to i32
  %18555 = load i8, i8* %arrayidx70.46, align 1
  %conv71.42.46 = zext i8 %18555 to i32
  %xor72.42.46 = xor i32 %conv71.42.46, %conv68.42.46
  %conv73.42.46 = trunc i32 %xor72.42.46 to i8
  store i8 %conv73.42.46, i8* %arrayidx70.46, align 1
  %scevgep20.43.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 43
  %18556 = load i8, i8* %scevgep20.43.46, align 1
  %conv68.43.46 = zext i8 %18556 to i32
  %18557 = load i8, i8* %arrayidx70.46, align 1
  %conv71.43.46 = zext i8 %18557 to i32
  %xor72.43.46 = xor i32 %conv71.43.46, %conv68.43.46
  %conv73.43.46 = trunc i32 %xor72.43.46 to i8
  store i8 %conv73.43.46, i8* %arrayidx70.46, align 1
  %scevgep20.44.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 44
  %18558 = load i8, i8* %scevgep20.44.46, align 1
  %conv68.44.46 = zext i8 %18558 to i32
  %18559 = load i8, i8* %arrayidx70.46, align 1
  %conv71.44.46 = zext i8 %18559 to i32
  %xor72.44.46 = xor i32 %conv71.44.46, %conv68.44.46
  %conv73.44.46 = trunc i32 %xor72.44.46 to i8
  store i8 %conv73.44.46, i8* %arrayidx70.46, align 1
  %scevgep20.45.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 45
  %18560 = load i8, i8* %scevgep20.45.46, align 1
  %conv68.45.46 = zext i8 %18560 to i32
  %18561 = load i8, i8* %arrayidx70.46, align 1
  %conv71.45.46 = zext i8 %18561 to i32
  %xor72.45.46 = xor i32 %conv71.45.46, %conv68.45.46
  %conv73.45.46 = trunc i32 %xor72.45.46 to i8
  store i8 %conv73.45.46, i8* %arrayidx70.46, align 1
  %scevgep20.47.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 47
  %18562 = load i8, i8* %scevgep20.47.46, align 1
  %conv68.47.46 = zext i8 %18562 to i32
  %18563 = load i8, i8* %arrayidx70.46, align 1
  %conv71.47.46 = zext i8 %18563 to i32
  %xor72.47.46 = xor i32 %conv71.47.46, %conv68.47.46
  %conv73.47.46 = trunc i32 %xor72.47.46 to i8
  store i8 %conv73.47.46, i8* %arrayidx70.46, align 1
  %scevgep20.48.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 48
  %18564 = load i8, i8* %scevgep20.48.46, align 1
  %conv68.48.46 = zext i8 %18564 to i32
  %18565 = load i8, i8* %arrayidx70.46, align 1
  %conv71.48.46 = zext i8 %18565 to i32
  %xor72.48.46 = xor i32 %conv71.48.46, %conv68.48.46
  %conv73.48.46 = trunc i32 %xor72.48.46 to i8
  store i8 %conv73.48.46, i8* %arrayidx70.46, align 1
  %scevgep20.49.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 49
  %18566 = load i8, i8* %scevgep20.49.46, align 1
  %conv68.49.46 = zext i8 %18566 to i32
  %18567 = load i8, i8* %arrayidx70.46, align 1
  %conv71.49.46 = zext i8 %18567 to i32
  %xor72.49.46 = xor i32 %conv71.49.46, %conv68.49.46
  %conv73.49.46 = trunc i32 %xor72.49.46 to i8
  store i8 %conv73.49.46, i8* %arrayidx70.46, align 1
  %scevgep20.50.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 50
  %18568 = load i8, i8* %scevgep20.50.46, align 1
  %conv68.50.46 = zext i8 %18568 to i32
  %18569 = load i8, i8* %arrayidx70.46, align 1
  %conv71.50.46 = zext i8 %18569 to i32
  %xor72.50.46 = xor i32 %conv71.50.46, %conv68.50.46
  %conv73.50.46 = trunc i32 %xor72.50.46 to i8
  store i8 %conv73.50.46, i8* %arrayidx70.46, align 1
  %scevgep20.51.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 51
  %18570 = load i8, i8* %scevgep20.51.46, align 1
  %conv68.51.46 = zext i8 %18570 to i32
  %18571 = load i8, i8* %arrayidx70.46, align 1
  %conv71.51.46 = zext i8 %18571 to i32
  %xor72.51.46 = xor i32 %conv71.51.46, %conv68.51.46
  %conv73.51.46 = trunc i32 %xor72.51.46 to i8
  store i8 %conv73.51.46, i8* %arrayidx70.46, align 1
  %scevgep20.52.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 52
  %18572 = load i8, i8* %scevgep20.52.46, align 1
  %conv68.52.46 = zext i8 %18572 to i32
  %18573 = load i8, i8* %arrayidx70.46, align 1
  %conv71.52.46 = zext i8 %18573 to i32
  %xor72.52.46 = xor i32 %conv71.52.46, %conv68.52.46
  %conv73.52.46 = trunc i32 %xor72.52.46 to i8
  store i8 %conv73.52.46, i8* %arrayidx70.46, align 1
  %scevgep20.53.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 53
  %18574 = load i8, i8* %scevgep20.53.46, align 1
  %conv68.53.46 = zext i8 %18574 to i32
  %18575 = load i8, i8* %arrayidx70.46, align 1
  %conv71.53.46 = zext i8 %18575 to i32
  %xor72.53.46 = xor i32 %conv71.53.46, %conv68.53.46
  %conv73.53.46 = trunc i32 %xor72.53.46 to i8
  store i8 %conv73.53.46, i8* %arrayidx70.46, align 1
  %scevgep20.54.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 54
  %18576 = load i8, i8* %scevgep20.54.46, align 1
  %conv68.54.46 = zext i8 %18576 to i32
  %18577 = load i8, i8* %arrayidx70.46, align 1
  %conv71.54.46 = zext i8 %18577 to i32
  %xor72.54.46 = xor i32 %conv71.54.46, %conv68.54.46
  %conv73.54.46 = trunc i32 %xor72.54.46 to i8
  store i8 %conv73.54.46, i8* %arrayidx70.46, align 1
  %scevgep20.55.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 55
  %18578 = load i8, i8* %scevgep20.55.46, align 1
  %conv68.55.46 = zext i8 %18578 to i32
  %18579 = load i8, i8* %arrayidx70.46, align 1
  %conv71.55.46 = zext i8 %18579 to i32
  %xor72.55.46 = xor i32 %conv71.55.46, %conv68.55.46
  %conv73.55.46 = trunc i32 %xor72.55.46 to i8
  store i8 %conv73.55.46, i8* %arrayidx70.46, align 1
  %scevgep20.56.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 56
  %18580 = load i8, i8* %scevgep20.56.46, align 1
  %conv68.56.46 = zext i8 %18580 to i32
  %18581 = load i8, i8* %arrayidx70.46, align 1
  %conv71.56.46 = zext i8 %18581 to i32
  %xor72.56.46 = xor i32 %conv71.56.46, %conv68.56.46
  %conv73.56.46 = trunc i32 %xor72.56.46 to i8
  store i8 %conv73.56.46, i8* %arrayidx70.46, align 1
  %scevgep20.57.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 57
  %18582 = load i8, i8* %scevgep20.57.46, align 1
  %conv68.57.46 = zext i8 %18582 to i32
  %18583 = load i8, i8* %arrayidx70.46, align 1
  %conv71.57.46 = zext i8 %18583 to i32
  %xor72.57.46 = xor i32 %conv71.57.46, %conv68.57.46
  %conv73.57.46 = trunc i32 %xor72.57.46 to i8
  store i8 %conv73.57.46, i8* %arrayidx70.46, align 1
  %scevgep20.58.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 58
  %18584 = load i8, i8* %scevgep20.58.46, align 1
  %conv68.58.46 = zext i8 %18584 to i32
  %18585 = load i8, i8* %arrayidx70.46, align 1
  %conv71.58.46 = zext i8 %18585 to i32
  %xor72.58.46 = xor i32 %conv71.58.46, %conv68.58.46
  %conv73.58.46 = trunc i32 %xor72.58.46 to i8
  store i8 %conv73.58.46, i8* %arrayidx70.46, align 1
  %scevgep20.59.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 59
  %18586 = load i8, i8* %scevgep20.59.46, align 1
  %conv68.59.46 = zext i8 %18586 to i32
  %18587 = load i8, i8* %arrayidx70.46, align 1
  %conv71.59.46 = zext i8 %18587 to i32
  %xor72.59.46 = xor i32 %conv71.59.46, %conv68.59.46
  %conv73.59.46 = trunc i32 %xor72.59.46 to i8
  store i8 %conv73.59.46, i8* %arrayidx70.46, align 1
  %scevgep20.60.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 0, i64 60
  %18588 = load i8, i8* %scevgep20.60.46, align 1
  %conv68.60.46 = zext i8 %18588 to i32
  %18589 = load i8, i8* %arrayidx70.46, align 1
  %conv71.60.46 = zext i8 %18589 to i32
  %xor72.60.46 = xor i32 %conv71.60.46, %conv68.60.46
  %conv73.60.46 = trunc i32 %xor72.60.46 to i8
  store i8 %conv73.60.46, i8* %arrayidx70.46, align 1
  %scevgep19.46 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18467, i64 0, i64 1, i64 0
  %18590 = bitcast i8* %scevgep19.46 to [61 x [61 x i8]]*
  %arrayidx51.47 = getelementptr inbounds i8, i8* %a, i64 47
  %18591 = load i8, i8* %arrayidx51.47, align 1
  %arrayidx53.47 = getelementptr inbounds i8, i8* %b, i64 47
  %18592 = load i8, i8* %arrayidx53.47, align 1
  %call54.47 = call zeroext i8 @mult(i8 zeroext %18591, i8 zeroext %18592)
  %arrayidx56.47 = getelementptr inbounds i8, i8* %c, i64 47
  store i8 %call54.47, i8* %arrayidx56.47, align 1
  %arrayidx70.47 = getelementptr inbounds i8, i8* %c, i64 47
  %scevgep20.47514 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 0
  %18593 = load i8, i8* %scevgep20.47514, align 1
  %conv68.47515 = zext i8 %18593 to i32
  %18594 = load i8, i8* %arrayidx70.47, align 1
  %conv71.47516 = zext i8 %18594 to i32
  %xor72.47517 = xor i32 %conv71.47516, %conv68.47515
  %conv73.47518 = trunc i32 %xor72.47517 to i8
  store i8 %conv73.47518, i8* %arrayidx70.47, align 1
  %scevgep20.1.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 1
  %18595 = load i8, i8* %scevgep20.1.47, align 1
  %conv68.1.47 = zext i8 %18595 to i32
  %18596 = load i8, i8* %arrayidx70.47, align 1
  %conv71.1.47 = zext i8 %18596 to i32
  %xor72.1.47 = xor i32 %conv71.1.47, %conv68.1.47
  %conv73.1.47 = trunc i32 %xor72.1.47 to i8
  store i8 %conv73.1.47, i8* %arrayidx70.47, align 1
  %scevgep20.2.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 2
  %18597 = load i8, i8* %scevgep20.2.47, align 1
  %conv68.2.47 = zext i8 %18597 to i32
  %18598 = load i8, i8* %arrayidx70.47, align 1
  %conv71.2.47 = zext i8 %18598 to i32
  %xor72.2.47 = xor i32 %conv71.2.47, %conv68.2.47
  %conv73.2.47 = trunc i32 %xor72.2.47 to i8
  store i8 %conv73.2.47, i8* %arrayidx70.47, align 1
  %scevgep20.3.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 3
  %18599 = load i8, i8* %scevgep20.3.47, align 1
  %conv68.3.47 = zext i8 %18599 to i32
  %18600 = load i8, i8* %arrayidx70.47, align 1
  %conv71.3.47 = zext i8 %18600 to i32
  %xor72.3.47 = xor i32 %conv71.3.47, %conv68.3.47
  %conv73.3.47 = trunc i32 %xor72.3.47 to i8
  store i8 %conv73.3.47, i8* %arrayidx70.47, align 1
  %scevgep20.4.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 4
  %18601 = load i8, i8* %scevgep20.4.47, align 1
  %conv68.4.47 = zext i8 %18601 to i32
  %18602 = load i8, i8* %arrayidx70.47, align 1
  %conv71.4.47 = zext i8 %18602 to i32
  %xor72.4.47 = xor i32 %conv71.4.47, %conv68.4.47
  %conv73.4.47 = trunc i32 %xor72.4.47 to i8
  store i8 %conv73.4.47, i8* %arrayidx70.47, align 1
  %scevgep20.5.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 5
  %18603 = load i8, i8* %scevgep20.5.47, align 1
  %conv68.5.47 = zext i8 %18603 to i32
  %18604 = load i8, i8* %arrayidx70.47, align 1
  %conv71.5.47 = zext i8 %18604 to i32
  %xor72.5.47 = xor i32 %conv71.5.47, %conv68.5.47
  %conv73.5.47 = trunc i32 %xor72.5.47 to i8
  store i8 %conv73.5.47, i8* %arrayidx70.47, align 1
  %scevgep20.6.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 6
  %18605 = load i8, i8* %scevgep20.6.47, align 1
  %conv68.6.47 = zext i8 %18605 to i32
  %18606 = load i8, i8* %arrayidx70.47, align 1
  %conv71.6.47 = zext i8 %18606 to i32
  %xor72.6.47 = xor i32 %conv71.6.47, %conv68.6.47
  %conv73.6.47 = trunc i32 %xor72.6.47 to i8
  store i8 %conv73.6.47, i8* %arrayidx70.47, align 1
  %scevgep20.7.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 7
  %18607 = load i8, i8* %scevgep20.7.47, align 1
  %conv68.7.47 = zext i8 %18607 to i32
  %18608 = load i8, i8* %arrayidx70.47, align 1
  %conv71.7.47 = zext i8 %18608 to i32
  %xor72.7.47 = xor i32 %conv71.7.47, %conv68.7.47
  %conv73.7.47 = trunc i32 %xor72.7.47 to i8
  store i8 %conv73.7.47, i8* %arrayidx70.47, align 1
  %scevgep20.8.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 8
  %18609 = load i8, i8* %scevgep20.8.47, align 1
  %conv68.8.47 = zext i8 %18609 to i32
  %18610 = load i8, i8* %arrayidx70.47, align 1
  %conv71.8.47 = zext i8 %18610 to i32
  %xor72.8.47 = xor i32 %conv71.8.47, %conv68.8.47
  %conv73.8.47 = trunc i32 %xor72.8.47 to i8
  store i8 %conv73.8.47, i8* %arrayidx70.47, align 1
  %scevgep20.9.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 9
  %18611 = load i8, i8* %scevgep20.9.47, align 1
  %conv68.9.47 = zext i8 %18611 to i32
  %18612 = load i8, i8* %arrayidx70.47, align 1
  %conv71.9.47 = zext i8 %18612 to i32
  %xor72.9.47 = xor i32 %conv71.9.47, %conv68.9.47
  %conv73.9.47 = trunc i32 %xor72.9.47 to i8
  store i8 %conv73.9.47, i8* %arrayidx70.47, align 1
  %scevgep20.10.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 10
  %18613 = load i8, i8* %scevgep20.10.47, align 1
  %conv68.10.47 = zext i8 %18613 to i32
  %18614 = load i8, i8* %arrayidx70.47, align 1
  %conv71.10.47 = zext i8 %18614 to i32
  %xor72.10.47 = xor i32 %conv71.10.47, %conv68.10.47
  %conv73.10.47 = trunc i32 %xor72.10.47 to i8
  store i8 %conv73.10.47, i8* %arrayidx70.47, align 1
  %scevgep20.11.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 11
  %18615 = load i8, i8* %scevgep20.11.47, align 1
  %conv68.11.47 = zext i8 %18615 to i32
  %18616 = load i8, i8* %arrayidx70.47, align 1
  %conv71.11.47 = zext i8 %18616 to i32
  %xor72.11.47 = xor i32 %conv71.11.47, %conv68.11.47
  %conv73.11.47 = trunc i32 %xor72.11.47 to i8
  store i8 %conv73.11.47, i8* %arrayidx70.47, align 1
  %scevgep20.12.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 12
  %18617 = load i8, i8* %scevgep20.12.47, align 1
  %conv68.12.47 = zext i8 %18617 to i32
  %18618 = load i8, i8* %arrayidx70.47, align 1
  %conv71.12.47 = zext i8 %18618 to i32
  %xor72.12.47 = xor i32 %conv71.12.47, %conv68.12.47
  %conv73.12.47 = trunc i32 %xor72.12.47 to i8
  store i8 %conv73.12.47, i8* %arrayidx70.47, align 1
  %scevgep20.13.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 13
  %18619 = load i8, i8* %scevgep20.13.47, align 1
  %conv68.13.47 = zext i8 %18619 to i32
  %18620 = load i8, i8* %arrayidx70.47, align 1
  %conv71.13.47 = zext i8 %18620 to i32
  %xor72.13.47 = xor i32 %conv71.13.47, %conv68.13.47
  %conv73.13.47 = trunc i32 %xor72.13.47 to i8
  store i8 %conv73.13.47, i8* %arrayidx70.47, align 1
  %scevgep20.14.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 14
  %18621 = load i8, i8* %scevgep20.14.47, align 1
  %conv68.14.47 = zext i8 %18621 to i32
  %18622 = load i8, i8* %arrayidx70.47, align 1
  %conv71.14.47 = zext i8 %18622 to i32
  %xor72.14.47 = xor i32 %conv71.14.47, %conv68.14.47
  %conv73.14.47 = trunc i32 %xor72.14.47 to i8
  store i8 %conv73.14.47, i8* %arrayidx70.47, align 1
  %scevgep20.15.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 15
  %18623 = load i8, i8* %scevgep20.15.47, align 1
  %conv68.15.47 = zext i8 %18623 to i32
  %18624 = load i8, i8* %arrayidx70.47, align 1
  %conv71.15.47 = zext i8 %18624 to i32
  %xor72.15.47 = xor i32 %conv71.15.47, %conv68.15.47
  %conv73.15.47 = trunc i32 %xor72.15.47 to i8
  store i8 %conv73.15.47, i8* %arrayidx70.47, align 1
  %scevgep20.16.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 16
  %18625 = load i8, i8* %scevgep20.16.47, align 1
  %conv68.16.47 = zext i8 %18625 to i32
  %18626 = load i8, i8* %arrayidx70.47, align 1
  %conv71.16.47 = zext i8 %18626 to i32
  %xor72.16.47 = xor i32 %conv71.16.47, %conv68.16.47
  %conv73.16.47 = trunc i32 %xor72.16.47 to i8
  store i8 %conv73.16.47, i8* %arrayidx70.47, align 1
  %scevgep20.17.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 17
  %18627 = load i8, i8* %scevgep20.17.47, align 1
  %conv68.17.47 = zext i8 %18627 to i32
  %18628 = load i8, i8* %arrayidx70.47, align 1
  %conv71.17.47 = zext i8 %18628 to i32
  %xor72.17.47 = xor i32 %conv71.17.47, %conv68.17.47
  %conv73.17.47 = trunc i32 %xor72.17.47 to i8
  store i8 %conv73.17.47, i8* %arrayidx70.47, align 1
  %scevgep20.18.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 18
  %18629 = load i8, i8* %scevgep20.18.47, align 1
  %conv68.18.47 = zext i8 %18629 to i32
  %18630 = load i8, i8* %arrayidx70.47, align 1
  %conv71.18.47 = zext i8 %18630 to i32
  %xor72.18.47 = xor i32 %conv71.18.47, %conv68.18.47
  %conv73.18.47 = trunc i32 %xor72.18.47 to i8
  store i8 %conv73.18.47, i8* %arrayidx70.47, align 1
  %scevgep20.19.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 19
  %18631 = load i8, i8* %scevgep20.19.47, align 1
  %conv68.19.47 = zext i8 %18631 to i32
  %18632 = load i8, i8* %arrayidx70.47, align 1
  %conv71.19.47 = zext i8 %18632 to i32
  %xor72.19.47 = xor i32 %conv71.19.47, %conv68.19.47
  %conv73.19.47 = trunc i32 %xor72.19.47 to i8
  store i8 %conv73.19.47, i8* %arrayidx70.47, align 1
  %scevgep20.20.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 20
  %18633 = load i8, i8* %scevgep20.20.47, align 1
  %conv68.20.47 = zext i8 %18633 to i32
  %18634 = load i8, i8* %arrayidx70.47, align 1
  %conv71.20.47 = zext i8 %18634 to i32
  %xor72.20.47 = xor i32 %conv71.20.47, %conv68.20.47
  %conv73.20.47 = trunc i32 %xor72.20.47 to i8
  store i8 %conv73.20.47, i8* %arrayidx70.47, align 1
  %scevgep20.21.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 21
  %18635 = load i8, i8* %scevgep20.21.47, align 1
  %conv68.21.47 = zext i8 %18635 to i32
  %18636 = load i8, i8* %arrayidx70.47, align 1
  %conv71.21.47 = zext i8 %18636 to i32
  %xor72.21.47 = xor i32 %conv71.21.47, %conv68.21.47
  %conv73.21.47 = trunc i32 %xor72.21.47 to i8
  store i8 %conv73.21.47, i8* %arrayidx70.47, align 1
  %scevgep20.22.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 22
  %18637 = load i8, i8* %scevgep20.22.47, align 1
  %conv68.22.47 = zext i8 %18637 to i32
  %18638 = load i8, i8* %arrayidx70.47, align 1
  %conv71.22.47 = zext i8 %18638 to i32
  %xor72.22.47 = xor i32 %conv71.22.47, %conv68.22.47
  %conv73.22.47 = trunc i32 %xor72.22.47 to i8
  store i8 %conv73.22.47, i8* %arrayidx70.47, align 1
  %scevgep20.23.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 23
  %18639 = load i8, i8* %scevgep20.23.47, align 1
  %conv68.23.47 = zext i8 %18639 to i32
  %18640 = load i8, i8* %arrayidx70.47, align 1
  %conv71.23.47 = zext i8 %18640 to i32
  %xor72.23.47 = xor i32 %conv71.23.47, %conv68.23.47
  %conv73.23.47 = trunc i32 %xor72.23.47 to i8
  store i8 %conv73.23.47, i8* %arrayidx70.47, align 1
  %scevgep20.24.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 24
  %18641 = load i8, i8* %scevgep20.24.47, align 1
  %conv68.24.47 = zext i8 %18641 to i32
  %18642 = load i8, i8* %arrayidx70.47, align 1
  %conv71.24.47 = zext i8 %18642 to i32
  %xor72.24.47 = xor i32 %conv71.24.47, %conv68.24.47
  %conv73.24.47 = trunc i32 %xor72.24.47 to i8
  store i8 %conv73.24.47, i8* %arrayidx70.47, align 1
  %scevgep20.25.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 25
  %18643 = load i8, i8* %scevgep20.25.47, align 1
  %conv68.25.47 = zext i8 %18643 to i32
  %18644 = load i8, i8* %arrayidx70.47, align 1
  %conv71.25.47 = zext i8 %18644 to i32
  %xor72.25.47 = xor i32 %conv71.25.47, %conv68.25.47
  %conv73.25.47 = trunc i32 %xor72.25.47 to i8
  store i8 %conv73.25.47, i8* %arrayidx70.47, align 1
  %scevgep20.26.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 26
  %18645 = load i8, i8* %scevgep20.26.47, align 1
  %conv68.26.47 = zext i8 %18645 to i32
  %18646 = load i8, i8* %arrayidx70.47, align 1
  %conv71.26.47 = zext i8 %18646 to i32
  %xor72.26.47 = xor i32 %conv71.26.47, %conv68.26.47
  %conv73.26.47 = trunc i32 %xor72.26.47 to i8
  store i8 %conv73.26.47, i8* %arrayidx70.47, align 1
  %scevgep20.27.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 27
  %18647 = load i8, i8* %scevgep20.27.47, align 1
  %conv68.27.47 = zext i8 %18647 to i32
  %18648 = load i8, i8* %arrayidx70.47, align 1
  %conv71.27.47 = zext i8 %18648 to i32
  %xor72.27.47 = xor i32 %conv71.27.47, %conv68.27.47
  %conv73.27.47 = trunc i32 %xor72.27.47 to i8
  store i8 %conv73.27.47, i8* %arrayidx70.47, align 1
  %scevgep20.28.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 28
  %18649 = load i8, i8* %scevgep20.28.47, align 1
  %conv68.28.47 = zext i8 %18649 to i32
  %18650 = load i8, i8* %arrayidx70.47, align 1
  %conv71.28.47 = zext i8 %18650 to i32
  %xor72.28.47 = xor i32 %conv71.28.47, %conv68.28.47
  %conv73.28.47 = trunc i32 %xor72.28.47 to i8
  store i8 %conv73.28.47, i8* %arrayidx70.47, align 1
  %scevgep20.29.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 29
  %18651 = load i8, i8* %scevgep20.29.47, align 1
  %conv68.29.47 = zext i8 %18651 to i32
  %18652 = load i8, i8* %arrayidx70.47, align 1
  %conv71.29.47 = zext i8 %18652 to i32
  %xor72.29.47 = xor i32 %conv71.29.47, %conv68.29.47
  %conv73.29.47 = trunc i32 %xor72.29.47 to i8
  store i8 %conv73.29.47, i8* %arrayidx70.47, align 1
  %scevgep20.30.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 30
  %18653 = load i8, i8* %scevgep20.30.47, align 1
  %conv68.30.47 = zext i8 %18653 to i32
  %18654 = load i8, i8* %arrayidx70.47, align 1
  %conv71.30.47 = zext i8 %18654 to i32
  %xor72.30.47 = xor i32 %conv71.30.47, %conv68.30.47
  %conv73.30.47 = trunc i32 %xor72.30.47 to i8
  store i8 %conv73.30.47, i8* %arrayidx70.47, align 1
  %scevgep20.31.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 31
  %18655 = load i8, i8* %scevgep20.31.47, align 1
  %conv68.31.47 = zext i8 %18655 to i32
  %18656 = load i8, i8* %arrayidx70.47, align 1
  %conv71.31.47 = zext i8 %18656 to i32
  %xor72.31.47 = xor i32 %conv71.31.47, %conv68.31.47
  %conv73.31.47 = trunc i32 %xor72.31.47 to i8
  store i8 %conv73.31.47, i8* %arrayidx70.47, align 1
  %scevgep20.32.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 32
  %18657 = load i8, i8* %scevgep20.32.47, align 1
  %conv68.32.47 = zext i8 %18657 to i32
  %18658 = load i8, i8* %arrayidx70.47, align 1
  %conv71.32.47 = zext i8 %18658 to i32
  %xor72.32.47 = xor i32 %conv71.32.47, %conv68.32.47
  %conv73.32.47 = trunc i32 %xor72.32.47 to i8
  store i8 %conv73.32.47, i8* %arrayidx70.47, align 1
  %scevgep20.33.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 33
  %18659 = load i8, i8* %scevgep20.33.47, align 1
  %conv68.33.47 = zext i8 %18659 to i32
  %18660 = load i8, i8* %arrayidx70.47, align 1
  %conv71.33.47 = zext i8 %18660 to i32
  %xor72.33.47 = xor i32 %conv71.33.47, %conv68.33.47
  %conv73.33.47 = trunc i32 %xor72.33.47 to i8
  store i8 %conv73.33.47, i8* %arrayidx70.47, align 1
  %scevgep20.34.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 34
  %18661 = load i8, i8* %scevgep20.34.47, align 1
  %conv68.34.47 = zext i8 %18661 to i32
  %18662 = load i8, i8* %arrayidx70.47, align 1
  %conv71.34.47 = zext i8 %18662 to i32
  %xor72.34.47 = xor i32 %conv71.34.47, %conv68.34.47
  %conv73.34.47 = trunc i32 %xor72.34.47 to i8
  store i8 %conv73.34.47, i8* %arrayidx70.47, align 1
  %scevgep20.35.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 35
  %18663 = load i8, i8* %scevgep20.35.47, align 1
  %conv68.35.47 = zext i8 %18663 to i32
  %18664 = load i8, i8* %arrayidx70.47, align 1
  %conv71.35.47 = zext i8 %18664 to i32
  %xor72.35.47 = xor i32 %conv71.35.47, %conv68.35.47
  %conv73.35.47 = trunc i32 %xor72.35.47 to i8
  store i8 %conv73.35.47, i8* %arrayidx70.47, align 1
  %scevgep20.36.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 36
  %18665 = load i8, i8* %scevgep20.36.47, align 1
  %conv68.36.47 = zext i8 %18665 to i32
  %18666 = load i8, i8* %arrayidx70.47, align 1
  %conv71.36.47 = zext i8 %18666 to i32
  %xor72.36.47 = xor i32 %conv71.36.47, %conv68.36.47
  %conv73.36.47 = trunc i32 %xor72.36.47 to i8
  store i8 %conv73.36.47, i8* %arrayidx70.47, align 1
  %scevgep20.37.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 37
  %18667 = load i8, i8* %scevgep20.37.47, align 1
  %conv68.37.47 = zext i8 %18667 to i32
  %18668 = load i8, i8* %arrayidx70.47, align 1
  %conv71.37.47 = zext i8 %18668 to i32
  %xor72.37.47 = xor i32 %conv71.37.47, %conv68.37.47
  %conv73.37.47 = trunc i32 %xor72.37.47 to i8
  store i8 %conv73.37.47, i8* %arrayidx70.47, align 1
  %scevgep20.38.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 38
  %18669 = load i8, i8* %scevgep20.38.47, align 1
  %conv68.38.47 = zext i8 %18669 to i32
  %18670 = load i8, i8* %arrayidx70.47, align 1
  %conv71.38.47 = zext i8 %18670 to i32
  %xor72.38.47 = xor i32 %conv71.38.47, %conv68.38.47
  %conv73.38.47 = trunc i32 %xor72.38.47 to i8
  store i8 %conv73.38.47, i8* %arrayidx70.47, align 1
  %scevgep20.39.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 39
  %18671 = load i8, i8* %scevgep20.39.47, align 1
  %conv68.39.47 = zext i8 %18671 to i32
  %18672 = load i8, i8* %arrayidx70.47, align 1
  %conv71.39.47 = zext i8 %18672 to i32
  %xor72.39.47 = xor i32 %conv71.39.47, %conv68.39.47
  %conv73.39.47 = trunc i32 %xor72.39.47 to i8
  store i8 %conv73.39.47, i8* %arrayidx70.47, align 1
  %scevgep20.40.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 40
  %18673 = load i8, i8* %scevgep20.40.47, align 1
  %conv68.40.47 = zext i8 %18673 to i32
  %18674 = load i8, i8* %arrayidx70.47, align 1
  %conv71.40.47 = zext i8 %18674 to i32
  %xor72.40.47 = xor i32 %conv71.40.47, %conv68.40.47
  %conv73.40.47 = trunc i32 %xor72.40.47 to i8
  store i8 %conv73.40.47, i8* %arrayidx70.47, align 1
  %scevgep20.41.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 41
  %18675 = load i8, i8* %scevgep20.41.47, align 1
  %conv68.41.47 = zext i8 %18675 to i32
  %18676 = load i8, i8* %arrayidx70.47, align 1
  %conv71.41.47 = zext i8 %18676 to i32
  %xor72.41.47 = xor i32 %conv71.41.47, %conv68.41.47
  %conv73.41.47 = trunc i32 %xor72.41.47 to i8
  store i8 %conv73.41.47, i8* %arrayidx70.47, align 1
  %scevgep20.42.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 42
  %18677 = load i8, i8* %scevgep20.42.47, align 1
  %conv68.42.47 = zext i8 %18677 to i32
  %18678 = load i8, i8* %arrayidx70.47, align 1
  %conv71.42.47 = zext i8 %18678 to i32
  %xor72.42.47 = xor i32 %conv71.42.47, %conv68.42.47
  %conv73.42.47 = trunc i32 %xor72.42.47 to i8
  store i8 %conv73.42.47, i8* %arrayidx70.47, align 1
  %scevgep20.43.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 43
  %18679 = load i8, i8* %scevgep20.43.47, align 1
  %conv68.43.47 = zext i8 %18679 to i32
  %18680 = load i8, i8* %arrayidx70.47, align 1
  %conv71.43.47 = zext i8 %18680 to i32
  %xor72.43.47 = xor i32 %conv71.43.47, %conv68.43.47
  %conv73.43.47 = trunc i32 %xor72.43.47 to i8
  store i8 %conv73.43.47, i8* %arrayidx70.47, align 1
  %scevgep20.44.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 44
  %18681 = load i8, i8* %scevgep20.44.47, align 1
  %conv68.44.47 = zext i8 %18681 to i32
  %18682 = load i8, i8* %arrayidx70.47, align 1
  %conv71.44.47 = zext i8 %18682 to i32
  %xor72.44.47 = xor i32 %conv71.44.47, %conv68.44.47
  %conv73.44.47 = trunc i32 %xor72.44.47 to i8
  store i8 %conv73.44.47, i8* %arrayidx70.47, align 1
  %scevgep20.45.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 45
  %18683 = load i8, i8* %scevgep20.45.47, align 1
  %conv68.45.47 = zext i8 %18683 to i32
  %18684 = load i8, i8* %arrayidx70.47, align 1
  %conv71.45.47 = zext i8 %18684 to i32
  %xor72.45.47 = xor i32 %conv71.45.47, %conv68.45.47
  %conv73.45.47 = trunc i32 %xor72.45.47 to i8
  store i8 %conv73.45.47, i8* %arrayidx70.47, align 1
  %scevgep20.46.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 46
  %18685 = load i8, i8* %scevgep20.46.47, align 1
  %conv68.46.47 = zext i8 %18685 to i32
  %18686 = load i8, i8* %arrayidx70.47, align 1
  %conv71.46.47 = zext i8 %18686 to i32
  %xor72.46.47 = xor i32 %conv71.46.47, %conv68.46.47
  %conv73.46.47 = trunc i32 %xor72.46.47 to i8
  store i8 %conv73.46.47, i8* %arrayidx70.47, align 1
  %scevgep20.48.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 48
  %18687 = load i8, i8* %scevgep20.48.47, align 1
  %conv68.48.47 = zext i8 %18687 to i32
  %18688 = load i8, i8* %arrayidx70.47, align 1
  %conv71.48.47 = zext i8 %18688 to i32
  %xor72.48.47 = xor i32 %conv71.48.47, %conv68.48.47
  %conv73.48.47 = trunc i32 %xor72.48.47 to i8
  store i8 %conv73.48.47, i8* %arrayidx70.47, align 1
  %scevgep20.49.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 49
  %18689 = load i8, i8* %scevgep20.49.47, align 1
  %conv68.49.47 = zext i8 %18689 to i32
  %18690 = load i8, i8* %arrayidx70.47, align 1
  %conv71.49.47 = zext i8 %18690 to i32
  %xor72.49.47 = xor i32 %conv71.49.47, %conv68.49.47
  %conv73.49.47 = trunc i32 %xor72.49.47 to i8
  store i8 %conv73.49.47, i8* %arrayidx70.47, align 1
  %scevgep20.50.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 50
  %18691 = load i8, i8* %scevgep20.50.47, align 1
  %conv68.50.47 = zext i8 %18691 to i32
  %18692 = load i8, i8* %arrayidx70.47, align 1
  %conv71.50.47 = zext i8 %18692 to i32
  %xor72.50.47 = xor i32 %conv71.50.47, %conv68.50.47
  %conv73.50.47 = trunc i32 %xor72.50.47 to i8
  store i8 %conv73.50.47, i8* %arrayidx70.47, align 1
  %scevgep20.51.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 51
  %18693 = load i8, i8* %scevgep20.51.47, align 1
  %conv68.51.47 = zext i8 %18693 to i32
  %18694 = load i8, i8* %arrayidx70.47, align 1
  %conv71.51.47 = zext i8 %18694 to i32
  %xor72.51.47 = xor i32 %conv71.51.47, %conv68.51.47
  %conv73.51.47 = trunc i32 %xor72.51.47 to i8
  store i8 %conv73.51.47, i8* %arrayidx70.47, align 1
  %scevgep20.52.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 52
  %18695 = load i8, i8* %scevgep20.52.47, align 1
  %conv68.52.47 = zext i8 %18695 to i32
  %18696 = load i8, i8* %arrayidx70.47, align 1
  %conv71.52.47 = zext i8 %18696 to i32
  %xor72.52.47 = xor i32 %conv71.52.47, %conv68.52.47
  %conv73.52.47 = trunc i32 %xor72.52.47 to i8
  store i8 %conv73.52.47, i8* %arrayidx70.47, align 1
  %scevgep20.53.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 53
  %18697 = load i8, i8* %scevgep20.53.47, align 1
  %conv68.53.47 = zext i8 %18697 to i32
  %18698 = load i8, i8* %arrayidx70.47, align 1
  %conv71.53.47 = zext i8 %18698 to i32
  %xor72.53.47 = xor i32 %conv71.53.47, %conv68.53.47
  %conv73.53.47 = trunc i32 %xor72.53.47 to i8
  store i8 %conv73.53.47, i8* %arrayidx70.47, align 1
  %scevgep20.54.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 54
  %18699 = load i8, i8* %scevgep20.54.47, align 1
  %conv68.54.47 = zext i8 %18699 to i32
  %18700 = load i8, i8* %arrayidx70.47, align 1
  %conv71.54.47 = zext i8 %18700 to i32
  %xor72.54.47 = xor i32 %conv71.54.47, %conv68.54.47
  %conv73.54.47 = trunc i32 %xor72.54.47 to i8
  store i8 %conv73.54.47, i8* %arrayidx70.47, align 1
  %scevgep20.55.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 55
  %18701 = load i8, i8* %scevgep20.55.47, align 1
  %conv68.55.47 = zext i8 %18701 to i32
  %18702 = load i8, i8* %arrayidx70.47, align 1
  %conv71.55.47 = zext i8 %18702 to i32
  %xor72.55.47 = xor i32 %conv71.55.47, %conv68.55.47
  %conv73.55.47 = trunc i32 %xor72.55.47 to i8
  store i8 %conv73.55.47, i8* %arrayidx70.47, align 1
  %scevgep20.56.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 56
  %18703 = load i8, i8* %scevgep20.56.47, align 1
  %conv68.56.47 = zext i8 %18703 to i32
  %18704 = load i8, i8* %arrayidx70.47, align 1
  %conv71.56.47 = zext i8 %18704 to i32
  %xor72.56.47 = xor i32 %conv71.56.47, %conv68.56.47
  %conv73.56.47 = trunc i32 %xor72.56.47 to i8
  store i8 %conv73.56.47, i8* %arrayidx70.47, align 1
  %scevgep20.57.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 57
  %18705 = load i8, i8* %scevgep20.57.47, align 1
  %conv68.57.47 = zext i8 %18705 to i32
  %18706 = load i8, i8* %arrayidx70.47, align 1
  %conv71.57.47 = zext i8 %18706 to i32
  %xor72.57.47 = xor i32 %conv71.57.47, %conv68.57.47
  %conv73.57.47 = trunc i32 %xor72.57.47 to i8
  store i8 %conv73.57.47, i8* %arrayidx70.47, align 1
  %scevgep20.58.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 58
  %18707 = load i8, i8* %scevgep20.58.47, align 1
  %conv68.58.47 = zext i8 %18707 to i32
  %18708 = load i8, i8* %arrayidx70.47, align 1
  %conv71.58.47 = zext i8 %18708 to i32
  %xor72.58.47 = xor i32 %conv71.58.47, %conv68.58.47
  %conv73.58.47 = trunc i32 %xor72.58.47 to i8
  store i8 %conv73.58.47, i8* %arrayidx70.47, align 1
  %scevgep20.59.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 59
  %18709 = load i8, i8* %scevgep20.59.47, align 1
  %conv68.59.47 = zext i8 %18709 to i32
  %18710 = load i8, i8* %arrayidx70.47, align 1
  %conv71.59.47 = zext i8 %18710 to i32
  %xor72.59.47 = xor i32 %conv71.59.47, %conv68.59.47
  %conv73.59.47 = trunc i32 %xor72.59.47 to i8
  store i8 %conv73.59.47, i8* %arrayidx70.47, align 1
  %scevgep20.60.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 0, i64 60
  %18711 = load i8, i8* %scevgep20.60.47, align 1
  %conv68.60.47 = zext i8 %18711 to i32
  %18712 = load i8, i8* %arrayidx70.47, align 1
  %conv71.60.47 = zext i8 %18712 to i32
  %xor72.60.47 = xor i32 %conv71.60.47, %conv68.60.47
  %conv73.60.47 = trunc i32 %xor72.60.47 to i8
  store i8 %conv73.60.47, i8* %arrayidx70.47, align 1
  %scevgep19.47 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18590, i64 0, i64 1, i64 0
  %18713 = bitcast i8* %scevgep19.47 to [61 x [61 x i8]]*
  %arrayidx51.48 = getelementptr inbounds i8, i8* %a, i64 48
  %18714 = load i8, i8* %arrayidx51.48, align 1
  %arrayidx53.48 = getelementptr inbounds i8, i8* %b, i64 48
  %18715 = load i8, i8* %arrayidx53.48, align 1
  %call54.48 = call zeroext i8 @mult(i8 zeroext %18714, i8 zeroext %18715)
  %arrayidx56.48 = getelementptr inbounds i8, i8* %c, i64 48
  store i8 %call54.48, i8* %arrayidx56.48, align 1
  %arrayidx70.48 = getelementptr inbounds i8, i8* %c, i64 48
  %scevgep20.48524 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 0
  %18716 = load i8, i8* %scevgep20.48524, align 1
  %conv68.48525 = zext i8 %18716 to i32
  %18717 = load i8, i8* %arrayidx70.48, align 1
  %conv71.48526 = zext i8 %18717 to i32
  %xor72.48527 = xor i32 %conv71.48526, %conv68.48525
  %conv73.48528 = trunc i32 %xor72.48527 to i8
  store i8 %conv73.48528, i8* %arrayidx70.48, align 1
  %scevgep20.1.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 1
  %18718 = load i8, i8* %scevgep20.1.48, align 1
  %conv68.1.48 = zext i8 %18718 to i32
  %18719 = load i8, i8* %arrayidx70.48, align 1
  %conv71.1.48 = zext i8 %18719 to i32
  %xor72.1.48 = xor i32 %conv71.1.48, %conv68.1.48
  %conv73.1.48 = trunc i32 %xor72.1.48 to i8
  store i8 %conv73.1.48, i8* %arrayidx70.48, align 1
  %scevgep20.2.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 2
  %18720 = load i8, i8* %scevgep20.2.48, align 1
  %conv68.2.48 = zext i8 %18720 to i32
  %18721 = load i8, i8* %arrayidx70.48, align 1
  %conv71.2.48 = zext i8 %18721 to i32
  %xor72.2.48 = xor i32 %conv71.2.48, %conv68.2.48
  %conv73.2.48 = trunc i32 %xor72.2.48 to i8
  store i8 %conv73.2.48, i8* %arrayidx70.48, align 1
  %scevgep20.3.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 3
  %18722 = load i8, i8* %scevgep20.3.48, align 1
  %conv68.3.48 = zext i8 %18722 to i32
  %18723 = load i8, i8* %arrayidx70.48, align 1
  %conv71.3.48 = zext i8 %18723 to i32
  %xor72.3.48 = xor i32 %conv71.3.48, %conv68.3.48
  %conv73.3.48 = trunc i32 %xor72.3.48 to i8
  store i8 %conv73.3.48, i8* %arrayidx70.48, align 1
  %scevgep20.4.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 4
  %18724 = load i8, i8* %scevgep20.4.48, align 1
  %conv68.4.48 = zext i8 %18724 to i32
  %18725 = load i8, i8* %arrayidx70.48, align 1
  %conv71.4.48 = zext i8 %18725 to i32
  %xor72.4.48 = xor i32 %conv71.4.48, %conv68.4.48
  %conv73.4.48 = trunc i32 %xor72.4.48 to i8
  store i8 %conv73.4.48, i8* %arrayidx70.48, align 1
  %scevgep20.5.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 5
  %18726 = load i8, i8* %scevgep20.5.48, align 1
  %conv68.5.48 = zext i8 %18726 to i32
  %18727 = load i8, i8* %arrayidx70.48, align 1
  %conv71.5.48 = zext i8 %18727 to i32
  %xor72.5.48 = xor i32 %conv71.5.48, %conv68.5.48
  %conv73.5.48 = trunc i32 %xor72.5.48 to i8
  store i8 %conv73.5.48, i8* %arrayidx70.48, align 1
  %scevgep20.6.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 6
  %18728 = load i8, i8* %scevgep20.6.48, align 1
  %conv68.6.48 = zext i8 %18728 to i32
  %18729 = load i8, i8* %arrayidx70.48, align 1
  %conv71.6.48 = zext i8 %18729 to i32
  %xor72.6.48 = xor i32 %conv71.6.48, %conv68.6.48
  %conv73.6.48 = trunc i32 %xor72.6.48 to i8
  store i8 %conv73.6.48, i8* %arrayidx70.48, align 1
  %scevgep20.7.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 7
  %18730 = load i8, i8* %scevgep20.7.48, align 1
  %conv68.7.48 = zext i8 %18730 to i32
  %18731 = load i8, i8* %arrayidx70.48, align 1
  %conv71.7.48 = zext i8 %18731 to i32
  %xor72.7.48 = xor i32 %conv71.7.48, %conv68.7.48
  %conv73.7.48 = trunc i32 %xor72.7.48 to i8
  store i8 %conv73.7.48, i8* %arrayidx70.48, align 1
  %scevgep20.8.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 8
  %18732 = load i8, i8* %scevgep20.8.48, align 1
  %conv68.8.48 = zext i8 %18732 to i32
  %18733 = load i8, i8* %arrayidx70.48, align 1
  %conv71.8.48 = zext i8 %18733 to i32
  %xor72.8.48 = xor i32 %conv71.8.48, %conv68.8.48
  %conv73.8.48 = trunc i32 %xor72.8.48 to i8
  store i8 %conv73.8.48, i8* %arrayidx70.48, align 1
  %scevgep20.9.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 9
  %18734 = load i8, i8* %scevgep20.9.48, align 1
  %conv68.9.48 = zext i8 %18734 to i32
  %18735 = load i8, i8* %arrayidx70.48, align 1
  %conv71.9.48 = zext i8 %18735 to i32
  %xor72.9.48 = xor i32 %conv71.9.48, %conv68.9.48
  %conv73.9.48 = trunc i32 %xor72.9.48 to i8
  store i8 %conv73.9.48, i8* %arrayidx70.48, align 1
  %scevgep20.10.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 10
  %18736 = load i8, i8* %scevgep20.10.48, align 1
  %conv68.10.48 = zext i8 %18736 to i32
  %18737 = load i8, i8* %arrayidx70.48, align 1
  %conv71.10.48 = zext i8 %18737 to i32
  %xor72.10.48 = xor i32 %conv71.10.48, %conv68.10.48
  %conv73.10.48 = trunc i32 %xor72.10.48 to i8
  store i8 %conv73.10.48, i8* %arrayidx70.48, align 1
  %scevgep20.11.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 11
  %18738 = load i8, i8* %scevgep20.11.48, align 1
  %conv68.11.48 = zext i8 %18738 to i32
  %18739 = load i8, i8* %arrayidx70.48, align 1
  %conv71.11.48 = zext i8 %18739 to i32
  %xor72.11.48 = xor i32 %conv71.11.48, %conv68.11.48
  %conv73.11.48 = trunc i32 %xor72.11.48 to i8
  store i8 %conv73.11.48, i8* %arrayidx70.48, align 1
  %scevgep20.12.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 12
  %18740 = load i8, i8* %scevgep20.12.48, align 1
  %conv68.12.48 = zext i8 %18740 to i32
  %18741 = load i8, i8* %arrayidx70.48, align 1
  %conv71.12.48 = zext i8 %18741 to i32
  %xor72.12.48 = xor i32 %conv71.12.48, %conv68.12.48
  %conv73.12.48 = trunc i32 %xor72.12.48 to i8
  store i8 %conv73.12.48, i8* %arrayidx70.48, align 1
  %scevgep20.13.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 13
  %18742 = load i8, i8* %scevgep20.13.48, align 1
  %conv68.13.48 = zext i8 %18742 to i32
  %18743 = load i8, i8* %arrayidx70.48, align 1
  %conv71.13.48 = zext i8 %18743 to i32
  %xor72.13.48 = xor i32 %conv71.13.48, %conv68.13.48
  %conv73.13.48 = trunc i32 %xor72.13.48 to i8
  store i8 %conv73.13.48, i8* %arrayidx70.48, align 1
  %scevgep20.14.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 14
  %18744 = load i8, i8* %scevgep20.14.48, align 1
  %conv68.14.48 = zext i8 %18744 to i32
  %18745 = load i8, i8* %arrayidx70.48, align 1
  %conv71.14.48 = zext i8 %18745 to i32
  %xor72.14.48 = xor i32 %conv71.14.48, %conv68.14.48
  %conv73.14.48 = trunc i32 %xor72.14.48 to i8
  store i8 %conv73.14.48, i8* %arrayidx70.48, align 1
  %scevgep20.15.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 15
  %18746 = load i8, i8* %scevgep20.15.48, align 1
  %conv68.15.48 = zext i8 %18746 to i32
  %18747 = load i8, i8* %arrayidx70.48, align 1
  %conv71.15.48 = zext i8 %18747 to i32
  %xor72.15.48 = xor i32 %conv71.15.48, %conv68.15.48
  %conv73.15.48 = trunc i32 %xor72.15.48 to i8
  store i8 %conv73.15.48, i8* %arrayidx70.48, align 1
  %scevgep20.16.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 16
  %18748 = load i8, i8* %scevgep20.16.48, align 1
  %conv68.16.48 = zext i8 %18748 to i32
  %18749 = load i8, i8* %arrayidx70.48, align 1
  %conv71.16.48 = zext i8 %18749 to i32
  %xor72.16.48 = xor i32 %conv71.16.48, %conv68.16.48
  %conv73.16.48 = trunc i32 %xor72.16.48 to i8
  store i8 %conv73.16.48, i8* %arrayidx70.48, align 1
  %scevgep20.17.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 17
  %18750 = load i8, i8* %scevgep20.17.48, align 1
  %conv68.17.48 = zext i8 %18750 to i32
  %18751 = load i8, i8* %arrayidx70.48, align 1
  %conv71.17.48 = zext i8 %18751 to i32
  %xor72.17.48 = xor i32 %conv71.17.48, %conv68.17.48
  %conv73.17.48 = trunc i32 %xor72.17.48 to i8
  store i8 %conv73.17.48, i8* %arrayidx70.48, align 1
  %scevgep20.18.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 18
  %18752 = load i8, i8* %scevgep20.18.48, align 1
  %conv68.18.48 = zext i8 %18752 to i32
  %18753 = load i8, i8* %arrayidx70.48, align 1
  %conv71.18.48 = zext i8 %18753 to i32
  %xor72.18.48 = xor i32 %conv71.18.48, %conv68.18.48
  %conv73.18.48 = trunc i32 %xor72.18.48 to i8
  store i8 %conv73.18.48, i8* %arrayidx70.48, align 1
  %scevgep20.19.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 19
  %18754 = load i8, i8* %scevgep20.19.48, align 1
  %conv68.19.48 = zext i8 %18754 to i32
  %18755 = load i8, i8* %arrayidx70.48, align 1
  %conv71.19.48 = zext i8 %18755 to i32
  %xor72.19.48 = xor i32 %conv71.19.48, %conv68.19.48
  %conv73.19.48 = trunc i32 %xor72.19.48 to i8
  store i8 %conv73.19.48, i8* %arrayidx70.48, align 1
  %scevgep20.20.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 20
  %18756 = load i8, i8* %scevgep20.20.48, align 1
  %conv68.20.48 = zext i8 %18756 to i32
  %18757 = load i8, i8* %arrayidx70.48, align 1
  %conv71.20.48 = zext i8 %18757 to i32
  %xor72.20.48 = xor i32 %conv71.20.48, %conv68.20.48
  %conv73.20.48 = trunc i32 %xor72.20.48 to i8
  store i8 %conv73.20.48, i8* %arrayidx70.48, align 1
  %scevgep20.21.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 21
  %18758 = load i8, i8* %scevgep20.21.48, align 1
  %conv68.21.48 = zext i8 %18758 to i32
  %18759 = load i8, i8* %arrayidx70.48, align 1
  %conv71.21.48 = zext i8 %18759 to i32
  %xor72.21.48 = xor i32 %conv71.21.48, %conv68.21.48
  %conv73.21.48 = trunc i32 %xor72.21.48 to i8
  store i8 %conv73.21.48, i8* %arrayidx70.48, align 1
  %scevgep20.22.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 22
  %18760 = load i8, i8* %scevgep20.22.48, align 1
  %conv68.22.48 = zext i8 %18760 to i32
  %18761 = load i8, i8* %arrayidx70.48, align 1
  %conv71.22.48 = zext i8 %18761 to i32
  %xor72.22.48 = xor i32 %conv71.22.48, %conv68.22.48
  %conv73.22.48 = trunc i32 %xor72.22.48 to i8
  store i8 %conv73.22.48, i8* %arrayidx70.48, align 1
  %scevgep20.23.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 23
  %18762 = load i8, i8* %scevgep20.23.48, align 1
  %conv68.23.48 = zext i8 %18762 to i32
  %18763 = load i8, i8* %arrayidx70.48, align 1
  %conv71.23.48 = zext i8 %18763 to i32
  %xor72.23.48 = xor i32 %conv71.23.48, %conv68.23.48
  %conv73.23.48 = trunc i32 %xor72.23.48 to i8
  store i8 %conv73.23.48, i8* %arrayidx70.48, align 1
  %scevgep20.24.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 24
  %18764 = load i8, i8* %scevgep20.24.48, align 1
  %conv68.24.48 = zext i8 %18764 to i32
  %18765 = load i8, i8* %arrayidx70.48, align 1
  %conv71.24.48 = zext i8 %18765 to i32
  %xor72.24.48 = xor i32 %conv71.24.48, %conv68.24.48
  %conv73.24.48 = trunc i32 %xor72.24.48 to i8
  store i8 %conv73.24.48, i8* %arrayidx70.48, align 1
  %scevgep20.25.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 25
  %18766 = load i8, i8* %scevgep20.25.48, align 1
  %conv68.25.48 = zext i8 %18766 to i32
  %18767 = load i8, i8* %arrayidx70.48, align 1
  %conv71.25.48 = zext i8 %18767 to i32
  %xor72.25.48 = xor i32 %conv71.25.48, %conv68.25.48
  %conv73.25.48 = trunc i32 %xor72.25.48 to i8
  store i8 %conv73.25.48, i8* %arrayidx70.48, align 1
  %scevgep20.26.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 26
  %18768 = load i8, i8* %scevgep20.26.48, align 1
  %conv68.26.48 = zext i8 %18768 to i32
  %18769 = load i8, i8* %arrayidx70.48, align 1
  %conv71.26.48 = zext i8 %18769 to i32
  %xor72.26.48 = xor i32 %conv71.26.48, %conv68.26.48
  %conv73.26.48 = trunc i32 %xor72.26.48 to i8
  store i8 %conv73.26.48, i8* %arrayidx70.48, align 1
  %scevgep20.27.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 27
  %18770 = load i8, i8* %scevgep20.27.48, align 1
  %conv68.27.48 = zext i8 %18770 to i32
  %18771 = load i8, i8* %arrayidx70.48, align 1
  %conv71.27.48 = zext i8 %18771 to i32
  %xor72.27.48 = xor i32 %conv71.27.48, %conv68.27.48
  %conv73.27.48 = trunc i32 %xor72.27.48 to i8
  store i8 %conv73.27.48, i8* %arrayidx70.48, align 1
  %scevgep20.28.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 28
  %18772 = load i8, i8* %scevgep20.28.48, align 1
  %conv68.28.48 = zext i8 %18772 to i32
  %18773 = load i8, i8* %arrayidx70.48, align 1
  %conv71.28.48 = zext i8 %18773 to i32
  %xor72.28.48 = xor i32 %conv71.28.48, %conv68.28.48
  %conv73.28.48 = trunc i32 %xor72.28.48 to i8
  store i8 %conv73.28.48, i8* %arrayidx70.48, align 1
  %scevgep20.29.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 29
  %18774 = load i8, i8* %scevgep20.29.48, align 1
  %conv68.29.48 = zext i8 %18774 to i32
  %18775 = load i8, i8* %arrayidx70.48, align 1
  %conv71.29.48 = zext i8 %18775 to i32
  %xor72.29.48 = xor i32 %conv71.29.48, %conv68.29.48
  %conv73.29.48 = trunc i32 %xor72.29.48 to i8
  store i8 %conv73.29.48, i8* %arrayidx70.48, align 1
  %scevgep20.30.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 30
  %18776 = load i8, i8* %scevgep20.30.48, align 1
  %conv68.30.48 = zext i8 %18776 to i32
  %18777 = load i8, i8* %arrayidx70.48, align 1
  %conv71.30.48 = zext i8 %18777 to i32
  %xor72.30.48 = xor i32 %conv71.30.48, %conv68.30.48
  %conv73.30.48 = trunc i32 %xor72.30.48 to i8
  store i8 %conv73.30.48, i8* %arrayidx70.48, align 1
  %scevgep20.31.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 31
  %18778 = load i8, i8* %scevgep20.31.48, align 1
  %conv68.31.48 = zext i8 %18778 to i32
  %18779 = load i8, i8* %arrayidx70.48, align 1
  %conv71.31.48 = zext i8 %18779 to i32
  %xor72.31.48 = xor i32 %conv71.31.48, %conv68.31.48
  %conv73.31.48 = trunc i32 %xor72.31.48 to i8
  store i8 %conv73.31.48, i8* %arrayidx70.48, align 1
  %scevgep20.32.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 32
  %18780 = load i8, i8* %scevgep20.32.48, align 1
  %conv68.32.48 = zext i8 %18780 to i32
  %18781 = load i8, i8* %arrayidx70.48, align 1
  %conv71.32.48 = zext i8 %18781 to i32
  %xor72.32.48 = xor i32 %conv71.32.48, %conv68.32.48
  %conv73.32.48 = trunc i32 %xor72.32.48 to i8
  store i8 %conv73.32.48, i8* %arrayidx70.48, align 1
  %scevgep20.33.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 33
  %18782 = load i8, i8* %scevgep20.33.48, align 1
  %conv68.33.48 = zext i8 %18782 to i32
  %18783 = load i8, i8* %arrayidx70.48, align 1
  %conv71.33.48 = zext i8 %18783 to i32
  %xor72.33.48 = xor i32 %conv71.33.48, %conv68.33.48
  %conv73.33.48 = trunc i32 %xor72.33.48 to i8
  store i8 %conv73.33.48, i8* %arrayidx70.48, align 1
  %scevgep20.34.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 34
  %18784 = load i8, i8* %scevgep20.34.48, align 1
  %conv68.34.48 = zext i8 %18784 to i32
  %18785 = load i8, i8* %arrayidx70.48, align 1
  %conv71.34.48 = zext i8 %18785 to i32
  %xor72.34.48 = xor i32 %conv71.34.48, %conv68.34.48
  %conv73.34.48 = trunc i32 %xor72.34.48 to i8
  store i8 %conv73.34.48, i8* %arrayidx70.48, align 1
  %scevgep20.35.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 35
  %18786 = load i8, i8* %scevgep20.35.48, align 1
  %conv68.35.48 = zext i8 %18786 to i32
  %18787 = load i8, i8* %arrayidx70.48, align 1
  %conv71.35.48 = zext i8 %18787 to i32
  %xor72.35.48 = xor i32 %conv71.35.48, %conv68.35.48
  %conv73.35.48 = trunc i32 %xor72.35.48 to i8
  store i8 %conv73.35.48, i8* %arrayidx70.48, align 1
  %scevgep20.36.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 36
  %18788 = load i8, i8* %scevgep20.36.48, align 1
  %conv68.36.48 = zext i8 %18788 to i32
  %18789 = load i8, i8* %arrayidx70.48, align 1
  %conv71.36.48 = zext i8 %18789 to i32
  %xor72.36.48 = xor i32 %conv71.36.48, %conv68.36.48
  %conv73.36.48 = trunc i32 %xor72.36.48 to i8
  store i8 %conv73.36.48, i8* %arrayidx70.48, align 1
  %scevgep20.37.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 37
  %18790 = load i8, i8* %scevgep20.37.48, align 1
  %conv68.37.48 = zext i8 %18790 to i32
  %18791 = load i8, i8* %arrayidx70.48, align 1
  %conv71.37.48 = zext i8 %18791 to i32
  %xor72.37.48 = xor i32 %conv71.37.48, %conv68.37.48
  %conv73.37.48 = trunc i32 %xor72.37.48 to i8
  store i8 %conv73.37.48, i8* %arrayidx70.48, align 1
  %scevgep20.38.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 38
  %18792 = load i8, i8* %scevgep20.38.48, align 1
  %conv68.38.48 = zext i8 %18792 to i32
  %18793 = load i8, i8* %arrayidx70.48, align 1
  %conv71.38.48 = zext i8 %18793 to i32
  %xor72.38.48 = xor i32 %conv71.38.48, %conv68.38.48
  %conv73.38.48 = trunc i32 %xor72.38.48 to i8
  store i8 %conv73.38.48, i8* %arrayidx70.48, align 1
  %scevgep20.39.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 39
  %18794 = load i8, i8* %scevgep20.39.48, align 1
  %conv68.39.48 = zext i8 %18794 to i32
  %18795 = load i8, i8* %arrayidx70.48, align 1
  %conv71.39.48 = zext i8 %18795 to i32
  %xor72.39.48 = xor i32 %conv71.39.48, %conv68.39.48
  %conv73.39.48 = trunc i32 %xor72.39.48 to i8
  store i8 %conv73.39.48, i8* %arrayidx70.48, align 1
  %scevgep20.40.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 40
  %18796 = load i8, i8* %scevgep20.40.48, align 1
  %conv68.40.48 = zext i8 %18796 to i32
  %18797 = load i8, i8* %arrayidx70.48, align 1
  %conv71.40.48 = zext i8 %18797 to i32
  %xor72.40.48 = xor i32 %conv71.40.48, %conv68.40.48
  %conv73.40.48 = trunc i32 %xor72.40.48 to i8
  store i8 %conv73.40.48, i8* %arrayidx70.48, align 1
  %scevgep20.41.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 41
  %18798 = load i8, i8* %scevgep20.41.48, align 1
  %conv68.41.48 = zext i8 %18798 to i32
  %18799 = load i8, i8* %arrayidx70.48, align 1
  %conv71.41.48 = zext i8 %18799 to i32
  %xor72.41.48 = xor i32 %conv71.41.48, %conv68.41.48
  %conv73.41.48 = trunc i32 %xor72.41.48 to i8
  store i8 %conv73.41.48, i8* %arrayidx70.48, align 1
  %scevgep20.42.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 42
  %18800 = load i8, i8* %scevgep20.42.48, align 1
  %conv68.42.48 = zext i8 %18800 to i32
  %18801 = load i8, i8* %arrayidx70.48, align 1
  %conv71.42.48 = zext i8 %18801 to i32
  %xor72.42.48 = xor i32 %conv71.42.48, %conv68.42.48
  %conv73.42.48 = trunc i32 %xor72.42.48 to i8
  store i8 %conv73.42.48, i8* %arrayidx70.48, align 1
  %scevgep20.43.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 43
  %18802 = load i8, i8* %scevgep20.43.48, align 1
  %conv68.43.48 = zext i8 %18802 to i32
  %18803 = load i8, i8* %arrayidx70.48, align 1
  %conv71.43.48 = zext i8 %18803 to i32
  %xor72.43.48 = xor i32 %conv71.43.48, %conv68.43.48
  %conv73.43.48 = trunc i32 %xor72.43.48 to i8
  store i8 %conv73.43.48, i8* %arrayidx70.48, align 1
  %scevgep20.44.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 44
  %18804 = load i8, i8* %scevgep20.44.48, align 1
  %conv68.44.48 = zext i8 %18804 to i32
  %18805 = load i8, i8* %arrayidx70.48, align 1
  %conv71.44.48 = zext i8 %18805 to i32
  %xor72.44.48 = xor i32 %conv71.44.48, %conv68.44.48
  %conv73.44.48 = trunc i32 %xor72.44.48 to i8
  store i8 %conv73.44.48, i8* %arrayidx70.48, align 1
  %scevgep20.45.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 45
  %18806 = load i8, i8* %scevgep20.45.48, align 1
  %conv68.45.48 = zext i8 %18806 to i32
  %18807 = load i8, i8* %arrayidx70.48, align 1
  %conv71.45.48 = zext i8 %18807 to i32
  %xor72.45.48 = xor i32 %conv71.45.48, %conv68.45.48
  %conv73.45.48 = trunc i32 %xor72.45.48 to i8
  store i8 %conv73.45.48, i8* %arrayidx70.48, align 1
  %scevgep20.46.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 46
  %18808 = load i8, i8* %scevgep20.46.48, align 1
  %conv68.46.48 = zext i8 %18808 to i32
  %18809 = load i8, i8* %arrayidx70.48, align 1
  %conv71.46.48 = zext i8 %18809 to i32
  %xor72.46.48 = xor i32 %conv71.46.48, %conv68.46.48
  %conv73.46.48 = trunc i32 %xor72.46.48 to i8
  store i8 %conv73.46.48, i8* %arrayidx70.48, align 1
  %scevgep20.47.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 47
  %18810 = load i8, i8* %scevgep20.47.48, align 1
  %conv68.47.48 = zext i8 %18810 to i32
  %18811 = load i8, i8* %arrayidx70.48, align 1
  %conv71.47.48 = zext i8 %18811 to i32
  %xor72.47.48 = xor i32 %conv71.47.48, %conv68.47.48
  %conv73.47.48 = trunc i32 %xor72.47.48 to i8
  store i8 %conv73.47.48, i8* %arrayidx70.48, align 1
  %scevgep20.49.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 49
  %18812 = load i8, i8* %scevgep20.49.48, align 1
  %conv68.49.48 = zext i8 %18812 to i32
  %18813 = load i8, i8* %arrayidx70.48, align 1
  %conv71.49.48 = zext i8 %18813 to i32
  %xor72.49.48 = xor i32 %conv71.49.48, %conv68.49.48
  %conv73.49.48 = trunc i32 %xor72.49.48 to i8
  store i8 %conv73.49.48, i8* %arrayidx70.48, align 1
  %scevgep20.50.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 50
  %18814 = load i8, i8* %scevgep20.50.48, align 1
  %conv68.50.48 = zext i8 %18814 to i32
  %18815 = load i8, i8* %arrayidx70.48, align 1
  %conv71.50.48 = zext i8 %18815 to i32
  %xor72.50.48 = xor i32 %conv71.50.48, %conv68.50.48
  %conv73.50.48 = trunc i32 %xor72.50.48 to i8
  store i8 %conv73.50.48, i8* %arrayidx70.48, align 1
  %scevgep20.51.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 51
  %18816 = load i8, i8* %scevgep20.51.48, align 1
  %conv68.51.48 = zext i8 %18816 to i32
  %18817 = load i8, i8* %arrayidx70.48, align 1
  %conv71.51.48 = zext i8 %18817 to i32
  %xor72.51.48 = xor i32 %conv71.51.48, %conv68.51.48
  %conv73.51.48 = trunc i32 %xor72.51.48 to i8
  store i8 %conv73.51.48, i8* %arrayidx70.48, align 1
  %scevgep20.52.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 52
  %18818 = load i8, i8* %scevgep20.52.48, align 1
  %conv68.52.48 = zext i8 %18818 to i32
  %18819 = load i8, i8* %arrayidx70.48, align 1
  %conv71.52.48 = zext i8 %18819 to i32
  %xor72.52.48 = xor i32 %conv71.52.48, %conv68.52.48
  %conv73.52.48 = trunc i32 %xor72.52.48 to i8
  store i8 %conv73.52.48, i8* %arrayidx70.48, align 1
  %scevgep20.53.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 53
  %18820 = load i8, i8* %scevgep20.53.48, align 1
  %conv68.53.48 = zext i8 %18820 to i32
  %18821 = load i8, i8* %arrayidx70.48, align 1
  %conv71.53.48 = zext i8 %18821 to i32
  %xor72.53.48 = xor i32 %conv71.53.48, %conv68.53.48
  %conv73.53.48 = trunc i32 %xor72.53.48 to i8
  store i8 %conv73.53.48, i8* %arrayidx70.48, align 1
  %scevgep20.54.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 54
  %18822 = load i8, i8* %scevgep20.54.48, align 1
  %conv68.54.48 = zext i8 %18822 to i32
  %18823 = load i8, i8* %arrayidx70.48, align 1
  %conv71.54.48 = zext i8 %18823 to i32
  %xor72.54.48 = xor i32 %conv71.54.48, %conv68.54.48
  %conv73.54.48 = trunc i32 %xor72.54.48 to i8
  store i8 %conv73.54.48, i8* %arrayidx70.48, align 1
  %scevgep20.55.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 55
  %18824 = load i8, i8* %scevgep20.55.48, align 1
  %conv68.55.48 = zext i8 %18824 to i32
  %18825 = load i8, i8* %arrayidx70.48, align 1
  %conv71.55.48 = zext i8 %18825 to i32
  %xor72.55.48 = xor i32 %conv71.55.48, %conv68.55.48
  %conv73.55.48 = trunc i32 %xor72.55.48 to i8
  store i8 %conv73.55.48, i8* %arrayidx70.48, align 1
  %scevgep20.56.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 56
  %18826 = load i8, i8* %scevgep20.56.48, align 1
  %conv68.56.48 = zext i8 %18826 to i32
  %18827 = load i8, i8* %arrayidx70.48, align 1
  %conv71.56.48 = zext i8 %18827 to i32
  %xor72.56.48 = xor i32 %conv71.56.48, %conv68.56.48
  %conv73.56.48 = trunc i32 %xor72.56.48 to i8
  store i8 %conv73.56.48, i8* %arrayidx70.48, align 1
  %scevgep20.57.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 57
  %18828 = load i8, i8* %scevgep20.57.48, align 1
  %conv68.57.48 = zext i8 %18828 to i32
  %18829 = load i8, i8* %arrayidx70.48, align 1
  %conv71.57.48 = zext i8 %18829 to i32
  %xor72.57.48 = xor i32 %conv71.57.48, %conv68.57.48
  %conv73.57.48 = trunc i32 %xor72.57.48 to i8
  store i8 %conv73.57.48, i8* %arrayidx70.48, align 1
  %scevgep20.58.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 58
  %18830 = load i8, i8* %scevgep20.58.48, align 1
  %conv68.58.48 = zext i8 %18830 to i32
  %18831 = load i8, i8* %arrayidx70.48, align 1
  %conv71.58.48 = zext i8 %18831 to i32
  %xor72.58.48 = xor i32 %conv71.58.48, %conv68.58.48
  %conv73.58.48 = trunc i32 %xor72.58.48 to i8
  store i8 %conv73.58.48, i8* %arrayidx70.48, align 1
  %scevgep20.59.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 59
  %18832 = load i8, i8* %scevgep20.59.48, align 1
  %conv68.59.48 = zext i8 %18832 to i32
  %18833 = load i8, i8* %arrayidx70.48, align 1
  %conv71.59.48 = zext i8 %18833 to i32
  %xor72.59.48 = xor i32 %conv71.59.48, %conv68.59.48
  %conv73.59.48 = trunc i32 %xor72.59.48 to i8
  store i8 %conv73.59.48, i8* %arrayidx70.48, align 1
  %scevgep20.60.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 0, i64 60
  %18834 = load i8, i8* %scevgep20.60.48, align 1
  %conv68.60.48 = zext i8 %18834 to i32
  %18835 = load i8, i8* %arrayidx70.48, align 1
  %conv71.60.48 = zext i8 %18835 to i32
  %xor72.60.48 = xor i32 %conv71.60.48, %conv68.60.48
  %conv73.60.48 = trunc i32 %xor72.60.48 to i8
  store i8 %conv73.60.48, i8* %arrayidx70.48, align 1
  %scevgep19.48 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18713, i64 0, i64 1, i64 0
  %18836 = bitcast i8* %scevgep19.48 to [61 x [61 x i8]]*
  %arrayidx51.49 = getelementptr inbounds i8, i8* %a, i64 49
  %18837 = load i8, i8* %arrayidx51.49, align 1
  %arrayidx53.49 = getelementptr inbounds i8, i8* %b, i64 49
  %18838 = load i8, i8* %arrayidx53.49, align 1
  %call54.49 = call zeroext i8 @mult(i8 zeroext %18837, i8 zeroext %18838)
  %arrayidx56.49 = getelementptr inbounds i8, i8* %c, i64 49
  store i8 %call54.49, i8* %arrayidx56.49, align 1
  %arrayidx70.49 = getelementptr inbounds i8, i8* %c, i64 49
  %scevgep20.49534 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 0
  %18839 = load i8, i8* %scevgep20.49534, align 1
  %conv68.49535 = zext i8 %18839 to i32
  %18840 = load i8, i8* %arrayidx70.49, align 1
  %conv71.49536 = zext i8 %18840 to i32
  %xor72.49537 = xor i32 %conv71.49536, %conv68.49535
  %conv73.49538 = trunc i32 %xor72.49537 to i8
  store i8 %conv73.49538, i8* %arrayidx70.49, align 1
  %scevgep20.1.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 1
  %18841 = load i8, i8* %scevgep20.1.49, align 1
  %conv68.1.49 = zext i8 %18841 to i32
  %18842 = load i8, i8* %arrayidx70.49, align 1
  %conv71.1.49 = zext i8 %18842 to i32
  %xor72.1.49 = xor i32 %conv71.1.49, %conv68.1.49
  %conv73.1.49 = trunc i32 %xor72.1.49 to i8
  store i8 %conv73.1.49, i8* %arrayidx70.49, align 1
  %scevgep20.2.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 2
  %18843 = load i8, i8* %scevgep20.2.49, align 1
  %conv68.2.49 = zext i8 %18843 to i32
  %18844 = load i8, i8* %arrayidx70.49, align 1
  %conv71.2.49 = zext i8 %18844 to i32
  %xor72.2.49 = xor i32 %conv71.2.49, %conv68.2.49
  %conv73.2.49 = trunc i32 %xor72.2.49 to i8
  store i8 %conv73.2.49, i8* %arrayidx70.49, align 1
  %scevgep20.3.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 3
  %18845 = load i8, i8* %scevgep20.3.49, align 1
  %conv68.3.49 = zext i8 %18845 to i32
  %18846 = load i8, i8* %arrayidx70.49, align 1
  %conv71.3.49 = zext i8 %18846 to i32
  %xor72.3.49 = xor i32 %conv71.3.49, %conv68.3.49
  %conv73.3.49 = trunc i32 %xor72.3.49 to i8
  store i8 %conv73.3.49, i8* %arrayidx70.49, align 1
  %scevgep20.4.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 4
  %18847 = load i8, i8* %scevgep20.4.49, align 1
  %conv68.4.49 = zext i8 %18847 to i32
  %18848 = load i8, i8* %arrayidx70.49, align 1
  %conv71.4.49 = zext i8 %18848 to i32
  %xor72.4.49 = xor i32 %conv71.4.49, %conv68.4.49
  %conv73.4.49 = trunc i32 %xor72.4.49 to i8
  store i8 %conv73.4.49, i8* %arrayidx70.49, align 1
  %scevgep20.5.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 5
  %18849 = load i8, i8* %scevgep20.5.49, align 1
  %conv68.5.49 = zext i8 %18849 to i32
  %18850 = load i8, i8* %arrayidx70.49, align 1
  %conv71.5.49 = zext i8 %18850 to i32
  %xor72.5.49 = xor i32 %conv71.5.49, %conv68.5.49
  %conv73.5.49 = trunc i32 %xor72.5.49 to i8
  store i8 %conv73.5.49, i8* %arrayidx70.49, align 1
  %scevgep20.6.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 6
  %18851 = load i8, i8* %scevgep20.6.49, align 1
  %conv68.6.49 = zext i8 %18851 to i32
  %18852 = load i8, i8* %arrayidx70.49, align 1
  %conv71.6.49 = zext i8 %18852 to i32
  %xor72.6.49 = xor i32 %conv71.6.49, %conv68.6.49
  %conv73.6.49 = trunc i32 %xor72.6.49 to i8
  store i8 %conv73.6.49, i8* %arrayidx70.49, align 1
  %scevgep20.7.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 7
  %18853 = load i8, i8* %scevgep20.7.49, align 1
  %conv68.7.49 = zext i8 %18853 to i32
  %18854 = load i8, i8* %arrayidx70.49, align 1
  %conv71.7.49 = zext i8 %18854 to i32
  %xor72.7.49 = xor i32 %conv71.7.49, %conv68.7.49
  %conv73.7.49 = trunc i32 %xor72.7.49 to i8
  store i8 %conv73.7.49, i8* %arrayidx70.49, align 1
  %scevgep20.8.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 8
  %18855 = load i8, i8* %scevgep20.8.49, align 1
  %conv68.8.49 = zext i8 %18855 to i32
  %18856 = load i8, i8* %arrayidx70.49, align 1
  %conv71.8.49 = zext i8 %18856 to i32
  %xor72.8.49 = xor i32 %conv71.8.49, %conv68.8.49
  %conv73.8.49 = trunc i32 %xor72.8.49 to i8
  store i8 %conv73.8.49, i8* %arrayidx70.49, align 1
  %scevgep20.9.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 9
  %18857 = load i8, i8* %scevgep20.9.49, align 1
  %conv68.9.49 = zext i8 %18857 to i32
  %18858 = load i8, i8* %arrayidx70.49, align 1
  %conv71.9.49 = zext i8 %18858 to i32
  %xor72.9.49 = xor i32 %conv71.9.49, %conv68.9.49
  %conv73.9.49 = trunc i32 %xor72.9.49 to i8
  store i8 %conv73.9.49, i8* %arrayidx70.49, align 1
  %scevgep20.10.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 10
  %18859 = load i8, i8* %scevgep20.10.49, align 1
  %conv68.10.49 = zext i8 %18859 to i32
  %18860 = load i8, i8* %arrayidx70.49, align 1
  %conv71.10.49 = zext i8 %18860 to i32
  %xor72.10.49 = xor i32 %conv71.10.49, %conv68.10.49
  %conv73.10.49 = trunc i32 %xor72.10.49 to i8
  store i8 %conv73.10.49, i8* %arrayidx70.49, align 1
  %scevgep20.11.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 11
  %18861 = load i8, i8* %scevgep20.11.49, align 1
  %conv68.11.49 = zext i8 %18861 to i32
  %18862 = load i8, i8* %arrayidx70.49, align 1
  %conv71.11.49 = zext i8 %18862 to i32
  %xor72.11.49 = xor i32 %conv71.11.49, %conv68.11.49
  %conv73.11.49 = trunc i32 %xor72.11.49 to i8
  store i8 %conv73.11.49, i8* %arrayidx70.49, align 1
  %scevgep20.12.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 12
  %18863 = load i8, i8* %scevgep20.12.49, align 1
  %conv68.12.49 = zext i8 %18863 to i32
  %18864 = load i8, i8* %arrayidx70.49, align 1
  %conv71.12.49 = zext i8 %18864 to i32
  %xor72.12.49 = xor i32 %conv71.12.49, %conv68.12.49
  %conv73.12.49 = trunc i32 %xor72.12.49 to i8
  store i8 %conv73.12.49, i8* %arrayidx70.49, align 1
  %scevgep20.13.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 13
  %18865 = load i8, i8* %scevgep20.13.49, align 1
  %conv68.13.49 = zext i8 %18865 to i32
  %18866 = load i8, i8* %arrayidx70.49, align 1
  %conv71.13.49 = zext i8 %18866 to i32
  %xor72.13.49 = xor i32 %conv71.13.49, %conv68.13.49
  %conv73.13.49 = trunc i32 %xor72.13.49 to i8
  store i8 %conv73.13.49, i8* %arrayidx70.49, align 1
  %scevgep20.14.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 14
  %18867 = load i8, i8* %scevgep20.14.49, align 1
  %conv68.14.49 = zext i8 %18867 to i32
  %18868 = load i8, i8* %arrayidx70.49, align 1
  %conv71.14.49 = zext i8 %18868 to i32
  %xor72.14.49 = xor i32 %conv71.14.49, %conv68.14.49
  %conv73.14.49 = trunc i32 %xor72.14.49 to i8
  store i8 %conv73.14.49, i8* %arrayidx70.49, align 1
  %scevgep20.15.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 15
  %18869 = load i8, i8* %scevgep20.15.49, align 1
  %conv68.15.49 = zext i8 %18869 to i32
  %18870 = load i8, i8* %arrayidx70.49, align 1
  %conv71.15.49 = zext i8 %18870 to i32
  %xor72.15.49 = xor i32 %conv71.15.49, %conv68.15.49
  %conv73.15.49 = trunc i32 %xor72.15.49 to i8
  store i8 %conv73.15.49, i8* %arrayidx70.49, align 1
  %scevgep20.16.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 16
  %18871 = load i8, i8* %scevgep20.16.49, align 1
  %conv68.16.49 = zext i8 %18871 to i32
  %18872 = load i8, i8* %arrayidx70.49, align 1
  %conv71.16.49 = zext i8 %18872 to i32
  %xor72.16.49 = xor i32 %conv71.16.49, %conv68.16.49
  %conv73.16.49 = trunc i32 %xor72.16.49 to i8
  store i8 %conv73.16.49, i8* %arrayidx70.49, align 1
  %scevgep20.17.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 17
  %18873 = load i8, i8* %scevgep20.17.49, align 1
  %conv68.17.49 = zext i8 %18873 to i32
  %18874 = load i8, i8* %arrayidx70.49, align 1
  %conv71.17.49 = zext i8 %18874 to i32
  %xor72.17.49 = xor i32 %conv71.17.49, %conv68.17.49
  %conv73.17.49 = trunc i32 %xor72.17.49 to i8
  store i8 %conv73.17.49, i8* %arrayidx70.49, align 1
  %scevgep20.18.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 18
  %18875 = load i8, i8* %scevgep20.18.49, align 1
  %conv68.18.49 = zext i8 %18875 to i32
  %18876 = load i8, i8* %arrayidx70.49, align 1
  %conv71.18.49 = zext i8 %18876 to i32
  %xor72.18.49 = xor i32 %conv71.18.49, %conv68.18.49
  %conv73.18.49 = trunc i32 %xor72.18.49 to i8
  store i8 %conv73.18.49, i8* %arrayidx70.49, align 1
  %scevgep20.19.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 19
  %18877 = load i8, i8* %scevgep20.19.49, align 1
  %conv68.19.49 = zext i8 %18877 to i32
  %18878 = load i8, i8* %arrayidx70.49, align 1
  %conv71.19.49 = zext i8 %18878 to i32
  %xor72.19.49 = xor i32 %conv71.19.49, %conv68.19.49
  %conv73.19.49 = trunc i32 %xor72.19.49 to i8
  store i8 %conv73.19.49, i8* %arrayidx70.49, align 1
  %scevgep20.20.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 20
  %18879 = load i8, i8* %scevgep20.20.49, align 1
  %conv68.20.49 = zext i8 %18879 to i32
  %18880 = load i8, i8* %arrayidx70.49, align 1
  %conv71.20.49 = zext i8 %18880 to i32
  %xor72.20.49 = xor i32 %conv71.20.49, %conv68.20.49
  %conv73.20.49 = trunc i32 %xor72.20.49 to i8
  store i8 %conv73.20.49, i8* %arrayidx70.49, align 1
  %scevgep20.21.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 21
  %18881 = load i8, i8* %scevgep20.21.49, align 1
  %conv68.21.49 = zext i8 %18881 to i32
  %18882 = load i8, i8* %arrayidx70.49, align 1
  %conv71.21.49 = zext i8 %18882 to i32
  %xor72.21.49 = xor i32 %conv71.21.49, %conv68.21.49
  %conv73.21.49 = trunc i32 %xor72.21.49 to i8
  store i8 %conv73.21.49, i8* %arrayidx70.49, align 1
  %scevgep20.22.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 22
  %18883 = load i8, i8* %scevgep20.22.49, align 1
  %conv68.22.49 = zext i8 %18883 to i32
  %18884 = load i8, i8* %arrayidx70.49, align 1
  %conv71.22.49 = zext i8 %18884 to i32
  %xor72.22.49 = xor i32 %conv71.22.49, %conv68.22.49
  %conv73.22.49 = trunc i32 %xor72.22.49 to i8
  store i8 %conv73.22.49, i8* %arrayidx70.49, align 1
  %scevgep20.23.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 23
  %18885 = load i8, i8* %scevgep20.23.49, align 1
  %conv68.23.49 = zext i8 %18885 to i32
  %18886 = load i8, i8* %arrayidx70.49, align 1
  %conv71.23.49 = zext i8 %18886 to i32
  %xor72.23.49 = xor i32 %conv71.23.49, %conv68.23.49
  %conv73.23.49 = trunc i32 %xor72.23.49 to i8
  store i8 %conv73.23.49, i8* %arrayidx70.49, align 1
  %scevgep20.24.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 24
  %18887 = load i8, i8* %scevgep20.24.49, align 1
  %conv68.24.49 = zext i8 %18887 to i32
  %18888 = load i8, i8* %arrayidx70.49, align 1
  %conv71.24.49 = zext i8 %18888 to i32
  %xor72.24.49 = xor i32 %conv71.24.49, %conv68.24.49
  %conv73.24.49 = trunc i32 %xor72.24.49 to i8
  store i8 %conv73.24.49, i8* %arrayidx70.49, align 1
  %scevgep20.25.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 25
  %18889 = load i8, i8* %scevgep20.25.49, align 1
  %conv68.25.49 = zext i8 %18889 to i32
  %18890 = load i8, i8* %arrayidx70.49, align 1
  %conv71.25.49 = zext i8 %18890 to i32
  %xor72.25.49 = xor i32 %conv71.25.49, %conv68.25.49
  %conv73.25.49 = trunc i32 %xor72.25.49 to i8
  store i8 %conv73.25.49, i8* %arrayidx70.49, align 1
  %scevgep20.26.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 26
  %18891 = load i8, i8* %scevgep20.26.49, align 1
  %conv68.26.49 = zext i8 %18891 to i32
  %18892 = load i8, i8* %arrayidx70.49, align 1
  %conv71.26.49 = zext i8 %18892 to i32
  %xor72.26.49 = xor i32 %conv71.26.49, %conv68.26.49
  %conv73.26.49 = trunc i32 %xor72.26.49 to i8
  store i8 %conv73.26.49, i8* %arrayidx70.49, align 1
  %scevgep20.27.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 27
  %18893 = load i8, i8* %scevgep20.27.49, align 1
  %conv68.27.49 = zext i8 %18893 to i32
  %18894 = load i8, i8* %arrayidx70.49, align 1
  %conv71.27.49 = zext i8 %18894 to i32
  %xor72.27.49 = xor i32 %conv71.27.49, %conv68.27.49
  %conv73.27.49 = trunc i32 %xor72.27.49 to i8
  store i8 %conv73.27.49, i8* %arrayidx70.49, align 1
  %scevgep20.28.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 28
  %18895 = load i8, i8* %scevgep20.28.49, align 1
  %conv68.28.49 = zext i8 %18895 to i32
  %18896 = load i8, i8* %arrayidx70.49, align 1
  %conv71.28.49 = zext i8 %18896 to i32
  %xor72.28.49 = xor i32 %conv71.28.49, %conv68.28.49
  %conv73.28.49 = trunc i32 %xor72.28.49 to i8
  store i8 %conv73.28.49, i8* %arrayidx70.49, align 1
  %scevgep20.29.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 29
  %18897 = load i8, i8* %scevgep20.29.49, align 1
  %conv68.29.49 = zext i8 %18897 to i32
  %18898 = load i8, i8* %arrayidx70.49, align 1
  %conv71.29.49 = zext i8 %18898 to i32
  %xor72.29.49 = xor i32 %conv71.29.49, %conv68.29.49
  %conv73.29.49 = trunc i32 %xor72.29.49 to i8
  store i8 %conv73.29.49, i8* %arrayidx70.49, align 1
  %scevgep20.30.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 30
  %18899 = load i8, i8* %scevgep20.30.49, align 1
  %conv68.30.49 = zext i8 %18899 to i32
  %18900 = load i8, i8* %arrayidx70.49, align 1
  %conv71.30.49 = zext i8 %18900 to i32
  %xor72.30.49 = xor i32 %conv71.30.49, %conv68.30.49
  %conv73.30.49 = trunc i32 %xor72.30.49 to i8
  store i8 %conv73.30.49, i8* %arrayidx70.49, align 1
  %scevgep20.31.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 31
  %18901 = load i8, i8* %scevgep20.31.49, align 1
  %conv68.31.49 = zext i8 %18901 to i32
  %18902 = load i8, i8* %arrayidx70.49, align 1
  %conv71.31.49 = zext i8 %18902 to i32
  %xor72.31.49 = xor i32 %conv71.31.49, %conv68.31.49
  %conv73.31.49 = trunc i32 %xor72.31.49 to i8
  store i8 %conv73.31.49, i8* %arrayidx70.49, align 1
  %scevgep20.32.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 32
  %18903 = load i8, i8* %scevgep20.32.49, align 1
  %conv68.32.49 = zext i8 %18903 to i32
  %18904 = load i8, i8* %arrayidx70.49, align 1
  %conv71.32.49 = zext i8 %18904 to i32
  %xor72.32.49 = xor i32 %conv71.32.49, %conv68.32.49
  %conv73.32.49 = trunc i32 %xor72.32.49 to i8
  store i8 %conv73.32.49, i8* %arrayidx70.49, align 1
  %scevgep20.33.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 33
  %18905 = load i8, i8* %scevgep20.33.49, align 1
  %conv68.33.49 = zext i8 %18905 to i32
  %18906 = load i8, i8* %arrayidx70.49, align 1
  %conv71.33.49 = zext i8 %18906 to i32
  %xor72.33.49 = xor i32 %conv71.33.49, %conv68.33.49
  %conv73.33.49 = trunc i32 %xor72.33.49 to i8
  store i8 %conv73.33.49, i8* %arrayidx70.49, align 1
  %scevgep20.34.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 34
  %18907 = load i8, i8* %scevgep20.34.49, align 1
  %conv68.34.49 = zext i8 %18907 to i32
  %18908 = load i8, i8* %arrayidx70.49, align 1
  %conv71.34.49 = zext i8 %18908 to i32
  %xor72.34.49 = xor i32 %conv71.34.49, %conv68.34.49
  %conv73.34.49 = trunc i32 %xor72.34.49 to i8
  store i8 %conv73.34.49, i8* %arrayidx70.49, align 1
  %scevgep20.35.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 35
  %18909 = load i8, i8* %scevgep20.35.49, align 1
  %conv68.35.49 = zext i8 %18909 to i32
  %18910 = load i8, i8* %arrayidx70.49, align 1
  %conv71.35.49 = zext i8 %18910 to i32
  %xor72.35.49 = xor i32 %conv71.35.49, %conv68.35.49
  %conv73.35.49 = trunc i32 %xor72.35.49 to i8
  store i8 %conv73.35.49, i8* %arrayidx70.49, align 1
  %scevgep20.36.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 36
  %18911 = load i8, i8* %scevgep20.36.49, align 1
  %conv68.36.49 = zext i8 %18911 to i32
  %18912 = load i8, i8* %arrayidx70.49, align 1
  %conv71.36.49 = zext i8 %18912 to i32
  %xor72.36.49 = xor i32 %conv71.36.49, %conv68.36.49
  %conv73.36.49 = trunc i32 %xor72.36.49 to i8
  store i8 %conv73.36.49, i8* %arrayidx70.49, align 1
  %scevgep20.37.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 37
  %18913 = load i8, i8* %scevgep20.37.49, align 1
  %conv68.37.49 = zext i8 %18913 to i32
  %18914 = load i8, i8* %arrayidx70.49, align 1
  %conv71.37.49 = zext i8 %18914 to i32
  %xor72.37.49 = xor i32 %conv71.37.49, %conv68.37.49
  %conv73.37.49 = trunc i32 %xor72.37.49 to i8
  store i8 %conv73.37.49, i8* %arrayidx70.49, align 1
  %scevgep20.38.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 38
  %18915 = load i8, i8* %scevgep20.38.49, align 1
  %conv68.38.49 = zext i8 %18915 to i32
  %18916 = load i8, i8* %arrayidx70.49, align 1
  %conv71.38.49 = zext i8 %18916 to i32
  %xor72.38.49 = xor i32 %conv71.38.49, %conv68.38.49
  %conv73.38.49 = trunc i32 %xor72.38.49 to i8
  store i8 %conv73.38.49, i8* %arrayidx70.49, align 1
  %scevgep20.39.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 39
  %18917 = load i8, i8* %scevgep20.39.49, align 1
  %conv68.39.49 = zext i8 %18917 to i32
  %18918 = load i8, i8* %arrayidx70.49, align 1
  %conv71.39.49 = zext i8 %18918 to i32
  %xor72.39.49 = xor i32 %conv71.39.49, %conv68.39.49
  %conv73.39.49 = trunc i32 %xor72.39.49 to i8
  store i8 %conv73.39.49, i8* %arrayidx70.49, align 1
  %scevgep20.40.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 40
  %18919 = load i8, i8* %scevgep20.40.49, align 1
  %conv68.40.49 = zext i8 %18919 to i32
  %18920 = load i8, i8* %arrayidx70.49, align 1
  %conv71.40.49 = zext i8 %18920 to i32
  %xor72.40.49 = xor i32 %conv71.40.49, %conv68.40.49
  %conv73.40.49 = trunc i32 %xor72.40.49 to i8
  store i8 %conv73.40.49, i8* %arrayidx70.49, align 1
  %scevgep20.41.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 41
  %18921 = load i8, i8* %scevgep20.41.49, align 1
  %conv68.41.49 = zext i8 %18921 to i32
  %18922 = load i8, i8* %arrayidx70.49, align 1
  %conv71.41.49 = zext i8 %18922 to i32
  %xor72.41.49 = xor i32 %conv71.41.49, %conv68.41.49
  %conv73.41.49 = trunc i32 %xor72.41.49 to i8
  store i8 %conv73.41.49, i8* %arrayidx70.49, align 1
  %scevgep20.42.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 42
  %18923 = load i8, i8* %scevgep20.42.49, align 1
  %conv68.42.49 = zext i8 %18923 to i32
  %18924 = load i8, i8* %arrayidx70.49, align 1
  %conv71.42.49 = zext i8 %18924 to i32
  %xor72.42.49 = xor i32 %conv71.42.49, %conv68.42.49
  %conv73.42.49 = trunc i32 %xor72.42.49 to i8
  store i8 %conv73.42.49, i8* %arrayidx70.49, align 1
  %scevgep20.43.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 43
  %18925 = load i8, i8* %scevgep20.43.49, align 1
  %conv68.43.49 = zext i8 %18925 to i32
  %18926 = load i8, i8* %arrayidx70.49, align 1
  %conv71.43.49 = zext i8 %18926 to i32
  %xor72.43.49 = xor i32 %conv71.43.49, %conv68.43.49
  %conv73.43.49 = trunc i32 %xor72.43.49 to i8
  store i8 %conv73.43.49, i8* %arrayidx70.49, align 1
  %scevgep20.44.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 44
  %18927 = load i8, i8* %scevgep20.44.49, align 1
  %conv68.44.49 = zext i8 %18927 to i32
  %18928 = load i8, i8* %arrayidx70.49, align 1
  %conv71.44.49 = zext i8 %18928 to i32
  %xor72.44.49 = xor i32 %conv71.44.49, %conv68.44.49
  %conv73.44.49 = trunc i32 %xor72.44.49 to i8
  store i8 %conv73.44.49, i8* %arrayidx70.49, align 1
  %scevgep20.45.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 45
  %18929 = load i8, i8* %scevgep20.45.49, align 1
  %conv68.45.49 = zext i8 %18929 to i32
  %18930 = load i8, i8* %arrayidx70.49, align 1
  %conv71.45.49 = zext i8 %18930 to i32
  %xor72.45.49 = xor i32 %conv71.45.49, %conv68.45.49
  %conv73.45.49 = trunc i32 %xor72.45.49 to i8
  store i8 %conv73.45.49, i8* %arrayidx70.49, align 1
  %scevgep20.46.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 46
  %18931 = load i8, i8* %scevgep20.46.49, align 1
  %conv68.46.49 = zext i8 %18931 to i32
  %18932 = load i8, i8* %arrayidx70.49, align 1
  %conv71.46.49 = zext i8 %18932 to i32
  %xor72.46.49 = xor i32 %conv71.46.49, %conv68.46.49
  %conv73.46.49 = trunc i32 %xor72.46.49 to i8
  store i8 %conv73.46.49, i8* %arrayidx70.49, align 1
  %scevgep20.47.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 47
  %18933 = load i8, i8* %scevgep20.47.49, align 1
  %conv68.47.49 = zext i8 %18933 to i32
  %18934 = load i8, i8* %arrayidx70.49, align 1
  %conv71.47.49 = zext i8 %18934 to i32
  %xor72.47.49 = xor i32 %conv71.47.49, %conv68.47.49
  %conv73.47.49 = trunc i32 %xor72.47.49 to i8
  store i8 %conv73.47.49, i8* %arrayidx70.49, align 1
  %scevgep20.48.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 48
  %18935 = load i8, i8* %scevgep20.48.49, align 1
  %conv68.48.49 = zext i8 %18935 to i32
  %18936 = load i8, i8* %arrayidx70.49, align 1
  %conv71.48.49 = zext i8 %18936 to i32
  %xor72.48.49 = xor i32 %conv71.48.49, %conv68.48.49
  %conv73.48.49 = trunc i32 %xor72.48.49 to i8
  store i8 %conv73.48.49, i8* %arrayidx70.49, align 1
  %scevgep20.50.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 50
  %18937 = load i8, i8* %scevgep20.50.49, align 1
  %conv68.50.49 = zext i8 %18937 to i32
  %18938 = load i8, i8* %arrayidx70.49, align 1
  %conv71.50.49 = zext i8 %18938 to i32
  %xor72.50.49 = xor i32 %conv71.50.49, %conv68.50.49
  %conv73.50.49 = trunc i32 %xor72.50.49 to i8
  store i8 %conv73.50.49, i8* %arrayidx70.49, align 1
  %scevgep20.51.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 51
  %18939 = load i8, i8* %scevgep20.51.49, align 1
  %conv68.51.49 = zext i8 %18939 to i32
  %18940 = load i8, i8* %arrayidx70.49, align 1
  %conv71.51.49 = zext i8 %18940 to i32
  %xor72.51.49 = xor i32 %conv71.51.49, %conv68.51.49
  %conv73.51.49 = trunc i32 %xor72.51.49 to i8
  store i8 %conv73.51.49, i8* %arrayidx70.49, align 1
  %scevgep20.52.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 52
  %18941 = load i8, i8* %scevgep20.52.49, align 1
  %conv68.52.49 = zext i8 %18941 to i32
  %18942 = load i8, i8* %arrayidx70.49, align 1
  %conv71.52.49 = zext i8 %18942 to i32
  %xor72.52.49 = xor i32 %conv71.52.49, %conv68.52.49
  %conv73.52.49 = trunc i32 %xor72.52.49 to i8
  store i8 %conv73.52.49, i8* %arrayidx70.49, align 1
  %scevgep20.53.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 53
  %18943 = load i8, i8* %scevgep20.53.49, align 1
  %conv68.53.49 = zext i8 %18943 to i32
  %18944 = load i8, i8* %arrayidx70.49, align 1
  %conv71.53.49 = zext i8 %18944 to i32
  %xor72.53.49 = xor i32 %conv71.53.49, %conv68.53.49
  %conv73.53.49 = trunc i32 %xor72.53.49 to i8
  store i8 %conv73.53.49, i8* %arrayidx70.49, align 1
  %scevgep20.54.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 54
  %18945 = load i8, i8* %scevgep20.54.49, align 1
  %conv68.54.49 = zext i8 %18945 to i32
  %18946 = load i8, i8* %arrayidx70.49, align 1
  %conv71.54.49 = zext i8 %18946 to i32
  %xor72.54.49 = xor i32 %conv71.54.49, %conv68.54.49
  %conv73.54.49 = trunc i32 %xor72.54.49 to i8
  store i8 %conv73.54.49, i8* %arrayidx70.49, align 1
  %scevgep20.55.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 55
  %18947 = load i8, i8* %scevgep20.55.49, align 1
  %conv68.55.49 = zext i8 %18947 to i32
  %18948 = load i8, i8* %arrayidx70.49, align 1
  %conv71.55.49 = zext i8 %18948 to i32
  %xor72.55.49 = xor i32 %conv71.55.49, %conv68.55.49
  %conv73.55.49 = trunc i32 %xor72.55.49 to i8
  store i8 %conv73.55.49, i8* %arrayidx70.49, align 1
  %scevgep20.56.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 56
  %18949 = load i8, i8* %scevgep20.56.49, align 1
  %conv68.56.49 = zext i8 %18949 to i32
  %18950 = load i8, i8* %arrayidx70.49, align 1
  %conv71.56.49 = zext i8 %18950 to i32
  %xor72.56.49 = xor i32 %conv71.56.49, %conv68.56.49
  %conv73.56.49 = trunc i32 %xor72.56.49 to i8
  store i8 %conv73.56.49, i8* %arrayidx70.49, align 1
  %scevgep20.57.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 57
  %18951 = load i8, i8* %scevgep20.57.49, align 1
  %conv68.57.49 = zext i8 %18951 to i32
  %18952 = load i8, i8* %arrayidx70.49, align 1
  %conv71.57.49 = zext i8 %18952 to i32
  %xor72.57.49 = xor i32 %conv71.57.49, %conv68.57.49
  %conv73.57.49 = trunc i32 %xor72.57.49 to i8
  store i8 %conv73.57.49, i8* %arrayidx70.49, align 1
  %scevgep20.58.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 58
  %18953 = load i8, i8* %scevgep20.58.49, align 1
  %conv68.58.49 = zext i8 %18953 to i32
  %18954 = load i8, i8* %arrayidx70.49, align 1
  %conv71.58.49 = zext i8 %18954 to i32
  %xor72.58.49 = xor i32 %conv71.58.49, %conv68.58.49
  %conv73.58.49 = trunc i32 %xor72.58.49 to i8
  store i8 %conv73.58.49, i8* %arrayidx70.49, align 1
  %scevgep20.59.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 59
  %18955 = load i8, i8* %scevgep20.59.49, align 1
  %conv68.59.49 = zext i8 %18955 to i32
  %18956 = load i8, i8* %arrayidx70.49, align 1
  %conv71.59.49 = zext i8 %18956 to i32
  %xor72.59.49 = xor i32 %conv71.59.49, %conv68.59.49
  %conv73.59.49 = trunc i32 %xor72.59.49 to i8
  store i8 %conv73.59.49, i8* %arrayidx70.49, align 1
  %scevgep20.60.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 0, i64 60
  %18957 = load i8, i8* %scevgep20.60.49, align 1
  %conv68.60.49 = zext i8 %18957 to i32
  %18958 = load i8, i8* %arrayidx70.49, align 1
  %conv71.60.49 = zext i8 %18958 to i32
  %xor72.60.49 = xor i32 %conv71.60.49, %conv68.60.49
  %conv73.60.49 = trunc i32 %xor72.60.49 to i8
  store i8 %conv73.60.49, i8* %arrayidx70.49, align 1
  %scevgep19.49 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18836, i64 0, i64 1, i64 0
  %18959 = bitcast i8* %scevgep19.49 to [61 x [61 x i8]]*
  %arrayidx51.50 = getelementptr inbounds i8, i8* %a, i64 50
  %18960 = load i8, i8* %arrayidx51.50, align 1
  %arrayidx53.50 = getelementptr inbounds i8, i8* %b, i64 50
  %18961 = load i8, i8* %arrayidx53.50, align 1
  %call54.50 = call zeroext i8 @mult(i8 zeroext %18960, i8 zeroext %18961)
  %arrayidx56.50 = getelementptr inbounds i8, i8* %c, i64 50
  store i8 %call54.50, i8* %arrayidx56.50, align 1
  %arrayidx70.50 = getelementptr inbounds i8, i8* %c, i64 50
  %scevgep20.50544 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 0
  %18962 = load i8, i8* %scevgep20.50544, align 1
  %conv68.50545 = zext i8 %18962 to i32
  %18963 = load i8, i8* %arrayidx70.50, align 1
  %conv71.50546 = zext i8 %18963 to i32
  %xor72.50547 = xor i32 %conv71.50546, %conv68.50545
  %conv73.50548 = trunc i32 %xor72.50547 to i8
  store i8 %conv73.50548, i8* %arrayidx70.50, align 1
  %scevgep20.1.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 1
  %18964 = load i8, i8* %scevgep20.1.50, align 1
  %conv68.1.50 = zext i8 %18964 to i32
  %18965 = load i8, i8* %arrayidx70.50, align 1
  %conv71.1.50 = zext i8 %18965 to i32
  %xor72.1.50 = xor i32 %conv71.1.50, %conv68.1.50
  %conv73.1.50 = trunc i32 %xor72.1.50 to i8
  store i8 %conv73.1.50, i8* %arrayidx70.50, align 1
  %scevgep20.2.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 2
  %18966 = load i8, i8* %scevgep20.2.50, align 1
  %conv68.2.50 = zext i8 %18966 to i32
  %18967 = load i8, i8* %arrayidx70.50, align 1
  %conv71.2.50 = zext i8 %18967 to i32
  %xor72.2.50 = xor i32 %conv71.2.50, %conv68.2.50
  %conv73.2.50 = trunc i32 %xor72.2.50 to i8
  store i8 %conv73.2.50, i8* %arrayidx70.50, align 1
  %scevgep20.3.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 3
  %18968 = load i8, i8* %scevgep20.3.50, align 1
  %conv68.3.50 = zext i8 %18968 to i32
  %18969 = load i8, i8* %arrayidx70.50, align 1
  %conv71.3.50 = zext i8 %18969 to i32
  %xor72.3.50 = xor i32 %conv71.3.50, %conv68.3.50
  %conv73.3.50 = trunc i32 %xor72.3.50 to i8
  store i8 %conv73.3.50, i8* %arrayidx70.50, align 1
  %scevgep20.4.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 4
  %18970 = load i8, i8* %scevgep20.4.50, align 1
  %conv68.4.50 = zext i8 %18970 to i32
  %18971 = load i8, i8* %arrayidx70.50, align 1
  %conv71.4.50 = zext i8 %18971 to i32
  %xor72.4.50 = xor i32 %conv71.4.50, %conv68.4.50
  %conv73.4.50 = trunc i32 %xor72.4.50 to i8
  store i8 %conv73.4.50, i8* %arrayidx70.50, align 1
  %scevgep20.5.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 5
  %18972 = load i8, i8* %scevgep20.5.50, align 1
  %conv68.5.50 = zext i8 %18972 to i32
  %18973 = load i8, i8* %arrayidx70.50, align 1
  %conv71.5.50 = zext i8 %18973 to i32
  %xor72.5.50 = xor i32 %conv71.5.50, %conv68.5.50
  %conv73.5.50 = trunc i32 %xor72.5.50 to i8
  store i8 %conv73.5.50, i8* %arrayidx70.50, align 1
  %scevgep20.6.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 6
  %18974 = load i8, i8* %scevgep20.6.50, align 1
  %conv68.6.50 = zext i8 %18974 to i32
  %18975 = load i8, i8* %arrayidx70.50, align 1
  %conv71.6.50 = zext i8 %18975 to i32
  %xor72.6.50 = xor i32 %conv71.6.50, %conv68.6.50
  %conv73.6.50 = trunc i32 %xor72.6.50 to i8
  store i8 %conv73.6.50, i8* %arrayidx70.50, align 1
  %scevgep20.7.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 7
  %18976 = load i8, i8* %scevgep20.7.50, align 1
  %conv68.7.50 = zext i8 %18976 to i32
  %18977 = load i8, i8* %arrayidx70.50, align 1
  %conv71.7.50 = zext i8 %18977 to i32
  %xor72.7.50 = xor i32 %conv71.7.50, %conv68.7.50
  %conv73.7.50 = trunc i32 %xor72.7.50 to i8
  store i8 %conv73.7.50, i8* %arrayidx70.50, align 1
  %scevgep20.8.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 8
  %18978 = load i8, i8* %scevgep20.8.50, align 1
  %conv68.8.50 = zext i8 %18978 to i32
  %18979 = load i8, i8* %arrayidx70.50, align 1
  %conv71.8.50 = zext i8 %18979 to i32
  %xor72.8.50 = xor i32 %conv71.8.50, %conv68.8.50
  %conv73.8.50 = trunc i32 %xor72.8.50 to i8
  store i8 %conv73.8.50, i8* %arrayidx70.50, align 1
  %scevgep20.9.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 9
  %18980 = load i8, i8* %scevgep20.9.50, align 1
  %conv68.9.50 = zext i8 %18980 to i32
  %18981 = load i8, i8* %arrayidx70.50, align 1
  %conv71.9.50 = zext i8 %18981 to i32
  %xor72.9.50 = xor i32 %conv71.9.50, %conv68.9.50
  %conv73.9.50 = trunc i32 %xor72.9.50 to i8
  store i8 %conv73.9.50, i8* %arrayidx70.50, align 1
  %scevgep20.10.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 10
  %18982 = load i8, i8* %scevgep20.10.50, align 1
  %conv68.10.50 = zext i8 %18982 to i32
  %18983 = load i8, i8* %arrayidx70.50, align 1
  %conv71.10.50 = zext i8 %18983 to i32
  %xor72.10.50 = xor i32 %conv71.10.50, %conv68.10.50
  %conv73.10.50 = trunc i32 %xor72.10.50 to i8
  store i8 %conv73.10.50, i8* %arrayidx70.50, align 1
  %scevgep20.11.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 11
  %18984 = load i8, i8* %scevgep20.11.50, align 1
  %conv68.11.50 = zext i8 %18984 to i32
  %18985 = load i8, i8* %arrayidx70.50, align 1
  %conv71.11.50 = zext i8 %18985 to i32
  %xor72.11.50 = xor i32 %conv71.11.50, %conv68.11.50
  %conv73.11.50 = trunc i32 %xor72.11.50 to i8
  store i8 %conv73.11.50, i8* %arrayidx70.50, align 1
  %scevgep20.12.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 12
  %18986 = load i8, i8* %scevgep20.12.50, align 1
  %conv68.12.50 = zext i8 %18986 to i32
  %18987 = load i8, i8* %arrayidx70.50, align 1
  %conv71.12.50 = zext i8 %18987 to i32
  %xor72.12.50 = xor i32 %conv71.12.50, %conv68.12.50
  %conv73.12.50 = trunc i32 %xor72.12.50 to i8
  store i8 %conv73.12.50, i8* %arrayidx70.50, align 1
  %scevgep20.13.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 13
  %18988 = load i8, i8* %scevgep20.13.50, align 1
  %conv68.13.50 = zext i8 %18988 to i32
  %18989 = load i8, i8* %arrayidx70.50, align 1
  %conv71.13.50 = zext i8 %18989 to i32
  %xor72.13.50 = xor i32 %conv71.13.50, %conv68.13.50
  %conv73.13.50 = trunc i32 %xor72.13.50 to i8
  store i8 %conv73.13.50, i8* %arrayidx70.50, align 1
  %scevgep20.14.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 14
  %18990 = load i8, i8* %scevgep20.14.50, align 1
  %conv68.14.50 = zext i8 %18990 to i32
  %18991 = load i8, i8* %arrayidx70.50, align 1
  %conv71.14.50 = zext i8 %18991 to i32
  %xor72.14.50 = xor i32 %conv71.14.50, %conv68.14.50
  %conv73.14.50 = trunc i32 %xor72.14.50 to i8
  store i8 %conv73.14.50, i8* %arrayidx70.50, align 1
  %scevgep20.15.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 15
  %18992 = load i8, i8* %scevgep20.15.50, align 1
  %conv68.15.50 = zext i8 %18992 to i32
  %18993 = load i8, i8* %arrayidx70.50, align 1
  %conv71.15.50 = zext i8 %18993 to i32
  %xor72.15.50 = xor i32 %conv71.15.50, %conv68.15.50
  %conv73.15.50 = trunc i32 %xor72.15.50 to i8
  store i8 %conv73.15.50, i8* %arrayidx70.50, align 1
  %scevgep20.16.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 16
  %18994 = load i8, i8* %scevgep20.16.50, align 1
  %conv68.16.50 = zext i8 %18994 to i32
  %18995 = load i8, i8* %arrayidx70.50, align 1
  %conv71.16.50 = zext i8 %18995 to i32
  %xor72.16.50 = xor i32 %conv71.16.50, %conv68.16.50
  %conv73.16.50 = trunc i32 %xor72.16.50 to i8
  store i8 %conv73.16.50, i8* %arrayidx70.50, align 1
  %scevgep20.17.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 17
  %18996 = load i8, i8* %scevgep20.17.50, align 1
  %conv68.17.50 = zext i8 %18996 to i32
  %18997 = load i8, i8* %arrayidx70.50, align 1
  %conv71.17.50 = zext i8 %18997 to i32
  %xor72.17.50 = xor i32 %conv71.17.50, %conv68.17.50
  %conv73.17.50 = trunc i32 %xor72.17.50 to i8
  store i8 %conv73.17.50, i8* %arrayidx70.50, align 1
  %scevgep20.18.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 18
  %18998 = load i8, i8* %scevgep20.18.50, align 1
  %conv68.18.50 = zext i8 %18998 to i32
  %18999 = load i8, i8* %arrayidx70.50, align 1
  %conv71.18.50 = zext i8 %18999 to i32
  %xor72.18.50 = xor i32 %conv71.18.50, %conv68.18.50
  %conv73.18.50 = trunc i32 %xor72.18.50 to i8
  store i8 %conv73.18.50, i8* %arrayidx70.50, align 1
  %scevgep20.19.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 19
  %19000 = load i8, i8* %scevgep20.19.50, align 1
  %conv68.19.50 = zext i8 %19000 to i32
  %19001 = load i8, i8* %arrayidx70.50, align 1
  %conv71.19.50 = zext i8 %19001 to i32
  %xor72.19.50 = xor i32 %conv71.19.50, %conv68.19.50
  %conv73.19.50 = trunc i32 %xor72.19.50 to i8
  store i8 %conv73.19.50, i8* %arrayidx70.50, align 1
  %scevgep20.20.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 20
  %19002 = load i8, i8* %scevgep20.20.50, align 1
  %conv68.20.50 = zext i8 %19002 to i32
  %19003 = load i8, i8* %arrayidx70.50, align 1
  %conv71.20.50 = zext i8 %19003 to i32
  %xor72.20.50 = xor i32 %conv71.20.50, %conv68.20.50
  %conv73.20.50 = trunc i32 %xor72.20.50 to i8
  store i8 %conv73.20.50, i8* %arrayidx70.50, align 1
  %scevgep20.21.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 21
  %19004 = load i8, i8* %scevgep20.21.50, align 1
  %conv68.21.50 = zext i8 %19004 to i32
  %19005 = load i8, i8* %arrayidx70.50, align 1
  %conv71.21.50 = zext i8 %19005 to i32
  %xor72.21.50 = xor i32 %conv71.21.50, %conv68.21.50
  %conv73.21.50 = trunc i32 %xor72.21.50 to i8
  store i8 %conv73.21.50, i8* %arrayidx70.50, align 1
  %scevgep20.22.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 22
  %19006 = load i8, i8* %scevgep20.22.50, align 1
  %conv68.22.50 = zext i8 %19006 to i32
  %19007 = load i8, i8* %arrayidx70.50, align 1
  %conv71.22.50 = zext i8 %19007 to i32
  %xor72.22.50 = xor i32 %conv71.22.50, %conv68.22.50
  %conv73.22.50 = trunc i32 %xor72.22.50 to i8
  store i8 %conv73.22.50, i8* %arrayidx70.50, align 1
  %scevgep20.23.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 23
  %19008 = load i8, i8* %scevgep20.23.50, align 1
  %conv68.23.50 = zext i8 %19008 to i32
  %19009 = load i8, i8* %arrayidx70.50, align 1
  %conv71.23.50 = zext i8 %19009 to i32
  %xor72.23.50 = xor i32 %conv71.23.50, %conv68.23.50
  %conv73.23.50 = trunc i32 %xor72.23.50 to i8
  store i8 %conv73.23.50, i8* %arrayidx70.50, align 1
  %scevgep20.24.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 24
  %19010 = load i8, i8* %scevgep20.24.50, align 1
  %conv68.24.50 = zext i8 %19010 to i32
  %19011 = load i8, i8* %arrayidx70.50, align 1
  %conv71.24.50 = zext i8 %19011 to i32
  %xor72.24.50 = xor i32 %conv71.24.50, %conv68.24.50
  %conv73.24.50 = trunc i32 %xor72.24.50 to i8
  store i8 %conv73.24.50, i8* %arrayidx70.50, align 1
  %scevgep20.25.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 25
  %19012 = load i8, i8* %scevgep20.25.50, align 1
  %conv68.25.50 = zext i8 %19012 to i32
  %19013 = load i8, i8* %arrayidx70.50, align 1
  %conv71.25.50 = zext i8 %19013 to i32
  %xor72.25.50 = xor i32 %conv71.25.50, %conv68.25.50
  %conv73.25.50 = trunc i32 %xor72.25.50 to i8
  store i8 %conv73.25.50, i8* %arrayidx70.50, align 1
  %scevgep20.26.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 26
  %19014 = load i8, i8* %scevgep20.26.50, align 1
  %conv68.26.50 = zext i8 %19014 to i32
  %19015 = load i8, i8* %arrayidx70.50, align 1
  %conv71.26.50 = zext i8 %19015 to i32
  %xor72.26.50 = xor i32 %conv71.26.50, %conv68.26.50
  %conv73.26.50 = trunc i32 %xor72.26.50 to i8
  store i8 %conv73.26.50, i8* %arrayidx70.50, align 1
  %scevgep20.27.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 27
  %19016 = load i8, i8* %scevgep20.27.50, align 1
  %conv68.27.50 = zext i8 %19016 to i32
  %19017 = load i8, i8* %arrayidx70.50, align 1
  %conv71.27.50 = zext i8 %19017 to i32
  %xor72.27.50 = xor i32 %conv71.27.50, %conv68.27.50
  %conv73.27.50 = trunc i32 %xor72.27.50 to i8
  store i8 %conv73.27.50, i8* %arrayidx70.50, align 1
  %scevgep20.28.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 28
  %19018 = load i8, i8* %scevgep20.28.50, align 1
  %conv68.28.50 = zext i8 %19018 to i32
  %19019 = load i8, i8* %arrayidx70.50, align 1
  %conv71.28.50 = zext i8 %19019 to i32
  %xor72.28.50 = xor i32 %conv71.28.50, %conv68.28.50
  %conv73.28.50 = trunc i32 %xor72.28.50 to i8
  store i8 %conv73.28.50, i8* %arrayidx70.50, align 1
  %scevgep20.29.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 29
  %19020 = load i8, i8* %scevgep20.29.50, align 1
  %conv68.29.50 = zext i8 %19020 to i32
  %19021 = load i8, i8* %arrayidx70.50, align 1
  %conv71.29.50 = zext i8 %19021 to i32
  %xor72.29.50 = xor i32 %conv71.29.50, %conv68.29.50
  %conv73.29.50 = trunc i32 %xor72.29.50 to i8
  store i8 %conv73.29.50, i8* %arrayidx70.50, align 1
  %scevgep20.30.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 30
  %19022 = load i8, i8* %scevgep20.30.50, align 1
  %conv68.30.50 = zext i8 %19022 to i32
  %19023 = load i8, i8* %arrayidx70.50, align 1
  %conv71.30.50 = zext i8 %19023 to i32
  %xor72.30.50 = xor i32 %conv71.30.50, %conv68.30.50
  %conv73.30.50 = trunc i32 %xor72.30.50 to i8
  store i8 %conv73.30.50, i8* %arrayidx70.50, align 1
  %scevgep20.31.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 31
  %19024 = load i8, i8* %scevgep20.31.50, align 1
  %conv68.31.50 = zext i8 %19024 to i32
  %19025 = load i8, i8* %arrayidx70.50, align 1
  %conv71.31.50 = zext i8 %19025 to i32
  %xor72.31.50 = xor i32 %conv71.31.50, %conv68.31.50
  %conv73.31.50 = trunc i32 %xor72.31.50 to i8
  store i8 %conv73.31.50, i8* %arrayidx70.50, align 1
  %scevgep20.32.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 32
  %19026 = load i8, i8* %scevgep20.32.50, align 1
  %conv68.32.50 = zext i8 %19026 to i32
  %19027 = load i8, i8* %arrayidx70.50, align 1
  %conv71.32.50 = zext i8 %19027 to i32
  %xor72.32.50 = xor i32 %conv71.32.50, %conv68.32.50
  %conv73.32.50 = trunc i32 %xor72.32.50 to i8
  store i8 %conv73.32.50, i8* %arrayidx70.50, align 1
  %scevgep20.33.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 33
  %19028 = load i8, i8* %scevgep20.33.50, align 1
  %conv68.33.50 = zext i8 %19028 to i32
  %19029 = load i8, i8* %arrayidx70.50, align 1
  %conv71.33.50 = zext i8 %19029 to i32
  %xor72.33.50 = xor i32 %conv71.33.50, %conv68.33.50
  %conv73.33.50 = trunc i32 %xor72.33.50 to i8
  store i8 %conv73.33.50, i8* %arrayidx70.50, align 1
  %scevgep20.34.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 34
  %19030 = load i8, i8* %scevgep20.34.50, align 1
  %conv68.34.50 = zext i8 %19030 to i32
  %19031 = load i8, i8* %arrayidx70.50, align 1
  %conv71.34.50 = zext i8 %19031 to i32
  %xor72.34.50 = xor i32 %conv71.34.50, %conv68.34.50
  %conv73.34.50 = trunc i32 %xor72.34.50 to i8
  store i8 %conv73.34.50, i8* %arrayidx70.50, align 1
  %scevgep20.35.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 35
  %19032 = load i8, i8* %scevgep20.35.50, align 1
  %conv68.35.50 = zext i8 %19032 to i32
  %19033 = load i8, i8* %arrayidx70.50, align 1
  %conv71.35.50 = zext i8 %19033 to i32
  %xor72.35.50 = xor i32 %conv71.35.50, %conv68.35.50
  %conv73.35.50 = trunc i32 %xor72.35.50 to i8
  store i8 %conv73.35.50, i8* %arrayidx70.50, align 1
  %scevgep20.36.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 36
  %19034 = load i8, i8* %scevgep20.36.50, align 1
  %conv68.36.50 = zext i8 %19034 to i32
  %19035 = load i8, i8* %arrayidx70.50, align 1
  %conv71.36.50 = zext i8 %19035 to i32
  %xor72.36.50 = xor i32 %conv71.36.50, %conv68.36.50
  %conv73.36.50 = trunc i32 %xor72.36.50 to i8
  store i8 %conv73.36.50, i8* %arrayidx70.50, align 1
  %scevgep20.37.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 37
  %19036 = load i8, i8* %scevgep20.37.50, align 1
  %conv68.37.50 = zext i8 %19036 to i32
  %19037 = load i8, i8* %arrayidx70.50, align 1
  %conv71.37.50 = zext i8 %19037 to i32
  %xor72.37.50 = xor i32 %conv71.37.50, %conv68.37.50
  %conv73.37.50 = trunc i32 %xor72.37.50 to i8
  store i8 %conv73.37.50, i8* %arrayidx70.50, align 1
  %scevgep20.38.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 38
  %19038 = load i8, i8* %scevgep20.38.50, align 1
  %conv68.38.50 = zext i8 %19038 to i32
  %19039 = load i8, i8* %arrayidx70.50, align 1
  %conv71.38.50 = zext i8 %19039 to i32
  %xor72.38.50 = xor i32 %conv71.38.50, %conv68.38.50
  %conv73.38.50 = trunc i32 %xor72.38.50 to i8
  store i8 %conv73.38.50, i8* %arrayidx70.50, align 1
  %scevgep20.39.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 39
  %19040 = load i8, i8* %scevgep20.39.50, align 1
  %conv68.39.50 = zext i8 %19040 to i32
  %19041 = load i8, i8* %arrayidx70.50, align 1
  %conv71.39.50 = zext i8 %19041 to i32
  %xor72.39.50 = xor i32 %conv71.39.50, %conv68.39.50
  %conv73.39.50 = trunc i32 %xor72.39.50 to i8
  store i8 %conv73.39.50, i8* %arrayidx70.50, align 1
  %scevgep20.40.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 40
  %19042 = load i8, i8* %scevgep20.40.50, align 1
  %conv68.40.50 = zext i8 %19042 to i32
  %19043 = load i8, i8* %arrayidx70.50, align 1
  %conv71.40.50 = zext i8 %19043 to i32
  %xor72.40.50 = xor i32 %conv71.40.50, %conv68.40.50
  %conv73.40.50 = trunc i32 %xor72.40.50 to i8
  store i8 %conv73.40.50, i8* %arrayidx70.50, align 1
  %scevgep20.41.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 41
  %19044 = load i8, i8* %scevgep20.41.50, align 1
  %conv68.41.50 = zext i8 %19044 to i32
  %19045 = load i8, i8* %arrayidx70.50, align 1
  %conv71.41.50 = zext i8 %19045 to i32
  %xor72.41.50 = xor i32 %conv71.41.50, %conv68.41.50
  %conv73.41.50 = trunc i32 %xor72.41.50 to i8
  store i8 %conv73.41.50, i8* %arrayidx70.50, align 1
  %scevgep20.42.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 42
  %19046 = load i8, i8* %scevgep20.42.50, align 1
  %conv68.42.50 = zext i8 %19046 to i32
  %19047 = load i8, i8* %arrayidx70.50, align 1
  %conv71.42.50 = zext i8 %19047 to i32
  %xor72.42.50 = xor i32 %conv71.42.50, %conv68.42.50
  %conv73.42.50 = trunc i32 %xor72.42.50 to i8
  store i8 %conv73.42.50, i8* %arrayidx70.50, align 1
  %scevgep20.43.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 43
  %19048 = load i8, i8* %scevgep20.43.50, align 1
  %conv68.43.50 = zext i8 %19048 to i32
  %19049 = load i8, i8* %arrayidx70.50, align 1
  %conv71.43.50 = zext i8 %19049 to i32
  %xor72.43.50 = xor i32 %conv71.43.50, %conv68.43.50
  %conv73.43.50 = trunc i32 %xor72.43.50 to i8
  store i8 %conv73.43.50, i8* %arrayidx70.50, align 1
  %scevgep20.44.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 44
  %19050 = load i8, i8* %scevgep20.44.50, align 1
  %conv68.44.50 = zext i8 %19050 to i32
  %19051 = load i8, i8* %arrayidx70.50, align 1
  %conv71.44.50 = zext i8 %19051 to i32
  %xor72.44.50 = xor i32 %conv71.44.50, %conv68.44.50
  %conv73.44.50 = trunc i32 %xor72.44.50 to i8
  store i8 %conv73.44.50, i8* %arrayidx70.50, align 1
  %scevgep20.45.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 45
  %19052 = load i8, i8* %scevgep20.45.50, align 1
  %conv68.45.50 = zext i8 %19052 to i32
  %19053 = load i8, i8* %arrayidx70.50, align 1
  %conv71.45.50 = zext i8 %19053 to i32
  %xor72.45.50 = xor i32 %conv71.45.50, %conv68.45.50
  %conv73.45.50 = trunc i32 %xor72.45.50 to i8
  store i8 %conv73.45.50, i8* %arrayidx70.50, align 1
  %scevgep20.46.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 46
  %19054 = load i8, i8* %scevgep20.46.50, align 1
  %conv68.46.50 = zext i8 %19054 to i32
  %19055 = load i8, i8* %arrayidx70.50, align 1
  %conv71.46.50 = zext i8 %19055 to i32
  %xor72.46.50 = xor i32 %conv71.46.50, %conv68.46.50
  %conv73.46.50 = trunc i32 %xor72.46.50 to i8
  store i8 %conv73.46.50, i8* %arrayidx70.50, align 1
  %scevgep20.47.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 47
  %19056 = load i8, i8* %scevgep20.47.50, align 1
  %conv68.47.50 = zext i8 %19056 to i32
  %19057 = load i8, i8* %arrayidx70.50, align 1
  %conv71.47.50 = zext i8 %19057 to i32
  %xor72.47.50 = xor i32 %conv71.47.50, %conv68.47.50
  %conv73.47.50 = trunc i32 %xor72.47.50 to i8
  store i8 %conv73.47.50, i8* %arrayidx70.50, align 1
  %scevgep20.48.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 48
  %19058 = load i8, i8* %scevgep20.48.50, align 1
  %conv68.48.50 = zext i8 %19058 to i32
  %19059 = load i8, i8* %arrayidx70.50, align 1
  %conv71.48.50 = zext i8 %19059 to i32
  %xor72.48.50 = xor i32 %conv71.48.50, %conv68.48.50
  %conv73.48.50 = trunc i32 %xor72.48.50 to i8
  store i8 %conv73.48.50, i8* %arrayidx70.50, align 1
  %scevgep20.49.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 49
  %19060 = load i8, i8* %scevgep20.49.50, align 1
  %conv68.49.50 = zext i8 %19060 to i32
  %19061 = load i8, i8* %arrayidx70.50, align 1
  %conv71.49.50 = zext i8 %19061 to i32
  %xor72.49.50 = xor i32 %conv71.49.50, %conv68.49.50
  %conv73.49.50 = trunc i32 %xor72.49.50 to i8
  store i8 %conv73.49.50, i8* %arrayidx70.50, align 1
  %scevgep20.51.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 51
  %19062 = load i8, i8* %scevgep20.51.50, align 1
  %conv68.51.50 = zext i8 %19062 to i32
  %19063 = load i8, i8* %arrayidx70.50, align 1
  %conv71.51.50 = zext i8 %19063 to i32
  %xor72.51.50 = xor i32 %conv71.51.50, %conv68.51.50
  %conv73.51.50 = trunc i32 %xor72.51.50 to i8
  store i8 %conv73.51.50, i8* %arrayidx70.50, align 1
  %scevgep20.52.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 52
  %19064 = load i8, i8* %scevgep20.52.50, align 1
  %conv68.52.50 = zext i8 %19064 to i32
  %19065 = load i8, i8* %arrayidx70.50, align 1
  %conv71.52.50 = zext i8 %19065 to i32
  %xor72.52.50 = xor i32 %conv71.52.50, %conv68.52.50
  %conv73.52.50 = trunc i32 %xor72.52.50 to i8
  store i8 %conv73.52.50, i8* %arrayidx70.50, align 1
  %scevgep20.53.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 53
  %19066 = load i8, i8* %scevgep20.53.50, align 1
  %conv68.53.50 = zext i8 %19066 to i32
  %19067 = load i8, i8* %arrayidx70.50, align 1
  %conv71.53.50 = zext i8 %19067 to i32
  %xor72.53.50 = xor i32 %conv71.53.50, %conv68.53.50
  %conv73.53.50 = trunc i32 %xor72.53.50 to i8
  store i8 %conv73.53.50, i8* %arrayidx70.50, align 1
  %scevgep20.54.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 54
  %19068 = load i8, i8* %scevgep20.54.50, align 1
  %conv68.54.50 = zext i8 %19068 to i32
  %19069 = load i8, i8* %arrayidx70.50, align 1
  %conv71.54.50 = zext i8 %19069 to i32
  %xor72.54.50 = xor i32 %conv71.54.50, %conv68.54.50
  %conv73.54.50 = trunc i32 %xor72.54.50 to i8
  store i8 %conv73.54.50, i8* %arrayidx70.50, align 1
  %scevgep20.55.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 55
  %19070 = load i8, i8* %scevgep20.55.50, align 1
  %conv68.55.50 = zext i8 %19070 to i32
  %19071 = load i8, i8* %arrayidx70.50, align 1
  %conv71.55.50 = zext i8 %19071 to i32
  %xor72.55.50 = xor i32 %conv71.55.50, %conv68.55.50
  %conv73.55.50 = trunc i32 %xor72.55.50 to i8
  store i8 %conv73.55.50, i8* %arrayidx70.50, align 1
  %scevgep20.56.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 56
  %19072 = load i8, i8* %scevgep20.56.50, align 1
  %conv68.56.50 = zext i8 %19072 to i32
  %19073 = load i8, i8* %arrayidx70.50, align 1
  %conv71.56.50 = zext i8 %19073 to i32
  %xor72.56.50 = xor i32 %conv71.56.50, %conv68.56.50
  %conv73.56.50 = trunc i32 %xor72.56.50 to i8
  store i8 %conv73.56.50, i8* %arrayidx70.50, align 1
  %scevgep20.57.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 57
  %19074 = load i8, i8* %scevgep20.57.50, align 1
  %conv68.57.50 = zext i8 %19074 to i32
  %19075 = load i8, i8* %arrayidx70.50, align 1
  %conv71.57.50 = zext i8 %19075 to i32
  %xor72.57.50 = xor i32 %conv71.57.50, %conv68.57.50
  %conv73.57.50 = trunc i32 %xor72.57.50 to i8
  store i8 %conv73.57.50, i8* %arrayidx70.50, align 1
  %scevgep20.58.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 58
  %19076 = load i8, i8* %scevgep20.58.50, align 1
  %conv68.58.50 = zext i8 %19076 to i32
  %19077 = load i8, i8* %arrayidx70.50, align 1
  %conv71.58.50 = zext i8 %19077 to i32
  %xor72.58.50 = xor i32 %conv71.58.50, %conv68.58.50
  %conv73.58.50 = trunc i32 %xor72.58.50 to i8
  store i8 %conv73.58.50, i8* %arrayidx70.50, align 1
  %scevgep20.59.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 59
  %19078 = load i8, i8* %scevgep20.59.50, align 1
  %conv68.59.50 = zext i8 %19078 to i32
  %19079 = load i8, i8* %arrayidx70.50, align 1
  %conv71.59.50 = zext i8 %19079 to i32
  %xor72.59.50 = xor i32 %conv71.59.50, %conv68.59.50
  %conv73.59.50 = trunc i32 %xor72.59.50 to i8
  store i8 %conv73.59.50, i8* %arrayidx70.50, align 1
  %scevgep20.60.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 0, i64 60
  %19080 = load i8, i8* %scevgep20.60.50, align 1
  %conv68.60.50 = zext i8 %19080 to i32
  %19081 = load i8, i8* %arrayidx70.50, align 1
  %conv71.60.50 = zext i8 %19081 to i32
  %xor72.60.50 = xor i32 %conv71.60.50, %conv68.60.50
  %conv73.60.50 = trunc i32 %xor72.60.50 to i8
  store i8 %conv73.60.50, i8* %arrayidx70.50, align 1
  %scevgep19.50 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %18959, i64 0, i64 1, i64 0
  %19082 = bitcast i8* %scevgep19.50 to [61 x [61 x i8]]*
  %arrayidx51.51 = getelementptr inbounds i8, i8* %a, i64 51
  %19083 = load i8, i8* %arrayidx51.51, align 1
  %arrayidx53.51 = getelementptr inbounds i8, i8* %b, i64 51
  %19084 = load i8, i8* %arrayidx53.51, align 1
  %call54.51 = call zeroext i8 @mult(i8 zeroext %19083, i8 zeroext %19084)
  %arrayidx56.51 = getelementptr inbounds i8, i8* %c, i64 51
  store i8 %call54.51, i8* %arrayidx56.51, align 1
  %arrayidx70.51 = getelementptr inbounds i8, i8* %c, i64 51
  %scevgep20.51554 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 0
  %19085 = load i8, i8* %scevgep20.51554, align 1
  %conv68.51555 = zext i8 %19085 to i32
  %19086 = load i8, i8* %arrayidx70.51, align 1
  %conv71.51556 = zext i8 %19086 to i32
  %xor72.51557 = xor i32 %conv71.51556, %conv68.51555
  %conv73.51558 = trunc i32 %xor72.51557 to i8
  store i8 %conv73.51558, i8* %arrayidx70.51, align 1
  %scevgep20.1.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 1
  %19087 = load i8, i8* %scevgep20.1.51, align 1
  %conv68.1.51 = zext i8 %19087 to i32
  %19088 = load i8, i8* %arrayidx70.51, align 1
  %conv71.1.51 = zext i8 %19088 to i32
  %xor72.1.51 = xor i32 %conv71.1.51, %conv68.1.51
  %conv73.1.51 = trunc i32 %xor72.1.51 to i8
  store i8 %conv73.1.51, i8* %arrayidx70.51, align 1
  %scevgep20.2.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 2
  %19089 = load i8, i8* %scevgep20.2.51, align 1
  %conv68.2.51 = zext i8 %19089 to i32
  %19090 = load i8, i8* %arrayidx70.51, align 1
  %conv71.2.51 = zext i8 %19090 to i32
  %xor72.2.51 = xor i32 %conv71.2.51, %conv68.2.51
  %conv73.2.51 = trunc i32 %xor72.2.51 to i8
  store i8 %conv73.2.51, i8* %arrayidx70.51, align 1
  %scevgep20.3.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 3
  %19091 = load i8, i8* %scevgep20.3.51, align 1
  %conv68.3.51 = zext i8 %19091 to i32
  %19092 = load i8, i8* %arrayidx70.51, align 1
  %conv71.3.51 = zext i8 %19092 to i32
  %xor72.3.51 = xor i32 %conv71.3.51, %conv68.3.51
  %conv73.3.51 = trunc i32 %xor72.3.51 to i8
  store i8 %conv73.3.51, i8* %arrayidx70.51, align 1
  %scevgep20.4.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 4
  %19093 = load i8, i8* %scevgep20.4.51, align 1
  %conv68.4.51 = zext i8 %19093 to i32
  %19094 = load i8, i8* %arrayidx70.51, align 1
  %conv71.4.51 = zext i8 %19094 to i32
  %xor72.4.51 = xor i32 %conv71.4.51, %conv68.4.51
  %conv73.4.51 = trunc i32 %xor72.4.51 to i8
  store i8 %conv73.4.51, i8* %arrayidx70.51, align 1
  %scevgep20.5.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 5
  %19095 = load i8, i8* %scevgep20.5.51, align 1
  %conv68.5.51 = zext i8 %19095 to i32
  %19096 = load i8, i8* %arrayidx70.51, align 1
  %conv71.5.51 = zext i8 %19096 to i32
  %xor72.5.51 = xor i32 %conv71.5.51, %conv68.5.51
  %conv73.5.51 = trunc i32 %xor72.5.51 to i8
  store i8 %conv73.5.51, i8* %arrayidx70.51, align 1
  %scevgep20.6.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 6
  %19097 = load i8, i8* %scevgep20.6.51, align 1
  %conv68.6.51 = zext i8 %19097 to i32
  %19098 = load i8, i8* %arrayidx70.51, align 1
  %conv71.6.51 = zext i8 %19098 to i32
  %xor72.6.51 = xor i32 %conv71.6.51, %conv68.6.51
  %conv73.6.51 = trunc i32 %xor72.6.51 to i8
  store i8 %conv73.6.51, i8* %arrayidx70.51, align 1
  %scevgep20.7.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 7
  %19099 = load i8, i8* %scevgep20.7.51, align 1
  %conv68.7.51 = zext i8 %19099 to i32
  %19100 = load i8, i8* %arrayidx70.51, align 1
  %conv71.7.51 = zext i8 %19100 to i32
  %xor72.7.51 = xor i32 %conv71.7.51, %conv68.7.51
  %conv73.7.51 = trunc i32 %xor72.7.51 to i8
  store i8 %conv73.7.51, i8* %arrayidx70.51, align 1
  %scevgep20.8.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 8
  %19101 = load i8, i8* %scevgep20.8.51, align 1
  %conv68.8.51 = zext i8 %19101 to i32
  %19102 = load i8, i8* %arrayidx70.51, align 1
  %conv71.8.51 = zext i8 %19102 to i32
  %xor72.8.51 = xor i32 %conv71.8.51, %conv68.8.51
  %conv73.8.51 = trunc i32 %xor72.8.51 to i8
  store i8 %conv73.8.51, i8* %arrayidx70.51, align 1
  %scevgep20.9.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 9
  %19103 = load i8, i8* %scevgep20.9.51, align 1
  %conv68.9.51 = zext i8 %19103 to i32
  %19104 = load i8, i8* %arrayidx70.51, align 1
  %conv71.9.51 = zext i8 %19104 to i32
  %xor72.9.51 = xor i32 %conv71.9.51, %conv68.9.51
  %conv73.9.51 = trunc i32 %xor72.9.51 to i8
  store i8 %conv73.9.51, i8* %arrayidx70.51, align 1
  %scevgep20.10.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 10
  %19105 = load i8, i8* %scevgep20.10.51, align 1
  %conv68.10.51 = zext i8 %19105 to i32
  %19106 = load i8, i8* %arrayidx70.51, align 1
  %conv71.10.51 = zext i8 %19106 to i32
  %xor72.10.51 = xor i32 %conv71.10.51, %conv68.10.51
  %conv73.10.51 = trunc i32 %xor72.10.51 to i8
  store i8 %conv73.10.51, i8* %arrayidx70.51, align 1
  %scevgep20.11.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 11
  %19107 = load i8, i8* %scevgep20.11.51, align 1
  %conv68.11.51 = zext i8 %19107 to i32
  %19108 = load i8, i8* %arrayidx70.51, align 1
  %conv71.11.51 = zext i8 %19108 to i32
  %xor72.11.51 = xor i32 %conv71.11.51, %conv68.11.51
  %conv73.11.51 = trunc i32 %xor72.11.51 to i8
  store i8 %conv73.11.51, i8* %arrayidx70.51, align 1
  %scevgep20.12.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 12
  %19109 = load i8, i8* %scevgep20.12.51, align 1
  %conv68.12.51 = zext i8 %19109 to i32
  %19110 = load i8, i8* %arrayidx70.51, align 1
  %conv71.12.51 = zext i8 %19110 to i32
  %xor72.12.51 = xor i32 %conv71.12.51, %conv68.12.51
  %conv73.12.51 = trunc i32 %xor72.12.51 to i8
  store i8 %conv73.12.51, i8* %arrayidx70.51, align 1
  %scevgep20.13.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 13
  %19111 = load i8, i8* %scevgep20.13.51, align 1
  %conv68.13.51 = zext i8 %19111 to i32
  %19112 = load i8, i8* %arrayidx70.51, align 1
  %conv71.13.51 = zext i8 %19112 to i32
  %xor72.13.51 = xor i32 %conv71.13.51, %conv68.13.51
  %conv73.13.51 = trunc i32 %xor72.13.51 to i8
  store i8 %conv73.13.51, i8* %arrayidx70.51, align 1
  %scevgep20.14.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 14
  %19113 = load i8, i8* %scevgep20.14.51, align 1
  %conv68.14.51 = zext i8 %19113 to i32
  %19114 = load i8, i8* %arrayidx70.51, align 1
  %conv71.14.51 = zext i8 %19114 to i32
  %xor72.14.51 = xor i32 %conv71.14.51, %conv68.14.51
  %conv73.14.51 = trunc i32 %xor72.14.51 to i8
  store i8 %conv73.14.51, i8* %arrayidx70.51, align 1
  %scevgep20.15.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 15
  %19115 = load i8, i8* %scevgep20.15.51, align 1
  %conv68.15.51 = zext i8 %19115 to i32
  %19116 = load i8, i8* %arrayidx70.51, align 1
  %conv71.15.51 = zext i8 %19116 to i32
  %xor72.15.51 = xor i32 %conv71.15.51, %conv68.15.51
  %conv73.15.51 = trunc i32 %xor72.15.51 to i8
  store i8 %conv73.15.51, i8* %arrayidx70.51, align 1
  %scevgep20.16.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 16
  %19117 = load i8, i8* %scevgep20.16.51, align 1
  %conv68.16.51 = zext i8 %19117 to i32
  %19118 = load i8, i8* %arrayidx70.51, align 1
  %conv71.16.51 = zext i8 %19118 to i32
  %xor72.16.51 = xor i32 %conv71.16.51, %conv68.16.51
  %conv73.16.51 = trunc i32 %xor72.16.51 to i8
  store i8 %conv73.16.51, i8* %arrayidx70.51, align 1
  %scevgep20.17.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 17
  %19119 = load i8, i8* %scevgep20.17.51, align 1
  %conv68.17.51 = zext i8 %19119 to i32
  %19120 = load i8, i8* %arrayidx70.51, align 1
  %conv71.17.51 = zext i8 %19120 to i32
  %xor72.17.51 = xor i32 %conv71.17.51, %conv68.17.51
  %conv73.17.51 = trunc i32 %xor72.17.51 to i8
  store i8 %conv73.17.51, i8* %arrayidx70.51, align 1
  %scevgep20.18.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 18
  %19121 = load i8, i8* %scevgep20.18.51, align 1
  %conv68.18.51 = zext i8 %19121 to i32
  %19122 = load i8, i8* %arrayidx70.51, align 1
  %conv71.18.51 = zext i8 %19122 to i32
  %xor72.18.51 = xor i32 %conv71.18.51, %conv68.18.51
  %conv73.18.51 = trunc i32 %xor72.18.51 to i8
  store i8 %conv73.18.51, i8* %arrayidx70.51, align 1
  %scevgep20.19.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 19
  %19123 = load i8, i8* %scevgep20.19.51, align 1
  %conv68.19.51 = zext i8 %19123 to i32
  %19124 = load i8, i8* %arrayidx70.51, align 1
  %conv71.19.51 = zext i8 %19124 to i32
  %xor72.19.51 = xor i32 %conv71.19.51, %conv68.19.51
  %conv73.19.51 = trunc i32 %xor72.19.51 to i8
  store i8 %conv73.19.51, i8* %arrayidx70.51, align 1
  %scevgep20.20.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 20
  %19125 = load i8, i8* %scevgep20.20.51, align 1
  %conv68.20.51 = zext i8 %19125 to i32
  %19126 = load i8, i8* %arrayidx70.51, align 1
  %conv71.20.51 = zext i8 %19126 to i32
  %xor72.20.51 = xor i32 %conv71.20.51, %conv68.20.51
  %conv73.20.51 = trunc i32 %xor72.20.51 to i8
  store i8 %conv73.20.51, i8* %arrayidx70.51, align 1
  %scevgep20.21.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 21
  %19127 = load i8, i8* %scevgep20.21.51, align 1
  %conv68.21.51 = zext i8 %19127 to i32
  %19128 = load i8, i8* %arrayidx70.51, align 1
  %conv71.21.51 = zext i8 %19128 to i32
  %xor72.21.51 = xor i32 %conv71.21.51, %conv68.21.51
  %conv73.21.51 = trunc i32 %xor72.21.51 to i8
  store i8 %conv73.21.51, i8* %arrayidx70.51, align 1
  %scevgep20.22.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 22
  %19129 = load i8, i8* %scevgep20.22.51, align 1
  %conv68.22.51 = zext i8 %19129 to i32
  %19130 = load i8, i8* %arrayidx70.51, align 1
  %conv71.22.51 = zext i8 %19130 to i32
  %xor72.22.51 = xor i32 %conv71.22.51, %conv68.22.51
  %conv73.22.51 = trunc i32 %xor72.22.51 to i8
  store i8 %conv73.22.51, i8* %arrayidx70.51, align 1
  %scevgep20.23.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 23
  %19131 = load i8, i8* %scevgep20.23.51, align 1
  %conv68.23.51 = zext i8 %19131 to i32
  %19132 = load i8, i8* %arrayidx70.51, align 1
  %conv71.23.51 = zext i8 %19132 to i32
  %xor72.23.51 = xor i32 %conv71.23.51, %conv68.23.51
  %conv73.23.51 = trunc i32 %xor72.23.51 to i8
  store i8 %conv73.23.51, i8* %arrayidx70.51, align 1
  %scevgep20.24.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 24
  %19133 = load i8, i8* %scevgep20.24.51, align 1
  %conv68.24.51 = zext i8 %19133 to i32
  %19134 = load i8, i8* %arrayidx70.51, align 1
  %conv71.24.51 = zext i8 %19134 to i32
  %xor72.24.51 = xor i32 %conv71.24.51, %conv68.24.51
  %conv73.24.51 = trunc i32 %xor72.24.51 to i8
  store i8 %conv73.24.51, i8* %arrayidx70.51, align 1
  %scevgep20.25.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 25
  %19135 = load i8, i8* %scevgep20.25.51, align 1
  %conv68.25.51 = zext i8 %19135 to i32
  %19136 = load i8, i8* %arrayidx70.51, align 1
  %conv71.25.51 = zext i8 %19136 to i32
  %xor72.25.51 = xor i32 %conv71.25.51, %conv68.25.51
  %conv73.25.51 = trunc i32 %xor72.25.51 to i8
  store i8 %conv73.25.51, i8* %arrayidx70.51, align 1
  %scevgep20.26.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 26
  %19137 = load i8, i8* %scevgep20.26.51, align 1
  %conv68.26.51 = zext i8 %19137 to i32
  %19138 = load i8, i8* %arrayidx70.51, align 1
  %conv71.26.51 = zext i8 %19138 to i32
  %xor72.26.51 = xor i32 %conv71.26.51, %conv68.26.51
  %conv73.26.51 = trunc i32 %xor72.26.51 to i8
  store i8 %conv73.26.51, i8* %arrayidx70.51, align 1
  %scevgep20.27.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 27
  %19139 = load i8, i8* %scevgep20.27.51, align 1
  %conv68.27.51 = zext i8 %19139 to i32
  %19140 = load i8, i8* %arrayidx70.51, align 1
  %conv71.27.51 = zext i8 %19140 to i32
  %xor72.27.51 = xor i32 %conv71.27.51, %conv68.27.51
  %conv73.27.51 = trunc i32 %xor72.27.51 to i8
  store i8 %conv73.27.51, i8* %arrayidx70.51, align 1
  %scevgep20.28.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 28
  %19141 = load i8, i8* %scevgep20.28.51, align 1
  %conv68.28.51 = zext i8 %19141 to i32
  %19142 = load i8, i8* %arrayidx70.51, align 1
  %conv71.28.51 = zext i8 %19142 to i32
  %xor72.28.51 = xor i32 %conv71.28.51, %conv68.28.51
  %conv73.28.51 = trunc i32 %xor72.28.51 to i8
  store i8 %conv73.28.51, i8* %arrayidx70.51, align 1
  %scevgep20.29.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 29
  %19143 = load i8, i8* %scevgep20.29.51, align 1
  %conv68.29.51 = zext i8 %19143 to i32
  %19144 = load i8, i8* %arrayidx70.51, align 1
  %conv71.29.51 = zext i8 %19144 to i32
  %xor72.29.51 = xor i32 %conv71.29.51, %conv68.29.51
  %conv73.29.51 = trunc i32 %xor72.29.51 to i8
  store i8 %conv73.29.51, i8* %arrayidx70.51, align 1
  %scevgep20.30.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 30
  %19145 = load i8, i8* %scevgep20.30.51, align 1
  %conv68.30.51 = zext i8 %19145 to i32
  %19146 = load i8, i8* %arrayidx70.51, align 1
  %conv71.30.51 = zext i8 %19146 to i32
  %xor72.30.51 = xor i32 %conv71.30.51, %conv68.30.51
  %conv73.30.51 = trunc i32 %xor72.30.51 to i8
  store i8 %conv73.30.51, i8* %arrayidx70.51, align 1
  %scevgep20.31.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 31
  %19147 = load i8, i8* %scevgep20.31.51, align 1
  %conv68.31.51 = zext i8 %19147 to i32
  %19148 = load i8, i8* %arrayidx70.51, align 1
  %conv71.31.51 = zext i8 %19148 to i32
  %xor72.31.51 = xor i32 %conv71.31.51, %conv68.31.51
  %conv73.31.51 = trunc i32 %xor72.31.51 to i8
  store i8 %conv73.31.51, i8* %arrayidx70.51, align 1
  %scevgep20.32.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 32
  %19149 = load i8, i8* %scevgep20.32.51, align 1
  %conv68.32.51 = zext i8 %19149 to i32
  %19150 = load i8, i8* %arrayidx70.51, align 1
  %conv71.32.51 = zext i8 %19150 to i32
  %xor72.32.51 = xor i32 %conv71.32.51, %conv68.32.51
  %conv73.32.51 = trunc i32 %xor72.32.51 to i8
  store i8 %conv73.32.51, i8* %arrayidx70.51, align 1
  %scevgep20.33.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 33
  %19151 = load i8, i8* %scevgep20.33.51, align 1
  %conv68.33.51 = zext i8 %19151 to i32
  %19152 = load i8, i8* %arrayidx70.51, align 1
  %conv71.33.51 = zext i8 %19152 to i32
  %xor72.33.51 = xor i32 %conv71.33.51, %conv68.33.51
  %conv73.33.51 = trunc i32 %xor72.33.51 to i8
  store i8 %conv73.33.51, i8* %arrayidx70.51, align 1
  %scevgep20.34.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 34
  %19153 = load i8, i8* %scevgep20.34.51, align 1
  %conv68.34.51 = zext i8 %19153 to i32
  %19154 = load i8, i8* %arrayidx70.51, align 1
  %conv71.34.51 = zext i8 %19154 to i32
  %xor72.34.51 = xor i32 %conv71.34.51, %conv68.34.51
  %conv73.34.51 = trunc i32 %xor72.34.51 to i8
  store i8 %conv73.34.51, i8* %arrayidx70.51, align 1
  %scevgep20.35.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 35
  %19155 = load i8, i8* %scevgep20.35.51, align 1
  %conv68.35.51 = zext i8 %19155 to i32
  %19156 = load i8, i8* %arrayidx70.51, align 1
  %conv71.35.51 = zext i8 %19156 to i32
  %xor72.35.51 = xor i32 %conv71.35.51, %conv68.35.51
  %conv73.35.51 = trunc i32 %xor72.35.51 to i8
  store i8 %conv73.35.51, i8* %arrayidx70.51, align 1
  %scevgep20.36.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 36
  %19157 = load i8, i8* %scevgep20.36.51, align 1
  %conv68.36.51 = zext i8 %19157 to i32
  %19158 = load i8, i8* %arrayidx70.51, align 1
  %conv71.36.51 = zext i8 %19158 to i32
  %xor72.36.51 = xor i32 %conv71.36.51, %conv68.36.51
  %conv73.36.51 = trunc i32 %xor72.36.51 to i8
  store i8 %conv73.36.51, i8* %arrayidx70.51, align 1
  %scevgep20.37.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 37
  %19159 = load i8, i8* %scevgep20.37.51, align 1
  %conv68.37.51 = zext i8 %19159 to i32
  %19160 = load i8, i8* %arrayidx70.51, align 1
  %conv71.37.51 = zext i8 %19160 to i32
  %xor72.37.51 = xor i32 %conv71.37.51, %conv68.37.51
  %conv73.37.51 = trunc i32 %xor72.37.51 to i8
  store i8 %conv73.37.51, i8* %arrayidx70.51, align 1
  %scevgep20.38.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 38
  %19161 = load i8, i8* %scevgep20.38.51, align 1
  %conv68.38.51 = zext i8 %19161 to i32
  %19162 = load i8, i8* %arrayidx70.51, align 1
  %conv71.38.51 = zext i8 %19162 to i32
  %xor72.38.51 = xor i32 %conv71.38.51, %conv68.38.51
  %conv73.38.51 = trunc i32 %xor72.38.51 to i8
  store i8 %conv73.38.51, i8* %arrayidx70.51, align 1
  %scevgep20.39.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 39
  %19163 = load i8, i8* %scevgep20.39.51, align 1
  %conv68.39.51 = zext i8 %19163 to i32
  %19164 = load i8, i8* %arrayidx70.51, align 1
  %conv71.39.51 = zext i8 %19164 to i32
  %xor72.39.51 = xor i32 %conv71.39.51, %conv68.39.51
  %conv73.39.51 = trunc i32 %xor72.39.51 to i8
  store i8 %conv73.39.51, i8* %arrayidx70.51, align 1
  %scevgep20.40.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 40
  %19165 = load i8, i8* %scevgep20.40.51, align 1
  %conv68.40.51 = zext i8 %19165 to i32
  %19166 = load i8, i8* %arrayidx70.51, align 1
  %conv71.40.51 = zext i8 %19166 to i32
  %xor72.40.51 = xor i32 %conv71.40.51, %conv68.40.51
  %conv73.40.51 = trunc i32 %xor72.40.51 to i8
  store i8 %conv73.40.51, i8* %arrayidx70.51, align 1
  %scevgep20.41.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 41
  %19167 = load i8, i8* %scevgep20.41.51, align 1
  %conv68.41.51 = zext i8 %19167 to i32
  %19168 = load i8, i8* %arrayidx70.51, align 1
  %conv71.41.51 = zext i8 %19168 to i32
  %xor72.41.51 = xor i32 %conv71.41.51, %conv68.41.51
  %conv73.41.51 = trunc i32 %xor72.41.51 to i8
  store i8 %conv73.41.51, i8* %arrayidx70.51, align 1
  %scevgep20.42.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 42
  %19169 = load i8, i8* %scevgep20.42.51, align 1
  %conv68.42.51 = zext i8 %19169 to i32
  %19170 = load i8, i8* %arrayidx70.51, align 1
  %conv71.42.51 = zext i8 %19170 to i32
  %xor72.42.51 = xor i32 %conv71.42.51, %conv68.42.51
  %conv73.42.51 = trunc i32 %xor72.42.51 to i8
  store i8 %conv73.42.51, i8* %arrayidx70.51, align 1
  %scevgep20.43.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 43
  %19171 = load i8, i8* %scevgep20.43.51, align 1
  %conv68.43.51 = zext i8 %19171 to i32
  %19172 = load i8, i8* %arrayidx70.51, align 1
  %conv71.43.51 = zext i8 %19172 to i32
  %xor72.43.51 = xor i32 %conv71.43.51, %conv68.43.51
  %conv73.43.51 = trunc i32 %xor72.43.51 to i8
  store i8 %conv73.43.51, i8* %arrayidx70.51, align 1
  %scevgep20.44.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 44
  %19173 = load i8, i8* %scevgep20.44.51, align 1
  %conv68.44.51 = zext i8 %19173 to i32
  %19174 = load i8, i8* %arrayidx70.51, align 1
  %conv71.44.51 = zext i8 %19174 to i32
  %xor72.44.51 = xor i32 %conv71.44.51, %conv68.44.51
  %conv73.44.51 = trunc i32 %xor72.44.51 to i8
  store i8 %conv73.44.51, i8* %arrayidx70.51, align 1
  %scevgep20.45.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 45
  %19175 = load i8, i8* %scevgep20.45.51, align 1
  %conv68.45.51 = zext i8 %19175 to i32
  %19176 = load i8, i8* %arrayidx70.51, align 1
  %conv71.45.51 = zext i8 %19176 to i32
  %xor72.45.51 = xor i32 %conv71.45.51, %conv68.45.51
  %conv73.45.51 = trunc i32 %xor72.45.51 to i8
  store i8 %conv73.45.51, i8* %arrayidx70.51, align 1
  %scevgep20.46.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 46
  %19177 = load i8, i8* %scevgep20.46.51, align 1
  %conv68.46.51 = zext i8 %19177 to i32
  %19178 = load i8, i8* %arrayidx70.51, align 1
  %conv71.46.51 = zext i8 %19178 to i32
  %xor72.46.51 = xor i32 %conv71.46.51, %conv68.46.51
  %conv73.46.51 = trunc i32 %xor72.46.51 to i8
  store i8 %conv73.46.51, i8* %arrayidx70.51, align 1
  %scevgep20.47.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 47
  %19179 = load i8, i8* %scevgep20.47.51, align 1
  %conv68.47.51 = zext i8 %19179 to i32
  %19180 = load i8, i8* %arrayidx70.51, align 1
  %conv71.47.51 = zext i8 %19180 to i32
  %xor72.47.51 = xor i32 %conv71.47.51, %conv68.47.51
  %conv73.47.51 = trunc i32 %xor72.47.51 to i8
  store i8 %conv73.47.51, i8* %arrayidx70.51, align 1
  %scevgep20.48.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 48
  %19181 = load i8, i8* %scevgep20.48.51, align 1
  %conv68.48.51 = zext i8 %19181 to i32
  %19182 = load i8, i8* %arrayidx70.51, align 1
  %conv71.48.51 = zext i8 %19182 to i32
  %xor72.48.51 = xor i32 %conv71.48.51, %conv68.48.51
  %conv73.48.51 = trunc i32 %xor72.48.51 to i8
  store i8 %conv73.48.51, i8* %arrayidx70.51, align 1
  %scevgep20.49.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 49
  %19183 = load i8, i8* %scevgep20.49.51, align 1
  %conv68.49.51 = zext i8 %19183 to i32
  %19184 = load i8, i8* %arrayidx70.51, align 1
  %conv71.49.51 = zext i8 %19184 to i32
  %xor72.49.51 = xor i32 %conv71.49.51, %conv68.49.51
  %conv73.49.51 = trunc i32 %xor72.49.51 to i8
  store i8 %conv73.49.51, i8* %arrayidx70.51, align 1
  %scevgep20.50.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 50
  %19185 = load i8, i8* %scevgep20.50.51, align 1
  %conv68.50.51 = zext i8 %19185 to i32
  %19186 = load i8, i8* %arrayidx70.51, align 1
  %conv71.50.51 = zext i8 %19186 to i32
  %xor72.50.51 = xor i32 %conv71.50.51, %conv68.50.51
  %conv73.50.51 = trunc i32 %xor72.50.51 to i8
  store i8 %conv73.50.51, i8* %arrayidx70.51, align 1
  %scevgep20.52.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 52
  %19187 = load i8, i8* %scevgep20.52.51, align 1
  %conv68.52.51 = zext i8 %19187 to i32
  %19188 = load i8, i8* %arrayidx70.51, align 1
  %conv71.52.51 = zext i8 %19188 to i32
  %xor72.52.51 = xor i32 %conv71.52.51, %conv68.52.51
  %conv73.52.51 = trunc i32 %xor72.52.51 to i8
  store i8 %conv73.52.51, i8* %arrayidx70.51, align 1
  %scevgep20.53.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 53
  %19189 = load i8, i8* %scevgep20.53.51, align 1
  %conv68.53.51 = zext i8 %19189 to i32
  %19190 = load i8, i8* %arrayidx70.51, align 1
  %conv71.53.51 = zext i8 %19190 to i32
  %xor72.53.51 = xor i32 %conv71.53.51, %conv68.53.51
  %conv73.53.51 = trunc i32 %xor72.53.51 to i8
  store i8 %conv73.53.51, i8* %arrayidx70.51, align 1
  %scevgep20.54.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 54
  %19191 = load i8, i8* %scevgep20.54.51, align 1
  %conv68.54.51 = zext i8 %19191 to i32
  %19192 = load i8, i8* %arrayidx70.51, align 1
  %conv71.54.51 = zext i8 %19192 to i32
  %xor72.54.51 = xor i32 %conv71.54.51, %conv68.54.51
  %conv73.54.51 = trunc i32 %xor72.54.51 to i8
  store i8 %conv73.54.51, i8* %arrayidx70.51, align 1
  %scevgep20.55.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 55
  %19193 = load i8, i8* %scevgep20.55.51, align 1
  %conv68.55.51 = zext i8 %19193 to i32
  %19194 = load i8, i8* %arrayidx70.51, align 1
  %conv71.55.51 = zext i8 %19194 to i32
  %xor72.55.51 = xor i32 %conv71.55.51, %conv68.55.51
  %conv73.55.51 = trunc i32 %xor72.55.51 to i8
  store i8 %conv73.55.51, i8* %arrayidx70.51, align 1
  %scevgep20.56.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 56
  %19195 = load i8, i8* %scevgep20.56.51, align 1
  %conv68.56.51 = zext i8 %19195 to i32
  %19196 = load i8, i8* %arrayidx70.51, align 1
  %conv71.56.51 = zext i8 %19196 to i32
  %xor72.56.51 = xor i32 %conv71.56.51, %conv68.56.51
  %conv73.56.51 = trunc i32 %xor72.56.51 to i8
  store i8 %conv73.56.51, i8* %arrayidx70.51, align 1
  %scevgep20.57.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 57
  %19197 = load i8, i8* %scevgep20.57.51, align 1
  %conv68.57.51 = zext i8 %19197 to i32
  %19198 = load i8, i8* %arrayidx70.51, align 1
  %conv71.57.51 = zext i8 %19198 to i32
  %xor72.57.51 = xor i32 %conv71.57.51, %conv68.57.51
  %conv73.57.51 = trunc i32 %xor72.57.51 to i8
  store i8 %conv73.57.51, i8* %arrayidx70.51, align 1
  %scevgep20.58.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 58
  %19199 = load i8, i8* %scevgep20.58.51, align 1
  %conv68.58.51 = zext i8 %19199 to i32
  %19200 = load i8, i8* %arrayidx70.51, align 1
  %conv71.58.51 = zext i8 %19200 to i32
  %xor72.58.51 = xor i32 %conv71.58.51, %conv68.58.51
  %conv73.58.51 = trunc i32 %xor72.58.51 to i8
  store i8 %conv73.58.51, i8* %arrayidx70.51, align 1
  %scevgep20.59.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 59
  %19201 = load i8, i8* %scevgep20.59.51, align 1
  %conv68.59.51 = zext i8 %19201 to i32
  %19202 = load i8, i8* %arrayidx70.51, align 1
  %conv71.59.51 = zext i8 %19202 to i32
  %xor72.59.51 = xor i32 %conv71.59.51, %conv68.59.51
  %conv73.59.51 = trunc i32 %xor72.59.51 to i8
  store i8 %conv73.59.51, i8* %arrayidx70.51, align 1
  %scevgep20.60.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 0, i64 60
  %19203 = load i8, i8* %scevgep20.60.51, align 1
  %conv68.60.51 = zext i8 %19203 to i32
  %19204 = load i8, i8* %arrayidx70.51, align 1
  %conv71.60.51 = zext i8 %19204 to i32
  %xor72.60.51 = xor i32 %conv71.60.51, %conv68.60.51
  %conv73.60.51 = trunc i32 %xor72.60.51 to i8
  store i8 %conv73.60.51, i8* %arrayidx70.51, align 1
  %scevgep19.51 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19082, i64 0, i64 1, i64 0
  %19205 = bitcast i8* %scevgep19.51 to [61 x [61 x i8]]*
  %arrayidx51.52 = getelementptr inbounds i8, i8* %a, i64 52
  %19206 = load i8, i8* %arrayidx51.52, align 1
  %arrayidx53.52 = getelementptr inbounds i8, i8* %b, i64 52
  %19207 = load i8, i8* %arrayidx53.52, align 1
  %call54.52 = call zeroext i8 @mult(i8 zeroext %19206, i8 zeroext %19207)
  %arrayidx56.52 = getelementptr inbounds i8, i8* %c, i64 52
  store i8 %call54.52, i8* %arrayidx56.52, align 1
  %arrayidx70.52 = getelementptr inbounds i8, i8* %c, i64 52
  %scevgep20.52564 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 0
  %19208 = load i8, i8* %scevgep20.52564, align 1
  %conv68.52565 = zext i8 %19208 to i32
  %19209 = load i8, i8* %arrayidx70.52, align 1
  %conv71.52566 = zext i8 %19209 to i32
  %xor72.52567 = xor i32 %conv71.52566, %conv68.52565
  %conv73.52568 = trunc i32 %xor72.52567 to i8
  store i8 %conv73.52568, i8* %arrayidx70.52, align 1
  %scevgep20.1.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 1
  %19210 = load i8, i8* %scevgep20.1.52, align 1
  %conv68.1.52 = zext i8 %19210 to i32
  %19211 = load i8, i8* %arrayidx70.52, align 1
  %conv71.1.52 = zext i8 %19211 to i32
  %xor72.1.52 = xor i32 %conv71.1.52, %conv68.1.52
  %conv73.1.52 = trunc i32 %xor72.1.52 to i8
  store i8 %conv73.1.52, i8* %arrayidx70.52, align 1
  %scevgep20.2.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 2
  %19212 = load i8, i8* %scevgep20.2.52, align 1
  %conv68.2.52 = zext i8 %19212 to i32
  %19213 = load i8, i8* %arrayidx70.52, align 1
  %conv71.2.52 = zext i8 %19213 to i32
  %xor72.2.52 = xor i32 %conv71.2.52, %conv68.2.52
  %conv73.2.52 = trunc i32 %xor72.2.52 to i8
  store i8 %conv73.2.52, i8* %arrayidx70.52, align 1
  %scevgep20.3.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 3
  %19214 = load i8, i8* %scevgep20.3.52, align 1
  %conv68.3.52 = zext i8 %19214 to i32
  %19215 = load i8, i8* %arrayidx70.52, align 1
  %conv71.3.52 = zext i8 %19215 to i32
  %xor72.3.52 = xor i32 %conv71.3.52, %conv68.3.52
  %conv73.3.52 = trunc i32 %xor72.3.52 to i8
  store i8 %conv73.3.52, i8* %arrayidx70.52, align 1
  %scevgep20.4.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 4
  %19216 = load i8, i8* %scevgep20.4.52, align 1
  %conv68.4.52 = zext i8 %19216 to i32
  %19217 = load i8, i8* %arrayidx70.52, align 1
  %conv71.4.52 = zext i8 %19217 to i32
  %xor72.4.52 = xor i32 %conv71.4.52, %conv68.4.52
  %conv73.4.52 = trunc i32 %xor72.4.52 to i8
  store i8 %conv73.4.52, i8* %arrayidx70.52, align 1
  %scevgep20.5.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 5
  %19218 = load i8, i8* %scevgep20.5.52, align 1
  %conv68.5.52 = zext i8 %19218 to i32
  %19219 = load i8, i8* %arrayidx70.52, align 1
  %conv71.5.52 = zext i8 %19219 to i32
  %xor72.5.52 = xor i32 %conv71.5.52, %conv68.5.52
  %conv73.5.52 = trunc i32 %xor72.5.52 to i8
  store i8 %conv73.5.52, i8* %arrayidx70.52, align 1
  %scevgep20.6.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 6
  %19220 = load i8, i8* %scevgep20.6.52, align 1
  %conv68.6.52 = zext i8 %19220 to i32
  %19221 = load i8, i8* %arrayidx70.52, align 1
  %conv71.6.52 = zext i8 %19221 to i32
  %xor72.6.52 = xor i32 %conv71.6.52, %conv68.6.52
  %conv73.6.52 = trunc i32 %xor72.6.52 to i8
  store i8 %conv73.6.52, i8* %arrayidx70.52, align 1
  %scevgep20.7.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 7
  %19222 = load i8, i8* %scevgep20.7.52, align 1
  %conv68.7.52 = zext i8 %19222 to i32
  %19223 = load i8, i8* %arrayidx70.52, align 1
  %conv71.7.52 = zext i8 %19223 to i32
  %xor72.7.52 = xor i32 %conv71.7.52, %conv68.7.52
  %conv73.7.52 = trunc i32 %xor72.7.52 to i8
  store i8 %conv73.7.52, i8* %arrayidx70.52, align 1
  %scevgep20.8.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 8
  %19224 = load i8, i8* %scevgep20.8.52, align 1
  %conv68.8.52 = zext i8 %19224 to i32
  %19225 = load i8, i8* %arrayidx70.52, align 1
  %conv71.8.52 = zext i8 %19225 to i32
  %xor72.8.52 = xor i32 %conv71.8.52, %conv68.8.52
  %conv73.8.52 = trunc i32 %xor72.8.52 to i8
  store i8 %conv73.8.52, i8* %arrayidx70.52, align 1
  %scevgep20.9.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 9
  %19226 = load i8, i8* %scevgep20.9.52, align 1
  %conv68.9.52 = zext i8 %19226 to i32
  %19227 = load i8, i8* %arrayidx70.52, align 1
  %conv71.9.52 = zext i8 %19227 to i32
  %xor72.9.52 = xor i32 %conv71.9.52, %conv68.9.52
  %conv73.9.52 = trunc i32 %xor72.9.52 to i8
  store i8 %conv73.9.52, i8* %arrayidx70.52, align 1
  %scevgep20.10.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 10
  %19228 = load i8, i8* %scevgep20.10.52, align 1
  %conv68.10.52 = zext i8 %19228 to i32
  %19229 = load i8, i8* %arrayidx70.52, align 1
  %conv71.10.52 = zext i8 %19229 to i32
  %xor72.10.52 = xor i32 %conv71.10.52, %conv68.10.52
  %conv73.10.52 = trunc i32 %xor72.10.52 to i8
  store i8 %conv73.10.52, i8* %arrayidx70.52, align 1
  %scevgep20.11.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 11
  %19230 = load i8, i8* %scevgep20.11.52, align 1
  %conv68.11.52 = zext i8 %19230 to i32
  %19231 = load i8, i8* %arrayidx70.52, align 1
  %conv71.11.52 = zext i8 %19231 to i32
  %xor72.11.52 = xor i32 %conv71.11.52, %conv68.11.52
  %conv73.11.52 = trunc i32 %xor72.11.52 to i8
  store i8 %conv73.11.52, i8* %arrayidx70.52, align 1
  %scevgep20.12.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 12
  %19232 = load i8, i8* %scevgep20.12.52, align 1
  %conv68.12.52 = zext i8 %19232 to i32
  %19233 = load i8, i8* %arrayidx70.52, align 1
  %conv71.12.52 = zext i8 %19233 to i32
  %xor72.12.52 = xor i32 %conv71.12.52, %conv68.12.52
  %conv73.12.52 = trunc i32 %xor72.12.52 to i8
  store i8 %conv73.12.52, i8* %arrayidx70.52, align 1
  %scevgep20.13.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 13
  %19234 = load i8, i8* %scevgep20.13.52, align 1
  %conv68.13.52 = zext i8 %19234 to i32
  %19235 = load i8, i8* %arrayidx70.52, align 1
  %conv71.13.52 = zext i8 %19235 to i32
  %xor72.13.52 = xor i32 %conv71.13.52, %conv68.13.52
  %conv73.13.52 = trunc i32 %xor72.13.52 to i8
  store i8 %conv73.13.52, i8* %arrayidx70.52, align 1
  %scevgep20.14.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 14
  %19236 = load i8, i8* %scevgep20.14.52, align 1
  %conv68.14.52 = zext i8 %19236 to i32
  %19237 = load i8, i8* %arrayidx70.52, align 1
  %conv71.14.52 = zext i8 %19237 to i32
  %xor72.14.52 = xor i32 %conv71.14.52, %conv68.14.52
  %conv73.14.52 = trunc i32 %xor72.14.52 to i8
  store i8 %conv73.14.52, i8* %arrayidx70.52, align 1
  %scevgep20.15.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 15
  %19238 = load i8, i8* %scevgep20.15.52, align 1
  %conv68.15.52 = zext i8 %19238 to i32
  %19239 = load i8, i8* %arrayidx70.52, align 1
  %conv71.15.52 = zext i8 %19239 to i32
  %xor72.15.52 = xor i32 %conv71.15.52, %conv68.15.52
  %conv73.15.52 = trunc i32 %xor72.15.52 to i8
  store i8 %conv73.15.52, i8* %arrayidx70.52, align 1
  %scevgep20.16.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 16
  %19240 = load i8, i8* %scevgep20.16.52, align 1
  %conv68.16.52 = zext i8 %19240 to i32
  %19241 = load i8, i8* %arrayidx70.52, align 1
  %conv71.16.52 = zext i8 %19241 to i32
  %xor72.16.52 = xor i32 %conv71.16.52, %conv68.16.52
  %conv73.16.52 = trunc i32 %xor72.16.52 to i8
  store i8 %conv73.16.52, i8* %arrayidx70.52, align 1
  %scevgep20.17.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 17
  %19242 = load i8, i8* %scevgep20.17.52, align 1
  %conv68.17.52 = zext i8 %19242 to i32
  %19243 = load i8, i8* %arrayidx70.52, align 1
  %conv71.17.52 = zext i8 %19243 to i32
  %xor72.17.52 = xor i32 %conv71.17.52, %conv68.17.52
  %conv73.17.52 = trunc i32 %xor72.17.52 to i8
  store i8 %conv73.17.52, i8* %arrayidx70.52, align 1
  %scevgep20.18.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 18
  %19244 = load i8, i8* %scevgep20.18.52, align 1
  %conv68.18.52 = zext i8 %19244 to i32
  %19245 = load i8, i8* %arrayidx70.52, align 1
  %conv71.18.52 = zext i8 %19245 to i32
  %xor72.18.52 = xor i32 %conv71.18.52, %conv68.18.52
  %conv73.18.52 = trunc i32 %xor72.18.52 to i8
  store i8 %conv73.18.52, i8* %arrayidx70.52, align 1
  %scevgep20.19.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 19
  %19246 = load i8, i8* %scevgep20.19.52, align 1
  %conv68.19.52 = zext i8 %19246 to i32
  %19247 = load i8, i8* %arrayidx70.52, align 1
  %conv71.19.52 = zext i8 %19247 to i32
  %xor72.19.52 = xor i32 %conv71.19.52, %conv68.19.52
  %conv73.19.52 = trunc i32 %xor72.19.52 to i8
  store i8 %conv73.19.52, i8* %arrayidx70.52, align 1
  %scevgep20.20.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 20
  %19248 = load i8, i8* %scevgep20.20.52, align 1
  %conv68.20.52 = zext i8 %19248 to i32
  %19249 = load i8, i8* %arrayidx70.52, align 1
  %conv71.20.52 = zext i8 %19249 to i32
  %xor72.20.52 = xor i32 %conv71.20.52, %conv68.20.52
  %conv73.20.52 = trunc i32 %xor72.20.52 to i8
  store i8 %conv73.20.52, i8* %arrayidx70.52, align 1
  %scevgep20.21.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 21
  %19250 = load i8, i8* %scevgep20.21.52, align 1
  %conv68.21.52 = zext i8 %19250 to i32
  %19251 = load i8, i8* %arrayidx70.52, align 1
  %conv71.21.52 = zext i8 %19251 to i32
  %xor72.21.52 = xor i32 %conv71.21.52, %conv68.21.52
  %conv73.21.52 = trunc i32 %xor72.21.52 to i8
  store i8 %conv73.21.52, i8* %arrayidx70.52, align 1
  %scevgep20.22.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 22
  %19252 = load i8, i8* %scevgep20.22.52, align 1
  %conv68.22.52 = zext i8 %19252 to i32
  %19253 = load i8, i8* %arrayidx70.52, align 1
  %conv71.22.52 = zext i8 %19253 to i32
  %xor72.22.52 = xor i32 %conv71.22.52, %conv68.22.52
  %conv73.22.52 = trunc i32 %xor72.22.52 to i8
  store i8 %conv73.22.52, i8* %arrayidx70.52, align 1
  %scevgep20.23.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 23
  %19254 = load i8, i8* %scevgep20.23.52, align 1
  %conv68.23.52 = zext i8 %19254 to i32
  %19255 = load i8, i8* %arrayidx70.52, align 1
  %conv71.23.52 = zext i8 %19255 to i32
  %xor72.23.52 = xor i32 %conv71.23.52, %conv68.23.52
  %conv73.23.52 = trunc i32 %xor72.23.52 to i8
  store i8 %conv73.23.52, i8* %arrayidx70.52, align 1
  %scevgep20.24.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 24
  %19256 = load i8, i8* %scevgep20.24.52, align 1
  %conv68.24.52 = zext i8 %19256 to i32
  %19257 = load i8, i8* %arrayidx70.52, align 1
  %conv71.24.52 = zext i8 %19257 to i32
  %xor72.24.52 = xor i32 %conv71.24.52, %conv68.24.52
  %conv73.24.52 = trunc i32 %xor72.24.52 to i8
  store i8 %conv73.24.52, i8* %arrayidx70.52, align 1
  %scevgep20.25.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 25
  %19258 = load i8, i8* %scevgep20.25.52, align 1
  %conv68.25.52 = zext i8 %19258 to i32
  %19259 = load i8, i8* %arrayidx70.52, align 1
  %conv71.25.52 = zext i8 %19259 to i32
  %xor72.25.52 = xor i32 %conv71.25.52, %conv68.25.52
  %conv73.25.52 = trunc i32 %xor72.25.52 to i8
  store i8 %conv73.25.52, i8* %arrayidx70.52, align 1
  %scevgep20.26.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 26
  %19260 = load i8, i8* %scevgep20.26.52, align 1
  %conv68.26.52 = zext i8 %19260 to i32
  %19261 = load i8, i8* %arrayidx70.52, align 1
  %conv71.26.52 = zext i8 %19261 to i32
  %xor72.26.52 = xor i32 %conv71.26.52, %conv68.26.52
  %conv73.26.52 = trunc i32 %xor72.26.52 to i8
  store i8 %conv73.26.52, i8* %arrayidx70.52, align 1
  %scevgep20.27.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 27
  %19262 = load i8, i8* %scevgep20.27.52, align 1
  %conv68.27.52 = zext i8 %19262 to i32
  %19263 = load i8, i8* %arrayidx70.52, align 1
  %conv71.27.52 = zext i8 %19263 to i32
  %xor72.27.52 = xor i32 %conv71.27.52, %conv68.27.52
  %conv73.27.52 = trunc i32 %xor72.27.52 to i8
  store i8 %conv73.27.52, i8* %arrayidx70.52, align 1
  %scevgep20.28.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 28
  %19264 = load i8, i8* %scevgep20.28.52, align 1
  %conv68.28.52 = zext i8 %19264 to i32
  %19265 = load i8, i8* %arrayidx70.52, align 1
  %conv71.28.52 = zext i8 %19265 to i32
  %xor72.28.52 = xor i32 %conv71.28.52, %conv68.28.52
  %conv73.28.52 = trunc i32 %xor72.28.52 to i8
  store i8 %conv73.28.52, i8* %arrayidx70.52, align 1
  %scevgep20.29.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 29
  %19266 = load i8, i8* %scevgep20.29.52, align 1
  %conv68.29.52 = zext i8 %19266 to i32
  %19267 = load i8, i8* %arrayidx70.52, align 1
  %conv71.29.52 = zext i8 %19267 to i32
  %xor72.29.52 = xor i32 %conv71.29.52, %conv68.29.52
  %conv73.29.52 = trunc i32 %xor72.29.52 to i8
  store i8 %conv73.29.52, i8* %arrayidx70.52, align 1
  %scevgep20.30.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 30
  %19268 = load i8, i8* %scevgep20.30.52, align 1
  %conv68.30.52 = zext i8 %19268 to i32
  %19269 = load i8, i8* %arrayidx70.52, align 1
  %conv71.30.52 = zext i8 %19269 to i32
  %xor72.30.52 = xor i32 %conv71.30.52, %conv68.30.52
  %conv73.30.52 = trunc i32 %xor72.30.52 to i8
  store i8 %conv73.30.52, i8* %arrayidx70.52, align 1
  %scevgep20.31.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 31
  %19270 = load i8, i8* %scevgep20.31.52, align 1
  %conv68.31.52 = zext i8 %19270 to i32
  %19271 = load i8, i8* %arrayidx70.52, align 1
  %conv71.31.52 = zext i8 %19271 to i32
  %xor72.31.52 = xor i32 %conv71.31.52, %conv68.31.52
  %conv73.31.52 = trunc i32 %xor72.31.52 to i8
  store i8 %conv73.31.52, i8* %arrayidx70.52, align 1
  %scevgep20.32.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 32
  %19272 = load i8, i8* %scevgep20.32.52, align 1
  %conv68.32.52 = zext i8 %19272 to i32
  %19273 = load i8, i8* %arrayidx70.52, align 1
  %conv71.32.52 = zext i8 %19273 to i32
  %xor72.32.52 = xor i32 %conv71.32.52, %conv68.32.52
  %conv73.32.52 = trunc i32 %xor72.32.52 to i8
  store i8 %conv73.32.52, i8* %arrayidx70.52, align 1
  %scevgep20.33.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 33
  %19274 = load i8, i8* %scevgep20.33.52, align 1
  %conv68.33.52 = zext i8 %19274 to i32
  %19275 = load i8, i8* %arrayidx70.52, align 1
  %conv71.33.52 = zext i8 %19275 to i32
  %xor72.33.52 = xor i32 %conv71.33.52, %conv68.33.52
  %conv73.33.52 = trunc i32 %xor72.33.52 to i8
  store i8 %conv73.33.52, i8* %arrayidx70.52, align 1
  %scevgep20.34.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 34
  %19276 = load i8, i8* %scevgep20.34.52, align 1
  %conv68.34.52 = zext i8 %19276 to i32
  %19277 = load i8, i8* %arrayidx70.52, align 1
  %conv71.34.52 = zext i8 %19277 to i32
  %xor72.34.52 = xor i32 %conv71.34.52, %conv68.34.52
  %conv73.34.52 = trunc i32 %xor72.34.52 to i8
  store i8 %conv73.34.52, i8* %arrayidx70.52, align 1
  %scevgep20.35.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 35
  %19278 = load i8, i8* %scevgep20.35.52, align 1
  %conv68.35.52 = zext i8 %19278 to i32
  %19279 = load i8, i8* %arrayidx70.52, align 1
  %conv71.35.52 = zext i8 %19279 to i32
  %xor72.35.52 = xor i32 %conv71.35.52, %conv68.35.52
  %conv73.35.52 = trunc i32 %xor72.35.52 to i8
  store i8 %conv73.35.52, i8* %arrayidx70.52, align 1
  %scevgep20.36.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 36
  %19280 = load i8, i8* %scevgep20.36.52, align 1
  %conv68.36.52 = zext i8 %19280 to i32
  %19281 = load i8, i8* %arrayidx70.52, align 1
  %conv71.36.52 = zext i8 %19281 to i32
  %xor72.36.52 = xor i32 %conv71.36.52, %conv68.36.52
  %conv73.36.52 = trunc i32 %xor72.36.52 to i8
  store i8 %conv73.36.52, i8* %arrayidx70.52, align 1
  %scevgep20.37.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 37
  %19282 = load i8, i8* %scevgep20.37.52, align 1
  %conv68.37.52 = zext i8 %19282 to i32
  %19283 = load i8, i8* %arrayidx70.52, align 1
  %conv71.37.52 = zext i8 %19283 to i32
  %xor72.37.52 = xor i32 %conv71.37.52, %conv68.37.52
  %conv73.37.52 = trunc i32 %xor72.37.52 to i8
  store i8 %conv73.37.52, i8* %arrayidx70.52, align 1
  %scevgep20.38.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 38
  %19284 = load i8, i8* %scevgep20.38.52, align 1
  %conv68.38.52 = zext i8 %19284 to i32
  %19285 = load i8, i8* %arrayidx70.52, align 1
  %conv71.38.52 = zext i8 %19285 to i32
  %xor72.38.52 = xor i32 %conv71.38.52, %conv68.38.52
  %conv73.38.52 = trunc i32 %xor72.38.52 to i8
  store i8 %conv73.38.52, i8* %arrayidx70.52, align 1
  %scevgep20.39.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 39
  %19286 = load i8, i8* %scevgep20.39.52, align 1
  %conv68.39.52 = zext i8 %19286 to i32
  %19287 = load i8, i8* %arrayidx70.52, align 1
  %conv71.39.52 = zext i8 %19287 to i32
  %xor72.39.52 = xor i32 %conv71.39.52, %conv68.39.52
  %conv73.39.52 = trunc i32 %xor72.39.52 to i8
  store i8 %conv73.39.52, i8* %arrayidx70.52, align 1
  %scevgep20.40.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 40
  %19288 = load i8, i8* %scevgep20.40.52, align 1
  %conv68.40.52 = zext i8 %19288 to i32
  %19289 = load i8, i8* %arrayidx70.52, align 1
  %conv71.40.52 = zext i8 %19289 to i32
  %xor72.40.52 = xor i32 %conv71.40.52, %conv68.40.52
  %conv73.40.52 = trunc i32 %xor72.40.52 to i8
  store i8 %conv73.40.52, i8* %arrayidx70.52, align 1
  %scevgep20.41.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 41
  %19290 = load i8, i8* %scevgep20.41.52, align 1
  %conv68.41.52 = zext i8 %19290 to i32
  %19291 = load i8, i8* %arrayidx70.52, align 1
  %conv71.41.52 = zext i8 %19291 to i32
  %xor72.41.52 = xor i32 %conv71.41.52, %conv68.41.52
  %conv73.41.52 = trunc i32 %xor72.41.52 to i8
  store i8 %conv73.41.52, i8* %arrayidx70.52, align 1
  %scevgep20.42.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 42
  %19292 = load i8, i8* %scevgep20.42.52, align 1
  %conv68.42.52 = zext i8 %19292 to i32
  %19293 = load i8, i8* %arrayidx70.52, align 1
  %conv71.42.52 = zext i8 %19293 to i32
  %xor72.42.52 = xor i32 %conv71.42.52, %conv68.42.52
  %conv73.42.52 = trunc i32 %xor72.42.52 to i8
  store i8 %conv73.42.52, i8* %arrayidx70.52, align 1
  %scevgep20.43.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 43
  %19294 = load i8, i8* %scevgep20.43.52, align 1
  %conv68.43.52 = zext i8 %19294 to i32
  %19295 = load i8, i8* %arrayidx70.52, align 1
  %conv71.43.52 = zext i8 %19295 to i32
  %xor72.43.52 = xor i32 %conv71.43.52, %conv68.43.52
  %conv73.43.52 = trunc i32 %xor72.43.52 to i8
  store i8 %conv73.43.52, i8* %arrayidx70.52, align 1
  %scevgep20.44.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 44
  %19296 = load i8, i8* %scevgep20.44.52, align 1
  %conv68.44.52 = zext i8 %19296 to i32
  %19297 = load i8, i8* %arrayidx70.52, align 1
  %conv71.44.52 = zext i8 %19297 to i32
  %xor72.44.52 = xor i32 %conv71.44.52, %conv68.44.52
  %conv73.44.52 = trunc i32 %xor72.44.52 to i8
  store i8 %conv73.44.52, i8* %arrayidx70.52, align 1
  %scevgep20.45.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 45
  %19298 = load i8, i8* %scevgep20.45.52, align 1
  %conv68.45.52 = zext i8 %19298 to i32
  %19299 = load i8, i8* %arrayidx70.52, align 1
  %conv71.45.52 = zext i8 %19299 to i32
  %xor72.45.52 = xor i32 %conv71.45.52, %conv68.45.52
  %conv73.45.52 = trunc i32 %xor72.45.52 to i8
  store i8 %conv73.45.52, i8* %arrayidx70.52, align 1
  %scevgep20.46.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 46
  %19300 = load i8, i8* %scevgep20.46.52, align 1
  %conv68.46.52 = zext i8 %19300 to i32
  %19301 = load i8, i8* %arrayidx70.52, align 1
  %conv71.46.52 = zext i8 %19301 to i32
  %xor72.46.52 = xor i32 %conv71.46.52, %conv68.46.52
  %conv73.46.52 = trunc i32 %xor72.46.52 to i8
  store i8 %conv73.46.52, i8* %arrayidx70.52, align 1
  %scevgep20.47.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 47
  %19302 = load i8, i8* %scevgep20.47.52, align 1
  %conv68.47.52 = zext i8 %19302 to i32
  %19303 = load i8, i8* %arrayidx70.52, align 1
  %conv71.47.52 = zext i8 %19303 to i32
  %xor72.47.52 = xor i32 %conv71.47.52, %conv68.47.52
  %conv73.47.52 = trunc i32 %xor72.47.52 to i8
  store i8 %conv73.47.52, i8* %arrayidx70.52, align 1
  %scevgep20.48.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 48
  %19304 = load i8, i8* %scevgep20.48.52, align 1
  %conv68.48.52 = zext i8 %19304 to i32
  %19305 = load i8, i8* %arrayidx70.52, align 1
  %conv71.48.52 = zext i8 %19305 to i32
  %xor72.48.52 = xor i32 %conv71.48.52, %conv68.48.52
  %conv73.48.52 = trunc i32 %xor72.48.52 to i8
  store i8 %conv73.48.52, i8* %arrayidx70.52, align 1
  %scevgep20.49.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 49
  %19306 = load i8, i8* %scevgep20.49.52, align 1
  %conv68.49.52 = zext i8 %19306 to i32
  %19307 = load i8, i8* %arrayidx70.52, align 1
  %conv71.49.52 = zext i8 %19307 to i32
  %xor72.49.52 = xor i32 %conv71.49.52, %conv68.49.52
  %conv73.49.52 = trunc i32 %xor72.49.52 to i8
  store i8 %conv73.49.52, i8* %arrayidx70.52, align 1
  %scevgep20.50.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 50
  %19308 = load i8, i8* %scevgep20.50.52, align 1
  %conv68.50.52 = zext i8 %19308 to i32
  %19309 = load i8, i8* %arrayidx70.52, align 1
  %conv71.50.52 = zext i8 %19309 to i32
  %xor72.50.52 = xor i32 %conv71.50.52, %conv68.50.52
  %conv73.50.52 = trunc i32 %xor72.50.52 to i8
  store i8 %conv73.50.52, i8* %arrayidx70.52, align 1
  %scevgep20.51.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 51
  %19310 = load i8, i8* %scevgep20.51.52, align 1
  %conv68.51.52 = zext i8 %19310 to i32
  %19311 = load i8, i8* %arrayidx70.52, align 1
  %conv71.51.52 = zext i8 %19311 to i32
  %xor72.51.52 = xor i32 %conv71.51.52, %conv68.51.52
  %conv73.51.52 = trunc i32 %xor72.51.52 to i8
  store i8 %conv73.51.52, i8* %arrayidx70.52, align 1
  %scevgep20.53.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 53
  %19312 = load i8, i8* %scevgep20.53.52, align 1
  %conv68.53.52 = zext i8 %19312 to i32
  %19313 = load i8, i8* %arrayidx70.52, align 1
  %conv71.53.52 = zext i8 %19313 to i32
  %xor72.53.52 = xor i32 %conv71.53.52, %conv68.53.52
  %conv73.53.52 = trunc i32 %xor72.53.52 to i8
  store i8 %conv73.53.52, i8* %arrayidx70.52, align 1
  %scevgep20.54.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 54
  %19314 = load i8, i8* %scevgep20.54.52, align 1
  %conv68.54.52 = zext i8 %19314 to i32
  %19315 = load i8, i8* %arrayidx70.52, align 1
  %conv71.54.52 = zext i8 %19315 to i32
  %xor72.54.52 = xor i32 %conv71.54.52, %conv68.54.52
  %conv73.54.52 = trunc i32 %xor72.54.52 to i8
  store i8 %conv73.54.52, i8* %arrayidx70.52, align 1
  %scevgep20.55.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 55
  %19316 = load i8, i8* %scevgep20.55.52, align 1
  %conv68.55.52 = zext i8 %19316 to i32
  %19317 = load i8, i8* %arrayidx70.52, align 1
  %conv71.55.52 = zext i8 %19317 to i32
  %xor72.55.52 = xor i32 %conv71.55.52, %conv68.55.52
  %conv73.55.52 = trunc i32 %xor72.55.52 to i8
  store i8 %conv73.55.52, i8* %arrayidx70.52, align 1
  %scevgep20.56.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 56
  %19318 = load i8, i8* %scevgep20.56.52, align 1
  %conv68.56.52 = zext i8 %19318 to i32
  %19319 = load i8, i8* %arrayidx70.52, align 1
  %conv71.56.52 = zext i8 %19319 to i32
  %xor72.56.52 = xor i32 %conv71.56.52, %conv68.56.52
  %conv73.56.52 = trunc i32 %xor72.56.52 to i8
  store i8 %conv73.56.52, i8* %arrayidx70.52, align 1
  %scevgep20.57.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 57
  %19320 = load i8, i8* %scevgep20.57.52, align 1
  %conv68.57.52 = zext i8 %19320 to i32
  %19321 = load i8, i8* %arrayidx70.52, align 1
  %conv71.57.52 = zext i8 %19321 to i32
  %xor72.57.52 = xor i32 %conv71.57.52, %conv68.57.52
  %conv73.57.52 = trunc i32 %xor72.57.52 to i8
  store i8 %conv73.57.52, i8* %arrayidx70.52, align 1
  %scevgep20.58.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 58
  %19322 = load i8, i8* %scevgep20.58.52, align 1
  %conv68.58.52 = zext i8 %19322 to i32
  %19323 = load i8, i8* %arrayidx70.52, align 1
  %conv71.58.52 = zext i8 %19323 to i32
  %xor72.58.52 = xor i32 %conv71.58.52, %conv68.58.52
  %conv73.58.52 = trunc i32 %xor72.58.52 to i8
  store i8 %conv73.58.52, i8* %arrayidx70.52, align 1
  %scevgep20.59.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 59
  %19324 = load i8, i8* %scevgep20.59.52, align 1
  %conv68.59.52 = zext i8 %19324 to i32
  %19325 = load i8, i8* %arrayidx70.52, align 1
  %conv71.59.52 = zext i8 %19325 to i32
  %xor72.59.52 = xor i32 %conv71.59.52, %conv68.59.52
  %conv73.59.52 = trunc i32 %xor72.59.52 to i8
  store i8 %conv73.59.52, i8* %arrayidx70.52, align 1
  %scevgep20.60.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 0, i64 60
  %19326 = load i8, i8* %scevgep20.60.52, align 1
  %conv68.60.52 = zext i8 %19326 to i32
  %19327 = load i8, i8* %arrayidx70.52, align 1
  %conv71.60.52 = zext i8 %19327 to i32
  %xor72.60.52 = xor i32 %conv71.60.52, %conv68.60.52
  %conv73.60.52 = trunc i32 %xor72.60.52 to i8
  store i8 %conv73.60.52, i8* %arrayidx70.52, align 1
  %scevgep19.52 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19205, i64 0, i64 1, i64 0
  %19328 = bitcast i8* %scevgep19.52 to [61 x [61 x i8]]*
  %arrayidx51.53 = getelementptr inbounds i8, i8* %a, i64 53
  %19329 = load i8, i8* %arrayidx51.53, align 1
  %arrayidx53.53 = getelementptr inbounds i8, i8* %b, i64 53
  %19330 = load i8, i8* %arrayidx53.53, align 1
  %call54.53 = call zeroext i8 @mult(i8 zeroext %19329, i8 zeroext %19330)
  %arrayidx56.53 = getelementptr inbounds i8, i8* %c, i64 53
  store i8 %call54.53, i8* %arrayidx56.53, align 1
  %arrayidx70.53 = getelementptr inbounds i8, i8* %c, i64 53
  %scevgep20.53574 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 0
  %19331 = load i8, i8* %scevgep20.53574, align 1
  %conv68.53575 = zext i8 %19331 to i32
  %19332 = load i8, i8* %arrayidx70.53, align 1
  %conv71.53576 = zext i8 %19332 to i32
  %xor72.53577 = xor i32 %conv71.53576, %conv68.53575
  %conv73.53578 = trunc i32 %xor72.53577 to i8
  store i8 %conv73.53578, i8* %arrayidx70.53, align 1
  %scevgep20.1.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 1
  %19333 = load i8, i8* %scevgep20.1.53, align 1
  %conv68.1.53 = zext i8 %19333 to i32
  %19334 = load i8, i8* %arrayidx70.53, align 1
  %conv71.1.53 = zext i8 %19334 to i32
  %xor72.1.53 = xor i32 %conv71.1.53, %conv68.1.53
  %conv73.1.53 = trunc i32 %xor72.1.53 to i8
  store i8 %conv73.1.53, i8* %arrayidx70.53, align 1
  %scevgep20.2.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 2
  %19335 = load i8, i8* %scevgep20.2.53, align 1
  %conv68.2.53 = zext i8 %19335 to i32
  %19336 = load i8, i8* %arrayidx70.53, align 1
  %conv71.2.53 = zext i8 %19336 to i32
  %xor72.2.53 = xor i32 %conv71.2.53, %conv68.2.53
  %conv73.2.53 = trunc i32 %xor72.2.53 to i8
  store i8 %conv73.2.53, i8* %arrayidx70.53, align 1
  %scevgep20.3.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 3
  %19337 = load i8, i8* %scevgep20.3.53, align 1
  %conv68.3.53 = zext i8 %19337 to i32
  %19338 = load i8, i8* %arrayidx70.53, align 1
  %conv71.3.53 = zext i8 %19338 to i32
  %xor72.3.53 = xor i32 %conv71.3.53, %conv68.3.53
  %conv73.3.53 = trunc i32 %xor72.3.53 to i8
  store i8 %conv73.3.53, i8* %arrayidx70.53, align 1
  %scevgep20.4.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 4
  %19339 = load i8, i8* %scevgep20.4.53, align 1
  %conv68.4.53 = zext i8 %19339 to i32
  %19340 = load i8, i8* %arrayidx70.53, align 1
  %conv71.4.53 = zext i8 %19340 to i32
  %xor72.4.53 = xor i32 %conv71.4.53, %conv68.4.53
  %conv73.4.53 = trunc i32 %xor72.4.53 to i8
  store i8 %conv73.4.53, i8* %arrayidx70.53, align 1
  %scevgep20.5.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 5
  %19341 = load i8, i8* %scevgep20.5.53, align 1
  %conv68.5.53 = zext i8 %19341 to i32
  %19342 = load i8, i8* %arrayidx70.53, align 1
  %conv71.5.53 = zext i8 %19342 to i32
  %xor72.5.53 = xor i32 %conv71.5.53, %conv68.5.53
  %conv73.5.53 = trunc i32 %xor72.5.53 to i8
  store i8 %conv73.5.53, i8* %arrayidx70.53, align 1
  %scevgep20.6.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 6
  %19343 = load i8, i8* %scevgep20.6.53, align 1
  %conv68.6.53 = zext i8 %19343 to i32
  %19344 = load i8, i8* %arrayidx70.53, align 1
  %conv71.6.53 = zext i8 %19344 to i32
  %xor72.6.53 = xor i32 %conv71.6.53, %conv68.6.53
  %conv73.6.53 = trunc i32 %xor72.6.53 to i8
  store i8 %conv73.6.53, i8* %arrayidx70.53, align 1
  %scevgep20.7.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 7
  %19345 = load i8, i8* %scevgep20.7.53, align 1
  %conv68.7.53 = zext i8 %19345 to i32
  %19346 = load i8, i8* %arrayidx70.53, align 1
  %conv71.7.53 = zext i8 %19346 to i32
  %xor72.7.53 = xor i32 %conv71.7.53, %conv68.7.53
  %conv73.7.53 = trunc i32 %xor72.7.53 to i8
  store i8 %conv73.7.53, i8* %arrayidx70.53, align 1
  %scevgep20.8.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 8
  %19347 = load i8, i8* %scevgep20.8.53, align 1
  %conv68.8.53 = zext i8 %19347 to i32
  %19348 = load i8, i8* %arrayidx70.53, align 1
  %conv71.8.53 = zext i8 %19348 to i32
  %xor72.8.53 = xor i32 %conv71.8.53, %conv68.8.53
  %conv73.8.53 = trunc i32 %xor72.8.53 to i8
  store i8 %conv73.8.53, i8* %arrayidx70.53, align 1
  %scevgep20.9.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 9
  %19349 = load i8, i8* %scevgep20.9.53, align 1
  %conv68.9.53 = zext i8 %19349 to i32
  %19350 = load i8, i8* %arrayidx70.53, align 1
  %conv71.9.53 = zext i8 %19350 to i32
  %xor72.9.53 = xor i32 %conv71.9.53, %conv68.9.53
  %conv73.9.53 = trunc i32 %xor72.9.53 to i8
  store i8 %conv73.9.53, i8* %arrayidx70.53, align 1
  %scevgep20.10.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 10
  %19351 = load i8, i8* %scevgep20.10.53, align 1
  %conv68.10.53 = zext i8 %19351 to i32
  %19352 = load i8, i8* %arrayidx70.53, align 1
  %conv71.10.53 = zext i8 %19352 to i32
  %xor72.10.53 = xor i32 %conv71.10.53, %conv68.10.53
  %conv73.10.53 = trunc i32 %xor72.10.53 to i8
  store i8 %conv73.10.53, i8* %arrayidx70.53, align 1
  %scevgep20.11.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 11
  %19353 = load i8, i8* %scevgep20.11.53, align 1
  %conv68.11.53 = zext i8 %19353 to i32
  %19354 = load i8, i8* %arrayidx70.53, align 1
  %conv71.11.53 = zext i8 %19354 to i32
  %xor72.11.53 = xor i32 %conv71.11.53, %conv68.11.53
  %conv73.11.53 = trunc i32 %xor72.11.53 to i8
  store i8 %conv73.11.53, i8* %arrayidx70.53, align 1
  %scevgep20.12.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 12
  %19355 = load i8, i8* %scevgep20.12.53, align 1
  %conv68.12.53 = zext i8 %19355 to i32
  %19356 = load i8, i8* %arrayidx70.53, align 1
  %conv71.12.53 = zext i8 %19356 to i32
  %xor72.12.53 = xor i32 %conv71.12.53, %conv68.12.53
  %conv73.12.53 = trunc i32 %xor72.12.53 to i8
  store i8 %conv73.12.53, i8* %arrayidx70.53, align 1
  %scevgep20.13.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 13
  %19357 = load i8, i8* %scevgep20.13.53, align 1
  %conv68.13.53 = zext i8 %19357 to i32
  %19358 = load i8, i8* %arrayidx70.53, align 1
  %conv71.13.53 = zext i8 %19358 to i32
  %xor72.13.53 = xor i32 %conv71.13.53, %conv68.13.53
  %conv73.13.53 = trunc i32 %xor72.13.53 to i8
  store i8 %conv73.13.53, i8* %arrayidx70.53, align 1
  %scevgep20.14.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 14
  %19359 = load i8, i8* %scevgep20.14.53, align 1
  %conv68.14.53 = zext i8 %19359 to i32
  %19360 = load i8, i8* %arrayidx70.53, align 1
  %conv71.14.53 = zext i8 %19360 to i32
  %xor72.14.53 = xor i32 %conv71.14.53, %conv68.14.53
  %conv73.14.53 = trunc i32 %xor72.14.53 to i8
  store i8 %conv73.14.53, i8* %arrayidx70.53, align 1
  %scevgep20.15.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 15
  %19361 = load i8, i8* %scevgep20.15.53, align 1
  %conv68.15.53 = zext i8 %19361 to i32
  %19362 = load i8, i8* %arrayidx70.53, align 1
  %conv71.15.53 = zext i8 %19362 to i32
  %xor72.15.53 = xor i32 %conv71.15.53, %conv68.15.53
  %conv73.15.53 = trunc i32 %xor72.15.53 to i8
  store i8 %conv73.15.53, i8* %arrayidx70.53, align 1
  %scevgep20.16.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 16
  %19363 = load i8, i8* %scevgep20.16.53, align 1
  %conv68.16.53 = zext i8 %19363 to i32
  %19364 = load i8, i8* %arrayidx70.53, align 1
  %conv71.16.53 = zext i8 %19364 to i32
  %xor72.16.53 = xor i32 %conv71.16.53, %conv68.16.53
  %conv73.16.53 = trunc i32 %xor72.16.53 to i8
  store i8 %conv73.16.53, i8* %arrayidx70.53, align 1
  %scevgep20.17.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 17
  %19365 = load i8, i8* %scevgep20.17.53, align 1
  %conv68.17.53 = zext i8 %19365 to i32
  %19366 = load i8, i8* %arrayidx70.53, align 1
  %conv71.17.53 = zext i8 %19366 to i32
  %xor72.17.53 = xor i32 %conv71.17.53, %conv68.17.53
  %conv73.17.53 = trunc i32 %xor72.17.53 to i8
  store i8 %conv73.17.53, i8* %arrayidx70.53, align 1
  %scevgep20.18.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 18
  %19367 = load i8, i8* %scevgep20.18.53, align 1
  %conv68.18.53 = zext i8 %19367 to i32
  %19368 = load i8, i8* %arrayidx70.53, align 1
  %conv71.18.53 = zext i8 %19368 to i32
  %xor72.18.53 = xor i32 %conv71.18.53, %conv68.18.53
  %conv73.18.53 = trunc i32 %xor72.18.53 to i8
  store i8 %conv73.18.53, i8* %arrayidx70.53, align 1
  %scevgep20.19.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 19
  %19369 = load i8, i8* %scevgep20.19.53, align 1
  %conv68.19.53 = zext i8 %19369 to i32
  %19370 = load i8, i8* %arrayidx70.53, align 1
  %conv71.19.53 = zext i8 %19370 to i32
  %xor72.19.53 = xor i32 %conv71.19.53, %conv68.19.53
  %conv73.19.53 = trunc i32 %xor72.19.53 to i8
  store i8 %conv73.19.53, i8* %arrayidx70.53, align 1
  %scevgep20.20.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 20
  %19371 = load i8, i8* %scevgep20.20.53, align 1
  %conv68.20.53 = zext i8 %19371 to i32
  %19372 = load i8, i8* %arrayidx70.53, align 1
  %conv71.20.53 = zext i8 %19372 to i32
  %xor72.20.53 = xor i32 %conv71.20.53, %conv68.20.53
  %conv73.20.53 = trunc i32 %xor72.20.53 to i8
  store i8 %conv73.20.53, i8* %arrayidx70.53, align 1
  %scevgep20.21.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 21
  %19373 = load i8, i8* %scevgep20.21.53, align 1
  %conv68.21.53 = zext i8 %19373 to i32
  %19374 = load i8, i8* %arrayidx70.53, align 1
  %conv71.21.53 = zext i8 %19374 to i32
  %xor72.21.53 = xor i32 %conv71.21.53, %conv68.21.53
  %conv73.21.53 = trunc i32 %xor72.21.53 to i8
  store i8 %conv73.21.53, i8* %arrayidx70.53, align 1
  %scevgep20.22.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 22
  %19375 = load i8, i8* %scevgep20.22.53, align 1
  %conv68.22.53 = zext i8 %19375 to i32
  %19376 = load i8, i8* %arrayidx70.53, align 1
  %conv71.22.53 = zext i8 %19376 to i32
  %xor72.22.53 = xor i32 %conv71.22.53, %conv68.22.53
  %conv73.22.53 = trunc i32 %xor72.22.53 to i8
  store i8 %conv73.22.53, i8* %arrayidx70.53, align 1
  %scevgep20.23.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 23
  %19377 = load i8, i8* %scevgep20.23.53, align 1
  %conv68.23.53 = zext i8 %19377 to i32
  %19378 = load i8, i8* %arrayidx70.53, align 1
  %conv71.23.53 = zext i8 %19378 to i32
  %xor72.23.53 = xor i32 %conv71.23.53, %conv68.23.53
  %conv73.23.53 = trunc i32 %xor72.23.53 to i8
  store i8 %conv73.23.53, i8* %arrayidx70.53, align 1
  %scevgep20.24.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 24
  %19379 = load i8, i8* %scevgep20.24.53, align 1
  %conv68.24.53 = zext i8 %19379 to i32
  %19380 = load i8, i8* %arrayidx70.53, align 1
  %conv71.24.53 = zext i8 %19380 to i32
  %xor72.24.53 = xor i32 %conv71.24.53, %conv68.24.53
  %conv73.24.53 = trunc i32 %xor72.24.53 to i8
  store i8 %conv73.24.53, i8* %arrayidx70.53, align 1
  %scevgep20.25.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 25
  %19381 = load i8, i8* %scevgep20.25.53, align 1
  %conv68.25.53 = zext i8 %19381 to i32
  %19382 = load i8, i8* %arrayidx70.53, align 1
  %conv71.25.53 = zext i8 %19382 to i32
  %xor72.25.53 = xor i32 %conv71.25.53, %conv68.25.53
  %conv73.25.53 = trunc i32 %xor72.25.53 to i8
  store i8 %conv73.25.53, i8* %arrayidx70.53, align 1
  %scevgep20.26.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 26
  %19383 = load i8, i8* %scevgep20.26.53, align 1
  %conv68.26.53 = zext i8 %19383 to i32
  %19384 = load i8, i8* %arrayidx70.53, align 1
  %conv71.26.53 = zext i8 %19384 to i32
  %xor72.26.53 = xor i32 %conv71.26.53, %conv68.26.53
  %conv73.26.53 = trunc i32 %xor72.26.53 to i8
  store i8 %conv73.26.53, i8* %arrayidx70.53, align 1
  %scevgep20.27.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 27
  %19385 = load i8, i8* %scevgep20.27.53, align 1
  %conv68.27.53 = zext i8 %19385 to i32
  %19386 = load i8, i8* %arrayidx70.53, align 1
  %conv71.27.53 = zext i8 %19386 to i32
  %xor72.27.53 = xor i32 %conv71.27.53, %conv68.27.53
  %conv73.27.53 = trunc i32 %xor72.27.53 to i8
  store i8 %conv73.27.53, i8* %arrayidx70.53, align 1
  %scevgep20.28.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 28
  %19387 = load i8, i8* %scevgep20.28.53, align 1
  %conv68.28.53 = zext i8 %19387 to i32
  %19388 = load i8, i8* %arrayidx70.53, align 1
  %conv71.28.53 = zext i8 %19388 to i32
  %xor72.28.53 = xor i32 %conv71.28.53, %conv68.28.53
  %conv73.28.53 = trunc i32 %xor72.28.53 to i8
  store i8 %conv73.28.53, i8* %arrayidx70.53, align 1
  %scevgep20.29.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 29
  %19389 = load i8, i8* %scevgep20.29.53, align 1
  %conv68.29.53 = zext i8 %19389 to i32
  %19390 = load i8, i8* %arrayidx70.53, align 1
  %conv71.29.53 = zext i8 %19390 to i32
  %xor72.29.53 = xor i32 %conv71.29.53, %conv68.29.53
  %conv73.29.53 = trunc i32 %xor72.29.53 to i8
  store i8 %conv73.29.53, i8* %arrayidx70.53, align 1
  %scevgep20.30.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 30
  %19391 = load i8, i8* %scevgep20.30.53, align 1
  %conv68.30.53 = zext i8 %19391 to i32
  %19392 = load i8, i8* %arrayidx70.53, align 1
  %conv71.30.53 = zext i8 %19392 to i32
  %xor72.30.53 = xor i32 %conv71.30.53, %conv68.30.53
  %conv73.30.53 = trunc i32 %xor72.30.53 to i8
  store i8 %conv73.30.53, i8* %arrayidx70.53, align 1
  %scevgep20.31.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 31
  %19393 = load i8, i8* %scevgep20.31.53, align 1
  %conv68.31.53 = zext i8 %19393 to i32
  %19394 = load i8, i8* %arrayidx70.53, align 1
  %conv71.31.53 = zext i8 %19394 to i32
  %xor72.31.53 = xor i32 %conv71.31.53, %conv68.31.53
  %conv73.31.53 = trunc i32 %xor72.31.53 to i8
  store i8 %conv73.31.53, i8* %arrayidx70.53, align 1
  %scevgep20.32.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 32
  %19395 = load i8, i8* %scevgep20.32.53, align 1
  %conv68.32.53 = zext i8 %19395 to i32
  %19396 = load i8, i8* %arrayidx70.53, align 1
  %conv71.32.53 = zext i8 %19396 to i32
  %xor72.32.53 = xor i32 %conv71.32.53, %conv68.32.53
  %conv73.32.53 = trunc i32 %xor72.32.53 to i8
  store i8 %conv73.32.53, i8* %arrayidx70.53, align 1
  %scevgep20.33.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 33
  %19397 = load i8, i8* %scevgep20.33.53, align 1
  %conv68.33.53 = zext i8 %19397 to i32
  %19398 = load i8, i8* %arrayidx70.53, align 1
  %conv71.33.53 = zext i8 %19398 to i32
  %xor72.33.53 = xor i32 %conv71.33.53, %conv68.33.53
  %conv73.33.53 = trunc i32 %xor72.33.53 to i8
  store i8 %conv73.33.53, i8* %arrayidx70.53, align 1
  %scevgep20.34.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 34
  %19399 = load i8, i8* %scevgep20.34.53, align 1
  %conv68.34.53 = zext i8 %19399 to i32
  %19400 = load i8, i8* %arrayidx70.53, align 1
  %conv71.34.53 = zext i8 %19400 to i32
  %xor72.34.53 = xor i32 %conv71.34.53, %conv68.34.53
  %conv73.34.53 = trunc i32 %xor72.34.53 to i8
  store i8 %conv73.34.53, i8* %arrayidx70.53, align 1
  %scevgep20.35.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 35
  %19401 = load i8, i8* %scevgep20.35.53, align 1
  %conv68.35.53 = zext i8 %19401 to i32
  %19402 = load i8, i8* %arrayidx70.53, align 1
  %conv71.35.53 = zext i8 %19402 to i32
  %xor72.35.53 = xor i32 %conv71.35.53, %conv68.35.53
  %conv73.35.53 = trunc i32 %xor72.35.53 to i8
  store i8 %conv73.35.53, i8* %arrayidx70.53, align 1
  %scevgep20.36.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 36
  %19403 = load i8, i8* %scevgep20.36.53, align 1
  %conv68.36.53 = zext i8 %19403 to i32
  %19404 = load i8, i8* %arrayidx70.53, align 1
  %conv71.36.53 = zext i8 %19404 to i32
  %xor72.36.53 = xor i32 %conv71.36.53, %conv68.36.53
  %conv73.36.53 = trunc i32 %xor72.36.53 to i8
  store i8 %conv73.36.53, i8* %arrayidx70.53, align 1
  %scevgep20.37.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 37
  %19405 = load i8, i8* %scevgep20.37.53, align 1
  %conv68.37.53 = zext i8 %19405 to i32
  %19406 = load i8, i8* %arrayidx70.53, align 1
  %conv71.37.53 = zext i8 %19406 to i32
  %xor72.37.53 = xor i32 %conv71.37.53, %conv68.37.53
  %conv73.37.53 = trunc i32 %xor72.37.53 to i8
  store i8 %conv73.37.53, i8* %arrayidx70.53, align 1
  %scevgep20.38.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 38
  %19407 = load i8, i8* %scevgep20.38.53, align 1
  %conv68.38.53 = zext i8 %19407 to i32
  %19408 = load i8, i8* %arrayidx70.53, align 1
  %conv71.38.53 = zext i8 %19408 to i32
  %xor72.38.53 = xor i32 %conv71.38.53, %conv68.38.53
  %conv73.38.53 = trunc i32 %xor72.38.53 to i8
  store i8 %conv73.38.53, i8* %arrayidx70.53, align 1
  %scevgep20.39.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 39
  %19409 = load i8, i8* %scevgep20.39.53, align 1
  %conv68.39.53 = zext i8 %19409 to i32
  %19410 = load i8, i8* %arrayidx70.53, align 1
  %conv71.39.53 = zext i8 %19410 to i32
  %xor72.39.53 = xor i32 %conv71.39.53, %conv68.39.53
  %conv73.39.53 = trunc i32 %xor72.39.53 to i8
  store i8 %conv73.39.53, i8* %arrayidx70.53, align 1
  %scevgep20.40.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 40
  %19411 = load i8, i8* %scevgep20.40.53, align 1
  %conv68.40.53 = zext i8 %19411 to i32
  %19412 = load i8, i8* %arrayidx70.53, align 1
  %conv71.40.53 = zext i8 %19412 to i32
  %xor72.40.53 = xor i32 %conv71.40.53, %conv68.40.53
  %conv73.40.53 = trunc i32 %xor72.40.53 to i8
  store i8 %conv73.40.53, i8* %arrayidx70.53, align 1
  %scevgep20.41.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 41
  %19413 = load i8, i8* %scevgep20.41.53, align 1
  %conv68.41.53 = zext i8 %19413 to i32
  %19414 = load i8, i8* %arrayidx70.53, align 1
  %conv71.41.53 = zext i8 %19414 to i32
  %xor72.41.53 = xor i32 %conv71.41.53, %conv68.41.53
  %conv73.41.53 = trunc i32 %xor72.41.53 to i8
  store i8 %conv73.41.53, i8* %arrayidx70.53, align 1
  %scevgep20.42.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 42
  %19415 = load i8, i8* %scevgep20.42.53, align 1
  %conv68.42.53 = zext i8 %19415 to i32
  %19416 = load i8, i8* %arrayidx70.53, align 1
  %conv71.42.53 = zext i8 %19416 to i32
  %xor72.42.53 = xor i32 %conv71.42.53, %conv68.42.53
  %conv73.42.53 = trunc i32 %xor72.42.53 to i8
  store i8 %conv73.42.53, i8* %arrayidx70.53, align 1
  %scevgep20.43.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 43
  %19417 = load i8, i8* %scevgep20.43.53, align 1
  %conv68.43.53 = zext i8 %19417 to i32
  %19418 = load i8, i8* %arrayidx70.53, align 1
  %conv71.43.53 = zext i8 %19418 to i32
  %xor72.43.53 = xor i32 %conv71.43.53, %conv68.43.53
  %conv73.43.53 = trunc i32 %xor72.43.53 to i8
  store i8 %conv73.43.53, i8* %arrayidx70.53, align 1
  %scevgep20.44.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 44
  %19419 = load i8, i8* %scevgep20.44.53, align 1
  %conv68.44.53 = zext i8 %19419 to i32
  %19420 = load i8, i8* %arrayidx70.53, align 1
  %conv71.44.53 = zext i8 %19420 to i32
  %xor72.44.53 = xor i32 %conv71.44.53, %conv68.44.53
  %conv73.44.53 = trunc i32 %xor72.44.53 to i8
  store i8 %conv73.44.53, i8* %arrayidx70.53, align 1
  %scevgep20.45.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 45
  %19421 = load i8, i8* %scevgep20.45.53, align 1
  %conv68.45.53 = zext i8 %19421 to i32
  %19422 = load i8, i8* %arrayidx70.53, align 1
  %conv71.45.53 = zext i8 %19422 to i32
  %xor72.45.53 = xor i32 %conv71.45.53, %conv68.45.53
  %conv73.45.53 = trunc i32 %xor72.45.53 to i8
  store i8 %conv73.45.53, i8* %arrayidx70.53, align 1
  %scevgep20.46.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 46
  %19423 = load i8, i8* %scevgep20.46.53, align 1
  %conv68.46.53 = zext i8 %19423 to i32
  %19424 = load i8, i8* %arrayidx70.53, align 1
  %conv71.46.53 = zext i8 %19424 to i32
  %xor72.46.53 = xor i32 %conv71.46.53, %conv68.46.53
  %conv73.46.53 = trunc i32 %xor72.46.53 to i8
  store i8 %conv73.46.53, i8* %arrayidx70.53, align 1
  %scevgep20.47.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 47
  %19425 = load i8, i8* %scevgep20.47.53, align 1
  %conv68.47.53 = zext i8 %19425 to i32
  %19426 = load i8, i8* %arrayidx70.53, align 1
  %conv71.47.53 = zext i8 %19426 to i32
  %xor72.47.53 = xor i32 %conv71.47.53, %conv68.47.53
  %conv73.47.53 = trunc i32 %xor72.47.53 to i8
  store i8 %conv73.47.53, i8* %arrayidx70.53, align 1
  %scevgep20.48.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 48
  %19427 = load i8, i8* %scevgep20.48.53, align 1
  %conv68.48.53 = zext i8 %19427 to i32
  %19428 = load i8, i8* %arrayidx70.53, align 1
  %conv71.48.53 = zext i8 %19428 to i32
  %xor72.48.53 = xor i32 %conv71.48.53, %conv68.48.53
  %conv73.48.53 = trunc i32 %xor72.48.53 to i8
  store i8 %conv73.48.53, i8* %arrayidx70.53, align 1
  %scevgep20.49.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 49
  %19429 = load i8, i8* %scevgep20.49.53, align 1
  %conv68.49.53 = zext i8 %19429 to i32
  %19430 = load i8, i8* %arrayidx70.53, align 1
  %conv71.49.53 = zext i8 %19430 to i32
  %xor72.49.53 = xor i32 %conv71.49.53, %conv68.49.53
  %conv73.49.53 = trunc i32 %xor72.49.53 to i8
  store i8 %conv73.49.53, i8* %arrayidx70.53, align 1
  %scevgep20.50.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 50
  %19431 = load i8, i8* %scevgep20.50.53, align 1
  %conv68.50.53 = zext i8 %19431 to i32
  %19432 = load i8, i8* %arrayidx70.53, align 1
  %conv71.50.53 = zext i8 %19432 to i32
  %xor72.50.53 = xor i32 %conv71.50.53, %conv68.50.53
  %conv73.50.53 = trunc i32 %xor72.50.53 to i8
  store i8 %conv73.50.53, i8* %arrayidx70.53, align 1
  %scevgep20.51.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 51
  %19433 = load i8, i8* %scevgep20.51.53, align 1
  %conv68.51.53 = zext i8 %19433 to i32
  %19434 = load i8, i8* %arrayidx70.53, align 1
  %conv71.51.53 = zext i8 %19434 to i32
  %xor72.51.53 = xor i32 %conv71.51.53, %conv68.51.53
  %conv73.51.53 = trunc i32 %xor72.51.53 to i8
  store i8 %conv73.51.53, i8* %arrayidx70.53, align 1
  %scevgep20.52.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 52
  %19435 = load i8, i8* %scevgep20.52.53, align 1
  %conv68.52.53 = zext i8 %19435 to i32
  %19436 = load i8, i8* %arrayidx70.53, align 1
  %conv71.52.53 = zext i8 %19436 to i32
  %xor72.52.53 = xor i32 %conv71.52.53, %conv68.52.53
  %conv73.52.53 = trunc i32 %xor72.52.53 to i8
  store i8 %conv73.52.53, i8* %arrayidx70.53, align 1
  %scevgep20.54.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 54
  %19437 = load i8, i8* %scevgep20.54.53, align 1
  %conv68.54.53 = zext i8 %19437 to i32
  %19438 = load i8, i8* %arrayidx70.53, align 1
  %conv71.54.53 = zext i8 %19438 to i32
  %xor72.54.53 = xor i32 %conv71.54.53, %conv68.54.53
  %conv73.54.53 = trunc i32 %xor72.54.53 to i8
  store i8 %conv73.54.53, i8* %arrayidx70.53, align 1
  %scevgep20.55.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 55
  %19439 = load i8, i8* %scevgep20.55.53, align 1
  %conv68.55.53 = zext i8 %19439 to i32
  %19440 = load i8, i8* %arrayidx70.53, align 1
  %conv71.55.53 = zext i8 %19440 to i32
  %xor72.55.53 = xor i32 %conv71.55.53, %conv68.55.53
  %conv73.55.53 = trunc i32 %xor72.55.53 to i8
  store i8 %conv73.55.53, i8* %arrayidx70.53, align 1
  %scevgep20.56.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 56
  %19441 = load i8, i8* %scevgep20.56.53, align 1
  %conv68.56.53 = zext i8 %19441 to i32
  %19442 = load i8, i8* %arrayidx70.53, align 1
  %conv71.56.53 = zext i8 %19442 to i32
  %xor72.56.53 = xor i32 %conv71.56.53, %conv68.56.53
  %conv73.56.53 = trunc i32 %xor72.56.53 to i8
  store i8 %conv73.56.53, i8* %arrayidx70.53, align 1
  %scevgep20.57.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 57
  %19443 = load i8, i8* %scevgep20.57.53, align 1
  %conv68.57.53 = zext i8 %19443 to i32
  %19444 = load i8, i8* %arrayidx70.53, align 1
  %conv71.57.53 = zext i8 %19444 to i32
  %xor72.57.53 = xor i32 %conv71.57.53, %conv68.57.53
  %conv73.57.53 = trunc i32 %xor72.57.53 to i8
  store i8 %conv73.57.53, i8* %arrayidx70.53, align 1
  %scevgep20.58.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 58
  %19445 = load i8, i8* %scevgep20.58.53, align 1
  %conv68.58.53 = zext i8 %19445 to i32
  %19446 = load i8, i8* %arrayidx70.53, align 1
  %conv71.58.53 = zext i8 %19446 to i32
  %xor72.58.53 = xor i32 %conv71.58.53, %conv68.58.53
  %conv73.58.53 = trunc i32 %xor72.58.53 to i8
  store i8 %conv73.58.53, i8* %arrayidx70.53, align 1
  %scevgep20.59.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 59
  %19447 = load i8, i8* %scevgep20.59.53, align 1
  %conv68.59.53 = zext i8 %19447 to i32
  %19448 = load i8, i8* %arrayidx70.53, align 1
  %conv71.59.53 = zext i8 %19448 to i32
  %xor72.59.53 = xor i32 %conv71.59.53, %conv68.59.53
  %conv73.59.53 = trunc i32 %xor72.59.53 to i8
  store i8 %conv73.59.53, i8* %arrayidx70.53, align 1
  %scevgep20.60.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 0, i64 60
  %19449 = load i8, i8* %scevgep20.60.53, align 1
  %conv68.60.53 = zext i8 %19449 to i32
  %19450 = load i8, i8* %arrayidx70.53, align 1
  %conv71.60.53 = zext i8 %19450 to i32
  %xor72.60.53 = xor i32 %conv71.60.53, %conv68.60.53
  %conv73.60.53 = trunc i32 %xor72.60.53 to i8
  store i8 %conv73.60.53, i8* %arrayidx70.53, align 1
  %scevgep19.53 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19328, i64 0, i64 1, i64 0
  %19451 = bitcast i8* %scevgep19.53 to [61 x [61 x i8]]*
  %arrayidx51.54 = getelementptr inbounds i8, i8* %a, i64 54
  %19452 = load i8, i8* %arrayidx51.54, align 1
  %arrayidx53.54 = getelementptr inbounds i8, i8* %b, i64 54
  %19453 = load i8, i8* %arrayidx53.54, align 1
  %call54.54 = call zeroext i8 @mult(i8 zeroext %19452, i8 zeroext %19453)
  %arrayidx56.54 = getelementptr inbounds i8, i8* %c, i64 54
  store i8 %call54.54, i8* %arrayidx56.54, align 1
  %arrayidx70.54 = getelementptr inbounds i8, i8* %c, i64 54
  %scevgep20.54584 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 0
  %19454 = load i8, i8* %scevgep20.54584, align 1
  %conv68.54585 = zext i8 %19454 to i32
  %19455 = load i8, i8* %arrayidx70.54, align 1
  %conv71.54586 = zext i8 %19455 to i32
  %xor72.54587 = xor i32 %conv71.54586, %conv68.54585
  %conv73.54588 = trunc i32 %xor72.54587 to i8
  store i8 %conv73.54588, i8* %arrayidx70.54, align 1
  %scevgep20.1.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 1
  %19456 = load i8, i8* %scevgep20.1.54, align 1
  %conv68.1.54 = zext i8 %19456 to i32
  %19457 = load i8, i8* %arrayidx70.54, align 1
  %conv71.1.54 = zext i8 %19457 to i32
  %xor72.1.54 = xor i32 %conv71.1.54, %conv68.1.54
  %conv73.1.54 = trunc i32 %xor72.1.54 to i8
  store i8 %conv73.1.54, i8* %arrayidx70.54, align 1
  %scevgep20.2.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 2
  %19458 = load i8, i8* %scevgep20.2.54, align 1
  %conv68.2.54 = zext i8 %19458 to i32
  %19459 = load i8, i8* %arrayidx70.54, align 1
  %conv71.2.54 = zext i8 %19459 to i32
  %xor72.2.54 = xor i32 %conv71.2.54, %conv68.2.54
  %conv73.2.54 = trunc i32 %xor72.2.54 to i8
  store i8 %conv73.2.54, i8* %arrayidx70.54, align 1
  %scevgep20.3.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 3
  %19460 = load i8, i8* %scevgep20.3.54, align 1
  %conv68.3.54 = zext i8 %19460 to i32
  %19461 = load i8, i8* %arrayidx70.54, align 1
  %conv71.3.54 = zext i8 %19461 to i32
  %xor72.3.54 = xor i32 %conv71.3.54, %conv68.3.54
  %conv73.3.54 = trunc i32 %xor72.3.54 to i8
  store i8 %conv73.3.54, i8* %arrayidx70.54, align 1
  %scevgep20.4.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 4
  %19462 = load i8, i8* %scevgep20.4.54, align 1
  %conv68.4.54 = zext i8 %19462 to i32
  %19463 = load i8, i8* %arrayidx70.54, align 1
  %conv71.4.54 = zext i8 %19463 to i32
  %xor72.4.54 = xor i32 %conv71.4.54, %conv68.4.54
  %conv73.4.54 = trunc i32 %xor72.4.54 to i8
  store i8 %conv73.4.54, i8* %arrayidx70.54, align 1
  %scevgep20.5.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 5
  %19464 = load i8, i8* %scevgep20.5.54, align 1
  %conv68.5.54 = zext i8 %19464 to i32
  %19465 = load i8, i8* %arrayidx70.54, align 1
  %conv71.5.54 = zext i8 %19465 to i32
  %xor72.5.54 = xor i32 %conv71.5.54, %conv68.5.54
  %conv73.5.54 = trunc i32 %xor72.5.54 to i8
  store i8 %conv73.5.54, i8* %arrayidx70.54, align 1
  %scevgep20.6.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 6
  %19466 = load i8, i8* %scevgep20.6.54, align 1
  %conv68.6.54 = zext i8 %19466 to i32
  %19467 = load i8, i8* %arrayidx70.54, align 1
  %conv71.6.54 = zext i8 %19467 to i32
  %xor72.6.54 = xor i32 %conv71.6.54, %conv68.6.54
  %conv73.6.54 = trunc i32 %xor72.6.54 to i8
  store i8 %conv73.6.54, i8* %arrayidx70.54, align 1
  %scevgep20.7.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 7
  %19468 = load i8, i8* %scevgep20.7.54, align 1
  %conv68.7.54 = zext i8 %19468 to i32
  %19469 = load i8, i8* %arrayidx70.54, align 1
  %conv71.7.54 = zext i8 %19469 to i32
  %xor72.7.54 = xor i32 %conv71.7.54, %conv68.7.54
  %conv73.7.54 = trunc i32 %xor72.7.54 to i8
  store i8 %conv73.7.54, i8* %arrayidx70.54, align 1
  %scevgep20.8.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 8
  %19470 = load i8, i8* %scevgep20.8.54, align 1
  %conv68.8.54 = zext i8 %19470 to i32
  %19471 = load i8, i8* %arrayidx70.54, align 1
  %conv71.8.54 = zext i8 %19471 to i32
  %xor72.8.54 = xor i32 %conv71.8.54, %conv68.8.54
  %conv73.8.54 = trunc i32 %xor72.8.54 to i8
  store i8 %conv73.8.54, i8* %arrayidx70.54, align 1
  %scevgep20.9.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 9
  %19472 = load i8, i8* %scevgep20.9.54, align 1
  %conv68.9.54 = zext i8 %19472 to i32
  %19473 = load i8, i8* %arrayidx70.54, align 1
  %conv71.9.54 = zext i8 %19473 to i32
  %xor72.9.54 = xor i32 %conv71.9.54, %conv68.9.54
  %conv73.9.54 = trunc i32 %xor72.9.54 to i8
  store i8 %conv73.9.54, i8* %arrayidx70.54, align 1
  %scevgep20.10.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 10
  %19474 = load i8, i8* %scevgep20.10.54, align 1
  %conv68.10.54 = zext i8 %19474 to i32
  %19475 = load i8, i8* %arrayidx70.54, align 1
  %conv71.10.54 = zext i8 %19475 to i32
  %xor72.10.54 = xor i32 %conv71.10.54, %conv68.10.54
  %conv73.10.54 = trunc i32 %xor72.10.54 to i8
  store i8 %conv73.10.54, i8* %arrayidx70.54, align 1
  %scevgep20.11.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 11
  %19476 = load i8, i8* %scevgep20.11.54, align 1
  %conv68.11.54 = zext i8 %19476 to i32
  %19477 = load i8, i8* %arrayidx70.54, align 1
  %conv71.11.54 = zext i8 %19477 to i32
  %xor72.11.54 = xor i32 %conv71.11.54, %conv68.11.54
  %conv73.11.54 = trunc i32 %xor72.11.54 to i8
  store i8 %conv73.11.54, i8* %arrayidx70.54, align 1
  %scevgep20.12.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 12
  %19478 = load i8, i8* %scevgep20.12.54, align 1
  %conv68.12.54 = zext i8 %19478 to i32
  %19479 = load i8, i8* %arrayidx70.54, align 1
  %conv71.12.54 = zext i8 %19479 to i32
  %xor72.12.54 = xor i32 %conv71.12.54, %conv68.12.54
  %conv73.12.54 = trunc i32 %xor72.12.54 to i8
  store i8 %conv73.12.54, i8* %arrayidx70.54, align 1
  %scevgep20.13.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 13
  %19480 = load i8, i8* %scevgep20.13.54, align 1
  %conv68.13.54 = zext i8 %19480 to i32
  %19481 = load i8, i8* %arrayidx70.54, align 1
  %conv71.13.54 = zext i8 %19481 to i32
  %xor72.13.54 = xor i32 %conv71.13.54, %conv68.13.54
  %conv73.13.54 = trunc i32 %xor72.13.54 to i8
  store i8 %conv73.13.54, i8* %arrayidx70.54, align 1
  %scevgep20.14.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 14
  %19482 = load i8, i8* %scevgep20.14.54, align 1
  %conv68.14.54 = zext i8 %19482 to i32
  %19483 = load i8, i8* %arrayidx70.54, align 1
  %conv71.14.54 = zext i8 %19483 to i32
  %xor72.14.54 = xor i32 %conv71.14.54, %conv68.14.54
  %conv73.14.54 = trunc i32 %xor72.14.54 to i8
  store i8 %conv73.14.54, i8* %arrayidx70.54, align 1
  %scevgep20.15.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 15
  %19484 = load i8, i8* %scevgep20.15.54, align 1
  %conv68.15.54 = zext i8 %19484 to i32
  %19485 = load i8, i8* %arrayidx70.54, align 1
  %conv71.15.54 = zext i8 %19485 to i32
  %xor72.15.54 = xor i32 %conv71.15.54, %conv68.15.54
  %conv73.15.54 = trunc i32 %xor72.15.54 to i8
  store i8 %conv73.15.54, i8* %arrayidx70.54, align 1
  %scevgep20.16.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 16
  %19486 = load i8, i8* %scevgep20.16.54, align 1
  %conv68.16.54 = zext i8 %19486 to i32
  %19487 = load i8, i8* %arrayidx70.54, align 1
  %conv71.16.54 = zext i8 %19487 to i32
  %xor72.16.54 = xor i32 %conv71.16.54, %conv68.16.54
  %conv73.16.54 = trunc i32 %xor72.16.54 to i8
  store i8 %conv73.16.54, i8* %arrayidx70.54, align 1
  %scevgep20.17.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 17
  %19488 = load i8, i8* %scevgep20.17.54, align 1
  %conv68.17.54 = zext i8 %19488 to i32
  %19489 = load i8, i8* %arrayidx70.54, align 1
  %conv71.17.54 = zext i8 %19489 to i32
  %xor72.17.54 = xor i32 %conv71.17.54, %conv68.17.54
  %conv73.17.54 = trunc i32 %xor72.17.54 to i8
  store i8 %conv73.17.54, i8* %arrayidx70.54, align 1
  %scevgep20.18.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 18
  %19490 = load i8, i8* %scevgep20.18.54, align 1
  %conv68.18.54 = zext i8 %19490 to i32
  %19491 = load i8, i8* %arrayidx70.54, align 1
  %conv71.18.54 = zext i8 %19491 to i32
  %xor72.18.54 = xor i32 %conv71.18.54, %conv68.18.54
  %conv73.18.54 = trunc i32 %xor72.18.54 to i8
  store i8 %conv73.18.54, i8* %arrayidx70.54, align 1
  %scevgep20.19.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 19
  %19492 = load i8, i8* %scevgep20.19.54, align 1
  %conv68.19.54 = zext i8 %19492 to i32
  %19493 = load i8, i8* %arrayidx70.54, align 1
  %conv71.19.54 = zext i8 %19493 to i32
  %xor72.19.54 = xor i32 %conv71.19.54, %conv68.19.54
  %conv73.19.54 = trunc i32 %xor72.19.54 to i8
  store i8 %conv73.19.54, i8* %arrayidx70.54, align 1
  %scevgep20.20.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 20
  %19494 = load i8, i8* %scevgep20.20.54, align 1
  %conv68.20.54 = zext i8 %19494 to i32
  %19495 = load i8, i8* %arrayidx70.54, align 1
  %conv71.20.54 = zext i8 %19495 to i32
  %xor72.20.54 = xor i32 %conv71.20.54, %conv68.20.54
  %conv73.20.54 = trunc i32 %xor72.20.54 to i8
  store i8 %conv73.20.54, i8* %arrayidx70.54, align 1
  %scevgep20.21.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 21
  %19496 = load i8, i8* %scevgep20.21.54, align 1
  %conv68.21.54 = zext i8 %19496 to i32
  %19497 = load i8, i8* %arrayidx70.54, align 1
  %conv71.21.54 = zext i8 %19497 to i32
  %xor72.21.54 = xor i32 %conv71.21.54, %conv68.21.54
  %conv73.21.54 = trunc i32 %xor72.21.54 to i8
  store i8 %conv73.21.54, i8* %arrayidx70.54, align 1
  %scevgep20.22.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 22
  %19498 = load i8, i8* %scevgep20.22.54, align 1
  %conv68.22.54 = zext i8 %19498 to i32
  %19499 = load i8, i8* %arrayidx70.54, align 1
  %conv71.22.54 = zext i8 %19499 to i32
  %xor72.22.54 = xor i32 %conv71.22.54, %conv68.22.54
  %conv73.22.54 = trunc i32 %xor72.22.54 to i8
  store i8 %conv73.22.54, i8* %arrayidx70.54, align 1
  %scevgep20.23.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 23
  %19500 = load i8, i8* %scevgep20.23.54, align 1
  %conv68.23.54 = zext i8 %19500 to i32
  %19501 = load i8, i8* %arrayidx70.54, align 1
  %conv71.23.54 = zext i8 %19501 to i32
  %xor72.23.54 = xor i32 %conv71.23.54, %conv68.23.54
  %conv73.23.54 = trunc i32 %xor72.23.54 to i8
  store i8 %conv73.23.54, i8* %arrayidx70.54, align 1
  %scevgep20.24.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 24
  %19502 = load i8, i8* %scevgep20.24.54, align 1
  %conv68.24.54 = zext i8 %19502 to i32
  %19503 = load i8, i8* %arrayidx70.54, align 1
  %conv71.24.54 = zext i8 %19503 to i32
  %xor72.24.54 = xor i32 %conv71.24.54, %conv68.24.54
  %conv73.24.54 = trunc i32 %xor72.24.54 to i8
  store i8 %conv73.24.54, i8* %arrayidx70.54, align 1
  %scevgep20.25.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 25
  %19504 = load i8, i8* %scevgep20.25.54, align 1
  %conv68.25.54 = zext i8 %19504 to i32
  %19505 = load i8, i8* %arrayidx70.54, align 1
  %conv71.25.54 = zext i8 %19505 to i32
  %xor72.25.54 = xor i32 %conv71.25.54, %conv68.25.54
  %conv73.25.54 = trunc i32 %xor72.25.54 to i8
  store i8 %conv73.25.54, i8* %arrayidx70.54, align 1
  %scevgep20.26.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 26
  %19506 = load i8, i8* %scevgep20.26.54, align 1
  %conv68.26.54 = zext i8 %19506 to i32
  %19507 = load i8, i8* %arrayidx70.54, align 1
  %conv71.26.54 = zext i8 %19507 to i32
  %xor72.26.54 = xor i32 %conv71.26.54, %conv68.26.54
  %conv73.26.54 = trunc i32 %xor72.26.54 to i8
  store i8 %conv73.26.54, i8* %arrayidx70.54, align 1
  %scevgep20.27.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 27
  %19508 = load i8, i8* %scevgep20.27.54, align 1
  %conv68.27.54 = zext i8 %19508 to i32
  %19509 = load i8, i8* %arrayidx70.54, align 1
  %conv71.27.54 = zext i8 %19509 to i32
  %xor72.27.54 = xor i32 %conv71.27.54, %conv68.27.54
  %conv73.27.54 = trunc i32 %xor72.27.54 to i8
  store i8 %conv73.27.54, i8* %arrayidx70.54, align 1
  %scevgep20.28.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 28
  %19510 = load i8, i8* %scevgep20.28.54, align 1
  %conv68.28.54 = zext i8 %19510 to i32
  %19511 = load i8, i8* %arrayidx70.54, align 1
  %conv71.28.54 = zext i8 %19511 to i32
  %xor72.28.54 = xor i32 %conv71.28.54, %conv68.28.54
  %conv73.28.54 = trunc i32 %xor72.28.54 to i8
  store i8 %conv73.28.54, i8* %arrayidx70.54, align 1
  %scevgep20.29.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 29
  %19512 = load i8, i8* %scevgep20.29.54, align 1
  %conv68.29.54 = zext i8 %19512 to i32
  %19513 = load i8, i8* %arrayidx70.54, align 1
  %conv71.29.54 = zext i8 %19513 to i32
  %xor72.29.54 = xor i32 %conv71.29.54, %conv68.29.54
  %conv73.29.54 = trunc i32 %xor72.29.54 to i8
  store i8 %conv73.29.54, i8* %arrayidx70.54, align 1
  %scevgep20.30.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 30
  %19514 = load i8, i8* %scevgep20.30.54, align 1
  %conv68.30.54 = zext i8 %19514 to i32
  %19515 = load i8, i8* %arrayidx70.54, align 1
  %conv71.30.54 = zext i8 %19515 to i32
  %xor72.30.54 = xor i32 %conv71.30.54, %conv68.30.54
  %conv73.30.54 = trunc i32 %xor72.30.54 to i8
  store i8 %conv73.30.54, i8* %arrayidx70.54, align 1
  %scevgep20.31.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 31
  %19516 = load i8, i8* %scevgep20.31.54, align 1
  %conv68.31.54 = zext i8 %19516 to i32
  %19517 = load i8, i8* %arrayidx70.54, align 1
  %conv71.31.54 = zext i8 %19517 to i32
  %xor72.31.54 = xor i32 %conv71.31.54, %conv68.31.54
  %conv73.31.54 = trunc i32 %xor72.31.54 to i8
  store i8 %conv73.31.54, i8* %arrayidx70.54, align 1
  %scevgep20.32.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 32
  %19518 = load i8, i8* %scevgep20.32.54, align 1
  %conv68.32.54 = zext i8 %19518 to i32
  %19519 = load i8, i8* %arrayidx70.54, align 1
  %conv71.32.54 = zext i8 %19519 to i32
  %xor72.32.54 = xor i32 %conv71.32.54, %conv68.32.54
  %conv73.32.54 = trunc i32 %xor72.32.54 to i8
  store i8 %conv73.32.54, i8* %arrayidx70.54, align 1
  %scevgep20.33.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 33
  %19520 = load i8, i8* %scevgep20.33.54, align 1
  %conv68.33.54 = zext i8 %19520 to i32
  %19521 = load i8, i8* %arrayidx70.54, align 1
  %conv71.33.54 = zext i8 %19521 to i32
  %xor72.33.54 = xor i32 %conv71.33.54, %conv68.33.54
  %conv73.33.54 = trunc i32 %xor72.33.54 to i8
  store i8 %conv73.33.54, i8* %arrayidx70.54, align 1
  %scevgep20.34.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 34
  %19522 = load i8, i8* %scevgep20.34.54, align 1
  %conv68.34.54 = zext i8 %19522 to i32
  %19523 = load i8, i8* %arrayidx70.54, align 1
  %conv71.34.54 = zext i8 %19523 to i32
  %xor72.34.54 = xor i32 %conv71.34.54, %conv68.34.54
  %conv73.34.54 = trunc i32 %xor72.34.54 to i8
  store i8 %conv73.34.54, i8* %arrayidx70.54, align 1
  %scevgep20.35.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 35
  %19524 = load i8, i8* %scevgep20.35.54, align 1
  %conv68.35.54 = zext i8 %19524 to i32
  %19525 = load i8, i8* %arrayidx70.54, align 1
  %conv71.35.54 = zext i8 %19525 to i32
  %xor72.35.54 = xor i32 %conv71.35.54, %conv68.35.54
  %conv73.35.54 = trunc i32 %xor72.35.54 to i8
  store i8 %conv73.35.54, i8* %arrayidx70.54, align 1
  %scevgep20.36.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 36
  %19526 = load i8, i8* %scevgep20.36.54, align 1
  %conv68.36.54 = zext i8 %19526 to i32
  %19527 = load i8, i8* %arrayidx70.54, align 1
  %conv71.36.54 = zext i8 %19527 to i32
  %xor72.36.54 = xor i32 %conv71.36.54, %conv68.36.54
  %conv73.36.54 = trunc i32 %xor72.36.54 to i8
  store i8 %conv73.36.54, i8* %arrayidx70.54, align 1
  %scevgep20.37.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 37
  %19528 = load i8, i8* %scevgep20.37.54, align 1
  %conv68.37.54 = zext i8 %19528 to i32
  %19529 = load i8, i8* %arrayidx70.54, align 1
  %conv71.37.54 = zext i8 %19529 to i32
  %xor72.37.54 = xor i32 %conv71.37.54, %conv68.37.54
  %conv73.37.54 = trunc i32 %xor72.37.54 to i8
  store i8 %conv73.37.54, i8* %arrayidx70.54, align 1
  %scevgep20.38.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 38
  %19530 = load i8, i8* %scevgep20.38.54, align 1
  %conv68.38.54 = zext i8 %19530 to i32
  %19531 = load i8, i8* %arrayidx70.54, align 1
  %conv71.38.54 = zext i8 %19531 to i32
  %xor72.38.54 = xor i32 %conv71.38.54, %conv68.38.54
  %conv73.38.54 = trunc i32 %xor72.38.54 to i8
  store i8 %conv73.38.54, i8* %arrayidx70.54, align 1
  %scevgep20.39.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 39
  %19532 = load i8, i8* %scevgep20.39.54, align 1
  %conv68.39.54 = zext i8 %19532 to i32
  %19533 = load i8, i8* %arrayidx70.54, align 1
  %conv71.39.54 = zext i8 %19533 to i32
  %xor72.39.54 = xor i32 %conv71.39.54, %conv68.39.54
  %conv73.39.54 = trunc i32 %xor72.39.54 to i8
  store i8 %conv73.39.54, i8* %arrayidx70.54, align 1
  %scevgep20.40.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 40
  %19534 = load i8, i8* %scevgep20.40.54, align 1
  %conv68.40.54 = zext i8 %19534 to i32
  %19535 = load i8, i8* %arrayidx70.54, align 1
  %conv71.40.54 = zext i8 %19535 to i32
  %xor72.40.54 = xor i32 %conv71.40.54, %conv68.40.54
  %conv73.40.54 = trunc i32 %xor72.40.54 to i8
  store i8 %conv73.40.54, i8* %arrayidx70.54, align 1
  %scevgep20.41.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 41
  %19536 = load i8, i8* %scevgep20.41.54, align 1
  %conv68.41.54 = zext i8 %19536 to i32
  %19537 = load i8, i8* %arrayidx70.54, align 1
  %conv71.41.54 = zext i8 %19537 to i32
  %xor72.41.54 = xor i32 %conv71.41.54, %conv68.41.54
  %conv73.41.54 = trunc i32 %xor72.41.54 to i8
  store i8 %conv73.41.54, i8* %arrayidx70.54, align 1
  %scevgep20.42.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 42
  %19538 = load i8, i8* %scevgep20.42.54, align 1
  %conv68.42.54 = zext i8 %19538 to i32
  %19539 = load i8, i8* %arrayidx70.54, align 1
  %conv71.42.54 = zext i8 %19539 to i32
  %xor72.42.54 = xor i32 %conv71.42.54, %conv68.42.54
  %conv73.42.54 = trunc i32 %xor72.42.54 to i8
  store i8 %conv73.42.54, i8* %arrayidx70.54, align 1
  %scevgep20.43.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 43
  %19540 = load i8, i8* %scevgep20.43.54, align 1
  %conv68.43.54 = zext i8 %19540 to i32
  %19541 = load i8, i8* %arrayidx70.54, align 1
  %conv71.43.54 = zext i8 %19541 to i32
  %xor72.43.54 = xor i32 %conv71.43.54, %conv68.43.54
  %conv73.43.54 = trunc i32 %xor72.43.54 to i8
  store i8 %conv73.43.54, i8* %arrayidx70.54, align 1
  %scevgep20.44.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 44
  %19542 = load i8, i8* %scevgep20.44.54, align 1
  %conv68.44.54 = zext i8 %19542 to i32
  %19543 = load i8, i8* %arrayidx70.54, align 1
  %conv71.44.54 = zext i8 %19543 to i32
  %xor72.44.54 = xor i32 %conv71.44.54, %conv68.44.54
  %conv73.44.54 = trunc i32 %xor72.44.54 to i8
  store i8 %conv73.44.54, i8* %arrayidx70.54, align 1
  %scevgep20.45.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 45
  %19544 = load i8, i8* %scevgep20.45.54, align 1
  %conv68.45.54 = zext i8 %19544 to i32
  %19545 = load i8, i8* %arrayidx70.54, align 1
  %conv71.45.54 = zext i8 %19545 to i32
  %xor72.45.54 = xor i32 %conv71.45.54, %conv68.45.54
  %conv73.45.54 = trunc i32 %xor72.45.54 to i8
  store i8 %conv73.45.54, i8* %arrayidx70.54, align 1
  %scevgep20.46.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 46
  %19546 = load i8, i8* %scevgep20.46.54, align 1
  %conv68.46.54 = zext i8 %19546 to i32
  %19547 = load i8, i8* %arrayidx70.54, align 1
  %conv71.46.54 = zext i8 %19547 to i32
  %xor72.46.54 = xor i32 %conv71.46.54, %conv68.46.54
  %conv73.46.54 = trunc i32 %xor72.46.54 to i8
  store i8 %conv73.46.54, i8* %arrayidx70.54, align 1
  %scevgep20.47.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 47
  %19548 = load i8, i8* %scevgep20.47.54, align 1
  %conv68.47.54 = zext i8 %19548 to i32
  %19549 = load i8, i8* %arrayidx70.54, align 1
  %conv71.47.54 = zext i8 %19549 to i32
  %xor72.47.54 = xor i32 %conv71.47.54, %conv68.47.54
  %conv73.47.54 = trunc i32 %xor72.47.54 to i8
  store i8 %conv73.47.54, i8* %arrayidx70.54, align 1
  %scevgep20.48.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 48
  %19550 = load i8, i8* %scevgep20.48.54, align 1
  %conv68.48.54 = zext i8 %19550 to i32
  %19551 = load i8, i8* %arrayidx70.54, align 1
  %conv71.48.54 = zext i8 %19551 to i32
  %xor72.48.54 = xor i32 %conv71.48.54, %conv68.48.54
  %conv73.48.54 = trunc i32 %xor72.48.54 to i8
  store i8 %conv73.48.54, i8* %arrayidx70.54, align 1
  %scevgep20.49.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 49
  %19552 = load i8, i8* %scevgep20.49.54, align 1
  %conv68.49.54 = zext i8 %19552 to i32
  %19553 = load i8, i8* %arrayidx70.54, align 1
  %conv71.49.54 = zext i8 %19553 to i32
  %xor72.49.54 = xor i32 %conv71.49.54, %conv68.49.54
  %conv73.49.54 = trunc i32 %xor72.49.54 to i8
  store i8 %conv73.49.54, i8* %arrayidx70.54, align 1
  %scevgep20.50.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 50
  %19554 = load i8, i8* %scevgep20.50.54, align 1
  %conv68.50.54 = zext i8 %19554 to i32
  %19555 = load i8, i8* %arrayidx70.54, align 1
  %conv71.50.54 = zext i8 %19555 to i32
  %xor72.50.54 = xor i32 %conv71.50.54, %conv68.50.54
  %conv73.50.54 = trunc i32 %xor72.50.54 to i8
  store i8 %conv73.50.54, i8* %arrayidx70.54, align 1
  %scevgep20.51.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 51
  %19556 = load i8, i8* %scevgep20.51.54, align 1
  %conv68.51.54 = zext i8 %19556 to i32
  %19557 = load i8, i8* %arrayidx70.54, align 1
  %conv71.51.54 = zext i8 %19557 to i32
  %xor72.51.54 = xor i32 %conv71.51.54, %conv68.51.54
  %conv73.51.54 = trunc i32 %xor72.51.54 to i8
  store i8 %conv73.51.54, i8* %arrayidx70.54, align 1
  %scevgep20.52.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 52
  %19558 = load i8, i8* %scevgep20.52.54, align 1
  %conv68.52.54 = zext i8 %19558 to i32
  %19559 = load i8, i8* %arrayidx70.54, align 1
  %conv71.52.54 = zext i8 %19559 to i32
  %xor72.52.54 = xor i32 %conv71.52.54, %conv68.52.54
  %conv73.52.54 = trunc i32 %xor72.52.54 to i8
  store i8 %conv73.52.54, i8* %arrayidx70.54, align 1
  %scevgep20.53.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 53
  %19560 = load i8, i8* %scevgep20.53.54, align 1
  %conv68.53.54 = zext i8 %19560 to i32
  %19561 = load i8, i8* %arrayidx70.54, align 1
  %conv71.53.54 = zext i8 %19561 to i32
  %xor72.53.54 = xor i32 %conv71.53.54, %conv68.53.54
  %conv73.53.54 = trunc i32 %xor72.53.54 to i8
  store i8 %conv73.53.54, i8* %arrayidx70.54, align 1
  %scevgep20.55.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 55
  %19562 = load i8, i8* %scevgep20.55.54, align 1
  %conv68.55.54 = zext i8 %19562 to i32
  %19563 = load i8, i8* %arrayidx70.54, align 1
  %conv71.55.54 = zext i8 %19563 to i32
  %xor72.55.54 = xor i32 %conv71.55.54, %conv68.55.54
  %conv73.55.54 = trunc i32 %xor72.55.54 to i8
  store i8 %conv73.55.54, i8* %arrayidx70.54, align 1
  %scevgep20.56.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 56
  %19564 = load i8, i8* %scevgep20.56.54, align 1
  %conv68.56.54 = zext i8 %19564 to i32
  %19565 = load i8, i8* %arrayidx70.54, align 1
  %conv71.56.54 = zext i8 %19565 to i32
  %xor72.56.54 = xor i32 %conv71.56.54, %conv68.56.54
  %conv73.56.54 = trunc i32 %xor72.56.54 to i8
  store i8 %conv73.56.54, i8* %arrayidx70.54, align 1
  %scevgep20.57.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 57
  %19566 = load i8, i8* %scevgep20.57.54, align 1
  %conv68.57.54 = zext i8 %19566 to i32
  %19567 = load i8, i8* %arrayidx70.54, align 1
  %conv71.57.54 = zext i8 %19567 to i32
  %xor72.57.54 = xor i32 %conv71.57.54, %conv68.57.54
  %conv73.57.54 = trunc i32 %xor72.57.54 to i8
  store i8 %conv73.57.54, i8* %arrayidx70.54, align 1
  %scevgep20.58.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 58
  %19568 = load i8, i8* %scevgep20.58.54, align 1
  %conv68.58.54 = zext i8 %19568 to i32
  %19569 = load i8, i8* %arrayidx70.54, align 1
  %conv71.58.54 = zext i8 %19569 to i32
  %xor72.58.54 = xor i32 %conv71.58.54, %conv68.58.54
  %conv73.58.54 = trunc i32 %xor72.58.54 to i8
  store i8 %conv73.58.54, i8* %arrayidx70.54, align 1
  %scevgep20.59.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 59
  %19570 = load i8, i8* %scevgep20.59.54, align 1
  %conv68.59.54 = zext i8 %19570 to i32
  %19571 = load i8, i8* %arrayidx70.54, align 1
  %conv71.59.54 = zext i8 %19571 to i32
  %xor72.59.54 = xor i32 %conv71.59.54, %conv68.59.54
  %conv73.59.54 = trunc i32 %xor72.59.54 to i8
  store i8 %conv73.59.54, i8* %arrayidx70.54, align 1
  %scevgep20.60.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 0, i64 60
  %19572 = load i8, i8* %scevgep20.60.54, align 1
  %conv68.60.54 = zext i8 %19572 to i32
  %19573 = load i8, i8* %arrayidx70.54, align 1
  %conv71.60.54 = zext i8 %19573 to i32
  %xor72.60.54 = xor i32 %conv71.60.54, %conv68.60.54
  %conv73.60.54 = trunc i32 %xor72.60.54 to i8
  store i8 %conv73.60.54, i8* %arrayidx70.54, align 1
  %scevgep19.54 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19451, i64 0, i64 1, i64 0
  %19574 = bitcast i8* %scevgep19.54 to [61 x [61 x i8]]*
  %arrayidx51.55 = getelementptr inbounds i8, i8* %a, i64 55
  %19575 = load i8, i8* %arrayidx51.55, align 1
  %arrayidx53.55 = getelementptr inbounds i8, i8* %b, i64 55
  %19576 = load i8, i8* %arrayidx53.55, align 1
  %call54.55 = call zeroext i8 @mult(i8 zeroext %19575, i8 zeroext %19576)
  %arrayidx56.55 = getelementptr inbounds i8, i8* %c, i64 55
  store i8 %call54.55, i8* %arrayidx56.55, align 1
  %arrayidx70.55 = getelementptr inbounds i8, i8* %c, i64 55
  %scevgep20.55594 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 0
  %19577 = load i8, i8* %scevgep20.55594, align 1
  %conv68.55595 = zext i8 %19577 to i32
  %19578 = load i8, i8* %arrayidx70.55, align 1
  %conv71.55596 = zext i8 %19578 to i32
  %xor72.55597 = xor i32 %conv71.55596, %conv68.55595
  %conv73.55598 = trunc i32 %xor72.55597 to i8
  store i8 %conv73.55598, i8* %arrayidx70.55, align 1
  %scevgep20.1.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 1
  %19579 = load i8, i8* %scevgep20.1.55, align 1
  %conv68.1.55 = zext i8 %19579 to i32
  %19580 = load i8, i8* %arrayidx70.55, align 1
  %conv71.1.55 = zext i8 %19580 to i32
  %xor72.1.55 = xor i32 %conv71.1.55, %conv68.1.55
  %conv73.1.55 = trunc i32 %xor72.1.55 to i8
  store i8 %conv73.1.55, i8* %arrayidx70.55, align 1
  %scevgep20.2.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 2
  %19581 = load i8, i8* %scevgep20.2.55, align 1
  %conv68.2.55 = zext i8 %19581 to i32
  %19582 = load i8, i8* %arrayidx70.55, align 1
  %conv71.2.55 = zext i8 %19582 to i32
  %xor72.2.55 = xor i32 %conv71.2.55, %conv68.2.55
  %conv73.2.55 = trunc i32 %xor72.2.55 to i8
  store i8 %conv73.2.55, i8* %arrayidx70.55, align 1
  %scevgep20.3.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 3
  %19583 = load i8, i8* %scevgep20.3.55, align 1
  %conv68.3.55 = zext i8 %19583 to i32
  %19584 = load i8, i8* %arrayidx70.55, align 1
  %conv71.3.55 = zext i8 %19584 to i32
  %xor72.3.55 = xor i32 %conv71.3.55, %conv68.3.55
  %conv73.3.55 = trunc i32 %xor72.3.55 to i8
  store i8 %conv73.3.55, i8* %arrayidx70.55, align 1
  %scevgep20.4.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 4
  %19585 = load i8, i8* %scevgep20.4.55, align 1
  %conv68.4.55 = zext i8 %19585 to i32
  %19586 = load i8, i8* %arrayidx70.55, align 1
  %conv71.4.55 = zext i8 %19586 to i32
  %xor72.4.55 = xor i32 %conv71.4.55, %conv68.4.55
  %conv73.4.55 = trunc i32 %xor72.4.55 to i8
  store i8 %conv73.4.55, i8* %arrayidx70.55, align 1
  %scevgep20.5.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 5
  %19587 = load i8, i8* %scevgep20.5.55, align 1
  %conv68.5.55 = zext i8 %19587 to i32
  %19588 = load i8, i8* %arrayidx70.55, align 1
  %conv71.5.55 = zext i8 %19588 to i32
  %xor72.5.55 = xor i32 %conv71.5.55, %conv68.5.55
  %conv73.5.55 = trunc i32 %xor72.5.55 to i8
  store i8 %conv73.5.55, i8* %arrayidx70.55, align 1
  %scevgep20.6.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 6
  %19589 = load i8, i8* %scevgep20.6.55, align 1
  %conv68.6.55 = zext i8 %19589 to i32
  %19590 = load i8, i8* %arrayidx70.55, align 1
  %conv71.6.55 = zext i8 %19590 to i32
  %xor72.6.55 = xor i32 %conv71.6.55, %conv68.6.55
  %conv73.6.55 = trunc i32 %xor72.6.55 to i8
  store i8 %conv73.6.55, i8* %arrayidx70.55, align 1
  %scevgep20.7.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 7
  %19591 = load i8, i8* %scevgep20.7.55, align 1
  %conv68.7.55 = zext i8 %19591 to i32
  %19592 = load i8, i8* %arrayidx70.55, align 1
  %conv71.7.55 = zext i8 %19592 to i32
  %xor72.7.55 = xor i32 %conv71.7.55, %conv68.7.55
  %conv73.7.55 = trunc i32 %xor72.7.55 to i8
  store i8 %conv73.7.55, i8* %arrayidx70.55, align 1
  %scevgep20.8.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 8
  %19593 = load i8, i8* %scevgep20.8.55, align 1
  %conv68.8.55 = zext i8 %19593 to i32
  %19594 = load i8, i8* %arrayidx70.55, align 1
  %conv71.8.55 = zext i8 %19594 to i32
  %xor72.8.55 = xor i32 %conv71.8.55, %conv68.8.55
  %conv73.8.55 = trunc i32 %xor72.8.55 to i8
  store i8 %conv73.8.55, i8* %arrayidx70.55, align 1
  %scevgep20.9.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 9
  %19595 = load i8, i8* %scevgep20.9.55, align 1
  %conv68.9.55 = zext i8 %19595 to i32
  %19596 = load i8, i8* %arrayidx70.55, align 1
  %conv71.9.55 = zext i8 %19596 to i32
  %xor72.9.55 = xor i32 %conv71.9.55, %conv68.9.55
  %conv73.9.55 = trunc i32 %xor72.9.55 to i8
  store i8 %conv73.9.55, i8* %arrayidx70.55, align 1
  %scevgep20.10.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 10
  %19597 = load i8, i8* %scevgep20.10.55, align 1
  %conv68.10.55 = zext i8 %19597 to i32
  %19598 = load i8, i8* %arrayidx70.55, align 1
  %conv71.10.55 = zext i8 %19598 to i32
  %xor72.10.55 = xor i32 %conv71.10.55, %conv68.10.55
  %conv73.10.55 = trunc i32 %xor72.10.55 to i8
  store i8 %conv73.10.55, i8* %arrayidx70.55, align 1
  %scevgep20.11.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 11
  %19599 = load i8, i8* %scevgep20.11.55, align 1
  %conv68.11.55 = zext i8 %19599 to i32
  %19600 = load i8, i8* %arrayidx70.55, align 1
  %conv71.11.55 = zext i8 %19600 to i32
  %xor72.11.55 = xor i32 %conv71.11.55, %conv68.11.55
  %conv73.11.55 = trunc i32 %xor72.11.55 to i8
  store i8 %conv73.11.55, i8* %arrayidx70.55, align 1
  %scevgep20.12.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 12
  %19601 = load i8, i8* %scevgep20.12.55, align 1
  %conv68.12.55 = zext i8 %19601 to i32
  %19602 = load i8, i8* %arrayidx70.55, align 1
  %conv71.12.55 = zext i8 %19602 to i32
  %xor72.12.55 = xor i32 %conv71.12.55, %conv68.12.55
  %conv73.12.55 = trunc i32 %xor72.12.55 to i8
  store i8 %conv73.12.55, i8* %arrayidx70.55, align 1
  %scevgep20.13.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 13
  %19603 = load i8, i8* %scevgep20.13.55, align 1
  %conv68.13.55 = zext i8 %19603 to i32
  %19604 = load i8, i8* %arrayidx70.55, align 1
  %conv71.13.55 = zext i8 %19604 to i32
  %xor72.13.55 = xor i32 %conv71.13.55, %conv68.13.55
  %conv73.13.55 = trunc i32 %xor72.13.55 to i8
  store i8 %conv73.13.55, i8* %arrayidx70.55, align 1
  %scevgep20.14.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 14
  %19605 = load i8, i8* %scevgep20.14.55, align 1
  %conv68.14.55 = zext i8 %19605 to i32
  %19606 = load i8, i8* %arrayidx70.55, align 1
  %conv71.14.55 = zext i8 %19606 to i32
  %xor72.14.55 = xor i32 %conv71.14.55, %conv68.14.55
  %conv73.14.55 = trunc i32 %xor72.14.55 to i8
  store i8 %conv73.14.55, i8* %arrayidx70.55, align 1
  %scevgep20.15.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 15
  %19607 = load i8, i8* %scevgep20.15.55, align 1
  %conv68.15.55 = zext i8 %19607 to i32
  %19608 = load i8, i8* %arrayidx70.55, align 1
  %conv71.15.55 = zext i8 %19608 to i32
  %xor72.15.55 = xor i32 %conv71.15.55, %conv68.15.55
  %conv73.15.55 = trunc i32 %xor72.15.55 to i8
  store i8 %conv73.15.55, i8* %arrayidx70.55, align 1
  %scevgep20.16.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 16
  %19609 = load i8, i8* %scevgep20.16.55, align 1
  %conv68.16.55 = zext i8 %19609 to i32
  %19610 = load i8, i8* %arrayidx70.55, align 1
  %conv71.16.55 = zext i8 %19610 to i32
  %xor72.16.55 = xor i32 %conv71.16.55, %conv68.16.55
  %conv73.16.55 = trunc i32 %xor72.16.55 to i8
  store i8 %conv73.16.55, i8* %arrayidx70.55, align 1
  %scevgep20.17.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 17
  %19611 = load i8, i8* %scevgep20.17.55, align 1
  %conv68.17.55 = zext i8 %19611 to i32
  %19612 = load i8, i8* %arrayidx70.55, align 1
  %conv71.17.55 = zext i8 %19612 to i32
  %xor72.17.55 = xor i32 %conv71.17.55, %conv68.17.55
  %conv73.17.55 = trunc i32 %xor72.17.55 to i8
  store i8 %conv73.17.55, i8* %arrayidx70.55, align 1
  %scevgep20.18.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 18
  %19613 = load i8, i8* %scevgep20.18.55, align 1
  %conv68.18.55 = zext i8 %19613 to i32
  %19614 = load i8, i8* %arrayidx70.55, align 1
  %conv71.18.55 = zext i8 %19614 to i32
  %xor72.18.55 = xor i32 %conv71.18.55, %conv68.18.55
  %conv73.18.55 = trunc i32 %xor72.18.55 to i8
  store i8 %conv73.18.55, i8* %arrayidx70.55, align 1
  %scevgep20.19.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 19
  %19615 = load i8, i8* %scevgep20.19.55, align 1
  %conv68.19.55 = zext i8 %19615 to i32
  %19616 = load i8, i8* %arrayidx70.55, align 1
  %conv71.19.55 = zext i8 %19616 to i32
  %xor72.19.55 = xor i32 %conv71.19.55, %conv68.19.55
  %conv73.19.55 = trunc i32 %xor72.19.55 to i8
  store i8 %conv73.19.55, i8* %arrayidx70.55, align 1
  %scevgep20.20.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 20
  %19617 = load i8, i8* %scevgep20.20.55, align 1
  %conv68.20.55 = zext i8 %19617 to i32
  %19618 = load i8, i8* %arrayidx70.55, align 1
  %conv71.20.55 = zext i8 %19618 to i32
  %xor72.20.55 = xor i32 %conv71.20.55, %conv68.20.55
  %conv73.20.55 = trunc i32 %xor72.20.55 to i8
  store i8 %conv73.20.55, i8* %arrayidx70.55, align 1
  %scevgep20.21.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 21
  %19619 = load i8, i8* %scevgep20.21.55, align 1
  %conv68.21.55 = zext i8 %19619 to i32
  %19620 = load i8, i8* %arrayidx70.55, align 1
  %conv71.21.55 = zext i8 %19620 to i32
  %xor72.21.55 = xor i32 %conv71.21.55, %conv68.21.55
  %conv73.21.55 = trunc i32 %xor72.21.55 to i8
  store i8 %conv73.21.55, i8* %arrayidx70.55, align 1
  %scevgep20.22.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 22
  %19621 = load i8, i8* %scevgep20.22.55, align 1
  %conv68.22.55 = zext i8 %19621 to i32
  %19622 = load i8, i8* %arrayidx70.55, align 1
  %conv71.22.55 = zext i8 %19622 to i32
  %xor72.22.55 = xor i32 %conv71.22.55, %conv68.22.55
  %conv73.22.55 = trunc i32 %xor72.22.55 to i8
  store i8 %conv73.22.55, i8* %arrayidx70.55, align 1
  %scevgep20.23.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 23
  %19623 = load i8, i8* %scevgep20.23.55, align 1
  %conv68.23.55 = zext i8 %19623 to i32
  %19624 = load i8, i8* %arrayidx70.55, align 1
  %conv71.23.55 = zext i8 %19624 to i32
  %xor72.23.55 = xor i32 %conv71.23.55, %conv68.23.55
  %conv73.23.55 = trunc i32 %xor72.23.55 to i8
  store i8 %conv73.23.55, i8* %arrayidx70.55, align 1
  %scevgep20.24.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 24
  %19625 = load i8, i8* %scevgep20.24.55, align 1
  %conv68.24.55 = zext i8 %19625 to i32
  %19626 = load i8, i8* %arrayidx70.55, align 1
  %conv71.24.55 = zext i8 %19626 to i32
  %xor72.24.55 = xor i32 %conv71.24.55, %conv68.24.55
  %conv73.24.55 = trunc i32 %xor72.24.55 to i8
  store i8 %conv73.24.55, i8* %arrayidx70.55, align 1
  %scevgep20.25.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 25
  %19627 = load i8, i8* %scevgep20.25.55, align 1
  %conv68.25.55 = zext i8 %19627 to i32
  %19628 = load i8, i8* %arrayidx70.55, align 1
  %conv71.25.55 = zext i8 %19628 to i32
  %xor72.25.55 = xor i32 %conv71.25.55, %conv68.25.55
  %conv73.25.55 = trunc i32 %xor72.25.55 to i8
  store i8 %conv73.25.55, i8* %arrayidx70.55, align 1
  %scevgep20.26.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 26
  %19629 = load i8, i8* %scevgep20.26.55, align 1
  %conv68.26.55 = zext i8 %19629 to i32
  %19630 = load i8, i8* %arrayidx70.55, align 1
  %conv71.26.55 = zext i8 %19630 to i32
  %xor72.26.55 = xor i32 %conv71.26.55, %conv68.26.55
  %conv73.26.55 = trunc i32 %xor72.26.55 to i8
  store i8 %conv73.26.55, i8* %arrayidx70.55, align 1
  %scevgep20.27.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 27
  %19631 = load i8, i8* %scevgep20.27.55, align 1
  %conv68.27.55 = zext i8 %19631 to i32
  %19632 = load i8, i8* %arrayidx70.55, align 1
  %conv71.27.55 = zext i8 %19632 to i32
  %xor72.27.55 = xor i32 %conv71.27.55, %conv68.27.55
  %conv73.27.55 = trunc i32 %xor72.27.55 to i8
  store i8 %conv73.27.55, i8* %arrayidx70.55, align 1
  %scevgep20.28.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 28
  %19633 = load i8, i8* %scevgep20.28.55, align 1
  %conv68.28.55 = zext i8 %19633 to i32
  %19634 = load i8, i8* %arrayidx70.55, align 1
  %conv71.28.55 = zext i8 %19634 to i32
  %xor72.28.55 = xor i32 %conv71.28.55, %conv68.28.55
  %conv73.28.55 = trunc i32 %xor72.28.55 to i8
  store i8 %conv73.28.55, i8* %arrayidx70.55, align 1
  %scevgep20.29.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 29
  %19635 = load i8, i8* %scevgep20.29.55, align 1
  %conv68.29.55 = zext i8 %19635 to i32
  %19636 = load i8, i8* %arrayidx70.55, align 1
  %conv71.29.55 = zext i8 %19636 to i32
  %xor72.29.55 = xor i32 %conv71.29.55, %conv68.29.55
  %conv73.29.55 = trunc i32 %xor72.29.55 to i8
  store i8 %conv73.29.55, i8* %arrayidx70.55, align 1
  %scevgep20.30.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 30
  %19637 = load i8, i8* %scevgep20.30.55, align 1
  %conv68.30.55 = zext i8 %19637 to i32
  %19638 = load i8, i8* %arrayidx70.55, align 1
  %conv71.30.55 = zext i8 %19638 to i32
  %xor72.30.55 = xor i32 %conv71.30.55, %conv68.30.55
  %conv73.30.55 = trunc i32 %xor72.30.55 to i8
  store i8 %conv73.30.55, i8* %arrayidx70.55, align 1
  %scevgep20.31.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 31
  %19639 = load i8, i8* %scevgep20.31.55, align 1
  %conv68.31.55 = zext i8 %19639 to i32
  %19640 = load i8, i8* %arrayidx70.55, align 1
  %conv71.31.55 = zext i8 %19640 to i32
  %xor72.31.55 = xor i32 %conv71.31.55, %conv68.31.55
  %conv73.31.55 = trunc i32 %xor72.31.55 to i8
  store i8 %conv73.31.55, i8* %arrayidx70.55, align 1
  %scevgep20.32.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 32
  %19641 = load i8, i8* %scevgep20.32.55, align 1
  %conv68.32.55 = zext i8 %19641 to i32
  %19642 = load i8, i8* %arrayidx70.55, align 1
  %conv71.32.55 = zext i8 %19642 to i32
  %xor72.32.55 = xor i32 %conv71.32.55, %conv68.32.55
  %conv73.32.55 = trunc i32 %xor72.32.55 to i8
  store i8 %conv73.32.55, i8* %arrayidx70.55, align 1
  %scevgep20.33.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 33
  %19643 = load i8, i8* %scevgep20.33.55, align 1
  %conv68.33.55 = zext i8 %19643 to i32
  %19644 = load i8, i8* %arrayidx70.55, align 1
  %conv71.33.55 = zext i8 %19644 to i32
  %xor72.33.55 = xor i32 %conv71.33.55, %conv68.33.55
  %conv73.33.55 = trunc i32 %xor72.33.55 to i8
  store i8 %conv73.33.55, i8* %arrayidx70.55, align 1
  %scevgep20.34.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 34
  %19645 = load i8, i8* %scevgep20.34.55, align 1
  %conv68.34.55 = zext i8 %19645 to i32
  %19646 = load i8, i8* %arrayidx70.55, align 1
  %conv71.34.55 = zext i8 %19646 to i32
  %xor72.34.55 = xor i32 %conv71.34.55, %conv68.34.55
  %conv73.34.55 = trunc i32 %xor72.34.55 to i8
  store i8 %conv73.34.55, i8* %arrayidx70.55, align 1
  %scevgep20.35.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 35
  %19647 = load i8, i8* %scevgep20.35.55, align 1
  %conv68.35.55 = zext i8 %19647 to i32
  %19648 = load i8, i8* %arrayidx70.55, align 1
  %conv71.35.55 = zext i8 %19648 to i32
  %xor72.35.55 = xor i32 %conv71.35.55, %conv68.35.55
  %conv73.35.55 = trunc i32 %xor72.35.55 to i8
  store i8 %conv73.35.55, i8* %arrayidx70.55, align 1
  %scevgep20.36.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 36
  %19649 = load i8, i8* %scevgep20.36.55, align 1
  %conv68.36.55 = zext i8 %19649 to i32
  %19650 = load i8, i8* %arrayidx70.55, align 1
  %conv71.36.55 = zext i8 %19650 to i32
  %xor72.36.55 = xor i32 %conv71.36.55, %conv68.36.55
  %conv73.36.55 = trunc i32 %xor72.36.55 to i8
  store i8 %conv73.36.55, i8* %arrayidx70.55, align 1
  %scevgep20.37.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 37
  %19651 = load i8, i8* %scevgep20.37.55, align 1
  %conv68.37.55 = zext i8 %19651 to i32
  %19652 = load i8, i8* %arrayidx70.55, align 1
  %conv71.37.55 = zext i8 %19652 to i32
  %xor72.37.55 = xor i32 %conv71.37.55, %conv68.37.55
  %conv73.37.55 = trunc i32 %xor72.37.55 to i8
  store i8 %conv73.37.55, i8* %arrayidx70.55, align 1
  %scevgep20.38.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 38
  %19653 = load i8, i8* %scevgep20.38.55, align 1
  %conv68.38.55 = zext i8 %19653 to i32
  %19654 = load i8, i8* %arrayidx70.55, align 1
  %conv71.38.55 = zext i8 %19654 to i32
  %xor72.38.55 = xor i32 %conv71.38.55, %conv68.38.55
  %conv73.38.55 = trunc i32 %xor72.38.55 to i8
  store i8 %conv73.38.55, i8* %arrayidx70.55, align 1
  %scevgep20.39.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 39
  %19655 = load i8, i8* %scevgep20.39.55, align 1
  %conv68.39.55 = zext i8 %19655 to i32
  %19656 = load i8, i8* %arrayidx70.55, align 1
  %conv71.39.55 = zext i8 %19656 to i32
  %xor72.39.55 = xor i32 %conv71.39.55, %conv68.39.55
  %conv73.39.55 = trunc i32 %xor72.39.55 to i8
  store i8 %conv73.39.55, i8* %arrayidx70.55, align 1
  %scevgep20.40.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 40
  %19657 = load i8, i8* %scevgep20.40.55, align 1
  %conv68.40.55 = zext i8 %19657 to i32
  %19658 = load i8, i8* %arrayidx70.55, align 1
  %conv71.40.55 = zext i8 %19658 to i32
  %xor72.40.55 = xor i32 %conv71.40.55, %conv68.40.55
  %conv73.40.55 = trunc i32 %xor72.40.55 to i8
  store i8 %conv73.40.55, i8* %arrayidx70.55, align 1
  %scevgep20.41.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 41
  %19659 = load i8, i8* %scevgep20.41.55, align 1
  %conv68.41.55 = zext i8 %19659 to i32
  %19660 = load i8, i8* %arrayidx70.55, align 1
  %conv71.41.55 = zext i8 %19660 to i32
  %xor72.41.55 = xor i32 %conv71.41.55, %conv68.41.55
  %conv73.41.55 = trunc i32 %xor72.41.55 to i8
  store i8 %conv73.41.55, i8* %arrayidx70.55, align 1
  %scevgep20.42.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 42
  %19661 = load i8, i8* %scevgep20.42.55, align 1
  %conv68.42.55 = zext i8 %19661 to i32
  %19662 = load i8, i8* %arrayidx70.55, align 1
  %conv71.42.55 = zext i8 %19662 to i32
  %xor72.42.55 = xor i32 %conv71.42.55, %conv68.42.55
  %conv73.42.55 = trunc i32 %xor72.42.55 to i8
  store i8 %conv73.42.55, i8* %arrayidx70.55, align 1
  %scevgep20.43.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 43
  %19663 = load i8, i8* %scevgep20.43.55, align 1
  %conv68.43.55 = zext i8 %19663 to i32
  %19664 = load i8, i8* %arrayidx70.55, align 1
  %conv71.43.55 = zext i8 %19664 to i32
  %xor72.43.55 = xor i32 %conv71.43.55, %conv68.43.55
  %conv73.43.55 = trunc i32 %xor72.43.55 to i8
  store i8 %conv73.43.55, i8* %arrayidx70.55, align 1
  %scevgep20.44.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 44
  %19665 = load i8, i8* %scevgep20.44.55, align 1
  %conv68.44.55 = zext i8 %19665 to i32
  %19666 = load i8, i8* %arrayidx70.55, align 1
  %conv71.44.55 = zext i8 %19666 to i32
  %xor72.44.55 = xor i32 %conv71.44.55, %conv68.44.55
  %conv73.44.55 = trunc i32 %xor72.44.55 to i8
  store i8 %conv73.44.55, i8* %arrayidx70.55, align 1
  %scevgep20.45.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 45
  %19667 = load i8, i8* %scevgep20.45.55, align 1
  %conv68.45.55 = zext i8 %19667 to i32
  %19668 = load i8, i8* %arrayidx70.55, align 1
  %conv71.45.55 = zext i8 %19668 to i32
  %xor72.45.55 = xor i32 %conv71.45.55, %conv68.45.55
  %conv73.45.55 = trunc i32 %xor72.45.55 to i8
  store i8 %conv73.45.55, i8* %arrayidx70.55, align 1
  %scevgep20.46.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 46
  %19669 = load i8, i8* %scevgep20.46.55, align 1
  %conv68.46.55 = zext i8 %19669 to i32
  %19670 = load i8, i8* %arrayidx70.55, align 1
  %conv71.46.55 = zext i8 %19670 to i32
  %xor72.46.55 = xor i32 %conv71.46.55, %conv68.46.55
  %conv73.46.55 = trunc i32 %xor72.46.55 to i8
  store i8 %conv73.46.55, i8* %arrayidx70.55, align 1
  %scevgep20.47.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 47
  %19671 = load i8, i8* %scevgep20.47.55, align 1
  %conv68.47.55 = zext i8 %19671 to i32
  %19672 = load i8, i8* %arrayidx70.55, align 1
  %conv71.47.55 = zext i8 %19672 to i32
  %xor72.47.55 = xor i32 %conv71.47.55, %conv68.47.55
  %conv73.47.55 = trunc i32 %xor72.47.55 to i8
  store i8 %conv73.47.55, i8* %arrayidx70.55, align 1
  %scevgep20.48.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 48
  %19673 = load i8, i8* %scevgep20.48.55, align 1
  %conv68.48.55 = zext i8 %19673 to i32
  %19674 = load i8, i8* %arrayidx70.55, align 1
  %conv71.48.55 = zext i8 %19674 to i32
  %xor72.48.55 = xor i32 %conv71.48.55, %conv68.48.55
  %conv73.48.55 = trunc i32 %xor72.48.55 to i8
  store i8 %conv73.48.55, i8* %arrayidx70.55, align 1
  %scevgep20.49.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 49
  %19675 = load i8, i8* %scevgep20.49.55, align 1
  %conv68.49.55 = zext i8 %19675 to i32
  %19676 = load i8, i8* %arrayidx70.55, align 1
  %conv71.49.55 = zext i8 %19676 to i32
  %xor72.49.55 = xor i32 %conv71.49.55, %conv68.49.55
  %conv73.49.55 = trunc i32 %xor72.49.55 to i8
  store i8 %conv73.49.55, i8* %arrayidx70.55, align 1
  %scevgep20.50.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 50
  %19677 = load i8, i8* %scevgep20.50.55, align 1
  %conv68.50.55 = zext i8 %19677 to i32
  %19678 = load i8, i8* %arrayidx70.55, align 1
  %conv71.50.55 = zext i8 %19678 to i32
  %xor72.50.55 = xor i32 %conv71.50.55, %conv68.50.55
  %conv73.50.55 = trunc i32 %xor72.50.55 to i8
  store i8 %conv73.50.55, i8* %arrayidx70.55, align 1
  %scevgep20.51.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 51
  %19679 = load i8, i8* %scevgep20.51.55, align 1
  %conv68.51.55 = zext i8 %19679 to i32
  %19680 = load i8, i8* %arrayidx70.55, align 1
  %conv71.51.55 = zext i8 %19680 to i32
  %xor72.51.55 = xor i32 %conv71.51.55, %conv68.51.55
  %conv73.51.55 = trunc i32 %xor72.51.55 to i8
  store i8 %conv73.51.55, i8* %arrayidx70.55, align 1
  %scevgep20.52.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 52
  %19681 = load i8, i8* %scevgep20.52.55, align 1
  %conv68.52.55 = zext i8 %19681 to i32
  %19682 = load i8, i8* %arrayidx70.55, align 1
  %conv71.52.55 = zext i8 %19682 to i32
  %xor72.52.55 = xor i32 %conv71.52.55, %conv68.52.55
  %conv73.52.55 = trunc i32 %xor72.52.55 to i8
  store i8 %conv73.52.55, i8* %arrayidx70.55, align 1
  %scevgep20.53.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 53
  %19683 = load i8, i8* %scevgep20.53.55, align 1
  %conv68.53.55 = zext i8 %19683 to i32
  %19684 = load i8, i8* %arrayidx70.55, align 1
  %conv71.53.55 = zext i8 %19684 to i32
  %xor72.53.55 = xor i32 %conv71.53.55, %conv68.53.55
  %conv73.53.55 = trunc i32 %xor72.53.55 to i8
  store i8 %conv73.53.55, i8* %arrayidx70.55, align 1
  %scevgep20.54.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 54
  %19685 = load i8, i8* %scevgep20.54.55, align 1
  %conv68.54.55 = zext i8 %19685 to i32
  %19686 = load i8, i8* %arrayidx70.55, align 1
  %conv71.54.55 = zext i8 %19686 to i32
  %xor72.54.55 = xor i32 %conv71.54.55, %conv68.54.55
  %conv73.54.55 = trunc i32 %xor72.54.55 to i8
  store i8 %conv73.54.55, i8* %arrayidx70.55, align 1
  %scevgep20.56.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 56
  %19687 = load i8, i8* %scevgep20.56.55, align 1
  %conv68.56.55 = zext i8 %19687 to i32
  %19688 = load i8, i8* %arrayidx70.55, align 1
  %conv71.56.55 = zext i8 %19688 to i32
  %xor72.56.55 = xor i32 %conv71.56.55, %conv68.56.55
  %conv73.56.55 = trunc i32 %xor72.56.55 to i8
  store i8 %conv73.56.55, i8* %arrayidx70.55, align 1
  %scevgep20.57.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 57
  %19689 = load i8, i8* %scevgep20.57.55, align 1
  %conv68.57.55 = zext i8 %19689 to i32
  %19690 = load i8, i8* %arrayidx70.55, align 1
  %conv71.57.55 = zext i8 %19690 to i32
  %xor72.57.55 = xor i32 %conv71.57.55, %conv68.57.55
  %conv73.57.55 = trunc i32 %xor72.57.55 to i8
  store i8 %conv73.57.55, i8* %arrayidx70.55, align 1
  %scevgep20.58.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 58
  %19691 = load i8, i8* %scevgep20.58.55, align 1
  %conv68.58.55 = zext i8 %19691 to i32
  %19692 = load i8, i8* %arrayidx70.55, align 1
  %conv71.58.55 = zext i8 %19692 to i32
  %xor72.58.55 = xor i32 %conv71.58.55, %conv68.58.55
  %conv73.58.55 = trunc i32 %xor72.58.55 to i8
  store i8 %conv73.58.55, i8* %arrayidx70.55, align 1
  %scevgep20.59.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 59
  %19693 = load i8, i8* %scevgep20.59.55, align 1
  %conv68.59.55 = zext i8 %19693 to i32
  %19694 = load i8, i8* %arrayidx70.55, align 1
  %conv71.59.55 = zext i8 %19694 to i32
  %xor72.59.55 = xor i32 %conv71.59.55, %conv68.59.55
  %conv73.59.55 = trunc i32 %xor72.59.55 to i8
  store i8 %conv73.59.55, i8* %arrayidx70.55, align 1
  %scevgep20.60.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 0, i64 60
  %19695 = load i8, i8* %scevgep20.60.55, align 1
  %conv68.60.55 = zext i8 %19695 to i32
  %19696 = load i8, i8* %arrayidx70.55, align 1
  %conv71.60.55 = zext i8 %19696 to i32
  %xor72.60.55 = xor i32 %conv71.60.55, %conv68.60.55
  %conv73.60.55 = trunc i32 %xor72.60.55 to i8
  store i8 %conv73.60.55, i8* %arrayidx70.55, align 1
  %scevgep19.55 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19574, i64 0, i64 1, i64 0
  %19697 = bitcast i8* %scevgep19.55 to [61 x [61 x i8]]*
  %arrayidx51.56 = getelementptr inbounds i8, i8* %a, i64 56
  %19698 = load i8, i8* %arrayidx51.56, align 1
  %arrayidx53.56 = getelementptr inbounds i8, i8* %b, i64 56
  %19699 = load i8, i8* %arrayidx53.56, align 1
  %call54.56 = call zeroext i8 @mult(i8 zeroext %19698, i8 zeroext %19699)
  %arrayidx56.56 = getelementptr inbounds i8, i8* %c, i64 56
  store i8 %call54.56, i8* %arrayidx56.56, align 1
  %arrayidx70.56 = getelementptr inbounds i8, i8* %c, i64 56
  %scevgep20.56604 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 0
  %19700 = load i8, i8* %scevgep20.56604, align 1
  %conv68.56605 = zext i8 %19700 to i32
  %19701 = load i8, i8* %arrayidx70.56, align 1
  %conv71.56606 = zext i8 %19701 to i32
  %xor72.56607 = xor i32 %conv71.56606, %conv68.56605
  %conv73.56608 = trunc i32 %xor72.56607 to i8
  store i8 %conv73.56608, i8* %arrayidx70.56, align 1
  %scevgep20.1.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 1
  %19702 = load i8, i8* %scevgep20.1.56, align 1
  %conv68.1.56 = zext i8 %19702 to i32
  %19703 = load i8, i8* %arrayidx70.56, align 1
  %conv71.1.56 = zext i8 %19703 to i32
  %xor72.1.56 = xor i32 %conv71.1.56, %conv68.1.56
  %conv73.1.56 = trunc i32 %xor72.1.56 to i8
  store i8 %conv73.1.56, i8* %arrayidx70.56, align 1
  %scevgep20.2.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 2
  %19704 = load i8, i8* %scevgep20.2.56, align 1
  %conv68.2.56 = zext i8 %19704 to i32
  %19705 = load i8, i8* %arrayidx70.56, align 1
  %conv71.2.56 = zext i8 %19705 to i32
  %xor72.2.56 = xor i32 %conv71.2.56, %conv68.2.56
  %conv73.2.56 = trunc i32 %xor72.2.56 to i8
  store i8 %conv73.2.56, i8* %arrayidx70.56, align 1
  %scevgep20.3.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 3
  %19706 = load i8, i8* %scevgep20.3.56, align 1
  %conv68.3.56 = zext i8 %19706 to i32
  %19707 = load i8, i8* %arrayidx70.56, align 1
  %conv71.3.56 = zext i8 %19707 to i32
  %xor72.3.56 = xor i32 %conv71.3.56, %conv68.3.56
  %conv73.3.56 = trunc i32 %xor72.3.56 to i8
  store i8 %conv73.3.56, i8* %arrayidx70.56, align 1
  %scevgep20.4.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 4
  %19708 = load i8, i8* %scevgep20.4.56, align 1
  %conv68.4.56 = zext i8 %19708 to i32
  %19709 = load i8, i8* %arrayidx70.56, align 1
  %conv71.4.56 = zext i8 %19709 to i32
  %xor72.4.56 = xor i32 %conv71.4.56, %conv68.4.56
  %conv73.4.56 = trunc i32 %xor72.4.56 to i8
  store i8 %conv73.4.56, i8* %arrayidx70.56, align 1
  %scevgep20.5.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 5
  %19710 = load i8, i8* %scevgep20.5.56, align 1
  %conv68.5.56 = zext i8 %19710 to i32
  %19711 = load i8, i8* %arrayidx70.56, align 1
  %conv71.5.56 = zext i8 %19711 to i32
  %xor72.5.56 = xor i32 %conv71.5.56, %conv68.5.56
  %conv73.5.56 = trunc i32 %xor72.5.56 to i8
  store i8 %conv73.5.56, i8* %arrayidx70.56, align 1
  %scevgep20.6.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 6
  %19712 = load i8, i8* %scevgep20.6.56, align 1
  %conv68.6.56 = zext i8 %19712 to i32
  %19713 = load i8, i8* %arrayidx70.56, align 1
  %conv71.6.56 = zext i8 %19713 to i32
  %xor72.6.56 = xor i32 %conv71.6.56, %conv68.6.56
  %conv73.6.56 = trunc i32 %xor72.6.56 to i8
  store i8 %conv73.6.56, i8* %arrayidx70.56, align 1
  %scevgep20.7.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 7
  %19714 = load i8, i8* %scevgep20.7.56, align 1
  %conv68.7.56 = zext i8 %19714 to i32
  %19715 = load i8, i8* %arrayidx70.56, align 1
  %conv71.7.56 = zext i8 %19715 to i32
  %xor72.7.56 = xor i32 %conv71.7.56, %conv68.7.56
  %conv73.7.56 = trunc i32 %xor72.7.56 to i8
  store i8 %conv73.7.56, i8* %arrayidx70.56, align 1
  %scevgep20.8.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 8
  %19716 = load i8, i8* %scevgep20.8.56, align 1
  %conv68.8.56 = zext i8 %19716 to i32
  %19717 = load i8, i8* %arrayidx70.56, align 1
  %conv71.8.56 = zext i8 %19717 to i32
  %xor72.8.56 = xor i32 %conv71.8.56, %conv68.8.56
  %conv73.8.56 = trunc i32 %xor72.8.56 to i8
  store i8 %conv73.8.56, i8* %arrayidx70.56, align 1
  %scevgep20.9.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 9
  %19718 = load i8, i8* %scevgep20.9.56, align 1
  %conv68.9.56 = zext i8 %19718 to i32
  %19719 = load i8, i8* %arrayidx70.56, align 1
  %conv71.9.56 = zext i8 %19719 to i32
  %xor72.9.56 = xor i32 %conv71.9.56, %conv68.9.56
  %conv73.9.56 = trunc i32 %xor72.9.56 to i8
  store i8 %conv73.9.56, i8* %arrayidx70.56, align 1
  %scevgep20.10.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 10
  %19720 = load i8, i8* %scevgep20.10.56, align 1
  %conv68.10.56 = zext i8 %19720 to i32
  %19721 = load i8, i8* %arrayidx70.56, align 1
  %conv71.10.56 = zext i8 %19721 to i32
  %xor72.10.56 = xor i32 %conv71.10.56, %conv68.10.56
  %conv73.10.56 = trunc i32 %xor72.10.56 to i8
  store i8 %conv73.10.56, i8* %arrayidx70.56, align 1
  %scevgep20.11.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 11
  %19722 = load i8, i8* %scevgep20.11.56, align 1
  %conv68.11.56 = zext i8 %19722 to i32
  %19723 = load i8, i8* %arrayidx70.56, align 1
  %conv71.11.56 = zext i8 %19723 to i32
  %xor72.11.56 = xor i32 %conv71.11.56, %conv68.11.56
  %conv73.11.56 = trunc i32 %xor72.11.56 to i8
  store i8 %conv73.11.56, i8* %arrayidx70.56, align 1
  %scevgep20.12.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 12
  %19724 = load i8, i8* %scevgep20.12.56, align 1
  %conv68.12.56 = zext i8 %19724 to i32
  %19725 = load i8, i8* %arrayidx70.56, align 1
  %conv71.12.56 = zext i8 %19725 to i32
  %xor72.12.56 = xor i32 %conv71.12.56, %conv68.12.56
  %conv73.12.56 = trunc i32 %xor72.12.56 to i8
  store i8 %conv73.12.56, i8* %arrayidx70.56, align 1
  %scevgep20.13.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 13
  %19726 = load i8, i8* %scevgep20.13.56, align 1
  %conv68.13.56 = zext i8 %19726 to i32
  %19727 = load i8, i8* %arrayidx70.56, align 1
  %conv71.13.56 = zext i8 %19727 to i32
  %xor72.13.56 = xor i32 %conv71.13.56, %conv68.13.56
  %conv73.13.56 = trunc i32 %xor72.13.56 to i8
  store i8 %conv73.13.56, i8* %arrayidx70.56, align 1
  %scevgep20.14.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 14
  %19728 = load i8, i8* %scevgep20.14.56, align 1
  %conv68.14.56 = zext i8 %19728 to i32
  %19729 = load i8, i8* %arrayidx70.56, align 1
  %conv71.14.56 = zext i8 %19729 to i32
  %xor72.14.56 = xor i32 %conv71.14.56, %conv68.14.56
  %conv73.14.56 = trunc i32 %xor72.14.56 to i8
  store i8 %conv73.14.56, i8* %arrayidx70.56, align 1
  %scevgep20.15.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 15
  %19730 = load i8, i8* %scevgep20.15.56, align 1
  %conv68.15.56 = zext i8 %19730 to i32
  %19731 = load i8, i8* %arrayidx70.56, align 1
  %conv71.15.56 = zext i8 %19731 to i32
  %xor72.15.56 = xor i32 %conv71.15.56, %conv68.15.56
  %conv73.15.56 = trunc i32 %xor72.15.56 to i8
  store i8 %conv73.15.56, i8* %arrayidx70.56, align 1
  %scevgep20.16.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 16
  %19732 = load i8, i8* %scevgep20.16.56, align 1
  %conv68.16.56 = zext i8 %19732 to i32
  %19733 = load i8, i8* %arrayidx70.56, align 1
  %conv71.16.56 = zext i8 %19733 to i32
  %xor72.16.56 = xor i32 %conv71.16.56, %conv68.16.56
  %conv73.16.56 = trunc i32 %xor72.16.56 to i8
  store i8 %conv73.16.56, i8* %arrayidx70.56, align 1
  %scevgep20.17.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 17
  %19734 = load i8, i8* %scevgep20.17.56, align 1
  %conv68.17.56 = zext i8 %19734 to i32
  %19735 = load i8, i8* %arrayidx70.56, align 1
  %conv71.17.56 = zext i8 %19735 to i32
  %xor72.17.56 = xor i32 %conv71.17.56, %conv68.17.56
  %conv73.17.56 = trunc i32 %xor72.17.56 to i8
  store i8 %conv73.17.56, i8* %arrayidx70.56, align 1
  %scevgep20.18.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 18
  %19736 = load i8, i8* %scevgep20.18.56, align 1
  %conv68.18.56 = zext i8 %19736 to i32
  %19737 = load i8, i8* %arrayidx70.56, align 1
  %conv71.18.56 = zext i8 %19737 to i32
  %xor72.18.56 = xor i32 %conv71.18.56, %conv68.18.56
  %conv73.18.56 = trunc i32 %xor72.18.56 to i8
  store i8 %conv73.18.56, i8* %arrayidx70.56, align 1
  %scevgep20.19.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 19
  %19738 = load i8, i8* %scevgep20.19.56, align 1
  %conv68.19.56 = zext i8 %19738 to i32
  %19739 = load i8, i8* %arrayidx70.56, align 1
  %conv71.19.56 = zext i8 %19739 to i32
  %xor72.19.56 = xor i32 %conv71.19.56, %conv68.19.56
  %conv73.19.56 = trunc i32 %xor72.19.56 to i8
  store i8 %conv73.19.56, i8* %arrayidx70.56, align 1
  %scevgep20.20.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 20
  %19740 = load i8, i8* %scevgep20.20.56, align 1
  %conv68.20.56 = zext i8 %19740 to i32
  %19741 = load i8, i8* %arrayidx70.56, align 1
  %conv71.20.56 = zext i8 %19741 to i32
  %xor72.20.56 = xor i32 %conv71.20.56, %conv68.20.56
  %conv73.20.56 = trunc i32 %xor72.20.56 to i8
  store i8 %conv73.20.56, i8* %arrayidx70.56, align 1
  %scevgep20.21.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 21
  %19742 = load i8, i8* %scevgep20.21.56, align 1
  %conv68.21.56 = zext i8 %19742 to i32
  %19743 = load i8, i8* %arrayidx70.56, align 1
  %conv71.21.56 = zext i8 %19743 to i32
  %xor72.21.56 = xor i32 %conv71.21.56, %conv68.21.56
  %conv73.21.56 = trunc i32 %xor72.21.56 to i8
  store i8 %conv73.21.56, i8* %arrayidx70.56, align 1
  %scevgep20.22.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 22
  %19744 = load i8, i8* %scevgep20.22.56, align 1
  %conv68.22.56 = zext i8 %19744 to i32
  %19745 = load i8, i8* %arrayidx70.56, align 1
  %conv71.22.56 = zext i8 %19745 to i32
  %xor72.22.56 = xor i32 %conv71.22.56, %conv68.22.56
  %conv73.22.56 = trunc i32 %xor72.22.56 to i8
  store i8 %conv73.22.56, i8* %arrayidx70.56, align 1
  %scevgep20.23.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 23
  %19746 = load i8, i8* %scevgep20.23.56, align 1
  %conv68.23.56 = zext i8 %19746 to i32
  %19747 = load i8, i8* %arrayidx70.56, align 1
  %conv71.23.56 = zext i8 %19747 to i32
  %xor72.23.56 = xor i32 %conv71.23.56, %conv68.23.56
  %conv73.23.56 = trunc i32 %xor72.23.56 to i8
  store i8 %conv73.23.56, i8* %arrayidx70.56, align 1
  %scevgep20.24.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 24
  %19748 = load i8, i8* %scevgep20.24.56, align 1
  %conv68.24.56 = zext i8 %19748 to i32
  %19749 = load i8, i8* %arrayidx70.56, align 1
  %conv71.24.56 = zext i8 %19749 to i32
  %xor72.24.56 = xor i32 %conv71.24.56, %conv68.24.56
  %conv73.24.56 = trunc i32 %xor72.24.56 to i8
  store i8 %conv73.24.56, i8* %arrayidx70.56, align 1
  %scevgep20.25.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 25
  %19750 = load i8, i8* %scevgep20.25.56, align 1
  %conv68.25.56 = zext i8 %19750 to i32
  %19751 = load i8, i8* %arrayidx70.56, align 1
  %conv71.25.56 = zext i8 %19751 to i32
  %xor72.25.56 = xor i32 %conv71.25.56, %conv68.25.56
  %conv73.25.56 = trunc i32 %xor72.25.56 to i8
  store i8 %conv73.25.56, i8* %arrayidx70.56, align 1
  %scevgep20.26.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 26
  %19752 = load i8, i8* %scevgep20.26.56, align 1
  %conv68.26.56 = zext i8 %19752 to i32
  %19753 = load i8, i8* %arrayidx70.56, align 1
  %conv71.26.56 = zext i8 %19753 to i32
  %xor72.26.56 = xor i32 %conv71.26.56, %conv68.26.56
  %conv73.26.56 = trunc i32 %xor72.26.56 to i8
  store i8 %conv73.26.56, i8* %arrayidx70.56, align 1
  %scevgep20.27.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 27
  %19754 = load i8, i8* %scevgep20.27.56, align 1
  %conv68.27.56 = zext i8 %19754 to i32
  %19755 = load i8, i8* %arrayidx70.56, align 1
  %conv71.27.56 = zext i8 %19755 to i32
  %xor72.27.56 = xor i32 %conv71.27.56, %conv68.27.56
  %conv73.27.56 = trunc i32 %xor72.27.56 to i8
  store i8 %conv73.27.56, i8* %arrayidx70.56, align 1
  %scevgep20.28.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 28
  %19756 = load i8, i8* %scevgep20.28.56, align 1
  %conv68.28.56 = zext i8 %19756 to i32
  %19757 = load i8, i8* %arrayidx70.56, align 1
  %conv71.28.56 = zext i8 %19757 to i32
  %xor72.28.56 = xor i32 %conv71.28.56, %conv68.28.56
  %conv73.28.56 = trunc i32 %xor72.28.56 to i8
  store i8 %conv73.28.56, i8* %arrayidx70.56, align 1
  %scevgep20.29.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 29
  %19758 = load i8, i8* %scevgep20.29.56, align 1
  %conv68.29.56 = zext i8 %19758 to i32
  %19759 = load i8, i8* %arrayidx70.56, align 1
  %conv71.29.56 = zext i8 %19759 to i32
  %xor72.29.56 = xor i32 %conv71.29.56, %conv68.29.56
  %conv73.29.56 = trunc i32 %xor72.29.56 to i8
  store i8 %conv73.29.56, i8* %arrayidx70.56, align 1
  %scevgep20.30.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 30
  %19760 = load i8, i8* %scevgep20.30.56, align 1
  %conv68.30.56 = zext i8 %19760 to i32
  %19761 = load i8, i8* %arrayidx70.56, align 1
  %conv71.30.56 = zext i8 %19761 to i32
  %xor72.30.56 = xor i32 %conv71.30.56, %conv68.30.56
  %conv73.30.56 = trunc i32 %xor72.30.56 to i8
  store i8 %conv73.30.56, i8* %arrayidx70.56, align 1
  %scevgep20.31.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 31
  %19762 = load i8, i8* %scevgep20.31.56, align 1
  %conv68.31.56 = zext i8 %19762 to i32
  %19763 = load i8, i8* %arrayidx70.56, align 1
  %conv71.31.56 = zext i8 %19763 to i32
  %xor72.31.56 = xor i32 %conv71.31.56, %conv68.31.56
  %conv73.31.56 = trunc i32 %xor72.31.56 to i8
  store i8 %conv73.31.56, i8* %arrayidx70.56, align 1
  %scevgep20.32.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 32
  %19764 = load i8, i8* %scevgep20.32.56, align 1
  %conv68.32.56 = zext i8 %19764 to i32
  %19765 = load i8, i8* %arrayidx70.56, align 1
  %conv71.32.56 = zext i8 %19765 to i32
  %xor72.32.56 = xor i32 %conv71.32.56, %conv68.32.56
  %conv73.32.56 = trunc i32 %xor72.32.56 to i8
  store i8 %conv73.32.56, i8* %arrayidx70.56, align 1
  %scevgep20.33.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 33
  %19766 = load i8, i8* %scevgep20.33.56, align 1
  %conv68.33.56 = zext i8 %19766 to i32
  %19767 = load i8, i8* %arrayidx70.56, align 1
  %conv71.33.56 = zext i8 %19767 to i32
  %xor72.33.56 = xor i32 %conv71.33.56, %conv68.33.56
  %conv73.33.56 = trunc i32 %xor72.33.56 to i8
  store i8 %conv73.33.56, i8* %arrayidx70.56, align 1
  %scevgep20.34.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 34
  %19768 = load i8, i8* %scevgep20.34.56, align 1
  %conv68.34.56 = zext i8 %19768 to i32
  %19769 = load i8, i8* %arrayidx70.56, align 1
  %conv71.34.56 = zext i8 %19769 to i32
  %xor72.34.56 = xor i32 %conv71.34.56, %conv68.34.56
  %conv73.34.56 = trunc i32 %xor72.34.56 to i8
  store i8 %conv73.34.56, i8* %arrayidx70.56, align 1
  %scevgep20.35.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 35
  %19770 = load i8, i8* %scevgep20.35.56, align 1
  %conv68.35.56 = zext i8 %19770 to i32
  %19771 = load i8, i8* %arrayidx70.56, align 1
  %conv71.35.56 = zext i8 %19771 to i32
  %xor72.35.56 = xor i32 %conv71.35.56, %conv68.35.56
  %conv73.35.56 = trunc i32 %xor72.35.56 to i8
  store i8 %conv73.35.56, i8* %arrayidx70.56, align 1
  %scevgep20.36.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 36
  %19772 = load i8, i8* %scevgep20.36.56, align 1
  %conv68.36.56 = zext i8 %19772 to i32
  %19773 = load i8, i8* %arrayidx70.56, align 1
  %conv71.36.56 = zext i8 %19773 to i32
  %xor72.36.56 = xor i32 %conv71.36.56, %conv68.36.56
  %conv73.36.56 = trunc i32 %xor72.36.56 to i8
  store i8 %conv73.36.56, i8* %arrayidx70.56, align 1
  %scevgep20.37.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 37
  %19774 = load i8, i8* %scevgep20.37.56, align 1
  %conv68.37.56 = zext i8 %19774 to i32
  %19775 = load i8, i8* %arrayidx70.56, align 1
  %conv71.37.56 = zext i8 %19775 to i32
  %xor72.37.56 = xor i32 %conv71.37.56, %conv68.37.56
  %conv73.37.56 = trunc i32 %xor72.37.56 to i8
  store i8 %conv73.37.56, i8* %arrayidx70.56, align 1
  %scevgep20.38.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 38
  %19776 = load i8, i8* %scevgep20.38.56, align 1
  %conv68.38.56 = zext i8 %19776 to i32
  %19777 = load i8, i8* %arrayidx70.56, align 1
  %conv71.38.56 = zext i8 %19777 to i32
  %xor72.38.56 = xor i32 %conv71.38.56, %conv68.38.56
  %conv73.38.56 = trunc i32 %xor72.38.56 to i8
  store i8 %conv73.38.56, i8* %arrayidx70.56, align 1
  %scevgep20.39.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 39
  %19778 = load i8, i8* %scevgep20.39.56, align 1
  %conv68.39.56 = zext i8 %19778 to i32
  %19779 = load i8, i8* %arrayidx70.56, align 1
  %conv71.39.56 = zext i8 %19779 to i32
  %xor72.39.56 = xor i32 %conv71.39.56, %conv68.39.56
  %conv73.39.56 = trunc i32 %xor72.39.56 to i8
  store i8 %conv73.39.56, i8* %arrayidx70.56, align 1
  %scevgep20.40.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 40
  %19780 = load i8, i8* %scevgep20.40.56, align 1
  %conv68.40.56 = zext i8 %19780 to i32
  %19781 = load i8, i8* %arrayidx70.56, align 1
  %conv71.40.56 = zext i8 %19781 to i32
  %xor72.40.56 = xor i32 %conv71.40.56, %conv68.40.56
  %conv73.40.56 = trunc i32 %xor72.40.56 to i8
  store i8 %conv73.40.56, i8* %arrayidx70.56, align 1
  %scevgep20.41.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 41
  %19782 = load i8, i8* %scevgep20.41.56, align 1
  %conv68.41.56 = zext i8 %19782 to i32
  %19783 = load i8, i8* %arrayidx70.56, align 1
  %conv71.41.56 = zext i8 %19783 to i32
  %xor72.41.56 = xor i32 %conv71.41.56, %conv68.41.56
  %conv73.41.56 = trunc i32 %xor72.41.56 to i8
  store i8 %conv73.41.56, i8* %arrayidx70.56, align 1
  %scevgep20.42.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 42
  %19784 = load i8, i8* %scevgep20.42.56, align 1
  %conv68.42.56 = zext i8 %19784 to i32
  %19785 = load i8, i8* %arrayidx70.56, align 1
  %conv71.42.56 = zext i8 %19785 to i32
  %xor72.42.56 = xor i32 %conv71.42.56, %conv68.42.56
  %conv73.42.56 = trunc i32 %xor72.42.56 to i8
  store i8 %conv73.42.56, i8* %arrayidx70.56, align 1
  %scevgep20.43.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 43
  %19786 = load i8, i8* %scevgep20.43.56, align 1
  %conv68.43.56 = zext i8 %19786 to i32
  %19787 = load i8, i8* %arrayidx70.56, align 1
  %conv71.43.56 = zext i8 %19787 to i32
  %xor72.43.56 = xor i32 %conv71.43.56, %conv68.43.56
  %conv73.43.56 = trunc i32 %xor72.43.56 to i8
  store i8 %conv73.43.56, i8* %arrayidx70.56, align 1
  %scevgep20.44.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 44
  %19788 = load i8, i8* %scevgep20.44.56, align 1
  %conv68.44.56 = zext i8 %19788 to i32
  %19789 = load i8, i8* %arrayidx70.56, align 1
  %conv71.44.56 = zext i8 %19789 to i32
  %xor72.44.56 = xor i32 %conv71.44.56, %conv68.44.56
  %conv73.44.56 = trunc i32 %xor72.44.56 to i8
  store i8 %conv73.44.56, i8* %arrayidx70.56, align 1
  %scevgep20.45.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 45
  %19790 = load i8, i8* %scevgep20.45.56, align 1
  %conv68.45.56 = zext i8 %19790 to i32
  %19791 = load i8, i8* %arrayidx70.56, align 1
  %conv71.45.56 = zext i8 %19791 to i32
  %xor72.45.56 = xor i32 %conv71.45.56, %conv68.45.56
  %conv73.45.56 = trunc i32 %xor72.45.56 to i8
  store i8 %conv73.45.56, i8* %arrayidx70.56, align 1
  %scevgep20.46.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 46
  %19792 = load i8, i8* %scevgep20.46.56, align 1
  %conv68.46.56 = zext i8 %19792 to i32
  %19793 = load i8, i8* %arrayidx70.56, align 1
  %conv71.46.56 = zext i8 %19793 to i32
  %xor72.46.56 = xor i32 %conv71.46.56, %conv68.46.56
  %conv73.46.56 = trunc i32 %xor72.46.56 to i8
  store i8 %conv73.46.56, i8* %arrayidx70.56, align 1
  %scevgep20.47.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 47
  %19794 = load i8, i8* %scevgep20.47.56, align 1
  %conv68.47.56 = zext i8 %19794 to i32
  %19795 = load i8, i8* %arrayidx70.56, align 1
  %conv71.47.56 = zext i8 %19795 to i32
  %xor72.47.56 = xor i32 %conv71.47.56, %conv68.47.56
  %conv73.47.56 = trunc i32 %xor72.47.56 to i8
  store i8 %conv73.47.56, i8* %arrayidx70.56, align 1
  %scevgep20.48.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 48
  %19796 = load i8, i8* %scevgep20.48.56, align 1
  %conv68.48.56 = zext i8 %19796 to i32
  %19797 = load i8, i8* %arrayidx70.56, align 1
  %conv71.48.56 = zext i8 %19797 to i32
  %xor72.48.56 = xor i32 %conv71.48.56, %conv68.48.56
  %conv73.48.56 = trunc i32 %xor72.48.56 to i8
  store i8 %conv73.48.56, i8* %arrayidx70.56, align 1
  %scevgep20.49.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 49
  %19798 = load i8, i8* %scevgep20.49.56, align 1
  %conv68.49.56 = zext i8 %19798 to i32
  %19799 = load i8, i8* %arrayidx70.56, align 1
  %conv71.49.56 = zext i8 %19799 to i32
  %xor72.49.56 = xor i32 %conv71.49.56, %conv68.49.56
  %conv73.49.56 = trunc i32 %xor72.49.56 to i8
  store i8 %conv73.49.56, i8* %arrayidx70.56, align 1
  %scevgep20.50.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 50
  %19800 = load i8, i8* %scevgep20.50.56, align 1
  %conv68.50.56 = zext i8 %19800 to i32
  %19801 = load i8, i8* %arrayidx70.56, align 1
  %conv71.50.56 = zext i8 %19801 to i32
  %xor72.50.56 = xor i32 %conv71.50.56, %conv68.50.56
  %conv73.50.56 = trunc i32 %xor72.50.56 to i8
  store i8 %conv73.50.56, i8* %arrayidx70.56, align 1
  %scevgep20.51.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 51
  %19802 = load i8, i8* %scevgep20.51.56, align 1
  %conv68.51.56 = zext i8 %19802 to i32
  %19803 = load i8, i8* %arrayidx70.56, align 1
  %conv71.51.56 = zext i8 %19803 to i32
  %xor72.51.56 = xor i32 %conv71.51.56, %conv68.51.56
  %conv73.51.56 = trunc i32 %xor72.51.56 to i8
  store i8 %conv73.51.56, i8* %arrayidx70.56, align 1
  %scevgep20.52.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 52
  %19804 = load i8, i8* %scevgep20.52.56, align 1
  %conv68.52.56 = zext i8 %19804 to i32
  %19805 = load i8, i8* %arrayidx70.56, align 1
  %conv71.52.56 = zext i8 %19805 to i32
  %xor72.52.56 = xor i32 %conv71.52.56, %conv68.52.56
  %conv73.52.56 = trunc i32 %xor72.52.56 to i8
  store i8 %conv73.52.56, i8* %arrayidx70.56, align 1
  %scevgep20.53.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 53
  %19806 = load i8, i8* %scevgep20.53.56, align 1
  %conv68.53.56 = zext i8 %19806 to i32
  %19807 = load i8, i8* %arrayidx70.56, align 1
  %conv71.53.56 = zext i8 %19807 to i32
  %xor72.53.56 = xor i32 %conv71.53.56, %conv68.53.56
  %conv73.53.56 = trunc i32 %xor72.53.56 to i8
  store i8 %conv73.53.56, i8* %arrayidx70.56, align 1
  %scevgep20.54.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 54
  %19808 = load i8, i8* %scevgep20.54.56, align 1
  %conv68.54.56 = zext i8 %19808 to i32
  %19809 = load i8, i8* %arrayidx70.56, align 1
  %conv71.54.56 = zext i8 %19809 to i32
  %xor72.54.56 = xor i32 %conv71.54.56, %conv68.54.56
  %conv73.54.56 = trunc i32 %xor72.54.56 to i8
  store i8 %conv73.54.56, i8* %arrayidx70.56, align 1
  %scevgep20.55.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 55
  %19810 = load i8, i8* %scevgep20.55.56, align 1
  %conv68.55.56 = zext i8 %19810 to i32
  %19811 = load i8, i8* %arrayidx70.56, align 1
  %conv71.55.56 = zext i8 %19811 to i32
  %xor72.55.56 = xor i32 %conv71.55.56, %conv68.55.56
  %conv73.55.56 = trunc i32 %xor72.55.56 to i8
  store i8 %conv73.55.56, i8* %arrayidx70.56, align 1
  %scevgep20.57.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 57
  %19812 = load i8, i8* %scevgep20.57.56, align 1
  %conv68.57.56 = zext i8 %19812 to i32
  %19813 = load i8, i8* %arrayidx70.56, align 1
  %conv71.57.56 = zext i8 %19813 to i32
  %xor72.57.56 = xor i32 %conv71.57.56, %conv68.57.56
  %conv73.57.56 = trunc i32 %xor72.57.56 to i8
  store i8 %conv73.57.56, i8* %arrayidx70.56, align 1
  %scevgep20.58.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 58
  %19814 = load i8, i8* %scevgep20.58.56, align 1
  %conv68.58.56 = zext i8 %19814 to i32
  %19815 = load i8, i8* %arrayidx70.56, align 1
  %conv71.58.56 = zext i8 %19815 to i32
  %xor72.58.56 = xor i32 %conv71.58.56, %conv68.58.56
  %conv73.58.56 = trunc i32 %xor72.58.56 to i8
  store i8 %conv73.58.56, i8* %arrayidx70.56, align 1
  %scevgep20.59.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 59
  %19816 = load i8, i8* %scevgep20.59.56, align 1
  %conv68.59.56 = zext i8 %19816 to i32
  %19817 = load i8, i8* %arrayidx70.56, align 1
  %conv71.59.56 = zext i8 %19817 to i32
  %xor72.59.56 = xor i32 %conv71.59.56, %conv68.59.56
  %conv73.59.56 = trunc i32 %xor72.59.56 to i8
  store i8 %conv73.59.56, i8* %arrayidx70.56, align 1
  %scevgep20.60.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 0, i64 60
  %19818 = load i8, i8* %scevgep20.60.56, align 1
  %conv68.60.56 = zext i8 %19818 to i32
  %19819 = load i8, i8* %arrayidx70.56, align 1
  %conv71.60.56 = zext i8 %19819 to i32
  %xor72.60.56 = xor i32 %conv71.60.56, %conv68.60.56
  %conv73.60.56 = trunc i32 %xor72.60.56 to i8
  store i8 %conv73.60.56, i8* %arrayidx70.56, align 1
  %scevgep19.56 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19697, i64 0, i64 1, i64 0
  %19820 = bitcast i8* %scevgep19.56 to [61 x [61 x i8]]*
  %arrayidx51.57 = getelementptr inbounds i8, i8* %a, i64 57
  %19821 = load i8, i8* %arrayidx51.57, align 1
  %arrayidx53.57 = getelementptr inbounds i8, i8* %b, i64 57
  %19822 = load i8, i8* %arrayidx53.57, align 1
  %call54.57 = call zeroext i8 @mult(i8 zeroext %19821, i8 zeroext %19822)
  %arrayidx56.57 = getelementptr inbounds i8, i8* %c, i64 57
  store i8 %call54.57, i8* %arrayidx56.57, align 1
  %arrayidx70.57 = getelementptr inbounds i8, i8* %c, i64 57
  %scevgep20.57614 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 0
  %19823 = load i8, i8* %scevgep20.57614, align 1
  %conv68.57615 = zext i8 %19823 to i32
  %19824 = load i8, i8* %arrayidx70.57, align 1
  %conv71.57616 = zext i8 %19824 to i32
  %xor72.57617 = xor i32 %conv71.57616, %conv68.57615
  %conv73.57618 = trunc i32 %xor72.57617 to i8
  store i8 %conv73.57618, i8* %arrayidx70.57, align 1
  %scevgep20.1.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 1
  %19825 = load i8, i8* %scevgep20.1.57, align 1
  %conv68.1.57 = zext i8 %19825 to i32
  %19826 = load i8, i8* %arrayidx70.57, align 1
  %conv71.1.57 = zext i8 %19826 to i32
  %xor72.1.57 = xor i32 %conv71.1.57, %conv68.1.57
  %conv73.1.57 = trunc i32 %xor72.1.57 to i8
  store i8 %conv73.1.57, i8* %arrayidx70.57, align 1
  %scevgep20.2.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 2
  %19827 = load i8, i8* %scevgep20.2.57, align 1
  %conv68.2.57 = zext i8 %19827 to i32
  %19828 = load i8, i8* %arrayidx70.57, align 1
  %conv71.2.57 = zext i8 %19828 to i32
  %xor72.2.57 = xor i32 %conv71.2.57, %conv68.2.57
  %conv73.2.57 = trunc i32 %xor72.2.57 to i8
  store i8 %conv73.2.57, i8* %arrayidx70.57, align 1
  %scevgep20.3.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 3
  %19829 = load i8, i8* %scevgep20.3.57, align 1
  %conv68.3.57 = zext i8 %19829 to i32
  %19830 = load i8, i8* %arrayidx70.57, align 1
  %conv71.3.57 = zext i8 %19830 to i32
  %xor72.3.57 = xor i32 %conv71.3.57, %conv68.3.57
  %conv73.3.57 = trunc i32 %xor72.3.57 to i8
  store i8 %conv73.3.57, i8* %arrayidx70.57, align 1
  %scevgep20.4.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 4
  %19831 = load i8, i8* %scevgep20.4.57, align 1
  %conv68.4.57 = zext i8 %19831 to i32
  %19832 = load i8, i8* %arrayidx70.57, align 1
  %conv71.4.57 = zext i8 %19832 to i32
  %xor72.4.57 = xor i32 %conv71.4.57, %conv68.4.57
  %conv73.4.57 = trunc i32 %xor72.4.57 to i8
  store i8 %conv73.4.57, i8* %arrayidx70.57, align 1
  %scevgep20.5.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 5
  %19833 = load i8, i8* %scevgep20.5.57, align 1
  %conv68.5.57 = zext i8 %19833 to i32
  %19834 = load i8, i8* %arrayidx70.57, align 1
  %conv71.5.57 = zext i8 %19834 to i32
  %xor72.5.57 = xor i32 %conv71.5.57, %conv68.5.57
  %conv73.5.57 = trunc i32 %xor72.5.57 to i8
  store i8 %conv73.5.57, i8* %arrayidx70.57, align 1
  %scevgep20.6.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 6
  %19835 = load i8, i8* %scevgep20.6.57, align 1
  %conv68.6.57 = zext i8 %19835 to i32
  %19836 = load i8, i8* %arrayidx70.57, align 1
  %conv71.6.57 = zext i8 %19836 to i32
  %xor72.6.57 = xor i32 %conv71.6.57, %conv68.6.57
  %conv73.6.57 = trunc i32 %xor72.6.57 to i8
  store i8 %conv73.6.57, i8* %arrayidx70.57, align 1
  %scevgep20.7.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 7
  %19837 = load i8, i8* %scevgep20.7.57, align 1
  %conv68.7.57 = zext i8 %19837 to i32
  %19838 = load i8, i8* %arrayidx70.57, align 1
  %conv71.7.57 = zext i8 %19838 to i32
  %xor72.7.57 = xor i32 %conv71.7.57, %conv68.7.57
  %conv73.7.57 = trunc i32 %xor72.7.57 to i8
  store i8 %conv73.7.57, i8* %arrayidx70.57, align 1
  %scevgep20.8.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 8
  %19839 = load i8, i8* %scevgep20.8.57, align 1
  %conv68.8.57 = zext i8 %19839 to i32
  %19840 = load i8, i8* %arrayidx70.57, align 1
  %conv71.8.57 = zext i8 %19840 to i32
  %xor72.8.57 = xor i32 %conv71.8.57, %conv68.8.57
  %conv73.8.57 = trunc i32 %xor72.8.57 to i8
  store i8 %conv73.8.57, i8* %arrayidx70.57, align 1
  %scevgep20.9.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 9
  %19841 = load i8, i8* %scevgep20.9.57, align 1
  %conv68.9.57 = zext i8 %19841 to i32
  %19842 = load i8, i8* %arrayidx70.57, align 1
  %conv71.9.57 = zext i8 %19842 to i32
  %xor72.9.57 = xor i32 %conv71.9.57, %conv68.9.57
  %conv73.9.57 = trunc i32 %xor72.9.57 to i8
  store i8 %conv73.9.57, i8* %arrayidx70.57, align 1
  %scevgep20.10.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 10
  %19843 = load i8, i8* %scevgep20.10.57, align 1
  %conv68.10.57 = zext i8 %19843 to i32
  %19844 = load i8, i8* %arrayidx70.57, align 1
  %conv71.10.57 = zext i8 %19844 to i32
  %xor72.10.57 = xor i32 %conv71.10.57, %conv68.10.57
  %conv73.10.57 = trunc i32 %xor72.10.57 to i8
  store i8 %conv73.10.57, i8* %arrayidx70.57, align 1
  %scevgep20.11.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 11
  %19845 = load i8, i8* %scevgep20.11.57, align 1
  %conv68.11.57 = zext i8 %19845 to i32
  %19846 = load i8, i8* %arrayidx70.57, align 1
  %conv71.11.57 = zext i8 %19846 to i32
  %xor72.11.57 = xor i32 %conv71.11.57, %conv68.11.57
  %conv73.11.57 = trunc i32 %xor72.11.57 to i8
  store i8 %conv73.11.57, i8* %arrayidx70.57, align 1
  %scevgep20.12.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 12
  %19847 = load i8, i8* %scevgep20.12.57, align 1
  %conv68.12.57 = zext i8 %19847 to i32
  %19848 = load i8, i8* %arrayidx70.57, align 1
  %conv71.12.57 = zext i8 %19848 to i32
  %xor72.12.57 = xor i32 %conv71.12.57, %conv68.12.57
  %conv73.12.57 = trunc i32 %xor72.12.57 to i8
  store i8 %conv73.12.57, i8* %arrayidx70.57, align 1
  %scevgep20.13.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 13
  %19849 = load i8, i8* %scevgep20.13.57, align 1
  %conv68.13.57 = zext i8 %19849 to i32
  %19850 = load i8, i8* %arrayidx70.57, align 1
  %conv71.13.57 = zext i8 %19850 to i32
  %xor72.13.57 = xor i32 %conv71.13.57, %conv68.13.57
  %conv73.13.57 = trunc i32 %xor72.13.57 to i8
  store i8 %conv73.13.57, i8* %arrayidx70.57, align 1
  %scevgep20.14.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 14
  %19851 = load i8, i8* %scevgep20.14.57, align 1
  %conv68.14.57 = zext i8 %19851 to i32
  %19852 = load i8, i8* %arrayidx70.57, align 1
  %conv71.14.57 = zext i8 %19852 to i32
  %xor72.14.57 = xor i32 %conv71.14.57, %conv68.14.57
  %conv73.14.57 = trunc i32 %xor72.14.57 to i8
  store i8 %conv73.14.57, i8* %arrayidx70.57, align 1
  %scevgep20.15.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 15
  %19853 = load i8, i8* %scevgep20.15.57, align 1
  %conv68.15.57 = zext i8 %19853 to i32
  %19854 = load i8, i8* %arrayidx70.57, align 1
  %conv71.15.57 = zext i8 %19854 to i32
  %xor72.15.57 = xor i32 %conv71.15.57, %conv68.15.57
  %conv73.15.57 = trunc i32 %xor72.15.57 to i8
  store i8 %conv73.15.57, i8* %arrayidx70.57, align 1
  %scevgep20.16.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 16
  %19855 = load i8, i8* %scevgep20.16.57, align 1
  %conv68.16.57 = zext i8 %19855 to i32
  %19856 = load i8, i8* %arrayidx70.57, align 1
  %conv71.16.57 = zext i8 %19856 to i32
  %xor72.16.57 = xor i32 %conv71.16.57, %conv68.16.57
  %conv73.16.57 = trunc i32 %xor72.16.57 to i8
  store i8 %conv73.16.57, i8* %arrayidx70.57, align 1
  %scevgep20.17.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 17
  %19857 = load i8, i8* %scevgep20.17.57, align 1
  %conv68.17.57 = zext i8 %19857 to i32
  %19858 = load i8, i8* %arrayidx70.57, align 1
  %conv71.17.57 = zext i8 %19858 to i32
  %xor72.17.57 = xor i32 %conv71.17.57, %conv68.17.57
  %conv73.17.57 = trunc i32 %xor72.17.57 to i8
  store i8 %conv73.17.57, i8* %arrayidx70.57, align 1
  %scevgep20.18.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 18
  %19859 = load i8, i8* %scevgep20.18.57, align 1
  %conv68.18.57 = zext i8 %19859 to i32
  %19860 = load i8, i8* %arrayidx70.57, align 1
  %conv71.18.57 = zext i8 %19860 to i32
  %xor72.18.57 = xor i32 %conv71.18.57, %conv68.18.57
  %conv73.18.57 = trunc i32 %xor72.18.57 to i8
  store i8 %conv73.18.57, i8* %arrayidx70.57, align 1
  %scevgep20.19.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 19
  %19861 = load i8, i8* %scevgep20.19.57, align 1
  %conv68.19.57 = zext i8 %19861 to i32
  %19862 = load i8, i8* %arrayidx70.57, align 1
  %conv71.19.57 = zext i8 %19862 to i32
  %xor72.19.57 = xor i32 %conv71.19.57, %conv68.19.57
  %conv73.19.57 = trunc i32 %xor72.19.57 to i8
  store i8 %conv73.19.57, i8* %arrayidx70.57, align 1
  %scevgep20.20.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 20
  %19863 = load i8, i8* %scevgep20.20.57, align 1
  %conv68.20.57 = zext i8 %19863 to i32
  %19864 = load i8, i8* %arrayidx70.57, align 1
  %conv71.20.57 = zext i8 %19864 to i32
  %xor72.20.57 = xor i32 %conv71.20.57, %conv68.20.57
  %conv73.20.57 = trunc i32 %xor72.20.57 to i8
  store i8 %conv73.20.57, i8* %arrayidx70.57, align 1
  %scevgep20.21.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 21
  %19865 = load i8, i8* %scevgep20.21.57, align 1
  %conv68.21.57 = zext i8 %19865 to i32
  %19866 = load i8, i8* %arrayidx70.57, align 1
  %conv71.21.57 = zext i8 %19866 to i32
  %xor72.21.57 = xor i32 %conv71.21.57, %conv68.21.57
  %conv73.21.57 = trunc i32 %xor72.21.57 to i8
  store i8 %conv73.21.57, i8* %arrayidx70.57, align 1
  %scevgep20.22.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 22
  %19867 = load i8, i8* %scevgep20.22.57, align 1
  %conv68.22.57 = zext i8 %19867 to i32
  %19868 = load i8, i8* %arrayidx70.57, align 1
  %conv71.22.57 = zext i8 %19868 to i32
  %xor72.22.57 = xor i32 %conv71.22.57, %conv68.22.57
  %conv73.22.57 = trunc i32 %xor72.22.57 to i8
  store i8 %conv73.22.57, i8* %arrayidx70.57, align 1
  %scevgep20.23.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 23
  %19869 = load i8, i8* %scevgep20.23.57, align 1
  %conv68.23.57 = zext i8 %19869 to i32
  %19870 = load i8, i8* %arrayidx70.57, align 1
  %conv71.23.57 = zext i8 %19870 to i32
  %xor72.23.57 = xor i32 %conv71.23.57, %conv68.23.57
  %conv73.23.57 = trunc i32 %xor72.23.57 to i8
  store i8 %conv73.23.57, i8* %arrayidx70.57, align 1
  %scevgep20.24.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 24
  %19871 = load i8, i8* %scevgep20.24.57, align 1
  %conv68.24.57 = zext i8 %19871 to i32
  %19872 = load i8, i8* %arrayidx70.57, align 1
  %conv71.24.57 = zext i8 %19872 to i32
  %xor72.24.57 = xor i32 %conv71.24.57, %conv68.24.57
  %conv73.24.57 = trunc i32 %xor72.24.57 to i8
  store i8 %conv73.24.57, i8* %arrayidx70.57, align 1
  %scevgep20.25.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 25
  %19873 = load i8, i8* %scevgep20.25.57, align 1
  %conv68.25.57 = zext i8 %19873 to i32
  %19874 = load i8, i8* %arrayidx70.57, align 1
  %conv71.25.57 = zext i8 %19874 to i32
  %xor72.25.57 = xor i32 %conv71.25.57, %conv68.25.57
  %conv73.25.57 = trunc i32 %xor72.25.57 to i8
  store i8 %conv73.25.57, i8* %arrayidx70.57, align 1
  %scevgep20.26.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 26
  %19875 = load i8, i8* %scevgep20.26.57, align 1
  %conv68.26.57 = zext i8 %19875 to i32
  %19876 = load i8, i8* %arrayidx70.57, align 1
  %conv71.26.57 = zext i8 %19876 to i32
  %xor72.26.57 = xor i32 %conv71.26.57, %conv68.26.57
  %conv73.26.57 = trunc i32 %xor72.26.57 to i8
  store i8 %conv73.26.57, i8* %arrayidx70.57, align 1
  %scevgep20.27.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 27
  %19877 = load i8, i8* %scevgep20.27.57, align 1
  %conv68.27.57 = zext i8 %19877 to i32
  %19878 = load i8, i8* %arrayidx70.57, align 1
  %conv71.27.57 = zext i8 %19878 to i32
  %xor72.27.57 = xor i32 %conv71.27.57, %conv68.27.57
  %conv73.27.57 = trunc i32 %xor72.27.57 to i8
  store i8 %conv73.27.57, i8* %arrayidx70.57, align 1
  %scevgep20.28.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 28
  %19879 = load i8, i8* %scevgep20.28.57, align 1
  %conv68.28.57 = zext i8 %19879 to i32
  %19880 = load i8, i8* %arrayidx70.57, align 1
  %conv71.28.57 = zext i8 %19880 to i32
  %xor72.28.57 = xor i32 %conv71.28.57, %conv68.28.57
  %conv73.28.57 = trunc i32 %xor72.28.57 to i8
  store i8 %conv73.28.57, i8* %arrayidx70.57, align 1
  %scevgep20.29.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 29
  %19881 = load i8, i8* %scevgep20.29.57, align 1
  %conv68.29.57 = zext i8 %19881 to i32
  %19882 = load i8, i8* %arrayidx70.57, align 1
  %conv71.29.57 = zext i8 %19882 to i32
  %xor72.29.57 = xor i32 %conv71.29.57, %conv68.29.57
  %conv73.29.57 = trunc i32 %xor72.29.57 to i8
  store i8 %conv73.29.57, i8* %arrayidx70.57, align 1
  %scevgep20.30.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 30
  %19883 = load i8, i8* %scevgep20.30.57, align 1
  %conv68.30.57 = zext i8 %19883 to i32
  %19884 = load i8, i8* %arrayidx70.57, align 1
  %conv71.30.57 = zext i8 %19884 to i32
  %xor72.30.57 = xor i32 %conv71.30.57, %conv68.30.57
  %conv73.30.57 = trunc i32 %xor72.30.57 to i8
  store i8 %conv73.30.57, i8* %arrayidx70.57, align 1
  %scevgep20.31.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 31
  %19885 = load i8, i8* %scevgep20.31.57, align 1
  %conv68.31.57 = zext i8 %19885 to i32
  %19886 = load i8, i8* %arrayidx70.57, align 1
  %conv71.31.57 = zext i8 %19886 to i32
  %xor72.31.57 = xor i32 %conv71.31.57, %conv68.31.57
  %conv73.31.57 = trunc i32 %xor72.31.57 to i8
  store i8 %conv73.31.57, i8* %arrayidx70.57, align 1
  %scevgep20.32.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 32
  %19887 = load i8, i8* %scevgep20.32.57, align 1
  %conv68.32.57 = zext i8 %19887 to i32
  %19888 = load i8, i8* %arrayidx70.57, align 1
  %conv71.32.57 = zext i8 %19888 to i32
  %xor72.32.57 = xor i32 %conv71.32.57, %conv68.32.57
  %conv73.32.57 = trunc i32 %xor72.32.57 to i8
  store i8 %conv73.32.57, i8* %arrayidx70.57, align 1
  %scevgep20.33.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 33
  %19889 = load i8, i8* %scevgep20.33.57, align 1
  %conv68.33.57 = zext i8 %19889 to i32
  %19890 = load i8, i8* %arrayidx70.57, align 1
  %conv71.33.57 = zext i8 %19890 to i32
  %xor72.33.57 = xor i32 %conv71.33.57, %conv68.33.57
  %conv73.33.57 = trunc i32 %xor72.33.57 to i8
  store i8 %conv73.33.57, i8* %arrayidx70.57, align 1
  %scevgep20.34.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 34
  %19891 = load i8, i8* %scevgep20.34.57, align 1
  %conv68.34.57 = zext i8 %19891 to i32
  %19892 = load i8, i8* %arrayidx70.57, align 1
  %conv71.34.57 = zext i8 %19892 to i32
  %xor72.34.57 = xor i32 %conv71.34.57, %conv68.34.57
  %conv73.34.57 = trunc i32 %xor72.34.57 to i8
  store i8 %conv73.34.57, i8* %arrayidx70.57, align 1
  %scevgep20.35.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 35
  %19893 = load i8, i8* %scevgep20.35.57, align 1
  %conv68.35.57 = zext i8 %19893 to i32
  %19894 = load i8, i8* %arrayidx70.57, align 1
  %conv71.35.57 = zext i8 %19894 to i32
  %xor72.35.57 = xor i32 %conv71.35.57, %conv68.35.57
  %conv73.35.57 = trunc i32 %xor72.35.57 to i8
  store i8 %conv73.35.57, i8* %arrayidx70.57, align 1
  %scevgep20.36.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 36
  %19895 = load i8, i8* %scevgep20.36.57, align 1
  %conv68.36.57 = zext i8 %19895 to i32
  %19896 = load i8, i8* %arrayidx70.57, align 1
  %conv71.36.57 = zext i8 %19896 to i32
  %xor72.36.57 = xor i32 %conv71.36.57, %conv68.36.57
  %conv73.36.57 = trunc i32 %xor72.36.57 to i8
  store i8 %conv73.36.57, i8* %arrayidx70.57, align 1
  %scevgep20.37.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 37
  %19897 = load i8, i8* %scevgep20.37.57, align 1
  %conv68.37.57 = zext i8 %19897 to i32
  %19898 = load i8, i8* %arrayidx70.57, align 1
  %conv71.37.57 = zext i8 %19898 to i32
  %xor72.37.57 = xor i32 %conv71.37.57, %conv68.37.57
  %conv73.37.57 = trunc i32 %xor72.37.57 to i8
  store i8 %conv73.37.57, i8* %arrayidx70.57, align 1
  %scevgep20.38.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 38
  %19899 = load i8, i8* %scevgep20.38.57, align 1
  %conv68.38.57 = zext i8 %19899 to i32
  %19900 = load i8, i8* %arrayidx70.57, align 1
  %conv71.38.57 = zext i8 %19900 to i32
  %xor72.38.57 = xor i32 %conv71.38.57, %conv68.38.57
  %conv73.38.57 = trunc i32 %xor72.38.57 to i8
  store i8 %conv73.38.57, i8* %arrayidx70.57, align 1
  %scevgep20.39.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 39
  %19901 = load i8, i8* %scevgep20.39.57, align 1
  %conv68.39.57 = zext i8 %19901 to i32
  %19902 = load i8, i8* %arrayidx70.57, align 1
  %conv71.39.57 = zext i8 %19902 to i32
  %xor72.39.57 = xor i32 %conv71.39.57, %conv68.39.57
  %conv73.39.57 = trunc i32 %xor72.39.57 to i8
  store i8 %conv73.39.57, i8* %arrayidx70.57, align 1
  %scevgep20.40.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 40
  %19903 = load i8, i8* %scevgep20.40.57, align 1
  %conv68.40.57 = zext i8 %19903 to i32
  %19904 = load i8, i8* %arrayidx70.57, align 1
  %conv71.40.57 = zext i8 %19904 to i32
  %xor72.40.57 = xor i32 %conv71.40.57, %conv68.40.57
  %conv73.40.57 = trunc i32 %xor72.40.57 to i8
  store i8 %conv73.40.57, i8* %arrayidx70.57, align 1
  %scevgep20.41.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 41
  %19905 = load i8, i8* %scevgep20.41.57, align 1
  %conv68.41.57 = zext i8 %19905 to i32
  %19906 = load i8, i8* %arrayidx70.57, align 1
  %conv71.41.57 = zext i8 %19906 to i32
  %xor72.41.57 = xor i32 %conv71.41.57, %conv68.41.57
  %conv73.41.57 = trunc i32 %xor72.41.57 to i8
  store i8 %conv73.41.57, i8* %arrayidx70.57, align 1
  %scevgep20.42.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 42
  %19907 = load i8, i8* %scevgep20.42.57, align 1
  %conv68.42.57 = zext i8 %19907 to i32
  %19908 = load i8, i8* %arrayidx70.57, align 1
  %conv71.42.57 = zext i8 %19908 to i32
  %xor72.42.57 = xor i32 %conv71.42.57, %conv68.42.57
  %conv73.42.57 = trunc i32 %xor72.42.57 to i8
  store i8 %conv73.42.57, i8* %arrayidx70.57, align 1
  %scevgep20.43.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 43
  %19909 = load i8, i8* %scevgep20.43.57, align 1
  %conv68.43.57 = zext i8 %19909 to i32
  %19910 = load i8, i8* %arrayidx70.57, align 1
  %conv71.43.57 = zext i8 %19910 to i32
  %xor72.43.57 = xor i32 %conv71.43.57, %conv68.43.57
  %conv73.43.57 = trunc i32 %xor72.43.57 to i8
  store i8 %conv73.43.57, i8* %arrayidx70.57, align 1
  %scevgep20.44.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 44
  %19911 = load i8, i8* %scevgep20.44.57, align 1
  %conv68.44.57 = zext i8 %19911 to i32
  %19912 = load i8, i8* %arrayidx70.57, align 1
  %conv71.44.57 = zext i8 %19912 to i32
  %xor72.44.57 = xor i32 %conv71.44.57, %conv68.44.57
  %conv73.44.57 = trunc i32 %xor72.44.57 to i8
  store i8 %conv73.44.57, i8* %arrayidx70.57, align 1
  %scevgep20.45.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 45
  %19913 = load i8, i8* %scevgep20.45.57, align 1
  %conv68.45.57 = zext i8 %19913 to i32
  %19914 = load i8, i8* %arrayidx70.57, align 1
  %conv71.45.57 = zext i8 %19914 to i32
  %xor72.45.57 = xor i32 %conv71.45.57, %conv68.45.57
  %conv73.45.57 = trunc i32 %xor72.45.57 to i8
  store i8 %conv73.45.57, i8* %arrayidx70.57, align 1
  %scevgep20.46.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 46
  %19915 = load i8, i8* %scevgep20.46.57, align 1
  %conv68.46.57 = zext i8 %19915 to i32
  %19916 = load i8, i8* %arrayidx70.57, align 1
  %conv71.46.57 = zext i8 %19916 to i32
  %xor72.46.57 = xor i32 %conv71.46.57, %conv68.46.57
  %conv73.46.57 = trunc i32 %xor72.46.57 to i8
  store i8 %conv73.46.57, i8* %arrayidx70.57, align 1
  %scevgep20.47.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 47
  %19917 = load i8, i8* %scevgep20.47.57, align 1
  %conv68.47.57 = zext i8 %19917 to i32
  %19918 = load i8, i8* %arrayidx70.57, align 1
  %conv71.47.57 = zext i8 %19918 to i32
  %xor72.47.57 = xor i32 %conv71.47.57, %conv68.47.57
  %conv73.47.57 = trunc i32 %xor72.47.57 to i8
  store i8 %conv73.47.57, i8* %arrayidx70.57, align 1
  %scevgep20.48.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 48
  %19919 = load i8, i8* %scevgep20.48.57, align 1
  %conv68.48.57 = zext i8 %19919 to i32
  %19920 = load i8, i8* %arrayidx70.57, align 1
  %conv71.48.57 = zext i8 %19920 to i32
  %xor72.48.57 = xor i32 %conv71.48.57, %conv68.48.57
  %conv73.48.57 = trunc i32 %xor72.48.57 to i8
  store i8 %conv73.48.57, i8* %arrayidx70.57, align 1
  %scevgep20.49.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 49
  %19921 = load i8, i8* %scevgep20.49.57, align 1
  %conv68.49.57 = zext i8 %19921 to i32
  %19922 = load i8, i8* %arrayidx70.57, align 1
  %conv71.49.57 = zext i8 %19922 to i32
  %xor72.49.57 = xor i32 %conv71.49.57, %conv68.49.57
  %conv73.49.57 = trunc i32 %xor72.49.57 to i8
  store i8 %conv73.49.57, i8* %arrayidx70.57, align 1
  %scevgep20.50.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 50
  %19923 = load i8, i8* %scevgep20.50.57, align 1
  %conv68.50.57 = zext i8 %19923 to i32
  %19924 = load i8, i8* %arrayidx70.57, align 1
  %conv71.50.57 = zext i8 %19924 to i32
  %xor72.50.57 = xor i32 %conv71.50.57, %conv68.50.57
  %conv73.50.57 = trunc i32 %xor72.50.57 to i8
  store i8 %conv73.50.57, i8* %arrayidx70.57, align 1
  %scevgep20.51.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 51
  %19925 = load i8, i8* %scevgep20.51.57, align 1
  %conv68.51.57 = zext i8 %19925 to i32
  %19926 = load i8, i8* %arrayidx70.57, align 1
  %conv71.51.57 = zext i8 %19926 to i32
  %xor72.51.57 = xor i32 %conv71.51.57, %conv68.51.57
  %conv73.51.57 = trunc i32 %xor72.51.57 to i8
  store i8 %conv73.51.57, i8* %arrayidx70.57, align 1
  %scevgep20.52.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 52
  %19927 = load i8, i8* %scevgep20.52.57, align 1
  %conv68.52.57 = zext i8 %19927 to i32
  %19928 = load i8, i8* %arrayidx70.57, align 1
  %conv71.52.57 = zext i8 %19928 to i32
  %xor72.52.57 = xor i32 %conv71.52.57, %conv68.52.57
  %conv73.52.57 = trunc i32 %xor72.52.57 to i8
  store i8 %conv73.52.57, i8* %arrayidx70.57, align 1
  %scevgep20.53.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 53
  %19929 = load i8, i8* %scevgep20.53.57, align 1
  %conv68.53.57 = zext i8 %19929 to i32
  %19930 = load i8, i8* %arrayidx70.57, align 1
  %conv71.53.57 = zext i8 %19930 to i32
  %xor72.53.57 = xor i32 %conv71.53.57, %conv68.53.57
  %conv73.53.57 = trunc i32 %xor72.53.57 to i8
  store i8 %conv73.53.57, i8* %arrayidx70.57, align 1
  %scevgep20.54.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 54
  %19931 = load i8, i8* %scevgep20.54.57, align 1
  %conv68.54.57 = zext i8 %19931 to i32
  %19932 = load i8, i8* %arrayidx70.57, align 1
  %conv71.54.57 = zext i8 %19932 to i32
  %xor72.54.57 = xor i32 %conv71.54.57, %conv68.54.57
  %conv73.54.57 = trunc i32 %xor72.54.57 to i8
  store i8 %conv73.54.57, i8* %arrayidx70.57, align 1
  %scevgep20.55.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 55
  %19933 = load i8, i8* %scevgep20.55.57, align 1
  %conv68.55.57 = zext i8 %19933 to i32
  %19934 = load i8, i8* %arrayidx70.57, align 1
  %conv71.55.57 = zext i8 %19934 to i32
  %xor72.55.57 = xor i32 %conv71.55.57, %conv68.55.57
  %conv73.55.57 = trunc i32 %xor72.55.57 to i8
  store i8 %conv73.55.57, i8* %arrayidx70.57, align 1
  %scevgep20.56.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 56
  %19935 = load i8, i8* %scevgep20.56.57, align 1
  %conv68.56.57 = zext i8 %19935 to i32
  %19936 = load i8, i8* %arrayidx70.57, align 1
  %conv71.56.57 = zext i8 %19936 to i32
  %xor72.56.57 = xor i32 %conv71.56.57, %conv68.56.57
  %conv73.56.57 = trunc i32 %xor72.56.57 to i8
  store i8 %conv73.56.57, i8* %arrayidx70.57, align 1
  %scevgep20.58.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 58
  %19937 = load i8, i8* %scevgep20.58.57, align 1
  %conv68.58.57 = zext i8 %19937 to i32
  %19938 = load i8, i8* %arrayidx70.57, align 1
  %conv71.58.57 = zext i8 %19938 to i32
  %xor72.58.57 = xor i32 %conv71.58.57, %conv68.58.57
  %conv73.58.57 = trunc i32 %xor72.58.57 to i8
  store i8 %conv73.58.57, i8* %arrayidx70.57, align 1
  %scevgep20.59.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 59
  %19939 = load i8, i8* %scevgep20.59.57, align 1
  %conv68.59.57 = zext i8 %19939 to i32
  %19940 = load i8, i8* %arrayidx70.57, align 1
  %conv71.59.57 = zext i8 %19940 to i32
  %xor72.59.57 = xor i32 %conv71.59.57, %conv68.59.57
  %conv73.59.57 = trunc i32 %xor72.59.57 to i8
  store i8 %conv73.59.57, i8* %arrayidx70.57, align 1
  %scevgep20.60.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 0, i64 60
  %19941 = load i8, i8* %scevgep20.60.57, align 1
  %conv68.60.57 = zext i8 %19941 to i32
  %19942 = load i8, i8* %arrayidx70.57, align 1
  %conv71.60.57 = zext i8 %19942 to i32
  %xor72.60.57 = xor i32 %conv71.60.57, %conv68.60.57
  %conv73.60.57 = trunc i32 %xor72.60.57 to i8
  store i8 %conv73.60.57, i8* %arrayidx70.57, align 1
  %scevgep19.57 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19820, i64 0, i64 1, i64 0
  %19943 = bitcast i8* %scevgep19.57 to [61 x [61 x i8]]*
  %arrayidx51.58 = getelementptr inbounds i8, i8* %a, i64 58
  %19944 = load i8, i8* %arrayidx51.58, align 1
  %arrayidx53.58 = getelementptr inbounds i8, i8* %b, i64 58
  %19945 = load i8, i8* %arrayidx53.58, align 1
  %call54.58 = call zeroext i8 @mult(i8 zeroext %19944, i8 zeroext %19945)
  %arrayidx56.58 = getelementptr inbounds i8, i8* %c, i64 58
  store i8 %call54.58, i8* %arrayidx56.58, align 1
  %arrayidx70.58 = getelementptr inbounds i8, i8* %c, i64 58
  %scevgep20.58624 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 0
  %19946 = load i8, i8* %scevgep20.58624, align 1
  %conv68.58625 = zext i8 %19946 to i32
  %19947 = load i8, i8* %arrayidx70.58, align 1
  %conv71.58626 = zext i8 %19947 to i32
  %xor72.58627 = xor i32 %conv71.58626, %conv68.58625
  %conv73.58628 = trunc i32 %xor72.58627 to i8
  store i8 %conv73.58628, i8* %arrayidx70.58, align 1
  %scevgep20.1.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 1
  %19948 = load i8, i8* %scevgep20.1.58, align 1
  %conv68.1.58 = zext i8 %19948 to i32
  %19949 = load i8, i8* %arrayidx70.58, align 1
  %conv71.1.58 = zext i8 %19949 to i32
  %xor72.1.58 = xor i32 %conv71.1.58, %conv68.1.58
  %conv73.1.58 = trunc i32 %xor72.1.58 to i8
  store i8 %conv73.1.58, i8* %arrayidx70.58, align 1
  %scevgep20.2.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 2
  %19950 = load i8, i8* %scevgep20.2.58, align 1
  %conv68.2.58 = zext i8 %19950 to i32
  %19951 = load i8, i8* %arrayidx70.58, align 1
  %conv71.2.58 = zext i8 %19951 to i32
  %xor72.2.58 = xor i32 %conv71.2.58, %conv68.2.58
  %conv73.2.58 = trunc i32 %xor72.2.58 to i8
  store i8 %conv73.2.58, i8* %arrayidx70.58, align 1
  %scevgep20.3.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 3
  %19952 = load i8, i8* %scevgep20.3.58, align 1
  %conv68.3.58 = zext i8 %19952 to i32
  %19953 = load i8, i8* %arrayidx70.58, align 1
  %conv71.3.58 = zext i8 %19953 to i32
  %xor72.3.58 = xor i32 %conv71.3.58, %conv68.3.58
  %conv73.3.58 = trunc i32 %xor72.3.58 to i8
  store i8 %conv73.3.58, i8* %arrayidx70.58, align 1
  %scevgep20.4.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 4
  %19954 = load i8, i8* %scevgep20.4.58, align 1
  %conv68.4.58 = zext i8 %19954 to i32
  %19955 = load i8, i8* %arrayidx70.58, align 1
  %conv71.4.58 = zext i8 %19955 to i32
  %xor72.4.58 = xor i32 %conv71.4.58, %conv68.4.58
  %conv73.4.58 = trunc i32 %xor72.4.58 to i8
  store i8 %conv73.4.58, i8* %arrayidx70.58, align 1
  %scevgep20.5.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 5
  %19956 = load i8, i8* %scevgep20.5.58, align 1
  %conv68.5.58 = zext i8 %19956 to i32
  %19957 = load i8, i8* %arrayidx70.58, align 1
  %conv71.5.58 = zext i8 %19957 to i32
  %xor72.5.58 = xor i32 %conv71.5.58, %conv68.5.58
  %conv73.5.58 = trunc i32 %xor72.5.58 to i8
  store i8 %conv73.5.58, i8* %arrayidx70.58, align 1
  %scevgep20.6.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 6
  %19958 = load i8, i8* %scevgep20.6.58, align 1
  %conv68.6.58 = zext i8 %19958 to i32
  %19959 = load i8, i8* %arrayidx70.58, align 1
  %conv71.6.58 = zext i8 %19959 to i32
  %xor72.6.58 = xor i32 %conv71.6.58, %conv68.6.58
  %conv73.6.58 = trunc i32 %xor72.6.58 to i8
  store i8 %conv73.6.58, i8* %arrayidx70.58, align 1
  %scevgep20.7.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 7
  %19960 = load i8, i8* %scevgep20.7.58, align 1
  %conv68.7.58 = zext i8 %19960 to i32
  %19961 = load i8, i8* %arrayidx70.58, align 1
  %conv71.7.58 = zext i8 %19961 to i32
  %xor72.7.58 = xor i32 %conv71.7.58, %conv68.7.58
  %conv73.7.58 = trunc i32 %xor72.7.58 to i8
  store i8 %conv73.7.58, i8* %arrayidx70.58, align 1
  %scevgep20.8.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 8
  %19962 = load i8, i8* %scevgep20.8.58, align 1
  %conv68.8.58 = zext i8 %19962 to i32
  %19963 = load i8, i8* %arrayidx70.58, align 1
  %conv71.8.58 = zext i8 %19963 to i32
  %xor72.8.58 = xor i32 %conv71.8.58, %conv68.8.58
  %conv73.8.58 = trunc i32 %xor72.8.58 to i8
  store i8 %conv73.8.58, i8* %arrayidx70.58, align 1
  %scevgep20.9.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 9
  %19964 = load i8, i8* %scevgep20.9.58, align 1
  %conv68.9.58 = zext i8 %19964 to i32
  %19965 = load i8, i8* %arrayidx70.58, align 1
  %conv71.9.58 = zext i8 %19965 to i32
  %xor72.9.58 = xor i32 %conv71.9.58, %conv68.9.58
  %conv73.9.58 = trunc i32 %xor72.9.58 to i8
  store i8 %conv73.9.58, i8* %arrayidx70.58, align 1
  %scevgep20.10.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 10
  %19966 = load i8, i8* %scevgep20.10.58, align 1
  %conv68.10.58 = zext i8 %19966 to i32
  %19967 = load i8, i8* %arrayidx70.58, align 1
  %conv71.10.58 = zext i8 %19967 to i32
  %xor72.10.58 = xor i32 %conv71.10.58, %conv68.10.58
  %conv73.10.58 = trunc i32 %xor72.10.58 to i8
  store i8 %conv73.10.58, i8* %arrayidx70.58, align 1
  %scevgep20.11.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 11
  %19968 = load i8, i8* %scevgep20.11.58, align 1
  %conv68.11.58 = zext i8 %19968 to i32
  %19969 = load i8, i8* %arrayidx70.58, align 1
  %conv71.11.58 = zext i8 %19969 to i32
  %xor72.11.58 = xor i32 %conv71.11.58, %conv68.11.58
  %conv73.11.58 = trunc i32 %xor72.11.58 to i8
  store i8 %conv73.11.58, i8* %arrayidx70.58, align 1
  %scevgep20.12.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 12
  %19970 = load i8, i8* %scevgep20.12.58, align 1
  %conv68.12.58 = zext i8 %19970 to i32
  %19971 = load i8, i8* %arrayidx70.58, align 1
  %conv71.12.58 = zext i8 %19971 to i32
  %xor72.12.58 = xor i32 %conv71.12.58, %conv68.12.58
  %conv73.12.58 = trunc i32 %xor72.12.58 to i8
  store i8 %conv73.12.58, i8* %arrayidx70.58, align 1
  %scevgep20.13.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 13
  %19972 = load i8, i8* %scevgep20.13.58, align 1
  %conv68.13.58 = zext i8 %19972 to i32
  %19973 = load i8, i8* %arrayidx70.58, align 1
  %conv71.13.58 = zext i8 %19973 to i32
  %xor72.13.58 = xor i32 %conv71.13.58, %conv68.13.58
  %conv73.13.58 = trunc i32 %xor72.13.58 to i8
  store i8 %conv73.13.58, i8* %arrayidx70.58, align 1
  %scevgep20.14.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 14
  %19974 = load i8, i8* %scevgep20.14.58, align 1
  %conv68.14.58 = zext i8 %19974 to i32
  %19975 = load i8, i8* %arrayidx70.58, align 1
  %conv71.14.58 = zext i8 %19975 to i32
  %xor72.14.58 = xor i32 %conv71.14.58, %conv68.14.58
  %conv73.14.58 = trunc i32 %xor72.14.58 to i8
  store i8 %conv73.14.58, i8* %arrayidx70.58, align 1
  %scevgep20.15.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 15
  %19976 = load i8, i8* %scevgep20.15.58, align 1
  %conv68.15.58 = zext i8 %19976 to i32
  %19977 = load i8, i8* %arrayidx70.58, align 1
  %conv71.15.58 = zext i8 %19977 to i32
  %xor72.15.58 = xor i32 %conv71.15.58, %conv68.15.58
  %conv73.15.58 = trunc i32 %xor72.15.58 to i8
  store i8 %conv73.15.58, i8* %arrayidx70.58, align 1
  %scevgep20.16.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 16
  %19978 = load i8, i8* %scevgep20.16.58, align 1
  %conv68.16.58 = zext i8 %19978 to i32
  %19979 = load i8, i8* %arrayidx70.58, align 1
  %conv71.16.58 = zext i8 %19979 to i32
  %xor72.16.58 = xor i32 %conv71.16.58, %conv68.16.58
  %conv73.16.58 = trunc i32 %xor72.16.58 to i8
  store i8 %conv73.16.58, i8* %arrayidx70.58, align 1
  %scevgep20.17.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 17
  %19980 = load i8, i8* %scevgep20.17.58, align 1
  %conv68.17.58 = zext i8 %19980 to i32
  %19981 = load i8, i8* %arrayidx70.58, align 1
  %conv71.17.58 = zext i8 %19981 to i32
  %xor72.17.58 = xor i32 %conv71.17.58, %conv68.17.58
  %conv73.17.58 = trunc i32 %xor72.17.58 to i8
  store i8 %conv73.17.58, i8* %arrayidx70.58, align 1
  %scevgep20.18.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 18
  %19982 = load i8, i8* %scevgep20.18.58, align 1
  %conv68.18.58 = zext i8 %19982 to i32
  %19983 = load i8, i8* %arrayidx70.58, align 1
  %conv71.18.58 = zext i8 %19983 to i32
  %xor72.18.58 = xor i32 %conv71.18.58, %conv68.18.58
  %conv73.18.58 = trunc i32 %xor72.18.58 to i8
  store i8 %conv73.18.58, i8* %arrayidx70.58, align 1
  %scevgep20.19.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 19
  %19984 = load i8, i8* %scevgep20.19.58, align 1
  %conv68.19.58 = zext i8 %19984 to i32
  %19985 = load i8, i8* %arrayidx70.58, align 1
  %conv71.19.58 = zext i8 %19985 to i32
  %xor72.19.58 = xor i32 %conv71.19.58, %conv68.19.58
  %conv73.19.58 = trunc i32 %xor72.19.58 to i8
  store i8 %conv73.19.58, i8* %arrayidx70.58, align 1
  %scevgep20.20.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 20
  %19986 = load i8, i8* %scevgep20.20.58, align 1
  %conv68.20.58 = zext i8 %19986 to i32
  %19987 = load i8, i8* %arrayidx70.58, align 1
  %conv71.20.58 = zext i8 %19987 to i32
  %xor72.20.58 = xor i32 %conv71.20.58, %conv68.20.58
  %conv73.20.58 = trunc i32 %xor72.20.58 to i8
  store i8 %conv73.20.58, i8* %arrayidx70.58, align 1
  %scevgep20.21.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 21
  %19988 = load i8, i8* %scevgep20.21.58, align 1
  %conv68.21.58 = zext i8 %19988 to i32
  %19989 = load i8, i8* %arrayidx70.58, align 1
  %conv71.21.58 = zext i8 %19989 to i32
  %xor72.21.58 = xor i32 %conv71.21.58, %conv68.21.58
  %conv73.21.58 = trunc i32 %xor72.21.58 to i8
  store i8 %conv73.21.58, i8* %arrayidx70.58, align 1
  %scevgep20.22.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 22
  %19990 = load i8, i8* %scevgep20.22.58, align 1
  %conv68.22.58 = zext i8 %19990 to i32
  %19991 = load i8, i8* %arrayidx70.58, align 1
  %conv71.22.58 = zext i8 %19991 to i32
  %xor72.22.58 = xor i32 %conv71.22.58, %conv68.22.58
  %conv73.22.58 = trunc i32 %xor72.22.58 to i8
  store i8 %conv73.22.58, i8* %arrayidx70.58, align 1
  %scevgep20.23.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 23
  %19992 = load i8, i8* %scevgep20.23.58, align 1
  %conv68.23.58 = zext i8 %19992 to i32
  %19993 = load i8, i8* %arrayidx70.58, align 1
  %conv71.23.58 = zext i8 %19993 to i32
  %xor72.23.58 = xor i32 %conv71.23.58, %conv68.23.58
  %conv73.23.58 = trunc i32 %xor72.23.58 to i8
  store i8 %conv73.23.58, i8* %arrayidx70.58, align 1
  %scevgep20.24.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 24
  %19994 = load i8, i8* %scevgep20.24.58, align 1
  %conv68.24.58 = zext i8 %19994 to i32
  %19995 = load i8, i8* %arrayidx70.58, align 1
  %conv71.24.58 = zext i8 %19995 to i32
  %xor72.24.58 = xor i32 %conv71.24.58, %conv68.24.58
  %conv73.24.58 = trunc i32 %xor72.24.58 to i8
  store i8 %conv73.24.58, i8* %arrayidx70.58, align 1
  %scevgep20.25.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 25
  %19996 = load i8, i8* %scevgep20.25.58, align 1
  %conv68.25.58 = zext i8 %19996 to i32
  %19997 = load i8, i8* %arrayidx70.58, align 1
  %conv71.25.58 = zext i8 %19997 to i32
  %xor72.25.58 = xor i32 %conv71.25.58, %conv68.25.58
  %conv73.25.58 = trunc i32 %xor72.25.58 to i8
  store i8 %conv73.25.58, i8* %arrayidx70.58, align 1
  %scevgep20.26.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 26
  %19998 = load i8, i8* %scevgep20.26.58, align 1
  %conv68.26.58 = zext i8 %19998 to i32
  %19999 = load i8, i8* %arrayidx70.58, align 1
  %conv71.26.58 = zext i8 %19999 to i32
  %xor72.26.58 = xor i32 %conv71.26.58, %conv68.26.58
  %conv73.26.58 = trunc i32 %xor72.26.58 to i8
  store i8 %conv73.26.58, i8* %arrayidx70.58, align 1
  %scevgep20.27.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 27
  %20000 = load i8, i8* %scevgep20.27.58, align 1
  %conv68.27.58 = zext i8 %20000 to i32
  %20001 = load i8, i8* %arrayidx70.58, align 1
  %conv71.27.58 = zext i8 %20001 to i32
  %xor72.27.58 = xor i32 %conv71.27.58, %conv68.27.58
  %conv73.27.58 = trunc i32 %xor72.27.58 to i8
  store i8 %conv73.27.58, i8* %arrayidx70.58, align 1
  %scevgep20.28.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 28
  %20002 = load i8, i8* %scevgep20.28.58, align 1
  %conv68.28.58 = zext i8 %20002 to i32
  %20003 = load i8, i8* %arrayidx70.58, align 1
  %conv71.28.58 = zext i8 %20003 to i32
  %xor72.28.58 = xor i32 %conv71.28.58, %conv68.28.58
  %conv73.28.58 = trunc i32 %xor72.28.58 to i8
  store i8 %conv73.28.58, i8* %arrayidx70.58, align 1
  %scevgep20.29.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 29
  %20004 = load i8, i8* %scevgep20.29.58, align 1
  %conv68.29.58 = zext i8 %20004 to i32
  %20005 = load i8, i8* %arrayidx70.58, align 1
  %conv71.29.58 = zext i8 %20005 to i32
  %xor72.29.58 = xor i32 %conv71.29.58, %conv68.29.58
  %conv73.29.58 = trunc i32 %xor72.29.58 to i8
  store i8 %conv73.29.58, i8* %arrayidx70.58, align 1
  %scevgep20.30.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 30
  %20006 = load i8, i8* %scevgep20.30.58, align 1
  %conv68.30.58 = zext i8 %20006 to i32
  %20007 = load i8, i8* %arrayidx70.58, align 1
  %conv71.30.58 = zext i8 %20007 to i32
  %xor72.30.58 = xor i32 %conv71.30.58, %conv68.30.58
  %conv73.30.58 = trunc i32 %xor72.30.58 to i8
  store i8 %conv73.30.58, i8* %arrayidx70.58, align 1
  %scevgep20.31.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 31
  %20008 = load i8, i8* %scevgep20.31.58, align 1
  %conv68.31.58 = zext i8 %20008 to i32
  %20009 = load i8, i8* %arrayidx70.58, align 1
  %conv71.31.58 = zext i8 %20009 to i32
  %xor72.31.58 = xor i32 %conv71.31.58, %conv68.31.58
  %conv73.31.58 = trunc i32 %xor72.31.58 to i8
  store i8 %conv73.31.58, i8* %arrayidx70.58, align 1
  %scevgep20.32.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 32
  %20010 = load i8, i8* %scevgep20.32.58, align 1
  %conv68.32.58 = zext i8 %20010 to i32
  %20011 = load i8, i8* %arrayidx70.58, align 1
  %conv71.32.58 = zext i8 %20011 to i32
  %xor72.32.58 = xor i32 %conv71.32.58, %conv68.32.58
  %conv73.32.58 = trunc i32 %xor72.32.58 to i8
  store i8 %conv73.32.58, i8* %arrayidx70.58, align 1
  %scevgep20.33.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 33
  %20012 = load i8, i8* %scevgep20.33.58, align 1
  %conv68.33.58 = zext i8 %20012 to i32
  %20013 = load i8, i8* %arrayidx70.58, align 1
  %conv71.33.58 = zext i8 %20013 to i32
  %xor72.33.58 = xor i32 %conv71.33.58, %conv68.33.58
  %conv73.33.58 = trunc i32 %xor72.33.58 to i8
  store i8 %conv73.33.58, i8* %arrayidx70.58, align 1
  %scevgep20.34.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 34
  %20014 = load i8, i8* %scevgep20.34.58, align 1
  %conv68.34.58 = zext i8 %20014 to i32
  %20015 = load i8, i8* %arrayidx70.58, align 1
  %conv71.34.58 = zext i8 %20015 to i32
  %xor72.34.58 = xor i32 %conv71.34.58, %conv68.34.58
  %conv73.34.58 = trunc i32 %xor72.34.58 to i8
  store i8 %conv73.34.58, i8* %arrayidx70.58, align 1
  %scevgep20.35.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 35
  %20016 = load i8, i8* %scevgep20.35.58, align 1
  %conv68.35.58 = zext i8 %20016 to i32
  %20017 = load i8, i8* %arrayidx70.58, align 1
  %conv71.35.58 = zext i8 %20017 to i32
  %xor72.35.58 = xor i32 %conv71.35.58, %conv68.35.58
  %conv73.35.58 = trunc i32 %xor72.35.58 to i8
  store i8 %conv73.35.58, i8* %arrayidx70.58, align 1
  %scevgep20.36.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 36
  %20018 = load i8, i8* %scevgep20.36.58, align 1
  %conv68.36.58 = zext i8 %20018 to i32
  %20019 = load i8, i8* %arrayidx70.58, align 1
  %conv71.36.58 = zext i8 %20019 to i32
  %xor72.36.58 = xor i32 %conv71.36.58, %conv68.36.58
  %conv73.36.58 = trunc i32 %xor72.36.58 to i8
  store i8 %conv73.36.58, i8* %arrayidx70.58, align 1
  %scevgep20.37.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 37
  %20020 = load i8, i8* %scevgep20.37.58, align 1
  %conv68.37.58 = zext i8 %20020 to i32
  %20021 = load i8, i8* %arrayidx70.58, align 1
  %conv71.37.58 = zext i8 %20021 to i32
  %xor72.37.58 = xor i32 %conv71.37.58, %conv68.37.58
  %conv73.37.58 = trunc i32 %xor72.37.58 to i8
  store i8 %conv73.37.58, i8* %arrayidx70.58, align 1
  %scevgep20.38.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 38
  %20022 = load i8, i8* %scevgep20.38.58, align 1
  %conv68.38.58 = zext i8 %20022 to i32
  %20023 = load i8, i8* %arrayidx70.58, align 1
  %conv71.38.58 = zext i8 %20023 to i32
  %xor72.38.58 = xor i32 %conv71.38.58, %conv68.38.58
  %conv73.38.58 = trunc i32 %xor72.38.58 to i8
  store i8 %conv73.38.58, i8* %arrayidx70.58, align 1
  %scevgep20.39.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 39
  %20024 = load i8, i8* %scevgep20.39.58, align 1
  %conv68.39.58 = zext i8 %20024 to i32
  %20025 = load i8, i8* %arrayidx70.58, align 1
  %conv71.39.58 = zext i8 %20025 to i32
  %xor72.39.58 = xor i32 %conv71.39.58, %conv68.39.58
  %conv73.39.58 = trunc i32 %xor72.39.58 to i8
  store i8 %conv73.39.58, i8* %arrayidx70.58, align 1
  %scevgep20.40.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 40
  %20026 = load i8, i8* %scevgep20.40.58, align 1
  %conv68.40.58 = zext i8 %20026 to i32
  %20027 = load i8, i8* %arrayidx70.58, align 1
  %conv71.40.58 = zext i8 %20027 to i32
  %xor72.40.58 = xor i32 %conv71.40.58, %conv68.40.58
  %conv73.40.58 = trunc i32 %xor72.40.58 to i8
  store i8 %conv73.40.58, i8* %arrayidx70.58, align 1
  %scevgep20.41.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 41
  %20028 = load i8, i8* %scevgep20.41.58, align 1
  %conv68.41.58 = zext i8 %20028 to i32
  %20029 = load i8, i8* %arrayidx70.58, align 1
  %conv71.41.58 = zext i8 %20029 to i32
  %xor72.41.58 = xor i32 %conv71.41.58, %conv68.41.58
  %conv73.41.58 = trunc i32 %xor72.41.58 to i8
  store i8 %conv73.41.58, i8* %arrayidx70.58, align 1
  %scevgep20.42.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 42
  %20030 = load i8, i8* %scevgep20.42.58, align 1
  %conv68.42.58 = zext i8 %20030 to i32
  %20031 = load i8, i8* %arrayidx70.58, align 1
  %conv71.42.58 = zext i8 %20031 to i32
  %xor72.42.58 = xor i32 %conv71.42.58, %conv68.42.58
  %conv73.42.58 = trunc i32 %xor72.42.58 to i8
  store i8 %conv73.42.58, i8* %arrayidx70.58, align 1
  %scevgep20.43.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 43
  %20032 = load i8, i8* %scevgep20.43.58, align 1
  %conv68.43.58 = zext i8 %20032 to i32
  %20033 = load i8, i8* %arrayidx70.58, align 1
  %conv71.43.58 = zext i8 %20033 to i32
  %xor72.43.58 = xor i32 %conv71.43.58, %conv68.43.58
  %conv73.43.58 = trunc i32 %xor72.43.58 to i8
  store i8 %conv73.43.58, i8* %arrayidx70.58, align 1
  %scevgep20.44.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 44
  %20034 = load i8, i8* %scevgep20.44.58, align 1
  %conv68.44.58 = zext i8 %20034 to i32
  %20035 = load i8, i8* %arrayidx70.58, align 1
  %conv71.44.58 = zext i8 %20035 to i32
  %xor72.44.58 = xor i32 %conv71.44.58, %conv68.44.58
  %conv73.44.58 = trunc i32 %xor72.44.58 to i8
  store i8 %conv73.44.58, i8* %arrayidx70.58, align 1
  %scevgep20.45.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 45
  %20036 = load i8, i8* %scevgep20.45.58, align 1
  %conv68.45.58 = zext i8 %20036 to i32
  %20037 = load i8, i8* %arrayidx70.58, align 1
  %conv71.45.58 = zext i8 %20037 to i32
  %xor72.45.58 = xor i32 %conv71.45.58, %conv68.45.58
  %conv73.45.58 = trunc i32 %xor72.45.58 to i8
  store i8 %conv73.45.58, i8* %arrayidx70.58, align 1
  %scevgep20.46.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 46
  %20038 = load i8, i8* %scevgep20.46.58, align 1
  %conv68.46.58 = zext i8 %20038 to i32
  %20039 = load i8, i8* %arrayidx70.58, align 1
  %conv71.46.58 = zext i8 %20039 to i32
  %xor72.46.58 = xor i32 %conv71.46.58, %conv68.46.58
  %conv73.46.58 = trunc i32 %xor72.46.58 to i8
  store i8 %conv73.46.58, i8* %arrayidx70.58, align 1
  %scevgep20.47.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 47
  %20040 = load i8, i8* %scevgep20.47.58, align 1
  %conv68.47.58 = zext i8 %20040 to i32
  %20041 = load i8, i8* %arrayidx70.58, align 1
  %conv71.47.58 = zext i8 %20041 to i32
  %xor72.47.58 = xor i32 %conv71.47.58, %conv68.47.58
  %conv73.47.58 = trunc i32 %xor72.47.58 to i8
  store i8 %conv73.47.58, i8* %arrayidx70.58, align 1
  %scevgep20.48.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 48
  %20042 = load i8, i8* %scevgep20.48.58, align 1
  %conv68.48.58 = zext i8 %20042 to i32
  %20043 = load i8, i8* %arrayidx70.58, align 1
  %conv71.48.58 = zext i8 %20043 to i32
  %xor72.48.58 = xor i32 %conv71.48.58, %conv68.48.58
  %conv73.48.58 = trunc i32 %xor72.48.58 to i8
  store i8 %conv73.48.58, i8* %arrayidx70.58, align 1
  %scevgep20.49.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 49
  %20044 = load i8, i8* %scevgep20.49.58, align 1
  %conv68.49.58 = zext i8 %20044 to i32
  %20045 = load i8, i8* %arrayidx70.58, align 1
  %conv71.49.58 = zext i8 %20045 to i32
  %xor72.49.58 = xor i32 %conv71.49.58, %conv68.49.58
  %conv73.49.58 = trunc i32 %xor72.49.58 to i8
  store i8 %conv73.49.58, i8* %arrayidx70.58, align 1
  %scevgep20.50.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 50
  %20046 = load i8, i8* %scevgep20.50.58, align 1
  %conv68.50.58 = zext i8 %20046 to i32
  %20047 = load i8, i8* %arrayidx70.58, align 1
  %conv71.50.58 = zext i8 %20047 to i32
  %xor72.50.58 = xor i32 %conv71.50.58, %conv68.50.58
  %conv73.50.58 = trunc i32 %xor72.50.58 to i8
  store i8 %conv73.50.58, i8* %arrayidx70.58, align 1
  %scevgep20.51.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 51
  %20048 = load i8, i8* %scevgep20.51.58, align 1
  %conv68.51.58 = zext i8 %20048 to i32
  %20049 = load i8, i8* %arrayidx70.58, align 1
  %conv71.51.58 = zext i8 %20049 to i32
  %xor72.51.58 = xor i32 %conv71.51.58, %conv68.51.58
  %conv73.51.58 = trunc i32 %xor72.51.58 to i8
  store i8 %conv73.51.58, i8* %arrayidx70.58, align 1
  %scevgep20.52.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 52
  %20050 = load i8, i8* %scevgep20.52.58, align 1
  %conv68.52.58 = zext i8 %20050 to i32
  %20051 = load i8, i8* %arrayidx70.58, align 1
  %conv71.52.58 = zext i8 %20051 to i32
  %xor72.52.58 = xor i32 %conv71.52.58, %conv68.52.58
  %conv73.52.58 = trunc i32 %xor72.52.58 to i8
  store i8 %conv73.52.58, i8* %arrayidx70.58, align 1
  %scevgep20.53.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 53
  %20052 = load i8, i8* %scevgep20.53.58, align 1
  %conv68.53.58 = zext i8 %20052 to i32
  %20053 = load i8, i8* %arrayidx70.58, align 1
  %conv71.53.58 = zext i8 %20053 to i32
  %xor72.53.58 = xor i32 %conv71.53.58, %conv68.53.58
  %conv73.53.58 = trunc i32 %xor72.53.58 to i8
  store i8 %conv73.53.58, i8* %arrayidx70.58, align 1
  %scevgep20.54.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 54
  %20054 = load i8, i8* %scevgep20.54.58, align 1
  %conv68.54.58 = zext i8 %20054 to i32
  %20055 = load i8, i8* %arrayidx70.58, align 1
  %conv71.54.58 = zext i8 %20055 to i32
  %xor72.54.58 = xor i32 %conv71.54.58, %conv68.54.58
  %conv73.54.58 = trunc i32 %xor72.54.58 to i8
  store i8 %conv73.54.58, i8* %arrayidx70.58, align 1
  %scevgep20.55.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 55
  %20056 = load i8, i8* %scevgep20.55.58, align 1
  %conv68.55.58 = zext i8 %20056 to i32
  %20057 = load i8, i8* %arrayidx70.58, align 1
  %conv71.55.58 = zext i8 %20057 to i32
  %xor72.55.58 = xor i32 %conv71.55.58, %conv68.55.58
  %conv73.55.58 = trunc i32 %xor72.55.58 to i8
  store i8 %conv73.55.58, i8* %arrayidx70.58, align 1
  %scevgep20.56.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 56
  %20058 = load i8, i8* %scevgep20.56.58, align 1
  %conv68.56.58 = zext i8 %20058 to i32
  %20059 = load i8, i8* %arrayidx70.58, align 1
  %conv71.56.58 = zext i8 %20059 to i32
  %xor72.56.58 = xor i32 %conv71.56.58, %conv68.56.58
  %conv73.56.58 = trunc i32 %xor72.56.58 to i8
  store i8 %conv73.56.58, i8* %arrayidx70.58, align 1
  %scevgep20.57.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 57
  %20060 = load i8, i8* %scevgep20.57.58, align 1
  %conv68.57.58 = zext i8 %20060 to i32
  %20061 = load i8, i8* %arrayidx70.58, align 1
  %conv71.57.58 = zext i8 %20061 to i32
  %xor72.57.58 = xor i32 %conv71.57.58, %conv68.57.58
  %conv73.57.58 = trunc i32 %xor72.57.58 to i8
  store i8 %conv73.57.58, i8* %arrayidx70.58, align 1
  %scevgep20.59.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 59
  %20062 = load i8, i8* %scevgep20.59.58, align 1
  %conv68.59.58 = zext i8 %20062 to i32
  %20063 = load i8, i8* %arrayidx70.58, align 1
  %conv71.59.58 = zext i8 %20063 to i32
  %xor72.59.58 = xor i32 %conv71.59.58, %conv68.59.58
  %conv73.59.58 = trunc i32 %xor72.59.58 to i8
  store i8 %conv73.59.58, i8* %arrayidx70.58, align 1
  %scevgep20.60.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 0, i64 60
  %20064 = load i8, i8* %scevgep20.60.58, align 1
  %conv68.60.58 = zext i8 %20064 to i32
  %20065 = load i8, i8* %arrayidx70.58, align 1
  %conv71.60.58 = zext i8 %20065 to i32
  %xor72.60.58 = xor i32 %conv71.60.58, %conv68.60.58
  %conv73.60.58 = trunc i32 %xor72.60.58 to i8
  store i8 %conv73.60.58, i8* %arrayidx70.58, align 1
  %scevgep19.58 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %19943, i64 0, i64 1, i64 0
  %20066 = bitcast i8* %scevgep19.58 to [61 x [61 x i8]]*
  %arrayidx51.59 = getelementptr inbounds i8, i8* %a, i64 59
  %20067 = load i8, i8* %arrayidx51.59, align 1
  %arrayidx53.59 = getelementptr inbounds i8, i8* %b, i64 59
  %20068 = load i8, i8* %arrayidx53.59, align 1
  %call54.59 = call zeroext i8 @mult(i8 zeroext %20067, i8 zeroext %20068)
  %arrayidx56.59 = getelementptr inbounds i8, i8* %c, i64 59
  store i8 %call54.59, i8* %arrayidx56.59, align 1
  %arrayidx70.59 = getelementptr inbounds i8, i8* %c, i64 59
  %scevgep20.59634 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 0
  %20069 = load i8, i8* %scevgep20.59634, align 1
  %conv68.59635 = zext i8 %20069 to i32
  %20070 = load i8, i8* %arrayidx70.59, align 1
  %conv71.59636 = zext i8 %20070 to i32
  %xor72.59637 = xor i32 %conv71.59636, %conv68.59635
  %conv73.59638 = trunc i32 %xor72.59637 to i8
  store i8 %conv73.59638, i8* %arrayidx70.59, align 1
  %scevgep20.1.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 1
  %20071 = load i8, i8* %scevgep20.1.59, align 1
  %conv68.1.59 = zext i8 %20071 to i32
  %20072 = load i8, i8* %arrayidx70.59, align 1
  %conv71.1.59 = zext i8 %20072 to i32
  %xor72.1.59 = xor i32 %conv71.1.59, %conv68.1.59
  %conv73.1.59 = trunc i32 %xor72.1.59 to i8
  store i8 %conv73.1.59, i8* %arrayidx70.59, align 1
  %scevgep20.2.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 2
  %20073 = load i8, i8* %scevgep20.2.59, align 1
  %conv68.2.59 = zext i8 %20073 to i32
  %20074 = load i8, i8* %arrayidx70.59, align 1
  %conv71.2.59 = zext i8 %20074 to i32
  %xor72.2.59 = xor i32 %conv71.2.59, %conv68.2.59
  %conv73.2.59 = trunc i32 %xor72.2.59 to i8
  store i8 %conv73.2.59, i8* %arrayidx70.59, align 1
  %scevgep20.3.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 3
  %20075 = load i8, i8* %scevgep20.3.59, align 1
  %conv68.3.59 = zext i8 %20075 to i32
  %20076 = load i8, i8* %arrayidx70.59, align 1
  %conv71.3.59 = zext i8 %20076 to i32
  %xor72.3.59 = xor i32 %conv71.3.59, %conv68.3.59
  %conv73.3.59 = trunc i32 %xor72.3.59 to i8
  store i8 %conv73.3.59, i8* %arrayidx70.59, align 1
  %scevgep20.4.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 4
  %20077 = load i8, i8* %scevgep20.4.59, align 1
  %conv68.4.59 = zext i8 %20077 to i32
  %20078 = load i8, i8* %arrayidx70.59, align 1
  %conv71.4.59 = zext i8 %20078 to i32
  %xor72.4.59 = xor i32 %conv71.4.59, %conv68.4.59
  %conv73.4.59 = trunc i32 %xor72.4.59 to i8
  store i8 %conv73.4.59, i8* %arrayidx70.59, align 1
  %scevgep20.5.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 5
  %20079 = load i8, i8* %scevgep20.5.59, align 1
  %conv68.5.59 = zext i8 %20079 to i32
  %20080 = load i8, i8* %arrayidx70.59, align 1
  %conv71.5.59 = zext i8 %20080 to i32
  %xor72.5.59 = xor i32 %conv71.5.59, %conv68.5.59
  %conv73.5.59 = trunc i32 %xor72.5.59 to i8
  store i8 %conv73.5.59, i8* %arrayidx70.59, align 1
  %scevgep20.6.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 6
  %20081 = load i8, i8* %scevgep20.6.59, align 1
  %conv68.6.59 = zext i8 %20081 to i32
  %20082 = load i8, i8* %arrayidx70.59, align 1
  %conv71.6.59 = zext i8 %20082 to i32
  %xor72.6.59 = xor i32 %conv71.6.59, %conv68.6.59
  %conv73.6.59 = trunc i32 %xor72.6.59 to i8
  store i8 %conv73.6.59, i8* %arrayidx70.59, align 1
  %scevgep20.7.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 7
  %20083 = load i8, i8* %scevgep20.7.59, align 1
  %conv68.7.59 = zext i8 %20083 to i32
  %20084 = load i8, i8* %arrayidx70.59, align 1
  %conv71.7.59 = zext i8 %20084 to i32
  %xor72.7.59 = xor i32 %conv71.7.59, %conv68.7.59
  %conv73.7.59 = trunc i32 %xor72.7.59 to i8
  store i8 %conv73.7.59, i8* %arrayidx70.59, align 1
  %scevgep20.8.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 8
  %20085 = load i8, i8* %scevgep20.8.59, align 1
  %conv68.8.59 = zext i8 %20085 to i32
  %20086 = load i8, i8* %arrayidx70.59, align 1
  %conv71.8.59 = zext i8 %20086 to i32
  %xor72.8.59 = xor i32 %conv71.8.59, %conv68.8.59
  %conv73.8.59 = trunc i32 %xor72.8.59 to i8
  store i8 %conv73.8.59, i8* %arrayidx70.59, align 1
  %scevgep20.9.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 9
  %20087 = load i8, i8* %scevgep20.9.59, align 1
  %conv68.9.59 = zext i8 %20087 to i32
  %20088 = load i8, i8* %arrayidx70.59, align 1
  %conv71.9.59 = zext i8 %20088 to i32
  %xor72.9.59 = xor i32 %conv71.9.59, %conv68.9.59
  %conv73.9.59 = trunc i32 %xor72.9.59 to i8
  store i8 %conv73.9.59, i8* %arrayidx70.59, align 1
  %scevgep20.10.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 10
  %20089 = load i8, i8* %scevgep20.10.59, align 1
  %conv68.10.59 = zext i8 %20089 to i32
  %20090 = load i8, i8* %arrayidx70.59, align 1
  %conv71.10.59 = zext i8 %20090 to i32
  %xor72.10.59 = xor i32 %conv71.10.59, %conv68.10.59
  %conv73.10.59 = trunc i32 %xor72.10.59 to i8
  store i8 %conv73.10.59, i8* %arrayidx70.59, align 1
  %scevgep20.11.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 11
  %20091 = load i8, i8* %scevgep20.11.59, align 1
  %conv68.11.59 = zext i8 %20091 to i32
  %20092 = load i8, i8* %arrayidx70.59, align 1
  %conv71.11.59 = zext i8 %20092 to i32
  %xor72.11.59 = xor i32 %conv71.11.59, %conv68.11.59
  %conv73.11.59 = trunc i32 %xor72.11.59 to i8
  store i8 %conv73.11.59, i8* %arrayidx70.59, align 1
  %scevgep20.12.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 12
  %20093 = load i8, i8* %scevgep20.12.59, align 1
  %conv68.12.59 = zext i8 %20093 to i32
  %20094 = load i8, i8* %arrayidx70.59, align 1
  %conv71.12.59 = zext i8 %20094 to i32
  %xor72.12.59 = xor i32 %conv71.12.59, %conv68.12.59
  %conv73.12.59 = trunc i32 %xor72.12.59 to i8
  store i8 %conv73.12.59, i8* %arrayidx70.59, align 1
  %scevgep20.13.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 13
  %20095 = load i8, i8* %scevgep20.13.59, align 1
  %conv68.13.59 = zext i8 %20095 to i32
  %20096 = load i8, i8* %arrayidx70.59, align 1
  %conv71.13.59 = zext i8 %20096 to i32
  %xor72.13.59 = xor i32 %conv71.13.59, %conv68.13.59
  %conv73.13.59 = trunc i32 %xor72.13.59 to i8
  store i8 %conv73.13.59, i8* %arrayidx70.59, align 1
  %scevgep20.14.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 14
  %20097 = load i8, i8* %scevgep20.14.59, align 1
  %conv68.14.59 = zext i8 %20097 to i32
  %20098 = load i8, i8* %arrayidx70.59, align 1
  %conv71.14.59 = zext i8 %20098 to i32
  %xor72.14.59 = xor i32 %conv71.14.59, %conv68.14.59
  %conv73.14.59 = trunc i32 %xor72.14.59 to i8
  store i8 %conv73.14.59, i8* %arrayidx70.59, align 1
  %scevgep20.15.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 15
  %20099 = load i8, i8* %scevgep20.15.59, align 1
  %conv68.15.59 = zext i8 %20099 to i32
  %20100 = load i8, i8* %arrayidx70.59, align 1
  %conv71.15.59 = zext i8 %20100 to i32
  %xor72.15.59 = xor i32 %conv71.15.59, %conv68.15.59
  %conv73.15.59 = trunc i32 %xor72.15.59 to i8
  store i8 %conv73.15.59, i8* %arrayidx70.59, align 1
  %scevgep20.16.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 16
  %20101 = load i8, i8* %scevgep20.16.59, align 1
  %conv68.16.59 = zext i8 %20101 to i32
  %20102 = load i8, i8* %arrayidx70.59, align 1
  %conv71.16.59 = zext i8 %20102 to i32
  %xor72.16.59 = xor i32 %conv71.16.59, %conv68.16.59
  %conv73.16.59 = trunc i32 %xor72.16.59 to i8
  store i8 %conv73.16.59, i8* %arrayidx70.59, align 1
  %scevgep20.17.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 17
  %20103 = load i8, i8* %scevgep20.17.59, align 1
  %conv68.17.59 = zext i8 %20103 to i32
  %20104 = load i8, i8* %arrayidx70.59, align 1
  %conv71.17.59 = zext i8 %20104 to i32
  %xor72.17.59 = xor i32 %conv71.17.59, %conv68.17.59
  %conv73.17.59 = trunc i32 %xor72.17.59 to i8
  store i8 %conv73.17.59, i8* %arrayidx70.59, align 1
  %scevgep20.18.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 18
  %20105 = load i8, i8* %scevgep20.18.59, align 1
  %conv68.18.59 = zext i8 %20105 to i32
  %20106 = load i8, i8* %arrayidx70.59, align 1
  %conv71.18.59 = zext i8 %20106 to i32
  %xor72.18.59 = xor i32 %conv71.18.59, %conv68.18.59
  %conv73.18.59 = trunc i32 %xor72.18.59 to i8
  store i8 %conv73.18.59, i8* %arrayidx70.59, align 1
  %scevgep20.19.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 19
  %20107 = load i8, i8* %scevgep20.19.59, align 1
  %conv68.19.59 = zext i8 %20107 to i32
  %20108 = load i8, i8* %arrayidx70.59, align 1
  %conv71.19.59 = zext i8 %20108 to i32
  %xor72.19.59 = xor i32 %conv71.19.59, %conv68.19.59
  %conv73.19.59 = trunc i32 %xor72.19.59 to i8
  store i8 %conv73.19.59, i8* %arrayidx70.59, align 1
  %scevgep20.20.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 20
  %20109 = load i8, i8* %scevgep20.20.59, align 1
  %conv68.20.59 = zext i8 %20109 to i32
  %20110 = load i8, i8* %arrayidx70.59, align 1
  %conv71.20.59 = zext i8 %20110 to i32
  %xor72.20.59 = xor i32 %conv71.20.59, %conv68.20.59
  %conv73.20.59 = trunc i32 %xor72.20.59 to i8
  store i8 %conv73.20.59, i8* %arrayidx70.59, align 1
  %scevgep20.21.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 21
  %20111 = load i8, i8* %scevgep20.21.59, align 1
  %conv68.21.59 = zext i8 %20111 to i32
  %20112 = load i8, i8* %arrayidx70.59, align 1
  %conv71.21.59 = zext i8 %20112 to i32
  %xor72.21.59 = xor i32 %conv71.21.59, %conv68.21.59
  %conv73.21.59 = trunc i32 %xor72.21.59 to i8
  store i8 %conv73.21.59, i8* %arrayidx70.59, align 1
  %scevgep20.22.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 22
  %20113 = load i8, i8* %scevgep20.22.59, align 1
  %conv68.22.59 = zext i8 %20113 to i32
  %20114 = load i8, i8* %arrayidx70.59, align 1
  %conv71.22.59 = zext i8 %20114 to i32
  %xor72.22.59 = xor i32 %conv71.22.59, %conv68.22.59
  %conv73.22.59 = trunc i32 %xor72.22.59 to i8
  store i8 %conv73.22.59, i8* %arrayidx70.59, align 1
  %scevgep20.23.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 23
  %20115 = load i8, i8* %scevgep20.23.59, align 1
  %conv68.23.59 = zext i8 %20115 to i32
  %20116 = load i8, i8* %arrayidx70.59, align 1
  %conv71.23.59 = zext i8 %20116 to i32
  %xor72.23.59 = xor i32 %conv71.23.59, %conv68.23.59
  %conv73.23.59 = trunc i32 %xor72.23.59 to i8
  store i8 %conv73.23.59, i8* %arrayidx70.59, align 1
  %scevgep20.24.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 24
  %20117 = load i8, i8* %scevgep20.24.59, align 1
  %conv68.24.59 = zext i8 %20117 to i32
  %20118 = load i8, i8* %arrayidx70.59, align 1
  %conv71.24.59 = zext i8 %20118 to i32
  %xor72.24.59 = xor i32 %conv71.24.59, %conv68.24.59
  %conv73.24.59 = trunc i32 %xor72.24.59 to i8
  store i8 %conv73.24.59, i8* %arrayidx70.59, align 1
  %scevgep20.25.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 25
  %20119 = load i8, i8* %scevgep20.25.59, align 1
  %conv68.25.59 = zext i8 %20119 to i32
  %20120 = load i8, i8* %arrayidx70.59, align 1
  %conv71.25.59 = zext i8 %20120 to i32
  %xor72.25.59 = xor i32 %conv71.25.59, %conv68.25.59
  %conv73.25.59 = trunc i32 %xor72.25.59 to i8
  store i8 %conv73.25.59, i8* %arrayidx70.59, align 1
  %scevgep20.26.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 26
  %20121 = load i8, i8* %scevgep20.26.59, align 1
  %conv68.26.59 = zext i8 %20121 to i32
  %20122 = load i8, i8* %arrayidx70.59, align 1
  %conv71.26.59 = zext i8 %20122 to i32
  %xor72.26.59 = xor i32 %conv71.26.59, %conv68.26.59
  %conv73.26.59 = trunc i32 %xor72.26.59 to i8
  store i8 %conv73.26.59, i8* %arrayidx70.59, align 1
  %scevgep20.27.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 27
  %20123 = load i8, i8* %scevgep20.27.59, align 1
  %conv68.27.59 = zext i8 %20123 to i32
  %20124 = load i8, i8* %arrayidx70.59, align 1
  %conv71.27.59 = zext i8 %20124 to i32
  %xor72.27.59 = xor i32 %conv71.27.59, %conv68.27.59
  %conv73.27.59 = trunc i32 %xor72.27.59 to i8
  store i8 %conv73.27.59, i8* %arrayidx70.59, align 1
  %scevgep20.28.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 28
  %20125 = load i8, i8* %scevgep20.28.59, align 1
  %conv68.28.59 = zext i8 %20125 to i32
  %20126 = load i8, i8* %arrayidx70.59, align 1
  %conv71.28.59 = zext i8 %20126 to i32
  %xor72.28.59 = xor i32 %conv71.28.59, %conv68.28.59
  %conv73.28.59 = trunc i32 %xor72.28.59 to i8
  store i8 %conv73.28.59, i8* %arrayidx70.59, align 1
  %scevgep20.29.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 29
  %20127 = load i8, i8* %scevgep20.29.59, align 1
  %conv68.29.59 = zext i8 %20127 to i32
  %20128 = load i8, i8* %arrayidx70.59, align 1
  %conv71.29.59 = zext i8 %20128 to i32
  %xor72.29.59 = xor i32 %conv71.29.59, %conv68.29.59
  %conv73.29.59 = trunc i32 %xor72.29.59 to i8
  store i8 %conv73.29.59, i8* %arrayidx70.59, align 1
  %scevgep20.30.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 30
  %20129 = load i8, i8* %scevgep20.30.59, align 1
  %conv68.30.59 = zext i8 %20129 to i32
  %20130 = load i8, i8* %arrayidx70.59, align 1
  %conv71.30.59 = zext i8 %20130 to i32
  %xor72.30.59 = xor i32 %conv71.30.59, %conv68.30.59
  %conv73.30.59 = trunc i32 %xor72.30.59 to i8
  store i8 %conv73.30.59, i8* %arrayidx70.59, align 1
  %scevgep20.31.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 31
  %20131 = load i8, i8* %scevgep20.31.59, align 1
  %conv68.31.59 = zext i8 %20131 to i32
  %20132 = load i8, i8* %arrayidx70.59, align 1
  %conv71.31.59 = zext i8 %20132 to i32
  %xor72.31.59 = xor i32 %conv71.31.59, %conv68.31.59
  %conv73.31.59 = trunc i32 %xor72.31.59 to i8
  store i8 %conv73.31.59, i8* %arrayidx70.59, align 1
  %scevgep20.32.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 32
  %20133 = load i8, i8* %scevgep20.32.59, align 1
  %conv68.32.59 = zext i8 %20133 to i32
  %20134 = load i8, i8* %arrayidx70.59, align 1
  %conv71.32.59 = zext i8 %20134 to i32
  %xor72.32.59 = xor i32 %conv71.32.59, %conv68.32.59
  %conv73.32.59 = trunc i32 %xor72.32.59 to i8
  store i8 %conv73.32.59, i8* %arrayidx70.59, align 1
  %scevgep20.33.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 33
  %20135 = load i8, i8* %scevgep20.33.59, align 1
  %conv68.33.59 = zext i8 %20135 to i32
  %20136 = load i8, i8* %arrayidx70.59, align 1
  %conv71.33.59 = zext i8 %20136 to i32
  %xor72.33.59 = xor i32 %conv71.33.59, %conv68.33.59
  %conv73.33.59 = trunc i32 %xor72.33.59 to i8
  store i8 %conv73.33.59, i8* %arrayidx70.59, align 1
  %scevgep20.34.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 34
  %20137 = load i8, i8* %scevgep20.34.59, align 1
  %conv68.34.59 = zext i8 %20137 to i32
  %20138 = load i8, i8* %arrayidx70.59, align 1
  %conv71.34.59 = zext i8 %20138 to i32
  %xor72.34.59 = xor i32 %conv71.34.59, %conv68.34.59
  %conv73.34.59 = trunc i32 %xor72.34.59 to i8
  store i8 %conv73.34.59, i8* %arrayidx70.59, align 1
  %scevgep20.35.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 35
  %20139 = load i8, i8* %scevgep20.35.59, align 1
  %conv68.35.59 = zext i8 %20139 to i32
  %20140 = load i8, i8* %arrayidx70.59, align 1
  %conv71.35.59 = zext i8 %20140 to i32
  %xor72.35.59 = xor i32 %conv71.35.59, %conv68.35.59
  %conv73.35.59 = trunc i32 %xor72.35.59 to i8
  store i8 %conv73.35.59, i8* %arrayidx70.59, align 1
  %scevgep20.36.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 36
  %20141 = load i8, i8* %scevgep20.36.59, align 1
  %conv68.36.59 = zext i8 %20141 to i32
  %20142 = load i8, i8* %arrayidx70.59, align 1
  %conv71.36.59 = zext i8 %20142 to i32
  %xor72.36.59 = xor i32 %conv71.36.59, %conv68.36.59
  %conv73.36.59 = trunc i32 %xor72.36.59 to i8
  store i8 %conv73.36.59, i8* %arrayidx70.59, align 1
  %scevgep20.37.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 37
  %20143 = load i8, i8* %scevgep20.37.59, align 1
  %conv68.37.59 = zext i8 %20143 to i32
  %20144 = load i8, i8* %arrayidx70.59, align 1
  %conv71.37.59 = zext i8 %20144 to i32
  %xor72.37.59 = xor i32 %conv71.37.59, %conv68.37.59
  %conv73.37.59 = trunc i32 %xor72.37.59 to i8
  store i8 %conv73.37.59, i8* %arrayidx70.59, align 1
  %scevgep20.38.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 38
  %20145 = load i8, i8* %scevgep20.38.59, align 1
  %conv68.38.59 = zext i8 %20145 to i32
  %20146 = load i8, i8* %arrayidx70.59, align 1
  %conv71.38.59 = zext i8 %20146 to i32
  %xor72.38.59 = xor i32 %conv71.38.59, %conv68.38.59
  %conv73.38.59 = trunc i32 %xor72.38.59 to i8
  store i8 %conv73.38.59, i8* %arrayidx70.59, align 1
  %scevgep20.39.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 39
  %20147 = load i8, i8* %scevgep20.39.59, align 1
  %conv68.39.59 = zext i8 %20147 to i32
  %20148 = load i8, i8* %arrayidx70.59, align 1
  %conv71.39.59 = zext i8 %20148 to i32
  %xor72.39.59 = xor i32 %conv71.39.59, %conv68.39.59
  %conv73.39.59 = trunc i32 %xor72.39.59 to i8
  store i8 %conv73.39.59, i8* %arrayidx70.59, align 1
  %scevgep20.40.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 40
  %20149 = load i8, i8* %scevgep20.40.59, align 1
  %conv68.40.59 = zext i8 %20149 to i32
  %20150 = load i8, i8* %arrayidx70.59, align 1
  %conv71.40.59 = zext i8 %20150 to i32
  %xor72.40.59 = xor i32 %conv71.40.59, %conv68.40.59
  %conv73.40.59 = trunc i32 %xor72.40.59 to i8
  store i8 %conv73.40.59, i8* %arrayidx70.59, align 1
  %scevgep20.41.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 41
  %20151 = load i8, i8* %scevgep20.41.59, align 1
  %conv68.41.59 = zext i8 %20151 to i32
  %20152 = load i8, i8* %arrayidx70.59, align 1
  %conv71.41.59 = zext i8 %20152 to i32
  %xor72.41.59 = xor i32 %conv71.41.59, %conv68.41.59
  %conv73.41.59 = trunc i32 %xor72.41.59 to i8
  store i8 %conv73.41.59, i8* %arrayidx70.59, align 1
  %scevgep20.42.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 42
  %20153 = load i8, i8* %scevgep20.42.59, align 1
  %conv68.42.59 = zext i8 %20153 to i32
  %20154 = load i8, i8* %arrayidx70.59, align 1
  %conv71.42.59 = zext i8 %20154 to i32
  %xor72.42.59 = xor i32 %conv71.42.59, %conv68.42.59
  %conv73.42.59 = trunc i32 %xor72.42.59 to i8
  store i8 %conv73.42.59, i8* %arrayidx70.59, align 1
  %scevgep20.43.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 43
  %20155 = load i8, i8* %scevgep20.43.59, align 1
  %conv68.43.59 = zext i8 %20155 to i32
  %20156 = load i8, i8* %arrayidx70.59, align 1
  %conv71.43.59 = zext i8 %20156 to i32
  %xor72.43.59 = xor i32 %conv71.43.59, %conv68.43.59
  %conv73.43.59 = trunc i32 %xor72.43.59 to i8
  store i8 %conv73.43.59, i8* %arrayidx70.59, align 1
  %scevgep20.44.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 44
  %20157 = load i8, i8* %scevgep20.44.59, align 1
  %conv68.44.59 = zext i8 %20157 to i32
  %20158 = load i8, i8* %arrayidx70.59, align 1
  %conv71.44.59 = zext i8 %20158 to i32
  %xor72.44.59 = xor i32 %conv71.44.59, %conv68.44.59
  %conv73.44.59 = trunc i32 %xor72.44.59 to i8
  store i8 %conv73.44.59, i8* %arrayidx70.59, align 1
  %scevgep20.45.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 45
  %20159 = load i8, i8* %scevgep20.45.59, align 1
  %conv68.45.59 = zext i8 %20159 to i32
  %20160 = load i8, i8* %arrayidx70.59, align 1
  %conv71.45.59 = zext i8 %20160 to i32
  %xor72.45.59 = xor i32 %conv71.45.59, %conv68.45.59
  %conv73.45.59 = trunc i32 %xor72.45.59 to i8
  store i8 %conv73.45.59, i8* %arrayidx70.59, align 1
  %scevgep20.46.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 46
  %20161 = load i8, i8* %scevgep20.46.59, align 1
  %conv68.46.59 = zext i8 %20161 to i32
  %20162 = load i8, i8* %arrayidx70.59, align 1
  %conv71.46.59 = zext i8 %20162 to i32
  %xor72.46.59 = xor i32 %conv71.46.59, %conv68.46.59
  %conv73.46.59 = trunc i32 %xor72.46.59 to i8
  store i8 %conv73.46.59, i8* %arrayidx70.59, align 1
  %scevgep20.47.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 47
  %20163 = load i8, i8* %scevgep20.47.59, align 1
  %conv68.47.59 = zext i8 %20163 to i32
  %20164 = load i8, i8* %arrayidx70.59, align 1
  %conv71.47.59 = zext i8 %20164 to i32
  %xor72.47.59 = xor i32 %conv71.47.59, %conv68.47.59
  %conv73.47.59 = trunc i32 %xor72.47.59 to i8
  store i8 %conv73.47.59, i8* %arrayidx70.59, align 1
  %scevgep20.48.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 48
  %20165 = load i8, i8* %scevgep20.48.59, align 1
  %conv68.48.59 = zext i8 %20165 to i32
  %20166 = load i8, i8* %arrayidx70.59, align 1
  %conv71.48.59 = zext i8 %20166 to i32
  %xor72.48.59 = xor i32 %conv71.48.59, %conv68.48.59
  %conv73.48.59 = trunc i32 %xor72.48.59 to i8
  store i8 %conv73.48.59, i8* %arrayidx70.59, align 1
  %scevgep20.49.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 49
  %20167 = load i8, i8* %scevgep20.49.59, align 1
  %conv68.49.59 = zext i8 %20167 to i32
  %20168 = load i8, i8* %arrayidx70.59, align 1
  %conv71.49.59 = zext i8 %20168 to i32
  %xor72.49.59 = xor i32 %conv71.49.59, %conv68.49.59
  %conv73.49.59 = trunc i32 %xor72.49.59 to i8
  store i8 %conv73.49.59, i8* %arrayidx70.59, align 1
  %scevgep20.50.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 50
  %20169 = load i8, i8* %scevgep20.50.59, align 1
  %conv68.50.59 = zext i8 %20169 to i32
  %20170 = load i8, i8* %arrayidx70.59, align 1
  %conv71.50.59 = zext i8 %20170 to i32
  %xor72.50.59 = xor i32 %conv71.50.59, %conv68.50.59
  %conv73.50.59 = trunc i32 %xor72.50.59 to i8
  store i8 %conv73.50.59, i8* %arrayidx70.59, align 1
  %scevgep20.51.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 51
  %20171 = load i8, i8* %scevgep20.51.59, align 1
  %conv68.51.59 = zext i8 %20171 to i32
  %20172 = load i8, i8* %arrayidx70.59, align 1
  %conv71.51.59 = zext i8 %20172 to i32
  %xor72.51.59 = xor i32 %conv71.51.59, %conv68.51.59
  %conv73.51.59 = trunc i32 %xor72.51.59 to i8
  store i8 %conv73.51.59, i8* %arrayidx70.59, align 1
  %scevgep20.52.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 52
  %20173 = load i8, i8* %scevgep20.52.59, align 1
  %conv68.52.59 = zext i8 %20173 to i32
  %20174 = load i8, i8* %arrayidx70.59, align 1
  %conv71.52.59 = zext i8 %20174 to i32
  %xor72.52.59 = xor i32 %conv71.52.59, %conv68.52.59
  %conv73.52.59 = trunc i32 %xor72.52.59 to i8
  store i8 %conv73.52.59, i8* %arrayidx70.59, align 1
  %scevgep20.53.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 53
  %20175 = load i8, i8* %scevgep20.53.59, align 1
  %conv68.53.59 = zext i8 %20175 to i32
  %20176 = load i8, i8* %arrayidx70.59, align 1
  %conv71.53.59 = zext i8 %20176 to i32
  %xor72.53.59 = xor i32 %conv71.53.59, %conv68.53.59
  %conv73.53.59 = trunc i32 %xor72.53.59 to i8
  store i8 %conv73.53.59, i8* %arrayidx70.59, align 1
  %scevgep20.54.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 54
  %20177 = load i8, i8* %scevgep20.54.59, align 1
  %conv68.54.59 = zext i8 %20177 to i32
  %20178 = load i8, i8* %arrayidx70.59, align 1
  %conv71.54.59 = zext i8 %20178 to i32
  %xor72.54.59 = xor i32 %conv71.54.59, %conv68.54.59
  %conv73.54.59 = trunc i32 %xor72.54.59 to i8
  store i8 %conv73.54.59, i8* %arrayidx70.59, align 1
  %scevgep20.55.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 55
  %20179 = load i8, i8* %scevgep20.55.59, align 1
  %conv68.55.59 = zext i8 %20179 to i32
  %20180 = load i8, i8* %arrayidx70.59, align 1
  %conv71.55.59 = zext i8 %20180 to i32
  %xor72.55.59 = xor i32 %conv71.55.59, %conv68.55.59
  %conv73.55.59 = trunc i32 %xor72.55.59 to i8
  store i8 %conv73.55.59, i8* %arrayidx70.59, align 1
  %scevgep20.56.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 56
  %20181 = load i8, i8* %scevgep20.56.59, align 1
  %conv68.56.59 = zext i8 %20181 to i32
  %20182 = load i8, i8* %arrayidx70.59, align 1
  %conv71.56.59 = zext i8 %20182 to i32
  %xor72.56.59 = xor i32 %conv71.56.59, %conv68.56.59
  %conv73.56.59 = trunc i32 %xor72.56.59 to i8
  store i8 %conv73.56.59, i8* %arrayidx70.59, align 1
  %scevgep20.57.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 57
  %20183 = load i8, i8* %scevgep20.57.59, align 1
  %conv68.57.59 = zext i8 %20183 to i32
  %20184 = load i8, i8* %arrayidx70.59, align 1
  %conv71.57.59 = zext i8 %20184 to i32
  %xor72.57.59 = xor i32 %conv71.57.59, %conv68.57.59
  %conv73.57.59 = trunc i32 %xor72.57.59 to i8
  store i8 %conv73.57.59, i8* %arrayidx70.59, align 1
  %scevgep20.58.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 58
  %20185 = load i8, i8* %scevgep20.58.59, align 1
  %conv68.58.59 = zext i8 %20185 to i32
  %20186 = load i8, i8* %arrayidx70.59, align 1
  %conv71.58.59 = zext i8 %20186 to i32
  %xor72.58.59 = xor i32 %conv71.58.59, %conv68.58.59
  %conv73.58.59 = trunc i32 %xor72.58.59 to i8
  store i8 %conv73.58.59, i8* %arrayidx70.59, align 1
  %scevgep20.60.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 0, i64 60
  %20187 = load i8, i8* %scevgep20.60.59, align 1
  %conv68.60.59 = zext i8 %20187 to i32
  %20188 = load i8, i8* %arrayidx70.59, align 1
  %conv71.60.59 = zext i8 %20188 to i32
  %xor72.60.59 = xor i32 %conv71.60.59, %conv68.60.59
  %conv73.60.59 = trunc i32 %xor72.60.59 to i8
  store i8 %conv73.60.59, i8* %arrayidx70.59, align 1
  %scevgep19.59 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20066, i64 0, i64 1, i64 0
  %20189 = bitcast i8* %scevgep19.59 to [61 x [61 x i8]]*
  %arrayidx51.60 = getelementptr inbounds i8, i8* %a, i64 60
  %20190 = load i8, i8* %arrayidx51.60, align 1
  %arrayidx53.60 = getelementptr inbounds i8, i8* %b, i64 60
  %20191 = load i8, i8* %arrayidx53.60, align 1
  %call54.60 = call zeroext i8 @mult(i8 zeroext %20190, i8 zeroext %20191)
  %arrayidx56.60 = getelementptr inbounds i8, i8* %c, i64 60
  store i8 %call54.60, i8* %arrayidx56.60, align 1
  %arrayidx70.60 = getelementptr inbounds i8, i8* %c, i64 60
  %scevgep20.60644 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 0
  %20192 = load i8, i8* %scevgep20.60644, align 1
  %conv68.60645 = zext i8 %20192 to i32
  %20193 = load i8, i8* %arrayidx70.60, align 1
  %conv71.60646 = zext i8 %20193 to i32
  %xor72.60647 = xor i32 %conv71.60646, %conv68.60645
  %conv73.60648 = trunc i32 %xor72.60647 to i8
  store i8 %conv73.60648, i8* %arrayidx70.60, align 1
  %scevgep20.1.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 1
  %20194 = load i8, i8* %scevgep20.1.60, align 1
  %conv68.1.60 = zext i8 %20194 to i32
  %20195 = load i8, i8* %arrayidx70.60, align 1
  %conv71.1.60 = zext i8 %20195 to i32
  %xor72.1.60 = xor i32 %conv71.1.60, %conv68.1.60
  %conv73.1.60 = trunc i32 %xor72.1.60 to i8
  store i8 %conv73.1.60, i8* %arrayidx70.60, align 1
  %scevgep20.2.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 2
  %20196 = load i8, i8* %scevgep20.2.60, align 1
  %conv68.2.60 = zext i8 %20196 to i32
  %20197 = load i8, i8* %arrayidx70.60, align 1
  %conv71.2.60 = zext i8 %20197 to i32
  %xor72.2.60 = xor i32 %conv71.2.60, %conv68.2.60
  %conv73.2.60 = trunc i32 %xor72.2.60 to i8
  store i8 %conv73.2.60, i8* %arrayidx70.60, align 1
  %scevgep20.3.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 3
  %20198 = load i8, i8* %scevgep20.3.60, align 1
  %conv68.3.60 = zext i8 %20198 to i32
  %20199 = load i8, i8* %arrayidx70.60, align 1
  %conv71.3.60 = zext i8 %20199 to i32
  %xor72.3.60 = xor i32 %conv71.3.60, %conv68.3.60
  %conv73.3.60 = trunc i32 %xor72.3.60 to i8
  store i8 %conv73.3.60, i8* %arrayidx70.60, align 1
  %scevgep20.4.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 4
  %20200 = load i8, i8* %scevgep20.4.60, align 1
  %conv68.4.60 = zext i8 %20200 to i32
  %20201 = load i8, i8* %arrayidx70.60, align 1
  %conv71.4.60 = zext i8 %20201 to i32
  %xor72.4.60 = xor i32 %conv71.4.60, %conv68.4.60
  %conv73.4.60 = trunc i32 %xor72.4.60 to i8
  store i8 %conv73.4.60, i8* %arrayidx70.60, align 1
  %scevgep20.5.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 5
  %20202 = load i8, i8* %scevgep20.5.60, align 1
  %conv68.5.60 = zext i8 %20202 to i32
  %20203 = load i8, i8* %arrayidx70.60, align 1
  %conv71.5.60 = zext i8 %20203 to i32
  %xor72.5.60 = xor i32 %conv71.5.60, %conv68.5.60
  %conv73.5.60 = trunc i32 %xor72.5.60 to i8
  store i8 %conv73.5.60, i8* %arrayidx70.60, align 1
  %scevgep20.6.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 6
  %20204 = load i8, i8* %scevgep20.6.60, align 1
  %conv68.6.60 = zext i8 %20204 to i32
  %20205 = load i8, i8* %arrayidx70.60, align 1
  %conv71.6.60 = zext i8 %20205 to i32
  %xor72.6.60 = xor i32 %conv71.6.60, %conv68.6.60
  %conv73.6.60 = trunc i32 %xor72.6.60 to i8
  store i8 %conv73.6.60, i8* %arrayidx70.60, align 1
  %scevgep20.7.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 7
  %20206 = load i8, i8* %scevgep20.7.60, align 1
  %conv68.7.60 = zext i8 %20206 to i32
  %20207 = load i8, i8* %arrayidx70.60, align 1
  %conv71.7.60 = zext i8 %20207 to i32
  %xor72.7.60 = xor i32 %conv71.7.60, %conv68.7.60
  %conv73.7.60 = trunc i32 %xor72.7.60 to i8
  store i8 %conv73.7.60, i8* %arrayidx70.60, align 1
  %scevgep20.8.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 8
  %20208 = load i8, i8* %scevgep20.8.60, align 1
  %conv68.8.60 = zext i8 %20208 to i32
  %20209 = load i8, i8* %arrayidx70.60, align 1
  %conv71.8.60 = zext i8 %20209 to i32
  %xor72.8.60 = xor i32 %conv71.8.60, %conv68.8.60
  %conv73.8.60 = trunc i32 %xor72.8.60 to i8
  store i8 %conv73.8.60, i8* %arrayidx70.60, align 1
  %scevgep20.9.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 9
  %20210 = load i8, i8* %scevgep20.9.60, align 1
  %conv68.9.60 = zext i8 %20210 to i32
  %20211 = load i8, i8* %arrayidx70.60, align 1
  %conv71.9.60 = zext i8 %20211 to i32
  %xor72.9.60 = xor i32 %conv71.9.60, %conv68.9.60
  %conv73.9.60 = trunc i32 %xor72.9.60 to i8
  store i8 %conv73.9.60, i8* %arrayidx70.60, align 1
  %scevgep20.10.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 10
  %20212 = load i8, i8* %scevgep20.10.60, align 1
  %conv68.10.60 = zext i8 %20212 to i32
  %20213 = load i8, i8* %arrayidx70.60, align 1
  %conv71.10.60 = zext i8 %20213 to i32
  %xor72.10.60 = xor i32 %conv71.10.60, %conv68.10.60
  %conv73.10.60 = trunc i32 %xor72.10.60 to i8
  store i8 %conv73.10.60, i8* %arrayidx70.60, align 1
  %scevgep20.11.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 11
  %20214 = load i8, i8* %scevgep20.11.60, align 1
  %conv68.11.60 = zext i8 %20214 to i32
  %20215 = load i8, i8* %arrayidx70.60, align 1
  %conv71.11.60 = zext i8 %20215 to i32
  %xor72.11.60 = xor i32 %conv71.11.60, %conv68.11.60
  %conv73.11.60 = trunc i32 %xor72.11.60 to i8
  store i8 %conv73.11.60, i8* %arrayidx70.60, align 1
  %scevgep20.12.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 12
  %20216 = load i8, i8* %scevgep20.12.60, align 1
  %conv68.12.60 = zext i8 %20216 to i32
  %20217 = load i8, i8* %arrayidx70.60, align 1
  %conv71.12.60 = zext i8 %20217 to i32
  %xor72.12.60 = xor i32 %conv71.12.60, %conv68.12.60
  %conv73.12.60 = trunc i32 %xor72.12.60 to i8
  store i8 %conv73.12.60, i8* %arrayidx70.60, align 1
  %scevgep20.13.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 13
  %20218 = load i8, i8* %scevgep20.13.60, align 1
  %conv68.13.60 = zext i8 %20218 to i32
  %20219 = load i8, i8* %arrayidx70.60, align 1
  %conv71.13.60 = zext i8 %20219 to i32
  %xor72.13.60 = xor i32 %conv71.13.60, %conv68.13.60
  %conv73.13.60 = trunc i32 %xor72.13.60 to i8
  store i8 %conv73.13.60, i8* %arrayidx70.60, align 1
  %scevgep20.14.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 14
  %20220 = load i8, i8* %scevgep20.14.60, align 1
  %conv68.14.60 = zext i8 %20220 to i32
  %20221 = load i8, i8* %arrayidx70.60, align 1
  %conv71.14.60 = zext i8 %20221 to i32
  %xor72.14.60 = xor i32 %conv71.14.60, %conv68.14.60
  %conv73.14.60 = trunc i32 %xor72.14.60 to i8
  store i8 %conv73.14.60, i8* %arrayidx70.60, align 1
  %scevgep20.15.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 15
  %20222 = load i8, i8* %scevgep20.15.60, align 1
  %conv68.15.60 = zext i8 %20222 to i32
  %20223 = load i8, i8* %arrayidx70.60, align 1
  %conv71.15.60 = zext i8 %20223 to i32
  %xor72.15.60 = xor i32 %conv71.15.60, %conv68.15.60
  %conv73.15.60 = trunc i32 %xor72.15.60 to i8
  store i8 %conv73.15.60, i8* %arrayidx70.60, align 1
  %scevgep20.16.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 16
  %20224 = load i8, i8* %scevgep20.16.60, align 1
  %conv68.16.60 = zext i8 %20224 to i32
  %20225 = load i8, i8* %arrayidx70.60, align 1
  %conv71.16.60 = zext i8 %20225 to i32
  %xor72.16.60 = xor i32 %conv71.16.60, %conv68.16.60
  %conv73.16.60 = trunc i32 %xor72.16.60 to i8
  store i8 %conv73.16.60, i8* %arrayidx70.60, align 1
  %scevgep20.17.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 17
  %20226 = load i8, i8* %scevgep20.17.60, align 1
  %conv68.17.60 = zext i8 %20226 to i32
  %20227 = load i8, i8* %arrayidx70.60, align 1
  %conv71.17.60 = zext i8 %20227 to i32
  %xor72.17.60 = xor i32 %conv71.17.60, %conv68.17.60
  %conv73.17.60 = trunc i32 %xor72.17.60 to i8
  store i8 %conv73.17.60, i8* %arrayidx70.60, align 1
  %scevgep20.18.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 18
  %20228 = load i8, i8* %scevgep20.18.60, align 1
  %conv68.18.60 = zext i8 %20228 to i32
  %20229 = load i8, i8* %arrayidx70.60, align 1
  %conv71.18.60 = zext i8 %20229 to i32
  %xor72.18.60 = xor i32 %conv71.18.60, %conv68.18.60
  %conv73.18.60 = trunc i32 %xor72.18.60 to i8
  store i8 %conv73.18.60, i8* %arrayidx70.60, align 1
  %scevgep20.19.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 19
  %20230 = load i8, i8* %scevgep20.19.60, align 1
  %conv68.19.60 = zext i8 %20230 to i32
  %20231 = load i8, i8* %arrayidx70.60, align 1
  %conv71.19.60 = zext i8 %20231 to i32
  %xor72.19.60 = xor i32 %conv71.19.60, %conv68.19.60
  %conv73.19.60 = trunc i32 %xor72.19.60 to i8
  store i8 %conv73.19.60, i8* %arrayidx70.60, align 1
  %scevgep20.20.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 20
  %20232 = load i8, i8* %scevgep20.20.60, align 1
  %conv68.20.60 = zext i8 %20232 to i32
  %20233 = load i8, i8* %arrayidx70.60, align 1
  %conv71.20.60 = zext i8 %20233 to i32
  %xor72.20.60 = xor i32 %conv71.20.60, %conv68.20.60
  %conv73.20.60 = trunc i32 %xor72.20.60 to i8
  store i8 %conv73.20.60, i8* %arrayidx70.60, align 1
  %scevgep20.21.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 21
  %20234 = load i8, i8* %scevgep20.21.60, align 1
  %conv68.21.60 = zext i8 %20234 to i32
  %20235 = load i8, i8* %arrayidx70.60, align 1
  %conv71.21.60 = zext i8 %20235 to i32
  %xor72.21.60 = xor i32 %conv71.21.60, %conv68.21.60
  %conv73.21.60 = trunc i32 %xor72.21.60 to i8
  store i8 %conv73.21.60, i8* %arrayidx70.60, align 1
  %scevgep20.22.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 22
  %20236 = load i8, i8* %scevgep20.22.60, align 1
  %conv68.22.60 = zext i8 %20236 to i32
  %20237 = load i8, i8* %arrayidx70.60, align 1
  %conv71.22.60 = zext i8 %20237 to i32
  %xor72.22.60 = xor i32 %conv71.22.60, %conv68.22.60
  %conv73.22.60 = trunc i32 %xor72.22.60 to i8
  store i8 %conv73.22.60, i8* %arrayidx70.60, align 1
  %scevgep20.23.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 23
  %20238 = load i8, i8* %scevgep20.23.60, align 1
  %conv68.23.60 = zext i8 %20238 to i32
  %20239 = load i8, i8* %arrayidx70.60, align 1
  %conv71.23.60 = zext i8 %20239 to i32
  %xor72.23.60 = xor i32 %conv71.23.60, %conv68.23.60
  %conv73.23.60 = trunc i32 %xor72.23.60 to i8
  store i8 %conv73.23.60, i8* %arrayidx70.60, align 1
  %scevgep20.24.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 24
  %20240 = load i8, i8* %scevgep20.24.60, align 1
  %conv68.24.60 = zext i8 %20240 to i32
  %20241 = load i8, i8* %arrayidx70.60, align 1
  %conv71.24.60 = zext i8 %20241 to i32
  %xor72.24.60 = xor i32 %conv71.24.60, %conv68.24.60
  %conv73.24.60 = trunc i32 %xor72.24.60 to i8
  store i8 %conv73.24.60, i8* %arrayidx70.60, align 1
  %scevgep20.25.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 25
  %20242 = load i8, i8* %scevgep20.25.60, align 1
  %conv68.25.60 = zext i8 %20242 to i32
  %20243 = load i8, i8* %arrayidx70.60, align 1
  %conv71.25.60 = zext i8 %20243 to i32
  %xor72.25.60 = xor i32 %conv71.25.60, %conv68.25.60
  %conv73.25.60 = trunc i32 %xor72.25.60 to i8
  store i8 %conv73.25.60, i8* %arrayidx70.60, align 1
  %scevgep20.26.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 26
  %20244 = load i8, i8* %scevgep20.26.60, align 1
  %conv68.26.60 = zext i8 %20244 to i32
  %20245 = load i8, i8* %arrayidx70.60, align 1
  %conv71.26.60 = zext i8 %20245 to i32
  %xor72.26.60 = xor i32 %conv71.26.60, %conv68.26.60
  %conv73.26.60 = trunc i32 %xor72.26.60 to i8
  store i8 %conv73.26.60, i8* %arrayidx70.60, align 1
  %scevgep20.27.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 27
  %20246 = load i8, i8* %scevgep20.27.60, align 1
  %conv68.27.60 = zext i8 %20246 to i32
  %20247 = load i8, i8* %arrayidx70.60, align 1
  %conv71.27.60 = zext i8 %20247 to i32
  %xor72.27.60 = xor i32 %conv71.27.60, %conv68.27.60
  %conv73.27.60 = trunc i32 %xor72.27.60 to i8
  store i8 %conv73.27.60, i8* %arrayidx70.60, align 1
  %scevgep20.28.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 28
  %20248 = load i8, i8* %scevgep20.28.60, align 1
  %conv68.28.60 = zext i8 %20248 to i32
  %20249 = load i8, i8* %arrayidx70.60, align 1
  %conv71.28.60 = zext i8 %20249 to i32
  %xor72.28.60 = xor i32 %conv71.28.60, %conv68.28.60
  %conv73.28.60 = trunc i32 %xor72.28.60 to i8
  store i8 %conv73.28.60, i8* %arrayidx70.60, align 1
  %scevgep20.29.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 29
  %20250 = load i8, i8* %scevgep20.29.60, align 1
  %conv68.29.60 = zext i8 %20250 to i32
  %20251 = load i8, i8* %arrayidx70.60, align 1
  %conv71.29.60 = zext i8 %20251 to i32
  %xor72.29.60 = xor i32 %conv71.29.60, %conv68.29.60
  %conv73.29.60 = trunc i32 %xor72.29.60 to i8
  store i8 %conv73.29.60, i8* %arrayidx70.60, align 1
  %scevgep20.30.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 30
  %20252 = load i8, i8* %scevgep20.30.60, align 1
  %conv68.30.60 = zext i8 %20252 to i32
  %20253 = load i8, i8* %arrayidx70.60, align 1
  %conv71.30.60 = zext i8 %20253 to i32
  %xor72.30.60 = xor i32 %conv71.30.60, %conv68.30.60
  %conv73.30.60 = trunc i32 %xor72.30.60 to i8
  store i8 %conv73.30.60, i8* %arrayidx70.60, align 1
  %scevgep20.31.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 31
  %20254 = load i8, i8* %scevgep20.31.60, align 1
  %conv68.31.60 = zext i8 %20254 to i32
  %20255 = load i8, i8* %arrayidx70.60, align 1
  %conv71.31.60 = zext i8 %20255 to i32
  %xor72.31.60 = xor i32 %conv71.31.60, %conv68.31.60
  %conv73.31.60 = trunc i32 %xor72.31.60 to i8
  store i8 %conv73.31.60, i8* %arrayidx70.60, align 1
  %scevgep20.32.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 32
  %20256 = load i8, i8* %scevgep20.32.60, align 1
  %conv68.32.60 = zext i8 %20256 to i32
  %20257 = load i8, i8* %arrayidx70.60, align 1
  %conv71.32.60 = zext i8 %20257 to i32
  %xor72.32.60 = xor i32 %conv71.32.60, %conv68.32.60
  %conv73.32.60 = trunc i32 %xor72.32.60 to i8
  store i8 %conv73.32.60, i8* %arrayidx70.60, align 1
  %scevgep20.33.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 33
  %20258 = load i8, i8* %scevgep20.33.60, align 1
  %conv68.33.60 = zext i8 %20258 to i32
  %20259 = load i8, i8* %arrayidx70.60, align 1
  %conv71.33.60 = zext i8 %20259 to i32
  %xor72.33.60 = xor i32 %conv71.33.60, %conv68.33.60
  %conv73.33.60 = trunc i32 %xor72.33.60 to i8
  store i8 %conv73.33.60, i8* %arrayidx70.60, align 1
  %scevgep20.34.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 34
  %20260 = load i8, i8* %scevgep20.34.60, align 1
  %conv68.34.60 = zext i8 %20260 to i32
  %20261 = load i8, i8* %arrayidx70.60, align 1
  %conv71.34.60 = zext i8 %20261 to i32
  %xor72.34.60 = xor i32 %conv71.34.60, %conv68.34.60
  %conv73.34.60 = trunc i32 %xor72.34.60 to i8
  store i8 %conv73.34.60, i8* %arrayidx70.60, align 1
  %scevgep20.35.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 35
  %20262 = load i8, i8* %scevgep20.35.60, align 1
  %conv68.35.60 = zext i8 %20262 to i32
  %20263 = load i8, i8* %arrayidx70.60, align 1
  %conv71.35.60 = zext i8 %20263 to i32
  %xor72.35.60 = xor i32 %conv71.35.60, %conv68.35.60
  %conv73.35.60 = trunc i32 %xor72.35.60 to i8
  store i8 %conv73.35.60, i8* %arrayidx70.60, align 1
  %scevgep20.36.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 36
  %20264 = load i8, i8* %scevgep20.36.60, align 1
  %conv68.36.60 = zext i8 %20264 to i32
  %20265 = load i8, i8* %arrayidx70.60, align 1
  %conv71.36.60 = zext i8 %20265 to i32
  %xor72.36.60 = xor i32 %conv71.36.60, %conv68.36.60
  %conv73.36.60 = trunc i32 %xor72.36.60 to i8
  store i8 %conv73.36.60, i8* %arrayidx70.60, align 1
  %scevgep20.37.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 37
  %20266 = load i8, i8* %scevgep20.37.60, align 1
  %conv68.37.60 = zext i8 %20266 to i32
  %20267 = load i8, i8* %arrayidx70.60, align 1
  %conv71.37.60 = zext i8 %20267 to i32
  %xor72.37.60 = xor i32 %conv71.37.60, %conv68.37.60
  %conv73.37.60 = trunc i32 %xor72.37.60 to i8
  store i8 %conv73.37.60, i8* %arrayidx70.60, align 1
  %scevgep20.38.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 38
  %20268 = load i8, i8* %scevgep20.38.60, align 1
  %conv68.38.60 = zext i8 %20268 to i32
  %20269 = load i8, i8* %arrayidx70.60, align 1
  %conv71.38.60 = zext i8 %20269 to i32
  %xor72.38.60 = xor i32 %conv71.38.60, %conv68.38.60
  %conv73.38.60 = trunc i32 %xor72.38.60 to i8
  store i8 %conv73.38.60, i8* %arrayidx70.60, align 1
  %scevgep20.39.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 39
  %20270 = load i8, i8* %scevgep20.39.60, align 1
  %conv68.39.60 = zext i8 %20270 to i32
  %20271 = load i8, i8* %arrayidx70.60, align 1
  %conv71.39.60 = zext i8 %20271 to i32
  %xor72.39.60 = xor i32 %conv71.39.60, %conv68.39.60
  %conv73.39.60 = trunc i32 %xor72.39.60 to i8
  store i8 %conv73.39.60, i8* %arrayidx70.60, align 1
  %scevgep20.40.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 40
  %20272 = load i8, i8* %scevgep20.40.60, align 1
  %conv68.40.60 = zext i8 %20272 to i32
  %20273 = load i8, i8* %arrayidx70.60, align 1
  %conv71.40.60 = zext i8 %20273 to i32
  %xor72.40.60 = xor i32 %conv71.40.60, %conv68.40.60
  %conv73.40.60 = trunc i32 %xor72.40.60 to i8
  store i8 %conv73.40.60, i8* %arrayidx70.60, align 1
  %scevgep20.41.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 41
  %20274 = load i8, i8* %scevgep20.41.60, align 1
  %conv68.41.60 = zext i8 %20274 to i32
  %20275 = load i8, i8* %arrayidx70.60, align 1
  %conv71.41.60 = zext i8 %20275 to i32
  %xor72.41.60 = xor i32 %conv71.41.60, %conv68.41.60
  %conv73.41.60 = trunc i32 %xor72.41.60 to i8
  store i8 %conv73.41.60, i8* %arrayidx70.60, align 1
  %scevgep20.42.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 42
  %20276 = load i8, i8* %scevgep20.42.60, align 1
  %conv68.42.60 = zext i8 %20276 to i32
  %20277 = load i8, i8* %arrayidx70.60, align 1
  %conv71.42.60 = zext i8 %20277 to i32
  %xor72.42.60 = xor i32 %conv71.42.60, %conv68.42.60
  %conv73.42.60 = trunc i32 %xor72.42.60 to i8
  store i8 %conv73.42.60, i8* %arrayidx70.60, align 1
  %scevgep20.43.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 43
  %20278 = load i8, i8* %scevgep20.43.60, align 1
  %conv68.43.60 = zext i8 %20278 to i32
  %20279 = load i8, i8* %arrayidx70.60, align 1
  %conv71.43.60 = zext i8 %20279 to i32
  %xor72.43.60 = xor i32 %conv71.43.60, %conv68.43.60
  %conv73.43.60 = trunc i32 %xor72.43.60 to i8
  store i8 %conv73.43.60, i8* %arrayidx70.60, align 1
  %scevgep20.44.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 44
  %20280 = load i8, i8* %scevgep20.44.60, align 1
  %conv68.44.60 = zext i8 %20280 to i32
  %20281 = load i8, i8* %arrayidx70.60, align 1
  %conv71.44.60 = zext i8 %20281 to i32
  %xor72.44.60 = xor i32 %conv71.44.60, %conv68.44.60
  %conv73.44.60 = trunc i32 %xor72.44.60 to i8
  store i8 %conv73.44.60, i8* %arrayidx70.60, align 1
  %scevgep20.45.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 45
  %20282 = load i8, i8* %scevgep20.45.60, align 1
  %conv68.45.60 = zext i8 %20282 to i32
  %20283 = load i8, i8* %arrayidx70.60, align 1
  %conv71.45.60 = zext i8 %20283 to i32
  %xor72.45.60 = xor i32 %conv71.45.60, %conv68.45.60
  %conv73.45.60 = trunc i32 %xor72.45.60 to i8
  store i8 %conv73.45.60, i8* %arrayidx70.60, align 1
  %scevgep20.46.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 46
  %20284 = load i8, i8* %scevgep20.46.60, align 1
  %conv68.46.60 = zext i8 %20284 to i32
  %20285 = load i8, i8* %arrayidx70.60, align 1
  %conv71.46.60 = zext i8 %20285 to i32
  %xor72.46.60 = xor i32 %conv71.46.60, %conv68.46.60
  %conv73.46.60 = trunc i32 %xor72.46.60 to i8
  store i8 %conv73.46.60, i8* %arrayidx70.60, align 1
  %scevgep20.47.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 47
  %20286 = load i8, i8* %scevgep20.47.60, align 1
  %conv68.47.60 = zext i8 %20286 to i32
  %20287 = load i8, i8* %arrayidx70.60, align 1
  %conv71.47.60 = zext i8 %20287 to i32
  %xor72.47.60 = xor i32 %conv71.47.60, %conv68.47.60
  %conv73.47.60 = trunc i32 %xor72.47.60 to i8
  store i8 %conv73.47.60, i8* %arrayidx70.60, align 1
  %scevgep20.48.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 48
  %20288 = load i8, i8* %scevgep20.48.60, align 1
  %conv68.48.60 = zext i8 %20288 to i32
  %20289 = load i8, i8* %arrayidx70.60, align 1
  %conv71.48.60 = zext i8 %20289 to i32
  %xor72.48.60 = xor i32 %conv71.48.60, %conv68.48.60
  %conv73.48.60 = trunc i32 %xor72.48.60 to i8
  store i8 %conv73.48.60, i8* %arrayidx70.60, align 1
  %scevgep20.49.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 49
  %20290 = load i8, i8* %scevgep20.49.60, align 1
  %conv68.49.60 = zext i8 %20290 to i32
  %20291 = load i8, i8* %arrayidx70.60, align 1
  %conv71.49.60 = zext i8 %20291 to i32
  %xor72.49.60 = xor i32 %conv71.49.60, %conv68.49.60
  %conv73.49.60 = trunc i32 %xor72.49.60 to i8
  store i8 %conv73.49.60, i8* %arrayidx70.60, align 1
  %scevgep20.50.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 50
  %20292 = load i8, i8* %scevgep20.50.60, align 1
  %conv68.50.60 = zext i8 %20292 to i32
  %20293 = load i8, i8* %arrayidx70.60, align 1
  %conv71.50.60 = zext i8 %20293 to i32
  %xor72.50.60 = xor i32 %conv71.50.60, %conv68.50.60
  %conv73.50.60 = trunc i32 %xor72.50.60 to i8
  store i8 %conv73.50.60, i8* %arrayidx70.60, align 1
  %scevgep20.51.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 51
  %20294 = load i8, i8* %scevgep20.51.60, align 1
  %conv68.51.60 = zext i8 %20294 to i32
  %20295 = load i8, i8* %arrayidx70.60, align 1
  %conv71.51.60 = zext i8 %20295 to i32
  %xor72.51.60 = xor i32 %conv71.51.60, %conv68.51.60
  %conv73.51.60 = trunc i32 %xor72.51.60 to i8
  store i8 %conv73.51.60, i8* %arrayidx70.60, align 1
  %scevgep20.52.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 52
  %20296 = load i8, i8* %scevgep20.52.60, align 1
  %conv68.52.60 = zext i8 %20296 to i32
  %20297 = load i8, i8* %arrayidx70.60, align 1
  %conv71.52.60 = zext i8 %20297 to i32
  %xor72.52.60 = xor i32 %conv71.52.60, %conv68.52.60
  %conv73.52.60 = trunc i32 %xor72.52.60 to i8
  store i8 %conv73.52.60, i8* %arrayidx70.60, align 1
  %scevgep20.53.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 53
  %20298 = load i8, i8* %scevgep20.53.60, align 1
  %conv68.53.60 = zext i8 %20298 to i32
  %20299 = load i8, i8* %arrayidx70.60, align 1
  %conv71.53.60 = zext i8 %20299 to i32
  %xor72.53.60 = xor i32 %conv71.53.60, %conv68.53.60
  %conv73.53.60 = trunc i32 %xor72.53.60 to i8
  store i8 %conv73.53.60, i8* %arrayidx70.60, align 1
  %scevgep20.54.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 54
  %20300 = load i8, i8* %scevgep20.54.60, align 1
  %conv68.54.60 = zext i8 %20300 to i32
  %20301 = load i8, i8* %arrayidx70.60, align 1
  %conv71.54.60 = zext i8 %20301 to i32
  %xor72.54.60 = xor i32 %conv71.54.60, %conv68.54.60
  %conv73.54.60 = trunc i32 %xor72.54.60 to i8
  store i8 %conv73.54.60, i8* %arrayidx70.60, align 1
  %scevgep20.55.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 55
  %20302 = load i8, i8* %scevgep20.55.60, align 1
  %conv68.55.60 = zext i8 %20302 to i32
  %20303 = load i8, i8* %arrayidx70.60, align 1
  %conv71.55.60 = zext i8 %20303 to i32
  %xor72.55.60 = xor i32 %conv71.55.60, %conv68.55.60
  %conv73.55.60 = trunc i32 %xor72.55.60 to i8
  store i8 %conv73.55.60, i8* %arrayidx70.60, align 1
  %scevgep20.56.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 56
  %20304 = load i8, i8* %scevgep20.56.60, align 1
  %conv68.56.60 = zext i8 %20304 to i32
  %20305 = load i8, i8* %arrayidx70.60, align 1
  %conv71.56.60 = zext i8 %20305 to i32
  %xor72.56.60 = xor i32 %conv71.56.60, %conv68.56.60
  %conv73.56.60 = trunc i32 %xor72.56.60 to i8
  store i8 %conv73.56.60, i8* %arrayidx70.60, align 1
  %scevgep20.57.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 57
  %20306 = load i8, i8* %scevgep20.57.60, align 1
  %conv68.57.60 = zext i8 %20306 to i32
  %20307 = load i8, i8* %arrayidx70.60, align 1
  %conv71.57.60 = zext i8 %20307 to i32
  %xor72.57.60 = xor i32 %conv71.57.60, %conv68.57.60
  %conv73.57.60 = trunc i32 %xor72.57.60 to i8
  store i8 %conv73.57.60, i8* %arrayidx70.60, align 1
  %scevgep20.58.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 58
  %20308 = load i8, i8* %scevgep20.58.60, align 1
  %conv68.58.60 = zext i8 %20308 to i32
  %20309 = load i8, i8* %arrayidx70.60, align 1
  %conv71.58.60 = zext i8 %20309 to i32
  %xor72.58.60 = xor i32 %conv71.58.60, %conv68.58.60
  %conv73.58.60 = trunc i32 %xor72.58.60 to i8
  store i8 %conv73.58.60, i8* %arrayidx70.60, align 1
  %scevgep20.59.60 = getelementptr [61 x [61 x i8]], [61 x [61 x i8]]* %20189, i64 0, i64 0, i64 59
  %20310 = load i8, i8* %scevgep20.59.60, align 1
  %conv68.59.60 = zext i8 %20310 to i32
  %20311 = load i8, i8* %arrayidx70.60, align 1
  %conv71.59.60 = zext i8 %20311 to i32
  %xor72.59.60 = xor i32 %conv71.59.60, %conv68.59.60
  %conv73.59.60 = trunc i32 %xor72.59.60 to i8
  store i8 %conv73.59.60, i8* %arrayidx70.60, align 1
  %call80 = call zeroext i8 @mult(i8 zeroext %call, i8 zeroext %call1)
  %conv81 = zext i8 %call80 to i32
  %20312 = load i8, i8* %c, align 1
  %scevgep.1 = getelementptr i8, i8* %c, i64 1
  %20313 = load i8, i8* %scevgep.1, align 1
  %conv.i.i113.1 = zext i8 %20313 to i32
  %conv1.i.i114.1 = zext i8 %20312 to i32
  %xor.i.i115.1 = xor i32 %conv1.i.i114.1, %conv.i.i113.1
  %conv2.i.i116.1 = trunc i32 %xor.i.i115.1 to i8
  %scevgep.2 = getelementptr i8, i8* %c, i64 2
  %20314 = load i8, i8* %scevgep.2, align 1
  %conv.i.i113.2 = zext i8 %20314 to i32
  %conv1.i.i114.2 = zext i8 %conv2.i.i116.1 to i32
  %xor.i.i115.2 = xor i32 %conv1.i.i114.2, %conv.i.i113.2
  %conv2.i.i116.2 = trunc i32 %xor.i.i115.2 to i8
  %scevgep.3 = getelementptr i8, i8* %c, i64 3
  %20315 = load i8, i8* %scevgep.3, align 1
  %conv.i.i113.3 = zext i8 %20315 to i32
  %conv1.i.i114.3 = zext i8 %conv2.i.i116.2 to i32
  %xor.i.i115.3 = xor i32 %conv1.i.i114.3, %conv.i.i113.3
  %conv2.i.i116.3 = trunc i32 %xor.i.i115.3 to i8
  %scevgep.4 = getelementptr i8, i8* %c, i64 4
  %20316 = load i8, i8* %scevgep.4, align 1
  %conv.i.i113.4 = zext i8 %20316 to i32
  %conv1.i.i114.4 = zext i8 %conv2.i.i116.3 to i32
  %xor.i.i115.4 = xor i32 %conv1.i.i114.4, %conv.i.i113.4
  %conv2.i.i116.4 = trunc i32 %xor.i.i115.4 to i8
  %scevgep.5 = getelementptr i8, i8* %c, i64 5
  %20317 = load i8, i8* %scevgep.5, align 1
  %conv.i.i113.5 = zext i8 %20317 to i32
  %conv1.i.i114.5 = zext i8 %conv2.i.i116.4 to i32
  %xor.i.i115.5 = xor i32 %conv1.i.i114.5, %conv.i.i113.5
  %conv2.i.i116.5 = trunc i32 %xor.i.i115.5 to i8
  %scevgep.6 = getelementptr i8, i8* %c, i64 6
  %20318 = load i8, i8* %scevgep.6, align 1
  %conv.i.i113.6 = zext i8 %20318 to i32
  %conv1.i.i114.6 = zext i8 %conv2.i.i116.5 to i32
  %xor.i.i115.6 = xor i32 %conv1.i.i114.6, %conv.i.i113.6
  %conv2.i.i116.6 = trunc i32 %xor.i.i115.6 to i8
  %scevgep.7 = getelementptr i8, i8* %c, i64 7
  %20319 = load i8, i8* %scevgep.7, align 1
  %conv.i.i113.7 = zext i8 %20319 to i32
  %conv1.i.i114.7 = zext i8 %conv2.i.i116.6 to i32
  %xor.i.i115.7 = xor i32 %conv1.i.i114.7, %conv.i.i113.7
  %conv2.i.i116.7 = trunc i32 %xor.i.i115.7 to i8
  %scevgep.8 = getelementptr i8, i8* %c, i64 8
  %20320 = load i8, i8* %scevgep.8, align 1
  %conv.i.i113.8 = zext i8 %20320 to i32
  %conv1.i.i114.8 = zext i8 %conv2.i.i116.7 to i32
  %xor.i.i115.8 = xor i32 %conv1.i.i114.8, %conv.i.i113.8
  %conv2.i.i116.8 = trunc i32 %xor.i.i115.8 to i8
  %scevgep.9 = getelementptr i8, i8* %c, i64 9
  %20321 = load i8, i8* %scevgep.9, align 1
  %conv.i.i113.9 = zext i8 %20321 to i32
  %conv1.i.i114.9 = zext i8 %conv2.i.i116.8 to i32
  %xor.i.i115.9 = xor i32 %conv1.i.i114.9, %conv.i.i113.9
  %conv2.i.i116.9 = trunc i32 %xor.i.i115.9 to i8
  %scevgep.10 = getelementptr i8, i8* %c, i64 10
  %20322 = load i8, i8* %scevgep.10, align 1
  %conv.i.i113.10 = zext i8 %20322 to i32
  %conv1.i.i114.10 = zext i8 %conv2.i.i116.9 to i32
  %xor.i.i115.10 = xor i32 %conv1.i.i114.10, %conv.i.i113.10
  %conv2.i.i116.10 = trunc i32 %xor.i.i115.10 to i8
  %scevgep.11 = getelementptr i8, i8* %c, i64 11
  %20323 = load i8, i8* %scevgep.11, align 1
  %conv.i.i113.11 = zext i8 %20323 to i32
  %conv1.i.i114.11 = zext i8 %conv2.i.i116.10 to i32
  %xor.i.i115.11 = xor i32 %conv1.i.i114.11, %conv.i.i113.11
  %conv2.i.i116.11 = trunc i32 %xor.i.i115.11 to i8
  %scevgep.12 = getelementptr i8, i8* %c, i64 12
  %20324 = load i8, i8* %scevgep.12, align 1
  %conv.i.i113.12 = zext i8 %20324 to i32
  %conv1.i.i114.12 = zext i8 %conv2.i.i116.11 to i32
  %xor.i.i115.12 = xor i32 %conv1.i.i114.12, %conv.i.i113.12
  %conv2.i.i116.12 = trunc i32 %xor.i.i115.12 to i8
  %scevgep.13 = getelementptr i8, i8* %c, i64 13
  %20325 = load i8, i8* %scevgep.13, align 1
  %conv.i.i113.13 = zext i8 %20325 to i32
  %conv1.i.i114.13 = zext i8 %conv2.i.i116.12 to i32
  %xor.i.i115.13 = xor i32 %conv1.i.i114.13, %conv.i.i113.13
  %conv2.i.i116.13 = trunc i32 %xor.i.i115.13 to i8
  %scevgep.14 = getelementptr i8, i8* %c, i64 14
  %20326 = load i8, i8* %scevgep.14, align 1
  %conv.i.i113.14 = zext i8 %20326 to i32
  %conv1.i.i114.14 = zext i8 %conv2.i.i116.13 to i32
  %xor.i.i115.14 = xor i32 %conv1.i.i114.14, %conv.i.i113.14
  %conv2.i.i116.14 = trunc i32 %xor.i.i115.14 to i8
  %scevgep.15 = getelementptr i8, i8* %c, i64 15
  %20327 = load i8, i8* %scevgep.15, align 1
  %conv.i.i113.15 = zext i8 %20327 to i32
  %conv1.i.i114.15 = zext i8 %conv2.i.i116.14 to i32
  %xor.i.i115.15 = xor i32 %conv1.i.i114.15, %conv.i.i113.15
  %conv2.i.i116.15 = trunc i32 %xor.i.i115.15 to i8
  %scevgep.16 = getelementptr i8, i8* %c, i64 16
  %20328 = load i8, i8* %scevgep.16, align 1
  %conv.i.i113.16 = zext i8 %20328 to i32
  %conv1.i.i114.16 = zext i8 %conv2.i.i116.15 to i32
  %xor.i.i115.16 = xor i32 %conv1.i.i114.16, %conv.i.i113.16
  %conv2.i.i116.16 = trunc i32 %xor.i.i115.16 to i8
  %scevgep.17 = getelementptr i8, i8* %c, i64 17
  %20329 = load i8, i8* %scevgep.17, align 1
  %conv.i.i113.17 = zext i8 %20329 to i32
  %conv1.i.i114.17 = zext i8 %conv2.i.i116.16 to i32
  %xor.i.i115.17 = xor i32 %conv1.i.i114.17, %conv.i.i113.17
  %conv2.i.i116.17 = trunc i32 %xor.i.i115.17 to i8
  %scevgep.18 = getelementptr i8, i8* %c, i64 18
  %20330 = load i8, i8* %scevgep.18, align 1
  %conv.i.i113.18 = zext i8 %20330 to i32
  %conv1.i.i114.18 = zext i8 %conv2.i.i116.17 to i32
  %xor.i.i115.18 = xor i32 %conv1.i.i114.18, %conv.i.i113.18
  %conv2.i.i116.18 = trunc i32 %xor.i.i115.18 to i8
  %scevgep.19 = getelementptr i8, i8* %c, i64 19
  %20331 = load i8, i8* %scevgep.19, align 1
  %conv.i.i113.19 = zext i8 %20331 to i32
  %conv1.i.i114.19 = zext i8 %conv2.i.i116.18 to i32
  %xor.i.i115.19 = xor i32 %conv1.i.i114.19, %conv.i.i113.19
  %conv2.i.i116.19 = trunc i32 %xor.i.i115.19 to i8
  %scevgep.20 = getelementptr i8, i8* %c, i64 20
  %20332 = load i8, i8* %scevgep.20, align 1
  %conv.i.i113.20 = zext i8 %20332 to i32
  %conv1.i.i114.20 = zext i8 %conv2.i.i116.19 to i32
  %xor.i.i115.20 = xor i32 %conv1.i.i114.20, %conv.i.i113.20
  %conv2.i.i116.20 = trunc i32 %xor.i.i115.20 to i8
  %scevgep.21 = getelementptr i8, i8* %c, i64 21
  %20333 = load i8, i8* %scevgep.21, align 1
  %conv.i.i113.21 = zext i8 %20333 to i32
  %conv1.i.i114.21 = zext i8 %conv2.i.i116.20 to i32
  %xor.i.i115.21 = xor i32 %conv1.i.i114.21, %conv.i.i113.21
  %conv2.i.i116.21 = trunc i32 %xor.i.i115.21 to i8
  %scevgep.22 = getelementptr i8, i8* %c, i64 22
  %20334 = load i8, i8* %scevgep.22, align 1
  %conv.i.i113.22 = zext i8 %20334 to i32
  %conv1.i.i114.22 = zext i8 %conv2.i.i116.21 to i32
  %xor.i.i115.22 = xor i32 %conv1.i.i114.22, %conv.i.i113.22
  %conv2.i.i116.22 = trunc i32 %xor.i.i115.22 to i8
  %scevgep.23 = getelementptr i8, i8* %c, i64 23
  %20335 = load i8, i8* %scevgep.23, align 1
  %conv.i.i113.23 = zext i8 %20335 to i32
  %conv1.i.i114.23 = zext i8 %conv2.i.i116.22 to i32
  %xor.i.i115.23 = xor i32 %conv1.i.i114.23, %conv.i.i113.23
  %conv2.i.i116.23 = trunc i32 %xor.i.i115.23 to i8
  %scevgep.24 = getelementptr i8, i8* %c, i64 24
  %20336 = load i8, i8* %scevgep.24, align 1
  %conv.i.i113.24 = zext i8 %20336 to i32
  %conv1.i.i114.24 = zext i8 %conv2.i.i116.23 to i32
  %xor.i.i115.24 = xor i32 %conv1.i.i114.24, %conv.i.i113.24
  %conv2.i.i116.24 = trunc i32 %xor.i.i115.24 to i8
  %scevgep.25 = getelementptr i8, i8* %c, i64 25
  %20337 = load i8, i8* %scevgep.25, align 1
  %conv.i.i113.25 = zext i8 %20337 to i32
  %conv1.i.i114.25 = zext i8 %conv2.i.i116.24 to i32
  %xor.i.i115.25 = xor i32 %conv1.i.i114.25, %conv.i.i113.25
  %conv2.i.i116.25 = trunc i32 %xor.i.i115.25 to i8
  %scevgep.26 = getelementptr i8, i8* %c, i64 26
  %20338 = load i8, i8* %scevgep.26, align 1
  %conv.i.i113.26 = zext i8 %20338 to i32
  %conv1.i.i114.26 = zext i8 %conv2.i.i116.25 to i32
  %xor.i.i115.26 = xor i32 %conv1.i.i114.26, %conv.i.i113.26
  %conv2.i.i116.26 = trunc i32 %xor.i.i115.26 to i8
  %scevgep.27 = getelementptr i8, i8* %c, i64 27
  %20339 = load i8, i8* %scevgep.27, align 1
  %conv.i.i113.27 = zext i8 %20339 to i32
  %conv1.i.i114.27 = zext i8 %conv2.i.i116.26 to i32
  %xor.i.i115.27 = xor i32 %conv1.i.i114.27, %conv.i.i113.27
  %conv2.i.i116.27 = trunc i32 %xor.i.i115.27 to i8
  %scevgep.28 = getelementptr i8, i8* %c, i64 28
  %20340 = load i8, i8* %scevgep.28, align 1
  %conv.i.i113.28 = zext i8 %20340 to i32
  %conv1.i.i114.28 = zext i8 %conv2.i.i116.27 to i32
  %xor.i.i115.28 = xor i32 %conv1.i.i114.28, %conv.i.i113.28
  %conv2.i.i116.28 = trunc i32 %xor.i.i115.28 to i8
  %scevgep.29 = getelementptr i8, i8* %c, i64 29
  %20341 = load i8, i8* %scevgep.29, align 1
  %conv.i.i113.29 = zext i8 %20341 to i32
  %conv1.i.i114.29 = zext i8 %conv2.i.i116.28 to i32
  %xor.i.i115.29 = xor i32 %conv1.i.i114.29, %conv.i.i113.29
  %conv2.i.i116.29 = trunc i32 %xor.i.i115.29 to i8
  %scevgep.30 = getelementptr i8, i8* %c, i64 30
  %20342 = load i8, i8* %scevgep.30, align 1
  %conv.i.i113.30 = zext i8 %20342 to i32
  %conv1.i.i114.30 = zext i8 %conv2.i.i116.29 to i32
  %xor.i.i115.30 = xor i32 %conv1.i.i114.30, %conv.i.i113.30
  %conv2.i.i116.30 = trunc i32 %xor.i.i115.30 to i8
  %scevgep.31 = getelementptr i8, i8* %c, i64 31
  %20343 = load i8, i8* %scevgep.31, align 1
  %conv.i.i113.31 = zext i8 %20343 to i32
  %conv1.i.i114.31 = zext i8 %conv2.i.i116.30 to i32
  %xor.i.i115.31 = xor i32 %conv1.i.i114.31, %conv.i.i113.31
  %conv2.i.i116.31 = trunc i32 %xor.i.i115.31 to i8
  %scevgep.32 = getelementptr i8, i8* %c, i64 32
  %20344 = load i8, i8* %scevgep.32, align 1
  %conv.i.i113.32 = zext i8 %20344 to i32
  %conv1.i.i114.32 = zext i8 %conv2.i.i116.31 to i32
  %xor.i.i115.32 = xor i32 %conv1.i.i114.32, %conv.i.i113.32
  %conv2.i.i116.32 = trunc i32 %xor.i.i115.32 to i8
  %scevgep.33 = getelementptr i8, i8* %c, i64 33
  %20345 = load i8, i8* %scevgep.33, align 1
  %conv.i.i113.33 = zext i8 %20345 to i32
  %conv1.i.i114.33 = zext i8 %conv2.i.i116.32 to i32
  %xor.i.i115.33 = xor i32 %conv1.i.i114.33, %conv.i.i113.33
  %conv2.i.i116.33 = trunc i32 %xor.i.i115.33 to i8
  %scevgep.34 = getelementptr i8, i8* %c, i64 34
  %20346 = load i8, i8* %scevgep.34, align 1
  %conv.i.i113.34 = zext i8 %20346 to i32
  %conv1.i.i114.34 = zext i8 %conv2.i.i116.33 to i32
  %xor.i.i115.34 = xor i32 %conv1.i.i114.34, %conv.i.i113.34
  %conv2.i.i116.34 = trunc i32 %xor.i.i115.34 to i8
  %scevgep.35 = getelementptr i8, i8* %c, i64 35
  %20347 = load i8, i8* %scevgep.35, align 1
  %conv.i.i113.35 = zext i8 %20347 to i32
  %conv1.i.i114.35 = zext i8 %conv2.i.i116.34 to i32
  %xor.i.i115.35 = xor i32 %conv1.i.i114.35, %conv.i.i113.35
  %conv2.i.i116.35 = trunc i32 %xor.i.i115.35 to i8
  %scevgep.36 = getelementptr i8, i8* %c, i64 36
  %20348 = load i8, i8* %scevgep.36, align 1
  %conv.i.i113.36 = zext i8 %20348 to i32
  %conv1.i.i114.36 = zext i8 %conv2.i.i116.35 to i32
  %xor.i.i115.36 = xor i32 %conv1.i.i114.36, %conv.i.i113.36
  %conv2.i.i116.36 = trunc i32 %xor.i.i115.36 to i8
  %scevgep.37 = getelementptr i8, i8* %c, i64 37
  %20349 = load i8, i8* %scevgep.37, align 1
  %conv.i.i113.37 = zext i8 %20349 to i32
  %conv1.i.i114.37 = zext i8 %conv2.i.i116.36 to i32
  %xor.i.i115.37 = xor i32 %conv1.i.i114.37, %conv.i.i113.37
  %conv2.i.i116.37 = trunc i32 %xor.i.i115.37 to i8
  %scevgep.38 = getelementptr i8, i8* %c, i64 38
  %20350 = load i8, i8* %scevgep.38, align 1
  %conv.i.i113.38 = zext i8 %20350 to i32
  %conv1.i.i114.38 = zext i8 %conv2.i.i116.37 to i32
  %xor.i.i115.38 = xor i32 %conv1.i.i114.38, %conv.i.i113.38
  %conv2.i.i116.38 = trunc i32 %xor.i.i115.38 to i8
  %scevgep.39 = getelementptr i8, i8* %c, i64 39
  %20351 = load i8, i8* %scevgep.39, align 1
  %conv.i.i113.39 = zext i8 %20351 to i32
  %conv1.i.i114.39 = zext i8 %conv2.i.i116.38 to i32
  %xor.i.i115.39 = xor i32 %conv1.i.i114.39, %conv.i.i113.39
  %conv2.i.i116.39 = trunc i32 %xor.i.i115.39 to i8
  %scevgep.40 = getelementptr i8, i8* %c, i64 40
  %20352 = load i8, i8* %scevgep.40, align 1
  %conv.i.i113.40 = zext i8 %20352 to i32
  %conv1.i.i114.40 = zext i8 %conv2.i.i116.39 to i32
  %xor.i.i115.40 = xor i32 %conv1.i.i114.40, %conv.i.i113.40
  %conv2.i.i116.40 = trunc i32 %xor.i.i115.40 to i8
  %scevgep.41 = getelementptr i8, i8* %c, i64 41
  %20353 = load i8, i8* %scevgep.41, align 1
  %conv.i.i113.41 = zext i8 %20353 to i32
  %conv1.i.i114.41 = zext i8 %conv2.i.i116.40 to i32
  %xor.i.i115.41 = xor i32 %conv1.i.i114.41, %conv.i.i113.41
  %conv2.i.i116.41 = trunc i32 %xor.i.i115.41 to i8
  %scevgep.42 = getelementptr i8, i8* %c, i64 42
  %20354 = load i8, i8* %scevgep.42, align 1
  %conv.i.i113.42 = zext i8 %20354 to i32
  %conv1.i.i114.42 = zext i8 %conv2.i.i116.41 to i32
  %xor.i.i115.42 = xor i32 %conv1.i.i114.42, %conv.i.i113.42
  %conv2.i.i116.42 = trunc i32 %xor.i.i115.42 to i8
  %scevgep.43 = getelementptr i8, i8* %c, i64 43
  %20355 = load i8, i8* %scevgep.43, align 1
  %conv.i.i113.43 = zext i8 %20355 to i32
  %conv1.i.i114.43 = zext i8 %conv2.i.i116.42 to i32
  %xor.i.i115.43 = xor i32 %conv1.i.i114.43, %conv.i.i113.43
  %conv2.i.i116.43 = trunc i32 %xor.i.i115.43 to i8
  %scevgep.44 = getelementptr i8, i8* %c, i64 44
  %20356 = load i8, i8* %scevgep.44, align 1
  %conv.i.i113.44 = zext i8 %20356 to i32
  %conv1.i.i114.44 = zext i8 %conv2.i.i116.43 to i32
  %xor.i.i115.44 = xor i32 %conv1.i.i114.44, %conv.i.i113.44
  %conv2.i.i116.44 = trunc i32 %xor.i.i115.44 to i8
  %scevgep.45 = getelementptr i8, i8* %c, i64 45
  %20357 = load i8, i8* %scevgep.45, align 1
  %conv.i.i113.45 = zext i8 %20357 to i32
  %conv1.i.i114.45 = zext i8 %conv2.i.i116.44 to i32
  %xor.i.i115.45 = xor i32 %conv1.i.i114.45, %conv.i.i113.45
  %conv2.i.i116.45 = trunc i32 %xor.i.i115.45 to i8
  %scevgep.46 = getelementptr i8, i8* %c, i64 46
  %20358 = load i8, i8* %scevgep.46, align 1
  %conv.i.i113.46 = zext i8 %20358 to i32
  %conv1.i.i114.46 = zext i8 %conv2.i.i116.45 to i32
  %xor.i.i115.46 = xor i32 %conv1.i.i114.46, %conv.i.i113.46
  %conv2.i.i116.46 = trunc i32 %xor.i.i115.46 to i8
  %scevgep.47 = getelementptr i8, i8* %c, i64 47
  %20359 = load i8, i8* %scevgep.47, align 1
  %conv.i.i113.47 = zext i8 %20359 to i32
  %conv1.i.i114.47 = zext i8 %conv2.i.i116.46 to i32
  %xor.i.i115.47 = xor i32 %conv1.i.i114.47, %conv.i.i113.47
  %conv2.i.i116.47 = trunc i32 %xor.i.i115.47 to i8
  %scevgep.48 = getelementptr i8, i8* %c, i64 48
  %20360 = load i8, i8* %scevgep.48, align 1
  %conv.i.i113.48 = zext i8 %20360 to i32
  %conv1.i.i114.48 = zext i8 %conv2.i.i116.47 to i32
  %xor.i.i115.48 = xor i32 %conv1.i.i114.48, %conv.i.i113.48
  %conv2.i.i116.48 = trunc i32 %xor.i.i115.48 to i8
  %scevgep.49 = getelementptr i8, i8* %c, i64 49
  %20361 = load i8, i8* %scevgep.49, align 1
  %conv.i.i113.49 = zext i8 %20361 to i32
  %conv1.i.i114.49 = zext i8 %conv2.i.i116.48 to i32
  %xor.i.i115.49 = xor i32 %conv1.i.i114.49, %conv.i.i113.49
  %conv2.i.i116.49 = trunc i32 %xor.i.i115.49 to i8
  %scevgep.50 = getelementptr i8, i8* %c, i64 50
  %20362 = load i8, i8* %scevgep.50, align 1
  %conv.i.i113.50 = zext i8 %20362 to i32
  %conv1.i.i114.50 = zext i8 %conv2.i.i116.49 to i32
  %xor.i.i115.50 = xor i32 %conv1.i.i114.50, %conv.i.i113.50
  %conv2.i.i116.50 = trunc i32 %xor.i.i115.50 to i8
  %scevgep.51 = getelementptr i8, i8* %c, i64 51
  %20363 = load i8, i8* %scevgep.51, align 1
  %conv.i.i113.51 = zext i8 %20363 to i32
  %conv1.i.i114.51 = zext i8 %conv2.i.i116.50 to i32
  %xor.i.i115.51 = xor i32 %conv1.i.i114.51, %conv.i.i113.51
  %conv2.i.i116.51 = trunc i32 %xor.i.i115.51 to i8
  %scevgep.52 = getelementptr i8, i8* %c, i64 52
  %20364 = load i8, i8* %scevgep.52, align 1
  %conv.i.i113.52 = zext i8 %20364 to i32
  %conv1.i.i114.52 = zext i8 %conv2.i.i116.51 to i32
  %xor.i.i115.52 = xor i32 %conv1.i.i114.52, %conv.i.i113.52
  %conv2.i.i116.52 = trunc i32 %xor.i.i115.52 to i8
  %scevgep.53 = getelementptr i8, i8* %c, i64 53
  %20365 = load i8, i8* %scevgep.53, align 1
  %conv.i.i113.53 = zext i8 %20365 to i32
  %conv1.i.i114.53 = zext i8 %conv2.i.i116.52 to i32
  %xor.i.i115.53 = xor i32 %conv1.i.i114.53, %conv.i.i113.53
  %conv2.i.i116.53 = trunc i32 %xor.i.i115.53 to i8
  %scevgep.54 = getelementptr i8, i8* %c, i64 54
  %20366 = load i8, i8* %scevgep.54, align 1
  %conv.i.i113.54 = zext i8 %20366 to i32
  %conv1.i.i114.54 = zext i8 %conv2.i.i116.53 to i32
  %xor.i.i115.54 = xor i32 %conv1.i.i114.54, %conv.i.i113.54
  %conv2.i.i116.54 = trunc i32 %xor.i.i115.54 to i8
  %scevgep.55 = getelementptr i8, i8* %c, i64 55
  %20367 = load i8, i8* %scevgep.55, align 1
  %conv.i.i113.55 = zext i8 %20367 to i32
  %conv1.i.i114.55 = zext i8 %conv2.i.i116.54 to i32
  %xor.i.i115.55 = xor i32 %conv1.i.i114.55, %conv.i.i113.55
  %conv2.i.i116.55 = trunc i32 %xor.i.i115.55 to i8
  %scevgep.56 = getelementptr i8, i8* %c, i64 56
  %20368 = load i8, i8* %scevgep.56, align 1
  %conv.i.i113.56 = zext i8 %20368 to i32
  %conv1.i.i114.56 = zext i8 %conv2.i.i116.55 to i32
  %xor.i.i115.56 = xor i32 %conv1.i.i114.56, %conv.i.i113.56
  %conv2.i.i116.56 = trunc i32 %xor.i.i115.56 to i8
  %scevgep.57 = getelementptr i8, i8* %c, i64 57
  %20369 = load i8, i8* %scevgep.57, align 1
  %conv.i.i113.57 = zext i8 %20369 to i32
  %conv1.i.i114.57 = zext i8 %conv2.i.i116.56 to i32
  %xor.i.i115.57 = xor i32 %conv1.i.i114.57, %conv.i.i113.57
  %conv2.i.i116.57 = trunc i32 %xor.i.i115.57 to i8
  %scevgep.58 = getelementptr i8, i8* %c, i64 58
  %20370 = load i8, i8* %scevgep.58, align 1
  %conv.i.i113.58 = zext i8 %20370 to i32
  %conv1.i.i114.58 = zext i8 %conv2.i.i116.57 to i32
  %xor.i.i115.58 = xor i32 %conv1.i.i114.58, %conv.i.i113.58
  %conv2.i.i116.58 = trunc i32 %xor.i.i115.58 to i8
  %scevgep.59 = getelementptr i8, i8* %c, i64 59
  %20371 = load i8, i8* %scevgep.59, align 1
  %conv.i.i113.59 = zext i8 %20371 to i32
  %conv1.i.i114.59 = zext i8 %conv2.i.i116.58 to i32
  %xor.i.i115.59 = xor i32 %conv1.i.i114.59, %conv.i.i113.59
  %conv2.i.i116.59 = trunc i32 %xor.i.i115.59 to i8
  %scevgep.60 = getelementptr i8, i8* %c, i64 60
  %20372 = load i8, i8* %scevgep.60, align 1
  %conv.i.i113.60 = zext i8 %20372 to i32
  %conv1.i.i114.60 = zext i8 %conv2.i.i116.59 to i32
  %xor.i.i115.60 = xor i32 %conv1.i.i114.60, %conv.i.i113.60
  %conv2.i.i116.60 = trunc i32 %xor.i.i115.60 to i8
  %conv83 = zext i8 %conv2.i.i116.60 to i32
  %cmp84 = icmp eq i32 %conv81, %conv83
  call void @assert(i1 zeroext %cmp84)
  ret void
}

declare dso_local zeroext i8 @rand(...) #1

declare dso_local void @assume(i1 zeroext) #1

declare dso_local zeroext i8 @mult(i8 zeroext, i8 zeroext) #1

declare dso_local void @assert(i1 zeroext) #1

; Function Attrs: alwaysinline nounwind uwtable
define dso_local void @refresh_masks(i8* %x) #0 {
entry:
  %call = call zeroext i8 (...) @rand()
  %conv = zext i8 %call to i32
  %0 = load i8, i8* %x, align 1
  %scevgep12.1 = getelementptr i8, i8* %x, i64 1
  %1 = load i8, i8* %scevgep12.1, align 1
  %conv.i.i.1 = zext i8 %1 to i32
  %conv1.i.i.1 = zext i8 %0 to i32
  %xor.i.i.1 = xor i32 %conv1.i.i.1, %conv.i.i.1
  %conv2.i.i.1 = trunc i32 %xor.i.i.1 to i8
  %scevgep12.2 = getelementptr i8, i8* %x, i64 2
  %2 = load i8, i8* %scevgep12.2, align 1
  %conv.i.i.2 = zext i8 %2 to i32
  %conv1.i.i.2 = zext i8 %conv2.i.i.1 to i32
  %xor.i.i.2 = xor i32 %conv1.i.i.2, %conv.i.i.2
  %conv2.i.i.2 = trunc i32 %xor.i.i.2 to i8
  %scevgep12.3 = getelementptr i8, i8* %x, i64 3
  %3 = load i8, i8* %scevgep12.3, align 1
  %conv.i.i.3 = zext i8 %3 to i32
  %conv1.i.i.3 = zext i8 %conv2.i.i.2 to i32
  %xor.i.i.3 = xor i32 %conv1.i.i.3, %conv.i.i.3
  %conv2.i.i.3 = trunc i32 %xor.i.i.3 to i8
  %scevgep12.4 = getelementptr i8, i8* %x, i64 4
  %4 = load i8, i8* %scevgep12.4, align 1
  %conv.i.i.4 = zext i8 %4 to i32
  %conv1.i.i.4 = zext i8 %conv2.i.i.3 to i32
  %xor.i.i.4 = xor i32 %conv1.i.i.4, %conv.i.i.4
  %conv2.i.i.4 = trunc i32 %xor.i.i.4 to i8
  %scevgep12.5 = getelementptr i8, i8* %x, i64 5
  %5 = load i8, i8* %scevgep12.5, align 1
  %conv.i.i.5 = zext i8 %5 to i32
  %conv1.i.i.5 = zext i8 %conv2.i.i.4 to i32
  %xor.i.i.5 = xor i32 %conv1.i.i.5, %conv.i.i.5
  %conv2.i.i.5 = trunc i32 %xor.i.i.5 to i8
  %scevgep12.6 = getelementptr i8, i8* %x, i64 6
  %6 = load i8, i8* %scevgep12.6, align 1
  %conv.i.i.6 = zext i8 %6 to i32
  %conv1.i.i.6 = zext i8 %conv2.i.i.5 to i32
  %xor.i.i.6 = xor i32 %conv1.i.i.6, %conv.i.i.6
  %conv2.i.i.6 = trunc i32 %xor.i.i.6 to i8
  %scevgep12.7 = getelementptr i8, i8* %x, i64 7
  %7 = load i8, i8* %scevgep12.7, align 1
  %conv.i.i.7 = zext i8 %7 to i32
  %conv1.i.i.7 = zext i8 %conv2.i.i.6 to i32
  %xor.i.i.7 = xor i32 %conv1.i.i.7, %conv.i.i.7
  %conv2.i.i.7 = trunc i32 %xor.i.i.7 to i8
  %scevgep12.8 = getelementptr i8, i8* %x, i64 8
  %8 = load i8, i8* %scevgep12.8, align 1
  %conv.i.i.8 = zext i8 %8 to i32
  %conv1.i.i.8 = zext i8 %conv2.i.i.7 to i32
  %xor.i.i.8 = xor i32 %conv1.i.i.8, %conv.i.i.8
  %conv2.i.i.8 = trunc i32 %xor.i.i.8 to i8
  %scevgep12.9 = getelementptr i8, i8* %x, i64 9
  %9 = load i8, i8* %scevgep12.9, align 1
  %conv.i.i.9 = zext i8 %9 to i32
  %conv1.i.i.9 = zext i8 %conv2.i.i.8 to i32
  %xor.i.i.9 = xor i32 %conv1.i.i.9, %conv.i.i.9
  %conv2.i.i.9 = trunc i32 %xor.i.i.9 to i8
  %scevgep12.10 = getelementptr i8, i8* %x, i64 10
  %10 = load i8, i8* %scevgep12.10, align 1
  %conv.i.i.10 = zext i8 %10 to i32
  %conv1.i.i.10 = zext i8 %conv2.i.i.9 to i32
  %xor.i.i.10 = xor i32 %conv1.i.i.10, %conv.i.i.10
  %conv2.i.i.10 = trunc i32 %xor.i.i.10 to i8
  %scevgep12.11 = getelementptr i8, i8* %x, i64 11
  %11 = load i8, i8* %scevgep12.11, align 1
  %conv.i.i.11 = zext i8 %11 to i32
  %conv1.i.i.11 = zext i8 %conv2.i.i.10 to i32
  %xor.i.i.11 = xor i32 %conv1.i.i.11, %conv.i.i.11
  %conv2.i.i.11 = trunc i32 %xor.i.i.11 to i8
  %scevgep12.12 = getelementptr i8, i8* %x, i64 12
  %12 = load i8, i8* %scevgep12.12, align 1
  %conv.i.i.12 = zext i8 %12 to i32
  %conv1.i.i.12 = zext i8 %conv2.i.i.11 to i32
  %xor.i.i.12 = xor i32 %conv1.i.i.12, %conv.i.i.12
  %conv2.i.i.12 = trunc i32 %xor.i.i.12 to i8
  %scevgep12.13 = getelementptr i8, i8* %x, i64 13
  %13 = load i8, i8* %scevgep12.13, align 1
  %conv.i.i.13 = zext i8 %13 to i32
  %conv1.i.i.13 = zext i8 %conv2.i.i.12 to i32
  %xor.i.i.13 = xor i32 %conv1.i.i.13, %conv.i.i.13
  %conv2.i.i.13 = trunc i32 %xor.i.i.13 to i8
  %scevgep12.14 = getelementptr i8, i8* %x, i64 14
  %14 = load i8, i8* %scevgep12.14, align 1
  %conv.i.i.14 = zext i8 %14 to i32
  %conv1.i.i.14 = zext i8 %conv2.i.i.13 to i32
  %xor.i.i.14 = xor i32 %conv1.i.i.14, %conv.i.i.14
  %conv2.i.i.14 = trunc i32 %xor.i.i.14 to i8
  %scevgep12.15 = getelementptr i8, i8* %x, i64 15
  %15 = load i8, i8* %scevgep12.15, align 1
  %conv.i.i.15 = zext i8 %15 to i32
  %conv1.i.i.15 = zext i8 %conv2.i.i.14 to i32
  %xor.i.i.15 = xor i32 %conv1.i.i.15, %conv.i.i.15
  %conv2.i.i.15 = trunc i32 %xor.i.i.15 to i8
  %scevgep12.16 = getelementptr i8, i8* %x, i64 16
  %16 = load i8, i8* %scevgep12.16, align 1
  %conv.i.i.16 = zext i8 %16 to i32
  %conv1.i.i.16 = zext i8 %conv2.i.i.15 to i32
  %xor.i.i.16 = xor i32 %conv1.i.i.16, %conv.i.i.16
  %conv2.i.i.16 = trunc i32 %xor.i.i.16 to i8
  %scevgep12.17 = getelementptr i8, i8* %x, i64 17
  %17 = load i8, i8* %scevgep12.17, align 1
  %conv.i.i.17 = zext i8 %17 to i32
  %conv1.i.i.17 = zext i8 %conv2.i.i.16 to i32
  %xor.i.i.17 = xor i32 %conv1.i.i.17, %conv.i.i.17
  %conv2.i.i.17 = trunc i32 %xor.i.i.17 to i8
  %scevgep12.18 = getelementptr i8, i8* %x, i64 18
  %18 = load i8, i8* %scevgep12.18, align 1
  %conv.i.i.18 = zext i8 %18 to i32
  %conv1.i.i.18 = zext i8 %conv2.i.i.17 to i32
  %xor.i.i.18 = xor i32 %conv1.i.i.18, %conv.i.i.18
  %conv2.i.i.18 = trunc i32 %xor.i.i.18 to i8
  %scevgep12.19 = getelementptr i8, i8* %x, i64 19
  %19 = load i8, i8* %scevgep12.19, align 1
  %conv.i.i.19 = zext i8 %19 to i32
  %conv1.i.i.19 = zext i8 %conv2.i.i.18 to i32
  %xor.i.i.19 = xor i32 %conv1.i.i.19, %conv.i.i.19
  %conv2.i.i.19 = trunc i32 %xor.i.i.19 to i8
  %scevgep12.20 = getelementptr i8, i8* %x, i64 20
  %20 = load i8, i8* %scevgep12.20, align 1
  %conv.i.i.20 = zext i8 %20 to i32
  %conv1.i.i.20 = zext i8 %conv2.i.i.19 to i32
  %xor.i.i.20 = xor i32 %conv1.i.i.20, %conv.i.i.20
  %conv2.i.i.20 = trunc i32 %xor.i.i.20 to i8
  %scevgep12.21 = getelementptr i8, i8* %x, i64 21
  %21 = load i8, i8* %scevgep12.21, align 1
  %conv.i.i.21 = zext i8 %21 to i32
  %conv1.i.i.21 = zext i8 %conv2.i.i.20 to i32
  %xor.i.i.21 = xor i32 %conv1.i.i.21, %conv.i.i.21
  %conv2.i.i.21 = trunc i32 %xor.i.i.21 to i8
  %scevgep12.22 = getelementptr i8, i8* %x, i64 22
  %22 = load i8, i8* %scevgep12.22, align 1
  %conv.i.i.22 = zext i8 %22 to i32
  %conv1.i.i.22 = zext i8 %conv2.i.i.21 to i32
  %xor.i.i.22 = xor i32 %conv1.i.i.22, %conv.i.i.22
  %conv2.i.i.22 = trunc i32 %xor.i.i.22 to i8
  %scevgep12.23 = getelementptr i8, i8* %x, i64 23
  %23 = load i8, i8* %scevgep12.23, align 1
  %conv.i.i.23 = zext i8 %23 to i32
  %conv1.i.i.23 = zext i8 %conv2.i.i.22 to i32
  %xor.i.i.23 = xor i32 %conv1.i.i.23, %conv.i.i.23
  %conv2.i.i.23 = trunc i32 %xor.i.i.23 to i8
  %scevgep12.24 = getelementptr i8, i8* %x, i64 24
  %24 = load i8, i8* %scevgep12.24, align 1
  %conv.i.i.24 = zext i8 %24 to i32
  %conv1.i.i.24 = zext i8 %conv2.i.i.23 to i32
  %xor.i.i.24 = xor i32 %conv1.i.i.24, %conv.i.i.24
  %conv2.i.i.24 = trunc i32 %xor.i.i.24 to i8
  %scevgep12.25 = getelementptr i8, i8* %x, i64 25
  %25 = load i8, i8* %scevgep12.25, align 1
  %conv.i.i.25 = zext i8 %25 to i32
  %conv1.i.i.25 = zext i8 %conv2.i.i.24 to i32
  %xor.i.i.25 = xor i32 %conv1.i.i.25, %conv.i.i.25
  %conv2.i.i.25 = trunc i32 %xor.i.i.25 to i8
  %scevgep12.26 = getelementptr i8, i8* %x, i64 26
  %26 = load i8, i8* %scevgep12.26, align 1
  %conv.i.i.26 = zext i8 %26 to i32
  %conv1.i.i.26 = zext i8 %conv2.i.i.25 to i32
  %xor.i.i.26 = xor i32 %conv1.i.i.26, %conv.i.i.26
  %conv2.i.i.26 = trunc i32 %xor.i.i.26 to i8
  %scevgep12.27 = getelementptr i8, i8* %x, i64 27
  %27 = load i8, i8* %scevgep12.27, align 1
  %conv.i.i.27 = zext i8 %27 to i32
  %conv1.i.i.27 = zext i8 %conv2.i.i.26 to i32
  %xor.i.i.27 = xor i32 %conv1.i.i.27, %conv.i.i.27
  %conv2.i.i.27 = trunc i32 %xor.i.i.27 to i8
  %scevgep12.28 = getelementptr i8, i8* %x, i64 28
  %28 = load i8, i8* %scevgep12.28, align 1
  %conv.i.i.28 = zext i8 %28 to i32
  %conv1.i.i.28 = zext i8 %conv2.i.i.27 to i32
  %xor.i.i.28 = xor i32 %conv1.i.i.28, %conv.i.i.28
  %conv2.i.i.28 = trunc i32 %xor.i.i.28 to i8
  %scevgep12.29 = getelementptr i8, i8* %x, i64 29
  %29 = load i8, i8* %scevgep12.29, align 1
  %conv.i.i.29 = zext i8 %29 to i32
  %conv1.i.i.29 = zext i8 %conv2.i.i.28 to i32
  %xor.i.i.29 = xor i32 %conv1.i.i.29, %conv.i.i.29
  %conv2.i.i.29 = trunc i32 %xor.i.i.29 to i8
  %scevgep12.30 = getelementptr i8, i8* %x, i64 30
  %30 = load i8, i8* %scevgep12.30, align 1
  %conv.i.i.30 = zext i8 %30 to i32
  %conv1.i.i.30 = zext i8 %conv2.i.i.29 to i32
  %xor.i.i.30 = xor i32 %conv1.i.i.30, %conv.i.i.30
  %conv2.i.i.30 = trunc i32 %xor.i.i.30 to i8
  %scevgep12.31 = getelementptr i8, i8* %x, i64 31
  %31 = load i8, i8* %scevgep12.31, align 1
  %conv.i.i.31 = zext i8 %31 to i32
  %conv1.i.i.31 = zext i8 %conv2.i.i.30 to i32
  %xor.i.i.31 = xor i32 %conv1.i.i.31, %conv.i.i.31
  %conv2.i.i.31 = trunc i32 %xor.i.i.31 to i8
  %scevgep12.32 = getelementptr i8, i8* %x, i64 32
  %32 = load i8, i8* %scevgep12.32, align 1
  %conv.i.i.32 = zext i8 %32 to i32
  %conv1.i.i.32 = zext i8 %conv2.i.i.31 to i32
  %xor.i.i.32 = xor i32 %conv1.i.i.32, %conv.i.i.32
  %conv2.i.i.32 = trunc i32 %xor.i.i.32 to i8
  %scevgep12.33 = getelementptr i8, i8* %x, i64 33
  %33 = load i8, i8* %scevgep12.33, align 1
  %conv.i.i.33 = zext i8 %33 to i32
  %conv1.i.i.33 = zext i8 %conv2.i.i.32 to i32
  %xor.i.i.33 = xor i32 %conv1.i.i.33, %conv.i.i.33
  %conv2.i.i.33 = trunc i32 %xor.i.i.33 to i8
  %scevgep12.34 = getelementptr i8, i8* %x, i64 34
  %34 = load i8, i8* %scevgep12.34, align 1
  %conv.i.i.34 = zext i8 %34 to i32
  %conv1.i.i.34 = zext i8 %conv2.i.i.33 to i32
  %xor.i.i.34 = xor i32 %conv1.i.i.34, %conv.i.i.34
  %conv2.i.i.34 = trunc i32 %xor.i.i.34 to i8
  %scevgep12.35 = getelementptr i8, i8* %x, i64 35
  %35 = load i8, i8* %scevgep12.35, align 1
  %conv.i.i.35 = zext i8 %35 to i32
  %conv1.i.i.35 = zext i8 %conv2.i.i.34 to i32
  %xor.i.i.35 = xor i32 %conv1.i.i.35, %conv.i.i.35
  %conv2.i.i.35 = trunc i32 %xor.i.i.35 to i8
  %scevgep12.36 = getelementptr i8, i8* %x, i64 36
  %36 = load i8, i8* %scevgep12.36, align 1
  %conv.i.i.36 = zext i8 %36 to i32
  %conv1.i.i.36 = zext i8 %conv2.i.i.35 to i32
  %xor.i.i.36 = xor i32 %conv1.i.i.36, %conv.i.i.36
  %conv2.i.i.36 = trunc i32 %xor.i.i.36 to i8
  %scevgep12.37 = getelementptr i8, i8* %x, i64 37
  %37 = load i8, i8* %scevgep12.37, align 1
  %conv.i.i.37 = zext i8 %37 to i32
  %conv1.i.i.37 = zext i8 %conv2.i.i.36 to i32
  %xor.i.i.37 = xor i32 %conv1.i.i.37, %conv.i.i.37
  %conv2.i.i.37 = trunc i32 %xor.i.i.37 to i8
  %scevgep12.38 = getelementptr i8, i8* %x, i64 38
  %38 = load i8, i8* %scevgep12.38, align 1
  %conv.i.i.38 = zext i8 %38 to i32
  %conv1.i.i.38 = zext i8 %conv2.i.i.37 to i32
  %xor.i.i.38 = xor i32 %conv1.i.i.38, %conv.i.i.38
  %conv2.i.i.38 = trunc i32 %xor.i.i.38 to i8
  %scevgep12.39 = getelementptr i8, i8* %x, i64 39
  %39 = load i8, i8* %scevgep12.39, align 1
  %conv.i.i.39 = zext i8 %39 to i32
  %conv1.i.i.39 = zext i8 %conv2.i.i.38 to i32
  %xor.i.i.39 = xor i32 %conv1.i.i.39, %conv.i.i.39
  %conv2.i.i.39 = trunc i32 %xor.i.i.39 to i8
  %scevgep12.40 = getelementptr i8, i8* %x, i64 40
  %40 = load i8, i8* %scevgep12.40, align 1
  %conv.i.i.40 = zext i8 %40 to i32
  %conv1.i.i.40 = zext i8 %conv2.i.i.39 to i32
  %xor.i.i.40 = xor i32 %conv1.i.i.40, %conv.i.i.40
  %conv2.i.i.40 = trunc i32 %xor.i.i.40 to i8
  %scevgep12.41 = getelementptr i8, i8* %x, i64 41
  %41 = load i8, i8* %scevgep12.41, align 1
  %conv.i.i.41 = zext i8 %41 to i32
  %conv1.i.i.41 = zext i8 %conv2.i.i.40 to i32
  %xor.i.i.41 = xor i32 %conv1.i.i.41, %conv.i.i.41
  %conv2.i.i.41 = trunc i32 %xor.i.i.41 to i8
  %scevgep12.42 = getelementptr i8, i8* %x, i64 42
  %42 = load i8, i8* %scevgep12.42, align 1
  %conv.i.i.42 = zext i8 %42 to i32
  %conv1.i.i.42 = zext i8 %conv2.i.i.41 to i32
  %xor.i.i.42 = xor i32 %conv1.i.i.42, %conv.i.i.42
  %conv2.i.i.42 = trunc i32 %xor.i.i.42 to i8
  %scevgep12.43 = getelementptr i8, i8* %x, i64 43
  %43 = load i8, i8* %scevgep12.43, align 1
  %conv.i.i.43 = zext i8 %43 to i32
  %conv1.i.i.43 = zext i8 %conv2.i.i.42 to i32
  %xor.i.i.43 = xor i32 %conv1.i.i.43, %conv.i.i.43
  %conv2.i.i.43 = trunc i32 %xor.i.i.43 to i8
  %scevgep12.44 = getelementptr i8, i8* %x, i64 44
  %44 = load i8, i8* %scevgep12.44, align 1
  %conv.i.i.44 = zext i8 %44 to i32
  %conv1.i.i.44 = zext i8 %conv2.i.i.43 to i32
  %xor.i.i.44 = xor i32 %conv1.i.i.44, %conv.i.i.44
  %conv2.i.i.44 = trunc i32 %xor.i.i.44 to i8
  %scevgep12.45 = getelementptr i8, i8* %x, i64 45
  %45 = load i8, i8* %scevgep12.45, align 1
  %conv.i.i.45 = zext i8 %45 to i32
  %conv1.i.i.45 = zext i8 %conv2.i.i.44 to i32
  %xor.i.i.45 = xor i32 %conv1.i.i.45, %conv.i.i.45
  %conv2.i.i.45 = trunc i32 %xor.i.i.45 to i8
  %scevgep12.46 = getelementptr i8, i8* %x, i64 46
  %46 = load i8, i8* %scevgep12.46, align 1
  %conv.i.i.46 = zext i8 %46 to i32
  %conv1.i.i.46 = zext i8 %conv2.i.i.45 to i32
  %xor.i.i.46 = xor i32 %conv1.i.i.46, %conv.i.i.46
  %conv2.i.i.46 = trunc i32 %xor.i.i.46 to i8
  %scevgep12.47 = getelementptr i8, i8* %x, i64 47
  %47 = load i8, i8* %scevgep12.47, align 1
  %conv.i.i.47 = zext i8 %47 to i32
  %conv1.i.i.47 = zext i8 %conv2.i.i.46 to i32
  %xor.i.i.47 = xor i32 %conv1.i.i.47, %conv.i.i.47
  %conv2.i.i.47 = trunc i32 %xor.i.i.47 to i8
  %scevgep12.48 = getelementptr i8, i8* %x, i64 48
  %48 = load i8, i8* %scevgep12.48, align 1
  %conv.i.i.48 = zext i8 %48 to i32
  %conv1.i.i.48 = zext i8 %conv2.i.i.47 to i32
  %xor.i.i.48 = xor i32 %conv1.i.i.48, %conv.i.i.48
  %conv2.i.i.48 = trunc i32 %xor.i.i.48 to i8
  %scevgep12.49 = getelementptr i8, i8* %x, i64 49
  %49 = load i8, i8* %scevgep12.49, align 1
  %conv.i.i.49 = zext i8 %49 to i32
  %conv1.i.i.49 = zext i8 %conv2.i.i.48 to i32
  %xor.i.i.49 = xor i32 %conv1.i.i.49, %conv.i.i.49
  %conv2.i.i.49 = trunc i32 %xor.i.i.49 to i8
  %scevgep12.50 = getelementptr i8, i8* %x, i64 50
  %50 = load i8, i8* %scevgep12.50, align 1
  %conv.i.i.50 = zext i8 %50 to i32
  %conv1.i.i.50 = zext i8 %conv2.i.i.49 to i32
  %xor.i.i.50 = xor i32 %conv1.i.i.50, %conv.i.i.50
  %conv2.i.i.50 = trunc i32 %xor.i.i.50 to i8
  %scevgep12.51 = getelementptr i8, i8* %x, i64 51
  %51 = load i8, i8* %scevgep12.51, align 1
  %conv.i.i.51 = zext i8 %51 to i32
  %conv1.i.i.51 = zext i8 %conv2.i.i.50 to i32
  %xor.i.i.51 = xor i32 %conv1.i.i.51, %conv.i.i.51
  %conv2.i.i.51 = trunc i32 %xor.i.i.51 to i8
  %scevgep12.52 = getelementptr i8, i8* %x, i64 52
  %52 = load i8, i8* %scevgep12.52, align 1
  %conv.i.i.52 = zext i8 %52 to i32
  %conv1.i.i.52 = zext i8 %conv2.i.i.51 to i32
  %xor.i.i.52 = xor i32 %conv1.i.i.52, %conv.i.i.52
  %conv2.i.i.52 = trunc i32 %xor.i.i.52 to i8
  %scevgep12.53 = getelementptr i8, i8* %x, i64 53
  %53 = load i8, i8* %scevgep12.53, align 1
  %conv.i.i.53 = zext i8 %53 to i32
  %conv1.i.i.53 = zext i8 %conv2.i.i.52 to i32
  %xor.i.i.53 = xor i32 %conv1.i.i.53, %conv.i.i.53
  %conv2.i.i.53 = trunc i32 %xor.i.i.53 to i8
  %scevgep12.54 = getelementptr i8, i8* %x, i64 54
  %54 = load i8, i8* %scevgep12.54, align 1
  %conv.i.i.54 = zext i8 %54 to i32
  %conv1.i.i.54 = zext i8 %conv2.i.i.53 to i32
  %xor.i.i.54 = xor i32 %conv1.i.i.54, %conv.i.i.54
  %conv2.i.i.54 = trunc i32 %xor.i.i.54 to i8
  %scevgep12.55 = getelementptr i8, i8* %x, i64 55
  %55 = load i8, i8* %scevgep12.55, align 1
  %conv.i.i.55 = zext i8 %55 to i32
  %conv1.i.i.55 = zext i8 %conv2.i.i.54 to i32
  %xor.i.i.55 = xor i32 %conv1.i.i.55, %conv.i.i.55
  %conv2.i.i.55 = trunc i32 %xor.i.i.55 to i8
  %scevgep12.56 = getelementptr i8, i8* %x, i64 56
  %56 = load i8, i8* %scevgep12.56, align 1
  %conv.i.i.56 = zext i8 %56 to i32
  %conv1.i.i.56 = zext i8 %conv2.i.i.55 to i32
  %xor.i.i.56 = xor i32 %conv1.i.i.56, %conv.i.i.56
  %conv2.i.i.56 = trunc i32 %xor.i.i.56 to i8
  %scevgep12.57 = getelementptr i8, i8* %x, i64 57
  %57 = load i8, i8* %scevgep12.57, align 1
  %conv.i.i.57 = zext i8 %57 to i32
  %conv1.i.i.57 = zext i8 %conv2.i.i.56 to i32
  %xor.i.i.57 = xor i32 %conv1.i.i.57, %conv.i.i.57
  %conv2.i.i.57 = trunc i32 %xor.i.i.57 to i8
  %scevgep12.58 = getelementptr i8, i8* %x, i64 58
  %58 = load i8, i8* %scevgep12.58, align 1
  %conv.i.i.58 = zext i8 %58 to i32
  %conv1.i.i.58 = zext i8 %conv2.i.i.57 to i32
  %xor.i.i.58 = xor i32 %conv1.i.i.58, %conv.i.i.58
  %conv2.i.i.58 = trunc i32 %xor.i.i.58 to i8
  %scevgep12.59 = getelementptr i8, i8* %x, i64 59
  %59 = load i8, i8* %scevgep12.59, align 1
  %conv.i.i.59 = zext i8 %59 to i32
  %conv1.i.i.59 = zext i8 %conv2.i.i.58 to i32
  %xor.i.i.59 = xor i32 %conv1.i.i.59, %conv.i.i.59
  %conv2.i.i.59 = trunc i32 %xor.i.i.59 to i8
  %scevgep12.60 = getelementptr i8, i8* %x, i64 60
  %60 = load i8, i8* %scevgep12.60, align 1
  %conv.i.i.60 = zext i8 %60 to i32
  %conv1.i.i.60 = zext i8 %conv2.i.i.59 to i32
  %xor.i.i.60 = xor i32 %conv1.i.i.60, %conv.i.i.60
  %conv2.i.i.60 = trunc i32 %xor.i.i.60 to i8
  %conv2 = zext i8 %conv2.i.i.60 to i32
  %cmp = icmp eq i32 %conv, %conv2
  call void @assume(i1 zeroext %cmp)
  %call7 = call zeroext i8 (...) @rand()
  %conv8 = zext i8 %call7 to i32
  %61 = load i8, i8* %x, align 1
  %conv9 = zext i8 %61 to i32
  %xor = xor i32 %conv9, %conv8
  %conv10 = trunc i32 %xor to i8
  store i8 %conv10, i8* %x, align 1
  %conv11 = zext i8 %call7 to i32
  %scevgep8 = getelementptr i8, i8* %x, i64 1
  %62 = load i8, i8* %scevgep8, align 1
  %conv13 = zext i8 %62 to i32
  %xor14 = xor i32 %conv13, %conv11
  %conv15 = trunc i32 %xor14 to i8
  store i8 %conv15, i8* %scevgep8, align 1
  %call7.1 = call zeroext i8 (...) @rand()
  %conv8.1 = zext i8 %call7.1 to i32
  %63 = load i8, i8* %x, align 1
  %conv9.1 = zext i8 %63 to i32
  %xor.1 = xor i32 %conv9.1, %conv8.1
  %conv10.1 = trunc i32 %xor.1 to i8
  store i8 %conv10.1, i8* %x, align 1
  %conv11.1 = zext i8 %call7.1 to i32
  %scevgep8.1 = getelementptr i8, i8* %x, i64 2
  %64 = load i8, i8* %scevgep8.1, align 1
  %conv13.1 = zext i8 %64 to i32
  %xor14.1 = xor i32 %conv13.1, %conv11.1
  %conv15.1 = trunc i32 %xor14.1 to i8
  store i8 %conv15.1, i8* %scevgep8.1, align 1
  %call7.2 = call zeroext i8 (...) @rand()
  %conv8.2 = zext i8 %call7.2 to i32
  %65 = load i8, i8* %x, align 1
  %conv9.2 = zext i8 %65 to i32
  %xor.2 = xor i32 %conv9.2, %conv8.2
  %conv10.2 = trunc i32 %xor.2 to i8
  store i8 %conv10.2, i8* %x, align 1
  %conv11.2 = zext i8 %call7.2 to i32
  %scevgep8.2 = getelementptr i8, i8* %x, i64 3
  %66 = load i8, i8* %scevgep8.2, align 1
  %conv13.2 = zext i8 %66 to i32
  %xor14.2 = xor i32 %conv13.2, %conv11.2
  %conv15.2 = trunc i32 %xor14.2 to i8
  store i8 %conv15.2, i8* %scevgep8.2, align 1
  %call7.3 = call zeroext i8 (...) @rand()
  %conv8.3 = zext i8 %call7.3 to i32
  %67 = load i8, i8* %x, align 1
  %conv9.3 = zext i8 %67 to i32
  %xor.3 = xor i32 %conv9.3, %conv8.3
  %conv10.3 = trunc i32 %xor.3 to i8
  store i8 %conv10.3, i8* %x, align 1
  %conv11.3 = zext i8 %call7.3 to i32
  %scevgep8.3 = getelementptr i8, i8* %x, i64 4
  %68 = load i8, i8* %scevgep8.3, align 1
  %conv13.3 = zext i8 %68 to i32
  %xor14.3 = xor i32 %conv13.3, %conv11.3
  %conv15.3 = trunc i32 %xor14.3 to i8
  store i8 %conv15.3, i8* %scevgep8.3, align 1
  %call7.4 = call zeroext i8 (...) @rand()
  %conv8.4 = zext i8 %call7.4 to i32
  %69 = load i8, i8* %x, align 1
  %conv9.4 = zext i8 %69 to i32
  %xor.4 = xor i32 %conv9.4, %conv8.4
  %conv10.4 = trunc i32 %xor.4 to i8
  store i8 %conv10.4, i8* %x, align 1
  %conv11.4 = zext i8 %call7.4 to i32
  %scevgep8.4 = getelementptr i8, i8* %x, i64 5
  %70 = load i8, i8* %scevgep8.4, align 1
  %conv13.4 = zext i8 %70 to i32
  %xor14.4 = xor i32 %conv13.4, %conv11.4
  %conv15.4 = trunc i32 %xor14.4 to i8
  store i8 %conv15.4, i8* %scevgep8.4, align 1
  %call7.5 = call zeroext i8 (...) @rand()
  %conv8.5 = zext i8 %call7.5 to i32
  %71 = load i8, i8* %x, align 1
  %conv9.5 = zext i8 %71 to i32
  %xor.5 = xor i32 %conv9.5, %conv8.5
  %conv10.5 = trunc i32 %xor.5 to i8
  store i8 %conv10.5, i8* %x, align 1
  %conv11.5 = zext i8 %call7.5 to i32
  %scevgep8.5 = getelementptr i8, i8* %x, i64 6
  %72 = load i8, i8* %scevgep8.5, align 1
  %conv13.5 = zext i8 %72 to i32
  %xor14.5 = xor i32 %conv13.5, %conv11.5
  %conv15.5 = trunc i32 %xor14.5 to i8
  store i8 %conv15.5, i8* %scevgep8.5, align 1
  %call7.6 = call zeroext i8 (...) @rand()
  %conv8.6 = zext i8 %call7.6 to i32
  %73 = load i8, i8* %x, align 1
  %conv9.6 = zext i8 %73 to i32
  %xor.6 = xor i32 %conv9.6, %conv8.6
  %conv10.6 = trunc i32 %xor.6 to i8
  store i8 %conv10.6, i8* %x, align 1
  %conv11.6 = zext i8 %call7.6 to i32
  %scevgep8.6 = getelementptr i8, i8* %x, i64 7
  %74 = load i8, i8* %scevgep8.6, align 1
  %conv13.6 = zext i8 %74 to i32
  %xor14.6 = xor i32 %conv13.6, %conv11.6
  %conv15.6 = trunc i32 %xor14.6 to i8
  store i8 %conv15.6, i8* %scevgep8.6, align 1
  %call7.7 = call zeroext i8 (...) @rand()
  %conv8.7 = zext i8 %call7.7 to i32
  %75 = load i8, i8* %x, align 1
  %conv9.7 = zext i8 %75 to i32
  %xor.7 = xor i32 %conv9.7, %conv8.7
  %conv10.7 = trunc i32 %xor.7 to i8
  store i8 %conv10.7, i8* %x, align 1
  %conv11.7 = zext i8 %call7.7 to i32
  %scevgep8.7 = getelementptr i8, i8* %x, i64 8
  %76 = load i8, i8* %scevgep8.7, align 1
  %conv13.7 = zext i8 %76 to i32
  %xor14.7 = xor i32 %conv13.7, %conv11.7
  %conv15.7 = trunc i32 %xor14.7 to i8
  store i8 %conv15.7, i8* %scevgep8.7, align 1
  %call7.8 = call zeroext i8 (...) @rand()
  %conv8.8 = zext i8 %call7.8 to i32
  %77 = load i8, i8* %x, align 1
  %conv9.8 = zext i8 %77 to i32
  %xor.8 = xor i32 %conv9.8, %conv8.8
  %conv10.8 = trunc i32 %xor.8 to i8
  store i8 %conv10.8, i8* %x, align 1
  %conv11.8 = zext i8 %call7.8 to i32
  %scevgep8.8 = getelementptr i8, i8* %x, i64 9
  %78 = load i8, i8* %scevgep8.8, align 1
  %conv13.8 = zext i8 %78 to i32
  %xor14.8 = xor i32 %conv13.8, %conv11.8
  %conv15.8 = trunc i32 %xor14.8 to i8
  store i8 %conv15.8, i8* %scevgep8.8, align 1
  %call7.9 = call zeroext i8 (...) @rand()
  %conv8.9 = zext i8 %call7.9 to i32
  %79 = load i8, i8* %x, align 1
  %conv9.9 = zext i8 %79 to i32
  %xor.9 = xor i32 %conv9.9, %conv8.9
  %conv10.9 = trunc i32 %xor.9 to i8
  store i8 %conv10.9, i8* %x, align 1
  %conv11.9 = zext i8 %call7.9 to i32
  %scevgep8.9 = getelementptr i8, i8* %x, i64 10
  %80 = load i8, i8* %scevgep8.9, align 1
  %conv13.9 = zext i8 %80 to i32
  %xor14.9 = xor i32 %conv13.9, %conv11.9
  %conv15.9 = trunc i32 %xor14.9 to i8
  store i8 %conv15.9, i8* %scevgep8.9, align 1
  %call7.10 = call zeroext i8 (...) @rand()
  %conv8.10 = zext i8 %call7.10 to i32
  %81 = load i8, i8* %x, align 1
  %conv9.10 = zext i8 %81 to i32
  %xor.10 = xor i32 %conv9.10, %conv8.10
  %conv10.10 = trunc i32 %xor.10 to i8
  store i8 %conv10.10, i8* %x, align 1
  %conv11.10 = zext i8 %call7.10 to i32
  %scevgep8.10 = getelementptr i8, i8* %x, i64 11
  %82 = load i8, i8* %scevgep8.10, align 1
  %conv13.10 = zext i8 %82 to i32
  %xor14.10 = xor i32 %conv13.10, %conv11.10
  %conv15.10 = trunc i32 %xor14.10 to i8
  store i8 %conv15.10, i8* %scevgep8.10, align 1
  %call7.11 = call zeroext i8 (...) @rand()
  %conv8.11 = zext i8 %call7.11 to i32
  %83 = load i8, i8* %x, align 1
  %conv9.11 = zext i8 %83 to i32
  %xor.11 = xor i32 %conv9.11, %conv8.11
  %conv10.11 = trunc i32 %xor.11 to i8
  store i8 %conv10.11, i8* %x, align 1
  %conv11.11 = zext i8 %call7.11 to i32
  %scevgep8.11 = getelementptr i8, i8* %x, i64 12
  %84 = load i8, i8* %scevgep8.11, align 1
  %conv13.11 = zext i8 %84 to i32
  %xor14.11 = xor i32 %conv13.11, %conv11.11
  %conv15.11 = trunc i32 %xor14.11 to i8
  store i8 %conv15.11, i8* %scevgep8.11, align 1
  %call7.12 = call zeroext i8 (...) @rand()
  %conv8.12 = zext i8 %call7.12 to i32
  %85 = load i8, i8* %x, align 1
  %conv9.12 = zext i8 %85 to i32
  %xor.12 = xor i32 %conv9.12, %conv8.12
  %conv10.12 = trunc i32 %xor.12 to i8
  store i8 %conv10.12, i8* %x, align 1
  %conv11.12 = zext i8 %call7.12 to i32
  %scevgep8.12 = getelementptr i8, i8* %x, i64 13
  %86 = load i8, i8* %scevgep8.12, align 1
  %conv13.12 = zext i8 %86 to i32
  %xor14.12 = xor i32 %conv13.12, %conv11.12
  %conv15.12 = trunc i32 %xor14.12 to i8
  store i8 %conv15.12, i8* %scevgep8.12, align 1
  %call7.13 = call zeroext i8 (...) @rand()
  %conv8.13 = zext i8 %call7.13 to i32
  %87 = load i8, i8* %x, align 1
  %conv9.13 = zext i8 %87 to i32
  %xor.13 = xor i32 %conv9.13, %conv8.13
  %conv10.13 = trunc i32 %xor.13 to i8
  store i8 %conv10.13, i8* %x, align 1
  %conv11.13 = zext i8 %call7.13 to i32
  %scevgep8.13 = getelementptr i8, i8* %x, i64 14
  %88 = load i8, i8* %scevgep8.13, align 1
  %conv13.13 = zext i8 %88 to i32
  %xor14.13 = xor i32 %conv13.13, %conv11.13
  %conv15.13 = trunc i32 %xor14.13 to i8
  store i8 %conv15.13, i8* %scevgep8.13, align 1
  %call7.14 = call zeroext i8 (...) @rand()
  %conv8.14 = zext i8 %call7.14 to i32
  %89 = load i8, i8* %x, align 1
  %conv9.14 = zext i8 %89 to i32
  %xor.14 = xor i32 %conv9.14, %conv8.14
  %conv10.14 = trunc i32 %xor.14 to i8
  store i8 %conv10.14, i8* %x, align 1
  %conv11.14 = zext i8 %call7.14 to i32
  %scevgep8.14 = getelementptr i8, i8* %x, i64 15
  %90 = load i8, i8* %scevgep8.14, align 1
  %conv13.14 = zext i8 %90 to i32
  %xor14.14 = xor i32 %conv13.14, %conv11.14
  %conv15.14 = trunc i32 %xor14.14 to i8
  store i8 %conv15.14, i8* %scevgep8.14, align 1
  %call7.15 = call zeroext i8 (...) @rand()
  %conv8.15 = zext i8 %call7.15 to i32
  %91 = load i8, i8* %x, align 1
  %conv9.15 = zext i8 %91 to i32
  %xor.15 = xor i32 %conv9.15, %conv8.15
  %conv10.15 = trunc i32 %xor.15 to i8
  store i8 %conv10.15, i8* %x, align 1
  %conv11.15 = zext i8 %call7.15 to i32
  %scevgep8.15 = getelementptr i8, i8* %x, i64 16
  %92 = load i8, i8* %scevgep8.15, align 1
  %conv13.15 = zext i8 %92 to i32
  %xor14.15 = xor i32 %conv13.15, %conv11.15
  %conv15.15 = trunc i32 %xor14.15 to i8
  store i8 %conv15.15, i8* %scevgep8.15, align 1
  %call7.16 = call zeroext i8 (...) @rand()
  %conv8.16 = zext i8 %call7.16 to i32
  %93 = load i8, i8* %x, align 1
  %conv9.16 = zext i8 %93 to i32
  %xor.16 = xor i32 %conv9.16, %conv8.16
  %conv10.16 = trunc i32 %xor.16 to i8
  store i8 %conv10.16, i8* %x, align 1
  %conv11.16 = zext i8 %call7.16 to i32
  %scevgep8.16 = getelementptr i8, i8* %x, i64 17
  %94 = load i8, i8* %scevgep8.16, align 1
  %conv13.16 = zext i8 %94 to i32
  %xor14.16 = xor i32 %conv13.16, %conv11.16
  %conv15.16 = trunc i32 %xor14.16 to i8
  store i8 %conv15.16, i8* %scevgep8.16, align 1
  %call7.17 = call zeroext i8 (...) @rand()
  %conv8.17 = zext i8 %call7.17 to i32
  %95 = load i8, i8* %x, align 1
  %conv9.17 = zext i8 %95 to i32
  %xor.17 = xor i32 %conv9.17, %conv8.17
  %conv10.17 = trunc i32 %xor.17 to i8
  store i8 %conv10.17, i8* %x, align 1
  %conv11.17 = zext i8 %call7.17 to i32
  %scevgep8.17 = getelementptr i8, i8* %x, i64 18
  %96 = load i8, i8* %scevgep8.17, align 1
  %conv13.17 = zext i8 %96 to i32
  %xor14.17 = xor i32 %conv13.17, %conv11.17
  %conv15.17 = trunc i32 %xor14.17 to i8
  store i8 %conv15.17, i8* %scevgep8.17, align 1
  %call7.18 = call zeroext i8 (...) @rand()
  %conv8.18 = zext i8 %call7.18 to i32
  %97 = load i8, i8* %x, align 1
  %conv9.18 = zext i8 %97 to i32
  %xor.18 = xor i32 %conv9.18, %conv8.18
  %conv10.18 = trunc i32 %xor.18 to i8
  store i8 %conv10.18, i8* %x, align 1
  %conv11.18 = zext i8 %call7.18 to i32
  %scevgep8.18 = getelementptr i8, i8* %x, i64 19
  %98 = load i8, i8* %scevgep8.18, align 1
  %conv13.18 = zext i8 %98 to i32
  %xor14.18 = xor i32 %conv13.18, %conv11.18
  %conv15.18 = trunc i32 %xor14.18 to i8
  store i8 %conv15.18, i8* %scevgep8.18, align 1
  %call7.19 = call zeroext i8 (...) @rand()
  %conv8.19 = zext i8 %call7.19 to i32
  %99 = load i8, i8* %x, align 1
  %conv9.19 = zext i8 %99 to i32
  %xor.19 = xor i32 %conv9.19, %conv8.19
  %conv10.19 = trunc i32 %xor.19 to i8
  store i8 %conv10.19, i8* %x, align 1
  %conv11.19 = zext i8 %call7.19 to i32
  %scevgep8.19 = getelementptr i8, i8* %x, i64 20
  %100 = load i8, i8* %scevgep8.19, align 1
  %conv13.19 = zext i8 %100 to i32
  %xor14.19 = xor i32 %conv13.19, %conv11.19
  %conv15.19 = trunc i32 %xor14.19 to i8
  store i8 %conv15.19, i8* %scevgep8.19, align 1
  %call7.20 = call zeroext i8 (...) @rand()
  %conv8.20 = zext i8 %call7.20 to i32
  %101 = load i8, i8* %x, align 1
  %conv9.20 = zext i8 %101 to i32
  %xor.20 = xor i32 %conv9.20, %conv8.20
  %conv10.20 = trunc i32 %xor.20 to i8
  store i8 %conv10.20, i8* %x, align 1
  %conv11.20 = zext i8 %call7.20 to i32
  %scevgep8.20 = getelementptr i8, i8* %x, i64 21
  %102 = load i8, i8* %scevgep8.20, align 1
  %conv13.20 = zext i8 %102 to i32
  %xor14.20 = xor i32 %conv13.20, %conv11.20
  %conv15.20 = trunc i32 %xor14.20 to i8
  store i8 %conv15.20, i8* %scevgep8.20, align 1
  %call7.21 = call zeroext i8 (...) @rand()
  %conv8.21 = zext i8 %call7.21 to i32
  %103 = load i8, i8* %x, align 1
  %conv9.21 = zext i8 %103 to i32
  %xor.21 = xor i32 %conv9.21, %conv8.21
  %conv10.21 = trunc i32 %xor.21 to i8
  store i8 %conv10.21, i8* %x, align 1
  %conv11.21 = zext i8 %call7.21 to i32
  %scevgep8.21 = getelementptr i8, i8* %x, i64 22
  %104 = load i8, i8* %scevgep8.21, align 1
  %conv13.21 = zext i8 %104 to i32
  %xor14.21 = xor i32 %conv13.21, %conv11.21
  %conv15.21 = trunc i32 %xor14.21 to i8
  store i8 %conv15.21, i8* %scevgep8.21, align 1
  %call7.22 = call zeroext i8 (...) @rand()
  %conv8.22 = zext i8 %call7.22 to i32
  %105 = load i8, i8* %x, align 1
  %conv9.22 = zext i8 %105 to i32
  %xor.22 = xor i32 %conv9.22, %conv8.22
  %conv10.22 = trunc i32 %xor.22 to i8
  store i8 %conv10.22, i8* %x, align 1
  %conv11.22 = zext i8 %call7.22 to i32
  %scevgep8.22 = getelementptr i8, i8* %x, i64 23
  %106 = load i8, i8* %scevgep8.22, align 1
  %conv13.22 = zext i8 %106 to i32
  %xor14.22 = xor i32 %conv13.22, %conv11.22
  %conv15.22 = trunc i32 %xor14.22 to i8
  store i8 %conv15.22, i8* %scevgep8.22, align 1
  %call7.23 = call zeroext i8 (...) @rand()
  %conv8.23 = zext i8 %call7.23 to i32
  %107 = load i8, i8* %x, align 1
  %conv9.23 = zext i8 %107 to i32
  %xor.23 = xor i32 %conv9.23, %conv8.23
  %conv10.23 = trunc i32 %xor.23 to i8
  store i8 %conv10.23, i8* %x, align 1
  %conv11.23 = zext i8 %call7.23 to i32
  %scevgep8.23 = getelementptr i8, i8* %x, i64 24
  %108 = load i8, i8* %scevgep8.23, align 1
  %conv13.23 = zext i8 %108 to i32
  %xor14.23 = xor i32 %conv13.23, %conv11.23
  %conv15.23 = trunc i32 %xor14.23 to i8
  store i8 %conv15.23, i8* %scevgep8.23, align 1
  %call7.24 = call zeroext i8 (...) @rand()
  %conv8.24 = zext i8 %call7.24 to i32
  %109 = load i8, i8* %x, align 1
  %conv9.24 = zext i8 %109 to i32
  %xor.24 = xor i32 %conv9.24, %conv8.24
  %conv10.24 = trunc i32 %xor.24 to i8
  store i8 %conv10.24, i8* %x, align 1
  %conv11.24 = zext i8 %call7.24 to i32
  %scevgep8.24 = getelementptr i8, i8* %x, i64 25
  %110 = load i8, i8* %scevgep8.24, align 1
  %conv13.24 = zext i8 %110 to i32
  %xor14.24 = xor i32 %conv13.24, %conv11.24
  %conv15.24 = trunc i32 %xor14.24 to i8
  store i8 %conv15.24, i8* %scevgep8.24, align 1
  %call7.25 = call zeroext i8 (...) @rand()
  %conv8.25 = zext i8 %call7.25 to i32
  %111 = load i8, i8* %x, align 1
  %conv9.25 = zext i8 %111 to i32
  %xor.25 = xor i32 %conv9.25, %conv8.25
  %conv10.25 = trunc i32 %xor.25 to i8
  store i8 %conv10.25, i8* %x, align 1
  %conv11.25 = zext i8 %call7.25 to i32
  %scevgep8.25 = getelementptr i8, i8* %x, i64 26
  %112 = load i8, i8* %scevgep8.25, align 1
  %conv13.25 = zext i8 %112 to i32
  %xor14.25 = xor i32 %conv13.25, %conv11.25
  %conv15.25 = trunc i32 %xor14.25 to i8
  store i8 %conv15.25, i8* %scevgep8.25, align 1
  %call7.26 = call zeroext i8 (...) @rand()
  %conv8.26 = zext i8 %call7.26 to i32
  %113 = load i8, i8* %x, align 1
  %conv9.26 = zext i8 %113 to i32
  %xor.26 = xor i32 %conv9.26, %conv8.26
  %conv10.26 = trunc i32 %xor.26 to i8
  store i8 %conv10.26, i8* %x, align 1
  %conv11.26 = zext i8 %call7.26 to i32
  %scevgep8.26 = getelementptr i8, i8* %x, i64 27
  %114 = load i8, i8* %scevgep8.26, align 1
  %conv13.26 = zext i8 %114 to i32
  %xor14.26 = xor i32 %conv13.26, %conv11.26
  %conv15.26 = trunc i32 %xor14.26 to i8
  store i8 %conv15.26, i8* %scevgep8.26, align 1
  %call7.27 = call zeroext i8 (...) @rand()
  %conv8.27 = zext i8 %call7.27 to i32
  %115 = load i8, i8* %x, align 1
  %conv9.27 = zext i8 %115 to i32
  %xor.27 = xor i32 %conv9.27, %conv8.27
  %conv10.27 = trunc i32 %xor.27 to i8
  store i8 %conv10.27, i8* %x, align 1
  %conv11.27 = zext i8 %call7.27 to i32
  %scevgep8.27 = getelementptr i8, i8* %x, i64 28
  %116 = load i8, i8* %scevgep8.27, align 1
  %conv13.27 = zext i8 %116 to i32
  %xor14.27 = xor i32 %conv13.27, %conv11.27
  %conv15.27 = trunc i32 %xor14.27 to i8
  store i8 %conv15.27, i8* %scevgep8.27, align 1
  %call7.28 = call zeroext i8 (...) @rand()
  %conv8.28 = zext i8 %call7.28 to i32
  %117 = load i8, i8* %x, align 1
  %conv9.28 = zext i8 %117 to i32
  %xor.28 = xor i32 %conv9.28, %conv8.28
  %conv10.28 = trunc i32 %xor.28 to i8
  store i8 %conv10.28, i8* %x, align 1
  %conv11.28 = zext i8 %call7.28 to i32
  %scevgep8.28 = getelementptr i8, i8* %x, i64 29
  %118 = load i8, i8* %scevgep8.28, align 1
  %conv13.28 = zext i8 %118 to i32
  %xor14.28 = xor i32 %conv13.28, %conv11.28
  %conv15.28 = trunc i32 %xor14.28 to i8
  store i8 %conv15.28, i8* %scevgep8.28, align 1
  %call7.29 = call zeroext i8 (...) @rand()
  %conv8.29 = zext i8 %call7.29 to i32
  %119 = load i8, i8* %x, align 1
  %conv9.29 = zext i8 %119 to i32
  %xor.29 = xor i32 %conv9.29, %conv8.29
  %conv10.29 = trunc i32 %xor.29 to i8
  store i8 %conv10.29, i8* %x, align 1
  %conv11.29 = zext i8 %call7.29 to i32
  %scevgep8.29 = getelementptr i8, i8* %x, i64 30
  %120 = load i8, i8* %scevgep8.29, align 1
  %conv13.29 = zext i8 %120 to i32
  %xor14.29 = xor i32 %conv13.29, %conv11.29
  %conv15.29 = trunc i32 %xor14.29 to i8
  store i8 %conv15.29, i8* %scevgep8.29, align 1
  %call7.30 = call zeroext i8 (...) @rand()
  %conv8.30 = zext i8 %call7.30 to i32
  %121 = load i8, i8* %x, align 1
  %conv9.30 = zext i8 %121 to i32
  %xor.30 = xor i32 %conv9.30, %conv8.30
  %conv10.30 = trunc i32 %xor.30 to i8
  store i8 %conv10.30, i8* %x, align 1
  %conv11.30 = zext i8 %call7.30 to i32
  %scevgep8.30 = getelementptr i8, i8* %x, i64 31
  %122 = load i8, i8* %scevgep8.30, align 1
  %conv13.30 = zext i8 %122 to i32
  %xor14.30 = xor i32 %conv13.30, %conv11.30
  %conv15.30 = trunc i32 %xor14.30 to i8
  store i8 %conv15.30, i8* %scevgep8.30, align 1
  %call7.31 = call zeroext i8 (...) @rand()
  %conv8.31 = zext i8 %call7.31 to i32
  %123 = load i8, i8* %x, align 1
  %conv9.31 = zext i8 %123 to i32
  %xor.31 = xor i32 %conv9.31, %conv8.31
  %conv10.31 = trunc i32 %xor.31 to i8
  store i8 %conv10.31, i8* %x, align 1
  %conv11.31 = zext i8 %call7.31 to i32
  %scevgep8.31 = getelementptr i8, i8* %x, i64 32
  %124 = load i8, i8* %scevgep8.31, align 1
  %conv13.31 = zext i8 %124 to i32
  %xor14.31 = xor i32 %conv13.31, %conv11.31
  %conv15.31 = trunc i32 %xor14.31 to i8
  store i8 %conv15.31, i8* %scevgep8.31, align 1
  %call7.32 = call zeroext i8 (...) @rand()
  %conv8.32 = zext i8 %call7.32 to i32
  %125 = load i8, i8* %x, align 1
  %conv9.32 = zext i8 %125 to i32
  %xor.32 = xor i32 %conv9.32, %conv8.32
  %conv10.32 = trunc i32 %xor.32 to i8
  store i8 %conv10.32, i8* %x, align 1
  %conv11.32 = zext i8 %call7.32 to i32
  %scevgep8.32 = getelementptr i8, i8* %x, i64 33
  %126 = load i8, i8* %scevgep8.32, align 1
  %conv13.32 = zext i8 %126 to i32
  %xor14.32 = xor i32 %conv13.32, %conv11.32
  %conv15.32 = trunc i32 %xor14.32 to i8
  store i8 %conv15.32, i8* %scevgep8.32, align 1
  %call7.33 = call zeroext i8 (...) @rand()
  %conv8.33 = zext i8 %call7.33 to i32
  %127 = load i8, i8* %x, align 1
  %conv9.33 = zext i8 %127 to i32
  %xor.33 = xor i32 %conv9.33, %conv8.33
  %conv10.33 = trunc i32 %xor.33 to i8
  store i8 %conv10.33, i8* %x, align 1
  %conv11.33 = zext i8 %call7.33 to i32
  %scevgep8.33 = getelementptr i8, i8* %x, i64 34
  %128 = load i8, i8* %scevgep8.33, align 1
  %conv13.33 = zext i8 %128 to i32
  %xor14.33 = xor i32 %conv13.33, %conv11.33
  %conv15.33 = trunc i32 %xor14.33 to i8
  store i8 %conv15.33, i8* %scevgep8.33, align 1
  %call7.34 = call zeroext i8 (...) @rand()
  %conv8.34 = zext i8 %call7.34 to i32
  %129 = load i8, i8* %x, align 1
  %conv9.34 = zext i8 %129 to i32
  %xor.34 = xor i32 %conv9.34, %conv8.34
  %conv10.34 = trunc i32 %xor.34 to i8
  store i8 %conv10.34, i8* %x, align 1
  %conv11.34 = zext i8 %call7.34 to i32
  %scevgep8.34 = getelementptr i8, i8* %x, i64 35
  %130 = load i8, i8* %scevgep8.34, align 1
  %conv13.34 = zext i8 %130 to i32
  %xor14.34 = xor i32 %conv13.34, %conv11.34
  %conv15.34 = trunc i32 %xor14.34 to i8
  store i8 %conv15.34, i8* %scevgep8.34, align 1
  %call7.35 = call zeroext i8 (...) @rand()
  %conv8.35 = zext i8 %call7.35 to i32
  %131 = load i8, i8* %x, align 1
  %conv9.35 = zext i8 %131 to i32
  %xor.35 = xor i32 %conv9.35, %conv8.35
  %conv10.35 = trunc i32 %xor.35 to i8
  store i8 %conv10.35, i8* %x, align 1
  %conv11.35 = zext i8 %call7.35 to i32
  %scevgep8.35 = getelementptr i8, i8* %x, i64 36
  %132 = load i8, i8* %scevgep8.35, align 1
  %conv13.35 = zext i8 %132 to i32
  %xor14.35 = xor i32 %conv13.35, %conv11.35
  %conv15.35 = trunc i32 %xor14.35 to i8
  store i8 %conv15.35, i8* %scevgep8.35, align 1
  %call7.36 = call zeroext i8 (...) @rand()
  %conv8.36 = zext i8 %call7.36 to i32
  %133 = load i8, i8* %x, align 1
  %conv9.36 = zext i8 %133 to i32
  %xor.36 = xor i32 %conv9.36, %conv8.36
  %conv10.36 = trunc i32 %xor.36 to i8
  store i8 %conv10.36, i8* %x, align 1
  %conv11.36 = zext i8 %call7.36 to i32
  %scevgep8.36 = getelementptr i8, i8* %x, i64 37
  %134 = load i8, i8* %scevgep8.36, align 1
  %conv13.36 = zext i8 %134 to i32
  %xor14.36 = xor i32 %conv13.36, %conv11.36
  %conv15.36 = trunc i32 %xor14.36 to i8
  store i8 %conv15.36, i8* %scevgep8.36, align 1
  %call7.37 = call zeroext i8 (...) @rand()
  %conv8.37 = zext i8 %call7.37 to i32
  %135 = load i8, i8* %x, align 1
  %conv9.37 = zext i8 %135 to i32
  %xor.37 = xor i32 %conv9.37, %conv8.37
  %conv10.37 = trunc i32 %xor.37 to i8
  store i8 %conv10.37, i8* %x, align 1
  %conv11.37 = zext i8 %call7.37 to i32
  %scevgep8.37 = getelementptr i8, i8* %x, i64 38
  %136 = load i8, i8* %scevgep8.37, align 1
  %conv13.37 = zext i8 %136 to i32
  %xor14.37 = xor i32 %conv13.37, %conv11.37
  %conv15.37 = trunc i32 %xor14.37 to i8
  store i8 %conv15.37, i8* %scevgep8.37, align 1
  %call7.38 = call zeroext i8 (...) @rand()
  %conv8.38 = zext i8 %call7.38 to i32
  %137 = load i8, i8* %x, align 1
  %conv9.38 = zext i8 %137 to i32
  %xor.38 = xor i32 %conv9.38, %conv8.38
  %conv10.38 = trunc i32 %xor.38 to i8
  store i8 %conv10.38, i8* %x, align 1
  %conv11.38 = zext i8 %call7.38 to i32
  %scevgep8.38 = getelementptr i8, i8* %x, i64 39
  %138 = load i8, i8* %scevgep8.38, align 1
  %conv13.38 = zext i8 %138 to i32
  %xor14.38 = xor i32 %conv13.38, %conv11.38
  %conv15.38 = trunc i32 %xor14.38 to i8
  store i8 %conv15.38, i8* %scevgep8.38, align 1
  %call7.39 = call zeroext i8 (...) @rand()
  %conv8.39 = zext i8 %call7.39 to i32
  %139 = load i8, i8* %x, align 1
  %conv9.39 = zext i8 %139 to i32
  %xor.39 = xor i32 %conv9.39, %conv8.39
  %conv10.39 = trunc i32 %xor.39 to i8
  store i8 %conv10.39, i8* %x, align 1
  %conv11.39 = zext i8 %call7.39 to i32
  %scevgep8.39 = getelementptr i8, i8* %x, i64 40
  %140 = load i8, i8* %scevgep8.39, align 1
  %conv13.39 = zext i8 %140 to i32
  %xor14.39 = xor i32 %conv13.39, %conv11.39
  %conv15.39 = trunc i32 %xor14.39 to i8
  store i8 %conv15.39, i8* %scevgep8.39, align 1
  %call7.40 = call zeroext i8 (...) @rand()
  %conv8.40 = zext i8 %call7.40 to i32
  %141 = load i8, i8* %x, align 1
  %conv9.40 = zext i8 %141 to i32
  %xor.40 = xor i32 %conv9.40, %conv8.40
  %conv10.40 = trunc i32 %xor.40 to i8
  store i8 %conv10.40, i8* %x, align 1
  %conv11.40 = zext i8 %call7.40 to i32
  %scevgep8.40 = getelementptr i8, i8* %x, i64 41
  %142 = load i8, i8* %scevgep8.40, align 1
  %conv13.40 = zext i8 %142 to i32
  %xor14.40 = xor i32 %conv13.40, %conv11.40
  %conv15.40 = trunc i32 %xor14.40 to i8
  store i8 %conv15.40, i8* %scevgep8.40, align 1
  %call7.41 = call zeroext i8 (...) @rand()
  %conv8.41 = zext i8 %call7.41 to i32
  %143 = load i8, i8* %x, align 1
  %conv9.41 = zext i8 %143 to i32
  %xor.41 = xor i32 %conv9.41, %conv8.41
  %conv10.41 = trunc i32 %xor.41 to i8
  store i8 %conv10.41, i8* %x, align 1
  %conv11.41 = zext i8 %call7.41 to i32
  %scevgep8.41 = getelementptr i8, i8* %x, i64 42
  %144 = load i8, i8* %scevgep8.41, align 1
  %conv13.41 = zext i8 %144 to i32
  %xor14.41 = xor i32 %conv13.41, %conv11.41
  %conv15.41 = trunc i32 %xor14.41 to i8
  store i8 %conv15.41, i8* %scevgep8.41, align 1
  %call7.42 = call zeroext i8 (...) @rand()
  %conv8.42 = zext i8 %call7.42 to i32
  %145 = load i8, i8* %x, align 1
  %conv9.42 = zext i8 %145 to i32
  %xor.42 = xor i32 %conv9.42, %conv8.42
  %conv10.42 = trunc i32 %xor.42 to i8
  store i8 %conv10.42, i8* %x, align 1
  %conv11.42 = zext i8 %call7.42 to i32
  %scevgep8.42 = getelementptr i8, i8* %x, i64 43
  %146 = load i8, i8* %scevgep8.42, align 1
  %conv13.42 = zext i8 %146 to i32
  %xor14.42 = xor i32 %conv13.42, %conv11.42
  %conv15.42 = trunc i32 %xor14.42 to i8
  store i8 %conv15.42, i8* %scevgep8.42, align 1
  %call7.43 = call zeroext i8 (...) @rand()
  %conv8.43 = zext i8 %call7.43 to i32
  %147 = load i8, i8* %x, align 1
  %conv9.43 = zext i8 %147 to i32
  %xor.43 = xor i32 %conv9.43, %conv8.43
  %conv10.43 = trunc i32 %xor.43 to i8
  store i8 %conv10.43, i8* %x, align 1
  %conv11.43 = zext i8 %call7.43 to i32
  %scevgep8.43 = getelementptr i8, i8* %x, i64 44
  %148 = load i8, i8* %scevgep8.43, align 1
  %conv13.43 = zext i8 %148 to i32
  %xor14.43 = xor i32 %conv13.43, %conv11.43
  %conv15.43 = trunc i32 %xor14.43 to i8
  store i8 %conv15.43, i8* %scevgep8.43, align 1
  %call7.44 = call zeroext i8 (...) @rand()
  %conv8.44 = zext i8 %call7.44 to i32
  %149 = load i8, i8* %x, align 1
  %conv9.44 = zext i8 %149 to i32
  %xor.44 = xor i32 %conv9.44, %conv8.44
  %conv10.44 = trunc i32 %xor.44 to i8
  store i8 %conv10.44, i8* %x, align 1
  %conv11.44 = zext i8 %call7.44 to i32
  %scevgep8.44 = getelementptr i8, i8* %x, i64 45
  %150 = load i8, i8* %scevgep8.44, align 1
  %conv13.44 = zext i8 %150 to i32
  %xor14.44 = xor i32 %conv13.44, %conv11.44
  %conv15.44 = trunc i32 %xor14.44 to i8
  store i8 %conv15.44, i8* %scevgep8.44, align 1
  %call7.45 = call zeroext i8 (...) @rand()
  %conv8.45 = zext i8 %call7.45 to i32
  %151 = load i8, i8* %x, align 1
  %conv9.45 = zext i8 %151 to i32
  %xor.45 = xor i32 %conv9.45, %conv8.45
  %conv10.45 = trunc i32 %xor.45 to i8
  store i8 %conv10.45, i8* %x, align 1
  %conv11.45 = zext i8 %call7.45 to i32
  %scevgep8.45 = getelementptr i8, i8* %x, i64 46
  %152 = load i8, i8* %scevgep8.45, align 1
  %conv13.45 = zext i8 %152 to i32
  %xor14.45 = xor i32 %conv13.45, %conv11.45
  %conv15.45 = trunc i32 %xor14.45 to i8
  store i8 %conv15.45, i8* %scevgep8.45, align 1
  %call7.46 = call zeroext i8 (...) @rand()
  %conv8.46 = zext i8 %call7.46 to i32
  %153 = load i8, i8* %x, align 1
  %conv9.46 = zext i8 %153 to i32
  %xor.46 = xor i32 %conv9.46, %conv8.46
  %conv10.46 = trunc i32 %xor.46 to i8
  store i8 %conv10.46, i8* %x, align 1
  %conv11.46 = zext i8 %call7.46 to i32
  %scevgep8.46 = getelementptr i8, i8* %x, i64 47
  %154 = load i8, i8* %scevgep8.46, align 1
  %conv13.46 = zext i8 %154 to i32
  %xor14.46 = xor i32 %conv13.46, %conv11.46
  %conv15.46 = trunc i32 %xor14.46 to i8
  store i8 %conv15.46, i8* %scevgep8.46, align 1
  %call7.47 = call zeroext i8 (...) @rand()
  %conv8.47 = zext i8 %call7.47 to i32
  %155 = load i8, i8* %x, align 1
  %conv9.47 = zext i8 %155 to i32
  %xor.47 = xor i32 %conv9.47, %conv8.47
  %conv10.47 = trunc i32 %xor.47 to i8
  store i8 %conv10.47, i8* %x, align 1
  %conv11.47 = zext i8 %call7.47 to i32
  %scevgep8.47 = getelementptr i8, i8* %x, i64 48
  %156 = load i8, i8* %scevgep8.47, align 1
  %conv13.47 = zext i8 %156 to i32
  %xor14.47 = xor i32 %conv13.47, %conv11.47
  %conv15.47 = trunc i32 %xor14.47 to i8
  store i8 %conv15.47, i8* %scevgep8.47, align 1
  %call7.48 = call zeroext i8 (...) @rand()
  %conv8.48 = zext i8 %call7.48 to i32
  %157 = load i8, i8* %x, align 1
  %conv9.48 = zext i8 %157 to i32
  %xor.48 = xor i32 %conv9.48, %conv8.48
  %conv10.48 = trunc i32 %xor.48 to i8
  store i8 %conv10.48, i8* %x, align 1
  %conv11.48 = zext i8 %call7.48 to i32
  %scevgep8.48 = getelementptr i8, i8* %x, i64 49
  %158 = load i8, i8* %scevgep8.48, align 1
  %conv13.48 = zext i8 %158 to i32
  %xor14.48 = xor i32 %conv13.48, %conv11.48
  %conv15.48 = trunc i32 %xor14.48 to i8
  store i8 %conv15.48, i8* %scevgep8.48, align 1
  %call7.49 = call zeroext i8 (...) @rand()
  %conv8.49 = zext i8 %call7.49 to i32
  %159 = load i8, i8* %x, align 1
  %conv9.49 = zext i8 %159 to i32
  %xor.49 = xor i32 %conv9.49, %conv8.49
  %conv10.49 = trunc i32 %xor.49 to i8
  store i8 %conv10.49, i8* %x, align 1
  %conv11.49 = zext i8 %call7.49 to i32
  %scevgep8.49 = getelementptr i8, i8* %x, i64 50
  %160 = load i8, i8* %scevgep8.49, align 1
  %conv13.49 = zext i8 %160 to i32
  %xor14.49 = xor i32 %conv13.49, %conv11.49
  %conv15.49 = trunc i32 %xor14.49 to i8
  store i8 %conv15.49, i8* %scevgep8.49, align 1
  %call7.50 = call zeroext i8 (...) @rand()
  %conv8.50 = zext i8 %call7.50 to i32
  %161 = load i8, i8* %x, align 1
  %conv9.50 = zext i8 %161 to i32
  %xor.50 = xor i32 %conv9.50, %conv8.50
  %conv10.50 = trunc i32 %xor.50 to i8
  store i8 %conv10.50, i8* %x, align 1
  %conv11.50 = zext i8 %call7.50 to i32
  %scevgep8.50 = getelementptr i8, i8* %x, i64 51
  %162 = load i8, i8* %scevgep8.50, align 1
  %conv13.50 = zext i8 %162 to i32
  %xor14.50 = xor i32 %conv13.50, %conv11.50
  %conv15.50 = trunc i32 %xor14.50 to i8
  store i8 %conv15.50, i8* %scevgep8.50, align 1
  %call7.51 = call zeroext i8 (...) @rand()
  %conv8.51 = zext i8 %call7.51 to i32
  %163 = load i8, i8* %x, align 1
  %conv9.51 = zext i8 %163 to i32
  %xor.51 = xor i32 %conv9.51, %conv8.51
  %conv10.51 = trunc i32 %xor.51 to i8
  store i8 %conv10.51, i8* %x, align 1
  %conv11.51 = zext i8 %call7.51 to i32
  %scevgep8.51 = getelementptr i8, i8* %x, i64 52
  %164 = load i8, i8* %scevgep8.51, align 1
  %conv13.51 = zext i8 %164 to i32
  %xor14.51 = xor i32 %conv13.51, %conv11.51
  %conv15.51 = trunc i32 %xor14.51 to i8
  store i8 %conv15.51, i8* %scevgep8.51, align 1
  %call7.52 = call zeroext i8 (...) @rand()
  %conv8.52 = zext i8 %call7.52 to i32
  %165 = load i8, i8* %x, align 1
  %conv9.52 = zext i8 %165 to i32
  %xor.52 = xor i32 %conv9.52, %conv8.52
  %conv10.52 = trunc i32 %xor.52 to i8
  store i8 %conv10.52, i8* %x, align 1
  %conv11.52 = zext i8 %call7.52 to i32
  %scevgep8.52 = getelementptr i8, i8* %x, i64 53
  %166 = load i8, i8* %scevgep8.52, align 1
  %conv13.52 = zext i8 %166 to i32
  %xor14.52 = xor i32 %conv13.52, %conv11.52
  %conv15.52 = trunc i32 %xor14.52 to i8
  store i8 %conv15.52, i8* %scevgep8.52, align 1
  %call7.53 = call zeroext i8 (...) @rand()
  %conv8.53 = zext i8 %call7.53 to i32
  %167 = load i8, i8* %x, align 1
  %conv9.53 = zext i8 %167 to i32
  %xor.53 = xor i32 %conv9.53, %conv8.53
  %conv10.53 = trunc i32 %xor.53 to i8
  store i8 %conv10.53, i8* %x, align 1
  %conv11.53 = zext i8 %call7.53 to i32
  %scevgep8.53 = getelementptr i8, i8* %x, i64 54
  %168 = load i8, i8* %scevgep8.53, align 1
  %conv13.53 = zext i8 %168 to i32
  %xor14.53 = xor i32 %conv13.53, %conv11.53
  %conv15.53 = trunc i32 %xor14.53 to i8
  store i8 %conv15.53, i8* %scevgep8.53, align 1
  %call7.54 = call zeroext i8 (...) @rand()
  %conv8.54 = zext i8 %call7.54 to i32
  %169 = load i8, i8* %x, align 1
  %conv9.54 = zext i8 %169 to i32
  %xor.54 = xor i32 %conv9.54, %conv8.54
  %conv10.54 = trunc i32 %xor.54 to i8
  store i8 %conv10.54, i8* %x, align 1
  %conv11.54 = zext i8 %call7.54 to i32
  %scevgep8.54 = getelementptr i8, i8* %x, i64 55
  %170 = load i8, i8* %scevgep8.54, align 1
  %conv13.54 = zext i8 %170 to i32
  %xor14.54 = xor i32 %conv13.54, %conv11.54
  %conv15.54 = trunc i32 %xor14.54 to i8
  store i8 %conv15.54, i8* %scevgep8.54, align 1
  %call7.55 = call zeroext i8 (...) @rand()
  %conv8.55 = zext i8 %call7.55 to i32
  %171 = load i8, i8* %x, align 1
  %conv9.55 = zext i8 %171 to i32
  %xor.55 = xor i32 %conv9.55, %conv8.55
  %conv10.55 = trunc i32 %xor.55 to i8
  store i8 %conv10.55, i8* %x, align 1
  %conv11.55 = zext i8 %call7.55 to i32
  %scevgep8.55 = getelementptr i8, i8* %x, i64 56
  %172 = load i8, i8* %scevgep8.55, align 1
  %conv13.55 = zext i8 %172 to i32
  %xor14.55 = xor i32 %conv13.55, %conv11.55
  %conv15.55 = trunc i32 %xor14.55 to i8
  store i8 %conv15.55, i8* %scevgep8.55, align 1
  %call7.56 = call zeroext i8 (...) @rand()
  %conv8.56 = zext i8 %call7.56 to i32
  %173 = load i8, i8* %x, align 1
  %conv9.56 = zext i8 %173 to i32
  %xor.56 = xor i32 %conv9.56, %conv8.56
  %conv10.56 = trunc i32 %xor.56 to i8
  store i8 %conv10.56, i8* %x, align 1
  %conv11.56 = zext i8 %call7.56 to i32
  %scevgep8.56 = getelementptr i8, i8* %x, i64 57
  %174 = load i8, i8* %scevgep8.56, align 1
  %conv13.56 = zext i8 %174 to i32
  %xor14.56 = xor i32 %conv13.56, %conv11.56
  %conv15.56 = trunc i32 %xor14.56 to i8
  store i8 %conv15.56, i8* %scevgep8.56, align 1
  %call7.57 = call zeroext i8 (...) @rand()
  %conv8.57 = zext i8 %call7.57 to i32
  %175 = load i8, i8* %x, align 1
  %conv9.57 = zext i8 %175 to i32
  %xor.57 = xor i32 %conv9.57, %conv8.57
  %conv10.57 = trunc i32 %xor.57 to i8
  store i8 %conv10.57, i8* %x, align 1
  %conv11.57 = zext i8 %call7.57 to i32
  %scevgep8.57 = getelementptr i8, i8* %x, i64 58
  %176 = load i8, i8* %scevgep8.57, align 1
  %conv13.57 = zext i8 %176 to i32
  %xor14.57 = xor i32 %conv13.57, %conv11.57
  %conv15.57 = trunc i32 %xor14.57 to i8
  store i8 %conv15.57, i8* %scevgep8.57, align 1
  %call7.58 = call zeroext i8 (...) @rand()
  %conv8.58 = zext i8 %call7.58 to i32
  %177 = load i8, i8* %x, align 1
  %conv9.58 = zext i8 %177 to i32
  %xor.58 = xor i32 %conv9.58, %conv8.58
  %conv10.58 = trunc i32 %xor.58 to i8
  store i8 %conv10.58, i8* %x, align 1
  %conv11.58 = zext i8 %call7.58 to i32
  %scevgep8.58 = getelementptr i8, i8* %x, i64 59
  %178 = load i8, i8* %scevgep8.58, align 1
  %conv13.58 = zext i8 %178 to i32
  %xor14.58 = xor i32 %conv13.58, %conv11.58
  %conv15.58 = trunc i32 %xor14.58 to i8
  store i8 %conv15.58, i8* %scevgep8.58, align 1
  %call7.59 = call zeroext i8 (...) @rand()
  %conv8.59 = zext i8 %call7.59 to i32
  %179 = load i8, i8* %x, align 1
  %conv9.59 = zext i8 %179 to i32
  %xor.59 = xor i32 %conv9.59, %conv8.59
  %conv10.59 = trunc i32 %xor.59 to i8
  store i8 %conv10.59, i8* %x, align 1
  %conv11.59 = zext i8 %call7.59 to i32
  %scevgep8.59 = getelementptr i8, i8* %x, i64 60
  %180 = load i8, i8* %scevgep8.59, align 1
  %conv13.59 = zext i8 %180 to i32
  %xor14.59 = xor i32 %conv13.59, %conv11.59
  %conv15.59 = trunc i32 %xor14.59 to i8
  store i8 %conv15.59, i8* %scevgep8.59, align 1
  %conv16 = zext i8 %call to i32
  %181 = load i8, i8* %x, align 1
  %scevgep.1 = getelementptr i8, i8* %x, i64 1
  %182 = load i8, i8* %scevgep.1, align 1
  %conv.i.i31.1 = zext i8 %182 to i32
  %conv1.i.i32.1 = zext i8 %181 to i32
  %xor.i.i33.1 = xor i32 %conv1.i.i32.1, %conv.i.i31.1
  %conv2.i.i34.1 = trunc i32 %xor.i.i33.1 to i8
  %scevgep.2 = getelementptr i8, i8* %x, i64 2
  %183 = load i8, i8* %scevgep.2, align 1
  %conv.i.i31.2 = zext i8 %183 to i32
  %conv1.i.i32.2 = zext i8 %conv2.i.i34.1 to i32
  %xor.i.i33.2 = xor i32 %conv1.i.i32.2, %conv.i.i31.2
  %conv2.i.i34.2 = trunc i32 %xor.i.i33.2 to i8
  %scevgep.3 = getelementptr i8, i8* %x, i64 3
  %184 = load i8, i8* %scevgep.3, align 1
  %conv.i.i31.3 = zext i8 %184 to i32
  %conv1.i.i32.3 = zext i8 %conv2.i.i34.2 to i32
  %xor.i.i33.3 = xor i32 %conv1.i.i32.3, %conv.i.i31.3
  %conv2.i.i34.3 = trunc i32 %xor.i.i33.3 to i8
  %scevgep.4 = getelementptr i8, i8* %x, i64 4
  %185 = load i8, i8* %scevgep.4, align 1
  %conv.i.i31.4 = zext i8 %185 to i32
  %conv1.i.i32.4 = zext i8 %conv2.i.i34.3 to i32
  %xor.i.i33.4 = xor i32 %conv1.i.i32.4, %conv.i.i31.4
  %conv2.i.i34.4 = trunc i32 %xor.i.i33.4 to i8
  %scevgep.5 = getelementptr i8, i8* %x, i64 5
  %186 = load i8, i8* %scevgep.5, align 1
  %conv.i.i31.5 = zext i8 %186 to i32
  %conv1.i.i32.5 = zext i8 %conv2.i.i34.4 to i32
  %xor.i.i33.5 = xor i32 %conv1.i.i32.5, %conv.i.i31.5
  %conv2.i.i34.5 = trunc i32 %xor.i.i33.5 to i8
  %scevgep.6 = getelementptr i8, i8* %x, i64 6
  %187 = load i8, i8* %scevgep.6, align 1
  %conv.i.i31.6 = zext i8 %187 to i32
  %conv1.i.i32.6 = zext i8 %conv2.i.i34.5 to i32
  %xor.i.i33.6 = xor i32 %conv1.i.i32.6, %conv.i.i31.6
  %conv2.i.i34.6 = trunc i32 %xor.i.i33.6 to i8
  %scevgep.7 = getelementptr i8, i8* %x, i64 7
  %188 = load i8, i8* %scevgep.7, align 1
  %conv.i.i31.7 = zext i8 %188 to i32
  %conv1.i.i32.7 = zext i8 %conv2.i.i34.6 to i32
  %xor.i.i33.7 = xor i32 %conv1.i.i32.7, %conv.i.i31.7
  %conv2.i.i34.7 = trunc i32 %xor.i.i33.7 to i8
  %scevgep.8 = getelementptr i8, i8* %x, i64 8
  %189 = load i8, i8* %scevgep.8, align 1
  %conv.i.i31.8 = zext i8 %189 to i32
  %conv1.i.i32.8 = zext i8 %conv2.i.i34.7 to i32
  %xor.i.i33.8 = xor i32 %conv1.i.i32.8, %conv.i.i31.8
  %conv2.i.i34.8 = trunc i32 %xor.i.i33.8 to i8
  %scevgep.9 = getelementptr i8, i8* %x, i64 9
  %190 = load i8, i8* %scevgep.9, align 1
  %conv.i.i31.9 = zext i8 %190 to i32
  %conv1.i.i32.9 = zext i8 %conv2.i.i34.8 to i32
  %xor.i.i33.9 = xor i32 %conv1.i.i32.9, %conv.i.i31.9
  %conv2.i.i34.9 = trunc i32 %xor.i.i33.9 to i8
  %scevgep.10 = getelementptr i8, i8* %x, i64 10
  %191 = load i8, i8* %scevgep.10, align 1
  %conv.i.i31.10 = zext i8 %191 to i32
  %conv1.i.i32.10 = zext i8 %conv2.i.i34.9 to i32
  %xor.i.i33.10 = xor i32 %conv1.i.i32.10, %conv.i.i31.10
  %conv2.i.i34.10 = trunc i32 %xor.i.i33.10 to i8
  %scevgep.11 = getelementptr i8, i8* %x, i64 11
  %192 = load i8, i8* %scevgep.11, align 1
  %conv.i.i31.11 = zext i8 %192 to i32
  %conv1.i.i32.11 = zext i8 %conv2.i.i34.10 to i32
  %xor.i.i33.11 = xor i32 %conv1.i.i32.11, %conv.i.i31.11
  %conv2.i.i34.11 = trunc i32 %xor.i.i33.11 to i8
  %scevgep.12 = getelementptr i8, i8* %x, i64 12
  %193 = load i8, i8* %scevgep.12, align 1
  %conv.i.i31.12 = zext i8 %193 to i32
  %conv1.i.i32.12 = zext i8 %conv2.i.i34.11 to i32
  %xor.i.i33.12 = xor i32 %conv1.i.i32.12, %conv.i.i31.12
  %conv2.i.i34.12 = trunc i32 %xor.i.i33.12 to i8
  %scevgep.13 = getelementptr i8, i8* %x, i64 13
  %194 = load i8, i8* %scevgep.13, align 1
  %conv.i.i31.13 = zext i8 %194 to i32
  %conv1.i.i32.13 = zext i8 %conv2.i.i34.12 to i32
  %xor.i.i33.13 = xor i32 %conv1.i.i32.13, %conv.i.i31.13
  %conv2.i.i34.13 = trunc i32 %xor.i.i33.13 to i8
  %scevgep.14 = getelementptr i8, i8* %x, i64 14
  %195 = load i8, i8* %scevgep.14, align 1
  %conv.i.i31.14 = zext i8 %195 to i32
  %conv1.i.i32.14 = zext i8 %conv2.i.i34.13 to i32
  %xor.i.i33.14 = xor i32 %conv1.i.i32.14, %conv.i.i31.14
  %conv2.i.i34.14 = trunc i32 %xor.i.i33.14 to i8
  %scevgep.15 = getelementptr i8, i8* %x, i64 15
  %196 = load i8, i8* %scevgep.15, align 1
  %conv.i.i31.15 = zext i8 %196 to i32
  %conv1.i.i32.15 = zext i8 %conv2.i.i34.14 to i32
  %xor.i.i33.15 = xor i32 %conv1.i.i32.15, %conv.i.i31.15
  %conv2.i.i34.15 = trunc i32 %xor.i.i33.15 to i8
  %scevgep.16 = getelementptr i8, i8* %x, i64 16
  %197 = load i8, i8* %scevgep.16, align 1
  %conv.i.i31.16 = zext i8 %197 to i32
  %conv1.i.i32.16 = zext i8 %conv2.i.i34.15 to i32
  %xor.i.i33.16 = xor i32 %conv1.i.i32.16, %conv.i.i31.16
  %conv2.i.i34.16 = trunc i32 %xor.i.i33.16 to i8
  %scevgep.17 = getelementptr i8, i8* %x, i64 17
  %198 = load i8, i8* %scevgep.17, align 1
  %conv.i.i31.17 = zext i8 %198 to i32
  %conv1.i.i32.17 = zext i8 %conv2.i.i34.16 to i32
  %xor.i.i33.17 = xor i32 %conv1.i.i32.17, %conv.i.i31.17
  %conv2.i.i34.17 = trunc i32 %xor.i.i33.17 to i8
  %scevgep.18 = getelementptr i8, i8* %x, i64 18
  %199 = load i8, i8* %scevgep.18, align 1
  %conv.i.i31.18 = zext i8 %199 to i32
  %conv1.i.i32.18 = zext i8 %conv2.i.i34.17 to i32
  %xor.i.i33.18 = xor i32 %conv1.i.i32.18, %conv.i.i31.18
  %conv2.i.i34.18 = trunc i32 %xor.i.i33.18 to i8
  %scevgep.19 = getelementptr i8, i8* %x, i64 19
  %200 = load i8, i8* %scevgep.19, align 1
  %conv.i.i31.19 = zext i8 %200 to i32
  %conv1.i.i32.19 = zext i8 %conv2.i.i34.18 to i32
  %xor.i.i33.19 = xor i32 %conv1.i.i32.19, %conv.i.i31.19
  %conv2.i.i34.19 = trunc i32 %xor.i.i33.19 to i8
  %scevgep.20 = getelementptr i8, i8* %x, i64 20
  %201 = load i8, i8* %scevgep.20, align 1
  %conv.i.i31.20 = zext i8 %201 to i32
  %conv1.i.i32.20 = zext i8 %conv2.i.i34.19 to i32
  %xor.i.i33.20 = xor i32 %conv1.i.i32.20, %conv.i.i31.20
  %conv2.i.i34.20 = trunc i32 %xor.i.i33.20 to i8
  %scevgep.21 = getelementptr i8, i8* %x, i64 21
  %202 = load i8, i8* %scevgep.21, align 1
  %conv.i.i31.21 = zext i8 %202 to i32
  %conv1.i.i32.21 = zext i8 %conv2.i.i34.20 to i32
  %xor.i.i33.21 = xor i32 %conv1.i.i32.21, %conv.i.i31.21
  %conv2.i.i34.21 = trunc i32 %xor.i.i33.21 to i8
  %scevgep.22 = getelementptr i8, i8* %x, i64 22
  %203 = load i8, i8* %scevgep.22, align 1
  %conv.i.i31.22 = zext i8 %203 to i32
  %conv1.i.i32.22 = zext i8 %conv2.i.i34.21 to i32
  %xor.i.i33.22 = xor i32 %conv1.i.i32.22, %conv.i.i31.22
  %conv2.i.i34.22 = trunc i32 %xor.i.i33.22 to i8
  %scevgep.23 = getelementptr i8, i8* %x, i64 23
  %204 = load i8, i8* %scevgep.23, align 1
  %conv.i.i31.23 = zext i8 %204 to i32
  %conv1.i.i32.23 = zext i8 %conv2.i.i34.22 to i32
  %xor.i.i33.23 = xor i32 %conv1.i.i32.23, %conv.i.i31.23
  %conv2.i.i34.23 = trunc i32 %xor.i.i33.23 to i8
  %scevgep.24 = getelementptr i8, i8* %x, i64 24
  %205 = load i8, i8* %scevgep.24, align 1
  %conv.i.i31.24 = zext i8 %205 to i32
  %conv1.i.i32.24 = zext i8 %conv2.i.i34.23 to i32
  %xor.i.i33.24 = xor i32 %conv1.i.i32.24, %conv.i.i31.24
  %conv2.i.i34.24 = trunc i32 %xor.i.i33.24 to i8
  %scevgep.25 = getelementptr i8, i8* %x, i64 25
  %206 = load i8, i8* %scevgep.25, align 1
  %conv.i.i31.25 = zext i8 %206 to i32
  %conv1.i.i32.25 = zext i8 %conv2.i.i34.24 to i32
  %xor.i.i33.25 = xor i32 %conv1.i.i32.25, %conv.i.i31.25
  %conv2.i.i34.25 = trunc i32 %xor.i.i33.25 to i8
  %scevgep.26 = getelementptr i8, i8* %x, i64 26
  %207 = load i8, i8* %scevgep.26, align 1
  %conv.i.i31.26 = zext i8 %207 to i32
  %conv1.i.i32.26 = zext i8 %conv2.i.i34.25 to i32
  %xor.i.i33.26 = xor i32 %conv1.i.i32.26, %conv.i.i31.26
  %conv2.i.i34.26 = trunc i32 %xor.i.i33.26 to i8
  %scevgep.27 = getelementptr i8, i8* %x, i64 27
  %208 = load i8, i8* %scevgep.27, align 1
  %conv.i.i31.27 = zext i8 %208 to i32
  %conv1.i.i32.27 = zext i8 %conv2.i.i34.26 to i32
  %xor.i.i33.27 = xor i32 %conv1.i.i32.27, %conv.i.i31.27
  %conv2.i.i34.27 = trunc i32 %xor.i.i33.27 to i8
  %scevgep.28 = getelementptr i8, i8* %x, i64 28
  %209 = load i8, i8* %scevgep.28, align 1
  %conv.i.i31.28 = zext i8 %209 to i32
  %conv1.i.i32.28 = zext i8 %conv2.i.i34.27 to i32
  %xor.i.i33.28 = xor i32 %conv1.i.i32.28, %conv.i.i31.28
  %conv2.i.i34.28 = trunc i32 %xor.i.i33.28 to i8
  %scevgep.29 = getelementptr i8, i8* %x, i64 29
  %210 = load i8, i8* %scevgep.29, align 1
  %conv.i.i31.29 = zext i8 %210 to i32
  %conv1.i.i32.29 = zext i8 %conv2.i.i34.28 to i32
  %xor.i.i33.29 = xor i32 %conv1.i.i32.29, %conv.i.i31.29
  %conv2.i.i34.29 = trunc i32 %xor.i.i33.29 to i8
  %scevgep.30 = getelementptr i8, i8* %x, i64 30
  %211 = load i8, i8* %scevgep.30, align 1
  %conv.i.i31.30 = zext i8 %211 to i32
  %conv1.i.i32.30 = zext i8 %conv2.i.i34.29 to i32
  %xor.i.i33.30 = xor i32 %conv1.i.i32.30, %conv.i.i31.30
  %conv2.i.i34.30 = trunc i32 %xor.i.i33.30 to i8
  %scevgep.31 = getelementptr i8, i8* %x, i64 31
  %212 = load i8, i8* %scevgep.31, align 1
  %conv.i.i31.31 = zext i8 %212 to i32
  %conv1.i.i32.31 = zext i8 %conv2.i.i34.30 to i32
  %xor.i.i33.31 = xor i32 %conv1.i.i32.31, %conv.i.i31.31
  %conv2.i.i34.31 = trunc i32 %xor.i.i33.31 to i8
  %scevgep.32 = getelementptr i8, i8* %x, i64 32
  %213 = load i8, i8* %scevgep.32, align 1
  %conv.i.i31.32 = zext i8 %213 to i32
  %conv1.i.i32.32 = zext i8 %conv2.i.i34.31 to i32
  %xor.i.i33.32 = xor i32 %conv1.i.i32.32, %conv.i.i31.32
  %conv2.i.i34.32 = trunc i32 %xor.i.i33.32 to i8
  %scevgep.33 = getelementptr i8, i8* %x, i64 33
  %214 = load i8, i8* %scevgep.33, align 1
  %conv.i.i31.33 = zext i8 %214 to i32
  %conv1.i.i32.33 = zext i8 %conv2.i.i34.32 to i32
  %xor.i.i33.33 = xor i32 %conv1.i.i32.33, %conv.i.i31.33
  %conv2.i.i34.33 = trunc i32 %xor.i.i33.33 to i8
  %scevgep.34 = getelementptr i8, i8* %x, i64 34
  %215 = load i8, i8* %scevgep.34, align 1
  %conv.i.i31.34 = zext i8 %215 to i32
  %conv1.i.i32.34 = zext i8 %conv2.i.i34.33 to i32
  %xor.i.i33.34 = xor i32 %conv1.i.i32.34, %conv.i.i31.34
  %conv2.i.i34.34 = trunc i32 %xor.i.i33.34 to i8
  %scevgep.35 = getelementptr i8, i8* %x, i64 35
  %216 = load i8, i8* %scevgep.35, align 1
  %conv.i.i31.35 = zext i8 %216 to i32
  %conv1.i.i32.35 = zext i8 %conv2.i.i34.34 to i32
  %xor.i.i33.35 = xor i32 %conv1.i.i32.35, %conv.i.i31.35
  %conv2.i.i34.35 = trunc i32 %xor.i.i33.35 to i8
  %scevgep.36 = getelementptr i8, i8* %x, i64 36
  %217 = load i8, i8* %scevgep.36, align 1
  %conv.i.i31.36 = zext i8 %217 to i32
  %conv1.i.i32.36 = zext i8 %conv2.i.i34.35 to i32
  %xor.i.i33.36 = xor i32 %conv1.i.i32.36, %conv.i.i31.36
  %conv2.i.i34.36 = trunc i32 %xor.i.i33.36 to i8
  %scevgep.37 = getelementptr i8, i8* %x, i64 37
  %218 = load i8, i8* %scevgep.37, align 1
  %conv.i.i31.37 = zext i8 %218 to i32
  %conv1.i.i32.37 = zext i8 %conv2.i.i34.36 to i32
  %xor.i.i33.37 = xor i32 %conv1.i.i32.37, %conv.i.i31.37
  %conv2.i.i34.37 = trunc i32 %xor.i.i33.37 to i8
  %scevgep.38 = getelementptr i8, i8* %x, i64 38
  %219 = load i8, i8* %scevgep.38, align 1
  %conv.i.i31.38 = zext i8 %219 to i32
  %conv1.i.i32.38 = zext i8 %conv2.i.i34.37 to i32
  %xor.i.i33.38 = xor i32 %conv1.i.i32.38, %conv.i.i31.38
  %conv2.i.i34.38 = trunc i32 %xor.i.i33.38 to i8
  %scevgep.39 = getelementptr i8, i8* %x, i64 39
  %220 = load i8, i8* %scevgep.39, align 1
  %conv.i.i31.39 = zext i8 %220 to i32
  %conv1.i.i32.39 = zext i8 %conv2.i.i34.38 to i32
  %xor.i.i33.39 = xor i32 %conv1.i.i32.39, %conv.i.i31.39
  %conv2.i.i34.39 = trunc i32 %xor.i.i33.39 to i8
  %scevgep.40 = getelementptr i8, i8* %x, i64 40
  %221 = load i8, i8* %scevgep.40, align 1
  %conv.i.i31.40 = zext i8 %221 to i32
  %conv1.i.i32.40 = zext i8 %conv2.i.i34.39 to i32
  %xor.i.i33.40 = xor i32 %conv1.i.i32.40, %conv.i.i31.40
  %conv2.i.i34.40 = trunc i32 %xor.i.i33.40 to i8
  %scevgep.41 = getelementptr i8, i8* %x, i64 41
  %222 = load i8, i8* %scevgep.41, align 1
  %conv.i.i31.41 = zext i8 %222 to i32
  %conv1.i.i32.41 = zext i8 %conv2.i.i34.40 to i32
  %xor.i.i33.41 = xor i32 %conv1.i.i32.41, %conv.i.i31.41
  %conv2.i.i34.41 = trunc i32 %xor.i.i33.41 to i8
  %scevgep.42 = getelementptr i8, i8* %x, i64 42
  %223 = load i8, i8* %scevgep.42, align 1
  %conv.i.i31.42 = zext i8 %223 to i32
  %conv1.i.i32.42 = zext i8 %conv2.i.i34.41 to i32
  %xor.i.i33.42 = xor i32 %conv1.i.i32.42, %conv.i.i31.42
  %conv2.i.i34.42 = trunc i32 %xor.i.i33.42 to i8
  %scevgep.43 = getelementptr i8, i8* %x, i64 43
  %224 = load i8, i8* %scevgep.43, align 1
  %conv.i.i31.43 = zext i8 %224 to i32
  %conv1.i.i32.43 = zext i8 %conv2.i.i34.42 to i32
  %xor.i.i33.43 = xor i32 %conv1.i.i32.43, %conv.i.i31.43
  %conv2.i.i34.43 = trunc i32 %xor.i.i33.43 to i8
  %scevgep.44 = getelementptr i8, i8* %x, i64 44
  %225 = load i8, i8* %scevgep.44, align 1
  %conv.i.i31.44 = zext i8 %225 to i32
  %conv1.i.i32.44 = zext i8 %conv2.i.i34.43 to i32
  %xor.i.i33.44 = xor i32 %conv1.i.i32.44, %conv.i.i31.44
  %conv2.i.i34.44 = trunc i32 %xor.i.i33.44 to i8
  %scevgep.45 = getelementptr i8, i8* %x, i64 45
  %226 = load i8, i8* %scevgep.45, align 1
  %conv.i.i31.45 = zext i8 %226 to i32
  %conv1.i.i32.45 = zext i8 %conv2.i.i34.44 to i32
  %xor.i.i33.45 = xor i32 %conv1.i.i32.45, %conv.i.i31.45
  %conv2.i.i34.45 = trunc i32 %xor.i.i33.45 to i8
  %scevgep.46 = getelementptr i8, i8* %x, i64 46
  %227 = load i8, i8* %scevgep.46, align 1
  %conv.i.i31.46 = zext i8 %227 to i32
  %conv1.i.i32.46 = zext i8 %conv2.i.i34.45 to i32
  %xor.i.i33.46 = xor i32 %conv1.i.i32.46, %conv.i.i31.46
  %conv2.i.i34.46 = trunc i32 %xor.i.i33.46 to i8
  %scevgep.47 = getelementptr i8, i8* %x, i64 47
  %228 = load i8, i8* %scevgep.47, align 1
  %conv.i.i31.47 = zext i8 %228 to i32
  %conv1.i.i32.47 = zext i8 %conv2.i.i34.46 to i32
  %xor.i.i33.47 = xor i32 %conv1.i.i32.47, %conv.i.i31.47
  %conv2.i.i34.47 = trunc i32 %xor.i.i33.47 to i8
  %scevgep.48 = getelementptr i8, i8* %x, i64 48
  %229 = load i8, i8* %scevgep.48, align 1
  %conv.i.i31.48 = zext i8 %229 to i32
  %conv1.i.i32.48 = zext i8 %conv2.i.i34.47 to i32
  %xor.i.i33.48 = xor i32 %conv1.i.i32.48, %conv.i.i31.48
  %conv2.i.i34.48 = trunc i32 %xor.i.i33.48 to i8
  %scevgep.49 = getelementptr i8, i8* %x, i64 49
  %230 = load i8, i8* %scevgep.49, align 1
  %conv.i.i31.49 = zext i8 %230 to i32
  %conv1.i.i32.49 = zext i8 %conv2.i.i34.48 to i32
  %xor.i.i33.49 = xor i32 %conv1.i.i32.49, %conv.i.i31.49
  %conv2.i.i34.49 = trunc i32 %xor.i.i33.49 to i8
  %scevgep.50 = getelementptr i8, i8* %x, i64 50
  %231 = load i8, i8* %scevgep.50, align 1
  %conv.i.i31.50 = zext i8 %231 to i32
  %conv1.i.i32.50 = zext i8 %conv2.i.i34.49 to i32
  %xor.i.i33.50 = xor i32 %conv1.i.i32.50, %conv.i.i31.50
  %conv2.i.i34.50 = trunc i32 %xor.i.i33.50 to i8
  %scevgep.51 = getelementptr i8, i8* %x, i64 51
  %232 = load i8, i8* %scevgep.51, align 1
  %conv.i.i31.51 = zext i8 %232 to i32
  %conv1.i.i32.51 = zext i8 %conv2.i.i34.50 to i32
  %xor.i.i33.51 = xor i32 %conv1.i.i32.51, %conv.i.i31.51
  %conv2.i.i34.51 = trunc i32 %xor.i.i33.51 to i8
  %scevgep.52 = getelementptr i8, i8* %x, i64 52
  %233 = load i8, i8* %scevgep.52, align 1
  %conv.i.i31.52 = zext i8 %233 to i32
  %conv1.i.i32.52 = zext i8 %conv2.i.i34.51 to i32
  %xor.i.i33.52 = xor i32 %conv1.i.i32.52, %conv.i.i31.52
  %conv2.i.i34.52 = trunc i32 %xor.i.i33.52 to i8
  %scevgep.53 = getelementptr i8, i8* %x, i64 53
  %234 = load i8, i8* %scevgep.53, align 1
  %conv.i.i31.53 = zext i8 %234 to i32
  %conv1.i.i32.53 = zext i8 %conv2.i.i34.52 to i32
  %xor.i.i33.53 = xor i32 %conv1.i.i32.53, %conv.i.i31.53
  %conv2.i.i34.53 = trunc i32 %xor.i.i33.53 to i8
  %scevgep.54 = getelementptr i8, i8* %x, i64 54
  %235 = load i8, i8* %scevgep.54, align 1
  %conv.i.i31.54 = zext i8 %235 to i32
  %conv1.i.i32.54 = zext i8 %conv2.i.i34.53 to i32
  %xor.i.i33.54 = xor i32 %conv1.i.i32.54, %conv.i.i31.54
  %conv2.i.i34.54 = trunc i32 %xor.i.i33.54 to i8
  %scevgep.55 = getelementptr i8, i8* %x, i64 55
  %236 = load i8, i8* %scevgep.55, align 1
  %conv.i.i31.55 = zext i8 %236 to i32
  %conv1.i.i32.55 = zext i8 %conv2.i.i34.54 to i32
  %xor.i.i33.55 = xor i32 %conv1.i.i32.55, %conv.i.i31.55
  %conv2.i.i34.55 = trunc i32 %xor.i.i33.55 to i8
  %scevgep.56 = getelementptr i8, i8* %x, i64 56
  %237 = load i8, i8* %scevgep.56, align 1
  %conv.i.i31.56 = zext i8 %237 to i32
  %conv1.i.i32.56 = zext i8 %conv2.i.i34.55 to i32
  %xor.i.i33.56 = xor i32 %conv1.i.i32.56, %conv.i.i31.56
  %conv2.i.i34.56 = trunc i32 %xor.i.i33.56 to i8
  %scevgep.57 = getelementptr i8, i8* %x, i64 57
  %238 = load i8, i8* %scevgep.57, align 1
  %conv.i.i31.57 = zext i8 %238 to i32
  %conv1.i.i32.57 = zext i8 %conv2.i.i34.56 to i32
  %xor.i.i33.57 = xor i32 %conv1.i.i32.57, %conv.i.i31.57
  %conv2.i.i34.57 = trunc i32 %xor.i.i33.57 to i8
  %scevgep.58 = getelementptr i8, i8* %x, i64 58
  %239 = load i8, i8* %scevgep.58, align 1
  %conv.i.i31.58 = zext i8 %239 to i32
  %conv1.i.i32.58 = zext i8 %conv2.i.i34.57 to i32
  %xor.i.i33.58 = xor i32 %conv1.i.i32.58, %conv.i.i31.58
  %conv2.i.i34.58 = trunc i32 %xor.i.i33.58 to i8
  %scevgep.59 = getelementptr i8, i8* %x, i64 59
  %240 = load i8, i8* %scevgep.59, align 1
  %conv.i.i31.59 = zext i8 %240 to i32
  %conv1.i.i32.59 = zext i8 %conv2.i.i34.58 to i32
  %xor.i.i33.59 = xor i32 %conv1.i.i32.59, %conv.i.i31.59
  %conv2.i.i34.59 = trunc i32 %xor.i.i33.59 to i8
  %scevgep.60 = getelementptr i8, i8* %x, i64 60
  %241 = load i8, i8* %scevgep.60, align 1
  %conv.i.i31.60 = zext i8 %241 to i32
  %conv1.i.i32.60 = zext i8 %conv2.i.i34.59 to i32
  %xor.i.i33.60 = xor i32 %conv1.i.i32.60, %conv.i.i31.60
  %conv2.i.i34.60 = trunc i32 %xor.i.i33.60 to i8
  %conv18 = zext i8 %conv2.i.i34.60 to i32
  %cmp19 = icmp eq i32 %conv16, %conv18
  call void @assert(i1 zeroext %cmp19)
  ret void
}

attributes #0 = { alwaysinline nounwind uwtable "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "min-legal-vector-width"="0" "no-infs-fp-math"="false" "no-jump-tables"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { "correctly-rounded-divide-sqrt-fp-math"="false" "disable-tail-calls"="false" "frame-pointer"="all" "less-precise-fpmad"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "no-signed-zeros-fp-math"="false" "no-trapping-math"="true" "stack-protector-buffer-size"="8" "target-cpu"="x86-64" "target-features"="+cx8,+fxsr,+mmx,+sse,+sse2,+x87" "unsafe-fp-math"="false" "use-soft-float"="false" }

!llvm.module.flags = !{!0}
!llvm.ident = !{!1}

!0 = !{i32 1, !"wchar_size", i32 4}
!1 = !{!"clang version 11.1.0 (https://github.com/llvm/llvm-project.git 7e99bddfeaab2713a8bb6ca538da25b66e6efc59)"}
